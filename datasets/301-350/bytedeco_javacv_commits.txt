File: platform/src/test/java/org/bytedeco/javacv/FrameFilterTest.java
Patch:
@@ -197,11 +197,11 @@ public void testFFmpegFrameFilterMultipleInputs() {
                     }
                     if (frame3.samples != null) {
                         d++;
-                        assertEquals(2, frame3.audioChannels);
+                        assertEquals(4, frame3.audioChannels);
                         assertEquals(1, frame3.samples.length);
-                        assertTrue(frame3.samples[0] instanceof ByteBuffer);
+                        assertTrue(frame3.samples[0] instanceof ShortBuffer);
                         assertEquals(frame2.samples.length, frame3.samples.length);
-                        assertEquals(frame2.samples[0].limit(), frame3.samples[0].limit());
+                        assertEquals(2 * frame2.samples[0].limit(), frame3.samples[0].limit());
                     }
                 }
             }

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -989,6 +989,7 @@ public synchronized void startUnsafe(boolean findStreamInfo) throws Exception {
                 throw new Exception("avformat_open_input() error " + ret + ": Could not open input \"" + filename + "\". (Has setFormat() been called?)");
             }
         }
+        FFmpegLogCallback.logRejectedOptions(options, "avformat_open_input");
         av_dict_free(options);
 
         oc.max_delay(maxDelay);
@@ -1072,6 +1073,7 @@ public synchronized void startUnsafe(boolean findStreamInfo) throws Exception {
             if ((ret = avcodec_open2(video_c, codec, options)) < 0) {
                 throw new Exception("avcodec_open2() error " + ret + ": Could not open video codec.");
             }
+            FFmpegLogCallback.logRejectedOptions(options, "avcodec_open2");
             av_dict_free(options);
 
             // Hack to correct wrong frame rates that seem to be generated by some codecs
@@ -1123,6 +1125,7 @@ public synchronized void startUnsafe(boolean findStreamInfo) throws Exception {
             if ((ret = avcodec_open2(audio_c, codec, options)) < 0) {
                 throw new Exception("avcodec_open2() error " + ret + ": Could not open audio codec.");
             }
+            FFmpegLogCallback.logRejectedOptions(options, "avcodec_open2");
             av_dict_free(options);
 
             // Allocate audio samples frame

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -286,7 +286,7 @@ public synchronized void releaseUnsafe() throws Exception {
                     avio = null;
                 }
                 if (oc != null) {
-                    avformat_free_context(oc);
+                    avformat_close_input(oc);
                     oc = null;
                 }
             }

File: src/main/java/org/bytedeco/javacv/FFmpegLogCallback.java
Patch:
@@ -41,7 +41,7 @@ public class FFmpegLogCallback extends LogCallback {
 
     static final FFmpegLogCallback instance = new FFmpegLogCallback().retainReference();
 
-    /** Returns an instance that can be used with {@link #setLogCallback(LogCallback)}. */
+    /** Returns an instance that can be used with {@link org.bytedeco.ffmpeg.global.avutil#setLogCallback(LogCallback)}. */
     public static FFmpegLogCallback getInstance() {
         return instance;
     }

File: src/main/java/org/bytedeco/javacv/Frame.java
Patch:
@@ -213,7 +213,7 @@ public <I extends Indexer> I createIndexer(boolean direct, int i) {
      * @return A deep copy of this frame.
      * @see {@link #cloneBufferArray}
      *
-     * @author Extension proposed by Dragos Dutu
+     * Extension proposed by Dragos Dutu
      * */
     @Override
     public Frame clone() {

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -1148,7 +1148,7 @@ private void initPictureRGB() {
                 int fmt = getPixelFormat();
 
                 // work around bug in swscale: https://trac.ffmpeg.org/ticket/1031
-                int align = 32;
+                int align = 64;
                 int stride = width;
                 for (int i = 1; i <= align; i += i) {
                      stride = (width + (i - 1)) & ~(i - 1);

File: src/main/java9/module-info.java
Patch:
@@ -13,7 +13,7 @@
     requires org.bytedeco.librealsense2;
     requires org.bytedeco.videoinput;
     requires org.bytedeco.artoolkitplus;
-    requires org.bytedeco.flandmark;
+//    requires org.bytedeco.flandmark;
     requires org.bytedeco.leptonica;
     requires org.bytedeco.tesseract;
 }

File: platform/src/test/java/org/bytedeco/javacv/FrameGrabberTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2016-2017 Samuel Audet
+ * Copyright (C) 2016-2023 Samuel Audet
  *
  * Licensed either under the Apache License, Version 2.0, or (at your option)
  * under the terms of the GNU General Public License as published by
@@ -318,6 +318,7 @@ public void testFFmpegFrameGrabberSeeking() throws IOException {
             recorder.setSampleFormat(AV_SAMPLE_FMT_FLTP);
             recorder.setAudioCodec(AV_CODEC_ID_AAC);
             recorder.setAudioQuality(0);
+            recorder.setDisplayRotation((seektestnum - 2) * 90.0);
             recorder.start();
             if (seektestnum!=2) {
                 Frame frame = new Frame(640, 480, Frame.DEPTH_UBYTE, 3);
@@ -361,6 +362,7 @@ public void testFFmpegFrameGrabberSeeking() throws IOException {
             FFmpegFrameGrabber grabber = new FFmpegFrameGrabber(tempFile);
             grabber.setVideoOption("threads", "1"); // more precise without threads
             grabber.start();
+            assertEquals((seektestnum - 2) * 90.0, grabber.getDisplayRotation(), 0);
             int length = (int) ( grabber.getLengthInTime() - 1000000L);
 
 

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -637,7 +637,7 @@ public synchronized void startUnsafe() throws Exception {
             }
 
             if ((video_codec.capabilities() & AV_CODEC_CAP_EXPERIMENTAL) != 0) {
-                video_c.strict_std_compliance(AVCodecContext.FF_COMPLIANCE_EXPERIMENTAL);
+                video_c.strict_std_compliance(FF_COMPLIANCE_EXPERIMENTAL);
             }
 
             if (maxBFrames >= 0) {
@@ -752,7 +752,7 @@ public synchronized void startUnsafe() throws Exception {
             }
 
             if ((audio_codec.capabilities() & AV_CODEC_CAP_EXPERIMENTAL) != 0) {
-                audio_c.strict_std_compliance(AVCodecContext.FF_COMPLIANCE_EXPERIMENTAL);
+                audio_c.strict_std_compliance(FF_COMPLIANCE_EXPERIMENTAL);
             }
         }
 

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -964,7 +964,7 @@ public void stop() throws Exception {
         record(frame, frame != null && frame.opaque instanceof AVFrame ? ((AVFrame)frame.opaque).format() : AV_PIX_FMT_NONE);
     }
     public synchronized void record(Frame frame, int pixelFormat) throws Exception {
-        if (frame == null || (frame.image == null && frame.samples == null)) {
+        if (frame == null || (frame.image == null && frame.samples == null && frame.data == null)) {
             recordImage(0, 0, 0, 0, 0, pixelFormat, (Buffer[])null);
         } else {
             if (frame.image != null) {

File: src/main/java/org/bytedeco/javacv/ProjectiveDevice.java
Patch:
@@ -737,8 +737,8 @@ public CvMat getRectifyingHomography(ProjectiveDevice peer, CvMat H) {
         CvMat R2 = R23x3.get(); CvMat P2 = P23x4.get();
         Size imageSize = new Size((peer.imageWidth  + imageWidth )/2,
                                   (peer.imageHeight + imageHeight)/2); // ?
-        stereoRectify(cvarrToMat(peer.cameraMatrix),     cvarrToMat(cameraMatrix),
-                      cvarrToMat(peer.distortionCoeffs), cvarrToMat(distortionCoeffs),
+        stereoRectify(cvarrToMat(peer.cameraMatrix), cvarrToMat(peer.distortionCoeffs),
+                      cvarrToMat(     cameraMatrix), cvarrToMat(     distortionCoeffs),
                       imageSize, cvarrToMat(relativeR), cvarrToMat(relativeT),
                       cvarrToMat(R1), cvarrToMat(R2), cvarrToMat(P1), cvarrToMat(P2),
                       new Mat(), 0, -1, new Size(), null, null);

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -1302,7 +1302,7 @@ private boolean record(AVFrame frame) throws Exception {
 
     private void writePacket(int mediaType, AVPacket avPacket) throws Exception {
 
-        AVStream avStream = (mediaType == AVMEDIA_TYPE_VIDEO) ? audio_st : (mediaType == AVMEDIA_TYPE_AUDIO) ? video_st : null;
+        AVStream avStream = (mediaType == AVMEDIA_TYPE_VIDEO) ? video_st : (mediaType == AVMEDIA_TYPE_AUDIO) ? audio_st : null;
         String mediaTypeStr = (mediaType == AVMEDIA_TYPE_VIDEO) ? "video" : (mediaType == AVMEDIA_TYPE_AUDIO) ? "audio" : "unsupported media stream type";
 
         synchronized (oc) {

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -1403,6 +1403,7 @@ public synchronized Frame grabFrame(boolean doAudio, boolean doVideo, boolean do
                         done = true;
                         frame.timestamp = timestamp;
                         frame.keyFrame = picture.key_frame() != 0;
+                        frame.pictType = (char)av_get_picture_type_char(picture.pict_type());
                     }
                 }
             } else if (doAudio && audio_st != null && pkt.stream_index() == audio_st.index()) {

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -1139,6 +1139,9 @@ private void processImage() throws Exception {
                     initPictureRGB();
                 }
 
+                // Copy "metadata" fields
+                av_frame_copy_props(picture_rgb, picture);
+
                 // Convert the image into BGR or GRAY format that OpenCV uses
                 img_convert_ctx = sws_getCachedContext(img_convert_ctx,
                         video_c.width(), video_c.height(), video_c.pix_fmt(),

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -1411,7 +1411,8 @@ public synchronized Frame grabFrame(boolean doAudio, boolean doVideo, boolean do
                 if (readPacket) {
                     ret = avcodec_send_packet(audio_c, pkt);
                     if (ret < 0) {
-                        throw new Exception("avcodec_send_packet() error " + ret + ": Error sending an audio packet for decoding.");
+                        // Ignore errors to emulate the behavior of the old API
+                        // throw new Exception("avcodec_send_packet() error " + ret + ": Error sending an audio packet for decoding.");
                     }
                 }
 

File: platform/src/test/java/org/bytedeco/javacv/FrameGrabberTest.java
Patch:
@@ -136,6 +136,7 @@ public void testFFmpegFrameGrabber() {
                 frames[n].close();
             }
         } catch (Exception e) {
+            e.printStackTrace();
             fail("Exception should not have been thrown: " + e);
         } finally {
             tempFile.delete();
@@ -238,6 +239,7 @@ public void run() {
                         }
                     } catch (Error | Exception e) {
                         failed[0] = true;
+                        e.printStackTrace();
                         fail("Exception should not have been thrown: " + e);
                     } finally {
                         tempFile.delete();

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -927,16 +927,16 @@ public synchronized void flush() throws Exception {
             } else {
                 av_write_frame(oc, null);
             }
-
-            /* write the trailer, if any */
-            av_write_trailer(oc);
         }
     }
 
     public void stop() throws Exception {
         if (oc != null) {
             try {
                 flush();
+
+                /* write the trailer, if any */
+                av_write_trailer(oc);
             } finally {
                 release();
             }

File: platform/src/test/java/org/bytedeco/javacv/FrameFilterTest.java
Patch:
@@ -129,6 +129,7 @@ public void testFFmpegFrameFilter() {
             grabber.restart();
             grabber.stop();
             grabber.release();
+            frame.close();
         } catch (Exception e) {
             e.printStackTrace();
             fail("Exception should not have been thrown: " + e);
@@ -215,6 +216,7 @@ public void testFFmpegFrameFilterMultipleInputs() {
             grabber.restart();
             grabber.stop();
             grabber.release();
+            frame.close();
         } catch (Exception e) {
             e.printStackTrace();
             fail("Exception should not have been thrown: " + e);

File: platform/src/test/java/org/bytedeco/javacv/FrameGrabberChangingResolutionTest.java
Patch:
@@ -72,6 +72,9 @@ private void makeTestfile() throws Exception {
         }
         recorder.stop();
         recorder.release();
+        for (int n = 0; n < frames.length; n++) {
+            frames[n].close();
+        }
     }
 
     final public void setupUDPSender(final int x, final int y, final int bandwidth, final int count) throws IOException {

File: platform/src/test/java/org/bytedeco/javacv/SeekableByteArrayOutputStreamTest.java
Patch:
@@ -80,6 +80,7 @@ private void createVideo(FFmpegFrameRecorder recorder) throws Exception {
                 }
             }
             recorder.record(frame);
+            frame.close();
         }
         recorder.close();
     }

File: src/main/java/org/bytedeco/javacv/Java2DFrameConverter.java
Patch:
@@ -728,6 +728,9 @@ public Frame getFrame(BufferedImage image, double gamma, boolean flipChannels) {
         }
         if (frame == null || frame.imageWidth != image.getWidth() || frame.imageHeight != image.getHeight()
                 || frame.imageDepth != depth || frame.imageChannels != numChannels) {
+            if (frame != null) {
+                frame.close();
+            }
             frame = new Frame(image.getWidth(), image.getHeight(), depth, numChannels);
         }
         copy(image, frame, gamma, flipChannels, null);

File: src/main/java/org/bytedeco/javacv/Java2DFrameUtils.java
Patch:
@@ -17,8 +17,8 @@
  *
  * All created Frame, Mat, IplImages and BufferedImages are cloned internally
  * after creation so that their memory locations remain valid after the
- * converters which created them are garbage collected. This is safer for the
- * called, but may be slower.
+ * converters which created them are closed or garbage collected. This is safer
+ * for the caller, but may be slower.
  *
  * If performance is critical, use the *FrameConverter classes directly, after
  * reading about the image validity constraints (eg, images data is only valid

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -184,7 +184,9 @@ public synchronized void releaseUnsafe() throws Exception {
         // Free the RGB image
         if (image_ptr != null) {
             for (int i = 0; i < image_ptr.length; i++) {
-                av_free(image_ptr[i]);
+                if (imageMode != ImageMode.RAW) {
+                    av_free(image_ptr[i]);
+                }
             }
             image_ptr = null;
         }

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -1047,7 +1047,8 @@ public synchronized boolean recordImage(int width, int height, int depth, int ch
             video_pkt.data(video_outbuf);
             video_pkt.size(video_outbuf_size);
             picture.quality(video_c.global_quality());
-            if ((ret = avcodec_encode_video2(video_c, video_pkt, image == null || image.length == 0 ? null : picture, got_video_packet)) < 0) {
+            if ((ret = avcodec_encode_video2(video_c, video_pkt, image == null || image.length == 0 ? null : picture, got_video_packet)) < 0
+                    && image != null && image.length != 0) {
                 throw new Exception("avcodec_encode_video2() error " + ret + ": Could not encode video packet.");
             }
             picture.pts(picture.pts() + 1); // magic required by libx264

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -479,7 +479,7 @@ public synchronized void startUnsafe() throws Exception {
                     inpVideoStream = inputStream;
                     videoCodec = inpVideoStream.codec().codec_id();
                     if (inpVideoStream.r_frame_rate().num() != AV_NOPTS_VALUE && inpVideoStream.r_frame_rate().den() != 0) {
-                        frameRate = (inpVideoStream.r_frame_rate().num()) / (inpVideoStream.r_frame_rate().den());
+                        frameRate = (inpVideoStream.r_frame_rate().num())*1.0d / (inpVideoStream.r_frame_rate().den());
                     }
 
                 } else if (inputStream.codec().codec_type() == AVMEDIA_TYPE_AUDIO) {
@@ -536,7 +536,7 @@ public synchronized void startUnsafe() throws Exception {
 
                 videoBitrate = (int) inpVideoStream.codec().bit_rate();
                 pixelFormat = inpVideoStream.codec().pix_fmt();
-                aspectRatio = inpVideoStream.codec().sample_aspect_ratio().den() / inpVideoStream.codec().sample_aspect_ratio().den() * 1.d;
+                aspectRatio = inpVideoStream.codec().sample_aspect_ratio().num()*1.0d/ inpVideoStream.codec().sample_aspect_ratio().den();
                 videoQuality = inpVideoStream.codec().global_quality();
                 video_c.codec_tag(0);
             }

File: platform/src/main/java9/module-info.java
Patch:
@@ -7,6 +7,7 @@
     requires org.bytedeco.libfreenect.platform;
     requires org.bytedeco.libfreenect2.platform;
     requires org.bytedeco.librealsense.platform;
+    requires org.bytedeco.librealsense2.platform;
     requires org.bytedeco.videoinput.platform;
     requires org.bytedeco.artoolkitplus.platform;
     requires org.bytedeco.flandmark.platform;

File: src/main/java9/module-info.java
Patch:
@@ -10,6 +10,7 @@
     requires org.bytedeco.libfreenect;
     requires org.bytedeco.libfreenect2;
     requires org.bytedeco.librealsense;
+    requires org.bytedeco.librealsense2;
     requires org.bytedeco.videoinput;
     requires org.bytedeco.artoolkitplus;
     requires org.bytedeco.flandmark;

File: src/main/java/org/bytedeco/javacv/FFmpegFrameFilter.java
Patch:
@@ -679,7 +679,9 @@ public synchronized void pushSamples(int n, int audioChannels, int sampleRate, i
         if (f == null && abuffersrc_ctx != null) {
             f = pullSamples();
         }
-        if (f == null && buffersrc_ctx == null && abuffersrc_ctx == null) {
+        if (f == null && inframe != null
+                && ((inframe.image != null && buffersrc_ctx == null)
+                || (inframe.samples != null && abuffersrc_ctx == null))) {
             f = inframe;
         }
         inframe = null;

File: src/main/java/org/bytedeco/javacv/OpenCVFrameConverter.java
Patch:
@@ -184,7 +184,8 @@ public org.opencv.core.Mat convertToOrgOpenCvCoreMat(Frame frame) {
             int depth = getMatDepth(frame.imageDepth);
             orgOpenCvCoreMat = depth < 0 ? null : new org.opencv.core.Mat(frame.imageHeight, frame.imageWidth,
                     CV_MAKETYPE(depth, frame.imageChannels), new BytePointer(new Pointer(frame.image[0].position(0)))
-                            .capacity(frame.image[0].capacity() * Math.abs(frame.imageDepth) / 8).asByteBuffer());
+                            .capacity(frame.image[0].capacity() * Math.abs(frame.imageDepth) / 8).asByteBuffer(),
+                    frame.imageStride * Math.abs(frame.imageDepth) / 8);
         }
         return orgOpenCvCoreMat;
     }

File: src/main/java/org/bytedeco/javacv/FFmpegFrameFilter.java
Patch:
@@ -54,6 +54,7 @@
 import java.nio.FloatBuffer;
 import java.nio.IntBuffer;
 import java.nio.ShortBuffer;
+import java.util.*;
 import org.bytedeco.javacpp.BytePointer;
 import org.bytedeco.javacpp.DoublePointer;
 import org.bytedeco.javacpp.FloatPointer;
@@ -303,8 +304,7 @@ private void startVideoUnsafe() throws Exception {
 
             /* buffer video source: the decoded frames from the decoder will be inserted here. */
             AVRational r = av_d2q(aspectRatio > 0 ? aspectRatio : 1, 255);
-            String args = String.format(
-                    "video_size=%dx%d:pix_fmt=%d:time_base=%d/%d:pixel_aspect=%d/%d",
+            String args = String.format(Locale.ROOT, "video_size=%dx%d:pix_fmt=%d:time_base=%d/%d:pixel_aspect=%d/%d",
                     imageWidth, imageHeight, pixelFormat, time_base.num(), time_base.den(), r.num(), r.den());
             buffersrc_ctx = new AVFilterContext[videoInputs];
             setpts_ctx = new AVFilterContext[videoInputs];
@@ -408,7 +408,7 @@ private void startAudioUnsafe() throws Exception {
                 aoutputs[i] = avfilter_inout_alloc();
 
                 /* buffer audio source: the decoded frames from the decoder will be inserted here. */
-                String aargs = String.format("channels=%d:sample_fmt=%d:sample_rate=%d:channel_layout=%d",
+                String aargs = String.format(Locale.ROOT, "channels=%d:sample_fmt=%d:sample_rate=%d:channel_layout=%d",
                         audioChannels, sampleFormat, sampleRate, av_get_default_channel_layout(audioChannels));
                 ret = avfilter_graph_create_filter(abuffersrc_ctx[i] = new AVFilterContext(), abuffersrc, name,
                                                    aargs, null, afilter_graph);

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -903,7 +903,7 @@ public void flush() throws Exception {
             while (video_st != null && ifmt_ctx == null && recordImage(0, 0, 0, 0, 0, AV_PIX_FMT_NONE, (Buffer[])null));
             while (audio_st != null && ifmt_ctx == null && recordSamples(0, 0, (Buffer[])null));
 
-            if (interleaved && video_st != null && audio_st != null) {
+            if (interleaved && (video_st != null || audio_st != null)) {
                 av_interleaved_write_frame(oc, null);
             } else {
                 av_write_frame(oc, null);

File: src/main/java/org/bytedeco/javacv/FFmpegFrameFilter.java
Patch:
@@ -484,13 +484,13 @@ public void stop() throws Exception {
     }
 
     @Override public void push(Frame frame) throws Exception {
-        push(frame, frame.opaque instanceof AVFrame ? ((AVFrame)frame.opaque).format() : AV_PIX_FMT_NONE);
+        push(frame, frame != null && frame.opaque instanceof AVFrame ? ((AVFrame)frame.opaque).format() : AV_PIX_FMT_NONE);
     }
     public void push(Frame frame, int pixelFormat) throws Exception {
         push(0, frame, pixelFormat);
     }
     public void push(int n, Frame frame) throws Exception {
-        push(n, frame, frame.opaque instanceof AVFrame ? ((AVFrame)frame.opaque).format() : AV_PIX_FMT_NONE);
+        push(n, frame, frame != null && frame.opaque instanceof AVFrame ? ((AVFrame)frame.opaque).format() : AV_PIX_FMT_NONE);
     }
     public void push(int n, Frame frame, int pixelFormat) throws Exception {
         inframe = frame;

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -833,7 +833,7 @@ public void startUnsafe() throws Exception {
             }
             inputStream.mark(maximumSize);
             oc = avformat_alloc_context();
-            avio = avio_alloc_context(new BytePointer(av_malloc(4096)), 4096, 0, oc, readCallback, null, seekCallback);
+            avio = avio_alloc_context(new BytePointer(av_malloc(4096)), 4096, 0, oc, readCallback, null, maximumSize > 0 ? seekCallback : null);
             oc.pb(avio);
 
             filename = inputStream.toString();

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -1171,7 +1171,8 @@ private void writeSamples(int nb_samples) throws Exception {
         for (int i = 0; i < samples_out.length; i++) {
             int linesize = 0;
             if (samples_out[0].position() > 0 && samples_out[0].position() < samples_out[0].limit()) {
-                linesize = (int)samples_out[i].position();
+                // align the end of the buffer to a 32-byte boundary as sometimes required by FFmpeg
+                linesize = ((int)samples_out[i].position() + 31) & ~31;
             } else {
                 linesize = (int)Math.min(samples_out[i].limit(), Integer.MAX_VALUE);
             }

File: src/main/java/org/bytedeco/javacv/IPCameraFrameGrabber.java
Patch:
@@ -63,7 +63,7 @@ public static void tryLoad() throws Exception {
         }
     }
 
-    private final FrameConverter converter = new OpenCVFrameConverter.ToIplImage();
+    private final FrameConverter converter = new OpenCVFrameConverter.ToMat();
     private final URL url;
     private final int connectionTimeout;
     private final int readTimeout;

File: src/main/java9/module-info.java
Patch:
@@ -1,5 +1,6 @@
 module org.bytedeco.javacv {
     exports org.bytedeco.javacv;
+    requires java.desktop;
     requires javafx.graphics;
     requires transitive org.bytedeco.javacpp;
     requires org.bytedeco.opencv;

File: platform/src/test/java/org/bytedeco/javacv/FrameFilterTest.java
Patch:
@@ -81,6 +81,8 @@ public void testFFmpegFrameFilter() {
                     grabber.getImageWidth(), grabber.getImageHeight(), grabber.getAudioChannels());
             filter.setPixelFormat(grabber.getPixelFormat());
             filter.setSampleFormat(grabber.getSampleFormat());
+            filter.setFrameRate(grabber.getFrameRate());
+            filter.setSampleRate(grabber.getSampleRate());
             filter.start();
 
             FFmpegFrameFilter nullFilter = new FFmpegFrameFilter(null, null, 0, 0, 0);
@@ -112,6 +114,7 @@ public void testFFmpegFrameFilter() {
                         assertEquals(frame2.samples.length, frame3.samples.length);
                         assertEquals(frame2.samples[0].limit() / 2, frame3.samples[0].limit());
                     }
+                    assertEquals(frame2.timestamp, frame3.timestamp);
                 }
                 nullFilter.push(frame2);
                 assertEquals(frame2, nullFilter.pull());

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -369,7 +369,7 @@ public void setCloseOutputStream(boolean closeOutputStream) {
         if (picture == null) { super.setFrameNumber(frameNumber); } else { picture.pts(frameNumber); }
     }
 
-    // best guess for timestamp in microseconds...
+    /** best guess for timestamp in microseconds... */
     @Override public long getTimestamp() {
         return Math.round(getFrameNumber() * 1000000L / getFrameRate());
     }

File: src/main/java/org/bytedeco/javacv/Frame.java
Patch:
@@ -97,7 +97,7 @@ public static enum Type {
     /** The underlying data object, for example, Pointer, AVFrame, IplImage, or Mat. */
     public Object opaque;
 
-    /** Timestamp of the frame creation. */
+    /** Timestamp of the frame creation in microseconds. */
     public long timestamp;
 
     /** Returns {@code Math.abs(depth) / 8}. */

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2009-2018 Samuel Audet
+ * Copyright (C) 2009-2019 Samuel Audet
  *
  * Licensed either under the Apache License, Version 2.0, or (at your option)
  * under the terms of the GNU General Public License as published by
@@ -897,7 +897,7 @@ public void stop() throws Exception {
     }
 
     @Override public void record(Frame frame) throws Exception {
-        record(frame, AV_PIX_FMT_NONE);
+        record(frame, frame.opaque instanceof AVFrame ? ((AVFrame)frame.opaque).format() : AV_PIX_FMT_NONE);
     }
     public void record(Frame frame, int pixelFormat) throws Exception {
         if (frame == null || (frame.image == null && frame.samples == null)) {

File: platform/src/test/java/org/bytedeco/javacv/FrameGrabberTest.java
Patch:
@@ -336,6 +336,7 @@ public void testFFmpegFrameGrabberSeeking() throws IOException {
             recorder.release();
 
             FFmpegFrameGrabber grabber = new FFmpegFrameGrabber(tempFile);
+            grabber.setVideoOption("threads", "1"); // more precise without threads
             grabber.start();
             int length = (int) ( grabber.getLengthInTime() - 1000000L);
 

File: platform/src/test/java/org/bytedeco/javacv/FrameGrabberTest.java
Patch:
@@ -163,7 +163,7 @@ public void run() {
                         recorder.setSampleFormat(AV_SAMPLE_FMT_S16);
                         recorder.setSampleRate(44100);
                         recorder.setAudioCodecName("pcm_s16le");
-                        recorder.start();
+                        recorder.startUnsafe();
 
                         Frame[] frames = new Frame[10];
                         for (int n = 0; n < frames.length; n++) {
@@ -195,7 +195,7 @@ public void run() {
 
                         FFmpegFrameGrabber grabber = new FFmpegFrameGrabber(new FileInputStream(tempFile));
                         grabber.setSampleMode(FrameGrabber.SampleMode.FLOAT);
-                        grabber.start();
+                        grabber.startUnsafe();
 
                         int n = 0, m = 0;
                         Frame frame2;

File: src/main/java/org/bytedeco/javacv/FrameRecorder.java
Patch:
@@ -390,6 +390,7 @@ public static class Exception extends IOException {
     }
 
     public abstract void start() throws Exception;
+    public abstract void flush() throws Exception;
     public abstract void stop() throws Exception;
     public abstract void record(Frame frame) throws Exception;
     public abstract void release() throws Exception;

File: src/main/java/org/bytedeco/javacv/OpenCVFrameRecorder.java
Patch:
@@ -98,6 +98,9 @@ private int fourCCCodec() {
         return videoCodec;
     }
 
+    public void flush() throws Exception {
+    }
+
     public void stop() throws Exception {
         release();
     }

File: platform/src/test/java/org/bytedeco/javacv/FrameConverterTest.java
Patch:
@@ -320,13 +320,13 @@ public class FrameConverterTest {
 
         converter.frame = null;
         Frame frame1 = converter.convert(pix);
-        assertEquals(frame1.opaque, pix);
+//        assertEquals(frame1.opaque, pix);
 
         PIX pix2 = PIX.createHeader(pix.w(), pix.h(), pix.d()).data(pix.data()).wpl(pix.wpl());
         assertNotEquals(pix, pix2);
 
         Frame frame2 = converter.convert(pix2);
-        assertEquals(frame2.opaque, pix2);
+//        assertEquals(frame2.opaque, pix2);
 
         IntBuffer frameBuf = ((ByteBuffer)frame.image[0].position(0)).asIntBuffer();
         IntBuffer frame1Buf = ((ByteBuffer)frame1.image[0].position(0)).asIntBuffer();

File: src/main/java/org/bytedeco/javacv/AndroidFrameConverter.java
Patch:
@@ -110,9 +110,10 @@ public Frame convert(byte[] data, int width, int height) {
             default: assert false;
         }
 
-        if (frame == null || frame.imageWidth != bitmap.getWidth()
+        if (frame == null || frame.imageWidth != bitmap.getWidth() || frame.imageStride != bitmap.getRowBytes()
                 || frame.imageHeight != bitmap.getHeight() || frame.imageChannels != channels) {
             frame = new Frame(bitmap.getWidth(), bitmap.getHeight(), Frame.DEPTH_UBYTE, channels);
+            frame.imageStride = bitmap.getRowBytes();
         }
 
         // assume matching strides

File: src/main/java/org/bytedeco/javacv/LeptonicaFrameConverter.java
Patch:
@@ -26,6 +26,7 @@
 import java.nio.ByteBuffer;
 import java.nio.ByteOrder;
 import org.bytedeco.javacpp.IntPointer;
+import org.bytedeco.javacpp.Loader;
 import org.bytedeco.javacpp.Pointer;
 
 import static org.bytedeco.javacpp.lept.*;
@@ -38,6 +39,8 @@
  * @author Samuel Audet
  */
 public class LeptonicaFrameConverter extends FrameConverter<PIX> {
+    static { Loader.load(org.bytedeco.javacpp.lept.class); }
+
     PIX pix;
     ByteBuffer frameBuffer, pixBuffer;
 

File: src/main/java/org/bytedeco/javacv/OpenCVFrameConverter.java
Patch:
@@ -25,6 +25,7 @@
 import java.nio.Buffer;
 import java.nio.ByteBuffer;
 import org.bytedeco.javacpp.BytePointer;
+import org.bytedeco.javacpp.Loader;
 import org.bytedeco.javacpp.Pointer;
 
 import static org.bytedeco.javacpp.opencv_core.*;
@@ -38,6 +39,8 @@
  * @author Samuel Audet
  */
 public abstract class OpenCVFrameConverter<F> extends FrameConverter<F> {
+    static { Loader.load(org.bytedeco.javacpp.opencv_core.class); }
+
     IplImage img;
     Mat mat;
     org.opencv.core.Mat orgOpenCvCoreMat;

File: samples/CaffeGooglenet.java
Patch:
@@ -84,7 +84,7 @@ public static void main(String[] args) throws Exception {
         //! [Prepare blob]
 
         //! [Set input blob]
-        net.setInput(inputBlob, "data");      //set the network input
+        net.setInput(inputBlob, "data", 1.0, null);      //set the network input
         //! [Set input blob]
 
         //! [Make forward pass]

File: samples/Demo.java
Patch:
@@ -37,8 +37,7 @@ public static void main(String[] args) throws Exception {
             classifierName = args[0];
         } else {
             URL url = new URL("https://raw.github.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt.xml");
-            File file = Loader.extractResource(url, null, "classifier", ".xml");
-            file.deleteOnExit();
+            File file = Loader.cacheResource(url);
             classifierName = file.getAbsolutePath();
         }
 

File: samples/OpenCVFaceRecognizer.java
Patch:
@@ -5,7 +5,7 @@
 import static org.bytedeco.javacpp.opencv_core.CV_32SC1;
 import static org.bytedeco.javacpp.opencv_core.CV_8UC1;
 import static org.bytedeco.javacpp.opencv_imgcodecs.imread;
-import static org.bytedeco.javacpp.opencv_imgcodecs.CV_LOAD_IMAGE_GRAYSCALE;
+import static org.bytedeco.javacpp.opencv_imgcodecs.IMREAD_GRAYSCALE;
 
 import org.bytedeco.javacpp.BytePointer;
 import org.bytedeco.javacpp.IntPointer;
@@ -45,7 +45,7 @@
 public class OpenCVFaceRecognizer {
     public static void main(String[] args) {
         String trainingDir = args[0];
-        Mat testImage = imread(args[1], CV_LOAD_IMAGE_GRAYSCALE);
+        Mat testImage = imread(args[1], IMREAD_GRAYSCALE);
 
         File root = new File(trainingDir);
 
@@ -66,7 +66,7 @@ public boolean accept(File dir, String name) {
         int counter = 0;
 
         for (File image : imageFiles) {
-            Mat img = imread(image.getAbsolutePath(), CV_LOAD_IMAGE_GRAYSCALE);
+            Mat img = imread(image.getAbsolutePath(), IMREAD_GRAYSCALE);
 
             int label = Integer.parseInt(image.getName().split("\\-")[0]);
 

File: samples/TemplateMatching.java
Patch:
@@ -39,7 +39,7 @@ public static void newStyle(String[] args){
         Mat sourceGrey = new Mat(sourceColor.size(), CV_8UC1);
        cvtColor(sourceColor, sourceGrey, COLOR_BGR2GRAY);
        //load in template in grey 
-       Mat template = imread(args[1],CV_LOAD_IMAGE_GRAYSCALE);//int = 0
+       Mat template = imread(args[1],IMREAD_GRAYSCALE);//int = 0
        //Size for the result image
        Size size = new Size(sourceGrey.cols()-template.cols()+1, sourceGrey.rows()-template.rows()+1);
        Mat result = new Mat(size, CV_32FC1);
@@ -134,4 +134,4 @@ public static void oldStyle(String[] args){
         cvReleaseImage(tmp);
         cvReleaseImage(result);
     }
-}
\ No newline at end of file
+}

File: src/main/java/org/bytedeco/javacv/OpenCVFrameConverter.java
Patch:
@@ -96,8 +96,7 @@ public IplImage convertToIplImage(Frame frame) {
             return (IplImage)frame.opaque;
         } else if (!isEqual(frame, img)) {
             int depth = getIplImageDepth(frame.imageDepth);
-            img = depth < 0 ? null : IplImage.createHeader(frame.imageWidth, frame.imageHeight, depth, frame.imageChannels)
-                    .imageData(new BytePointer(new Pointer(frame.image[0].position(0))))
+            img = depth < 0 ? null : IplImage.create(frame.imageWidth, frame.imageHeight, depth, frame.imageChannels, new Pointer(frame.image[0].position(0)))
                     .widthStep(frame.imageStride * Math.abs(frame.imageDepth) / 8)
                     .imageSize(frame.image[0].capacity() * Math.abs(frame.imageDepth) / 8);
         }

File: src/main/java/org/bytedeco/javacv/JavaCV.java
Patch:
@@ -992,7 +992,7 @@ public static void main(String[] args) {
         }
         System.out.println(
             "JavaCV version " + version + "\n" +
-            "Copyright (C) 2009-2016 Samuel Audet <samuel.audet@gmail.com>\n" +
+            "Copyright (C) 2009-2018 Samuel Audet <samuel.audet@gmail.com>\n" +
             "Project site: https://github.com/bytedeco/javacv");
         System.exit(0);
     }

File: src/main/java/org/bytedeco/javacv/OpenCVFrameConverter.java
Patch:
@@ -32,7 +32,8 @@
 /**
  * A utility class to map data between {@link Frame} and {@link IplImage} or {@link Mat}.
  * Since this is an abstract class, one must choose between two concrete classes:
- * {@link ToIplImage} or {@link ToMat}.
+ * {@link ToIplImage} or {@link ToMat}. {@link ToOrgOpenCvCoreMat} is also available to
+ * do the same with {@link org.opencv.core.Mat} from the official Java API of OpenCV.
  *
  * @author Samuel Audet
  */

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2009-2017 Samuel Audet
+ * Copyright (C) 2009-2018 Samuel Audet
  *
  * Licensed either under the Apache License, Version 2.0, or (at your option)
  * under the terms of the GNU General Public License as published by
@@ -967,7 +967,8 @@ private void processImage() throws Exception {
                 // Convert the image into BGR or GRAY format that OpenCV uses
                 img_convert_ctx = sws_getCachedContext(img_convert_ctx,
                         video_c.width(), video_c.height(), video_c.pix_fmt(),
-                        frame.imageWidth, frame.imageHeight, getPixelFormat(), SWS_BILINEAR,
+                        frame.imageWidth, frame.imageHeight, getPixelFormat(),
+                        imageScalingFlags != 0 ? imageScalingFlags : SWS_BILINEAR,
                         null, null, (DoublePointer)null);
                 if (img_convert_ctx == null) {
                     throw new Exception("sws_getCachedContext() error: Cannot initialize the conversion context.");

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2009-2017 Samuel Audet
+ * Copyright (C) 2009-2018 Samuel Audet
  *
  * Licensed either under the Apache License, Version 2.0, or (at your option)
  * under the terms of the GNU General Public License as published by
@@ -919,7 +919,8 @@ public boolean recordImage(int width, int height, int depth, int channels, int s
             if (video_c.pix_fmt() != pixelFormat || video_c.width() != width || video_c.height() != height) {
                 /* convert to the codec pixel format if needed */
                 img_convert_ctx = sws_getCachedContext(img_convert_ctx, width, height, pixelFormat,
-                        video_c.width(), video_c.height(), video_c.pix_fmt(), SWS_BILINEAR,
+                        video_c.width(), video_c.height(), video_c.pix_fmt(),
+                        imageScalingFlags != 0 ? imageScalingFlags : SWS_BILINEAR,
                         null, null, (DoublePointer)null);
                 if (img_convert_ctx == null) {
                     throw new Exception("sws_getCachedContext() error: Cannot initialize the conversion context.");

File: src/main/java/org/bytedeco/javacv/FFmpegFrameFilter.java
Patch:
@@ -61,6 +61,7 @@
 import org.bytedeco.javacpp.Loader;
 import org.bytedeco.javacpp.Pointer;
 import org.bytedeco.javacpp.PointerPointer;
+import org.bytedeco.javacpp.PointerScope;
 import org.bytedeco.javacpp.ShortPointer;
 
 import static org.bytedeco.javacpp.avcodec.*;

File: src/main/java/org/bytedeco/javacv/OpenCVFrameConverter.java
Patch:
@@ -106,8 +106,8 @@ public Frame convert(IplImage img) {
             frame.imageChannels = img.nChannels();
             frame.imageStride = img.widthStep() * 8 / Math.abs(frame.imageDepth);
             frame.image = new Buffer[] { img.createBuffer() };
-            frame.opaque = img;
         }
+        frame.opaque = img;
         return frame;
     }
 

File: samples/RecordActivity.java
Patch:
@@ -111,7 +111,7 @@ public class RecordActivity extends Activity implements OnClickListener {
     private boolean isPreviewOn = false;
 
     /*Filter information, change boolean to true if adding a fitler*/
-    private boolean addFilter = false;
+    private boolean addFilter = true;
     private String filterString = "";
     FFmpegFrameFilter filter;
 
@@ -145,7 +145,7 @@ public class RecordActivity extends Activity implements OnClickListener {
     private Button btnRecorderControl;
 
     /* The number of seconds in the continuous record loop (or 0 to disable loop). */
-    final int RECORD_LENGTH = 10;
+    final int RECORD_LENGTH = 0;
     Frame[] images;
     long[] timestamps;
     ShortBuffer[] samples;
@@ -562,7 +562,7 @@ public void onPreviewFrame(byte[] data, Camera camera) {
                         filter.push(yuvImage);
                         Frame frame2;
                         while ((frame2 = filter.pull()) != null) {
-                            recorder.record(frame2);
+                            recorder.record(frame2, filter.getPixelFormat());
                         }
                     } else {
                         recorder.record(yuvImage);

File: src/main/java/org/bytedeco/javacv/FFmpegFrameFilter.java
Patch:
@@ -567,7 +567,7 @@ public Frame pullImage() throws Exception {
 
         /* pull a filtered frame from the filtergraph */
         int ret = av_buffersink_get_frame(buffersink_ctx, filt_frame);
-        if (ret == -11 /*AVERROR(EAGAIN)*/ || ret == AVERROR_EOF) {
+        if (ret == AVERROR_EAGAIN() || ret == AVERROR_EOF()) {
             return null;
         } else if (ret < 0) {
             throw new Exception("av_buffersink_get_frame(): Error occurred: "
@@ -607,7 +607,7 @@ public Frame pullSamples() throws Exception {
 
         /* pull a filtered frame from the filtergraph */
         int ret = av_buffersink_get_frame(abuffersink_ctx, filt_frame);
-        if (ret == -11 /*AVERROR(EAGAIN)*/ || ret == AVERROR_EOF) {
+        if (ret == AVERROR_EAGAIN() || ret == AVERROR_EOF()) {
             return null;
         } else if (ret < 0) {
             throw new Exception("av_buffersink_get_frame(): Error occurred: "

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -983,7 +983,7 @@ public boolean recordSamples(int sampleRate, int audioChannels, Buffer ... sampl
             throw new Exception("No audio output stream (Is audioChannels > 0 and has start() been called?)");
         }
 
-        if (samples == null) {
+        if (samples == null && samples_out[0].position() > 0) {
             // Typically samples_out[0].limit() is double the audio_input_frame_size --> sampleDivisor = 2
             double sampleDivisor = Math.floor((int)Math.min(samples_out[0].limit(), Integer.MAX_VALUE) / audio_input_frame_size);
             writeSamples((int)Math.floor((int)samples_out[0].position() / sampleDivisor));

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -910,6 +910,7 @@ public Frame grabFrame(boolean doAudio, boolean doVideo, boolean doProcessing, b
         }
         boolean videoFrameGrabbed = frameGrabbed && frame.image != null;
         boolean audioFrameGrabbed = frameGrabbed && frame.samples != null;
+        frameGrabbed = false;
         frame.keyFrame = false;
         frame.imageWidth = 0;
         frame.imageHeight = 0;
@@ -936,7 +937,6 @@ public Frame grabFrame(boolean doAudio, boolean doVideo, boolean doProcessing, b
             frame.opaque = samples_frame;
             return frame;
         }
-        frameGrabbed = false;
         boolean done = false;
         while (!done) {
             if (pkt2.size() <= 0) {

File: samples/FaceRecognizerInVideo.java
Patch:
@@ -35,8 +35,8 @@ public static void main(String[] args) throws Exception {
 
         CascadeClassifier face_cascade = new CascadeClassifier(
                 "data\\haarcascade_frontalface_default.xml");
-        FaceRecognizer lbphFaceRecognizer = createLBPHFaceRecognizer();
-        lbphFaceRecognizer.load(trainedResult);
+        FaceRecognizer lbphFaceRecognizer = LBPHFaceRecognizer.create();
+        lbphFaceRecognizer.read(trainedResult);
 
         File f = new File(videoFileName);
 

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -476,11 +476,11 @@ static class SeekCallback extends Seek_Pointer_long_int {
                (or vice versa)
             */
             int count = 0; // prevent infinite loops with corrupted files
-            while (this.timestamp > timestamp + 1 && grabFrame(false, true, false, false) != null && count++ < 1000) {
+            while (this.timestamp > timestamp + 1 && grabFrame(true, true, false, false) != null && count++ < 1000) {
                 // flush frames if seeking backwards
             }
             count = 0;
-            while (this.timestamp < timestamp - 1 && grabFrame(false, true, false, false) != null && count++ < 1000) {
+            while (this.timestamp < timestamp - 1 && grabFrame(true, true, false, false) != null && count++ < 1000) {
                 // decode up to the desired frame
             }
             if (video_c != null) {

File: samples/CaffeGooglenet.java
Patch:
@@ -87,7 +87,7 @@ public static void main(String[] args) throws Exception {
         }
 
         resize(img, img, new Size(224, 224)); //GoogLeNet accepts only 224x224 RGB-images
-        Blob inputBlob = new Blob(img);       //Convert Mat to dnn::Blob image batch
+        Blob inputBlob = Blob.fromImages(img);//Convert Mat to 4-dimensional dnn::Blob from image
         //! [Prepare blob]
 
         //! [Set input blob]

File: src/main/java/org/bytedeco/javacv/OpenCVFrameConverter.java
Patch:
@@ -153,8 +153,8 @@ public Frame convert(Mat mat) {
             frame.imageChannels = mat.channels();
             frame.imageStride = (int)mat.step() * 8 / Math.abs(frame.imageDepth);
             frame.image = new Buffer[] { mat.createBuffer() };
-            frame.opaque = mat;
         }
+        frame.opaque = mat;
         return frame;
     }
 }

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -226,6 +226,7 @@ void releaseUnsafe() throws Exception {
         audio_st = null;
         filename = null;
 
+        AVFormatContext outputStreamKey = oc;
         if (oc != null && !oc.isNull()) {
             if (outputStream == null && (oformat.flags() & AVFMT_NOFILE) == 0) {
                 /* close the output file */
@@ -267,7 +268,7 @@ void releaseUnsafe() throws Exception {
                 throw new Exception("Error on OutputStream.close(): ", ex);
             } finally {
                 outputStream = null;
-                outputStreams.remove(oc);
+                outputStreams.remove(outputStreamKey);
                 if (avio != null) {
                     if (avio.buffer() != null) {
                         av_free(avio.buffer());

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -810,7 +810,9 @@ void startUnsafe() throws Exception {
         avformat_write_header(oc.metadata(metadata), options);
         av_dict_free(options);
 
-        av_dump_format(oc, 0, filename, 1);
+        if (av_log_get_level() >= AV_LOG_INFO) {
+            av_dump_format(oc, 0, filename, 1);
+        }
     }
 
     public void stop() throws Exception {

File: src/main/java/org/bytedeco/javacv/FlyCapture2FrameGrabber.java
Patch:
@@ -507,7 +507,7 @@ public Frame grab() throws FrameGrabber.Exception {
                 || format == PIXEL_FORMAT_BGR || format == PIXEL_FORMAT_BGRU;
         boolean coloryuv = format == PIXEL_FORMAT_411YUV8 || format == PIXEL_FORMAT_422YUV8
                 || format == PIXEL_FORMAT_444YUV8;
-        BytePointer imageData = raw_image.GetData();
+        BytePointer imageData = raw_image.GetData().capacity(raw_image.GetDataSize());
 
         if ((depth == IPL_DEPTH_8U || frameEndian.equals(ByteOrder.nativeOrder()))
                 && (imageMode == FrameGrabber.ImageMode.RAW || (imageMode == FrameGrabber.ImageMode.COLOR && numChannels == 3)
@@ -550,7 +550,7 @@ public Frame grab() throws FrameGrabber.Exception {
             }
             if (depth != IPL_DEPTH_8U && conv_image.GetPixelFormat() == format && conv_image.GetStride() == stride) {
                 // we just need a copy to swap bytes..
-                ShortBuffer in = raw_image.GetData().asByteBuffer().order(frameEndian).asShortBuffer();
+                ShortBuffer in = imageData.asByteBuffer().order(frameEndian).asShortBuffer();
                 ShortBuffer out = temp_image.getByteBuffer().order(ByteOrder.nativeOrder()).asShortBuffer();
                 out.put(in);
                 alreadySwapped = true;

File: platform/src/test/java/org/bytedeco/javacv/FrameGrabberTest.java
Patch:
@@ -90,6 +90,7 @@ public class FrameGrabberTest {
                 }
             }
             assertEquals(grabber.grab(), null);
+            grabber.restart();
             grabber.stop();
             grabber.release();
         } catch (Exception e) {

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -879,7 +879,7 @@ public boolean recordSamples(int sampleRate, int audioChannels, Buffer ... sampl
             audioChannels = audio_c.channels();
         }
         int inputSize = samples != null ? samples[0].limit() - samples[0].position() : 0;
-        int inputFormat = AV_SAMPLE_FMT_NONE;
+        int inputFormat = samples_format;
         int inputChannels = samples != null && samples.length > 1 ? 1 : audioChannels;
         int inputDepth = 0;
         int outputFormat = audio_c.sample_fmt();

File: src/main/java/org/bytedeco/javacv/OpenCVFrameGrabber.java
Patch:
@@ -78,7 +78,8 @@ public void release() throws Exception {
     private String filename = null;
     private VideoCapture capture = null;
     private Mat returnMatrix = null;
-    private OpenCVFrameConverter converter = new OpenCVFrameConverter.ToMat();
+    private final OpenCVFrameConverter converter = new OpenCVFrameConverter.ToMat();
+    private final Mat mat = new Mat();
 
     @Override public double getGamma() {
         // default to a gamma of 2.2 for cheap Webcams, DV cameras, etc.
@@ -236,7 +237,6 @@ public void trigger() throws Exception {
     }
 
     public Frame grab() throws Exception {
-        Mat mat = new Mat();
         if (!capture.retrieve(mat)) {
             throw new Exception("retrieve() Error: Could not retrieve frame. (Has start() been called?)");
         }

File: src/main/java/org/bytedeco/javacv/AndroidFrameConverter.java
Patch:
@@ -34,6 +34,8 @@
  * <p>
  * This class is not optimized for speed. For best performance, convert first
  * your data to and from RGBA with optimized functions from FFmpeg or OpenCV.
+ * Further, pixel formats other than grayscale, BGR, and RGBA are not well
+ * supported. Their conversions might fail in undefined ways.
  *
  * @author Samuel Audet
  */

File: src/main/java/org/bytedeco/javacv/FFmpegFrameFilter.java
Patch:
@@ -328,7 +328,7 @@ public Frame pull() throws Exception {
             }
             frame.image = image_buf;
             frame.image[0].position(0).limit(size);
-            frame.imageChannels = 2;
+            frame.imageChannels = (size + frame.imageWidth * frame.imageHeight - 1) / (frame.imageWidth * frame.imageHeight);
             ret = avpicture_layout(new AVPicture(filt_frame), filt_frame.format(),
                     frame.imageWidth, frame.imageHeight, (ByteBuffer) frame.image[0].position(0), frame.image[0].capacity());
         }

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -632,6 +632,8 @@ public Frame grabKeyFrame() throws Exception {
     public Frame grabFrame(boolean doAudio, boolean doVideo, boolean processImage, boolean keyFrames) throws Exception {
         if (oc == null || oc.isNull()) {
             throw new Exception("Could not grab: No AVFormatContext. (Has start() been called?)");
+        } else if ((!doVideo || video_st == null) && (!doAudio || audio_st == null)) {
+            return null;
         }
         frame.keyFrame = false;
         frame.imageWidth = 0;

File: src/main/java/org/bytedeco/javacv/IPCameraFrameGrabber.java
Patch:
@@ -88,7 +88,7 @@ public IPCameraFrameGrabber(URL url, int startTimeout, int grabTimeout, TimeUnit
             throw new IllegalArgumentException("URL can not be null");
         }
         this.url = url;
-        if (timeUnit == null) {
+        if (timeUnit != null) {
             this.connectionTimeout = toIntExact(TimeUnit.MILLISECONDS.convert(startTimeout, timeUnit));
             this.readTimeout = toIntExact(TimeUnit.MILLISECONDS.convert(grabTimeout, timeUnit));
         } else {

File: src/main/java/org/bytedeco/javacv/IPCameraFrameGrabber.java
Patch:
@@ -88,7 +88,7 @@ public IPCameraFrameGrabber(URL url, int startTimeout, int grabTimeout, TimeUnit
             throw new IllegalArgumentException("URL can not be null");
         }
         this.url = url;
-        if (timeUnit == null) {
+        if (timeUnit != null) {
             this.connectionTimeout = toIntExact(TimeUnit.MILLISECONDS.convert(startTimeout, timeUnit));
             this.readTimeout = toIntExact(TimeUnit.MILLISECONDS.convert(grabTimeout, timeUnit));
         } else {

File: src/main/java/org/bytedeco/javacv/DC1394FrameGrabber.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2009-2012 Samuel Audet
+ * Copyright (C) 2009-2016 Samuel Audet
  *
  * Licensed either under the Apache License, Version 2.0, or (at your option)
  * under the terms of the GNU General Public License as published by
@@ -130,7 +130,7 @@ public void release() throws Exception {
     private static final boolean linux = Loader.getPlatform().startsWith("linux");
     private dc1394_t d = null;
     private dc1394camera_t camera = null;
-    private pollfd fds = new pollfd();
+    private pollfd fds = linux ? new pollfd() : null;
     private boolean oneShotMode = false;
     private boolean resetDone   = false;
     private dc1394video_frame_t[] raw_image =

File: src/main/java/org/bytedeco/javacv/IPCameraFrameGrabber.java
Patch:
@@ -104,7 +104,7 @@ public IPCameraFrameGrabber(String urlstr, int connectionTimeout, int readTimeou
     /**
      * @param urlstr A string to be used to create the URL.
      * @throws MalformedURLException if the urlstr is a malformed URL
-     * @gi By not setting the connection timeout and the read timeout if your network ever crashes
+     * @deprecated By not setting the connection timeout and the read timeout if your network ever crashes
      * then {@link #start()} or {@link #grab()} can hang for upwards of 45 to 60 seconds before failing.
      * You should always explicitly set the connectionTimeout and readTimeout so that your application can
      * respond appropriately to a loss or failure to connect.

File: src/main/java/org/bytedeco/javacv/DC1394FrameGrabber.java
Patch:
@@ -339,7 +339,9 @@ public void start(boolean tryReset, boolean try1394b) throws Exception {
                 } catch (InterruptedException ex) {
                     // reset interrupt to be nice
                     Thread.currentThread().interrupt();
-                    return;
+                }
+                if (!resetDone) {
+                    throw new Exception("dc1394_reset_bus() Error: Could not reset bus and try to start again.");
                 }
             } else {
                 throw e;

File: samples/FaceApplet.java
Patch:
@@ -95,7 +95,8 @@ public void run() {
                     cvClearMemStorage(storage);
                     cvCvtColor(grabbedImage, grayImage, CV_BGR2GRAY);
                     cvResize(grayImage, smallImage, CV_INTER_AREA);
-                    faces = cvHaarDetectObjects(smallImage, classifier, storage, 1.1, 3, CV_HAAR_DO_CANNY_PRUNING);
+                    faces = cvHaarDetectObjects(smallImage, classifier, storage, 1.1, 3,
+                            CV_HAAR_FIND_BIGGEST_OBJECT | CV_HAAR_DO_ROUGH_SEARCH);
                     repaint();
                 }
             }

File: samples/FacePreview.java
Patch:
@@ -168,7 +168,8 @@ protected void processImage(byte[] data, int width, int height) {
         }
 
         cvClearMemStorage(storage);
-        faces = cvHaarDetectObjects(grayImage, classifier, storage, 1.1, 3, CV_HAAR_DO_CANNY_PRUNING);
+        faces = cvHaarDetectObjects(grayImage, classifier, storage, 1.1, 3,
+                CV_HAAR_FIND_BIGGEST_OBJECT | CV_HAAR_DO_ROUGH_SEARCH);
         postInvalidate();
     }
 

File: src/main/java/org/bytedeco/javacv/AndroidFrameConverter.java
Patch:
@@ -118,7 +118,7 @@ public Frame convert(byte[] data, int width, int height) {
     }
 
     @Override public Bitmap convert(Frame frame) {
-        if (frame == null) {
+        if (frame == null || frame.image == null) {
             return null;
         }
 

File: src/main/java/org/bytedeco/javacv/Java2DFrameConverter.java
Patch:
@@ -576,7 +576,7 @@ public BufferedImage getBufferedImage(Frame frame, double gamma) {
         return getBufferedImage(frame, gamma, false, null);
     }
     public BufferedImage getBufferedImage(Frame frame, double gamma, boolean flipChannels, ColorSpace cs) {
-        if (frame == null) {
+        if (frame == null || frame.image == null) {
             return null;
         }
         int type = getBufferedImageType(frame);

File: src/main/java/org/bytedeco/javacv/OpenCVFrameConverter.java
Patch:
@@ -82,7 +82,7 @@ && new Pointer(frame.image[0]).address() == img.imageData().address()
                 && frame.imageStride * Math.abs(frame.imageDepth) / 8 == img.widthStep();
     }
     public IplImage convertToIplImage(Frame frame) {
-        if (frame == null) {
+        if (frame == null || frame.image == null) {
             return null;
         } else if (frame.opaque instanceof IplImage) {
             return (IplImage)frame.opaque;
@@ -131,7 +131,7 @@ && new Pointer(frame.image[0]).address() == mat.data().address()
                 && frame.imageStride * Math.abs(frame.imageDepth) / 8 == (int)mat.step();
     }
     public Mat convertToMat(Frame frame) {
-        if (frame == null) {
+        if (frame == null || frame.image == null) {
             return null;
         } else if (frame.opaque instanceof Mat) {
             return (Mat)frame.opaque;

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -355,10 +355,10 @@ void releaseUnsafe() throws Exception {
                to ...666 and the given timestamp has been rounded to ...667
                (or vice versa)
             */
-            while (this.timestamp > timestamp + 1 && grabFrame(true, true, false, false) != null) {
+            while (this.timestamp > timestamp + 1 && grabFrame(false, true, false, false) != null) {
                 // flush frames if seeking backwards
             }
-            while (this.timestamp < timestamp - 1 && grabFrame(true, true, false, false) != null) {
+            while (this.timestamp < timestamp - 1 && grabFrame(false, true, false, false) != null) {
                 // decode up to the desired frame
             }
             if (video_c != null) {

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -453,6 +453,7 @@ void startUnsafe() throws Exception {
                 release();
                 throw new Exception("avcodec_find_encoder() error: Audio codec not found.");
             }
+            oformat.audio_codec(audio_codec.id());
 
             if ((audio_st = avformat_new_stream(oc, audio_codec)) == null) {
                 release();

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -347,6 +347,7 @@ void startUnsafe() throws Exception {
                 release();
                 throw new Exception("avcodec_find_encoder() error: Video codec not found.");
             }
+            oformat.video_codec(video_codec.id());
 
             AVRational frame_rate = av_d2q(frameRate, 1001000);
             AVRational supported_framerates = video_codec.supported_framerates();

File: src/main/java/org/bytedeco/javacv/ObjectFinder.java
Patch:
@@ -170,6 +170,7 @@ public void setSettings(Settings settings) {
             flannIndex = new Index();
             indexParams = new LshIndexParams(12, 20, 2); // using LSH Hamming distance
             searchParams = new SearchParams(64, 0, true); // maximum number of leafs checked
+            searchParams.deallocate(false); // for some reason FLANN seems to do it for us
         }
         pt1  = new Mat(total, 1, CV_32FC2);
         pt2  = new Mat(total, 1, CV_32FC2);

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -125,7 +125,7 @@ public void release() throws Exception {
             releaseUnsafe();
         }
     }
-    public void releaseUnsafe() throws Exception {
+    void releaseUnsafe() throws Exception {
         if (pkt != null && pkt2 != null) {
             if (pkt2.size() > 0) {
                 av_free_packet(pkt);
@@ -380,7 +380,7 @@ public void start() throws Exception {
             startUnsafe();
         }
     }
-    public void startUnsafe() throws Exception {
+    void startUnsafe() throws Exception {
         int ret;
         img_convert_ctx = null;
         oc              = new AVFormatContext(null);

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -154,7 +154,7 @@ public void release() throws Exception {
             releaseUnsafe();
         }
     }
-    public void releaseUnsafe() throws Exception {
+    void releaseUnsafe() throws Exception {
         /* close each codec */
         if (video_c != null) {
             avcodec_close(video_c);
@@ -288,7 +288,7 @@ public void start() throws Exception {
             startUnsafe();
         }
     }
-    public void startUnsafe() throws Exception {
+    void startUnsafe() throws Exception {
         int ret;
         picture = null;
         tmp_picture = null;

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -274,6 +274,9 @@ public void releaseUnsafe() throws Exception {
             return super.getFrameRate();
         } else {
             AVRational r = video_st.avg_frame_rate();
+            if (r.num() == 0 && r.den() == 0) {
+                r = video_st.r_frame_rate();
+            }
             return (double)r.num() / r.den();
         }
     }

File: src/main/java/org/bytedeco/javacv/FrameRecorder.java
Patch:
@@ -72,7 +72,7 @@ public static Class<? extends FrameRecorder> get(String className) throws Except
     public static FrameRecorder create(Class<? extends FrameRecorder> c, Class p, Object o, int w, int h) throws Exception {
         Throwable cause = null;
         try {
-            return c.getConstructor(p, int.class, int.class).newInstance(o, w, h);
+            return (FrameRecoder)c.getConstructor(p, int.class, int.class).newInstance(o, w, h);
         } catch (InstantiationException ex) {
             cause = ex;
         } catch (IllegalAccessException ex) {

File: src/main/java/org/bytedeco/javacv/Java2DFrameConverter.java
Patch:
@@ -470,7 +470,7 @@ public static void copy(Frame frame, BufferedImage bufferedImage, double gamma,
             int[] a = ((DataBufferInt)out).getData();
             int stride = frame.imageStride;
             if (in instanceof ByteBuffer) {
-                in = ((ByteBuffer)in).order(ByteOrder.BIG_ENDIAN).asIntBuffer();
+                in = ((ByteBuffer)in).order(flipChannels ? ByteOrder.LITTLE_ENDIAN : ByteOrder.BIG_ENDIAN).asIntBuffer();
                 stride /= 4;
             }
             flipCopyWithGamma((IntBuffer)in, stride, IntBuffer.wrap(a, start, a.length - start), step, gamma, false, flipChannels ? channels : 0);
@@ -525,7 +525,7 @@ public static void copy(BufferedImage image, Frame frame, double gamma, boolean
             int[] a = ((DataBufferInt)in).getData();
             int stride = frame.imageStride;
             if (out instanceof ByteBuffer) {
-                out = ((ByteBuffer)out).order(ByteOrder.BIG_ENDIAN).asIntBuffer();
+                out = ((ByteBuffer)out).order(flipChannels ? ByteOrder.LITTLE_ENDIAN : ByteOrder.BIG_ENDIAN).asIntBuffer();
                 stride /= 4;
             }
             flipCopyWithGamma(IntBuffer.wrap(a, start, a.length - start), step, (IntBuffer)out, stride, gamma, false, flipChannels ? channels : 0);

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -192,11 +192,11 @@ public void releaseUnsafe() throws Exception {
             av_free(audio_outbuf);
             audio_outbuf = null;
         }
-        if (video_st.metadata() != null) {
+        if (video_st != null && video_st.metadata() != null) {
             av_dict_free(video_st.metadata());
             video_st.metadata(null);
         }
-        if (audio_st.metadata() != null) {
+        if (audio_st != null && audio_st.metadata() != null) {
             av_dict_free(audio_st.metadata());
             audio_st.metadata(null);
         }
@@ -794,7 +794,7 @@ public boolean recordImage(int width, int height, int depth, int channels, int s
                 }
             }
         }
-        return (video_pkt.flags() & AV_PKT_FLAG_KEY) == 1;
+        return image != null ? (video_pkt.flags() & AV_PKT_FLAG_KEY) != 0 : got_video_packet[0] != 0;
     }
 
     public boolean recordSamples(Buffer ... samples) throws Exception {

File: src/main/java/org/bytedeco/javacv/Java2DFrameConverter.java
Patch:
@@ -41,6 +41,7 @@
 import java.awt.image.WritableRaster;
 import java.nio.Buffer;
 import java.nio.ByteBuffer;
+import java.nio.ByteOrder;
 import java.nio.DoubleBuffer;
 import java.nio.FloatBuffer;
 import java.nio.IntBuffer;
@@ -517,7 +518,7 @@ public static void copy(BufferedImage image, Frame frame, double gamma, boolean
             int[] a = ((DataBufferInt)in).getData();
             int stride = frame.imageStride;
             if (out instanceof ByteBuffer) {
-                out = ((ByteBuffer)out).asIntBuffer();
+                out = ((ByteBuffer)out).order(ByteOrder.BIG_ENDIAN).asIntBuffer();
                 stride /= 4;
             }
             flipCopyWithGamma(IntBuffer.wrap(a, start, a.length - start), step, (IntBuffer)out, stride, gamma, false, flipChannels ? channels : 0);

File: src/test/java/org/bytedeco/javacv/FrameConverterTest.java
Patch:
@@ -102,8 +102,8 @@ public class FrameConverterTest {
             WritableRaster raster2 = image2.getRaster();
             byte[] array2 = ((DataBufferByte)raster2.getDataBuffer()).getData();
             for (int j = 0; j < array.length; j++) {
-                int n = ((array2[4 * j + 3] & 0xFF) << 24) | ((array2[4 * j + 2] & 0xFF) << 16)
-                      | ((array2[4 * j + 1] & 0xFF) << 8) | (array2[4 * j] & 0xFF);
+                int n = ((array2[4 * j    ] & 0xFF) << 24) | ((array2[4 * j + 1] & 0xFF) << 16)
+                      | ((array2[4 * j + 2] & 0xFF) << 8)  |  (array2[4 * j + 3] & 0xFF);
                 assertEquals(array[j], n);
             }
         }

File: src/main/java/org/bytedeco/javacv/Java2DFrameConverter.java
Patch:
@@ -515,10 +515,12 @@ public static void copy(BufferedImage image, Frame frame, double gamma, boolean
             flipCopyWithGamma(FloatBuffer.wrap(a, start, a.length - start), step, (FloatBuffer)out, frame.imageStride, gamma, false, flipChannels ? channels : 0);
         } else if (in instanceof DataBufferInt) {
             int[] a = ((DataBufferInt)in).getData();
+            int stride = frame.imageStride;
             if (out instanceof ByteBuffer) {
                 out = ((ByteBuffer)out).asIntBuffer();
+                stride /= 4;
             }
-            flipCopyWithGamma(IntBuffer.wrap(a, start, a.length - start), step, (IntBuffer)out, frame.imageStride, gamma, false, flipChannels ? channels : 0);
+            flipCopyWithGamma(IntBuffer.wrap(a, start, a.length - start), step, (IntBuffer)out, stride, gamma, false, flipChannels ? channels : 0);
         } else if (in instanceof DataBufferShort) {
             short[] a = ((DataBufferShort)in).getData();
             flipCopyWithGamma(ShortBuffer.wrap(a, start, a.length - start), step, (ShortBuffer)out, frame.imageStride, true, gamma, false, flipChannels ? channels : 0);

File: samples/WebcamAndMicrophoneCapture.java
Patch:
@@ -123,7 +123,9 @@ public void run()
                 try
                 {
                     // Open and start capturing audio
-                    TargetDataLine line = (TargetDataLine) mixer.getLine(dataLineInfo);
+                    // It's possible to have more control over the chosen audio device with this line:
+                    // TargetDataLine line = (TargetDataLine)mixer.getLine(dataLineInfo);
+                    TargetDataLine line = (TargetDataLine)AudioSystem.getLine(dataLineInfo);
                     line.open(audioFormat);
                     line.start();
 

File: src/main/java/org/bytedeco/javacv/OpenCVFrameConverter.java
Patch:
@@ -38,10 +38,12 @@ public abstract class OpenCVFrameConverter<F> extends FrameConverter<F> {
     Mat mat;
 
     public static class ToIplImage extends OpenCVFrameConverter<IplImage> {
+        @Override public Frame convert(IplImage img) { return super.convert(img); }
         @Override public IplImage convert(Frame frame) { return convertToIplImage(frame); }
     }
 
     public static class ToMat extends OpenCVFrameConverter<Mat> {
+        @Override public Frame convert(Mat mat) { return super.convert(mat); }
         @Override public Mat convert(Frame frame) { return convertToMat(frame); }
     }
 

File: src/main/java/org/bytedeco/javacv/Java2DFrameConverter.java
Patch:
@@ -515,6 +515,9 @@ public static void copy(BufferedImage image, Frame frame, double gamma, boolean
             flipCopyWithGamma(FloatBuffer.wrap(a, start, a.length - start), step, (FloatBuffer)out, frame.imageStride, gamma, false, flipChannels ? channels : 0);
         } else if (in instanceof DataBufferInt) {
             int[] a = ((DataBufferInt)in).getData();
+            if (out instanceof ByteBuffer) {
+                out = ((ByteBuffer)out).asIntBuffer();
+            }
             flipCopyWithGamma(IntBuffer.wrap(a, start, a.length - start), step, (IntBuffer)out, frame.imageStride, gamma, false, flipChannels ? channels : 0);
         } else if (in instanceof DataBufferShort) {
             short[] a = ((DataBufferShort)in).getData();

File: samples/BlobDemo.java
Patch:
@@ -1,5 +1,6 @@
 import org.bytedeco.javacv.Blobs;
 import org.bytedeco.javacv.CanvasFrame;
+import org.bytedeco.javacv.OpenCVFrameConverter;
 
 import static org.bytedeco.javacpp.opencv_core.*;
 import static org.bytedeco.javacpp.opencv_highgui.*;
@@ -118,7 +119,8 @@ public static void ShowImage(IplImage image, String caption, int width, int heig
         CanvasFrame canvas = new CanvasFrame(caption, 1);   // gamma=1
         canvas.setDefaultCloseOperation(javax.swing.JFrame.EXIT_ON_CLOSE);
         canvas.setCanvasSize(width, height);
-        canvas.showImage(image);
+        OpenCVFrameConverter converter = new OpenCVFrameConverter.ToIplImage();
+        canvas.showImage(converter.convert(image));
     }
     
     public static void Highlight(IplImage image, int [] inVec)

File: samples/OpenCVFaceRecognizer.java
Patch:
@@ -29,7 +29,6 @@
  * Source: http://pcbje.com/2012/12/doing-face-recognition-with-javacv/
  *
  * @author Petter Christian Bjelland
- * @author Samuel Audet
  */
 public class OpenCVFaceRecognizer {
     public static void main(String[] args) {

File: samples/OpticalFlowDense.java
Patch:
@@ -8,7 +8,6 @@
  * (Frame-1 & Frame-2) and put the velocity of every pixel to another image (OF) in their coordinate.
  *
  * @author Dawit Gebreyohannes
- * @author Samuel Audet
  */
 public class OpticalFlowDense {
     public static void main(String[] args) {

File: src/main/java/org/bytedeco/javacv/DC1394FrameGrabber.java
Patch:
@@ -137,6 +137,7 @@ public void release() throws Exception {
     private dc1394video_frame_t frame = null;
     private dc1394video_frame_t enqueue_image = null;
     private IplImage temp_image, return_image = null;
+    private FrameConverter converter = new OpenCVFrameConverter.ToIplImage();
     private final int[] out = new int[1];
     private final float[] outFloat = new float[1];
     private final float[] gammaOut = new float[1];
@@ -418,7 +419,7 @@ public void trigger() throws Exception {
         }
     }
 
-    public IplImage grab() throws Exception {
+    public Frame grab() throws Exception {
         enqueue();
         if (linux) {
             fds.events(POLLIN);
@@ -601,6 +602,6 @@ public IplImage grab() throws Exception {
 //        long[] local_time = { 0 };
 //        dc1394_read_cycle_timer(camera, cycle_timer, local_time);
 //System.out.println("frame age = " + (local_time[0] - timestamp));
-        return return_image;
+        return converter.convert(return_image);
     }
 }

File: src/main/java/org/bytedeco/javacv/FlyCapture2FrameGrabber.java
Patch:
@@ -175,6 +175,7 @@ protected void finalize() throws Throwable {
     private Image raw_image = new Image();
     private Image conv_image = new Image();
     private IplImage temp_image, return_image = null;
+    private FrameConverter converter = new OpenCVFrameConverter.ToIplImage();
     private final int[] regOut = new int[1];
     private final float[] outFloat = new float[1];
     private final float[] gammaOut = new float[1];
@@ -367,7 +368,7 @@ private void setStride(Image image, int stride) {
                 image.GetBayerTileFormat());
     }
 
-    public IplImage grab() throws FrameGrabber.Exception {
+    public Frame grab() throws FrameGrabber.Exception {
         Error error = camera.RetrieveBuffer(raw_image);
         if (error.notEquals(PGRERROR_OK)) {
             throw new FrameGrabber.Exception("flycaptureGrabImage2() Error " + error + " (Has start() been called?)");
@@ -492,6 +493,6 @@ public IplImage grab() throws FrameGrabber.Exception {
 
         TimeStamp timeStamp = raw_image.GetTimeStamp();
         timestamp = timeStamp.seconds() * 1000000L + timeStamp.microSeconds();
-        return return_image;
+        return converter.convert(return_image);
     }
 }

File: src/main/java/org/bytedeco/javacv/FlyCaptureFrameGrabber.java
Patch:
@@ -119,6 +119,7 @@ public void release() throws Exception {
     private FlyCaptureImage raw_image = new FlyCaptureImage();
     private FlyCaptureImage conv_image = new FlyCaptureImage();
     private IplImage temp_image, return_image = null;
+    private FrameConverter converter = new OpenCVFrameConverter.ToIplImage();
     private final int[] regOut = new int[1];
     private final float[] outFloat = new float[1];
     private final float[] gammaOut = new float[1];
@@ -357,7 +358,7 @@ private int getDepth(int pixelFormat) {
         }
     }
 
-    public IplImage grab() throws Exception {
+    public Frame grab() throws Exception {
         int error = flycaptureGrabImage2(context, raw_image);
         if (error != FLYCAPTURE_OK) {
             throw new Exception("flycaptureGrabImage2() Error " + error + " (Has start() been called?)");
@@ -469,6 +470,6 @@ public IplImage grab() throws Exception {
 
         FlyCaptureTimestamp timeStamp = raw_image.timeStamp();
         timestamp = timeStamp.ulSeconds() * 1000000L + timeStamp.ulMicroSeconds();
-        return return_image;
+        return converter.convert(return_image);
     }
 }

File: src/main/java/org/bytedeco/javacv/IPCameraFrameGrabber.java
Patch:
@@ -65,6 +65,7 @@ public static void tryLoad() throws Exception {
     private Map<String, List<String>> headerfields;
     private String boundryKey;
     private IplImage decoded = null;
+    private FrameConverter converter = new OpenCVFrameConverter.ToIplImage();
 
     public IPCameraFrameGrabber(String urlstr) throws MalformedURLException {
         url = new URL(urlstr);
@@ -112,14 +113,14 @@ public void trigger() throws Exception {
     }
 
     @Override
-    public IplImage grab() throws Exception {
+    public Frame grab() throws Exception {
         try {
             byte[] b = readImage();
             CvMat mat = cvMat(1, b.length, CV_8UC1, new BytePointer(b));
             if (decoded != null){
                 cvReleaseImage(decoded);
             }
-            return decoded = cvDecodeImage(mat);
+            return converter.convert(decoded = cvDecodeImage(mat));
         } catch (IOException e) {
             throw new Exception(e.getMessage(), e);
         }

File: src/main/java/org/bytedeco/javacv/ObjectFinder.java
Patch:
@@ -411,15 +411,16 @@ public static void main(String[] args) throws Exception {
 
         CanvasFrame objectFrame = new CanvasFrame("Object");
         CanvasFrame correspondFrame = new CanvasFrame("Object Correspond");
+        OpenCVFrameConverter converter = new OpenCVFrameConverter.ToIplImage();
 
-        correspondFrame.showImage(correspond);
+        correspondFrame.showImage(converter.convert(correspond));
         for (int i = 0; i < finder.objectKeypoints.length; i++ ) {
             CvSURFPoint r = finder.objectKeypoints[i];
             CvPoint center = cvPointFrom32f(r.pt());
             int radius = Math.round(r.size()*1.2f/9*2);
             cvCircle(objectColor, center, radius, CvScalar.RED, 1, 8, 0);
         }
-        objectFrame.showImage(objectColor);
+        objectFrame.showImage(converter.convert(objectColor));
 
         objectFrame.waitKey();
 

File: src/main/java/org/bytedeco/javacv/OpenCVFrameGrabber.java
Patch:
@@ -75,6 +75,7 @@ public void release() throws Exception {
     private String filename = null;
     private CvCapture capture = null;
     private IplImage return_image = null;
+    private FrameConverter converter = new OpenCVFrameConverter.ToIplImage();
 
     @Override public double getGamma() {
         // default to a gamma of 2.2 for cheap Webcams, DV cameras, etc.
@@ -230,7 +231,7 @@ public void trigger() throws Exception {
         }
     }
 
-    public IplImage grab() throws Exception {
+    public Frame grab() throws Exception {
         IplImage image = cvRetrieveFrame(capture);
         if (image == null) {
             throw new Exception("cvRetrieveFrame() Error: Could not retrieve frame. (Has start() been called?)");
@@ -255,6 +256,6 @@ public IplImage grab() throws Exception {
         } else {
             return_image = image;
         }
-        return return_image;
+        return converter.convert(return_image);
     }
 }

File: src/main/java/org/bytedeco/javacv/PS3EyeFrameGrabber.java
Patch:
@@ -97,6 +97,7 @@ public static void tryLoad() throws Exception {
 
     IplImage image_4ch = null;
     IplImage image_1ch = null;
+    FrameConverter converter = new OpenCVFrameConverter.ToIplImage();
 
     String stat;                  // status of PS3 camera handling - mostly for debugging
     String uuid;                  // assigned camera unique key
@@ -265,7 +266,7 @@ public IplImage grab_RGB4() {
      *  @return "read-only" RGB, 4-channel or GRAY/1-channel image, it throws exception if no image is available
      */
     @Override
-    public IplImage grab() throws Exception {
+    public Frame grab() throws Exception {
         IplImage img = null;
         switch (triggered) {
             case NO_TRIGGER:
@@ -285,7 +286,7 @@ public IplImage grab() throws Exception {
                 cvCvtColor(img, image_1ch, CV_RGB2GRAY);
                 img = image_1ch;
         }
-        return img;
+        return converter.convert(img);
     }
 
 

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -459,6 +459,9 @@ public void startUnsafe() throws Exception {
                     // Assign appropriate parts of buffer to image planes in picture_rgb
                     // Note that picture_rgb is an AVFrame, but AVFrame is a superset of AVPicture
                     avpicture_fill(new AVPicture(picture_rgb), buffer_rgb, fmt, width, height);
+                    picture_rgb.format(fmt);
+                    picture_rgb.width(width);
+                    picture_rgb.height(height);
 
                     return_image = IplImage.createHeader(width, height, IPL_DEPTH_8U, 1);
                     break;

File: src/main/java/org/bytedeco/javacv/FFmpegFrameRecorder.java
Patch:
@@ -359,6 +359,7 @@ public void startUnsafe() throws Exception {
                timebase should be 1/framerate and timestamp increments should be
                identically 1. */
             video_c.time_base(av_inv_q(frame_rate));
+            video_st.time_base(av_inv_q(frame_rate));
             if (gopSize >= 0) {
                 video_c.gop_size(gopSize); /* emit one intra frame every gopSize frames at most */
             }
@@ -454,6 +455,7 @@ public void startUnsafe() throws Exception {
                 audio_c.sample_fmt(AV_SAMPLE_FMT_S16);
             }
             audio_c.time_base().num(1).den(sampleRate);
+            audio_st.time_base().num(1).den(sampleRate);
             switch (audio_c.sample_fmt()) {
                 case AV_SAMPLE_FMT_U8:
                 case AV_SAMPLE_FMT_U8P:  audio_c.bits_per_raw_sample(8);  break;

File: src/main/java/org/bytedeco/javacv/CanvasFrame.java
Patch:
@@ -196,6 +196,9 @@ protected void initCanvas(boolean fullScreen, DisplayMode displayMode, double ga
                 // NullPointerException or IllegalStateException,
                 // but otherwise seems to work fine.
                 try {
+                    if (canvas.getWidth() <= 0 || canvas.getHeight() <= 0) {
+                        return;
+                    }
                     BufferStrategy strategy = canvas.getBufferStrategy();
                     do {
                         do {

File: src/main/java/org/bytedeco/javacv/CanvasFrame.java
Patch:
@@ -196,6 +196,9 @@ protected void initCanvas(boolean fullScreen, DisplayMode displayMode, double ga
                 // NullPointerException or IllegalStateException,
                 // but otherwise seems to work fine.
                 try {
+                    if (canvas.getWidth() <= 0 || canvas.getHeight() <= 0) {
+                        return;
+                    }
                     BufferStrategy strategy = canvas.getBufferStrategy();
                     do {
                         do {

File: src/main/java/org/bytedeco/javacv/JavaCVCL.java
Patch:
@@ -21,7 +21,6 @@
 package org.bytedeco.javacv;
 
 import com.jogamp.opencl.CLCommandQueue;
-import com.jogamp.opencl.CLCommandQueue.Mode;
 import com.jogamp.opencl.CLBuffer;
 import com.jogamp.opencl.CLContext;
 import com.jogamp.opencl.CLDevice;
@@ -107,7 +106,7 @@ public JavaCVCL(GLCapabilitiesImmutable caps, GLContext shareWith, CLDevice devi
         GLPbuffer pbuffer = null;
         if (caps != null) {
             GLDrawableFactory factory = GLDrawableFactory.getFactory(caps.getGLProfile());
-            if (factory.canCreateGLPbuffer(null)) {
+            if (factory.canCreateGLPbuffer(null, caps.getGLProfile())) {
                 try {
                     // makes a new buffer
                     pbuffer = factory.createGLPbuffer(null, caps, null, 32, 32, shareWith);

File: src/main/java/org/bytedeco/javacv/CanvasFrame.java
Patch:
@@ -222,6 +222,7 @@ protected void initCanvas(boolean fullScreen, DisplayMode displayMode, double ga
             canvas.setSize(getSize());
             needInitialResize = false;
         } else {
+            canvas.setSize(10,10); // mac bug
             needInitialResize = true;
         }
         getContentPane().add(canvas);

File: src/main/java/org/bytedeco/javacv/DC1394FrameGrabber.java
Patch:
@@ -71,8 +71,8 @@ public static String[] getDeviceDescriptions() throws Exception {
         return descriptions;
     }
 
-    public static DC1394FrameGrabber createDefault(File deviceFile)   throws Exception { return null; }
-    public static DC1394FrameGrabber createDefault(String devicePath) throws Exception { return null; }
+    public static DC1394FrameGrabber createDefault(File deviceFile)   throws Exception { throw new Exception(DC1394FrameGrabber.class + " does not support device files."); }
+    public static DC1394FrameGrabber createDefault(String devicePath) throws Exception { throw new Exception(DC1394FrameGrabber.class + " does not support device paths."); }
     public static DC1394FrameGrabber createDefault(int deviceNumber)  throws Exception { return new DC1394FrameGrabber(deviceNumber); }
 
     private static Exception loadingException = null;

File: src/main/java/org/bytedeco/javacv/FFmpegFrameGrabber.java
Patch:
@@ -75,7 +75,7 @@ public static String[] getDeviceDescriptions() throws Exception {
 
     public static FFmpegFrameGrabber createDefault(File deviceFile)   throws Exception { return new FFmpegFrameGrabber(deviceFile); }
     public static FFmpegFrameGrabber createDefault(String devicePath) throws Exception { return new FFmpegFrameGrabber(devicePath); }
-    public static FFmpegFrameGrabber createDefault(int deviceNumber)  throws Exception { return null; }
+    public static FFmpegFrameGrabber createDefault(int deviceNumber)  throws Exception { throw new Exception(FFmpegFrameGrabber.class + " does not support device numbers."); }
 
     private static Exception loadingException = null;
     public static void tryLoad() throws Exception {

File: src/main/java/org/bytedeco/javacv/FlyCaptureFrameGrabber.java
Patch:
@@ -64,8 +64,8 @@ public static String[] getDeviceDescriptions() throws Exception {
         return descriptions;
     }
 
-    public static FlyCaptureFrameGrabber createDefault(File deviceFile)   throws Exception { return null; }
-    public static FlyCaptureFrameGrabber createDefault(String devicePath) throws Exception { return null; }
+    public static FlyCaptureFrameGrabber createDefault(File deviceFile)   throws Exception { throw new Exception(FlyCaptureFrameGrabber.class + " does not support device files."); }
+    public static FlyCaptureFrameGrabber createDefault(String devicePath) throws Exception { throw new Exception(FlyCaptureFrameGrabber.class + " does not support device paths."); }
     public static FlyCaptureFrameGrabber createDefault(int deviceNumber)  throws Exception { return new FlyCaptureFrameGrabber(deviceNumber); }
 
     private static Exception loadingException = null;

File: src/main/java/org/bytedeco/javacv/OpenKinectFrameGrabber.java
Patch:
@@ -63,8 +63,8 @@ public static String[] getDeviceDescriptions() throws Exception {
         return descriptions;
     }
 
-    public static OpenKinectFrameGrabber createDefault(File deviceFile)   throws Exception { return null; }
-    public static OpenKinectFrameGrabber createDefault(String devicePath) throws Exception { return null; }
+    public static OpenKinectFrameGrabber createDefault(File deviceFile)   throws Exception { throw new Exception(OpenKinectFrameGrabber.class + " does not support device files."); }
+    public static OpenKinectFrameGrabber createDefault(String devicePath) throws Exception { throw new Exception(OpenKinectFrameGrabber.class + " does not support device paths."); }
     public static OpenKinectFrameGrabber createDefault(int deviceNumber)  throws Exception { return new OpenKinectFrameGrabber(deviceNumber); }
 
     private static Exception loadingException = null;

File: src/main/java/org/bytedeco/javacv/PS3EyeFrameGrabber.java
Patch:
@@ -73,8 +73,8 @@ public static String[] getDeviceDescriptions() throws Exception {
         return descriptions;
     }
 
-    public static PS3EyeFrameGrabber createDefault(File deviceFile)   throws Exception { return null; }
-    public static PS3EyeFrameGrabber createDefault(String devicePath) throws Exception { return null; }
+    public static PS3EyeFrameGrabber createDefault(File deviceFile)   throws Exception { throw new Exception(PS3EyeFrameGrabber.class + " does not support device files."); }
+    public static PS3EyeFrameGrabber createDefault(String devicePath) throws Exception { throw new Exception(PS3EyeFrameGrabber.class + " does not support device paths."); }
     public static PS3EyeFrameGrabber createDefault(int deviceNumber)  throws Exception { return new PS3EyeFrameGrabber(deviceNumber); }
 
     private static Exception loadingException = null;

File: src/main/java/org/bytedeco/javacv/VideoInputFrameGrabber.java
Patch:
@@ -44,8 +44,8 @@ public static String[] getDeviceDescriptions() throws Exception {
         return descriptions;
     }
 
-    public static VideoInputFrameGrabber createDefault(File deviceFile)   throws Exception { return null; }
-    public static VideoInputFrameGrabber createDefault(String devicePath) throws Exception { return null; }
+    public static VideoInputFrameGrabber createDefault(File deviceFile)   throws Exception { throw new Exception(VideoInputFrameGrabber.class + " does not support device files."); }
+    public static VideoInputFrameGrabber createDefault(String devicePath) throws Exception { throw new Exception(VideoInputFrameGrabber.class + " does not support device paths."); }
     public static VideoInputFrameGrabber createDefault(int deviceNumber)  throws Exception { return new VideoInputFrameGrabber(deviceNumber); }
 
     private static Exception loadingException = null;

File: samples/FaceRecognition.java
Patch:
@@ -18,7 +18,7 @@
  *
  *
  * Fixes and changes by Samuel Audet:
- * The all10.txt, lower3.txt, and upper3.txt were taken from the http://www.shervinemami.info/facerecExample_ORL.zip archive.
+ * all10.txt, lower3.txt, and upper6.txt were taken from the http://www.shervinemami.info/facerecExample_ORL.zip archive.
  * Please also extract the content of http://www.shervinemami.info/Cambridge_FaceDB.zip inside this directory.
  * The need for the data subdirectory has been removed.
  *
@@ -38,14 +38,14 @@
  * along with JavaCV.  If not, see <http://www.gnu.org/licenses/>.
  *
  */
-import org.bytedeco.javacpp.FloatPointer;
-import org.bytedeco.javacpp.Pointer;
 import java.io.BufferedReader;
 import java.io.FileReader;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.logging.Logger;
+import org.bytedeco.javacpp.FloatPointer;
+import org.bytedeco.javacpp.Pointer;
 import static org.bytedeco.javacpp.opencv_core.*;
 import static org.bytedeco.javacpp.opencv_highgui.*;
 import static org.bytedeco.javacpp.opencv_legacy.*;

File: samples/BlobDemo.java
Patch:
@@ -1,9 +1,9 @@
 import org.bytedeco.javacv.Blobs;
 import org.bytedeco.javacv.CanvasFrame;
 
-import static org.bytedeco.javacv.cpp.opencv_core.*;
-import static org.bytedeco.javacv.cpp.opencv_highgui.*;
-import static org.bytedeco.javacv.cpp.opencv_imgproc.*;
+import static org.bytedeco.javacpp.opencv_core.*;
+import static org.bytedeco.javacpp.opencv_highgui.*;
+import static org.bytedeco.javacpp.opencv_imgproc.*;
 
 ///////////////////////////////////////////////////////////////////
 //*                                                             *//

File: samples/FaceRecognition.java
Patch:
@@ -39,9 +39,9 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.logging.Logger;
-import static org.bytedeco.javacv.cpp.opencv_core.*;
-import static org.bytedeco.javacv.cpp.opencv_highgui.*;
-import static org.bytedeco.javacv.cpp.opencv_legacy.*;
+import static org.bytedeco.javacpp.opencv_core.*;
+import static org.bytedeco.javacpp.opencv_highgui.*;
+import static org.bytedeco.javacpp.opencv_legacy.*;
 
 /** Recognizes faces.
  *

File: samples/HoughLines.java
Patch:
@@ -1,9 +1,9 @@
 import javax.swing.JFrame;
 import org.bytedeco.javacpp.Pointer;
 import org.bytedeco.javacv.*;
-import static org.bytedeco.javacv.cpp.opencv_core.*;
-import static org.bytedeco.javacv.cpp.opencv_imgproc.*;
-import static org.bytedeco.javacv.cpp.opencv_highgui.*;
+import static org.bytedeco.javacpp.opencv_core.*;
+import static org.bytedeco.javacpp.opencv_imgproc.*;
+import static org.bytedeco.javacpp.opencv_highgui.*;
 
 /**
  * C to Java translation of the houghlines.c sample provided in the c sample directory of OpenCV 2.1,

File: samples/RecordActivity.java
Patch:
@@ -88,7 +88,7 @@
 
 import org.bytedeco.javacv.FFmpegFrameRecorder;
 
-import static org.bytedeco.javacv.cpp.opencv_core.*;
+import static org.bytedeco.javacpp.opencv_core.*;
 
 public class RecordActivity extends Activity implements OnClickListener {
 

File: samples/FaceRecognition.java
Patch:
@@ -625,11 +625,9 @@ private IplImage convertFloatImageToUcharImage(IplImage srcImg) {
     IplImage dstImg;
     if ((srcImg != null) && (srcImg.width() > 0 && srcImg.height() > 0)) {
       // Spread the 32bit floating point pixels to fit within 8bit pixel range.
-      CvPoint minloc = new CvPoint();
-      CvPoint maxloc = new CvPoint();
       double[] minVal = new double[1];
       double[] maxVal = new double[1];
-      cvMinMaxLoc(srcImg, minVal, maxVal, minloc, maxloc, null);
+      cvMinMaxLoc(srcImg, minVal, maxVal);
       // Deal with NaN and extreme values, since the DFT seems to give some NaN results.
       if (minVal[0] < -1e30) {
         minVal[0] = -1e30;

File: samples/HoughLines.java
Patch:
@@ -78,7 +78,7 @@ else if(args.length==2 && args[1].contentEquals("multiscale")){
 
                 double a = Math.cos((double) theta), b = Math.sin((double) theta);
                 double x0 = a * rho, y0 = b * rho;
-                CvPoint pt1 = new CvPoint((int) Math.round(x0 + 1000 * (-b)), (int) Math.round(y0 + 1000 * (a))), pt2 = new CvPoint((int) Math.round(x0 - 1000 * (-b)), (int) Math.round(y0 - 1000 * (a)));
+                CvPoint pt1 = cvPoint((int) Math.round(x0 + 1000 * (-b)), (int) Math.round(y0 + 1000 * (a))), pt2 = cvPoint((int) Math.round(x0 - 1000 * (-b)), (int) Math.round(y0 - 1000 * (a)));
                 System.out.println("Line spoted: ");
                 System.out.println("\t rho= " + rho);
                 System.out.println("\t theta= " + theta);
@@ -99,7 +99,7 @@ else if(args.length==2 && args[1].contentEquals("multiscale")){
 
                 double a = Math.cos((double) theta), b = Math.sin((double) theta);
                 double x0 = a * rho, y0 = b * rho;
-                CvPoint pt1 = new CvPoint((int) Math.round(x0 + 1000 * (-b)), (int) Math.round(y0 + 1000 * (a))), pt2 = new CvPoint((int) Math.round(x0 - 1000 * (-b)), (int) Math.round(y0 - 1000 * (a)));
+                CvPoint pt1 = cvPoint((int) Math.round(x0 + 1000 * (-b)), (int) Math.round(y0 + 1000 * (a))), pt2 = cvPoint((int) Math.round(x0 - 1000 * (-b)), (int) Math.round(y0 - 1000 * (a)));
                 System.out.println("Line spotted: ");
                 System.out.println("\t rho= " + rho);
                 System.out.println("\t theta= " + theta);

File: src/main/java/com/googlecode/javacv/ProCamTransformer.java
Patch:
@@ -20,7 +20,7 @@
 
 package com.googlecode.javacv;
 
-import static com.googlecode.javacv.cpp.cvkernels.*;
+import static com.googlecode.javacv.cvkernels.*;
 import static com.googlecode.javacv.cpp.opencv_calib3d.*;
 import static com.googlecode.javacv.cpp.opencv_core.*;
 import static com.googlecode.javacv.cpp.opencv_imgproc.*;

File: src/main/java/com/googlecode/javacv/ProjectiveColorTransformer.java
Patch:
@@ -22,7 +22,7 @@
 
 import java.util.Arrays;
 
-import static com.googlecode.javacv.cpp.cvkernels.*;
+import static com.googlecode.javacv.cvkernels.*;
 import static com.googlecode.javacv.cpp.opencv_core.*;
 
 /**
@@ -375,4 +375,4 @@ public CvMat getB() {
             return p;
         }
     }
-}
\ No newline at end of file
+}

File: src/main/java/com/googlecode/javacv/ProjectiveTransformer.java
Patch:
@@ -20,7 +20,7 @@
 
 package com.googlecode.javacv;
 
-import static com.googlecode.javacv.cpp.cvkernels.*;
+import static com.googlecode.javacv.cvkernels.*;
 import static com.googlecode.javacv.cpp.opencv_calib3d.*;
 import static com.googlecode.javacv.cpp.opencv_core.*;
 import static com.googlecode.javacv.cpp.opencv_imgproc.*;

File: src/main/java/com/googlecode/javacv/cvkernels.java
Patch:
@@ -18,7 +18,7 @@
  * along with JavaCV.  If not, see <http://www.gnu.org/licenses/>.
  */
 
-package com.googlecode.javacv.cpp;
+package com.googlecode.javacv;
 
 import com.googlecode.javacv.Parallel;
 import java.nio.ByteBuffer;

File: src/main/java/com/googlecode/javacv/FFmpegFrameRecorder.java
Patch:
@@ -353,7 +353,9 @@ public void startUnsafe() throws Exception {
                timebase should be 1/framerate and timestamp increments should be
                identically 1. */
             video_c.time_base(av_inv_q(frame_rate));
-            video_c.gop_size(12); /* emit one intra frame every twelve frames at most */
+            if (gopSize >= 0) {
+                video_c.gop_size(gopSize); /* emit one intra frame every gopSize frames at most */
+            }
             if (videoQuality >= 0) {
                 video_c.flags(video_c.flags() | CODEC_FLAG_QSCALE);
                 video_c.global_quality((int)Math.round(FF_QP2LAMBDA * videoQuality));

File: src/main/java/com/googlecode/javacv/FlyCaptureFrameGrabber.java
Patch:
@@ -86,7 +86,7 @@ public FlyCaptureFrameGrabber(int deviceNumber) throws Exception {
         if (error != FLYCAPTURE_OK) {
             throw new Exception("flycaptureCreateContext() Error " + error);
         }
-        error = flycaptureInitializePlus(context, deviceNumber, numBuffers, null);
+        error = flycaptureInitializePlus(context, deviceNumber, numBuffers, (BytePointer)null);
         if (error != FLYCAPTURE_OK) {
             throw new Exception("flycaptureInitialize() Error " + error);
         }

File: src/main/java/com/googlecode/javacv/Blobs.java
Patch:
@@ -1,7 +1,6 @@
 package com.googlecode.javacv;
 
-import com.googlecode.javacv.cpp.opencv_core.CvMat;
-import com.googlecode.javacv.cpp.opencv_core.IplImage;
+import static com.googlecode.javacv.cpp.opencv_core.*;
 
 //***************************************************************//
 //* Blob analysis package  Version3.0 3 Oct 2012                *//

File: src/main/java/com/googlecode/javacv/CameraDevice.java
Patch:
@@ -526,7 +526,7 @@ public static CameraDevice[] read(CvFileStorage fs) throws Exception {
         for (int i = 0; i < count; i++) {
             Pointer p = cvGetSeqElem(seq, i);
             if (p == null) continue;
-            String name = cvReadString(new CvFileNode(p), null);
+            String name = cvReadString(new CvFileNode(p), (String)null);
             devices[i] = new CameraDevice(name, fs);
         }
         return devices;

File: src/main/java/com/googlecode/javacv/FFmpegFrameRecorder.java
Patch:
@@ -120,7 +120,7 @@ public FFmpegFrameRecorder(String filename, int imageWidth, int imageHeight) {
         this(filename, imageWidth, imageHeight, 0);
     }
     public FFmpegFrameRecorder(File file, int imageWidth, int imageHeight, int audioChannels) {
-        this(file.getAbsolutePath(), imageWidth, imageHeight);
+        this(file.getAbsolutePath(), imageWidth, imageHeight, audioChannels);
     }
     public FFmpegFrameRecorder(String filename, int imageWidth, int imageHeight, int audioChannels) {
         this.filename      = filename;

File: src/main/java/com/googlecode/javacv/Frame.java
Patch:
@@ -1,8 +1,9 @@
 package com.googlecode.javacv;
 
-import com.googlecode.javacv.cpp.opencv_core.IplImage;
 import java.nio.Buffer;
 
+import static com.googlecode.javacv.cpp.opencv_core.*;
+
 /**
  *
  * @author Samuel Audet

File: src/main/java/com/googlecode/javacv/JavaCVCL.java
Patch:
@@ -21,6 +21,7 @@
 package com.googlecode.javacv;
 
 import com.googlecode.javacpp.Loader;
+import com.googlecode.javacpp.BytePointer;
 import com.jogamp.opencl.CLCommandQueue;
 import com.jogamp.opencl.CLCommandQueue.Mode;
 import com.jogamp.opencl.CLBuffer;
@@ -378,9 +379,9 @@ public CLBuffer createPinnedBuffer(int size) {
 
     class PinnedIplImage extends IplImage {
         PinnedIplImage(int width, int height, int depth, int channels) {
-            super(cvCreateImageHeader(new CvSize(width, height), depth, channels));
+            super(cvCreateImageHeader(new CvSize().width(width).height(height), depth, channels));
             pinnedBuffer = createPinnedBuffer(imageSize());
-            imageData(getByteBuffer());
+            imageData(new BytePointer(getByteBuffer()));
         }
 
         final CLBuffer pinnedBuffer;

File: src/main/java/com/googlecode/javacv/ProCamColorCalibrator.java
Patch:
@@ -270,11 +270,11 @@ public boolean processCameraImage(IplImage cameraImage) {
                 boardPts[j*2    ] -= (boardPts[j*2    ] - cx)*settings.trimmingFraction;
                 boardPts[j*2 + 1] -= (boardPts[j*2 + 1] - cy)*settings.trimmingFraction;
             }
-            cvFillConvexPoly(mask, new CvPoint((byte)16, boardPts, 0, 8),
+            cvFillConvexPoly(mask, new CvPoint(4).put((byte)16, boardPts, 0, 8),
                     4, CvScalar.WHITE, 8, 16);
 
             for (int j = 0; j < (boardPts.length-8)/8; j++) {
-                cvFillConvexPoly(mask, new CvPoint((byte)16, boardPts, 8 + j*8, 8),
+                cvFillConvexPoly(mask, new CvPoint(4).put((byte)16, boardPts, 8 + j*8, 8),
                         4, CvScalar.BLACK, 8, 16);
             }
 
@@ -289,7 +289,7 @@ public boolean processCameraImage(IplImage cameraImage) {
                 projPts[j*2    ] -= (projPts[j*2    ] - cx)*settings.trimmingFraction;
                 projPts[j*2 + 1] -= (projPts[j*2 + 1] - cy)*settings.trimmingFraction;
             }
-            cvFillConvexPoly(mask2, new CvPoint((byte)16, projPts, 0, 8),
+            cvFillConvexPoly(mask2, new CvPoint(4).put((byte)16, projPts, 0, 8),
                     4, CvScalar.WHITE, 8, 16);
 
             cvAnd(mask, mask2, mask, null);

File: src/main/java/com/googlecode/javacv/ProjectorDevice.java
Patch:
@@ -382,7 +382,7 @@ public static ProjectorDevice[] read(CvFileStorage fs) throws Exception {
         for (int i = 0; i < count; i++) {
             Pointer p = cvGetSeqElem(seq, i);
             if (p == null) continue;
-            String name = cvReadString(new CvFileNode(p), null);
+            String name = cvReadString(new CvFileNode(p), (String)null);
             devices[i] = new ProjectorDevice(name, fs);
         }
         return devices;

File: src/main/java/com/googlecode/javacv/ReflectanceInitializer.java
Patch:
@@ -85,7 +85,7 @@ public IplImage initializeReflectance(IplImage[] cameraImages, IplImage reflecta
 
         IplImage mask = IplImage.create(w, h, IPL_DEPTH_8U, 1);
         cvSetZero(mask);
-        cvFillConvexPoly(mask, new CvPoint((byte)(16-cameraDevice.getMapsPyramidLevel()), roiPts),
+        cvFillConvexPoly(mask, new CvPoint(roiPts.length/2).put((byte)(16-cameraDevice.getMapsPyramidLevel()), roiPts),
                 4, CvScalar.WHITE, 8, 16);
 
         // make the images very very smooth to compensate for small movements

File: src/main/java/com/googlecode/javacv/cpp/opencv_objdetect.java
Patch:
@@ -869,11 +869,11 @@ public Detector(@ByRef ModalityVector modalities, @Const @StdVector int[] T_pyra
         private native void allocate();
         private native void allocate(@ByRef ModalityVector modalities, @Const @StdVector int[] T_pyramid);
 
-        public native void match(@Const(true) @StdVector("IplImage*,cv::Mat") IplImageArray sources, float threshold,
+        public native void match(@Const({false, true}) @StdVector("IplImage*,cv::Mat") IplImageArray sources, float threshold,
                 @StdVector Match matches, @ByRef StringVector class_ids/*=null*/, @InputArray IplImageArray quantized_images/*=null*/,
-                @Const(true) @StdVector("IplImage*,cv::Mat") IplImageArray masks/*=null*/);
+                @Const({false, true}) @StdVector("IplImage*,cv::Mat") IplImageArray masks/*=null*/);
 
-        public native int addTemplate(@Const(true) @StdVector("IplImage*,cv::Mat") IplImageArray sources,
+        public native int addTemplate(@Const({false, true}) @StdVector("IplImage*,cv::Mat") IplImageArray sources,
                 String class_id, IplImage object_mask, @Const @Adapter("RectAdapter") CvRect bounding_box/*=null*/);
 
         public native int addSyntheticTemplate(@Const @StdVector Template templates, String class_id);

File: src/main/java/com/googlecode/javacv/cpp/opencv_contrib.java
Patch:
@@ -313,9 +313,9 @@ public EmptyMeshException() { }
         public native void writeAsVrml(String file, @Const @StdVector("CvScalar, cv::Scalar") CvScalar colors/*=null*/);
 
         @StdVector("CvPoint3D32f,cv::Point3f")
-        public native CvPoint3D32f vtx();     public native Mesh3D vtx(@Const CvPoint3D32f vtx);
+        public native CvPoint3D32f vtx();     public native Mesh3D vtx(CvPoint3D32f vtx);
         @StdVector("CvPoint3D32f,cv::Point3f")
-        public native CvPoint3D32f normals(); public native Mesh3D normals(@Const CvPoint3D32f normals);
+        public native CvPoint3D32f normals(); public native Mesh3D normals(CvPoint3D32f normals);
         public native float resolution();     public native Mesh3D resolution(float resolution);
         public native @ByRef Octree octree(); public native Mesh3D octree(Octree octree);
 

File: src/main/java/com/googlecode/javacv/cpp/opencv_nonfree.java
Patch:
@@ -76,7 +76,7 @@
  */
 @Properties(inherit={opencv_calib3d.class, opencv_features2d.class, opencv_objdetect.class,
         opencv_photo.class, opencv_ml.class, opencv_legacy.class, opencv_video.class}, value={
-    @Platform(include={"<opencv2/nonfree/nonfree.hpp>", "<opencv2/features2d/features2d.hpp>"},
+    @Platform(include={"<opencv2/nonfree/nonfree.hpp>", "<opencv2/nonfree/features2d.hpp>"},
         link={"opencv_nonfree@.2.4"}, preload={"opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
     @Platform(value="windows", link={"opencv_nonfree248"}, preload={"opencv_gpu248", "opencv_ocl248"}) })
 public class opencv_nonfree {

File: src/main/java/com/googlecode/javacv/FFmpegFrameGrabber.java
Patch:
@@ -342,7 +342,9 @@ public void startUnsafe() throws Exception {
             AVRational r = av_d2q(frameRate, 1001000);
             av_dict_set(options, "framerate", r.num() + "/" + r.den(), 0);
         }
-        if (imageMode != ImageMode.RAW) {
+        if (pixelFormat >= 0) {
+            av_dict_set(options, "pixel_format", av_get_pix_fmt_name(pixelFormat).getString(), 0);
+        } else if (imageMode != ImageMode.RAW) {
             av_dict_set(options, "pixel_format", imageMode == ImageMode.COLOR ? "bgr24" : "gray8", 0);
         }
         if (imageWidth > 0 && imageHeight > 0) {

File: src/main/java/com/googlecode/javacv/FFmpegFrameGrabber.java
Patch:
@@ -539,6 +539,7 @@ private Frame grabFrame(boolean processImage, boolean doAudio, boolean keyFrames
         frame.keyFrame = false;
         frame.image = null;
         frame.sampleRate = 0;
+        frame.audioChannels = 0;
         frame.samples = null;
         frame.opaque = null;
         if (frameGrabbed) {
@@ -622,6 +623,7 @@ private Frame grabFrame(boolean processImage, boolean doAudio, boolean keyFrames
                         }
                         frame.keyFrame = samples_frame.key_frame() != 0;
                         frame.sampleRate = audio_c.sample_rate();
+                        frame.audioChannels = audio_c.channels();
                         frame.samples = samples_buf;
                         frame.opaque = samples_frame;
                         int sample_size = data_size / av_get_bytes_per_sample(sample_format);

File: src/main/java/com/googlecode/javacv/Frame.java
Patch:
@@ -10,7 +10,7 @@
 public class Frame {
     public boolean keyFrame;
     public IplImage image;   // for video frame
-    public int sampleRate;
+    public int sampleRate, audioChannels;
     public Buffer[] samples; // for audio frame
     public Object opaque;
 }

File: src/main/java/com/googlecode/javacv/FrameRecorder.java
Patch:
@@ -270,9 +270,9 @@ public static class Exception extends java.lang.Exception {
     public abstract void stop() throws Exception;
     public abstract boolean record(IplImage image) throws Exception;
     public boolean record(Buffer ... samples) throws Exception {
-        return record(0, samples);
+        return record(0, 0, samples);
     }
-    public boolean record(int sampleRate, Buffer ... samples) throws Exception {
+    public boolean record(int sampleRate, int audioChannels, Buffer ... samples) throws Exception {
         throw new UnsupportedOperationException("This FrameRecorder does not support audio.");
     }
     public void record(Frame frame) throws Exception {
@@ -283,7 +283,7 @@ public void record(Frame frame) throws Exception {
                 frame.keyFrame = record(frame.image);
             }
             if (frame.samples != null) {
-                frame.keyFrame = record(frame.sampleRate, frame.samples);
+                frame.keyFrame = record(frame.sampleRate, frame.audioChannels, frame.samples);
             }
         }
     }

File: src/main/java/com/googlecode/javacv/cpp/opencv_legacy.java
Patch:
@@ -91,9 +91,8 @@
  */
 @Properties(inherit={opencv_calib3d.class, opencv_features2d.class, opencv_video.class, opencv_ml.class}, value={
     @Platform(include={"<opencv2/legacy/compat.hpp>", "<opencv2/legacy/legacy.hpp>",
-        "<opencv2/legacy/blobtrack.hpp>"}, link={"opencv_legacy@.2.4", "opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
-    @Platform(value="windows", link={"opencv_legacy248", "opencv_gpu248", "opencv_ocl248"}),
-    @Platform(value="android", link={"opencv_legacy"}) })
+        "<opencv2/legacy/blobtrack.hpp>"}, link={"opencv_legacy@.2.4"}, preload={"opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
+    @Platform(value="windows", link={"opencv_legacy248"}, preload={"opencv_gpu248", "opencv_ocl248"}) })
 public class opencv_legacy {
     static { load(); }
 

File: src/main/java/com/googlecode/javacv/cpp/opencv_nonfree.java
Patch:
@@ -77,9 +77,8 @@
 @Properties(inherit={opencv_calib3d.class, opencv_features2d.class, opencv_objdetect.class,
         opencv_photo.class, opencv_ml.class, opencv_legacy.class, opencv_video.class}, value={
     @Platform(include={"<opencv2/nonfree/nonfree.hpp>", "<opencv2/features2d/features2d.hpp>"},
-        link={"opencv_nonfree@.2.4", "opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
-    @Platform(value="windows", link={"opencv_nonfree248", "opencv_gpu248", "opencv_ocl248"}),
-    @Platform(value="android", link={"opencv_nonfree"}) })
+        link={"opencv_nonfree@.2.4"}, preload={"opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
+    @Platform(value="windows", link={"opencv_nonfree248"}, preload={"opencv_gpu248", "opencv_ocl248"}) })
 public class opencv_nonfree {
     static {
         if (load() != null) {

File: src/main/java/com/googlecode/javacv/cpp/opencv_videostab.java
Patch:
@@ -79,9 +79,8 @@
  */
 @Properties(inherit={opencv_calib3d.class, opencv_features2d.class, opencv_objdetect.class, opencv_photo.class,
         opencv_nonfree.class, opencv_video.class, opencv_ml.class, opencv_legacy.class}, value={
-    @Platform(include="<opencv2/videostab/videostab.hpp>", link={"opencv_videostab@.2.4", "opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
-    @Platform(value="windows", link={"opencv_videostab248", "opencv_gpu248", "opencv_ocl248"}),
-    @Platform(value="android", link={"opencv_videostab"}) })
+    @Platform(include="<opencv2/videostab/videostab.hpp>", link={"opencv_videostab@.2.4"}, preload={"opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
+    @Platform(value="windows", link={"opencv_videostab248"}, preload={"opencv_gpu248", "opencv_ocl248"}) })
 public class opencv_videostab {
     static { load(); }
 

File: src/main/java/com/googlecode/javacv/cpp/opencv_legacy.java
Patch:
@@ -91,8 +91,8 @@
  */
 @Properties(inherit={opencv_calib3d.class, opencv_features2d.class, opencv_video.class, opencv_ml.class}, value={
     @Platform(include={"<opencv2/legacy/compat.hpp>", "<opencv2/legacy/legacy.hpp>",
-        "<opencv2/legacy/blobtrack.hpp>"}, link={"opencv_legacy@.2.4", "opencv_gpu@.2.4"}),
-    @Platform(value="windows", link={"opencv_legacy248", "opencv_gpu248"}),
+        "<opencv2/legacy/blobtrack.hpp>"}, link={"opencv_legacy@.2.4", "opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
+    @Platform(value="windows", link={"opencv_legacy248", "opencv_gpu248", "opencv_ocl248"}),
     @Platform(value="android", link={"opencv_legacy"}) })
 public class opencv_legacy {
     static { load(); }

File: src/main/java/com/googlecode/javacv/cpp/opencv_nonfree.java
Patch:
@@ -77,8 +77,8 @@
 @Properties(inherit={opencv_calib3d.class, opencv_features2d.class, opencv_objdetect.class,
         opencv_photo.class, opencv_ml.class, opencv_legacy.class, opencv_video.class}, value={
     @Platform(include={"<opencv2/nonfree/nonfree.hpp>", "<opencv2/features2d/features2d.hpp>"},
-        link={"opencv_nonfree@.2.4", "opencv_gpu@.2.4"}),
-    @Platform(value="windows", link={"opencv_nonfree248", "opencv_gpu248"}),
+        link={"opencv_nonfree@.2.4", "opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
+    @Platform(value="windows", link={"opencv_nonfree248", "opencv_gpu248", "opencv_ocl248"}),
     @Platform(value="android", link={"opencv_nonfree"}) })
 public class opencv_nonfree {
     static {

File: src/main/java/com/googlecode/javacv/cpp/opencv_stitching.java
Patch:
@@ -85,8 +85,8 @@
 @Properties(inherit={opencv_calib3d.class, opencv_features2d.class, opencv_objdetect.class, opencv_nonfree.class,
         opencv_photo.class, opencv_ml.class, opencv_legacy.class, opencv_video.class}, value={
     @Platform(include={"<opencv2/stitching/stitcher.hpp>", "<opencv2/stitching/detail/autocalib.hpp>"},
-        link={"opencv_stitching@.2.4", "opencv_gpu@.2.4"}),
-    @Platform(value="windows", link={"opencv_stitching248", "opencv_gpu248"}),
+        link={"opencv_stitching@.2.4", "opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
+    @Platform(value="windows", link={"opencv_stitching248", "opencv_gpu248", "opencv_ocl248"}),
     @Platform(value="android", link={"opencv_stitching"}) })
 public class opencv_stitching {
     static { load(); }

File: src/main/java/com/googlecode/javacv/cpp/opencv_videostab.java
Patch:
@@ -79,8 +79,8 @@
  */
 @Properties(inherit={opencv_calib3d.class, opencv_features2d.class, opencv_objdetect.class, opencv_photo.class,
         opencv_nonfree.class, opencv_video.class, opencv_ml.class, opencv_legacy.class}, value={
-    @Platform(include="<opencv2/videostab/videostab.hpp>", link={"opencv_videostab@.2.4", "opencv_gpu@.2.4"}),
-    @Platform(value="windows", link={"opencv_videostab248", "opencv_gpu248"}),
+    @Platform(include="<opencv2/videostab/videostab.hpp>", link={"opencv_videostab@.2.4", "opencv_gpu@.2.4", "opencv_ocl@.2.4"}),
+    @Platform(value="windows", link={"opencv_videostab248", "opencv_gpu248", "opencv_ocl248"}),
     @Platform(value="android", link={"opencv_videostab"}) })
 public class opencv_videostab {
     static { load(); }

File: src/main/java/com/googlecode/javacv/Frame.java
Patch:
@@ -12,4 +12,5 @@ public class Frame {
     public IplImage image;   // for video frame
     public int sampleRate;
     public Buffer[] samples; // for audio frame
+    public Object opaque;
 }

File: src/main/java/com/googlecode/javacv/VideoInputFrameGrabber.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2011,2012 Samuel Audet
+ * Copyright (C) 2011,2012,2013 Samuel Audet
  *
  * This file is part of JavaCV.
  *
@@ -102,8 +102,8 @@ public void start(int connection) throws Exception {
         if (frameRate > 0) {
             myVideoInput.setIdealFramerate(deviceNumber, (int)frameRate);
         }
-        if (imageWidth <= 0 || imageHeight <= 0 ? !myVideoInput.setupDevice(deviceNumber, connection) :
-                !myVideoInput.setupDevice(deviceNumber, imageWidth, imageHeight, connection)) {
+        if (!myVideoInput.setupDevice(deviceNumber, imageWidth  > 0 ? imageWidth  : 640,
+                                                    imageHeight > 0 ? imageHeight : 480, connection)) {
             myVideoInput = null;
             throw new Exception("videoInput.setupDevice() Error: Could not setup device.");
         }

File: src/main/java/com/googlecode/javacv/cpp/opencv_calib3d.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in calib3d.hpp
- * of OpenCV 2.4.7, which are covered by the following copyright notice:
+ * of OpenCV 2.4.8, which are covered by the following copyright notice:
  *
  *                          License Agreement
  *                For Open Source Computer Vision Library
@@ -83,7 +83,7 @@
  */
 @Properties(inherit={opencv_highgui.class, opencv_flann.class, opencv_features2d.class}, value={
     @Platform(include="<opencv2/calib3d/calib3d.hpp>", link="opencv_calib3d@.2.4"),
-    @Platform(value="windows", link="opencv_calib3d247") })
+    @Platform(value="windows", link="opencv_calib3d248") })
 public class opencv_calib3d {
     static { load(); }
 

File: src/main/java/com/googlecode/javacv/cpp/opencv_contrib.java
Patch:
@@ -20,7 +20,7 @@
  *
  * This file is based on information found in contrib.hpp, retina.hpp,
  * detection_based_tracker.hpp, hybrid_tracker.hpp, and openfabmap.hpp
- * of OpenCV 2.4.7, which are covered by the following copyright notice:
+ * of OpenCV 2.4.8, which are covered by the following copyright notice:
  *
  *                           License Agreement
  *                For Open Source Computer Vision Library
@@ -91,7 +91,7 @@
 @Properties(inherit={opencv_calib3d.class, opencv_objdetect.class, opencv_video.class, opencv_ml.class}, value={
     @Platform(include={"<opencv2/contrib/contrib.hpp>", "<opencv2/contrib/detection_based_tracker.hpp>",
         "<opencv2/contrib/hybridtracker.hpp>"}, link="opencv_contrib@.2.4"),
-    @Platform(value="windows", link="opencv_contrib247") })
+    @Platform(value="windows", link="opencv_contrib248") })
 public class opencv_contrib {
     static {
         if (load() != null) {

File: src/main/java/com/googlecode/javacv/cpp/opencv_core.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in core/types_c.h, core_c.h, and
- * core.hpp of OpenCV 2.4.7, which are covered by the following copyright notice:
+ * core.hpp of OpenCV 2.4.8, which are covered by the following copyright notice:
  *
  *                          License Agreement
  *                For Open Source Computer Vision Library
@@ -125,7 +125,7 @@
 @Properties({
     @Platform(include={"<opencv2/core/core.hpp>", "opencv_adapters.h"}, link="opencv_core@.2.4", preload="tbb"),
     @Platform(value="windows", define="_WIN32_WINNT 0x0502", includepath="C:/opencv/build/include/",
-        link="opencv_core247", preload={"msvcr100", "msvcp100"}),
+        link="opencv_core248", preload={"msvcr100", "msvcp100"}),
     @Platform(value="windows-x86",    linkpath="C:/opencv/build/x86/vc10/lib/", preloadpath="C:/opencv/build/x86/vc10/bin/"),
     @Platform(value="windows-x86_64", linkpath="C:/opencv/build/x64/vc10/lib/", preloadpath="C:/opencv/build/x64/vc10/bin/") })
 public class opencv_core {
@@ -144,7 +144,7 @@ public class opencv_core {
     public static final int
             CV_VERSION_EPOCH    = 2,
             CV_VERSION_MAJOR    = 4,
-            CV_VERSION_MINOR    = 7,
+            CV_VERSION_MINOR    = 8,
             CV_VERSION_REVISION = 0,
             CV_MAJOR_VERSION    = CV_VERSION_EPOCH,
             CV_MINOR_VERSION    = CV_VERSION_MAJOR,

File: src/main/java/com/googlecode/javacv/cpp/opencv_features2d.java
Patch:
@@ -18,7 +18,7 @@
  * along with JavaCV.  If not, see <http://www.gnu.org/licenses/>.
  *
  *
- * This file is based on information found in features2d.hpp of OpenCV 2.4.7,
+ * This file is based on information found in features2d.hpp of OpenCV 2.4.8,
  * which is covered by the following copyright notice:
  *
  *                          License Agreement
@@ -81,7 +81,7 @@
  */
 @Properties(inherit={opencv_highgui.class, opencv_flann.class}, value={
     @Platform(include="<opencv2/features2d/features2d.hpp>", link="opencv_features2d@.2.4"),
-    @Platform(value="windows", link="opencv_features2d247") })
+    @Platform(value="windows", link="opencv_features2d248") })
 public class opencv_features2d {
     static {
         if (load() != null) {

File: src/main/java/com/googlecode/javacv/cpp/opencv_flann.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in config.h, defines.h, and miniflann.hpp
- * of OpenCV 2.4.7, which ares covered by the following copyright notice:
+ * of OpenCV 2.4.8, which ares covered by the following copyright notice:
  *
  *                          License Agreement
  *                For Open Source Computer Vision Library
@@ -78,7 +78,7 @@
  */
 @Properties(inherit=opencv_core.class, value={
     @Platform(include="<opencv2/flann/miniflann.hpp>", link="opencv_flann@.2.4"),
-    @Platform(value="windows", link="opencv_flann247") })
+    @Platform(value="windows", link="opencv_flann248") })
 public class opencv_flann {
     static { load(); }
 

File: src/main/java/com/googlecode/javacv/cpp/opencv_imgproc.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in imgproc/types_c.h, imgproc_c.h, and
- * imgproc.hpp of OpenCV 2.4.7, which are covered by the following copyright notice:
+ * imgproc.hpp of OpenCV 2.4.8, which are covered by the following copyright notice:
  *
  *                          License Agreement
  *                For Open Source Computer Vision Library
@@ -86,7 +86,7 @@
  */
 @Properties(inherit=opencv_core.class, value={
     @Platform(include={"<opencv2/imgproc/imgproc_c.h>", "<opencv2/imgproc/imgproc.hpp>"}, link="opencv_imgproc@.2.4"),
-    @Platform(value="windows", link="opencv_imgproc247") })
+    @Platform(value="windows", link="opencv_imgproc248") })
 public class opencv_imgproc {
     static { load(); }
 

File: src/main/java/com/googlecode/javacv/cpp/opencv_legacy.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in compat.hpp, legacy.hpp, and
- * blobtrack.hpp of OpenCV 2.4.7, which are covered by the following copyright notice:
+ * blobtrack.hpp of OpenCV 2.4.8, which are covered by the following copyright notice:
  *
  *                        Intel License Agreement
  *                For Open Source Computer Vision Library
@@ -92,7 +92,7 @@
 @Properties(inherit={opencv_calib3d.class, opencv_features2d.class, opencv_video.class, opencv_ml.class}, value={
     @Platform(include={"<opencv2/legacy/compat.hpp>", "<opencv2/legacy/legacy.hpp>",
         "<opencv2/legacy/blobtrack.hpp>"}, link={"opencv_legacy@.2.4", "opencv_gpu@.2.4"}),
-    @Platform(value="windows", link={"opencv_legacy247", "opencv_gpu247"}),
+    @Platform(value="windows", link={"opencv_legacy248", "opencv_gpu248"}),
     @Platform(value="android", link={"opencv_legacy"}) })
 public class opencv_legacy {
     static { load(); }

File: src/main/java/com/googlecode/javacv/cpp/opencv_ml.java
Patch:
@@ -18,7 +18,7 @@
  * along with JavaCV.  If not, see <http://www.gnu.org/licenses/>.
  *
  *
- * This file is based on information found in ml.hpp of OpenCV 2.4.7,
+ * This file is based on information found in ml.hpp of OpenCV 2.4.8,
  * which is covered by the following copyright notice:
  *
  *                        Intel License Agreement
@@ -87,7 +87,7 @@
  */
 @Properties(inherit=opencv_core.class, value={
     @Platform(include="<opencv2/ml/ml.hpp>", link="opencv_ml@.2.4"),
-    @Platform(value="windows", link="opencv_ml247") })
+    @Platform(value="windows", link="opencv_ml248") })
 public class opencv_ml {
     static { load(opencv_core.class);
         if (load() != null) {

File: src/main/java/com/googlecode/javacv/cpp/opencv_nonfree.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in nonfree/features2d.hpp and
- * nonfree.hpp of OpenCV 2.4.7, which are covered by the following copyright notice:
+ * nonfree.hpp of OpenCV 2.4.8, which are covered by the following copyright notice:
  *
  *                          License Agreement
  *                For Open Source Computer Vision Library
@@ -78,7 +78,7 @@
         opencv_photo.class, opencv_ml.class, opencv_legacy.class, opencv_video.class}, value={
     @Platform(include={"<opencv2/nonfree/nonfree.hpp>", "<opencv2/features2d/features2d.hpp>"},
         link={"opencv_nonfree@.2.4", "opencv_gpu@.2.4"}),
-    @Platform(value="windows", link={"opencv_nonfree247", "opencv_gpu247"}),
+    @Platform(value="windows", link={"opencv_nonfree248", "opencv_gpu248"}),
     @Platform(value="android", link={"opencv_nonfree"}) })
 public class opencv_nonfree {
     static {

File: src/main/java/com/googlecode/javacv/cpp/opencv_objdetect.java
Patch:
@@ -18,7 +18,7 @@
  * along with JavaCV.  If not, see <http://www.gnu.org/licenses/>.
  *
  *
- * This file is based on information found in objdetect.hpp of OpenCV 2.4.7,
+ * This file is based on information found in objdetect.hpp of OpenCV 2.4.8,
  * which is covered by the following copyright notice:
  *
  *                          License Agreement
@@ -86,7 +86,7 @@
  */
 @Properties(inherit=opencv_highgui.class, value={
     @Platform(include="<opencv2/objdetect/objdetect.hpp>", link="opencv_objdetect@.2.4"),
-    @Platform(value="windows", link="opencv_objdetect247") })
+    @Platform(value="windows", link="opencv_objdetect248") })
 public class opencv_objdetect {
     static { load(); }
 

File: src/main/java/com/googlecode/javacv/cpp/opencv_photo.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in photo_c.h and photo.hpp
- * of OpenCV 2.4.7, which are covered by the following copyright notice:
+ * of OpenCV 2.4.8, which are covered by the following copyright notice:
  *
  *                          License Agreement
  *                For Open Source Computer Vision Library
@@ -70,7 +70,7 @@
  */
 @Properties(inherit=opencv_imgproc.class, value={
     @Platform(include={"<opencv2/photo/photo_c.h>", "<opencv2/photo/photo.hpp>"}, link="opencv_photo@.2.4"),
-    @Platform(value="windows", link="opencv_photo247") })
+    @Platform(value="windows", link="opencv_photo248") })
 public class opencv_photo {
     static { load(); }
 

File: src/main/java/com/googlecode/javacv/cpp/opencv_stitching.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in stitcher.hpp and all included
- * files of of OpenCV 2.4.7, which are covered by the following copyright notice:
+ * files of of OpenCV 2.4.8, which are covered by the following copyright notice:
  *
  *                          License Agreement
  *                For Open Source Computer Vision Library
@@ -86,7 +86,7 @@
         opencv_photo.class, opencv_ml.class, opencv_legacy.class, opencv_video.class}, value={
     @Platform(include={"<opencv2/stitching/stitcher.hpp>", "<opencv2/stitching/detail/autocalib.hpp>"},
         link={"opencv_stitching@.2.4", "opencv_gpu@.2.4"}),
-    @Platform(value="windows", link={"opencv_stitching247", "opencv_gpu247"}),
+    @Platform(value="windows", link={"opencv_stitching248", "opencv_gpu248"}),
     @Platform(value="android", link={"opencv_stitching"}) })
 public class opencv_stitching {
     static { load(); }

File: src/main/java/com/googlecode/javacv/cpp/opencv_video.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in tracking.hpp and background_segm.hpp
- * of OpenCV 2.4.7, which are covered by the following copyright notice:
+ * of OpenCV 2.4.8, which are covered by the following copyright notice:
  *
  *                          License Agreement
  *                For Open Source Computer Vision Library
@@ -78,7 +78,7 @@
  */
 @Properties(inherit=opencv_imgproc.class, value={
     @Platform(include="<opencv2/video/video.hpp>", link="opencv_video@.2.4"),
-    @Platform(value="windows", link="opencv_video247") })
+    @Platform(value="windows", link="opencv_video248") })
 public class opencv_video {
     static { load(opencv_imgproc.class);
         if (load() != null) {

File: src/main/java/com/googlecode/javacv/cpp/opencv_videostab.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in videostab.hpp and all included
- * files of OpenCV 2.4.7, which are covered by the following copyright notice:
+ * files of OpenCV 2.4.8, which are covered by the following copyright notice:
  *
  *                          License Agreement
  *                For Open Source Computer Vision Library
@@ -80,7 +80,7 @@
 @Properties(inherit={opencv_calib3d.class, opencv_features2d.class, opencv_objdetect.class, opencv_photo.class,
         opencv_nonfree.class, opencv_video.class, opencv_ml.class, opencv_legacy.class}, value={
     @Platform(include="<opencv2/videostab/videostab.hpp>", link={"opencv_videostab@.2.4", "opencv_gpu@.2.4"}),
-    @Platform(value="windows", link={"opencv_videostab247", "opencv_gpu247"}),
+    @Platform(value="windows", link={"opencv_videostab248", "opencv_gpu248"}),
     @Platform(value="android", link={"opencv_videostab"}) })
 public class opencv_videostab {
     static { load(); }

File: src/main/java/com/googlecode/javacv/FFmpegFrameGrabber.java
Patch:
@@ -528,6 +528,7 @@ private Frame grabFrame(boolean processImage, boolean doAudio) throws Exception
         }
         frame.keyFrame = false;
         frame.image = null;
+        frame.sampleRate = 0;
         frame.samples = null;
         if (frameGrabbed) {
             frameGrabbed = false;
@@ -603,6 +604,7 @@ private Frame grabFrame(boolean processImage, boolean doAudio) throws Exception
                             samples_buf = new Buffer[planes];
                         }
                         frame.keyFrame = samples_frame.key_frame() != 0;
+                        frame.sampleRate = audio_c.sample_rate();
                         frame.samples = samples_buf;
                         int sample_size = data_size / av_get_bytes_per_sample(sample_format);
                         for (int i = 0; i < planes; i++) {

File: src/main/java/com/googlecode/javacv/Frame.java
Patch:
@@ -10,5 +10,6 @@
 public class Frame {
     public boolean keyFrame;
     public IplImage image;   // for video frame
+    public int sampleRate;
     public Buffer[] samples; // for audio frame
 }

File: samples/MotionDetector.java
Patch:
@@ -33,6 +33,8 @@ public static void main(String[] args) throws Exception {
         CvMemStorage storage = CvMemStorage.create();
 
         while (canvasFrame.isVisible() && (frame = grabber.grab()) != null) {
+            cvClearMemStorage(storage);
+
             cvSmooth(frame, frame, CV_GAUSSIAN, 9, 9, 2, 2);
             if (image == null) {
                 image = IplImage.create(frame.width(), frame.height(), IPL_DEPTH_8U, 1);

File: src/main/java/com/googlecode/javacv/FFmpegFrameGrabber.java
Patch:
@@ -547,7 +547,7 @@ private Frame grabFrame(boolean processImage, boolean doAudio) throws Exception
                     AVRational time_base = video_st.time_base();
                     timestamp = 1000000L * pts * time_base.num() / time_base.den();
                     // best guess, AVCodecContext.frame_number = number of decoded frames...
-                    frameNumber = (int)(1000000L * getFrameRate() / timestamp);
+                    frameNumber = (int)(timestamp * getFrameRate() / 1000000L);
                     if (processImage) {
                         processImage();
                     }

File: src/main/java/com/googlecode/javacv/cpp/cvkernels.java
Patch:
@@ -41,7 +41,7 @@
  * @author Samuel Audet
  */
 @Properties(inherit=opencv_core.class, value={
-    @Platform(define="MAX_SIZE 16", include="cvkernels.h", options="fastfpu") })
+    @Platform(define={"MAX_SIZE 16", "CV_INLINE static inline"}, include="cvkernels.h", options="fastfpu") })
 public class cvkernels {
     static { load(); }
 

File: src/main/java/com/googlecode/javacv/cpp/opencv_legacy.java
Patch:
@@ -99,7 +99,9 @@
               "opencv_flann245", "opencv_calib3d245", "opencv_highgui245", "opencv_imgproc245", "opencv_core245"}),
     @Platform(value="windows-x86",    linkpath=windowsx86Linkpath, preloadpath=windowsx86Preloadpath),
     @Platform(value="windows-x86_64", linkpath=windowsx64Linkpath, preloadpath=windowsx64Preloadpath),
-    @Platform(value="android", includepath=androidIncludepath, linkpath=androidLinkpath) })
+    @Platform(value="android", includepath=androidIncludepath, linkpath=androidLinkpath,
+        link={"opencv_legacy", "opencv_nonfree", "opencv_ml", "opencv_video", "opencv_features2d",
+              "opencv_flann", "opencv_calib3d", "opencv_highgui", "opencv_imgproc", "opencv_core"}) })
 public class opencv_legacy {
     static {
         load(opencv_calib3d.class); load(opencv_features2d.class); load(opencv_video.class);

File: samples/RecordActivity.java
Patch:
@@ -321,9 +321,9 @@ public void run() {
             int bufferReadResult;
 
             bufferSize = AudioRecord.getMinBufferSize(sampleAudioRateInHz, 
-                    AudioFormat.CHANNEL_CONFIGURATION_MONO, AudioFormat.ENCODING_PCM_16BIT);
+                    AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT);
             audioRecord = new AudioRecord(MediaRecorder.AudioSource.MIC, sampleAudioRateInHz, 
-                    AudioFormat.CHANNEL_CONFIGURATION_MONO, AudioFormat.ENCODING_PCM_16BIT, bufferSize);
+                    AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT, bufferSize);
 
             audioData = new short[bufferSize];
 

File: src/main/java/com/googlecode/javacv/FFmpegFrameGrabber.java
Patch:
@@ -507,6 +507,7 @@ private IplImage grab(boolean processImage) throws Exception {
         return grabFrame(true, true);
     }
     private Frame grabFrame(boolean processImage, boolean doAudio) throws Exception {
+        frame.keyFrame = false;
         frame.image = null;
         frame.samples = null;
         if (frameGrabbed) {
@@ -547,6 +548,7 @@ private Frame grabFrame(boolean processImage, boolean doAudio) throws Exception
                         processImage();
                     }
                     done = true;
+                    frame.keyFrame = picture.key_frame() != 0;
                     frame.image = return_image;
                 }
             } else if (doAudio && audio_st != null && pkt.stream_index() == audio_st.index()) {
@@ -575,6 +577,7 @@ private Frame grabFrame(boolean processImage, boolean doAudio) throws Exception
                             samples_ptr = new BytePointer[planes];
                             samples_buf = new Buffer[planes];
                         }
+                        frame.keyFrame = samples_frame.key_frame() != 0;
                         frame.samples = samples_buf;
                         int sample_size = data_size / av_get_bytes_per_sample(sample_format);
                         for (int i = 0; i < planes; i++) {

File: src/main/java/com/googlecode/javacv/Frame.java
Patch:
@@ -8,6 +8,7 @@
  * @author Samuel Audet
  */
 public class Frame {
+    public boolean keyFrame;
     public IplImage image;   // for video frame
     public Buffer[] samples; // for audio frame
 }

File: src/main/java/com/googlecode/javacv/OpenCVFrameRecorder.java
Patch:
@@ -85,13 +85,14 @@ public void stop() throws Exception {
         release();
     }
 
-    public void record(IplImage frame) throws Exception {
+    public boolean record(IplImage frame) throws Exception {
         if (writer != null) {
             if (cvWriteFrame(writer, frame) == 0) {
                 throw new Exception("cvWriteFrame(): Could not record frame");
             }
         } else {
             throw new Exception("Cannot record: There is no writer (Has start() been called?)");
         }
+        return true;
     }
 }

File: src/main/java/com/googlecode/javacv/cpp/opencv_legacy.java
Patch:
@@ -92,16 +92,16 @@
 @Properties({
     @Platform(includepath=genericIncludepath, linkpath=genericLinkpath,
         include={"<opencv2/legacy/compat.hpp>", "<opencv2/legacy/legacy.hpp>", "<opencv2/legacy/blobtrack.hpp>", "opencv_adapters.h"},
-        link={"opencv_legacy@.2.4", "opencv_ml@.2.4", "opencv_video@.2.4","opencv_nonfree@.2.4", "opencv_features2d@.2.4",
+        link={"opencv_legacy@.2.4", "opencv_ml@.2.4", "opencv_video@.2.4", "opencv_features2d@.2.4",
               "opencv_flann@.2.4", "opencv_calib3d@.2.4", "opencv_highgui@.2.4", "opencv_imgproc@.2.4", "opencv_core@.2.4"}),
     @Platform(value="windows", includepath=windowsIncludepath,
-        link={"opencv_legacy245", "opencv_ml245", "opencv_video245", "opencv_nonfree245", "opencv_features2d245",
+        link={"opencv_legacy245", "opencv_ml245", "opencv_video245", "opencv_features2d245",
               "opencv_flann245", "opencv_calib3d245", "opencv_highgui245", "opencv_imgproc245", "opencv_core245"}),
     @Platform(value="windows-x86",    linkpath=windowsx86Linkpath, preloadpath=windowsx86Preloadpath),
     @Platform(value="windows-x86_64", linkpath=windowsx64Linkpath, preloadpath=windowsx64Preloadpath),
     @Platform(value="android", includepath=androidIncludepath, linkpath=androidLinkpath) })
 public class opencv_legacy {
-    static { load(opencv_calib3d.class); load(opencv_features2d.class); load(opencv_nonfree.class); load(opencv_video.class); load(opencv_ml.class); load(); }
+    static { load(opencv_calib3d.class); load(opencv_features2d.class); load(opencv_video.class); load(opencv_ml.class); load(); }
 
     public static float cvQueryHistValue_1D(CvHistogram hist, int idx0) {
         return (float)cvGetReal1D(hist.bins(), idx0);

File: src/main/java/com/googlecode/javacv/FrameRecorder.java
Patch:
@@ -255,7 +255,7 @@ public static class Exception extends java.lang.Exception {
     public abstract void start() throws Exception;
     public abstract void stop() throws Exception;
     public abstract void record(IplImage image) throws Exception;
-    public void record(Buffer[] samples) throws Exception {
+    public void record(Buffer ... samples) throws Exception {
         throw new UnsupportedOperationException("This FrameRecorder does not support audio.");
     }
     public void record(Frame frame) throws Exception {

File: samples/FaceRecognition.java
Patch:
@@ -544,7 +544,7 @@ private CvMat loadTrainingData() {
     pAvgTrainImg = new IplImage(pointer);
 
     eigenVectArr = new IplImage[nTrainFaces];
-    for (i = 0; i < nEigens; i++) {
+    for (i = 0; i <= nEigens; i++) {
       String varname = "eigenVect_" + i;
       pointer = cvReadByName(
               fileStorage,

File: src/main/java/com/googlecode/javacv/cpp/opencv_stitching.java
Patch:
@@ -1114,8 +1114,8 @@ private native void allocate(int cost_type/*=COST_COLOR_GRAD*/,
         public native void prepare(@Const @StdVector("CvPoint,cv::Point") CvPoint corners,
                 @Const @StdVector("CvSize,cv::Size") CvSize sizes);
         public native void prepare(@ByVal CvRect dst_roi);
-        public native void feed(@InputMat CvArr img, @InputMat CvArr mask, @ByVal CvPoint tl);
-        public native void blend(@InputMat CvArr dst, @InputMat CvArr dst_mask);
+        public native void feed(@InputMat IplImage img, @InputMat IplImage mask, @ByVal CvPoint tl);
+        public native void blend(@OutputMat IplImage dst, @OutputMat IplImage dst_mask);
 
 //        protected native @OutputMat CvMat dst_();
 //        protected native @OutputMat CvMat dst_mask_();

File: src/main/java/com/googlecode/javacv/cpp/opencv_core.java
Patch:
@@ -159,7 +159,7 @@ public class opencv_core {
 
     public static final String CV_VERSION = CV_MAJOR_VERSION + "." + CV_MINOR_VERSION + "." + CV_SUBMINOR_VERSION;
 
-    @Opaque public static abstract class CvArr extends Pointer implements Cloneable {
+    @Opaque public static class CvArr extends Pointer implements Cloneable {
         static { load(); }
         protected CvArr() { }
         protected CvArr(Pointer p) { super(p); }

File: src/main/java/com/googlecode/javacv/OpenCVFrameGrabber.java
Patch:
@@ -143,7 +143,7 @@ public void release() throws Exception {
     }
 
     @Override public long getTimestamp() {
-        return capture == null ? super.getFrameNumber() :
+        return capture == null ? super.getTimestamp() :
                 Math.round(cvGetCaptureProperty(capture, CV_CAP_PROP_POS_MSEC)*1000);
     }
     @Override public void setTimestamp(long timestamp) throws Exception {

File: src/main/java/com/googlecode/javacv/cpp/avdevice.java
Patch:
@@ -53,7 +53,7 @@
  */
 @Properties({
     @Platform(define="__STDC_CONSTANT_MACROS", cinclude="<libavdevice/avdevice.h>",
-        includepath=genericIncludepath, linkpath=genericLinkpath, link={"avdevice@.54", "avfilter@.2",
+        includepath=genericIncludepath, linkpath=genericLinkpath, link={"avdevice@.54", "avfilter@.3",
         "swscale@.2", "swresample@.0", "postproc@.52", "avformat@.54", "avcodec@.54", "avutil@.51"}),
     @Platform(value="windows", includepath=windowsIncludepath, linkpath=windowsLinkpath,
         preloadpath=windowsPreloadpath, preload="avdevice-54"),

File: src/main/java/com/googlecode/javacv/cpp/avutil.java
Patch:
@@ -69,7 +69,7 @@
         "<libavutil/cpu.h>", "<libavutil/dict.h>", "<libavutil/opt.h>", "<libavutil/samplefmt.h>", "<libavutil/imgutils.h>"},
         includepath=genericIncludepath, linkpath=genericLinkpath, link="avutil@.51"),
     @Platform(value="windows", includepath=windowsIncludepath, linkpath=windowsLinkpath,
-        preloadpath=windowsPreloadpath, preload="avutil-51"),
+        preloadpath=windowsPreloadpath, preload={"avutil-51", "avutil-52"}),
     @Platform(value="android", includepath=androidIncludepath, linkpath=androidLinkpath) })
 public class avutil {
     static { load(); }

File: src/main/java/com/googlecode/javacv/FFmpegFrameRecorder.java
Patch:
@@ -76,6 +76,8 @@
  * @author Samuel Audet
  */
 public class FFmpegFrameRecorder extends FrameRecorder {
+    public static FFmpegFrameRecorder createDefault(File f, int w, int h)   throws Exception { return new FFmpegFrameRecorder(f, w, h); }
+    public static FFmpegFrameRecorder createDefault(String f, int w, int h) throws Exception { return new FFmpegFrameRecorder(f, w, h); }
 
     private static Exception loadingException = null;
     public static void tryLoad() throws Exception {
@@ -367,7 +369,7 @@ public void start() throws Exception {
         /*
          * add an audio output stream
          */
-        if (audioChannels > 0) {
+        if (audioChannels > 0 && audioBitrate > 0 && sampleRate > 0) {
             if (audioCodec != AV_CODEC_ID_NONE) {
                 oformat.audio_codec(audioCodec);
             } else if ("flv".equals(format_name) || "mp4".equals(format_name) || "3gp".equals(format_name)) {

File: src/main/java/com/googlecode/javacv/FrameGrabber.java
Patch:
@@ -172,7 +172,7 @@ public static enum ImageMode {
     protected long sensorPattern = -1L;
     protected int pixelFormat = -1;
     protected double frameRate = 0;
-    protected int sampleFormat, sampleRate;
+    protected int sampleFormat = 0, sampleRate = 0;
     protected boolean triggerMode = false;
     protected int bpp = 0;
     protected int timeout = 10000;

File: src/main/java/com/googlecode/javacv/OpenCVFrameRecorder.java
Patch:
@@ -31,6 +31,8 @@
  * @author Samuel Audet
  */
 public class OpenCVFrameRecorder extends FrameRecorder {
+    public static OpenCVFrameRecorder createDefault(File f, int w, int h)   throws Exception { return new OpenCVFrameRecorder(f, w, h); }
+    public static OpenCVFrameRecorder createDefault(String f, int w, int h) throws Exception { return new OpenCVFrameRecorder(f, w, h); }
 
     private static Exception loadingException = null;
     public static void tryLoad() throws Exception {

File: src/main/java/com/googlecode/javacv/cpp/opencv_ml.java
Patch:
@@ -18,7 +18,7 @@
  * along with JavaCV.  If not, see <http://www.gnu.org/licenses/>.
  *
  *
- * This file is based on information found in ml.hpp of OpenCV 2.4.2,
+ * This file is based on information found in ml.hpp of OpenCV 2.4.3rc,
  * which is covered by the following copyright notice:
  *
  *                        Intel License Agreement
@@ -88,7 +88,7 @@
 @Properties({
     @Platform(includepath=genericIncludepath, linkpath=genericLinkpath,
         include={"<opencv2/ml/ml.hpp>", "opencv_adapters.h"}, link={"opencv_ml@.2.4", "opencv_core@.2.4"}),
-    @Platform(value="windows", includepath=windowsIncludepath, link={"opencv_ml242", "opencv_core242"}),
+    @Platform(value="windows", includepath=windowsIncludepath, link={"opencv_ml243", "opencv_core243"}),
     @Platform(value="windows-x86",    linkpath=windowsx86Linkpath, preloadpath=windowsx86Preloadpath),
     @Platform(value="windows-x86_64", linkpath=windowsx64Linkpath, preloadpath=windowsx64Preloadpath),
     @Platform(value="android", includepath=androidIncludepath, linkpath=androidLinkpath) })

File: src/main/java/com/googlecode/javacv/cpp/opencv_nonfree.java
Patch:
@@ -19,7 +19,7 @@
  *
  *
  * This file is based on information found in nonfree/features2d.hpp and
- * nonfree.hpp of OpenCV 2.4.2, which are covered by the following copyright notice:
+ * nonfree.hpp of OpenCV 2.4.3rc, which are covered by the following copyright notice:
  *
  *                          License Agreement
  *                For Open Source Computer Vision Library
@@ -79,7 +79,7 @@
         include={"<opencv2/nonfree/nonfree.hpp>", "<opencv2/features2d/features2d.hpp>", "opencv_adapters.h"},
         link={"opencv_nonfree@.2.4", "opencv_features2d@.2.4", "opencv_flann@.2.4", "opencv_highgui@.2.4", "opencv_imgproc@2.4", "opencv_core@.2.4"}),
     @Platform(value="windows", includepath=windowsIncludepath,
-        link={"opencv_nonfree242", "opencv_features2d242", "opencv_flann242", "opencv_highgui242", "opencv_imgproc242", "opencv_core242"}),
+        link={"opencv_nonfree243", "opencv_features2d243", "opencv_flann243", "opencv_highgui243", "opencv_imgproc243", "opencv_core243"}),
     @Platform(value="windows-x86",    linkpath=windowsx86Linkpath, preloadpath=windowsx86Preloadpath),
     @Platform(value="windows-x86_64", linkpath=windowsx64Linkpath, preloadpath=windowsx64Preloadpath),
     @Platform(value="android", includepath=androidIncludepath, linkpath=androidLinkpath) })

File: src/main/java/com/googlecode/javacv/FFmpegFrameRecorder.java
Patch:
@@ -236,10 +236,10 @@ public void release() throws Exception {
 
     // best guess for timestamp in microseconds...
     @Override public long getTimestamp() {
-        return (long)(getFrameNumber() * 1000000 / getFrameRate());
+        return Math.round(getFrameNumber() * 1000000L / getFrameRate());
     }
     @Override public void setTimestamp(long timestamp)  {
-        setTimestamp((int)(timestamp * getFrameRate() / 1000000));
+        setFrameNumber((int)Math.round(timestamp * getFrameRate() / 1000000L));
     }
 
     public void start() throws Exception {

File: src/main/java/com/googlecode/javacv/FlyCaptureFrameGrabber.java
Patch:
@@ -463,7 +463,7 @@ public IplImage grab() throws Exception {
         }
 
         FlyCaptureTimestamp timeStamp = raw_image.timeStamp();
-        timestamp = timeStamp.ulSeconds()*1000000 + timeStamp.ulMicroSeconds();
+        timestamp = timeStamp.ulSeconds() * 1000000L + timeStamp.ulMicroSeconds();
         return return_image;
     }
 }

File: src/main/java/com/googlecode/javacv/OpenCVFrameGrabber.java
Patch:
@@ -157,7 +157,7 @@ public void release() throws Exception {
                 (int)cvGetCaptureProperty(capture, CV_CAP_PROP_FRAME_COUNT);
     }
     @Override public long getLengthInTime() {
-        return Math.round(getLengthInFrames() * 1000000 / getFrameRate());
+        return Math.round(getLengthInFrames() * 1000000L / getFrameRate());
     }
 
     public void start() throws Exception {

File: src/main/java/com/googlecode/javacv/FFmpegFrameGrabber.java
Patch:
@@ -147,7 +147,7 @@ public void release() throws Exception {
             oc = null;
         }
 
-        if (img_convert_ctx != null && !img_convert_ctx.isNull()) {
+        if (img_convert_ctx != null) {
             sws_freeContext(img_convert_ctx);
             img_convert_ctx = null;
         }
@@ -272,7 +272,7 @@ public void release() throws Exception {
 
     @Override public int getLengthInFrames() {
         // best guess...
-        return (int)(1000000 * getFrameRate() / getLengthInTime());
+        return (int)(getLengthInTime() * getFrameRate() / 1000000);
     }
     @Override public long getLengthInTime() {
         return oc.duration() * 1000000 / AV_TIME_BASE;

File: src/main/java/com/googlecode/javacv/cpp/ARToolKitPlus.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2009,2010,2011 Samuel Audet
+ * Copyright (C) 2009,2010,2011,2012 Samuel Audet
  *
  * This file is part of JavaCV.
  *

File: src/main/java/com/googlecode/javacv/cpp/cvkernels.java
Patch:
@@ -96,7 +96,7 @@ public KernelData dstDstDot(DoubleBuffer dstDstDot) {
             return setDstDstDot(dstDstDot);
         }
 
-        private native @Name("operator=") @ByRef KernelData copy(@ByRef KernelData x);
+        private native @Name("operator=") @ByRef KernelData put(@ByRef KernelData x);
     }
 
     private static class ParallelData {
@@ -134,7 +134,7 @@ public static void multiWarpColorTransform(final KernelData data, final CvRect r
             }
             for (int j = 0; j < size; j++) {
                 KernelData d = pd[i].data.position(j);
-                d.copy(data.position(j));
+                d.put(data.position(j));
                 d.dstDstDot(d.dstDstDot()); // reset dstDstDot pointer
             }
         }

File: src/main/java/com/googlecode/javacv/cpp/swresample.java
Patch:
@@ -42,8 +42,8 @@
 
 package com.googlecode.javacv.cpp;
 
-import com.googlecode.javacpp.BytePointer;
 import com.googlecode.javacpp.Pointer;
+import com.googlecode.javacpp.PointerPointer;
 import com.googlecode.javacpp.annotation.ByPtrPtr;
 import com.googlecode.javacpp.annotation.Cast;
 import com.googlecode.javacpp.annotation.Const;
@@ -174,8 +174,8 @@ public static native SwrContext swr_alloc_set_opts(SwrContext s,
      * @return number of samples output per channel, negative value on error
      */
     public static native int swr_convert(SwrContext s,
-                  @Cast("uint8_t**") BytePointer out, int out_count,
-            @Cast("const uint8_t**") BytePointer in , int in_count);
+                  @Cast("uint8_t**") PointerPointer out, int out_count,
+            @Cast("const uint8_t**") PointerPointer in , int in_count);
 
     /**
      * Convert the next timestamp from input to output

File: src/main/java/com/googlecode/javacv/FFmpegFrameGrabber.java
Patch:
@@ -21,8 +21,8 @@
  * Based on the avcodec_sample.0.5.0.c file available at
  * http://web.me.com/dhoerl/Home/Tech_Blog/Entries/2009/1/22_Revised_avcodec_sample.c_files/avcodec_sample.0.5.0.c
  * by Martin Böhme, Stephen Dranger, and David Hoerl
- * as well as on the decoding_encoding.c file included in FFmpeg 0.11.1, which is
- * covered by the following copyright notice:
+ * as well as on the decoding_encoding.c file included in FFmpeg 0.11.1,
+ * which is covered by the following copyright notice:
  *
  * Copyright (c) 2001 Fabrice Bellard
  *

File: src/main/java/com/googlecode/javacv/cpp/opencv_features2d.java
Patch:
@@ -313,17 +313,17 @@ private native void allocate(int nfeatures/*=500*/, float scaleFactor/*=1.2*/, i
         public static final int kBytes = 32, HARRIS_SCORE=0, FAST_SCORE=1;
         public FREAK() { allocate(); }
         public FREAK(Pointer p) { super(p); }
-        public FREAK(FREAK rhs) { allocate(rhs); }
+//        public FREAK(FREAK rhs) { allocate(rhs); }
         public FREAK(boolean orientationNormalized/*=true*/, boolean scaleNormalized/*=true*/,
                float patternScale/*=22.0f*/, int nOctaves/*=4*/, @Adapter("VectorAdapter<int>") IntPointer selectedPairs/*=null*/) {
             allocate(orientationNormalized, scaleNormalized, patternScale, nOctaves, selectedPairs);
         }
         private native void allocate();
-        private native void allocate(@ByRef FREAK rhs);
+//        private native void allocate(@ByRef FREAK rhs);
         private native void allocate(boolean orientationNormalized/*=true*/, boolean scaleNormalized/*=true*/,
                float patternScale/*=22.0f*/, int nOctaves/*=4*/, @Adapter("VectorAdapter<int>") IntPointer selectedPairs/*=null*/);
 
-        public native @Name("operator=") @ByRef FREAK copy(@ByRef FREAK rhs);
+//        public native @Name("operator=") @ByRef FREAK copy(@ByRef FREAK rhs);
 
 //        public native int descriptorSize();
 //        public native int descriptorType();

File: src/main/java/com/googlecode/javacv/cpp/avdevice.java
Patch:
@@ -82,7 +82,7 @@ public class avdevice {
      * @}
      */
 
-    public static final int LIBAVDEVICE_VERSION_MAJOR = 52;
+    public static final int LIBAVDEVICE_VERSION_MAJOR = 54;
     public static final int LIBAVDEVICE_VERSION_MINOR =  0;
     public static final int LIBAVDEVICE_VERSION_MICRO = 100;
 

File: src/main/java/com/googlecode/javacv/FrameRecorder.java
Patch:
@@ -205,7 +205,7 @@ public void record(Buffer samples) throws Exception {
         throw new UnsupportedOperationException("This FrameRecorder does not support audio.");
     }
     public void record(Frame frame) throws Exception {
-        if (frame == null) {
+        if (frame == null || (frame.image == null && frame.samples == null)) {
             record((IplImage)null);
         } else {
             if (frame.image != null) {

File: src/main/java/com/googlecode/javacv/FFmpegFrameGrabber.java
Patch:
@@ -209,7 +209,7 @@ public void start() throws Exception {
         AVFormatParameters fp = null;
         if (frameRate > 0 || bpp > 0 || imageWidth > 0 || imageHeight > 0) {
             fp = new AVFormatParameters();
-            fp.time_base(av_d2q(1/frameRate, FFmpegFrameRecorder.DEFAULT_FRAME_RATE_BASE));
+            fp.time_base(av_d2q(1/frameRate, 1001000));
             fp.sample_rate(bpp);
             fp.channels(imageMode == ImageMode.COLOR ? 3 : 1);
             fp.width(imageWidth);

File: src/main/java/com/googlecode/javacv/cpp/ARToolKitPlus.java
Patch:
@@ -164,7 +164,7 @@ public static class ARMultiMarkerInfoT extends Pointer {
         @MemberGetter public native @Cast("ARFloat(*)[4]") DoublePointer transR();
     }
 
-    @Opaque public static class Logger extends Pointer {
+    public static class Logger extends Pointer {
         static { load(); }
         public Logger() { }
         public Logger(Pointer p) { super(p); }
@@ -182,7 +182,7 @@ public Profiler() { }
         public Profiler(Pointer p) { super(p); }
     }
 
-    @Opaque public static class Tracker extends Pointer {
+    public static class Tracker extends Pointer {
         static { load(); }
         public Tracker() { }
         public Tracker(Pointer p) { super(p); }
@@ -265,7 +265,7 @@ public static class ArtLogFunction extends FunctionPointer {
         protected final native void allocate();
         public native void call(String nStr);
     }
-    @Opaque public static class FunctionLogger extends Logger {
+    public static class FunctionLogger extends Logger {
         static { load(); }
         public FunctionLogger(ArtLogFunction f) {  allocate(f); }
         public FunctionLogger(Pointer p) { super(p); }

File: src/main/java/com/googlecode/javacv/cpp/opencv_contrib.java
Patch:
@@ -843,7 +843,7 @@ public LDA(@Adapter("ArrayAdapter") CvArr src, @Adapter("ArrayAdapter") CvArr la
         public FaceRecognizer() { }
         public FaceRecognizer(Pointer p) { super(p); }
 
-        public /*abstract*/ native void train(@Adapter("ArrayAdapter") CvArr src, @Adapter("ArrayAdapter") CvArr labels);
+        public /*abstract*/ native void train(@ByRef MatVector src, @Adapter("ArrayAdapter") CvArr labels);
         public /*abstract*/ native int predict(@Adapter("ArrayAdapter") CvArr src);
         public native void save(String filename);
         public native void load(String filename);

File: src/main/java/com/googlecode/javacv/cpp/opencv_legacy.java
Patch:
@@ -100,7 +100,7 @@
     @Platform(value="windows-x86_64", linkpath=windowsx64Linkpath, preloadpath=windowsx64Preloadpath),
     @Platform(value="android", includepath=androidIncludepath, linkpath=androidLinkpath) })
 public class opencv_legacy {
-    static { load(opencv_features2d.class); load(opencv_nonfree.class); load(opencv_video.class); load(opencv_ml.class); load(); }
+    static { load(opencv_calib3d.class); load(opencv_features2d.class); load(opencv_nonfree.class); load(opencv_video.class); load(opencv_ml.class); load(); }
 
     public static float cvQueryHistValue_1D(CvHistogram hist, int idx0) {
         return (float)cvGetReal1D(hist.bins(), idx0);

File: src/main/java/com/googlecode/javacv/ObjectFinder.java
Patch:
@@ -35,10 +35,10 @@
 
 import static com.googlecode.javacv.cpp.opencv_calib3d.*;
 import static com.googlecode.javacv.cpp.opencv_core.*;
-import static com.googlecode.javacv.cpp.opencv_features2d.*;
 import static com.googlecode.javacv.cpp.opencv_flann.*;
 import static com.googlecode.javacv.cpp.opencv_highgui.*;
 import static com.googlecode.javacv.cpp.opencv_imgproc.*;
+import static com.googlecode.javacv.cpp.opencv_legacy.*;
 
 /**
  *
@@ -369,6 +369,7 @@ public static void main(String[] args) throws Exception {
         ObjectFinder.Settings settings = new ObjectFinder.Settings();
         settings.objectImage = object;
         settings.useFLANN = true;
+        settings.ransacReprojThreshold = 5;
         ObjectFinder finder = new ObjectFinder(settings);
 
         long start = System.currentTimeMillis();

File: src/main/java/com/googlecode/javacv/cpp/avutil.java
Patch:
@@ -76,7 +76,7 @@ public class avutil {
     static { load(); }
     public static final String genericIncludepath = "/opt/local/include/ffmpeg/:/usr/local/include/ffmpeg/:/opt/local/include/:/usr/include/ffmpeg/";
     public static final String genericLinkpath    = "/opt/local/lib/:/opt/local/lib64/:/usr/local/lib/:/usr/local/lib64/";
-    public static final String windowsIncludepath = "C:/MinGW/local/include/ffmpeg/;C:/MinGW/include/ffmpeg/;C:/MinGW/local/include/;src/com/googlecode/javacv/cpp/";
+    public static final String windowsIncludepath = "C:/MinGW/local/include/ffmpeg/;C:/MinGW/include/ffmpeg/;C:/MinGW/local/include/;src/main/resources/com/googlecode/javacv/cpp/";
     public static final String windowsLinkpath    = "C:/MinGW/local/lib/;C:/MinGW/lib/";
     public static final String windowsPreloadpath = "C:/MinGW/local/bin/;C:/MinGW/bin/";
     public static final String androidIncludepath = "../include/";

