File: powerjob-common/src/main/java/tech/powerjob/common/PowerJobDKey.java
Patch:
@@ -64,4 +64,6 @@ public class PowerJobDKey {
 
     public static final String WORKER_RUNTIME_SWAP_TASK_SCHEDULE_INTERVAL_MS = "powerjob.worker.swap.scan-interval";
 
+    public static final String SERVER_TEST_ACCOUNT_USERNAME = "powerjob.server.test-accounts";
+
 }

File: powerjob-worker/src/main/java/tech/powerjob/worker/core/tracker/task/heavy/CommonTaskTracker.java
Patch:
@@ -232,6 +232,8 @@ private void innerRun() {
 
                             } else {
 
+                                log.info("[TaskTracker-{}] all subTask has done, start to create final task", instanceId);
+
                                 // 不存在，代表前置任务刚刚执行完毕，需要创建 lastTask，最终任务必须在本机执行！
                                 TaskDO newLastTask = new TaskDO();
                                 newLastTask.setTaskName(TaskConstant.LAST_TASK_NAME);

File: powerjob-worker/src/main/java/tech/powerjob/worker/core/tracker/task/heavy/HeavyTaskTracker.java
Patch:
@@ -298,7 +298,7 @@ public boolean submitTask(List<TaskDO> newTaskList) {
      * @param heartbeatReq ProcessorTracker（任务的执行管理器）发来的心跳包，包含了其当前状态
      */
     public void receiveProcessorTrackerHeartbeat(ProcessorTrackerStatusReportReq heartbeatReq) {
-        log.debug("[TaskTracker-{}] receive heartbeat: {}", instanceId, heartbeatReq);
+        log.debug("[TaskTracker-{}] receive PT's heartbeat: {}", instanceId, heartbeatReq);
         ptStatusHolder.updateStatus(heartbeatReq);
 
         // 上报空闲，检查是否已经接收到全部该 ProcessorTracker 负责的任务

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/openapi/OpenApiInterceptor.java
Patch:
@@ -46,6 +46,7 @@ public class OpenApiInterceptor implements HandlerInterceptor {
     public boolean preHandle(@NonNull HttpServletRequest request, @NonNull HttpServletResponse response, @NonNull Object handler) throws Exception {
 
         if (!enableOpenApiAuth) {
+            response.addHeader(OpenAPIConstant.RESPONSE_HEADER_AUTH_STATUS, Boolean.TRUE.toString());
             return true;
         }
 

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/openapi/OpenApiInterceptor.java
Patch:
@@ -46,6 +46,7 @@ public class OpenApiInterceptor implements HandlerInterceptor {
     public boolean preHandle(@NonNull HttpServletRequest request, @NonNull HttpServletResponse response, @NonNull Object handler) throws Exception {
 
         if (!enableOpenApiAuth) {
+            response.addHeader(OpenAPIConstant.RESPONSE_HEADER_AUTH_STATUS, Boolean.TRUE.toString());
             return true;
         }
 

File: powerjob-client/src/main/java/tech/powerjob/client/service/impl/ClusterRequestServiceOkHttp3Impl.java
Patch:
@@ -126,10 +126,10 @@ private OkHttpClient.Builder commonOkHttpBuilder() {
                 // 设置读取超时时间
                 .readTimeout(Optional.ofNullable(config.getReadTimeout()).orElse(DEFAULT_TIMEOUT_SECONDS), TimeUnit.SECONDS)
                 // 设置写的超时时间
-                .writeTimeout(Optional.ofNullable(config.getReadTimeout()).orElse(DEFAULT_TIMEOUT_SECONDS), TimeUnit.SECONDS)
+                .writeTimeout(Optional.ofNullable(config.getWriteTimeout()).orElse(DEFAULT_TIMEOUT_SECONDS), TimeUnit.SECONDS)
                 // 设置连接超时时间
-                .connectTimeout(Optional.ofNullable(config.getReadTimeout()).orElse(DEFAULT_TIMEOUT_SECONDS), TimeUnit.SECONDS)
-                .callTimeout(Optional.ofNullable(config.getReadTimeout()).orElse(DEFAULT_TIMEOUT_SECONDS), TimeUnit.SECONDS);
+                .connectTimeout(Optional.ofNullable(config.getConnectionTimeout()).orElse(DEFAULT_TIMEOUT_SECONDS), TimeUnit.SECONDS)
+                .callTimeout(Optional.ofNullable(config.getConnectionTimeout()).orElse(DEFAULT_TIMEOUT_SECONDS), TimeUnit.SECONDS);
     }
 
     @Override

File: powerjob-client/src/test/java/tech/powerjob/client/test/ClientInitializer.java
Patch:
@@ -1,5 +1,6 @@
 package tech.powerjob.client.test;
 
+import com.google.common.collect.Lists;
 import org.junit.jupiter.api.BeforeAll;
 import tech.powerjob.client.IPowerJobClient;
 import tech.powerjob.client.PowerJobClient;
@@ -16,6 +17,6 @@ public class ClientInitializer {
 
     @BeforeAll
     public static void initClient() throws Exception {
-        powerJobClient = new PowerJobClient("127.0.0.1:7700", "powerjob-worker-samples", "powerjob12345");
+        powerJobClient = new PowerJobClient(Lists.newArrayList("127.0.0.1:7700", "127.0.0.1:7701"), "powerjob-worker-samples", "powerjob123");
     }
 }

File: powerjob-server/powerjob-server-auth/src/main/java/tech/powerjob/server/auth/jwt/JwtService.java
Patch:
@@ -12,5 +12,5 @@ public interface JwtService {
 
     String build(Map<String, Object> body, String extraSk);
 
-    Map<String, Object> parse(String jwt, String extraSk);
+    ParseResult parse(String jwt, String extraSk);
 }

File: powerjob-server/powerjob-server-auth/src/main/java/tech/powerjob/server/auth/service/login/impl/PowerJobLoginServiceImpl.java
Patch:
@@ -236,7 +236,7 @@ private Optional<JwtBody> parseJwt(HttpServletRequest httpServletRequest) {
         if (StringUtils.isEmpty(jwtStr)) {
             return Optional.empty();
         }
-        final Map<String, Object> jwtBodyMap = jwtService.parse(jwtStr, null);
+        final Map<String, Object> jwtBodyMap = jwtService.parse(jwtStr, null).getResult();
 
         if (MapUtils.isEmpty(jwtBodyMap)) {
             return Optional.empty();

File: powerjob-common/src/main/java/tech/powerjob/common/utils/HttpUtils.java
Patch:
@@ -21,6 +21,7 @@ public class HttpUtils {
         client = new OkHttpClient.Builder()
                 .connectTimeout(1, TimeUnit.SECONDS)
                 .readTimeout(5, TimeUnit.SECONDS)
+                .writeTimeout(10, TimeUnit.SECONDS)
                 .build();
     }
 

File: powerjob-common/src/main/java/tech/powerjob/common/utils/NetUtils.java
Patch:
@@ -217,9 +217,10 @@ static boolean isPassedCheckNetworkInterface(NetworkInterface networkInterface,
         if (networkInterfaceChecker == null) {
             return false;
         }
-        log.info("[Net] try to choose NetworkInterface by NetworkInterfaceChecker, current NetworkInterface: {}", networkInterface);
         try {
-            return networkInterfaceChecker.ok(networkInterface, getFirstReachableInetAddress(networkInterface));
+            boolean ok = networkInterfaceChecker.ok(networkInterface, getFirstReachableInetAddress(networkInterface));
+            log.info("[Net] try to choose NetworkInterface by NetworkInterfaceChecker, current NetworkInterface[{}], ok: {}", networkInterface, ok);
+            return ok;
         } catch (Exception e) {
             log.warn("[Net] isPassedCheckerNetworkInterface failed, current networkInterface: {}", networkInterface, e);
         }

File: powerjob-common/src/main/java/tech/powerjob/common/utils/net/PingPongUtils.java
Patch:
@@ -30,6 +30,9 @@ public static boolean checkConnectivity(String targetIp, int targetPort) {
 
         try (Socket s = new Socket(targetIp, targetPort);InputStream is = s.getInputStream();OutputStream os = s.getOutputStream();BufferedReader br = new BufferedReader(new InputStreamReader(is))) {
 
+            s.setSoTimeout(2000);
+            s.setKeepAlive(false);
+
             // 发送 PING 请求
             os.write(PING.getBytes(StandardCharsets.UTF_8));
             os.flush();

File: powerjob-remote/powerjob-remote-framework/src/main/java/tech/powerjob/remote/framework/engine/impl/PowerJobRemoteEngine.java
Patch:
@@ -41,6 +41,7 @@ public EngineOutput start(EngineConfig engineConfig) {
 
         csInitializer.init(new CSInitializerConfig()
                 .setBindAddress(engineConfig.getBindAddress())
+                .setExternalAddress(engineConfig.getExternalAddress())
                 .setServerType(engineConfig.getServerType())
         );
 

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/server/election/ServerElectionService.java
Patch:
@@ -6,7 +6,6 @@
 import org.apache.commons.lang3.StringUtils;
 import org.springframework.beans.factory.annotation.Value;
 import org.springframework.stereotype.Service;
-import tech.powerjob.common.enums.Protocol;
 import tech.powerjob.common.exception.PowerJobException;
 import tech.powerjob.common.request.ServerDiscoveryRequest;
 import tech.powerjob.common.response.AskResponse;
@@ -16,8 +15,8 @@
 import tech.powerjob.server.persistence.remote.model.AppInfoDO;
 import tech.powerjob.server.persistence.remote.repository.AppInfoRepository;
 import tech.powerjob.server.remote.transporter.ProtocolInfo;
-import tech.powerjob.server.remote.transporter.impl.ServerURLFactory;
 import tech.powerjob.server.remote.transporter.TransportService;
+import tech.powerjob.server.remote.transporter.impl.ServerURLFactory;
 
 import java.util.Date;
 import java.util.Optional;
@@ -150,7 +149,7 @@ private String activeAddress(String serverAddress, Set<String> downServerCache,
 
         URL targetUrl = ServerURLFactory.ping2Friend(serverAddress);
         try {
-            AskResponse response = transportService.ask(Protocol.HTTP.name(), targetUrl, ping, AskResponse.class)
+            AskResponse response = transportService.ask(transportService.defaultProtocol().getProtocol(), targetUrl, ping, AskResponse.class)
                     .toCompletableFuture()
                     .get(PING_TIMEOUT_MS, TimeUnit.MILLISECONDS);
             if (response.isSuccess()) {

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/server/redirector/DesignateServerAspect.java
Patch:
@@ -14,14 +14,13 @@
 import org.springframework.core.annotation.Order;
 import org.springframework.stereotype.Component;
 import tech.powerjob.common.RemoteConstant;
-import tech.powerjob.common.enums.Protocol;
 import tech.powerjob.common.exception.PowerJobException;
 import tech.powerjob.common.response.AskResponse;
 import tech.powerjob.remote.framework.base.URL;
 import tech.powerjob.server.persistence.remote.model.AppInfoDO;
 import tech.powerjob.server.persistence.remote.repository.AppInfoRepository;
-import tech.powerjob.server.remote.transporter.impl.ServerURLFactory;
 import tech.powerjob.server.remote.transporter.TransportService;
+import tech.powerjob.server.remote.transporter.impl.ServerURLFactory;
 
 import java.lang.reflect.Method;
 import java.lang.reflect.ParameterizedType;
@@ -100,7 +99,7 @@ public Object execute(ProceedingJoinPoint point, DesignateServer designateServer
 
         final URL friendUrl = ServerURLFactory.process2Friend(targetServer);
 
-        CompletionStage<AskResponse> askCS = transportService.ask(Protocol.HTTP.name(), friendUrl, remoteProcessReq, AskResponse.class);
+        CompletionStage<AskResponse> askCS = transportService.ask(transportService.defaultProtocol().getProtocol(), friendUrl, remoteProcessReq, AskResponse.class);
         AskResponse askResponse = askCS.toCompletableFuture().get(RemoteConstant.DEFAULT_TIMEOUT_MS, TimeUnit.MILLISECONDS);
 
         if (!askResponse.isSuccess()) {

File: powerjob-server/powerjob-server-auth/src/main/java/tech/powerjob/server/auth/common/AuthConstants.java
Patch:
@@ -39,7 +39,8 @@ public class AuthConstants {
      * JWT key
      * 前端 header 默认首字母大写，保持一致方便处理
      */
-    public static final String JWT_NAME = "Power_jwt";
+    public static final String OLD_JWT_NAME = "Power_jwt";
+    public static final String JWT_NAME = "PowerJwt";
 
     /**
      * 前端跳转到指定页面指令

File: powerjob-server/powerjob-server-auth/src/main/java/tech/powerjob/server/auth/service/login/impl/PowerJobLoginServiceImpl.java
Patch:
@@ -216,6 +216,9 @@ private void fillJwt(PowerJobUser powerJobUser, String encryptedToken) {
     private Optional<JwtBody> parseJwt(HttpServletRequest httpServletRequest) {
         // header、cookie 都能获取
         String jwtStr = HttpServletUtils.fetchFromHeader(AuthConstants.JWT_NAME, httpServletRequest);
+        if (StringUtils.isEmpty(jwtStr)) {
+            jwtStr = HttpServletUtils.fetchFromHeader(AuthConstants.OLD_JWT_NAME, httpServletRequest);
+        }
 
         /*
 

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/container/ContainerService.java
Patch:
@@ -336,7 +336,6 @@ public String fetchDeployedInfo(Long appId, Long containerId) {
             sb.append("WARN: there exists multi version container now, please redeploy to fix this problem").append(System.lineSeparator());
         }
 
-        sb.append("divisive version ==> ").append(System.lineSeparator());
         version2DeployedContainerInfoList.asMap().forEach((version, deployedContainerInfos) -> {
             sb.append("[version] ").append(version).append(System.lineSeparator());
             deployedContainerInfos.forEach(deployedContainerInfo -> sb.append(String.format("Address: %s, DeployedTime: %s", deployedContainerInfo.getWorkerAddress(), CommonUtils.formatTime(deployedContainerInfo.getDeployedTime()))).append(System.lineSeparator()));

File: powerjob-server/powerjob-server-auth/src/main/java/tech/powerjob/server/auth/service/permission/PowerJobPermissionService.java
Patch:
@@ -6,6 +6,7 @@
 
 import java.util.List;
 import java.util.Map;
+import java.util.Set;
 
 /**
  * PowerJob 鉴权服务
@@ -49,9 +50,9 @@ public interface PowerJobPermissionService {
      * 获取有相关权限的用户
      * @param roleScope 角色范围
      * @param target 目标
-     * @return 角色对应的用户列表
+     * @return 角色对应的用户列表，user 可能重复，需要用 SET 去重（save APP/namespace 等场景，创建人自动被授权成为 ADMIN，如果用户在面板将自己添加到管理员，就会存在2套授权机制2次授权出现重复）
      */
-    Map<Role, List<Long>> fetchUserWithPermissions(RoleScope roleScope, Long target);
+    Map<Role, Set<Long>> fetchUserWithPermissions(RoleScope roleScope, Long target);
 
     /**
      * 获取用户有权限的目标

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/converter/NamespaceConverter.java
Patch:
@@ -16,7 +16,9 @@ public class NamespaceConverter {
 
     public static NamespaceBaseVO do2BaseVo(NamespaceDO d) {
         NamespaceBaseVO v = new NamespaceBaseVO();
+
         BeanUtils.copyProperties(d, v);
+
         v.setGmtCreateStr(CommonUtils.formatTime(d.getGmtCreate()));
         v.setGmtModifiedStr(CommonUtils.formatTime(d.getGmtModified()));
         v.setStatusStr(SwitchableStatus.of(d.getStatus()).name());

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/controller/AppInfoController.java
Patch:
@@ -194,7 +194,8 @@ private List<AppInfoVO> convert(List<AppInfoDO> data, boolean fillDetail) {
             return Lists.newLinkedList();
         }
 
-        return data.parallelStream().map(appInfoDO -> {
+        // app 界面使用频率不高，数据库操作 rt 也不会太长，展示不考虑性能问题，简单期间串行补全
+        return data.stream().map(appInfoDO -> {
             AppInfoVO appInfoVO = new AppInfoVO();
             BeanUtils.copyProperties(appInfoDO, appInfoVO);
 

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/worker/selector/impl/SpecifyTaskTrackerSelector.java
Patch:
@@ -1,7 +1,7 @@
 package tech.powerjob.server.remote.worker.selector.impl;
 
+import com.google.common.collect.Lists;
 import lombok.extern.slf4j.Slf4j;
-import org.apache.commons.compress.utils.Lists;
 import org.apache.commons.lang3.StringUtils;
 import org.springframework.stereotype.Component;
 import tech.powerjob.common.enums.DispatchStrategy;

File: powerjob-worker/src/main/java/tech/powerjob/worker/container/OmsContainerFactory.java
Patch:
@@ -92,6 +92,7 @@ public static synchronized void deployContainer(ServerDeployContainerRequest req
 
         try {
             if (!jarFile.exists()) {
+                log.info("[OmsContainer-{}] container not exist(path={}), try to download from server!", containerId, jarFile.getPath());
                 FileUtils.forceMkdirParent(jarFile);
                 FileUtils.copyURLToFile(new URL(request.getDownloadURL()), jarFile, 5000, 300000);
                 log.info("[OmsContainer-{}] download jar successfully, path={}", containerId, jarFile.getPath());
@@ -107,6 +108,7 @@ public static synchronized void deployContainer(ServerDeployContainerRequest req
 
             if (oldContainer != null) {
                 // 销毁旧容器
+                log.info("[OmsContainer-{}] start to destroy old container(version={})", containerId, oldContainer.getVersion());
                 oldContainer.destroy();
             }
 

File: powerjob-worker/src/main/java/tech/powerjob/worker/processor/impl/JarContainerProcessorFactory.java
Patch:
@@ -46,7 +46,9 @@ public ProcessorBean build(ProcessorDefinition processorDefinition) {
         if (omsContainer != null) {
             return new ProcessorBean()
                     .setProcessor(omsContainer.getProcessor(className))
-                    .setClassLoader(omsContainer.getContainerClassLoader());
+                    .setClassLoader(omsContainer.getContainerClassLoader())
+                    .setStable(false)
+                    ;
         } else {
             log.warn("[ProcessorFactory] load container failed. processor info : {}", processorInfo);
         }

File: powerjob-server/powerjob-server-persistence/src/test/java/tech/powerjob/server/persistence/storage/impl/AliOssServiceTest.java
Patch:
@@ -1,8 +1,8 @@
 package tech.powerjob.server.persistence.storage.impl;
 
 import com.aliyun.oss.common.utils.AuthUtils;
-import com.aliyun.oss.common.utils.StringUtils;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.lang3.StringUtils;
 import org.apache.commons.lang3.exception.ExceptionUtils;
 import tech.powerjob.server.extension.dfs.DFsService;
 
@@ -33,7 +33,7 @@ protected Optional<DFsService> fetchService() {
 
         log.info("[AliOssServiceTest] ak: {}, sk: {}", accessKeyId, secretAccessKey);
 
-        if (org.apache.commons.lang3.StringUtils.isAnyEmpty(accessKeyId, secretAccessKey)) {
+        if (StringUtils.isAnyEmpty(accessKeyId, secretAccessKey)) {
             return Optional.empty();
         }
 

File: powerjob-worker-samples/src/main/java/tech/powerjob/samples/processors/MapReduceProcessorDemo.java
Patch:
@@ -173,7 +173,7 @@ public ProcessResult reduce(TaskContext context, List<TaskResult> taskResults) {
      */
     @Data
     @AllArgsConstructor
-    private static class SubTask implements Serializable {
+    public static class SubTask implements Serializable {
 
         /**
          * 再次强调，一定要有无参构造方法

File: powerjob-worker/src/main/java/tech/powerjob/worker/core/tracker/task/heavy/CommonTaskTracker.java
Patch:
@@ -185,7 +185,7 @@ private void innerRun() {
             String result = null;
 
             // 2. 如果未完成任务数为0，判断是否真正结束，并获取真正结束任务的执行结果
-            if (unfinishedNum == 0) {
+            if (unfinishedNum <= 0) {
 
                 // 数据库中一个任务都没有，说明根任务创建失败，该任务实例失败
                 if (finishedNum == 0) {

File: powerjob-worker/src/main/java/tech/powerjob/worker/core/tracker/task/heavy/HeavyTaskTracker.java
Patch:
@@ -59,7 +59,7 @@ public abstract class HeavyTaskTracker extends TaskTracker {
     /**
      * 数据库持久化服务
      */
-    protected TaskPersistenceService taskPersistenceService;
+    protected final TaskPersistenceService taskPersistenceService;
     /**
      * 定时任务线程池
      */

File: powerjob-worker/src/main/java/tech/powerjob/worker/persistence/DbTaskPersistenceService.java
Patch:
@@ -23,7 +23,7 @@
 import java.util.function.Consumer;
 
 /**
- * desc
+ * 基于内置数据库的任务持久化服务
  *
  * @author tjq
  * @since 2024/2/23

File: powerjob-worker-samples/src/main/java/tech/powerjob/samples/processors/MapReduceProcessorDemo.java
Patch:
@@ -29,7 +29,7 @@
  * @since 2020/4/17
  */
 @Slf4j
-@Component("testMapReduceProcessor")
+@Component("demoMapReduceProcessor")
 public class MapReduceProcessorDemo implements MapReduceProcessor {
 
     @Override

File: powerjob-worker/src/main/java/tech/powerjob/worker/core/tracker/task/heavy/HeavyTaskTracker.java
Patch:
@@ -470,7 +470,7 @@ public void run0() {
 
             // 2. 没有可用 ProcessorTracker，本次不派发
             if (availablePtIps.isEmpty()) {
-                log.debug("[TaskTracker-{}] no available ProcessorTracker now.", instanceId);
+                log.warn("[TaskTracker-{}] no available ProcessorTracker now, skip dispatch", instanceId);
                 return;
             }
 

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/ControllerExceptionHandler.java
Patch:
@@ -10,6 +10,7 @@
 import org.springframework.web.bind.annotation.ResponseBody;
 import tech.powerjob.common.exception.PowerJobException;
 import tech.powerjob.common.response.ResultDTO;
+import tech.powerjob.server.web.response.WebResultDTO;
 
 /**
  * 统一处理 web 层异常信息
@@ -23,9 +24,9 @@ public class ControllerExceptionHandler {
 
     @ResponseBody
     @ExceptionHandler(Exception.class)
-    public ResultDTO<Void> exceptionHandler(Exception e) {
+    public WebResultDTO<Void> exceptionHandler(Exception e) {
 
-        ResultDTO<Void> ret = ResultDTO.failed(ExceptionUtils.getMessage(e));
+        WebResultDTO<Void> ret = new WebResultDTO<>(ResultDTO.failed(ExceptionUtils.getMessage(e)));
 
         // 不是所有异常都需要打印完整堆栈，后续可以定义内部的Exception，便于判断
         if (e instanceof PowerJobException) {

File: powerjob-server/powerjob-server-auth/src/main/java/tech/powerjob/server/auth/service/login/impl/PowerJobLoginServiceImpl.java
Patch:
@@ -94,6 +94,7 @@ public PowerJobUser doLogin(LoginRequest loginRequest) throws PowerJobAuthExcept
             newUser.setUsername(dbUserName);
             // 写入账号体系类型
             newUser.setAccountType(loginType);
+            newUser.setOriginUsername(bizUser.getUsername());
 
             // 同步素材
             newUser.setEmail(bizUser.getEmail());

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/request/ChangePasswordRequest.java
Patch:
@@ -13,7 +13,7 @@
 @Data
 public class ChangePasswordRequest implements Serializable {
 
-    private Long userId;
+    private String username;
 
     private String oldPassword;
 

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/request/ModifyUserInfoRequest.java
Patch:
@@ -26,4 +26,6 @@ public class ModifyUserInfoRequest {
      * 邮箱地址
      */
     private String email;
+
+    private String extra;
 }

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/response/UserDetailVO.java
Patch:
@@ -39,6 +39,8 @@ public class UserDetailVO extends UserBaseVO {
      * webHook
      */
     private String webHook;
+
+    private String originUsername;
     /**
      * 扩展字段
      */

File: powerjob-common/src/main/java/tech/powerjob/common/serialize/JsonUtils.java
Patch:
@@ -3,6 +3,7 @@
 import com.fasterxml.jackson.core.JsonParser;
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.core.type.TypeReference;
+import com.fasterxml.jackson.databind.DeserializationFeature;
 import com.fasterxml.jackson.databind.MapperFeature;
 import com.fasterxml.jackson.databind.json.JsonMapper;
 import lombok.extern.slf4j.Slf4j;
@@ -28,6 +29,7 @@ public class JsonUtils {
             .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true)
             .configure(JsonParser.Feature.ALLOW_SINGLE_QUOTES, true)
             .configure(JsonParser.Feature.IGNORE_UNDEFINED, true)
+            .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)
             .build();
 
     private static final TypeReference<Map<String, Object>>  MAP_TYPE_REFERENCE  = new TypeReference<Map<String, Object>> () {};

File: powerjob-server/powerjob-server-auth/src/main/java/tech/powerjob/server/auth/common/AuthErrorCode.java
Patch:
@@ -22,7 +22,9 @@ public enum AuthErrorCode {
     /**
      * 无效请求，一般是参数问题
      */
-    INVALID_REQUEST("-300", "INVALID_REQUEST")
+    INVALID_REQUEST("-300", "INVALID_REQUEST"),
+
+    INCORRECT_PASSWORD("-400", "INCORRECT_PASSWORD")
 
     ;
 

File: powerjob-server/powerjob-server-persistence/src/main/java/tech/powerjob/server/persistence/remote/repository/AppInfoRepository.java
Patch:
@@ -8,6 +8,7 @@
 import org.springframework.data.repository.query.Param;
 import tech.powerjob.server.persistence.remote.model.AppInfoDO;
 
+import java.util.Collection;
 import java.util.List;
 import java.util.Optional;
 
@@ -34,4 +35,6 @@ public interface AppInfoRepository extends JpaRepository<AppInfoDO, Long>, JpaSp
 
     List<AppInfoDO> findAllByNamespaceId(Long namespaceId);
 
+
+    List<AppInfoDO> findAllByIdIn(Collection<Long> ids);
 }

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/response/UserBaseVO.java
Patch:
@@ -14,7 +14,7 @@
 @Setter
 @NoArgsConstructor
 public class UserBaseVO {
-    private Long id;
-    private String username;
-    private String nick;
+    protected Long id;
+    protected String username;
+    protected String nick;
 }
\ No newline at end of file

File: powerjob-server/powerjob-server-auth/src/main/java/tech/powerjob/server/auth/common/AuthConstants.java
Patch:
@@ -18,4 +18,6 @@ public class AuthConstants {
      * 前端跳转到指定页面指令
      */
     public static final String FE_REDIRECT_KEY = "FE-REDIRECT:";
+
+    public static final String TIPS_NO_PERMISSION_TO_SEE = "NO_PERMISSION_TO_SEE";
 }

File: powerjob-server/powerjob-server-auth/src/main/java/tech/powerjob/server/auth/common/utils/HttpServletUtils.java
Patch:
@@ -17,7 +17,7 @@ public static String fetchFromHeader(String key, HttpServletRequest httpServletR
         String v = httpServletRequest.getHeader(key);
 
         // 解决 window.localStorage.getItem 为 null 的问题
-        if (OmsConstant.NULL.equalsIgnoreCase(v)) {
+        if (OmsConstant.NULL.equalsIgnoreCase(v) || "undefined".equalsIgnoreCase(v)) {
             return null;
         }
 

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/auth/service/impl/WebAuthServiceImpl.java
Patch:
@@ -56,9 +56,7 @@ public boolean hasPermission(RoleScope roleScope, Long target, Permission permis
             return false;
         }
 
-        powerJobPermissionService.hasPermission(powerJobUser.getId(), roleScope, target, permission);
-
-        return false;
+        return powerJobPermissionService.hasPermission(powerJobUser.getId(), roleScope, target, permission);
     }
 
     private void diffGrant(RoleScope roleScope, Long target, Role role, List<Long> uids, Map<Role, List<Long>> originRole2Uids) {

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/controller/NamespaceController.java
Patch:
@@ -12,6 +12,7 @@
 import tech.powerjob.server.auth.LoginUserHolder;
 import tech.powerjob.server.auth.Permission;
 import tech.powerjob.server.auth.RoleScope;
+import tech.powerjob.server.auth.common.AuthConstants;
 import tech.powerjob.server.auth.interceptor.ApiPermission;
 import tech.powerjob.server.auth.plugin.ModifyOrCreateDynamicPermission;
 import tech.powerjob.server.auth.plugin.SaveNamespaceGrantPermissionPlugin;
@@ -105,6 +106,7 @@ public ResultDTO<Void> deleteNamespace(Long id) {
     }
 
     @PostMapping("/list")
+    @ApiPermission(name = "Namespace-List", roleScope = RoleScope.NAMESPACE, requiredPermission = Permission.NONE)
     public ResultDTO<PageResult<NamespaceVO>> listNamespace(@RequestBody QueryNamespaceRequest queryNamespaceRequest) {
 
         String codeLike = queryNamespaceRequest.getCodeLike();
@@ -155,9 +157,7 @@ private void fillPermissionInfo(NamespaceDO namespaceDO, NamespaceVO namespaceVO
 
         // 有权限用户填充 token
         boolean hasPermission = webAuthService.hasPermission(RoleScope.NAMESPACE, namespaceId, Permission.READ);
-        if (hasPermission) {
-            namespaceVO.setToken(namespaceDO.getToken());
-        }
+        namespaceVO.setToken(hasPermission ? namespaceDO.getToken() : AuthConstants.TIPS_NO_PERMISSION_TO_SEE);
     }
 
     private NamespaceDO fetchById(Long id) {

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/request/QueryAppInfoRequest.java
Patch:
@@ -22,7 +22,9 @@ public class QueryAppInfoRequest {
     /**
      * 任务名称
      */
-    private String appName;
+    private String appNameLike;
+
+    private String tagLike;
 
     /**
      * 查询与我相关的任务（我有直接权限的）

File: powerjob-common/src/main/java/tech/powerjob/common/OmsConstant.java
Patch:
@@ -30,4 +30,6 @@ public class OmsConstant {
 
     public static final String HTTP_HEADER_CONTENT_TYPE = "Content-Type";
     public static final String JSON_MEDIA_TYPE = "application/json; charset=utf-8";
+
+    public static final String NULL = "null";
 }

File: powerjob-server/powerjob-server-persistence/src/main/java/tech/powerjob/server/persistence/QueryConvertUtils.java
Patch:
@@ -86,7 +86,7 @@ public static <T> Specification<T> toSpecification(PowerQuery powerQuery) {
         };
     }
 
-    private static String convertLikeParams(Object o) {
+    public static String convertLikeParams(Object o) {
         String s = (String) o;
         if (!s.startsWith("%")) {
             s = "%" + s;

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/alarm/impl/MailAlarmService.java
Patch:
@@ -44,7 +44,7 @@ public void onFailed(Alarm alarm, List<AlarmTarget> targetUserList) {
         SimpleMailMessage sm = new SimpleMailMessage();
         try {
             sm.setFrom(from);
-            sm.setTo(targetUserList.stream().map(AlarmTarget::getEmail).filter(Objects::nonNull).toArray(String[]::new));
+            sm.setTo(targetUserList.stream().map(AlarmTarget::getEmail).filter(Objects::nonNull).filter(email -> !email.isEmpty()).toArray(String[]::new));
             sm.setSubject(alarm.fetchTitle());
             sm.setText(alarm.fetchContent());
 

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/instance/InstanceService.java
Patch:
@@ -260,10 +260,12 @@ public InstanceStatus getInstanceStatus(Long instanceId) {
     /**
      * 获取任务实例的详细运行详细
      *
+     * @param appId 用于远程 server 路由，勿删！
      * @param instanceId 任务实例ID
      * @return 详细运行状态
      */
-    public InstanceDetail getInstanceDetail(Long instanceId) {
+    @DesignateServer
+    public InstanceDetail getInstanceDetail(Long appId, Long instanceId) {
 
         InstanceInfoDO instanceInfoDO = fetchInstanceInfo(instanceId);
 

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/alarm/impl/MailAlarmService.java
Patch:
@@ -44,7 +44,7 @@ public void onFailed(Alarm alarm, List<AlarmTarget> targetUserList) {
         SimpleMailMessage sm = new SimpleMailMessage();
         try {
             sm.setFrom(from);
-            sm.setTo(targetUserList.stream().map(AlarmTarget::getEmail).filter(Objects::nonNull).toArray(String[]::new));
+            sm.setTo(targetUserList.stream().map(AlarmTarget::getEmail).filter(Objects::nonNull).filter(email -> !email.isEmpty()).toArray(String[]::new));
             sm.setSubject(alarm.fetchTitle());
             sm.setText(alarm.fetchContent());
 

File: powerjob-worker/src/main/java/tech/powerjob/worker/background/OmsLogHandler.java
Patch:
@@ -69,10 +69,10 @@ public void submitLog(long instanceId, LogLevel logLevel, String logContent) {
 
 
 
-    private class LogSubmitter implements Runnable {
+    private class LogSubmitter extends RunnableAndCatch {
 
         @Override
-        public void run() {
+        public void run0() {
 
             boolean lockResult = reportLock.tryLock();
             if (!lockResult) {

File: powerjob-worker/src/main/java/tech/powerjob/worker/background/WorkerHealthReporter.java
Patch:
@@ -22,12 +22,12 @@
  */
 @Slf4j
 @RequiredArgsConstructor
-public class WorkerHealthReporter implements Runnable {
+public class WorkerHealthReporter extends RunnableAndCatch {
 
     private final WorkerRuntime workerRuntime;
 
     @Override
-    public void run() {
+    public void run0() {
 
         // 没有可用Server，无法上报
         String currentServer = workerRuntime.getServerDiscoveryService().getCurrentServerAddress();

File: powerjob-worker/src/main/java/tech/powerjob/worker/core/tracker/processor/ProcessorTracker.java
Patch:
@@ -9,6 +9,7 @@
 import tech.powerjob.common.enums.TimeExpressionType;
 import tech.powerjob.common.utils.CollectionUtils;
 import tech.powerjob.common.utils.CommonUtils;
+import tech.powerjob.worker.background.RunnableAndCatch;
 import tech.powerjob.worker.common.WorkerRuntime;
 import tech.powerjob.worker.common.constants.TaskStatus;
 import tech.powerjob.worker.common.utils.TransportUtils;
@@ -237,11 +238,11 @@ private void initTimingJob() {
     /**
      * 定时向 TaskTracker 汇报（携带任务执行信息的心跳）
      */
-    private class CheckerAndReporter implements Runnable {
+    private class CheckerAndReporter extends RunnableAndCatch {
 
         @Override
         @SuppressWarnings({"squid:S1066","squid:S3776"})
-        public void run() {
+        public void run0() {
 
             // 超时检查，如果超时则自动关闭 TaskTracker
             long interval = System.currentTimeMillis() - startTime;

File: powerjob-worker/src/main/java/tech/powerjob/worker/common/utils/SystemInfoUtils.java
Patch:
@@ -68,7 +68,8 @@ private static void fillDiskInfo(SystemMetrics metrics) {
         }
 
         metrics.setDiskUsed(bytes2GB(total - free));
-        metrics.setDiskTotal(bytes2GB(total));
+        // 防止内存溢出导致total为负数,导致找不到worker实例
+        metrics.setDiskTotal(bytes2GB(total < 0 ? Long.MAX_VALUE >> 6 : total ));
         metrics.setDiskUsage(miniDouble(metrics.getDiskUsed() / metrics.getDiskTotal()));
     }
 

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/worker/WorkerClusterQueryService.java
Patch:
@@ -75,6 +75,7 @@ public List<WorkerInfo> getAllWorkers(Long appId) {
      * @param appId appId
      * @return alive workers
      */
+    @DesignateServer
     public List<WorkerInfo> getAllAliveWorkers(Long appId) {
         List<WorkerInfo> workers = Lists.newLinkedList(getWorkerInfosByAppId(appId).values());
         workers.removeIf(WorkerInfo::timeout);

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/worker/WorkerClusterQueryService.java
Patch:
@@ -75,6 +75,7 @@ public List<WorkerInfo> getAllWorkers(Long appId) {
      * @param appId appId
      * @return alive workers
      */
+    @DesignateServer
     public List<WorkerInfo> getAllAliveWorkers(Long appId) {
         List<WorkerInfo> workers = Lists.newLinkedList(getWorkerInfosByAppId(appId).values());
         workers.removeIf(WorkerInfo::timeout);

File: powerjob-common/src/main/java/tech/powerjob/common/utils/NetUtils.java
Patch:
@@ -170,8 +170,8 @@ public static NetworkInterface findNetworkInterface() {
             log.warn("[Net] findNetworkInterface failed", e);
         }
 
-        // sort by interface index, the smaller is preferred.
-        validNetworkInterfaces.sort(Comparator.comparingInt(NetworkInterface::getIndex));
+        // sort by interface index, the smaller is preferred. （部分用户反馈 IP 获取逻辑反而劣化了，先注释）
+        // validNetworkInterfaces.sort(Comparator.comparingInt(NetworkInterface::getIndex));
 
         // Try to find the preferred one
         for (NetworkInterface networkInterface : validNetworkInterfaces) {

File: powerjob-worker/src/main/java/tech/powerjob/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -73,6 +73,7 @@ protected TaskTracker(ServerScheduleJobReq req, WorkerRuntime workerRuntime) {
         instanceInfo.setThreadConcurrency(req.getThreadConcurrency());
         instanceInfo.setTaskRetryNum(req.getTaskRetryNum());
         instanceInfo.setLogConfig(req.getLogConfig());
+        instanceInfo.setInstanceTimeoutMS(req.getInstanceTimeoutMS());
 
         // 特殊处理超时时间
         if (instanceInfo.getInstanceTimeoutMS() <= 0) {

File: powerjob-worker/src/main/java/tech/powerjob/worker/processor/impl/BuildInSpringMethodProcessorFactory.java
Patch:
@@ -6,7 +6,6 @@
 import tech.powerjob.worker.annotation.PowerJobHandler;
 import tech.powerjob.worker.extension.processor.ProcessorBean;
 import tech.powerjob.worker.extension.processor.ProcessorDefinition;
-import tech.powerjob.worker.processor.MethodBasicProcessor;
 
 import java.lang.reflect.Method;
 import java.util.LinkedList;

File: powerjob-remote/powerjob-remote-impl-http/src/main/java/tech/powerjob/remote/http/vertx/VertxInitializer.java
Patch:
@@ -53,8 +53,8 @@ private static void tryEnableCompression(HttpServerOptions httpServerOptions) {
                     .addCompressor(io.netty.handler.codec.compression.StandardCompressionOptions.gzip())
                     .setCompressionSupported(true);
             log.warn("[PowerJob-Vertx] enable server side compression successfully!");
-        } catch (Exception e) {
-            log.warn("[PowerJob-Vertx] enable server side compression failed!", e);
+        } catch (Throwable t) {
+            log.warn("[PowerJob-Vertx] enable server side compression failed. The error is not fatal, but performance may be degraded", t);
         }
     }
 

File: powerjob-server/powerjob-server-persistence/src/main/java/tech/powerjob/server/persistence/config/PowerJobPhysicalNamingStrategy.java
Patch:
@@ -39,7 +39,7 @@ public Identifier toPhysicalTableName(Identifier name, JdbcEnvironment jdbcEnvir
 
         String text = name.getText();
         String noDOText = StringUtils.endsWithIgnoreCase(text, "do") ? text.substring(0, text.length() - 2) : text;
-        String newText = StringUtils.isEmpty(tablePrefix) ? tablePrefix + noDOText : noDOText;
+        String newText = StringUtils.isNotEmpty(tablePrefix) ? tablePrefix + noDOText : noDOText;
         return super.toPhysicalTableName(new Identifier(newText, name.isQuoted()), jdbcEnvironment);
     }
 

File: powerjob-worker-samples/src/main/java/tech/powerjob/samples/tester/TestFindByBeanNameProcessor.java
Patch:
@@ -7,6 +7,7 @@
 
 /**
  * 测试直接使用 BeanName 获取处理器
+ * 控制台可填写 powerJobTestBeanNameProcessor 作为处理器信息
  *
  * @author tjq
  * @since 2023/3/5

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/controller/JobController.java
Patch:
@@ -84,6 +84,9 @@ public ResultDTO<PageResult<JobInfoVO>> listJobs(@RequestBody QueryJobInfoReques
         if (request.getJobId() != null) {
 
             Optional<JobInfoDO> jobInfoOpt = jobInfoRepository.findById(request.getJobId());
+            if (!jobInfoOpt.get().getAppId().equals(request.getAppId())){
+                return ResultDTO.failed("请输入该app下的jobId");
+            }
             PageResult<JobInfoVO> result = new PageResult<>();
             result.setIndex(0);
             result.setPageSize(request.getPageSize());

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/scheduler/auxiliary/impl/DailyTimeIntervalStrategyHandler.java
Patch:
@@ -74,7 +74,7 @@ public Long calculateNextTriggerTime(Long preTriggerTime, String timeExpression,
         long interval = timeUnit.toMillis(ep.interval);
 
         Long ret = calculateInRangeTime(preTriggerTime + interval, ep);
-        if (ret == null || ret <= endTime) {
+        if (ret == null || ret <= Optional.ofNullable(endTime).orElse(Long.MAX_VALUE)) {
             return ret;
         }
         return null;

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/worker/WorkerClusterQueryService.java
Patch:
@@ -76,6 +76,7 @@ public List<WorkerInfo> getAllWorkers(Long appId) {
      * @param appId appId
      * @return alive workers
      */
+    @DesignateServer
     public List<WorkerInfo> getAllAliveWorkers(Long appId) {
         List<WorkerInfo> workers = Lists.newLinkedList(getWorkerInfosByAppId(appId).values());
         workers.removeIf(WorkerInfo::timeout);

File: powerjob-official-processors/src/main/java/tech/powerjob/official/processors/impl/sql/SpringDatasourceSqlProcessor.java
Patch:
@@ -3,13 +3,13 @@
 import tech.powerjob.worker.core.processor.TaskContext;
 import com.google.common.collect.Maps;
 import lombok.extern.slf4j.Slf4j;
-import org.springframework.util.Assert;
 import org.apache.commons.lang3.StringUtils;
 
 import javax.sql.DataSource;
 import java.sql.Connection;
 import java.sql.SQLException;
 import java.util.Map;
+import java.util.Objects;
 
 /**
  * 简单 Spring SQL 处理器，目前只能用 Spring Bean 的方式加载
@@ -75,8 +75,8 @@ protected void validateParams(SqlParams sqlParams) {
      * @param dataSource     数据源
      */
     public void registerDataSource(String dataSourceName, DataSource dataSource) {
-        Assert.notNull(dataSourceName, "DataSource name must not be null");
-        Assert.notNull(dataSource, "DataSource must not be null");
+        Objects.requireNonNull(dataSourceName, "DataSource name must not be null");
+        Objects.requireNonNull(dataSource, "DataSource must not be null");
         dataSourceMap.put(dataSourceName, dataSource);
         log.info("register data source({})' successfully.", dataSourceName);
     }

File: powerjob-common/src/main/java/tech/powerjob/common/utils/JavaUtils.java
Patch:
@@ -53,8 +53,9 @@ public static String determinePackageVersion(Class<?> clz) {
         }
         catch (Throwable t) {
             log.warn("[JavaUtils] determinePackageVersion for clz[{}] failed, msg: {}", clz.getSimpleName(), t.toString());
+            // windows 下无权限访问会一直报错一直重试，需要在此兼容
+            return "UNKNOWN";
         }
-        return null;
     }
     private static String getImplementationVersion(JarFile jarFile) throws IOException {
         return jarFile.getManifest().getMainAttributes().getValue(Attributes.Name.IMPLEMENTATION_VERSION);

File: powerjob-remote/powerjob-remote-impl-akka/src/main/java/tech/powerjob/remote/akka/AkkaMappingService.java
Patch:
@@ -24,6 +24,9 @@ public class AkkaMappingService {
     static {
         addMappingRule(RemoteConstant.S4W_PATH, "server_actor", "w-r-c-d");
         addMappingRule(RemoteConstant.S4S_PATH, "friend_actor", "friend-request-actor-dispatcher");
+
+        addMappingRule(RemoteConstant.WTT_PATH, "task_tracker", "task-tracker-dispatcher");
+        addMappingRule(RemoteConstant.WPT_PATH, "processor_tracker", "processor-tracker-dispatcher");
     }
 
     private static final String DEFAULT_DISPATCH_NAME = "common-dispatcher";

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/handler/AbWorkerRequestHandler.java
Patch:
@@ -53,7 +53,7 @@ public abstract class AbWorkerRequestHandler implements IWorkerRequestHandler {
 
     protected abstract void processWorkerHeartbeat0(WorkerHeartbeat heartbeat, WorkerHeartbeatEvent event);
 
-    protected abstract Optional<AskResponse> processTaskTrackerReportInstanceStatus0(TaskTrackerReportInstanceStatusReq req, TtReportInstanceStatusEvent event) throws Exception;
+    protected abstract AskResponse processTaskTrackerReportInstanceStatus0(TaskTrackerReportInstanceStatusReq req, TtReportInstanceStatusEvent event) throws Exception;
 
     protected abstract void processWorkerLogReport0(WorkerLogReportReq req, WorkerLogReportEvent event);
 
@@ -77,7 +77,7 @@ public void processWorkerHeartbeat(WorkerHeartbeat heartbeat) {
 
     @Override
     @Handler(path = S4W_HANDLER_REPORT_INSTANCE_STATUS, processType = ProcessType.BLOCKING)
-    public Optional<AskResponse> processTaskTrackerReportInstanceStatus(TaskTrackerReportInstanceStatusReq req) {
+    public AskResponse processTaskTrackerReportInstanceStatus(TaskTrackerReportInstanceStatusReq req) {
         long startMs = System.currentTimeMillis();
         TtReportInstanceStatusEvent event = new TtReportInstanceStatusEvent()
                 .setAppId(req.getAppId())
@@ -92,7 +92,7 @@ public Optional<AskResponse> processTaskTrackerReportInstanceStatus(TaskTrackerR
         } catch (Exception e) {
             event.setServerProcessStatus(TtReportInstanceStatusEvent.Status.FAILED);
             log.error("[WorkerRequestHandler] processTaskTrackerReportInstanceStatus failed for request: {}", req, e);
-            return Optional.of(AskResponse.failed(ExceptionUtils.getMessage(e)));
+            return AskResponse.failed(ExceptionUtils.getMessage(e));
         } finally {
             event.setServerProcessCost(System.currentTimeMillis() - startMs);
             monitorService.monitor(event);

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/handler/IWorkerRequestHandler.java
Patch:
@@ -3,8 +3,6 @@
 import tech.powerjob.common.request.*;
 import tech.powerjob.common.response.AskResponse;
 
-import java.util.Optional;
-
 /**
  * 定义 server 与 worker 之间需要处理的协议
  *
@@ -24,7 +22,7 @@ public interface IWorkerRequestHandler {
      * @param req 上报请求
      * @return 响应信息
      */
-    Optional<AskResponse> processTaskTrackerReportInstanceStatus(TaskTrackerReportInstanceStatusReq req);
+    AskResponse processTaskTrackerReportInstanceStatus(TaskTrackerReportInstanceStatusReq req);
 
     /**
      * 处理 worker 查询执行器集群

File: powerjob-worker/src/main/java/tech/powerjob/worker/processor/impl/BuiltInSpringProcessorFactory.java
Patch:
@@ -46,7 +46,7 @@ public ProcessorBean build(ProcessorDefinition processorDefinition) {
                     .setProcessor(basicProcessor)
                     .setClassLoader(basicProcessor.getClass().getClassLoader());
         } catch (Throwable t) {
-            log.warn("[ProcessorFactory] load by BuiltInSpringProcessorFactory failed!", t);
+            log.warn("[ProcessorFactory] load by BuiltInSpringProcessorFactory failed. If you are using Spring, make sure this bean was managed by Spring", t);
         }
 
         return null;

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/server/FriendActor.java
Patch:
@@ -37,8 +37,7 @@ public FriendActor(TransportService transportService) {
      */
     @Handler(path = S4S_HANDLER_PING, processType = ProcessType.NO_BLOCKING)
     public AskResponse onReceivePing(Ping ping) {
-        final AskResponse response = AskResponse.succeed(transportService.allProtocols());
-        return response;
+        return AskResponse.succeed(transportService.allProtocols());
     }
 
     @Handler(path = S4S_HANDLER_PROCESS, processType = ProcessType.BLOCKING)

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/server/election/ServerElectionService.java
Patch:
@@ -117,7 +117,7 @@ private String getServer0(ServerDiscoveryRequest discoveryRequest) {
                 }
             }catch (Exception e) {
                 log.error("[ServerElection] write new server to db failed for app {}.", appName, e);
-            }finally {
+            } finally {
                 lockService.unlock(lockName);
             }
         }
@@ -150,10 +150,10 @@ private String activeAddress(String serverAddress, Set<String> downServerCache,
                     .get(PING_TIMEOUT_MS, TimeUnit.MILLISECONDS);
             if (response.isSuccess()) {
                 log.info("[ServerElection] server[{}] is active, it will be the master.", serverAddress);
-                downServerCache.remove(serverAddress);
                 // 检测通过的是远程 server 的暴露地址，需要返回 worker 需要的协议地址
                 final JSONObject protocolInfo = JsonUtils.parseObject(response.getData(), JSONObject.class).getJSONObject(protocol);
                 if (protocolInfo != null) {
+                    downServerCache.remove(serverAddress);
                     return protocolInfo.toJavaObject(ProtocolInfo.class).getAddress();
                 }
             }

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/server/redirector/DesignateServerAspect.java
Patch:
@@ -86,7 +86,7 @@ public Object execute(ProceedingJoinPoint point, DesignateServer designateServer
         }
 
         // 目标IP与本地符合则本地执行
-        if (Objects.equals(targetServer, transportService.defaultProtocol())) {
+        if (Objects.equals(targetServer, transportService.defaultProtocol().getAddress())) {
             return point.proceed();
         }
 

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/controller/ServerController.java
Patch:
@@ -7,6 +7,7 @@
 import org.springframework.web.bind.annotation.RequestMapping;
 import org.springframework.web.bind.annotation.RequestParam;
 import org.springframework.web.bind.annotation.RestController;
+import tech.powerjob.common.request.ServerDiscoveryRequest;
 import tech.powerjob.common.response.ResultDTO;
 import tech.powerjob.common.utils.CommonUtils;
 import tech.powerjob.common.utils.NetUtils;
@@ -47,8 +48,8 @@ public ResultDTO<Long> assertAppName(String appName) {
     }
 
     @GetMapping("/acquire")
-    public ResultDTO<String> acquireServer(Long appId, String protocol, String currentServer) {
-        return ResultDTO.success(serverElectionService.elect(appId, protocol, currentServer));
+    public ResultDTO<String> acquireServer(ServerDiscoveryRequest request) {
+        return ResultDTO.success(serverElectionService.elect(request));
     }
 
     @GetMapping("/hello")

File: powerjob-common/src/main/java/tech/powerjob/common/utils/JavaUtils.java
Patch:
@@ -44,7 +44,7 @@ public static String determinePackageVersion(Class<?> clz) {
             }
             final File file = new File(codeSourceLocation.toURI());
             // idea 场景，查找版本失败
-            if (file.isDirectory()) {
+            if (!file.exists() || file.isDirectory()) {
                 return "UNKNOWN";
             }
             try (JarFile jarFile = new JarFile(file)) {

File: powerjob-remote/powerjob-remote-framework/src/main/java/tech/powerjob/remote/framework/base/HandlerLocation.java
Patch:
@@ -27,9 +27,9 @@ public class HandlerLocation implements Serializable {
      */
     private String methodPath;
     /**
-     * 是否在本集群内（用于兼容 AKKA 等除了IP还需要指定 system 访问的情况）
+     * 调用的集群类型（用于兼容 AKKA 等除了IP还需要指定 system 访问的情况）
      */
-    private boolean insideCluster;
+    private ServerType serverType;
 
     public String toPath() {
         return String.format("/%s/%s", rootPath, methodPath);

File: powerjob-remote/powerjob-remote-impl-akka/src/main/java/tech/powerjob/remote/akka/AkkaCSInitializer.java
Patch:
@@ -58,7 +58,7 @@ public void init(CSInitializerConfig config) {
         log.info("[PowerJob-AKKA] try to start AKKA System by config: {}", akkaFinalConfig);
 
         // 启动时绑定当前的 actorSystemName
-        String actorSystemName = AkkaConstant.fetchActorSystemName(config.getServerType(), true);
+        String actorSystemName = AkkaConstant.fetchActorSystemName(config.getServerType());
         this.actorSystem = ActorSystem.create(actorSystemName, akkaFinalConfig);
 
         // 处理系统中产生的异常情况
@@ -70,7 +70,7 @@ public void init(CSInitializerConfig config) {
 
     @Override
     public Transporter buildTransporter() {
-        return new AkkaTransporter(config.getServerType(), actorSystem);
+        return new AkkaTransporter(actorSystem);
     }
 
     @Override

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/response/JobInfoVO.java
Patch:
@@ -2,6 +2,7 @@
 
 import com.alibaba.fastjson.JSON;
 import com.alibaba.fastjson.JSONObject;
+import org.apache.commons.lang3.StringUtils;
 import tech.powerjob.common.enums.ExecuteType;
 import tech.powerjob.common.enums.ProcessorType;
 import tech.powerjob.common.enums.TimeExpressionType;
@@ -16,7 +17,6 @@
 import com.google.common.collect.Lists;
 import lombok.Data;
 import org.springframework.beans.BeanUtils;
-import org.springframework.util.StringUtils;
 
 import java.util.Date;
 import java.util.List;
@@ -180,6 +180,8 @@ public static JobInfoVO from(JobInfoDO jobInfoDO) {
 
         if (!StringUtils.isEmpty(jobInfoDO.getAlarmConfig())){
             jobInfoVO.setAlarmConfig(JSON.parseObject(jobInfoDO.getAlarmConfig(),AlarmConfig.class));
+        } else {
+            jobInfoVO.setAlarmConfig(new AlarmConfig());
         }
         if (!StringUtils.isEmpty(jobInfoDO.getLifecycle())){
             jobInfoVO.setLifeCycle(LifeCycle.parse(jobInfoDO.getLifecycle()));

File: powerjob-worker/src/main/java/tech/powerjob/worker/log/OmsLoggerFactory.java
Patch:
@@ -1,6 +1,7 @@
 package tech.powerjob.worker.log;
 
 import org.apache.commons.lang3.StringUtils;
+import tech.powerjob.common.enums.LogType;
 import tech.powerjob.common.model.LogConfig;
 import tech.powerjob.common.serialize.JsonUtils;
 import tech.powerjob.worker.common.WorkerRuntime;
@@ -29,7 +30,7 @@ public static OmsLogger build(Long instanceId, String logConfig, WorkerRuntime w
             }
         }
 
-        switch (LogConfig.LogType.of(cfg.getType())) {
+        switch (LogType.of(cfg.getType())) {
             case LOCAL:
                 return new OmsLocalLogger(cfg);
             case STDOUT:

File: powerjob-worker/src/main/java/tech/powerjob/worker/log/impl/AbstractOmsLogger.java
Patch:
@@ -4,6 +4,7 @@
 import org.slf4j.helpers.FormattingTuple;
 import org.slf4j.helpers.MessageFormatter;
 import tech.powerjob.common.enums.LogLevel;
+import tech.powerjob.common.enums.LogType;
 import tech.powerjob.common.model.LogConfig;
 import tech.powerjob.worker.log.OmsLogger;
 
@@ -25,7 +26,7 @@ public AbstractOmsLogger(LogConfig logConfig) {
             logConfig.setLevel(LogLevel.INFO.getV());
         }
         if (logConfig.getType() == null) {
-            logConfig.setType(LogConfig.LogType.ONLINE.getV());
+            logConfig.setType(LogType.ONLINE.getV());
         }
     }
 

File: powerjob-worker-samples/src/main/java/tech/powerjob/samples/processors/MapProcessorDemo.java
Patch:
@@ -87,7 +87,7 @@ public ProcessResult process(TaskContext context) throws Exception {
     @Getter
     @NoArgsConstructor
     @AllArgsConstructor
-    private static class SubTask {
+    public static class SubTask {
         private Integer siteId;
         private List<Integer> itemIds;
     }

File: powerjob-worker-samples/src/main/java/tech/powerjob/samples/processors/MapReduceProcessorDemo.java
Patch:
@@ -87,7 +87,7 @@ public ProcessResult reduce(TaskContext context, List<TaskResult> taskResults) {
     @ToString
     @NoArgsConstructor
     @AllArgsConstructor
-    private static class TestSubTask {
+    public static class TestSubTask {
         private String name;
         private int age;
     }

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/response/JobInfoVO.java
Patch:
@@ -187,6 +187,9 @@ public static JobInfoVO from(JobInfoDO jobInfoDO) {
 
         if (!StringUtils.isEmpty(jobInfoDO.getLogConfig())) {
             jobInfoVO.setLogConfig(JSONObject.parseObject(jobInfoDO.getLogConfig(), LogConfig.class));
+        } else {
+            // 不存在 job 配置时防止前端报错
+            jobInfoVO.setLogConfig(new LogConfig());
         }
 
         return jobInfoVO;

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/handler/impl/Initializer.java
Patch:
@@ -1,5 +1,6 @@
 package tech.powerjob.server.core.handler.impl;
 
+import org.springframework.boot.autoconfigure.condition.ConditionalOnExpression;
 import org.springframework.stereotype.Component;
 import tech.powerjob.common.RemoteConstant;
 import tech.powerjob.server.remote.transport.starter.AkkaStarter;
@@ -14,6 +15,7 @@
  * @since 2022/9/11
  */
 @Component
+@ConditionalOnExpression("'${execution.env}'!='test'")
 public class Initializer {
 
     @PostConstruct

File: powerjob-server/powerjob-server-starter/src/test/java/tech/powerjob/server/core/scheduler/CronTimingStrategyHandlerTest.java
Patch:
@@ -4,8 +4,8 @@
 import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.lang3.time.DateFormatUtils;
 import org.assertj.core.util.Lists;
-import org.junit.Test;
 import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Test;
 import tech.powerjob.common.OmsConstant;
 import tech.powerjob.server.core.scheduler.auxiliary.impl.CronTimingStrategyHandler;
 

File: powerjob-server/powerjob-server-starter/src/test/java/tech/powerjob/server/core/validator/NodeValidatorTest.java
Patch:
@@ -1,6 +1,6 @@
 package tech.powerjob.server.core.validator;
 
-import org.junit.Assert;
+import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
 import org.springframework.beans.BeanUtils;
 import tech.powerjob.common.enums.WorkflowNodeType;
@@ -41,7 +41,7 @@ void testDecisionNodeValidator() {
         final WorkflowNodeInfoDO workflowNodeInfo1 = new WorkflowNodeInfoDO();
         BeanUtils.copyProperties(node1, workflowNodeInfo1);
         workflowNodeInfo1.setId(node1.getNodeId());
-        Assert.assertThrows(PowerJobException.class, () -> decisionNodeValidator.complexValidate(workflowNodeInfo1, dag));
+        Assertions.assertThrows(PowerJobException.class, () -> decisionNodeValidator.complexValidate(workflowNodeInfo1, dag));
 
     }
 

File: powerjob-server/powerjob-server-starter/src/test/java/tech/powerjob/server/test/ConflictTest.java
Patch:
@@ -2,7 +2,7 @@
 
 import lombok.SneakyThrows;
 import lombok.extern.slf4j.Slf4j;
-import org.junit.Test;
+import org.junit.jupiter.api.Test;
 import tech.powerjob.common.utils.CommonUtils;
 import tech.powerjob.server.core.uid.SnowFlakeIdGenerator;
 
@@ -27,7 +27,7 @@ public void segmentLockMockTest() {
 
         int len = CommonUtils.formatSize(1024) - 1;
         Map<Integer, Integer> matchCount = new TreeMap<>();
-        int maxTime = 100000;
+        int maxTime = 10000;
         int expectedMaxConflict = maxTime / len;
 
         for (int i = 0; i < maxTime; i++) {

File: powerjob-server/powerjob-server-starter/src/test/java/tech/powerjob/server/test/ServiceTest.java
Patch:
@@ -1,11 +1,10 @@
 package tech.powerjob.server.test;
 
 import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Test;
 import tech.powerjob.server.core.uid.IdGenerateService;
 import tech.powerjob.server.extension.LockService;
 import tech.powerjob.server.core.scheduler.CleanService;
-import org.junit.Test;
-import org.junit.runner.RunWith;
 import org.springframework.boot.test.context.SpringBootTest;
 import org.springframework.test.context.junit4.SpringRunner;
 
@@ -18,7 +17,6 @@
  * @since 2020/4/2
  */
 //@ActiveProfiles("daily")
-@RunWith(SpringRunner.class)
 @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
 public class ServiceTest {
 

File: powerjob-server/powerjob-server-starter/src/test/java/tech/powerjob/server/test/UtilsTest.java
Patch:
@@ -2,7 +2,7 @@
 
 import com.google.common.collect.Lists;
 import org.apache.commons.lang3.StringUtils;
-import org.junit.Test;
+import org.junit.jupiter.api.Test;
 
 import java.util.List;
 import java.util.Objects;

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/server/self/ServerInfoServiceImpl.java
Patch:
@@ -88,7 +88,6 @@ public ServerInfoServiceImpl(LockService lockService, ServerInfoRepository serve
         log.info("[ServerInfoService] ip:{}, id:{}, cost:{}", ip, serverInfo.getId(), sw);
     }
 
-    @Async(PJThreadPool.TIMING_POOL)
     @Scheduled(fixedRate = 15000, initialDelay = 15000)
     public void heartbeat() {
         serverInfoRepository.updateGmtModifiedByIp(serverInfo.getIp(), new Date());

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/server/self/ServerInfoServiceImpl.java
Patch:
@@ -2,9 +2,11 @@
 
 import org.apache.commons.lang3.StringUtils;
 import org.springframework.boot.info.BuildProperties;
+import org.springframework.scheduling.annotation.Async;
 import tech.powerjob.common.exception.PowerJobException;
 import tech.powerjob.common.utils.CommonUtils;
 import tech.powerjob.common.utils.NetUtils;
+import tech.powerjob.server.common.constants.PJThreadPool;
 import tech.powerjob.server.common.module.ServerInfo;
 import tech.powerjob.server.extension.LockService;
 import tech.powerjob.server.persistence.remote.model.ServerInfoDO;
@@ -86,6 +88,7 @@ public ServerInfoServiceImpl(LockService lockService, ServerInfoRepository serve
         log.info("[ServerInfoService] ip:{}, id:{}, cost:{}", ip, serverInfo.getId(), sw);
     }
 
+    @Async(PJThreadPool.TIMING_POOL)
     @Scheduled(fixedRate = 15000, initialDelay = 15000)
     public void heartbeat() {
         serverInfoRepository.updateGmtModifiedByIp(serverInfo.getIp(), new Date());

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/DispatchService.java
Patch:
@@ -181,6 +181,7 @@ private ServerScheduleJobReq constructServerScheduleJobReq(JobInfoDO jobInfo, In
         }
         req.setInstanceId(instanceInfo.getInstanceId());
         req.setAllWorkerAddress(finalWorkersIpList);
+        req.setMaxWorkerCount(jobInfo.getMaxWorkerCount());
 
         // 设置工作流ID
         req.setWfInstanceId(instanceInfo.getWfInstanceId());

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/service/JobService.java
Patch:
@@ -252,7 +252,7 @@ private void calculateNextTriggerTime(JobInfoDO jobInfo) {
         // 计算下次调度时间
         if (TimeExpressionType.FREQUENT_TYPES.contains(jobInfo.getTimeExpressionType())) {
             // 固定频率类型的任务不计算
-            jobInfo.setTimeExpression(null);
+            jobInfo.setNextTriggerTime(null);
         } else {
             LifeCycle lifeCycle = LifeCycle.parse(jobInfo.getLifecycle());
             Long nextValidTime = timingStrategyService.calculateNextTriggerTimeWithInspection(TimeExpressionType.of(jobInfo.getTimeExpressionType()), jobInfo.getTimeExpression(), lifeCycle.getStart(), lifeCycle.getEnd());

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/scheduler/PowerScheduleService.java
Patch:
@@ -255,7 +255,7 @@ private void scheduleFrequentJob(List<Long> appIds) {
                             log.info("[FrequentScheduler] disable frequent job,id:{}.", jobInfoDO.getId());
                         } else if (lifeCycle.getStart() == null || lifeCycle.getStart() < System.currentTimeMillis() + SCHEDULE_RATE * 2) {
                             log.info("[FrequentScheduler] schedule frequent job,id:{}.", jobInfoDO.getId());
-                            jobService.runJob(jobInfoDO.getAppId(), jobId, null, Optional.of(lifeCycle.getStart()).orElse(0L) - System.currentTimeMillis());
+                            jobService.runJob(jobInfoDO.getAppId(), jobId, null, Optional.ofNullable(lifeCycle.getStart()).orElse(0L) - System.currentTimeMillis());
                         }
                     });
                 });

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/scheduler/TimingStrategyService.java
Patch:
@@ -83,15 +83,14 @@ public Long calculateNextTriggerTime(Long preTriggerTime, TimeExpressionType tim
     /**
      * 计算下次的调度时间并检查校验规则
      *
-     * @param preTriggerTime     上次触发时间(nullable)
      * @param timeExpressionType 定时表达式类型
      * @param timeExpression     表达式
      * @param startTime          起始时间(include)
      * @param endTime            结束时间(include)
      * @return 下次的调度时间
      */
-    public Long calculateNextTriggerTimeWithInspection(Long preTriggerTime, TimeExpressionType timeExpressionType, String timeExpression, Long startTime, Long endTime) {
-        Long nextTriggerTime = calculateNextTriggerTime(preTriggerTime, timeExpressionType, timeExpression, startTime, endTime);
+    public Long calculateNextTriggerTimeWithInspection( TimeExpressionType timeExpressionType, String timeExpression, Long startTime, Long endTime) {
+        Long nextTriggerTime = calculateNextTriggerTime(null, timeExpressionType, timeExpression, startTime, endTime);
         if (TimeExpressionType.INSPECT_TYPES.contains(timeExpressionType.getV()) && nextTriggerTime == null) {
             throw new PowerJobException("time expression is out of date: " + timeExpression);
         }

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/service/JobService.java
Patch:
@@ -91,7 +91,7 @@ public Long saveJob(SaveJobInfoRequest request) {
         if (!CollectionUtils.isEmpty(request.getNotifyUserIds())) {
             jobInfoDO.setNotifyUserIds(SJ.COMMA_JOINER.join(request.getNotifyUserIds()));
         }
-        LifeCycle lifecycle = Optional.of(request.getLifecycle()).orElse(LifeCycle.EMPTY_LIFE_CYCLE);
+        LifeCycle lifecycle = Optional.ofNullable(request.getLifecycle()).orElse(LifeCycle.EMPTY_LIFE_CYCLE);
         jobInfoDO.setLifecycle(JSON.toJSONString(lifecycle));
         // 检查定时策略
         timingStrategyService.validate(request.getTimeExpressionType(), request.getTimeExpression(), lifecycle.getStart(), lifecycle.getEnd());
@@ -255,7 +255,7 @@ private void calculateNextTriggerTime(JobInfoDO jobInfo) {
             jobInfo.setTimeExpression(null);
         } else {
             LifeCycle lifeCycle = LifeCycle.parse(jobInfo.getLifecycle());
-            Long nextValidTime = timingStrategyService.calculateNextTriggerTimeWithInspection(jobInfo.getNextTriggerTime(), TimeExpressionType.CRON, jobInfo.getTimeExpression(), lifeCycle.getStart(), lifeCycle.getEnd());
+            Long nextValidTime = timingStrategyService.calculateNextTriggerTimeWithInspection(TimeExpressionType.of(jobInfo.getTimeExpressionType()), jobInfo.getTimeExpression(), lifeCycle.getStart(), lifeCycle.getEnd());
             jobInfo.setNextTriggerTime(nextValidTime);
         }
         // 重写最后修改时间

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/controller/JobController.java
Patch:
@@ -39,7 +39,7 @@ public class JobController {
     private JobInfoRepository jobInfoRepository;
 
     @PostMapping("/save")
-    public ResultDTO<Void> saveJobInfo(@RequestBody SaveJobInfoRequest request) throws Exception {
+    public ResultDTO<Void> saveJobInfo(@RequestBody SaveJobInfoRequest request) {
         jobService.saveJob(request);
         return ResultDTO.success(null);
     }

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/controller/OpenAPIController.java
Patch:
@@ -204,7 +204,7 @@ public ResultDTO<List<WorkflowNodeInfoDO>> saveWorkflowNode(@RequestBody List<Sa
 
     @PostMapping(OpenAPIConstant.STOP_WORKFLOW_INSTANCE)
     public ResultDTO<Void> stopWorkflowInstance(Long wfInstanceId, Long appId) {
-        workflowInstanceService.stopWorkflowInstance(wfInstanceId, appId);
+        workflowInstanceService.stopWorkflowInstanceEntrance(wfInstanceId, appId);
         return ResultDTO.success(null);
     }
 

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/controller/WorkflowInstanceController.java
Patch:
@@ -39,7 +39,7 @@ public class WorkflowInstanceController {
 
     @GetMapping("/stop")
     public ResultDTO<Void> stopWfInstance(Long wfInstanceId, Long appId) {
-        workflowInstanceService.stopWorkflowInstance(wfInstanceId, appId);
+        workflowInstanceService.stopWorkflowInstanceEntrance(wfInstanceId, appId);
         return ResultDTO.success(null);
     }
 

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/scheduler/PowerScheduleService.java
Patch:
@@ -278,7 +278,7 @@ private void refreshWorkflow(WorkflowInfoDO wfInfo) throws ParseException {
 
         if (nextTriggerTime == null) {
             log.warn("[Workflow-{}] this workflow won't be scheduled anymore, system will set the status to DISABLE!", wfInfo.getId());
-            wfInfo.setStatus(SwitchableStatus.DISABLE.getV());
+            updateEntity.setStatus(SwitchableStatus.DISABLE.getV());
         } else {
             updateEntity.setNextTriggerTime(nextTriggerTime.getTime());
         }

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/workflow/WorkflowInstanceManager.java
Patch:
@@ -238,12 +238,10 @@ public void start(WorkflowInfoDO wfInfo, Long wfInstanceId) {
             }
             if (readyNodes.isEmpty()) {
                 // 没有就绪的节点（所有节点都被禁用）
-                wfInstanceInfo.setStatus(WorkflowInstanceStatus.SUCCEED.getV());
-                wfInstanceInfo.setResult(SystemInstanceResult.NO_ENABLED_NODES);
                 wfInstanceInfo.setFinishedTime(System.currentTimeMillis());
                 wfInstanceInfo.setDag(JSON.toJSONString(dag));
                 log.warn("[Workflow-{}|{}] workflowInstance({}) needn't running ", wfInfo.getId(), wfInstanceId, wfInstanceInfo);
-                workflowInstanceInfoRepository.saveAndFlush(wfInstanceInfo);
+                handleWfInstanceFinalStatus(wfInstanceInfo, SystemInstanceResult.NO_ENABLED_NODES, WorkflowInstanceStatus.SUCCEED);
                 return;
             }
             // 需要更新工作流实例状态

File: powerjob-client/src/test/java/tech/powerjob/client/test/TestWorkflow.java
Patch:
@@ -71,18 +71,18 @@ void testSaveWorkflow() {
         SaveWorkflowNodeRequest saveWorkflowNodeRequest1 = new SaveWorkflowNodeRequest();
         saveWorkflowNodeRequest1.setJobId(1L);
         saveWorkflowNodeRequest1.setNodeName("DAG-Node-1");
-        saveWorkflowNodeRequest1.setType(WorkflowNodeType.JOB);
+        saveWorkflowNodeRequest1.setType(WorkflowNodeType.JOB.getCode());
 
         SaveWorkflowNodeRequest saveWorkflowNodeRequest2 = new SaveWorkflowNodeRequest();
         saveWorkflowNodeRequest2.setJobId(1L);
         saveWorkflowNodeRequest2.setNodeName("DAG-Node-2");
-        saveWorkflowNodeRequest2.setType(WorkflowNodeType.JOB);
+        saveWorkflowNodeRequest2.setType(WorkflowNodeType.JOB.getCode());
 
 
         SaveWorkflowNodeRequest saveWorkflowNodeRequest3 = new SaveWorkflowNodeRequest();
         saveWorkflowNodeRequest3.setJobId(1L);
         saveWorkflowNodeRequest3.setNodeName("DAG-Node-3");
-        saveWorkflowNodeRequest3.setType(WorkflowNodeType.JOB);
+        saveWorkflowNodeRequest3.setType(WorkflowNodeType.JOB.getCode());
 
 
         List<WorkflowNodeInfoDTO> nodeList = powerJobClient.saveWorkflowNode(Lists.newArrayList(saveWorkflowNodeRequest1,saveWorkflowNodeRequest2,saveWorkflowNodeRequest3)).getData();

File: powerjob-common/src/main/java/tech/powerjob/common/serialize/SerializerUtils.java
Patch:
@@ -4,6 +4,7 @@
 import com.esotericsoftware.kryo.kryo5.Kryo;
 import com.esotericsoftware.kryo.kryo5.io.Input;
 import com.esotericsoftware.kryo.kryo5.io.Output;
+import com.esotericsoftware.kryo.kryo5.serializers.CompatibleFieldSerializer;
 
 /**
  * 序列化器
@@ -23,6 +24,8 @@ public class SerializerUtils {
         kryo.setReferences(true); //默认值就是 true，添加此行的目的是为了提醒维护者，不要改变这个配置
         // 关闭序列化注册，会导致性能些许下降，但在分布式环境中，注册类生成ID不一致会导致错误
         kryo.setRegistrationRequired(false);
+        // 支持删除或者新增字段
+        kryo.setDefaultSerializer(CompatibleFieldSerializer.class);
         // 设置类加载器为线程上下文类加载器（如果Processor来源于容器，必须使用容器的类加载器，否则妥妥的CNF）
         kryo.setClassLoader(Thread.currentThread().getContextClassLoader());
 

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/instance/InstanceService.java
Patch:
@@ -191,8 +191,8 @@ public void retryInstance(Long appId, Long instanceId) {
      * @param instanceId 任务实例
      */
     @DesignateServer
-    public void cancelInstance(Long instanceId) {
-        log.info("[Instance-{}] try to cancel the instance.", instanceId);
+    public void cancelInstance(Long appId, Long instanceId) {
+        log.info("[Instance-{}] try to cancel the instance with appId {}.", instanceId, appId);
 
         try {
             InstanceInfoDO instanceInfo = fetchInstanceInfo(instanceId);

File: powerjob-server/powerjob-server-starter/src/main/java/tech/powerjob/server/web/controller/OpenAPIController.java
Patch:
@@ -126,7 +126,7 @@ public ResultDTO<Void> stopInstance(Long instanceId, Long appId) {
     @PostMapping(OpenAPIConstant.CANCEL_INSTANCE)
     public ResultDTO<Void> cancelInstance(Long instanceId, Long appId) {
         checkInstanceIdValid(instanceId, appId);
-        instanceService.cancelInstance(instanceId);
+        instanceService.cancelInstance(appId, instanceId);
         return ResultDTO.success(null);
     }
 

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/server/election/ServerElectionService.java
Patch:
@@ -93,7 +93,7 @@ private String getServer0(Long appId, String protocol) {
 
                 // 可能上一台机器已经完成了Server选举，需要再次判断
                 AppInfoDO appInfo = appInfoRepository.findById(appId).orElseThrow(() -> new RuntimeException("impossible, unless we just lost our database."));
-                String address = activeAddress(originServer, downServerCache, protocol);
+                String address = activeAddress(appInfo.getCurrentServer(), downServerCache, protocol);
                 if (StringUtils.isNotEmpty(address)) {
                     return address;
                 }

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/server/election/ServerElectionService.java
Patch:
@@ -93,7 +93,7 @@ private String getServer0(Long appId, String protocol) {
 
                 // 可能上一台机器已经完成了Server选举，需要再次判断
                 AppInfoDO appInfo = appInfoRepository.findById(appId).orElseThrow(() -> new RuntimeException("impossible, unless we just lost our database."));
-                String address = activeAddress(originServer, downServerCache, protocol);
+                String address = activeAddress(appInfo.getCurrentServer(), downServerCache, protocol);
                 if (StringUtils.isNotEmpty(address)) {
                     return address;
                 }

File: powerjob-common/src/main/java/tech/powerjob/common/response/AskResponse.java
Patch:
@@ -23,6 +23,7 @@ public class AskResponse implements PowerSerializable {
     /*
     - 使用 Object 会报错：java.lang.ClassCastException: scala.collection.immutable.HashMap cannot be cast to XXX，只能自己序列化反序列化了
     - 嵌套类型（比如 Map<String, B>），如果B也是个复杂对象，那么反序列化后B的类型为 LinkedHashMap... 处理比较麻烦（转成JSON再转回来）
+    - 考虑到多语言通讯，data 必须使用 JSON 序列化为字节数组
      */
     private byte[] data;
 

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/container/ContainerService.java
Patch:
@@ -95,9 +95,9 @@ public void save(ContainerInfoDO container) {
 
         Long originId = container.getId();
         if (originId != null) {
-            container = containerInfoRepository.findById(originId).orElseThrow(() -> new IllegalArgumentException("can't find container by id: " + originId));
-        }else {
-            container = new ContainerInfoDO();
+            // just validate
+            containerInfoRepository.findById(originId).orElseThrow(() -> new IllegalArgumentException("can't find container by id: " + originId));
+        } else {
             container.setGmtCreate(new Date());
         }
         container.setGmtModified(new Date());

File: powerjob-worker-samples/src/main/java/com/github/kfcfans/powerjob/samples/config/SqlProcessorConfiguration.java
Patch:
@@ -1,5 +1,6 @@
 package com.github.kfcfans.powerjob.samples.config;
 
+import com.github.kfcfans.powerjob.common.utils.CommonUtils;
 import com.zaxxer.hikari.HikariConfig;
 import com.zaxxer.hikari.HikariDataSource;
 import org.h2.Driver;
@@ -22,7 +23,7 @@ public class SqlProcessorConfiguration {
     @Bean
     @DependsOn({"initPowerJob"})
     public DataSource sqlProcessorDataSource() {
-        String path = System.getProperty("user.home") + "/test/h2/";
+        String path = System.getProperty("user.home") + "/test/h2/" + CommonUtils.genUUID() + "/";
         String jdbcUrl = String.format("jdbc:h2:file:%spowerjob_sql_processor_db;DB_CLOSE_DELAY=-1;DATABASE_TO_UPPER=false", path);
         HikariConfig config = new HikariConfig();
         config.setDriverClassName(Driver.class.getName());

File: powerjob-worker-samples/src/main/java/com/github/kfcfans/powerjob/samples/config/SqlProcessorConfiguration.java
Patch:
@@ -1,6 +1,5 @@
 package com.github.kfcfans.powerjob.samples.config;
 
-import com.github.kfcfans.powerjob.worker.common.utils.OmsWorkerFileUtils;
 import com.zaxxer.hikari.HikariConfig;
 import com.zaxxer.hikari.HikariDataSource;
 import org.h2.Driver;
@@ -23,7 +22,8 @@ public class SqlProcessorConfiguration {
     @Bean
     @DependsOn({"initPowerJob"})
     public DataSource sqlProcessorDataSource() {
-        String jdbcUrl = String.format("jdbc:h2:file:%spowerjob_sql_processor_db;DB_CLOSE_DELAY=-1;DATABASE_TO_UPPER=false", OmsWorkerFileUtils.getH2WorkDir());
+        String path = System.getProperty("user.home") + "/test/h2/";
+        String jdbcUrl = String.format("jdbc:h2:file:%spowerjob_sql_processor_db;DB_CLOSE_DELAY=-1;DATABASE_TO_UPPER=false", path);
         HikariConfig config = new HikariConfig();
         config.setDriverClassName(Driver.class.getName());
         config.setJdbcUrl(jdbcUrl);

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/persistence/ConnectionFactory.java
Patch:
@@ -1,7 +1,7 @@
 package com.github.kfcfans.powerjob.worker.persistence;
 
+import com.github.kfcfans.powerjob.common.utils.CommonUtils;
 import com.github.kfcfans.powerjob.worker.common.constants.StoreStrategy;
-import com.github.kfcfans.powerjob.worker.common.utils.OmsWorkerFileUtils;
 import com.zaxxer.hikari.HikariConfig;
 import com.zaxxer.hikari.HikariDataSource;
 import lombok.extern.slf4j.Slf4j;
@@ -24,7 +24,7 @@ public class ConnectionFactory {
 
     private volatile DataSource dataSource;
 
-    private final String H2_PATH = OmsWorkerFileUtils.getH2WorkDir();
+    private final String H2_PATH = System.getProperty("user.home") + "/h2/" + CommonUtils.genUUID() + "/";
     private final String DISK_JDBC_URL = String.format("jdbc:h2:file:%spowerjob_worker_db;DB_CLOSE_DELAY=-1;DATABASE_TO_UPPER=false", H2_PATH);
     private final String MEMORY_JDBC_URL = String.format("jdbc:h2:mem:%spowerjob_worker_db;DB_CLOSE_DELAY=-1;DATABASE_TO_UPPER=false", H2_PATH);
 

File: powerjob-official-processors/src/main/java/tech/powerjob/official/processors/util/CommonUtils.java
Patch:
@@ -17,7 +17,7 @@ private CommonUtils() {
 
     public static String parseParams(TaskContext context) {
         // 工作流中的总是优先使用 jobParams
-        if (context.getWfInstanceId() != null) {
+        if (context.getWorkflowContext().getWfInstanceId() != null) {
             return context.getJobParams();
         }
         if (StringUtils.isNotEmpty(context.getInstanceParams())) {

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/instance/InstanceService.java
Patch:
@@ -104,7 +104,7 @@ public Long create(Long jobId, Long appId, String jobParams, String instancePara
      *
      * @param instanceId 任务实例ID
      */
-    @DesignateServer(appIdParameterName = "appId")
+    @DesignateServer
     public void stopInstance(Long appId,Long instanceId) {
 
         log.info("[Instance-{}] try to stop the instance instance in appId: {}", instanceId,appId);
@@ -152,7 +152,7 @@ public void stopInstance(Long appId,Long instanceId) {
      *
      * @param instanceId 任务实例ID
      */
-    @DesignateServer(appIdParameterName = "appId")
+    @DesignateServer
     public void retryInstance(Long appId, Long instanceId) {
 
         log.info("[Instance-{}] retry instance in appId: {}", instanceId, appId);
@@ -186,6 +186,7 @@ public void retryInstance(Long appId, Long instanceId) {
      *
      * @param instanceId 任务实例
      */
+    @DesignateServer
     public void cancelInstance(Long instanceId) {
         log.info("[Instance-{}] try to cancel the instance.", instanceId);
 

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/lock/UseSegmentLockAspect.java
Patch:
@@ -1,6 +1,7 @@
 package tech.powerjob.server.core.lock;
 
 import com.github.kfcfans.powerjob.common.utils.SegmentLock;
+import org.springframework.core.annotation.Order;
 import tech.powerjob.server.common.utils.AOPUtils;
 import com.google.common.collect.Maps;
 import lombok.extern.slf4j.Slf4j;
@@ -20,6 +21,7 @@
 @Slf4j
 @Aspect
 @Component
+@Order(1)
 public class UseSegmentLockAspect {
 
     private final Map<String, SegmentLock> lockStore = Maps.newConcurrentMap();

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/service/JobService.java
Patch:
@@ -145,7 +145,7 @@ public List<JobInfoDTO> queryJob(PowerQuery powerQuery) {
      * @param delay          延迟时间，单位 毫秒
      * @return 任务实例ID
      */
-    @DesignateServer(appIdParameterName = "appId")
+    @DesignateServer
     public long runJob(Long appId, Long jobId, String instanceParams, Long delay) {
 
         delay = delay == null ? 0 : delay;

File: powerjob-server/powerjob-server-core/src/main/java/tech/powerjob/server/core/workflow/WorkflowService.java
Patch:
@@ -265,7 +265,7 @@ public void enableWorkflow(Long wfId, Long appId) {
      * @param delay      延迟时间
      * @return 该 workflow 实例的 instanceId（wfInstanceId）
      */
-    @DesignateServer(appIdParameterName = "appId")
+    @DesignateServer
     public Long runWorkflow(Long wfId, Long appId, String initParams, Long delay) {
 
         delay = delay == null ? 0 : delay;

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/server/redirector/DesignateServer.java
Patch:
@@ -17,8 +17,8 @@
 public @interface DesignateServer {
 
     /**
-     * 转发请求需要 AppInfo 下的 currentServer 信息，因此必须要有 appId 作为入参，该字段指定了 appId 字段的参数名称
+     * 转发请求需要 AppInfo 下的 currentServer 信息，因此必须要有 appId 作为入参，该字段指定了 appId 字段的参数名称，默认为 appId
      * @return appId 参数名称
      */
-    String appIdParameterName();
+    String appIdParameterName() default "appId";
 }

File: powerjob-server/powerjob-server-remote/src/main/java/tech/powerjob/server/remote/worker/WorkerClusterQueryService.java
Patch:
@@ -53,7 +53,7 @@ public List<WorkerInfo> getSuitableWorkers(JobInfoDO jobInfo) {
         return workers;
     }
 
-    @DesignateServer(appIdParameterName = "appId")
+    @DesignateServer
     public List<WorkerInfo> getAllWorkers(Long appId) {
         List<WorkerInfo> workers = Lists.newLinkedList(getWorkerInfosByAppId(appId).values());
         workers.sort((o1, o2) -> o2 .getSystemMetrics().calculateScore() - o1.getSystemMetrics().calculateScore());

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/remote/DispatchService.java
Patch:
@@ -180,7 +180,9 @@ private ServerScheduleJobReq constructServerScheduleJobReq(JobInfoDO jobInfo, In
         req.setProcessorType(ProcessorType.of(jobInfo.getProcessorType()).name());
 
         req.setTimeExpressionType(TimeExpressionType.of(jobInfo.getTimeExpressionType()).name());
-        req.setInstanceTimeoutMS(jobInfo.getInstanceTimeLimit());
+        if (jobInfo.getInstanceTimeLimit() != null) {
+            req.setInstanceTimeoutMS(jobInfo.getInstanceTimeLimit());
+        }
         req.setThreadConcurrency(jobInfo.getConcurrency());
         return req;
     }

File: powerjob-official-processors/src/main/java/tech/powerjob/official/processors/util/CommonUtils.java
Patch:
@@ -17,7 +17,7 @@ private CommonUtils() {
 
     public static String parseParams(TaskContext context) {
         // 工作流中的总是优先使用 jobParams
-        if (context.getWfInstanceId() == null) {
+        if (context.getWfInstanceId() != null) {
             return context.getJobParams();
         }
         if (StringUtils.isNotEmpty(context.getInstanceParams())) {

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/JobService.java
Patch:
@@ -197,7 +197,7 @@ private void shutdownOrStopJob(Long jobId, SwitchableStatus status) {
         executeLogs.forEach(instance -> {
             try {
                 // 重复查询了数据库，不过问题不大，这个调用量很小
-                instanceService.stopInstance(instance.getInstanceId());
+                instanceService.stopInstance(instance.getAppId(),instance.getInstanceId());
             } catch (Exception ignore) {
                 // ignore exception
             }

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/controller/OpenAPIController.java
Patch:
@@ -110,7 +110,7 @@ public ResultDTO<Long> runJob(Long appId, Long jobId, @RequestParam(required = f
     @PostMapping(OpenAPIConstant.STOP_INSTANCE)
     public ResultDTO<Void> stopInstance(Long instanceId, Long appId) {
         checkInstanceIdValid(instanceId, appId);
-        instanceService.stopInstance(instanceId);
+        instanceService.stopInstance(appId,instanceId);
         return ResultDTO.success(null);
     }
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/JobInfoRepository.java
Patch:
@@ -34,11 +34,11 @@ public interface JobInfoRepository extends JpaRepository<JobInfoDO, Long>, JpaSp
     /**
      * 校验工作流包含的任务
      * @param appId APP ID
-     * @param status 状态
+     * @param statusSet 状态列表
      * @param jobIds 任务ID
      * @return 数量
      */
-    long countByAppIdAndStatusAndIdIn(Long appId, int status, Set<Long> jobIds);
+    long countByAppIdAndStatusInAndIdIn(Long appId, Set<Integer> statusSet , Set<Long> jobIds);
 
     long countByAppIdAndStatusNot(long appId, int status);
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/workflow/WorkflowInstanceManager.java
Patch:
@@ -119,7 +119,8 @@ public Long create(WorkflowInfoDO wfInfo, String initParams, Long expectTriggerT
             node.setStatus(InstanceStatus.WAITING_DISPATCH.getV());
         });
         int needNum = allJobIds.size();
-        long dbNum = jobInfoRepository.countByAppIdAndStatusAndIdIn(wfInfo.getAppId(), SwitchableStatus.ENABLE.getV(), allJobIds);
+        // 检查工作流中的任务是否均处于可用状态（没有被删除）
+        long dbNum = jobInfoRepository.countByAppIdAndStatusInAndIdIn(wfInfo.getAppId(), Sets.newHashSet(SwitchableStatus.ENABLE.getV(), SwitchableStatus.DISABLE.getV()), allJobIds);
         log.debug("[Workflow-{}|{}] contains {} jobs, find {} jobs in database.", wfId, wfInstanceId, needNum, dbNum);
         // 先 set 一次，异常的话直接存这个信息
         newWfInstance.setDag(JSON.toJSONString(dag));

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/controller/InstanceController.java
Patch:
@@ -73,8 +73,8 @@ public ResultDTO<Void> retryInstance(String appId, Long instanceId) {
     }
 
     @GetMapping("/detail")
-    public ResultDTO<InstanceDetailVO> getInstanceDetail(String instanceId) {
-        return ResultDTO.success(InstanceDetailVO.from(instanceService.getInstanceDetail(Long.valueOf(instanceId))));
+    public ResultDTO<InstanceDetailVO> getInstanceDetail(Long instanceId) {
+        return ResultDTO.success(InstanceDetailVO.from(instanceService.getInstanceDetail(instanceId)));
     }
 
     @GetMapping("/log")

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/workflow/WorkflowService.java
Patch:
@@ -215,8 +215,8 @@ public List<WorkflowNodeInfoDO> addWorkflowNode(List<AddWorkflowNodeRequest> req
      */
     public void modifyWorkflowNode(ModifyWorkflowNodeRequest req) {
         req.valid();
-        permissionCheck(req.getId(), req.getAppId());
-        WorkflowNodeInfoDO workflowNodeInfoDO = workflowNodeInfoRepository.findById(req.getId()).orElseThrow(() -> new IllegalArgumentException("can't find workflowNod by id: " + req.getId()));
+        permissionCheck(req.getWorkflowId(), req.getAppId());
+        WorkflowNodeInfoDO workflowNodeInfoDO = workflowNodeInfoRepository.findById(req.getId()).orElseThrow(() -> new IllegalArgumentException("can't find workflow Node by id: " + req.getId()));
         BeanUtils.copyProperties(req, workflowNodeInfoDO);
         workflowNodeInfoDO.setGmtModified(new Date());
         workflowNodeInfoRepository.saveAndFlush(workflowNodeInfoDO);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/workflow/WorkflowService.java
Patch:
@@ -264,8 +264,7 @@ public void saveWorkflowDAG(SaveWorkflowDAGRequest req) {
 
     private WorkflowInfoVO convert2WorkflowInfoVO(WorkflowInfoDO wfInfo) {
 
-        WorkflowInfoVO res = new WorkflowInfoVO();
-        BeanUtils.copyProperties(wfInfo, res);
+        WorkflowInfoVO res =  WorkflowInfoVO.from(wfInfo);
 
         PEWorkflowDAG dagInfo;
         try {

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/response/WorkflowInfoVO.java
Patch:
@@ -58,8 +58,7 @@ public class WorkflowInfoVO {
     /**
      * ENABLE / DISABLE
      */
-    private boolean enable;
-
+    private Boolean enable;
     /**
      * 工作流整体失败的报警
      */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/workflow/WorkflowInstanceManager.java
Patch:
@@ -291,6 +291,8 @@ public void move(Long wfInstanceId, Long instanceId, InstanceStatus status, Stri
                 }
                 // 注意：这里会直接跳过 disable 的节点
                 List<PEWorkflowDAG.Node> readyNodes = WorkflowDAGUtils.listReadyNodes(dag);
+                // 这里得重新更新一下，因为 WorkflowDAGUtils#listReadyNodes 可能会更新节点状态
+                wfInstance.setDag(JSON.toJSONString(dag));
                 // 如果没有就绪的节点，需要再次判断是否已经全部完成
                 if (readyNodes.isEmpty() && isFinish(dag)) {
                     allFinished = true;
@@ -315,7 +317,7 @@ public void move(Long wfInstanceId, Long instanceId, InstanceStatus status, Stri
                     readyNode.setStatus(InstanceStatus.RUNNING.getV());
                     log.debug("[Workflow-{}|{}] workflowInstance start to process new node(nodeId={},jobId={},instanceId={})", wfId, wfInstanceId, readyNode.getNodeId(), readyNode.getJobId(), newInstanceId);
                 }
-
+                // 这里也得更新 DAG 信息
                 wfInstance.setDag(JSON.toJSONString(dag));
                 workflowInstanceInfoRepository.saveAndFlush(wfInstance);
                 // 持久化结束后，开始调度执行所有的任务

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/DispatchService.java
Patch:
@@ -80,7 +80,7 @@ public void redispatch(JobInfoDO jobInfo, long instanceId) {
     public void dispatch(JobInfoDO jobInfo, long instanceId) {
         // 检查当前任务是否被取消
         InstanceInfoDO instanceInfo = instanceInfoRepository.findByInstanceId(instanceId);
-        Long jobId = instanceInfo.getId();
+        Long jobId = instanceInfo.getJobId();
         if (CANCELED.getV() == instanceInfo.getStatus()) {
             log.info("[Dispatcher-{}|{}] cancel dispatch due to instance has been canceled", jobId, instanceId);
             return;

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -312,6 +312,8 @@ public void broadcast(boolean preExecuteSuccess, long subInstanceId, String preT
                 subTask.setSubInstanceId(subInstanceId);
                 subTask.setTaskName(TaskConstant.BROADCAST_TASK_NAME);
                 subTask.setTaskId(preTaskId + "." + i);
+                // 广播任务直接写入派发地址
+                subTask.setAddress(allWorkerAddress.get(i));
                 subTaskList.add(subTask);
             }
             submitTask(subTaskList);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/remote/server/FriendRequestHandler.java
Patch:
@@ -2,13 +2,14 @@
 
 import akka.actor.AbstractActor;
 import com.alibaba.fastjson.JSONObject;
-import com.github.kfcfans.powerjob.server.remote.worker.cluster.WorkerInfo;
 import com.github.kfcfans.powerjob.common.response.AskResponse;
 import com.github.kfcfans.powerjob.server.common.utils.SpringUtils;
 import com.github.kfcfans.powerjob.server.remote.server.request.FriendQueryWorkerClusterStatusReq;
 import com.github.kfcfans.powerjob.server.remote.server.request.Ping;
 import com.github.kfcfans.powerjob.server.remote.server.request.RemoteProcessReq;
+import com.github.kfcfans.powerjob.server.remote.transport.TransportService;
 import com.github.kfcfans.powerjob.server.remote.worker.cluster.WorkerClusterManagerService;
+import com.github.kfcfans.powerjob.server.remote.worker.cluster.WorkerInfo;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.lang3.exception.ExceptionUtils;
 import org.springframework.util.ReflectionUtils;
@@ -38,7 +39,7 @@ public Receive createReceive() {
      * 处理存活检测的请求
      */
     private void onReceivePing(Ping ping) {
-        getSender().tell(AskResponse.succeed(System.currentTimeMillis() - ping.getCurrentTime()), getSelf());
+        getSender().tell(AskResponse.succeed(TransportService.getAllAddress()), getSelf());
     }
 
     /**

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/OmsConstant.java
Patch:
@@ -19,5 +19,6 @@ public class OmsConstant {
     public static final String COMMA = ",";
     public static final String LINE_SEPARATOR = "\r\n";
 
+    public static final String HTTP_HEADER_CONTENT_TYPE = "Content-Type";
     public static final String JSON_MEDIA_TYPE = "application/json; charset=utf-8";
 }

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/handler/outer/WorkerRequestAkkaHandler.java
Patch:
@@ -26,7 +26,7 @@ public Receive createReceive() {
                 .match(WorkerLogReportReq.class, req -> getWorkerRequestHandler().onReceiveWorkerLogReportReq(req))
                 .match(WorkerNeedDeployContainerRequest.class, this::onReceiveWorkerNeedDeployContainerRequest)
                 .match(WorkerQueryExecutorClusterReq.class, this::onReceiveWorkerQueryExecutorClusterReq)
-                .matchAny(obj -> log.warn("[ServerActor] receive unknown request: {}.", obj))
+                .matchAny(obj -> log.warn("[WorkerRequestAkkaHandler] receive unknown request: {}.", obj))
                 .build();
     }
 
@@ -44,7 +44,7 @@ private void onReceiveTaskTrackerReportInstanceStatusReq(TaskTrackerReportInstan
                 getSender().tell(AskResponse.succeed(null), getSelf());
             }
         }catch (Exception e) {
-            log.error("[ServerActor] update instance status failed for request: {}.", req, e);
+            log.error("[WorkerRequestAkkaHandler] update instance status failed for request: {}.", req, e);
         }
     }
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/ha/DefaultServerElectionService.java
Patch:
@@ -106,7 +106,7 @@ private String getServer0(Long appId, String protocol) {
                 log.info("[ServerElection] this server({}) become the new server for app(appId={}).", appInfo.getCurrentServer(), appId);
                 return getProtocolServerAddress(protocol);
             }catch (Exception e) {
-                log.warn("[ServerElection] write new server to db failed for app {}.", appName);
+                log.error("[ServerElection] write new server to db failed for app {}.", appName, e);
             }finally {
                 lockService.unlock(lockName);
             }

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/common/config/ThreadPoolConfig.java
Patch:
@@ -34,7 +34,7 @@ public Executor getTimingPool() {
         executor.setQueueCapacity(0);
         executor.setKeepAliveSeconds(60);
         executor.setThreadNamePrefix("omsTimingPool-");
-        executor.setRejectedExecutionHandler(RejectedExecutionHandlerFactory.newThreadRun("PowerJob"));
+        executor.setRejectedExecutionHandler(RejectedExecutionHandlerFactory.newThreadRun("PowerJobTiming"));
         return executor;
     }
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/JobService.java
Patch:
@@ -233,6 +233,9 @@ private void fillDefaultValue(JobInfoDO jobInfoDO) {
         if (jobInfoDO.getTaskRetryNum() == null) {
             jobInfoDO.setTaskRetryNum(0);
         }
+        if (jobInfoDO.getInstanceTimeLimit() == null) {
+            jobInfoDO.setInstanceTimeLimit(0L);
+        }
     }
 
     private static JobInfoDTO convert(JobInfoDO jobInfoDO) {

File: powerjob-worker-samples/src/main/java/com/github/kfcfans/powerjob/samples/processors/BroadcastProcessorDemo.java
Patch:
@@ -13,7 +13,6 @@
 
 /**
  * 广播处理器 示例
- * com.github.kfcfans.oms.server.processors.BroadcastProcessorDemo
  *
  * @author tjq
  * @since 2020/4/17

File: powerjob-worker-samples/src/main/java/com/github/kfcfans/powerjob/samples/processors/MapReduceProcessorDemo.java
Patch:
@@ -21,8 +21,7 @@
 
 /**
  * MapReduce 处理器示例
- * com.github.kfcfans.oms.server.processors.MapReduceProcessorDemo
- * {"batchSize": 100, "batchNum": 2}
+ * 控制台参数：{"batchSize": 100, "batchNum": 2}
  *
  * @author tjq
  * @since 2020/4/17

File: powerjob-worker-samples/src/main/java/com/github/kfcfans/powerjob/samples/processors/StandaloneProcessorDemo.java
Patch:
@@ -11,7 +11,7 @@
 
 /**
  * 单机处理器 示例
- * com.github.kfcfans.oms.server.processors.StandaloneProcessorDemo
+ * com.github.kfcfans.powerjob.samples.processors.StandaloneProcessorDemo
  *
  * @author tjq
  * @since 2020/4/17

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/FrequentTaskTracker.java
Patch:
@@ -60,7 +60,7 @@ public class FrequentTaskTracker extends TaskTracker {
 
     private static final int HISTORY_SIZE = 10;
     private static final String LAST_TASK_ID_PREFIX = "L";
-    private static final int MIN_INTERVAL = 1000;
+    private static final int MIN_INTERVAL = 50;
 
     protected FrequentTaskTracker(ServerScheduleJobReq req) {
         super(req);

File: powerjob-official-processors/src/main/java/tech/powerjob/official/processors/util/CommonUtils.java
Patch:
@@ -12,7 +12,7 @@
 public class CommonUtils {
 
     public static String parseParams(TaskContext context) {
-        if (StringUtils.isEmpty(context.getInstanceParams())) {
+        if (StringUtils.isNotEmpty(context.getInstanceParams())) {
             return context.getInstanceParams();
         }
         return context.getJobParams();

File: powerjob-official-processors/src/main/java/tech/powerjob/official/processors/CommonBasicProcessor.java
Patch:
@@ -1,4 +1,4 @@
-package tech.powerjob.offical.processors;
+package tech.powerjob.official.processors;
 
 import com.github.kfcfans.powerjob.worker.core.processor.ProcessResult;
 import com.github.kfcfans.powerjob.worker.core.processor.TaskContext;

File: powerjob-official-processors/src/main/java/tech/powerjob/official/processors/impl/HttpProcessor.java
Patch:
@@ -1,4 +1,4 @@
-package tech.powerjob.offical.processors.impl;
+package tech.powerjob.official.processors.impl;
 
 import com.alibaba.fastjson.JSONObject;
 import com.alibaba.fastjson.JSONValidator;
@@ -8,7 +8,7 @@
 import lombok.Data;
 import okhttp3.*;
 import org.apache.commons.lang3.StringUtils;
-import tech.powerjob.offical.processors.CommonBasicProcessor;
+import tech.powerjob.official.processors.CommonBasicProcessor;
 
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;

File: powerjob-official-processors/src/test/java/tech/powerjob/official/processors/TestUtils.java
Patch:
@@ -1,4 +1,4 @@
-package tech.powerjob.offical.processors;
+package tech.powerjob.official.processors;
 
 import com.github.kfcfans.powerjob.worker.core.processor.TaskContext;
 import com.github.kfcfans.powerjob.worker.log.impl.OmsServerLogger;

File: powerjob-offical-processors/src/main/java/tech/powerjob/offical/processors/impl/HttpProcessor.java
Patch:
@@ -49,6 +49,7 @@ public ProcessResult process0(TaskContext taskContext) throws Exception {
             httpParams.method = "GET";
             omsLogger.info("[HttpProcessor] using default request method: GET");
         } else {
+            httpParams.method = httpParams.method.toUpperCase();
             omsLogger.info("[HttpProcessor] request method: {}", httpParams.method);
         }
 

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/request/query/JobInfoQuery.java
Patch:
@@ -16,7 +16,7 @@
  */
 @Getter
 @Setter
-@Accessors(chain = true, fluent = true)
+@Accessors(chain = true)
 public class JobInfoQuery extends PowerQuery {
 
     private Long idEq;
@@ -31,7 +31,6 @@ public class JobInfoQuery extends PowerQuery {
     private String jobParamsLike;
 
     private List<Integer> timeExpressionTypeIn;
-    private List<String> timeExpressionIn;
     private List<Integer> executeTypeIn;
     private List<Integer> processorTypeIn;
 

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/SystemInstanceResult.java
Patch:
@@ -22,6 +22,7 @@ public class SystemInstanceResult {
     public static final String UNKNOWN_BUG = "unknown bug";
     // TaskTracker 长时间未上报
     public static final String REPORT_TIMEOUT = "worker report timeout, maybe TaskTracker down";
+    public static final String CAN_NOT_FIND_JOB_INFO = "can't find job info";
 
     /* *********** workflow 专用 *********** */
     public static final String MIDDLE_JOB_FAILED = "middle job failed";

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/FrequentTaskTracker.java
Patch:
@@ -173,7 +173,7 @@ public void innerRun() {
             // 判断是否超出最大执行实例数
             if (maxInstanceNum > 0) {
                 if (timeExpressionType == TimeExpressionType.FIXED_RATE) {
-                    if (subInstanceId2TimeHolder.size() > maxInstanceNum) {
+                    if (subInstanceId2TimeHolder.size() >= maxInstanceNum) {
                         log.warn("[FQTaskTracker-{}] cancel to launch the subInstance({}) due to too much subInstance is running.", instanceId, subInstanceId);
                         processFinishedSubInstance(subInstanceId, false, "TOO_MUCH_INSTANCE");
                         return;

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/FrequentTaskTracker.java
Patch:
@@ -173,7 +173,7 @@ public void innerRun() {
             // 判断是否超出最大执行实例数
             if (maxInstanceNum > 0) {
                 if (timeExpressionType == TimeExpressionType.FIXED_RATE) {
-                    if (subInstanceId2TimeHolder.size() > maxInstanceNum) {
+                    if (subInstanceId2TimeHolder.size() >= maxInstanceNum) {
                         log.warn("[FQTaskTracker-{}] cancel to launch the subInstance({}) due to too much subInstance is running.", instanceId, subInstanceId);
                         processFinishedSubInstance(subInstanceId, false, "TOO_MUCH_INSTANCE");
                         return;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/DispatchService.java
Patch:
@@ -10,6 +10,7 @@
 import com.github.kfcfans.powerjob.server.service.ha.WorkerManagerService;
 import com.github.kfcfans.powerjob.server.service.instance.InstanceManager;
 import com.github.kfcfans.powerjob.server.service.instance.InstanceMetadataService;
+import com.github.kfcfans.powerjob.server.service.lock.local.UseSegmentLock;
 import com.google.common.base.Splitter;
 import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
@@ -46,6 +47,7 @@ public class DispatchService {
 
     private static final Splitter commaSplitter = Splitter.on(",");
 
+    @UseSegmentLock(type = "dispatch", key = "#jobInfo.getId().intValue()", concurrencyLevel = 1024)
     public void redispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTimes) {
         InstanceInfoDO instanceInfo = instanceInfoRepository.findByInstanceId(instanceId);
         dispatch(jobInfo, instanceId, currentRunningTimes, instanceInfo.getInstanceParams(), instanceInfo.getWfInstanceId());
@@ -59,6 +61,7 @@ public void redispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTi
      * @param instanceParams 实例的运行参数，API触发方式专用
      * @param wfInstanceId 工作流任务实例ID，workflow 任务专用
      */
+    @UseSegmentLock(type = "dispatch", key = "#jobInfo.getId().intValue()", concurrencyLevel = 1024)
     public void dispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTimes, String instanceParams, Long wfInstanceId) {
         Long jobId = jobInfo.getId();
         log.info("[Dispatcher-{}|{}] start to dispatch job: {};instancePrams: {}.", jobId, instanceId, jobInfo, instanceParams);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/ValidateService.java
Patch:
@@ -33,8 +33,8 @@ public static List<String> calculateNextTriggerTime(TimeExpressionType timeExpre
             case API: return Lists.newArrayList(OmsConstant.NONE);
             case WORKFLOW: return Lists.newArrayList("VALID: depends on workflow");
             case CRON: return calculateCronExpression(timeExpression);
-            case FIX_RATE: return calculateFixRate(timeExpression);
-            case FIX_DELAY: return Lists.newArrayList("VALID: depends on execution cost time");
+            case FIXED_RATE: return calculateFixRate(timeExpression);
+            case FIXED_DELAY: return Lists.newArrayList("VALID: depends on execution cost time");
         }
         // impossible
         return Collections.emptyList();

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/FrequentTaskTracker.java
Patch:
@@ -88,7 +88,7 @@ protected void initTaskTracker(ServerScheduleJobReq req) {
 
         // 2. 启动任务发射器
         launcher = new Launcher();
-        if (timeExpressionType == TimeExpressionType.FIX_RATE) {
+        if (timeExpressionType == TimeExpressionType.FIXED_RATE) {
             // 固定频率需要设置最小间隔
             if (timeParams < MIN_INTERVAL) {
                 throw new PowerJobException("time interval too small, please set the timeExpressionInfo >= 1000");
@@ -172,7 +172,7 @@ public void innerRun() {
 
             // 判断是否超出最大执行实例数
             if (maxInstanceNum > 0) {
-                if (timeExpressionType == TimeExpressionType.FIX_RATE) {
+                if (timeExpressionType == TimeExpressionType.FIXED_RATE) {
                     if (subInstanceId2TimeHolder.size() > maxInstanceNum) {
                         log.warn("[FQTaskTracker-{}] cancel to launch the subInstance({}) due to too much subInstance is running.", instanceId, subInstanceId);
                         processFinishedSubInstance(subInstanceId, false, "TOO_MUCH_INSTANCE");
@@ -368,7 +368,7 @@ private void processFinishedSubInstance(long subInstanceId, boolean success, Str
         taskPersistenceService.deleteAllSubInstanceTasks(instanceId, subInstanceId);
 
         // FIX_DELAY 则调度下次任务
-        if (timeExpressionType == TimeExpressionType.FIX_DELAY) {
+        if (timeExpressionType == TimeExpressionType.FIXED_DELAY) {
             scheduledPool.schedule(launcher, timeParams, TimeUnit.MILLISECONDS);
         }
     }

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -115,8 +115,8 @@ public static TaskTracker create(ServerScheduleJobReq req) {
         try {
             TimeExpressionType timeExpressionType = TimeExpressionType.valueOf(req.getTimeExpressionType());
             switch (timeExpressionType) {
-                case FIX_RATE:
-                case FIX_DELAY:return new FrequentTaskTracker(req);
+                case FIXED_RATE:
+                case FIXED_DELAY:return new FrequentTaskTracker(req);
                 default:return new CommonTaskTracker(req);
             }
         } catch (Exception e) {

File: powerjob-worker/src/test/java/com/github/kfcfans/powerjob/FrequentTaskTrackerTest.java
Patch:
@@ -41,13 +41,13 @@ public static void init() throws Exception {
 
     @Test
     public void testFixRateJob() throws Exception {
-        remoteTaskTracker.tell(TestUtils.genServerScheduleJobReq(ExecuteType.STANDALONE, TimeExpressionType.FIX_RATE), null);
+        remoteTaskTracker.tell(TestUtils.genServerScheduleJobReq(ExecuteType.STANDALONE, TimeExpressionType.FIXED_RATE), null);
         Thread.sleep(5000000);
     }
 
     @Test
     public void testFixDelayJob() throws Exception {
-        remoteTaskTracker.tell(TestUtils.genServerScheduleJobReq(ExecuteType.MAP_REDUCE, TimeExpressionType.FIX_DELAY), null);
+        remoteTaskTracker.tell(TestUtils.genServerScheduleJobReq(ExecuteType.MAP_REDUCE, TimeExpressionType.FIXED_DELAY), null);
         Thread.sleep(5000000);
     }
 }

File: powerjob-worker/src/test/java/com/github/kfcfans/powerjob/TestUtils.java
Patch:
@@ -32,8 +32,8 @@ public static ServerScheduleJobReq genServerScheduleJobReq(ExecuteType executeTy
         req.setTimeExpressionType(timeExpressionType.name());
         switch (timeExpressionType) {
             case CRON:req.setTimeExpression("0 * * * * ? ");
-            case FIX_RATE:
-            case FIX_DELAY:req.setTimeExpression("5000");
+            case FIXED_RATE:
+            case FIXED_DELAY:req.setTimeExpression("5000");
         }
 
         switch (executeType) {

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -119,7 +119,7 @@ public static TaskTracker create(ServerScheduleJobReq req) {
                 case FIX_DELAY:return new FrequentTaskTracker(req);
                 default:return new CommonTaskTracker(req);
             }
-        }catch (Exception e) {
+        } catch (Exception e) {
             log.warn("[TaskTracker-{}] create TaskTracker from request({}) failed.", req.getInstanceId(), req, e);
 
             // 直接发送失败请求

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/workflow/WorkflowInstanceManager.java
Patch:
@@ -314,7 +314,7 @@ public void move(Long wfInstanceId, Long instanceId, InstanceStatus status, Stri
     }
 
     /**
-     * 允许任务实例
+     * 运行任务实例
      * 需要将创建和运行任务实例分离，否则在秒失败情况下，会发生DAG覆盖更新的问题
      * @param jobId 任务ID
      * @param instanceId 任务实例ID

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -446,7 +446,7 @@ public void run() {
 
             // 3. 避免大查询，分批派发任务
             long currentDispatchNum = 0;
-            long maxDispatchNum = availablePtIps.size() * instanceInfo.getThreadConcurrency() * 2;
+            long maxDispatchNum = availablePtIps.size() * instanceInfo.getThreadConcurrency() * 2L;
             AtomicInteger index = new AtomicInteger(0);
 
             // 4. 循环查询数据库，获取需要派发的任务

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/controller/OpenAPIController.java
Patch:
@@ -122,9 +122,6 @@ public ResultDTO<InstanceInfoDTO> fetchInstanceInfo(Long instanceId) {
     /* ************* Workflow 区 ************* */
     @PostMapping(OpenAPIConstant.SAVE_WORKFLOW)
     public ResultDTO<Long> saveWorkflow(@RequestBody SaveWorkflowRequest request) throws Exception {
-        if (request.getId() != null) {
-            checkJobIdValid(request.getId(), request.getAppId());
-        }
         return ResultDTO.success(workflowService.saveWorkflow(request));
     }
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/common/redirect/DesignateServer.java
Patch:
@@ -6,7 +6,7 @@
 import java.lang.annotation.Target;
 
 /**
- * 执行服务器运行
+ * 需要在指定的服务器运行
  * 注意：该注解所在方法的参数必须为对象，不可以是 long 等基本类型
  *
  * @author tjq

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/common/redirect/DesignateServerAspect.java
Patch:
@@ -62,7 +62,7 @@ public Object execute(ProceedingJoinPoint point, DesignateServer designateServer
         }
 
         if (appId == null) {
-            throw new PowerJobException("can't find appId in params!");
+            throw new PowerJobException("can't find appId in params for:" + signature.toString());
         }
 
         // 获取执行机器

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -5,7 +5,6 @@
 import lombok.Data;
 import lombok.NoArgsConstructor;
 import org.hibernate.annotations.GenericGenerator;
-import org.hibernate.annotations.Type;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -37,7 +36,6 @@ public class InstanceInfoDO {
     // 任务实例参数
     @Lob
     @Column
-    @Type(type = TypeDefConstant.STRING_TYPE)
     private String instanceParams;
 
     // 该任务实例的类型，普通/工作流（InstanceType）
@@ -51,7 +49,6 @@ public class InstanceInfoDO {
     // 执行结果（允许存储稍大的结果）
     @Lob
     @Column
-    @Type(type = TypeDefConstant.STRING_TYPE)
     private String result;
     // 预计触发时间
     private Long expectedTriggerTime;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/JobInfoDO.java
Patch:
@@ -5,7 +5,6 @@
 import lombok.Data;
 import lombok.NoArgsConstructor;
 import org.hibernate.annotations.GenericGenerator;
-import org.hibernate.annotations.Type;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -53,7 +52,6 @@ public class JobInfoDO {
     // 执行器信息（可能需要存储整个脚本文件）
     @Lob
     @Column
-    @Type(type = TypeDefConstant.STRING_TYPE)
     private String processorInfo;
 
     /* ************************** 运行时配置 ************************** */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInfoDO.java
Patch:
@@ -4,7 +4,6 @@
 import lombok.Data;
 import lombok.NoArgsConstructor;
 import org.hibernate.annotations.GenericGenerator;
-import org.hibernate.annotations.Type;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -36,7 +35,6 @@ public class WorkflowInfoDO {
     // 工作流的DAG图信息（点线式DAG的json）
     @Lob
     @Column
-    @Type(type = TypeDefConstant.STRING_TYPE)
     private String peDAG;
 
     /* ************************** 定时参数 ************************** */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/DispatchService.java
Patch:
@@ -81,7 +81,7 @@ public void dispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTime
         if (maxInstanceNum > 0) {
 
             // 这个 runningInstanceCount 已经包含了本 instance
-            // 不统计 WAITING_DISPATCH 的状态：使用 OpenAPI 触发的延迟任务显然不应该统计进去（比如 delay 是 1 天）
+            // 不统计 WAITING_DISPATCH 的状态：使用 OpenAPI 触发的延迟任务不应该统计进去（比如 delay 是 1 天）
             long runningInstanceCount = instanceInfoRepository.countByJobIdAndStatusIn(jobId, Lists.newArrayList(WAITING_WORKER_RECEIVE.getV(), RUNNING.getV()));
             // 超出最大同时运行限制，不执行调度
             if (runningInstanceCount > maxInstanceNum) {

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -5,6 +5,7 @@
 import lombok.Data;
 import lombok.NoArgsConstructor;
 import org.hibernate.annotations.GenericGenerator;
+import org.hibernate.annotations.Type;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -36,6 +37,7 @@ public class InstanceInfoDO {
     // 任务实例参数
     @Lob
     @Column
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String instanceParams;
 
     // 该任务实例的类型，普通/工作流（InstanceType）
@@ -49,6 +51,7 @@ public class InstanceInfoDO {
     // 执行结果（允许存储稍大的结果）
     @Lob
     @Column
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String result;
     // 预计触发时间
     private Long expectedTriggerTime;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/JobInfoDO.java
Patch:
@@ -5,6 +5,7 @@
 import lombok.Data;
 import lombok.NoArgsConstructor;
 import org.hibernate.annotations.GenericGenerator;
+import org.hibernate.annotations.Type;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -52,6 +53,7 @@ public class JobInfoDO {
     // 执行器信息（可能需要存储整个脚本文件）
     @Lob
     @Column
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String processorInfo;
 
     /* ************************** 运行时配置 ************************** */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInfoDO.java
Patch:
@@ -4,6 +4,7 @@
 import lombok.Data;
 import lombok.NoArgsConstructor;
 import org.hibernate.annotations.GenericGenerator;
+import org.hibernate.annotations.Type;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -35,6 +36,7 @@ public class WorkflowInfoDO {
     // 工作流的DAG图信息（点线式DAG的json）
     @Lob
     @Column
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String peDAG;
 
     /* ************************** 定时参数 ************************** */

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/InstanceStatus.java
Patch:
@@ -24,8 +24,8 @@ public enum InstanceStatus {
     CANCELED(9, "取消"),
     STOPPED(10, "手动停止");
 
-    private int v;
-    private String des;
+    private final int v;
+    private final String des;
 
     // 广义的运行状态
     public static final List<Integer> generalizedRunningStatus = Lists.newArrayList(WAITING_DISPATCH.v, WAITING_WORKER_RECEIVE.v, RUNNING.v);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/DispatchService.java
Patch:
@@ -81,6 +81,7 @@ public void dispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTime
         if (maxInstanceNum > 0) {
 
             // 这个 runningInstanceCount 已经包含了本 instance
+            // 不统计 WAITING_DISPATCH 的状态：使用 OpenAPI 触发的延迟任务显然不应该统计进去（比如 delay 是 1 天）
             long runningInstanceCount = instanceInfoRepository.countByJobIdAndStatusIn(jobId, Lists.newArrayList(WAITING_WORKER_RECEIVE.getV(), RUNNING.getV()));
             // 超出最大同时运行限制，不执行调度
             if (runningInstanceCount > maxInstanceNum) {

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -37,7 +37,7 @@ public class InstanceInfoDO {
     // 任务实例参数
     @Lob
     @Column
-    @Type(type ="org.hibernate.type.StringType")
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String instanceParams;
 
     // 该任务实例的类型，普通/工作流（InstanceType）
@@ -51,7 +51,7 @@ public class InstanceInfoDO {
     // 执行结果（允许存储稍大的结果）
     @Lob
     @Column
-    @Type(type ="org.hibernate.type.StringType")
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String result;
     // 预计触发时间
     private Long expectedTriggerTime;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/JobInfoDO.java
Patch:
@@ -53,7 +53,7 @@ public class JobInfoDO {
     // 执行器信息（可能需要存储整个脚本文件）
     @Lob
     @Column
-    @Type(type ="org.hibernate.type.StringType")
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String processorInfo;
 
     /* ************************** 运行时配置 ************************** */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInfoDO.java
Patch:
@@ -36,7 +36,7 @@ public class WorkflowInfoDO {
     // 工作流的DAG图信息（点线式DAG的json）
     @Lob
     @Column
-    @Type(type ="org.hibernate.type.StringType")
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String peDAG;
 
     /* ************************** 定时参数 ************************** */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInstanceInfoDO.java
Patch:
@@ -40,16 +40,16 @@ public class WorkflowInstanceInfoDO {
     // 工作流启动参数
     @Lob
     @Column
-    @Type(type ="org.hibernate.type.StringType")
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String wfInitParams;
 
     @Lob
     @Column
-    @Type(type ="org.hibernate.type.StringType")
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String dag;
     @Lob
     @Column
-    @Type(type ="org.hibernate.type.StringType")
+    @Type(type = TypeDefConstant.STRING_TYPE)
     private String result;
 
     // 预计触发时间

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/processor/ProcessorTrackerPool.java
Patch:
@@ -40,7 +40,7 @@ public static ProcessorTracker getProcessorTracker(Long instanceId, String addre
         return processorTracker;
     }
 
-    public static List<ProcessorTracker> removeProcessorTracker(Long instanceId) {
+    public static synchronized List<ProcessorTracker> removeProcessorTracker(Long instanceId) {
 
         List<ProcessorTracker> res = Lists.newLinkedList();
         Map<String, ProcessorTracker> ttAddress2Pt = processorTrackerPool.remove(instanceId);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/timing/schedule/OmsScheduleService.java
Patch:
@@ -220,6 +220,9 @@ private void scheduleFrequentJob(List<Long> appIds) {
             try {
                 // 查询所有的秒级任务（只包含ID）
                 List<Long> jobIds = jobInfoRepository.findByAppIdInAndStatusAndTimeExpressionTypeIn(partAppIds, SwitchableStatus.ENABLE.getV(), TimeExpressionType.frequentTypes);
+                if (CollectionUtils.isEmpty(jobIds)) {
+                    return;
+                }
                 // 查询日志记录表中是否存在相关的任务
                 List<Long> runningJobIdList = instanceInfoRepository.findByJobIdInAndStatusIn(jobIds, InstanceStatus.generalizedRunningStatus);
                 Set<Long> runningJobIdSet = Sets.newHashSet(runningJobIdList);

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/SystemInstanceResult.java
Patch:
@@ -11,7 +11,7 @@ public class SystemInstanceResult {
     /* *********** 普通instance 专用 *********** */
 
     // 同时运行的任务实例数过多
-    public static final String TOO_MUCH_INSTANCE = "too much instance(%d>%d)";
+    public static final String TOO_MANY_INSTANCES = "too many instances(%d>%d)";
     // 无可用worker
     public static final String NO_WORKER_AVAILABLE = "no worker available";
     // 任务执行超时

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/DispatchService.java
Patch:
@@ -84,7 +84,7 @@ public void dispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTime
             long runningInstanceCount = instanceInfoRepository.countByJobIdAndStatusIn(jobId, Lists.newArrayList(WAITING_WORKER_RECEIVE.getV(), RUNNING.getV()));
             // 超出最大同时运行限制，不执行调度
             if (runningInstanceCount > maxInstanceNum) {
-                String result = String.format(SystemInstanceResult.TOO_MUCH_INSTANCE, runningInstanceCount, maxInstanceNum);
+                String result = String.format(SystemInstanceResult.TOO_MANY_INSTANCES, runningInstanceCount, maxInstanceNum);
                 log.warn("[Dispatcher-{}|{}] cancel dispatch job due to too much instance is running ({} > {}).", jobId, instanceId, runningInstanceCount, maxInstanceNum);
                 instanceInfoRepository.update4TriggerFailed(instanceId, FAILED.getV(), currentRunningTimes, current, current, RemoteConstant.EMPTY_ADDRESS, result, dbInstanceParams, now);
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/workflow/WorkflowInstanceManager.java
Patch:
@@ -131,7 +131,7 @@ public void start(WorkflowInfoDO wfInfo, Long wfInstanceId, String initParams) {
         // 并发度控制
         int instanceConcurrency = workflowInstanceInfoRepository.countByWorkflowIdAndStatusIn(wfInfo.getId(), WorkflowInstanceStatus.generalizedRunningStatus);
         if (instanceConcurrency > wfInfo.getMaxWfInstanceNum()) {
-            onWorkflowInstanceFailed(String.format(SystemInstanceResult.TOO_MUCH_INSTANCE, instanceConcurrency, wfInfo.getMaxWfInstanceNum()), wfInstanceInfo);
+            onWorkflowInstanceFailed(String.format(SystemInstanceResult.TOO_MANY_INSTANCES, instanceConcurrency, wfInfo.getMaxWfInstanceNum()), wfInstanceInfo);
             return;
         }
 

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/WorkflowInstanceStatus.java
Patch:
@@ -24,7 +24,8 @@ public enum WorkflowInstanceStatus {
 
     // 广义的运行状态
     public static final List<Integer> generalizedRunningStatus = Lists.newArrayList(WAITING.v, RUNNING.v);
-
+    // 结束状态
+    public static final List<Integer> finishedStatus = Lists.newArrayList(FAILED.v, SUCCEED.v, STOPPED.v);
 
     private int v;
     private String des;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/InstanceInfoRepository.java
Patch:
@@ -71,6 +71,6 @@ public interface InstanceInfoRepository extends JpaRepository<InstanceInfoDO, Lo
     // 结果只能用 int 接收
     @Modifying
     @Transactional
-    @Query(value = "delete from InstanceInfoDO where gmtModified < ?1")
-    int deleteAllByGmtModifiedBefore(Date time);
+    @Query(value = "delete from InstanceInfoDO where gmtModified < ?1 and status in ?2")
+    int deleteAllByGmtModifiedBeforeAndStatusIn(Date time, List<Integer> status);
 }

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/WorkflowInstanceInfoRepository.java
Patch:
@@ -24,8 +24,8 @@ public interface WorkflowInstanceInfoRepository extends JpaRepository<WorkflowIn
     // 结果只能用 int 接收
     @Modifying
     @Transactional
-    @Query(value = "delete from WorkflowInstanceInfoDO where gmtModified < ?1")
-    int deleteAllByGmtModifiedBefore(Date time);
+    @Query(value = "delete from WorkflowInstanceInfoDO where gmtModified < ?1 and status in ?2")
+    int deleteAllByGmtModifiedBeforeAndStatusIn(Date time, List<Integer> status);
 
     int countByWorkflowIdAndStatusIn(Long workflowId, List<Integer> status);
 

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/response/WorkflowInstanceInfoDTO.java
Patch:
@@ -27,6 +27,8 @@ public class WorkflowInstanceInfoDTO {
     private String dag;
     private String result;
 
+    // 预计触发时间
+    private Long expectedTriggerTime;
     // 实际触发时间
     private Long actualTriggerTime;
     // 结束时间

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInstanceInfoDO.java
Patch:
@@ -48,6 +48,8 @@ public class WorkflowInstanceInfoDO {
     @Column
     private String result;
 
+    // 预计触发时间
+    private Long expectedTriggerTime;
     // 实际触发时间
     private Long actualTriggerTime;
     // 结束时间

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/WorkflowInstanceInfoRepository.java
Patch:
@@ -30,5 +30,5 @@ public interface WorkflowInstanceInfoRepository extends JpaRepository<WorkflowIn
     int countByWorkflowIdAndStatusIn(Long workflowId, List<Integer> status);
 
     // 状态检查
-    List<WorkflowInstanceInfoDO> findByAppIdInAndStatusAndGmtModifiedBefore(List<Long> appIds, int status, Date before);
+    List<WorkflowInstanceInfoDO> findByAppIdInAndStatusAndExpectedTriggerTimeLessThan(List<Long> appIds, int status, long time);
 }

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/timing/InstanceStatusCheckService.java
Patch:
@@ -162,7 +162,7 @@ private void checkWorkflowInstance(List<Long> allAppIds) {
         // 重试长时间处于 WAITING 状态的工作流实例
         long threshold = System.currentTimeMillis() - WORKFLOW_WAITING_TIMEOUT_MS;
         Lists.partition(allAppIds, MAX_BATCH_NUM).forEach(partAppIds -> {
-            List<WorkflowInstanceInfoDO> waitingWfInstanceList = workflowInstanceInfoRepository.findByAppIdInAndStatusAndGmtModifiedBefore(partAppIds, WorkflowInstanceStatus.WAITING.getV(), new Date(threshold));
+            List<WorkflowInstanceInfoDO> waitingWfInstanceList = workflowInstanceInfoRepository.findByAppIdInAndStatusAndExpectedTriggerTimeLessThan(partAppIds, WorkflowInstanceStatus.WAITING.getV(), threshold);
             if (!CollectionUtils.isEmpty(waitingWfInstanceList)) {
 
                 List<Long> wfInstanceIds = waitingWfInstanceList.stream().map(WorkflowInstanceInfoDO::getWfInstanceId).collect(Collectors.toList());

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/timing/schedule/OmsScheduleService.java
Patch:
@@ -193,7 +193,7 @@ private void scheduleWorkflow(List<Long> appIds) {
             wfInfos.forEach(wfInfo -> {
 
                 // 1. 先生成调度记录，防止不调度的情况发生
-                Long wfInstanceId = workflowInstanceManager.create(wfInfo, null);
+                Long wfInstanceId = workflowInstanceManager.create(wfInfo, null, wfInfo.getNextTriggerTime());
 
                 // 2. 推入时间轮，准备调度执行
                 long delay = wfInfo.getNextTriggerTime() - System.currentTimeMillis();

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/workflow/WorkflowInstanceManager.java
Patch:
@@ -68,9 +68,10 @@ public class WorkflowInstanceManager {
      * 创建工作流任务实例
      * @param wfInfo 工作流任务元数据（描述信息）
      * @param initParams 启动参数
+     * @param expectTriggerTime 预计执行时间
      * @return wfInstanceId
      */
-    public Long create(WorkflowInfoDO wfInfo, String initParams) {
+    public Long create(WorkflowInfoDO wfInfo, String initParams, Long expectTriggerTime) {
 
         Long wfId = wfInfo.getId();
         Long wfInstanceId = idGenerateService.allocate();
@@ -82,6 +83,7 @@ public Long create(WorkflowInfoDO wfInfo, String initParams) {
         newWfInstance.setWfInstanceId(wfInstanceId);
         newWfInstance.setWorkflowId(wfId);
         newWfInstance.setStatus(WorkflowInstanceStatus.WAITING.getV());
+        newWfInstance.setExpectedTriggerTime(expectTriggerTime);
         newWfInstance.setActualTriggerTime(System.currentTimeMillis());
         newWfInstance.setWfInitParams(initParams);
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/workflow/WorkflowService.java
Patch:
@@ -168,7 +168,7 @@ public Long runWorkflow(Long wfId, Long appId, String initParams, long delay) {
 
     private Long realRunWorkflow(WorkflowInfoDO wfInfo, String initParams, long delay) {
         log.info("[WorkflowService-{}] try to run workflow, initParams={},delay={} ms.", wfInfo.getId(), initParams, delay);
-        Long wfInstanceId = workflowInstanceManager.create(wfInfo, initParams);
+        Long wfInstanceId = workflowInstanceManager.create(wfInfo, initParams, System.currentTimeMillis() + delay);
         if (delay <= 0) {
             workflowInstanceManager.start(wfInfo, wfInstanceId, initParams);
         }else {

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/response/WorkflowInstanceInfoVO.java
Patch:
@@ -32,6 +32,8 @@ public class WorkflowInstanceInfoVO {
     private PEWorkflowDAG pEWorkflowDAG;
     private String result;
 
+    // 预计触发时间
+    private String expectedTriggerTime;
     // 实际触发时间（需要格式化为人看得懂的时间）
     private String actualTriggerTime;
     // 结束时间（同理，需要格式化）
@@ -49,6 +51,7 @@ public static WorkflowInstanceInfoVO from(WorkflowInstanceInfoDO wfInstanceDO, S
         vo.setWorkflowId(String.valueOf(wfInstanceDO.getWorkflowId()));
 
         // 格式化时间
+        vo.setExpectedTriggerTime(DateFormatUtils.format(wfInstanceDO.getExpectedTriggerTime(), OmsConstant.TIME_PATTERN));
         vo.setActualTriggerTime(DateFormatUtils.format(wfInstanceDO.getActualTriggerTime(), OmsConstant.TIME_PATTERN));
         if (wfInstanceDO.getFinishedTime() == null) {
             vo.setFinishedTime(OmsConstant.NONE);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/request/ModifyAppInfoRequest.java
Patch:
@@ -15,6 +15,7 @@
 public class ModifyAppInfoRequest {
 
     private Long id;
+    private String oldPassword;
     private String appName;
     private String password;
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/common/utils/timewheel/HashedWheelTimer.java
Patch:
@@ -159,7 +159,7 @@ public boolean isCancelled() {
 
         @Override
         public boolean isDone() {
-            return startTime == FINISHED;
+            return status == FINISHED;
         }
     }
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/JobService.java
Patch:
@@ -120,7 +120,7 @@ public long runJob(Long jobId, String instanceParams, long delay) {
         }
 
         // 转发请求
-        log.info("[Job-{}] redirect run request to target server: {}", jobId, targetServer);
+        log.info("[Job-{}] redirect run request[params={}] to target server: {}", jobId, instanceParams, targetServer);
         RunJobOrWorkflowReq req = new RunJobOrWorkflowReq(RunJobOrWorkflowReq.JOB, jobId, delay, instanceParams, jobInfo.getAppId());
         try {
             return Long.parseLong(OhMyServer.askFriend(targetServer, req));
@@ -237,7 +237,7 @@ private void fillDefaultValue(JobInfoDO jobInfoDO) {
             jobInfoDO.setMaxInstanceNum(0);
         }
         if (jobInfoDO.getConcurrency() == null) {
-            jobInfoDO.setConcurrency(0);
+            jobInfoDO.setConcurrency(5);
         }
         if (jobInfoDO.getInstanceRetryNum() == null) {
             jobInfoDO.setInstanceRetryNum(0);

File: powerjob-client/src/main/java/com/github/kfcfans/powerjob/client/OhMyClient.java
Patch:
@@ -9,6 +9,7 @@
 import com.github.kfcfans.powerjob.common.response.*;
 import com.github.kfcfans.powerjob.common.utils.CommonUtils;
 import com.github.kfcfans.powerjob.common.utils.HttpUtils;
+import com.github.kfcfans.powerjob.common.utils.JsonUtils;
 import com.google.common.collect.Lists;
 import lombok.extern.slf4j.Slf4j;
 import okhttp3.FormBody;
@@ -283,7 +284,8 @@ public ResultDTO<InstanceInfoDTO> fetchInstanceInfo(Long instanceId) throws Powe
     public ResultDTO<Long> saveWorkflow(SaveWorkflowRequest request) throws PowerJobException {
         request.setAppId(appId);
         MediaType jsonType = MediaType.parse("application/json; charset=utf-8");
-        String json = JSONObject.toJSONString(request);
+        // 中坑记录：用 FastJSON 序列化会导致 Server 接收时 pEWorkflowDAG 为 null，无语.jpg
+        String json = JsonUtils.toJSONStringUnsafe(request);
         String post = postHA(OpenAPIConstant.SAVE_WORKFLOW, RequestBody.create(jsonType, json));
         return JSONObject.parseObject(post, LONG_RESULT_TYPE);
     }

File: powerjob-client/src/test/java/TestWorkflow.java
Patch:
@@ -64,6 +64,7 @@ public void testSaveWorkflow() throws Exception {
         req.setEnable(true);
         req.setTimeExpressionType(TimeExpressionType.API);
 
+        System.out.println("req ->" + JSONObject.toJSON(req));
         System.out.println(ohMyClient.saveWorkflow(req));
     }
 

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/RemoteConstant.java
Patch:
@@ -33,5 +33,5 @@ public class RemoteConstant {
 
     /* ************************ OTHERS ************************ */
     public static final String EMPTY_ADDRESS = "N/A";
-    public static final long DEFAULT_TIMEOUT_MS = 3000;
+    public static final long DEFAULT_TIMEOUT_MS = 5000;
 }

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/request/http/SaveWorkflowRequest.java
Patch:
@@ -6,6 +6,7 @@
 import com.google.common.collect.Lists;
 import lombok.Data;
 
+import java.io.Serializable;
 import java.util.List;
 
 /**
@@ -15,7 +16,7 @@
  * @since 2020/5/26
  */
 @Data
-public class SaveWorkflowRequest {
+public class SaveWorkflowRequest implements Serializable {
 
     private Long id;
 

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/response/AskResponse.java
Patch:
@@ -53,7 +53,7 @@ public <T> T getData(Class<T> clz) throws Exception {
         return JsonUtils.parseObject(data, clz);
     }
 
-    public String getDataAsString() {
+    public String parseDataAsString() {
         return new String(data, StandardCharsets.UTF_8);
     }
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/akka/OhMyServer.java
Patch:
@@ -97,16 +97,16 @@ public static ActorSelection getWorkerActor(String address) {
     }
 
     /**
-     * ASK 其他 powejob-server，要求 AskResponse 中的 Data 为 String
-     * @param address 其他 powejob-server 的地址（ip:port）
+     * ASK 其他 powerjob-server，要求 AskResponse 中的 Data 为 String
+     * @param address 其他 powerjob-server 的地址（ip:port）
      * @param request 请求
      * @return 返回值 OR 异常
      */
     public static String askFriend(String address, Object request) throws Exception {
         CompletionStage<Object> askCS = Patterns.ask(getFriendActor(address), request, Duration.ofMillis(RemoteConstant.DEFAULT_TIMEOUT_MS));
         AskResponse askResponse = (AskResponse) askCS.toCompletableFuture().get();
         if (askResponse.isSuccess()) {
-            return askResponse.getDataAsString();
+            return askResponse.parseDataAsString();
         }
         throw new PowerJobException("remote server process failed:" + askResponse.getMessage());
     }

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/JobService.java
Patch:
@@ -142,7 +142,7 @@ private long realRunJob(JobInfoDO jobInfo, String instanceParams, long delay) {
                 dispatchService.dispatch(jobInfo, instanceId, 0, instanceParams, null);
             });
         }
-        log.info("[Job-{}] run job successfully, params= {}, instanceId={}", jobInfo.getId(), instanceParams, instanceId);
+        log.info("[Job-{}] run job successfully, params={}, instanceId={}", jobInfo.getId(), instanceParams, instanceId);
         return instanceId;
     }
 

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/processor/ProcessorTracker.java
Patch:
@@ -323,7 +323,7 @@ private void initProcessor() throws Exception {
 
         if (processor == null) {
             log.warn("[ProcessorTracker-{}] fetch Processor(type={},info={}) failed.", instanceId, processorType, processorInfo);
-            throw new PowerJobException("fetch Processor failed");
+            throw new PowerJobException("fetch Processor failed, please check your processorType and processorInfo config");
         }
     }
 

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/CommonTaskTracker.java
Patch:
@@ -236,8 +236,8 @@ private void innerRun() {
                 try {
                     AskResponse askResponse = (AskResponse) askCS.toCompletableFuture().get(RemoteConstant.DEFAULT_TIMEOUT_MS, TimeUnit.MILLISECONDS);
                     serverAccepted = askResponse.isSuccess();
-                }catch (Exception ignore) {
-                    log.warn("[TaskTracker-{}] report finished status failed, result={}.", instanceId, result);
+                }catch (Exception e) {
+                    log.warn("[TaskTracker-{}] report finished status failed, result={}.", instanceId, result, e);
                 }
 
                 // 服务器未接受上报，则等待下次重新上报

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/processor/ProcessorTracker.java
Patch:
@@ -63,7 +63,7 @@ public class ProcessorTracker {
     private ThreadPoolExecutor threadPool;
     private ScheduledExecutorService timingPool;
 
-    private static final int THREAD_POOL_QUEUE_MAX_SIZE = 100;
+    private static final int THREAD_POOL_QUEUE_MAX_SIZE = 128;
     // 长时间空闲的 ProcessorTracker 会发起销毁请求
     private static final long MAX_IDLE_TIME = 300000;
 

File: powerjob-worker-samples/src/main/java/com/github/kfcfans/powerjob/samples/processors/BroadcastProcessorDemo.java
Patch:
@@ -36,6 +36,7 @@ public ProcessResult preProcess(TaskContext context) throws Exception {
     public ProcessResult process(TaskContext taskContext) throws Exception {
         System.out.println("===== BroadcastProcessorDemo#process ======");
         taskContext.getOmsLogger().info("BroadcastProcessorDemo#process, current host: {}", NetUtils.getLocalHost());
+        Thread.sleep(45 * 1000);
         return new ProcessResult(true);
     }
 

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/actors/TaskTrackerActor.java
Patch:
@@ -65,7 +65,7 @@ private void onReceiveProcessorReportTaskStatusReq(ProcessorReportTaskStatusReq
             taskTracker.broadcast(taskStatus == TaskStatus.WORKER_PROCESS_SUCCESS.getValue(), req.getSubInstanceId(), req.getTaskId(), req.getResult());
         }
 
-        taskTracker.updateTaskStatus(req.getTaskId(), taskStatus, req.getReportTime(), req.getResult());
+        taskTracker.updateTaskStatus(req.getSubInstanceId(), req.getTaskId(), taskStatus, req.getReportTime(), req.getResult());
     }
 
     /**

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -138,12 +138,13 @@ public static TaskTracker create(ServerScheduleJobReq req) {
     /**
      * 更新Task状态
      * V1.0.0 -> V1.0.1（e405e283ad7f97b0b4e5d369c7de884c0caf9192） 锁方案变更，从 synchronized (taskId.intern()) 修改为分段锁，能大大减少内存占用，损失的只有理论并发度而已
+     * @param subInstanceId 子任务实例ID
      * @param taskId task的ID（task为任务实例的执行单位）
      * @param newStatus task的新状态
      * @param reportTime 上报时间
      * @param result task的执行结果，未执行完成时为空
      */
-    public void updateTaskStatus(String taskId, int newStatus, long reportTime, @Nullable String result) {
+    public void updateTaskStatus(Long subInstanceId, String taskId, int newStatus, long reportTime, @Nullable String result) {
 
         if (finished.get()) {
             return;
@@ -278,7 +279,7 @@ public void receiveProcessorTrackerHeartbeat(ProcessorTrackerStatusReportReq hea
             List<TaskDO> unfinishedTask = TaskPersistenceService.INSTANCE.getAllUnFinishedTaskByAddress(instanceId, idlePtAddress);
             if (!CollectionUtils.isEmpty(unfinishedTask)) {
                 log.warn("[TaskTracker-{}] ProcessorTracker({}) is idle now but have unfinished tasks: {}", instanceId, idlePtAddress, unfinishedTask);
-                unfinishedTask.forEach(task -> updateTaskStatus(task.getTaskId(), TaskStatus.WORKER_PROCESS_FAILED.getValue(), System.currentTimeMillis(), "SYSTEM: unreceived process result"));
+                unfinishedTask.forEach(task -> updateTaskStatus(task.getSubInstanceId(), task.getTaskId(), TaskStatus.WORKER_PROCESS_FAILED.getValue(), System.currentTimeMillis(), "SYSTEM: unreceived process result"));
             }
         }
     }

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/common/utils/SystemInfoUtils.java
Patch:
@@ -21,6 +21,8 @@ public class SystemInfoUtils {
         NF.setMaximumFractionDigits(4);
         NF.setMinimumFractionDigits(4);
         NF.setRoundingMode(RoundingMode.HALF_UP);
+        // 不按照千分位输出
+        NF.setGroupingUsed(false);
     }
 
     // JMX bean can be accessed externally and is meant for management tools like hyperic ( or even nagios ) - It would delegate to Runtime anyway.

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/common/utils/SystemInfoUtils.java
Patch:
@@ -21,6 +21,8 @@ public class SystemInfoUtils {
         NF.setMaximumFractionDigits(4);
         NF.setMinimumFractionDigits(4);
         NF.setRoundingMode(RoundingMode.HALF_UP);
+        // 不按照千分位输出
+        NF.setGroupingUsed(false);
     }
 
     // JMX bean can be accessed externally and is meant for management tools like hyperic ( or even nagios ) - It would delegate to Runtime anyway.

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/model/SystemMetrics.java
Patch:
@@ -34,7 +34,8 @@ public class SystemMetrics implements OmsSerializable, Comparable<SystemMetrics>
 
     @Override
     public int compareTo(SystemMetrics that) {
-        return this.calculateScore() - that.calculateScore();
+        // 降序排列
+        return that.calculateScore() - this.calculateScore();
     }
 
     /**

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/model/SystemMetrics.java
Patch:
@@ -56,7 +56,8 @@ public int calculateScore() {
             cpuScore = 1;
         }
 
-        return (int) (memScore + cpuScore);
+        score = (int) (memScore + cpuScore);
+        return score;
     }
 
     /**

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/akka/OhMyServer.java
Patch:
@@ -7,6 +7,7 @@
 import com.github.kfcfans.powerjob.server.akka.actors.FriendActor;
 import com.github.kfcfans.powerjob.server.akka.actors.ServerActor;
 import com.github.kfcfans.powerjob.server.akka.actors.ServerTroubleshootingActor;
+import com.github.kfcfans.powerjob.server.common.PowerJobServerConfigKey;
 import com.github.kfcfans.powerjob.server.common.utils.PropertyUtils;
 import com.google.common.base.Stopwatch;
 import com.google.common.collect.Maps;
@@ -44,7 +45,7 @@ public static void init() {
         // 解析配置文件
         PropertyUtils.init();
         Properties properties = PropertyUtils.getProperties();
-        int port = Integer.parseInt(properties.getProperty("oms.akka.port", "10086"));
+        int port = Integer.parseInt(properties.getProperty(PowerJobServerConfigKey.AKKA_PORT, "10086"));
 
         // 启动 ActorSystem
         Map<String, Object> overrideConfig = Maps.newHashMap();

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/config/PowerJobPhysicalNamingStrategy.java
Patch:
@@ -1,5 +1,6 @@
 package com.github.kfcfans.powerjob.server.persistence.config;
 
+import com.github.kfcfans.powerjob.server.common.PowerJobServerConfigKey;
 import com.github.kfcfans.powerjob.server.common.utils.PropertyUtils;
 import org.hibernate.boot.model.naming.Identifier;
 import org.hibernate.engine.jdbc.env.spi.JdbcEnvironment;
@@ -34,7 +35,7 @@ public class PowerJobPhysicalNamingStrategy extends SpringPhysicalNamingStrategy
     @Override
     public Identifier toPhysicalTableName(Identifier name, JdbcEnvironment jdbcEnvironment) {
 
-        String tablePrefix = PropertyUtils.getProperties().getProperty("oms.table-prefix");
+        String tablePrefix = PropertyUtils.getProperties().getProperty(PowerJobServerConfigKey.TABLE_PREFIX);
 
         String text = name.getText();
         String noDOText = StringUtils.endsWithIgnoreCase(text, "do") ? text.substring(0, text.length() - 2) : text;

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/common/OmsWorkerVersion.java
Patch:
@@ -28,10 +28,9 @@ public final class OmsWorkerVersion {
      * @see Package#getImplementationVersion()
      */
     public static String getVersion() {
-        if (StringUtils.isNotEmpty(CACHE)) {
-            return CACHE;
+        if (StringUtils.isEmpty(CACHE)) {
+            CACHE = determineSpringBootVersion();
         }
-        CACHE = determineSpringBootVersion();
         return CACHE;
     }
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/AppInfoDO.java
Patch:
@@ -1,6 +1,7 @@
 package com.github.kfcfans.powerjob.server.persistence.core.model;
 
 import lombok.Data;
+import org.hibernate.annotations.GenericGenerator;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -17,7 +18,8 @@
 public class AppInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.AUTO)
+    @GeneratedValue(strategy = GenerationType.AUTO, generator = "native")
+    @GenericGenerator(name = "native", strategy = "native")
     private Long id;
 
     private String appName;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/ContainerInfoDO.java
Patch:
@@ -1,6 +1,7 @@
 package com.github.kfcfans.powerjob.server.persistence.core.model;
 
 import lombok.Data;
+import org.hibernate.annotations.GenericGenerator;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -17,7 +18,8 @@
 public class ContainerInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.AUTO)
+    @GeneratedValue(strategy = GenerationType.AUTO, generator = "native")
+    @GenericGenerator(name = "native", strategy = "native")
     private Long id;
 
     // 所属的应用ID

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -4,6 +4,7 @@
 import lombok.AllArgsConstructor;
 import lombok.Data;
 import lombok.NoArgsConstructor;
+import org.hibernate.annotations.GenericGenerator;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -22,7 +23,8 @@
 public class InstanceInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.AUTO)
+    @GeneratedValue(strategy = GenerationType.AUTO, generator = "native")
+    @GenericGenerator(name = "native", strategy = "native")
     private Long id;
 
     // 任务ID

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/JobInfoDO.java
Patch:
@@ -4,6 +4,7 @@
 import lombok.AllArgsConstructor;
 import lombok.Data;
 import lombok.NoArgsConstructor;
+import org.hibernate.annotations.GenericGenerator;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -23,7 +24,8 @@ public class JobInfoDO {
 
 
     @Id
-    @GeneratedValue(strategy = GenerationType.AUTO)
+    @GeneratedValue(strategy = GenerationType.AUTO, generator = "native")
+    @GenericGenerator(name = "native", strategy = "native")
     private Long id;
 
     /* ************************** 任务基本信息 ************************** */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/OmsLockDO.java
Patch:
@@ -2,6 +2,7 @@
 
 import lombok.Data;
 import lombok.NoArgsConstructor;
+import org.hibernate.annotations.GenericGenerator;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -19,7 +20,8 @@
 public class OmsLockDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.AUTO)
+    @GeneratedValue(strategy = GenerationType.AUTO, generator = "native")
+    @GenericGenerator(name = "native", strategy = "native")
     private Long id;
 
     private String lockName;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/ServerInfoDO.java
Patch:
@@ -2,6 +2,7 @@
 
 import lombok.Data;
 import lombok.NoArgsConstructor;
+import org.hibernate.annotations.GenericGenerator;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -19,7 +20,8 @@
 public class ServerInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.AUTO)
+    @GeneratedValue(strategy = GenerationType.AUTO, generator = "native")
+    @GenericGenerator(name = "native", strategy = "native")
     private Long id;
 
     /**

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/UserInfoDO.java
Patch:
@@ -1,6 +1,7 @@
 package com.github.kfcfans.powerjob.server.persistence.core.model;
 
 import lombok.Data;
+import org.hibernate.annotations.GenericGenerator;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -17,7 +18,8 @@
 public class UserInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.AUTO)
+    @GeneratedValue(strategy = GenerationType.AUTO, generator = "native")
+    @GenericGenerator(name = "native", strategy = "native")
     private Long id;
 
     private String username;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInfoDO.java
Patch:
@@ -3,6 +3,7 @@
 import lombok.AllArgsConstructor;
 import lombok.Data;
 import lombok.NoArgsConstructor;
+import org.hibernate.annotations.GenericGenerator;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -21,7 +22,8 @@
 public class WorkflowInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.AUTO)
+    @GeneratedValue(strategy = GenerationType.AUTO, generator = "native")
+    @GenericGenerator(name = "native", strategy = "native")
     private Long id;
 
     private String wfName;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInstanceInfoDO.java
Patch:
@@ -3,6 +3,7 @@
 import lombok.AllArgsConstructor;
 import lombok.Data;
 import lombok.NoArgsConstructor;
+import org.hibernate.annotations.GenericGenerator;
 
 import javax.persistence.*;
 import java.util.Date;
@@ -21,7 +22,8 @@
 public class WorkflowInstanceInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.AUTO)
+    @GeneratedValue(strategy = GenerationType.AUTO, generator = "native")
+    @GenericGenerator(name = "native", strategy = "native")
     private Long id;
     // 任务所属应用的ID，冗余提高查询效率
     private Long appId;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/AppInfoDO.java
Patch:
@@ -17,7 +17,7 @@
 public class AppInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     private String appName;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/ContainerInfoDO.java
Patch:
@@ -17,7 +17,7 @@
 public class ContainerInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     // 所属的应用ID

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -22,7 +22,7 @@
 public class InstanceInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     // 任务ID
@@ -33,7 +33,7 @@ public class InstanceInfoDO {
     private Long instanceId;
     // 任务实例参数
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String instanceParams;
 
     // 该任务实例的类型，普通/工作流（InstanceType）
@@ -46,7 +46,7 @@ public class InstanceInfoDO {
     private Integer status;
     // 执行结果（允许存储稍大的结果）
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String result;
     // 预计触发时间
     private Long expectedTriggerTime;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/JobInfoDO.java
Patch:
@@ -23,7 +23,7 @@ public class JobInfoDO {
 
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     /* ************************** 任务基本信息 ************************** */
@@ -49,7 +49,7 @@ public class JobInfoDO {
     private Integer processorType;
     // 执行器信息（可能需要存储整个脚本文件）
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String processorInfo;
 
     /* ************************** 运行时配置 ************************** */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/OmsLockDO.java
Patch:
@@ -19,7 +19,7 @@
 public class OmsLockDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     private String lockName;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/ServerInfoDO.java
Patch:
@@ -19,7 +19,7 @@
 public class ServerInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     /**

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/UserInfoDO.java
Patch:
@@ -17,7 +17,7 @@
 public class UserInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     private String username;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInfoDO.java
Patch:
@@ -21,7 +21,7 @@
 public class WorkflowInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     private String wfName;
@@ -32,7 +32,7 @@ public class WorkflowInfoDO {
 
     // 工作流的DAG图信息（点线式DAG的json）
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String peDAG;
 
     /* ************************** 定时参数 ************************** */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInstanceInfoDO.java
Patch:
@@ -21,7 +21,7 @@
 public class WorkflowInstanceInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
     // 任务所属应用的ID，冗余提高查询效率
     private Long appId;
@@ -35,10 +35,10 @@ public class WorkflowInstanceInfoDO {
     private Integer status;
 
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String dag;
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String result;
 
     // 实际触发时间

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/AppInfoDO.java
Patch:
@@ -17,7 +17,7 @@
 public class AppInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     private String appName;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/ContainerInfoDO.java
Patch:
@@ -17,7 +17,7 @@
 public class ContainerInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     // 所属的应用ID

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -22,7 +22,7 @@
 public class InstanceInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     // 任务ID
@@ -33,7 +33,7 @@ public class InstanceInfoDO {
     private Long instanceId;
     // 任务实例参数
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String instanceParams;
 
     // 该任务实例的类型，普通/工作流（InstanceType）
@@ -46,7 +46,7 @@ public class InstanceInfoDO {
     private Integer status;
     // 执行结果（允许存储稍大的结果）
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String result;
     // 预计触发时间
     private Long expectedTriggerTime;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/JobInfoDO.java
Patch:
@@ -23,7 +23,7 @@ public class JobInfoDO {
 
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     /* ************************** 任务基本信息 ************************** */
@@ -49,7 +49,7 @@ public class JobInfoDO {
     private Integer processorType;
     // 执行器信息（可能需要存储整个脚本文件）
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String processorInfo;
 
     /* ************************** 运行时配置 ************************** */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/OmsLockDO.java
Patch:
@@ -19,7 +19,7 @@
 public class OmsLockDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     private String lockName;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/ServerInfoDO.java
Patch:
@@ -19,7 +19,7 @@
 public class ServerInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     /**

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/UserInfoDO.java
Patch:
@@ -17,7 +17,7 @@
 public class UserInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     private String username;

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInfoDO.java
Patch:
@@ -21,7 +21,7 @@
 public class WorkflowInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
 
     private String wfName;
@@ -32,7 +32,7 @@ public class WorkflowInfoDO {
 
     // 工作流的DAG图信息（点线式DAG的json）
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String peDAG;
 
     /* ************************** 定时参数 ************************** */

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInstanceInfoDO.java
Patch:
@@ -21,7 +21,7 @@
 public class WorkflowInstanceInfoDO {
 
     @Id
-    @GeneratedValue(strategy = GenerationType.IDENTITY)
+    @GeneratedValue(strategy = GenerationType.AUTO)
     private Long id;
     // 任务所属应用的ID，冗余提高查询效率
     private Long appId;
@@ -35,10 +35,10 @@ public class WorkflowInstanceInfoDO {
     private Integer status;
 
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String dag;
     @Lob
-    @Column(columnDefinition="TEXT")
+    @Column
     private String result;
 
     // 实际触发时间

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -176,7 +176,7 @@ public void updateTaskStatus(String taskId, int newStatus, long reportTime, @Nul
             // 过滤过期的请求（潜在的集群时间一致性需求，重试跨Worker时，时间不一致可能导致问题）
             if (lastReportTime > reportTime) {
                 log.warn("[TaskTracker-{}] receive expired(last {} > current {}) task status report(taskId={},newStatus={}), TaskTracker will drop this report.",
-                        lastReportTime, reportTime, instanceId, taskId, newStatus);
+                        instanceId, lastReportTime, reportTime, taskId, newStatus);
                 return;
             }
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/DispatchService.java
Patch:
@@ -68,9 +68,8 @@ public void dispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTime
 
         // 检查当前任务是否被取消
         InstanceInfoDO instanceInfo = instanceInfoRepository.findByInstanceId(instanceId);
-        InstanceStatus currentStatus = InstanceStatus.of(instanceInfo.getStatus());
-        if (currentStatus != WAITING_DISPATCH) {
-            log.info("[Dispatcher-{}|{}] cancel dispatch job due to instance status({}) is not WAITING_DISPATCH", jobId, instanceId, currentStatus.name());
+        if (instanceInfo.getStatus() == CANCELED.getV()) {
+            log.info("[Dispatcher-{}|{}] cancel dispatch due to instance has been canceled", jobId, instanceId);
             return;
         }
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/timing/InstanceStatusCheckService.java
Patch:
@@ -115,7 +115,7 @@ private void checkInstance(List<Long> allAppIds) {
             threshold = System.currentTimeMillis() - RECEIVE_TIMEOUT_MS;
             List<InstanceInfoDO> waitingWorkerReceiveInstances = instanceInfoRepository.findByAppIdInAndStatusAndActualTriggerTimeLessThan(partAppIds, InstanceStatus.WAITING_WORKER_RECEIVE.getV(), threshold);
             if (!CollectionUtils.isEmpty(waitingWorkerReceiveInstances)) {
-                log.warn("[InstanceStatusChecker] instances({}) did n’t receive any reply from worker.", waitingWorkerReceiveInstances);
+                log.warn("[InstanceStatusChecker] instances({}) didn't receive any reply from worker.", waitingWorkerReceiveInstances);
                 waitingWorkerReceiveInstances.forEach(instance -> {
                     // 重新派发
                     JobInfoDO jobInfoDO = jobInfoRepository.findById(instance.getJobId()).orElseGet(JobInfoDO::new);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/common/utils/timewheel/HashedWheelTimer.java
Patch:
@@ -184,7 +184,6 @@ public void expireTimerTasks(long currentTick) {
                         log.warn("[HashedWheelTimer] timerFuture.totalTicks < currentTick, please fix the bug");
                     }
 
-                    timerFuture.status = HashedWheelTimerFuture.RUNNING;
                     try {
                         // 提交执行
                         runTask(timerFuture);
@@ -202,6 +201,7 @@ public void expireTimerTasks(long currentTick) {
     }
 
     private void runTask(HashedWheelTimerFuture timerFuture) {
+        timerFuture.status = HashedWheelTimerFuture.RUNNING;
         if (taskProcessPool == null) {
             timerFuture.timerTask.run();
         }else {

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/persistence/TaskDO.java
Patch:
@@ -68,13 +68,16 @@ public String getUpdateSQL() {
     public String toString() {
         return "{" +
                 "taskId='" + taskId + '\'' +
+                ", instanceId=" + instanceId +
+                ", subInstanceId=" + subInstanceId +
                 ", taskName='" + taskName + '\'' +
                 ", address='" + address + '\'' +
                 ", status=" + status +
                 ", result='" + result + '\'' +
                 ", failedCnt=" + failedCnt +
                 ", createdTime=" + createdTime +
                 ", lastModifiedTime=" + lastModifiedTime +
+                ", lastReportTime=" + lastReportTime +
                 '}';
     }
 }

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/InstanceStatus.java
Patch:
@@ -21,6 +21,7 @@ public enum InstanceStatus {
     RUNNING(3, "运行中"),
     FAILED(4, "失败"),
     SUCCEED(5, "成功"),
+    CANCELED(9, "取消"),
     STOPPED(10, "手动停止");
 
     private int v;
@@ -29,7 +30,7 @@ public enum InstanceStatus {
     // 广义的运行状态
     public static final List<Integer> generalizedRunningStatus = Lists.newArrayList(WAITING_DISPATCH.v, WAITING_WORKER_RECEIVE.v, RUNNING.v);
     // 结束状态
-    public static final List<Integer> finishedStatus = Lists.newArrayList(FAILED.v, SUCCEED.v, STOPPED.v);
+    public static final List<Integer> finishedStatus = Lists.newArrayList(FAILED.v, SUCCEED.v, CANCELED.v, STOPPED.v);
 
     public static InstanceStatus of(int v) {
         for (InstanceStatus is : values()) {

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/OpenAPIConstant.java
Patch:
@@ -22,6 +22,7 @@ public class OpenAPIConstant {
 
     /* ************* Instance 区 ************* */
     public static final String STOP_INSTANCE = "/stopInstance";
+    public static final String CANCEL_INSTANCE = "/cancelInstance";
     public static final String FETCH_INSTANCE_STATUS = "/fetchInstanceStatus";
     public static final String FETCH_INSTANCE_INFO = "/fetchInstanceInfo";
 

File: powerjob-common/src/main/java/com/github/kfcfans/powerjob/common/SystemInstanceResult.java
Patch:
@@ -30,6 +30,7 @@ public class SystemInstanceResult {
 
     // 被用户手动停止
     public static final String STOPPED_BY_USER = "stopped by user";
+    public static final String CANCELED_BY_USER = "canceled by user";
 
 
 }

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/common/utils/timewheel/HashedWheelTimer.java
Patch:
@@ -30,7 +30,7 @@ public class HashedWheelTimer implements Timer {
 
     private final Indicator indicator;
 
-    private long startTime;
+    private final long startTime;
 
     private final Queue<HashedWheelTimerFuture> waitingTasks = Queues.newLinkedBlockingQueue();
     private final Queue<HashedWheelTimerFuture> canceledTasks = Queues.newLinkedBlockingQueue();

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/instance/InstanceManager.java
Patch:
@@ -107,7 +107,7 @@ public void updateStatus(TaskTrackerReportInstanceStatusReq req) throws Exceptio
                 log.info("[InstanceManager-{}] instance execute failed but will take the {}th retry.", instanceId, instanceInfo.getRunningTimes());
 
                 // 延迟10S重试（由于重试不改变 instanceId，如果派发到同一台机器，上一个 TaskTracker 还处于资源释放阶段，无法创建新的TaskTracker，任务失败）
-                HashedWheelTimerHolder.TIMER.schedule(() -> {
+                HashedWheelTimerHolder.INACCURATE_TIMER.schedule(() -> {
                     dispatchService.redispatch(jobInfo, instanceId, instanceInfo.getRunningTimes());
                 }, 10, TimeUnit.SECONDS);
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/timing/schedule/HashedWheelTimerHolder.java
Patch:
@@ -10,9 +10,6 @@
  */
 public class HashedWheelTimerHolder {
 
-    // 精确时间轮，每 1S 走一格
-    public static final HashedWheelTimer TIMER = new HashedWheelTimer(1, 4096, Runtime.getRuntime().availableProcessors() * 4);
-
     // 非精确时间轮，每 5S 走一格
     public static final HashedWheelTimer INACCURATE_TIMER = new HashedWheelTimer(5, 16, 0);
 

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/processor/built/ScriptProcessor.java
Patch:
@@ -96,7 +96,9 @@ public ProcessResult process(TaskContext context) throws Exception {
             }
             String result = String.format("[INPUT]: %s;[ERROR]: %s", inputSB.toString(), errorSB.toString());
 
-            return new ProcessResult(true, result);
+            // 0 代表正常退出
+            int exitValue = process.exitValue();
+            return new ProcessResult(exitValue == 0, result);
         }catch (InterruptedException ie) {
             omsLogger.info("SYSTEM===> ScriptProcessor has been interrupted");
             return new ProcessResult(false, "Interrupted");

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/AppInfoDO.java
Patch:
@@ -13,7 +13,7 @@
  */
 @Data
 @Entity
-@Table(name = "app_info", uniqueConstraints = {@UniqueConstraint(name = "appNameUK", columnNames = {"appName"})})
+@Table(uniqueConstraints = {@UniqueConstraint(name = "appNameUK", columnNames = {"appName"})})
 public class AppInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/ContainerInfoDO.java
Patch:
@@ -13,7 +13,7 @@
  */
 @Data
 @Entity
-@Table(name = "container_info", indexes = {@Index(columnList = "appId")})
+@Table(indexes = {@Index(columnList = "appId")})
 public class ContainerInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -18,7 +18,7 @@
 @Entity
 @NoArgsConstructor
 @AllArgsConstructor
-@Table(name = "instance_info", indexes = {@Index(columnList = "jobId"), @Index(columnList = "appId"), @Index(columnList = "instanceId")})
+@Table(indexes = {@Index(columnList = "jobId"), @Index(columnList = "appId"), @Index(columnList = "instanceId")})
 public class InstanceInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/JobInfoDO.java
Patch:
@@ -18,7 +18,7 @@
 @Entity
 @NoArgsConstructor
 @AllArgsConstructor
-@Table(name = "job_info", indexes = {@Index(columnList = "appId")})
+@Table(indexes = {@Index(columnList = "appId")})
 public class JobInfoDO {
 
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/OmsLockDO.java
Patch:
@@ -15,7 +15,7 @@
 @Data
 @Entity
 @NoArgsConstructor
-@Table(name = "oms_lock", uniqueConstraints = {@UniqueConstraint(name = "lockNameUK", columnNames = {"lockName"})})
+@Table(uniqueConstraints = {@UniqueConstraint(name = "lockNameUK", columnNames = {"lockName"})})
 public class OmsLockDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/ServerInfoDO.java
Patch:
@@ -15,7 +15,7 @@
 @Data
 @Entity
 @NoArgsConstructor
-@Table(name = "server_info", uniqueConstraints = {@UniqueConstraint(columnNames = "ip")})
+@Table(uniqueConstraints = {@UniqueConstraint(columnNames = "ip")})
 public class ServerInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/UserInfoDO.java
Patch:
@@ -13,7 +13,7 @@
  */
 @Data
 @Entity
-@Table(name = "user_info")
+@Table
 public class UserInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInfoDO.java
Patch:
@@ -17,7 +17,7 @@
 @Entity
 @NoArgsConstructor
 @AllArgsConstructor
-@Table(name = "workflow_info", indexes = {@Index(columnList = "appId")})
+@Table(indexes = {@Index(columnList = "appId")})
 public class WorkflowInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInstanceInfoDO.java
Patch:
@@ -17,7 +17,7 @@
 @Entity
 @NoArgsConstructor
 @AllArgsConstructor
-@Table(name = "workflow_instance_info")
+@Table
 public class WorkflowInstanceInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/JobInfoRepository.java
Patch:
@@ -20,7 +20,7 @@ public interface JobInfoRepository extends JpaRepository<JobInfoDO, Long> {
     // 调度专用
     List<JobInfoDO> findByAppIdInAndStatusAndTimeExpressionTypeAndNextTriggerTimeLessThanEqual(List<Long> appIds, int status, int timeExpressionType, long time);
 
-    @Query(value = "select id from job_info where app_id in ?1 and status = ?2 and time_expression_type in ?3", nativeQuery = true)
+    @Query(value = "select id from JobInfoDO where appId in ?1 and status = ?2 and timeExpressionType in ?3")
     List<Long> findByAppIdInAndStatusAndTimeExpressionTypeIn(List<Long> appIds, int status, List<Integer> timeTypes);
 
     Page<JobInfoDO> findByAppIdAndStatusNot(Long appId, int status, Pageable pageable);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/OmsLockRepository.java
Patch:
@@ -17,7 +17,7 @@ public interface OmsLockRepository extends JpaRepository<OmsLockDO, Long> {
 
     @Modifying
     @Transactional
-    @Query(value = "delete from oms_lock where lock_name = ?1", nativeQuery = true)
+    @Query(value = "delete from OmsLockDO where lockName = ?1")
     int deleteByLockName(String lockName);
 
     OmsLockDO findByLockName(String lockName);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/WorkflowInstanceInfoRepository.java
Patch:
@@ -24,7 +24,7 @@ public interface WorkflowInstanceInfoRepository extends JpaRepository<WorkflowIn
     // 结果只能用 int 接收
     @Modifying
     @Transactional
-    @Query(value = "delete from workflow_instance_info where gmt_modified < ?1", nativeQuery = true)
+    @Query(value = "delete from WorkflowInstanceInfoDO where gmtModified < ?1")
     int deleteAllByGmtModifiedBefore(Date time);
 
     int countByWorkflowIdAndStatusIn(Long workflowId, List<Integer> status);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/AppInfoDO.java
Patch:
@@ -13,7 +13,7 @@
  */
 @Data
 @Entity
-@Table(name = "app_info", uniqueConstraints = {@UniqueConstraint(name = "appNameUK", columnNames = {"appName"})})
+@Table(uniqueConstraints = {@UniqueConstraint(name = "appNameUK", columnNames = {"appName"})})
 public class AppInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/ContainerInfoDO.java
Patch:
@@ -13,7 +13,7 @@
  */
 @Data
 @Entity
-@Table(name = "container_info", indexes = {@Index(columnList = "appId")})
+@Table(indexes = {@Index(columnList = "appId")})
 public class ContainerInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -18,7 +18,7 @@
 @Entity
 @NoArgsConstructor
 @AllArgsConstructor
-@Table(name = "instance_info", indexes = {@Index(columnList = "jobId"), @Index(columnList = "appId"), @Index(columnList = "instanceId")})
+@Table(indexes = {@Index(columnList = "jobId"), @Index(columnList = "appId"), @Index(columnList = "instanceId")})
 public class InstanceInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/JobInfoDO.java
Patch:
@@ -18,7 +18,7 @@
 @Entity
 @NoArgsConstructor
 @AllArgsConstructor
-@Table(name = "job_info", indexes = {@Index(columnList = "appId")})
+@Table(indexes = {@Index(columnList = "appId")})
 public class JobInfoDO {
 
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/OmsLockDO.java
Patch:
@@ -15,7 +15,7 @@
 @Data
 @Entity
 @NoArgsConstructor
-@Table(name = "oms_lock", uniqueConstraints = {@UniqueConstraint(name = "lockNameUK", columnNames = {"lockName"})})
+@Table(uniqueConstraints = {@UniqueConstraint(name = "lockNameUK", columnNames = {"lockName"})})
 public class OmsLockDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/ServerInfoDO.java
Patch:
@@ -15,7 +15,7 @@
 @Data
 @Entity
 @NoArgsConstructor
-@Table(name = "server_info", uniqueConstraints = {@UniqueConstraint(columnNames = "ip")})
+@Table(uniqueConstraints = {@UniqueConstraint(columnNames = "ip")})
 public class ServerInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/UserInfoDO.java
Patch:
@@ -13,7 +13,7 @@
  */
 @Data
 @Entity
-@Table(name = "user_info")
+@Table
 public class UserInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInfoDO.java
Patch:
@@ -17,7 +17,7 @@
 @Entity
 @NoArgsConstructor
 @AllArgsConstructor
-@Table(name = "workflow_info", indexes = {@Index(columnList = "appId")})
+@Table(indexes = {@Index(columnList = "appId")})
 public class WorkflowInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/WorkflowInstanceInfoDO.java
Patch:
@@ -17,7 +17,7 @@
 @Entity
 @NoArgsConstructor
 @AllArgsConstructor
-@Table(name = "workflow_instance_info")
+@Table
 public class WorkflowInstanceInfoDO {
 
     @Id

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/JobInfoRepository.java
Patch:
@@ -20,7 +20,7 @@ public interface JobInfoRepository extends JpaRepository<JobInfoDO, Long> {
     // 调度专用
     List<JobInfoDO> findByAppIdInAndStatusAndTimeExpressionTypeAndNextTriggerTimeLessThanEqual(List<Long> appIds, int status, int timeExpressionType, long time);
 
-    @Query(value = "select id from job_info where app_id in ?1 and status = ?2 and time_expression_type in ?3", nativeQuery = true)
+    @Query(value = "select id from JobInfoDO where appId in ?1 and status = ?2 and timeExpressionType in ?3")
     List<Long> findByAppIdInAndStatusAndTimeExpressionTypeIn(List<Long> appIds, int status, List<Integer> timeTypes);
 
     Page<JobInfoDO> findByAppIdAndStatusNot(Long appId, int status, Pageable pageable);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/OmsLockRepository.java
Patch:
@@ -17,7 +17,7 @@ public interface OmsLockRepository extends JpaRepository<OmsLockDO, Long> {
 
     @Modifying
     @Transactional
-    @Query(value = "delete from oms_lock where lock_name = ?1", nativeQuery = true)
+    @Query(value = "delete from OmsLockDO where lockName = ?1")
     int deleteByLockName(String lockName);
 
     OmsLockDO findByLockName(String lockName);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/WorkflowInstanceInfoRepository.java
Patch:
@@ -24,7 +24,7 @@ public interface WorkflowInstanceInfoRepository extends JpaRepository<WorkflowIn
     // 结果只能用 int 接收
     @Modifying
     @Transactional
-    @Query(value = "delete from workflow_instance_info where gmt_modified < ?1", nativeQuery = true)
+    @Query(value = "delete from WorkflowInstanceInfoDO where gmtModified < ?1")
     int deleteAllByGmtModifiedBefore(Date time);
 
     int countByWorkflowIdAndStatusIn(Long workflowId, List<Integer> status);

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/instance/InstanceService.java
Patch:
@@ -194,7 +194,7 @@ public InstanceDetail getInstanceDetail(Long instanceId) {
             }
 
         }catch (Exception e) {
-            log.error("[Instance-{}] ask InstanceStatus from TaskTracker failed, exception is {}", instanceId, e.toString());
+            log.warn("[Instance-{}] ask InstanceStatus from TaskTracker failed, exception is {}", instanceId, e.toString());
         }
 
         // 失败则返回基础版信息

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/controller/InstanceController.java
Patch:
@@ -1,7 +1,6 @@
 package com.github.kfcfans.powerjob.server.web.controller;
 
 import com.github.kfcfans.powerjob.common.InstanceStatus;
-import com.github.kfcfans.powerjob.common.model.InstanceDetail;
 import com.github.kfcfans.powerjob.common.response.ResultDTO;
 import com.github.kfcfans.powerjob.server.akka.OhMyServer;
 import com.github.kfcfans.powerjob.server.common.utils.OmsFileUtils;
@@ -15,6 +14,7 @@
 import com.github.kfcfans.powerjob.server.service.InstanceLogService;
 import com.github.kfcfans.powerjob.server.service.instance.InstanceService;
 import com.github.kfcfans.powerjob.server.web.request.QueryInstanceRequest;
+import com.github.kfcfans.powerjob.server.web.response.InstanceDetailVO;
 import com.github.kfcfans.powerjob.server.web.response.InstanceInfoVO;
 import org.springframework.beans.BeanUtils;
 import org.springframework.beans.factory.annotation.Value;
@@ -65,8 +65,8 @@ public ResultDTO<Void> stopInstance(Long instanceId) {
     }
 
     @GetMapping("/detail")
-    public ResultDTO<InstanceDetail> getInstanceDetail(String instanceId) {
-        return ResultDTO.success(instanceService.getInstanceDetail(Long.valueOf(instanceId)));
+    public ResultDTO<InstanceDetailVO> getInstanceDetail(String instanceId) {
+        return ResultDTO.success(InstanceDetailVO.from(instanceService.getInstanceDetail(Long.valueOf(instanceId))));
     }
 
     @GetMapping("/log")

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/common/config/SwaggerConfig.java
Patch:
@@ -24,11 +24,11 @@ public class SwaggerConfig {
     public Docket createRestApi() {
         // apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中
         ApiInfo apiInfo = new ApiInfoBuilder()
-                .title("OhMyScheduler")
+                .title("PowerJob")
                 .description("Distributed scheduling and computing framework.")
                 .license("Apache Licence 2")
-                .termsOfServiceUrl("https://github.com/KFCFans/OhMyScheduler")
-                .version("2.0.0")
+                .termsOfServiceUrl("https://github.com/KFCFans/PowerJob")
+                .version("3.1.3")
                 .build();
 
         return new Docket(DocumentationType.SWAGGER_2)

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/JobInfoRepository.java
Patch:
@@ -30,6 +30,6 @@ public interface JobInfoRepository extends JpaRepository<JobInfoDO, Long> {
     // 校验工作流包含的任务
     long countByAppIdAndStatusAndIdIn(Long appId, int status, List<Long> jobIds);
 
-    long countByAppId(long appId);
+    long countByAppIdAndStatusNot(long appId, int status);
 
 }

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/instance/InstanceManager.java
Patch:
@@ -143,7 +143,7 @@ public void processFinishedInstance(Long instanceId, Long wfInstanceId, Instance
         log.info("[Instance-{}] process finished, final status is {}.", instanceId, status.name());
 
         // 上报日志数据
-        instanceLogService.sync(instanceId);
+        HashedWheelTimerHolder.INACCURATE_TIMER.schedule(() -> instanceLogService.sync(instanceId), 15, TimeUnit.SECONDS);
 
         // workflow 特殊处理
         if (wfInstanceId != null) {

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/controller/SystemInfoController.java
Patch:
@@ -11,6 +11,7 @@
 import com.github.kfcfans.powerjob.common.utils.JsonUtils;
 import com.github.kfcfans.powerjob.server.akka.OhMyServer;
 import com.github.kfcfans.powerjob.server.akka.requests.FriendQueryWorkerClusterStatusReq;
+import com.github.kfcfans.powerjob.server.common.constans.SwitchableStatus;
 import com.github.kfcfans.powerjob.server.persistence.core.model.AppInfoDO;
 import com.github.kfcfans.powerjob.server.persistence.core.repository.AppInfoRepository;
 import com.github.kfcfans.powerjob.server.persistence.core.repository.InstanceInfoRepository;
@@ -98,7 +99,7 @@ public ResultDTO<SystemOverviewVO> getSystemOverview(Long appId) {
         SystemOverviewVO overview = new SystemOverviewVO();
 
         // 总任务数量
-        overview.setJobCount(jobInfoRepository.countByAppId(appId));
+        overview.setJobCount(jobInfoRepository.countByAppIdAndStatusNot(appId, SwitchableStatus.DELETED.getV()));
         // 运行任务数
         overview.setRunningInstanceCount(instanceInfoRepository.countByAppIdAndStatus(appId, InstanceStatus.RUNNING.getV()));
         // 近期失败任务数（24H内）

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/common/config/SwaggerConfig.java
Patch:
@@ -24,11 +24,11 @@ public class SwaggerConfig {
     public Docket createRestApi() {
         // apiInfo()用来创建该Api的基本信息（这些基本信息会展现在文档页面中
         ApiInfo apiInfo = new ApiInfoBuilder()
-                .title("OhMyScheduler")
+                .title("PowerJob")
                 .description("Distributed scheduling and computing framework.")
                 .license("Apache Licence 2")
-                .termsOfServiceUrl("https://github.com/KFCFans/OhMyScheduler")
-                .version("2.0.0")
+                .termsOfServiceUrl("https://github.com/KFCFans/PowerJob")
+                .version("3.1.3")
                 .build();
 
         return new Docket(DocumentationType.SWAGGER_2)

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/common/config/ThreadPoolConfig.java
Patch:
@@ -14,6 +14,7 @@
  * 公用线程池配置
  * omsTimingPool：用于执行定时任务的线程池
  * omsCommonPool：用于执行普通任务的线程池
+ * omsCommonPool：用于执行后台任务的线程池，这类任务对时间不敏感，慢慢执行细水长流即可
  * taskScheduler：用于定时调度的线程池
  *
  * @author tjq

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/JobInfoRepository.java
Patch:
@@ -30,6 +30,6 @@ public interface JobInfoRepository extends JpaRepository<JobInfoDO, Long> {
     // 校验工作流包含的任务
     long countByAppIdAndStatusAndIdIn(Long appId, int status, List<Long> jobIds);
 
-    long countByAppId(long appId);
+    long countByAppIdAndStatusNot(long appId, int status);
 
 }

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/controller/SystemInfoController.java
Patch:
@@ -11,6 +11,7 @@
 import com.github.kfcfans.powerjob.common.utils.JsonUtils;
 import com.github.kfcfans.powerjob.server.akka.OhMyServer;
 import com.github.kfcfans.powerjob.server.akka.requests.FriendQueryWorkerClusterStatusReq;
+import com.github.kfcfans.powerjob.server.common.constans.SwitchableStatus;
 import com.github.kfcfans.powerjob.server.persistence.core.model.AppInfoDO;
 import com.github.kfcfans.powerjob.server.persistence.core.repository.AppInfoRepository;
 import com.github.kfcfans.powerjob.server.persistence.core.repository.InstanceInfoRepository;
@@ -98,7 +99,7 @@ public ResultDTO<SystemOverviewVO> getSystemOverview(Long appId) {
         SystemOverviewVO overview = new SystemOverviewVO();
 
         // 总任务数量
-        overview.setJobCount(jobInfoRepository.countByAppId(appId));
+        overview.setJobCount(jobInfoRepository.countByAppIdAndStatusNot(appId, SwitchableStatus.DELETED.getV()));
         // 运行任务数
         overview.setRunningInstanceCount(instanceInfoRepository.countByAppIdAndStatus(appId, InstanceStatus.RUNNING.getV()));
         // 近期失败任务数（24H内）

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/instance/InstanceManager.java
Patch:
@@ -143,7 +143,7 @@ public void processFinishedInstance(Long instanceId, Long wfInstanceId, Instance
         log.info("[Instance-{}] process finished, final status is {}.", instanceId, status.name());
 
         // 上报日志数据
-        instanceLogService.sync(instanceId);
+        HashedWheelTimerHolder.INACCURATE_TIMER.schedule(() -> instanceLogService.sync(instanceId), 15, TimeUnit.SECONDS);
 
         // workflow 特殊处理
         if (wfInstanceId != null) {

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/actors/ProcessorTrackerActor.java
Patch:
@@ -59,9 +59,7 @@ private void onReceiveTaskTrackerStopInstanceReq(TaskTrackerStopInstanceReq req)
 
         Long instanceId = req.getInstanceId();
         List<ProcessorTracker> removedPts = ProcessorTrackerPool.removeProcessorTracker(instanceId);
-        if (CollectionUtils.isEmpty(removedPts)) {
-            log.warn("[ProcessorTrackerActor] ProcessorTracker for instance(instanceId={}) already destroyed.", instanceId);
-        }else {
+        if (!CollectionUtils.isEmpty(removedPts)) {
             removedPts.forEach(ProcessorTracker::destroy);
         }
     }

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/processor/ProcessorTracker.java
Patch:
@@ -65,7 +65,7 @@ public class ProcessorTracker {
 
     private static final int THREAD_POOL_QUEUE_MAX_SIZE = 100;
     // 长时间空闲的 ProcessorTracker 会发起销毁请求
-    private static final long MAX_IDLE_TIME = 120000;
+    private static final long MAX_IDLE_TIME = 300000;
 
     // 当 ProcessorTracker 出现根本性错误（比如 Processor 创建失败，所有的任务直接失败）
     private boolean lethal = false;
@@ -179,7 +179,7 @@ public void destroy() {
         statusReportRetryQueue.clear();
         ProcessorTrackerPool.removeProcessorTracker(instanceId);
 
-        log.info("[ProcessorTracker-{}] ProcessorTracker already destroyed!", instanceId);
+        log.info("[ProcessorTracker-{}] ProcessorTracker destroyed successfully!", instanceId);
 
         // 3. 关闭定时线程池
         CommonUtils.executeIgnoreException(() -> timingPool.shutdownNow());

File: powerjob-client/src/main/java/com/github/kfcfans/powerjob/client/OhMyClient.java
Patch:
@@ -66,9 +66,11 @@ public OhMyClient(List<String> addressList, String appName, String password) {
                         appId = Long.parseLong(resultDTO.getData().toString());
                         currentAddress = addr;
                         break;
+                    }else {
+                        throw new OmsException(resultDTO.getMessage());
                     }
                 }
-            }catch (Exception ignore) {
+            }catch (IOException ignore) {
             }
         }
 

File: powerjob-client/src/test/java/TestClient.java
Patch:
@@ -21,7 +21,7 @@ public class TestClient {
 
     @BeforeAll
     public static void initClient() throws Exception {
-        ohMyClient = new OhMyClient("127.0.0.1:7700", "oms-test2", null);
+        ohMyClient = new OhMyClient("127.0.0.1:7700", "powerjob-agent-test", "123");
     }
 
     @Test
@@ -70,7 +70,7 @@ public void testDeleteJob() throws Exception {
 
     @Test
     public void testRunJob() throws Exception {
-        System.out.println(ohMyClient.runJob(8L, "this is instanceParams", 20));
+        System.out.println(ohMyClient.runJob(6L, "this is instanceParams", 60000));
     }
 
     @Test

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/controller/SystemInfoController.java
Patch:
@@ -59,7 +59,7 @@ public ResultDTO<List<WorkerStatusVO>> listWorker(Long appId) {
         }
         String server =appInfoOpt.get().getCurrentServer();
 
-        // 没有Server
+        // 没有 Server，说明从来没有该 appId 的 worker 集群连接过
         if (StringUtils.isEmpty(server)) {
             return ResultDTO.success(Collections.emptyList());
         }

File: powerjob-worker-samples/src/main/java/com/github/kfcfans/powerjob/samples/OhMySchedulerConfig.java
Patch:
@@ -31,7 +31,7 @@ public OhMyWorker initOMS() throws Exception {
         // 1. 创建配置文件
         OhMyConfig config = new OhMyConfig();
         config.setPort(port);
-        config.setAppName("powerjob");
+        config.setAppName("powerjob-agent-test");
         config.setServerAddress(serverAddress);
         // 如果没有大型 Map/MapReduce 的需求，建议使用内存来加速计算
         // 为了本地模拟多个实例，只能使用 MEMORY 启动（文件只能由一个应用占有）

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/container/OmsJarContainer.java
Patch:
@@ -190,7 +190,7 @@ public void tryRelease() {
         // 需要满足的条件：引用计数器减为0 & 有更新的容器出现
         if (referenceCount.decrementAndGet() <= 0) {
 
-            OmsContainer container = OmsContainerFactory.getContainer(containerId);
+            OmsContainer container = OmsContainerFactory.fetchContainer(containerId, false);
             if (container != this) {
                 try {
                     destroy();

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/processor/ProcessorTracker.java
Patch:
@@ -309,9 +309,11 @@ private void initProcessor() throws Exception {
                 String[] split = processorInfo.split("#");
                 log.info("[ProcessorTracker-{}] try to load processor({}) in container({})", instanceId, split[1], split[0]);
 
-                omsContainer = OmsContainerFactory.getContainer(Long.valueOf(split[0]));
+                omsContainer = OmsContainerFactory.fetchContainer(Long.valueOf(split[0]), true);
                 if (omsContainer != null) {
                     processor = omsContainer.getProcessor(split[1]);
+                }else {
+                    log.warn("[ProcessorTracker-{}] load container failed.", instanceId);
                 }
                 break;
             default:

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/common/utils/LRUCache.java
Patch:
@@ -19,7 +19,7 @@ public class LRUCache<K, V> {
     public LRUCache(int cacheSize) {
         innerCache = CacheBuilder.newBuilder()
                 .concurrencyLevel(2)
-                .initialCapacity(cacheSize)
+                .maximumSize(cacheSize)
                 .build();
     }
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/timing/CleanService.java
Patch:
@@ -60,7 +60,6 @@ public void timingClean() {
 
         // 释放本地缓存
         WorkerManagerService.releaseContainerInfos();
-        InstanceManager.releaseCache();
 
         // 删除数据库运行记录
         cleanInstanceLog();

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/repository/InstanceInfoRepository.java
Patch:
@@ -68,7 +68,7 @@ public interface InstanceInfoRepository extends JpaRepository<InstanceInfoDO, Lo
     List<Long> findByJobIdInAndStatusIn(List<Long> jobIds, List<Integer> status);
 
     // 删除历史数据，JPA自带的删除居然是根据ID循环删，2000条数据删了几秒，也太拉垮了吧...
-    // 结果只能用 int 接受
+    // 结果只能用 int 接收
     @Modifying
     @Transactional
     @Query(value = "delete from instance_info where gmt_modified < ?1", nativeQuery = true)

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/common/OhMyConfig.java
Patch:
@@ -3,8 +3,10 @@
 import com.github.kfcfans.powerjob.common.RemoteConstant;
 import com.github.kfcfans.powerjob.worker.common.constants.StoreStrategy;
 import com.github.kfcfans.powerjob.worker.core.processor.ProcessResult;
+import com.google.common.collect.Lists;
 import lombok.Data;
 
+import java.util.Collections;
 import java.util.List;
 
 /**
@@ -26,7 +28,7 @@ public class OhMyConfig {
     /**
      * 调度服务器地址，ip:port 或 域名
      */
-    private List<String> serverAddress;
+    private List<String> serverAddress = Lists.newArrayList();
     /**
      * 本地持久化方式，默认使用磁盘
      */

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/persistence/ConnectionFactory.java
Patch:
@@ -33,7 +33,8 @@ private static DataSource getDataSource() {
         synchronized (ConnectionFactory.class) {
             if (dataSource == null) {
 
-                StoreStrategy strategy = OhMyWorker.getConfig().getStoreStrategy();
+                // 兼容单元测试，否则没办法单独测试 DAO 层了
+                StoreStrategy strategy = OhMyWorker.getConfig() == null ? StoreStrategy.DISK : OhMyWorker.getConfig().getStoreStrategy();
 
                 HikariConfig config = new HikariConfig();
                 config.setDriverClassName("org.h2.Driver");

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/persistence/TaskDO.java
Patch:
@@ -66,9 +66,8 @@ public String getUpdateSQL() {
 
     @Override
     public String toString() {
-        return "TaskDO{" +
+        return "{" +
                 "taskId='" + taskId + '\'' +
-                ", instanceId='" + instanceId + '\'' +
                 ", taskName='" + taskName + '\'' +
                 ", address='" + address + '\'' +
                 ", status=" + status +

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/web/WebLogAspect.java
Patch:
@@ -36,7 +36,7 @@ public class WebLogAspect {
      * 第三个*：所有的方法
      * 最后的两个点：所有类型的参数
      */
-    @Pointcut("execution(public * com.github.kfcfans.oms.server.web.controller..*.*(..))")
+    @Pointcut("execution(public * com.github.kfcfans.powerjob.server.web.controller..*.*(..))")
     public void include() {
     }
 

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/executor/ProcessorRunnable.java
Patch:
@@ -156,6 +156,9 @@ public void innerRun() throws InterruptedException {
 
     /**
      * 上报状态给 TaskTracker
+     * @param status Task状态
+     * @param result 执行结果，只有结束时才存在
+     * @param cmd 特殊需求，比如广播执行需要创建广播任务
      */
     private void reportStatus(TaskStatus status, String result, Integer cmd) {
         ProcessorReportTaskStatusReq req = new ProcessorReportTaskStatusReq();

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/processor/sdk/MapProcessor.java
Patch:
@@ -23,7 +23,6 @@
 public abstract class MapProcessor implements BasicProcessor {
 
     private static final int RECOMMEND_BATCH_SIZE = 200;
-    private static final int REQUEST_TIMEOUT_MS = 5000;
 
     /**
      * 分发子任务

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -54,6 +54,8 @@ public class InstanceInfoDO {
     private Long actualTriggerTime;
     // 结束时间
     private Long finishedTime;
+    // 最后上报时间
+    private Long lastReportTime;
     // TaskTracker地址
     private String taskTrackerAddress;
 

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/timing/CleanService.java
Patch:
@@ -60,7 +60,7 @@ public void timingClean() {
 
         // 释放本地缓存
         WorkerManagerService.releaseContainerInfos();
-        InstanceManager.releaseInstanceInfos();
+        InstanceManager.releaseCache();
 
         // 删除数据库运行记录
         cleanInstanceLog();

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/timing/InstanceStatusCheckService.java
Patch:
@@ -44,6 +44,8 @@ public class InstanceStatusCheckService {
     @Resource
     private DispatchService dispatchService;
     @Resource
+    private InstanceManager instanceManager;
+    @Resource
     private WorkflowInstanceManager workflowInstanceManager;
 
     @Resource
@@ -190,6 +192,6 @@ private void updateFailedInstance(InstanceInfoDO instance) {
         instance.setResult(SystemInstanceResult.REPORT_TIMEOUT);
         instanceInfoRepository.saveAndFlush(instance);
 
-        InstanceManager.processFinishedInstance(instance.getInstanceId(), instance.getWfInstanceId(), InstanceStatus.FAILED, "timeout, maybe TaskTracker down!");
+        instanceManager.processFinishedInstance(instance.getInstanceId(), instance.getWfInstanceId(), InstanceStatus.FAILED, "timeout, maybe TaskTracker down!");
     }
 }

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/container/OmsJarContainer.java
Patch:
@@ -133,7 +133,7 @@ public void init() throws Exception {
             Thread.currentThread().setContextClassLoader(oldCL);
         }
 
-        log.info("[OmsJarContainer] init container(name={},jarPath={}) successfully", containerId, localJarFile.getPath());
+        log.info("[OmsJarContainer-{}] init container(name={},jarPath={}) successfully", containerId, name, localJarFile.getPath());
     }
 
     @Override

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/processor/ProcessorTracker.java
Patch:
@@ -86,7 +86,7 @@ public ProcessorTracker(TaskTrackerStartTaskReq request) {
             initProcessor();
 
             log.info("[ProcessorTracker-{}] ProcessorTracker was successfully created!", instanceId);
-        }catch (Exception e) {
+        }catch (Throwable e) {
             log.warn("[ProcessorTracker-{}] create ProcessorTracker failed, all tasks submitted here will fail.", instanceId, e);
             lethal = true;
             lethalReason = e.toString();
@@ -263,6 +263,8 @@ private void initProcessor() throws Exception {
                 break;
             case JAVA_CONTAINER:
                 String[] split = processorInfo.split("#");
+                log.info("[ProcessorRunnable-{}] try to load processor({}) in container({})", instanceId, split[1], split[0]);
+
                 omsContainer = OmsContainerFactory.getContainer(Long.valueOf(split[0]));
                 if (omsContainer != null) {
                     processor = omsContainer.getProcessor(split[1]);

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -162,7 +162,6 @@ public void updateTaskStatus(String taskId, int newStatus, long reportTime, @Nul
 
             // 此时本次请求已经有效，先写入最新的时间
             taskId2LastReportTime.put(taskId, reportTime);
-            log.debug("[TaskTracker-{}] task({}) receive new status: {}", instanceId, taskId, newStatus);
 
             // 处理失败的情况
             int configTaskRetryNum = instanceInfo.getTaskRetryNum();

File: powerjob-server/src/main/java/com/github/kfcfans/powerjob/server/service/timing/InstanceStatusCheckService.java
Patch:
@@ -139,7 +139,7 @@ private void checkInstance(List<Long> allAppIds) {
                     }
 
                     // CRON 和 API一样，失败次数 + 1，根据重试配置进行重试
-                    if (instance.getRunningTimes() > jobInfoDO.getInstanceRetryNum()) {
+                    if (instance.getRunningTimes() < jobInfoDO.getInstanceRetryNum()) {
                         dispatchService.redispatch(jobInfoDO, instance.getInstanceId(), instance.getRunningTimes());
                     }else {
                         updateFailedInstance(instance);

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -162,6 +162,7 @@ public void updateTaskStatus(String taskId, int newStatus, long reportTime, @Nul
 
             // 此时本次请求已经有效，先写入最新的时间
             taskId2LastReportTime.put(taskId, reportTime);
+            log.debug("[TaskTracker-{}] task({}) receive new status: {}", instanceId, taskId, newStatus);
 
             // 处理失败的情况
             int configTaskRetryNum = instanceInfo.getTaskRetryNum();

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/CommonTaskTracker.java
Patch:
@@ -47,7 +47,9 @@ protected CommonTaskTracker(ServerScheduleJobReq req) {
     @Override
     protected void initTaskTracker(ServerScheduleJobReq req) {
 
-        ThreadFactory factory = new ThreadFactoryBuilder().setNameFormat("oms-TaskTrackerTimingPool-%d").build();
+        // CommonTaskTrackerTimingPool 缩写
+        String poolName = String.format("ctttp-%d", req.getInstanceId()) + "-%d";
+        ThreadFactory factory = new ThreadFactoryBuilder().setNameFormat(poolName).build();
         this.scheduledPool = Executors.newScheduledThreadPool(2, factory);
 
         // 持久化根任务

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/tracker/task/FrequentTaskTracker.java
Patch:
@@ -82,7 +82,8 @@ protected void initTaskTracker(ServerScheduleJobReq req) {
         subInstanceId2TimeHolder = Maps.newConcurrentMap();
 
         // 1. 初始化定时调度线程池
-        ThreadFactory factory = new ThreadFactoryBuilder().setNameFormat("oms-TaskTrackerTimingPool-%d").build();
+        String poolName = String.format("ftttp-%d", req.getInstanceId()) + "-%d";
+        ThreadFactory factory = new ThreadFactoryBuilder().setNameFormat(poolName).build();
         this.scheduledPool = Executors.newScheduledThreadPool(3, factory);
 
         // 2. 启动任务发射器

File: powerjob-client/src/test/java/TestClient.java
Patch:
@@ -49,7 +49,7 @@ public void testSaveJob() throws Exception {
 
     @Test
     public void testFetchJob() throws Exception {
-        ResultDTO<JobInfoDTO> fetchJob = ohMyClient.fetchJob(7L);
+        ResultDTO<JobInfoDTO> fetchJob = ohMyClient.fetchJob(1L);
         System.out.println(JsonUtils.toJSONStringUnsafe(fetchJob));
     }
 

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/core/processor/sdk/BroadcastProcessor.java
Patch:
@@ -36,6 +36,6 @@ public static ProcessResult defaultResult(List<TaskResult> taskResults) {
                 failed ++;
             }
         }
-        return new ProcessResult(succeed == 0, String.format("succeed:%d, failed:%d", succeed, failed));
+        return new ProcessResult(failed == 0, String.format("succeed:%d, failed:%d", succeed, failed));
     }
 }

File: powerjob-worker/src/main/java/com/github/kfcfans/powerjob/worker/persistence/ConnectionFactory.java
Patch:
@@ -19,8 +19,8 @@ public class ConnectionFactory {
 
     private static volatile DataSource dataSource;
 
-    private static final String DISK_JDBC_URL = "jdbc:h2:file:~/oms/h2/oms_worker_db";
-    private static final String MEMORY_JDBC_URL = "jdbc:h2:mem:~/oms/h2/oms_worker_db";
+    private static final String DISK_JDBC_URL = "jdbc:h2:file:~/powerjob/h2/oms_worker_db";
+    private static final String MEMORY_JDBC_URL = "jdbc:h2:mem:~/powerjob/h2/oms_worker_db";
 
     public static Connection getConnection() throws SQLException {
         return getDataSource().getConnection();

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/ContainerService.java
Patch:
@@ -442,6 +442,7 @@ private void downloadJarFromGridFS(String mongoFileName, File targetFile) {
                 return;
             }
             try {
+                FileUtils.forceMkdirParent(targetFile);
                 gridFsManager.download(targetFile, GridFsManager.CONTAINER_BUCKET, mongoFileName);
             }catch (Exception e) {
                 CommonUtils.executeIgnoreException(() -> FileUtils.forceDelete(targetFile));

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/oms/common/SystemInstanceResult.java
Patch:
@@ -25,6 +25,8 @@ public class SystemInstanceResult {
 
     /* *********** workflow 专用 *********** */
     public static final String MIDDLE_JOB_FAILED = "middle job failed";
+    public static final String MIDDLE_JOB_STOPPED = "middle job stopped by user";
+    public static final String CAN_NOT_FIND_JOB = "can't find some job";
 
     // 被用户手动停止
     public static final String STOPPED_BY_USER = "stopped by user";

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/oms/common/model/PEWorkflowDAG.java
Patch:
@@ -1,5 +1,7 @@
 package com.github.kfcfans.oms.common.model;
 
+import com.fasterxml.jackson.databind.annotation.JsonSerialize;
+import com.fasterxml.jackson.databind.ser.std.ToStringSerializer;
 import com.google.common.collect.Lists;
 import lombok.AllArgsConstructor;
 import lombok.Data;
@@ -33,6 +35,7 @@ public static class Node {
         private String jobName;
 
         // 运行时参数，图定义不需要
+        @JsonSerialize(using= ToStringSerializer.class)
         private Long instanceId;
         private Integer status;
         private String result;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/persistence/core/repository/JobInfoRepository.java
Patch:
@@ -27,6 +27,8 @@ public interface JobInfoRepository extends JpaRepository<JobInfoDO, Long> {
 
     Page<JobInfoDO> findByAppIdAndJobNameLikeAndStatusNot(Long appId, String condition, int status, Pageable pageable);
 
+    // 校验工作流包含的任务
+    long countByAppIdAndStatusAndIdIn(Long appId, int status, List<Long> jobIds);
 
     long countByAppId(long appId);
 

File: oh-my-scheduler-worker-samples/src/main/java/com/github/kfcfans/oms/samples/processors/MapReduceProcessorDemo.java
Patch:
@@ -76,7 +76,7 @@ public ProcessResult process(TaskContext context) throws Exception {
 
     @Override
     public ProcessResult reduce(TaskContext context, List<TaskResult> taskResults) {
-        log.info("================ MapReduceProcessorDemo#postProcess ================");
+        log.info("================ MapReduceProcessorDemo#reduce ================");
         log.info("TaskContext: {}", JSONObject.toJSONString(context));
         log.info("List<TaskResult>: {}", JSONObject.toJSONString(taskResults));
         context.getOmsLogger().info("MapReduce job finished, result is {}.", taskResults);

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/JobService.java
Patch:
@@ -61,7 +61,6 @@ public Long saveJob(SaveJobInfoRequest request) throws Exception {
         BeanUtils.copyProperties(request, jobInfoDO);
 
         // 拷贝枚举值
-
         jobInfoDO.setExecuteType(request.getExecuteType().getV());
         jobInfoDO.setProcessorType(request.getProcessorType().getV());
         jobInfoDO.setTimeExpressionType(request.getTimeExpressionType().getV());
@@ -182,6 +181,8 @@ private void refreshJob(JobInfoDO jobInfoDO) throws Exception {
             CronExpression cronExpression = new CronExpression(jobInfoDO.getTimeExpression());
             Date nextValidTime = cronExpression.getNextValidTimeAfter(now);
             jobInfoDO.setNextTriggerTime(nextValidTime.getTime());
+        }else if (timeExpressionType == TimeExpressionType.API || timeExpressionType == TimeExpressionType.WORKFLOW) {
+            jobInfoDO.setTimeExpression(null);
         }
         // 重写最后修改时间
         jobInfoDO.setGmtModified(now);

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/workflow/WorkflowService.java
Patch:
@@ -67,6 +67,8 @@ public Long saveWorkflow(SaveWorkflowRequest req) throws Exception {
             CronExpression cronExpression = new CronExpression(req.getTimeExpression());
             Date nextValidTime = cronExpression.getNextValidTimeAfter(new Date());
             wf.setNextTriggerTime(nextValidTime.getTime());
+        }else {
+            wf.setTimeExpression(null);
         }
 
         WorkflowInfoDO newEntity = workflowInfoRepository.saveAndFlush(wf);

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/persistence/core/repository/AppInfoRepository.java
Patch:
@@ -1,6 +1,8 @@
 package com.github.kfcfans.oms.server.persistence.core.repository;
 
 import com.github.kfcfans.oms.server.persistence.core.model.AppInfoDO;
+import org.springframework.data.domain.Page;
+import org.springframework.data.domain.Pageable;
 import org.springframework.data.jpa.repository.JpaRepository;
 
 import java.util.List;
@@ -16,7 +18,7 @@ public interface AppInfoRepository extends JpaRepository<AppInfoDO, Long> {
 
     Optional<AppInfoDO> findByAppName(String appName);
 
-    List<AppInfoDO> findByAppNameLike(String condition);
+    Page<AppInfoDO> findByAppNameLike(String condition, Pageable pageable);
 
     /**
      * 根据 currentServer 查询 appId

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/persistence/TaskDAOImpl.java
Patch:
@@ -23,7 +23,8 @@ public void initTable() throws Exception {
 
         String delTableSQL = "drop table if exists task_info";
         // 感谢 Gitee 用户 @Linfly 反馈的 BUG
-        String createTableSQL = "create table task_info (task_id varchar(20), instance_id bigint(20), sub_instance_id bigint(20), task_name varchar(20), task_content blob, address varchar(22), status int(5), result text, failed_cnt int(11), created_time bigint(20), last_modified_time bigint(20), last_report_time bigint(20), unique KEY pkey (instance_id, task_id))";
+        // bigint(20) 与 Java Long 取值范围完全一致
+        String createTableSQL = "create table task_info (task_id varchar(255), instance_id bigint(20), sub_instance_id bigint(20), task_name varchar(255), task_content blob, address varchar(255), status int(5), result text, failed_cnt int(11), created_time bigint(20), last_modified_time bigint(20), last_report_time bigint(20), unique KEY pkey (instance_id, task_id))";
 
         try (Connection conn = ConnectionFactory.getConnection(); Statement stat = conn.createStatement()) {
             stat.execute(delTableSQL);

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/persistence/TaskDAOImpl.java
Patch:
@@ -22,7 +22,8 @@ public class TaskDAOImpl implements TaskDAO {
     public void initTable() throws Exception {
 
         String delTableSQL = "drop table if exists task_info";
-        String createTableSQL = "create table task_info (task_id varchar(20), instance_id bigint(20), sub_instance_id bigint(20), task_name varchar(20), task_content blob, address varchar(20), status int(5), result text, failed_cnt int(11), created_time bigint(20), last_modified_time bigint(20), last_report_time bigint(20), unique KEY pkey (instance_id, task_id))";
+        // 感谢 Gitee 用户 @Linfly 反馈的 BUG
+        String createTableSQL = "create table task_info (task_id varchar(20), instance_id bigint(20), sub_instance_id bigint(20), task_name varchar(20), task_content blob, address varchar(22), status int(5), result text, failed_cnt int(11), created_time bigint(20), last_modified_time bigint(20), last_report_time bigint(20), unique KEY pkey (instance_id, task_id))";
 
         try (Connection conn = ConnectionFactory.getConnection(); Statement stat = conn.createStatement()) {
             stat.execute(delTableSQL);

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/common/config/SwaggerConfig.java
Patch:
@@ -26,9 +26,9 @@ public Docket createRestApi() {
         ApiInfo apiInfo = new ApiInfoBuilder()
                 .title("OhMyScheduler")
                 .description("Distributed scheduling and computing framework.")
-                .license("GPL")
+                .license("Apache Licence 2")
                 .termsOfServiceUrl("https://github.com/KFCFans/OhMyScheduler")
-                .version("DEVELOP-VERSION")
+                .version("2.0.0")
                 .build();
 
         return new Docket(DocumentationType.SWAGGER_2)

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/oms/common/utils/JsonUtils.java
Patch:
@@ -1,5 +1,6 @@
 package com.github.kfcfans.oms.common.utils;
 
+import com.fasterxml.jackson.core.JsonParser;
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.ObjectMapper;
 import com.github.kfcfans.oms.common.OmsException;
@@ -16,7 +17,7 @@ public class JsonUtils {
     private static final ObjectMapper objectMapper = new ObjectMapper();
 
     static {
-
+        objectMapper.configure(JsonParser.Feature.ALLOW_SINGLE_QUOTES, true);
     }
 
     public static String toJSONString(Object obj) {

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/workflow/WorkflowInstanceService.java
Patch:
@@ -1,10 +1,10 @@
 package com.github.kfcfans.oms.server.service.workflow;
 
+import com.alibaba.fastjson.JSONObject;
 import com.github.kfcfans.oms.common.OmsException;
 import com.github.kfcfans.oms.common.SystemInstanceResult;
 import com.github.kfcfans.oms.common.WorkflowInstanceStatus;
 import com.github.kfcfans.oms.common.model.WorkflowDAG;
-import com.github.kfcfans.oms.common.utils.JsonUtils;
 import com.github.kfcfans.oms.server.persistence.core.model.WorkflowInstanceInfoDO;
 import com.github.kfcfans.oms.server.persistence.core.repository.WorkflowInstanceInfoRepository;
 import com.github.kfcfans.oms.server.service.instance.InstanceService;
@@ -54,7 +54,7 @@ public void stopWorkflowInstance(Long wfInstanceId, Long appId) {
         wfInstanceInfoRepository.saveAndFlush(wfInstance);
 
         // 停止所有已启动且未完成的服务
-        WorkflowDAG workflowDAG = JsonUtils.parseObjectUnsafe(wfInstance.getDag(), WorkflowDAG.class);
+        WorkflowDAG workflowDAG = JSONObject.parseObject(wfInstance.getDag(), WorkflowDAG.class);
         Queue<WorkflowDAG.Node> queue = Queues.newLinkedBlockingQueue();
         queue.add(workflowDAG.getRoot());
         while (!queue.isEmpty()) {

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/workflow/WorkflowService.java
Patch:
@@ -1,9 +1,9 @@
 package com.github.kfcfans.oms.server.service.workflow;
 
+import com.alibaba.fastjson.JSONObject;
 import com.github.kfcfans.oms.common.OmsException;
 import com.github.kfcfans.oms.common.TimeExpressionType;
 import com.github.kfcfans.oms.common.request.http.SaveWorkflowRequest;
-import com.github.kfcfans.oms.common.utils.JsonUtils;
 import com.github.kfcfans.oms.common.utils.WorkflowDAGUtils;
 import com.github.kfcfans.oms.server.common.SJ;
 import com.github.kfcfans.oms.server.common.constans.SwitchableStatus;
@@ -53,7 +53,7 @@ public Long saveWorkflow(SaveWorkflowRequest req) throws Exception {
 
         BeanUtils.copyProperties(req, wf);
         wf.setGmtModified(new Date());
-        wf.setPeDAG(JsonUtils.toJSONString(req.getPEWorkflowDAG()));
+        wf.setPeDAG(JSONObject.toJSONString(req.getPEWorkflowDAG()));
         wf.setStatus(req.isEnable() ? SwitchableStatus.ENABLE.getV() : SwitchableStatus.DISABLE.getV());
         wf.setTimeExpressionType(req.getTimeExpressionType().getV());
 

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/web/response/InstanceInfoVO.java
Patch:
@@ -18,7 +18,7 @@ public class InstanceInfoVO {
     // 任务实例ID（JS精度丢失）
     private String instanceId;
     // 该任务实例所属的 workflow ID，仅 workflow 任务存在
-    private Long wfInstanceId;
+    private String wfInstanceId;
 
     // 执行结果
     private String result;

File: oh-my-scheduler-worker-samples/src/main/java/com/github/kfcfans/oms/samples/processors/StandaloneProcessorDemo.java
Patch:
@@ -36,6 +36,7 @@ public ProcessResult process(TaskContext context) throws Exception {
         }
 
         System.out.println("================ StandaloneProcessorDemo#process ================");
+        System.out.println(context.getJobParams());
         // 根据控制台参数判断是否成功
         boolean success = !"failed".equals(context.getJobParams());
         omsLogger.info("StandaloneProcessorDemo finished process,success: .", success);

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/oms/common/model/WorkflowDAG.java
Patch:
@@ -31,7 +31,7 @@ public static final class Node {
 
         // 运行时参数
         private Long instanceId;
-        private boolean finished = false;
+        private boolean finished;
         private String result;
     }
 }

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/oms/common/utils/WorkflowDAGUtils.java
Patch:
@@ -34,7 +34,7 @@ public static WorkflowDAG convert(PEWorkflowDAG PEWorkflowDAG) {
         // 创建节点
         PEWorkflowDAG.getNodes().forEach(node -> {
             Long jobId = node.getJobId();
-            WorkflowDAG.Node n = new WorkflowDAG.Node(Lists.newLinkedList(), jobId, node.getJobName(), null, null, null);
+            WorkflowDAG.Node n = new WorkflowDAG.Node(Lists.newLinkedList(), jobId, node.getJobName(), null, false, null);
             id2Node.put(jobId, n);
 
             // 初始阶段，每一个点都设为顶点

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/persistence/core/repository/WorkflowInfoRepository.java
Patch:
@@ -21,5 +21,5 @@ public interface WorkflowInfoRepository extends JpaRepository<WorkflowInfoDO, Lo
     // 对外查询（list）三兄弟
     Page<WorkflowInfoDO> findByAppIdAndStatusNot(Long appId, int nStatus, Pageable pageable);
     Page<WorkflowInfoDO> findByIdAndStatusNot(Long id, int nStatus, Pageable pageable);
-    Page<WorkflowInfoDO> findByAppIdInAndStatusNotAndWfNameLike(Long appId, int nStatus, String condition, Pageable pageable);
+    Page<WorkflowInfoDO> findByAppIdAndStatusNotAndWfNameLike(Long appId, int nStatus, String condition, Pageable pageable);
 }

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/DispatchService.java
Patch:
@@ -42,7 +42,7 @@ public class DispatchService {
 
     public void redispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTimes) {
         InstanceInfoDO instanceInfo = instanceInfoRepository.findByInstanceId(instanceId);
-        dispatch(jobInfo, instanceId, currentRunningTimes, instanceInfo.getInstanceParams(), instanceInfo.getWorkflowId());
+        dispatch(jobInfo, instanceId, currentRunningTimes, instanceInfo.getInstanceParams(), instanceInfo.getWfInstanceId());
     }
 
     /**

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/web/controller/WorkflowController.java
Patch:
@@ -66,7 +66,7 @@ public ResultDTO<PageResult<WorkflowInfoVO>> list(@RequestBody QueryWorkflowInfo
             wfPage = workflowInfoRepository.findByIdAndStatusNot(req.getWorkflowId(), nStatus, pageRequest);
         }else {
             String condition = "%" + req.getKeyword() + "%";
-            wfPage = workflowInfoRepository.findByAppIdInAndStatusNotAndWfNameLike(req.getAppId(), nStatus, condition, pageRequest);
+            wfPage = workflowInfoRepository.findByAppIdAndStatusNotAndWfNameLike(req.getAppId(), nStatus, condition, pageRequest);
         }
         return ResultDTO.success(convertPage(wfPage));
     }

File: oh-my-scheduler-worker-agent/src/main/java/com/github/kfcfans/oms/worker/MainApplication.java
Patch:
@@ -30,7 +30,7 @@ public class MainApplication implements Runnable {
     private String storeStrategy = "DISK";
 
     @Option(names = {"-s", "--server"}, description = "调度中心地址，多值英文逗号分隔，格式 IP:Port OR domain")
-    private String server = "127.0.0.1:7700";
+    private String server = "localhost:7700";
 
     @Option(names = {"-l", "--length"}, description = "返回值最大长度")
     private int length = 1024;

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/oms/common/request/http/WorkerNeedDeployContainerRequest.java
Patch:
@@ -15,5 +15,5 @@
 @NoArgsConstructor
 @AllArgsConstructor
 public class WorkerNeedDeployContainerRequest implements OmsSerializable {
-    private String containerName;
+    private Long containerId;
 }

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/akka/actors/ServerActor.java
Patch:
@@ -87,7 +87,7 @@ private void onReceiveWorkerNeedDeployContainerRequest(WorkerNeedDeployContainer
         Environment environment = SpringUtils.getBean(Environment.class);
         String port = environment.getProperty("local.server.port");
 
-        Optional<ContainerInfoDO> containerInfoOpt = containerInfoRepository.findByContainerName(req.getContainerName());
+        Optional<ContainerInfoDO> containerInfoOpt = containerInfoRepository.findById(req.getContainerId());
         AskResponse askResponse = new AskResponse();
         askResponse.setSuccess(false);
         if (containerInfoOpt.isPresent()) {

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/processor/ProcessorTracker.java
Patch:
@@ -266,7 +266,7 @@ private void initProcessor() throws Exception {
                 break;
             case JAVA_CONTAINER:
                 String[] split = processorInfo.split("#");
-                omsContainer = OmsContainerFactory.getContainer(split[0]);
+                omsContainer = OmsContainerFactory.getContainer(Long.valueOf(split[0]));
                 if (omsContainer != null) {
                     processor = omsContainer.getProcessor(split[1]);
                 }

File: oh-my-scheduler-worker-samples/src/main/java/com/github/kfcfans/oms/samples/OhMySchedulerConfig.java
Patch:
@@ -25,6 +25,7 @@ public OhMyWorker initOMS() throws Exception {
 
         // 1. 创建配置文件
         OhMyConfig config = new OhMyConfig();
+        config.setPort(27777);
         config.setAppName("oms-test");
         config.setServerAddress(serverAddress);
         // 如果没有大型 Map/MapReduce 的需求，建议使用内存来加速计算

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/akka/OhMyServer.java
Patch:
@@ -8,7 +8,6 @@
 import com.github.kfcfans.oms.server.akka.actors.FriendActor;
 import com.github.kfcfans.oms.server.akka.actors.ServerActor;
 import com.github.kfcfans.oms.server.common.utils.PropertyUtils;
-import com.github.kfcfans.oms.server.common.utils.TimeUtils;
 import com.google.common.base.Stopwatch;
 import com.google.common.collect.Maps;
 import com.typesafe.config.Config;
@@ -39,7 +38,8 @@ public static void init() {
         Stopwatch stopwatch = Stopwatch.createStarted();
         log.info("[OhMyServer] OhMyServer's akka system start to bootstrap...");
 
-        TimeUtils.check();
+        // 忽略了一个问题，机器是没办法访问外网的，除非架设自己的NTP服务器
+        // TimeUtils.check();
 
         // 解析配置文件
         PropertyUtils.init();

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/common/constans/ContainerSourceType.java
Patch:
@@ -13,7 +13,7 @@
 @AllArgsConstructor
 public enum ContainerSourceType {
 
-    JarFile(1, "Jar文件"),
+    FatJar(1, "Jar文件"),
     Git(2, "Git代码库");
 
     private final int v;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/common/utils/TimeUtils.java
Patch:
@@ -55,6 +55,8 @@ public static void check() throws TimeCheckException {
         }
     }
 
+
+
     public static final class TimeCheckException extends RuntimeException {
         public TimeCheckException(String message) {
             super(message);

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/ContainerService.java
Patch:
@@ -90,7 +90,7 @@ public void save(SaveContainerInfoRequest request) {
         container.setStatus(request.getStatus().getV());
 
         // 文件上传形式的 sourceInfo 为该文件的 md5 值，Git形式的 md5 在部署阶段生成
-        if (request.getSourceType() == ContainerSourceType.JarFile) {
+        if (request.getSourceType() == ContainerSourceType.FatJar) {
             container.setVersion(request.getSourceInfo());
         }else {
             container.setVersion("init");

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/web/controller/InstanceController.java
Patch:
@@ -78,7 +78,7 @@ public ResultDTO<StringPage> getInstanceLog(Long instanceId, Long index, HttpSer
         // 转发HTTP请求（如果使用Akka，则需要传输两次，而转发HTTP请求只需要传输一次"大"数据包）
         if (!OhMyServer.getActorSystemAddress().equals(targetServer)) {
             String ip = targetServer.split(":")[0];
-            String url = "http://" + ip + ":" + port + "/instance/log?instanceId=" + instanceId;
+            String url = String.format("http://%s:%s/instance/log?instanceId=%d&index=%d", ip, port, instanceId, index);
             try {
                 response.sendRedirect(url);
                 return ResultDTO.success(StringPage.simple("redirecting..."));

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/web/response/ContainerInfoVO.java
Patch:
@@ -18,18 +18,18 @@ public class ContainerInfoVO {
     private String containerName;
 
     // 容器类型，枚举值为 ContainerSourceType
-    private Integer sourceType;
+    private String sourceType;
     // 由 sourceType 决定，JarFile -> String，存储文件名称；Git -> JSON，包括 URL，branch，username，password
     private String sourceInfo;
 
     // 版本 （Jar包使用md5，Git使用commitId，前者32位，后者40位，不会产生碰撞）
     private String version;
 
     // 状态，枚举值为 ContainerStatus
-    private Integer status;
+    private String status;
 
     // 上一次部署时间
-    private Date lastDeployTime;
+    private String lastDeployTime;
 
     private Date gmtCreate;
     private Date gmtModified;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/akka/OhMyServer.java
Patch:
@@ -8,6 +8,7 @@
 import com.github.kfcfans.oms.server.akka.actors.FriendActor;
 import com.github.kfcfans.oms.server.akka.actors.ServerActor;
 import com.github.kfcfans.oms.server.common.utils.PropertyUtils;
+import com.github.kfcfans.oms.server.common.utils.TimeUtils;
 import com.google.common.base.Stopwatch;
 import com.google.common.collect.Maps;
 import com.typesafe.config.Config;
@@ -38,6 +39,8 @@ public static void init() {
         Stopwatch stopwatch = Stopwatch.createStarted();
         log.info("[OhMyServer] OhMyServer's akka system start to bootstrap...");
 
+        TimeUtils.check();
+
         // 解析配置文件
         PropertyUtils.init();
         Properties properties = PropertyUtils.getProperties();

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/ContainerService.java
Patch:
@@ -151,7 +151,9 @@ public String uploadContainerJarFile(MultipartFile file) throws IOException {
             // 将文件拷贝到正确的路径
             String finalFileStr = OmsFileUtils.genContainerJarPath() + fileName;
             File finalFile = new File(finalFileStr);
-            FileUtils.forceDelete(finalFile);
+            if (finalFile.exists()) {
+                FileUtils.forceDelete(finalFile);
+            }
             FileUtils.moveFile(tmpFile, finalFile);
 
             return md5;

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/common/utils/SerializerUtils.java
Patch:
@@ -4,7 +4,6 @@
 import com.esotericsoftware.kryo.Kryo;
 import com.esotericsoftware.kryo.io.Input;
 import com.esotericsoftware.kryo.io.Output;
-import com.esotericsoftware.kryo.util.Pool;
 
 /**
  * 序列化器

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -18,7 +18,7 @@
 @Entity
 @NoArgsConstructor
 @AllArgsConstructor
-@Table(name = "instance_log", indexes = {@Index(columnList = "jobId"), @Index(columnList = "appId")})
+@Table(name = "instance_info", indexes = {@Index(columnList = "jobId"), @Index(columnList = "appId"), @Index(columnList = "instanceId")})
 public class InstanceInfoDO {
 
     @Id

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/ContainerService.java
Patch:
@@ -329,8 +329,10 @@ private File prepareJarFile(ContainerInfoDO container, Session session) throws E
 
                 if (!gridFsManager.exists(GridFsManager.CONTAINER_BUCKET, jarFileName)) {
                     remote.sendText("SYSTEM: can't find the jar resource in remote, maybe this is a new version, start to upload new version.");
-                    gridFsManager.download(jarWithDependency, GridFsManager.CONTAINER_BUCKET, jarFileName);
+                    gridFsManager.store(jarWithDependency, GridFsManager.CONTAINER_BUCKET, jarFileName);
                     remote.sendText("SYSTEM: upload to GridFS successfully~");
+                }else {
+                    remote.sendText("SYSTEM: find the jar resource in remote successfully, so it's no need to upload anymore.");
                 }
 
                 // 将文件从临时工作目录移动到正式目录

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/processor/ProcessorTracker.java
Patch:
@@ -121,7 +121,8 @@ public void submitTask(TaskDO newTask) {
         newTask.setInstanceId(instanceInfo.getInstanceId());
         newTask.setAddress(taskTrackerAddress);
 
-        ProcessorRunnable processorRunnable = new ProcessorRunnable(instanceInfo, taskTrackerActorRef, newTask, processor, omsLogger);
+        ClassLoader classLoader = omsContainer == null ? getClass().getClassLoader() : omsContainer.getContainerClassLoader();
+        ProcessorRunnable processorRunnable = new ProcessorRunnable(instanceInfo, taskTrackerActorRef, newTask, processor, omsLogger, classLoader);
         try {
             threadPool.submit(processorRunnable);
             success = true;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/common/utils/ContainerTemplateGenerator.java
Patch:
@@ -37,8 +37,8 @@ public static File generate(String group, String artifact, String name, String p
         if (resource == null) {
             throw new RuntimeException("generate container template failed, can't find zip file in classpath.");
         }
-        String originTemplate = resource.getPath();
-        ZipFile zipFile = new ZipFile(originTemplate);
+
+        ZipFile zipFile = new ZipFile(resource.getFile());
 
         String tmpPath = OmsFileUtils.genTemporaryPath();
         zipFile.extractAll(tmpPath);

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/common/OhMyConfig.java
Patch:
@@ -18,7 +18,7 @@ public class OhMyConfig {
      */
     private String appName;
     /**
-     * 调度服务器地址，ip:port
+     * 调度服务器地址，ip:port 或 域名
      */
     private List<String> serverAddress;
     /**

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/akka/actors/ServerActor.java
Patch:
@@ -96,7 +96,7 @@ private void onReceiveWorkerNeedDeployContainerRequest(WorkerNeedDeployContainer
 
             ServerDeployContainerRequest dpReq = new ServerDeployContainerRequest();
             BeanUtils.copyProperties(containerInfo, dpReq);
-            String downloadURL = String.format("http://%s:%s/container/downloadJar?md5=%s", NetUtils.getLocalHost(), port, containerInfo.getMd5());
+            String downloadURL = String.format("http://%s:%s/container/downloadJar?version=%s", NetUtils.getLocalHost(), port, containerInfo.getVersion());
             dpReq.setDownloadURL(downloadURL);
 
             askResponse.setData(JsonUtils.toBytes(dpReq));

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/persistence/core/model/ContainerInfoDO.java
Patch:
@@ -30,8 +30,8 @@ public class ContainerInfoDO {
     // 由 sourceType 决定，JarFile -> String，存储文件名称；Git -> JSON，包括 URL，branch，username，password
     private String sourceInfo;
 
-    // jar的MD5，唯一，作为 GridFS 的文件名
-    private String md5;
+    // 版本 （Jar包使用md5，Git使用commitId，前者32位，后者40位，不会产生碰撞）
+    private String version;
 
     // 状态，枚举值为 ContainerStatus
     private Integer status;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/web/controller/ContainerController.java
Patch:
@@ -39,8 +39,8 @@ public class ContainerController {
     private ContainerService containerService;
 
     @GetMapping("/downloadJar")
-    public void downloadJar(String filename, HttpServletResponse response) throws IOException {
-        File file = containerService.fetchContainerJarFile(filename);
+    public void downloadJar(String version, HttpServletResponse response) throws IOException {
+        File file = containerService.fetchContainerJarFile(version);
         if (file.exists()) {
             OmsFileUtils.file2HttpResponse(file, response);
         }

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/common/utils/OmsFileUtils.java
Patch:
@@ -120,9 +120,9 @@ public static void storeFile2GridFS(GridFsTemplate gridFsTemplate, File localFil
      * 计算文件的 MD5
      * @param f 文件
      * @return md5
-     * @throws Exception 异常
+     * @throws IOException 异常
      */
-    public static String md5(File f) throws Exception {
+    public static String md5(File f) throws IOException {
         String md5;
         try(FileInputStream fis = new FileInputStream(f)) {
             md5 = DigestUtils.md5DigestAsHex(fis);

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/web/controller/ContainerController.java
Patch:
@@ -2,7 +2,6 @@
 
 import com.github.kfcfans.oms.common.response.ResultDTO;
 import com.github.kfcfans.oms.server.common.constans.ContainerSourceType;
-import com.github.kfcfans.oms.server.common.constans.ContainerStatus;
 import com.github.kfcfans.oms.server.common.utils.OmsFilePathUtils;
 import com.github.kfcfans.oms.server.persistence.core.model.ContainerInfoDO;
 import com.github.kfcfans.oms.server.persistence.core.repository.ContainerInfoRepository;
@@ -35,7 +34,7 @@
  * @since 2020/5/15
  */
 @Slf4j
-@RestController
+@RestController("/container")
 public class ContainerController {
 
     private GridFsTemplate gridFsTemplate;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/persistence/core/model/InstanceInfoDO.java
Patch:
@@ -30,6 +30,8 @@ public class InstanceInfoDO {
     private Long appId;
     // 任务实例ID
     private Long instanceId;
+    // 任务实例参数
+    private String instanceParams;
     /**
      * 任务状态 {@link com.github.kfcfans.common.InstanceStatus}
      */

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/instance/InstanceService.java
Patch:
@@ -64,7 +64,7 @@ public void stopInstance(Long instanceId) {
             instanceInfoDO.setResult(SystemInstanceResult.STOPPED_BY_USER);
             instanceInfoRepository.saveAndFlush(instanceInfoDO);
 
-            InstanceManager.processFinishedInstance(instanceId);
+            InstanceManager.processFinishedInstance(instanceId, STOPPED.getV());
 
             /*
             不可靠通知停止 TaskTracker

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/timing/schedule/JobScheduleService.java
Patch:
@@ -153,7 +153,7 @@ private void scheduleCornJob(List<Long> appIds) {
                     }
 
                     HashedWheelTimerHolder.TIMER.schedule(() -> {
-                        dispatchService.dispatch(jobInfoDO, instanceId, 0);
+                        dispatchService.dispatch(jobInfoDO, instanceId, 0, null);
                     }, delay, TimeUnit.MILLISECONDS);
                 });
 

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -118,7 +118,7 @@ public static TaskTracker create(ServerScheduleJobReq req) {
     /* *************************** 对外方法区 *************************** */
     /**
      * 更新Task状态
-     * V1.0.0 -> V1.0.1 锁方案变更，从 synchronized (taskId.intern()) 修改为分段锁，能大大减少内存占用，损失的只有理论并发度而已
+     * V1.0.0 -> V1.0.1（e405e283ad7f97b0b4e5d369c7de884c0caf9192） 锁方案变更，从 synchronized (taskId.intern()) 修改为分段锁，能大大减少内存占用，损失的只有理论并发度而已
      * @param taskId task的ID（task为任务实例的执行单位）
      * @param newStatus task的新状态
      * @param reportTime 上报时间

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/persistence/local/LocalInstanceLogRepository.java
Patch:
@@ -1,6 +1,7 @@
 package com.github.kfcfans.oms.server.persistence.local;
 
 import org.springframework.data.jpa.repository.JpaRepository;
+import org.springframework.transaction.annotation.Transactional;
 
 import java.util.List;
 import java.util.stream.Stream;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/InstanceLogService.java
Patch:
@@ -21,6 +21,7 @@
 import org.springframework.scheduling.annotation.Async;
 import org.springframework.scheduling.annotation.Scheduled;
 import org.springframework.stereotype.Service;
+import org.springframework.transaction.annotation.Transactional;
 import org.springframework.util.CollectionUtils;
 
 import javax.annotation.Resource;
@@ -87,6 +88,7 @@ public void submitLogs(String workerAddress, List<InstanceLogContent> logs) {
      * @param instanceId 任务实例ID
      * @return 文本字符串
      */
+    @Transactional(readOnly = true)
     public String fetchInstanceLog(Long instanceId) {
 
         try {
@@ -126,6 +128,7 @@ public String fetchInstanceLog(Long instanceId) {
      * @param instanceId 任务实例ID
      */
     @Async("commonTaskExecutor")
+    @Transactional(readOnly = true)
     public void sync(Long instanceId) {
 
         // 休眠10秒等待全部数据上报（OmsLogHandler 每隔5秒上报数据）

File: oh-my-scheduler-worker-samples/src/main/java/com/github/kfcfans/oms/server/processors/StandaloneProcessorDemo.java
Patch:
@@ -21,11 +21,13 @@ public class StandaloneProcessorDemo implements BasicProcessor {
     @Override
     public ProcessResult process(TaskContext context) throws Exception {
 
+        context.getOmsLogger().info("StandaloneProcessorDemo start process,context is {}.", context);
         System.out.println("================ StandaloneProcessorDemo#process ================");
         // 根据控制台参数判断是否成功
         boolean success = "success".equals(context.getJobParams());
         System.out.println("TaskContext: " + JSONObject.toJSONString(context));
         System.out.println("ProcessSuccess: " + success);
+        context.getOmsLogger().info("StandaloneProcessorDemo finished process,success: .", success);
         return new ProcessResult(success, context + ": " + success);
     }
 }

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/common/model/InstanceDetail.java
Patch:
@@ -33,6 +33,8 @@ public class InstanceDetail implements OmsSerializable {
     // 秒级任务专用
     private List<SubInstanceDetail> subInstanceDetails;
 
+    // 重试次数
+    private Long runningTimes;
 
     // 秒级任务的 extra -> List<SubInstanceDetail>
     @Data

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/id/IdGenerateService.java
Patch:
@@ -10,7 +10,7 @@
 /**
  * 唯一ID生成服务，使用 Twitter snowflake 算法
  * 机房ID：固定为0，占用2位
- * 机器ID：数据库自增，占用8位（最多支持256台机器，如果频繁部署需要删除数据库重置id）
+ * 机器ID：数据库自增，占用14位（如果频繁部署需要删除数据库重置id）
  *
  * @author tjq
  * @since 2020/4/6

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/id/SnowFlakeIdGenerator.java
Patch:
@@ -16,8 +16,8 @@ class SnowFlakeIdGenerator {
     /**
      * 每一部分占用的位数
      */
-    private final static long SEQUENCE_BIT = 12; //序列号占用的位数
-    private final static long MACHINE_BIT = 8;   //机器标识占用的位数
+    private final static long SEQUENCE_BIT = 6; //序列号占用的位数
+    private final static long MACHINE_BIT = 14;   //机器标识占用的位数
     private final static long DATA_CENTER_BIT = 2;//数据中心占用的位数
 
     /**

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/instance/InstanceService.java
Patch:
@@ -128,7 +128,9 @@ public InstanceDetail getInstanceDetail(Long instanceId) {
             AskResponse askResponse = (AskResponse) askCS.toCompletableFuture().get(RemoteConstant.DEFAULT_TIMEOUT_MS, TimeUnit.MILLISECONDS);
 
             if (askResponse.isSuccess()) {
-                return askResponse.getData(InstanceDetail.class);
+                InstanceDetail instanceDetail = askResponse.getData(InstanceDetail.class);
+                instanceDetail.setRunningTimes(instanceLogDO.getRunningTimes());
+                return instanceDetail;
             }else {
                 log.warn("[InstanceService] ask InstanceStatus from TaskTracker failed, the message is {}.", askResponse.getMessage());
             }

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -264,6 +264,7 @@ public void broadcast(boolean preExecuteSuccess, long subInstanceId, String preT
      */
     public void destroy() {
 
+        Stopwatch sw = Stopwatch.createStarted();
         // 0. 开始关闭线程池，不能使用 shutdownNow()，因为 destroy 方法本身就在 scheduledPool 的线程中执行，强行关闭会打断 destroy 的执行。
         scheduledPool.shutdown();
 
@@ -290,7 +291,7 @@ public void destroy() {
         // 3. 移除顶层引用，送去 GC
         TaskTrackerPool.remove(instanceId);
 
-        log.info("[TaskTracker-{}] TaskTracker has left the world, bye~", instanceId);
+        log.info("[TaskTracker-{}] TaskTracker has left the world(using {}), bye~", instanceId, sw.stop());
 
         // 4. 强制关闭线程池
         if (!scheduledPool.isTerminated()) {

File: oh-my-scheduler-worker/src/test/java/com/github/kfcfans/oms/CommonTaskTrackerTest.java
Patch:
@@ -30,6 +30,8 @@ public static void init() throws Exception {
         OhMyConfig ohMyConfig = new OhMyConfig();
         ohMyConfig.setAppName("oms-test");
         ohMyConfig.setServerAddress(Lists.newArrayList("127.0.0.1:7700"));
+        ohMyConfig.setEnableTestMode(true);
+
         OhMyWorker worker = new OhMyWorker();
         worker.setConfig(ohMyConfig);
         worker.init();

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/JobService.java
Patch:
@@ -3,6 +3,7 @@
 import com.github.kfcfans.common.InstanceStatus;
 import com.github.kfcfans.common.TimeExpressionType;
 import com.github.kfcfans.oms.server.common.constans.JobStatus;
+import com.github.kfcfans.oms.server.common.utils.CronExpression;
 import com.github.kfcfans.oms.server.persistence.model.InstanceLogDO;
 import com.github.kfcfans.oms.server.persistence.model.JobInfoDO;
 import com.github.kfcfans.oms.server.persistence.repository.InstanceLogRepository;
@@ -99,6 +100,7 @@ private void shutdownOrStopJob(Long jobId, JobStatus status) throws IllegalArgum
         }
         JobInfoDO jobInfoDO = jobInfoOPT.get();
         jobInfoDO.setStatus(status.getV());
+        jobInfoDO.setGmtModified(new Date());
         jobInfoRepository.saveAndFlush(jobInfoDO);
 
         // 2. 关闭秒级任务
@@ -111,11 +113,10 @@ private void shutdownOrStopJob(Long jobId, JobStatus status) throws IllegalArgum
             return;
         }
         if (executeLogs.size() > 1) {
-            log.warn("[JobController] frequent job should just have one running instance, there must have some bug.");
+            log.warn("[JobService] frequent job should just have one running instance, there must have some bug.");
         }
         executeLogs.forEach(instance -> {
             try {
-
                 // 重复查询了数据库，不过问题不大，这个调用量很小
                 instanceService.stopInstance(instance.getInstanceId());
             }catch (Exception ignore) {

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/timing/schedule/JobScheduleService.java
Patch:
@@ -5,7 +5,6 @@
 import com.github.kfcfans.common.TimeExpressionType;
 import com.github.kfcfans.oms.server.common.utils.CronExpression;
 import com.github.kfcfans.oms.server.service.JobService;
-import com.github.kfcfans.oms.server.service.instance.InstanceManager;
 import com.github.kfcfans.oms.server.akka.OhMyServer;
 import com.github.kfcfans.oms.server.persistence.model.AppInfoDO;
 import com.github.kfcfans.oms.server.persistence.model.InstanceLogDO;
@@ -142,8 +141,6 @@ private void scheduleCornJob(List<Long> appIds) {
                 jobInfos.forEach(jobInfoDO ->  {
 
                     Long instanceId = jobId2InstanceId.get(jobInfoDO.getId());
-                    // 注册到任务实例管理中心
-                    InstanceManager.register(instanceId, jobInfoDO);
 
                     long targetTriggerTime = jobInfoDO.getNextTriggerTime();
                     long delay = 0;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/web/controller/JobController.java
Patch:
@@ -36,7 +36,7 @@
  */
 @Slf4j
 @RestController
-@RequestMapping("job")
+@RequestMapping("/job")
 public class JobController {
 
     @Resource

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/processor/ProcessorTracker.java
Patch:
@@ -211,7 +211,7 @@ private void initProcessor() throws Exception {
                     try {
                         processor = SpringUtils.getBean(processorInfo);
                     }catch (Exception e) {
-                        log.warn("[ProcessorRunnable-{}] no spring bean of processor(className={}).", instanceId, processorInfo);
+                        log.warn("[ProcessorRunnable-{}] no spring bean of processor(className={}).", instanceId, processorInfo, e);
                     }
                 }
                 // 反射加载

File: oh-my-scheduler-worker-samples/src/main/java/com/github/kfcfans/oms/server/processors/BroadcastProcessorDemo.java
Patch:
@@ -6,6 +6,7 @@
 import com.github.kfcfans.oms.worker.core.processor.TaskResult;
 import com.github.kfcfans.oms.worker.core.processor.sdk.BroadcastProcessor;
 import lombok.extern.slf4j.Slf4j;
+import org.springframework.stereotype.Component;
 
 import java.util.List;
 import java.util.concurrent.ThreadLocalRandom;
@@ -18,6 +19,7 @@
  * @since 2020/4/17
  */
 @Slf4j
+@Component
 public class BroadcastProcessorDemo extends BroadcastProcessor {
 
     @Override

File: oh-my-scheduler-worker-samples/src/main/java/com/github/kfcfans/oms/server/processors/MapReduceProcessorDemo.java
Patch:
@@ -12,6 +12,7 @@
 import lombok.NoArgsConstructor;
 import lombok.ToString;
 import lombok.extern.slf4j.Slf4j;
+import org.springframework.stereotype.Component;
 
 import java.util.List;
 import java.util.concurrent.ThreadLocalRandom;
@@ -24,6 +25,7 @@
  * @since 2020/4/17
  */
 @Slf4j
+@Component
 public class MapReduceProcessorDemo extends MapReduceProcessor {
 
     // 每一批发送任务大小

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -146,7 +146,7 @@ public void updateTaskStatus(String taskId, int newStatus, long reportTime, @Nul
 
             // 处理失败的情况
             int configTaskRetryNum = instanceInfo.getTaskRetryNum();
-            if (nTaskStatus == TaskStatus.WORKER_PROCESS_FAILED && configTaskRetryNum > 1) {
+            if (nTaskStatus == TaskStatus.WORKER_PROCESS_FAILED && configTaskRetryNum >= 1) {
 
                 // 失败不是主要的情况，多查一次数据库也问题不大（况且前面有缓存顶着，大部分情况之前不会去查DB）
                 Optional<TaskDO> taskOpt = taskPersistenceService.getTask(instanceId, taskId);

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/common/model/SystemMetrics.java
Patch:
@@ -1,5 +1,6 @@
 package com.github.kfcfans.common.model;
 
+import com.github.kfcfans.common.OmsSerializable;
 import lombok.Data;
 
 import java.io.Serializable;
@@ -11,7 +12,7 @@
  * @since 2020/3/25
  */
 @Data
-public class SystemMetrics implements Serializable, Comparable<SystemMetrics> {
+public class SystemMetrics implements OmsSerializable, Comparable<SystemMetrics> {
 
     // CPU核心数量
     private int cpuProcessors;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/akka/actors/ServerActor.java
Patch:
@@ -46,9 +46,7 @@ private void onReceiveTaskTrackerReportInstanceStatusReq(TaskTrackerReportInstan
             InstanceManager.updateStatus(req);
 
             // 回复接收成功
-            AskResponse askResponse = new AskResponse();
-            askResponse.setSuccess(true);
-            getSender().tell(askResponse, getSelf());
+            getSender().tell(AskResponse.succeed(null), getSelf());
         }catch (Exception e) {
             log.error("[ServerActor] update instance status failed for request: {}.", req, e);
         }

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/DispatchService.java
Patch:
@@ -62,7 +62,7 @@ public void dispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTime
         if (runningInstanceCount > jobInfo.getMaxInstanceNum()) {
             String result = String.format(SystemInstanceResult.TOO_MUCH_INSTANCE, runningInstanceCount, jobInfo.getMaxInstanceNum());
             log.warn("[DispatchService] cancel dispatch job(jobId={}) due to too much instance(num={}) is running.", jobId, runningInstanceCount);
-            instanceLogRepository.update4Trigger(instanceId, FAILED.getV(), currentRunningTimes, current, RemoteConstant.EMPTY_ADDRESS, result);
+            instanceLogRepository.update4TriggerFailed(instanceId, FAILED.getV(), currentRunningTimes, current, current, RemoteConstant.EMPTY_ADDRESS, result);
             return;
         }
 
@@ -85,7 +85,7 @@ public void dispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTime
         if (CollectionUtils.isEmpty(finalWorkers)) {
             String clusterStatusDescription = WorkerManagerService.getWorkerClusterStatusDescription(jobInfo.getAppId());
             log.warn("[DispatchService] cancel dispatch job(jobId={}) due to no worker available, clusterStatus is {}.", jobId, clusterStatusDescription);
-            instanceLogRepository.update4Trigger(instanceId, FAILED.getV(), currentRunningTimes, current, RemoteConstant.EMPTY_ADDRESS, SystemInstanceResult.NO_WORKER_AVAILABLE);
+            instanceLogRepository.update4TriggerFailed(instanceId, FAILED.getV(), currentRunningTimes, current, current, RemoteConstant.EMPTY_ADDRESS, SystemInstanceResult.NO_WORKER_AVAILABLE);
             return;
         }
 
@@ -120,6 +120,6 @@ public void dispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTime
         log.debug("[DispatchService] send request({}) to TaskTracker({}) succeed.", req, taskTrackerActor.pathString());
 
         // 修改状态
-        instanceLogRepository.update4Trigger(instanceId, WAITING_WORKER_RECEIVE.getV(), currentRunningTimes + 1, current, taskTrackerAddress, EMPTY_RESULT);
+        instanceLogRepository.update4TriggerSucceed(instanceId, WAITING_WORKER_RECEIVE.getV(), currentRunningTimes + 1, current, taskTrackerAddress);
     }
 }

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/instance/InstanceService.java
Patch:
@@ -114,9 +114,9 @@ public InstanceDetail getInstanceDetail(Long instanceId) {
             AskResponse askResponse = (AskResponse) askCS.toCompletableFuture().get(RemoteConstant.DEFAULT_TIMEOUT_MS, TimeUnit.MILLISECONDS);
 
             if (askResponse.isSuccess()) {
-                return (InstanceDetail) askResponse.getExtra();
+                return askResponse.getData(InstanceDetail.class);
             }else {
-                log.warn("[InstanceService] ask InstanceStatus from TaskTracker failed, the message is {}.", askResponse.getExtra());
+                log.warn("[InstanceService] ask InstanceStatus from TaskTracker failed, the message is {}.", askResponse.getMessage());
             }
 
         }catch (Exception e) {

File: oh-my-scheduler-server/src/test/java/com/github/kfcfans/oms/server/test/RepositoryTest.java
Patch:
@@ -67,7 +67,7 @@ public void testUpdate() {
 
     @Test
     public void testExecuteLogUpdate() {
-        instanceLogRepository.update4Trigger(1586310414570L, 2, 100, System.currentTimeMillis(), "192.168.1.1", "NULL");
+        instanceLogRepository.update4TriggerFailed(1586310414570L, 2, 100, System.currentTimeMillis(), System.currentTimeMillis(), "192.168.1.1", "NULL");
         instanceLogRepository.update4FrequentJob(1586310419650L, 2, 200);
     }
 

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/processor/sdk/MapProcessor.java
Patch:
@@ -44,7 +44,7 @@ public ProcessResult map(List<?> taskList, String taskName) {
         }
 
         if (taskList.size() > RECOMMEND_BATCH_SIZE) {
-            log.warn("[MapReduceProcessor] map task size is too large, network maybe overload... please try to split the tasks.");
+            log.warn("[MapProcessor] map task size is too large, network maybe overload... please try to split the tasks.");
         }
 
         TaskDO task = ThreadLocalStore.getTask();
@@ -61,7 +61,7 @@ public ProcessResult map(List<?> taskList, String taskName) {
             AskResponse respObj = (AskResponse) requestCS.toCompletableFuture().get(REQUEST_TIMEOUT_MS, TimeUnit.MILLISECONDS);
             requestSucceed = respObj.isSuccess();
         }catch (Exception e) {
-            log.warn("[MapReduceProcessor] map failed.", e);
+            log.warn("[MapProcessor] map failed.", e);
         }
 
         if (requestSucceed) {

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/task/CommonTaskTracker.java
Patch:
@@ -73,7 +73,7 @@ public InstanceDetail fetchRunningStatus() {
         taskDetail.setSucceedTaskNum(holder.succeedNum);
         taskDetail.setFailedTaskNum(holder.failedNum);
         taskDetail.setTotalTaskNum(holder.getTotalTaskNum());
-        detail.setExtra(taskDetail);
+        detail.setTaskDetail(taskDetail);
 
         return detail;
     }

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/DispatchService.java
Patch:
@@ -99,6 +99,8 @@ public void dispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTime
         // 构造请求
         ServerScheduleJobReq req = new ServerScheduleJobReq();
         BeanUtils.copyProperties(jobInfo, req);
+        // 传入 JobId
+        req.setJobId(jobInfo.getId());
         req.setInstanceParams(instanceParams);
         req.setInstanceId(instanceId);
         req.setAllWorkerAddress(finalWorkers);

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/common/request/ServerScheduleJobReq.java
Patch:
@@ -22,7 +22,6 @@ public class ServerScheduleJobReq implements Serializable {
     /**
      * 基础信息
      */
-    private Long jobId;
     private Long instanceId;
 
     /**

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/persistence/model/JobInfoDO.java
Patch:
@@ -31,6 +31,8 @@ public class JobInfoDO {
     private Long appId;
     // 任务自带的参数
     private String jobParams;
+    // 任务实例的参数(API触发专用)
+    private String instanceParams;
 
     /* ************************** 定时参数 ************************** */
     // 时间表达式类型（CRON/API/FIX_RATE/FIX_DELAY）

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/web/request/ModifyJobInfoRequest.java
Patch:
@@ -25,6 +25,8 @@ public class ModifyJobInfoRequest {
     private String groupName;
     // 任务自带的参数
     private String jobParams;
+    // 任务实例的参数(API触发专用)
+    private String instanceParams;
 
     /* ************************** 定时参数 ************************** */
     // 时间表达式类型（CRON/API/FIX_RATE/FIX_DELAY）

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/classloader/ProcessorBeanFactory.java
Patch:
@@ -27,7 +27,7 @@ public ProcessorBeanFactory() {
 
         // 1. 初始化类加载器
         ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();
-        URL path = contextClassLoader.getResource("/");
+        URL path = contextClassLoader.getResource("");
         ohMyClassLoader = new OhMyClassLoader(new URL[]{path}, contextClassLoader);
 
         // 2. 初始化对象缓存
@@ -41,7 +41,7 @@ public BasicProcessor getLocalProcessor(String className) {
             try {
 
                 Class<?> clz = ohMyClassLoader.loadClass(className);
-                BasicProcessor processor = (BasicProcessor) clz.newInstance();
+                BasicProcessor processor = (BasicProcessor) clz.getDeclaredConstructor().newInstance();
                 processor.init();
 
                 return processor;

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/task/CommonTaskTracker.java
Patch:
@@ -206,8 +206,7 @@ private void innerRun() {
                 }
 
                 // 服务器已经更新状态，任务已经执行完毕，开始释放所有资源
-                log.info("[TaskTracker-{}] instance(jobId={}) process finished,result = {}, start to release resource...",
-                        instanceId, instanceInfo.getJobId(), result);
+                log.info("[TaskTracker-{}] instance process finished,result = {}, start to release resource...", instanceId, result);
 
                 destroy();
                 return;
@@ -231,6 +230,8 @@ private void innerRun() {
                         if (!TaskConstant.LAST_TASK_NAME.equals(uncheckTask.getTaskName())) {
                             updateEntity.setAddress(RemoteConstant.EMPTY_ADDRESS);
                         }
+                        // 失败次数 + 1
+                        updateEntity.setFailedCnt(uncheckTask.getFailedCnt() + 1);
 
                         taskPersistenceService.updateTask(instanceId, uncheckTask.getTaskId(), updateEntity);
 

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/task/TaskTracker.java
Patch:
@@ -269,6 +269,8 @@ protected void dispatchTask(TaskDO task, String processorTrackerAddress) {
         // 更新数据库（如果更新数据库失败，可能导致重复执行，先不处理）
         TaskDO updateEntity = new TaskDO();
         updateEntity.setStatus(TaskStatus.DISPATCH_SUCCESS_WORKER_UNCHECK.getValue());
+        // 写入处理该任务的 ProcessorTracker
+        updateEntity.setAddress(processorTrackerAddress);
         taskPersistenceService.updateTask(instanceId, task.getTaskId(), updateEntity);
 
         log.debug("[TaskTracker-{}] dispatch task(taskId={},taskName={}) successfully.", instanceId, task.getTaskId(), task.getTaskName());

File: oh-my-scheduler-worker/src/test/java/com/github/kfcfans/oms/TestUtils.java
Patch:
@@ -19,7 +19,6 @@ public class TestUtils {
     public static ServerScheduleJobReq genServerScheduleJobReq(ExecuteType executeType, TimeExpressionType timeExpressionType) {
         ServerScheduleJobReq req = new ServerScheduleJobReq();
 
-        req.setJobId(1L);
         req.setInstanceId(10086L);
         req.setAllWorkerAddress(Lists.newArrayList(NetUtils.getLocalHost() + ":" + RemoteConstant.DEFAULT_WORKER_PORT));
 

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/core/InstanceManager.java
Patch:
@@ -2,7 +2,7 @@
 
 import com.github.kfcfans.common.InstanceStatus;
 import com.github.kfcfans.common.request.TaskTrackerReportInstanceStatusReq;
-import com.github.kfcfans.oms.server.common.constans.TimeExpressionType;
+import com.github.kfcfans.common.TimeExpressionType;
 import com.github.kfcfans.oms.server.common.utils.SpringUtils;
 import com.github.kfcfans.oms.server.persistence.model.ExecuteLogDO;
 import com.github.kfcfans.oms.server.persistence.model.JobInfoDO;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/timing/schedule/JobScheduleService.java
Patch:
@@ -2,7 +2,7 @@
 
 import com.github.kfcfans.common.InstanceStatus;
 import com.github.kfcfans.oms.server.common.constans.JobStatus;
-import com.github.kfcfans.oms.server.common.constans.TimeExpressionType;
+import com.github.kfcfans.common.TimeExpressionType;
 import com.github.kfcfans.oms.server.common.utils.CronExpression;
 import com.github.kfcfans.oms.server.core.InstanceManager;
 import com.github.kfcfans.oms.server.core.akka.OhMyServer;

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/web/controller/JobController.java
Patch:
@@ -2,7 +2,7 @@
 
 import com.github.kfcfans.common.ExecuteType;
 import com.github.kfcfans.common.ProcessorType;
-import com.github.kfcfans.oms.server.common.constans.TimeExpressionType;
+import com.github.kfcfans.common.TimeExpressionType;
 import com.github.kfcfans.oms.server.common.utils.CronExpression;
 import com.github.kfcfans.oms.server.persistence.repository.JobInfoRepository;
 import com.github.kfcfans.common.response.ResultDTO;

File: oh-my-scheduler-server/src/test/java/com/github/kfcfans/oms/server/test/RepositoryTest.java
Patch:
@@ -2,7 +2,7 @@
 
 import com.github.kfcfans.common.utils.NetUtils;
 import com.github.kfcfans.oms.server.common.constans.JobStatus;
-import com.github.kfcfans.oms.server.common.constans.TimeExpressionType;
+import com.github.kfcfans.common.TimeExpressionType;
 import com.github.kfcfans.oms.server.persistence.model.ExecuteLogDO;
 import com.github.kfcfans.oms.server.persistence.model.JobInfoDO;
 import com.github.kfcfans.oms.server.persistence.model.OmsLockDO;

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/actors/ProcessorTrackerActor.java
Patch:
@@ -44,6 +44,7 @@ private void onReceiveTaskTrackerStartTaskReq(TaskTrackerStartTaskReq req) {
         task.setTaskName(req.getTaskName());
         task.setTaskContent(req.getTaskContent());
         task.setFailedCnt(req.getTaskCurrentRetryNums());
+        task.setSubInstanceId(req.getSubInstanceId());
 
         processorTracker.submitTask(task);
     }

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/executor/ProcessorRunnable.java
Patch:
@@ -80,6 +80,7 @@ public void innerRun() {
                 BroadcastTaskPreExecuteFinishedReq spReq = new BroadcastTaskPreExecuteFinishedReq();
                 spReq.setTaskId(taskId);
                 spReq.setInstanceId(instanceId);
+                spReq.setSubInstanceId(task.getSubInstanceId());
 
                 try {
                     ProcessResult processResult = broadcastProcessor.preProcess(taskContext);

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/processor/ProcessorTracker.java
Patch:
@@ -75,7 +75,6 @@ public void submitTask(TaskDO newTask) {
 
         boolean success = false;
         // 1. 设置值并提交执行
-        newTask.setJobId(instanceInfo.getJobId());
         newTask.setInstanceId(instanceInfo.getInstanceId());
         newTask.setAddress(taskTrackerAddress);
 

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/tracker/task/TaskTrackerPool.java
Patch:
@@ -6,7 +6,7 @@
 import java.util.function.Function;
 
 /**
- * 持有 Processor 对象
+ * 持有 TaskTracker 对象
  *
  * @author tjq
  * @since 2020/3/24

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/persistence/TaskDO.java
Patch:
@@ -19,8 +19,9 @@ public class TaskDO {
     // 层次命名法，可以表示 Map 后的父子关系，如 0.1.2 代表 rootTask map 的第一个 task map 的第二个 task
     private String taskId;
 
-    private Long jobId;
     private Long instanceId;
+    // 秒级任务专用
+    private Long subInstanceId;
     // 任务名称
     private String taskName;
     // 任务对象（序列化后的二进制数据）
@@ -62,7 +63,6 @@ public String getUpdateSQL() {
     public String toString() {
         return "TaskDO{" +
                 "taskId='" + taskId + '\'' +
-                ", jobId='" + jobId + '\'' +
                 ", instanceId='" + instanceId + '\'' +
                 ", taskName='" + taskName + '\'' +
                 ", address='" + address + '\'' +

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/pojo/request/BroadcastTaskPreExecuteFinishedReq.java
Patch:
@@ -14,6 +14,7 @@
 public class BroadcastTaskPreExecuteFinishedReq implements Serializable {
 
     private Long instanceId;
+    private Long subInstanceId;
     private String taskId;
 
     private boolean success;

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/pojo/request/ProcessorMapTaskRequest.java
Patch:
@@ -22,6 +22,7 @@
 public class ProcessorMapTaskRequest implements Serializable {
 
     private Long instanceId;
+    private Long subInstanceId;
 
     private String taskName;
     private List<SubTask> subTasks;
@@ -37,6 +38,7 @@ public static class SubTask {
     public ProcessorMapTaskRequest(TaskDO parentTask, List<?> subTaskList, String taskName) {
 
         this.instanceId = parentTask.getInstanceId();
+        this.subInstanceId = parentTask.getSubInstanceId();
         this.taskName = taskName;
         this.subTasks = Lists.newLinkedList();
 

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/sdk/TaskContext.java
Patch:
@@ -18,8 +18,8 @@
 @Setter
 public class TaskContext {
 
-    private String jobId;
-    private String instanceId;
+    private Long instanceId;
+    private Long subInstanceId;
     private String taskId;
     private String taskName;
 
@@ -34,7 +34,7 @@ public class TaskContext {
 
 
     public String getDescription() {
-        return "jobId='" + jobId + '\'' +
+        return "subInstanceId='" + subInstanceId + '\'' +
                 ", instanceId='" + instanceId + '\'' +
                 ", taskId='" + taskId + '\'' +
                 ", taskName='" + taskName + '\'' +

File: oh-my-scheduler-worker/src/test/java/com/github/kfcfans/oms/PersistenceServiceTest.java
Patch:
@@ -29,8 +29,9 @@ public static void initTable() throws Exception {
             TaskDO task = new TaskDO();
             taskList.add(task);
 
-            task.setJobId(1L);
-            task.setInstanceId(10086L + ThreadLocalRandom.current().nextInt(2));
+            long instanceId = 10086L + ThreadLocalRandom.current().nextInt(2);
+            task.setSubInstanceId(instanceId);
+            task.setInstanceId(instanceId);
             task.setTaskId(i + "");
             task.setFailedCnt(0);
             task.setStatus(TaskStatus.WORKER_RECEIVED.getValue());

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/core/InstanceManager.java
Patch:
@@ -88,7 +88,7 @@ public static void updateStatus(TaskTrackerReportInstanceStatusReq req) {
             return;
         }
 
-        ExecuteLogDO updateEntity = getExecuteLogRepository().findById(instanceId).orElseGet(ExecuteLogDO::new);
+        ExecuteLogDO updateEntity = getExecuteLogRepository().findByInstanceId(instanceId);
         updateEntity.setStatus(newStatus.getV());
         updateEntity.setGmtModified(new Date());
 

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/DispatchService.java
Patch:
@@ -35,7 +35,7 @@ public class DispatchService {
     // 前三个状态都视为运行中
     private static final List<Integer> runningStatus = Lists.newArrayList(WAITING_DISPATCH.getV(), WAITING_WORKER_RECEIVE.getV(), RUNNING.getV());
 
-    private static final String FAILED_REASON = "%d instance is running";
+    private static final String TOO_MUCH_REASON = "too much instance(%d>%d)";
     private static final String NO_WORKER_REASON = "no worker available";
     private static final String EMPTY_RESULT = "";
 
@@ -48,7 +48,7 @@ public void dispatch(JobInfoDO jobInfo, long instanceId, long currentRunningTime
 
         // 超出最大同时运行限制，不执行调度
         if (runningInstanceCount > jobInfo.getMaxInstanceNum()) {
-            String result = String.format(FAILED_REASON, runningInstanceCount);
+            String result = String.format(TOO_MUCH_REASON, runningInstanceCount, jobInfo.getMaxInstanceNum());
             log.warn("[DispatchService] cancel dispatch job({}) due to too much instance(num={}) is running.", jobInfo, runningInstanceCount);
             executeLogRepository.update4Trigger(instanceId, FAILED.getV(), currentRunningTimes, result);
 

File: oh-my-scheduler-server/src/main/java/com/github/kfcfans/oms/server/service/timing/schedule/JobScheduleService.java
Patch:
@@ -80,7 +80,7 @@ public void timingSchedule() {
 
         // 调度 FIX_RATE 和 FIX_DELAY JOB
         try {
-            scheduleFrequentJob(allAppIds);
+//            scheduleFrequentJob(allAppIds);
         }catch (Exception e) {
             log.error("[JobScheduleService] schedule frequent job failed.", e);
         }

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/persistence/TaskDAOImpl.java
Patch:
@@ -1,9 +1,7 @@
 package com.github.kfcfans.oms.worker.persistence;
 
-import com.github.kfcfans.common.utils.CommonUtils;
 import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
-import org.springframework.util.CollectionUtils;
 
 import java.sql.*;
 import java.util.Collection;

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/executor/ProcessorRunnable.java
Patch:
@@ -25,6 +25,7 @@
 import org.springframework.beans.BeanUtils;
 
 import java.util.Map;
+import java.util.concurrent.atomic.AtomicLong;
 
 /**
  * Processor 执行器
@@ -57,6 +58,7 @@ public void run() {
                 taskContext.setSubTask(SerializerUtils.deSerialized(request.getSubTaskContent()));
             }
             ThreadLocalStore.TASK_CONTEXT_THREAD_LOCAL.set(taskContext);
+            ThreadLocalStore.TASK_ID_THREAD_LOCAL.set(new AtomicLong(0));
 
             reportStatus(TaskStatus.PROCESSING, null);
 

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/persistence/ConnectionFactory.java
Patch:
@@ -36,7 +36,7 @@ private static DataSource getDataSource() {
                 // 池中最小空闲连接数量
                 config.setMinimumIdle(2);
                 // 池中最大连接数量
-                config.setMaximumPoolSize(16);
+                config.setMaximumPoolSize(32);
                 dataSource = new HikariDataSource(config);
             }
         }

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/persistence/TaskDAOImpl.java
Patch:
@@ -66,7 +66,7 @@ public boolean batchSave(Collection<TaskDO> tasks) {
 
     @Override
     public int batchDelete(String instanceId, List<String> taskIds) {
-        String deleteSQL = "delete from task_info where instance_id = %s and task_id in %s";
+        String deleteSQL = "delete from task_info where instance_id = '%s' and task_id in %s";
         String sql = String.format(deleteSQL, instanceId, getInStringCondition(taskIds));
         try (Connection conn = ConnectionFactory.getConnection(); Statement stat = conn.createStatement()) {
 

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/persistence/TaskDO.java
Patch:
@@ -63,7 +63,6 @@ public String toString() {
                 ", jobId='" + jobId + '\'' +
                 ", instanceId='" + instanceId + '\'' +
                 ", taskName='" + taskName + '\'' +
-                ", taskContent=" + (taskContent == null ? "" : new String(taskContent)) +
                 ", address='" + address + '\'' +
                 ", status=" + status +
                 ", result='" + result + '\'' +

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/common/request/TaskTrackerReportInstanceStatusReq.java
Patch:
@@ -2,14 +2,16 @@
 
 import lombok.Data;
 
+import java.io.Serializable;
+
 /**
  * TaskTracker 将状态上报给服务器
  *
  * @author tjq
  * @since 2020/3/17
  */
 @Data
-public class TaskTrackerReportInstanceStatusReq {
+public class TaskTrackerReportInstanceStatusReq implements Serializable {
 
     private String jobId;
     private String instanceId;

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/common/request/WorkerHealthReportReq.java
Patch:
@@ -3,14 +3,16 @@
 import com.github.kfcfans.common.model.SystemMetrics;
 import lombok.Data;
 
+import java.io.Serializable;
+
 /**
  * Worker 上报健康信息（worker定时发送的heartbeat）
  *
  * @author tjq
  * @since 2020/3/25
  */
 @Data
-public class WorkerHealthReportReq {
+public class WorkerHealthReportReq implements Serializable {
 
     // 本机地址 -> IP:port
     private String totalAddress;

File: oh-my-scheduler-common/src/main/java/com/github/kfcfans/common/response/AskResponse.java
Patch:
@@ -4,6 +4,8 @@
 import lombok.Data;
 import lombok.NoArgsConstructor;
 
+import java.io.Serializable;
+
 /**
  * Pattens.ask 的响应
  *
@@ -13,6 +15,6 @@
 @Data
 @NoArgsConstructor
 @AllArgsConstructor
-public class AskResponse {
+public class AskResponse implements Serializable {
     private boolean success;
 }

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/core/executor/ProcessorRunnable.java
Patch:
@@ -58,7 +58,7 @@ public void run() {
             }
             ThreadLocalStore.TASK_CONTEXT_THREAD_LOCAL.set(taskContext);
 
-            reportStatus(TaskStatus.WORKER_PROCESSING, null);
+            reportStatus(TaskStatus.PROCESSING, null);
 
             // 1. 获取 Processor
             BasicProcessor processor = getProcessor();
@@ -123,7 +123,7 @@ public void run() {
                     log.warn("[ProcessorRunnable] execute last task(instanceId={},taskId={}) failed.", instanceId, taskId, e);
                 }
 
-                TaskStatus status = lastResult.isSuccess() ? TaskStatus.WORKER_PROCESS_SUCCESS : TaskStatus.PROCESS_FAILED;
+                TaskStatus status = lastResult.isSuccess() ? TaskStatus.PROCESS_SUCCESS : TaskStatus.PROCESS_FAILED;
                 reportStatus(status, lastResult.getMsg());
 
                 log.info("[ProcessorRunnable] instance(instanceId={},taskId={})' last task execute successfully, using time: {}", instanceId, taskId, stopwatch);
@@ -139,7 +139,7 @@ public void run() {
                 log.warn("[ProcessorRunnable] task({}) process failed.", taskContext.getDescription(), e);
                 processResult = new ProcessResult(false, e.toString());
             }
-            reportStatus(processResult.isSuccess() ? TaskStatus.WORKER_PROCESS_SUCCESS : TaskStatus.PROCESS_FAILED, processResult.getMsg());
+            reportStatus(processResult.isSuccess() ? TaskStatus.PROCESS_SUCCESS : TaskStatus.PROCESS_FAILED, processResult.getMsg());
 
         }catch (Exception e) {
             log.error("[ProcessorRunnable] execute failed, please fix this bug!", e);

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/persistence/TaskPersistenceService.java
Patch:
@@ -97,8 +97,9 @@ public Map<TaskStatus, Long> getTaskStatusStatistics(String instanceId) {
 
         Map<TaskStatus, Long> result = Maps.newHashMap();
         dbRES.forEach(row -> {
-            int status = Integer.parseInt(String.valueOf(row.get("status")));
-            long num = Long.parseLong(String.valueOf(row.get("num")));
+            // H2 数据库都是大写...
+            int status = Integer.parseInt(String.valueOf(row.get("STATUS")));
+            long num = Long.parseLong(String.valueOf(row.get("NUM")));
             result.put(TaskStatus.of(status), num);
         });
         return result;

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/pojo/request/BroadcastTaskPreExecuteFinishedReq.java
Patch:
@@ -2,14 +2,16 @@
 
 import lombok.Data;
 
+import java.io.Serializable;
+
 /**
  * 广播任务 preExecute 结束信息
  *
  * @author tjq
  * @since 2020/3/23
  */
 @Data
-public class BroadcastTaskPreExecuteFinishedReq {
+public class BroadcastTaskPreExecuteFinishedReq implements Serializable {
 
     private String instanceId;
     private String taskId;

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/pojo/request/ProcessorMapTaskRequest.java
Patch:
@@ -8,6 +8,7 @@
 import lombok.Getter;
 import lombok.NoArgsConstructor;
 
+import java.io.Serializable;
 import java.util.List;
 
 /**
@@ -18,7 +19,7 @@
  */
 @Getter
 @NoArgsConstructor
-public class ProcessorMapTaskRequest {
+public class ProcessorMapTaskRequest implements Serializable {
 
     private String instanceId;
 

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/pojo/request/ProcessorReportTaskStatusReq.java
Patch:
@@ -2,14 +2,16 @@
 
 import lombok.Data;
 
+import java.io.Serializable;
+
 /**
  * worker 上报 task 执行情况
  *
  * @author tjq
  * @since 2020/3/17
  */
 @Data
-public class ProcessorReportTaskStatusReq {
+public class ProcessorReportTaskStatusReq implements Serializable {
 
     private String instanceId;
     private String taskId;

File: oh-my-scheduler-worker/src/main/java/com/github/kfcfans/oms/worker/pojo/request/TaskTrackerStopInstanceReq.java
Patch:
@@ -2,6 +2,8 @@
 
 import lombok.Data;
 
+import java.io.Serializable;
+
 /**
  * TaskTracker 停止 ProcessorTracker，释放相关资源
  * 任务执行完毕后停止 OR 手动强制停止
@@ -10,7 +12,7 @@
  * @since 2020/3/25
  */
 @Data
-public class TaskTrackerStopInstanceReq {
+public class TaskTrackerStopInstanceReq implements Serializable {
 
     private String instanceId;
     // 保留字段，暂时没用

