File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/StillImageActivity.java
Patch:
@@ -94,7 +94,7 @@ public final class StillImageActivity extends AppCompatActivity {
   private static final String TEXT_RECOGNITION_JAPANESE = "Text Recognition Japanese";
   private static final String TEXT_RECOGNITION_KOREAN = "Text Recognition Korean";
   private static final String FACE_MESH_DETECTION = "Face Mesh Detection (Beta)";
-  private static final String SUBJECT_SEGMENTATION = "Subject Segmentation";
+  private static final String SUBJECT_SEGMENTATION = "Subject Segmentation (Beta)";
 
   private static final String SIZE_SCREEN = "w:screen"; // Match screen width
   private static final String SIZE_1024_768 = "w:1024"; // ~1024*768 in a normal ratio

File: android/android-snippets/app/src/main/java/com/google/example/mlkit/BarcodeScanningActivity.java
Patch:
@@ -25,7 +25,7 @@
 import com.google.android.gms.tasks.OnFailureListener;
 import com.google.android.gms.tasks.OnSuccessListener;
 import com.google.android.gms.tasks.Task;
-import com.google.mlkit.vision.barcode.Barcode;
+import com.google.mlkit.vision.barcode.common.Barcode;
 import com.google.mlkit.vision.barcode.BarcodeScanner;
 import com.google.mlkit.vision.barcode.BarcodeScannerOptions;
 import com.google.mlkit.vision.barcode.BarcodeScanning;

File: android/android-snippets/app/src/main/java/com/google/example/mlkit/TextRecognitionActivity.java
Patch:
@@ -29,7 +29,7 @@
 import com.google.mlkit.vision.text.Text;
 import com.google.mlkit.vision.text.TextRecognition;
 import com.google.mlkit.vision.text.TextRecognizer;
-import com.google.mlkit.vision.text.TextRecognizerOptions;
+import com.google.mlkit.vision.text.latin.TextRecognizerOptions;
 
 public class TextRecognitionActivity extends AppCompatActivity {
 

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/CameraSource.java
Patch:
@@ -24,11 +24,11 @@
 import android.graphics.SurfaceTexture;
 import android.hardware.Camera;
 import android.hardware.Camera.CameraInfo;
-import androidx.annotation.Nullable;
 import android.util.Log;
 import android.view.Surface;
 import android.view.SurfaceHolder;
 import android.view.WindowManager;
+import androidx.annotation.Nullable;
 import androidx.annotation.RequiresPermission;
 import com.google.android.gms.common.images.Size;
 import com.google.mlkit.vision.demo.preference.PreferenceUtils;

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/VisionImageProcessor.java
Patch:
@@ -17,8 +17,6 @@
 package com.google.mlkit.vision.demo;
 
 import android.graphics.Bitmap;
-import android.os.Build.VERSION_CODES;
-import androidx.annotation.RequiresApi;
 import androidx.camera.core.ImageProxy;
 import com.google.mlkit.common.MlKitException;
 import java.nio.ByteBuffer;
@@ -35,7 +33,6 @@ void processByteBuffer(
       throws MlKitException;
 
   /** Processes ImageProxy image data, e.g. used for CameraX live preview case. */
-  @RequiresApi(VERSION_CODES.KITKAT)
   void processImageProxy(ImageProxy image, GraphicOverlay graphicOverlay) throws MlKitException;
 
   /** Stops the underlying machine learning model and release resources. */

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/CameraXLivePreviewActivity.java
Patch:
@@ -19,7 +19,6 @@
 import android.content.Intent;
 import android.os.Build.VERSION_CODES;
 import android.os.Bundle;
-import androidx.annotation.Nullable;
 import androidx.appcompat.app.AppCompatActivity;
 import android.util.Log;
 import android.util.Size;
@@ -33,6 +32,7 @@
 import android.widget.Toast;
 import android.widget.ToggleButton;
 import androidx.annotation.NonNull;
+import androidx.annotation.Nullable;
 import androidx.annotation.RequiresApi;
 import androidx.camera.core.CameraInfoUnavailableException;
 import androidx.camera.core.CameraSelector;

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/VisionProcessorBase.java
Patch:
@@ -25,11 +25,11 @@
 import android.graphics.Bitmap;
 import android.os.Build.VERSION_CODES;
 import android.os.SystemClock;
-import androidx.annotation.Nullable;
 import android.util.Log;
 import android.widget.Toast;
 import androidx.annotation.GuardedBy;
 import androidx.annotation.NonNull;
+import androidx.annotation.Nullable;
 import androidx.annotation.RequiresApi;
 import androidx.camera.core.ExperimentalGetImage;
 import androidx.camera.core.ImageProxy;

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/facedetector/FaceGraphic.java
Patch:
@@ -254,6 +254,7 @@ public void draw(Canvas canvas) {
     drawFaceLandmark(canvas, FaceLandmark.RIGHT_EYE);
     drawFaceLandmark(canvas, FaceLandmark.LEFT_CHEEK);
     drawFaceLandmark(canvas, FaceLandmark.RIGHT_CHEEK);
+    drawFaceLandmark(canvas, FaceLandmark.LEFT_EAR);
   }
 
   private void drawFaceLandmark(Canvas canvas, @LandmarkType int landmarkType) {

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/CameraXLivePreviewPreferenceFragment.java
Patch:
@@ -25,8 +25,8 @@
 import android.os.Build.VERSION_CODES;
 import android.preference.ListPreference;
 import android.preference.PreferenceCategory;
-import androidx.annotation.Nullable;
 import android.util.Size;
+import androidx.annotation.Nullable;
 import androidx.annotation.RequiresApi;
 import androidx.annotation.StringRes;
 import androidx.camera.core.CameraSelector;

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/PreferenceUtils.java
Patch:
@@ -293,8 +293,7 @@ public static boolean showLanguageTag(Context context) {
 
   public static boolean preferGPUForPoseDetection(Context context) {
     SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
-    String prefKey =
-        context.getString(R.string.pref_key_pose_detector_prefer_gpu);
+    String prefKey = context.getString(R.string.pref_key_pose_detector_prefer_gpu);
     return sharedPreferences.getBoolean(prefKey, true);
   }
 

File: android/digitalink/app/src/main/java/com/google/mlkit/samples/vision/digitalink/DigitalInkMainActivity.java
Patch:
@@ -152,6 +152,7 @@ public void onDownloadedModelsChanged(Set<String> downloadedLanguageTags) {
       ModelLanguageContainer container = languageAdapter.getItem(i);
       container.setDownloaded(downloadedLanguageTags.contains(container.languageTag));
     }
+    languageAdapter.notifyDataSetChanged();
   }
 
   private ArrayAdapter<ModelLanguageContainer> populateLanguageAdapter() {

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/PreferenceUtils.java
Patch:
@@ -266,13 +266,13 @@ public static PoseDetectorOptionsBase getPoseDetectorOptionsForStillImage(Contex
   public static boolean shouldGroupRecognizedTextInBlocks(Context context) {
     SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
     String prefKey = context.getString(R.string.pref_key_group_recognized_text_in_blocks);
-    return sharedPreferences.getBoolean(prefKey, true);
+    return sharedPreferences.getBoolean(prefKey, false);
   }
 
   public static boolean showLanguageTag(Context context) {
     SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
     String prefKey = context.getString(R.string.pref_key_show_language_tag);
-    return sharedPreferences.getBoolean(prefKey, true);
+    return sharedPreferences.getBoolean(prefKey, false);
   }
 
   public static boolean shouldShowPoseDetectionInFrameLikelihoodLivePreview(Context context) {

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/PreferenceUtils.java
Patch:
@@ -266,13 +266,13 @@ public static PoseDetectorOptionsBase getPoseDetectorOptionsForStillImage(Contex
   public static boolean shouldGroupRecognizedTextInBlocks(Context context) {
     SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
     String prefKey = context.getString(R.string.pref_key_group_recognized_text_in_blocks);
-    return sharedPreferences.getBoolean(prefKey, true);
+    return sharedPreferences.getBoolean(prefKey, false);
   }
 
   public static boolean showLanguageTag(Context context) {
     SharedPreferences sharedPreferences = PreferenceManager.getDefaultSharedPreferences(context);
     String prefKey = context.getString(R.string.pref_key_show_language_tag);
-    return sharedPreferences.getBoolean(prefKey, true);
+    return sharedPreferences.getBoolean(prefKey, false);
   }
 
   public static boolean shouldShowPoseDetectionInFrameLikelihoodLivePreview(Context context) {

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/barcodescanner/BarcodeGraphic.java
Patch:
@@ -81,14 +81,14 @@ public void draw(Canvas canvas) {
 
     // Draws other object info.
     float lineHeight = TEXT_SIZE + (2 * STROKE_WIDTH);
-    float textWidth = barcodePaint.measureText(barcode.getRawValue());
+    float textWidth = barcodePaint.measureText(barcode.getDisplayValue());
     canvas.drawRect(
         rect.left - STROKE_WIDTH,
         rect.top - lineHeight,
         rect.left + textWidth + (2 * STROKE_WIDTH),
         rect.top,
         labelPaint);
     // Renders the barcode at the bottom of the box.
-    canvas.drawText(barcode.getRawValue(), rect.left, rect.top - STROKE_WIDTH, barcodePaint);
+    canvas.drawText(barcode.getDisplayValue(), rect.left, rect.top - STROKE_WIDTH, barcodePaint);
   }
 }

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/facedetector/FaceGraphic.java
Patch:
@@ -222,6 +222,7 @@ public void draw(Canvas canvas) {
           left,
           top + yLabelOffset,
           idPaints[colorID]);
+      yLabelOffset += lineHeight;
     }
     if (rightEye != null) {
       float rightEyeLeft =
@@ -237,7 +238,6 @@ public void draw(Canvas canvas) {
           rightEyeLeft,
           translateY(rightEye.getPosition().y) + ID_Y_OFFSET,
           idPaints[colorID]);
-      yLabelOffset += lineHeight;
     }
 
     canvas.drawText(

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/PreferenceUtils.java
Patch:
@@ -185,7 +185,7 @@ private static CustomObjectDetectorOptions getCustomObjectDetectorOptions(
     return builder.build();
   }
 
-  public static FaceDetectorOptions getFaceDetectorOptionsForLivePreview(Context context) {
+  public static FaceDetectorOptions getFaceDetectorOptions(Context context) {
     int landmarkMode =
         getModeTypePreferenceValue(
             context,

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/StillImagePreferenceFragment.java
Patch:
@@ -27,5 +27,6 @@ public class StillImagePreferenceFragment extends PreferenceFragment {
   public void onCreate(Bundle savedInstanceState) {
     super.onCreate(savedInstanceState);
     addPreferencesFromResource(R.xml.preference_still_image);
+    FaceDetectionUtils.setUpFaceDetectionPreferences(this, /* isStreamMode = */false);
   }
 }

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/StillImageActivity.java
Patch:
@@ -81,10 +81,10 @@ public final class StillImageActivity extends AppCompatActivity {
   private static final String POSE_DETECTION = "Pose Detection";
   private static final String SELFIE_SEGMENTATION = "Selfie Segmentation";
 
-  private static final String SIZE_ORIGINAL = "w:original"; // Original image size
   private static final String SIZE_SCREEN = "w:screen"; // Match screen width
   private static final String SIZE_1024_768 = "w:1024"; // ~1024*768 in a normal ratio
   private static final String SIZE_640_480 = "w:640"; // ~640*480 in a normal ratio
+  private static final String SIZE_ORIGINAL = "w:original"; // Original image size
 
   private static final String KEY_IMAGE_URI = "com.google.mlkit.vision.demo.KEY_IMAGE_URI";
   private static final String KEY_SELECTED_SIZE = "com.google.mlkit.vision.demo.KEY_SELECTED_SIZE";
@@ -95,7 +95,7 @@ public final class StillImageActivity extends AppCompatActivity {
   private ImageView preview;
   private GraphicOverlay graphicOverlay;
   private String selectedMode = OBJECT_DETECTION;
-  private String selectedSize = SIZE_ORIGINAL;
+  private String selectedSize = SIZE_SCREEN;
 
   boolean isLandScape;
 
@@ -235,10 +235,10 @@ public void onNothingSelected(AdapterView<?> arg0) {}
   private void populateSizeSelector() {
     Spinner sizeSpinner = findViewById(R.id.size_selector);
     List<String> options = new ArrayList<>();
-    options.add(SIZE_ORIGINAL);
     options.add(SIZE_SCREEN);
     options.add(SIZE_1024_768);
     options.add(SIZE_640_480);
+    options.add(SIZE_ORIGINAL);
 
     // Creating adapter for featureSpinner
     ArrayAdapter<String> dataAdapter = new ArrayAdapter<>(this, R.layout.spinner_style, options);

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/LivePreviewActivity.java
Patch:
@@ -67,14 +67,14 @@ public final class LivePreviewActivity extends AppCompatActivity
         OnItemSelectedListener,
         CompoundButton.OnCheckedChangeListener {
   private static final String OBJECT_DETECTION = "Object Detection";
-  private static final String OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Bird)";
+  private static final String OBJECT_DETECTION_CUSTOM = "Custom Object Detection";
   private static final String CUSTOM_AUTOML_OBJECT_DETECTION =
       "Custom AutoML Object Detection (Flower)";
   private static final String FACE_DETECTION = "Face Detection";
   private static final String TEXT_RECOGNITION = "Text Recognition";
   private static final String BARCODE_SCANNING = "Barcode Scanning";
   private static final String IMAGE_LABELING = "Image Labeling";
-  private static final String IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Bird)";
+  private static final String IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Birds)";
   private static final String CUSTOM_AUTOML_LABELING = "Custom AutoML Image Labeling (Flower)";
   private static final String POSE_DETECTION = "Pose Detection";
   private static final String SELFIE_SEGMENTATION = "Selfie Segmentation";
@@ -197,7 +197,7 @@ private void createCameraSource(String model) {
           Log.i(TAG, "Using Custom Object Detector Processor");
           LocalModel localModel =
               new LocalModel.Builder()
-                  .setAssetFilePath("custom_models/bird_classifier.tflite")
+                  .setAssetFilePath("custom_models/object_labeler.tflite")
                   .build();
           CustomObjectDetectorOptions customObjectDetectorOptions =
               PreferenceUtils.getCustomObjectDetectorOptionsForLivePreview(this, localModel);

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/objectdetector/ObjectGraphic.java
Patch:
@@ -53,7 +53,7 @@ public class ObjectGraphic extends Graphic {
   private final Paint[] textPaints;
   private final Paint[] labelPaints;
 
-  ObjectGraphic(GraphicOverlay overlay, DetectedObject object) {
+  public ObjectGraphic(GraphicOverlay overlay, DetectedObject object) {
     super(overlay);
 
     this.object = object;

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/SettingsActivity.java
Patch:
@@ -36,7 +36,9 @@ public enum LaunchSource {
     STILL_IMAGE(R.string.pref_screen_title_still_image, StillImagePreferenceFragment.class),
     CAMERAX_LIVE_PREVIEW(
         R.string.pref_screen_title_camerax_live_preview,
-        CameraXLivePreviewPreferenceFragment.class);
+        CameraXLivePreviewPreferenceFragment.class),
+    CAMERAXSOURCE_DEMO(
+        R.string.pref_screen_title_cameraxsource_demo, CameraXSourceDemoPreferenceFragment.class);
 
     private final int titleResId;
     private final Class<? extends PreferenceFragment> prefFragmentClass;

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/LivePreviewActivity.java
Patch:
@@ -67,14 +67,14 @@ public final class LivePreviewActivity extends AppCompatActivity
         OnItemSelectedListener,
         CompoundButton.OnCheckedChangeListener {
   private static final String OBJECT_DETECTION = "Object Detection";
-  private static final String OBJECT_DETECTION_CUSTOM = "Custom Object Detection (Bird)";
+  private static final String OBJECT_DETECTION_CUSTOM = "Custom Object Detection";
   private static final String CUSTOM_AUTOML_OBJECT_DETECTION =
       "Custom AutoML Object Detection (Flower)";
   private static final String FACE_DETECTION = "Face Detection";
   private static final String TEXT_RECOGNITION = "Text Recognition";
   private static final String BARCODE_SCANNING = "Barcode Scanning";
   private static final String IMAGE_LABELING = "Image Labeling";
-  private static final String IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Bird)";
+  private static final String IMAGE_LABELING_CUSTOM = "Custom Image Labeling (Birds)";
   private static final String CUSTOM_AUTOML_LABELING = "Custom AutoML Image Labeling (Flower)";
   private static final String POSE_DETECTION = "Pose Detection";
   private static final String SELFIE_SEGMENTATION = "Selfie Segmentation";
@@ -197,7 +197,7 @@ private void createCameraSource(String model) {
           Log.i(TAG, "Using Custom Object Detector Processor");
           LocalModel localModel =
               new LocalModel.Builder()
-                  .setAssetFilePath("custom_models/bird_classifier.tflite")
+                  .setAssetFilePath("custom_models/object_labeler.tflite")
                   .build();
           CustomObjectDetectorOptions customObjectDetectorOptions =
               PreferenceUtils.getCustomObjectDetectorOptionsForLivePreview(this, localModel);

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/objectdetector/ObjectGraphic.java
Patch:
@@ -53,7 +53,7 @@ public class ObjectGraphic extends Graphic {
   private final Paint[] textPaints;
   private final Paint[] labelPaints;
 
-  ObjectGraphic(GraphicOverlay overlay, DetectedObject object) {
+  public ObjectGraphic(GraphicOverlay overlay, DetectedObject object) {
     super(overlay);
 
     this.object = object;

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/preference/SettingsActivity.java
Patch:
@@ -36,7 +36,9 @@ public enum LaunchSource {
     STILL_IMAGE(R.string.pref_screen_title_still_image, StillImagePreferenceFragment.class),
     CAMERAX_LIVE_PREVIEW(
         R.string.pref_screen_title_camerax_live_preview,
-        CameraXLivePreviewPreferenceFragment.class);
+        CameraXLivePreviewPreferenceFragment.class),
+    CAMERAXSOURCE_DEMO(
+        R.string.pref_screen_title_cameraxsource_demo, CameraXSourceDemoPreferenceFragment.class);
 
     private final int titleResId;
     private final Class<? extends PreferenceFragment> prefFragmentClass;

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/InferenceInfoGraphic.java
Patch:
@@ -48,6 +48,7 @@ public InferenceInfoGraphic(
     textPaint = new Paint();
     textPaint.setColor(TEXT_COLOR);
     textPaint.setTextSize(TEXT_SIZE);
+    textPaint.setShadowLayer(5.0f, 0f, 0f, Color.BLACK);
     postInvalidate();
   }
 

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/java/posedetector/PoseGraphic.java
Patch:
@@ -70,6 +70,7 @@ public class PoseGraphic extends Graphic {
     classificationTextPaint = new Paint();
     classificationTextPaint.setColor(Color.WHITE);
     classificationTextPaint.setTextSize(POSE_CLASSIFICATION_TEXT_SIZE);
+    classificationTextPaint.setShadowLayer(5.0f, 0f, 0f, Color.BLACK);
 
     whitePaint = new Paint();
     whitePaint.setStrokeWidth(STROKE_WIDTH);

File: android/android-snippets/app/src/main/java/com/google/example/mlkit/BarcodeScanningActivity.java
Patch:
@@ -94,7 +94,7 @@ public void onFailure(@NonNull Exception e) {
                         // Task failed with an exception
                         // ...
                     }
-                        });
+                });
         // [END run_detector]
     }
 

File: android/android-snippets/app/src/main/java/com/google/example/mlkit/FaceDetectionActivity.java
Patch:
@@ -46,7 +46,7 @@ private void detectFaces(InputImage image) {
         // [START set_detector_options]
         FaceDetectorOptions options =
                 new FaceDetectorOptions.Builder()
-                        .setClassificationMode(FaceDetectorOptions.PERFORMANCE_MODE_ACCURATE)
+                        .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_ACCURATE)
                         .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_ALL)
                         .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)
                         .setMinFaceSize(0.15f)

File: android/automl/app/src/main/java/com/google/mlkit/vision/automl/demo/BitmapUtils.java
Patch:
@@ -34,6 +34,7 @@
 
 import androidx.annotation.Nullable;
 import androidx.annotation.RequiresApi;
+import androidx.camera.core.ExperimentalGetImage;
 import androidx.camera.core.ImageProxy;
 import androidx.exifinterface.media.ExifInterface;
 
@@ -78,6 +79,7 @@ public static Bitmap getBitmap(ByteBuffer data, FrameMetadata metadata) {
      */
     @RequiresApi(VERSION_CODES.KITKAT)
     @Nullable
+    @ExperimentalGetImage
     public static Bitmap getBitmap(ImageProxy image) {
         FrameMetadata frameMetadata = new FrameMetadata.Builder()
                 .setWidth(image.getWidth())

File: android/vision-quickstart/app/src/main/java/com/google/mlkit/vision/demo/BitmapUtils.java
Patch:
@@ -34,6 +34,7 @@
 
 import androidx.annotation.Nullable;
 import androidx.annotation.RequiresApi;
+import androidx.camera.core.ExperimentalGetImage;
 import androidx.camera.core.ImageProxy;
 import androidx.exifinterface.media.ExifInterface;
 
@@ -78,6 +79,7 @@ public static Bitmap getBitmap(ByteBuffer data, FrameMetadata metadata) {
      */
     @RequiresApi(VERSION_CODES.KITKAT)
     @Nullable
+    @ExperimentalGetImage
     public static Bitmap getBitmap(ImageProxy image) {
         FrameMetadata frameMetadata = new FrameMetadata.Builder()
                 .setWidth(image.getWidth())

File: android/smartreply/app/src/main/java/com/google/mlkit/samples/smartreply/java/chat/ChatFragment.java
Patch:
@@ -138,14 +138,14 @@ public void onClick(View view) {
             }
         });
 
-        mViewModel.getSuggestions().observe(this, new Observer<List<SmartReplySuggestion>>() {
+        mViewModel.getSuggestions().observe(getViewLifecycleOwner(), new Observer<List<SmartReplySuggestion>>() {
             @Override
             public void onChanged(List<SmartReplySuggestion> suggestions) {
                mChipAdapter.setSuggestions(suggestions);
             }
         });
 
-        mViewModel.getMessages().observe(this, new Observer<List<Message>>() {
+        mViewModel.getMessages().observe(getViewLifecycleOwner(), new Observer<List<Message>>() {
             @Override
             public void onChanged(List<Message> messages) {
                 mChatAdapter.setMessages(messages);
@@ -155,7 +155,7 @@ public void onChanged(List<Message> messages) {
             }
         });
 
-        mViewModel.getEmulatingRemoteUser().observe(this, new Observer<Boolean>() {
+        mViewModel.getEmulatingRemoteUser().observe(getViewLifecycleOwner(), new Observer<Boolean>() {
             @Override
             public void onChanged(Boolean isEmulatingRemoteUser) {
                 if (isEmulatingRemoteUser) {

File: android/smartreply/app/src/main/java/com/google/mlkit/samples/smartreply/java/chat/ChatFragment.java
Patch:
@@ -138,14 +138,14 @@ public void onClick(View view) {
             }
         });
 
-        mViewModel.getSuggestions().observe(this, new Observer<List<SmartReplySuggestion>>() {
+        mViewModel.getSuggestions().observe(getViewLifecycleOwner(), new Observer<List<SmartReplySuggestion>>() {
             @Override
             public void onChanged(List<SmartReplySuggestion> suggestions) {
                mChipAdapter.setSuggestions(suggestions);
             }
         });
 
-        mViewModel.getMessages().observe(this, new Observer<List<Message>>() {
+        mViewModel.getMessages().observe(getViewLifecycleOwner(), new Observer<List<Message>>() {
             @Override
             public void onChanged(List<Message> messages) {
                 mChatAdapter.setMessages(messages);
@@ -155,7 +155,7 @@ public void onChanged(List<Message> messages) {
             }
         });
 
-        mViewModel.getEmulatingRemoteUser().observe(this, new Observer<Boolean>() {
+        mViewModel.getEmulatingRemoteUser().observe(getViewLifecycleOwner(), new Observer<Boolean>() {
             @Override
             public void onChanged(Boolean isEmulatingRemoteUser) {
                 if (isEmulatingRemoteUser) {

File: android/android-snippets/app/src/main/java/com/google/example/mlkit/FaceDetectionActivity.java
Patch:
@@ -56,6 +56,8 @@ private void detectFaces(InputImage image) {
 
         // [START get_detector]
         FaceDetector detector = FaceDetection.getClient(options);
+        // Or, to use the default option:
+        // FaceDetector detector = FaceDetection.getClient();
         // [END get_detector]
 
         // [START run_detector]

File: android/android-snippets/app/src/main/java/com/google/example/mlkit/FaceDetectionActivity.java
Patch:
@@ -56,6 +56,8 @@ private void detectFaces(InputImage image) {
 
         // [START get_detector]
         FaceDetector detector = FaceDetection.getClient(options);
+        // Or, to use the default option:
+        // FaceDetector detector = FaceDetection.getClient();
         // [END get_detector]
 
         // [START run_detector]

