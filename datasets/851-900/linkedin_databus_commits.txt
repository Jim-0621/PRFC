File: databus-core/databus-core-impl/src/main/java/com/linkedin/databus/core/DbusEventBuffer.java
Patch:
@@ -3400,6 +3400,7 @@ private int readEventsInternal(ReadableByteChannel readChannel,
                       writePos.moveToNextBuffer();
                       _tail.copy(_currentWritePosition);
                       assert assertBuffersLimits();
+                      preEndPeriodEvent = false;
                     }
                   }
                   else

File: databus-core/databus-core-impl/src/main/java/com/linkedin/databus/core/DbusEventBuffer.java
Patch:
@@ -3400,6 +3400,7 @@ private int readEventsInternal(ReadableByteChannel readChannel,
                       writePos.moveToNextBuffer();
                       _tail.copy(_currentWritePosition);
                       assert assertBuffersLimits();
+                      preEndPeriodEvent = false;
                     }
                   }
                   else

File: databus2-relay/databus2-event-producer-or/src/main/java/com/linkedin/databus2/producers/TransactionWriter.java
Patch:
@@ -115,6 +115,8 @@ public void run()
         }
       }
     }
+    log.info("transactionWriter thread done!");
+    doShutdownNotify();
   }
 
 }

File: databus2-relay/databus2-event-producer-or/src/main/java/com/linkedin/databus2/producers/ORListener.java
Patch:
@@ -535,7 +535,7 @@ private Object orToAvroType(Column s, Field avroField)
 		{
 			LongLongColumn llc = (LongLongColumn) s;
 			BigInteger b = new BigInteger(llc.getValue() + "");
-			return b.add(new BigInteger(unsignedOffset(s, avroField) + ""));
+			return b.add(new BigInteger(unsignedOffset(s, avroField) + "")).longValue();
 		}
 		return Long.parseLong(s.getValue() + "") + unsignedOffset(s, avroField);
 	}

File: databus2-relay/databus2-event-producer-or/src/main/java/com/linkedin/databus2/producers/ORListener.java
Patch:
@@ -535,7 +535,7 @@ private Object orToAvroType(Column s, Field avroField)
 		{
 			LongLongColumn llc = (LongLongColumn) s;
 			BigInteger b = new BigInteger(llc.getValue() + "");
-			return b.add(new BigInteger(unsignedOffset(s, avroField) + ""));
+			return b.add(new BigInteger(unsignedOffset(s, avroField) + "")).longValue();
 		}
 		return Long.parseLong(s.getValue() + "") + unsignedOffset(s, avroField);
 	}

File: databus-util-cmdline/databus-util-cmdline-impl/src/main/java/com/linkedin/databus/util/FieldToAvro.java
Patch:
@@ -202,7 +202,7 @@ private Map<String, Object> simpleTypeToAvro(FieldInfo fieldInfo, SimpleTypeInfo
     field.put("default", null);
 
     // Field type
-    String[] type = new String[] { "null", typeInfo.getPrimitiveType().getAvroType() };
+    String[] type = new String[] {"null", typeInfo.getPrimitiveType().getAvroType()};
     field.put("type", type);
 
     // Field metadata

File: databus-util-cmdline/databus-util-cmdline-impl/src/main/java/com/linkedin/databus/util/FieldToAvro.java
Patch:
@@ -202,7 +202,7 @@ private Map<String, Object> simpleTypeToAvro(FieldInfo fieldInfo, SimpleTypeInfo
     field.put("default", null);
 
     // Field type
-    String[] type = new String[] { "null", typeInfo.getPrimitiveType().getAvroType() };
+    String[] type = new String[] { typeInfo.getPrimitiveType().getAvroType(), "null"};
     field.put("type", type);
 
     // Field metadata

File: databus-util-cmdline/databus-util-cmdline-impl/src/main/java/com/linkedin/databus/util/AvroPrimitiveTypes.java
Patch:
@@ -57,7 +57,8 @@ public enum AvroPrimitiveTypes
   INT("long"),
   INT_UNSIGNED("long"),
   BIGINT("long"),
-  BIGINT_UNSIGNED("long");
+  BIGINT_UNSIGNED("long"),
+  YEAR("int");
 
   private final String _avroType;
   private AvroPrimitiveTypes(String avroType)

File: databus-util-cmdline/databus-util-cmdline-impl/src/main/java/com/linkedin/databus/util/AvroPrimitiveTypes.java
Patch:
@@ -57,7 +57,8 @@ public enum AvroPrimitiveTypes
   INT("long"),
   INT_UNSIGNED("long"),
   BIGINT("long"),
-  BIGINT_UNSIGNED("long");
+  BIGINT_UNSIGNED("long"),
+  YEAR("int");
 
   private final String _avroType;
   private AvroPrimitiveTypes(String avroType)

File: databus2-relay/databus2-event-producer-or/src/main/java/com/linkedin/databus2/producers/OpenReplicatorEventProducer.java
Patch:
@@ -478,7 +478,7 @@ public void onEndTransaction(Transaction txn)
       try
       {
         addTxnToBuffer(txn);
-        _maxSCNReaderWriter.saveMaxScn(txn.getScn());
+        _maxSCNReaderWriter.saveMaxScn(txn.getIgnoredSourceScn()!=-1 ? txn.getIgnoredSourceScn() : txn.getScn());
       }
       catch (UnsupportedKeyException e)
       {

File: databus2-relay/databus2-event-producer-or/src/main/java/com/linkedin/databus2/producers/OpenReplicatorEventProducer.java
Patch:
@@ -478,7 +478,7 @@ public void onEndTransaction(Transaction txn)
       try
       {
         addTxnToBuffer(txn);
-        _maxSCNReaderWriter.saveMaxScn(txn.getScn());
+        _maxSCNReaderWriter.saveMaxScn(txn.getIgnoredSourceScn()!=-1 ? txn.getIgnoredSourceScn() : txn.getScn());
       }
       catch (UnsupportedKeyException e)
       {

File: databus-util-cmdline/databus-util-cmdline-impl/src/main/java/com/linkedin/databus/util/AvroPrimitiveTypes.java
Patch:
@@ -33,13 +33,15 @@ public enum AvroPrimitiveTypes
   LONG("long"),
   RAW("bytes"),
   FLOAT("float"),
+  DECIMAL("double"),
   DOUBLE("double"),
   CLOB("string"),
   VARCHAR("string"),
   VARCHAR2("string"),
   NVARCHAR("string"),
   NVARCHAR2("string"),
   TIMESTAMP("long"),
+  DATETIME("long"),
   CHAR("string"),
   DATE("long"),
   BLOB("bytes"),

File: databus2-relay/databus2-event-producer-or/src/main/java/com/linkedin/databus2/producers/OpenReplicatorAvroEventFactory.java
Patch:
@@ -143,6 +143,7 @@ protected byte[] serializeEvent(GenericRecord record)
     catch(RuntimeException ex)
     {
       // Avro likes to throw RuntimeExceptions instead of checked exceptions when serialization fails.
+      _log.error("Exception for record: " + record + " with schema: " + record.getSchema().getFullName());
       throw new EventCreationException("Failed to serialize the Avro GenericRecord", ex);
     }
 

File: databus2-relay/databus2-event-producer-or/src/main/java/com/linkedin/databus2/producers/OpenReplicatorEventProducer.java
Patch:
@@ -73,7 +73,7 @@
 public class OpenReplicatorEventProducer extends AbstractEventProducer
 {
   public static final Integer DEFAULT_MYSQL_PORT = 3306;
-  public static final Pattern PATH_PATTERN = Pattern.compile("/([0-9]+)/[a-z|A-Z|-]+");
+  public static final Pattern PATH_PATTERN = Pattern.compile("/([0-9]+)/[0-9a-zA-Z-]+");
 
   protected final Logger _log;
   private final OpenReplicator _or;
@@ -181,7 +181,7 @@ private ORMonitoredSourceInfo buildORMonitoredSourceInfo( LogicalSourceStaticCon
    * @return Bin Log Prefix
    * @throws InvalidConfigException if URI is incorrect or missing information
    */
-  static protected String processUri(URI uri, OpenReplicator or) throws InvalidConfigException
+  public static String processUri(URI uri, OpenReplicator or) throws InvalidConfigException
   {
     String userInfo = uri.getUserInfo();
     if (null == userInfo)

File: databus-client/databus-client-http/src/main/java/com/linkedin/databus/client/ChunkedBodyReadableByteChannel.java
Patch:
@@ -80,7 +80,7 @@ public void close() throws IOException
     {
       //awake anyone blocked waiting for chunks
       //getChunk() checks the _open flag and it will exit immediately.
-      _hasChunksCondition.signalAll();
+      signalNoMoreChunks();
       _hasChunkSpaceCondition.signalAll();
     }
     finally

File: databus-client/databus-client-http/src/main/java/com/linkedin/databus/client/ChunkedBodyReadableByteChannel.java
Patch:
@@ -80,7 +80,7 @@ public void close() throws IOException
     {
       //awake anyone blocked waiting for chunks
       //getChunk() checks the _open flag and it will exit immediately.
-      _hasChunksCondition.signalAll();
+      signalNoMoreChunks();
       _hasChunkSpaceCondition.signalAll();
     }
     finally

File: databus-bootstrap-utils/databus-bootstrap-utils-impl/src/main/java/com/linkedin/databus/bootstrap/utils/BootstrapSeederMain.java
Patch:
@@ -157,10 +157,10 @@ public static void init(String[] args)
 	    try
 	    {
 	    	Class oracleDataSourceClass = OracleJarUtils.loadClass("oracle.jdbc.pool.OracleDataSource");
-	    	Object ods = oracleDataSourceClass.newInstance(); 	  
-	    	_sDataStore = (DataSource) ods;
+	    	Object ods = oracleDataSourceClass.newInstance();
 		    Method setURLMethod = oracleDataSourceClass.getMethod("setURL", String.class);
-		    setURLMethod.invoke(_sDataStore, uri);
+		    setURLMethod.invoke(ods, uri);
+	    	_sDataStore = (DataSource) ods;
 	    } catch (Exception e)
 	    {
 	    	String errMsg = "Error creating a data source object ";

File: databus2-relay/databus2-relay-impl/src/main/java/com/linkedin/databus2/relay/OracleEventProducerFactory.java
Patch:
@@ -68,7 +68,7 @@ public EventProducer buildEventProducer(PhysicalSourceStaticConfig physicalSourc
     DataSource ds = null;
     try
     {
-        OracleJarUtils.createOracleDataSource(uri);    	
+        ds = OracleJarUtils.createOracleDataSource(uri);    	
     } catch (Exception e)
     {
     	String errMsg = "Oracle URI likely not supported. Trouble creating OracleDataSource";

File: databus2-relay/databus2-relay-impl/src/main/java/com/linkedin/databus2/relay/MonitoringEventProducer.java
Patch:
@@ -303,8 +303,8 @@ private DataSource createOracleDataSource(String uri)
 		  ds = (DataSource) ods;
 
 		  Method setURLMethod = oracleDataSourceClass.getMethod("setURL", String.class);
-		  Method setConnectionPropertiesMethod = oracleDataSourceClass.getMethod("getConnectionProperties");
-		  Method getConnectionPropertiesMethod = oracleDataSourceClass.getMethod("setConnectionProperties", Properties.class);
+		  Method getConnectionPropertiesMethod = oracleDataSourceClass.getMethod("getConnectionProperties");
+		  Method setConnectionPropertiesMethod = oracleDataSourceClass.getMethod("setConnectionProperties", Properties.class);
 		  setURLMethod.invoke(ods, uri);
 		  // DDS-425. Set oracle.jdbc.V8Compatible so DATE column will be mapped to java.sql.TimeStamp
 		  //          oracle jdbc 11g fixed this. So we can skip this after will upgrade jdbc to 11g.

File: databus-bootstrap-utils/databus-bootstrap-utils-impl/src/main/java/com/linkedin/databus/bootstrap/utils/BootstrapAuditMain.java
Patch:
@@ -855,7 +855,8 @@ public OracleTableReader(
 
 			   try
 			   {
-				   URL ojdbcJarFile = new URL("ojdbc6.jar");
+				   File file = new File("ojdbc6-11.2.0.2.0.jar");
+				   URL ojdbcJarFile = file.toURL();
 				   URLClassLoader cl = URLClassLoader.newInstance(new URL[]{ojdbcJarFile});
 				   _oraclePreparedStatementClass = cl.loadClass("oracle.jdbc.OraclePreparedStatement");
 				   _setLobPrefetchSizeMethod = _oraclePreparedStatementClass.getMethod("setLobPrefetchSize", int.class);

File: databus-bootstrap-utils/databus-bootstrap-utils-impl/src/main/java/com/linkedin/databus/bootstrap/utils/BootstrapAuditTester.java
Patch:
@@ -1,5 +1,6 @@
 package com.linkedin.databus.bootstrap.utils;
 
+import java.io.File;
 import java.lang.reflect.Method;
 import java.net.URL;
 import java.net.URLClassLoader;
@@ -130,7 +131,8 @@ else if(databaseFieldValue instanceof Date)
             	Method dateValueMethod = null;
             	try
             	{
-            		URL ojdbcJarFile = new URL("ojdbc6.jar");
+            		File file = new File("ojdbc6-11.2.0.2.0.jar");
+            		URL ojdbcJarFile = file.toURL();
             		URLClassLoader cl = URLClassLoader.newInstance(new URL[]{ojdbcJarFile});
             		timestampClass = cl.loadClass("oracle.sql.TIMESTAMP");    		 
             		dateClass = cl.loadClass("oracle.sql.DATE");

File: databus-bootstrap-utils/databus-bootstrap-utils-impl/src/main/java/com/linkedin/databus/bootstrap/utils/BootstrapSeederMain.java
Patch:
@@ -153,7 +153,9 @@ public static void init(String[] args)
 	    }
 
 	    // Create the OracleDataSource used to get DB connection(s)
-	    URL ojdbcJarFile = new URL("ojdbc6.jar");
+	    File file = new File("ojdbc6-11.2.0.2.0.jar");
+        URL ojdbcJarFile = file.toURL();
+
 	    URLClassLoader cl = URLClassLoader.newInstance(new URL[]{ojdbcJarFile});
 	    Class oracleDataSourceClass = cl.loadClass("oracle.jdbc.pool.OracleDataSource");
 	    Object ods = oracleDataSourceClass.newInstance(); 	  

File: databus-bootstrap-utils/databus-bootstrap-utils-impl/src/main/java/com/linkedin/databus/bootstrap/utils/BootstrapSrcDBEventReader.java
Patch:
@@ -140,7 +140,8 @@ public BootstrapSrcDBEventReader(DataSource dataSource,
 		_beginSrcKeyMap = config.getBeginSrcKeyMap();
 		_endSrcKeyMap = config.getEndSrcKeyMap();
 		
-		URL ojdbcJarFile = new URL("ojdbc6.jar");
+        File file = new File("ojdbc6-11.2.0.2.0.jar");
+		URL ojdbcJarFile = file.toURL();
 		URLClassLoader cl = URLClassLoader.newInstance(new URL[]{ojdbcJarFile});
 		_oraclePreparedStatementClass = cl.loadClass("oracle.jdbc.OraclePreparedStatement");
 		_setLobPrefetchSizeMethod = _oraclePreparedStatementClass.getMethod("setLobPrefetchSize", int.class);

File: databus2-relay/databus2-relay-impl/src/main/java/com/linkedin/databus2/producers/db/OracleAvroGenericEventFactory.java
Patch:
@@ -4,6 +4,7 @@
 package com.linkedin.databus2.producers.db;
 
 import java.io.ByteArrayOutputStream;
+import java.io.File;
 import java.io.IOException;
 import java.io.Reader;
 import java.io.StringWriter;
@@ -495,7 +496,8 @@ else if(databaseFieldValue instanceof Date)
     	  Method dateValueMethod = null;
     	  try
     	  {
-    		  URL ojdbcJarFile = new URL("ojdbc6.jar");
+    		  File file = new File("ojdbc6-11.2.0.2.0.jar");
+    		  URL ojdbcJarFile = file.toURL();
     		  URLClassLoader cl = URLClassLoader.newInstance(new URL[]{ojdbcJarFile});
     		  timestampClass = cl.loadClass("oracle.sql.TIMESTAMP");    		 
     		  dateClass = cl.loadClass("oracle.sql.DATE");

File: databus2-relay/databus2-relay-impl/src/main/java/com/linkedin/databus2/relay/MonitoringEventProducer.java
Patch:
@@ -1,5 +1,6 @@
 package com.linkedin.databus2.relay;
 
+import java.io.File;
 import java.lang.reflect.Method;
 import java.net.URL;
 import java.net.URLClassLoader;
@@ -294,7 +295,8 @@ private DataSource createOracleDataSource(String uri)
 	  DataSource ds = null;
 	  try
 	  {
-		  URL ojdbcJarFile = new URL("ojdbc6.jar");
+		  File file = new File("ojdbc6-11.2.0.2.0.jar");
+		  URL ojdbcJarFile = file.toURL();
 		  URLClassLoader cl = URLClassLoader.newInstance(new URL[]{ojdbcJarFile});
 		  Class oracleDataSourceClass = cl.loadClass("oracle.jdbc.pool.OracleDataSource");
 		  Object ods = oracleDataSourceClass.newInstance(); 	  

File: databus-core/databus-core-impl/src/main/java/com/linkedin/databus/core/DbusEventBuffer.java
Patch:
@@ -4737,7 +4737,7 @@ public Config()
       _defaultMemUsage = DEFAULT_DEFAULT_MEMUSAGE;
 
       deriveSizesFromMemPct();
-      _allocationPolicy = getMaxSize() > 10000 ? "MMAPPED_MEMORY":"HEAP_MEMORY";
+      _allocationPolicy = getMaxSize() > 10000 ? "DIRECT_MEMORY":"HEAP_MEMORY";
       _mmapDirectory = DEFAULT_MMAP_DIRECTORY;
       _queuePolicy = DEFAULT_QUEUE_POLICY.toString();
       _trace = new RelayEventTraceOptionBuilder();

File: databus-core/databus-core-container/src/main/java/com/linkedin/databus2/core/container/netty/ServerContainer.java
Patch:
@@ -240,7 +240,7 @@ public ServerContainer(StaticConfig config) throws IOException, InvalidConfigExc
     _componentAdmin.registerAsMBean();
 
     _globalStatsMerger = new GlobalStatsCalc(GLOBAL_STATS_MERGE_INTERVAL_MS);
-    _globalStatsThread = new Thread(_globalStatsMerger, "GlogalStatsThread");
+    _globalStatsThread = new Thread(_globalStatsMerger, "GlobalStatsThread");
     _globalStatsThread.setDaemon(true);
 
     initializeContainerNetworking();

File: databus2-example/databus2-example-relay/src/main/java/com/linkedin/databus/relay/example/PersonRelayServer.java
Patch:
@@ -53,7 +53,7 @@ public PersonRelayServer(HttpRelay.StaticConfig config, PhysicalSourceStaticConf
    */
   public static void main(String[] args) throws Exception {
 	  
-		_dbRelayConfigFiles = new String[] { "config/sources-person.json" };
+		_dbRelayConfigFiles = new String[] { "conf/sources-person.json" };
 
 		 String [] leftOverArgs = processLocalArgs(args);
 

File: databus2-relay/databus2-relay-impl/src/main/java/com/linkedin/databus2/producers/RelayEventProducer.java
Patch:
@@ -190,6 +190,8 @@ public static DatabusSourcesConnection createDatabusSourcesConnection(
 		confBuilder.setId(id);
 		// consume whatever is in relay
 		confBuilder.setConsumeCurrent(true);
+		//this is set to false as the behaviour is to read the latest SCN when SCN is not found, the buffer isn't cleared
+		//as such , so a possibility of gaps in events arises. What we want ideally is to clear existing buffer and then consume from latest SCN
 		confBuilder.setReadLatestScnOnError(false);
 		// set size of largest expected event
 		confBuilder.setFreeBufferThreshold(largestEventSize);
@@ -206,6 +208,7 @@ public static DatabusSourcesConnection createDatabusSourcesConnection(
 		bufferConf.setMaxSize(internalBufferMaxSize);
 		int readBufferSize = Math.max((int)(0.2*internalBufferMaxSize), 2*largestEventSize);
 		bufferConf.setReadBufferSize(readBufferSize);
+		bufferConf.setAllocationPolicy("DIRECT_MEMORY");
 		//client buffer's scn index- not used
 		bufferConf.setScnIndexSize(64*1024);
 		String queuePolicy = blockingBuffer ? "BLOCK_ON_WRITE"

File: databus2-relay/databus2-relay-impl/src/main/java/com/linkedin/databus2/producers/RelayEventProducer.java
Patch:
@@ -190,6 +190,8 @@ public static DatabusSourcesConnection createDatabusSourcesConnection(
 		confBuilder.setId(id);
 		// consume whatever is in relay
 		confBuilder.setConsumeCurrent(true);
+		//this is set to false as the behaviour is to read the latest SCN when SCN is not found, the buffer isn't cleared
+		//as such , so a possibility of gaps in events arises. What we want ideally is to clear existing buffer and then consume from latest SCN
 		confBuilder.setReadLatestScnOnError(false);
 		// set size of largest expected event
 		confBuilder.setFreeBufferThreshold(largestEventSize);
@@ -206,6 +208,7 @@ public static DatabusSourcesConnection createDatabusSourcesConnection(
 		bufferConf.setMaxSize(internalBufferMaxSize);
 		int readBufferSize = Math.max((int)(0.2*internalBufferMaxSize), 2*largestEventSize);
 		bufferConf.setReadBufferSize(readBufferSize);
+		bufferConf.setAllocationPolicy("DIRECT_MEMORY");
 		//client buffer's scn index- not used
 		bufferConf.setScnIndexSize(64*1024);
 		String queuePolicy = blockingBuffer ? "BLOCK_ON_WRITE"

File: databus-core/databus-core-impl/src/main/java/com/linkedin/databus/core/DbusEventBuffer.java
Patch:
@@ -588,7 +588,7 @@ private void copyBufferEndpoints() throws InterruptedException, TimeoutException
             _currentPosition.copy(_head);
           }
 
-          if ( _currentPosition.getPosition() < _head.getPosition())
+          if (empty() || _currentPosition.getPosition() < _head.getPosition())
           {
         	  _currentPosition.copy(_head);
           }

File: databus-client/databus-client-http/src/main/java/com/linkedin/databus/client/BootstrapPullThread.java
Patch:
@@ -225,7 +225,7 @@ private void doSetSourcesSchemas(SourcesMessage sourcesMessage)
                                DispatcherState.create().switchToStartDispatchEvents(
                                    _currentState.getSourceIdMap(),
                                    _currentState.getSourcesSchemas(),
-                                   _sourcesConn.getBootstrapEventsBuffer().acquireIterator(getName() + ".DispatcherIterator")));
+                                   _currentState.getDataEventsBuffer()));
   }
 
   private void doSetSourcesIds(SourcesMessage sourcesMessage)

File: databus-client/databus-client-http/src/main/java/com/linkedin/databus/client/RelayPullThread.java
Patch:
@@ -545,7 +545,7 @@ protected void doRegisterResponseSuccess(ConnectionState curState)
           DispatcherState.create().switchToStartDispatchEvents(
               curState.getSourceIdMap(),
               curState.getSourcesSchemas(),
-              _sourcesConn.getDataEventsBuffer().acquireIterator(getName() + ".DispatcherIterator")));
+              curState.getDataEventsBuffer()));
 
       // Determine the checkpoint for read events in the following order
       // 1. Existing checkpoint in the current state

File: databus-core/databus-core-impl/src/main/java/com/linkedin/databus/core/DbusEventBufferStreamAppendable.java
Patch:
@@ -12,7 +12,7 @@ public interface DbusEventBufferStreamAppendable
 {
 
   /*
-   * Stream events to buffer
+   * Read events from a channel and append them to a buffer.
    * @param readChannel : ByteChannel to read events from
    * @param eventListeners : List of listeners interested in the events in the channel
    * @param statsCollector : Stats Collector for this event

File: databus-core/databus-core-impl/src/main/java/com/linkedin/databus/core/util/BufferPosition.java
Patch:
@@ -147,8 +147,9 @@ public long incrementGenId()
   }
 
   /*
-   * Increment the index in the stored address by 1.
-   * If we reach the end of the bufferIndex, the genId will be incremented by 1 and index/offset reset.
+   * Moves the position to the beginning of the next ByteBuffer.
+   * If we reach the end of the bufferIndex, the genId will be incremented by 1 and index/offset 
+   * reset.
    *
    * @return the position with the incremented index
    */

File: databus-core/databus-core-impl/src/main/java/com/linkedin/databus/core/util/BufferPositionParser.java
Patch:
@@ -227,14 +227,13 @@ public long incrementGenId(long currentPosition)
 
 
   /*
-   * increment the index stored in the position by 1
+   * Generates the gen-id position at the beginning of the next ByteBuffer.
    *
    * @param position position to be incremented
    * @param buffers the list of buffers in the eventBuffer which is the universe for the position
    * @return the incremented position
    */
-  public long incrementIndex(long currentPosition,
-                             ByteBuffer[] buffers)
+  public long incrementIndex(long currentPosition, ByteBuffer[] buffers)
   {
     int bufferIndex = bufferIndex(currentPosition);
     int nextIndex = (bufferIndex +1) % buffers.length;

File: databus-core/databus-core-impl/src/main/java/com/linkedin/databus2/core/DatabusException.java
Patch:
@@ -4,8 +4,7 @@
 package com.linkedin.databus2.core;
 
 /**
- * @author Jemiah Westerman<jwesterman@linkedin.com>
- * @version $Revision: 168967 $
+ * Generic Databus exception
  */
 public class DatabusException
     extends Exception

