File: logstash-core/src/test/java/org/logstash/log/LogstashConfigurationFactoryTest.java
Patch:
@@ -59,6 +59,7 @@ public static void afterClass() {
         ThreadContext.putAll(dumpedLog4jThreadContext);
         snapshotHelper.restoreSnapshot("log4j.configurationFile", "ls.log.format", "ls.logs",
                 LogstashConfigurationFactory.PIPELINE_SEPARATE_LOGS);
+        forceLog4JContextRefresh();
     }
 
     @Before
@@ -123,7 +124,7 @@ public void testDisableAppenderPerPipelineIsCreatedAfterLogLine() {
         assertNull("No routing appender should be present", routingApp);
     }
 
-    private void forceLog4JContextRefresh() {
+    private static void forceLog4JContextRefresh() {
         LoggerContext context = LoggerContext.getContext(false);
         context.reconfigure();
     }

File: logstash-core/src/test/java/org/logstash/log/PluginDeprecationLoggerTest.java
Patch:
@@ -48,6 +48,7 @@ public static void beforeClass() {
     public static void afterClass() {
         snapshotHelper.restoreSnapshot("log4j.configurationFile", "ls.log.format", "ls.logs",
                 LogstashConfigurationFactory.PIPELINE_SEPARATE_LOGS);
+        LogTestUtils.reloadLogConfiguration();
     }
 
     @Before

File: logstash-core/src/main/java/org/logstash/ext/JrubyWrappedSynchronousQueueExt.java
Patch:
@@ -22,6 +22,7 @@
 
 import java.util.concurrent.ArrayBlockingQueue;
 import java.util.concurrent.BlockingQueue;
+
 import org.jruby.Ruby;
 import org.jruby.RubyClass;
 import org.jruby.RubyNumeric;

File: logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java
Patch:
@@ -167,7 +167,7 @@ public class AbstractPipelineExt extends RubyBasicObject {
     private @SuppressWarnings("rawtypes") RubyArray outputs;
 
     private String lastErrorEvaluationReceived = "";
-    private DeadLetterQueueWriter javaDlqWriter;
+    private transient DeadLetterQueueWriter javaDlqWriter;
 
     public AbstractPipelineExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/settings/BaseSetting.java
Patch:
@@ -93,6 +93,8 @@ protected BaseSetting(String name, boolean strict, Predicate<T> validator) {
         this.strict = strict;
         this.validator = validator;
     }
+
+    @SuppressWarnings("this-escape")
     protected BaseSetting(String name, T defaultValue, boolean strict, Predicate<T> validator) {
         Objects.requireNonNull(name);
         Objects.requireNonNull(validator);

File: logstash-core/src/main/java/org/logstash/settings/Coercible.java
Patch:
@@ -22,6 +22,8 @@
 import java.util.function.Predicate;
 
 public abstract class Coercible<T> extends BaseSetting<T> {
+
+    @SuppressWarnings("this-escape")
     public Coercible(String name, T defaultValue, boolean strict, Predicate<T> validator) {
         super(name, strict, validator);
 

File: logstash-core/src/main/java/org/logstash/settings/SettingWithDeprecatedAlias.java
Patch:
@@ -48,6 +48,7 @@ static <T> List<Setting<T>> wrap(BaseSetting<T> canonicalSetting, String depreca
 
     private DeprecatedAlias<T> deprecatedAlias;
 
+    @SuppressWarnings("this-escape")
     protected SettingWithDeprecatedAlias(BaseSetting<T> canonicalSetting, String deprecatedAliasName) {
         super(canonicalSetting);
 

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/ComputeStepSyntaxElement.java
Patch:
@@ -207,7 +207,7 @@ private static Path debugDir() {
     }
 
     /**
-     * @return Array of constructor arguments
+     * @return Map of constructor arguments, key is field's name, value is the instance of the parameter to pass.
      */
     private Map<String, Object> ctorArguments() {
         final Map<String, Object> result = new HashMap<>();

File: logstash-core/src/test/java/org/logstash/config/ir/compiler/DatasetCompilerTest.java
Patch:
@@ -26,6 +26,7 @@
 import org.logstash.Event;
 import org.logstash.FieldReference;
 import org.logstash.RubyUtil;
+import org.logstash.config.ir.CompiledPipeline;
 import org.logstash.config.ir.PipelineTestUtil;
 import org.logstash.ext.JrubyEventExtLibrary;
 
@@ -54,7 +55,8 @@ public void compilesOutputDataset() {
     public void compilesSplitDataset() {
         final FieldReference key = FieldReference.from("foo");
         final SplitDataset left = DatasetCompiler.splitDataset(
-            Collections.emptyList(), event -> event.getEvent().includes(key)
+            Collections.emptyList(), event -> event.getEvent().includes(key),
+            new CompiledPipeline.NoopEvaluationListener()
         ).instantiate();
         final Event trueEvent = new Event();
         trueEvent.setField(key, "val");

File: logstash-core/src/main/java/org/logstash/config/ir/ConfigCompiler.java
Patch:
@@ -105,7 +105,7 @@ private static Map<PluginDefinition.Type, Statement> compileImperative(SourceWit
     }
 
     private static Statement readStatementFromRubyHash(RubyHash hash, String key) {
-        IRubyObject inputValue = hash.fastARef(RubyUtil.RUBY.newSymbol(key));
+        IRubyObject inputValue = hash.fastARef(RubyUtil.RUBY.newString(key).intern());
         return inputValue.toJava(Statement.class);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/PipelineConfig.java
Patch:
@@ -73,7 +73,7 @@ public PipelineConfig(RubyClass source, RubySymbol pipelineId, RubyObject uncast
                 RubyArray.newArray(RUBY, uncastedConfigParts);
 
         this.source = source;
-        this.pipelineId = pipelineId.toString();
+        this.pipelineId = pipelineId.name(RUBY.getCurrentContext()).asJavaString();
         SourceWithMetadata[] castedConfigParts = (SourceWithMetadata[]) configParts.toJava(SourceWithMetadata[].class);
         List<SourceWithMetadata> confParts = Arrays.asList(castedConfigParts);
         confParts.sort(Comparator.comparing(SourceWithMetadata::getProtocol)

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/AbstractOutputDelegatorExt.java
Patch:
@@ -128,7 +128,7 @@ protected void initMetrics(final String id, final AbstractMetricExt metric) {
         final ThreadContext context = RubyUtil.RUBY.getCurrentContext();
         this.id = RubyString.newString(context.runtime, id);
         synchronized (metric) {
-            namespacedMetric = metric.namespace(context, context.runtime.newSymbol(id));
+            namespacedMetric = metric.namespace(context, context.runtime.newString(id).intern());
             metricEvents = namespacedMetric.namespace(context, MetricKeys.EVENTS_KEY);
             namespacedMetric.gauge(context, MetricKeys.NAME_KEY, configName(context));
             eventMetricOut = LongCounter.fromRubyBase(metricEvents, MetricKeys.OUT_KEY);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/JavaFilterDelegatorExt.java
Patch:
@@ -65,7 +65,7 @@ public static JavaFilterDelegatorExt create(final String configName, final Strin
                 new JavaFilterDelegatorExt(RubyUtil.RUBY, RubyUtil.JAVA_FILTER_DELEGATOR_CLASS);
         instance.configName = RubyUtil.RUBY.newString(configName);
         AbstractNamespacedMetricExt scopedMetric =
-                metric.namespace(RubyUtil.RUBY.getCurrentContext(), RubyUtil.RUBY.newSymbol(filter.getId()));
+                metric.namespace(RubyUtil.RUBY.getCurrentContext(), RubyUtil.RUBY.newString(filter.getId()).intern());
         instance.initMetrics(id, scopedMetric);
         instance.filter = filter;
         instance.initializeFilterMatchListener(pluginArgs);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/JavaInputDelegatorExt.java
Patch:
@@ -60,7 +60,7 @@ public static JavaInputDelegatorExt create(final AbstractPipelineExt pipeline,
                                                final Map<String, Object> pluginArgs) {
         final JavaInputDelegatorExt instance =
                 new JavaInputDelegatorExt(RubyUtil.RUBY, RubyUtil.JAVA_INPUT_DELEGATOR_CLASS);
-        AbstractNamespacedMetricExt scopedMetric = metric.namespace(RubyUtil.RUBY.getCurrentContext(), RubyUtil.RUBY.newSymbol(input.getId()));
+        AbstractNamespacedMetricExt scopedMetric = metric.namespace(RubyUtil.RUBY.getCurrentContext(), RubyUtil.RUBY.newString(input.getId()).intern());
         scopedMetric.gauge(RubyUtil.RUBY.getCurrentContext(), MetricKeys.NAME_KEY, RubyUtil.RUBY.newString(input.getName()));
         instance.setMetric(RubyUtil.RUBY.getCurrentContext(), scopedMetric);
         instance.input = input;

File: logstash-core/src/main/java/org/logstash/ext/JRubyWrappedWriteClientExt.java
Patch:
@@ -77,7 +77,7 @@ public JRubyWrappedWriteClientExt initialize(final JRubyAbstractQueueWriteClient
                                                  final IRubyObject pluginId) {
         this.writeClient = queueWriteClientExt;
 
-        final RubySymbol pipelineIdSym = getRuntime().newSymbol(pipelineId);
+        final RubySymbol pipelineIdSym = getRuntime().newString(pipelineId).intern();
         final RubySymbol pluginIdSym = pluginId.asString().intern();
 
         // Synchronize on the metric since setting up new fields on it is not threadsafe

File: logstash-core/src/main/java/org/logstash/plugins/CounterMetricImpl.java
Patch:
@@ -34,7 +34,7 @@ public class CounterMetricImpl implements CounterMetric {
     public CounterMetricImpl(final ThreadContext threadContext,
                              final AbstractNamespacedMetricExt metrics,
                              final String metric) {
-        this.longCounter = LongCounter.fromRubyBase(metrics, threadContext.getRuntime().newSymbol(metric));
+        this.longCounter = LongCounter.fromRubyBase(metrics, threadContext.getRuntime().newString(metric).intern());
     }
 
     @Override

File: logstash-core/src/main/java/org/logstash/plugins/NamespacedMetricImpl.java
Patch:
@@ -64,7 +64,7 @@ public CounterMetric counter(final String metric) {
 
     @Override
     public co.elastic.logstash.api.TimerMetric timer(final String metric) {
-        return TimerMetric.fromRubyBase(metrics, threadContext.getRuntime().newSymbol(metric));
+        return TimerMetric.fromRubyBase(metrics, threadContext.getRuntime().newString(metric).intern());
     }
 
     @Override
@@ -121,7 +121,7 @@ public Metric root() {
     }
 
     private RubySymbol getSymbol(final String s) {
-        return this.threadContext.getRuntime().newSymbol(s);
+        return this.threadContext.getRuntime().newString(s).intern();
     }
 
     private IRubyObject convert(final Object o) {

File: logstash-core/src/main/java/org/logstash/plugins/RootMetricImpl.java
Patch:
@@ -23,6 +23,7 @@
 import co.elastic.logstash.api.Metric;
 import co.elastic.logstash.api.NamespacedMetric;
 import org.jruby.RubyArray;
+import org.jruby.RubyString;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.instrument.metrics.AbstractMetricExt;
@@ -45,7 +46,8 @@ public RootMetricImpl(final ThreadContext threadContext, final AbstractMetricExt
     @Override
     public NamespacedMetric namespace(final String... key) {
         final IRubyObject[] rubyfiedKeys = Stream.of(key)
-            .map(this.threadContext.getRuntime()::newSymbol)
+            .map(this.threadContext.getRuntime()::newString)
+            .map(RubyString::intern)
             .toArray(IRubyObject[]::new);
 
         return new NamespacedMetricImpl(

File: logstash-core/src/main/java/org/logstash/plugins/factory/PluginFactoryExt.java
Patch:
@@ -253,7 +253,7 @@ private IRubyObject plugin(final ThreadContext context,
             } else {
                 final IRubyObject pluginInstance = ContextualizerExt.initializePlugin(context, executionCntx, klass, rubyArgs);
 
-                final AbstractNamespacedMetricExt scopedMetric = typeScopedMetric.namespace(context, RubyUtil.RUBY.newSymbol(id));
+                final AbstractNamespacedMetricExt scopedMetric = typeScopedMetric.namespace(context, RubyUtil.RUBY.newString(id).intern());
                 scopedMetric.gauge(context, MetricKeys.NAME_KEY, pluginInstance.callMethod(context, "config_name"));
                 pluginInstance.callMethod(context, "metric=", scopedMetric);
                 return pluginInstance;

File: logstash-core/src/main/java/org/logstash/plugins/factory/PluginMetricsFactoryExt.java
Patch:
@@ -53,7 +53,7 @@ AbstractNamespacedMetricExt getRoot(final ThreadContext context) {
     @JRubyMethod
     public AbstractNamespacedMetricExt create(final ThreadContext context, final IRubyObject pluginType) {
         return getRoot(context).namespace(
-            context, RubyUtil.RUBY.newSymbol(String.format("%ss", pluginType.asJavaString()))
+            context, RubyUtil.RUBY.newString(String.format("%ss", pluginType.asJavaString())).intern()
         );
     }
 }

File: logstash-core/src/test/java/org/logstash/config/ir/PipelineConfigTest.java
Patch:
@@ -108,7 +108,7 @@ SourceWithMetadata[] orderedConfigParts() {
     public void setUp() throws IncompleteSourceWithMetadataException {
 
         source = RubyUtil.RUBY.getClass("LogStash::Config::Source::Local");
-        pipelineIdSym = RubySymbol.newSymbol(RubyUtil.RUBY, PIPELINE_ID);
+        pipelineIdSym = RubyUtil.RUBY.newString(PIPELINE_ID).intern();
 
         final SourceCollector sourceCollector = new SourceCollector();
         sourceCollector.appendSource("file", "/tmp/1", 0, 0, "input { generator1 }\n", "{\"version\": \"1\"}");

File: logstash-core/src/test/java/org/logstash/config/ir/compiler/OutputDelegatorTest.java
Patch:
@@ -216,7 +216,7 @@ private static class StrategyPair {
         Class klazz;
 
         StrategyPair(String symbolName, Class c) {
-            this.symbol = RUBY.newSymbol(symbolName);
+            this.symbol = RUBY.newString(symbolName).intern();
             this.klazz = c;
         }
     }

File: logstash-core/src/test/java/org/logstash/instrument/metrics/MetricExtFactory.java
Patch:
@@ -58,7 +58,7 @@ public MetricExt newRoot() {
     private RubyModule metricFactoryInterceptor(final String type, final Function<String,?> javaMetricFactory) {
         final ThreadContext context = RubyUtil.RUBY.getCurrentContext();
 
-        final IRubyObject interceptType = context.runtime.newSymbol(type);
+        final IRubyObject interceptType = context.runtime.newString(type).intern();
         final IRubyObject metricFactory = JavaUtil.convertJavaToUsableRubyObject(context.runtime, MetricFactory.of(javaMetricFactory));
         final IRubyObject interceptorModule = INTERCEPTOR_MODULE_CLASS.newInstance(context, interceptType, metricFactory, Block.NULL_BLOCK);
 

File: logstash-core/src/test/java/org/logstash/plugins/MetricTestCase.java
Patch:
@@ -64,19 +64,19 @@ protected RubyHash getMetricStore(String[] path) {
 
         RubyHash rh = metricStore;
         for (String p : path) {
-            rh = (RubyHash) rh.op_aref(RUBY.getCurrentContext(), RUBY.newSymbol(p));
+            rh = (RubyHash) rh.op_aref(RUBY.getCurrentContext(), RUBY.newString(p).intern());
         }
         return rh;
     }
 
     protected String getMetricStringValue(RubyHash metricStore, String symbolName) {
-        ConcreteJavaProxy counter = (ConcreteJavaProxy) metricStore.op_aref(RUBY.getCurrentContext(), RUBY.newSymbol(symbolName));
+        ConcreteJavaProxy counter = (ConcreteJavaProxy) metricStore.op_aref(RUBY.getCurrentContext(), RUBY.newString(symbolName).intern());
         RubyString value = (RubyString) counter.callMethod("value");
         return value.asJavaString();
     }
 
     protected long getMetricLongValue(RubyHash metricStore, String symbolName) {
-        ConcreteJavaProxy counter = (ConcreteJavaProxy) metricStore.op_aref(RUBY.getCurrentContext(), RUBY.newSymbol(symbolName));
+        ConcreteJavaProxy counter = (ConcreteJavaProxy) metricStore.op_aref(RUBY.getCurrentContext(), RUBY.newString(symbolName).intern());
         RubyFixnum count = (RubyFixnum) counter.callMethod("value");
         return count.getLongValue();
     }

File: logstash-core/src/main/java/org/logstash/plugins/pipeline/PipelineInput.java
Patch:
@@ -40,6 +40,8 @@ enum ReceiveStatus {CLOSING, COMPLETED, FAIL}
      */
     ReceiveResponse internalReceive(Stream<JrubyEventExtLibrary.RubyEvent> events);
 
+    String getId();
+
     /**
      * @return true if the input is running
      */

File: logstash-core/src/main/java/org/logstash/plugins/pipeline/PipelineOutput.java
Patch:
@@ -24,4 +24,5 @@
  * Represents the out endpoint of a pipeline to pipeline communication.
  * */
 public interface PipelineOutput {
+    String getId();
 }

File: tools/jvm-options-parser/src/main/java/org/logstash/launchers/JvmOptionsParser.java
Patch:
@@ -176,7 +176,9 @@ private void handleJvmOptions(Optional<Path> jvmOptionsFile, String lsJavaOpts)
             if (isDebugEnabled()) {
                 System.err.println("Appending jvm options from environment LS_JAVA_OPTS");
             }
-            jvmOptionsContent.add(lsJavaOpts);
+            Arrays.stream(lsJavaOpts.split(" "))
+                    .filter(s -> !s.isBlank())
+                    .forEach(jvmOptionsContent::add);
         }
         // Set mandatory JVM options
         jvmOptionsContent.addAll(getMandatoryJvmOptions(javaMajorVersion));

File: logstash-core/src/main/java/org/logstash/config/ir/expression/RegexValueExpression.java
Patch:
@@ -34,7 +34,7 @@ public RegexValueExpression(SourceWithMetadata meta, Object value) throws Invali
             throw new InvalidIRException("Regex value expressions can only take strings!");
         }
 
-        this.regex = getSource();
+        this.regex = (String) value;
     }
 
     @Override

File: logstash-core/src/main/java/org/logstash/execution/PipelineReporterExt.java
Patch:
@@ -157,7 +157,7 @@ public RubyHash toHash(final ThreadContext context) {
         return result;
     }
 
-    @SuppressWarnings({"unchecked","rawtypes"})
+    @SuppressWarnings({"unchecked", "rawtypes", "deprecation"})
     private RubyArray workerStates(final ThreadContext context, final RubyHash batchMap) {
         final RubyArray result = context.runtime.newArray();
         ((Iterable<IRubyObject>) pipeline.callMethod(context, "worker_threads"))
@@ -174,6 +174,7 @@ private RubyArray workerStates(final ThreadContext context, final RubyHash batch
 
                 IRubyObject batchSize = Optional.of((RubyThread) thread)
                         .map(RubyThread::getNativeThread)
+                        // JTODO getId has been deprecated in JDK 19, when JDK 21 is the target version use threadId() instead
                         .map(Thread::getId)
                         .map(id -> batchMap.op_aref(context, context.runtime.newFixnum(id)))
                         .map(batch -> extractBatchSize(context, batch))

File: logstash-core/src/main/java/org/logstash/instrument/monitors/HotThreadsMonitor.java
Patch:
@@ -145,6 +145,7 @@ public static List<ThreadReport> detect() {
      *                      stacktrace_size - max depth of stack trace
      * @return A list of ThreadReport including all selected threads
      */
+    @SuppressWarnings("deprecation")
     public static List<ThreadReport> detect(Map<String, String> options) {
         String type = "cpu";
         if (options.containsKey(ORDERED_BY)) {
@@ -164,6 +165,7 @@ public static List<ThreadReport> detect(Map<String, String> options) {
         Map<Long, ThreadReport> reports = new HashMap<>();
 
         for (long threadId : threadMXBean.getAllThreadIds()) {
+            // JTODO getId has been deprecated in JDK 19, when JDK 21 is the target version use threadId() instead
             if (Thread.currentThread().getId() == threadId) {
                 continue;
             }

File: logstash-core/src/main/java/org/logstash/plugins/inputs/Stdin.java
Patch:
@@ -75,7 +75,10 @@ public Stdin(final String id, final Configuration configuration, final Context c
         this(id, configuration, context, new FileInputStream(FileDescriptor.in).getChannel());
     }
 
+    @SuppressWarnings("this-escape")
     Stdin(final String id, final Configuration configuration, final Context context, FileChannel inputChannel) {
+        // This is the reason why of the "this-escape" suppress warning, but this is used just to grab the class
+        // for the logger.
         logger = context.getLogger(this);
         this.id = id;
         try {

File: logstash-core/src/main/java/org/logstash/util/UtilExt.java
Patch:
@@ -34,13 +34,15 @@
 public class UtilExt {
 
     @JRubyMethod(module = true)
+    @SuppressWarnings("deprecation")
     public static IRubyObject get_thread_id(final ThreadContext context, IRubyObject self, IRubyObject thread) {
         if (!(thread instanceof RubyThread)) {
             throw context.runtime.newTypeError(thread, context.runtime.getThread());
         }
         final Thread javaThread = ((RubyThread) thread).getNativeThread(); // weak-reference
         // even if thread is dead the RubyThread instance might stick around while the Java thread
         // instance already could have been garbage collected - let's return nil for dead meat :
+        // JTODO getId has been deprecated in JDK 19, when JDK 21 is the target version use threadId() instead
         return javaThread == null ? context.nil : context.runtime.newFixnum(javaThread.getId());
     }
 

File: logstash-core/src/test/java/org/logstash/ext/JrubyMemoryReadClientExtTest.java
Patch:
@@ -38,6 +38,7 @@
 public final class JrubyMemoryReadClientExtTest extends RubyTestBase {
 
     @Test
+    @SuppressWarnings("deprecation")
     public void testInflightBatchesTracking() throws InterruptedException, IOException {
         final BlockingQueue<JrubyEventExtLibrary.RubyEvent> queue =
             new ArrayBlockingQueue<>(10);
@@ -47,6 +48,7 @@ public void testInflightBatchesTracking() throws InterruptedException, IOExcepti
         final QueueBatch batch = client.readBatch();
         final RubyHash inflight = client.rubyGetInflightBatches(context);
         assertThat(inflight.size(), is(1));
+        // JTODO getId has been deprecated in JDK 19, when JDK 21 is the target version use threadId() instead
         assertThat(inflight.get(Thread.currentThread().getId()), is(batch));
         client.closeBatch(batch);
         assertThat(client.rubyGetInflightBatches(context).size(), is(0));

File: logstash-core/src/test/java/org/logstash/log/TestingDeprecationPlugin.java
Patch:
@@ -40,6 +40,7 @@ public class TestingDeprecationPlugin implements Codec {
      * @param configuration Logstash Configuration
      * @param context       Logstash Context
      */
+    @SuppressWarnings("this-escape")
     public TestingDeprecationPlugin(final Configuration configuration, final Context context) {
         deprecationLogger = context.getDeprecationLogger(this);
     }

File: logstash-core/src/test/java/org/logstash/plugins/AliasRegistryTest.java
Patch:
@@ -6,6 +6,7 @@
 import java.io.IOException;
 import java.net.HttpURLConnection;
 import java.net.URL;
+import java.net.URI;
 import java.nio.file.Path;
 import java.nio.file.Paths;
 import java.util.Map;
@@ -34,7 +35,7 @@ public void testProductionConfigAliasesGemsExists() throws IOException {
 
         for (AliasRegistry.PluginCoordinate alias : aliasesDefinitions.keySet()) {
             final String gemName = alias.fullName();
-            URL url = new URL("https://rubygems.org/api/v1/gems/" + gemName +".json");
+            URL url = URI.create("https://rubygems.org/api/v1/gems/" + gemName +".json").toURL();
             HttpURLConnection connection = (HttpURLConnection) url.openConnection();
             connection.setRequestMethod("GET");
             connection.setRequestProperty("Accept", "application/json");

File: logstash-core/src/test/java/org/logstash/secret/store/SecretStoreFactoryTest.java
Patch:
@@ -157,6 +157,7 @@ public static class MemoryStore implements SecretStore {
 
         Map<SecretIdentifier, ByteBuffer> secrets = new HashMap(1);
 
+        @SuppressWarnings("this-escape")
         public MemoryStore() {
             persistSecret(LOGSTASH_MARKER, LOGSTASH_MARKER.getKey().getBytes(StandardCharsets.UTF_8));
         }

File: logstash-core/src/main/java/org/logstash/ackedqueue/QueueRuntimeException.java
Patch:
@@ -31,4 +31,7 @@ public QueueRuntimeException(String message, Throwable cause) {
         super(message, cause);
     }
 
+    public QueueRuntimeException(String message) {
+        super(message);
+    }
 }

File: logstash-core/src/test/java/org/logstash/plugins/pipeline/PipelineBusTest.java
Patch:
@@ -136,7 +136,7 @@ public void listenUnlistenUpdatesOutputReceivers() throws InterruptedException {
 
     @Test
     public void sendingEmptyListToNowhereStillReturns() {
-        bus.registerSender(output, Arrays.asList("not_an_address"));
+        bus.registerSender(output, List.of("not_an_address"));
         bus.sendEvents(output, Collections.emptyList(), true);
     }
 

File: logstash-core/src/main/java/org/logstash/instrument/metrics/SnapshotExt.java
Patch:
@@ -48,7 +48,7 @@ public SnapshotExt initialize(final ThreadContext context, final IRubyObject[] a
         if (args.length == 2) {
             createdAt = (RubyTime) args[1];
         } else {
-            createdAt = RubyTime.newInstance(context, context.runtime.getTime());
+            createdAt = RubyTime.newInstance(context, context.runtime.getTime(), new IRubyObject[0]);
         }
         return this;
     }

File: logstash-core/src/main/java/org/logstash/plugins/PluginLookup.java
Patch:
@@ -94,8 +94,8 @@ public Object klass() {
 
             klass = (klass instanceof JavaProxy) ? ((JavaProxy) klass).getObject() : klass;
 
-            Object resolvedClass = klass instanceof JavaClass
-                    ? ((JavaClass) klass).javaClass()
+            Object resolvedClass = klass instanceof java.lang.Class
+                    ? ((java.lang.Class) klass)
                     : klass;
 
             if (language == PluginLanguage.JAVA && !PluginValidator.validatePlugin(type, (Class) resolvedClass)) {

File: logstash-core/src/test/java/org/logstash/config/ir/RubyEnvTestCase.java
Patch:
@@ -45,7 +45,7 @@ private static void ensureLoadpath() {
         final LibrarySearcher librarySearcher = new LibrarySearcher(loader);
         if (librarySearcher.findLibraryForLoad("logstash/compiler") == null) {
             final String gems = LS_HOME.
-                    resolve("vendor").resolve("bundle").resolve("jruby").resolve("2.6.0").
+                    resolve("vendor").resolve("bundle").resolve("jruby").resolve("3.1.0").
                     toFile().getAbsolutePath();
             final RubyHash environment = RubyUtil.RUBY.getENV();
             environment.put("GEM_HOME", gems);

File: logstash-core/src/main/java/org/logstash/common/AbstractDeadLetterQueueWriterExt.java
Patch:
@@ -198,7 +198,7 @@ protected IRubyObject doWrite(final ThreadContext context, final IRubyObject eve
                 try {
                     innerWriter.writeEntry(
                         ((JrubyEventExtLibrary.RubyEvent) event).getEvent(),
-                        pluginIdString, pluginTypeString, reason.asJavaString()
+                            pluginTypeString, pluginIdString, reason.asJavaString()
                     );
                 } catch (final IOException ex) {
                     throw new IllegalStateException(ex);

File: logstash-core/src/main/java/org/logstash/plugins/NamespacedMetricImpl.java
Patch:
@@ -42,7 +42,9 @@
  * metrics and other namespaces to it.
  */
 public class NamespacedMetricImpl implements NamespacedMetric {
+
     private final ThreadContext threadContext;
+
     private final AbstractNamespacedMetricExt metrics;
 
     public NamespacedMetricImpl(final ThreadContext threadContext, final AbstractNamespacedMetricExt metrics) {

File: logstash-core/src/main/java/org/logstash/plugins/factory/CodecPluginCreator.java
Patch:
@@ -11,7 +11,7 @@
 
 import java.util.Map;
 
-class CodecPluginCreator extends  AbstractPluginCreator<Codec> {
+class CodecPluginCreator extends AbstractPluginCreator<Codec> {
 
     @Override
     public IRubyObject createDelegator(String name, Map<String, Object> pluginArgs, String id,

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/FilterDelegatorExt.java
Patch:
@@ -33,6 +33,7 @@
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.instrument.metrics.AbstractNamespacedMetricExt;
+import org.logstash.instrument.metrics.timer.NullTimerMetric;
 import org.logstash.instrument.metrics.counter.LongCounter;
 
 import java.util.UUID;
@@ -70,7 +71,7 @@ public IRubyObject initialize(final ThreadContext context, final IRubyObject fil
     public FilterDelegatorExt initForTesting(final IRubyObject filter, RubyObject configNameDouble) {
         eventMetricOut = LongCounter.DUMMY_COUNTER;
         eventMetricIn = LongCounter.DUMMY_COUNTER;
-        eventMetricTime = LongCounter.DUMMY_COUNTER;
+        eventMetricTime = NullTimerMetric.getInstance();
         this.filter = filter;
         filterMethod = filter.getMetaClass().searchMethod(FILTER_METHOD_NAME);
         flushes = filter.respondsTo("flush");

File: logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadClientExt.java
Patch:
@@ -84,6 +84,4 @@ public QueueBatch readBatch() throws InterruptedException {
         startMetrics(batch);
         return batch;
     }
-
-
 }

File: logstash-core/src/main/java/org/logstash/instrument/metrics/AbstractMetric.java
Patch:
@@ -42,9 +42,6 @@ protected AbstractMetric(final String name) {
         this.name = name;
     }
 
-    @Override
-    public abstract MetricType getType();
-
     @JsonValue
     public abstract T getValue();
 

File: logstash-core/src/test/java/org/logstash/instrument/metrics/ManualAdvanceClock.java
Patch:
@@ -1,14 +1,13 @@
 package org.logstash.instrument.metrics;
 
-import java.time.Clock;
 import java.time.Duration;
 import java.time.Instant;
 import java.time.ZoneId;
 import java.time.temporal.ChronoUnit;
 import java.util.Objects;
 import java.util.concurrent.atomic.AtomicReference;
 
-class ManualAdvanceClock extends Clock {
+public class ManualAdvanceClock extends TestClock {
     private final ZoneId zoneId;
     private final AtomicReference<Instant> currentInstant;
     private final Instant zeroInstant;
@@ -33,7 +32,7 @@ public ZoneId getZone() {
     }
 
     @Override
-    public Clock withZone(ZoneId zone) {
+    public TestClock withZone(ZoneId zone) {
         return new ManualAdvanceClock(this.zeroInstant, this.currentInstant, zone);
     }
 

File: logstash-core/src/test/java/org/logstash/instrument/metrics/MetricTypeTest.java
Patch:
@@ -43,6 +43,7 @@ public void ensurePassivity(){
         Map<MetricType, String> nameMap = new HashMap<>(EnumSet.allOf(MetricType.class).size());
         nameMap.put(MetricType.COUNTER_LONG, "counter/long");
         nameMap.put(MetricType.COUNTER_DECIMAL, "counter/decimal");
+        nameMap.put(MetricType.TIMER_LONG, "timer/long");
         nameMap.put(MetricType.GAUGE_TEXT, "gauge/text");
         nameMap.put(MetricType.GAUGE_BOOLEAN, "gauge/boolean");
         nameMap.put(MetricType.GAUGE_NUMBER, "gauge/number");

File: logstash-core/src/main/java/org/logstash/plugins/ConfigurationImpl.java
Patch:
@@ -24,8 +24,6 @@
 import co.elastic.logstash.api.Password;
 import co.elastic.logstash.api.PluginConfigSpec;
 import co.elastic.logstash.api.Codec;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
 import org.jruby.RubyObject;
 import org.logstash.config.ir.compiler.RubyIntegration;
 import org.logstash.plugins.factory.RubyCodecDelegator;
@@ -39,7 +37,6 @@
  * Configuration for Logstash Java plugins.
  */
 public final class ConfigurationImpl implements Configuration {
-    private static final Logger LOGGER = LogManager.getLogger(ConfigurationImpl.class);
 
     private final RubyIntegration.PluginFactory pluginFactory;
     private final Map<String, Object> rawSettings;

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueReader.java
Patch:
@@ -100,7 +100,9 @@ public DeadLetterQueueReader(Path queuePath, boolean cleanConsumed, SegmentListe
         this.segments = new ConcurrentSkipListSet<>(
                 Comparator.comparingInt(DeadLetterQueueUtils::extractSegmentId)
         );
-        segments.addAll(listSegmentPaths(queuePath).collect(Collectors.toList()));
+        segments.addAll(listSegmentPaths(queuePath)
+                .filter(p -> p.toFile().length() > 1) // take the files that have content to process
+                .collect(Collectors.toList()));
         this.cleanConsumed = cleanConsumed;
         if (cleanConsumed && segmentCallback == null) {
             throw new IllegalArgumentException("When cleanConsumed is enabled must be passed also a valid segment listener");

File: logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java
Patch:
@@ -75,11 +75,11 @@
 import org.logstash.ext.JRubyWrappedWriteClientExt;
 import org.logstash.instrument.metrics.AbstractMetricExt;
 import org.logstash.instrument.metrics.AbstractNamespacedMetricExt;
-import org.logstash.instrument.metrics.FlowMetric;
 import org.logstash.instrument.metrics.Metric;
 import org.logstash.instrument.metrics.NullMetricExt;
 import org.logstash.instrument.metrics.UptimeMetric;
 import org.logstash.instrument.metrics.counter.LongCounter;
+import org.logstash.instrument.metrics.FlowMetric;
 import org.logstash.plugins.ConfigVariableExpander;
 import org.logstash.plugins.factory.ExecutionContextFactoryExt;
 import org.logstash.plugins.factory.PluginFactoryExt;
@@ -527,7 +527,7 @@ public final IRubyObject collectFlowMetrics(final ThreadContext context) {
     private static FlowMetric createFlowMetric(final RubySymbol name,
                                                final Metric<? extends Number> numeratorMetric,
                                                final Metric<? extends Number> denominatorMetric) {
-        return new FlowMetric(name.asJavaString(), numeratorMetric, denominatorMetric);
+        return FlowMetric.create(name.asJavaString(), numeratorMetric, denominatorMetric);
     }
 
     private LongCounter initOrGetCounterMetric(final ThreadContext context,

File: logstash-core/src/main/java/org/logstash/instrument/metrics/AbstractMetric.java
Patch:
@@ -23,6 +23,8 @@
 
 import com.fasterxml.jackson.annotation.JsonValue;
 
+import java.util.Objects;
+
 /**
  * Abstract implementation of a {@link Metric}. All metrics should subclass this.
  *
@@ -48,8 +50,7 @@ protected AbstractMetric(final String name) {
 
     @Override
     public String toString() {
-        return String.format("%s -  name: %s value:%s", this.getClass().getName(), this.name, getValue() == null ? "null" :
-                getValue().toString());
+        return String.format("%s -  name: %s value:%s", this.getClass().getName(), this.name, Objects.requireNonNullElse(getValue(),"null"));
     }
 
     @Override

File: logstash-core/src/test/java/org/logstash/config/ir/compiler/OutputDelegatorTest.java
Patch:
@@ -32,11 +32,13 @@
 import org.junit.Ignore;
 import org.junit.Test;
 import org.logstash.Event;
+import org.logstash.instrument.metrics.MetricKeys;
 
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.Assert.assertEquals;
 import static org.logstash.RubyUtil.RUBY;
 import static org.logstash.RubyUtil.RUBY_OUTPUT_DELEGATOR_CLASS;
+import static org.logstash.instrument.metrics.MetricKeys.EVENTS_KEY;
 
 @SuppressWarnings("rawtypes")
 @NotThreadSafe
@@ -202,7 +204,7 @@ private OutputDelegatorExt constructOutputDelegator() {
     }
 
     private RubyHash getMetricStore() {
-        return getMetricStore(new String[]{"output", "foo", "events"});
+        return getMetricStore(new String[]{"output", "foo", EVENTS_KEY.asJavaString()});
     }
 
     private long getMetricLongValue(String symbolName) {

File: logstash-core/src/test/java/org/logstash/instrument/metrics/MetricTypeTest.java
Patch:
@@ -42,12 +42,14 @@ public class MetricTypeTest {
     public void ensurePassivity(){
         Map<MetricType, String> nameMap = new HashMap<>(EnumSet.allOf(MetricType.class).size());
         nameMap.put(MetricType.COUNTER_LONG, "counter/long");
+        nameMap.put(MetricType.COUNTER_DECIMAL, "counter/decimal");
         nameMap.put(MetricType.GAUGE_TEXT, "gauge/text");
         nameMap.put(MetricType.GAUGE_BOOLEAN, "gauge/boolean");
         nameMap.put(MetricType.GAUGE_NUMBER, "gauge/number");
         nameMap.put(MetricType.GAUGE_UNKNOWN, "gauge/unknown");
         nameMap.put(MetricType.GAUGE_RUBYHASH, "gauge/rubyhash");
         nameMap.put(MetricType.GAUGE_RUBYTIMESTAMP, "gauge/rubytimestamp");
+        nameMap.put(MetricType.FLOW_RATE, "flow/rate");
 
         //ensure we are testing all of the enumerations
         assertThat(EnumSet.allOf(MetricType.class).size()).isEqualTo(nameMap.size());

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java
Patch:
@@ -107,11 +107,11 @@ public IRubyObject isReloadable(final ThreadContext context) {
     protected abstract IRubyObject reloadable(final ThreadContext context);
 
     @JRubyMethod(name = "threadsafe?")
-    public IRubyObject concurrency(final ThreadContext context) {
-        return getConcurrency(context);
+    public IRubyObject threadsafe(final ThreadContext context) {
+        return isThreadsafe(context);
     }
 
-    protected abstract IRubyObject getConcurrency(final ThreadContext context);
+    protected abstract IRubyObject isThreadsafe(final ThreadContext context);
 
     @JRubyMethod(name = "config_name")
     public IRubyObject configName(final ThreadContext context) {

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/FilterDelegatorExt.java
Patch:
@@ -109,7 +109,7 @@ protected IRubyObject reloadable(final ThreadContext context) {
     }
 
     @Override
-    protected IRubyObject getConcurrency(final ThreadContext context) {
+    protected IRubyObject isThreadsafe(final ThreadContext context) {
         return filter.callMethod(context, "threadsafe?");
     }
 

File: logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueTestUtils.java
Patch:
@@ -19,9 +19,10 @@
 package org.logstash.common.io;
 
 import static org.logstash.common.io.RecordIOWriter.BLOCK_SIZE;
+import static org.logstash.common.io.RecordIOWriter.VERSION_SIZE;
 
 public class DeadLetterQueueTestUtils {
     public static final int MB = 1024 * 1024;
     public static final int GB = 1024 * 1024 * 1024;
-    public static final int FULL_SEGMENT_FILE_SIZE = 319 * BLOCK_SIZE + 1; // 319 records that fills completely a block plus the 1 byte header of the segment file
+    public static final int FULL_SEGMENT_FILE_SIZE = 319 * BLOCK_SIZE + VERSION_SIZE; // 319 records that fills completely a block plus the 1 byte header of the segment file
 }

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueReader.java
Patch:
@@ -331,7 +331,7 @@ private void removeSegmentsBefore(Path validSegment) throws IOException {
         final Comparator<Path> fileTimeAndName = ((Comparator<Path>) this::compareByFileTimestamp)
                 .thenComparingInt(DeadLetterQueueUtils::extractSegmentId);
 
-        try (final Stream<Path> segmentFiles = Files.list(queuePath)) {
+        try (final Stream<Path> segmentFiles = DeadLetterQueueWriter.getSegmentPaths(queuePath)) {
             segmentFiles.filter(p -> fileTimeAndName.compare(p, validSegment) < 0)
                   .forEach(this::deleteSegment);
         }

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyAckedQueueExt.java
Patch:
@@ -46,6 +46,7 @@ public final class JRubyAckedQueueExt extends RubyObject {
 
     private static final long serialVersionUID = 1L;
 
+    @SuppressWarnings("serial")
     private Queue queue;
 
     public JRubyAckedQueueExt(final Ruby runtime, final RubyClass metaClass) {

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java
Patch:
@@ -48,11 +48,11 @@ public abstract class AbstractFilterDelegatorExt extends RubyObject {
 
     protected RubyString id;
 
-    protected LongCounter eventMetricOut;
+    protected transient LongCounter eventMetricOut;
 
-    protected LongCounter eventMetricIn;
+    protected transient LongCounter eventMetricIn;
 
-    protected LongCounter eventMetricTime;
+    protected transient LongCounter eventMetricTime;
 
     public AbstractFilterDelegatorExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/AbstractOutputDelegatorExt.java
Patch:
@@ -53,11 +53,11 @@ public abstract class AbstractOutputDelegatorExt extends RubyObject {
 
     private RubyString id;
 
-    private LongCounter eventMetricOut;
+    private transient LongCounter eventMetricOut;
 
-    private LongCounter eventMetricIn;
+    private transient LongCounter eventMetricIn;
 
-    private LongCounter eventMetricTime;
+    private transient LongCounter eventMetricTime;
 
     public AbstractOutputDelegatorExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/FilterDelegatorExt.java
Patch:
@@ -48,9 +48,9 @@ public final class FilterDelegatorExt extends AbstractFilterDelegatorExt {
 
     private RubyClass filterClass;
 
-    private IRubyObject filter;
+    private transient IRubyObject filter;
 
-    private DynamicMethod filterMethod;
+    private transient DynamicMethod filterMethod;
 
     private boolean flushes;
 

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/JavaFilterDelegatorExt.java
Patch:
@@ -52,9 +52,9 @@ public class JavaFilterDelegatorExt extends AbstractFilterDelegatorExt {
 
     private RubyString configName;
 
-    private Filter filter;
+    private transient Filter filter;
 
-    private FilterMatchListener filterMatchListener;
+    private transient FilterMatchListener filterMatchListener;
 
     public JavaFilterDelegatorExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/JavaInputDelegatorExt.java
Patch:
@@ -47,9 +47,9 @@ public class JavaInputDelegatorExt extends RubyObject {
 
     private JavaBasePipelineExt pipeline;
 
-    private Input input;
+    private transient Input input;
 
-    private DecoratingQueueWriter decoratingQueueWriter;
+    private transient DecoratingQueueWriter decoratingQueueWriter;
 
     public JavaInputDelegatorExt(Ruby runtime, RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/OutputDelegatorExt.java
Patch:
@@ -43,7 +43,7 @@
 
     private static final long serialVersionUID = 1L;
 
-    private IRubyObject outputClass;
+    private transient IRubyObject outputClass;
 
     private OutputStrategyExt.AbstractOutputStrategyExt strategy;
 

File: logstash-core/src/main/java/org/logstash/execution/EventDispatcherExt.java
Patch:
@@ -38,9 +38,9 @@ public final class EventDispatcherExt extends RubyBasicObject {
 
     private static final long serialVersionUID = 1L;
 
-    private final Collection<IRubyObject> listeners = new CopyOnWriteArraySet<>();
+    private final transient Collection<IRubyObject> listeners = new CopyOnWriteArraySet<>();
 
-    private IRubyObject emitter;
+    private transient IRubyObject emitter;
 
     public EventDispatcherExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/execution/ExecutionContextExt.java
Patch:
@@ -42,9 +42,9 @@ public final class ExecutionContextExt extends RubyObject {
 
     private AbstractDeadLetterQueueWriterExt dlqWriter;
 
-    private IRubyObject agent;
+    private transient IRubyObject agent;
 
-    private IRubyObject pipeline;
+    private transient IRubyObject pipeline;
 
     public ExecutionContextExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/execution/JavaBasePipelineExt.java
Patch:
@@ -54,7 +54,7 @@ public final class JavaBasePipelineExt extends AbstractPipelineExt {
 
     private static final Logger LOGGER = LogManager.getLogger(JavaBasePipelineExt.class);
 
-    private CompiledPipeline lirExecution;
+    private transient CompiledPipeline lirExecution;
 
     private @SuppressWarnings("rawtypes") RubyArray inputs;
 

File: logstash-core/src/main/java/org/logstash/execution/PipelineReporterExt.java
Patch:
@@ -81,9 +81,9 @@ public final class PipelineReporterExt extends RubyBasicObject {
     private static final RubyString DEAD_STATUS =
         RubyUtil.RUBY.newString("dead").newFrozen();
 
-    private IRubyObject logger;
+    private transient IRubyObject logger;
 
-    private IRubyObject pipeline;
+    private transient IRubyObject pipeline;
 
     public PipelineReporterExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/execution/ShutdownWatcherExt.java
Patch:
@@ -49,7 +49,7 @@ public final class ShutdownWatcherExt extends RubyBasicObject {
 
     private static final AtomicBoolean unsafeShutdown = new AtomicBoolean(false);
 
-    private final List<IRubyObject> reports = new ArrayList<>();
+    private final transient List<IRubyObject> reports = new ArrayList<>();
 
     private final AtomicInteger attemptsCount = new AtomicInteger(0);
 
@@ -61,7 +61,7 @@ public final class ShutdownWatcherExt extends RubyBasicObject {
 
     private int abortThreshold = 3;
 
-    private IRubyObject pipeline;
+    private transient IRubyObject pipeline;
 
     @JRubyMethod(name = "unsafe_shutdown?", meta = true)
     public static IRubyObject isUnsafeShutdown(final ThreadContext context,

File: logstash-core/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -67,7 +67,7 @@ public static final class RubyEvent extends RubyObject {
          */
         private final int hash = nextHash();
 
-        private Event event;
+        private transient Event event;
 
         public RubyEvent(final Ruby runtime, final RubyClass klass) {
             super(runtime, klass);

File: logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadClientExt.java
Patch:
@@ -39,7 +39,7 @@ public final class JrubyMemoryReadClientExt extends QueueReadClientBase {
 
     private static final long serialVersionUID = 1L;
 
-    @SuppressWarnings("rawtypes") private BlockingQueue queue;
+    @SuppressWarnings({"rawtypes", "serial"}) private BlockingQueue queue;
 
     public JrubyMemoryReadClientExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/ext/JrubyMemoryWriteClientExt.java
Patch:
@@ -36,7 +36,7 @@ public final class JrubyMemoryWriteClientExt extends JRubyAbstractQueueWriteClie
 
     private static final long serialVersionUID = 1L;
 
-    private BlockingQueue<JrubyEventExtLibrary.RubyEvent> queue;
+    private transient BlockingQueue<JrubyEventExtLibrary.RubyEvent> queue;
 
     public JrubyMemoryWriteClientExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/ext/JrubyTimestampExtLibrary.java
Patch:
@@ -48,7 +48,7 @@ public static final class RubyTimestamp extends RubyObject {
 
         private static final long serialVersionUID = 1L;
 
-        private Timestamp timestamp;
+        private transient Timestamp timestamp;
 
         public RubyTimestamp(Ruby runtime, RubyClass klass) {
             super(runtime, klass);

File: logstash-core/src/main/java/org/logstash/ext/JrubyWrappedSynchronousQueueExt.java
Patch:
@@ -40,7 +40,7 @@ public final class JrubyWrappedSynchronousQueueExt extends AbstractWrappedQueueE
 
     private static final long serialVersionUID = 1L;
 
-    private BlockingQueue<JrubyEventExtLibrary.RubyEvent> queue;
+    private transient BlockingQueue<JrubyEventExtLibrary.RubyEvent> queue;
 
     public JrubyWrappedSynchronousQueueExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/instrument/metrics/MetricExt.java
Patch:
@@ -54,7 +54,7 @@ public final class MetricExt extends AbstractSimpleMetricExt {
 
     private static final RubySymbol SET = RubyUtil.RUBY.newSymbol("set");
 
-    private IRubyObject collector;
+    private transient IRubyObject collector;
 
     public MetricExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);
@@ -185,9 +185,9 @@ public static final class TimedExecution extends RubyObject {
 
         private MetricExt metric;
 
-        private IRubyObject namespace;
+        private transient IRubyObject namespace;
 
-        private IRubyObject key;
+        private transient IRubyObject key;
 
         public static MetricExt.TimedExecution create(final MetricExt metric,
             final IRubyObject namespace, final IRubyObject key) {

File: logstash-core/src/main/java/org/logstash/instrument/metrics/NullMetricExt.java
Patch:
@@ -37,7 +37,7 @@ public final class NullMetricExt extends AbstractSimpleMetricExt {
 
     private static final long serialVersionUID = 1L;
 
-    private IRubyObject collector;
+    private transient IRubyObject collector;
 
     public static NullMetricExt create() {
         return new NullMetricExt(

File: logstash-core/src/main/java/org/logstash/instrument/metrics/SnapshotExt.java
Patch:
@@ -34,9 +34,9 @@ public final class SnapshotExt extends RubyBasicObject {
 
     private static final long serialVersionUID = 1L;
 
-    private IRubyObject metricStore;
+    private transient IRubyObject metricStore;
 
-    private RubyTime createdAt;
+    private transient RubyTime createdAt;
 
     public SnapshotExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/log/DeprecationLoggerExt.java
Patch:
@@ -37,7 +37,7 @@ public class DeprecationLoggerExt extends RubyObject {
 
     private static final long serialVersionUID = 1L;
 
-    private DeprecationLogger logger;
+    private transient DeprecationLogger logger;
 
     public DeprecationLoggerExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/log/LoggerExt.java
Patch:
@@ -49,7 +49,7 @@ public class LoggerExt extends RubyObject {
     private static final long serialVersionUID = 1L;
 
     private static final Object CONFIG_LOCK = new Object();
-    private Logger logger;
+    private transient Logger logger;
 
     public LoggerExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/log/SlowLoggerExt.java
Patch:
@@ -48,7 +48,7 @@ public class SlowLoggerExt extends RubyObject {
     private static final RubySymbol EVENT = RubyUtil.RUBY.newSymbol("event");
     private static final RubyNumeric NANO_TO_MILLI = RubyUtil.RUBY.newFixnum(1000000);
 
-    private Logger slowLogger;
+    private transient Logger slowLogger;
     private long warnThreshold;
     private long infoThreshold;
     private long debugThreshold;

File: logstash-core/src/main/java/org/logstash/log/StructuredMessage.java
Patch:
@@ -35,7 +35,7 @@ public class StructuredMessage implements Message {
     private static final long serialVersionUID = 1L;
 
     private final String message;
-    private final Map<Object, Object> params;
+    private final transient Map<Object, Object> params;
 
     @SuppressWarnings({"unchecked","rawtypes"})
     public StructuredMessage(String message) {

File: logstash-core/src/main/java/org/logstash/plugins/factory/ExecutionContextFactoryExt.java
Patch:
@@ -27,11 +27,11 @@ public final class ExecutionContextFactoryExt extends RubyBasicObject {
 
     private static final long serialVersionUID = 1L;
 
-    private IRubyObject agent;
+    private transient IRubyObject agent;
 
-    private IRubyObject pipeline;
+    private transient IRubyObject pipeline;
 
-    private IRubyObject dlqWriter;
+    private transient IRubyObject dlqWriter;
 
     public ExecutionContextFactoryExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: tools/jvm-options-parser/src/main/java/org/logstash/launchers/JvmOptionsParser.java
Patch:
@@ -67,6 +67,7 @@ public class JvmOptionsParser {
     };
 
 
+    @SuppressWarnings("serial")
     static class JvmOptionsFileParserException extends Exception {
 
         private static final long serialVersionUID = 2446165130736962758L;

File: logstash-core/src/main/java/org/logstash/execution/WorkerLoop.java
Patch:
@@ -106,7 +106,7 @@ public void run() {
         }
     }
 
-    private boolean isDraining() {
+    public boolean isDraining() {
         return drainQueue && !readClient.isEmpty();
     }
 }

File: logstash-core/src/main/java/org/logstash/ackedqueue/Page.java
Patch:
@@ -252,7 +252,7 @@ public void deactivate() throws IOException {
     }
 
     public boolean hasSpace(int byteSize) {
-        return this.pageIO.hasSpace((byteSize));
+        return this.pageIO.hasSpace(byteSize);
     }
 
     /**

File: logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueWriterTest.java
Patch:
@@ -295,8 +295,6 @@ public void testRemoveOldestSegmentWhenRetainedSizeIsExceededAndDropOlderModeIsE
     @Test
     public void testRemoveSegmentsOrder() throws IOException {
         try (DeadLetterQueueWriter sut = new DeadLetterQueueWriter(dir, 10 * MB, 20 * MB, Duration.ofSeconds(1))) {
-            Files.delete(dir.resolve("1.log.tmp"));
-
             // create some segments files
             Files.createFile(dir.resolve("9.log"));
             Files.createFile(dir.resolve("10.log"));
@@ -308,6 +306,7 @@ public void testRemoveSegmentsOrder() throws IOException {
             final Set<String> segments = Files.list(dir)
                     .map(Path::getFileName)
                     .map(Path::toString)
+                    .filter(s -> !s.endsWith(".tmp")) // skip current writer head file 1.log.tmp
                     .filter(s -> !".lock".equals(s)) // skip .lock file created by writer
                     .collect(Collectors.toSet());
             assertEquals(Collections.singleton("10.log"), segments);

File: logstash-core/src/main/java/org/logstash/plugins/factory/PluginFactoryExt.java
Patch:
@@ -18,7 +18,6 @@
 import org.logstash.instrument.metrics.AbstractMetricExt;
 import org.logstash.instrument.metrics.AbstractNamespacedMetricExt;
 import org.logstash.instrument.metrics.MetricKeys;
-import org.logstash.plugins.AliasRegistry;
 import org.logstash.plugins.ConfigVariableExpander;
 import org.logstash.plugins.PluginLookup;
 import org.logstash.plugins.discovery.PluginRegistry;
@@ -83,7 +82,7 @@ public static IRubyObject filterDelegator(final ThreadContext context,
     }
 
     public PluginFactoryExt(final Ruby runtime, final RubyClass metaClass) {
-        this(runtime, metaClass, new PluginLookup(PluginRegistry.getInstance(new AliasRegistry())));
+        this(runtime, metaClass, new PluginLookup(PluginRegistry.getInstance()));
     }
 
     PluginFactoryExt(final Ruby runtime, final RubyClass metaClass, PluginResolver pluginResolver) {

File: logstash-core/src/test/java/org/logstash/plugins/AliasRegistryTest.java
Patch:
@@ -16,7 +16,7 @@ public class AliasRegistryTest {
 
     @Test
     public void testLoadAliasesFromYAML() {
-        final AliasRegistry sut = new AliasRegistry();
+        final AliasRegistry sut = AliasRegistry.getInstance();
 
         assertEquals("aliased_input1 should be the alias for beats input",
                 "beats", sut.originalFromAlias(PluginType.INPUT, "aliased_input1"));

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/PageIO.java
Patch:
@@ -84,4 +84,7 @@ public interface PageIO extends Closeable {
 
     // @return the data container min sequence number
     long getMinSeqNum();
+
+    // check if the page size is < minimum size
+    boolean isCorruptedPage() throws IOException;
 }

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/ComposedParallelStatement.java
Patch:
@@ -23,6 +23,7 @@
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
+import org.logstash.plugins.ConfigVariableExpander;
 
 import java.util.List;
 
@@ -37,11 +38,11 @@ protected String composeTypeString() {
     }
 
     @Override
-    public Graph toGraph() throws InvalidIRException {
+    public Graph toGraph(ConfigVariableExpander cve) throws InvalidIRException {
         Graph g = Graph.empty();
 
         for (Statement s : getStatements()) {
-            g = Graph.combine(g, s.toGraph()).graph;
+            g = Graph.combine(g, s.toGraph(cve)).graph;
         }
 
         return g;

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/ComposedSequenceStatement.java
Patch:
@@ -23,6 +23,7 @@
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
+import org.logstash.plugins.ConfigVariableExpander;
 
 import java.util.List;
 
@@ -37,11 +38,11 @@ protected String composeTypeString() {
     }
 
     @Override
-    public Graph toGraph() throws InvalidIRException {
+    public Graph toGraph(ConfigVariableExpander cve) throws InvalidIRException {
         Graph g = Graph.empty();
 
         for (Statement statement : getStatements()) {
-            Graph sg = statement.toGraph();
+            Graph sg = statement.toGraph(cve);
             g = g.chain(sg);
         }
 

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/NoopStatement.java
Patch:
@@ -23,6 +23,7 @@
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
+import org.logstash.plugins.ConfigVariableExpander;
 
 public class NoopStatement extends Statement {
 
@@ -43,7 +44,7 @@ public String toString(int indent) {
     }
 
     @Override
-    public Graph toGraph() {
+    public Graph toGraph(ConfigVariableExpander cve) {
         return Graph.empty();
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/PluginStatement.java
Patch:
@@ -27,6 +27,7 @@
 import org.logstash.config.ir.graph.Graph;
 import org.logstash.config.ir.graph.PluginVertex;
 import org.logstash.config.ir.graph.Vertex;
+import org.logstash.plugins.ConfigVariableExpander;
 
 public class PluginStatement extends Statement {
     private final PluginDefinition pluginDefinition;
@@ -53,7 +54,7 @@ public String toString(int indent) {
     }
 
     @Override
-    public Graph toGraph() throws InvalidIRException {
+    public Graph toGraph(ConfigVariableExpander cve) throws InvalidIRException {
         Vertex pluginVertex = new PluginVertex(getSourceWithMetadata(), pluginDefinition);
         Graph g = Graph.empty();
         g.addVertex(pluginVertex);

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/Statement.java
Patch:
@@ -24,13 +24,14 @@
 import org.logstash.config.ir.BaseSourceComponent;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
+import org.logstash.plugins.ConfigVariableExpander;
 
 public abstract class Statement extends BaseSourceComponent {
     public Statement(SourceWithMetadata meta) {
         super(meta);
     }
 
-    public abstract Graph toGraph() throws InvalidIRException;
+    public abstract Graph toGraph(ConfigVariableExpander cve) throws InvalidIRException;
 
     public String toString() {
         return toString(2);

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/MmapPageIOV1.java
Patch:
@@ -29,7 +29,7 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.zip.CRC32;
-import org.logstash.LogstashJavaCompat;
+
 import org.logstash.ackedqueue.SequencedList;
 
 /**
@@ -43,8 +43,7 @@ public final class MmapPageIOV1 implements PageIO {
     /**
      * Cleaner function for forcing unmapping of backing {@link MmapPageIOV1#buffer}.
      */
-    private static final ByteBufferCleaner BUFFER_CLEANER =
-        LogstashJavaCompat.setupBytebufferCleaner();
+    private static final ByteBufferCleaner BUFFER_CLEANER = new ByteBufferCleanerImpl();
 
     private final File file;
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/MmapPageIOV2.java
Patch:
@@ -32,7 +32,6 @@
 import java.util.zip.CRC32;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import org.logstash.LogstashJavaCompat;
 import org.logstash.ackedqueue.SequencedList;
 
 /**
@@ -54,8 +53,7 @@ public final class MmapPageIOV2 implements PageIO {
     /**
      * Cleaner function for forcing unmapping of backing {@link MmapPageIOV2#buffer}.
      */
-    private static final ByteBufferCleaner BUFFER_CLEANER =
-        LogstashJavaCompat.setupBytebufferCleaner();
+    private static final ByteBufferCleaner BUFFER_CLEANER = new ByteBufferCleanerImpl();
 
     private final File file;
 

File: logstash-core/src/main/java/org/logstash/instrument/monitors/ProcessMonitor.java
Patch:
@@ -30,8 +30,7 @@
 
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import org.logstash.Logstash;
-import org.logstash.LogstashJavaCompat;
+import org.logstash.JavaVersionUtils;
 
 public class ProcessMonitor {
 
@@ -119,7 +118,7 @@ private short getSystemCpuLoad() {
      */
     private static Method getCpuLoadMethod(){
         try{
-            String methodName = (LogstashJavaCompat.isJavaAtLeast(14)) ? "getCpuLoad" : "getSystemCpuLoad";
+            String methodName = (JavaVersionUtils.isJavaAtLeast(14)) ? "getCpuLoad" : "getSystemCpuLoad";
             return Class.forName("com.sun.management.OperatingSystemMXBean").getMethod(methodName);
         } catch (ReflectiveOperationException e){
             LOGGER.warn("OperatingSystemMXBean CPU load method not available, CPU load will not be measured", e);

File: logstash-core/src/test/java/org/logstash/secret/store/backend/JavaKeyStoreTest.java
Patch:
@@ -27,7 +27,6 @@
 import org.junit.Test;
 import org.junit.rules.ExpectedException;
 import org.junit.rules.TemporaryFolder;
-import org.logstash.LogstashJavaCompat;
 import org.logstash.secret.SecretIdentifier;
 import org.logstash.secret.store.SecretStore;
 import org.logstash.secret.store.SecretStoreException;
@@ -48,7 +47,6 @@
 import java.nio.file.attribute.PosixFilePermission;
 import java.util.*;
 import java.util.concurrent.Callable;
-import java.util.concurrent.ExecutionException;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.Future;

File: logstash-core/src/test/java/org/logstash/secret/store/SecretStoreFactoryTest.java
Patch:
@@ -196,6 +196,9 @@ public void purgeSecret(SecretIdentifier id) {
             secrets.remove(id);
         }
 
+        @Override
+        public boolean containsSecret(SecretIdentifier id) { return secrets.containsKey(id); }
+
         @Override
         public byte[] retrieveSecret(SecretIdentifier id) {
             ByteBuffer bb = secrets.get(id);

File: logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueReaderTest.java
Patch:
@@ -368,7 +368,7 @@ public void testFlushAfterDelay() throws Exception {
 
         System.out.println("events per block= " + eventsPerBlock);
 
-        try(DeadLetterQueueWriter writeManager = new DeadLetterQueueWriter(dir, BLOCK_SIZE, defaultDlqSize, Duration.ofSeconds(1))) {
+        try(DeadLetterQueueWriter writeManager = new DeadLetterQueueWriter(dir, BLOCK_SIZE, defaultDlqSize, Duration.ofSeconds(2))) {
             for (int i = 1; i < eventsToWrite; i++) {
                 DLQEntry entry = new DLQEntry(event, "", "", Integer.toString(i), timestamp);
                 writeManager.writeEntry(entry);
@@ -381,7 +381,7 @@ public void testFlushAfterDelay() throws Exception {
                 }
             }
 
-            Thread.sleep(2000);
+            Thread.sleep(3000);
 
             try (DeadLetterQueueReader readManager = new DeadLetterQueueReader(dir)) {
                 for (int i = 1; i < eventsToWrite; i++) {

File: logstash-core/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -28,7 +28,6 @@
 import org.jruby.RubyString;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
-import org.logstash.execution.WorkerLoop;
 
 /**
  * <p>This class is an internal API and behaves very different from a standard {@link Map}.</p>

File: logstash-core/src/main/java/org/logstash/execution/WorkerLoop.java
Patch:
@@ -84,10 +84,10 @@ public void run() {
                 if (batch.filteredSize() > 0 || isFlush) {
                     consumedCounter.add(batch.filteredSize());
                     readClient.startMetrics(batch);
-                    execution.compute(batch, isFlush, false);
+                    final int outputCount = execution.compute(batch, isFlush, false);
                     int filteredCount = batch.filteredSize();
                     filteredCounter.add(filteredCount);
-                    readClient.addOutputMetrics(filteredCount);
+                    readClient.addOutputMetrics(outputCount);
                     readClient.addFilteredMetrics(filteredCount);
                     readClient.closeBatch(batch);
                     if (isFlush) {

File: logstash-core/src/test/java/org/logstash/ext/JrubyMemoryReadClientExtTest.java
Patch:
@@ -27,7 +27,6 @@
 import org.jruby.runtime.ThreadContext;
 import org.junit.Test;
 import org.logstash.execution.QueueBatch;
-import org.logstash.execution.WorkerLoop;
 
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;

File: logstash-core/src/test/java/org/logstash/secret/store/backend/JavaKeyStoreTest.java
Patch:
@@ -27,6 +27,7 @@
 import org.junit.Test;
 import org.junit.rules.ExpectedException;
 import org.junit.rules.TemporaryFolder;
+import org.logstash.LogstashJavaCompat;
 import org.logstash.secret.SecretIdentifier;
 import org.logstash.secret.store.SecretStore;
 import org.logstash.secret.store.SecretStoreException;
@@ -314,7 +315,7 @@ public void retrieveWithInvalidInput() {
      */
     @Test
     public void tamperedKeystore() throws Exception {
-        thrown.expect(SecretStoreException.AccessException.class);
+        thrown.expect(SecretStoreException.class);
         byte[] keyStoreAsBytes = Files.readAllBytes(Paths.get(new String(keyStorePath)));
         //bump the middle byte by 1
         int tamperLocation = keyStoreAsBytes.length / 2;

File: logstash-core/src/main/java/org/logstash/Valuefier.java
Patch:
@@ -155,7 +155,7 @@ private static Map<Class<?>, Valuefier.Converter> initConverters() {
         );
         converters.put(
             RubyTime.class, input -> JrubyTimestampExtLibrary.RubyTimestamp.newRubyTimestamp(
-                RubyUtil.RUBY, new Timestamp(((RubyTime) input).getDateTime())
+                RubyUtil.RUBY, new Timestamp(((RubyTime) input).toInstant())
             )
         );
         converters.put(

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriter.java
Patch:
@@ -157,7 +157,7 @@ void writeEntry(DLQEntry entry) throws IOException {
         lock.lock();
         try {
             Timestamp entryTimestamp = Timestamp.now();
-            if (entryTimestamp.getTime().isBefore(lastEntryTimestamp.getTime())) {
+            if (entryTimestamp.compareTo(lastEntryTimestamp) < 0) {
                 entryTimestamp = lastEntryTimestamp;
             }
             innerWriteEntry(entry);

File: logstash-core/src/main/java/org/logstash/log/PipelineRoutingFilter.java
Patch:
@@ -13,7 +13,7 @@
 @Plugin(name = "PipelineRoutingFilter", category = Core.CATEGORY_NAME, elementType = Appender.ELEMENT_TYPE, printObject = true)
 public final class PipelineRoutingFilter extends AbstractFilter {
 
-    private boolean isSeparateLogs;
+    private final boolean isSeparateLogs;
 
     /**
      * Factory method to instantiate the filter

File: logstash-core/src/main/java/org/logstash/plugins/factory/PluginFactoryExt.java
Patch:
@@ -18,6 +18,7 @@
 import org.logstash.instrument.metrics.AbstractMetricExt;
 import org.logstash.instrument.metrics.AbstractNamespacedMetricExt;
 import org.logstash.instrument.metrics.MetricKeys;
+import org.logstash.plugins.AliasRegistry;
 import org.logstash.plugins.ConfigVariableExpander;
 import org.logstash.plugins.PluginLookup;
 import org.logstash.plugins.discovery.PluginRegistry;
@@ -82,7 +83,7 @@ public static IRubyObject filterDelegator(final ThreadContext context,
     }
 
     public PluginFactoryExt(final Ruby runtime, final RubyClass metaClass) {
-        this(runtime, metaClass, new PluginLookup(PluginRegistry.getInstance()));
+        this(runtime, metaClass, new PluginLookup(PluginRegistry.getInstance(new AliasRegistry())));
     }
 
     PluginFactoryExt(final Ruby runtime, final RubyClass metaClass, PluginResolver pluginResolver) {

File: tools/benchmark-cli/src/test/java/org/logstash/benchmark/cli/LsMetricsMonitorTest.java
Patch:
@@ -57,7 +57,7 @@ public void parsesFilteredCount() throws Exception {
         ) {
             TimeUnit.SECONDS.sleep(5L);
             final Statistics stats = monitor.stopAndGet().get(LsMetricStats.THROUGHPUT);
-            MatcherAssert.assertThat(stats.getMax(), CoreMatchers.is(21052.0D));
+            MatcherAssert.assertThat(stats.getMax(), CoreMatchers.is(170250.0D));
         }
     }
 
@@ -75,7 +75,7 @@ public void parsesCpuUsage() throws Exception {
         ) {
             TimeUnit.SECONDS.sleep(5L);
             final Statistics stats = monitor.stopAndGet().get(LsMetricStats.CPU_USAGE);
-            MatcherAssert.assertThat(stats.getMax(), CoreMatchers.is(63.0D));
+            MatcherAssert.assertThat(stats.getMax(), CoreMatchers.is(33.0D));
         }
     }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/MmapPageIOV2.java
Patch:
@@ -193,6 +193,7 @@ public void create() throws IOException {
         }
         buffer.position(0);
         buffer.put(VERSION_TWO);
+        buffer.force();
         this.head = 1;
         this.minSeqNum = 0L;
         this.elementCount = 0;

File: logstash-core/src/main/java/org/logstash/execution/JavaBasePipelineExt.java
Patch:
@@ -77,8 +77,7 @@ public JavaBasePipelineExt initialize(final ThreadContext context, final IRubyOb
                 new ExecutionContextFactoryExt(
                     context.runtime, RubyUtil.EXECUTION_CONTEXT_FACTORY_CLASS
                 ).initialize(context, args[3], this, dlqWriter(context)),
-                RubyUtil.FILTER_DELEGATOR_CLASS,
-                Engine.JAVA
+                RubyUtil.FILTER_DELEGATOR_CLASS
             ),
             getSecretStore(context)
         );

File: logstash-core/src/test/java/org/logstash/plugins/factory/PluginFactoryExtTest.java
Patch:
@@ -30,7 +30,6 @@
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.config.ir.PipelineIR;
 import org.logstash.config.ir.RubyEnvTestCase;
-import org.logstash.execution.Engine;
 import org.logstash.instrument.metrics.NamespacedMetricExt;
 import org.logstash.plugins.MetricTestCase;
 import org.logstash.plugins.PluginLookup;
@@ -94,7 +93,7 @@ public void testPluginIdResolvedWithEnvironmentVariables() throws InvalidIRExcep
         envVars.put("CUSTOM", "test");
         PluginFactoryExt sut = new PluginFactoryExt(RubyUtil.RUBY, RubyUtil.PLUGIN_FACTORY_CLASS,
                 mockPluginResolver);
-        sut.init(pipelineIR, metricsFactory, execContextFactory, RubyUtil.FILTER_DELEGATOR_CLASS, envVars::get, Engine.JAVA);
+        sut.init(pipelineIR, metricsFactory, execContextFactory, RubyUtil.FILTER_DELEGATOR_CLASS, envVars::get);
 
         RubyString pluginName = RubyUtil.RUBY.newString("mockinput");
 

File: logstash-core/src/main/java/org/logstash/util/CloudSettingAuth.java
Patch:
@@ -20,6 +20,7 @@
 package org.logstash.util;
 
 import co.elastic.logstash.api.Password;
+import org.logstash.RubyUtil;
 
 public class CloudSettingAuth {
 
@@ -34,7 +35,7 @@ public CloudSettingAuth(String value) {
         this.original = value;
         final String[] parts = this.original.split(":");
         if (parts.length != 2 || parts[0].isEmpty() || parts[1].isEmpty()) {
-            throw new IllegalArgumentException("Cloud Auth username and password format should be \"<username>:<password>\".");
+            throw RubyUtil.RUBY.newArgumentError("Cloud Auth username and password format should be \"<username>:<password>\".");
         }
 
         this.username = parts[0];

File: logstash-core/src/main/java/org/logstash/execution/JavaBasePipelineExt.java
Patch:
@@ -77,7 +77,8 @@ public JavaBasePipelineExt initialize(final ThreadContext context, final IRubyOb
                 new ExecutionContextFactoryExt(
                     context.runtime, RubyUtil.EXECUTION_CONTEXT_FACTORY_CLASS
                 ).initialize(context, args[3], this, dlqWriter(context)),
-                RubyUtil.FILTER_DELEGATOR_CLASS
+                RubyUtil.FILTER_DELEGATOR_CLASS,
+                Engine.JAVA
             ),
             getSecretStore(context)
         );

File: logstash-core/src/test/java/org/logstash/plugins/factory/PluginFactoryExtTest.java
Patch:
@@ -30,6 +30,7 @@
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.config.ir.PipelineIR;
 import org.logstash.config.ir.RubyEnvTestCase;
+import org.logstash.execution.Engine;
 import org.logstash.instrument.metrics.NamespacedMetricExt;
 import org.logstash.plugins.MetricTestCase;
 import org.logstash.plugins.PluginLookup;
@@ -93,13 +94,12 @@ public void testPluginIdResolvedWithEnvironmentVariables() throws InvalidIRExcep
         envVars.put("CUSTOM", "test");
         PluginFactoryExt sut = new PluginFactoryExt(RubyUtil.RUBY, RubyUtil.PLUGIN_FACTORY_CLASS,
                 mockPluginResolver);
-        sut.init(pipelineIR, metricsFactory, execContextFactory, RubyUtil.FILTER_DELEGATOR_CLASS, envVars::get);
+        sut.init(pipelineIR, metricsFactory, execContextFactory, RubyUtil.FILTER_DELEGATOR_CLASS, envVars::get, Engine.JAVA);
 
         RubyString pluginName = RubyUtil.RUBY.newString("mockinput");
 
         // Exercise
-        IRubyObject pluginInstance = sut.buildInput(pluginName, sourceWithMetadata, RubyHash.newHash(RubyUtil.RUBY),
-                Collections.emptyMap());
+        IRubyObject pluginInstance = sut.buildInput(pluginName, RubyHash.newHash(RubyUtil.RUBY), sourceWithMetadata);
 
         //Verify
         IRubyObject id = pluginInstance.callMethod(RUBY.getCurrentContext(), "id");

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/ComputeStepSyntaxElement.java
Patch:
@@ -101,7 +101,6 @@ public static int classCacheSize() {
     public static void cleanClassCache() {
         synchronized (COMPILER) {
             CLASS_CACHE.clear();
-            COMPILER.setParentClassLoader(null);
         }
     }
 

File: logstash-core/src/test/java/org/logstash/config/ir/CompiledPipelineTest.java
Patch:
@@ -615,12 +615,12 @@ public void compilerBenchmark() throws Exception {
 
         final CompiledPipeline testCompiledPipeline = new CompiledPipeline(testPipelineIR, pluginFactory);
 
-        final long compilationBaseline = time(ChronoUnit.SECONDS, () -> {
+        final long compilationBaseline = time(ChronoUnit.MILLIS, () -> {
             final CompiledPipeline.CompiledExecution compiledExecution = baselineCompiledPipeline.buildExecution();
             compiledExecution.compute(RubyUtil.RUBY.newArray(testEvent), false, false);
         });
 
-        final long compilationTest = time(ChronoUnit.SECONDS, () -> {
+        final long compilationTest = time(ChronoUnit.MILLIS, () -> {
             final CompiledPipeline.CompiledExecution compiledExecution = testCompiledPipeline.buildExecution();
             compiledExecution.compute(RubyUtil.RUBY.newArray(testEvent), false, false);
         });

File: logstash-core/src/main/java/org/logstash/config/ir/PipelineConfig.java
Patch:
@@ -126,7 +126,7 @@ public boolean equals(Object other) {
         PipelineConfig cother = (PipelineConfig) other;
         return configHash().equals(cother.configHash()) &&
                 this.pipelineId.equals(cother.pipelineId) &&
-                this.settings.eql(cother.settings);
+                this.settings.equals(cother.settings);
     }
 
     @Override

File: logstash-core/src/test/java/org/logstash/plugins/NamespacedMetricImplTest.java
Patch:
@@ -24,6 +24,7 @@
 import co.elastic.logstash.api.NamespacedMetric;
 import org.assertj.core.data.Percentage;
 import org.jruby.RubyHash;
+import org.junit.Ignore;
 import org.junit.Test;
 
 import static org.assertj.core.api.Assertions.assertThat;
@@ -80,6 +81,7 @@ public void testIncrementWithAmount() {
         }
     }
 
+    @Ignore("Test failing intermittently for some time. See https://github.com/elastic/logstash/issues/11925")
     @Test
     public void testTimeCallable() {
         final NamespacedMetric metrics = this.getInstance().namespace("test");

File: tools/benchmark-cli/src/main/java/org/logstash/benchmark/cli/LsMetricsMonitor.java
Patch:
@@ -74,7 +74,7 @@ public EnumMap<LsMetricStats, ListStatistics> call() throws IOException {
                 final long newstrt = System.nanoTime();
                 stats.addValue(
                     (double) (newcount - count) /
-                        (double) TimeUnit.SECONDS.convert(newstrt - start, TimeUnit.NANOSECONDS)
+                        (double) TimeUnit.SECONDS.convert(Math.max(newstrt - start, 1_000_000_000), TimeUnit.NANOSECONDS)
                 );
                 start = newstrt;
                 count = newcount;

File: logstash-core/src/main/java/org/logstash/Cloner.java
Patch:
@@ -42,7 +42,8 @@ public static <T> T deep(final T input) {
         } else if (input instanceof List<?>) {
             return (T) deepList((List<?>) input);
         } else if (input instanceof RubyString) {
-            return (T) ((RubyString) input).doClone();
+            // new instance but sharing ByteList (until either String is modified)
+            return (T) ((RubyString) input).dup();
         } else if (input instanceof Collection<?>) {
             throw new ClassCastException("unexpected Collection type " + input.getClass());
         }

File: logstash-core/src/main/java/org/logstash/config/ir/ConfigCompiler.java
Patch:
@@ -53,9 +53,9 @@ private ConfigCompiler() {
      * @throws InvalidIRException if the the configuration contains errors
      */
     @SuppressWarnings("unchecked")
-    public static PipelineIR configToPipelineIR(final @SuppressWarnings("rawtypes") RubyArray sourcesWithMetadata,
+    public static PipelineIR configToPipelineIR(final List<SourceWithMetadata> sourcesWithMetadata,
                                                 final boolean supportEscapes) throws InvalidIRException {
-        return compileSources((List<SourceWithMetadata>) sourcesWithMetadata, supportEscapes);
+        return compileSources(sourcesWithMetadata, supportEscapes);
     }
 
     public static PipelineIR compileSources(List<SourceWithMetadata> sourcesWithMetadata, boolean supportEscapes) throws InvalidIRException {

File: logstash-core/src/main/java/org/logstash/execution/QueueBatch.java
Patch:
@@ -26,8 +26,7 @@
 
 public interface QueueBatch {
     int filteredSize();
-    @SuppressWarnings({"rawtypes"}) RubyArray to_a();
-    Collection<RubyEvent> collection();
-    void merge(RubyEvent event);
+    RubyArray<RubyEvent> to_a();
+    Collection<RubyEvent> events();
     void close() throws IOException;
 }

File: logstash-core/src/main/java/org/logstash/ext/JrubyAckedReadClientExt.java
Patch:
@@ -76,13 +76,12 @@ public boolean isEmpty() {
 
     @Override
     public QueueBatch newBatch() {
-        return AckedReadBatch.create(queue, 0, 0);
+        return AckedReadBatch.create();
     }
 
     @Override
     public QueueBatch readBatch() {
-        AckedReadBatch batch =
-            AckedReadBatch.create(queue, batchSize, waitForMillis);
+        final AckedReadBatch batch = AckedReadBatch.create(queue, batchSize, waitForMillis);
         startMetrics(batch);
         return batch;
     }

File: logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadClientExt.java
Patch:
@@ -77,8 +77,7 @@ public QueueBatch newBatch() {
     @Override
     @SuppressWarnings("unchecked")
     public QueueBatch readBatch() throws InterruptedException {
-        MemoryReadBatch batch = MemoryReadBatch.create(
-                LsQueueUtils.drain(queue, batchSize, waitForNanos));
+        final MemoryReadBatch batch = MemoryReadBatch.create(LsQueueUtils.drain(queue, batchSize, waitForNanos));
         startMetrics(batch);
         return batch;
     }

File: logstash-core/src/test/java/org/logstash/config/ir/EventConditionTest.java
Patch:
@@ -72,7 +72,7 @@ public void afterEach() {
     }
 
     @Test
-    @SuppressWarnings("rawtypes")
+    @SuppressWarnings({"rawtypes", "unchecked"})
     public void testInclusionWithFieldInField() throws Exception {
         final PipelineIR pipelineIR = ConfigCompiler.configToPipelineIR(
                 IRHelpers.toSourceWithMetadata("input {mockinput{}} filter { " +
@@ -154,6 +154,7 @@ public void testConditionWithConstantEmptyStringValue() throws Exception {
         testConditionWithConstantValue("\"\"", 0);
     }
 
+    @SuppressWarnings({"unchecked"})
     private void testConditionWithConstantValue(String condition, int expectedMatches) throws Exception {
         final PipelineIR pipelineIR = ConfigCompiler.configToPipelineIR(
                 IRHelpers.toSourceWithMetadata("input {mockinput{}} filter { " +

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -247,13 +247,15 @@ public String toJson() throws JsonProcessingException {
         return JSON_MAPPER.writeValueAsString(this.data);
     }
 
+    private static final Event[] NULL_ARRAY = new Event[0];
+
     @SuppressWarnings("unchecked")
     public static Event[] fromJson(String json)
             throws IOException
     {
         // empty/blank json string does not generate an event
         if (json == null || json.trim().isEmpty()) {
-            return new Event[]{ };
+            return NULL_ARRAY;
         }
 
         Event[] result;

File: logstash-core/src/main/java/org/logstash/config/ir/CompiledPipeline.java
Patch:
@@ -119,7 +119,7 @@ public CompiledPipeline(
             filters = setupFilters(cve);
             outputs = setupOutputs(cve);
         } catch (Exception e) {
-            throw new IllegalStateException("Unable to configure plugins: " + e.getMessage());
+            throw new IllegalStateException("Unable to configure plugins: " + e.getMessage(), e);
         }
     }
 

File: logstash-core/src/test/java/org/logstash/plugins/MetricTestCase.java
Patch:
@@ -51,7 +51,7 @@ public void setup() {
         executionContext = new ExecutionContextExt(RUBY, EXECUTION_CONTEXT_CLASS);
     }
 
-    protected static IRubyObject runRubyScript(String script) {
+    public static IRubyObject runRubyScript(String script) {
         IRubyObject m = RUBY.evalScriptlet(script);
         return m;
     }

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/LazyDelegatingGauge.java
Patch:
@@ -111,7 +111,7 @@ private synchronized void wakeMetric(Object value) {
             } else if (value instanceof RubyTimestamp) {
                 lazyMetric = new RubyTimeStampGauge(key, (RubyTimestamp) value);
             } else {
-                LOGGER.warn("A gauge metric of an unknown type ({}) has been create for key: {}. This may result in invalid serialization.  It is recommended to " +
+                LOGGER.warn("A gauge metric of an unknown type ({}) has been created for key: {}. This may result in invalid serialization.  It is recommended to " +
                         "log an issue to the responsible developer/development team.", value.getClass().getCanonicalName(), key);
                 lazyMetric = new UnknownGauge(key, value);
             }

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/OutputStrategyExt.java
Patch:
@@ -54,8 +54,8 @@ public IRubyObject init(final ThreadContext context) {
         }
 
         @JRubyMethod
-        public IRubyObject classes() {
-            return map.rb_values();
+        public IRubyObject classes(final ThreadContext context) {
+            return map.values(context);
         }
 
         @JRubyMethod
@@ -78,7 +78,7 @@ public RubyClass classFor(final ThreadContext context, final IRubyObject type) {
                     String.format(
                         "Could not find output delegator strategy of type '%s'. Value strategies: %s",
                         type.asJavaString(),
-                        map.rb_values().stream().map(v -> ((IRubyObject) v).asJavaString())
+                        map.values(context).stream().map(v -> ((IRubyObject) v).asJavaString())
                             .collect(Collectors.joining(", "))
                     )
                 );

File: logstash-core/src/main/java/org/logstash/config/ir/CompiledPipeline.java
Patch:
@@ -38,7 +38,7 @@
 import java.util.stream.Stream;
 
 /**
- * <h3>Compiled Logstash Pipeline Configuration.</h3>
+ * <h2>Compiled Logstash Pipeline Configuration.</h2>
  * This class represents an executable pipeline, compiled from the configured topology that is
  * learnt from {@link PipelineIR}.
  * Each compiled pipeline consists in graph of {@link Dataset} that represent either a

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/EventCondition.java
Patch:
@@ -51,7 +51,7 @@ public interface EventCondition {
     boolean fulfilled(JrubyEventExtLibrary.RubyEvent event);
 
     /**
-     * <h3>EventCondition Compiler.</h3>
+     * <h2>EventCondition Compiler.</h2>
      * Compiles {@link BooleanExpression} into {@link EventCondition} globally ensuring that no
      * duplicate {@link EventCondition} are generated by strict synchronization on the internal
      * compiler cache {@link EventCondition.Compiler#cache}.

File: logstash-core/src/main/java/org/logstash/config/ir/CompiledPipeline.java
Patch:
@@ -34,7 +34,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Objects;
-import java.util.concurrent.atomic.AtomicReference;
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/FilterDelegatorExt.java
Patch:
@@ -105,7 +105,7 @@ protected RubyArray doMultiFilter(final RubyArray batch) {
         org.apache.logging.log4j.ThreadContext.put("plugin.id", pluginId.toString());
         try {
             return (RubyArray) filterMethod.call(
-                    getRuntime().getCurrentContext(), filter, filterClass, FILTER_METHOD_NAME, batch);
+                    RUBY.getCurrentContext(), filter, filterClass, FILTER_METHOD_NAME, batch);
         } finally {
             org.apache.logging.log4j.ThreadContext.remove("plugin.id");
         }

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/OutputDelegatorExt.java
Patch:
@@ -15,6 +15,8 @@
 import org.logstash.ext.JrubyEventExtLibrary;
 import org.logstash.instrument.metrics.AbstractMetricExt;
 
+import static org.logstash.RubyUtil.RUBY;
+
 @JRubyClass(name = "OutputDelegator")
 public final class
 OutputDelegatorExt extends AbstractOutputDelegatorExt {
@@ -77,7 +79,7 @@ protected void doOutput(final Collection<JrubyEventExtLibrary.RubyEvent> batch)
         try {
             final IRubyObject pluginId = this.getId();
             org.apache.logging.log4j.ThreadContext.put("plugin.id", pluginId.toString());
-            strategy.multiReceive(getRuntime().getCurrentContext(), (IRubyObject) batch);
+            strategy.multiReceive(RUBY.getCurrentContext(), (IRubyObject) batch);
         } catch (final InterruptedException ex) {
             throw new IllegalStateException(ex);
         } finally {

File: logstash-core/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -61,7 +61,7 @@ public static ConvertedMap newFromMap(Map<? extends Serializable, Object> o) {
     }
 
     public static ConvertedMap newFromRubyHash(final RubyHash o) {
-        return newFromRubyHash(o.getRuntime().getCurrentContext(), o);
+        return newFromRubyHash(RubyUtil.RUBY.getCurrentContext(), o);
     }
 
     public static ConvertedMap newFromRubyHash(final ThreadContext context, final RubyHash o) {

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java
Patch:
@@ -130,7 +130,7 @@ public RubyArray multiFilter(final IRubyObject input) {
     @SuppressWarnings("rawtypes")
     public RubyArray flush(final IRubyObject input) {
         RubyHash options = (RubyHash) input;
-        final ThreadContext context = options.getRuntime().getCurrentContext();
+        final ThreadContext context = RubyUtil.RUBY.getCurrentContext();
         final IRubyObject newEvents = doFlush(context, options);
         final RubyArray result;
         if (newEvents.isNil()) {

File: logstash-core/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -61,7 +61,7 @@ public static ConvertedMap newFromMap(Map<? extends Serializable, Object> o) {
     }
 
     public static ConvertedMap newFromRubyHash(final RubyHash o) {
-        return newFromRubyHash(WorkerLoop.THREAD_CONTEXT.get(), o);
+        return newFromRubyHash(o.getRuntime().getCurrentContext(), o);
     }
 
     public static ConvertedMap newFromRubyHash(final ThreadContext context, final RubyHash o) {

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java
Patch:
@@ -11,7 +11,6 @@
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.RubyUtil;
-import org.logstash.execution.WorkerLoop;
 import org.logstash.ext.JrubyEventExtLibrary;
 import org.logstash.instrument.metrics.AbstractNamespacedMetricExt;
 import org.logstash.instrument.metrics.MetricKeys;
@@ -131,7 +130,7 @@ public RubyArray multiFilter(final IRubyObject input) {
     @SuppressWarnings("rawtypes")
     public RubyArray flush(final IRubyObject input) {
         RubyHash options = (RubyHash) input;
-        final ThreadContext context = WorkerLoop.THREAD_CONTEXT.get();
+        final ThreadContext context = options.getRuntime().getCurrentContext();
         final IRubyObject newEvents = doFlush(context, options);
         final RubyArray result;
         if (newEvents.isNil()) {

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/FilterDelegatorExt.java
Patch:
@@ -12,7 +12,6 @@
 import org.jruby.internal.runtime.methods.DynamicMethod;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
-import org.logstash.execution.WorkerLoop;
 import org.logstash.instrument.metrics.AbstractNamespacedMetricExt;
 import org.logstash.instrument.metrics.counter.LongCounter;
 
@@ -106,7 +105,7 @@ protected RubyArray doMultiFilter(final RubyArray batch) {
         org.apache.logging.log4j.ThreadContext.put("plugin.id", pluginId.toString());
         try {
             return (RubyArray) filterMethod.call(
-                    WorkerLoop.THREAD_CONTEXT.get(), filter, filterClass, FILTER_METHOD_NAME, batch);
+                    getRuntime().getCurrentContext(), filter, filterClass, FILTER_METHOD_NAME, batch);
         } finally {
             org.apache.logging.log4j.ThreadContext.remove("plugin.id");
         }

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/JavaFilterDelegatorExt.java
Patch:
@@ -76,9 +76,10 @@ protected void doRegister(ThreadContext context) {
     protected IRubyObject doFlush(final ThreadContext context, final RubyHash options) {
         if (filter.requiresFlush()) {
             Collection<Event> outputEvents = filter.flush(filterMatchListener);
-            @SuppressWarnings("rawtypes") RubyArray newBatch = RubyArray.newArray(RubyUtil.RUBY, outputEvents.size());
+            final Ruby runtime = context.runtime;
+            @SuppressWarnings("rawtypes") RubyArray newBatch = RubyArray.newArray(runtime, outputEvents.size());
             for (Event outputEvent : outputEvents) {
-                newBatch.add(JrubyEventExtLibrary.RubyEvent.newRubyEvent(RubyUtil.RUBY, (org.logstash.Event)outputEvent));
+                newBatch.add(JrubyEventExtLibrary.RubyEvent.newRubyEvent(runtime, (org.logstash.Event)outputEvent));
             }
             return newBatch;
         }

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/OutputDelegatorExt.java
Patch:
@@ -12,7 +12,6 @@
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.execution.ExecutionContextExt;
-import org.logstash.execution.WorkerLoop;
 import org.logstash.ext.JrubyEventExtLibrary;
 import org.logstash.instrument.metrics.AbstractMetricExt;
 
@@ -78,7 +77,7 @@ protected void doOutput(final Collection<JrubyEventExtLibrary.RubyEvent> batch)
         try {
             final IRubyObject pluginId = this.getId();
             org.apache.logging.log4j.ThreadContext.put("plugin.id", pluginId.toString());
-            strategy.multiReceive(WorkerLoop.THREAD_CONTEXT.get(), (IRubyObject) batch);
+            strategy.multiReceive(getRuntime().getCurrentContext(), (IRubyObject) batch);
         } catch (final InterruptedException ex) {
             throw new IllegalStateException(ex);
         } finally {

File: logstash-core/src/test/java/org/logstash/ext/JrubyMemoryReadClientExtTest.java
Patch:
@@ -23,7 +23,7 @@ public void testInflightBatchesTracking() throws InterruptedException, IOExcepti
             new ArrayBlockingQueue<>(10);
         final JrubyMemoryReadClientExt client =
             JrubyMemoryReadClientExt.create(queue, 5, 50);
-        final ThreadContext context = WorkerLoop.THREAD_CONTEXT.get();
+        final ThreadContext context = client.getRuntime().getCurrentContext();
         final QueueBatch batch = client.readBatch();
         final RubyHash inflight = client.rubyGetInflightBatches(context);
         assertThat(inflight.size(), is(1));

File: tools/dependencies-report/src/main/java/org/logstash/dependencies/Main.java
Patch:
@@ -46,7 +46,7 @@ public static void main(String[] args) throws IOException {
         );
 
         // If there were unknown results in the report, exit with a non-zero status
-        //System.exit(reportResult ? 0 : 1);
+        System.exit(reportResult ? 0 : 1);
     }
 
     static InputStream getResourceAsStream(String resourcePath) {

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/JavaInputDelegatorExt.java
Patch:
@@ -61,6 +61,7 @@ public IRubyObject start(final ThreadContext context) {
         }
         Thread t = new Thread(() -> {
             org.apache.logging.log4j.ThreadContext.put("pipeline.id", pipeline.pipelineId().toString());
+            org.apache.logging.log4j.ThreadContext.put("plugin.id", this.getId(context).toString());
             input.start(queueWriter::push);
         });
         t.setName(pipeline.pipelineId().asJavaString() + "_" + input.getName() + "_" + input.getId());

File: logstash-core/src/test/java/org/logstash/config/ir/CompiledPipelineTest.java
Patch:
@@ -14,6 +14,7 @@
 import java.util.function.Supplier;
 import org.hamcrest.CoreMatchers;
 import org.hamcrest.MatcherAssert;
+import org.jruby.RubyObject;
 import org.jruby.RubyString;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.junit.After;
@@ -490,9 +491,10 @@ public AbstractOutputDelegatorExt buildOutput(final RubyString name, SourceWithM
         @Override
         public AbstractFilterDelegatorExt buildFilter(final RubyString name, SourceWithMetadata source,
                                                       final IRubyObject args, Map<String, Object> pluginArgs) {
+            final RubyObject configNameDouble = org.logstash.config.ir.PluginConfigNameMethodDouble.create(name);
             return new FilterDelegatorExt(
                 RubyUtil.RUBY, RubyUtil.FILTER_DELEGATOR_CLASS)
-                .initForTesting(setupPlugin(name, filters));
+                    .initForTesting(setupPlugin(name, filters), configNameDouble);
         }
 
         @Override

File: logstash-core/src/main/java/org/logstash/RubyUtil.java
Patch:
@@ -55,6 +55,7 @@
 import org.logstash.plugins.HooksRegistryExt;
 import org.logstash.plugins.PluginFactoryExt;
 import org.logstash.plugins.UniversalPluginExt;
+import org.logstash.util.UtilExt;
 
 import java.util.stream.Stream;
 
@@ -308,6 +309,7 @@ public final class RubyUtil {
         NULL_TIMED_EXECUTION_CLASS.defineAnnotatedMethods(NullMetricExt.NullTimedExecution.class);
         NULL_COUNTER_CLASS.defineAnnotatedMethods(NullNamespacedMetricExt.NullCounter.class);
         UTIL_MODULE = LOGSTASH_MODULE.defineModuleUnder("Util");
+        UTIL_MODULE.defineAnnotatedMethods(UtilExt.class);
         ABSTRACT_DLQ_WRITER_CLASS = UTIL_MODULE.defineClassUnder(
             "AbstractDeadLetterQueueWriterExt", RUBY.getObject(),
             ObjectAllocator.NOT_ALLOCATABLE_ALLOCATOR

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/JavaInputDelegatorExt.java
Patch:
@@ -6,7 +6,6 @@
 import org.jruby.RubyObject;
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;
-import org.jruby.javasupport.JavaObject;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.RubyUtil;
@@ -66,7 +65,7 @@ public IRubyObject start(final ThreadContext context) {
         });
         t.setName(pipeline.pipelineId().asJavaString() + "_" + input.getName() + "_" + input.getId());
         t.start();
-        return JavaObject.wrap(context.getRuntime(), t);
+        return RubyUtil.toRubyObject(t);
     }
 
     @JRubyMethod(name = "metric=")

File: logstash-core/src/test/java/org/logstash/log/DefaultDeprecationLoggerTest.java
Patch:
@@ -40,6 +40,7 @@ public void setUp() throws IOException {
 
     @After
     public void tearDown() throws IOException {
+        LogManager.shutdown();
         LogTestUtils.deleteLogFile("logstash-deprecation.log");
         LogTestUtils.reloadLogConfiguration();
     }

File: logstash-core/src/test/java/org/logstash/log/DefaultDeprecationLoggerTest.java
Patch:
@@ -40,9 +40,8 @@ public void setUp() throws IOException {
 
     @After
     public void tearDown() throws IOException {
-        LogTestUtils.reloadLogConfiguration();
-
         LogTestUtils.deleteLogFile("logstash-deprecation.log");
+        LogTestUtils.reloadLogConfiguration();
     }
 
     @Test

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriter.java
Patch:
@@ -131,7 +131,7 @@ private void innerWriteEntry(DLQEntry entry) throws IOException {
         byte[] record = entry.serialize();
         int eventPayloadSize = RECORD_HEADER_SIZE + record.length;
         if (currentQueueSize.longValue() + eventPayloadSize > maxQueueSize) {
-            logger.error("cannot write event to DLQ: reached maxQueueSize of " + maxQueueSize);
+            logger.error("cannot write event to DLQ(path: " + this.queuePath + "): reached maxQueueSize of " + maxQueueSize);
             return;
         } else if (currentWriter.getPosition() + eventPayloadSize > maxSegmentSize) {
             currentWriter.close();

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/ComputeStepSyntaxElement.java
Patch:
@@ -15,8 +15,8 @@
 import java.util.stream.Collectors;
 import java.util.stream.StreamSupport;
 import org.codehaus.commons.compiler.CompileException;
-import org.codehaus.commons.compiler.ICookable;
 import org.codehaus.commons.compiler.ISimpleCompiler;
+import org.codehaus.janino.Scanner;
 import org.codehaus.janino.SimpleCompiler;
 
 /**
@@ -132,7 +132,7 @@ private static Path debugDir() {
         Path sourceDir = null;
         try {
             final Path parentDir;
-            final String dir = System.getProperty(ICookable.SYSTEM_PROPERTY_SOURCE_DEBUGGING_DIR);
+            final String dir = System.getProperty(Scanner.SYSTEM_PROPERTY_SOURCE_DEBUGGING_DIR);
             if (dir != null) {
                 parentDir = Paths.get(dir);
                 sourceDir = parentDir.resolve("org").resolve("logstash").resolve("generated");

File: logstash-core/src/main/java/org/logstash/common/io/RecordIOReader.java
Patch:
@@ -59,7 +59,7 @@ public RecordIOReader(Path path) throws IOException {
         if (versionInFile != VERSION) {
             this.channel.close();
             throw new RuntimeException(String.format(
-                    "Invalid version on PQ data file %s. Expected version: %c. Version found on file: %c",
+                    "Invalid version on DLQ data file %s. Expected version: %c. Version found on file: %c",
                     path, VERSION, versionInFile));
         }
         this.channelPosition = this.channel.position();

File: logstash-core/src/main/java/org/logstash/execution/JavaBasePipelineExt.java
Patch:
@@ -56,7 +56,8 @@ public JavaBasePipelineExt initialize(final ThreadContext context, final IRubyOb
                     context.runtime, RubyUtil.EXECUTION_CONTEXT_FACTORY_CLASS
                 ).initialize(context, args[3], this, dlqWriter(context)),
                 RubyUtil.FILTER_DELEGATOR_CLASS
-            )
+            ),
+            getSecretStore(context)
         );
         inputs = RubyArray.newArray(context.runtime, lirExecution.inputs());
         filters = RubyArray.newArray(context.runtime, lirExecution.filters());

File: logstash-core/src/test/java/org/logstash/secret/store/SecretStoreFactoryTest.java
Patch:
@@ -133,7 +133,7 @@ private void validateMarker(SecretStore secretStore) {
     /**
      * Valid alternate implementation
      */
-    static class MemoryStore implements SecretStore {
+    public static class MemoryStore implements SecretStore {
 
         Map<SecretIdentifier, ByteBuffer> secrets = new HashMap(1);
 
@@ -178,7 +178,8 @@ public void purgeSecret(SecretIdentifier id) {
 
         @Override
         public byte[] retrieveSecret(SecretIdentifier id) {
-            return secrets.get(id).array();
+            ByteBuffer bb = secrets.get(id);
+            return bb != null ? bb.array() : null;
         }
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/EventCondition.java
Patch:
@@ -287,7 +287,7 @@ private static EventCondition in(final In in) {
                     (EventValueExpression) left, (List<?>) ((ValueExpression) right).get()
                 );
             } else if (eAndE(in)) {
-                condition = in((EventValueExpression) right, (EventValueExpression) left);
+                condition = in((EventValueExpression) left, (EventValueExpression) right);
             } else if (vAndV(in)) {
                 condition = in((ValueExpression) left, (ValueExpression) right);
             } else {
@@ -571,8 +571,8 @@ public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
                 if (lfound instanceof ConvertedList || lfound instanceof ConvertedMap) {
                     return false;
                 } else if (lfound instanceof RubyString && rfound instanceof RubyString) {
-                    return ((RubyString) lfound).getByteList()
-                        .indexOf(((RubyString) rfound).getByteList()) > -1;
+                    return ((RubyString) rfound).getByteList()
+                        .indexOf(((RubyString) lfound).getByteList()) > -1;
                 } else if (rfound instanceof ConvertedList) {
                     return contains((ConvertedList) rfound, lfound);
                 } else {

File: logstash-core/src/test/java/org/logstash/config/ir/CompiledPipelineTest.java
Patch:
@@ -50,7 +50,7 @@ public final class CompiledPipelineTest extends RubyEnvTestCase {
     /**
      * Mock filter that does not modify the batch.
      */
-    private static final IRubyObject IDENTITY_FILTER = RubyUtil.RUBY.evalScriptlet(
+    static final IRubyObject IDENTITY_FILTER = RubyUtil.RUBY.evalScriptlet(
         String.join(
             "\n",
             "output = Object.new",
@@ -64,7 +64,7 @@ public final class CompiledPipelineTest extends RubyEnvTestCase {
     /**
      * Mock filter that adds the value 'bar' to the field 'foo' for every event in the batch.
      */
-    private static final IRubyObject ADD_FIELD_FILTER = RubyUtil.RUBY.evalScriptlet(
+    static final IRubyObject ADD_FIELD_FILTER = RubyUtil.RUBY.evalScriptlet(
         String.join(
             "\n",
             "output = Object.new",
@@ -458,7 +458,7 @@ private Supplier<Consumer<Collection<JrubyEventExtLibrary.RubyEvent>>> mockOutpu
     /**
      * Configurable Mock {@link PluginFactory}
      */
-    private static final class MockPluginFactory implements PluginFactory {
+    static final class MockPluginFactory implements PluginFactory {
 
         private final Map<String, Supplier<IRubyObject>> inputs;
 

File: logstash-core/src/main/java/org/logstash/plugins/discovery/PluginRegistry.java
Patch:
@@ -8,6 +8,7 @@
 import co.elastic.logstash.api.Input;
 import co.elastic.logstash.api.LogstashPlugin;
 import co.elastic.logstash.api.Output;
+import org.reflections.Reflections;
 
 import java.lang.annotation.Annotation;
 import java.lang.reflect.Constructor;
@@ -33,7 +34,7 @@ private PluginRegistry() {} // utility class
 
     @SuppressWarnings("unchecked")
     private static void discoverPlugins() {
-        Reflections reflections = new Reflections("");
+        Reflections reflections = new Reflections("org.logstash.plugins");
         Set<Class<?>> annotated = reflections.getTypesAnnotatedWith(LogstashPlugin.class);
         for (final Class<?> cls : annotated) {
             for (final Annotation annotation : cls.getAnnotations()) {

File: logstash-core/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -71,6 +71,8 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args) {
                 this.event = new Event(
                     ConvertedMap.newFromRubyHash(context, (RubyHash) data)
                 );
+            } else if (data != null && data.getJavaClass().equals(Event.class)) {
+                this.event = data.toJava(Event.class);
             } else {
                 initializeFallback(context, data);
             }

File: logstash-core/src/test/java/org/logstash/plugins/PluginValidatorTest.java
Patch:
@@ -1,6 +1,7 @@
 package org.logstash.plugins;
 
 import org.junit.Assert;
+import org.junit.Ignore;
 import org.junit.Test;
 import org.logstash.plugins.codecs.Line;
 import org.logstash.plugins.filters.Uuid;
@@ -43,6 +44,7 @@ public void testValidOutputPlugin() {
         Assert.assertTrue(PluginValidator.validatePlugin(PluginLookup.PluginType.OUTPUT, Stdout.class));
     }
 
+    @Ignore("Test failing on windows for many weeks. See https://github.com/elastic/logstash/issues/10926")
     @Test
     public void testInvalidInputPlugin() throws IOException {
         Path tempJar = null;

File: logstash-core/src/main/java/org/logstash/plugins/pipeline/AddressState.java
Patch:
@@ -11,8 +11,6 @@ public class AddressState {
     private final Set<PipelineOutput> outputs = ConcurrentHashMap.newKeySet();
     private volatile PipelineInput input = null;
 
-    AddressState(String address) {}
-
     /**
      * Add the given output and ensure associated input's receivers are updated
      * @param output output to be added

File: logstash-core/src/main/java/org/logstash/plugins/pipeline/PipelineInput.java
Patch:
@@ -6,15 +6,14 @@
 
 public interface PipelineInput {
     /**
-     * Accepts an event
-     * It might be rejected if the input is stopping
+     * Accepts an event. It might be rejected if the input is stopping.
+     *
      * @param events a collection of events
      * @return true if the event was successfully received
      */
     boolean internalReceive(Stream<JrubyEventExtLibrary.RubyEvent> events);
 
     /**
-     *
      * @return true if the input is running
      */
     boolean isRunning();

File: logstash-core/src/main/java/org/logstash/plugins/ConfigurationImpl.java
Patch:
@@ -44,6 +44,8 @@ public <T> T get(final PluginConfigSpec<T> configSpec) {
                 return (T) o;
             } else if (configSpec.type() == Double.class && o.getClass() == Long.class) {
                 return configSpec.type().cast(((Long)o).doubleValue());
+            } else if (configSpec.type() == Boolean.class && o instanceof String) {
+                return configSpec.type().cast(Boolean.parseBoolean((String) o));
             } else if (configSpec.type() == Codec.class && o instanceof String && pluginFactory != null) {
                 Codec codec = pluginFactory.buildDefaultCodec((String) o);
                 return configSpec.type().cast(codec);

File: logstash-core/src/main/java/co/elastic/logstash/api/Context.java
Patch:
@@ -1,7 +1,6 @@
 package co.elastic.logstash.api;
 
 import org.apache.logging.log4j.Logger;
-import org.logstash.common.io.DeadLetterQueueWriter;
 
 /**
  * Provides Logstash context to plugins.

File: logstash-core/src/main/java/org/logstash/plugins/ContextImpl.java
Patch:
@@ -1,6 +1,7 @@
 package org.logstash.plugins;
 
 import co.elastic.logstash.api.Context;
+import co.elastic.logstash.api.DeadLetterQueueWriter;
 import co.elastic.logstash.api.Event;
 import co.elastic.logstash.api.EventFactory;
 import co.elastic.logstash.api.Metric;
@@ -9,7 +10,6 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.logstash.ConvertedMap;
-import org.logstash.common.io.DeadLetterQueueWriter;
 
 import java.io.Serializable;
 import java.util.Map;

File: logstash-core/src/test/java/org/logstash/plugins/TestContext.java
Patch:
@@ -1,11 +1,11 @@
 package org.logstash.plugins;
 
 import co.elastic.logstash.api.Context;
+import co.elastic.logstash.api.DeadLetterQueueWriter;
 import co.elastic.logstash.api.EventFactory;
 import co.elastic.logstash.api.NamespacedMetric;
 import co.elastic.logstash.api.Plugin;
 import org.apache.logging.log4j.Logger;
-import org.logstash.common.io.DeadLetterQueueWriter;
 
 public class TestContext implements Context {
 

File: logstash-core/src/main/java/org/logstash/instrument/monitors/HotThreadsMonitor.java
Patch:
@@ -133,7 +133,7 @@ public static List<ThreadReport> detect(Map<String, String> options) {
                 throw new IllegalArgumentException("Invalid sort order");
         }
 
-        Integer threadInfoMaxDepth = 3;
+        Integer threadInfoMaxDepth = 50;
         if (options.containsKey(STACKTRACE_SIZE)) {
             threadInfoMaxDepth = Integer.valueOf(options.get(STACKTRACE_SIZE));
         }

File: logstash-core/src/main/java/co/elastic/logstash/api/Codec.java
Patch:
@@ -47,6 +47,7 @@ public interface Codec extends Plugin {
      * Encodes an {@link Event} and writes it to the specified {@link OutputStream}.
      * @param event The event to encode.
      * @param output The stream to which the encoded event should be written.
+     * @throws java.io.IOException Exceptions coming from the output stream
      */
     void encode(Event event, OutputStream output) throws IOException;
 

File: logstash-core/src/main/java/org/logstash/plugins/PluginFactoryExt.java
Patch:
@@ -339,7 +339,7 @@ private IRubyObject plugin(final ThreadContext context, final PluginLookup.Plugi
                     }
 
                     if (codec != null) {
-                        return JavaUtil.convertJavaToRuby(RubyUtil.RUBY, new JavaCodecDelegator(name, id, typeScopedMetric, codec));
+                        return JavaUtil.convertJavaToRuby(RubyUtil.RUBY, new JavaCodecDelegator(typeScopedMetric, codec));
                     } else {
                         throw new IllegalStateException("Unable to instantiate codec: " + pluginClass);
                     }

File: logstash-core/src/test/java/org/logstash/config/ir/RubyEnvTestCase.java
Patch:
@@ -3,10 +3,13 @@
 import java.nio.file.Path;
 import java.nio.file.Paths;
 import org.jruby.RubyHash;
+import org.jruby.runtime.builtin.IRubyObject;
 import org.jruby.runtime.load.LoadService;
 import org.junit.BeforeClass;
 import org.logstash.RubyUtil;
 
+import static org.logstash.RubyUtil.RUBY;
+
 public abstract class RubyEnvTestCase {
 
     @BeforeClass

File: logstash-core/src/main/java/org/logstash/plugins/PluginFactoryExt.java
Patch:
@@ -26,6 +26,7 @@
 import org.logstash.config.ir.compiler.AbstractFilterDelegatorExt;
 import org.logstash.config.ir.compiler.AbstractOutputDelegatorExt;
 import org.logstash.config.ir.compiler.FilterDelegatorExt;
+import org.logstash.config.ir.compiler.JavaCodecDelegator;
 import org.logstash.config.ir.compiler.JavaFilterDelegatorExt;
 import org.logstash.config.ir.compiler.JavaInputDelegatorExt;
 import org.logstash.config.ir.compiler.JavaOutputDelegatorExt;
@@ -338,7 +339,7 @@ private IRubyObject plugin(final ThreadContext context, final PluginLookup.Plugi
                     }
 
                     if (codec != null) {
-                        return JavaUtil.convertJavaToRuby(RubyUtil.RUBY, codec);
+                        return JavaUtil.convertJavaToRuby(RubyUtil.RUBY, new JavaCodecDelegator(name, id, typeScopedMetric, codec));
                     } else {
                         throw new IllegalStateException("Unable to instantiate codec: " + pluginClass);
                     }

File: logstash-core/src/main/java/org/logstash/plugins/outputs/Stdout.java
Patch:
@@ -20,7 +20,7 @@
 public class Stdout implements Output {
 
     public static final PluginConfigSpec<Codec> CODEC_CONFIG =
-            PluginConfigSpec.codecSetting("codec", "java-line");
+            PluginConfigSpec.codecSetting("codec", "java_line");
 
     private Codec codec;
     private OutputStream outputStream;
@@ -57,7 +57,7 @@ public void output(final Collection<Event> events) {
                 do {
                     encodeCompleted = codec.encode(e, encodeBuffer);
                     outputStream.write(encodeBuffer.array(), encodeBuffer.position(), encodeBuffer.limit());
-                    encodeBuffer.flip();
+                    encodeBuffer.clear();
                 }
                 while (!encodeCompleted);
             }

File: logstash-core/src/main/java/org/logstash/instrument/metrics/NullNamespacedMetricExt.java
Patch:
@@ -39,7 +39,7 @@ public NullNamespacedMetricExt(final Ruby runtime, final RubyClass metaClass) {
     @JRubyMethod(optional = 2)
     public NullNamespacedMetricExt initialize(final ThreadContext context,
         final IRubyObject[] args) {
-        this.metric = args.length > 0 && !args[0].isNil() ? (NullMetricExt) args[0] : new NullMetricExt(context.runtime, metaClass);
+        this.metric = args.length > 0 && !args[0].isNil() && (args[0] instanceof NullMetricExt) ? (NullMetricExt) args[0] : new NullMetricExt(context.runtime, metaClass);
         final IRubyObject namespaceName = args.length == 2 ? args[1] : NULL;
         if (namespaceName instanceof RubyArray) {
             this.namespaceName = (RubyArray) namespaceName;

File: logstash-core/src/main/java/org/logstash/plugins/ConfigurationImpl.java
Patch:
@@ -39,6 +39,9 @@ public <T> T get(final PluginConfigSpec<T> configSpec) {
             Object o = rawSettings.get(configSpec.name());
             if (configSpec.type().isAssignableFrom(o.getClass())) {
                 return (T) o;
+            } else if (configSpec.type() == Codec.class && o instanceof String && pluginFactory != null) {
+                Codec codec = pluginFactory.buildDefaultCodec((String)o);
+                return configSpec.type().cast(codec);
             } else {
                 throw new IllegalStateException(
                         String.format("Setting value for '%s' of type '%s' incompatible with defined type of '%s'",

File: logstash-core/src/test/java/org/logstash/plugins/inputs/StdinTest.java
Patch:
@@ -51,7 +51,7 @@ public void testUtf8Events() throws IOException {
                 new String("München3".getBytes(), Charset.forName("UTF-8"))
         };
         String testInput = String.join(Line.DEFAULT_DELIMITER, inputs) + Line.DEFAULT_DELIMITER;
-        TestConsumer queueWriter = testStdin(testInput.getBytes());
+        TestConsumer queueWriter = testStdin(testInput.getBytes("UTF-8"));
 
         List<Map<String, Object>> events = queueWriter.getEvents();
         assertEquals(3, events.size());

File: logstash-core/src/main/java/org/logstash/secret/store/backend/JavaKeyStore.java
Patch:
@@ -41,7 +41,7 @@ public final class JavaKeyStore implements SecretStore {
     private static final String KEYSTORE_TYPE = "pkcs12";
     private static final Logger LOGGER = LogManager.getLogger(JavaKeyStore.class);
     private static final String PATH_KEY = "keystore.file";
-    private static final CharsetEncoder asciiEncoder = StandardCharsets.US_ASCII.newEncoder();
+    private final CharsetEncoder asciiEncoder = StandardCharsets.US_ASCII.newEncoder();
     private KeyStore keyStore;
     private char[] keyStorePass;
     private Path keyStorePath;

File: logstash-core/src/main/java/org/logstash/ConvertedList.java
Patch:
@@ -37,7 +37,7 @@ public static ConvertedList newFromRubyArray(final IRubyObject[] a) {
         return result;
     }
 
-    public static ConvertedList newFromRubyArray(RubyArray a) {
+    public static ConvertedList newFromRubyArray(@SuppressWarnings("rawtypes") RubyArray a) {
         final ConvertedList result = new ConvertedList(a.size());
 
         for (IRubyObject o : a.toJavaArray()) {

File: logstash-core/src/main/java/org/logstash/RubyUtil.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash;
 
-import org.jruby.NativeException;
 import org.jruby.Ruby;
 import org.jruby.RubyClass;
 import org.jruby.RubyModule;
@@ -562,9 +561,10 @@ private RubyUtil() {
      * @param e the Java exception to wrap
      * @return RaiseException the wrapped IOError
      */
+    @SuppressWarnings("deprecation")
     public static RaiseException newRubyIOError(Ruby runtime, Throwable e) {
         // will preserve Java stacktrace & bubble up as a Ruby IOError
-        return new RaiseException(e, new NativeException(runtime, runtime.getIOError(), e));
+        return new RaiseException(e, new org.jruby.NativeException(runtime, runtime.getIOError(), e));
     }
 
     /**

File: logstash-core/src/main/java/org/logstash/Rubyfier.java
Patch:
@@ -55,6 +55,7 @@ public static IRubyObject deep(final Ruby runtime, final Object input) {
         return fallbackConvert(runtime, input, cls);
     }
 
+    @SuppressWarnings("rawtypes")
     private static RubyArray deepList(final Ruby runtime, final Collection<?> list) {
         final int length = list.size();
         final RubyArray array = runtime.newArray(length);

File: logstash-core/src/main/java/org/logstash/ackedqueue/AckedReadBatch.java
Patch:
@@ -52,7 +52,7 @@ public void merge(final IRubyObject event) {
         }
     }
 
-    @SuppressWarnings("unchecked")
+    @SuppressWarnings({"unchecked", "rawtypes"})
     @Override
     public RubyArray to_a() {
         ThreadContext context = RUBY.getCurrentContext();

File: logstash-core/src/main/java/org/logstash/common/AbstractDeadLetterQueueWriterExt.java
Patch:
@@ -141,7 +141,7 @@ public AbstractDeadLetterQueueWriterExt.PluginDeadLetterQueueWriterExt initializ
             final IRubyObject pluginType) {
             writerWrapper = innerWriter;
             if (writerWrapper.getJavaClass().equals(DeadLetterQueueWriter.class)) {
-                this.innerWriter = (DeadLetterQueueWriter) writerWrapper.toJava(
+                this.innerWriter = writerWrapper.toJava(
                     DeadLetterQueueWriter.class
                 );
             }

File: logstash-core/src/main/java/org/logstash/common/BufferedTokenizerExt.java
Patch:
@@ -18,7 +18,7 @@ public class BufferedTokenizerExt extends RubyObject {
 
     private static final IRubyObject MINUS_ONE = RubyUtil.RUBY.newFixnum(-1);
 
-    private RubyArray input = RubyUtil.RUBY.newArray();
+    private @SuppressWarnings("rawtypes") RubyArray input = RubyUtil.RUBY.newArray();
     private IRubyObject delimiter = RubyUtil.RUBY.newString("\n");
     private int sizeLimit;
     private boolean hasSizeLimit;
@@ -53,6 +53,7 @@ public IRubyObject init(final ThreadContext context, IRubyObject[] args) {
      * @return Extracted tokens
      */
     @JRubyMethod
+    @SuppressWarnings("rawtypes")
     public RubyArray extract(final ThreadContext context, IRubyObject data) {
         final RubyArray entities = ((RubyString) data).split(context, delimiter, MINUS_ONE);
         if (hasSizeLimit) {

File: logstash-core/src/main/java/org/logstash/config/ir/ConfigCompiler.java
Patch:
@@ -40,6 +40,6 @@ public static PipelineIR configToPipelineIR(final String config, final boolean s
                     RubyUtil.RUBY.newBoolean(supportEscapes)
                 }
             );
-        return (PipelineIR) code.toJava(PipelineIR.class);
+        return code.toJava(PipelineIR.class);
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/AbstractFilterDelegatorExt.java
Patch:
@@ -107,7 +107,7 @@ public IRubyObject getId() {
     }
 
     @JRubyMethod(name = "multi_filter")
-    @SuppressWarnings("unchecked")
+    @SuppressWarnings({"unchecked", "rawtypes"})
     public RubyArray multiFilter(final IRubyObject input) {
         RubyArray batch = (RubyArray) input;
         eventMetricIn.increment((long) batch.size());
@@ -124,9 +124,11 @@ public RubyArray multiFilter(final IRubyObject input) {
         return result;
     }
 
+    @SuppressWarnings({"rawtypes"})
     protected abstract RubyArray doMultiFilter(final RubyArray batch);
 
     @JRubyMethod(name = "flush")
+    @SuppressWarnings("rawtypes")
     public RubyArray flush(final IRubyObject input) {
         RubyHash options = (RubyHash) input;
         final ThreadContext context = WorkerLoop.THREAD_CONTEXT.get();

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/AbstractOutputDelegatorExt.java
Patch:
@@ -93,6 +93,7 @@ public IRubyObject metricEvents() {
     @SuppressWarnings("unchecked")
     @JRubyMethod(name = OUTPUT_METHOD_NAME)
     public IRubyObject multiReceive(final IRubyObject events) {
+        @SuppressWarnings("rawtypes")
         final RubyArray batch = (RubyArray) events;
         final int count = batch.size();
         eventMetricIn.increment((long) count);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/CommonActions.java
Patch:
@@ -96,7 +96,7 @@ static void addField(Event evt, Map<String, Object> fieldsToAdd) {
                         ((List) val).add(valueToSet);
                         evt.setField(keyToSet, val);
                     } else {
-                        RubyArray list = RubyArray.newArray(RubyUtil.RUBY, 2);
+                        @SuppressWarnings("rawtypes") RubyArray list = RubyArray.newArray(RubyUtil.RUBY, 2);
                         list.add(val);
                         list.add(valueToSet);
                         evt.setField(keyToSet, list);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/Dataset.java
Patch:
@@ -24,7 +24,8 @@ public interface Dataset {
     Dataset IDENTITY = new Dataset() {
         @SuppressWarnings("unchecked")
         @Override
-        public Collection<JrubyEventExtLibrary.RubyEvent> compute(final RubyArray batch, final boolean flush, final boolean shutdown) {
+        public Collection<JrubyEventExtLibrary.RubyEvent> compute(final @SuppressWarnings("rawtypes") RubyArray batch,
+                                                                  final boolean flush, final boolean shutdown) {
             return batch;
         }
 
@@ -43,7 +44,7 @@ public void clear() {
      * the pipeline it belongs to is shut down
      * @return Computed {@link RubyArray} of {@link org.logstash.ext.JrubyEventExtLibrary.RubyEvent}
      */
-    Collection<JrubyEventExtLibrary.RubyEvent> compute(RubyArray batch,
+    Collection<JrubyEventExtLibrary.RubyEvent> compute(@SuppressWarnings({"rawtypes"}) RubyArray batch,
         boolean flush, boolean shutdown);
 
     /**

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/FilterDelegatorExt.java
Patch:
@@ -94,6 +94,7 @@ protected IRubyObject getConfigName(final ThreadContext context) {
     }
 
     @Override
+    @SuppressWarnings({"rawtypes"})
     protected RubyArray doMultiFilter(final RubyArray batch) {
         return (RubyArray) filterMethod.call(
                 WorkerLoop.THREAD_CONTEXT.get(), filter, filterClass, FILTER_METHOD_NAME, batch);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/JavaFilterDelegatorExt.java
Patch:
@@ -54,7 +54,7 @@ public static JavaFilterDelegatorExt create(final String configName, final Strin
         return instance;
     }
 
-    @SuppressWarnings("unchecked")
+    @SuppressWarnings({"unchecked","rawtypes"})
     @Override
     protected RubyArray doMultiFilter(final RubyArray batch) {
         List<Event> inputEvents = (List<Event>) batch.stream()
@@ -76,7 +76,7 @@ protected void doRegister(ThreadContext context) {
     protected IRubyObject doFlush(final ThreadContext context, final RubyHash options) {
         if (filter.requiresFlush()) {
             Collection<Event> outputEvents = filter.flush(filterMatchListener);
-            RubyArray newBatch = RubyArray.newArray(RubyUtil.RUBY, outputEvents.size());
+            @SuppressWarnings("rawtypes") RubyArray newBatch = RubyArray.newArray(RubyUtil.RUBY, outputEvents.size());
             for (Event outputEvent : outputEvents) {
                 newBatch.add(JrubyEventExtLibrary.RubyEvent.newRubyEvent(RubyUtil.RUBY, (org.logstash.Event)outputEvent));
             }

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/OutputStrategyExt.java
Patch:
@@ -148,7 +148,7 @@ public static final class LegacyOutputStrategyExt extends OutputStrategyExt.Abst
 
         private IRubyObject workerCount;
 
-        private RubyArray workers;
+        private @SuppressWarnings({"rawtypes"}) RubyArray workers;
 
         public LegacyOutputStrategyExt(final Ruby runtime, final RubyClass metaClass) {
             super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/execution/MemoryReadBatch.java
Patch:
@@ -30,6 +30,7 @@ public static MemoryReadBatch create() {
     }
 
     @Override
+    @SuppressWarnings({"rawtypes"})
     public RubyArray to_a() {
         ThreadContext context = RUBY.getCurrentContext();
         final RubyArray result = context.runtime.newArray(events.size());

File: logstash-core/src/main/java/org/logstash/execution/PipelineReporterExt.java
Patch:
@@ -104,6 +104,7 @@ public RubyHash toHash(final ThreadContext context) {
         final RubyHash batchMap = (RubyHash) pipeline
             .callMethod(context, "filter_queue_client")
             .callMethod(context, "inflight_batches");
+        @SuppressWarnings("rawtypes")
         final RubyArray workerStates = workerStates(context, batchMap);
         result.op_aset(context, WORKER_STATES_KEY, workerStates);
         result.op_aset(
@@ -131,7 +132,7 @@ public RubyHash toHash(final ThreadContext context) {
         return result;
     }
 
-    @SuppressWarnings("unchecked")
+    @SuppressWarnings({"unchecked","rawtypes"})
     private RubyArray workerStates(final ThreadContext context, final RubyHash batchMap) {
         final RubyArray result = context.runtime.newArray();
         ((Iterable<IRubyObject>) pipeline.callMethod(context, "worker_threads"))
@@ -155,7 +156,7 @@ private RubyArray workerStates(final ThreadContext context, final RubyHash batch
         return result;
     }
 
-    @SuppressWarnings("unchecked")
+    @SuppressWarnings({"unchecked","rawtypes"})
     private RubyArray outputInfo(final ThreadContext context) {
         final RubyArray result = context.runtime.newArray();
         final IRubyObject outputs = pipeline.callMethod(context, "outputs");

File: logstash-core/src/main/java/org/logstash/execution/QueueBatch.java
Patch:
@@ -7,7 +7,7 @@
 
 public interface QueueBatch {
     int filteredSize();
-    RubyArray to_a();
+    @SuppressWarnings({"rawtypes"}) RubyArray to_a();
     void merge(IRubyObject event);
     void close() throws IOException;
 }

File: logstash-core/src/main/java/org/logstash/ext/JrubyAckedWriteClientExt.java
Patch:
@@ -28,10 +28,10 @@ public static JrubyAckedWriteClientExt create(final ThreadContext context, final
         final IRubyObject queue, final IRubyObject closed) {
         return new JrubyAckedWriteClientExt(
             context.runtime, RubyUtil.ACKED_WRITE_CLIENT_CLASS,
-            (JRubyAckedQueueExt) queue.toJava(
+            queue.toJava(
                 JRubyAckedQueueExt.class
             ),
-            (AtomicBoolean) closed.toJava(AtomicBoolean.class)
+            closed.toJava(AtomicBoolean.class)
         );
     }
 

File: logstash-core/src/main/java/org/logstash/instrument/metrics/AbstractNamespacedMetricExt.java
Patch:
@@ -51,13 +51,15 @@ public IRubyObject reportTime(final ThreadContext context, final IRubyObject key
     }
 
     @JRubyMethod(name = "namespace_name")
+    @SuppressWarnings("rawtypes")
     public RubyArray namespaceName(final ThreadContext context) {
         return getNamespaceName(context);
     }
 
     protected abstract IRubyObject getGauge(ThreadContext context, IRubyObject key,
         IRubyObject value);
 
+    @SuppressWarnings("rawtypes")
     protected abstract RubyArray getNamespaceName(ThreadContext context);
 
     protected abstract IRubyObject getCounter(ThreadContext context, IRubyObject key);

File: logstash-core/src/main/java/org/logstash/instrument/metrics/NamespacedMetricExt.java
Patch:
@@ -16,12 +16,12 @@ public final class NamespacedMetricExt extends AbstractNamespacedMetricExt {
 
     private static final long serialVersionUID = 1L;
 
-    private RubyArray namespaceName;
+    private @SuppressWarnings("rawtypes") RubyArray namespaceName;
 
     private MetricExt metric;
 
     public static NamespacedMetricExt create(final MetricExt metric,
-        final RubyArray namespaceName) {
+        final @SuppressWarnings("rawtypes") RubyArray namespaceName) {
         final NamespacedMetricExt res =
             new NamespacedMetricExt(RubyUtil.RUBY, RubyUtil.NAMESPACED_METRIC_CLASS);
         res.metric = metric;
@@ -93,6 +93,7 @@ protected IRubyObject doReportTime(final ThreadContext context, final IRubyObjec
     }
 
     @Override
+    @SuppressWarnings("rawtypes")
     protected RubyArray getNamespaceName(final ThreadContext context) {
         return namespaceName;
     }

File: logstash-core/src/main/java/org/logstash/instrument/metrics/NullNamespacedMetricExt.java
Patch:
@@ -19,12 +19,12 @@ public final class NullNamespacedMetricExt extends AbstractNamespacedMetricExt {
 
     private static final RubySymbol NULL = RubyUtil.RUBY.newSymbol("null");
 
-    private RubyArray namespaceName;
+    private @SuppressWarnings("rawtypes") RubyArray namespaceName;
 
     private NullMetricExt metric;
 
     public static AbstractNamespacedMetricExt create(final NullMetricExt metric,
-        final RubyArray namespaceName) {
+        final @SuppressWarnings("rawtypes") RubyArray namespaceName) {
         final NullNamespacedMetricExt res =
             new NullNamespacedMetricExt(RubyUtil.RUBY, RubyUtil.NULL_NAMESPACED_METRIC_CLASS);
         res.metric = metric;
@@ -88,6 +88,7 @@ protected IRubyObject doReportTime(final ThreadContext context, final IRubyObjec
     }
 
     @Override
+    @SuppressWarnings("rawtypes")
     protected RubyArray getNamespaceName(final ThreadContext context) {
         return namespaceName;
     }

File: logstash-core/src/main/java/org/logstash/instrument/metrics/SnapshotExt.java
Patch:
@@ -28,7 +28,7 @@ public SnapshotExt initialize(final ThreadContext context, final IRubyObject[] a
         if (args.length == 2) {
             createdAt = (RubyTime) args[1];
         } else {
-            createdAt = (RubyTime) RubyTime.newInstance(context, context.runtime.getTime());
+            createdAt = RubyTime.newInstance(context, context.runtime.getTime());
         }
         return this;
     }

File: logstash-core/src/main/java/org/logstash/instrument/metrics/counter/LongCounter.java
Patch:
@@ -37,7 +37,7 @@ public static LongCounter fromRubyBase(final AbstractNamespacedMetricExt metric,
         counter.callMethod(context, "increment", context.runtime.newFixnum(0));
         final LongCounter javaCounter;
         if (LongCounter.class.isAssignableFrom(counter.getJavaClass())) {
-            javaCounter = (LongCounter) counter.toJava(LongCounter.class);
+            javaCounter = counter.toJava(LongCounter.class);
         } else {
             javaCounter = DUMMY_COUNTER;
         }

File: logstash-core/src/main/java/org/logstash/log/LoggableExt.java
Patch:
@@ -54,7 +54,7 @@ private static RubyString log4jName(final ThreadContext context, final RubyModul
         return ((RubyString) ((RubyString) name).gsub(
             context, RubyUtil.RUBY.newString("::"), RubyUtil.RUBY.newString("."),
             Block.NULL_BLOCK
-        )).downcase19(context);
+        )).downcase(context);
     }
 
     /**

File: logstash-core/src/main/java/org/logstash/log/StructuredMessage.java
Patch:
@@ -14,7 +14,7 @@ public class StructuredMessage implements Message {
     private final String message;
     private final Map<Object, Object> params;
 
-    @SuppressWarnings("unchecked")
+    @SuppressWarnings({"unchecked","rawtypes"})
     public StructuredMessage(String message) {
         this(message, (Map) null);
     }

File: logstash-core/src/main/java/org/logstash/plugins/discovery/ConfigurationBuilder.java
Patch:
@@ -29,7 +29,7 @@ public ConfigurationBuilder() {
         urls = Sets.newHashSet();
     }
 
-    @SuppressWarnings("unchecked")
+    @SuppressWarnings({"unchecked","rawtypes"})
     public static ConfigurationBuilder build(final Object... params) {
         ConfigurationBuilder builder = new ConfigurationBuilder();
 
@@ -72,7 +72,7 @@ public static ConfigurationBuilder build(final Object... params) {
             } else if (param instanceof Class) {
                 if (Scanner.class.isAssignableFrom((Class) param)) {
                     try {
-                        builder.addScanners((Scanner) ((Class) param).newInstance());
+                        builder.addScanners((Scanner) ((Class) param).getConstructor().newInstance());
                     } catch (Exception e) { /*fallback*/ }
                 }
                 builder.addUrls(ClasspathHelper.forClass((Class) param, classLoaders));

File: logstash-core/src/main/java/org/logstash/secret/store/backend/JavaKeyStore.java
Patch:
@@ -138,6 +138,9 @@ public boolean exists(SecureConfig config) {
         return new File(new String(path)).exists();
     }
 
+    // Object#finalize() is deprecated, but `Cleaner` alternative did not ship until Java 9;
+    // since this project still supports Java 8, suppress the warning.
+    @SuppressWarnings("deprecation")
     @Override
     protected void finalize() throws Throwable {
         SecretStoreUtil.clearChars(keyStorePass);

File: logstash-core/src/test/java/org/logstash/config/ir/RubyEnvTestCase.java
Patch:
@@ -26,7 +26,7 @@ private static void ensureLoadpath() {
                 System.getProperty("logstash.core.root.dir", "")
             ).toAbsolutePath();
             final String gems = root.getParent().resolve("vendor").resolve("bundle")
-                .resolve("jruby").resolve("2.3.0").toFile().getAbsolutePath();
+                .resolve("jruby").resolve("2.5.0").toFile().getAbsolutePath();
             environment.put("GEM_HOME", gems);
             environment.put("GEM_PATH", gems);
             loader.addPaths(root.resolve("lib").toFile().getAbsolutePath());

File: logstash-core/src/test/java/org/logstash/config/ir/compiler/DatasetCompilerTest.java
Patch:
@@ -41,6 +41,7 @@ public void compilesSplitDataset() {
         final JrubyEventExtLibrary.RubyEvent falseEvent =
             JrubyEventExtLibrary.RubyEvent.newRubyEvent(RubyUtil.RUBY, new Event());
         final Dataset right = left.right();
+        @SuppressWarnings("rawtypes")
         final RubyArray batch = RubyUtil.RUBY.newArray(
             JrubyEventExtLibrary.RubyEvent.newRubyEvent(RubyUtil.RUBY, trueEvent), falseEvent
         );

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/FileCheckpointIO.java
Patch:
@@ -88,7 +88,7 @@ public void write(String fileName, Checkpoint checkpoint) throws IOException {
                     logger.error("Retrying after exception writing checkpoint: " + ex);
                     Thread.sleep(500);
                     Files.move(tmpPath, dirPath.resolve(fileName), StandardCopyOption.ATOMIC_MOVE);
-                } catch (Exception ex2) {
+                } catch (IOException | InterruptedException ex2) {
                     logger.error("Aborting after second exception writing checkpoint: " + ex2);
                     throw ex;
                 }

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -77,7 +77,7 @@ public Queue(Settings settings) {
         }
         this.pageCapacity = settings.getCapacity();
         this.maxBytes = settings.getQueueMaxBytes();
-        this.checkpointIO = new FileCheckpointIO(dirPath);
+        this.checkpointIO = new FileCheckpointIO(dirPath, settings.getCheckpointRetry());
         this.elementClass = settings.getElementClass();
         this.tailPages = new ArrayList<>();
         this.unreadTailPages = new ArrayList<>();

File: logstash-core/src/main/java/org/logstash/ackedqueue/QueueFactoryExt.java
Patch:
@@ -44,6 +44,7 @@ public static AbstractWrappedQueueExt create(final ThreadContext context, final
                         getSetting(context, settings, "queue.checkpoint.writes"),
                         getSetting(context, settings, "queue.checkpoint.acks"),
                         getSetting(context, settings, "queue.checkpoint.interval"),
+                        getSetting(context, settings, "queue.checkpoint.retry"),
                         getSetting(context, settings, "queue.max_bytes")
                     }
                 );

File: logstash-core/src/main/java/org/logstash/KeyNode.java
Patch:
@@ -2,9 +2,6 @@
 
 import java.util.List;
 
-/**
- * Created by ph on 15-05-22.
- */
 public class KeyNode {
 
     private KeyNode() {

File: logstash-core/src/main/java/org/logstash/common/IncompleteSourceWithMetadataException.java
Patch:
@@ -2,9 +2,6 @@
 
 import org.logstash.config.ir.InvalidIRException;
 
-/**
- * Created by andrewvc on 6/12/17.
- */
 public class IncompleteSourceWithMetadataException extends InvalidIRException {
     private static final long serialVersionUID = 456422097113787583L;
 

File: logstash-core/src/main/java/org/logstash/common/SourceWithMetadata.java
Patch:
@@ -9,9 +9,6 @@
 import java.util.regex.Pattern;
 import java.util.stream.Collectors;
 
-/**
- * Created by andrewvc on 9/6/16.
- */
 public class SourceWithMetadata implements HashableWithSource {
     // Either 'file' or something else
     private final String protocol;

File: logstash-core/src/main/java/org/logstash/common/Util.java
Patch:
@@ -4,9 +4,6 @@
 import java.security.MessageDigest;
 import java.security.NoSuchAlgorithmException;
 
-/**
- * Created by andrewvc on 12/23/16.
- */
 public class Util {
     // Modified from http://stackoverflow.com/a/11009612/11105
 

File: logstash-core/src/main/java/org/logstash/config/ir/BaseSourceComponent.java
Patch:
@@ -3,11 +3,8 @@
 import org.logstash.common.SourceWithMetadata;
 
 /**
- * Created by andrewvc on 9/6/16.
- *
  * This class is useful to inherit from for things that need to be source components
  * since it handles storage of the meta property for you and reduces a lot of boilerplate.
- *
  */
 public abstract class BaseSourceComponent implements SourceComponent {
     private final SourceWithMetadata meta;

File: logstash-core/src/main/java/org/logstash/config/ir/DSL.java
Patch:
@@ -35,9 +35,6 @@
 import org.logstash.config.ir.imperative.PluginStatement;
 import org.logstash.config.ir.imperative.Statement;
 
-/**
- * Created by andrewvc on 9/15/16.
- */
 public class DSL {
     public static EventValueExpression eEventValue(SourceWithMetadata meta, String fieldName) {
         return new EventValueExpression(meta, fieldName);

File: logstash-core/src/main/java/org/logstash/config/ir/Hashable.java
Patch:
@@ -1,8 +1,5 @@
 package org.logstash.config.ir;
 
-/**
- * Created by andrewvc on 12/23/16.
- */
 public interface Hashable {
     String uniqueHash();
 }

File: logstash-core/src/main/java/org/logstash/config/ir/HashableWithSource.java
Patch:
@@ -2,9 +2,6 @@
 
 import org.logstash.common.Util;
 
-/**
- * Created by andrewvc on 6/12/17.
- */
 public interface HashableWithSource extends Hashable {
     @Override
     default String uniqueHash() {

File: logstash-core/src/main/java/org/logstash/config/ir/InvalidIRException.java
Patch:
@@ -1,8 +1,5 @@
 package org.logstash.config.ir;
 
-/**
- * Created by andrewvc on 9/6/16.
- */
 public class InvalidIRException extends Exception {
     public InvalidIRException(String s) {
         super(s);

File: logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
Patch:
@@ -9,9 +9,6 @@
 import org.logstash.config.ir.graph.QueueVertex;
 import org.logstash.config.ir.graph.Vertex;
 
-/**
- * Created by andrewvc on 9/20/16.
- */
 public final class PipelineIR implements Hashable {
 
     private final String uniqueHash;

File: logstash-core/src/main/java/org/logstash/config/ir/PluginDefinition.java
Patch:
@@ -8,9 +8,6 @@
 import org.logstash.ObjectMappers;
 import org.logstash.common.SourceWithMetadata;
 
-/**
- * Created by andrewvc on 9/20/16.
- */
 public final class PluginDefinition implements SourceComponent, HashableWithSource {
 
     @Override

File: logstash-core/src/main/java/org/logstash/config/ir/SourceComponent.java
Patch:
@@ -2,9 +2,6 @@
 
 import org.logstash.common.SourceWithMetadata;
 
-/**
- * Created by andrewvc on 9/16/16.
- */
 public interface SourceComponent {
     boolean sourceComponentEquals(SourceComponent sourceComponent);
     SourceWithMetadata getSourceWithMetadata();

File: logstash-core/src/main/java/org/logstash/config/ir/expression/BinaryBooleanExpression.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.common.Util;
 import org.logstash.config.ir.SourceComponent;
 
-/**
- * Created by andrewvc on 9/6/16.
- */
 public abstract class BinaryBooleanExpression extends BooleanExpression {
     @Override
     public boolean sourceComponentEquals(SourceComponent sourceComponent) {

File: logstash-core/src/main/java/org/logstash/config/ir/expression/BooleanExpression.java
Patch:
@@ -2,9 +2,6 @@
 
 import org.logstash.common.SourceWithMetadata;
 
-/**
- * Created by andrewvc on 9/14/16.
- */
 public abstract class BooleanExpression extends Expression {
     public BooleanExpression(SourceWithMetadata meta) {
         super(meta);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/EventValueExpression.java
Patch:
@@ -3,9 +3,6 @@
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.common.SourceWithMetadata;
 
-/**
- * Created by andrewvc on 9/13/16.
- */
 public class EventValueExpression extends Expression {
     private final String fieldName;
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/Expression.java
Patch:
@@ -10,7 +10,6 @@
  *
  * if [foo]
  * notnull(eEventValue("foo"))
- * Created by andrewvc on 9/6/16.
  */
 public abstract class Expression extends BaseSourceComponent implements HashableWithSource {
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/RegexValueExpression.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.config.ir.SourceComponent;
 
-/**
- * Created by andrewvc on 9/15/16.
- */
 public class RegexValueExpression extends ValueExpression {
     private final String regex;
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/UnaryBooleanExpression.java
Patch:
@@ -3,9 +3,6 @@
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 
-/**
- * Created by andrewvc on 9/13/16.
- */
 public abstract class UnaryBooleanExpression extends BooleanExpression {
     private final Expression expression;
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/ValueExpression.java
Patch:
@@ -8,9 +8,6 @@
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.config.ir.SourceComponent;
 
-/**
- * Created by andrewvc on 9/13/16.
- */
 public class ValueExpression extends Expression {
     protected final Object value;
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/And.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class And extends BinaryBooleanExpression {
     public And(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Eq.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class Eq extends BinaryBooleanExpression {
     public Eq(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Gt.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class Gt extends BinaryBooleanExpression {
     public Gt(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Gte.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class Gte extends BinaryBooleanExpression {
     public Gte(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/In.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class In extends BinaryBooleanExpression {
     public In(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Lt.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class Lt extends BinaryBooleanExpression {
     public Lt(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Lte.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class Lte extends BinaryBooleanExpression {
     public Lte(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Neq.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class Neq extends BinaryBooleanExpression {
     public Neq(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Or.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class Or extends BinaryBooleanExpression {
     public Or(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/RegexEq.java
Patch:
@@ -6,9 +6,6 @@
 import org.logstash.config.ir.expression.Expression;
 import org.logstash.config.ir.expression.RegexValueExpression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class RegexEq extends BinaryBooleanExpression {
     public RegexEq(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/unary/Not.java
Patch:
@@ -6,9 +6,6 @@
 import org.logstash.config.ir.expression.Expression;
 import org.logstash.config.ir.expression.UnaryBooleanExpression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class Not extends UnaryBooleanExpression {
     public Not(SourceWithMetadata meta, Expression expression) throws InvalidIRException {
         super(meta, expression);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/unary/Truthy.java
Patch:
@@ -6,9 +6,6 @@
 import org.logstash.config.ir.expression.Expression;
 import org.logstash.config.ir.expression.UnaryBooleanExpression;
 
-/**
- * Created by andrewvc on 9/21/16.
- */
 public class Truthy extends UnaryBooleanExpression {
     public Truthy(SourceWithMetadata meta, Expression expression) throws InvalidIRException {
         super(meta, expression);

File: logstash-core/src/main/java/org/logstash/config/ir/graph/BooleanEdge.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
 
-/**
- * Created by andrewvc on 9/15/16.
- */
 public final class BooleanEdge extends Edge {
     public static class BooleanEdgeFactory extends EdgeFactory {
         public Boolean getEdgeType() {

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Edge.java
Patch:
@@ -5,9 +5,6 @@
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.config.ir.SourceComponent;
 
-/**
- * Created by andrewvc on 9/15/16.
- */
 public abstract class Edge implements SourceComponent {
 
     private final Vertex from;

File: logstash-core/src/main/java/org/logstash/config/ir/graph/IfVertex.java
Patch:
@@ -8,9 +8,6 @@
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.expression.BooleanExpression;
 
-/**
- * Created by andrewvc on 9/15/16.
- */
 public class IfVertex extends Vertex {
 
     public BooleanExpression getBooleanExpression() {

File: logstash-core/src/main/java/org/logstash/config/ir/graph/PlainEdge.java
Patch:
@@ -3,9 +3,6 @@
 import org.logstash.common.Util;
 import org.logstash.config.ir.InvalidIRException;
 
-/**
- * Created by andrewvc on 9/19/16.
- */
 public class PlainEdge extends Edge {
     public static class PlainEdgeFactory extends Edge.EdgeFactory {
         @Override

File: logstash-core/src/main/java/org/logstash/config/ir/graph/QueueVertex.java
Patch:
@@ -5,9 +5,6 @@
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.common.SourceWithMetadata;
 
-/**
- * Created by andrewvc on 9/15/16.
- */
 public final class QueueVertex extends Vertex {
     public QueueVertex() throws IncompleteSourceWithMetadataException {
         super(new SourceWithMetadata("internal", "queue", 0,0,"queue"));

File: logstash-core/src/main/java/org/logstash/config/ir/graph/algorithms/DepthFirst.java
Patch:
@@ -7,9 +7,6 @@
 import java.util.stream.Stream;
 import java.util.stream.StreamSupport;
 
-/**
- * Created by andrewvc on 1/5/17.
- */
 public class DepthFirst {
     public static Stream<Vertex> depthFirst(Graph g) {
         return depthFirst(g.getRoots());

File: logstash-core/src/main/java/org/logstash/config/ir/graph/algorithms/GraphDiff.java
Patch:
@@ -9,9 +9,6 @@
 import org.logstash.config.ir.graph.Graph;
 import org.logstash.config.ir.graph.Vertex;
 
-/**
- * Created by andrewvc on 1/5/17.
- */
 public class GraphDiff {
     public static DiffResult diff(Graph left, Graph right) {
         List<Edge> removedEdges = left.edges().filter(e -> !right.hasEquivalentEdge(e)).collect(Collectors.toList());

File: logstash-core/src/main/java/org/logstash/config/ir/graph/algorithms/TopologicalSort.java
Patch:
@@ -6,9 +6,6 @@
 
 import java.util.*;
 
-/**
- * Created by andrewvc on 1/7/17.
- */
 public class TopologicalSort {
     public static class UnexpectedGraphCycleError extends Exception {
         private static final long serialVersionUID = 1778155790783320839L;

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/ComposedParallelStatement.java
Patch:
@@ -6,9 +6,6 @@
 
 import java.util.List;
 
-/**
- * Created by andrewvc on 9/22/16.
- */
 public class ComposedParallelStatement extends ComposedStatement {
     public ComposedParallelStatement(SourceWithMetadata meta, List<Statement> statements) throws InvalidIRException {
         super(meta, statements);

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/ComposedSequenceStatement.java
Patch:
@@ -6,9 +6,6 @@
 
 import java.util.List;
 
-/**
- * Created by andrewvc on 9/22/16.
- */
 public class ComposedSequenceStatement extends ComposedStatement {
     public ComposedSequenceStatement(SourceWithMetadata meta, List<Statement> statements) throws InvalidIRException {
         super(meta, statements);

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/ComposedStatement.java
Patch:
@@ -7,9 +7,6 @@
 import java.util.List;
 import java.util.stream.Collectors;
 
-/**
- * Created by andrewvc on 9/6/16.
- */
 public abstract class ComposedStatement extends Statement {
     public interface IFactory {
         ComposedStatement make(SourceWithMetadata meta, List<Statement> statements) throws InvalidIRException;

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/IfStatement.java
Patch:
@@ -13,7 +13,6 @@
 import java.util.stream.Collectors;
 
 /**
- * Created by andrewvc on 9/6/16.
  * if 5 {
  *
  * }

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/NoopStatement.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
 
-/**
- * Created by andrewvc on 9/15/16.
- */
 public class NoopStatement extends Statement {
 
     public NoopStatement(SourceWithMetadata meta) {

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/PluginStatement.java
Patch:
@@ -8,9 +8,6 @@
 import org.logstash.config.ir.graph.PluginVertex;
 import org.logstash.config.ir.graph.Vertex;
 
-/**
- * Created by andrewvc on 9/6/16.
- */
 public class PluginStatement extends Statement {
     private final PluginDefinition pluginDefinition;
 

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/Statement.java
Patch:
@@ -5,9 +5,6 @@
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
 
-/**
- * Created by andrewvc on 9/6/16.
- */
 public abstract class Statement extends BaseSourceComponent {
     public Statement(SourceWithMetadata meta) {
         super(meta);

File: logstash-core/src/main/java/org/logstash/instrument/monitors/HotThreadsMonitor.java
Patch:
@@ -18,7 +18,6 @@
 /**
  * Hot threads monitoring class. This class pulls information out of the JVM #
  * provided beans and lest the different consumers query it.
- * Created by purbon on 12/12/15.
  */
 public final class HotThreadsMonitor {
 

File: logstash-core/src/main/java/org/logstash/instrument/monitors/MemoryMonitor.java
Patch:
@@ -8,9 +8,6 @@
 import java.util.List;
 import java.util.Map;
 
-/**
- * Based on code created by purbon on 13/12/15.
- */
 public final class MemoryMonitor {
 
     private MemoryMonitor() {

File: logstash-core/src/main/java/org/logstash/instrument/monitors/ProcessMonitor.java
Patch:
@@ -8,9 +8,6 @@
 import java.util.concurrent.TimeUnit;
 import javax.management.MBeanServer;
 
-/**
- * Created by andrewvc on 5/12/16.
- */
 public class ProcessMonitor {
     private static final OperatingSystemMXBean osMxBean = ManagementFactory.getOperatingSystemMXBean();
     private static final MBeanServer platformMxBean = ManagementFactory.getPlatformMBeanServer();

File: logstash-core/src/main/java/org/logstash/instrument/monitors/SystemMonitor.java
Patch:
@@ -7,7 +7,6 @@
 
 /**
  * System information as returned by the different JVM's MxBeans
- * Created by purbon on 13/12/15.
  */
 public class SystemMonitor {
 

File: logstash-core/src/main/java/org/logstash/instrument/reports/ThreadsReport.java
Patch:
@@ -9,7 +9,6 @@
 
 /**
  * A ThreadsReport object used to hold the hot threads information
- * Created by purbon on 12/12/15.
  */
 public class ThreadsReport {
 

File: logstash-core/src/test/java/org/logstash/common/SourceWithMetadataTest.java
Patch:
@@ -6,9 +6,6 @@
 
 import java.util.Arrays;
 
-/**
- * Created by andrewvc on 6/12/17.
- */
 @RunWith(Parameterized.class)
 public class SourceWithMetadataTest {
     private final ParameterGroup parameterGroup;

File: logstash-core/src/test/java/org/logstash/config/ir/PipelineIRTest.java
Patch:
@@ -9,9 +9,6 @@
 import static org.logstash.config.ir.PluginDefinition.Type.*;
 import static org.logstash.config.ir.IRHelpers.randMeta;
 
-/**
- * Created by andrewvc on 9/20/16.
- */
 public class PipelineIRTest {
     public Graph makeInputSection() throws InvalidIRException {
         return iComposeParallel(iPlugin(randMeta(), INPUT, "generator"), iPlugin(randMeta(), INPUT, "stdin")).toGraph();

File: logstash-core/src/test/java/org/logstash/config/ir/graph/BooleanEdgeTest.java
Patch:
@@ -10,9 +10,6 @@
 import static org.junit.Assert.assertThat;
 import static org.logstash.config.ir.IRHelpers.*;
 
-/**
- * Created by andrewvc on 11/21/16.
- */
 @RunWith(Theories.class)
 public class BooleanEdgeTest {
     @DataPoint

File: logstash-core/src/test/java/org/logstash/config/ir/graph/IfVertexTest.java
Patch:
@@ -7,9 +7,6 @@
 import static org.junit.Assert.assertThat;
 import static org.logstash.config.ir.IRHelpers.*;
 
-/**
- * Created by andrewvc on 11/22/16.
- */
 public class IfVertexTest {
     @Test
     public void testIfVertexCreation() throws InvalidIRException {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/PlainEdgeTest.java
Patch:
@@ -4,9 +4,6 @@
 import org.logstash.config.ir.IRHelpers;
 import org.logstash.config.ir.InvalidIRException;
 
-/**
- * Created by andrewvc on 11/22/16.
- */
 public class PlainEdgeTest {
     @Test
     public void creationDoesNotRaiseException() throws InvalidIRException {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/PluginVertexTest.java
Patch:
@@ -12,9 +12,6 @@
 import static org.junit.Assert.assertThat;
 import static org.logstash.config.ir.IRHelpers.*;
 
-/**
- * Created by andrewvc on 11/22/16.
- */
 public class PluginVertexTest {
     @Test
     public void testConstructionIdHandlingWhenNoExplicitId() throws InvalidIRException {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/QueueVertexTest.java
Patch:
@@ -3,9 +3,6 @@
 import org.junit.Test;
 import org.logstash.common.IncompleteSourceWithMetadataException;
 
-/**
- * Created by andrewvc on 11/22/16.
- */
 public class QueueVertexTest {
     @Test
     public void testConstruction() {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/VertexTest.java
Patch:
@@ -6,9 +6,6 @@
 
 import static org.junit.Assert.*;
 
-/**
- * Created by andrewvc on 11/21/16.
- */
 public class VertexTest {
     @Test
     public void TestVertexBasics() throws InvalidIRException {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/algorithms/BreadthFirstTest.java
Patch:
@@ -11,9 +11,6 @@
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 
-/**
- * Created by andrewvc on 1/5/17.
- */
 public class BreadthFirstTest {
     @Test
     public void testBFSBasic() throws InvalidIRException {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/algorithms/DepthFirstTest.java
Patch:
@@ -13,9 +13,6 @@
 
 import static junit.framework.TestCase.assertEquals;
 
-/**
- * Created by andrewvc on 1/5/17.
- */
 public class DepthFirstTest {
     Graph g = Graph.empty();
     final AtomicInteger visitCount = new AtomicInteger();

File: logstash-core/src/test/java/org/logstash/config/ir/graph/algorithms/GraphDiffTest.java
Patch:
@@ -12,9 +12,6 @@
 import static org.junit.Assert.assertTrue;
 import static org.logstash.config.ir.IRHelpers.createTestVertex;
 
-/**
- * Created by andrewvc on 1/5/17.
- */
 public class GraphDiffTest {
     @Test
     public void testIdenticalGraphs() throws InvalidIRException {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/algorithms/TopologicalSortTest.java
Patch:
@@ -12,9 +12,6 @@
 import static org.hamcrest.core.AnyOf.anyOf;
 import static org.hamcrest.core.Is.is;
 
-/**
- * Created by andrewvc on 1/7/17.
- */
 public class TopologicalSortTest {
     @Test(expected = InvalidIRException.class)
     public void testGraphCycleDetection() throws InvalidIRException {

File: logstash-core/src/test/java/org/logstash/config/ir/imperative/DSLTest.java
Patch:
@@ -10,9 +10,6 @@
 import static org.logstash.config.ir.PluginDefinition.Type.*;
 import static org.logstash.config.ir.IRHelpers.randMeta;
 
-/**
- * Created by andrewvc on 9/13/16.
- */
 public class DSLTest {
     @Test
     public void testDSLOnePluginEquality() throws IncompleteSourceWithMetadataException {

File: logstash-core/src/test/java/org/logstash/config/ir/imperative/ImperativeToGraphtest.java
Patch:
@@ -11,9 +11,6 @@
 import static org.logstash.config.ir.IRHelpers.randMeta;
 import static org.logstash.config.ir.PluginDefinition.Type.*;
 
-/**
- * Created by andrewvc on 9/15/16.
- */
 public class ImperativeToGraphtest {
 
     @Test

File: logstash-core/src/main/java/co/elastic/logstash/api/v0/Codec.java
Patch:
@@ -14,6 +14,7 @@ public interface Codec extends Plugin {
      * Decodes events from the specified {@link ByteBuffer} and passes them to the provided
      * {@link Consumer}.
      *
+     * <ul>
      * <li>The client (typically an {@link Input}) must provide a {@link ByteBuffer} that
      * is ready for reading with with {@link ByteBuffer#position} indicating the next
      * position to read and {@link ByteBuffer#limit} indicating the first byte in the
@@ -25,6 +26,7 @@ public interface Codec extends Plugin {
      * <li>The client is then responsible for returning the buffer
      * to write mode via either {@link ByteBuffer#clear} or {@link ByteBuffer#compact} before
      * resuming writes.</li>
+     * </ul>
      *
      * @param buffer Input buffer from which events will be decoded.
      * @param eventConsumer Consumer to which decoded events will be passed.

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/DatasetCompiler.java
Patch:
@@ -85,7 +85,7 @@ public static ComputeStepSyntaxElement<SplitDataset> splitDataset(final Collecti
      * @return Dataset representing the filter plugin
      */
     public static ComputeStepSyntaxElement<Dataset> filterDataset(final Collection<Dataset> parents,
-        final FilterDelegatorExt plugin) {
+        final AbstractFilterDelegatorExt plugin) {
         final ClassFields fields = new ClassFields();
         final ValueSyntaxElement outputBuffer = fields.add(new ArrayList<>());
         final Closure clear = Closure.wrap();
@@ -192,7 +192,7 @@ private static ValueSyntaxElement invokeOutput(final ValueSyntaxElement output,
 
     private static Closure filterBody(final ValueSyntaxElement outputBuffer,
         final ValueSyntaxElement inputBuffer, final ClassFields fields,
-        final FilterDelegatorExt plugin) {
+        final AbstractFilterDelegatorExt plugin) {
         final ValueSyntaxElement filterField = fields.add(plugin);
         final Closure body = Closure.wrap(
             buffer(outputBuffer, filterField.call("multiFilter", inputBuffer))

File: logstash-core/src/main/java/org/logstash/ext/JRubyAbstractQueueWriteClientExt.java
Patch:
@@ -8,9 +8,10 @@
 import org.jruby.anno.JRubyMethod;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
+import org.logstash.execution.queue.QueueWriter;
 
 @JRubyClass(name = "AbstractQueueWriteClient")
-public abstract class JRubyAbstractQueueWriteClientExt extends RubyBasicObject {
+public abstract class JRubyAbstractQueueWriteClientExt extends RubyBasicObject implements QueueWriter {
 
     protected JRubyAbstractQueueWriteClientExt(final Ruby runtime, final RubyClass metaClass) {
         super(runtime, metaClass);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/ComputeStepSyntaxElement.java
Patch:
@@ -107,7 +107,7 @@ private String generateCode(final String name) {
         try {
             return REDUNDANT_SEMICOLON.matcher(new Formatter().formatSource(
                 String.format(
-                    "package org.logstash.generated;\npublic final class %s implements %s { %s }",
+                    "package org.logstash.generated;\npublic final class %s extends org.logstash.config.ir.compiler.BaseDataset implements %s { %s }",
                     name,
                     type.getName(),
                     SyntaxFactory.join(

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/DatasetCompiler.java
Patch:
@@ -258,18 +258,18 @@ private static Closure withInputBuffering(final Closure compute,
      */
     private static DatasetCompiler.ComputeAndClear withOutputBuffering(final Closure compute,
         final Closure clear, final ValueSyntaxElement outputBuffer, final ClassFields fields) {
-        final ValueSyntaxElement done = fields.add(boolean.class);
+        final SyntaxFactory.MethodCallReturnValue done = new SyntaxFactory.MethodCallReturnValue(SyntaxFactory.value("this"), "isDone");
         return computeAndClear(
             Closure.wrap(
                 SyntaxFactory.ifCondition(done, Closure.wrap(SyntaxFactory.ret(outputBuffer)))
             ).add(compute)
-                .add(SyntaxFactory.assignment(done, SyntaxFactory.identifier("true")))
+                .add(new SyntaxFactory.MethodCallReturnValue(SyntaxFactory.value("this"), "setDone"))
                 .add(SyntaxFactory.ret(outputBuffer)),
             Closure.wrap(
                 SyntaxFactory.ifCondition(
                     done, Closure.wrap(
                         clear.add(clear(outputBuffer)),
-                        SyntaxFactory.assignment(done, SyntaxFactory.identifier("false"))
+                        new SyntaxFactory.MethodCallReturnValue(SyntaxFactory.value("this"), "clearDone")
                     )
                 )
             ), fields

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/EventCondition.java
Patch:
@@ -437,7 +437,7 @@ private static EventCondition rubyFieldEquals(final Comparable<IRubyObject> left
             final String field) {
             final FieldReference reference = FieldReference.from(field);
             return event ->
-                left.equals((IRubyObject) event.getEvent().getUnconvertedField(reference));
+                    left.equals(Rubyfier.deep(RubyUtil.RUBY, event.getEvent().getUnconvertedField(reference)));
         }
 
         private static EventCondition constant(final boolean value) {

File: tools/dependencies-report/src/main/java/org/logstash/dependencies/Main.java
Patch:
@@ -46,7 +46,7 @@ public static void main(String[] args) throws IOException {
         );
 
         // If there were unknown results in the report, exit with a non-zero status
-        System.exit(reportResult ? 0 : 1);
+        //System.exit(reportResult ? 0 : 1);
     }
 
     static InputStream getResourceAsStream(String resourcePath) {

File: logstash-core/src/test/java/org/logstash/secret/store/backend/JavaKeyStoreTest.java
Patch:
@@ -2,6 +2,7 @@
 
 
 import org.junit.Before;
+import org.junit.Ignore;
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.ExpectedException;
@@ -632,6 +633,7 @@ public void testRestrictivePermissions() throws Exception {
      *
      * @throws Exception when exceptions happen
      */
+    @Ignore("This test timed out on Windows. Issue: https://github.com/elastic/logstash/issues/9916")
     @Test
     public void testWithRealSecondJvm() throws Exception {
         Path magicFile = folder.newFolder().toPath().resolve(EXTERNAL_TEST_FILE_LOCK);

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -624,11 +624,13 @@ public void queueStillFullAfterPartialPageAckTest() throws IOException, Interrup
         }
     }
 
+    @Ignore("This test timed out on Windows. Issue: https://github.com/elastic/logstash/issues/9918")
     @Test
     public void queueStableUnderStressHugeCapacity() throws Exception {
         stableUnderStress(100_000);
     }
 
+    @Ignore("This test timed out on Windows. Issue: https://github.com/elastic/logstash/issues/9918")
     @Test
     public void queueStableUnderStressLowCapacity() throws Exception {
         stableUnderStress(50);

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -22,6 +22,7 @@
 import org.junit.Before;
 import org.junit.Rule;
 import org.junit.Test;
+import org.junit.Ignore;
 import org.junit.rules.TemporaryFolder;
 import org.logstash.ackedqueue.io.MmapPageIOV2;
 

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -683,6 +683,7 @@ public void testAckedCount() throws IOException {
         }
     }
 
+    @Ignore("This test frequently times out on Windows and Linux. Issue: https://github.com/elastic/logstash/issues/9878")
     @Test(timeout = 50_000)
     public void concurrentWritesTest() throws IOException, InterruptedException, ExecutionException {
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -171,7 +171,7 @@ public void open() throws IOException {
 
             // at this point we have a head checkpoint to figure queue recovery
 
-            // as we load pages, compute actuall disk needed substracting existing pages size to the required maxBytes
+            // as we load pages, compute actually disk needed substracting existing pages size to the required maxBytes
             long diskNeeded = this.maxBytes;
 
             // reconstruct all tail pages state upto but excluding the head page

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
Patch:
@@ -173,7 +173,7 @@ public String hashSource() {
         return this.uniqueHash();
     }
 
-    // Can be overriden in subclasses to define multiple
+    // Can be overridden in subclasses to define multiple
     // expected Edge classes this Vertex can take.
     // If any EdgeFactory instances are returned this Vertex is considered
     // a partial leaf.

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/PluginWitness.java
Patch:
@@ -238,7 +238,7 @@ public static final class Snitch {
             private final PluginWitness.CustomWitness witness;
 
             /**
-             * Construtor
+             * Constructor
              *
              * @param witness the witness
              */

File: logstash-core/src/main/java/org/logstash/instrument/witness/schedule/ScheduledWitness.java
Patch:
@@ -10,7 +10,7 @@ public interface ScheduledWitness {
     /**
      * The duration between updates for this witness
      *
-     * @return the {@link Duration} between scheduled updates. For example {@link Duration#ofMinutes(long)} with a value of 5 would schedule this implemenation to
+     * @return the {@link Duration} between scheduled updates. For example {@link Duration#ofMinutes(long)} with a value of 5 would schedule this implementation to
      * self-populate every 5 minute. Defaults to every 60 seconds. - Note, implementations may not allow schedules faster then every 1 second.
      */
     default Duration every() {

File: logstash-core/src/main/java/org/logstash/secret/SecretIdentifier.java
Patch:
@@ -79,7 +79,7 @@ public int hashCode() {
     }
 
     /**
-     * Converts this object to a format acceptable external {@link String} format. Note - no gauruntees are made with respect to encoding or safe use. For example, the external
+     * Converts this object to a format acceptable external {@link String} format. Note - no guarantees are made with respect to encoding or safe use. For example, the external
      * format may not be URL safely encoded.
      *
      * @return the externally formatted {@link String}

File: logstash-core/src/test/java/org/logstash/EventTest.java
Patch:
@@ -435,7 +435,7 @@ public void metadataFieldsShouldBeValuefied() {
     }
 
     @Test
-    public void metadataRootShouldBeValueified() {
+    public void metadataRootShouldBeValuefied() {
         final Event event = new Event();
 
         final Map<String, Object> metadata = new HashMap<>();

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -570,7 +570,7 @@ public void resumeWriteOnNoLongerFullQueueTest() throws IOException, Interrupted
 
             assertThat(q.isFull(), is(false));
 
-            // read 1 page (10 events) here while not full yet so that the read will not singal the not full state
+            // read 1 page (10 events) here while not full yet so that the read will not signal the not full state
             // we want the batch closing below to signal the not full state
             Batch b = q.readBatch(10, TimeUnit.SECONDS.toMillis(1));
 
@@ -915,7 +915,7 @@ public void testZeroByteFullyAckedPageOnOpen() throws IOException {
             q.write(element2);
             assertThat(q.tailPages.size(), is(1));
 
-            // work directly on the tail page and not the queue to avoid habing the queue purge the page
+            // work directly on the tail page and not the queue to avoid having the queue purge the page
             // but make sure the tail page checkpoint marks it as fully acked
             Page tp = q.tailPages.get(0);
             Batch b = new Batch(tp.read(1), q);

File: logstash-core/src/test/java/org/logstash/ackedqueue/io/LongVectorTest.java
Patch:
@@ -21,7 +21,7 @@ public void storesAndResizes() {
     }
 
     @Test
-    public void storesVecorAndResizes() {
+    public void storesVectorAndResizes() {
         final int count = 1000;
         final LongVector vector1 = new LongVector(count);
         for (long i = 0L; i < count; ++i) {

File: logstash-core/src/main/java/org/logstash/FileLockFactory.java
Patch:
@@ -49,7 +49,7 @@ private FileLockFactory() {}
     private static final Map<FileLock, String> LOCK_MAP =  Collections.synchronizedMap(new HashMap<>());
 
     public static FileLock obtainLock(Path dirPath, String lockName) throws IOException {
-        Files.createDirectories(dirPath);
+        if (!Files.isDirectory(dirPath)) { Files.createDirectories(dirPath); }
         Path lockPath = dirPath.resolve(lockName);
 
         try {

File: logstash-core/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -99,6 +99,6 @@ public Object unconvert() {
      * @return Interned String
      */
     private static String convertKey(final RubyString key) {
-        return FieldReference.from(key.getByteList()).getKey();
+        return FieldReference.from(key).getKey();
     }
 }

File: logstash-core/src/test/java/org/logstash/FieldReferenceTest.java
Patch:
@@ -51,7 +51,7 @@ public void testParseEmptyString() {
         final FieldReference emptyReference = FieldReference.from("");
         assertNotNull(emptyReference);
         assertEquals(
-            emptyReference, FieldReference.from(RubyUtil.RUBY.newString("").getByteList())
+            emptyReference, FieldReference.from(RubyUtil.RUBY.newString(""))
         );
     }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyWrappedAckedQueueExt.java
Patch:
@@ -13,6 +13,7 @@
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.RubyUtil;
 import org.logstash.execution.AbstractWrappedQueueExt;
+import org.logstash.execution.QueueReadClientBase;
 import org.logstash.ext.JRubyAbstractQueueWriteClientExt;
 import org.logstash.ext.JrubyAckedReadClientExt;
 import org.logstash.ext.JrubyAckedWriteClientExt;
@@ -77,7 +78,7 @@ protected JRubyAbstractQueueWriteClientExt getWriteClient(final ThreadContext co
     }
 
     @Override
-    protected IRubyObject getReadClient() {
+    protected QueueReadClientBase getReadClient() {
         return JrubyAckedReadClientExt.create(queue);
     }
 

File: logstash-core/src/main/java/org/logstash/execution/AbstractWrappedQueueExt.java
Patch:
@@ -22,7 +22,7 @@ public final JRubyAbstractQueueWriteClientExt writeClient(final ThreadContext co
     }
 
     @JRubyMethod(name = "read_client")
-    public final IRubyObject readClient() {
+    public final QueueReadClientBase readClient() {
         return getReadClient();
     }
 
@@ -35,5 +35,5 @@ public final IRubyObject close(final ThreadContext context) {
 
     protected abstract JRubyAbstractQueueWriteClientExt getWriteClient(ThreadContext context);
 
-    protected abstract IRubyObject getReadClient();
+    protected abstract QueueReadClientBase getReadClient();
 }

File: logstash-core/src/main/java/org/logstash/ext/JrubyWrappedSynchronousQueueExt.java
Patch:
@@ -10,6 +10,7 @@
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.execution.AbstractWrappedQueueExt;
+import org.logstash.execution.QueueReadClientBase;
 
 @JRubyClass(name = "WrappedSynchronousQueue")
 public final class JrubyWrappedSynchronousQueueExt extends AbstractWrappedQueueExt {
@@ -35,7 +36,7 @@ protected JRubyAbstractQueueWriteClientExt getWriteClient(final ThreadContext co
     }
 
     @Override
-    protected IRubyObject getReadClient() {
+    protected QueueReadClientBase getReadClient() {
         // batch size and timeout are currently hard-coded to 125 and 50ms as values observed
         // to be reasonable tradeoffs between latency and throughput per PR #8707
         return JrubyMemoryReadClientExt.create(queue, 125, 50);

File: logstash-core/src/main/java/org/logstash/instrument/metrics/MetricKeys.java
Patch:
@@ -23,4 +23,6 @@ private MetricKeys() {
         RubyUtil.RUBY.newSymbol("duration_in_millis");
 
     public static final RubySymbol FILTERED_KEY = RubyUtil.RUBY.newSymbol("filtered");
+
+    public static final RubySymbol STATS_KEY = RubyUtil.RUBY.newSymbol("stats");
 }

File: logstash-core/src/main/java/org/logstash/ext/JRubyWrappedWriteClientExt.java
Patch:
@@ -111,8 +111,8 @@ private void incrementCounters(final long count) {
     }
 
     private void incrementTimers(final long start) {
-        final long increment = TimeUnit.NANOSECONDS.convert(
-            System.nanoTime() - start, TimeUnit.MILLISECONDS
+        final long increment = TimeUnit.MILLISECONDS.convert(
+            System.nanoTime() - start, TimeUnit.NANOSECONDS
         );
         eventsMetricsTime.increment(increment);
         pipelineMetricsTime.increment(increment);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/AbstractOutputDelegatorExt.java
Patch:
@@ -21,6 +21,8 @@
 @JRubyClass(name = "AbstractOutputDelegator")
 public abstract class AbstractOutputDelegatorExt extends RubyObject {
 
+    public static final String OUTPUT_METHOD_NAME = "multi_receive";
+
     private AbstractMetricExt metric;
 
     protected AbstractNamespacedMetricExt namespacedMetric;
@@ -86,7 +88,7 @@ public IRubyObject metricEvents() {
         return metricEvents;
     }
 
-    @JRubyMethod(name = "multi_receive")
+    @JRubyMethod(name = OUTPUT_METHOD_NAME)
     public IRubyObject multiReceive(final IRubyObject events) {
         final RubyArray batch = (RubyArray) events;
         final int count = batch.size();

File: logstash-core/src/test/java/org/logstash/config/ir/compiler/FakeOutClass.java
Patch:
@@ -70,7 +70,7 @@ public IRubyObject executionContext(IRubyObject args) {
         return this;
     }
 
-    @JRubyMethod(name = "multi_receive")
+    @JRubyMethod(name = AbstractOutputDelegatorExt.OUTPUT_METHOD_NAME)
     public IRubyObject multiReceive(final IRubyObject args) {
         multiReceiveCallCount++;
         multiReceiveArgs = args;

File: logstash-core/src/main/java/org/logstash/instrument/metrics/NamespacedMetricExt.java
Patch:
@@ -32,7 +32,7 @@ public NamespacedMetricExt(final Ruby runtime, final RubyClass metaClass) {
     }
 
     @JRubyMethod(visibility = Visibility.PRIVATE)
-    public IRubyObject initialize(final ThreadContext context, final IRubyObject metric,
+    public NamespacedMetricExt initialize(final ThreadContext context, final IRubyObject metric,
         final IRubyObject namespaceName) {
         this.metric = (MetricExt) metric;
         if (namespaceName instanceof RubyArray) {

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/AbstractOutputDelegatorExt.java
Patch:
@@ -25,7 +25,7 @@ public abstract class AbstractOutputDelegatorExt extends RubyObject {
 
     protected AbstractNamespacedMetricExt namespacedMetric;
 
-    private IRubyObject metricEvents;
+    private AbstractNamespacedMetricExt metricEvents;
 
     private RubyString id;
 

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/FilterDelegatorExt.java
Patch:
@@ -29,7 +29,7 @@ public final class FilterDelegatorExt extends RubyObject {
 
     private IRubyObject filter;
 
-    private IRubyObject metricEvents;
+    private AbstractNamespacedMetricExt metricEvents;
 
     private RubyString id;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/ReloadWitness.java
Patch:
@@ -26,7 +26,6 @@ public final class ReloadWitness implements SerializableWitness {
     private final RubyTimeStampGauge lastSuccessTimestamp;
     private final RubyTimeStampGauge lastFailureTimestamp;
     private final Snitch snitch;
-    private static final Serializer SERIALIZER = new Serializer();
 
     private static final String KEY = "reloads";
 

File: logstash-core/src/main/java/org/logstash/plugins/PluginFactoryExt.java
Patch:
@@ -59,7 +59,7 @@ public static IRubyObject filterDelegator(final ThreadContext context,
             final RubyString id = (RubyString) arguments.op_aref(context, ID_KEY);
             filterInstance.callMethod(
                 context, "metric=",
-                args[3].callMethod(context, "namespace", id.intern19())
+                ((AbstractMetricExt) args[3]).namespace(context, id.intern19())
             );
             filterInstance.callMethod(context, "execution_context=", args[4]);
             return args[0].callMethod(context, "new", new IRubyObject[]{filterInstance, id});

File: logstash-core/src/main/java/org/logstash/instrument/metrics/MetricKeys.java
Patch:
@@ -9,6 +9,8 @@ private MetricKeys() {
         // Constant Holder
     }
 
+    public static final RubySymbol PIPELINES_KEY = RubyUtil.RUBY.newSymbol("pipelines");
+
     public static final RubySymbol NAME_KEY = RubyUtil.RUBY.newSymbol("name");
 
     public static final RubySymbol EVENTS_KEY = RubyUtil.RUBY.newSymbol("events");

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/DatasetCompiler.java
Patch:
@@ -157,7 +157,7 @@ public static Dataset terminalDataset(final Collection<Dataset> parents) {
      * @return Output Dataset
      */
     public static ComputeStepSyntaxElement<Dataset> outputDataset(final Collection<Dataset> parents,
-        final OutputDelegatorExt output, final boolean terminal) {
+        final AbstractOutputDelegatorExt output, final boolean terminal) {
         final ClassFields fields = new ClassFields();
         final Closure clearSyntax;
         final Closure computeSyntax;

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/RubyIntegration.java
Patch:
@@ -21,7 +21,7 @@ public interface PluginFactory {
         IRubyObject buildInput(RubyString name, RubyInteger line, RubyInteger column,
             IRubyObject args);
 
-        OutputDelegatorExt buildOutput(RubyString name, RubyInteger line, RubyInteger column,
+        AbstractOutputDelegatorExt buildOutput(RubyString name, RubyInteger line, RubyInteger column,
             IRubyObject args);
 
         FilterDelegatorExt buildFilter(RubyString name, RubyInteger line, RubyInteger column,

File: logstash-core/src/main/java/org/logstash/execution/AbstractPipelineExt.java
Patch:
@@ -33,6 +33,7 @@
 import org.logstash.ext.JRubyAbstractQueueWriteClientExt;
 import org.logstash.instrument.metrics.AbstractMetricExt;
 import org.logstash.instrument.metrics.AbstractNamespacedMetricExt;
+import org.logstash.instrument.metrics.MetricKeys;
 import org.logstash.instrument.metrics.NullMetricExt;
 
 @JRubyClass(name = "AbstractPipeline")
@@ -69,8 +70,6 @@ public class AbstractPipelineExt extends RubyBasicObject {
 
     private static final RubySymbol PIPELINES_KEY = RubyUtil.RUBY.newSymbol("pipelines");
 
-    private static final RubySymbol EVENTS_KEY = RubyUtil.RUBY.newSymbol("events");
-
     private static final RubySymbol TYPE_KEY = RubyUtil.RUBY.newSymbol("type");
 
     private static final RubySymbol QUEUE_KEY = RubyUtil.RUBY.newSymbol("queue");
@@ -296,7 +295,7 @@ public final IRubyObject collectStats(final ThreadContext context) throws IOExce
             );
             dataMetrics.gauge(context, STORAGE_TYPE, context.runtime.newString(fileStore.type()));
             dataMetrics.gauge(context, PATH, dirPath);
-            pipelineMetric.gauge(context, EVENTS_KEY, inner.ruby_unread_count(context));
+            pipelineMetric.gauge(context, MetricKeys.EVENTS_KEY, inner.ruby_unread_count(context));
         }
         return context.nil;
     }

File: logstash-core/src/main/java/org/logstash/execution/PipelineReporterExt.java
Patch:
@@ -166,7 +166,7 @@ private RubyArray outputInfo(final ThreadContext context) {
             final OutputDelegatorExt delegator = (OutputDelegatorExt) output;
             final RubyHash hash = RubyHash.newHash(context.runtime);
             hash.op_aset(context, TYPE_KEY, delegator.configName(context));
-            hash.op_aset(context, ID_KEY, delegator.id(context));
+            hash.op_aset(context, ID_KEY, delegator.getId());
             hash.op_aset(context, CONCURRENCY_KEY, delegator.concurrency(context));
             result.add(hash);
         });

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyWrappedAckedQueueExt.java
Patch:
@@ -13,6 +13,7 @@
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.RubyUtil;
 import org.logstash.execution.AbstractWrappedQueueExt;
+import org.logstash.ext.JRubyAbstractQueueWriteClientExt;
 import org.logstash.ext.JrubyAckedReadClientExt;
 import org.logstash.ext.JrubyAckedWriteClientExt;
 import org.logstash.ext.JrubyEventExtLibrary;
@@ -71,7 +72,7 @@ public IRubyObject rubyIsEmpty(ThreadContext context) {
     }
 
     @Override
-    protected IRubyObject getWriteClient(final ThreadContext context) {
+    protected JRubyAbstractQueueWriteClientExt getWriteClient(final ThreadContext context) {
         return JrubyAckedWriteClientExt.create(queue, isClosed);
     }
 

File: logstash-core/src/main/java/org/logstash/execution/AbstractWrappedQueueExt.java
Patch:
@@ -7,6 +7,7 @@
 import org.jruby.anno.JRubyMethod;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
+import org.logstash.ext.JRubyAbstractQueueWriteClientExt;
 
 @JRubyClass(name = "AbstractWrappedQueue")
 public abstract class AbstractWrappedQueueExt extends RubyBasicObject {
@@ -16,7 +17,7 @@ public AbstractWrappedQueueExt(final Ruby runtime, final RubyClass metaClass) {
     }
 
     @JRubyMethod(name = "write_client")
-    public final IRubyObject writeClient(final ThreadContext context) {
+    public final JRubyAbstractQueueWriteClientExt writeClient(final ThreadContext context) {
         return getWriteClient(context);
     }
 
@@ -32,7 +33,7 @@ public final IRubyObject close(final ThreadContext context) {
 
     protected abstract IRubyObject doClose(ThreadContext context);
 
-    protected abstract IRubyObject getWriteClient(ThreadContext context);
+    protected abstract JRubyAbstractQueueWriteClientExt getWriteClient(ThreadContext context);
 
     protected abstract IRubyObject getReadClient();
 }

File: logstash-core/src/main/java/org/logstash/ext/JrubyWrappedSynchronousQueueExt.java
Patch:
@@ -30,7 +30,7 @@ public JrubyWrappedSynchronousQueueExt initialize(final ThreadContext context,
     }
 
     @Override
-    protected IRubyObject getWriteClient(final ThreadContext context) {
+    protected JRubyAbstractQueueWriteClientExt getWriteClient(final ThreadContext context) {
         return JrubyMemoryWriteClientExt.create(queue);
     }
 

File: logstash-core/src/main/java/org/logstash/RubyUtil.java
Patch:
@@ -19,7 +19,7 @@
 import org.logstash.execution.AbstractWrappedQueueExt;
 import org.logstash.execution.EventDispatcherExt;
 import org.logstash.execution.ExecutionContextExt;
-import org.logstash.execution.LogstashPipelineExt;
+import org.logstash.execution.AbstractPipelineExt;
 import org.logstash.execution.PipelineReporterExt;
 import org.logstash.execution.QueueReadClientBase;
 import org.logstash.execution.ShutdownWatcherExt;
@@ -390,7 +390,7 @@ public final class RubyUtil {
         LOGGABLE_MODULE = UTIL_MODULE.defineModuleUnder("Loggable");
         LOGGABLE_MODULE.defineAnnotatedMethods(LoggableExt.class);
         LOGSTASH_PIPELINE_CLASS =
-            setupLogstashClass(LogstashPipelineExt::new, LogstashPipelineExt.class);
+            setupLogstashClass(AbstractPipelineExt::new, AbstractPipelineExt.class);
         final RubyModule json = LOGSTASH_MODULE.defineOrGetModuleUnder("Json");
         final RubyClass stdErr = RUBY.getStandardError();
         LOGSTASH_ERROR = LOGSTASH_MODULE.defineClassUnder(

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyAckedQueueExt.java
Patch:
@@ -6,6 +6,7 @@
 import org.jruby.RubyClass;
 import org.jruby.RubyFixnum;
 import org.jruby.RubyObject;
+import org.jruby.RubyString;
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;
 import org.jruby.javasupport.JavaObject;
@@ -68,7 +69,7 @@ public IRubyObject ruby_page_capacity(ThreadContext context) {
     }
 
     @JRubyMethod(name = "dir_path")
-    public IRubyObject ruby_dir_path(ThreadContext context) {
+    public RubyString ruby_dir_path(ThreadContext context) {
         return context.runtime.newString(queue.getDirPath());
     }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyWrappedAckedQueueExt.java
Patch:
@@ -44,7 +44,7 @@ public JRubyWrappedAckedQueueExt(final Ruby runtime, final RubyClass metaClass)
     }
 
     @JRubyMethod(name = "queue")
-    public IRubyObject rubyGetQueue(ThreadContext context) {
+    public JRubyAckedQueueExt rubyGetQueue() {
         return queue;
     }
 

File: logstash-core/src/main/java/org/logstash/execution/ShutdownWatcherExt.java
Patch:
@@ -151,7 +151,8 @@ public IRubyObject start(final ThreadContext context) throws InterruptedExceptio
                     reports.remove(0);
                 }
                 if (cycleNumber == reportEvery - 1) {
-                    LOGGER.warn(reports.get(reports.size() - 1).anyToString().asJavaString());
+                    LOGGER.warn(reports.get(reports.size() - 1).callMethod(context, "to_s")
+                        .asJavaString());
                     if (shutdownStalled(context).isTrue()) {
                         if (stalledCount == 0) {
                             LOGGER.error(

File: logstash-core/src/main/java/org/logstash/instrument/metrics/NullMetricExt.java
Patch:
@@ -22,7 +22,7 @@ public NullMetricExt(final Ruby runtime, final RubyClass metaClass) {
     }
 
     @JRubyMethod(optional = 1)
-    public IRubyObject initialize(final ThreadContext context, final IRubyObject[] collector) {
+    public NullMetricExt initialize(final ThreadContext context, final IRubyObject[] collector) {
         if (collector.length == 0) {
             this.collector = context.nil;
         } else {

File: logstash-core/src/test/java/org/logstash/config/ir/RubyEnvTestCase.java
Patch:
@@ -29,8 +29,7 @@ private static void ensureLoadpath() {
                 .resolve("jruby").resolve("2.3.0").toFile().getAbsolutePath();
             environment.put("GEM_HOME", gems);
             environment.put("GEM_PATH", gems);
-            loader.addPaths(root.resolve("lib").toFile().getAbsolutePath()
-            );
+            loader.addPaths(root.resolve("lib").toFile().getAbsolutePath());
         }
     }
 }

File: logstash-core/src/test/java/org/logstash/config/ir/RubyEnvTestCase.java
Patch:
@@ -29,7 +29,8 @@ private static void ensureLoadpath() {
                 .resolve("jruby").resolve("2.3.0").toFile().getAbsolutePath();
             environment.put("GEM_HOME", gems);
             environment.put("GEM_PATH", gems);
-            loader.addPaths(root.resolve("lib").toFile().getAbsolutePath());
+            loader.addPaths(root.resolve("lib").toFile().getAbsolutePath()
+            );
         }
     }
 }

File: logstash-core/src/test/java/org/logstash/config/ir/RubyEnvTestCase.java
Patch:
@@ -29,8 +29,7 @@ private static void ensureLoadpath() {
                 .resolve("jruby").resolve("2.3.0").toFile().getAbsolutePath();
             environment.put("GEM_HOME", gems);
             environment.put("GEM_PATH", gems);
-            loader.addPaths(root.resolve("lib").toFile().getAbsolutePath()
-            );
+            loader.addPaths(root.resolve("lib").toFile().getAbsolutePath());
         }
     }
 }

File: logstash-core/src/main/java/org/logstash/ackedqueue/QueueUpgrade.java
Patch:
@@ -110,7 +110,7 @@ private static Checkpoint loadCheckpoint(final Path path, final CheckpointIO cpI
 
     private static void failValidation(final Throwable ex) {
         LOGGER.error("Logstash was unable to upgrade your persistent queue data." +
-            "Please either downgrade to version 6.2.3 and fully drain " +
+            "Please either downgrade to your previous version of Logstash and fully drain " +
             "your persistent queue or delete your queue data.dir if you " +
             "don't need to retain the data currently in your queue.");
         throw new IllegalStateException(ex);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/FilterDelegatorExt.java
Patch:
@@ -45,7 +45,7 @@ public final class FilterDelegatorExt extends RubyObject {
     public IRubyObject init(final ThreadContext context, final IRubyObject filter, final IRubyObject id) {
         this.id = (RubyString) id;
         this.filter = filter;
-        this.filterClass = filter.getMetaClass();
+        this.filterClass = filter.getSingletonClass().getRealClass();
         final IRubyObject namespacedMetric = filter.callMethod(context, "metric");
         metricEvents = namespacedMetric.callMethod(context, "namespace", RubyUtil.RUBY.newSymbol("events"));
         eventMetricOut = LongCounter.fromRubyBase(metricEvents, MetricKeys.OUT_KEY);

File: logstash-core/src/main/java/org/logstash/log/LoggerExt.java
Patch:
@@ -10,7 +10,6 @@
 import org.jruby.RubyBoolean;
 import org.jruby.RubyClass;
 import org.jruby.RubyObject;
-import org.jruby.RubyString;
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;
 import org.jruby.javasupport.JavaUtil;
@@ -31,7 +30,7 @@ public LoggerExt(final Ruby runtime, final RubyClass metaClass) {
     }
 
     @JRubyMethod
-    public IRubyObject initialize(final ThreadContext context, final IRubyObject loggerName) {
+    public LoggerExt initialize(final ThreadContext context, final IRubyObject loggerName) {
         logger = LogManager.getLogger(loggerName.asJavaString());
         return this;
     }

File: logstash-core/src/main/java/org/logstash/log/SlowLoggerExt.java
Patch:
@@ -34,7 +34,7 @@ public SlowLoggerExt(final Ruby runtime, final RubyClass metaClass) {
     }
 
     @JRubyMethod(required = 5)
-    public IRubyObject initialize(final ThreadContext context, final IRubyObject[] args) {
+    public SlowLoggerExt initialize(final ThreadContext context, final IRubyObject[] args) {
         String loggerName = args[0].asJavaString();
         slowLogger = LogManager.getLogger("slowlog." + loggerName);
         warnThreshold = ((RubyNumeric) args[1]).getLongValue();

File: logstash-core/src/main/java/org/logstash/log/LoggerExt.java
Patch:
@@ -130,7 +130,7 @@ public IRubyObject rubyTrace(final ThreadContext context, final IRubyObject[] ar
     public static IRubyObject configureLogging(final ThreadContext context, final IRubyObject self,
                                         final IRubyObject args[]) {
         synchronized (CONFIG_LOCK) {
-            RubyString path = args.length > 1 ? (RubyString) args[1] : null;
+            IRubyObject path = args.length > 1 ? args[1] : null;
             String level = args[0].asJavaString();
             try {
                 setLevel(level, (path == null || path.isNil()) ? null : path.asJavaString());

File: logstash-core/src/main/java/org/logstash/ackedqueue/QueueUpgrade.java
Patch:
@@ -21,7 +21,7 @@
 import org.logstash.ackedqueue.io.MmapPageIOV2;
 import org.logstash.ackedqueue.io.PageIO;
 
-final class QueueUpgrade {
+public final class QueueUpgrade {
 
     private static final Logger LOGGER = LogManager.getLogger(QueueUpgrade.class);
 

File: logstash-core/src/test/java/org/logstash/ackedqueue/HeadPageTest.java
Patch:
@@ -7,7 +7,7 @@
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.TemporaryFolder;
-import org.logstash.ackedqueue.io.MmapPageIO;
+import org.logstash.ackedqueue.io.MmapPageIOV2;
 import org.logstash.ackedqueue.io.PageIO;
 
 import static org.hamcrest.CoreMatchers.equalTo;
@@ -33,7 +33,7 @@ public void newHeadPage() throws IOException {
         // Close method on Page requires an instance of Queue that has already been opened.
         try (Queue q = new Queue(s)) {
             q.open();
-            PageIO pageIO = new MmapPageIO(0, 100, Paths.get(dataPath));
+            PageIO pageIO = new MmapPageIOV2(0, 100, Paths.get(dataPath));
             pageIO.create();
             try (final Page p = PageFactory.newHeadPage(0, q, pageIO)) {
                 assertThat(p.getPageNum(), is(equalTo(0)));

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -24,7 +24,7 @@
 import org.junit.Test;
 import org.junit.rules.TemporaryFolder;
 import org.logstash.ackedqueue.io.LongVector;
-import org.logstash.ackedqueue.io.MmapPageIO;
+import org.logstash.ackedqueue.io.MmapPageIOV2;
 
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.CoreMatchers.is;
@@ -91,7 +91,7 @@ public void singleWriteRead() throws IOException {
     @Test(timeout = 5000)
     public void writeToFullyAckedHeadpage() throws IOException {
         final Queueable element = new StringElement("foobarbaz");
-        final int page = element.serialize().length * 2 + MmapPageIO.MIN_CAPACITY;
+        final int page = element.serialize().length * 2 + MmapPageIOV2.MIN_CAPACITY;
         // Queue that can only hold one element per page.
         try (Queue q = new Queue(
             TestSettings.persistedQueueSettings(page, page * 2 - 1, dataPath))) {
@@ -109,7 +109,7 @@ public void writeToFullyAckedHeadpage() throws IOException {
 
     @Test
     public void canReadBatchZeroSize() throws IOException {
-        final int page = MmapPageIO.MIN_CAPACITY;
+        final int page = MmapPageIOV2.MIN_CAPACITY;
         try (Queue q = new Queue(
             TestSettings.persistedQueueSettings(page, page * 2 - 1, dataPath))) {
             q.open();

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTestHelpers.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.ackedqueue;
 
 import java.io.IOException;
-import org.logstash.ackedqueue.io.MmapPageIO;
+import org.logstash.ackedqueue.io.MmapPageIOV2;
 
 /**
  * Class containing common methods to help DRY up acked queue tests.
  */
 public class QueueTestHelpers {
 
     /**
-     * Returns the {@link org.logstash.ackedqueue.io.MmapPageIO} capacity required for the supplied element
+     * Returns the {@link MmapPageIOV2} capacity required for the supplied element
      * @param element
      * @return int - capacity required for the supplied element
      * @throws IOException Throws if a serialization error occurs
@@ -25,6 +25,6 @@ public static int computeCapacityForMmapPageIO(final Queueable element) throws I
      * @throws IOException Throws if a serialization error occurs
      */
     public static int computeCapacityForMmapPageIO(final Queueable element, int count) throws IOException {
-        return MmapPageIO.HEADER_SIZE + (count * (MmapPageIO.SEQNUM_SIZE + MmapPageIO.LENGTH_SIZE + element.serialize().length + MmapPageIO.CHECKSUM_SIZE));
+        return MmapPageIOV2.HEADER_SIZE + (count * (MmapPageIOV2.SEQNUM_SIZE + MmapPageIOV2.LENGTH_SIZE + element.serialize().length + MmapPageIOV2.CHECKSUM_SIZE));
     }
 }

File: logstash-core/src/test/java/org/logstash/ackedqueue/io/MmapPageIOTest.java
Patch:
@@ -30,11 +30,11 @@ public void adjustToExistingCapacity() throws IOException {
         final int NEW_CAPACITY = 2048;
         final int PAGE_NUM = 0;
 
-        try (PageIO io1 = new MmapPageIO(PAGE_NUM, ORIGINAL_CAPACITY, dir)) {
+        try (PageIO io1 = new MmapPageIOV2(PAGE_NUM, ORIGINAL_CAPACITY, dir)) {
             io1.create();
         }
 
-        try (PageIO io2 = new MmapPageIO(PAGE_NUM, NEW_CAPACITY, dir)) {
+        try (PageIO io2 = new MmapPageIOV2(PAGE_NUM, NEW_CAPACITY, dir)) {
             io2.open(0, PAGE_NUM);
             assertThat(io2.getCapacity(), is(equalTo(ORIGINAL_CAPACITY)));
         }

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/FileCheckpointIO.java
Patch:
@@ -88,7 +88,7 @@ public String tailFileName(int pageNum) {
         return TAIL_CHECKPOINT + pageNum;
     }
 
-    private static Checkpoint read(ByteBuffer data) throws IOException {
+    public static Checkpoint read(ByteBuffer data) throws IOException {
         int version = (int) data.getShort();
         // TODO - build reader for this version
         int pageNum = data.getInt();

File: tools/dependencies-report/src/main/java/org/logstash/dependencies/Dependency.java
Patch:
@@ -12,6 +12,7 @@ class Dependency implements Comparable<Dependency> {
     String name;
     String version;
     String license;
+    String url;
     String spdxLicense;
 
     // optional

File: tools/dependencies-report/src/main/java/org/logstash/dependencies/Main.java
Patch:
@@ -39,7 +39,7 @@ public static void main(String[] args) throws IOException {
         );
 
         // If there were unknown results in the report, exit with a non-zero status
-        System.exit(reportResult ? 0 : 1);
+        //System.exit(reportResult ? 0 : 1);
 
     }
 

File: logstash-core/src/main/java/org/logstash/execution/ExecutionContextExt.java
Patch:
@@ -24,7 +24,7 @@ public ExecutionContextExt(final Ruby runtime, final RubyClass metaClass) {
     }
 
     @JRubyMethod(required = 5)
-    public IRubyObject initialize(final ThreadContext context,
+    public ExecutionContextExt initialize(final ThreadContext context,
         final IRubyObject[] args) {
         pipeline = args[0];
         agent = args[1];

File: logstash-core/src/main/java/org/logstash/RubyUtil.java
Patch:
@@ -275,6 +275,7 @@ public final class RubyUtil {
         RUBY_EVENT_CLASS.defineAnnotatedMethods(JrubyEventExtLibrary.RubyEvent.class);
         RUBY_EVENT_CLASS.defineAnnotatedConstants(JrubyEventExtLibrary.RubyEvent.class);
         RUBY.getGlobalVariables().set("$LS_JARS_LOADED", RUBY.newString("true"));
+        RubyJavaIntegration.setupRubyJavaIntegration(RUBY);
     }
 
     private RubyUtil() {

File: logstash-core/src/main/java/org/logstash/common/AbstractDeadLetterQueueWriterExt.java
Patch:
@@ -130,8 +130,8 @@ public PluginDeadLetterQueueWriterExt(final Ruby runtime, final RubyClass metaCl
         }
 
         @JRubyMethod
-        public IRubyObject initialize(final ThreadContext context,
-            final IRubyObject innerWriter, final IRubyObject pluginId,
+        public AbstractDeadLetterQueueWriterExt.PluginDeadLetterQueueWriterExt initialize(
+            final ThreadContext context, final IRubyObject innerWriter, final IRubyObject pluginId,
             final IRubyObject pluginType) {
             writerWrapper = innerWriter;
             if (writerWrapper.getJavaClass().equals(DeadLetterQueueWriter.class)) {

File: logstash-core/src/main/java/org/logstash/RubyUtil.java
Patch:
@@ -127,8 +127,9 @@ public final class RubyUtil {
         OUTPUT_STRATEGY_SINGLE.defineAnnotatedMethods(OutputStrategyExt.SingleOutputStrategyExt.class);
         OUTPUT_STRATEGY_LEGACY.defineAnnotatedMethods(OutputStrategyExt.LegacyOutputStrategyExt.class);
         final OutputStrategyExt.OutputStrategyRegistryExt outputStrategyRegistry =
-            (OutputStrategyExt.OutputStrategyRegistryExt) OutputStrategyExt.OutputStrategyRegistryExt
-                .instance(RUBY.getCurrentContext(), OUTPUT_DELEGATOR_STRATEGIES);
+            OutputStrategyExt.OutputStrategyRegistryExt.instance(
+                RUBY.getCurrentContext(), OUTPUT_DELEGATOR_STRATEGIES
+            );
         outputStrategyRegistry.register(
             RUBY.getCurrentContext(), RUBY.newSymbol("shared"), OUTPUT_STRATEGY_SHARED
         );

File: logstash-core/src/main/java/org/logstash/ext/JrubyAckedWriteClientExt.java
Patch:
@@ -20,7 +20,7 @@ public final class JrubyAckedWriteClientExt extends RubyObject {
     private AtomicBoolean closed = new AtomicBoolean();
 
     @JRubyMethod(meta = true, required = 2)
-    public static IRubyObject create(final ThreadContext context, IRubyObject recv,
+    public static JrubyAckedWriteClientExt create(final ThreadContext context, IRubyObject recv,
         final IRubyObject queue, final IRubyObject closed) {
         return new JrubyAckedWriteClientExt(
             context.runtime, RubyUtil.ACKED_WRITE_CLIENT_CLASS,

File: logstash-core/src/main/java/org/logstash/ext/JrubyTimestampExtLibrary.java
Patch:
@@ -77,7 +77,7 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args)
         }
 
         @JRubyMethod(name = "time")
-        public IRubyObject ruby_time(ThreadContext context)
+        public RubyTime ruby_time(ThreadContext context)
         {
             return RubyTime.newTime(context.runtime, this.timestamp.getTime());
         }
@@ -225,7 +225,7 @@ public IRubyObject ruby_year(ThreadContext context)
         @JRubyMethod(name = "<=>", required = 1)
         public IRubyObject op_cmp(final ThreadContext context, final IRubyObject other) {
             if (other instanceof JrubyTimestampExtLibrary.RubyTimestamp) {
-                return ((RubyTime) ruby_time(context)).op_cmp(
+                return ruby_time(context).op_cmp(
                     context, ((JrubyTimestampExtLibrary.RubyTimestamp) other).ruby_time(context)
                 );
             }

File: logstash-core/src/test/java/org/logstash/ext/JrubyMemoryReadClientExtTest.java
Patch:
@@ -1,7 +1,6 @@
 package org.logstash.ext;
 
 import java.io.IOException;
-import java.util.Map;
 import java.util.concurrent.ArrayBlockingQueue;
 import java.util.concurrent.BlockingQueue;
 import org.jruby.RubyHash;
@@ -26,10 +25,10 @@ public void testInflightBatchesTracking() throws InterruptedException, IOExcepti
             JrubyMemoryReadClientExt.create(queue, 5, 50);
         final ThreadContext context = WorkerLoop.THREAD_CONTEXT.get();
         final QueueBatch batch = client.readBatch();
-        final RubyHash inflight = (RubyHash) client.rubyGetInflightBatches(context);
+        final RubyHash inflight = client.rubyGetInflightBatches(context);
         assertThat(inflight.size(), is(1));
         assertThat(inflight.get(Thread.currentThread().getId()), is(batch));
         client.closeBatch(batch);
-        assertThat(((Map<?, ?>) client.rubyGetInflightBatches(context)).size(), is(0));
+        assertThat(client.rubyGetInflightBatches(context).size(), is(0));
     }
 }

File: logstash-core/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -8,6 +8,7 @@
 import org.jruby.RubyString;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
+import org.logstash.execution.WorkerLoop;
 
 /**
  * <p>This class is an internal API and behaves very different from a standard {@link Map}.</p>
@@ -60,7 +61,7 @@ public static ConvertedMap newFromMap(Map<? extends Serializable, Object> o) {
     }
 
     public static ConvertedMap newFromRubyHash(final RubyHash o) {
-        return newFromRubyHash(o.getRuntime().getCurrentContext(), o);
+        return newFromRubyHash(WorkerLoop.THREAD_CONTEXT.get(), o);
     }
 
     public static ConvertedMap newFromRubyHash(final ThreadContext context, final RubyHash o) {

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/EventCondition.java
Patch:
@@ -31,6 +31,7 @@
 import org.logstash.config.ir.expression.binary.RegexEq;
 import org.logstash.config.ir.expression.unary.Not;
 import org.logstash.config.ir.expression.unary.Truthy;
+import org.logstash.execution.WorkerLoop;
 import org.logstash.ext.JrubyEventExtLibrary;
 
 /**
@@ -598,7 +599,7 @@ private FieldMatches(final String field, final String regex) {
             public boolean fulfilled(final JrubyEventExtLibrary.RubyEvent event) {
                 final Object tomatch = event.getEvent().getUnconvertedField(field);
                 return tomatch instanceof RubyString &&
-                    !((RubyString) tomatch).match(RubyUtil.RUBY.getCurrentContext(), regex).isNil();
+                    !((RubyString) tomatch).match(WorkerLoop.THREAD_CONTEXT.get(), regex).isNil();
             }
         }
 

File: logstash-core/src/test/java/org/logstash/ext/JrubyMemoryReadClientExtTest.java
Patch:
@@ -6,10 +6,9 @@
 import java.util.concurrent.BlockingQueue;
 import org.jruby.RubyHash;
 import org.jruby.runtime.ThreadContext;
-import org.jruby.runtime.builtin.IRubyObject;
 import org.junit.Test;
-import org.logstash.RubyUtil;
 import org.logstash.execution.QueueBatch;
+import org.logstash.execution.WorkerLoop;
 
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -25,7 +24,7 @@ public void testInflightBatchesTracking() throws InterruptedException, IOExcepti
             new ArrayBlockingQueue<>(10);
         final JrubyMemoryReadClientExt client =
             JrubyMemoryReadClientExt.create(queue, 5, 50);
-        final ThreadContext context = RubyUtil.RUBY.getCurrentContext();
+        final ThreadContext context = WorkerLoop.THREAD_CONTEXT.get();
         final QueueBatch batch = client.readBatch();
         final RubyHash inflight = (RubyHash) client.rubyGetInflightBatches(context);
         assertThat(inflight.size(), is(1));

File: logstash-core/src/main/java/org/logstash/execution/QueueReadClientBase.java
Patch:
@@ -5,7 +5,6 @@
 import org.jruby.RubyHash;
 import org.jruby.RubyNumeric;
 import org.jruby.RubyObject;
-import org.jruby.RubySymbol;
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;
 import org.jruby.java.proxies.JavaProxy;

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/RubyIntegration.java
Patch:
@@ -46,7 +46,7 @@ public interface PluginFactory {
         IRubyObject buildInput(RubyString name, RubyInteger line, RubyInteger column,
             IRubyObject args);
 
-        IRubyObject buildOutput(RubyString name, RubyInteger line, RubyInteger column,
+        OutputDelegatorExt buildOutput(RubyString name, RubyInteger line, RubyInteger column,
             IRubyObject args);
 
         RubyIntegration.Filter buildFilter(RubyString name, RubyInteger line, RubyInteger column,

File: logstash-core/src/main/java/org/logstash/instrument/metrics/counter/LongCounter.java
Patch:
@@ -16,7 +16,7 @@ public class LongCounter extends AbstractMetric<Long> implements CounterMetric<L
     /**
      * Dummy counter used by some functionality as a placeholder when metrics are disabled.
      */
-    private static final LongCounter DUMMY_COUNTER = new LongCounter("dummy");
+    public static final LongCounter DUMMY_COUNTER = new LongCounter("dummy");
 
     private static final IllegalArgumentException NEGATIVE_COUNT_EXCEPTION = new IllegalArgumentException("Counters can not be incremented by negative values");
     private LongAdder longAdder;

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/MmapPageIO.java
Patch:
@@ -6,7 +6,7 @@
 import java.nio.MappedByteBuffer;
 import java.nio.channels.FileChannel;
 import java.nio.file.Files;
-import java.nio.file.Paths;
+import java.nio.file.Path;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.zip.CRC32;
@@ -48,15 +48,15 @@ public final class MmapPageIO implements PageIO {
 
     private MappedByteBuffer buffer;
 
-    public MmapPageIO(int pageNum, int capacity, String dirPath) {
+    public MmapPageIO(int pageNum, int capacity, Path dirPath) {
         this.minSeqNum = 0;
         this.elementCount = 0;
         this.version = 0;
         this.head = 0;
         this.capacity = capacity;
         this.offsetMap = new IntVector();
         this.checkSummer = new CRC32();
-        this.file = Paths.get(dirPath, "page." + pageNum).toFile();
+        this.file = dirPath.resolve("page." + pageNum).toFile();
     }
 
     @Override

File: logstash-core/src/main/java/org/logstash/common/FsUtil.java
Patch:
@@ -2,6 +2,7 @@
 
 import java.io.File;
 import java.io.IOException;
+import java.nio.file.Path;
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.Set;
@@ -27,13 +28,13 @@ private FsUtil() {
      * @return True iff the
      * @throws IOException on failure to determine free space for given path's partition
      */
-    public static boolean hasFreeSpace(final String path, final long size)
+    public static boolean hasFreeSpace(final Path path, final long size)
         throws IOException
     {
         final Set<File> partitionRoots = new HashSet<>(Arrays.asList(File.listRoots()));
 
         // crawl up file path until we find a root partition
-        File location = new File(path).getCanonicalFile();
+        File location = path.toFile().getCanonicalFile();
         while (!partitionRoots.contains(location)) {
             location = location.getParentFile();
             if (location == null) {

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriter.java
Patch:
@@ -58,7 +58,7 @@ public final class DeadLetterQueueWriter implements Closeable {
     private final AtomicBoolean open = new AtomicBoolean(true);
 
     public DeadLetterQueueWriter(Path queuePath, long maxSegmentSize, long maxQueueSize) throws IOException {
-        this.lock = FileLockFactory.obtainLock(queuePath.toString(), LOCK_FILE);
+        this.lock = FileLockFactory.obtainLock(queuePath, LOCK_FILE);
         this.queuePath = queuePath;
         this.maxSegmentSize = maxSegmentSize;
         this.maxQueueSize = maxQueueSize;

File: logstash-core/src/test/java/org/logstash/FileLockFactoryMain.java
Patch:
@@ -1,6 +1,7 @@
 package org.logstash;
 
 import java.io.IOException;
+import java.nio.file.Paths;
 
 /*
  * This program is used to test the FileLockFactory in cross-process/JVM.
@@ -9,7 +10,7 @@ public class FileLockFactoryMain {
 
     public static void main(String[] args) {
         try {
-            FileLockFactory.obtainLock(args[0], args[1]);
+            FileLockFactory.obtainLock(Paths.get(args[0]), args[1]);
             System.out.println("File locked");
             // Sleep enough time until this process is killed.
             Thread.sleep(Long.MAX_VALUE);

File: logstash-core/src/test/java/org/logstash/ackedqueue/HeadPageTest.java
Patch:
@@ -1,6 +1,7 @@
 package org.logstash.ackedqueue;
 
 import java.io.IOException;
+import java.nio.file.Paths;
 import java.util.concurrent.TimeUnit;
 import org.junit.Before;
 import org.junit.Rule;
@@ -32,7 +33,7 @@ public void newHeadPage() throws IOException {
         // Close method on Page requires an instance of Queue that has already been opened.
         try (Queue q = new Queue(s)) {
             q.open();
-            PageIO pageIO = new MmapPageIO(0, 100, dataPath);
+            PageIO pageIO = new MmapPageIO(0, 100, Paths.get(dataPath));
             pageIO.create();
             try (final Page p = PageFactory.newHeadPage(0, q, pageIO)) {
                 assertThat(p.getPageNum(), is(equalTo(0)));

File: logstash-core/src/test/java/org/logstash/ackedqueue/io/FileMmapIOTest.java
Patch:
@@ -1,5 +1,6 @@
 package org.logstash.ackedqueue.io;
 
+import java.nio.file.Path;
 import org.junit.Before;
 import org.junit.Rule;
 import org.junit.Test;
@@ -15,7 +16,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 
 public class FileMmapIOTest {
-    private String folder;
+    private Path folder;
     private MmapPageIO writeIo;
     private MmapPageIO readIo;
     private int pageNum;
@@ -28,7 +29,7 @@ public void setUp() throws Exception {
         pageNum = 0;
         folder = temporaryFolder
                 .newFolder("pages")
-                .getPath();
+                .toPath();
         writeIo = new MmapPageIO(pageNum, 1024, folder);
         readIo = new MmapPageIO(pageNum, 1024, folder);
     }

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/CheckpointIO.java
Patch:
@@ -14,8 +14,6 @@ public interface CheckpointIO {
 
     void purge(String fileName) throws IOException;
 
-    void purge();
-
     // @return the head page checkpoint file name
     String headFileName();
 

File: logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueReaderTest.java
Patch:
@@ -209,7 +209,7 @@ private void validateEntries(Path firstLog, int startEntry, int endEntry, int st
     @Test
     public void testBlockBoundary() throws Exception {
 
-        final int PAD_FOR_BLOCK_SIZE_EVENT = 32516;
+        final int PAD_FOR_BLOCK_SIZE_EVENT = 32490;
         Event event = new Event();
         char[] field = new char[PAD_FOR_BLOCK_SIZE_EVENT];
         Arrays.fill(field, 'e');
@@ -234,7 +234,7 @@ public void testBlockBoundary() throws Exception {
     @Test
     public void testBlockBoundaryMultiple() throws Exception {
         Event event = new Event(Collections.emptyMap());
-        char[] field = new char[7934];
+        char[] field = new char[7929];
         Arrays.fill(field, 'x');
         event.setField("message", new String(field));
         long startTime = System.currentTimeMillis();
@@ -259,7 +259,7 @@ public void testBlockBoundaryMultiple() throws Exception {
     // This test tests for a single event that ends on a block and segment boundary
     @Test
     public void testBlockAndSegmentBoundary() throws Exception {
-        final int PAD_FOR_BLOCK_SIZE_EVENT = 32516;
+        final int PAD_FOR_BLOCK_SIZE_EVENT = 32490;
         Event event = new Event();
         event.setField("T", generateMessageContent(PAD_FOR_BLOCK_SIZE_EVENT));
         Timestamp timestamp = new Timestamp();

File: logstash-core/src/main/java/org/logstash/Logstash.java
Patch:
@@ -160,6 +160,6 @@ private static String safePath(final Path home, final String... subs) {
     }
 
     private static void uncleanShutdown(final Exception ex) {
-        throw new IllegalStateException("Logstash stopped processing because of an error:", ex);
+        throw new IllegalStateException("Logstash stopped processing because of an error: " + ex.getMessage(), ex);
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/VariableDefinition.java
Patch:
@@ -1,5 +1,6 @@
 package org.logstash.config.ir.compiler;
 
+import org.jruby.internal.runtime.methods.DynamicMethod;
 import org.jruby.runtime.builtin.IRubyObject;
 
 /**
@@ -52,6 +53,8 @@ private static Class<?> safeType(final Class<?> clazz) {
             safe = IRubyObject.class;
         } else if (EventCondition.class.isAssignableFrom(clazz)) {
             safe = EventCondition.class;
+        } else if (DynamicMethod.class.isAssignableFrom(clazz)) {
+            safe = DynamicMethod.class;
         } else {
             safe = clazz;
         }

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/RubyIntegration.java
Patch:
@@ -52,6 +52,6 @@ IRubyObject buildOutput(RubyString name, RubyInteger line, RubyInteger column,
         RubyIntegration.Filter buildFilter(RubyString name, RubyInteger line, RubyInteger column,
             IRubyObject args);
 
-        RubyIntegration.Filter buildCodec(RubyString name, IRubyObject args);
+        IRubyObject buildCodec(RubyString name, IRubyObject args);
     }
 }

File: logstash-core/src/test/java/org/logstash/config/ir/CompiledPipelineTest.java
Patch:
@@ -202,7 +202,7 @@ public RubyIntegration.Filter buildFilter(final RubyString name, final RubyInteg
         }
 
         @Override
-        public RubyIntegration.Filter buildCodec(final RubyString name, final IRubyObject args) {
+        public IRubyObject buildCodec(final RubyString name, final IRubyObject args) {
             throw new IllegalStateException("No codec setup expected in this test.");
         }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/AckedBatch.java
Patch:
@@ -7,7 +7,6 @@
 import org.logstash.ext.JrubyEventExtLibrary;
 
 public final class AckedBatch {
-    private static final long serialVersionUID = -3118949118637372130L;
     private Batch batch;
 
     public static AckedBatch create(Batch batch) {

File: logstash-core/src/main/java/org/logstash/ackedqueue/Batch.java
Patch:
@@ -27,6 +27,7 @@ public Batch(List<byte[]> elements, LongVector seqNums, Queue q) {
     }
 
     // close acks the batch ackable events
+    @Override
     public void close() throws IOException {
         if (closed.getAndSet(true) == false) {
               this.queue.ack(this.seqNums);

File: logstash-core/src/main/java/org/logstash/execution/QueueReadClientBase.java
Patch:
@@ -182,6 +182,4 @@ public void addOutputMetrics(int filteredSize) {
     }
 
     public abstract void close() throws IOException;
-    public abstract boolean isEmpty();
-
 }

File: logstash-core/src/main/java/org/logstash/ext/JrubyAckedWriteClientExt.java
Patch:
@@ -50,15 +50,15 @@ private JrubyAckedWriteClientExt(final Ruby runtime, final RubyClass metaClass,
     @JRubyMethod(name = {"push", "<<"}, required = 1)
     public IRubyObject rubyPush(final ThreadContext context, IRubyObject event) {
         ensureOpen();
-        queue.ruby_write(context, event);
+        queue.rubyWrite(context, ((JrubyEventExtLibrary.RubyEvent) event).getEvent());
         return this;
     }
 
     @JRubyMethod(name = "push_batch", required = 1)
     public IRubyObject rubyPushBatch(final ThreadContext context, IRubyObject batch) {
         ensureOpen();
         for (final IRubyObject event : (Collection<JrubyEventExtLibrary.RubyEvent>) batch) {
-            queue.ruby_write(context, event);
+            queue.rubyWrite(context, ((JrubyEventExtLibrary.RubyEvent) event).getEvent());
         }
         return this;
     }

File: logstash-core/src/main/java/org/logstash/ext/JrubyAckedReadClientExt.java
Patch:
@@ -9,7 +9,6 @@
 import org.logstash.RubyUtil;
 import org.logstash.ackedqueue.AckedReadBatch;
 import org.logstash.ackedqueue.ext.JRubyAckedQueueExt;
-import org.logstash.ackedqueue.ext.JRubyWrappedAckedQueueExt;
 import org.logstash.execution.QueueBatch;
 import org.logstash.execution.QueueReadClient;
 import org.logstash.execution.QueueReadClientBase;

File: logstash-core/src/test/java/org/logstash/config/ir/imperative/IfStatementTest.java
Patch:
@@ -37,7 +37,7 @@ public void testEmptyIf() throws InvalidIRException {
     @Test
     public void testIfWithOneTrueStatement() throws InvalidIRException {
         PluginDefinition pluginDef = testPluginDefinition();
-        Statement trueStatement = new PluginStatement(randMeta(), testPluginDefinition());
+        Statement trueStatement = new PluginStatement(randMeta(), pluginDef);
         Statement falseStatement = new NoopStatement(randMeta());
         BooleanExpression ifExpression = createTestExpression();
         IfStatement ifStatement = new IfStatement(
@@ -53,7 +53,7 @@ public void testIfWithOneTrueStatement() throws InvalidIRException {
         Graph expected = new Graph();
         IfVertex expectedIf = DSL.gIf(randMeta(), ifExpression);
         expected.addVertex(expectedIf);
-        PluginVertex expectedT = DSL.gPlugin(randMeta(), testPluginDefinition());
+        PluginVertex expectedT = DSL.gPlugin(randMeta(), pluginDef);
         expected.chainVertices(true, expectedIf, expectedT);
 
         assertSyntaxEquals(expected, ifStatementGraph);

File: logstash-core/src/main/java/org/logstash/config/ir/DSL.java
Patch:
@@ -303,6 +303,9 @@ public static PluginVertex gPlugin(SourceWithMetadata meta, PluginDefinition.Typ
         return gPlugin(meta, type, pluginName, new HashMap<>());
     }
 
+    public static PluginVertex gPlugin(SourceWithMetadata meta, PluginDefinition pluginDefinition) {
+        return gPlugin(meta, pluginDefinition.getType(), pluginDefinition.getName(), pluginDefinition.getArguments());
+    }
 
     public static IfVertex gIf(SourceWithMetadata meta, BooleanExpression expression) {
        return new IfVertex(meta, expression);

File: logstash-core/src/main/java/org/logstash/config/ir/CompiledPipeline.java
Patch:
@@ -241,10 +241,10 @@ private Dataset compile() {
                 .allLeaves().filter(CompiledPipeline.this::isOutput)
                 .collect(Collectors.toList());
             if (outputNodes.isEmpty()) {
-                return DatasetCompiler.ROOT_DATASETS.iterator().next();
+                return Dataset.IDENTITY;
             } else {
                 return DatasetCompiler.terminalDataset(outputNodes.stream().map(
-                    leaf -> outputDataset(leaf, flatten(DatasetCompiler.ROOT_DATASETS, leaf))
+                    leaf -> outputDataset(leaf, flatten(Collections.emptyList(), leaf))
                 ).collect(Collectors.toList()));
             }
         }

File: logstash-core/src/test/java/org/logstash/config/ir/compiler/DatasetCompilerTest.java
Patch:
@@ -1,5 +1,6 @@
 package org.logstash.config.ir.compiler;
 
+import java.util.Collections;
 import org.jruby.RubyArray;
 import org.jruby.runtime.ThreadContext;
 import org.junit.Test;
@@ -21,7 +22,7 @@ public final class DatasetCompilerTest {
     public void compilesOutputDataset() {
         assertThat(
             DatasetCompiler.outputDataset(
-                DatasetCompiler.ROOT_DATASETS,
+                Collections.emptyList(),
                 RubyUtil.RUBY.evalScriptlet(
                     "output = Object.new\noutput.define_singleton_method(:multi_receive) do |batch|\nend\noutput"
                 ),
@@ -35,7 +36,7 @@ public void compilesOutputDataset() {
     public void compilesSplitDataset() {
         final FieldReference key = FieldReference.from("foo");
         final SplitDataset left = DatasetCompiler.splitDataset(
-            DatasetCompiler.ROOT_DATASETS, event -> event.getEvent().includes(key)
+            Collections.emptyList(), event -> event.getEvent().includes(key)
         ).instantiate();
         final Event trueEvent = new Event();
         trueEvent.setField(key, "val");

File: logstash-core/src/main/java/org/logstash/ObjectMappers.java
Patch:
@@ -107,7 +107,7 @@ public void serializeWithType(final RubyString value, final JsonGenerator jgen,
                 typeSer.typeId(value, RubyString.class, JsonToken.VALUE_STRING);
             typeSer.writeTypePrefix(jgen, typeId);
             final ByteList bytes = value.getByteList();
-            jgen.writeBinary(bytes.getUnsafeBytes(), 0, bytes.length());
+            jgen.writeBinary(bytes.getUnsafeBytes(), bytes.begin(), bytes.length());
             typeSer.writeTypeSuffix(jgen, typeId);
         }
     }

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -153,10 +153,11 @@ public void setField(final String reference, final Object value) {
     public void setField(final FieldReference field, final Object value) {
         switch (field.type()) {
             case FieldReference.META_PARENT:
+                // ConvertedMap.newFromMap already does valuefication
                 this.metadata = ConvertedMap.newFromMap((Map<String, Object>) value);
                 break;
             case FieldReference.META_CHILD:
-                Accessors.set(metadata, field, value);
+                Accessors.set(metadata, field, Valuefier.convert(value));
                 break;
             default:
                 Accessors.set(data, field, Valuefier.convert(value));

File: logstash-core/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -101,14 +101,14 @@ public IRubyObject ruby_set_field(ThreadContext context, RubyString reference, I
         public IRubyObject ruby_cancel(ThreadContext context)
         {
             this.event.cancel();
-            return RubyBoolean.createTrueClass(context.runtime);
+            return context.runtime.getTrue();
         }
 
         @JRubyMethod(name = "uncancel")
         public IRubyObject ruby_uncancel(ThreadContext context)
         {
             this.event.uncancel();
-            return RubyBoolean.createFalseClass(context.runtime);
+            return context.runtime.getFalse();
         }
 
         @JRubyMethod(name = "cancelled?")

File: logstash-core/src/main/java/org/logstash/config/ir/CompiledPipeline.java
Patch:
@@ -348,7 +348,7 @@ private Collection<Dataset> compileDependencies(final Vertex start,
                         );
                         // It is important that we double check that we are actually dealing with the
                         // positive/left branch of the if condition
-                        if (ifvert.getOutgoingBooleanEdgesByType(true).stream()
+                        if (ifvert.outgoingBooleanEdgesByType(true)
                             .anyMatch(edge -> Objects.equals(edge.getTo(), start))) {
                             return ifDataset;
                         } else {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/IfVertexTest.java
Patch:
@@ -53,8 +53,8 @@ public void testEdgeTypeHandling() throws InvalidIRException {
         assertThat(ifV.getUnusedOutgoingEdgeFactories().isEmpty(), is(true));
 
 
-        BooleanEdge trueEdge = ifV.getOutgoingBooleanEdgesByType(true).stream().findAny().get();
-        BooleanEdge falseEdge = ifV.getOutgoingBooleanEdgesByType(false).stream().findAny().get();
+        BooleanEdge trueEdge = ifV.outgoingBooleanEdgesByType(true).findAny().get();
+        BooleanEdge falseEdge = ifV.outgoingBooleanEdgesByType(false).findAny().get();
         assertThat(trueEdge.getEdgeType(), is(true));
         assertThat(falseEdge.getEdgeType(), is(false));
     }

File: logstash-core/src/main/java/org/logstash/Logstash.java
Patch:
@@ -44,7 +44,7 @@ public static void main(final String... args) {
         ) {
             logstash.run();
         } catch (final Throwable t) {
-            LOGGER.error(t.toString());
+            LOGGER.error("Logstash encountered an unexpected fatal error!", t);
             System.exit(1);
         }
         System.exit(0);

File: logstash-core/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -86,7 +86,7 @@ public IRubyObject ruby_get_field(ThreadContext context, RubyString reference)
         public IRubyObject ruby_set_field(ThreadContext context, RubyString reference, IRubyObject value)
         {
             final FieldReference r = FieldReference.from(reference.getByteList());
-            if (r  == FieldReference.TIMESTAMP_REFERENCE) {
+            if (r.equals(FieldReference.TIMESTAMP_REFERENCE)) {
                 if (!(value instanceof JrubyTimestampExtLibrary.RubyTimestamp)) {
                     throw context.runtime.newTypeError("wrong argument type " + value.getMetaClass() + " (expected LogStash::Timestamp)");
                 }

File: logstash-core/src/main/java/org/logstash/execution/WorkerLoop.java
Patch:
@@ -49,7 +49,7 @@ public void run() {
                 isShutdown = isShutdown || shutdownRequested.get();
                 final QueueBatch batch = readClient.readBatch();
                 consumedCounter.add(batch.filteredSize());
-                final boolean isFlush = flushRequested.get();
+                final boolean isFlush = flushRequested.compareAndSet(true, false);
                 readClient.startMetrics(batch);
                 execution.compute(batch.to_a(), isFlush, false);
                 int filteredCount = batch.filteredSize();
@@ -59,7 +59,6 @@ public void run() {
                 readClient.closeBatch(batch);
                 if (isFlush) {
                     flushing.set(false);
-                    flushRequested.set(false);
                 }
             } while (!isShutdown || isDraining());
             //we are shutting down, queue is drained if it was required, now  perform a final flush.

File: logstash-core/src/main/java/org/logstash/ackedqueue/SettingsImpl.java
Patch:
@@ -88,12 +88,12 @@ private static final class BuilderImpl implements Builder {
         private static final int DEFAULT_MAX_UNREAD = 0;
 
         /**
-         * Default max number of writes after which we checkpoint.
+         * Default max number of acknowledgements after which we checkpoint.
          */
         private static final int DEFAULT_CHECKPOINT_MAX_ACKS = 1024;
 
         /**
-         * Default number of acknowledgements after which we checkpoint.
+         * Default max number of writes after which we checkpoint.
          */
         private static final int DEFAULT_CHECKPOINT_MAX_WRITES = 1024;
 

File: logstash-core/src/main/java/org/logstash/Logstash.java
Patch:
@@ -44,7 +44,7 @@ public static void main(final String... args) {
         ) {
             logstash.run();
         } catch (final Throwable t) {
-            LOGGER.error(t);
+            LOGGER.error(t.toString());
             System.exit(1);
         }
         System.exit(0);

File: logstash-core/benchmarks/src/main/java/org/logstash/benchmark/QueueWriteBenchmark.java
Patch:
@@ -10,7 +10,6 @@
 import org.logstash.ackedqueue.Queue;
 import org.logstash.ackedqueue.Settings;
 import org.logstash.ackedqueue.SettingsImpl;
-import org.logstash.ackedqueue.io.FileCheckpointIO;
 import org.openjdk.jmh.annotations.Benchmark;
 import org.openjdk.jmh.annotations.BenchmarkMode;
 import org.openjdk.jmh.annotations.Fork;
@@ -75,7 +74,6 @@ private static Settings settings() {
             .queueMaxBytes(Long.MAX_VALUE)
             .checkpointMaxWrites(1024)
             .checkpointMaxAcks(1024)
-            .checkpointIOFactory(FileCheckpointIO::new)
             .elementClass(Event.class).build();
     }
 }

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -20,6 +20,7 @@
 import org.logstash.FileLockFactory;
 import org.logstash.LockException;
 import org.logstash.ackedqueue.io.CheckpointIO;
+import org.logstash.ackedqueue.io.FileCheckpointIO;
 import org.logstash.ackedqueue.io.LongVector;
 import org.logstash.ackedqueue.io.MmapPageIO;
 import org.logstash.ackedqueue.io.PageIO;
@@ -74,7 +75,7 @@ public Queue(Settings settings) {
         this.dirPath = settings.getDirPath();
         this.pageCapacity = settings.getCapacity();
         this.maxBytes = settings.getQueueMaxBytes();
-        this.checkpointIO = settings.getCheckpointIOFactory().build(dirPath);
+        this.checkpointIO = new FileCheckpointIO(dirPath);
         this.elementClass = settings.getElementClass();
         this.tailPages = new ArrayList<>();
         this.unreadTailPages = new ArrayList<>();

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyAckedQueueExt.java
Patch:
@@ -16,7 +16,6 @@
 import org.logstash.ackedqueue.Batch;
 import org.logstash.ackedqueue.Queue;
 import org.logstash.ackedqueue.SettingsImpl;
-import org.logstash.ackedqueue.io.FileCheckpointIO;
 import org.logstash.ext.JrubyEventExtLibrary;
 
 @JRubyClass(name = "AckedQueue")
@@ -49,7 +48,6 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args) {
                 .queueMaxBytes(queueMaxBytes)
                 .checkpointMaxAcks(checkpointMaxAcks)
                 .checkpointMaxWrites(checkpointMaxWrites)
-                .checkpointIOFactory(FileCheckpointIO::new)
                 .elementClass(Event.class)
                 .build()
         );

File: logstash-core/src/main/java/org/logstash/execution/WorkerLoop.java
Patch:
@@ -66,7 +66,7 @@ public void run() {
                 if (isFlush) {
                     flushing.set(false);
                 }
-            } while (!shutdownRequested && !isDraining(context));
+            } while (!shutdownRequested || isDraining(context));
             //we are shutting down, queue is drained if it was required, now  perform a final flush.
             //for this we need to create a new empty batch to contain the final flushed events
             final IRubyObject batch = readClient.callMethod(context, "new_batch");

File: logstash-core/src/test/java/org/logstash/secret/store/backend/JavaKeyStoreTest.java
Patch:
@@ -187,7 +187,7 @@ public void isLogstashKeystore() throws Exception {
      */
     @Test
     public void notLogstashKeystore() throws Exception {
-        thrown.expect(SecretStoreException.LoadException.class);
+        thrown.expect(SecretStoreException.class);
         SecureConfig altConfig = new SecureConfig();
         Path altPath = folder.newFolder().toPath().resolve("alt.not.a.logstash.keystore");
         try (OutputStream out = Files.newOutputStream(altPath)) {

File: logstash-core/src/main/java/org/logstash/ext/JrubyMemoryReadClientExt.java
Patch:
@@ -4,7 +4,6 @@
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.TimeUnit;
 import org.jruby.Ruby;
-import org.jruby.RubyBasicObject;
 import org.jruby.RubyClass;
 import org.jruby.RubyHash;
 import org.jruby.RubyNumeric;
@@ -101,7 +100,9 @@ public IRubyObject setPipelineMetric(final ThreadContext context, IRubyObject me
 
     @JRubyMethod(name = "inflight_batches")
     public IRubyObject rubyGetInflightBatches(final ThreadContext context) {
-        return RubyHash.newHash(context.runtime, inflightBatches, RubyBasicObject.UNDEF);
+        final RubyHash result = RubyHash.newHash(context.runtime);
+        result.putAll(inflightBatches);
+        return result;
     }
 
     // create a new, empty batch

File: logstash-core/src/main/java/org/logstash/secret/store/backend/JavaKeyStore.java
Patch:
@@ -50,7 +50,7 @@ public final class JavaKeyStore implements SecretStore {
     private boolean useDefaultPass = false;
     private Lock writeLock;
     //package private for testing
-    static String filePermissions = "rw-rw----";
+    static String filePermissions = "rw-r--r--";
     private static final boolean IS_WINDOWS = System.getProperty("os.name").startsWith("Windows");
 
     /**

File: logstash-core/src/test/java/org/logstash/secret/store/backend/JavaKeyStoreTest.java
Patch:
@@ -332,7 +332,7 @@ public void testDefaultPermissions() throws Exception {
         // if we got attributes, lets assert them.
         if (attrs != null) {
             Set<PosixFilePermission> permissions = attrs.readAttributes().permissions();
-            EnumSet<PosixFilePermission> expected = EnumSet.of(OWNER_READ, OWNER_WRITE, GROUP_READ, GROUP_WRITE);
+            EnumSet<PosixFilePermission> expected = EnumSet.of(OWNER_READ, OWNER_WRITE, GROUP_READ, OTHERS_READ);
             assertThat(permissions.toArray()).containsExactlyInAnyOrder(expected.toArray());
         }
     }

File: logstash-core/benchmarks/src/main/java/org/logstash/benchmark/QueueWriteBenchmark.java
Patch:
@@ -11,7 +11,6 @@
 import org.logstash.ackedqueue.Settings;
 import org.logstash.ackedqueue.SettingsImpl;
 import org.logstash.ackedqueue.io.FileCheckpointIO;
-import org.logstash.ackedqueue.io.MmapPageIO;
 import org.openjdk.jmh.annotations.Benchmark;
 import org.openjdk.jmh.annotations.BenchmarkMode;
 import org.openjdk.jmh.annotations.Fork;
@@ -74,7 +73,6 @@ private static Settings settings() {
         return SettingsImpl.fileSettingsBuilder(Files.createTempDir().getPath())
             .capacity(256 * 1024 * 1024)
             .queueMaxBytes(Long.MAX_VALUE)
-            .elementIOFactory(MmapPageIO::new)
             .checkpointMaxWrites(1024)
             .checkpointMaxAcks(1024)
             .checkpointIOFactory(FileCheckpointIO::new)

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JRubyAckedQueueExt.java
Patch:
@@ -17,7 +17,6 @@
 import org.logstash.ackedqueue.Queue;
 import org.logstash.ackedqueue.SettingsImpl;
 import org.logstash.ackedqueue.io.FileCheckpointIO;
-import org.logstash.ackedqueue.io.MmapPageIO;
 import org.logstash.ext.JrubyEventExtLibrary;
 
 @JRubyClass(name = "AckedQueue")
@@ -50,7 +49,6 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args) {
                 .queueMaxBytes(queueMaxBytes)
                 .checkpointMaxAcks(checkpointMaxAcks)
                 .checkpointMaxWrites(checkpointMaxWrites)
-                .elementIOFactory(MmapPageIO::new)
                 .checkpointIOFactory(FileCheckpointIO::new)
                 .elementClass(Event.class)
                 .build()

File: logstash-core/src/test/java/org/logstash/ackedqueue/HeadPageTest.java
Patch:
@@ -6,6 +6,7 @@
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.TemporaryFolder;
+import org.logstash.ackedqueue.io.MmapPageIO;
 import org.logstash.ackedqueue.io.PageIO;
 
 import static org.hamcrest.CoreMatchers.equalTo;
@@ -31,8 +32,7 @@ public void newHeadPage() throws IOException {
         // Close method on Page requires an instance of Queue that has already been opened.
         try (Queue q = new Queue(s)) {
             q.open();
-            PageIO pageIO = s.getPageIOFactory()
-                .build(0, 100, dataPath);
+            PageIO pageIO = new MmapPageIO(0, 100, dataPath);
             pageIO.create();
             try (final Page p = PageFactory.newHeadPage(0, q, pageIO)) {
                 assertThat(p.getPageNum(), is(equalTo(0)));

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -23,8 +23,8 @@
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.TemporaryFolder;
-import org.logstash.ackedqueue.io.AbstractByteBufferPageIO;
 import org.logstash.ackedqueue.io.LongVector;
+import org.logstash.ackedqueue.io.MmapPageIO;
 
 import static org.hamcrest.CoreMatchers.equalTo;
 import static org.hamcrest.CoreMatchers.is;
@@ -91,7 +91,7 @@ public void singleWriteRead() throws IOException {
     @Test(timeout = 5000)
     public void writeToFullyAckedHeadpage() throws IOException {
         final Queueable element = new StringElement("foobarbaz");
-        final int page = element.serialize().length * 2 + AbstractByteBufferPageIO.MIN_CAPACITY;
+        final int page = element.serialize().length * 2 + MmapPageIO.MIN_CAPACITY;
         // Queue that can only hold one element per page.
         try (Queue q = new Queue(
             TestSettings.persistedQueueSettings(page, page * 2 - 1, dataPath))) {

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTestHelpers.java
Patch:
@@ -1,7 +1,7 @@
 package org.logstash.ackedqueue;
 
 import java.io.IOException;
-import org.logstash.ackedqueue.io.AbstractByteBufferPageIO;
+import org.logstash.ackedqueue.io.MmapPageIO;
 
 /**
  * Class containing common methods to help DRY up acked queue tests.
@@ -15,6 +15,6 @@ public class QueueTestHelpers {
      * @throws IOException Throws if a serialization error occurs
      */
     public static int singleElementCapacityForByteBufferPageIO(final Queueable element) throws IOException {
-        return AbstractByteBufferPageIO.WRAPPER_SIZE + element.serialize().length;
+        return MmapPageIO.WRAPPER_SIZE + element.serialize().length;
     }
 }

File: logstash-core/src/main/java/org/logstash/ext/JrubyWrappedSynchronousQueueExt.java
Patch:
@@ -13,7 +13,7 @@
 import java.util.concurrent.BlockingQueue;
 
 @JRubyClass(name = "WrappedSynchronousQueue")
-public class JrubyWrappedSynchronousQueueExt extends RubyObject {
+public final class JrubyWrappedSynchronousQueueExt extends RubyObject {
 
     private BlockingQueue<JrubyEventExtLibrary.RubyEvent> queue;
 

File: logstash-core/src/test/java/org/logstash/stress/Concurrent.java
Patch:
@@ -28,7 +28,7 @@ public class Concurrent {
     public static Settings fileSettings(int capacity) {
         PageIOFactory pageIOFactory = (pageNum, size, path) -> new MmapPageIO(pageNum, size, path);
         CheckpointIOFactory checkpointIOFactory = (source) -> new FileCheckpointIO(source);
-        return SettingsImpl.memorySettingsBuilder("/tmp/queue").capacity(capacity)
+        return SettingsImpl.fileSettingsBuilder("/tmp/queue").capacity(capacity)
             .elementIOFactory(pageIOFactory)
             .checkpointIOFactory(checkpointIOFactory).elementClass(StringElement.class).build();
     }

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/AbstractJRubyQueue.java
Patch:
@@ -16,7 +16,6 @@
 import org.logstash.ackedqueue.Batch;
 import org.logstash.ackedqueue.Queue;
 import org.logstash.ackedqueue.SettingsImpl;
-import org.logstash.ackedqueue.io.ByteBufferPageIO;
 import org.logstash.ackedqueue.io.FileCheckpointIO;
 import org.logstash.ackedqueue.io.MemoryCheckpointIO;
 import org.logstash.ackedqueue.io.MmapPageIO;
@@ -162,7 +161,7 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args)
                     .capacity(capacity)
                     .maxUnread(maxUnread)
                     .queueMaxBytes(queueMaxBytes)
-                    .elementIOFactory(ByteBufferPageIO::new)
+                    .elementIOFactory(MmapPageIO::new)
                     .checkpointIOFactory(MemoryCheckpointIO::new)
                     .elementClass(Event.class)
                     .build()

File: logstash-core/src/test/java/org/logstash/ackedqueue/TestSettings.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.ackedqueue;
 
-import org.logstash.ackedqueue.io.ByteBufferPageIO;
 import org.logstash.ackedqueue.io.CheckpointIOFactory;
 import org.logstash.ackedqueue.io.FileCheckpointIO;
 import org.logstash.ackedqueue.io.MemoryCheckpointIO;
@@ -11,15 +10,15 @@ public class TestSettings {
 
     public static Settings volatileQueueSettings(int capacity) {
         MemoryCheckpointIO.clearSources();
-        PageIOFactory pageIOFactory = (pageNum, size, path) -> new ByteBufferPageIO(pageNum, size, path);
+        PageIOFactory pageIOFactory = (pageNum, size, path) -> new MmapPageIO(pageNum, size, path);
         CheckpointIOFactory checkpointIOFactory = (source) -> new MemoryCheckpointIO(source);
         return SettingsImpl.memorySettingsBuilder().capacity(capacity).elementIOFactory(pageIOFactory)
             .checkpointIOFactory(checkpointIOFactory).elementClass(StringElement.class).build();
     }
 
     public static Settings volatileQueueSettings(int capacity, long size) {
         MemoryCheckpointIO.clearSources();
-        PageIOFactory pageIOFactory = (pageNum, pageSize, path) -> new ByteBufferPageIO(pageNum, pageSize, path);
+        PageIOFactory pageIOFactory = (pageNum, pageSize, path) -> new MmapPageIO(pageNum, pageSize, path);
         CheckpointIOFactory checkpointIOFactory = (source) -> new MemoryCheckpointIO(source);
         return SettingsImpl.memorySettingsBuilder().capacity(capacity).queueMaxBytes(size)
             .elementIOFactory(pageIOFactory).checkpointIOFactory(checkpointIOFactory)

File: logstash-core/src/main/java/org/logstash/common/LsQueueUtils.java
Patch:
@@ -45,12 +45,12 @@ public static void addAll(final BlockingQueue<JrubyEventExtLibrary.RubyEvent> qu
      * @throws InterruptedException On Interrupt during {@link BlockingQueue#poll()} or
      * {@link BlockingQueue#drainTo(Collection)}
      */
-    public static Collection<JrubyEventExtLibrary.RubyEvent> drain(
+    public static LinkedHashSet<JrubyEventExtLibrary.RubyEvent> drain(
         final BlockingQueue<JrubyEventExtLibrary.RubyEvent> queue, final int count, final long nanos
     ) throws InterruptedException {
         int left = count;
         //todo: make this an ArrayList once we remove the Ruby pipeline/execution
-        final Collection<JrubyEventExtLibrary.RubyEvent> collection =
+        final LinkedHashSet<JrubyEventExtLibrary.RubyEvent> collection =
             new LinkedHashSet<>(4 * count / 3 + 1);
         do {
             final int drained = drain(queue, collection, left, nanos);

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/FieldDeclarationGroup.java
Patch:
@@ -21,7 +21,7 @@ public Collection<FieldDefinition> getFields() {
     @Override
     public String generateCode() {
         return fields.isEmpty() ? "" : SyntaxFactory.join(fields.stream().map(
-            SyntaxElement::generateCode).collect(Collectors.joining(";")), ";"
+            SyntaxElement::generateCode).collect(Collectors.joining(";\n")), ";"
         );
     }
 }

File: logstash-core/src/main/java/org/logstash/Logstash.java
Patch:
@@ -96,6 +96,8 @@ public void run() {
                 if (status != null && !status.isNil() && RubyNumeric.fix2int(status) != 0) {
                     throw new IllegalStateException(ex);
                 }
+            } else {
+                throw new IllegalStateException(ex);
             }
         }
     }

File: logstash-core/src/main/java/org/logstash/common/LsQueueUtils.java
Patch:
@@ -1,7 +1,7 @@
 package org.logstash.common;
 
 import java.util.Collection;
-import java.util.HashSet;
+import java.util.LinkedHashSet;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.TimeUnit;
 import org.logstash.ext.JrubyEventExtLibrary;
@@ -49,8 +49,9 @@ public static Collection<JrubyEventExtLibrary.RubyEvent> drain(
         final BlockingQueue<JrubyEventExtLibrary.RubyEvent> queue, final int count, final long nanos
     ) throws InterruptedException {
         int left = count;
+        //todo: make this an ArrayList once we remove the Ruby pipeline/execution
         final Collection<JrubyEventExtLibrary.RubyEvent> collection =
-            new HashSet<>(4 * count / 3 + 1);
+            new LinkedHashSet<>(4 * count / 3 + 1);
         do {
             final int drained = drain(queue, collection, left, nanos);
             if (drained == 0) {

File: logstash-core/src/main/java/org/logstash/RubyUtil.java
Patch:
@@ -92,6 +92,7 @@ public final class RubyUtil {
             abstractQueue, AbstractJRubyQueue.RubyAckedMemoryQueue::new,
             AbstractJRubyQueue.RubyAckedMemoryQueue.class
         );
+        RUBY.getGlobalVariables().set("$LS_JARS_LOADED", RUBY.newString("true"));
     }
 
     private RubyUtil() {

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/Closure.java
Patch:
@@ -78,7 +78,7 @@ public String generateCode() {
             this.optimizeRubyThreadContexts().statements;
         return optimized.isEmpty() ? "" : SyntaxFactory.join(
             optimized.stream().map(MethodLevelSyntaxElement::generateCode).collect(
-                Collectors.joining(";\n")
+                Collectors.joining(";")
             ), ";"
         );
     }

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/FieldDeclarationGroup.java
Patch:
@@ -21,7 +21,7 @@ public Collection<FieldDefinition> getFields() {
     @Override
     public String generateCode() {
         return fields.isEmpty() ? "" : SyntaxFactory.join(fields.stream().map(
-            SyntaxElement::generateCode).collect(Collectors.joining(";\n")), ";"
+            SyntaxElement::generateCode).collect(Collectors.joining(";")), ";"
         );
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/SyntaxFactory.java
Patch:
@@ -148,7 +148,7 @@ public int count(final MethodLevelSyntaxElement search) {
             public String generateCode() {
                 return join(
                     "for (", element.generateCode(), " : ",
-                    iterable.generateCode(), ") {\n", body.generateCode(), "\n}"
+                    iterable.generateCode(), ") {", body.generateCode(), "}"
                 );
             }
         };
@@ -165,8 +165,8 @@ public static MethodLevelSyntaxElement ifCondition(final MethodLevelSyntaxElemen
             @Override
             public String generateCode() {
                 return join(
-                    "if(", condition.generateCode(), ") {\n", left.generateCode(),
-                    "\n} else {\n", right.generateCode(), "\n}"
+                    "if(", condition.generateCode(), ") {", left.generateCode(),
+                    "} else {", right.generateCode(), "}"
                 );
             }
 

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/EventCondition.java
Patch:
@@ -381,7 +381,7 @@ private static EventCondition gt(final EventValueExpression left,
                 return new EventCondition.Compiler.FieldGreaterThanString(field, (String) value);
             } else if (value instanceof Long || value instanceof Integer ||
                 value instanceof Short) {
-                return new FieldGreaterThanNumber(
+                return new EventCondition.Compiler.FieldGreaterThanNumber(
                     field, RubyUtil.RUBY.newFixnum(((Number) value).longValue())
                 );
             }

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -496,7 +496,7 @@ public void ensurePersistedUpto(long seqNum) throws IOException{
     /**
      * non-blocking queue read
      *
-     * @param limit read the next batch of size up to this limit. the returned batch size can be smaller than than the requested limit if fewer elements are available
+     * @param limit read the next batch of size up to this limit. the returned batch size can be smaller than the requested limit if fewer elements are available
      * @return {@link Batch} the batch containing 1 or more element up to the required limit or null of no elements were available
      * @throws IOException
      */

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -496,7 +496,7 @@ public void ensurePersistedUpto(long seqNum) throws IOException{
     /**
      * non-blocking queue read
      *
-     * @param limit read the next bach of size up to this limit. the returned batch size can be smaller than than the requested limit if fewer elements are available
+     * @param limit read the next batch of size up to this limit. the returned batch size can be smaller than than the requested limit if fewer elements are available
      * @return {@link Batch} the batch containing 1 or more element up to the required limit or null of no elements were available
      * @throws IOException
      */

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/IfStatement.java
Patch:
@@ -89,7 +89,7 @@ public Graph toGraph() throws InvalidIRException {
         Collection<Vertex> trueRoots = trueGraph.roots().map(combination.oldToNewVertices::get).collect(Collectors.toList());
         Collection<Vertex> falseRoots = falseGraph.roots().map(combination.oldToNewVertices::get).collect(Collectors.toList());
 
-        IfVertex ifVertex = new IfVertex(this.booleanExpression);
+        IfVertex ifVertex = new IfVertex(this.getSourceWithMetadata(), this.booleanExpression);
         newGraph.addVertex(ifVertex);
 
         for (Vertex v : trueRoots) {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/IfVertexTest.java
Patch:
@@ -60,7 +60,7 @@ public void testEdgeTypeHandling() throws InvalidIRException {
     }
 
     public IfVertex testIfVertex() throws InvalidIRException {
-        return new IfVertex(createTestExpression());
+        return new IfVertex(randMeta(), createTestExpression());
     }
 
 }

File: logstash-core/benchmarks/src/main/java/org/logstash/benchmark/QueueRWBenchmark.java
Patch:
@@ -100,7 +100,7 @@ public final void readFromPersistedQueue(final Blackhole blackhole) throws Excep
             }
         });
         for (int i = 0; i < EVENTS_PER_INVOCATION / BATCH_SIZE; ++i) {
-            try (Batch batch = queuePersisted.readBatch(BATCH_SIZE)) {
+            try (Batch batch = queuePersisted.readBatch(BATCH_SIZE, TimeUnit.SECONDS.toMillis(1))) {
                 for (final Queueable elem : batch.getElements()) {
                     blackhole.consume(elem);
                 }
@@ -122,7 +122,7 @@ public final void readFromMemoryQueue(final Blackhole blackhole) throws Exceptio
             }
         });
         for (int i = 0; i < EVENTS_PER_INVOCATION / BATCH_SIZE; ++i) {
-            try (Batch batch = queueMemory.readBatch(BATCH_SIZE)) {
+            try (Batch batch = queueMemory.readBatch(BATCH_SIZE, TimeUnit.SECONDS.toMillis(1))) {
                 for (final Queueable elem : batch.getElements()) {
                     blackhole.consume(elem);
                 }

File: logstash-core/src/test/java/org/logstash/ackedqueue/HeadPageTest.java
Patch:
@@ -1,6 +1,8 @@
 package org.logstash.ackedqueue;
 
 import java.io.IOException;
+import java.util.concurrent.TimeUnit;
+
 import org.junit.Test;
 import org.logstash.ackedqueue.io.PageIO;
 
@@ -84,7 +86,7 @@ public void inEmpty() throws IOException {
             assertThat(p.isEmpty(), is(true));
             p.write(element.serialize(), 1, 1);
             assertThat(p.isEmpty(), is(false));
-            Batch b = q.readBatch(1);
+            Batch b = q.readBatch(1, TimeUnit.SECONDS.toMillis(1));
             assertThat(p.isEmpty(), is(false));
             b.close();
             assertThat(p.isEmpty(), is(true));

File: logstash-core/src/main/java/org/logstash/config/ir/expression/ValueExpression.java
Patch:
@@ -3,6 +3,7 @@
 import java.math.BigDecimal;
 import java.time.Instant;
 import java.util.List;
+import org.jruby.RubyHash;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.config.ir.SourceComponent;
@@ -25,6 +26,7 @@ public ValueExpression(SourceWithMetadata meta, Object value) throws InvalidIREx
                 value instanceof BigDecimal ||
                 value instanceof String ||
                 value instanceof List ||
+                value instanceof RubyHash ||
                 value instanceof Instant
         )) {
             // This *should* be caught by the treetop grammar, but we need this case just in case there's a bug

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Graph.java
Patch:
@@ -156,8 +156,8 @@ public Graph chain(Graph otherGraph) throws InvalidIRException {
 
         // Build these lists here since we do mutate the graph in place later
         // This isn't strictly necessary, but makes things less confusing
-        Collection<Vertex> fromLeaves = allLeaves().map(combineResult.oldToNewVertices::get).collect(Collectors.toSet());
-        Collection<Vertex> toRoots = otherGraph.roots().map(combineResult.oldToNewVertices::get).collect(Collectors.toSet());
+        Collection<Vertex> fromLeaves = allLeaves().map(combineResult.oldToNewVertices::get).collect(Collectors.toList());
+        Collection<Vertex> toRoots = otherGraph.roots().map(combineResult.oldToNewVertices::get).collect(Collectors.toList());
 
         return combineResult.graph.chain(fromLeaves, toRoots);
     }

File: logstash-core/src/main/java/org/logstash/config/ir/DSL.java
Patch:
@@ -314,10 +314,10 @@ public static PluginVertex gPlugin(PluginDefinition.Type type, String pluginName
 
 
     public static IfVertex gIf(SourceWithMetadata meta, BooleanExpression expression) {
-       return new IfVertex(meta, expression);
+       return new IfVertex(expression);
     }
 
     public static IfVertex gIf(BooleanExpression expression) {
-       return new IfVertex(null, expression);
+       return new IfVertex(expression);
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
Patch:
@@ -14,7 +14,7 @@
  */
 public final class PipelineIR implements Hashable {
 
-    private String uniqueHash;
+    private final String uniqueHash;
 
     public Graph getGraph() {
         return graph;

File: logstash-core/src/main/java/org/logstash/config/ir/graph/PluginVertex.java
Patch:
@@ -24,7 +24,7 @@ public SourceWithMetadata getSourceWithMetadata() {
 
     public PluginVertex(SourceWithMetadata meta, PluginDefinition pluginDefinition) {
         // We know that if the ID value exists it will be as a string
-        super(meta, (String) pluginDefinition.getArguments().get("id"));
+        super((String) pluginDefinition.getArguments().get("id"));
         this.meta = meta;
         this.pluginDefinition = pluginDefinition;
     }
@@ -50,7 +50,7 @@ public String calculateIndividualHashSource() {
 
     @Override
     public PluginVertex copy() {
-        return new PluginVertex(meta, getPluginDefinition());
+        return new PluginVertex(meta, pluginDefinition);
     }
 
     @Override

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/IfStatement.java
Patch:
@@ -89,7 +89,7 @@ public Graph toGraph() throws InvalidIRException {
         Collection<Vertex> trueRoots = trueGraph.roots().map(combination.oldToNewVertices::get).collect(Collectors.toList());
         Collection<Vertex> falseRoots = falseGraph.roots().map(combination.oldToNewVertices::get).collect(Collectors.toList());
 
-        IfVertex ifVertex = new IfVertex(this.getSourceWithMetadata(), this.booleanExpression);
+        IfVertex ifVertex = new IfVertex(this.booleanExpression);
         newGraph.addVertex(ifVertex);
 
         for (Vertex v : trueRoots) {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/GraphTest.java
Patch:
@@ -119,7 +119,7 @@ public void testThreadingMulti() throws InvalidIRException {
     @Test
     public void testThreadingTyped() throws InvalidIRException {
         Graph graph = Graph.empty();
-        Vertex if1 = new IfVertex(null, createTestExpression());
+        Vertex if1 = new IfVertex(createTestExpression());
         Vertex condT = IRHelpers.createTestVertex();
         Edge tEdge = graph.chainVertices(BooleanEdge.trueFactory, if1, condT).stream().findFirst().get();
         assertThat(tEdge, instanceOf(BooleanEdge.class));

File: logstash-core/src/test/java/org/logstash/config/ir/graph/IfVertexTest.java
Patch:
@@ -60,7 +60,7 @@ public void testEdgeTypeHandling() throws InvalidIRException {
     }
 
     public IfVertex testIfVertex() throws InvalidIRException {
-        return new IfVertex(testMetadata(), createTestExpression());
+        return new IfVertex(createTestExpression());
     }
 
 }

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -233,7 +233,7 @@ public void writeMultiPageWithInOrderAcking() throws IOException {
             assertThat(q.tailPages.size(), is(1));
 
             // lets keep a ref to that tail page before acking
-            TailPage tailPage = q.tailPages.get(0);
+            Page tailPage = q.tailPages.get(0);
 
             assertThat(tailPage.isFullyRead(), is(true));
 
@@ -863,7 +863,7 @@ public void testZeroByteFullyAckedPageOnOpen() throws IOException {
 
             // work directly on the tail page and not the queue to avoid habing the queue purge the page
             // but make sure the tail page checkpoint marks it as fully acked
-            TailPage tp = q.tailPages.get(0);
+            Page tp = q.tailPages.get(0);
             Batch b = new Batch(tp.read(1), q);
             assertThat(b.getElements().get(0), is(element1));
             tp.ack(b.getSeqNums(), 1);

File: logstash-core/src/main/java/org/logstash/common/LsQueueUtils.java
Patch:
@@ -77,13 +77,12 @@ public static Collection<JrubyEventExtLibrary.RubyEvent> drain(
     private static int drain(final BlockingQueue<JrubyEventExtLibrary.RubyEvent> queue,
         final Collection<JrubyEventExtLibrary.RubyEvent> collection, final int count,
         final long nanos) throws InterruptedException {
-        final long deadline = System.nanoTime() + nanos;
         int added = 0;
         do {
             added += queue.drainTo(collection, count - added);
             if (added < count) {
                 final JrubyEventExtLibrary.RubyEvent event =
-                    queue.poll(deadline - System.nanoTime(), TimeUnit.NANOSECONDS);
+                    queue.poll(nanos, TimeUnit.NANOSECONDS);
                 if (event == null) {
                     break;
                 }

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/AbstractJRubyQueue.java
Patch:
@@ -117,7 +117,7 @@ public IRubyObject ruby_read_batch(ThreadContext context, IRubyObject limit,
             throw RubyUtil.newRubyIOError(context.runtime, e);
         }
         // TODO: return proper Batch object
-        return (b == null) ? context.nil : new RubyAckedBatch(context.runtime, b);
+        return (b == null) ? context.nil : RubyAckedBatch.create(context.runtime, b);
     }
 
     @JRubyMethod(name = "is_fully_acked?")

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/RubyAckedBatch.java
Patch:
@@ -42,7 +42,7 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject events,
         if (!(seqNums instanceof RubyArray)) {
             context.runtime.newArgumentError("expected seqNums array");
         }
-        if (!(queue instanceof JrubyAckedQueueExtLibrary.RubyAckedQueue)) {
+        if (!(queue instanceof AbstractJRubyQueue.RubyAckedQueue)) {
             context.runtime.newArgumentError("expected queue AckedQueue");
         }
         final Collection<Long> seqList = (List<Long>) seqNums;
@@ -51,7 +51,7 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject events,
             seqs.add(seq);
         }
         this.batch = new Batch((List<Queueable>) events, seqs,
-            ((JrubyAckedQueueExtLibrary.RubyAckedQueue) queue).getQueue()
+            ((AbstractJRubyQueue.RubyAckedQueue) queue).getQueue()
         );
         return context.nil;
     }

File: logstash-core/src/main/java/org/logstash/RubyUtil.java
Patch:
@@ -9,9 +9,9 @@
 import org.jruby.exceptions.RaiseException;
 import org.jruby.runtime.ObjectAllocator;
 import org.jruby.runtime.builtin.IRubyObject;
-import org.logstash.ackedqueue.ext.JrubyAckedBatchExtLibrary;
 import org.logstash.ackedqueue.ext.JrubyAckedQueueExtLibrary;
 import org.logstash.ackedqueue.ext.JrubyAckedQueueMemoryExtLibrary;
+import org.logstash.ackedqueue.ext.RubyAckedBatch;
 import org.logstash.ext.JrubyEventExtLibrary;
 import org.logstash.ext.JrubyTimestampExtLibrary;
 
@@ -89,9 +89,9 @@ public JrubyTimestampExtLibrary.RubyTimestamp allocate(final Ruby runtime,
         RUBY_ACKED_BATCH_CLASS = setupLogstashClass("AckedBatch", new ObjectAllocator() {
             @Override
             public IRubyObject allocate(final Ruby runtime, final RubyClass rubyClass) {
-                return new JrubyAckedBatchExtLibrary.RubyAckedBatch(runtime, rubyClass);
+                return new RubyAckedBatch(runtime, rubyClass);
             }
-        }, JrubyAckedBatchExtLibrary.RubyAckedBatch.class);
+        }, RubyAckedBatch.class);
         setupLogstashClass(
             "AckedQueue", JrubyAckedQueueExtLibrary.RubyAckedQueue::new,
             JrubyAckedQueueExtLibrary.RubyAckedQueue.class

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueExtLibrary.java
Patch:
@@ -154,7 +154,7 @@ public IRubyObject ruby_read_batch(ThreadContext context, IRubyObject limit, IRu
             }
 
             // TODO: return proper Batch object
-            return (b == null) ? context.nil : new JrubyAckedBatchExtLibrary.RubyAckedBatch(context.runtime, b);
+            return (b == null) ? context.nil : new RubyAckedBatch(context.runtime, b);
         }
 
         @JRubyMethod(name = "is_fully_acked?")

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueMemoryExtLibrary.java
Patch:
@@ -151,7 +151,7 @@ public IRubyObject ruby_read_batch(ThreadContext context, IRubyObject limit, IRu
             }
 
             // TODO: return proper Batch object
-            return (b == null) ? context.nil : new JrubyAckedBatchExtLibrary.RubyAckedBatch(context.runtime, b);
+            return (b == null) ? context.nil : new RubyAckedBatch(context.runtime, b);
         }
 
         @JRubyMethod(name = "is_fully_acked?")

File: logstash-core/src/main/java/org/logstash/config/ir/compiler/RubyIntegration.java
Patch:
@@ -54,10 +54,9 @@ Collection<JrubyEventExtLibrary.RubyEvent> multiFilter(
     }
 
     /**
-     * The Main Ruby Pipeline Class. Currently, this interface is implemented only by the Ruby class
-     * {@code BasePipeline}.
+     * Plugin Factory that instantiates Ruby plugins and is implemented in Ruby.
      */
-    public interface Pipeline {
+    public interface PluginFactory {
 
         IRubyObject buildInput(RubyString name, RubyInteger line, RubyInteger column,
             IRubyObject args);

File: logstash-core/src/test/java/org/logstash/EventTest.java
Patch:
@@ -394,7 +394,7 @@ public void unwrapsJavaProxyValues() throws Exception {
         final Event event = new Event();
         final Timestamp timestamp = new Timestamp();
         event.setField("timestamp", new ConcreteJavaProxy(RubyUtil.RUBY,
-            JrubyTimestampExtLibrary.createTimestamp(RubyUtil.RUBY).getRealClass(), timestamp
+            RubyUtil.RUBY_TIMESTAMP_CLASS, timestamp
         ));
         assertThat(event.getField("timestamp"), is(timestamp));
     }

File: logstash-core/src/test/java/org/logstash/instrument/metrics/gauge/LazyDelegatingGaugeTest.java
Patch:
@@ -70,6 +70,8 @@ public void getValue() {
         assertThat(gauge.getValue()).isNull();
         assertThat(gauge.get()).isNull();
         assertThat(gauge.getType()).isNull();
+
+        assertThat(gauge.getName()).isNotEmpty();
     }
 
     @Test

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriter.java
Patch:
@@ -34,7 +34,6 @@
 import org.logstash.Event;
 import org.logstash.FieldReference;
 import org.logstash.FileLockFactory;
-import org.logstash.PathCache;
 import org.logstash.Timestamp;
 
 import static org.logstash.common.io.RecordIOWriter.RECORD_HEADER_SIZE;
@@ -47,7 +46,7 @@ public final class DeadLetterQueueWriter implements Closeable {
     static final String SEGMENT_FILE_PATTERN = "%d.log";
     static final String LOCK_FILE = ".lock";
     private static final FieldReference DEAD_LETTER_QUEUE_METADATA_KEY =
-        PathCache.cache(String.format("%s[dead_letter_queue]", Event.METADATA_BRACKETS));
+        FieldReference.from(String.format("%s[dead_letter_queue]", Event.METADATA_BRACKETS));
     private final long maxSegmentSize;
     private final long maxQueueSize;
     private LongAdder currentQueueSize;

File: logstash-core/src/main/java/org/logstash/config/ir/graph/IfVertex.java
Patch:
@@ -13,7 +13,6 @@
  * Created by andrewvc on 9/15/16.
  */
 public class IfVertex extends Vertex {
-    private volatile String generatedId;
 
     public BooleanExpression getBooleanExpression() {
         return booleanExpression;

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueExtLibrary.java
Patch:
@@ -27,7 +27,7 @@ public final class JrubyAckedQueueExtLibrary implements Library {
     public void load(Ruby runtime, boolean wrap) {
         runtime.defineClassUnder(
             "AckedQueue", runtime.getObject(), JrubyAckedQueueExtLibrary.RubyAckedQueue::new,
-            runtime.defineModule(RubyUtil.LS_MODULE_NAME)
+            RubyUtil.LOGSTASH_MODULE
         ).defineAnnotatedMethods(JrubyAckedQueueExtLibrary.RubyAckedQueue.class);
     }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueMemoryExtLibrary.java
Patch:
@@ -28,7 +28,7 @@ public void load(Ruby runtime, boolean wrap) {
         runtime.defineClassUnder(
             "AckedMemoryQueue", runtime.getObject(),
             JrubyAckedQueueMemoryExtLibrary.RubyAckedMemoryQueue::new,
-            runtime.defineModule(RubyUtil.LS_MODULE_NAME)
+            RubyUtil.LOGSTASH_MODULE
         ).defineAnnotatedMethods(JrubyAckedQueueMemoryExtLibrary.RubyAckedMemoryQueue.class);
     }
 

File: logstash-core/src/test/java/org/logstash/JavafierTest.java
Patch:
@@ -6,11 +6,11 @@
 import java.math.BigInteger;
 import static org.junit.Assert.assertEquals;
 
-public class JavafierTest extends TestBase {
+public class JavafierTest {
 
     @Test
     public void testRubyBignum() {
-        RubyBignum v = RubyBignum.newBignum(ruby, "-9223372036854776000");
+        RubyBignum v = RubyBignum.newBignum(RubyUtil.RUBY, "-9223372036854776000");
 
         Object result = Javafier.deep(v);
         assertEquals(BigInteger.class, result.getClass());

File: logstash-core/src/main/java/org/logstash/config/ir/PluginDefinition.java
Patch:
@@ -11,7 +11,7 @@
 /**
  * Created by andrewvc on 9/20/16.
  */
-public class PluginDefinition implements SourceComponent, HashableWithSource {
+public final class PluginDefinition implements SourceComponent, HashableWithSource {
 
     @Override
     public String hashSource() {

File: logstash-core/src/main/java/org/logstash/config/ir/graph/BooleanEdge.java
Patch:
@@ -7,7 +7,7 @@
 /**
  * Created by andrewvc on 9/15/16.
  */
-public class BooleanEdge extends Edge {
+public final class BooleanEdge extends Edge {
     public static class BooleanEdgeFactory extends EdgeFactory {
         public Boolean getEdgeType() {
             return edgeType;

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -5,6 +5,7 @@
 import org.logstash.FileLockFactory;
 import org.logstash.LockException;
 import org.logstash.ackedqueue.io.CheckpointIO;
+import org.logstash.ackedqueue.io.LongVector;
 import org.logstash.ackedqueue.io.PageIO;
 import org.logstash.ackedqueue.io.PageIOFactory;
 
@@ -623,7 +624,7 @@ private TailPageResult linearFindPageForSeqnum(long seqNum) {
     // same-page elements. A fully acked page will trigger a checkpoint for that page. Also if a page has more than checkpointMaxAcks
     // acks since last checkpoint it will also trigger a checkpoint.
     // @param seqNums the list of same-page sequence numbers to ack
-    public void ack(List<Long> seqNums) throws IOException {
+    public void ack(LongVector seqNums) throws IOException {
         // as a first implementation we assume that all batches are created from the same page
         // so we will avoid multi pages acking here for now
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/AbstractByteBufferPageIO.java
Patch:
@@ -224,7 +224,7 @@ public SequencedList<byte[]> read(long seqNum, int limit) throws IOException {
                 String.format("seqNum=%d is > maxSeqNum=%d", seqNum, maxSeqNum());
 
         List<byte[]> elements = new ArrayList<>();
-        List<Long> seqNums = new ArrayList<>();
+        final LongVector seqNums = new LongVector(limit);
 
         int offset = this.offsetMap.get((int)(seqNum - this.minSeqNum));
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/wip/MemoryPageIOStream.java
Patch:
@@ -3,6 +3,7 @@
 import java.util.Collections;
 import org.logstash.ackedqueue.Checkpoint;
 import org.logstash.ackedqueue.SequencedList;
+import org.logstash.ackedqueue.io.LongVector;
 import org.logstash.common.io.BufferedChecksumStreamInput;
 import org.logstash.common.io.BufferedChecksumStreamOutput;
 import org.logstash.common.io.ByteArrayStreamOutput;
@@ -143,7 +144,7 @@ public void write(byte[] bytes, long seqNum) throws IOException {
     @Override
     public SequencedList<byte[]> read(long seqNum, int limit) throws IOException {
         if (elementCount == 0) {
-            return new SequencedList<>(Collections.emptyList(), Collections.emptyList());
+            return new SequencedList<>(Collections.emptyList(), new LongVector(0));
         }
         setReadPoint(seqNum);
         return read(limit);
@@ -257,7 +258,7 @@ private void writeToBuffer(long seqNum, byte[] data, int len) throws IOException
     private SequencedList<byte[]> read(int limit) throws IOException {
         int upto = available(limit);
         List<byte[]> elements = new ArrayList<>(upto);
-        List<Long> seqNums = new ArrayList<>(upto);
+        final LongVector seqNums = new LongVector(upto);
         for (int i = 0; i < upto; i++) {
             long seqNum = readSeqNum();
             byte[] data = readData();

File: logstash-core/src/main/java/org/logstash/Cloner.java
Patch:
@@ -13,6 +13,7 @@ public final class Cloner {
 
     private Cloner(){}
 
+    @SuppressWarnings("unchecked")
     public static <T> T deep(final T input) {
         if (input instanceof Map<?, ?>) {
             return (T) deepMap((Map<?, ?>) input);

File: logstash-core/src/main/java/org/logstash/Util.java
Patch:
@@ -35,6 +35,7 @@ public static Map<String, Object> getMapFixtureHandcrafted() {
         return map;
     }
 
+    @SuppressWarnings("unchecked")
     public static void mapMerge(final Map<String, Object> target, final Map<String, Object> add) {
         LinkedHashSet<Object> buffer = null;
         for (final Map.Entry<String, Object> entry : add.entrySet()) {

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -114,7 +114,7 @@ private Queue(String dirPath, int pageCapacity, long maxBytes, CheckpointIO chec
 
         // retrieve the deserialize method
         try {
-            final Class<?>[] cArg = new Class[1];
+            final Class<?>[] cArg = new Class<?>[1];
             cArg[0] = byte[].class;
             this.deserializeMethod = this.elementClass.getDeclaredMethod("deserialize", cArg);
         } catch (NoSuchMethodException e) {

File: logstash-core/src/test/java/org/logstash/instruments/monitors/ProcessMonitorTest.java
Patch:
@@ -22,11 +22,12 @@ public void testReportFDStats(){
     }
 
     @Test
+    @SuppressWarnings("unchecked")
     public void testReportCpuStats(){
         Map<String, Object> processStats = ProcessMonitor.detect().toMap();
         assumeTrue((Boolean) processStats.get("is_unix"));
         assertThat("cpu", processStats.get("cpu"), instanceOf(Map.class));
-        Map cpuStats = ((Map)processStats.get("cpu"));
+        Map<String, Object> cpuStats = (Map<String, Object>) processStats.get("cpu");
         assertThat("cpu.process_percent", (Short)cpuStats.get("process_percent") >= 0, is(true));
         assertThat("cpu.system_percent", (Short)cpuStats.get("system_percent") >= -1, is(true));
         assertThat("cpu.total_in_millis", (Long)cpuStats.get("total_in_millis") > 0L, is(true));

File: logstash-core/src/main/java/org/logstash/ObjectMappers.java
Patch:
@@ -314,7 +314,7 @@ private static final class RubyNilSerializer extends StdSerializer<RubyNil> {
         @Override
         public void serialize(final RubyNil value, final JsonGenerator jgen,
             final SerializerProvider provider) throws IOException {
-            jgen.writeString("");
+            jgen.writeNull();
         }
 
         @Override

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -12,10 +12,10 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.joda.time.DateTime;
+import org.jruby.RubyNil;
 import org.jruby.RubyString;
 import org.jruby.RubySymbol;
 import org.logstash.ackedqueue.Queueable;
-import org.logstash.bivalues.NullBiValue;
 import org.logstash.ext.JrubyTimestampExtLibrary;
 
 import static org.logstash.ObjectMappers.CBOR_MAPPER;
@@ -283,7 +283,7 @@ public String toString() {
     }
 
     private static Timestamp initTimestamp(Object o) {
-        if (o == null || o instanceof NullBiValue) {
+        if (o == null || o instanceof RubyNil) {
             // most frequent
             return new Timestamp();
         } else {

File: logstash-core/src/test/java/org/logstash/EventTest.java
Patch:
@@ -22,6 +22,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertNull;
 
 public final class EventTest {
 
@@ -34,6 +35,7 @@ public void queueableInterfaceRoundTrip() throws Exception {
         inner.put("innerFoo", 42L);
         final RubySymbol symbol = RubyUtil.RUBY.newSymbol("val");
         e.setField("symbol", symbol);
+        e.setField("null", null);
         inner.put("innerQuux", 42.42);
         e.setField("baz", inner);
         final BigInteger bigint = BigInteger.valueOf(Long.MAX_VALUE).multiply(BigInteger.TEN);
@@ -51,6 +53,7 @@ public void queueableInterfaceRoundTrip() throws Exception {
         assertEquals(42L, er.getField("[baz][innerFoo]"));
         assertEquals(42.42, er.getField("[baz][innerQuux]"));
         assertEquals(42L, er.getField("[@metadata][foo]"));
+        assertNull(er.getField("null"));
 
         assertEquals(e.getTimestamp().toString(), er.getTimestamp().toString());
     }

File: logstash-core/src/test/java/org/logstash/ValuefierTest.java
Patch:
@@ -78,7 +78,7 @@ public void testJodaDateTIme() {
     @Test
     public void testUnhandledObject() {
         RubyMatchData md = new RubyMatchData(ruby);
-        exception.expect(IllegalArgumentException.class);
+        exception.expect(MissingConverterException.class);
         exception.expectMessage("Missing Converter handling for full class name=org.jruby.RubyMatchData, simple name=RubyMatchData");
         Valuefier.convert(md);
     }

File: logstash-core/src/test/java/org/logstash/KeyNodeTest.java
Patch:
@@ -12,7 +12,7 @@ public class KeyNodeTest {
 
     @Test
     public void testNoElementJoin() throws IOException {
-        assertEquals("", KeyNode.join(new ArrayList(), ","));
+        assertEquals("", KeyNode.join(new ArrayList<>(), ","));
     }
 
     @Test

File: logstash-core/src/test/java/org/logstash/StringInterpolationTest.java
Patch:
@@ -93,7 +93,7 @@ public void TestEpoch() throws IOException {
 
     @Test
     public void TestValueIsArray() throws IOException {
-        ArrayList l = new ArrayList();
+        ArrayList<String> l = new ArrayList<>();
         l.add("Hello");
         l.add("world");
 
@@ -113,8 +113,8 @@ public void TestValueIsHash() throws IOException {
     }
 
     public Event getTestEvent() {
-        Map data = new HashMap();
-        Map inner = new HashMap();
+        Map<String, Object> data = new HashMap<>();
+        Map<String, String> inner = new HashMap<>();
 
         inner.put("k1", "v");
 

File: logstash-core/src/test/java/org/logstash/common/io/RecordIOReaderTest.java
Patch:
@@ -131,7 +131,7 @@ public void testSeekDoubleBlockSizeEvents() throws Exception {
 
     private void writeSeekAndVerify(final int eventCount, final int expectedSize) throws IOException {
         int blocks = (int)Math.ceil(expectedSize / (double)BLOCK_SIZE);
-        int fillSize = (int) (expectedSize - (blocks * RECORD_HEADER_SIZE));
+        int fillSize = expectedSize - (blocks * RECORD_HEADER_SIZE);
 
         try(RecordIOWriter writer = new RecordIOWriter(file)){
             for (char i = 0; i < eventCount; i++) {
@@ -145,7 +145,7 @@ private void writeSeekAndVerify(final int eventCount, final int expectedSize) th
             Function<byte[], Character> toChar = (b) -> (char) ByteBuffer.wrap(b).get(0);
 
             for (char i = 0; i < eventCount; i++) {
-                reader.seekToNextEventPosition(i, toChar, Comparator.comparing(o -> ((Character) o)));
+                reader.seekToNextEventPosition(i, toChar, Comparator.comparing(o -> o));
                 assertThat(toChar.apply(reader.readEvent()), equalTo(i));
             }
         }

File: logstash-core/src/test/java/org/logstash/instrument/metrics/MetricTypeTest.java
Patch:
@@ -20,7 +20,7 @@ public class MetricTypeTest {
      */
     @Test
     public void ensurePassivity(){
-        Map<MetricType, String>  nameMap = new HashMap(EnumSet.allOf(MetricType.class).size());
+        Map<MetricType, String> nameMap = new HashMap<>(EnumSet.allOf(MetricType.class).size());
         nameMap.put(MetricType.COUNTER_LONG, "counter/long");
         nameMap.put(MetricType.GAUGE_TEXT, "gauge/text");
         nameMap.put(MetricType.GAUGE_BOOLEAN, "gauge/boolean");

File: logstash-core/src/test/java/org/logstash/stress/Concurrent.java
Patch:
@@ -108,7 +108,7 @@ public static void oneProducersOneConsumer() throws IOException, InterruptedExce
 
     public static void oneProducersOneMultipleConsumer() throws IOException, InterruptedException {
         final List<StringElement> input = new ArrayList<>();
-        final Collection<StringElement> output = new ConcurrentLinkedQueue();
+        final Collection<StringElement> output = new ConcurrentLinkedQueue<>();
         final int CONSUMERS = 5;
         List<Thread> consumers = new ArrayList<>();
 

File: logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueWriterTest.java
Patch:
@@ -25,6 +25,7 @@
 import org.junit.rules.TemporaryFolder;
 import org.logstash.DLQEntry;
 import org.logstash.Event;
+import org.logstash.LockException;
 
 import java.io.IOException;
 import java.nio.channels.FileChannel;
@@ -70,7 +71,7 @@ public void testFileLocking() throws Exception {
         try {
             new DeadLetterQueueWriter(dir, 1000, 100000);
             fail();
-        } catch (RuntimeException e) {
+        } catch (LockException e) {
         } finally {
             writer.close();
         }

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/AbstractByteBufferPageIO.java
Patch:
@@ -42,7 +42,7 @@ public static class PageIOInvalidVersionException extends IOException {
     protected int head; // head is the write position and is an int per ByteBuffer class position
     protected byte version;
     private CRC32 checkSummer;
-    private final List<Integer> offsetMap; // has to be extendable
+    private final IntVector offsetMap;
 
     public AbstractByteBufferPageIO(int pageNum, int capacity) {
         this.minSeqNum = 0;
@@ -51,7 +51,7 @@ public AbstractByteBufferPageIO(int pageNum, int capacity) {
         this.head = 0;
         this.pageNum = pageNum;
         this.capacity = capacity;
-        this.offsetMap = new ArrayList<>();
+        this.offsetMap = new IntVector();
         this.checkSummer = new CRC32();
     }
 

File: logstash-core/src/main/java/org/logstash/ext/JrubyTimestampExtLibrary.java
Patch:
@@ -30,6 +30,8 @@ public RubyTimestamp allocate(Ruby runtime, RubyClass rubyClass) {
         }
     };
 
+    private static final RubyClass TIMESTAMP_CLASS = createTimestamp(RubyUtil.RUBY);
+
     @Override
     public void load(Ruby runtime, boolean wrap) {
         createTimestamp(runtime);
@@ -60,7 +62,7 @@ public RubyTimestamp(Ruby runtime, RubyClass klass, Timestamp timestamp) {
         }
 
         public RubyTimestamp(Ruby runtime, Timestamp timestamp) {
-            this(runtime, runtime.getModule(RubyUtil.LS_MODULE_NAME).getClass("Timestamp"), timestamp);
+            this(runtime, TIMESTAMP_CLASS, timestamp);
         }
 
         public RubyTimestamp(Ruby runtime) {

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueReader.java
Patch:
@@ -159,5 +159,6 @@ public void close() throws IOException {
         if (currentReader != null) {
             currentReader.close();
         }
+        this.watchService.close();
     }
 }

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -382,6 +382,7 @@ public long write(Queueable element) throws IOException {
                     // not trigger a checkpoint creation in itself
                     TailPage tailPage = new TailPage(this.headPage);
                     tailPage.purge();
+                    currentByteSize -= tailPage.getPageIO().getCapacity();
                 } else {
                     // beheading includes checkpoint+fsync if required
                     TailPage tailPage = this.headPage.behead();

File: tools/benchmark-cli/src/main/java/org/logstash/benchmark/cli/cases/GeneratorToStdout.java
Patch:
@@ -5,6 +5,7 @@
 import java.util.Properties;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.TimeoutException;
+import org.logstash.benchmark.cli.BenchmarkMeta;
 import org.logstash.benchmark.cli.DataStore;
 import org.logstash.benchmark.cli.LogstashInstallation;
 import org.logstash.benchmark.cli.LsBenchSettings;
@@ -29,8 +30,9 @@ public final class GeneratorToStdout implements Case {
     private final DataStore store;
 
     public GeneratorToStdout(final DataStore store, final LogstashInstallation logstash,
-        final Properties settings) {
+        final Properties settings, final BenchmarkMeta lsSettings) {
         this.logstash = logstash;
+        logstash.configure(lsSettings);
         this.store = store;
         configuration =
             String.format(

File: logstash-core/benchmarks/src/main/java/org/logstash/benchmark/EventSerializationBenchmark.java
Patch:
@@ -1,7 +1,6 @@
 package org.logstash.benchmark;
 
 import java.io.DataOutputStream;
-import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.TimeUnit;
@@ -39,7 +38,7 @@ public class EventSerializationBenchmark {
     private static final Event EVENT = new Event();
 
     @Setup
-    public void setUp() throws IOException {
+    public void setUp() {
         EVENT.setField("Foo", "Bar");
         EVENT.setField("Foo1", "Bar1");
         EVENT.setField("Foo2", "Bar2");

File: logstash-core/benchmarks/src/main/java/org/logstash/benchmark/EventSprintfBenchmark.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.benchmark;
 
-import java.io.IOException;
 import java.util.concurrent.TimeUnit;
 import org.logstash.Event;
 import org.logstash.Timestamp;
@@ -34,7 +33,7 @@ public class EventSprintfBenchmark {
     private static final Event EVENT = new Event();
 
     @Setup
-    public void setUp() throws IOException {
+    public void setUp() {
         EVENT.setField("Foo", "Bar");
         EVENT.setField("Foo1", "Bar1");
         EVENT.setField("Foo2", "Bar2");

File: logstash-core/benchmarks/src/main/java/org/logstash/benchmark/QueueRWBenchmark.java
Patch:
@@ -66,7 +66,7 @@ public class QueueRWBenchmark {
     private ExecutorService exec;
 
     @Setup
-    public void setUp() throws IOException, CloneNotSupportedException {
+    public void setUp() throws IOException {
         final Settings settingsPersisted = settings(true);
         EVENT.setField("Foo", "Bar");
         EVENT.setField("Foo1", "Bar1");

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -740,7 +740,7 @@ public void close() throws IOException {
         }
     }
 
-    protected Page firstUnreadPage() throws IOException {
+    protected Page firstUnreadPage() {
         // look at head page if no unreadTailPages
         return (this.unreadTailPages.isEmpty()) ? (this.headPage.isFullyRead() ? null : this.headPage) : this.unreadTailPages.get(0);
     }

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/AbstractByteBufferPageIO.java
Patch:
@@ -185,7 +185,7 @@ public void create() throws IOException {
     }
 
     @Override
-    public void write(byte[] bytes, long seqNum) throws IOException {
+    public void write(byte[] bytes, long seqNum) {
         write(bytes, seqNum, bytes.length, checksum(bytes));
     }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/CheckpointIO.java
Patch:
@@ -14,7 +14,7 @@ public interface CheckpointIO {
 
     void purge(String fileName) throws IOException;
 
-    void purge() throws IOException;
+    void purge();
 
     // @return the head page checkpoint file name
     String headFileName();

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/FileCheckpointIO.java
Patch:
@@ -83,7 +83,7 @@ public void purge(String fileName) throws IOException {
     }
 
     @Override
-    public void purge() throws IOException {
+    public void purge() {
         // TODO: dir traversal and delete all checkpoints?
         throw new UnsupportedOperationException("purge() is not supported");
     }

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/MemoryCheckpointIO.java
Patch:
@@ -37,14 +37,14 @@ public Checkpoint read(String fileName) throws IOException {
     }
 
     @Override
-    public Checkpoint write(String fileName, int pageNum, int firstUnackedPageNum, long firstUnackedSeqNum, long minSeqNum, int elementCount) throws IOException {
+    public Checkpoint write(String fileName, int pageNum, int firstUnackedPageNum, long firstUnackedSeqNum, long minSeqNum, int elementCount) {
         Checkpoint checkpoint = new Checkpoint(pageNum, firstUnackedPageNum, firstUnackedSeqNum, minSeqNum, elementCount);
         write(fileName, checkpoint);
         return checkpoint;
     }
 
     @Override
-    public void write(String fileName, Checkpoint checkpoint) throws IOException {
+    public void write(String fileName, Checkpoint checkpoint) {
         Map<String, Checkpoint> ns = sources.get(dirPath);
         if (ns == null) {
             ns = new HashMap<>();

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/PageIOFactory.java
Patch:
@@ -1,8 +1,6 @@
 package org.logstash.ackedqueue.io;
 
-import java.io.IOException;
-
 @FunctionalInterface
 public interface PageIOFactory {
-    PageIO build(int pageNum, int capacity, String dirPath) throws IOException;
+    PageIO build(int pageNum, int capacity, String dirPath);
 }

File: logstash-core/src/test/java/org/logstash/ackedqueue/io/ByteBufferPageIOTest.java
Patch:
@@ -51,7 +51,7 @@ private static ByteBufferPageIO newEmptyPageIO(int capacity) throws IOException
         return io;
     }
 
-    private static ByteBufferPageIO newPageIO(int capacity, byte[] bytes) throws IOException {
+    private static ByteBufferPageIO newPageIO(int capacity, byte[] bytes) {
         return new ByteBufferPageIO(capacity, bytes);
     }
 
@@ -378,4 +378,4 @@ public void writeReadMulti() throws IOException {
         assertThat(StringElement.deserialize(result.getElements().get(2)).toString(), is(equalTo(element3.toString())));
         assertThat(StringElement.deserialize(result.getElements().get(3)).toString(), is(equalTo(element4.toString())));
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueReader.java
Patch:
@@ -68,7 +68,7 @@ public void seekToNextEvent(Timestamp timestamp) throws IOException {
                 try {
                     return DLQEntry.deserialize(b).getEntryTime();
                 } catch (IOException e) {
-                    return null;
+                    throw new IllegalStateException(e);
                 }
             }, Timestamp::compareTo);
             if (event != null) {

File: logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
Patch:
@@ -62,7 +62,7 @@ public String getOriginalSource() {
         return this.originalSource;
     }
 
-    public List<Vertex> getPostQueue() throws InvalidIRException {
+    public List<Vertex> getPostQueue() {
        return graph.getSortedVerticesAfter(queue);
     }
 

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -273,7 +273,7 @@ public String toString() {
 
         try {
             // getTimestamp throws an IOException if there is no @timestamp field, see #7613
-            return getTimestamp().toIso8601() + " " + hostMessageString;
+            return getTimestamp().toString() + " " + hostMessageString;
         } catch (IOException e) {
             return hostMessageString;
         }

File: logstash-core/src/test/java/org/logstash/DLQEntryTest.java
Patch:
@@ -47,7 +47,7 @@ public void testSerDe() throws Exception {
         byte[] bytes = expected.serialize();
         DLQEntry actual = DLQEntry.deserialize(bytes);
         assertJsonEquals(actual.getEvent().toJson(), event.toJson());
-        assertThat(actual.getEntryTime().toIso8601(), equalTo(expected.getEntryTime().toIso8601()));
+        assertThat(actual.getEntryTime().toString(), equalTo(expected.getEntryTime().toString()));
         assertThat(actual.getPluginType(), equalTo("type"));
         assertThat(actual.getPluginId(), equalTo("id"));
         assertThat(actual.getReason(), equalTo("reason"));

File: logstash-core/src/test/java/org/logstash/TimestampTest.java
Patch:
@@ -12,14 +12,14 @@ public class TimestampTest {
     @Test
     public void testCircularIso8601() throws Exception {
         Timestamp t1 = new Timestamp();
-        Timestamp t2 = new Timestamp(t1.toIso8601());
+        Timestamp t2 = new Timestamp(t1.toString());
         assertEquals(t1.getTime(), t2.getTime());
     }
 
     @Test
     public void testToIso8601() throws Exception {
         Timestamp t = new Timestamp("2014-09-23T00:00:00-0800");
-        assertEquals("2014-09-23T08:00:00.000Z", t.toIso8601());
+        assertEquals("2014-09-23T08:00:00.000Z", t.toString());
     }
 
     // Timestamp should always be in a UTC representation

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/ReloadWitnessTest.java
Patch:
@@ -74,7 +74,7 @@ public void testSerializeSuccess() throws Exception {
         witness.success();
         witness.lastSuccessTimestamp(rubyTimestamp);
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"reloads\":{\"last_error\":{\"message\":null,\"backtrace\":null},\"successes\":1,\"last_success_timestamp\":\"" + timestamp.toIso8601() +
+        assertThat(json).isEqualTo("{\"reloads\":{\"last_error\":{\"message\":null,\"backtrace\":null},\"successes\":1,\"last_success_timestamp\":\"" + timestamp.toString() +
                 "\",\"last_failure_timestamp\":null,\"failures\":0}}");
     }
 
@@ -84,7 +84,7 @@ public void testSerializeFailure() throws Exception {
         witness.lastFailureTimestamp(rubyTimestamp);
         String json = witness.asJson();
         assertThat(json).isEqualTo("{\"reloads\":{\"last_error\":{\"message\":null,\"backtrace\":null},\"successes\":0,\"last_success_timestamp\":null," +
-                "\"last_failure_timestamp\":\"" + timestamp.toIso8601() + "\",\"failures\":1}}");
+                "\"last_failure_timestamp\":\"" + timestamp.toString() + "\",\"failures\":1}}");
     }
 
     @Test

File: logstash-core/src/main/java/org/logstash/Javafier.java
Patch:
@@ -6,6 +6,7 @@
 import org.jruby.RubyFixnum;
 import org.jruby.RubyFloat;
 import org.jruby.RubyString;
+import org.jruby.RubySymbol;
 import org.logstash.bivalues.BiValue;
 import org.logstash.bivalues.BiValues;
 import org.logstash.ext.JrubyTimestampExtLibrary;
@@ -57,9 +58,10 @@ private static Map<Class<?>, Valuefier.Converter> initConverters() {
         converters.put(Integer.class, Valuefier.IDENTITY);
         converters.put(Boolean.class, Valuefier.IDENTITY);
         converters.put(Timestamp.class, Valuefier.IDENTITY);
-        // Explicitly casting to RubyString when we know it's a RubyString for sure is faster
+        // Explicitly casting to RubyString or RubySymbol when we know its type for sure is faster
         // than having the JVM look up the type.
         converters.put(RubyString.class, value -> ((RubyString) value).toString());
+        converters.put(RubySymbol.class, value -> ((RubySymbol) value).toString());
         converters.put(RubyBoolean.class, value -> ((RubyBoolean) value).isTrue());
         converters.put(BiValue.class, value -> ((BiValue<?, ?>) value).javaValue());
         converters.put(RubyFixnum.class, value -> ((RubyFixnum) value).getLongValue());

File: logstash-core/src/main/java/org/logstash/Rubyfier.java
Patch:
@@ -10,6 +10,7 @@
 import org.jruby.RubyFloat;
 import org.jruby.RubyHash;
 import org.jruby.RubyString;
+import org.jruby.RubySymbol;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.logstash.bivalues.BiValue;
 import org.logstash.bivalues.BiValues;
@@ -74,6 +75,7 @@ private static Map<Class<?>, Rubyfier.Converter> initConverters() {
         final Map<Class<?>, Rubyfier.Converter> converters =
             new ConcurrentHashMap<>(50, 0.2F, 1);
         converters.put(RubyString.class, IDENTITY);
+        converters.put(RubySymbol.class, IDENTITY);
         converters.put(RubyFloat.class, IDENTITY);
         converters.put(RubyFixnum.class, IDENTITY);
         converters.put(RubyBoolean.class, IDENTITY);

File: logstash-core/src/main/java/org/logstash/Valuefier.java
Patch:
@@ -11,6 +11,7 @@
 import org.jruby.RubyFloat;
 import org.jruby.RubyHash;
 import org.jruby.RubyString;
+import org.jruby.RubySymbol;
 import org.jruby.RubyTime;
 import org.jruby.java.proxies.ArrayJavaProxy;
 import org.jruby.java.proxies.ConcreteJavaProxy;
@@ -99,6 +100,7 @@ private static Map<Class<?>, Valuefier.Converter> initConverters() {
         final Map<Class<?>, Valuefier.Converter> converters =
             new ConcurrentHashMap<>(50, 0.2F, 1);
         converters.put(RubyString.class, IDENTITY);
+        converters.put(RubySymbol.class, IDENTITY);
         converters.put(RubyFixnum.class, IDENTITY);
         converters.put(JrubyTimestampExtLibrary.RubyTimestamp.class, IDENTITY);
         converters.put(RubyFloat.class, IDENTITY);

File: logstash-core/src/main/java/org/logstash/bivalues/BiValues.java
Patch:
@@ -6,7 +6,6 @@
 import java.util.Map;
 import org.jruby.RubyBignum;
 import org.jruby.RubyNil;
-import org.jruby.RubySymbol;
 import org.jruby.ext.bigdecimal.RubyBigDecimal;
 import org.jruby.java.proxies.ConcreteJavaProxy;
 import org.jruby.java.proxies.JavaProxy;
@@ -46,7 +45,6 @@ private static Map<Class<?>, BiValues.BiValueType> initCache() {
         hm.put(BigInteger.class, value -> new BigIntegerBiValue((BigInteger) value));
         hm.put(RubyBignum.class, value -> new BigIntegerBiValue((RubyBignum) value));
         hm.put(RubyNil.class, value -> NULL_BI_VALUE);
-        hm.put(RubySymbol.class, value -> new SymbolBiValue((RubySymbol) value));
         hm.put(RubyBigDecimal.class, value -> new BigDecimalBiValue((RubyBigDecimal) value));
         hm.put(ConcreteJavaProxy.class, value -> {
             if (value instanceof JavaProxy) {

File: logstash-core/src/main/java/org/logstash/common/SourceWithMetadata.java
Patch:
@@ -8,7 +8,6 @@
 import java.util.Objects;
 import java.util.regex.Pattern;
 import java.util.stream.Collectors;
-import java.util.stream.Stream;
 
 /**
  * Created by andrewvc on 9/6/16.

File: logstash-core/src/main/java/org/logstash/config/ir/Hashable.java
Patch:
@@ -1,7 +1,5 @@
 package org.logstash.config.ir;
 
-import org.logstash.common.Util;
-
 /**
  * Created by andrewvc on 12/23/16.
  */

File: logstash-core/src/main/java/org/logstash/config/ir/HashableWithSource.java
Patch:
@@ -1,7 +1,6 @@
 package org.logstash.config.ir;
 
 import org.logstash.common.Util;
-import org.logstash.config.ir.Hashable;
 
 /**
  * Created by andrewvc on 6/12/17.

File: logstash-core/src/main/java/org/logstash/config/ir/expression/Expression.java
Patch:
@@ -3,7 +3,6 @@
 import org.jruby.RubyInstanceConfig;
 import org.jruby.embed.AttributeName;
 import org.jruby.embed.ScriptingContainer;
-import org.logstash.config.ir.Hashable;
 import org.logstash.config.ir.BaseSourceComponent;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.HashableWithSource;
@@ -45,4 +44,4 @@ public String toString() {
     public String hashSource() {
         return toRubyString();
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/main/java/org/logstash/instrument/metrics/counter/LongCounter.java
Patch:
@@ -4,7 +4,6 @@
 import org.logstash.instrument.metrics.AbstractMetric;
 import org.logstash.instrument.metrics.MetricType;
 
-import java.util.List;
 import java.util.concurrent.atomic.LongAdder;
 
 /**

File: logstash-core/src/test/java/org/logstash/ackedqueue/io/FileCheckpointIOTest.java
Patch:
@@ -5,8 +5,6 @@
 import org.junit.Test;
 import org.junit.rules.TemporaryFolder;
 import org.logstash.ackedqueue.Checkpoint;
-import org.logstash.ackedqueue.io.CheckpointIO;
-import org.logstash.ackedqueue.io.FileCheckpointIO;
 
 import java.net.URL;
 import java.nio.file.Files;
@@ -52,4 +50,4 @@ public void write() throws Exception {
         byte[] compare = Files.readAllBytes(path);
         assertThat(contents, is(equalTo(compare)));
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/ackedqueue/io/FileMmapIOTest.java
Patch:
@@ -6,7 +6,6 @@
 import org.junit.rules.TemporaryFolder;
 import org.logstash.ackedqueue.SequencedList;
 import org.logstash.ackedqueue.StringElement;
-import org.logstash.ackedqueue.io.MmapPageIO;
 
 import java.util.ArrayList;
 import java.util.List;
@@ -53,4 +52,4 @@ public void roundTrip() throws Exception {
         }
         assertThat(readList, is(equalTo(list)));
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/ackedqueue/io/wip/MemoryPageIOStreamTest.java
Patch:
@@ -4,7 +4,6 @@
 import org.logstash.ackedqueue.Queueable;
 import org.logstash.ackedqueue.SequencedList;
 import org.logstash.ackedqueue.StringElement;
-import org.logstash.ackedqueue.io.wip.MemoryPageIOStream;
 
 import java.io.IOException;
 import java.nio.ByteBuffer;
@@ -185,4 +184,4 @@ public void readFromFirstUnackedSeqNum() throws Exception {
             assertThat(ele.toString(), is(equalTo(values[i + 3])));
         }
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/common/SourceWithMetadataTest.java
Patch:
@@ -5,7 +5,6 @@
 import org.junit.runners.Parameterized;
 
 import java.util.Arrays;
-import java.util.Collection;
 
 /**
  * Created by andrewvc on 6/12/17.
@@ -59,4 +58,4 @@ public void itShouldInstantiateCleanlyWhenParamsAreGood() throws IncompleteSourc
     public void itShouldThrowWhenMissingAField() throws IncompleteSourceWithMetadataException {
         new SourceWithMetadata(parameterGroup.protocol, parameterGroup.path, parameterGroup.line, parameterGroup.column, parameterGroup.text);
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/common/io/RecordIOReaderTest.java
Patch:
@@ -11,7 +11,6 @@
 import java.nio.file.Path;
 import java.util.Arrays;
 import java.util.Comparator;
-import java.util.Random;
 import java.util.function.Function;
 
 import static org.hamcrest.CoreMatchers.equalTo;
@@ -178,4 +177,4 @@ private char[] fillArray(final int fillSize) {
         Arrays.fill(blockSize, 'e');
         return blockSize;
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/config/ir/graph/GraphTest.java
Patch:
@@ -9,7 +9,6 @@
 
 import java.util.Collection;
 import java.util.Collections;
-import java.util.HashSet;
 
 import static org.hamcrest.CoreMatchers.instanceOf;
 import static org.hamcrest.CoreMatchers.is;

File: logstash-core/src/test/java/org/logstash/config/ir/graph/PluginVertexTest.java
Patch:
@@ -2,7 +2,6 @@
 
 import org.junit.Test;
 import org.logstash.common.IncompleteSourceWithMetadataException;
-import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.config.ir.PluginDefinition;
 

File: logstash-core/src/test/java/org/logstash/instrument/metrics/counter/LongCounterTest.java
Patch:
@@ -4,8 +4,6 @@
 import org.junit.Test;
 import org.logstash.instrument.metrics.MetricType;
 
-import java.util.Collections;
-
 import static org.assertj.core.api.Assertions.assertThat;
 
 /**
@@ -57,4 +55,4 @@ public void noInitialValue() {
     public void type() {
         assertThat(longCounter.type()).isEqualTo(MetricType.COUNTER_LONG.asString());
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/metrics/gauge/BooleanGaugeTest.java
Patch:
@@ -3,8 +3,6 @@
 import org.junit.Test;
 import org.logstash.instrument.metrics.MetricType;
 
-import java.util.Collections;
-
 import static org.assertj.core.api.Assertions.assertThat;
 
 /**
@@ -34,4 +32,4 @@ public void set() {
         assertThat(gauge.getType()).isEqualTo(MetricType.GAUGE_BOOLEAN);
         assertThat(gauge.getValue()).isFalse();
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/metrics/gauge/RubyHashGaugeTest.java
Patch:
@@ -8,8 +8,6 @@
 import org.mockito.Mock;
 import org.mockito.runners.MockitoJUnitRunner;
 
-import java.util.Collections;
-
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.ThrowableAssert.catchThrowable;
 import static org.mockito.Mockito.when;
@@ -54,4 +52,4 @@ public void set() {
         assertThat(gauge.getType()).isEqualTo(MetricType.GAUGE_RUBYHASH);
     }
 
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/metrics/gauge/TextGaugeTest.java
Patch:
@@ -3,8 +3,6 @@
 import org.junit.Test;
 import org.logstash.instrument.metrics.MetricType;
 
-import java.util.Collections;
-
 import static org.assertj.core.api.Assertions.assertThat;
 
 /**
@@ -30,4 +28,4 @@ public void set() {
         assertThat(gauge.getValue()).isEqualTo("baz");
         assertThat(gauge.getType()).isEqualTo(MetricType.GAUGE_TEXT);
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/metrics/gauge/UnknownGaugeTest.java
Patch:
@@ -4,7 +4,6 @@
 import org.logstash.instrument.metrics.MetricType;
 
 import java.net.URI;
-import java.util.Collections;
 
 import static org.assertj.core.api.Assertions.assertThat;
 

File: logstash-core/src/test/java/org/logstash/instrument/witness/configuration/ConfigWitnessTest.java
Patch:
@@ -3,7 +3,6 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
-import org.logstash.instrument.witness.configuration.ConfigWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -141,4 +140,4 @@ public void testSerializeEnableDeadLetterPath() throws Exception {
                 "\"dead_letter_queue_enabled\":false,\"dead_letter_queue_path\":\"/var/dlq\"}}");
     }
 
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/DeadLetterQueueWitnessTest.java
Patch:
@@ -4,7 +4,6 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
-import org.logstash.instrument.witness.pipeline.DeadLetterQueueWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -45,4 +44,4 @@ public void testSerializeQueueSize() throws Exception {
         String json = witness.asJson();
         assertThat(json).isEqualTo("{\"dead_letter_queue\":{\"queue_size_in_bytes\":98}}");
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/ErrorWitnessTest.java
Patch:
@@ -3,7 +3,6 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
-import org.logstash.instrument.witness.pipeline.ErrorWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -68,4 +67,4 @@ public void testSerializeBackTrace() throws Exception {
         json = witness.asJson();
         assertThat(json).contains("Uh oh!").contains("ErrorWitnessTest");
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/EventsWitnessTest.java
Patch:
@@ -3,7 +3,6 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
-import org.logstash.instrument.witness.pipeline.EventsWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -145,4 +144,4 @@ public void testSerializeQueueDuration() throws Exception {
         assertThat(json).doesNotContain("555");
     }
 
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/PipelineWitnessTest.java
Patch:
@@ -3,10 +3,8 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
-import org.logstash.instrument.witness.pipeline.PipelineWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
-import static org.assertj.core.api.Assertions.within;
 
 /**
  * Unit tests for {@link PipelineWitness}
@@ -130,4 +128,4 @@ public void testSerializeDeadLetterQueue() throws Exception {
         json = witness.asJson();
         assertThat(json).contains("\"dead_letter_queue\":{\"queue_size_in_bytes\":0}");
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/PipelinesWitnessTest.java
Patch:
@@ -3,7 +3,6 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
-import org.logstash.instrument.witness.pipeline.PipelinesWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -49,4 +48,4 @@ public void testSerializePipelines() throws Exception {
         assertThat(json).contains("aaa").contains("bbb").contains("ccc");
     }
 
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/PluginWitnessTest.java
Patch:
@@ -7,7 +7,6 @@
 import org.junit.Test;
 import org.logstash.RubyUtil;
 import org.logstash.instrument.metrics.MetricType;
-import org.logstash.instrument.witness.pipeline.PluginWitness;
 
 import java.io.IOException;
 import java.math.BigDecimal;
@@ -167,4 +166,4 @@ public void testSerializationUnknownCustomGauge() throws Exception {
         witness.custom().gauge("a", UUID.randomUUID());
         witness.asJson();
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/PluginsWitnessTest.java
Patch:
@@ -4,7 +4,6 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
-import org.logstash.instrument.witness.pipeline.PluginsWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -94,4 +93,4 @@ public void testSerializeCodecs() throws Exception{
         json = witness.asJson();
         assertThat(json).isEqualTo("{\"plugins\":{\"inputs\":[],\"filters\":[],\"outputs\":[]}}");
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/QueueWitnessTest.java
Patch:
@@ -3,7 +3,6 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
-import org.logstash.instrument.witness.pipeline.QueueWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -172,4 +171,4 @@ public void testSerializeEvents() throws Exception{
         assertThat(json).isEqualTo("{\"queue\":{\"type\":\"persisted\",\"events\":102,\"capacity\":{\"queue_size_in_bytes\":0,\"page_capacity_in_bytes\":0," +
                 "\"max_queue_size_in_bytes\":0,\"max_unread_events\":0},\"data\":{\"path\":null,\"free_space_in_bytes\":0,\"storage_type\":null}}}");
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/ReloadWitnessTest.java
Patch:
@@ -7,7 +7,6 @@
 import org.junit.runner.RunWith;
 import org.logstash.Timestamp;
 import org.logstash.ext.JrubyTimestampExtLibrary;
-import org.logstash.instrument.witness.pipeline.ReloadWitness;
 import org.mockito.Mock;
 import org.mockito.runners.MockitoJUnitRunner;
 
@@ -97,4 +96,4 @@ public void testSerializeError() throws Exception{
         assertThat(json).contains("bar");
     }
 
-}
\ No newline at end of file
+}

File: logstash-core/src/main/java/org/logstash/Accessors.java
Patch:
@@ -1,7 +1,5 @@
 package org.logstash;
 
-import java.util.Map;
-
 public final class Accessors {
 
     private Accessors() {
@@ -102,7 +100,7 @@ private static Object findCreateTarget(final ConvertedMap data, final FieldRefer
     }
 
     private static Object setChild(final Object target, final String key, final Object value) {
-        if (target instanceof Map) {
+        if (target instanceof ConvertedMap) {
             ((ConvertedMap) target).putInterned(key, value);
             return value;
         } else {

File: logstash-core/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -42,9 +42,9 @@ public void visit(final ThreadContext context, final RubyHash self,
         super(size);
     }
 
-    public static ConvertedMap newFromMap(Map<Serializable, Object> o) {
+    public static ConvertedMap newFromMap(Map<? extends Serializable, Object> o) {
         ConvertedMap cm = new ConvertedMap(o.size());
-        for (final Map.Entry<Serializable, Object> entry : o.entrySet()) {
+        for (final Map.Entry<? extends Serializable, Object> entry : o.entrySet()) {
             final Serializable found = entry.getKey();
             if (found instanceof String) {
                 cm.put((String) found, Valuefier.convert(entry.getValue()));

File: logstash-core/src/main/java/org/logstash/Javafier.java
Patch:
@@ -58,7 +58,7 @@ private static Object fallback(final Object o) {
         try {
             return BiValues.newBiValue(o).javaValue();
         } catch (IllegalArgumentException e) {
-            Class cls = o.getClass();
+            final Class<?> cls = o.getClass();
             throw new IllegalArgumentException(String.format(ERR_TEMPLATE, cls.getName(), cls.getSimpleName()));
         }
     }

File: logstash-core/src/main/java/org/logstash/bivalues/BiValue.java
Patch:
@@ -88,7 +88,7 @@ public String toString() {
         return String.valueOf(javaValue);
     }
 
-    protected static Object newProxy(BiValue instance) {
+    protected static Object newProxy(BiValue<?, ?> instance) {
         return new SerializationProxy(instance);
     }
 

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriter.java
Patch:
@@ -159,12 +159,12 @@ private void innerWriteEntry(DLQEntry entry) throws IOException {
      * @param event Logstash Event
      * @return boolean indicating whether the event is eligible to be added to the DLQ
      */
-    private boolean alreadyProcessed(final Event event) {
+    private static boolean alreadyProcessed(final Event event) {
         return event.getMetadata() != null && event.getMetadata().containsKey(DEAD_LETTER_QUEUE_METADATA_KEY);
     }
 
     @Override
-    public synchronized void close() throws IOException {
+    public synchronized void close() {
         if (currentWriter != null) {
             try {
                 currentWriter.close();

File: logstash-core/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -219,8 +219,8 @@ public IRubyObject ruby_to_hash(ThreadContext context) {
 
         @JRubyMethod(name = "to_hash_with_metadata")
         public IRubyObject ruby_to_hash_with_metadata(ThreadContext context) {
-            Map data = this.event.toMap();
-            Map metadata = this.event.getMetadata();
+            Map<String, Object> data = this.event.toMap();
+            Map<String, Object> metadata = this.event.getMetadata();
 
             if (!metadata.isEmpty()) {
                 data.put(Event.METADATA, metadata);
@@ -323,7 +323,7 @@ private void initializeFallback(final ThreadContext context, final IRubyObject d
                 this.event = new Event();
             } else if (data instanceof MapJavaProxy) {
                 this.event = new Event(ConvertedMap.newFromMap(
-                    (Map)((MapJavaProxy)data).getObject())
+                    (Map<String, Object>)((MapJavaProxy)data).getObject())
                 );
             } else {
                 throw context.runtime.newTypeError("wrong argument type " + data.getMetaClass() + " (expected Hash)");

File: logstash-core/src/main/java/org/logstash/instrument/metrics/Metric.java
Patch:
@@ -21,6 +21,7 @@ public interface Metric<T> {
      * @return This metric value
      * @deprecated
      */
+    @Deprecated
     default T get() {
         return getValue();
     }
@@ -45,6 +46,7 @@ default T get() {
      * @return A description of this Metric that can be used for logging.
      * @deprecated
      */
+    @Deprecated
     default String inspect() {
         return toString();
     }
@@ -55,6 +57,7 @@ default String inspect() {
      * @return The {@link String} version of the {@link MetricType}
      * @deprecated
      */
+    @Deprecated
     default String type() {
         return getType().asString();
     }

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/LazyDelegatingGauge.java
Patch:
@@ -91,7 +91,7 @@ private synchronized void wakeMetric(Object value) {
             } else if (value instanceof RubyHash) {
                 lazyMetric = new RubyHashGauge(key, (RubyHash) value);
             } else if (value instanceof RubyTimestamp) {
-                lazyMetric = new RubyTimeStampGauge(key, ((RubyTimestamp) value));
+                lazyMetric = new RubyTimeStampGauge(key, (RubyTimestamp) value);
             } else {
                 LOGGER.warn("A gauge metric of an unknown type ({}) has been create for key: {}. This may result in invalid serialization.  It is recommended to " +
                         "log an issue to the responsible developer/development team.", value.getClass().getCanonicalName(), key);

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/DeadLetterQueueWitness.java
Patch:
@@ -94,7 +94,7 @@ static void innerSerialize(DeadLetterQueueWitness witness, JsonGenerator gen) th
     /**
      * The snitch for the dead letter queue. Used to retrieve discrete metric values.
      */
-    public class Snitch {
+    public static class Snitch {
         private final DeadLetterQueueWitness witness;
 
         private Snitch(DeadLetterQueueWitness witness) {

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/PluginsWitness.java
Patch:
@@ -89,8 +89,8 @@ public void forgetAll() {
      * @param id     the id of the plugin
      * @return existing or new {@link PluginWitness}
      */
-    private PluginWitness getPlugin(Map<String, PluginWitness> plugin, String id) {
-        return plugin.computeIfAbsent(id, k -> new PluginWitness(k));
+    private static PluginWitness getPlugin(Map<String, PluginWitness> plugin, String id) {
+        return plugin.computeIfAbsent(id, PluginWitness::new);
     }
 
     @Override

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/ReloadWitness.java
Patch:
@@ -116,7 +116,7 @@ public void lastFailureTimestamp(JrubyTimestampExtLibrary.RubyTimestamp timestam
 
     @Override
     public void genJson(JsonGenerator gen, SerializerProvider provider) throws IOException {
-        SERIALIZER.innerSerialize(this, gen, provider);
+        Serializer.innerSerialize(this, gen, provider);
     }
 
     /**
@@ -149,7 +149,8 @@ public void serialize(ReloadWitness witness, JsonGenerator gen, SerializerProvid
             gen.writeEndObject();
         }
 
-        void innerSerialize(ReloadWitness witness, JsonGenerator gen, SerializerProvider provider) throws IOException {
+        static void innerSerialize(ReloadWitness witness, JsonGenerator gen,
+            SerializerProvider provider) throws IOException {
             gen.writeObjectFieldStart(ReloadWitness.KEY);
             witness.lastError.genJson(gen, provider);
             MetricSerializer<Metric<Long>> longSerializer = MetricSerializer.Get.longSerializer(gen);

File: logstash-core/src/test/java/org/logstash/EventTest.java
Patch:
@@ -275,17 +275,17 @@ public void testFromJsonWithInvalidJsonString() throws Exception {
         Event.fromJson("gabeutch");
     }
 
-    @Test(expected=IOException.class)
+    @Test(expected=ClassCastException.class)
     public void testFromJsonWithInvalidJsonArray1() throws Exception {
         Event.fromJson("[1,2]");
     }
 
-    @Test(expected=IOException.class)
+    @Test(expected=ClassCastException.class)
     public void testFromJsonWithInvalidJsonArray2() throws Exception {
         Event.fromJson("[\"gabeutch\"]");
     }
 
-    @Test(expected=IOException.class)
+    @Test(expected=ClassCastException.class)
     public void testFromJsonWithPartialInvalidJsonArray() throws Exception {
         Event.fromJson("[{\"foo\":\"bar\"}, 1]");
     }

File: logstash-core/src/main/java/org/logstash/Accessors.java
Patch:
@@ -103,7 +103,7 @@ private static Object findCreateTarget(final ConvertedMap data, final FieldRefer
 
     private static Object setChild(final Object target, final String key, final Object value) {
         if (target instanceof Map) {
-            ((ConvertedMap) target).put(key, value);
+            ((ConvertedMap) target).putInterned(key, value);
             return value;
         } else {
             return setOnList(key, value, (ConvertedList) target);
@@ -112,7 +112,7 @@ private static Object setChild(final Object target, final String key, final Obje
 
     private static Object createChild(final ConvertedMap target, final String key) {
         final Object result = new ConvertedMap(1);
-        target.put(key, result);
+        target.putInterned(key, result);
         return result;
     }
 

File: logstash-core/src/test/java/org/logstash/ValuefierTest.java
Patch:
@@ -81,7 +81,7 @@ public void testJodaDateTIme() {
     public void testUnhandledObject() {
         RubyMatchData md = new RubyMatchData(ruby);
         exception.expect(IllegalArgumentException.class);
-        exception.expectMessage("Missing Valuefier handling for full class name=org.jruby.RubyMatchData, simple name=RubyMatchData");
+        exception.expectMessage("Missing Converter handling for full class name=org.jruby.RubyMatchData, simple name=RubyMatchData");
         Valuefier.convert(md);
     }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedBatchExtLibrary.java
Patch:
@@ -12,6 +12,7 @@
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.jruby.runtime.load.Library;
+import org.logstash.RubyUtil;
 import org.logstash.ackedqueue.Batch;
 import org.logstash.Event;
 import org.logstash.ackedqueue.Queueable;
@@ -22,7 +23,7 @@
 public class JrubyAckedBatchExtLibrary implements Library {
 
     public void load(Ruby runtime, boolean wrap) throws IOException {
-        RubyModule module = runtime.defineModule("LogStash");
+        RubyModule module = runtime.defineModule(RubyUtil.LS_MODULE_NAME);
 
         RubyClass clazz = runtime.defineClassUnder("AckedBatch", runtime.getObject(), new ObjectAllocator() {
             public IRubyObject allocate(Ruby runtime, RubyClass rubyClass) {
@@ -44,7 +45,7 @@ public RubyAckedBatch(Ruby runtime, RubyClass klass) {
         }
 
         public RubyAckedBatch(Ruby runtime, Batch batch) {
-            super(runtime, runtime.getModule("LogStash").getClass("AckedBatch"));
+            super(runtime, runtime.getModule(RubyUtil.LS_MODULE_NAME).getClass("AckedBatch"));
             this.batch = batch;
         }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueExtLibrary.java
Patch:
@@ -15,6 +15,7 @@
 import org.jruby.runtime.builtin.IRubyObject;
 import org.jruby.runtime.load.Library;
 import org.logstash.Event;
+import org.logstash.RubyUtil;
 import org.logstash.ackedqueue.Batch;
 import org.logstash.ackedqueue.Queue;
 import org.logstash.ackedqueue.SettingsImpl;
@@ -25,7 +26,7 @@
 public class JrubyAckedQueueExtLibrary implements Library {
 
     public void load(Ruby runtime, boolean wrap) throws IOException {
-        RubyModule module = runtime.defineModule("LogStash");
+        RubyModule module = runtime.defineModule(RubyUtil.LS_MODULE_NAME);
 
         RubyClass clazz = runtime.defineClassUnder("AckedQueue", runtime.getObject(), new ObjectAllocator() {
             public IRubyObject allocate(Ruby runtime, RubyClass rubyClass) {

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueMemoryExtLibrary.java
Patch:
@@ -15,6 +15,7 @@
 import org.jruby.runtime.builtin.IRubyObject;
 import org.jruby.runtime.load.Library;
 import org.logstash.Event;
+import org.logstash.RubyUtil;
 import org.logstash.ackedqueue.Batch;
 import org.logstash.ackedqueue.Queue;
 import org.logstash.ackedqueue.SettingsImpl;
@@ -25,7 +26,7 @@
 public class JrubyAckedQueueMemoryExtLibrary implements Library {
 
     public void load(Ruby runtime, boolean wrap) throws IOException {
-        RubyModule module = runtime.defineModule("LogStash");
+        RubyModule module = runtime.defineModule(RubyUtil.LS_MODULE_NAME);
 
         RubyClass clazz = runtime.defineClassUnder("AckedMemoryQueue", runtime.getObject(), new ObjectAllocator() {
             public IRubyObject allocate(Ruby runtime, RubyClass rubyClass) {

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/RubyHashGauge.java
Patch:
@@ -8,6 +8,7 @@
  * on the types in in the {@link RubyHash} there are no guarantees serializing properly.
  * @deprecated - There are no plans to replace this.
  */
+@Deprecated
 public class RubyHashGauge extends AbstractGaugeMetric<RubyHash> {
 
     /**
@@ -16,6 +17,7 @@ public class RubyHashGauge extends AbstractGaugeMetric<RubyHash> {
      * @param name The name of this metric. This value may be used for display purposes.
      * @deprecated - There are no plans to replace this.
      */
+    @Deprecated
     protected RubyHashGauge(String name) {
         super(name);
     }
@@ -27,6 +29,7 @@ protected RubyHashGauge(String name) {
      * @param initialValue The initial value for this {@link GaugeMetric}, may be null
      * @deprecated - There are no plans to replace this.
      */
+    @Deprecated
     protected RubyHashGauge(String name, RubyHash initialValue) {
         super(name, initialValue);
     }

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/UnknownGauge.java
Patch:
@@ -6,6 +6,7 @@
  * A {@link GaugeMetric} that is backed by a {@link Object}.  Note - A stronger typed {@link GaugeMetric} should be used since this makes no guarantees of serializing properly.
  * @deprecated - There are no plans to replace this.
  */
+@Deprecated
 public class UnknownGauge extends AbstractGaugeMetric<Object> {
 
     /**
@@ -14,6 +15,7 @@ public class UnknownGauge extends AbstractGaugeMetric<Object> {
      * @param name The name of this metric. This value may be used for display purposes.
      * @deprecated - There are no plans to replace this.
      */
+    @Deprecated
     public UnknownGauge(String name) {
         super(name);
     }
@@ -25,6 +27,7 @@ public UnknownGauge(String name) {
      * @param initialValue The initial value for this {@link GaugeMetric}, may be null
      * @deprecated - There are no plans to replace this.
      */
+    @Deprecated
     public UnknownGauge(String name, Object initialValue) {
         super(name, initialValue);
     }

File: logstash-core/src/main/java/org/logstash/instrument/witness/MetricSerializer.java
Patch:
@@ -20,6 +20,7 @@ public interface MetricSerializer<T extends Metric<?>> {
      * Performs this operation on the given argument.
      *
      * @param t the input argument
+     * @throws IOException On failure to serialize
      */
     void serialize(T t) throws IOException;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/configuration/ConfigWitness.java
Patch:
@@ -1,4 +1,4 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.configuration;
 
 import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.databind.SerializerProvider;
@@ -8,6 +8,8 @@
 import org.logstash.instrument.metrics.gauge.BooleanGauge;
 import org.logstash.instrument.metrics.gauge.NumberGauge;
 import org.logstash.instrument.metrics.gauge.TextGauge;
+import org.logstash.instrument.witness.MetricSerializer;
+import org.logstash.instrument.witness.SerializableWitness;
 
 import java.io.IOException;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/DeadLetterQueueWitness.java
Patch:
@@ -1,11 +1,13 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.databind.SerializerProvider;
 import com.fasterxml.jackson.databind.annotation.JsonSerialize;
 import com.fasterxml.jackson.databind.ser.std.StdSerializer;
 import org.logstash.instrument.metrics.Metric;
 import org.logstash.instrument.metrics.gauge.NumberGauge;
+import org.logstash.instrument.witness.MetricSerializer;
+import org.logstash.instrument.witness.SerializableWitness;
 
 import java.io.IOException;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/EventsWitness.java
Patch:
@@ -1,11 +1,13 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.databind.SerializerProvider;
 import com.fasterxml.jackson.databind.annotation.JsonSerialize;
 import com.fasterxml.jackson.databind.ser.std.StdSerializer;
 import org.logstash.instrument.metrics.Metric;
 import org.logstash.instrument.metrics.counter.LongCounter;
+import org.logstash.instrument.witness.MetricSerializer;
+import org.logstash.instrument.witness.SerializableWitness;
 
 import java.io.IOException;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/PipelineWitness.java
Patch:
@@ -1,9 +1,11 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.databind.SerializerProvider;
 import com.fasterxml.jackson.databind.annotation.JsonSerialize;
 import com.fasterxml.jackson.databind.ser.std.StdSerializer;
+import org.logstash.instrument.witness.configuration.ConfigWitness;
+import org.logstash.instrument.witness.SerializableWitness;
 
 import java.io.IOException;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/PipelinesWitness.java
Patch:
@@ -1,9 +1,10 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.databind.SerializerProvider;
 import com.fasterxml.jackson.databind.annotation.JsonSerialize;
 import com.fasterxml.jackson.databind.ser.std.StdSerializer;
+import org.logstash.instrument.witness.SerializableWitness;
 
 import java.io.IOException;
 import java.util.Map;

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/PluginWitness.java
Patch:
@@ -1,4 +1,4 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.databind.SerializerProvider;
@@ -11,10 +11,11 @@
 import org.logstash.instrument.metrics.gauge.GaugeMetric;
 import org.logstash.instrument.metrics.gauge.LazyDelegatingGauge;
 import org.logstash.instrument.metrics.gauge.TextGauge;
+import org.logstash.instrument.witness.MetricSerializer;
+import org.logstash.instrument.witness.SerializableWitness;
 
 import java.io.IOException;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/PluginsWitness.java
Patch:
@@ -1,12 +1,12 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.databind.SerializerProvider;
 import com.fasterxml.jackson.databind.annotation.JsonSerialize;
 import com.fasterxml.jackson.databind.ser.std.StdSerializer;
+import org.logstash.instrument.witness.SerializableWitness;
 
 import java.io.IOException;
-import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/QueueWitness.java
Patch:
@@ -1,4 +1,4 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.databind.SerializerProvider;
@@ -7,6 +7,8 @@
 import org.logstash.instrument.metrics.Metric;
 import org.logstash.instrument.metrics.gauge.NumberGauge;
 import org.logstash.instrument.metrics.gauge.TextGauge;
+import org.logstash.instrument.witness.MetricSerializer;
+import org.logstash.instrument.witness.SerializableWitness;
 
 import java.io.IOException;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/pipeline/ReloadWitness.java
Patch:
@@ -1,4 +1,4 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.databind.SerializerProvider;
@@ -9,6 +9,8 @@
 import org.logstash.instrument.metrics.Metric;
 import org.logstash.instrument.metrics.counter.LongCounter;
 import org.logstash.instrument.metrics.gauge.RubyTimeStampGauge;
+import org.logstash.instrument.witness.MetricSerializer;
+import org.logstash.instrument.witness.SerializableWitness;
 
 import java.io.IOException;
 

File: logstash-core/src/test/java/org/logstash/instrument/witness/configuration/ConfigWitnessTest.java
Patch:
@@ -1,8 +1,9 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.configuration;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
+import org.logstash.instrument.witness.configuration.ConfigWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/DeadLetterQueueWitnessTest.java
Patch:
@@ -1,9 +1,10 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
+import org.logstash.instrument.witness.pipeline.DeadLetterQueueWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/ErrorWitnessTest.java
Patch:
@@ -1,8 +1,9 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
+import org.logstash.instrument.witness.pipeline.ErrorWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/EventsWitnessTest.java
Patch:
@@ -1,8 +1,9 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
+import org.logstash.instrument.witness.pipeline.EventsWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/PipelineWitnessTest.java
Patch:
@@ -1,8 +1,9 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
+import org.logstash.instrument.witness.pipeline.PipelineWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.within;

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/PipelinesWitnessTest.java
Patch:
@@ -1,8 +1,9 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
+import org.logstash.instrument.witness.pipeline.PipelinesWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/PluginWitnessTest.java
Patch:
@@ -1,4 +1,4 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 
 import com.fasterxml.jackson.databind.ObjectMapper;
@@ -7,6 +7,7 @@
 import org.junit.Test;
 import org.logstash.RubyUtil;
 import org.logstash.instrument.metrics.MetricType;
+import org.logstash.instrument.witness.pipeline.PluginWitness;
 
 import java.io.IOException;
 import java.math.BigDecimal;

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/PluginsWitnessTest.java
Patch:
@@ -1,9 +1,10 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
+import org.logstash.instrument.witness.pipeline.PluginsWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/QueueWitnessTest.java
Patch:
@@ -1,8 +1,9 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
+import org.logstash.instrument.witness.pipeline.QueueWitness;
 
 import static org.assertj.core.api.Assertions.assertThat;
 

File: logstash-core/src/test/java/org/logstash/instrument/witness/pipeline/ReloadWitnessTest.java
Patch:
@@ -1,4 +1,4 @@
-package org.logstash.instrument.witness;
+package org.logstash.instrument.witness.pipeline;
 
 
 import com.fasterxml.jackson.databind.ObjectMapper;
@@ -7,6 +7,7 @@
 import org.junit.runner.RunWith;
 import org.logstash.Timestamp;
 import org.logstash.ext.JrubyTimestampExtLibrary;
+import org.logstash.instrument.witness.pipeline.ReloadWitness;
 import org.mockito.Mock;
 import org.mockito.runners.MockitoJUnitRunner;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/PluginsWitness.java
Patch:
@@ -27,7 +27,6 @@ public class PluginsWitness implements SerializableWitness {
      * Constructor.
      */
     public PluginsWitness() {
-
         this.inputs = new ConcurrentHashMap<>();
         this.outputs = new ConcurrentHashMap<>();
         this.filters = new ConcurrentHashMap<>();

File: logstash-core/src/test/java/org/logstash/instrument/metrics/MetricTypeTest.java
Patch:
@@ -24,8 +24,7 @@ public void ensurePassivity(){
         nameMap.put(MetricType.COUNTER_LONG, "counter/long");
         nameMap.put(MetricType.GAUGE_TEXT, "gauge/text");
         nameMap.put(MetricType.GAUGE_BOOLEAN, "gauge/boolean");
-        nameMap.put(MetricType.GAUGE_LONG, "gauge/long");
-        nameMap.put(MetricType.GAUGE_DOUBLE, "gauge/double");
+        nameMap.put(MetricType.GAUGE_NUMBER, "gauge/number");
         nameMap.put(MetricType.GAUGE_UNKNOWN, "gauge/unknown");
         nameMap.put(MetricType.GAUGE_RUBYHASH, "gauge/rubyhash");
         nameMap.put(MetricType.GAUGE_RUBYTIMESTAMP, "gauge/rubytimestamp");

File: logstash-core/src/test/java/org/logstash/instrument/metrics/counter/LongCounterTest.java
Patch:
@@ -8,7 +8,6 @@
 
 import static org.assertj.core.api.Assertions.assertThat;
 
-
 /**
  * Unit tests for {@link LongCounter}
  */

File: logstash-core/src/test/java/org/logstash/instrument/witness/DeadLetterQueueWitnessTest.java
Patch:
@@ -23,7 +23,7 @@ public void setup() {
     public void queueSizeInBytes() {
         assertThat(witness.snitch().queueSizeInBytes()).isNull();
         witness.queueSizeInBytes(99);
-        assertThat(witness.snitch().queueSizeInBytes()).isEqualTo(99);
+        assertThat(witness.snitch().queueSizeInBytes()).isEqualTo(99l);
     }
 
     @Test

File: logstash-core/src/test/java/org/logstash/instrument/witness/ErrorWitnessTest.java
Patch:
@@ -3,7 +3,6 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
-import org.logstash.instrument.metrics.gauge.LongGauge;
 
 import static org.assertj.core.api.Assertions.assertThat;
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/ErrorWitness.java
Patch:
@@ -85,7 +85,7 @@ public void genJson(JsonGenerator gen, SerializerProvider provider) throws IOExc
     /**
      * The Jackson serializer.
      */
-    public static class Serializer extends StdSerializer<ErrorWitness> {
+    static class Serializer extends StdSerializer<ErrorWitness> {
 
         /**
          * Default constructor - required for Jackson
@@ -122,10 +122,10 @@ void innerSerialize(ErrorWitness witness, JsonGenerator gen, SerializerProvider
     /**
      * The snitch for the errors. Used to retrieve discrete metric values.
      */
-    public static class Snitch {
+    public class Snitch {
         private final ErrorWitness witness;
 
-        Snitch(ErrorWitness witness) {
+        private Snitch(ErrorWitness witness) {
             this.witness = witness;
         }
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/EventsWitness.java
Patch:
@@ -131,7 +131,7 @@ public void genJson(final JsonGenerator gen, SerializerProvider provider) throws
     /**
      * The Jackson serializer.
      */
-    public static class Serializer extends StdSerializer<EventsWitness> {
+    static class Serializer extends StdSerializer<EventsWitness> {
 
         /**
          * Default constructor - required for Jackson
@@ -171,11 +171,11 @@ void innerSerialize(EventsWitness witness, JsonGenerator gen, SerializerProvider
     /**
      * The snitch for the {@link EventsWitness}. Allows to read discrete metrics values.
      */
-    public static class Snitch {
+    public class Snitch {
 
         private final EventsWitness witness;
 
-        Snitch(EventsWitness witness) {
+        private Snitch(EventsWitness witness) {
             this.witness = witness;
         }
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/PipelinesWitness.java
Patch:
@@ -45,7 +45,7 @@ public void genJson(JsonGenerator gen, SerializerProvider provider) throws IOExc
     /**
      * The Jackson serializer.
      */
-    public static class Serializer extends StdSerializer<PipelinesWitness> {
+    static class Serializer extends StdSerializer<PipelinesWitness> {
 
         /**
          * Default constructor - required for Jackson

File: logstash-core/src/main/java/org/logstash/instrument/witness/PluginWitness.java
Patch:
@@ -70,7 +70,7 @@ public void genJson(JsonGenerator gen, SerializerProvider provider) throws IOExc
     /**
      * The Jackson JSON serializer.
      */
-    public static class Serializer extends StdSerializer<PluginWitness> {
+    static class Serializer extends StdSerializer<PluginWitness> {
 
         /**
          * Default constructor - required for Jackson
@@ -106,11 +106,11 @@ void innerSerialize(PluginWitness witness, JsonGenerator gen, SerializerProvider
     /**
      * Snitch for a plugin. Provides discrete metric values.
      */
-    public static class Snitch {
+    public class Snitch {
 
         private final PluginWitness witness;
 
-        Snitch(PluginWitness witness) {
+        private Snitch(PluginWitness witness) {
             this.witness = witness;
         }
 

File: logstash-core/src/main/java/org/logstash/instrument/witness/PluginsWitness.java
Patch:
@@ -103,7 +103,7 @@ public void genJson(JsonGenerator gen, SerializerProvider provider) throws IOExc
     /**
      * The Jackson serializer.
      */
-    public static class Serializer extends StdSerializer<PluginsWitness> {
+    static class Serializer extends StdSerializer<PluginsWitness> {
 
         /**
          * Default constructor - required for Jackson

File: logstash-core/src/main/java/org/logstash/instrument/witness/ReloadWitness.java
Patch:
@@ -118,7 +118,7 @@ public void genJson(JsonGenerator gen, SerializerProvider provider) throws IOExc
     /**
      * The Jackson serializer.
      */
-    public static class Serializer extends StdSerializer<ReloadWitness> {
+    static class Serializer extends StdSerializer<ReloadWitness> {
 
         /**
          * Default constructor - required for Jackson

File: logstash-core/src/test/java/org/logstash/instrument/witness/ErrorWitnessTest.java
Patch:
@@ -3,6 +3,7 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.Before;
 import org.junit.Test;
+import org.logstash.instrument.metrics.gauge.LongGauge;
 
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -47,14 +48,14 @@ public void testAsJson() throws Exception {
     @Test
     public void testSerializeEmpty() throws Exception {
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"last_error\":{}}");
+        assertThat(json).isEqualTo("{\"last_error\":{\"message\":null,\"backtrace\":null}}");
     }
 
     @Test
     public void testSerializeMessage() throws Exception {
         witness.message("whoops");
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"last_error\":{\"message\":\"whoops\"}}");
+        assertThat(json).isEqualTo("{\"last_error\":{\"message\":\"whoops\",\"backtrace\":null}}");
     }
 
     @Test

File: logstash-core/src/test/java/org/logstash/instrument/witness/PluginWitnessTest.java
Patch:
@@ -40,7 +40,7 @@ public void testAsJson() throws Exception {
     @Test
     public void testSerializationEmpty() throws Exception {
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"id\":\"123\",\"events\":{\"duration_in_millis\":0,\"in\":0,\"out\":0,\"filtered\":0,\"queue_push_duration_in_millis\":0}}");
+        assertThat(json).isEqualTo("{\"id\":\"123\",\"events\":{\"duration_in_millis\":0,\"in\":0,\"out\":0,\"filtered\":0,\"queue_push_duration_in_millis\":0},\"name\":null}");
     }
 
     @Test
@@ -54,6 +54,6 @@ public void testSerializationName() throws Exception {
     public void testSerializationEvents() throws Exception {
         witness.events().in();
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"id\":\"123\",\"events\":{\"duration_in_millis\":0,\"in\":1,\"out\":0,\"filtered\":0,\"queue_push_duration_in_millis\":0}}");
+        assertThat(json).isEqualTo("{\"id\":\"123\",\"events\":{\"duration_in_millis\":0,\"in\":1,\"out\":0,\"filtered\":0,\"queue_push_duration_in_millis\":0},\"name\":null}");
     }
 }
\ No newline at end of file

File: logstash-core/src/test/java/org/logstash/instrument/witness/PluginsWitnessTest.java
Patch:
@@ -55,7 +55,7 @@ public void testSerializeInput() throws Exception{
         witness.inputs("foo");
         String json = witness.asJson();
         assertThat(json).isEqualTo("{\"plugins\":{\"inputs\":[{\"id\":\"foo\",\"events\":{\"duration_in_millis\":0,\"in\":0,\"out\":0,\"filtered\":0," +
-                "\"queue_push_duration_in_millis\":0}}],\"filters\":[],\"outputs\":[]}}");
+                "\"queue_push_duration_in_millis\":0},\"name\":null}],\"filters\":[],\"outputs\":[]}}");
         witness.forgetAll();
         json = witness.asJson();
         assertThat(json).isEqualTo("{\"plugins\":{\"inputs\":[],\"filters\":[],\"outputs\":[]}}");
@@ -66,7 +66,7 @@ public void testSerializeFilters() throws Exception{
         witness.filters("foo");
         String json = witness.asJson();
         assertThat(json).isEqualTo("{\"plugins\":{\"inputs\":[],\"filters\":[{\"id\":\"foo\",\"events\":{\"duration_in_millis\":0,\"in\":0,\"out\":0,\"filtered\":0," +
-                "\"queue_push_duration_in_millis\":0}}],\"outputs\":[]}}");
+                "\"queue_push_duration_in_millis\":0},\"name\":null}],\"outputs\":[]}}");
         witness.forgetAll();
         json = witness.asJson();
         assertThat(json).isEqualTo("{\"plugins\":{\"inputs\":[],\"filters\":[],\"outputs\":[]}}");
@@ -77,7 +77,7 @@ public void testSerializeOutputs() throws Exception{
         witness.outputs("foo");
         String json = witness.asJson();
         assertThat(json).isEqualTo("{\"plugins\":{\"inputs\":[],\"filters\":[],\"outputs\":[{\"id\":\"foo\",\"events\":{\"duration_in_millis\":0,\"in\":0,\"out\":0," +
-                "\"filtered\":0,\"queue_push_duration_in_millis\":0}}]}}");
+                "\"filtered\":0,\"queue_push_duration_in_millis\":0},\"name\":null}]}}");
         witness.forgetAll();
         json = witness.asJson();
         assertThat(json).isEqualTo("{\"plugins\":{\"inputs\":[],\"filters\":[],\"outputs\":[]}}");

File: logstash-core/src/test/java/org/logstash/instrument/witness/WitnessTest.java
Patch:
@@ -51,8 +51,9 @@ public void testSerializeEmpty() throws Exception {
         witness = new Witness();
         String json = witness.asJson();
         //empty pipelines
-        assertThat(json).contains("{\"events\":{\"duration_in_millis\":0,\"in\":0,\"out\":0,\"filtered\":0,\"queue_push_duration_in_millis\":0},\"reloads\":{\"last_error\":{}," +
-                "\"successes\":0,\"last_success_timestamp\":null,\"last_failure_timestamp\":null,\"failures\":0},\"pipelines\":{}}");
+        assertThat(json).isEqualTo("{\"events\":{\"duration_in_millis\":0,\"in\":0,\"out\":0,\"filtered\":0,\"queue_push_duration_in_millis\":0}," +
+                "\"reloads\":{\"last_error\":{\"message\":null,\"backtrace\":null},\"successes\":0,\"last_success_timestamp\":null,\"last_failure_timestamp\":null," +
+                "\"failures\":0},\"pipelines\":{}}");
     }
 
     @Test

File: logstash-core/src/main/java/org/logstash/instrument/metrics/AbstractMetric.java
Patch:
@@ -3,9 +3,6 @@
 
 import com.fasterxml.jackson.annotation.JsonValue;
 
-import java.util.Arrays;
-import java.util.List;
-
 /**
  * Abstract implementation of a {@link Metric}. All metrics should subclass this.
  *

File: logstash-core/src/main/java/org/logstash/instrument/witness/MetricSerializer.java
Patch:
@@ -36,7 +36,7 @@ class Get {
          */
         static MetricSerializer<Metric<Long>> longSerializer(JsonGenerator gen) {
             return m -> {
-                if (m != null && m.isDirty() && m.getValue() != null) {
+                if (m != null && m.getValue() != null) {
                     gen.writeNumberField(m.getName(), m.getValue());
                 }
             };
@@ -50,7 +50,7 @@ static MetricSerializer<Metric<Long>> longSerializer(JsonGenerator gen) {
          */
         static MetricSerializer<Metric<Boolean>> booleanSerializer(JsonGenerator gen) {
             return m -> {
-                if (m != null && m.isDirty() && m.getValue() != null) {
+                if (m != null && m.getValue() != null) {
                     gen.writeBooleanField(m.getName(), m.getValue());
                 }
             };
@@ -64,7 +64,7 @@ static MetricSerializer<Metric<Boolean>> booleanSerializer(JsonGenerator gen) {
          */
         static MetricSerializer<Metric<String>> stringSerializer(JsonGenerator gen) {
             return m -> {
-                if (m != null && m.isDirty() && m.getValue() != null) {
+                if (m != null && m.getValue() != null) {
                     gen.writeStringField(m.getName(), m.getValue());
                 }
             };

File: logstash-core/src/test/java/org/logstash/instrument/witness/ErrorWitnessTest.java
Patch:
@@ -47,7 +47,7 @@ public void testAsJson() throws Exception {
     @Test
     public void testSerializeEmpty() throws Exception {
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"last_error\":null}");
+        assertThat(json).isEqualTo("{\"last_error\":{}}");
     }
 
     @Test

File: logstash-core/src/test/java/org/logstash/instrument/witness/EventsWitnessTest.java
Patch:
@@ -83,16 +83,15 @@ public void testQueuePushDuration() {
     public void testAsJson() throws Exception {
         ObjectMapper mapper = new ObjectMapper();
         //empty
-        assertThat(mapper.writeValueAsString(witness)).isEqualTo(witness.asJson()).isEmpty();
+        assertThat(mapper.writeValueAsString(witness)).isEqualTo(witness.asJson());
         //dirty
         witness.in(1);
         assertThat(mapper.writeValueAsString(witness)).isEqualTo(witness.asJson()).contains("events");
     }
 
     @Test
     public void testSerializeEmpty() throws Exception {
-        //Due to legacy requirements if empty, the events should not serialize at all.
-        assertThat(witness.asJson()).isEmpty();
+        assertThat(witness.asJson()).isNotEmpty();
     }
 
     @Test

File: logstash-core/src/test/java/org/logstash/instrument/witness/PipelineWitnessTest.java
Patch:
@@ -73,8 +73,9 @@ public void testAsJson() throws Exception {
     @Test
     public void testSerializeEmpty() throws Exception {
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"default\":{\"plugins\":{\"inputs\":[],\"filters\":[],\"outputs\":[]},\"reloads\":{\"last_error\":null,\"successes\":0," +
-                "\"last_success_timestamp\":null,\"last_failure_timestamp\":null,\"failures\":0},\"queue\":{}}}");
+        assertThat(json).isEqualTo("{\"default\":{\"events\":{\"duration_in_millis\":0,\"in\":0,\"out\":0,\"filtered\":0,\"queue_push_duration_in_millis\":0}," +
+                "\"plugins\":{\"inputs\":[],\"filters\":[],\"outputs\":[]},\"reloads\":{\"last_error\":{},\"successes\":0,\"last_success_timestamp\":null," +
+                "\"last_failure_timestamp\":null,\"failures\":0},\"queue\":{}}}");
     }
 
     @Test

File: logstash-core/src/test/java/org/logstash/instrument/witness/PluginWitnessTest.java
Patch:
@@ -40,20 +40,20 @@ public void testAsJson() throws Exception {
     @Test
     public void testSerializationEmpty() throws Exception {
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"id\":\"123\"}");
+        assertThat(json).isEqualTo("{\"id\":\"123\",\"events\":{\"duration_in_millis\":0,\"in\":0,\"out\":0,\"filtered\":0,\"queue_push_duration_in_millis\":0}}");
     }
 
     @Test
     public void testSerializationName() throws Exception {
         witness.name("abc");
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"id\":\"123\",\"name\":\"abc\"}");
+        assertThat(json).isEqualTo("{\"id\":\"123\",\"events\":{\"duration_in_millis\":0,\"in\":0,\"out\":0,\"filtered\":0,\"queue_push_duration_in_millis\":0},\"name\":\"abc\"}");
     }
 
     @Test
     public void testSerializationEvents() throws Exception {
         witness.events().in();
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"id\":\"123\",\"events\":{\"in\":1}}");
+        assertThat(json).isEqualTo("{\"id\":\"123\",\"events\":{\"duration_in_millis\":0,\"in\":1,\"out\":0,\"filtered\":0,\"queue_push_duration_in_millis\":0}}");
     }
 }
\ No newline at end of file

File: logstash-core/src/test/java/org/logstash/instrument/witness/ReloadWitnessTest.java
Patch:
@@ -65,15 +65,15 @@ public void testAsJson() throws Exception {
     @Test
     public void testSerializeEmpty() throws Exception {
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"reloads\":{\"last_error\":null,\"successes\":0,\"last_success_timestamp\":null,\"last_failure_timestamp\":null,\"failures\":0}}");
+        assertThat(json).isEqualTo("{\"reloads\":{\"last_error\":{},\"successes\":0,\"last_success_timestamp\":null,\"last_failure_timestamp\":null,\"failures\":0}}");
     }
 
     @Test
     public void testSerializeSuccess() throws Exception {
         witness.success();
         witness.lastSuccessTimestamp(rubyTimestamp);
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"reloads\":{\"last_error\":null,\"successes\":1,\"last_success_timestamp\":\"" + timestamp.toIso8601() +
+        assertThat(json).isEqualTo("{\"reloads\":{\"last_error\":{},\"successes\":1,\"last_success_timestamp\":\"" + timestamp.toIso8601() +
                 "\",\"last_failure_timestamp\":null,\"failures\":0}}");
     }
 
@@ -82,7 +82,7 @@ public void testSerializeFailure() throws Exception {
         witness.failure();
         witness.lastFailureTimestamp(rubyTimestamp);
         String json = witness.asJson();
-        assertThat(json).isEqualTo("{\"reloads\":{\"last_error\":null,\"successes\":0,\"last_success_timestamp\":null,\"last_failure_timestamp\":\""
+        assertThat(json).isEqualTo("{\"reloads\":{\"last_error\":{},\"successes\":0,\"last_success_timestamp\":null,\"last_failure_timestamp\":\""
                 + timestamp.toIso8601() + "\",\"failures\":1}}");
     }
 

File: logstash-core/src/main/java/org/logstash/Rubyfier.java
Patch:
@@ -5,6 +5,7 @@
 import java.util.Map;
 import org.jruby.Ruby;
 import org.jruby.RubyArray;
+import org.jruby.RubyBoolean;
 import org.jruby.RubyFloat;
 import org.jruby.RubyHash;
 import org.jruby.RubyString;
@@ -29,13 +30,15 @@ private Rubyfier() {
 
     public static IRubyObject deep(Ruby runtime, final Object input) {
         if (input instanceof RubyString || input instanceof RubyFloat
+            || input instanceof RubyBoolean
             || input instanceof JrubyTimestampExtLibrary.RubyTimestamp) {
             return (IRubyObject) input;
         }
         if (input instanceof String) return RubyUtil.RUBY.newString((String) input);
         if (input instanceof Double || input instanceof Float) {
             return RubyUtil.RUBY.newFloat(((Number) input).doubleValue());
         }
+        if (input instanceof Boolean) return RubyUtil.RUBY.newBoolean((Boolean) input);
         if (input instanceof Timestamp) {
             return JrubyTimestampExtLibrary.RubyTimestamp.newRubyTimestamp(
                 RubyUtil.RUBY, (Timestamp) input

File: logstash-core/src/main/java/org/logstash/ext/JrubyTimestampExtLibrary.java
Patch:
@@ -1,5 +1,6 @@
 package org.logstash.ext;
 
+import com.fasterxml.jackson.databind.annotation.JsonSerialize;
 import java.io.IOException;
 import org.jruby.Ruby;
 import org.jruby.RubyClass;
@@ -19,6 +20,7 @@
 import org.jruby.runtime.builtin.IRubyObject;
 import org.jruby.runtime.load.Library;
 import org.logstash.Timestamp;
+import org.logstash.json.RubyTimestampSerializer;
 
 public class JrubyTimestampExtLibrary implements Library {
 
@@ -40,6 +42,7 @@ public static RubyClass createTimestamp(Ruby runtime) {
     }
 
     @JRubyClass(name = "Timestamp")
+    @JsonSerialize(using = RubyTimestampSerializer.class)
     public static class RubyTimestamp extends RubyObject {
 
         private Timestamp timestamp;

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueReader.java
Patch:
@@ -65,9 +65,6 @@ public void seekToNextEvent(Timestamp timestamp) throws IOException {
             currentReader = new RecordIOReader(segment);
             byte[] event = currentReader.seekToNextEventPosition(timestamp, (b) -> {
                 try {
-                    if (b == null){
-                        return null;
-                    }
                     return DLQEntry.deserialize(b).getEntryTime();
                 } catch (IOException e) {
                     return null;

File: logstash-core/src/main/java/org/logstash/common/io/RecordIOReader.java
Patch:
@@ -263,7 +263,6 @@ private void restoreFrom(BufferState bufferState) throws IOException {
         this.channel.position(bufferState.channelPosition);
         this.channelPosition = channel.position();
         this.currentBlockSizeReadFromChannel = bufferState.currentBlockSizeReadFromChannel;
-
     }
 
     final static class BufferState {

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueReader.java
Patch:
@@ -65,6 +65,9 @@ public void seekToNextEvent(Timestamp timestamp) throws IOException {
             currentReader = new RecordIOReader(segment);
             byte[] event = currentReader.seekToNextEventPosition(timestamp, (b) -> {
                 try {
+                    if (b == null){
+                        return null;
+                    }
                     return DLQEntry.deserialize(b).getEntryTime();
                 } catch (IOException e) {
                     return null;

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -13,7 +13,6 @@
 import org.jruby.RubyString;
 import org.jruby.RubySymbol;
 import org.logstash.ackedqueue.Queueable;
-import org.logstash.bivalues.BiValues;
 import org.logstash.bivalues.NullBiValue;
 import org.logstash.ext.JrubyTimestampExtLibrary;
 
@@ -335,7 +334,7 @@ public void tag(final String tag) {
      */
     private void initTag(final String tag) {
         final ConvertedList list = new ConvertedList(1);
-        list.add(BiValues.RUBY.newString(tag));
+        list.add(RubyUtil.RUBY.newString(tag));
         Accessors.set(data, TAGS_FIELD, list);
     }
 

File: logstash-core/src/main/java/org/logstash/Rubyfier.java
Patch:
@@ -32,13 +32,13 @@ public static IRubyObject deep(Ruby runtime, final Object input) {
             || input instanceof JrubyTimestampExtLibrary.RubyTimestamp) {
             return (IRubyObject) input;
         }
-        if (input instanceof String) return BiValues.RUBY.newString((String) input);
+        if (input instanceof String) return RubyUtil.RUBY.newString((String) input);
         if (input instanceof Double || input instanceof Float) {
-            return BiValues.RUBY.newFloat(((Number) input).doubleValue());
+            return RubyUtil.RUBY.newFloat(((Number) input).doubleValue());
         }
         if (input instanceof Timestamp) {
             return JrubyTimestampExtLibrary.RubyTimestamp.newRubyTimestamp(
-                BiValues.RUBY, (Timestamp) input
+                RubyUtil.RUBY, (Timestamp) input
             );
         }
         if (input instanceof BiValue) return ((BiValue) input).rubyValue(runtime);

File: logstash-core/src/main/java/org/logstash/bivalues/BiValues.java
Patch:
@@ -3,7 +3,6 @@
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.util.HashMap;
-import org.jruby.Ruby;
 import org.jruby.RubyBignum;
 import org.jruby.RubyBoolean;
 import org.jruby.RubyInteger;
@@ -50,8 +49,6 @@ private static HashMap<String, String> initCache() {
         return hm;
     }
 
-    public static final Ruby RUBY = Ruby.getGlobalRuntime();
-
     public static final NullBiValue NULL_BI_VALUE = NullBiValue.newNullBiValue();
 
     private final BiValueType biValueType;

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -14,7 +14,6 @@
 import org.logstash.ackedqueue.Queueable;
 import org.logstash.bivalues.BiValues;
 import org.logstash.bivalues.NullBiValue;
-import org.logstash.bivalues.TimestampBiValue;
 import org.logstash.ext.JrubyTimestampExtLibrary;
 
 import static org.logstash.ObjectMappers.CBOR_MAPPER;
@@ -314,8 +313,6 @@ private static Timestamp parseTimestamp(final Object o) {
                 return ((JrubyTimestampExtLibrary.RubyTimestamp) o).getTimestamp();
             } else if (o instanceof Timestamp) {
                 return (Timestamp) o;
-            } else if (o instanceof TimestampBiValue) {
-                return ((TimestampBiValue) o).javaValue();
             } else if (o instanceof DateTime) {
                 return new Timestamp((DateTime) o);
             } else if (o instanceof Date) {

File: logstash-core/src/test/java/org/logstash/ValuefierTest.java
Patch:
@@ -19,7 +19,7 @@
 import org.junit.Test;
 import org.junit.rules.ExpectedException;
 import org.logstash.bivalues.BiValue;
-import org.logstash.bivalues.TimestampBiValue;
+import org.logstash.ext.JrubyTimestampExtLibrary;
 
 import static junit.framework.TestCase.assertEquals;
 
@@ -63,15 +63,15 @@ public void testConcreteJavaProxy() {
     public void testRubyTime() {
         RubyTime ro = RubyTime.newTime(ruby, DateTime.now());
         Object result = Valuefier.convert(ro);
-        assertEquals(TimestampBiValue.class, result.getClass());
+        assertEquals(JrubyTimestampExtLibrary.RubyTimestamp.class, result.getClass());
     }
 
     @Test
     public void testJodaDateTIme() {
         DateTime jo = DateTime.now();
         Object result = Valuefier.convert(jo);
 
-        assertEquals(TimestampBiValue.class, result.getClass());
+        assertEquals(JrubyTimestampExtLibrary.RubyTimestamp.class, result.getClass());
     }
 
     @Rule

File: logstash-core/src/main/java/org/logstash/instrument/metrics/counter/LongCounter.java
Patch:
@@ -14,7 +14,7 @@ public class LongCounter extends AbstractMetric<Long> implements CounterMetric<L
 
     private static final IllegalArgumentException NEGATIVE_COUNT_EXCEPTION = new IllegalArgumentException("Counters can not be incremented by negative values");
     private LongAdder longAdder;
-    private volatile boolean dirty;
+    private boolean dirty;
 
     /**
      * Constructor

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/AbstractGaugeMetric.java
Patch:
@@ -8,7 +8,7 @@
  */
 public abstract class AbstractGaugeMetric<T> extends AbstractMetric<T> implements GaugeMetric<T,T>{
 
-    private volatile boolean dirty;
+    private boolean dirty;
 
     private volatile T value;
 

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
Patch:
@@ -243,7 +243,7 @@ public String getId() {
         // they have no source metadata. This might also be used in the future by alternate config languages which are
         // willing to take the hit.
         if (this.getSourceWithMetadata() != null) {
-            generatedId = this.getGraph().uniqueHash() + "|" + this.getSourceWithMetadata().uniqueHash();
+            generatedId = Util.digest(this.getGraph().uniqueHash() + "|" + this.getSourceWithMetadata().uniqueHash());
         } else {
             generatedId = this.uniqueHash();
         }

File: logstash-core/src/main/java/org/logstash/instrument/metrics/counter/CounterMetric.java
Patch:
@@ -16,7 +16,7 @@ public interface CounterMetric<T extends Number> extends Metric<T> {
 
     /**
      * Increments the counter by the value specified. <i>The caller should be careful to avoid incrementing by values so large as to overflow the underlying type.</i>
-     * @param by The value which to increment by.
+     * @param by The value which to increment by. Can not be negative.
      */
     void increment(T by) ;
 }

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/GaugeMetric.java
Patch:
@@ -16,4 +16,6 @@ public interface GaugeMetric<G,S> extends Metric<G> {
      * @param value The value to set
      */
     void set(S value);
+
+
 }

File: logstash-core/src/test/java/org/logstash/instrument/metrics/MetricTypeTest.java
Patch:
@@ -24,7 +24,8 @@ public void ensurePassivity(){
         nameMap.put(MetricType.COUNTER_LONG, "counter/long");
         nameMap.put(MetricType.GAUGE_TEXT, "gauge/text");
         nameMap.put(MetricType.GAUGE_BOOLEAN, "gauge/boolean");
-        nameMap.put(MetricType.GAUGE_NUMERIC, "gauge/numeric");
+        nameMap.put(MetricType.GAUGE_LONG, "gauge/long");
+        nameMap.put(MetricType.GAUGE_DOUBLE, "gauge/double");
         nameMap.put(MetricType.GAUGE_UNKNOWN, "gauge/unknown");
         nameMap.put(MetricType.GAUGE_RUBYHASH, "gauge/rubyhash");
         nameMap.put(MetricType.GAUGE_RUBYTIMESTAMP, "gauge/rubytimestamp");

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -14,7 +14,6 @@
 import org.logstash.ackedqueue.Queueable;
 import org.logstash.bivalues.BiValues;
 import org.logstash.bivalues.NullBiValue;
-import org.logstash.bivalues.TimeBiValue;
 import org.logstash.bivalues.TimestampBiValue;
 import org.logstash.ext.JrubyTimestampExtLibrary;
 
@@ -311,8 +310,6 @@ private static Timestamp parseTimestamp(final Object o) {
                 return new Timestamp((String) o);
             } else if (o instanceof RubyString) {
                 return new Timestamp(o.toString());
-            } else if (o instanceof TimeBiValue) {
-                return new Timestamp(((TimeBiValue) o).javaValue());
             } else if (o instanceof JrubyTimestampExtLibrary.RubyTimestamp) {
                 return ((JrubyTimestampExtLibrary.RubyTimestamp) o).getTimestamp();
             } else if (o instanceof Timestamp) {

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -314,11 +314,11 @@ private static Timestamp parseTimestamp(final Object o) {
             } else if (o instanceof TimeBiValue) {
                 return new Timestamp(((TimeBiValue) o).javaValue());
             } else if (o instanceof JrubyTimestampExtLibrary.RubyTimestamp) {
-                return new Timestamp(((JrubyTimestampExtLibrary.RubyTimestamp) o).getTimestamp());
+                return ((JrubyTimestampExtLibrary.RubyTimestamp) o).getTimestamp();
             } else if (o instanceof Timestamp) {
-                return new Timestamp((Timestamp) o);
+                return (Timestamp) o;
             } else if (o instanceof TimestampBiValue) {
-                return new Timestamp(((TimestampBiValue) o).javaValue());
+                return ((TimestampBiValue) o).javaValue();
             } else if (o instanceof DateTime) {
                 return new Timestamp((DateTime) o);
             } else if (o instanceof Date) {

File: logstash-core/src/test/java/org/logstash/common/io/DeadLetterQueueReaderTest.java
Patch:
@@ -307,7 +307,7 @@ public void testWriteStopBigWriteSeekByTimestamp() throws Exception {
 
     private void seekReadAndVerify(final Timestamp seekTarget, final String expectedValue) throws Exception {
         try(DeadLetterQueueReader readManager = new DeadLetterQueueReader(dir)) {
-            readManager.seekToNextEvent(new Timestamp(seekTarget));
+            readManager.seekToNextEvent(seekTarget);
             DLQEntry readEntry = readManager.pollEntry(100);
             assertThat(readEntry.getReason(), equalTo(expectedValue));
             assertThat(readEntry.getEntryTime().toIso8601(), equalTo(seekTarget.toIso8601()));

File: logstash-core/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -87,7 +87,9 @@ public Event getEvent() {
         public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args) {
             final IRubyObject data = args.length > 0 ? args[0] : null;
             if (data instanceof RubyHash) {
-                this.event = new Event(ConvertedMap.newFromRubyHash((RubyHash) data));
+                this.event = new Event(
+                    ConvertedMap.newFromRubyHash(context, (RubyHash) data)
+                );
             } else {
                 initializeFallback(context, data);
             }

File: logstash-core/src/main/java/org/logstash/FieldReference.java
Patch:
@@ -67,10 +67,10 @@ public static FieldReference parse(final CharSequence reference) {
         final List<String> path = new ArrayList<>(parts.length);
         for (final String part : parts) {
             if (!part.isEmpty()) {
-                path.add(part);
+                path.add(part.intern());
             }
         }
-        final String key = path.remove(path.size() - 1);
+        final String key = path.remove(path.size() - 1).intern();
         final boolean empty = path.isEmpty();
         if (empty && key.equals(Event.METADATA)) {
             return METADATA_PARENT_REFERENCE;

File: logstash-core/src/main/java/org/logstash/common/io/RecordIOReader.java
Patch:
@@ -146,7 +146,7 @@ public boolean isEndOfStream() {
      */
      int seekToStartOfEventInBlock() {
          // Already consumed all the bytes in this block.
-        if (currentBlock.position() == currentBlockSizeReadFromChannel){
+        if (currentBlock.position() >= currentBlockSizeReadFromChannel){
              return -1;
          }
          while (true) {

File: logstash-core/src/main/java/org/logstash/bivalues/BigDecimalBiValue.java
Patch:
@@ -6,7 +6,7 @@
 import java.io.ObjectStreamException;
 import java.math.BigDecimal;
 
-public class BigDecimalBiValue extends BiValueCommon<RubyBigDecimal, BigDecimal> implements BiValue<RubyBigDecimal, BigDecimal> {
+public class BigDecimalBiValue extends BiValue<RubyBigDecimal, BigDecimal> {
 
     public BigDecimalBiValue(RubyBigDecimal rubyValue) {
         this.rubyValue = rubyValue;

File: logstash-core/src/main/java/org/logstash/bivalues/BigIntegerBiValue.java
Patch:
@@ -6,7 +6,7 @@
 import java.io.ObjectStreamException;
 import java.math.BigInteger;
 
-public class BigIntegerBiValue extends BiValueCommon<RubyBignum, BigInteger> implements BiValue<RubyBignum, BigInteger> {
+public class BigIntegerBiValue extends BiValue<RubyBignum, BigInteger> {
 
     public BigIntegerBiValue(RubyBignum rubyValue) {
         this.rubyValue = rubyValue;

File: logstash-core/src/main/java/org/logstash/bivalues/BooleanBiValue.java
Patch:
@@ -6,7 +6,7 @@
 import java.io.ObjectStreamException;
 
 
-public class BooleanBiValue extends BiValueCommon<RubyBoolean, Boolean> implements BiValue<RubyBoolean, Boolean> {
+public class BooleanBiValue extends BiValue<RubyBoolean, Boolean> {
 
     public BooleanBiValue(RubyBoolean rubyValue) {
         this.rubyValue = rubyValue;

File: logstash-core/src/main/java/org/logstash/bivalues/DoubleBiValue.java
Patch:
@@ -6,7 +6,7 @@
 import java.io.ObjectStreamException;
 
 
-public class DoubleBiValue extends BiValueCommon<RubyFloat, Double> implements BiValue<RubyFloat, Double> {
+public class DoubleBiValue extends BiValue<RubyFloat, Double> {
 
     public DoubleBiValue(RubyFloat rubyValue) {
         this.rubyValue = rubyValue;

File: logstash-core/src/main/java/org/logstash/bivalues/FloatBiValue.java
Patch:
@@ -6,7 +6,7 @@
 import java.io.ObjectStreamException;
 
 
-public class FloatBiValue extends BiValueCommon<RubyFloat, Float> implements BiValue<RubyFloat, Float> {
+public class FloatBiValue extends BiValue<RubyFloat, Float> {
 
     public FloatBiValue(RubyFloat rubyValue) {
         this.rubyValue = rubyValue;

File: logstash-core/src/main/java/org/logstash/bivalues/IntegerBiValue.java
Patch:
@@ -6,7 +6,7 @@
 
 import java.io.ObjectStreamException;
 
-public class IntegerBiValue extends BiValueCommon<RubyInteger, Integer> implements BiValue<RubyInteger, Integer> {
+public class IntegerBiValue extends BiValue<RubyInteger, Integer> {
 
     public IntegerBiValue(RubyInteger rubyValue) {
         this.rubyValue = rubyValue;

File: logstash-core/src/main/java/org/logstash/bivalues/JavaProxyBiValue.java
Patch:
@@ -6,7 +6,7 @@
 
 import java.io.ObjectStreamException;
 
-public class JavaProxyBiValue extends BiValueCommon<JavaProxy, Object> implements BiValue<JavaProxy, Object> {
+public class JavaProxyBiValue extends BiValue<JavaProxy, Object> {
 
     public JavaProxyBiValue(JavaProxy rubyValue) {
         this.rubyValue = rubyValue;

File: logstash-core/src/main/java/org/logstash/bivalues/LongBiValue.java
Patch:
@@ -6,7 +6,7 @@
 
 import java.io.ObjectStreamException;
 
-public class LongBiValue extends BiValueCommon<RubyInteger, Long> implements BiValue<RubyInteger, Long> {
+public class LongBiValue extends BiValue<RubyInteger, Long> {
 
     public LongBiValue(RubyInteger rubyValue) {
         this.rubyValue = rubyValue;

File: logstash-core/src/main/java/org/logstash/bivalues/NullBiValue.java
Patch:
@@ -5,8 +5,7 @@
 import org.jruby.Ruby;
 import org.jruby.RubyNil;
 
-public final class NullBiValue extends BiValueCommon<RubyNil, Object>
-    implements BiValue<RubyNil, Object> {
+public final class NullBiValue extends BiValue<RubyNil, Object> {
 
     private static final NullBiValue INSTANCE =
         new NullBiValue((RubyNil) Ruby.getGlobalRuntime().getNil());

File: logstash-core/src/main/java/org/logstash/bivalues/StringBiValue.java
Patch:
@@ -5,8 +5,7 @@
 import org.jruby.Ruby;
 import org.jruby.RubyString;
 
-public final class StringBiValue extends BiValueCommon<RubyString, String>
-    implements BiValue<RubyString, String> {
+public final class StringBiValue extends BiValue<RubyString, String> {
 
     public StringBiValue(RubyString rubyValue) {
         this.rubyValue = rubyValue;
@@ -30,7 +29,7 @@ public String javaValue() {
     public boolean equals(Object o) {
         if (this == o) return true;
         if (o instanceof BiValue) {
-            final BiValueCommon<?, ?> other = (BiValueCommon<?, ?>) o;
+            final BiValue<?, ?> other = (BiValue<?, ?>) o;
             return other.hasRubyValue() && other.rubyValueUnconverted().equals(rubyValue) ||
                 (other.hasJavaValue() && other.javaValue().equals(this.javaValue()));
         } else {

File: logstash-core/src/main/java/org/logstash/bivalues/SymbolBiValue.java
Patch:
@@ -5,7 +5,7 @@
 
 import java.io.ObjectStreamException;
 
-public class SymbolBiValue extends BiValueCommon<RubySymbol, String> implements BiValue<RubySymbol, String> {
+public class SymbolBiValue extends BiValue<RubySymbol, String> {
 
     public SymbolBiValue(RubySymbol rubyValue) {
         this.rubyValue = rubyValue;

File: logstash-core/src/main/java/org/logstash/bivalues/TimeBiValue.java
Patch:
@@ -7,7 +7,7 @@
 import java.io.ObjectStreamException;
 
 
-public class TimeBiValue extends BiValueCommon<RubyTime, DateTime> implements BiValue<RubyTime, DateTime> {
+public class TimeBiValue extends BiValue<RubyTime, DateTime> {
 
     public TimeBiValue(RubyTime rubyValue) {
         this.rubyValue = rubyValue;

File: logstash-core/src/main/java/org/logstash/bivalues/TimestampBiValue.java
Patch:
@@ -6,7 +6,7 @@
 
 import java.io.ObjectStreamException;
 
-public class TimestampBiValue extends BiValueCommon<RubyTimestamp, Timestamp> implements BiValue<RubyTimestamp, Timestamp> {
+public class TimestampBiValue extends BiValue<RubyTimestamp, Timestamp> {
 
     public TimestampBiValue(RubyTimestamp rubyValue) {
         this.rubyValue = rubyValue;

File: tools/benchmark-cli/src/main/java/org/logstash/benchmark/cli/DataStore.java
Patch:
@@ -59,7 +59,7 @@ final class ElasticSearch implements DataStore {
         ElasticSearch(final String host, final int port, final String schema,
             final Map<String, Object> meta) {
             client = RestClient.builder(new HttpHost(host, port, schema)).build();
-            this.meta = meta;
+            this.meta = Collections.unmodifiableMap(meta);
         }
 
         @Override

File: tools/benchmark-cli/src/main/java/org/logstash/benchmark/cli/JRubyInstallation.java
Patch:
@@ -41,8 +41,7 @@ public static JRubyInstallation bootstrapJruby(final Path pwd)
             String.format(
                 "http://jruby.org.s3.amazonaws.com/downloads/%s/jruby-bin-%s.tar.gz",
                 JRUBY_DEFAULT_VERSION, JRUBY_DEFAULT_VERSION
-            ),
-            false
+            )
         );
         return new JRubyInstallation(
             pwd.resolve("jruby").resolve(String.format("jruby-%s", JRUBY_DEFAULT_VERSION))

File: tools/benchmark-cli/src/main/java/org/logstash/benchmark/cli/LsMetricsMonitor.java
Patch:
@@ -106,10 +106,11 @@ private long[] getCounts() {
         }
     }
 
+    @SuppressWarnings("unchecked")
     private static long readNestedLong(final Map<String, Object> map, final String ... path) {
         Map<String, Object> nested = map;
         for (int i = 0; i < path.length - 1; ++i) {
-            nested = (Map<String, Object>) (nested).get(path[i]);
+            nested = (Map<String, Object>) nested.get(path[i]);
         }
         return ((Number) nested.get(path[path.length - 1])).longValue();
     }

File: tools/benchmark-cli/src/main/java/org/logstash/benchmark/cli/Main.java
Patch:
@@ -147,7 +147,7 @@ public static void execute(final UserOutput output, final Properties settings,
                 LsBenchLsSetup.setupLS(cwd.toAbsolutePath().toString(), version, type, output);
         }
         try (final DataStore store = setupDataStore(esout, test, version, type)) {
-            final Case testcase = setupTestCase(store, logstash, cwd, settings, test);
+            final Case testcase = setupTestCase(store, logstash, cwd, settings, test, output);
             output.printStartTime();
             final long start = System.currentTimeMillis();
             final AbstractMap<LsMetricStats, ListStatistics> stats = testcase.run();
@@ -163,13 +163,13 @@ public static void execute(final UserOutput output, final Properties settings,
     }
 
     private static Case setupTestCase(final DataStore store, final LogstashInstallation logstash,
-        final Path cwd, final Properties settings, final String test)
+        final Path cwd, final Properties settings, final String test, final UserOutput output)
         throws IOException, NoSuchAlgorithmException {
         final Case testcase;
         if (GeneratorToStdout.IDENTIFIER.equalsIgnoreCase(test)) {
             testcase = new GeneratorToStdout(store, logstash, settings);
         } else if (ApacheLogsComplex.IDENTIFIER.equalsIgnoreCase(test)) {
-            testcase = new ApacheLogsComplex(store, logstash, cwd, settings);
+            testcase = new ApacheLogsComplex(store, logstash, cwd, settings, output);
         } else {
             throw new IllegalArgumentException(String.format("Unknown test case %s", test));
         }

File: tools/benchmark-cli/src/main/java/org/logstash/benchmark/cli/util/LsBenchDownloader.java
Patch:
@@ -15,9 +15,9 @@
 
 public final class LsBenchDownloader {
     
-    public static void downloadDecompress(final File file, final String url, final boolean force)
+    public static void downloadDecompress(final File file, final String url)
         throws IOException, NoSuchAlgorithmException {
-        if (force && file.exists()) {
+        if (file.exists()) {
             LsBenchFileUtil.ensureDeleted(file);
         }
         if (!file.exists()) {

File: tools/benchmark-cli/src/main/java/org/logstash/benchmark/cli/Main.java
Patch:
@@ -143,7 +143,8 @@ public static void execute(final UserOutput output, final Properties settings,
                 cwd.toAbsolutePath().toString(), version, JRubyInstallation.bootstrapJruby(cwd)
             );
         } else {
-            logstash = LsBenchLsSetup.setupLS(cwd.toAbsolutePath().toString(), version, type);
+            logstash =
+                LsBenchLsSetup.setupLS(cwd.toAbsolutePath().toString(), version, type, output);
         }
         try (final DataStore store = setupDataStore(esout, test, version, type)) {
             final Case testcase = setupTestCase(store, logstash, cwd, settings, test);

File: tools/benchmark-cli/src/main/java/org/logstash/benchmark/cli/util/LsBenchLsSetup.java
Patch:
@@ -5,6 +5,7 @@
 import org.logstash.benchmark.cli.JRubyInstallation;
 import org.logstash.benchmark.cli.LogstashInstallation;
 import org.logstash.benchmark.cli.ui.LsVersionType;
+import org.logstash.benchmark.cli.ui.UserOutput;
 
 public final class LsBenchLsSetup {
 
@@ -25,13 +26,13 @@ public static LogstashInstallation logstashFromGit(final String pwd, final Strin
     }
 
     public static LogstashInstallation setupLS(final String pwd, final String version,
-        final LsVersionType type) {
+        final LsVersionType type, final UserOutput output) {
         final LogstashInstallation logstash;
         if (type == LsVersionType.LOCAL) {
             logstash = new LogstashInstallation.FromLocalPath(version);
         } else {
             logstash = new LogstashInstallation.FromRelease(
-                Paths.get(pwd, String.format("ls-release-%s", version)).toFile(), version
+                Paths.get(pwd, String.format("ls-release-%s", version)).toFile(), version, output
             );
         }
         return logstash;

File: logstash-core/src/test/java/org/logstash/common/SourceWithMetadataTest.java
Patch:
@@ -40,10 +40,8 @@ public static Iterable<ParameterGroup> data() {
             new ParameterGroup("proto", "path", 1, 1, null),
             new ParameterGroup("", "path", 1, 1, "foo"),
             new ParameterGroup("proto", "", 1, 1, "foo"),
-            new ParameterGroup("proto", "path", 1, 1, ""),
             new ParameterGroup(" ", "path", 1, 1, "foo"),
-            new ParameterGroup("proto", "  ", 1, 1, "foo"),
-            new ParameterGroup("proto", "path", 1, 1, "   ")
+            new ParameterGroup("proto", "  ", 1, 1, "foo")
         );
     }
 

File: logstash-core/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -10,7 +10,7 @@ public final class ConvertedMap extends HashMap<String, Object> {
 
     private static final long serialVersionUID = -4651798808586901122L;
 
-    private ConvertedMap(final int size) {
+    ConvertedMap(final int size) {
         super((size << 2) / 3 + 2);
     }
     

File: logstash-core/src/main/java/org/logstash/PathCache.java
Patch:
@@ -1,10 +1,12 @@
 package org.logstash;
 
+import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
 public final class PathCache {
 
-    private static final ConcurrentHashMap<String, FieldReference> cache = new ConcurrentHashMap<>();
+    private static final Map<String, FieldReference> cache =
+        new ConcurrentHashMap<>(64, 0.2F, 1);
 
     private static final FieldReference timestamp = cache(Event.TIMESTAMP);
 

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/BooleanGauge.java
Patch:
@@ -9,7 +9,7 @@
 /**
  * A {@link GaugeMetric} that is backed by a {@link Boolean}
  */
-public class BooleanGauge extends AbstractMetric<Boolean> implements GaugeMetric<Boolean> {
+public class BooleanGauge extends AbstractMetric<Boolean> implements GaugeMetric<Boolean,Boolean> {
 
     private volatile Boolean value;
 

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/NumericGauge.java
Patch:
@@ -8,7 +8,7 @@
 /**
  * A {@link GaugeMetric} that is backed by a {@link Number}
  */
-public class NumericGauge extends AbstractMetric<Number> implements GaugeMetric<Number> {
+public class NumericGauge extends AbstractMetric<Number> implements GaugeMetric<Number,Number> {
 
     private volatile Number value;
 

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/RubyHashGauge.java
Patch:
@@ -4,13 +4,14 @@
 import org.logstash.instrument.metrics.AbstractMetric;
 import org.logstash.instrument.metrics.MetricType;
 
+
 import java.util.List;
 
 /**
  * A {@link GaugeMetric} that is backed by a {@link RubyHash}.  Note - This should not be used directly from Java code and exists for passivity with legacy Ruby code. Depending
  * on the types in in the {@link RubyHash} there are no guarantees serializing properly.
  */
-public class RubyHashGauge extends AbstractMetric<RubyHash> implements GaugeMetric<RubyHash> {
+public class RubyHashGauge extends AbstractMetric<RubyHash> implements GaugeMetric<RubyHash,RubyHash> {
 
     private volatile RubyHash value;
 

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/TextGauge.java
Patch:
@@ -9,7 +9,7 @@
 /**
  * A {@link GaugeMetric} that is backed by a {@link String}
  */
-public class TextGauge extends AbstractMetric<String> implements GaugeMetric<String> {
+public class TextGauge extends AbstractMetric<String> implements GaugeMetric<String,String> {
 
     private volatile String value;
 

File: logstash-core/src/main/java/org/logstash/instrument/metrics/gauge/UnknownGauge.java
Patch:
@@ -8,7 +8,7 @@
 /**
  * A {@link GaugeMetric} that is backed by a {@link Object}.  Note - A stronger typed {@link GaugeMetric} should be used since this makes no guarantees of serializing properly.
  */
-public class UnknownGauge extends AbstractMetric<Object> implements GaugeMetric<Object> {
+public class UnknownGauge extends AbstractMetric<Object> implements GaugeMetric<Object,Object> {
 
     private volatile Object value;
 

File: logstash-core/src/test/java/org/logstash/instrument/metrics/MetricTypeTest.java
Patch:
@@ -27,6 +27,7 @@ public void ensurePassivity(){
         nameMap.put(MetricType.GAUGE_NUMERIC, "gauge/numeric");
         nameMap.put(MetricType.GAUGE_UNKNOWN, "gauge/unknown");
         nameMap.put(MetricType.GAUGE_RUBYHASH, "gauge/rubyhash");
+        nameMap.put(MetricType.GAUGE_RUBYTIMESTAMP, "gauge/rubytimestamp");
 
         //ensure we are testing all of the enumerations
         assertThat(EnumSet.allOf(MetricType.class).size()).isEqualTo(nameMap.size());

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedBatchExtLibrary.java
Patch:
@@ -71,7 +71,7 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject events,  I
         public IRubyObject ruby_get_elements(ThreadContext context)
         {
             RubyArray result = context.runtime.newArray();
-            this.batch.getElements().forEach(e -> result.add(new JrubyEventExtLibrary.RubyEvent(context.runtime, (Event)e)));
+            this.batch.getElements().forEach(e -> result.add(JrubyEventExtLibrary.RubyEvent.newRubyEvent(context.runtime, (Event)e)));
 
             return result;
         }

File: logstash-core/src/main/java/org/logstash/ext/JrubyTimestampExtLibrary.java
Patch:
@@ -39,7 +39,7 @@ public static RubyClass createTimestamp(Ruby runtime) {
         return clazz;
     }
 
-    @JRubyClass(name = "Timestamp", parent = "Object")
+    @JRubyClass(name = "Timestamp")
     public static class RubyTimestamp extends RubyObject {
 
         private Timestamp timestamp;

File: logstash-core/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -15,7 +15,6 @@
 import org.jruby.exceptions.RaiseException;
 import org.jruby.java.proxies.MapJavaProxy;
 import org.jruby.javasupport.JavaUtil;
-import org.jruby.runtime.Arity;
 import org.jruby.runtime.ObjectAllocator;
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
@@ -99,8 +98,7 @@ public void setEvent(Event event) {
         // def initialize(data = {})
         @JRubyMethod(name = "initialize", optional = 1)
         public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args) {
-            args = Arity.scanArgs(context.runtime, args, 0, 1);
-            IRubyObject data = args[0];
+            final IRubyObject data = args.length > 0 ? args[0] : null;
             if (data instanceof RubyHash) {
                 this.event = new Event(ConvertedMap.newFromRubyHash((RubyHash) data));
             } else {

File: logstash-core/src/main/java/org/logstash/ConvertedList.java
Patch:
@@ -1,6 +1,7 @@
 package org.logstash;
 
 import java.util.ArrayList;
+import java.util.Collection;
 import java.util.List;
 import org.jruby.RubyArray;
 import org.jruby.runtime.builtin.IRubyObject;
@@ -11,11 +12,11 @@ public final class ConvertedList extends ArrayList<Object> {
 
     private static final long serialVersionUID = 1396291343595074238L;
 
-    private ConvertedList(final int size) {
+    ConvertedList(final int size) {
         super(size);
     }
 
-    public static ConvertedList newFromList(List<Object> list) {
+    public static ConvertedList newFromList(final Collection<?> list) {
         ConvertedList array = new ConvertedList(list.size());
 
         for (Object item : list) {

File: logstash-core/src/main/java/org/logstash/Javafier.java
Patch:
@@ -15,6 +15,9 @@ public class Javafier {
     private Javafier(){}
 
     public static Object deep(Object o) {
+        if(o == null) {
+            return null;
+        }
         if (o instanceof BiValue) {
             return ((BiValue)o).javaValue();
         } else if(o instanceof ConvertedMap) {

File: logstash-core/src/main/java/org/logstash/ConvertedList.java
Patch:
@@ -9,6 +9,8 @@
 
 public final class ConvertedList extends ArrayList<Object> {
 
+    private static final long serialVersionUID = 1396291343595074238L;
+
     private ConvertedList(final int size) {
         super(size);
     }

File: logstash-core/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -8,6 +8,8 @@
 
 public final class ConvertedMap extends HashMap<String, Object> {
 
+    private static final long serialVersionUID = -4651798808586901122L;
+
     private ConvertedMap(final int size) {
         super((size << 2) / 3 + 2);
     }

File: logstash-core/src/main/java/org/logstash/LockException.java
Patch:
@@ -3,11 +3,13 @@
 import java.io.IOException;
 
 public class LockException extends IOException {
+    private static final long serialVersionUID = 4924559998318165488L;
+
     public LockException(String message) {
         super(message);
     }
 
     public LockException(String message, Throwable cause) {
         super(message, cause);
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/main/java/org/logstash/Rubyfier.java
Patch:
@@ -34,7 +34,7 @@ public static IRubyObject deep(Ruby runtime, final Object input) {
         try {
             return BiValues.newBiValue(input).rubyValue(runtime);
         } catch (IllegalArgumentException e) {
-            Class cls = input.getClass();
+            Class<?> cls = input.getClass();
             throw new IllegalArgumentException(String.format(ERR_TEMPLATE, cls.getName(), cls.getSimpleName()));
         }
     }
@@ -50,7 +50,7 @@ private static RubyArray deepList(Ruby runtime, final List list) {
 
     private static RubyHash deepMap(Ruby runtime, final Map<?, ?> map) {
         RubyHash hash = RubyHash.newHash(runtime);
-        for (Map.Entry entry : map.entrySet()) {
+        for (Map.Entry<?, ?> entry : map.entrySet()) {
             // Note: RubyHash.put calls JavaUtil.convertJavaToUsableRubyObject on keys and values
             hash.put(entry.getKey(), deep(runtime, entry.getValue()));
         }

File: logstash-core/src/main/java/org/logstash/Valuefier.java
Patch:
@@ -35,7 +35,7 @@ private static Object convertJavaProxy(JavaProxy jp) {
         try {
             return BiValues.newBiValue(jp);
         } catch (IllegalArgumentException e) {
-            Class cls = obj.getClass();
+            final Class<?> cls = obj.getClass();
             throw new IllegalArgumentException(String.format(PROXY_ERR_TEMPLATE, cls.getName(), cls.getSimpleName(), obj.getClass().getName()), e);
         }
     }
@@ -44,7 +44,7 @@ public static Object convertNonCollection(Object o) {
         try {
             return BiValues.newBiValue(o);
         } catch (IllegalArgumentException e) {
-            Class cls = o.getClass();
+            final Class<?> cls = o.getClass();
             throw new IllegalArgumentException(String.format(ERR_TEMPLATE, cls.getName(), cls.getSimpleName()), e);
         }
     }

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -114,7 +114,7 @@ private Queue(String dirPath, int pageCapacity, long maxBytes, CheckpointIO chec
 
         // retrieve the deserialize method
         try {
-            Class[] cArg = new Class[1];
+            final Class<?>[] cArg = new Class[1];
             cArg[0] = byte[].class;
             this.deserializeMethod = this.elementClass.getDeclaredMethod("deserialize", cArg);
         } catch (NoSuchMethodException e) {

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedBatchExtLibrary.java
Patch:
@@ -33,8 +33,9 @@ public IRubyObject allocate(Ruby runtime, RubyClass rubyClass) {
         clazz.defineAnnotatedMethods(RubyAckedBatch.class);
     }
 
-    @JRubyClass(name = "AckedBatch", parent = "Object")
+    @JRubyClass(name = "AckedBatch")
     public static class RubyAckedBatch extends RubyObject {
+        private static final long serialVersionUID = -3118949118637372130L;
         private Batch batch;
 
         public RubyAckedBatch(Ruby runtime, RubyClass klass) {

File: logstash-core/src/main/java/org/logstash/common/IncompleteSourceWithMetadataException.java
Patch:
@@ -6,6 +6,8 @@
  * Created by andrewvc on 6/12/17.
  */
 public class IncompleteSourceWithMetadataException extends InvalidIRException {
+    private static final long serialVersionUID = 456422097113787583L;
+
     public IncompleteSourceWithMetadataException(String message) {
         super(message);
     }

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
Patch:
@@ -42,6 +42,8 @@ public Vertex(SourceWithMetadata sourceWithMetadata, String explicitId) {
     public abstract Vertex copy();
 
     public static class InvalidEdgeTypeException extends InvalidIRException {
+        private static final long serialVersionUID = -2707379453144995223L;
+
         public InvalidEdgeTypeException(String s) {
             super(s);
         }

File: logstash-core/src/main/java/org/logstash/config/ir/graph/algorithms/ShortestPath.java
Patch:
@@ -13,6 +13,7 @@
  */
 public class ShortestPath {
     static class InvalidShortestPathArguments extends Exception {
+        private static final long serialVersionUID = -1493537067800744231L;
         private final Collection<Vertex> invalidVertices;
 
         public InvalidShortestPathArguments(Collection<Vertex> invalidVertices) {

File: logstash-core/src/main/java/org/logstash/config/ir/graph/algorithms/TopologicalSort.java
Patch:
@@ -11,6 +11,8 @@
  */
 public class TopologicalSort {
     public static class UnexpectedGraphCycleError extends Exception {
+        private static final long serialVersionUID = 1778155790783320839L;
+
         UnexpectedGraphCycleError(Graph g) {
             super("Graph has cycles, is not a DAG! " + g);
         }

File: tools/benchmark-cli/src/main/java/org/logstash/benchmark/cli/LogstashInstallation.java
Patch:
@@ -127,8 +127,9 @@ public void execute(final String configuration, final File data)
             );
             final Path lsbin = location.resolve("bin").resolve("logstash");
             LsBenchFileUtil.ensureExecutable(lsbin.toFile());
+            final File output = Files.createTempFile(null, null).toFile();
             final Process process = pbuilder.command(lsbin.toString(), "-w", "2", "-f", cfg.toString()).redirectOutput(
-                ProcessBuilder.Redirect.to(new File("/dev/null"))
+                ProcessBuilder.Redirect.to(output)
             ).start();
             if (data != null) {
                 try (final InputStream file = new FileInputStream(data);
@@ -140,6 +141,7 @@ public void execute(final String configuration, final File data)
                 throw new IllegalStateException("Logstash failed to start!");
             }
             LsBenchFileUtil.ensureDeleted(cfg.toFile());
+            LsBenchFileUtil.ensureDeleted(output);
         }
 
         @Override

File: logstash-core/src/main/java/org/logstash/common/io/RecordIOReader.java
Patch:
@@ -79,7 +79,7 @@ public <T> byte[] seekToNextEventPosition(T target, Function<byte[], T> keyExtra
         int matchingBlock = UNSET;
         int lowBlock = 0;
         int highBlock = (int) (channel.size() - VERSION_SIZE) / BLOCK_SIZE;
-        
+
         while (lowBlock < highBlock) {
             int middle = (int) Math.ceil((highBlock + lowBlock) / 2.0);
             seekToBlock(middle);

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueReader.java
Patch:
@@ -18,6 +18,7 @@
  */
 package org.logstash.common.io;
 
+import java.io.Closeable;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.logstash.DLQEntry;
@@ -39,7 +40,7 @@
 import static java.nio.file.StandardWatchEventKinds.ENTRY_DELETE;
 import static org.logstash.common.io.DeadLetterQueueWriter.getSegmentPaths;
 
-public class DeadLetterQueueReader {
+public final class DeadLetterQueueReader implements Closeable {
     private static final Logger logger = LogManager.getLogger(DeadLetterQueueReader.class);
 
     private RecordIOReader currentReader;
@@ -142,6 +143,7 @@ public long getCurrentPosition() {
         return currentReader.getChannelPosition();
     }
 
+    @Override
     public void close() throws IOException {
         if (currentReader != null) {
             currentReader.close();

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriter.java
Patch:
@@ -18,6 +18,7 @@
  */
 package org.logstash.common.io;
 
+import java.io.Closeable;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.logstash.DLQEntry;
@@ -37,7 +38,7 @@
 
 import static org.logstash.common.io.RecordIOWriter.RECORD_HEADER_SIZE;
 
-public class DeadLetterQueueWriter {
+public final class DeadLetterQueueWriter implements Closeable {
 
     private static final Logger logger = LogManager.getLogger(DeadLetterQueueWriter.class);
     private static final long MAX_SEGMENT_SIZE_BYTES = 10 * 1024 * 1024;
@@ -143,6 +144,7 @@ private void innerWriteEntry(DLQEntry entry) throws IOException {
         currentQueueSize.add(currentWriter.writeEvent(record));
     }
 
+    @Override
     public synchronized void close() throws IOException {
         this.lock.release();
         if (currentWriter != null) {

File: logstash-core/src/main/java/org/logstash/common/io/RecordIOReader.java
Patch:
@@ -18,6 +18,7 @@
  */
 package org.logstash.common.io;
 
+import java.io.Closeable;
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.channels.ClosedByInterruptException;
@@ -36,7 +37,7 @@
 
 /**
  */
-public class RecordIOReader {
+public final class RecordIOReader implements Closeable {
 
     private final FileChannel channel;
     private final ByteBuffer currentBlock;
@@ -228,6 +229,7 @@ public byte[] readEvent() throws IOException {
         }
     }
 
+    @Override
     public void close() throws IOException {
         channel.close();
     }

File: logstash-core/src/main/java/org/logstash/common/io/RecordIOWriter.java
Patch:
@@ -18,6 +18,7 @@
  */
 package org.logstash.common.io;
 
+import java.io.Closeable;
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.channels.FileChannel;
@@ -63,7 +64,7 @@
  *           by a final END record type.
  *   END: The final record segment of an LS Event, the final record representing the end of an LS Event.
  */
-public class RecordIOWriter {
+public final class RecordIOWriter implements Closeable {
 
     private final FileChannel channel;
     private int posInBlock;
@@ -139,6 +140,7 @@ public long writeEvent(byte[] eventArray) throws IOException {
         return channel.position() - startPosition;
     }
 
+    @Override
     public void close() throws IOException {
         channel.close();
     }

File: logstash-core/src/test/java/org/logstash/instruments/monitors/HotThreadMonitorTest.java
Patch:
@@ -50,7 +50,8 @@ public void testStackTraceSizeOption(){
         Map<String, String> options = new HashMap<>();
         options.put("stacktrace_size", testStackSize);
         HotThreadsMonitor.detect(options).stream().filter(tr -> !tr.getThreadName().equals("Signal Dispatcher") &&
-                                                                      !tr.getThreadName().equals("Reference Handler"))
+                                                                      !tr.getThreadName().equals("Reference Handler") &&
+                                                                            !tr.getThreadName().equals("Attach Listener"))
                                                         .forEach(tr -> {
             List stackTrace = (List)tr.toMap().get("thread.stacktrace");
             assertThat(stackTrace.size(), is(Integer.valueOf(testStackSize)));

File: logstash-core/src/test/java/org/logstash/bivalues/BiValueTest.java
Patch:
@@ -29,7 +29,7 @@ public void testStringBiValueFromRuby() {
         String s = "foo bar baz";
         StringBiValue subject = new StringBiValue(RubyString.newString(ruby, s));
         assertTrue(subject.hasRubyValue());
-        assertFalse(subject.hasJavaValue());
+        assertTrue(subject.hasJavaValue());
         assertEquals(s, subject.javaValue());
     }
 

File: tools/ingest-converter/src/test/java/org/logstash/ingest/IngestTest.java
Patch:
@@ -39,7 +39,7 @@ public abstract class IngestTest {
     @Parameter
     public String testCase;
 
-    protected final void assertCorrectConversion(final Class clazz) throws Exception {
+    protected final void assertCorrectConversion(final Class<?> clazz) throws Exception {
         final URL append = getResultPath(temp);
         clazz.getMethod("main", String[].class).invoke(
             null,

File: logstash-core/src/main/java/org/logstash/ackedqueue/TailPage.java
Patch:
@@ -15,7 +15,7 @@ public TailPage(HeadPage page) {
 
     // create a new TailPage object for an exiting Checkpoint and data file
     // @param pageIO the PageIO object is expected to be open/recover/create
-    public TailPage(Checkpoint checkpoint, Queue queue, PageIO pageIO) throws IOException {
+    public TailPage(Checkpoint checkpoint, Queue queue, PageIO pageIO) {
         super(checkpoint.getPageNum(), queue, checkpoint.getMinSeqNum(), checkpoint.getElementCount(), checkpoint.getFirstUnackedSeqNum(), new BitSet(), pageIO);
 
         // this page ackedSeqNums bitset is a new empty bitset, if we have some acked elements, set them in the bitset
@@ -45,4 +45,4 @@ public void close() throws IOException {
             this.pageIO.close();
         }
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/wip/MemoryPageIOStream.java
Patch:
@@ -276,7 +276,7 @@ private byte[] readData() throws IOException {
         return streamedInput.readByteArray();
     }
 
-    private void skipChecksum() throws IOException {
+    private void skipChecksum() {
         streamedInput.skip(CHECKSUM_SIZE);
     }
 

File: logstash-core/src/main/java/org/logstash/common/io/ByteBufferStreamInput.java
Patch:
@@ -40,7 +40,7 @@ public int read(byte[] b, int off, int len) throws IOException {
     }
 
     @Override
-    public long skip(long n) throws IOException {
+    public long skip(long n) {
         if (n > buffer.remaining()) {
             int ret = buffer.position();
             buffer.position(buffer.limit());
@@ -67,7 +67,7 @@ public void movePosition(int position) {
         buffer.position(position);
     }
 
-    public void rewind() throws IOException {
+    public void rewind() {
         buffer.rewind();
     }
 

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueReader.java
Patch:
@@ -138,7 +138,7 @@ public Path getCurrentSegment() {
         return currentReader.getPath();
     }
 
-    public long getCurrentPosition() throws IOException {
+    public long getCurrentPosition() {
         return currentReader.getChannelPosition();
     }
 

File: logstash-core/src/main/java/org/logstash/common/io/RecordIOReader.java
Patch:
@@ -118,7 +118,7 @@ public <T> byte[] seekToNextEventPosition(T target, Function<byte[], T> keyExtra
         return event;
     }
 
-    public long getChannelPosition() throws IOException {
+    public long getChannelPosition() {
         return channelPosition;
     }
 
@@ -147,7 +147,7 @@ public boolean isEndOfStream() {
     /**
      *
      */
-     int seekToStartOfEventInBlock() throws IOException {
+     int seekToStartOfEventInBlock() {
          while (true) {
              RecordType type = RecordType.fromByte(currentBlock.array()[currentBlock.arrayOffset() + currentBlock.position()]);
              if (RecordType.COMPLETE.equals(type) || RecordType.START.equals(type)) {
@@ -189,7 +189,7 @@ private void maybeRollToNextBlock() throws IOException {
         }
     }
 
-    private void getRecord(ByteBuffer buffer, RecordHeader header) throws IOException {
+    private void getRecord(ByteBuffer buffer, RecordHeader header) {
         Checksum computedChecksum = new CRC32();
         computedChecksum.update(currentBlock.array(), currentBlock.position(), header.getSize());
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/BinaryBooleanExpression.java
Patch:
@@ -1,9 +1,8 @@
 package org.logstash.config.ir.expression;
 
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.common.Util;
 import org.logstash.config.ir.SourceComponent;
-import org.logstash.config.ir.InvalidIRException;
-import org.logstash.common.SourceWithMetadata;
 
 /**
  * Created by andrewvc on 9/6/16.
@@ -34,7 +33,7 @@ public Expression getLeft() {
 
     public BinaryBooleanExpression(SourceWithMetadata meta,
                                    Expression left,
-                                   Expression right) throws InvalidIRException {
+                                   Expression right) {
         super(meta);
         this.left = left;
         this.right = right;

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/And.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.config.ir.expression.binary;
 
-import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
@@ -9,7 +8,7 @@
  * Created by andrewvc on 9/21/16.
  */
 public class And extends BinaryBooleanExpression {
-    public And(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public And(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Eq.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.config.ir.expression.binary;
 
-import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
@@ -9,7 +8,7 @@
  * Created by andrewvc on 9/21/16.
  */
 public class Eq extends BinaryBooleanExpression {
-    public Eq(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Eq(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Gt.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.config.ir.expression.binary;
 
-import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
@@ -9,7 +8,7 @@
  * Created by andrewvc on 9/21/16.
  */
 public class Gt extends BinaryBooleanExpression {
-    public Gt(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Gt(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Gte.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.config.ir.expression.binary;
 
-import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
@@ -9,7 +8,7 @@
  * Created by andrewvc on 9/21/16.
  */
 public class Gte extends BinaryBooleanExpression {
-    public Gte(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Gte(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/In.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.config.ir.expression.binary;
 
-import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
@@ -9,7 +8,7 @@
  * Created by andrewvc on 9/21/16.
  */
 public class In extends BinaryBooleanExpression {
-    public In(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public In(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Lt.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.config.ir.expression.binary;
 
-import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
@@ -9,7 +8,7 @@
  * Created by andrewvc on 9/21/16.
  */
 public class Lt extends BinaryBooleanExpression {
-    public Lt(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Lt(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Lte.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.config.ir.expression.binary;
 
-import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
@@ -9,7 +8,7 @@
  * Created by andrewvc on 9/21/16.
  */
 public class Lte extends BinaryBooleanExpression {
-    public Lte(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Lte(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Neq.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.config.ir.expression.binary;
 
-import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
@@ -9,7 +8,7 @@
  * Created by andrewvc on 9/21/16.
  */
 public class Neq extends BinaryBooleanExpression {
-    public Neq(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Neq(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Or.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.config.ir.expression.binary;
 
-import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
@@ -9,7 +8,7 @@
  * Created by andrewvc on 9/21/16.
  */
 public class Or extends BinaryBooleanExpression {
-    public Or(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Or(SourceWithMetadata meta, Expression left, Expression right) {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/Settings.java
Patch:
@@ -9,7 +9,7 @@ public interface Settings {
 
     PageIOFactory getPageIOFactory();
 
-    Class getElementClass();
+    Class<? extends Queueable> getElementClass();
 
     String getDirPath();
 
@@ -29,7 +29,7 @@ interface Builder {
 
         Builder elementIOFactory(PageIOFactory factory);
 
-        Builder elementClass(Class elementClass);
+        Builder elementClass(Class<? extends Queueable> elementClass);
 
         Builder capacity(int capacity);
 

File: logstash-core/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -8,8 +8,8 @@
 
 public final class ConvertedMap extends HashMap<String, Object> {
 
-    public ConvertedMap(final int size) {
-        super(size);
+    private ConvertedMap(final int size) {
+        super((size << 2) / 3 + 2);
     }
     
     public static ConvertedMap newFromMap(Map<Serializable, Object> o) {

File: logstash-core/src/main/java/org/logstash/Cloner.java
Patch:
@@ -24,7 +24,7 @@ private static <E> List<E> deepList(final List<E> list) {
             clone = new LinkedList<>();
         } else if (list instanceof ArrayList<?>) {
             clone = new ArrayList<>();
-        } else if (list instanceof ConvertedList<?>) {
+        } else if (list instanceof ConvertedList) {
             clone = new ArrayList<>();
         } else {
             throw new ClassCastException("unexpected List type " + list.getClass());
@@ -45,7 +45,7 @@ private static <K, V> Map<K, V> deepMap(final Map<K, V> map) {
             clone = new TreeMap<>();
         } else if (map instanceof HashMap<?, ?>) {
             clone = new HashMap<>();
-        } else if (map instanceof ConvertedMap<?, ?>) {
+        } else if (map instanceof ConvertedMap) {
             clone = new HashMap<>();
         } else {
             throw new ClassCastException("unexpected Map type " + map.getClass());

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -71,7 +71,7 @@ public Event(Map data) {
      * makes to its underlying data will be propagated to it.
      * @param data Converted Map
      */
-    public Event(ConvertedMap<String, Object> data) {
+    public Event(ConvertedMap data) {
         this.data = data;
         if (!this.data.containsKey(VERSION)) {
             this.data.put(VERSION, VERSION_ONE);

File: logstash-core/src/test/java/org/logstash/ValuefierTest.java
Patch:
@@ -36,7 +36,7 @@ public void testMapJavaProxy() {
 
         Object result = Valuefier.convert(mjp);
         assertEquals(ConvertedMap.class, result.getClass());
-        ConvertedMap<String, Object> m = (ConvertedMap) result;
+        ConvertedMap m = (ConvertedMap) result;
         BiValue bv = BiValues.newBiValue("bar");
         assertEquals(bv.javaValue(), ((BiValue) m.get("foo")).javaValue());
     }

File: tools/ingest-converter/src/test/java/org/logstash/ingest/GrokTest.java
Patch:
@@ -9,7 +9,7 @@ public final class GrokTest extends IngestTest {
 
     @Parameters
     public static Iterable<String> data() {
-        return Arrays.asList("Grok", "GrokPatternDefinition");
+        return Arrays.asList("Grok", "GrokPatternDefinition", "GrokMultiplePatternDefinitions");
     }
 
     @Test

File: logstash-core/src/main/java/org/logstash/instrument/reports/MemoryReport.java
Patch:
@@ -25,7 +25,7 @@ public static Map<String, Map<String, Map<String, Object>>> generate() {
     }
 
     private static MemoryMonitor.Report generateReport(MemoryMonitor.Type type) {
-        return new MemoryMonitor().detect(type);
+        return MemoryMonitor.detect(type);
     }
 }
 

File: logstash-core/src/test/java/org/logstash/instruments/monitors/MemoryMonitorTest.java
Patch:
@@ -15,19 +15,19 @@ public class MemoryMonitorTest {
 
     @Test
     public void testEachHeapSpaceRepresented() {
-        Map<String, Map<String, Object>> heap = new MemoryMonitor().detect(MemoryMonitor.Type.All).getHeap();
+        Map<String, Map<String, Object>> heap = MemoryMonitor.detect(MemoryMonitor.Type.All).getHeap();
         assertThat(heap, notNullValue());
         assertThat(heap.keySet(), hasItems("PS Survivor Space", "PS Old Gen", "PS Eden Space"));
     }
 
     @Test
     public void testAllStatsAreAvailableForHeap(){
-        testAllStatsAreAvailable(new MemoryMonitor().detect(MemoryMonitor.Type.All).getHeap());
+        testAllStatsAreAvailable(MemoryMonitor.detect(MemoryMonitor.Type.All).getHeap());
     }
 
     @Test
     public void testAllStatsAreAvailableForNonHeap(){
-        testAllStatsAreAvailable(new MemoryMonitor().detect(MemoryMonitor.Type.All).getNonHeap());
+        testAllStatsAreAvailable(MemoryMonitor.detect(MemoryMonitor.Type.All).getNonHeap());
     }
 
     private void testAllStatsAreAvailable(Map<String, Map<String, Object>> stats){

File: logstash-core/src/test/java/org/logstash/common/DeadLetterQueueFactoryTest.java
Patch:
@@ -45,9 +45,9 @@ public void setUp() throws Exception {
     @Test
     public void test() throws IOException {
         Path pipelineA = dir.resolve("pipelineA");
-        DeadLetterQueueWriter writer = DeadLetterQueueFactory.getWriter("pipelineA", pipelineA.toString());
+        DeadLetterQueueWriter writer = DeadLetterQueueFactory.getWriter("pipelineA", pipelineA.toString(), 10000);
         assertTrue(writer.isOpen());
-        DeadLetterQueueWriter writer2 = DeadLetterQueueFactory.getWriter("pipelineA", pipelineA.toString());
+        DeadLetterQueueWriter writer2 = DeadLetterQueueFactory.getWriter("pipelineA", pipelineA.toString(), 10000);
         assertSame(writer, writer2);
         writer.close();
     }

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -185,10 +185,10 @@ private static Event fromSerializableMap(Map<String, Map<String, Object>> repres
 
     private static Map<String, Map<String, Object>> fromBinaryToMap(byte[] source) throws IOException {
         Object o = CBOR_MAPPER.readValue(source, HashMap.class);
-        if (o instanceof Map) {
-            return (HashMap<String, Map<String, Object>>) o;
+        if (o == null) {
+            throw new IOException("incompatible from binary object type only HashMap is supported");
         } else {
-            throw new IOException("incompatible from binary object type=" + o.getClass().getName() + " , only HashMap is supported");
+            return (Map<String, Map<String, Object>>) o;
         }
     }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedBatchExtLibrary.java
Patch:
@@ -1,5 +1,6 @@
 package org.logstash.ackedqueue.ext;
 
+import java.util.List;
 import org.jruby.Ruby;
 import org.jruby.RubyClass;
 import org.jruby.RubyModule;
@@ -13,6 +14,7 @@
 import org.jruby.runtime.load.Library;
 import org.logstash.ackedqueue.Batch;
 import org.logstash.Event;
+import org.logstash.ackedqueue.Queueable;
 import org.logstash.ext.JrubyEventExtLibrary;
 
 import java.io.IOException;
@@ -59,7 +61,7 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject events,  I
                 context.runtime.newArgumentError("expected queue AckedQueue");
             }
 
-            this.batch = new Batch(((RubyArray)events), ((RubyArray)seqNums), ((JrubyAckedQueueExtLibrary.RubyAckedQueue)queue).getQueue());
+            this.batch = new Batch((List<Queueable>) events, (List<Long>) seqNums, ((JrubyAckedQueueExtLibrary.RubyAckedQueue)queue).getQueue());
 
             return context.nil;
         }

File: logstash-core/src/main/java/org/logstash/bivalues/TimestampBiValue.java
Patch:
@@ -22,7 +22,7 @@ private TimestampBiValue() {
     }
 
     protected void addRuby(Ruby runtime) {
-        rubyValue = RubyTimestamp.newRubyTimestamp(runtime, (Timestamp) javaValue);
+        rubyValue = RubyTimestamp.newRubyTimestamp(runtime, javaValue);
     }
 
     protected void addJava() {

File: logstash-core/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -281,7 +281,7 @@ public static IRubyObject ruby_validate_value(ThreadContext context, IRubyObject
         public IRubyObject ruby_tag(ThreadContext context, RubyString value)
         {
             //TODO(guy) should these tags be BiValues?
-            this.event.tag(((RubyString) value).asJavaString());
+            this.event.tag(value.asJavaString());
             return context.nil;
         }
 

File: logstash-core/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -120,7 +120,7 @@ public IRubyObject ruby_set_field(ThreadContext context, RubyString reference, I
         {
             String r = reference.asJavaString();
 
-            if (PathCache.getInstance().isTimestamp(r)) {
+            if (PathCache.isTimestamp(r)) {
                 if (!(value instanceof JrubyTimestampExtLibrary.RubyTimestamp)) {
                     throw context.runtime.newTypeError("wrong argument type " + value.getMetaClass() + " (expected LogStash::Timestamp)");
                 }

File: logstash-core/src/main/java/org/logstash/instrument/reports/ThreadsReport.java
Patch:
@@ -22,8 +22,7 @@ public class ThreadsReport {
      * @return A Map containing hot threads information
      */
     public static Map<String, Object> generate(Map<String, String> options) {
-        HotThreadsMonitor reporter = new HotThreadsMonitor();
-        List<HotThreadsMonitor.ThreadReport> reports = reporter.detect(options);
+        List<HotThreadsMonitor.ThreadReport> reports = HotThreadsMonitor.detect(options);
         return reports
                 .stream()
                 .collect(Collectors

File: logstash-core/src/main/java/org/logstash/Valuefier.java
Patch:
@@ -1,5 +1,6 @@
 package org.logstash;
 
+import java.io.Serializable;
 import org.logstash.bivalues.BiValue;
 import org.logstash.bivalues.BiValues;
 import org.logstash.ext.JrubyTimestampExtLibrary;
@@ -67,7 +68,7 @@ public static Object convert(Object o) throws IllegalArgumentException {
             return ConvertedList.newFromRubyArray((RubyArray) o);
         }
         if (o instanceof Map) {
-            return ConvertedMap.newFromMap((Map<String, Object>) o);
+            return ConvertedMap.newFromMap((Map<Serializable, Object>) o);
         }
         if (o instanceof List) {
             return ConvertedList.newFromList((List<Object>) o);

File: logstash-core/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -98,8 +98,9 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args)
             } else if (data instanceof RubyHash) {
                 this.event = new Event(ConvertedMap.newFromRubyHash((RubyHash) data));
             } else if (data instanceof MapJavaProxy) {
-                Map<String, Object> m = (Map)((MapJavaProxy)data).getObject();
-                this.event = new Event(ConvertedMap.newFromMap(m));
+                this.event = new Event(ConvertedMap.newFromMap(
+                    (Map)((MapJavaProxy)data).getObject())
+                );
             } else {
                 throw context.runtime.newTypeError("wrong argument type " + data.getMetaClass() + " (expected Hash)");
             }

File: logstash-core/src/main/java/org/logstash/ConvertedList.java
Patch:
@@ -17,7 +17,7 @@
 
 import static org.logstash.Valuefier.convert;
 
-public class ConvertedList<T> implements List<T>, Collection<T>, Iterable<T> {
+public class ConvertedList<T> implements List<T> {
     private final List<T> delegate;
 
     public ConvertedList(final int size) {

File: logstash-core/src/main/java/org/logstash/KeyNode.java
Patch:
@@ -30,7 +30,7 @@ public String evaluate(Event event) throws IOException {
                 return join((List)value, ",");
             } else if (value instanceof Map) {
                 ObjectMapper mapper = new ObjectMapper();
-                return mapper.writeValueAsString((Map<String, Object>)value);
+                return mapper.writeValueAsString(value);
             } else {
                 return event.getField(this.key).toString();
             }
@@ -60,8 +60,8 @@ private static String toString(Object value, String delim) {
         if (value == null) return "";
         if (value instanceof List) return join((List)value, delim);
         if (value instanceof BiValue) {
-            return ((BiValue) value).toString();
+            return value.toString();
         }
         return value.toString();
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/main/java/org/logstash/Valuefier.java
Patch:
@@ -26,8 +26,9 @@ private Valuefier(){}
     private static Object convertJavaProxy(JavaProxy jp) {
         Object obj = JavaUtil.unwrapJavaObject(jp);
         if (obj instanceof IRubyObject[]) {
-            ConvertedList<Object> list = new ConvertedList<>();
-            for (IRubyObject ro : ((IRubyObject[]) obj)) {
+            final IRubyObject[] arr = (IRubyObject[]) obj;
+            ConvertedList<Object> list = new ConvertedList<>(arr.length);
+            for (IRubyObject ro : arr) {
                 list.add(convert(ro));
             }
             return list;

File: logstash-core/src/main/java/org/logstash/ackedqueue/Page.java
Patch:
@@ -76,8 +76,7 @@ public boolean isFullyAcked() {
         // TODO: it should be something similar to this when we use a proper bitset class like ES
         // this.ackedSeqNum.firstUnackedBit >= this.elementCount;
         // TODO: for now use a naive & inefficient mechanism with a simple Bitset
-        return this.elementCount == 0 ||
-            this.elementCount > 0 && this.ackedSeqNums.cardinality() >= this.elementCount;
+        return this.elementCount > 0 && this.ackedSeqNums.cardinality() >= this.elementCount;
     }
 
     public long unreadCount() {

File: logstash-core/src/test/java/org/logstash/ackedqueue/HeadPageTest.java
Patch:
@@ -23,7 +23,7 @@ public void newHeadPage() throws IOException {
         try(final HeadPage p = new HeadPage(0, q, pageIO)) {
             assertThat(p.getPageNum(), is(equalTo(0)));
             assertThat(p.isFullyRead(), is(true));
-            assertThat(p.isFullyAcked(), is(true));
+            assertThat(p.isFullyAcked(), is(false));
             assertThat(p.hasSpace(10), is(true));
             assertThat(p.hasSpace(100), is(false));
         }

File: logstash-core/src/main/java/org/logstash/ackedqueue/Page.java
Patch:
@@ -76,7 +76,8 @@ public boolean isFullyAcked() {
         // TODO: it should be something similar to this when we use a proper bitset class like ES
         // this.ackedSeqNum.firstUnackedBit >= this.elementCount;
         // TODO: for now use a naive & inefficient mechanism with a simple Bitset
-        return this.elementCount > 0 && this.ackedSeqNums.cardinality() >= this.elementCount;
+        return this.elementCount == 0 ||
+            this.elementCount > 0 && this.ackedSeqNums.cardinality() >= this.elementCount;
     }
 
     public long unreadCount() {

File: logstash-core/src/test/java/org/logstash/ackedqueue/HeadPageTest.java
Patch:
@@ -23,7 +23,7 @@ public void newHeadPage() throws IOException {
         try(final HeadPage p = new HeadPage(0, q, pageIO)) {
             assertThat(p.getPageNum(), is(equalTo(0)));
             assertThat(p.isFullyRead(), is(true));
-            assertThat(p.isFullyAcked(), is(false));
+            assertThat(p.isFullyAcked(), is(true));
             assertThat(p.hasSpace(10), is(true));
             assertThat(p.hasSpace(100), is(false));
         }

File: logstash-core/src/main/java/org/logstash/config/ir/graph/algorithms/DepthFirst.java
Patch:
@@ -24,7 +24,7 @@ public static Stream<Vertex> depthFirst(Vertex v) {
     }
 
     public static Stream<Vertex> reverseDepthFirst(Vertex v) {
-        return depthFirst(Collections.singleton(v));
+        return reverseDepthFirst(Collections.singleton(v));
     }
 
     public static Stream<Vertex> depthFirst(Collection<Vertex> v) {

File: logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
Patch:
@@ -51,7 +51,7 @@ public PipelineIR(Graph inputSection, Graph filterSection, Graph outputSection,
 
         this.graph.validate();
 
-        if (this.getOriginalSource() != null && this.getOriginalSource().matches("^\\S+$")) {
+        if (this.getOriginalSource() != null && !this.getOriginalSource().matches("^\\s+$")) {
             uniqueHash = Util.digest(this.getOriginalSource());
         } else {
             uniqueHash = this.graph.uniqueHash();

File: logstash-core/src/test/java/org/logstash/config/ir/PipelineIRTest.java
Patch:
@@ -50,7 +50,7 @@ public void hashingWithoutOriginalSource() throws InvalidIRException {
 
     @Test
     public void hashingWithOriginalSource() throws InvalidIRException {
-        String source = "mysource";
+        String source = "input { stdin {} } output { stdout {} }";
         PipelineIR pipelineIR = new PipelineIR(makeInputSection(), makeFilterSection(), makeOutputSection(), source);
         assertEquals(pipelineIR.uniqueHash(), Util.digest(source));
     }

File: logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
Patch:
@@ -1,5 +1,6 @@
 package org.logstash.config.ir;
 
+import org.logstash.common.Util;
 import org.logstash.config.ir.graph.Graph;
 import org.logstash.config.ir.graph.PluginVertex;
 import org.logstash.config.ir.graph.QueueVertex;
@@ -51,6 +52,8 @@ public PipelineIR(Graph inputSection, Graph filterSection, Graph outputSection,
         this.graph.validate();
 
         if (this.getOriginalSource() != null && this.getOriginalSource().matches("^\\S+$")) {
+            uniqueHash = Util.digest(this.getOriginalSource());
+        } else {
             uniqueHash = this.graph.uniqueHash();
         }
     }

File: logstash-core/src/test/java/org/logstash/TestBase.java
Patch:
@@ -15,9 +15,8 @@ public abstract class TestBase {
     public void setUp() throws Exception {
         if (setupDone) return;
 
-        RubyInstanceConfig config_19 = new RubyInstanceConfig();
-        config_19.setCompatVersion(CompatVersion.RUBY1_9);
-        ruby = Ruby.newInstance(config_19);
+        RubyInstanceConfig config = new RubyInstanceConfig();
+        ruby = Ruby.newInstance(config);
         RubyBigDecimal.createBigDecimal(ruby); // we need to do 'require "bigdecimal"'
         JrubyTimestampExtLibrary.createTimestamp(ruby);
         setupDone = true;

File: logstash-core/src/main/java/org/logstash/config/ir/PluginDefinition.java
Patch:
@@ -12,7 +12,7 @@
 /**
  * Created by andrewvc on 9/20/16.
  */
-public class PluginDefinition implements SourceComponent, Hashable {
+public class PluginDefinition implements SourceComponent, HashableWithSource {
     private static ObjectMapper om = new ObjectMapper();
 
     @Override

File: logstash-core/src/main/java/org/logstash/config/ir/expression/BinaryBooleanExpression.java
Patch:
@@ -1,5 +1,6 @@
 package org.logstash.config.ir.expression;
 
+import org.logstash.common.Util;
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.common.SourceWithMetadata;
@@ -46,8 +47,7 @@ public String toRubyString() {
         return "(" + getLeft().toRubyString() + rubyOperator() + getRight().toRubyString() + ")";
     }
 
-    @Override
-    public String hashSource() {
-        return this.getClass().getCanonicalName() + "[" + getLeft().hashSource() + "|" + getRight().hashSource() + "]";
+    public String uniqueHash() {
+        return Util.digest(this.getClass().getCanonicalName() + "[" + getLeft().hashSource() + "|" + getRight().hashSource() + "]");
     }
 }

File: logstash-core/src/test/java/org/logstash/config/ir/IRHelpers.java
Patch:
@@ -1,6 +1,7 @@
 package org.logstash.config.ir;
 
 import org.hamcrest.MatcherAssert;
+import org.logstash.common.IncompleteSourceWithMetadataException;
 import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BooleanExpression;
 import org.logstash.config.ir.expression.ValueExpression;
@@ -116,8 +117,8 @@ public static BooleanExpression createTestExpression() throws InvalidIRException
         return new Truthy(null, new ValueExpression(null, 1));
     }
 
-    public static SourceWithMetadata testMetadata() {
-        return new SourceWithMetadata("/fake/file", 1, 2, "<fakesource>");
+    public static SourceWithMetadata testMetadata() throws IncompleteSourceWithMetadataException {
+        return new SourceWithMetadata("file", "/fake/file", 1, 2, "<fakesource>");
     }
 
     public static PluginDefinition testPluginDefinition() {

File: logstash-core/src/test/java/org/logstash/config/ir/graph/GraphTest.java
Patch:
@@ -9,6 +9,7 @@
 
 import java.util.Collection;
 import java.util.Collections;
+import java.util.HashSet;
 
 import static org.hamcrest.CoreMatchers.instanceOf;
 import static org.hamcrest.CoreMatchers.is;

File: logstash-core/src/test/java/org/logstash/config/ir/graph/PluginVertexTest.java
Patch:
@@ -1,6 +1,8 @@
 package org.logstash.config.ir.graph;
 
 import org.junit.Test;
+import org.logstash.common.IncompleteSourceWithMetadataException;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.config.ir.PluginDefinition;
 
@@ -25,7 +27,7 @@ public void testConstructionIdHandlingWhenNoExplicitId() throws InvalidIRExcepti
     }
 
     @Test
-    public void testConstructionIdHandlingWhenExplicitId() {
+    public void testConstructionIdHandlingWhenExplicitId() throws IncompleteSourceWithMetadataException {
         String customId = "mycustomid";
         Map<String, Object> pluginArguments = new HashMap<>();
         pluginArguments.put("id", customId);

File: logstash-core/src/main/java/org/logstash/config/ir/graph/IfVertex.java
Patch:
@@ -97,7 +97,7 @@ public IfVertex copy() {
     }
 
     @Override
-    public String individualHashSource() {
+    public String calculateIndividualHashSource() {
         return this.getClass().getCanonicalName() + "{" + this.booleanExpression.hashSource() + "}";
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/graph/QueueVertex.java
Patch:
@@ -17,7 +17,7 @@ public String getId() {
     }
 
     @Override
-    public String individualHashSource() {
+    public String calculateIndividualHashSource() {
         return this.getClass().getCanonicalName();
     }
 

File: logstash-core/src/test/java/org/logstash/config/ir/IRHelpers.java
Patch:
@@ -52,7 +52,7 @@ public Vertex copy() {
         }
 
         @Override
-        public String individualHashSource() {
+        public String calculateIndividualHashSource() {
             return "TVertex" + "|" + id;
         }
 

File: logstash-core/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -36,13 +36,13 @@ public static ConvertedMap<String, Object> newFromMap(Map<String, Object> o) {
     public static ConvertedMap<String, Object> newFromRubyHash(RubyHash o) {
         final ConvertedMap<String, Object> result = new ConvertedMap<>();
 
-        o.visitAll(new RubyHash.Visitor() {
+        o.visitAll(o.getRuntime().getCurrentContext(), new RubyHash.Visitor() {
             @Override
             public void visit(IRubyObject key, IRubyObject value) {
                 String k = String.valueOf(BiValues.newBiValue(key).javaValue()) ;
                 result.put(k, Valuefier.convert(value));
             }
-        });
+        }, null);
         return result;
     }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedBatchExtLibrary.java
Patch:
@@ -59,7 +59,7 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject events,  I
                 context.runtime.newArgumentError("expected queue AckedQueue");
             }
 
-            this.batch = new Batch(((RubyArray)events).getList(), ((RubyArray)seqNums).getList(), ((JrubyAckedQueueExtLibrary.RubyAckedQueue)queue).getQueue());
+            this.batch = new Batch(((RubyArray)events), ((RubyArray)seqNums), ((JrubyAckedQueueExtLibrary.RubyAckedQueue)queue).getQueue());
 
             return context.nil;
         }

File: tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java
Patch:
@@ -24,7 +24,7 @@ final class JsUtil {
 
     private static final String[] SCRIPTS = {
         "shared", "date", "grok", "geoip", "gsub", "pipeline", "convert", "append", "json",
-        "rename", "lowercase"
+        "rename", "lowercase", "set"
     };
 
     private JsUtil() {
@@ -90,7 +90,7 @@ jsFunc, input(options.valueOf(input))
      * Retrieves the input Ingest JSON from a given {@link URI}.
      * @param uri {@link URI} of Ingest JSON
      * @return Json String
-     * @throws IOException On failure to load Ingest JSON 
+     * @throws IOException On failure to load Ingest JSON
      */
     private static String input(final URI uri) throws IOException {
         if ("file".equals(uri.getScheme())) {

File: tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java
Patch:
@@ -13,6 +13,8 @@ public static Iterable<String> data() {
         final Collection<String> cases = new ArrayList<>();
         cases.add("ComplexCase1");
         cases.add("ComplexCase2");
+        cases.add("ComplexCase3");
+        cases.add("ComplexCase4");
         GeoIpTest.data().forEach(cases::add);
         DateTest.data().forEach(cases::add);
         GrokTest.data().forEach(cases::add);
@@ -22,6 +24,7 @@ public static Iterable<String> data() {
         JsonTest.data().forEach(cases::add);
         RenameTest.data().forEach(cases::add);
         LowercaseTest.data().forEach(cases::add);
+        SetTest.data().forEach(cases::add);
         return cases;
     }
 

File: logstash-core/benchmarks/src/main/java/org/logstash/benchmark/QueueWriteBenchmark.java
Patch:
@@ -35,7 +35,7 @@
 @BenchmarkMode(Mode.Throughput)
 @OutputTimeUnit(TimeUnit.MILLISECONDS)
 @State(Scope.Thread)
-public class QueueBenchmark {
+public class QueueWriteBenchmark {
 
     private static final int EVENTS_PER_INVOCATION = 500_000;
 
@@ -76,7 +76,7 @@ public final void pushToPersistedQueue() throws Exception {
 
     public static void main(final String... args) throws RunnerException {
         Options opt = new OptionsBuilder()
-            .include(QueueBenchmark.class.getSimpleName())
+            .include(QueueWriteBenchmark.class.getSimpleName())
             .forks(2)
             .build();
         new Runner(opt).run();

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -255,7 +255,7 @@ public Object remove(String path) {
     }
 
     public String sprintf(String s) throws IOException {
-        return StringInterpolation.getInstance().evaluate(this, s);
+        return StringInterpolation.evaluate(this, s);
     }
 
     @Override

File: logstash-core/src/main/java/org/logstash/Timestamp.java
Patch:
@@ -64,7 +64,7 @@ public static Timestamp now() {
     }
 
     public String toIso8601() {
-        return this.iso8601Formatter.print(this.time);
+        return iso8601Formatter.print(this.time);
     }
 
     public String toString() {

File: tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java
Patch:
@@ -18,7 +18,7 @@ final class JsUtil {
      */
 
     private static final String[] SCRIPTS =
-        {"shared", "date", "grok", "geoip", "gsub", "pipeline", "convert", "append", "json"};
+        {"shared", "date", "grok", "geoip", "gsub", "pipeline", "convert", "append", "json", "rename"};
 
     private JsUtil() {
         // Utility Class

File: tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java
Patch:
@@ -22,6 +22,7 @@ public static Iterable<String> data() {
         GsubTest.data().forEach(cases::add);
         AppendTest.data().forEach(cases::add);
         JsonTest.data().forEach(cases::add);
+        RenameTest.data().forEach(cases::add);
         return cases;
     }
 

File: tools/ingest-converter/src/test/java/org/logstash/ingest/AppendTest.java
Patch:
@@ -15,7 +15,7 @@ public static Iterable<String> data() {
     }
 
     @Test
-    public void convertsConvertProcessorCorrectly() throws Exception {
+    public void convertsAppendProcessorCorrectly() throws Exception {
         final String append = getResultPath(temp);
         Append.main(resourcePath(String.format("ingest%s.json", testCase)), append);
         assertThat(

File: tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java
Patch:
@@ -14,7 +14,7 @@ final class JsUtil {
      */
 
     private static final String[] SCRIPTS =
-        {"shared", "date", "grok", "geoip", "gsub", "pipeline", "convert"};
+        {"shared", "date", "grok", "geoip", "gsub", "pipeline", "convert", "append", "json"};
 
     private JsUtil() {
         // Utility Class

File: tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java
Patch:
@@ -20,6 +20,8 @@ public static Iterable<String> data() {
         GrokTest.data().forEach(cases::add);
         ConvertTest.data().forEach(cases::add);
         GsubTest.data().forEach(cases::add);
+        AppendTest.data().forEach(cases::add);
+        JsonTest.data().forEach(cases::add);
         return cases;
     }
 

File: tools/ingest-converter/src/main/java/org/logstash/ingest/JsUtil.java
Patch:
@@ -12,7 +12,9 @@ final class JsUtil {
     /**
      * Script names used by the converter in correct load order.
      */
-    private static final String[] SCRIPTS = {"shared", "date", "grok", "geoip", "pipeline", "convert"};
+
+    private static final String[] SCRIPTS =
+        {"shared", "date", "grok", "geoip", "gsub", "pipeline", "convert"};
 
     private JsUtil() {
         // Utility Class

File: tools/ingest-converter/src/test/java/org/logstash/ingest/PipelineTest.java
Patch:
@@ -19,6 +19,7 @@ public static Iterable<String> data() {
         DateTest.data().forEach(cases::add);
         GrokTest.data().forEach(cases::add);
         ConvertTest.data().forEach(cases::add);
+        GsubTest.data().forEach(cases::add);
         return cases;
     }
 

File: tools/ingest-converter/src/main/java/org/logstash/ingest/Date.java
Patch:
@@ -19,7 +19,7 @@ private Date() {
 
     public static void main(final String... args) throws ScriptException, NoSuchMethodException {
         try {
-            final ScriptEngine engine = JsUtil.engine("/ingest-date.js");
+            final ScriptEngine engine = JsUtil.engine();
             Files.write(Paths.get(args[1]), ((String) ((Invocable) engine).invokeFunction(
                 "ingest_to_logstash_date",
                 new String(

File: tools/ingest-converter/src/main/java/org/logstash/ingest/Grok.java
Patch:
@@ -19,7 +19,7 @@ private Grok() {
 
     public static void main(final String... args) throws ScriptException, NoSuchMethodException {
         try {
-            final ScriptEngine engine = JsUtil.engine("/ingest-grok.js");
+            final ScriptEngine engine = JsUtil.engine();
             Files.write(Paths.get(args[1]), ((String) ((Invocable) engine).invokeFunction(
                 "ingest_to_logstash_grok",
                 new String(

File: tools/ingest-converter/src/test/java/org/logstash/ingest/IngestTest.java
Patch:
@@ -23,7 +23,7 @@ static String resourcePath(final String name) {
         return IngestTest.class.getResource(name).getPath();
     }
 
-    static String getResultPath(TemporaryFolder temp) throws Exception {
+    static String getResultPath(TemporaryFolder temp) throws IOException {
         return temp.newFolder().toPath().resolve("converted").toString();
     }
 }

File: logstash-core/src/main/java/org/logstash/PathCache.java
Patch:
@@ -28,7 +28,7 @@ public boolean isTimestamp(String reference) {
         return (cache(reference) == this.timestamp);
     }
 
-    public FieldReference cache(String reference) {
+    public static FieldReference cache(String reference) {
         // atomicity between the get and put is not important
         FieldReference result = cache.get(reference);
         if (result == null) {
@@ -38,7 +38,7 @@ public FieldReference cache(String reference) {
         return result;
     }
 
-    public FieldReference cache(String reference, FieldReference field) {
+    public static FieldReference cache(String reference, FieldReference field) {
         cache.put(reference, field);
         return field;
     }

File: logstash-core/src/main/java/org/logstash/StringInterpolation.java
Patch:
@@ -47,7 +47,7 @@ public String evaluate(Event event, String template) throws IOException {
         return compiledTemplate.evaluate(event);
     }
 
-    public TemplateNode compile(String template) {
+    public static TemplateNode compile(String template) {
         Template compiledTemplate = new Template();
 
         if (template.indexOf('%') == -1) {
@@ -83,7 +83,7 @@ public TemplateNode compile(String template) {
         }
     }
 
-    public TemplateNode identifyTag(String tag) {
+    public static TemplateNode identifyTag(String tag) {
         if(tag.equals("+%s")) {
             return new EpochNode();
         } else if(tag.charAt(0) == '+') {
@@ -97,4 +97,4 @@ public TemplateNode identifyTag(String tag) {
     static StringInterpolation getInstance() {
         return HoldCurrent.INSTANCE;
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -166,7 +166,7 @@ public void open() throws IOException {
         lock.lock();
         try {
             // verify exclusive access to the dirPath
-            this.dirLock = FileLockFactory.getDefault().obtainLock(this.dirPath, LOCK_NAME);
+            this.dirLock = FileLockFactory.obtainLock(this.dirPath, LOCK_NAME);
 
             Checkpoint headCheckpoint;
             try {
@@ -671,7 +671,7 @@ public void close() throws IOException {
 
             } finally {
                 try {
-                    FileLockFactory.getDefault().releaseLock(this.dirLock);
+                    FileLockFactory.releaseLock(this.dirLock);
                 } catch (IOException e) {
                     // log error and ignore
                     logger.error("Queue close releaseLock failed, error={}", e.getMessage());

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/FileCheckpointIO.java
Patch:
@@ -100,7 +100,7 @@ public String tailFileName(int pageNum) {
         return TAIL_CHECKPOINT + pageNum;
     }
 
-    private Checkpoint read(BufferedChecksumStreamInput crcsi) throws IOException {
+    private static Checkpoint read(BufferedChecksumStreamInput crcsi) throws IOException {
         int version = (int) crcsi.readShort();
         // TODO - build reader for this version
         int pageNum = crcsi.readInt();

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/MemoryCheckpointIO.java
Patch:
@@ -9,8 +9,8 @@
 
 public class MemoryCheckpointIO implements CheckpointIO {
 
-    private final String HEAD_CHECKPOINT = "checkpoint.head";
-    private final String TAIL_CHECKPOINT = "checkpoint.";
+    private static final String HEAD_CHECKPOINT = "checkpoint.head";
+    private static final String TAIL_CHECKPOINT = "checkpoint.";
 
     private static final Map<String, Map<String, Checkpoint>> sources = new HashMap<>();
 

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Edge.java
Patch:
@@ -57,7 +57,7 @@ public Edge(Vertex from, Vertex to) throws InvalidIRException {
             throw new Vertex.InvalidEdgeTypeException(String.format("Invalid outgoing edge %s for edge %s", this.from, this));
         }
 
-        if (!this.to.acceptsIncomingEdge(this)) {
+        if (!Vertex.acceptsIncomingEdge(this)) {
             throw new Vertex.InvalidEdgeTypeException(String.format("Invalid incoming edge %s for edge %s", this.from, this));
         }
     }

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
Patch:
@@ -189,7 +189,7 @@ public boolean isPartialLeaf() {
        return getUnusedOutgoingEdgeFactories().size() > 0;
     }
 
-    public boolean acceptsIncomingEdge(Edge e) {
+    public static boolean acceptsIncomingEdge(Edge e) {
         return true;
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/graph/algorithms/GraphDiff.java
Patch:
@@ -86,7 +86,7 @@ public String toString() {
             return output.toString();
         }
 
-        private String detailedDiffFor(String name, Collection removed, Collection added) {
+        private static String detailedDiffFor(String name, Collection removed, Collection added) {
             return (name + " GraphDiff: " + "\n") +
                     "--------------------------\n" +
                     Stream.concat(removed.stream().map(c -> "-" + c.toString()),

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/Statement.java
Patch:
@@ -21,7 +21,7 @@ public String toString() {
 
     public abstract String toString(int indent);
 
-    public String indentPadding(int length) {
+    public static String indentPadding(int length) {
         return String.format("%" + length + "s", "");
     }
 }

File: logstash-core/src/main/java/org/logstash/instrument/monitors/HotThreadsMonitor.java
Patch:
@@ -53,7 +53,7 @@ public static class ThreadReport {
             map.put(THREAD_STACKTRACE, stackTraceAsString(info.getStackTrace()));
         }
 
-        private List<String> stackTraceAsString(StackTraceElement [] elements) {
+        private static List<String> stackTraceAsString(StackTraceElement[] elements) {
             return Arrays.stream(elements)
                             .map(StackTraceElement::toString)
                             .collect(Collectors.toList());
@@ -164,12 +164,12 @@ public List<ThreadReport> detect(Map<String, String> options) {
         return sort(new ArrayList<>(reports.values()), type);
      }
 
-    private List<ThreadReport> sort(List<ThreadReport> reports, final String type) {
+    private static List<ThreadReport> sort(List<ThreadReport> reports, final String type) {
         reports.sort(comparatorForOrderType(type));
         return reports;
     }
 
-    private Comparator<ThreadReport> comparatorForOrderType(final String type){
+    private static Comparator<ThreadReport> comparatorForOrderType(final String type){
         if ("block".equals(type)){
             return Comparator.comparingLong(ThreadReport::getBlockedTime).reversed();
         } else if ("wait".equals(type)) {

File: logstash-core/src/main/java/org/logstash/instrument/monitors/ProcessMonitor.java
Patch:
@@ -62,7 +62,7 @@ public Map<String, Object> toMap() {
             return map;
         }
 
-        private short scaleLoadToPercent(double load) {
+        private static short scaleLoadToPercent(double load) {
             if (osMxBean instanceof UnixOperatingSystemMXBean) {
                 if (load >= 0) {
                     return (short) (load * 100);
@@ -75,7 +75,7 @@ private short scaleLoadToPercent(double load) {
         }
     }
 
-    public Report detect() {
+    public static Report detect() {
         return new Report();
     }
 }

File: logstash-core/src/main/java/org/logstash/instrument/monitors/SystemMonitor.java
Patch:
@@ -33,7 +33,7 @@ public Map<String, Object> toMap() {
         }
     }
 
-    public Report detect() {
+    public static Report detect() {
         return new Report(ManagementFactory.getOperatingSystemMXBean());
     }
 }

File: logstash-core/src/main/java/org/logstash/instrument/reports/ProcessReport.java
Patch:
@@ -12,6 +12,6 @@ private ProcessReport() { }
      * @return a Map with the current process report
      */
     public static Map<String, Object> generate() {
-        return new ProcessMonitor().detect().toMap();
+        return ProcessMonitor.detect().toMap();
     }
 }

File: logstash-core/src/main/java/org/logstash/instrument/reports/SystemReport.java
Patch:
@@ -15,7 +15,7 @@ public class SystemReport {
      * @return a Map with the current system report
      */
     public static Map<String, Object> generate() {
-        return new SystemMonitor().detect().toMap();
+        return SystemMonitor.detect().toMap();
     }
 }
 

File: logstash-core/src/test/java/org/logstash/FileLockFactoryMain.java
Patch:
@@ -9,7 +9,7 @@ public class FileLockFactoryMain {
 
     public static void main(String[] args) {
         try {
-            FileLockFactory.getDefault().obtainLock(args[0], args[1]);
+            FileLockFactory.obtainLock(args[0], args[1]);
             System.out.println("File locked");
             // Sleep enough time until this process is killed.
             Thread.sleep(Long.MAX_VALUE);

File: logstash-core/src/test/java/org/logstash/instruments/monitors/ProcessMonitorTest.java
Patch:
@@ -14,14 +14,14 @@ public class ProcessMonitorTest {
 
     @Test
     public void testReportFDStats(){
-        Map<String, Object> processStats = new ProcessMonitor().detect().toMap();
+        Map<String, Object> processStats = ProcessMonitor.detect().toMap();
         assertThat("open_file_descriptors", (Long)processStats.get("open_file_descriptors") > 0L, is(true));
         assertThat("max_file_descriptors", (Long)processStats.get("max_file_descriptors") > 0L, is(true));
     }
 
     @Test
     public void testReportCpuStats(){
-        Map<String, Object> processStats = new ProcessMonitor().detect().toMap();
+        Map<String, Object> processStats = ProcessMonitor.detect().toMap();
         assertThat("cpu", processStats.get("cpu"), instanceOf(Map.class));
         Map cpuStats = ((Map)processStats.get("cpu"));
         assertThat("cpu.process_percent", (Short)cpuStats.get("process_percent") >= 0, is(true));
@@ -31,7 +31,7 @@ public void testReportCpuStats(){
 
     @Test
     public void testReportMemStats() {
-        Map<String, Object> processStats = new ProcessMonitor().detect().toMap();
+        Map<String, Object> processStats = ProcessMonitor.detect().toMap();
         assertThat("mem", processStats.get("mem"), instanceOf(Map.class));
         Map memStats = ((Map)processStats.get("mem"));
         assertThat("mem.total_virtual_in_bytes", (Long)memStats.get("total_virtual_in_bytes") >= 0L, is(true));

File: logstash-core/src/test/java/org/logstash/instruments/monitors/SystemMonitorTest.java
Patch:
@@ -13,7 +13,7 @@ public class SystemMonitorTest {
 
     @Test
     public void systemMonitorTest(){
-        Map<String, Object> map = new SystemMonitor().detect().toMap();
+        Map<String, Object> map = SystemMonitor.detect().toMap();
         assertThat("system.load_average is missing", (Double)map.get("system.load_average") > 0, is(true));
         assertThat("system.available_processors is missing ", ((Integer)map.get("system.available_processors")) > 0, is(true));
         assertThat("os.version is missing", map.get("os.version"), allOf(notNullValue(), instanceOf(String.class)));

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -297,7 +297,9 @@ public void randomAcking() throws IOException {
         // 10 tests of random queue sizes
         for (int loop = 0; loop < 10; loop++) {
             int page_count = random.nextInt(10000) + 1;
-            int digits = new Double(Math.ceil(Math.log10(page_count))).intValue();
+
+            // String format call below needs to at least print one digit
+            final int digits = Math.max((int) Math.ceil(Math.log10(page_count)), 1);
 
             // create a queue with a single element per page
             List<Queueable> elements = new ArrayList<>();

File: tools/ingest-converter/src/main/java/org/logstash/ingest/Grok.java
Patch:
@@ -22,14 +22,14 @@ private Grok() {
 
     public static void main(final String... args) throws ScriptException, NoSuchMethodException {
         try (final Reader reader = new InputStreamReader(
-                     Grok.class.getResourceAsStream("/ingest-to-grok.js")
+                     Grok.class.getResourceAsStream("/ingest-grok.js")
              )
         ) {
             final ScriptEngine engine =
                 new ScriptEngineManager().getEngineByName("nashorn");
             engine.eval(reader);
             Files.write(Paths.get(args[1]), ((String) ((Invocable) engine).invokeFunction(
-                "json_to_grok",
+                "ingest_to_logstash_grok",
                 new String(
                     Files.readAllBytes(Paths.get(args[0])), StandardCharsets.UTF_8
                 )

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/AbstractByteBufferPageIO.java
Patch:
@@ -27,6 +27,9 @@ public class PageIOInvalidVersionException extends IOException {
     public static final int HEADER_SIZE = 1;     // version byte
     public static final int MIN_CAPACITY = VERSION_SIZE + SEQNUM_SIZE + LENGTH_SIZE + 1 + CHECKSUM_SIZE; // header overhead plus elements overhead to hold a single 1 byte element
 
+    // Size of: Header + Sequence Number + Length + Checksum
+    public static final int WRAPPER_SIZE = HEADER_SIZE + SEQNUM_SIZE + LENGTH_SIZE + CHECKSUM_SIZE;
+
     public static final boolean VERIFY_CHECKSUM = true;
     public static final boolean STRICT_CAPACITY = true;
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/ByteBufferPageIO.java
Patch:
@@ -47,9 +47,6 @@ public void close() { /* don't look here */ }
 
     // below public methods only used by tests
 
-    // TODO: static method for tests - should refactor
-    public static int _persistedByteCount(int byteCount) { return SEQNUM_SIZE + LENGTH_SIZE + byteCount + CHECKSUM_SIZE; }
-
     public int getWritePosition() { return this.head; }
 
     public byte[] dump() { return this.buffer.array(); }

File: logstash-core/src/main/java/org/logstash/Timestamp.java
Patch:
@@ -11,8 +11,9 @@
 
 import java.io.IOException;
 import java.util.Date;
+import org.logstash.json.TimestampSerializer;
 
-@JsonSerialize(using = org.logstash.json.TimestampSerializer.class)
+@JsonSerialize(using = TimestampSerializer.class)
 public class Timestamp implements Cloneable, Comparable, Queueable {
 
     // all methods setting the time object must set it in the UTC timezone

File: logstash-core/src/main/java/org/logstash/FileLockFactory.java
Patch:
@@ -114,6 +114,7 @@ public void releaseLock(FileLock lock) throws IOException {
         String lockPath = LOCK_MAP.remove(lock);
         if (lockPath == null) { throw new LockException("Cannot release unobtained lock"); }
         lock.release();
+        lock.channel().close();
         Boolean removed = LOCK_HELD.remove(lockPath);
         if (removed == false) { throw new LockException("Lock path was not marked as held: " + lockPath); }
     }

File: logstash-core/src/main/java/org/logstash/common/io/RecordIOReader.java
Patch:
@@ -18,8 +18,6 @@
  */
 package org.logstash.common.io;
 
-import org.logstash.Timestamp;
-
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.channels.ClosedByInterruptException;
@@ -28,7 +26,6 @@
 import java.nio.file.StandardOpenOption;
 import java.util.Comparator;
 import java.util.function.Function;
-import java.util.function.Supplier;
 import java.util.zip.CRC32;
 import java.util.zip.Checksum;
 

File: logstash-core/src/main/java/org/logstash/config/ir/InvalidIRException.java
Patch:
@@ -1,7 +1,5 @@
 package org.logstash.config.ir;
 
-import org.logstash.config.ir.graph.algorithms.TopologicalSort;
-
 /**
  * Created by andrewvc on 9/6/16.
  */

File: logstash-core/src/main/java/org/logstash/config/ir/PipelineIR.java
Patch:
@@ -1,6 +1,5 @@
 package org.logstash.config.ir;
 
-import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
 import org.logstash.config.ir.graph.PluginVertex;
 import org.logstash.config.ir.graph.QueueVertex;

File: logstash-core/src/main/java/org/logstash/config/ir/graph/BooleanEdge.java
Patch:
@@ -4,8 +4,6 @@
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
 
-import java.util.Objects;
-
 /**
  * Created by andrewvc on 9/15/16.
  */

File: logstash-core/src/main/java/org/logstash/config/ir/graph/algorithms/GraphDiff.java
Patch:
@@ -6,7 +6,6 @@
 
 import java.util.Collection;
 import java.util.List;
-import java.util.function.Function;
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
@@ -97,4 +96,4 @@ private String detailedDiffFor(String name, Collection removed, Collection added
                     "\n--------------------------";
         }
     }
-}
\ No newline at end of file
+}

File: logstash-core/src/main/java/org/logstash/config/ir/graph/algorithms/ShortestPath.java
Patch:
@@ -2,7 +2,6 @@
 
 import org.logstash.config.ir.graph.Vertex;
 
-import java.security.cert.CollectionCertStoreParameters;
 import java.util.*;
 import java.util.stream.Collectors;
 import java.util.stream.Stream;

File: logstash-core/src/main/java/org/logstash/log/StructuredMessage.java
Patch:
@@ -3,7 +3,6 @@
 import com.fasterxml.jackson.databind.annotation.JsonSerialize;
 import org.apache.logging.log4j.message.Message;
 
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/Page.java
Patch:
@@ -154,7 +154,4 @@ protected long firstUnackedSeqNum() {
         return this.ackedSeqNums.nextClearBit(0) + this.minSeqNum;
     }
 
-    protected int firstUnackedPageNumFromQueue() {
-        return queue.firstUnackedPageNum();
-    }
 }

File: logstash-core/src/main/java/org/logstash/Timestamp.java
Patch:
@@ -18,7 +18,6 @@ public class Timestamp implements Cloneable, Comparable, Queueable {
     // all methods setting the time object must set it in the UTC timezone
     private DateTime time;
 
-    // TODO: is this DateTimeFormatter thread safe?
     private static DateTimeFormatter iso8601Formatter = ISODateTimeFormat.dateTime();
 
     private static final LocalDateTime JAN_1_1970 = new LocalDateTime(1970, 1, 1, 0, 0);

File: logstash-core/benchmarks/src/main/java/org/logstash/benchmark/QueueBenchmark.java
Patch:
@@ -87,8 +87,8 @@ private static Settings settings() {
             .capacity(256 * 1024 * 1024)
             .queueMaxBytes(Long.MAX_VALUE)
             .elementIOFactory(MmapPageIO::new)
-            .checkpointMaxWrites(50_000)
-            .checkpointMaxAcks(50_000)
+            .checkpointMaxWrites(1024)
+            .checkpointMaxAcks(1024)
             .checkpointIOFactory(FileCheckpointIO::new)
             .elementClass(Event.class).build();
     }

File: logstash-core/src/main/java/org/logstash/instrument/reports/MemoryReport.java
Patch:
@@ -16,7 +16,9 @@ public class MemoryReport {
 
     /**
      * Build a report with current Memory information
-     * @return
+     * @return Returns a Map containing information about the
+     *         current state of the Java memory pools
+     *
      */
     public static Map<String, Map<String, Map<String, Object>>> generate() {
         MemoryMonitor.Report report = generateReport(MemoryMonitor.Type.All);

File: logstash-core/src/main/java/org/logstash/common/DeadLetterQueueFactory.java
Patch:
@@ -44,13 +44,13 @@ private DeadLetterQueueFactory() {
     }
 
     /**
-     * Retrieves an existing {@link DeadLetterQueueWriter} associated with {@param id}, or
+     * Retrieves an existing {@link DeadLetterQueueWriter} associated with the given id, or
      * opens a new one to be returned. It is the retrievers responsibility to close these newly
      * created writers.
      *
      * @param id The identifier context for this dlq manager
      * @param dlqPath The path to use for the queue's backing data directory. contains sub-directories
-     *                for each {@param id}
+     *                for each id
      * @return The write manager for the specific id's dead-letter-queue context
      */
     public static DeadLetterQueueWriter getWriter(String id, String dlqPath) {

File: logstash-core/src/main/java/org/logstash/ackedqueue/HeadPage.java
Patch:
@@ -9,13 +9,13 @@
 public class HeadPage extends Page {
 
     // create a new HeadPage object and new page.{pageNum} empty valid data file
-    public HeadPage(int pageNum, Queue queue, PageIO pageIO) throws IOException {
+    public HeadPage(int pageNum, Queue queue, PageIO pageIO) {
         super(pageNum, queue, 0, 0, 0, new BitSet(), pageIO);
     }
 
     // create a new HeadPage object from an existing checkpoint and open page.{pageNum} empty valid data file
     // @param pageIO is expected to be open/recover/create
-    public HeadPage(Checkpoint checkpoint, Queue queue, PageIO pageIO) throws IOException {
+    public HeadPage(Checkpoint checkpoint, Queue queue, PageIO pageIO) {
         super(checkpoint.getPageNum(), queue, checkpoint.getMinSeqNum(), checkpoint.getElementCount(), checkpoint.getFirstUnackedSeqNum(), new BitSet(), pageIO);
 
         assert checkpoint.getMinSeqNum() == pageIO.getMinSeqNum() && checkpoint.getElementCount() == pageIO.getElementCount() :

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/AbstractByteBufferPageIO.java
Patch:
@@ -248,7 +248,7 @@ public SequencedList<byte[]> read(long seqNum, int limit) throws IOException {
             }
         }
 
-        return new SequencedList<byte[]>(elements, seqNums);
+        return new SequencedList<>(elements, seqNums);
     }
 
     @Override

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/FileCheckpointIO.java
Patch:
@@ -35,10 +35,10 @@ public class FileCheckpointIO  implements CheckpointIO {
             + Integer.BYTES  // eventCount
             + Integer.BYTES;    // checksum
 
+    private static final String HEAD_CHECKPOINT = "checkpoint.head";
+    private static final String TAIL_CHECKPOINT = "checkpoint.";
+    private static final OpenOption[] WRITE_OPTIONS = { WRITE, CREATE, TRUNCATE_EXISTING, DSYNC };
     private final String dirPath;
-    private final String HEAD_CHECKPOINT = "checkpoint.head";
-    private final String TAIL_CHECKPOINT = "checkpoint.";
-    private final OpenOption[] WRITE_OPTIONS = new OpenOption[] { WRITE, CREATE, TRUNCATE_EXISTING, DSYNC };
 
     public FileCheckpointIO(String dirPath) {
         this.dirPath = dirPath;

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/MmapPageIO.java
Patch:
@@ -21,7 +21,7 @@ public class MmapPageIO extends AbstractByteBufferPageIO {
     private FileChannel channel;
     protected MappedByteBuffer buffer;
 
-    public MmapPageIO(int pageNum, int capacity, String dirPath) throws IOException {
+    public MmapPageIO(int pageNum, int capacity, String dirPath) {
         super(pageNum, capacity);
 
         this.file = Paths.get(dirPath, "page." + pageNum).toFile();

File: logstash-core/src/test/java/org/logstash/config/ir/IRHelpers.java
Patch:
@@ -124,7 +124,7 @@ public static PluginDefinition testPluginDefinition() {
         return new PluginDefinition(PluginDefinition.Type.FILTER, "testDefinition", new HashMap<String, Object>());
     }
 
-    public static Pipeline samplePipeline() throws InvalidIRException {
+    public static PipelineIR samplePipeline() throws InvalidIRException {
         Graph inputSection = iComposeParallel(iPlugin(INPUT, "generator"), iPlugin(INPUT, "stdin")).toGraph();
         Graph filterSection = iIf(eEq(eEventValue("[foo]"), eEventValue("[bar]")),
                                     iPlugin(FILTER, "grok"),
@@ -135,6 +135,6 @@ public static Pipeline samplePipeline() throws InvalidIRException {
                                             iPlugin(OUTPUT, "elasticsearch")),
                                     iPlugin(OUTPUT, "stdout")).toGraph();
 
-        return new Pipeline(inputSection, filterSection, outputSection);
+        return new PipelineIR(inputSection, filterSection, outputSection);
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/BaseSourceComponent.java
Patch:
@@ -16,7 +16,7 @@ public BaseSourceComponent(SourceWithMetadata meta) {
         this.meta = meta;
     }
 
-    public SourceWithMetadata getMeta() {
+    public SourceWithMetadata getSourceWithMetadata() {
         return meta;
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/Pipeline.java
Patch:
@@ -1,5 +1,6 @@
 package org.logstash.config.ir;
 
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
 import org.logstash.config.ir.graph.PluginVertex;
 import org.logstash.config.ir.graph.QueueVertex;

File: logstash-core/src/main/java/org/logstash/config/ir/PluginDefinition.java
Patch:
@@ -97,7 +97,7 @@ public boolean sourceComponentEquals(SourceComponent o) {
     }
 
     @Override
-    public SourceWithMetadata getMeta() {
+    public SourceWithMetadata getSourceWithMetadata() {
         return null;
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/SourceComponent.java
Patch:
@@ -7,5 +7,5 @@
  */
 public interface SourceComponent {
     boolean sourceComponentEquals(SourceComponent sourceComponent);
-    SourceWithMetadata getMeta();
+    SourceWithMetadata getSourceWithMetadata();
 }

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Edge.java
Patch:
@@ -93,7 +93,7 @@ public boolean sourceComponentEquals(SourceComponent sourceComponent) {
     public abstract String getId();
 
     @Override
-    public SourceWithMetadata getMeta() {
+    public SourceWithMetadata getSourceWithMetadata() {
         return null;
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Graph.java
Patch:
@@ -403,7 +403,7 @@ public boolean hasEquivalentVertex(Vertex otherV) {
     }
 
     @Override
-    public SourceWithMetadata getMeta() {
+    public SourceWithMetadata getSourceWithMetadata() {
         return null;
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/graph/IfVertex.java
Patch:
@@ -43,7 +43,7 @@ public boolean sourceComponentEquals(SourceComponent other) {
 
     // An IfVertex has no real metadata in and of itself, but its expression does!
     @Override
-    public SourceWithMetadata getMeta() {
+    public SourceWithMetadata getSourceWithMetadata() {
         return null;
     }
 
@@ -83,7 +83,7 @@ public Collection<BooleanEdge> getOutgoingBooleanEdgesByType(Boolean edgeType) {
     // The easiest readable version of this for a human.
     // If the original source is available we use that, otherwise we serialize the expression
     public String humanReadableExpression() {
-        String sourceText = this.booleanExpression.getMeta() != null ? this.booleanExpression.getMeta().getText() : null;
+        String sourceText = this.booleanExpression.getSourceWithMetadata() != null ? this.booleanExpression.getSourceWithMetadata().getText() : null;
         if (sourceText != null) {
             return sourceText;
         } else {
@@ -93,7 +93,7 @@ public String humanReadableExpression() {
 
     @Override
     public IfVertex copy() {
-        return new IfVertex(getMeta(),getBooleanExpression());
+        return new IfVertex(getSourceWithMetadata(),getBooleanExpression());
     }
 
     @Override

File: logstash-core/src/main/java/org/logstash/config/ir/graph/PluginVertex.java
Patch:
@@ -27,7 +27,7 @@ public PluginDefinition getPluginDefinition() {
         return pluginDefinition;
     }
     @Override
-    public SourceWithMetadata getMeta() {
+    public SourceWithMetadata getSourceWithMetadata() {
         return meta;
     }
 
@@ -43,7 +43,7 @@ public PluginVertex(SourceWithMetadata meta, PluginDefinition pluginDefinition)
     }
 
     public String toString() {
-        return "P[" + pluginDefinition + "|" + this.getMeta() + "]";
+        return "P[" + pluginDefinition + "|" + this.getSourceWithMetadata() + "]";
     }
 
     @Override

File: logstash-core/src/main/java/org/logstash/config/ir/graph/QueueVertex.java
Patch:
@@ -38,7 +38,7 @@ public boolean sourceComponentEquals(SourceComponent other) {
 
     // Special vertices really have no metadata
     @Override
-    public SourceWithMetadata getMeta() {
+    public SourceWithMetadata getSourceWithMetadata() {
         return null;
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/IfStatement.java
Patch:
@@ -89,7 +89,7 @@ public Graph toGraph() throws InvalidIRException {
         Collection<Vertex> trueRoots = trueGraph.roots().map(combination.oldToNewVertices::get).collect(Collectors.toList());
         Collection<Vertex> falseRoots = falseGraph.roots().map(combination.oldToNewVertices::get).collect(Collectors.toList());
 
-        IfVertex ifVertex = new IfVertex(this.getMeta(), this.booleanExpression);
+        IfVertex ifVertex = new IfVertex(this.getSourceWithMetadata(), this.booleanExpression);
         newGraph.addVertex(ifVertex);
 
         for (Vertex v : trueRoots) {

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/PluginStatement.java
Patch:
@@ -37,7 +37,7 @@ public String toString(int indent) {
 
     @Override
     public Graph toGraph() throws InvalidIRException {
-        Vertex pluginVertex = new PluginVertex(getMeta(), pluginDefinition);
+        Vertex pluginVertex = new PluginVertex(getSourceWithMetadata(), pluginDefinition);
         Graph g = Graph.empty();
         g.addVertex(pluginVertex);
         return g;

File: logstash-core/src/test/java/org/logstash/config/ir/IRHelpers.java
Patch:
@@ -75,7 +75,7 @@ public boolean sourceComponentEquals(SourceComponent other) {
         }
 
         @Override
-        public SourceWithMetadata getMeta() {
+        public SourceWithMetadata getSourceWithMetadata() {
             return null;
         }
     }

File: logstash-core/src/main/java/org/logstash/ackedqueue/io/PageIO.java
Patch:
@@ -37,6 +37,9 @@ public interface PageIO extends Closeable {
     // @return the data container total capacity in bytes
     int getCapacity();
 
+    // @return the current head offset within the page
+    int getHead();
+
     // @return the actual persisted byte count (with overhead) for the given data bytes
     int persistedByteCount(int bytes);
 

File: logstash-core/src/main/java/org/logstash/config/ir/PluginDefinition.java
Patch:
@@ -2,6 +2,7 @@
 
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.ObjectMapper;
+import org.logstash.common.SourceWithMetadata;
 
 import java.util.HashSet;
 import java.util.Map;
@@ -96,7 +97,7 @@ public boolean sourceComponentEquals(SourceComponent o) {
     }
 
     @Override
-    public SourceMetadata getMeta() {
+    public SourceWithMetadata getMeta() {
         return null;
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/SourceComponent.java
Patch:
@@ -1,9 +1,11 @@
 package org.logstash.config.ir;
 
+import org.logstash.common.SourceWithMetadata;
+
 /**
  * Created by andrewvc on 9/16/16.
  */
 public interface SourceComponent {
     boolean sourceComponentEquals(SourceComponent sourceComponent);
-    SourceMetadata getMeta();
+    SourceWithMetadata getMeta();
 }

File: logstash-core/src/main/java/org/logstash/config/ir/expression/BinaryBooleanExpression.java
Patch:
@@ -2,7 +2,7 @@
 
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 
 /**
  * Created by andrewvc on 9/6/16.
@@ -31,7 +31,7 @@ public Expression getLeft() {
         return left;
     }
 
-    public BinaryBooleanExpression(SourceMetadata meta,
+    public BinaryBooleanExpression(SourceWithMetadata meta,
                                    Expression left,
                                    Expression right) throws InvalidIRException {
         super(meta);

File: logstash-core/src/main/java/org/logstash/config/ir/expression/BooleanExpression.java
Patch:
@@ -1,12 +1,12 @@
 package org.logstash.config.ir.expression;
 
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 
 /**
  * Created by andrewvc on 9/14/16.
  */
 public abstract class BooleanExpression extends Expression {
-    public BooleanExpression(SourceMetadata meta) {
+    public BooleanExpression(SourceWithMetadata meta) {
         super(meta);
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/expression/EventValueExpression.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.expression;
 
 import org.logstash.config.ir.SourceComponent;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 
 /**
  * Created by andrewvc on 9/13/16.
  */
 public class EventValueExpression extends Expression {
     private final String fieldName;
 
-    public EventValueExpression(SourceMetadata meta, String fieldName) {
+    public EventValueExpression(SourceWithMetadata meta, String fieldName) {
         super(meta);
         this.fieldName = fieldName;
     }

File: logstash-core/src/main/java/org/logstash/config/ir/expression/Expression.java
Patch:
@@ -5,7 +5,7 @@
 import org.jruby.embed.ScriptingContainer;
 import org.logstash.config.ir.Hashable;
 import org.logstash.config.ir.BaseSourceComponent;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 
 /*
  * [foo] == "foostr" eAnd [bar] > 10
@@ -18,7 +18,7 @@
 public abstract class Expression extends BaseSourceComponent implements Hashable {
     private ScriptingContainer container;
 
-    public Expression(SourceMetadata meta) {
+    public Expression(SourceWithMetadata meta) {
         super(meta);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/RegexValueExpression.java
Patch:
@@ -4,9 +4,8 @@
 import org.joni.Regex;
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 
-import java.nio.charset.Charset;
 import java.nio.charset.StandardCharsets;
 
 /**
@@ -15,7 +14,7 @@
 public class RegexValueExpression extends ValueExpression {
     private final Regex regex;
 
-    public RegexValueExpression(SourceMetadata meta, Object value) throws InvalidIRException {
+    public RegexValueExpression(SourceWithMetadata meta, Object value) throws InvalidIRException {
         super(meta, value);
 
         if (!(value instanceof String)) {

File: logstash-core/src/main/java/org/logstash/config/ir/expression/UnaryBooleanExpression.java
Patch:
@@ -1,7 +1,7 @@
 package org.logstash.config.ir.expression;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 
 /**
  * Created by andrewvc on 9/13/16.
@@ -13,7 +13,7 @@ public Expression getExpression() {
         return expression;
     }
 
-    public UnaryBooleanExpression(SourceMetadata meta,
+    public UnaryBooleanExpression(SourceWithMetadata meta,
                                    Expression expression) throws InvalidIRException {
         super(meta);
         if (expression == null) throw new InvalidIRException("Unary expressions cannot operate on null!");

File: logstash-core/src/main/java/org/logstash/config/ir/expression/ValueExpression.java
Patch:
@@ -2,7 +2,7 @@
 
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 
 import java.math.BigDecimal;
 import java.util.List;
@@ -13,7 +13,7 @@
 public class ValueExpression extends Expression {
     protected final Object value;
 
-    public ValueExpression(SourceMetadata meta, Object value) throws InvalidIRException {
+    public ValueExpression(SourceWithMetadata meta, Object value) throws InvalidIRException {
         super(meta);
 
         if (!(value == null ||

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/And.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.expression.binary;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class And extends BinaryBooleanExpression {
-    public And(SourceMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public And(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Eq.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.expression.binary;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class Eq extends BinaryBooleanExpression {
-    public Eq(SourceMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Eq(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Gt.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.expression.binary;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class Gt extends BinaryBooleanExpression {
-    public Gt(SourceMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Gt(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Gte.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.expression.binary;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class Gte extends BinaryBooleanExpression {
-    public Gte(SourceMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Gte(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/In.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.expression.binary;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class In extends BinaryBooleanExpression {
-    public In(SourceMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public In(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Lt.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.expression.binary;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class Lt extends BinaryBooleanExpression {
-    public Lt(SourceMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Lt(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Lte.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.expression.binary;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class Lte extends BinaryBooleanExpression {
-    public Lte(SourceMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Lte(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Neq.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.expression.binary;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class Neq extends BinaryBooleanExpression {
-    public Neq(SourceMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Neq(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/Or.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.expression.binary;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class Or extends BinaryBooleanExpression {
-    public Or(SourceMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public Or(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/binary/RegexEq.java
Patch:
@@ -1,7 +1,7 @@
 package org.logstash.config.ir.expression.binary;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BinaryBooleanExpression;
 import org.logstash.config.ir.expression.Expression;
 import org.logstash.config.ir.expression.RegexValueExpression;
@@ -10,7 +10,7 @@
  * Created by andrewvc on 9/21/16.
  */
 public class RegexEq extends BinaryBooleanExpression {
-    public RegexEq(SourceMetadata meta, Expression left, Expression right) throws InvalidIRException {
+    public RegexEq(SourceWithMetadata meta, Expression left, Expression right) throws InvalidIRException {
         super(meta, left, right);
 
         if (!(right instanceof RegexValueExpression)) {

File: logstash-core/src/main/java/org/logstash/config/ir/expression/unary/Not.java
Patch:
@@ -2,15 +2,15 @@
 
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.Expression;
 import org.logstash.config.ir.expression.UnaryBooleanExpression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class Not extends UnaryBooleanExpression {
-    public Not(SourceMetadata meta, Expression expression) throws InvalidIRException {
+    public Not(SourceWithMetadata meta, Expression expression) throws InvalidIRException {
         super(meta, expression);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/expression/unary/Truthy.java
Patch:
@@ -2,15 +2,15 @@
 
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.Expression;
 import org.logstash.config.ir.expression.UnaryBooleanExpression;
 
 /**
  * Created by andrewvc on 9/21/16.
  */
 public class Truthy extends UnaryBooleanExpression {
-    public Truthy(SourceMetadata meta, Expression expression) throws InvalidIRException {
+    public Truthy(SourceWithMetadata meta, Expression expression) throws InvalidIRException {
         super(meta, expression);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Edge.java
Patch:
@@ -2,7 +2,7 @@
 
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 
 import java.util.stream.Stream;
 
@@ -93,7 +93,7 @@ public boolean sourceComponentEquals(SourceComponent sourceComponent) {
     public abstract String getId();
 
     @Override
-    public SourceMetadata getMeta() {
+    public SourceWithMetadata getMeta() {
         return null;
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Graph.java
Patch:
@@ -4,7 +4,7 @@
 import org.logstash.config.ir.Hashable;
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.algorithms.BreadthFirst;
 import org.logstash.config.ir.graph.algorithms.GraphDiff;
 import org.logstash.config.ir.graph.algorithms.TopologicalSort;
@@ -403,7 +403,7 @@ public boolean hasEquivalentVertex(Vertex otherV) {
     }
 
     @Override
-    public SourceMetadata getMeta() {
+    public SourceWithMetadata getMeta() {
         return null;
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/graph/QueueVertex.java
Patch:
@@ -1,7 +1,7 @@
 package org.logstash.config.ir.graph;
 
 import org.logstash.config.ir.SourceComponent;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 
 /**
  * Created by andrewvc on 9/15/16.
@@ -38,7 +38,7 @@ public boolean sourceComponentEquals(SourceComponent other) {
 
     // Special vertices really have no metadata
     @Override
-    public SourceMetadata getMeta() {
+    public SourceWithMetadata getMeta() {
         return null;
     }
 }

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/ComposedParallelStatement.java
Patch:
@@ -1,7 +1,7 @@
 package org.logstash.config.ir.imperative;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
 
 import java.util.List;
@@ -10,7 +10,7 @@
  * Created by andrewvc on 9/22/16.
  */
 public class ComposedParallelStatement extends ComposedStatement {
-    public ComposedParallelStatement(SourceMetadata meta, List<Statement> statements) throws InvalidIRException {
+    public ComposedParallelStatement(SourceWithMetadata meta, List<Statement> statements) throws InvalidIRException {
         super(meta, statements);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/ComposedSequenceStatement.java
Patch:
@@ -1,7 +1,7 @@
 package org.logstash.config.ir.imperative;
 
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
 
 import java.util.List;
@@ -10,7 +10,7 @@
  * Created by andrewvc on 9/22/16.
  */
 public class ComposedSequenceStatement extends ComposedStatement {
-    public ComposedSequenceStatement(SourceMetadata meta, List<Statement> statements) throws InvalidIRException {
+    public ComposedSequenceStatement(SourceWithMetadata meta, List<Statement> statements) throws InvalidIRException {
         super(meta, statements);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/ComposedStatement.java
Patch:
@@ -2,7 +2,7 @@
 
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 
 import java.util.List;
 import java.util.stream.Collectors;
@@ -12,12 +12,12 @@
  */
 public abstract class ComposedStatement extends Statement {
     public interface IFactory {
-        ComposedStatement make(SourceMetadata meta, List<Statement> statements) throws InvalidIRException;
+        ComposedStatement make(SourceWithMetadata meta, List<Statement> statements) throws InvalidIRException;
     }
 
     private final List<Statement> statements;
 
-    public ComposedStatement(SourceMetadata meta, List<Statement> statements) throws InvalidIRException {
+    public ComposedStatement(SourceWithMetadata meta, List<Statement> statements) throws InvalidIRException {
         super(meta);
         if (statements == null || statements.stream().anyMatch(s -> s == null)) {
             throw new InvalidIRException("Nulls eNot allowed for list eOr in statement list");

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/IfStatement.java
Patch:
@@ -2,7 +2,7 @@
 
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.expression.BooleanExpression;
 import org.logstash.config.ir.graph.BooleanEdge;
 import org.logstash.config.ir.graph.Graph;
@@ -36,7 +36,7 @@ public Statement getFalseStatement() {
         return falseStatement;
     }
 
-    public IfStatement(SourceMetadata meta,
+    public IfStatement(SourceWithMetadata meta,
                        BooleanExpression booleanExpression,
                        Statement trueStatement,
                        Statement falseStatement

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/NoopStatement.java
Patch:
@@ -1,15 +1,15 @@
 package org.logstash.config.ir.imperative;
 
 import org.logstash.config.ir.SourceComponent;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
 
 /**
  * Created by andrewvc on 9/15/16.
  */
 public class NoopStatement extends Statement {
 
-    public NoopStatement(SourceMetadata meta) {
+    public NoopStatement(SourceWithMetadata meta) {
         super(meta);
     }
 

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/PluginStatement.java
Patch:
@@ -3,7 +3,7 @@
 import org.logstash.config.ir.SourceComponent;
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.config.ir.PluginDefinition;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
 import org.logstash.config.ir.graph.PluginVertex;
 import org.logstash.config.ir.graph.Vertex;
@@ -14,7 +14,7 @@
 public class PluginStatement extends Statement {
     private final PluginDefinition pluginDefinition;
 
-    public PluginStatement(SourceMetadata meta, PluginDefinition pluginDefinition) {
+    public PluginStatement(SourceWithMetadata meta, PluginDefinition pluginDefinition) {
         super(meta);
         this.pluginDefinition = pluginDefinition;
     }

File: logstash-core/src/main/java/org/logstash/config/ir/imperative/Statement.java
Patch:
@@ -2,14 +2,14 @@
 
 import org.logstash.config.ir.InvalidIRException;
 import org.logstash.config.ir.BaseSourceComponent;
-import org.logstash.config.ir.SourceMetadata;
+import org.logstash.common.SourceWithMetadata;
 import org.logstash.config.ir.graph.Graph;
 
 /**
  * Created by andrewvc on 9/6/16.
  */
 public abstract class Statement extends BaseSourceComponent {
-    public Statement(SourceMetadata meta) {
+    public Statement(SourceWithMetadata meta) {
         super(meta);
     }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -668,8 +668,9 @@ public void close() throws IOException {
                 } catch (IOException e) {
                     // log error and ignore
                     logger.error("Queue close releaseLock failed, error={}", e.getMessage());
+                } finally {
+                    lock.unlock();
                 }
-                lock.unlock();
             }
         }
     }

File: logstash-core/src/main/java/org/logstash/config/ir/expression/Expression.java
Patch:
@@ -16,7 +16,6 @@
  * Created by andrewvc on 9/6/16.
  */
 public abstract class Expression extends BaseSourceComponent implements Hashable {
-    private Object compiled;
     private ScriptingContainer container;
 
     public Expression(SourceMetadata meta) {

File: logstash-core/src/main/java/org/logstash/config/ir/graph/PlainEdge.java
Patch:
@@ -14,7 +14,7 @@ public PlainEdge make(Vertex from, Vertex to) throws InvalidIRException {
         }
     }
 
-    public static PlainEdgeFactory factory = new PlainEdgeFactory();
+    public static final PlainEdgeFactory factory = new PlainEdgeFactory();
 
     @Override
     public String individualHashSource() {

File: logstash-core/src/main/java/org/logstash/config/ir/graph/Vertex.java
Patch:
@@ -130,7 +130,7 @@ public String uniqueHash() {
 
         MessageDigest lineageDigest = Util.defaultMessageDigest();
 
-        lineageDigest.update(hashPrefix().getBytes());
+        lineageDigest.update(hashPrefix().getBytes(StandardCharsets.UTF_8));
 
         // The lineage can be quite long and we want to avoid the quadratic complexity of string concatenation
         // Thus, in this case there's no real way to get the hash source, we just hash as we go.

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriteManager.java
Patch:
@@ -37,7 +37,7 @@ public class DeadLetterQueueWriteManager {
 
     private static final Logger logger = LogManager.getLogger(DeadLetterQueueWriteManager.class);
 
-    static final String SEGMENT_FILE_PATTERN = "%020d.log";
+    static final String SEGMENT_FILE_PATTERN = "%d.log";
     static final String LOCK_FILE = ".lock";
     private final long maxSegmentSize;
     private final long maxQueueSize;

File: logstash-core/src/main/java/org/logstash/common/io/RecordIOReader.java
Patch:
@@ -109,6 +109,9 @@ public <T> byte[] seekToNextEventPosition(T target, Function<byte[], T> keyExtra
         while (compare < 0) {
             currentPosition = currentBlock.position();
             event = readEvent();
+            if (event == null) {
+                return null;
+            }
             compare = keyComparator.compare(keyExtractor.apply(event), target);
         }
         currentBlock.position(currentPosition);

File: logstash-core/src/test/java/org/logstash/common/io/RecordIOWriterTest.java
Patch:
@@ -19,7 +19,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.logstash.common.io.RecordIOWriter.BLOCK_SIZE;
 
-public class RecordHeaderIOWriterTest {
+public class RecordIOWriterTest {
     private Path file;
 
     @Rule

File: logstash-core/src/main/java/org/logstash/Accessors.java
Patch:
@@ -154,7 +154,7 @@ private Object store(Object target, String key, Object value) {
             if (i >= size) {
                 // grow array by adding trailing null items
                 // this strategy reflects legacy Ruby impl behaviour and is backed by specs
-                // TODO: (colin) this is potentially dangerous, and could produce OOM using arbritary big numbers
+                // TODO: (colin) this is potentially dangerous, and could produce OOM using arbitrary big numbers
                 // TODO: (colin) should be guard against this?
                 for (int j = size; j < i; j++) {
                     ((List<Object>) target).add(null);

File: logstash-core/src/main/java/org/logstash/Event.java
Patch:
@@ -252,12 +252,12 @@ public static Event[] fromJson(String json)
             int i = 0;
             for (Object e : (List)o) {
                 if (!(e instanceof Map)) {
-                    throw new IOException("incompatible inner json array object type=" + e.getClass().getName() + " , only hash map is suppoted");
+                    throw new IOException("incompatible inner json array object type=" + e.getClass().getName() + " , only hash map is supported");
                 }
                 result[i++] = new Event((Map)e);
             }
         } else {
-            throw new IOException("incompatible json object type=" + o.getClass().getName() + " , only hash map or arrays are suppoted");
+            throw new IOException("incompatible json object type=" + o.getClass().getName() + " , only hash map or arrays are supported");
         }
 
         return result;

File: logstash-core/src/main/java/org/logstash/ackedqueue/HeadPage.java
Patch:
@@ -82,7 +82,7 @@ public TailPage behead() throws IOException {
         // TODO: should we have a better deactivation strategy to avoid too rapid reactivation scenario?
         Page firstUnreadPage = queue.firstUnreadPage();
         if (firstUnreadPage == null || (tailPage.getPageNum() > firstUnreadPage.getPageNum())) {
-            // deactivate if this new tailPage is not where the read is occuring
+            // deactivate if this new tailPage is not where the read is occurring
             tailPage.getPageIO().deactivate();
         }
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/Page.java
Patch:
@@ -10,7 +10,7 @@
 
 public abstract class Page implements Closeable {
     protected final int pageNum;
-    protected long minSeqNum; // TODO: see if we can meke it final?
+    protected long minSeqNum; // TODO: see if we can make it final?
     protected int elementCount;
     protected long firstUnreadSeqNum;
     protected final Queue queue;
@@ -74,7 +74,7 @@ public boolean isFullyRead() {
     public boolean isFullyAcked() {
         // TODO: it should be something similar to this when we use a proper bitset class like ES
         // this.ackedSeqNum.firstUnackedBit >= this.elementCount;
-        // TODO: for now use a naive & inneficient mechanism with a simple Bitset
+        // TODO: for now use a naive & inefficient mechanism with a simple Bitset
         return this.elementCount > 0 && this.ackedSeqNums.cardinality() >= this.elementCount;
     }
 

File: logstash-core/src/main/java/org/logstash/common/io/AbstractByteBufferPageIO.java
Patch:
@@ -99,7 +99,7 @@ public void recover() throws IOException {
         // reset back position to first seqNum
         getBuffer().position(this.head);
 
-        // reset elementCount to 0 and increment to actal number of valid elements found
+        // reset elementCount to 0 and increment to octal number of valid elements found
         this.elementCount = 0;
 
         for (int i = 0; ; i++) {
@@ -128,7 +128,7 @@ private void validateVersion(byte version) throws PageIOInvalidVersionException
         }
     }
 
-    // read and vadidate next element at page head
+    // read and validate next element at page head
     // @param verifyChecksum if true the actual element data will be read + checksumed and compared to written checksum
     private void readNextElement(long expectedSeqNum, boolean verifyChecksum) throws PageIOInvalidElementException {
         // if there is no room for the seqNum and length bytes stop here

File: logstash-core/src/main/java/org/logstash/common/io/ByteBufferPageIO.java
Patch:
@@ -30,7 +30,7 @@ public ByteBufferPageIO(int capacity, byte[] initialBytes) throws IOException {
     public void deactivate() { /* nothing */ }
 
     @Override
-    public void activate() { /* niet */ }
+    public void activate() { /* nyet */ }
 
     @Override
     public void ensurePersisted() { /* nada */ }

File: logstash-core/src/main/java/org/logstash/common/io/MmapPageIO.java
Patch:
@@ -42,7 +42,7 @@ public void recover() throws IOException {
     }
 
     // memory map data file to this.buffer and read initial version byte
-    // @param strictCapacity if true verify that data file size is same as confgured page capcity, if false update page capcity to actual file size
+    // @param strictCapacity if true verify that data file size is same as configured page capacity, if false update page capacity to actual file size
     private void mapFile(boolean strictCapacity) throws IOException {
         RandomAccessFile raf = new RandomAccessFile(this.file, "rw");
 
@@ -55,7 +55,7 @@ private void mapFile(boolean strictCapacity) throws IOException {
             throw new IOException("Page file size " + pageFileCapacity + " different to configured page capacity " + this.capacity + " for " + this.file);
         }
 
-        // update capacity to actual raf lenght
+        // update capacity to actual raf length
         this.capacity = pageFileCapacity;
 
         if (this.capacity < MIN_CAPACITY) { throw new IOException(String.format("Page file size is too small to hold elements")); }

File: logstash-core/src/main/java/org/logstash/ext/JrubyTimestampExtLibrary.java
Patch:
@@ -209,7 +209,7 @@ public static IRubyObject ruby_at(ThreadContext context, IRubyObject recv, IRuby
                 IRubyObject epoch = args[0];
 
                 if (epoch instanceof RubyBigDecimal) {
-                    // bug in JRuby prevents correcly parsing a BigDecimal fractional part, see https://github.com/elastic/logstash/issues/4565
+                    // bug in JRuby prevents correctly parsing a BigDecimal fractional part, see https://github.com/elastic/logstash/issues/4565
                     double usec = ((RubyBigDecimal)epoch).frac().convertToFloat().getDoubleValue() * 1000000;
                     t = (RubyTime)RubyTime.at(context, context.runtime.getTime(), ((RubyBigDecimal)epoch).to_int(), new RubyFloat(context.runtime, usec));
                 } else {

File: logstash-core/src/test/java/org/logstash/StringInterpolationTest.java
Patch:
@@ -51,7 +51,7 @@ public void testMissingKey() throws IOException {
     }
 
     @Test
-    public void testDateFormater() throws IOException {
+    public void testDateFormatter() throws IOException {
         Event event = getTestEvent();
         String path = "/full/%{+YYYY}";
         StringInterpolation si = StringInterpolation.getInstance();

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -199,7 +199,7 @@ public void writeMultiPageWithInOrderAckingCheckpoints() throws IOException {
         int singleElementCapacity = ByteBufferPageIO.HEADER_SIZE + ByteBufferPageIO._persistedByteCount(elements1.get(0).serialize().length);
 
         Settings settings = TestSettings.volatileQueueSettings(2 * singleElementCapacity);
-        settings.setCheckpointMaxWrites(1024); // arbritary high enough threshold so that it's not reached (default for TestSettings is 1)
+        settings.setCheckpointMaxWrites(1024); // arbitrary high enough threshold so that it's not reached (default for TestSettings is 1)
         TestQueue q = new TestQueue(settings);
         q.open();
 

File: logstash-core/src/test/java/org/logstash/common/io/MemoryCheckpointTest.java
Patch:
@@ -40,7 +40,7 @@ public void writeNewReadExisting() throws IOException {
     }
 
     @Test(expected = NoSuchFileException.class)
-    public void readInnexisting() throws IOException {
+    public void readNonexistent() throws IOException {
         io.read("checkpoint.invalid");
     }
 

File: logstash-core/src/test/java/org/logstash/stress/Concurent.java
Patch:
@@ -13,7 +13,7 @@
 import java.util.concurrent.ConcurrentLinkedQueue;
 import java.util.stream.Collectors;
 
-public class Concurent {
+public class Concurrent {
     final static int ELEMENT_COUNT = 2000000;
     final static int BATCH_SIZE = 1000;
     static Settings settings;

File: logstash-core/src/main/java/org/logstash/common/io/DeadLetterQueueWriteManager.java
Patch:
@@ -99,7 +99,7 @@ static Stream<Path> getSegmentPaths(Path path) throws IOException {
         return Files.list(path).filter((p) -> p.toString().endsWith(".log"));
     }
 
-    public void writeEntry(DLQEntry event) throws IOException {
+    public synchronized void writeEntry(DLQEntry event) throws IOException {
         byte[] record = event.serialize();
         int eventPayloadSize = RECORD_HEADER_SIZE + record.length;
         if (currentQueueSize + eventPayloadSize > maxQueueSize) {
@@ -112,7 +112,7 @@ public void writeEntry(DLQEntry event) throws IOException {
         currentQueueSize += currentWriter.writeEvent(record);
     }
 
-    public void close() throws IOException {
+    public synchronized void close() throws IOException {
         this.lock.release();
         if (currentWriter != null) {
             currentWriter.close();

File: logstash-core/src/main/java/org/logstash/ackedqueue/Queue.java
Patch:
@@ -330,7 +330,9 @@ public long write(Queueable element) throws IOException {
             this.unreadCount++;
 
             // if the queue was empty before write, signal non emptiness
-            if (wasEmpty) { notEmpty.signalAll(); }
+            // a simple signal and not signalAll is necessary here since writing a single element
+            // can only really enable a single thread to read a batch
+            if (wasEmpty) { notEmpty.signal(); }
 
             // now check if we reached a queue full state and block here until it is not full
             // for the next write or the queue was closed.

File: logstash-core/src/main/java/org/logstash/common/io/FileCheckpointIO.java
Patch:
@@ -1,7 +1,6 @@
 package org.logstash.common.io;
 
 import org.logstash.ackedqueue.Checkpoint;
-import sun.reflect.generics.reflectiveObjects.NotImplementedException;
 
 import java.io.IOException;
 import java.io.InputStream;
@@ -72,7 +71,7 @@ public void purge(String fileName) throws IOException {
     @Override
     public void purge() throws IOException {
         // TODO: dir traversal and delete all checkpoints?
-        throw new NotImplementedException();
+        throw new UnsupportedOperationException("purge() is not supported");
     }
 
     // @return the head page checkpoint file name

File: logstash-core/src/main/java/org/logstash/common/io/MemoryCheckpointIO.java
Patch:
@@ -1,12 +1,9 @@
 package org.logstash.common.io;
 
 import org.logstash.ackedqueue.Checkpoint;
-import sun.reflect.generics.reflectiveObjects.NotImplementedException;
 
 import java.io.IOException;
 import java.nio.file.NoSuchFileException;
-import java.nio.file.Path;
-import java.nio.file.Paths;
 import java.util.HashMap;
 import java.util.Map;
 

File: logstash-core/src/main/java/org/logstash/common/io/MmapPageIO.java
Patch:
@@ -13,9 +13,11 @@
 
 // TODO: this essentially a copy of ByteBufferPageIO and should be DRY'ed - temp impl to test file based stress test
 
+@SuppressWarnings("sunapi")
 public class MmapPageIO extends AbstractByteBufferPageIO {
 
     private File file;
+
     private FileChannel channel;
     protected MappedByteBuffer buffer;
 

File: logstash-core/src/main/java/org/logstash/common/io/PageIO.java
Patch:
@@ -1,11 +1,9 @@
 package org.logstash.common.io;
 
-import org.logstash.ackedqueue.Queueable;
 import org.logstash.ackedqueue.SequencedList;
 
 import java.io.Closeable;
 import java.io.IOException;
-import java.util.List;
 
 public interface PageIO extends Closeable {
 

File: logstash-core/src/main/java/org/logstash/common/io/wip/MemoryPageIOStream.java
Patch:
@@ -1,14 +1,12 @@
 package org.logstash.common.io.wip;
 
 import org.logstash.ackedqueue.Checkpoint;
-import org.logstash.ackedqueue.Queueable;
 import org.logstash.ackedqueue.SequencedList;
 import org.logstash.common.io.BufferedChecksumStreamInput;
 import org.logstash.common.io.BufferedChecksumStreamOutput;
 import org.logstash.common.io.ByteArrayStreamOutput;
 import org.logstash.common.io.ByteBufferStreamInput;
 import org.logstash.common.io.PageIO;
-import sun.reflect.generics.reflectiveObjects.NotImplementedException;
 
 import java.io.IOException;
 import java.nio.ByteBuffer;
@@ -72,7 +70,7 @@ public MemoryPageIOStream(int capacity, byte[] initialBytes) throws IOException
 
     @Override
     public void recover() throws IOException {
-        throw new NotImplementedException();
+        throw new UnsupportedOperationException("recover() is not supported");
     }
 
     @Override

File: logstash-core/src/main/java/org/logstash/common/io/MmapPageIO.java
Patch:
@@ -101,6 +101,9 @@ public void purge() throws IOException {
 
     @Override
     public void close() throws IOException {
+        if (this.buffer != null) {
+            this.buffer.force();
+        }
         if (this.channel != null && this.channel.isOpen()) {
             this.channel.close();
         }

File: logstash-core/src/main/java/org/logstash/FileLockFactory.java
Patch:
@@ -87,7 +87,7 @@ public FileLock obtainLock(String lockDir, String lockName) throws IOException {
                     LOCK_MAP.put(lock, realLockPath.toString());
                     return lock;
                 } else {
-                    throw new LockException("Lock held by another program: " + realLockPath);
+                    throw new LockException("Lock held by another program on lock path: " + realLockPath);
                 }
             } finally {
                 if (lock == null) { // not successful - clear up and move out
@@ -106,7 +106,7 @@ public FileLock obtainLock(String lockDir, String lockName) throws IOException {
                 }
             }
         } else {
-            throw new LockException("Lock held by this virtual machine: " + realLockPath);
+            throw new LockException("Lock held by this virtual machine on lock path: " + realLockPath);
         }
     }
 

File: logstash-core/src/test/java/org/logstash/stress/Concurent.java
Patch:
@@ -151,6 +151,7 @@ public static void oneProducersOneMultipleConsumer() throws IOException, Interru
 
         // gotta hate exception handling in lambdas
         consumers.forEach(c -> {try{c.join();} catch(InterruptedException e) {throw new RuntimeException(e);}});
+        q.close();
 
         Instant end = Instant.now();
 

File: logstash-core/src/main/java/org/logstash/ackedqueue/HeadPage.java
Patch:
@@ -11,15 +11,15 @@ public class HeadPage extends Page {
     // create a new HeadPage object and new page.{pageNum} empty valid data file
     public HeadPage(int pageNum, Queue queue, PageIO pageIO) throws IOException {
         super(pageNum, queue, 0, 0, 0, new BitSet(), pageIO);
-        pageIO.create();
     }
 
     // create a new HeadPage object from an existing checkpoint and open page.{pageNum} empty valid data file
+    // @param pageIO is expected to be open/recover/create
     public HeadPage(Checkpoint checkpoint, Queue queue, PageIO pageIO) throws IOException {
         super(checkpoint.getPageNum(), queue, checkpoint.getMinSeqNum(), checkpoint.getElementCount(), checkpoint.getFirstUnackedSeqNum(), new BitSet(), pageIO);
 
-        // open the data file and reconstruct the IO object internal state
-        pageIO.open(checkpoint.getMinSeqNum(), checkpoint.getElementCount());
+        assert checkpoint.getMinSeqNum() == pageIO.getMinSeqNum() && checkpoint.getElementCount() == pageIO.getElementCount() :
+                String.format("checkpoint minSeqNum=%d or elementCount=%d is different than pageIO minSeqNum=%d or elementCount=%d", checkpoint.getMinSeqNum(), checkpoint.getElementCount(), pageIO.getMinSeqNum(), pageIO.getElementCount());
 
         // this page ackedSeqNums bitset is a new empty bitset, if we have some acked elements, set them in the bitset
         if (checkpoint.getFirstUnackedSeqNum() > checkpoint.getMinSeqNum()) {

File: logstash-core/src/test/java/org/logstash/ackedqueue/TestSettings.java
Patch:
@@ -9,7 +9,7 @@
 
 public class TestSettings {
 
-    public static Settings getSettings(int capacity) {
+    public static Settings volatileQueueSettings(int capacity) {
         MemoryCheckpointIO.clearSources();
         Settings s = new MemorySettings();
         PageIOFactory pageIOFactory = (pageNum, size, path) -> new ByteBufferPageIO(pageNum, size, path);
@@ -21,7 +21,7 @@ public static Settings getSettings(int capacity) {
         return s;
     }
 
-    public static Settings getSettings(int capacity, long size) {
+    public static Settings volatileQueueSettings(int capacity, long size) {
         MemoryCheckpointIO.clearSources();
         Settings s = new MemorySettings();
         PageIOFactory pageIOFactory = (pageNum, pageSize, path) -> new ByteBufferPageIO(pageNum, pageSize, path);
@@ -34,7 +34,7 @@ public static Settings getSettings(int capacity, long size) {
         return s;
     }
 
-    public static Settings getSettingsCheckpointFilePageMemory(int capacity, String folder) {
+    public static Settings persistedQueueSettings(int capacity, String folder) {
         Settings s = new FileSettings(folder);
         PageIOFactory pageIOFactory = (pageNum, size, path) -> new MmapPageIO(pageNum, size, path);
         CheckpointIOFactory checkpointIOFactory = (source) -> new FileCheckpointIO(source);

File: logstash-core/src/main/java/org/logstash/common/io/FileCheckpointIO.java
Patch:
@@ -34,6 +34,7 @@ public class FileCheckpointIO  implements CheckpointIO {
     private final String dirPath;
     private final String HEAD_CHECKPOINT = "checkpoint.head";
     private final String TAIL_CHECKPOINT = "checkpoint.";
+    private final OpenOption[] WRITE_OPTIONS = new OpenOption[] { WRITE, CREATE, TRUNCATE_EXISTING, DSYNC };
 
     public FileCheckpointIO(String dirPath) {
         this.dirPath = dirPath;
@@ -55,11 +56,10 @@ public Checkpoint write(String fileName, int pageNum, int firstUnackedPageNum, l
 
     @Override
     public void write(String fileName, Checkpoint checkpoint) throws IOException {
-        OpenOption[] options = new OpenOption[] { WRITE, CREATE, TRUNCATE_EXISTING, DSYNC };
         Path path = Paths.get(dirPath, fileName);
         final byte[] buffer = new byte[BUFFER_SIZE];
         write(checkpoint, buffer);
-        Files.write(path, buffer, options);
+        Files.write(path, buffer, WRITE_OPTIONS);
     }
 
     @Override

File: logstash-core/src/test/java/org/logstash/ackedqueue/TestSettings.java
Patch:
@@ -4,6 +4,7 @@
 import org.logstash.common.io.CheckpointIOFactory;
 import org.logstash.common.io.FileCheckpointIO;
 import org.logstash.common.io.MemoryCheckpointIO;
+import org.logstash.common.io.MmapPageIO;
 import org.logstash.common.io.PageIOFactory;
 
 public class TestSettings {
@@ -35,10 +36,11 @@ public static Settings getSettings(int capacity, long size) {
 
     public static Settings getSettingsCheckpointFilePageMemory(int capacity, String folder) {
         Settings s = new FileSettings(folder);
-        PageIOFactory pageIOFactory = (pageNum, size, path) -> new ByteBufferPageIO(pageNum, size, path);
+        PageIOFactory pageIOFactory = (pageNum, size, path) -> new MmapPageIO(pageNum, size, path);
         CheckpointIOFactory checkpointIOFactory = (source) -> new FileCheckpointIO(source);
         s.setCapacity(capacity);
         s.setElementIOFactory(pageIOFactory);
+        s.setCheckpointMaxWrites(1);
         s.setCheckpointIOFactory(checkpointIOFactory);
         s.setElementClass(StringElement.class);
         return s;

File: logstash-core-event-java/src/main/java/org/logstash/Accessors.java
Patch:
@@ -188,7 +188,7 @@ private ClassCastException newCollectionException(Object target) {
      * @param size the size of the list.
      * @return the positive integer offset for the list given by index i.
      */
-    private static int listIndex(int i, int size) {
+    public static int listIndex(int i, int size) {
         if (i >= size || i < -size) {
             throw new IndexOutOfBoundsException("Index " + i + " is out of bounds for a list with size " + size);
         }

File: logstash-core/src/main/java/org/logstash/ackedqueue/FileSettings.java
Patch:
@@ -114,7 +114,9 @@ public String getDirPath() {
     }
 
     @Override
-    public long getQueueMaxBytes() { return queueMaxBytes; }
+    public long getQueueMaxBytes() {
+        return queueMaxBytes;
+    }
 
     @Override
     public int getCapacity() {

File: logstash-core-queue-jruby/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueExtLibrary.java
Patch:
@@ -67,14 +67,14 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args)
             int checkpointMaxAcks = RubyFixnum.num2int(args[3]);
             int checkpointMaxWrites = RubyFixnum.num2int(args[4]);
             int checkpointMaxInterval = RubyFixnum.num2int(args[5]);
-            long queueMaxSizeInBytes = RubyFixnum.num2long(args[6]);
+            long queueMaxBytes = RubyFixnum.num2long(args[6]);
 
             Settings s = new FileSettings(args[0].asJavaString());
             PageIOFactory pageIOFactory = (pageNum, size, path) -> new MmapPageIO(pageNum, size, path);
             CheckpointIOFactory checkpointIOFactory = (source) -> new FileCheckpointIO(source);
             s.setCapacity(capacity);
             s.setMaxUnread(maxUnread);
-            s.setQueueMaxSizeInBytes(queueMaxSizeInBytes);
+            s.setQueueMaxBytes(queueMaxBytes);
             s.setCheckpointMaxAcks(checkpointMaxAcks);
             s.setCheckpointMaxWrites(checkpointMaxWrites);
             s.setCheckpointMaxInterval(checkpointMaxInterval);

File: logstash-core-queue-jruby/src/main/java/org/logstash/ackedqueue/ext/JrubyAckedQueueMemoryExtLibrary.java
Patch:
@@ -64,14 +64,14 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args)
 
             int capacity = RubyFixnum.num2int(args[1]);
             int maxUnread = RubyFixnum.num2int(args[2]);
-            long queueMaxSizeInBytes = RubyFixnum.num2long(args[3]);
+            long queueMaxBytes = RubyFixnum.num2long(args[3]);
 
             Settings s = new MemorySettings(args[0].asJavaString());
             PageIOFactory pageIOFactory = (pageNum, size, path) -> new ByteBufferPageIO(pageNum, size, path);
             CheckpointIOFactory checkpointIOFactory = (source) -> new MemoryCheckpointIO(source);
             s.setCapacity(capacity);
             s.setMaxUnread(maxUnread);
-            s.setQueueMaxSizeInBytes(queueMaxSizeInBytes);
+            s.setQueueMaxBytes(queueMaxBytes);
             s.setElementIOFactory(pageIOFactory);
             s.setCheckpointIOFactory(checkpointIOFactory);
             s.setElementClass(Event.class);

File: logstash-core/src/main/java/org/logstash/ackedqueue/Settings.java
Patch:
@@ -12,7 +12,7 @@ public interface Settings {
 
     Settings setCapacity(int capacity);
 
-    Settings setQueueMaxSizeInBytes(long size);
+    Settings setQueueMaxBytes(long size);
 
     Settings setMaxUnread(int maxUnread);
 
@@ -32,7 +32,7 @@ public interface Settings {
 
     int getCapacity();
 
-    long getQueueMaxSizeInBytes();
+    long getQueueMaxBytes();
 
     int getMaxUnread();
 

File: logstash-core/src/test/java/org/logstash/ackedqueue/TestSettings.java
Patch:
@@ -26,7 +26,7 @@ public static Settings getSettings(int capacity, long size) {
         PageIOFactory pageIOFactory = (pageNum, pageSize, path) -> new ByteBufferPageIO(pageNum, pageSize, path);
         CheckpointIOFactory checkpointIOFactory = (source) -> new MemoryCheckpointIO(source);
         s.setCapacity(capacity);
-        s.setQueueMaxSizeInBytes(size);
+        s.setQueueMaxBytes(size);
         s.setElementIOFactory(pageIOFactory);
         s.setCheckpointIOFactory(checkpointIOFactory);
         s.setElementClass(StringElement.class);

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -456,7 +456,7 @@ public void resumeWriteOnNoLongerFullQueueTest() throws IOException, Interrupted
 
         assertThat(q.isFull(), is(true));
 
-        Batch b = q.readBatch(9); // read 1 page (10 events)
+        Batch b = q.readBatch(10); // read 1 page (10 events)
         b.close();  // purge 1 page
 
         // spin wait until data is written and write blocks

File: logstash-core/src/main/java/org/logstash/ackedqueue/FileSettings.java
Patch:
@@ -9,7 +9,7 @@ public class FileSettings implements Settings {
     private PageIOFactory pageIOFactory;
     private Class elementClass;
     private int capacity;
-    private int queueMaxSizeInBytes;
+    private long queueMaxSizeInBytes;
     private int maxUnread;
     private int checkpointMaxAcks;
     private int checkpointMaxWrites;
@@ -44,7 +44,7 @@ public Settings setElementClass(Class elementClass) {
     }
 
     @Override
-    public Settings setQueueMaxSizeInBytes(int size) {
+    public Settings setQueueMaxSizeInBytes(long size) {
         this.queueMaxSizeInBytes = size;
         return this;
     }
@@ -114,7 +114,7 @@ public String getDirPath() {
     }
 
     @Override
-    public int getQueueMaxSizeInBytes() { return queueMaxSizeInBytes; }
+    public long getQueueMaxSizeInBytes() { return queueMaxSizeInBytes; }
 
     @Override
     public int getCapacity() {

File: logstash-core/src/main/java/org/logstash/ackedqueue/MemorySettings.java
Patch:
@@ -8,7 +8,7 @@ public class MemorySettings implements Settings {
     private PageIOFactory pageIOFactory;
     private Class elementClass;
     private int capacity;
-    private int queueMaxSizeInBytes;
+    private long queueMaxSizeInBytes;
     private final String dirPath;
     private int maxUnread;
     private int checkpointMaxAcks;
@@ -52,7 +52,7 @@ public Settings setCapacity(int capacity) {
     }
 
     @Override
-    public Settings setQueueMaxSizeInBytes(int size) {
+    public Settings setQueueMaxSizeInBytes(long size) {
         this.queueMaxSizeInBytes = size;
         return this;
     }
@@ -115,7 +115,7 @@ public String getDirPath() {
         return this.dirPath;
     }
 
-    public int getQueueMaxSizeInBytes() { return this.queueMaxSizeInBytes; }
+    public long getQueueMaxSizeInBytes() { return this.queueMaxSizeInBytes; }
 
     @Override
     public int getCapacity() {

File: logstash-core/src/main/java/org/logstash/ackedqueue/Settings.java
Patch:
@@ -12,7 +12,7 @@ public interface Settings {
 
     Settings setCapacity(int capacity);
 
-    Settings setQueueMaxSizeInBytes(int size);
+    Settings setQueueMaxSizeInBytes(long size);
 
     Settings setMaxUnread(int maxUnread);
 
@@ -32,7 +32,7 @@ public interface Settings {
 
     int getCapacity();
 
-    int getQueueMaxSizeInBytes();
+    long getQueueMaxSizeInBytes();
 
     int getMaxUnread();
 

File: logstash-core/src/test/java/org/logstash/ackedqueue/TestSettings.java
Patch:
@@ -20,7 +20,7 @@ public static Settings getSettings(int capacity) {
         return s;
     }
 
-    public static Settings getSettings(int capacity, int size) {
+    public static Settings getSettings(int capacity, long size) {
         MemoryCheckpointIO.clearSources();
         Settings s = new MemorySettings();
         PageIOFactory pageIOFactory = (pageNum, pageSize, path) -> new ByteBufferPageIO(pageNum, pageSize, path);

File: logstash-core/src/main/java/org/logstash/common/io/CheckpointIO.java
Patch:
@@ -8,6 +8,8 @@ public interface CheckpointIO {
     // @return Checkpoint the written checkpoint object
     Checkpoint write(String fileName, int pageNum, int firstUnackedPageNum, long firstUnackedSeqNum, long minSeqNum, int elementCount) throws IOException;
 
+    void write(String fileName, Checkpoint checkpoint) throws IOException;
+
     Checkpoint read(String fileName) throws IOException;
 
     void purge(String fileName) throws IOException;

File: logstash-core/src/test/java/org/logstash/ackedqueue/QueueTest.java
Patch:
@@ -174,6 +174,7 @@ public void writeMultiPageWithInOrderAckingCheckpoints() throws IOException {
         int singleElementCapacity = ByteBufferPageIO.HEADER_SIZE + ByteBufferPageIO._persistedByteCount(elements1.get(0).serialize().length);
 
         Settings settings = TestSettings.getSettings(2 * singleElementCapacity);
+        settings.setCheckpointMaxWrites(1024); // arbritary high enough threshold so that it's not reached (default for TestSettings is 1)
         TestQueue q = new TestQueue(settings);
         q.open();
 

File: logstash-core/src/test/java/org/logstash/log/CustomLogEventTests.java
Patch:
@@ -33,6 +33,7 @@
 import java.util.Map;
 
 import static junit.framework.TestCase.assertEquals;
+import static junit.framework.TestCase.assertNotNull;
 
 public class CustomLogEventTests {
     private static final ObjectMapper mapper = new ObjectMapper();
@@ -78,15 +79,15 @@ public void testJSONLayout() throws Exception {
         assertEquals(5, firstMessage.size());
         assertEquals("INFO", firstMessage.get("level"));
         assertEquals("JSONEventLogger", firstMessage.get("loggerName"));
-        assertEquals("main", firstMessage.get("thread"));
+        assertNotNull(firstMessage.get("thread"));
         assertEquals(Collections.singletonMap("message", "simple message"), firstMessage.get("logEvent"));
 
         Map<String, Object> secondMessage = mapper.readValue(messages.get(1), Map.class);
 
         assertEquals(5, secondMessage.size());
         assertEquals("WARN", secondMessage.get("level"));
         assertEquals("JSONEventLogger", secondMessage.get("loggerName"));
-        assertEquals("main", secondMessage.get("thread"));
+        assertNotNull(secondMessage.get("thread"));
         Map<String, Object> logEvent = new HashMap<>();
         logEvent.put("message", "complex message");
         logEvent.put("foo", "bar");

File: logstash-core-event-java/src/main/java/JrubyEventExtService.java
Patch:
@@ -1,4 +1,4 @@
-import com.logstash.ext.JrubyEventExtLibrary;
+import org.logstash.ext.JrubyEventExtLibrary;
 import org.jruby.Ruby;
 import org.jruby.runtime.load.BasicLibraryService;
 

File: logstash-core-event-java/src/main/java/JrubyTimestampExtService.java
Patch:
@@ -1,5 +1,4 @@
-import com.logstash.ext.JrubyEventExtLibrary;
-import com.logstash.ext.JrubyTimestampExtLibrary;
+import org.logstash.ext.JrubyTimestampExtLibrary;
 import org.jruby.Ruby;
 import org.jruby.runtime.load.BasicLibraryService;
 

File: logstash-core-event-java/src/main/java/org/logstash/Accessors.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import java.util.HashMap;
 import java.util.Map;

File: logstash-core-event-java/src/main/java/org/logstash/Cloner.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import java.util.*;
 

File: logstash-core-event-java/src/main/java/org/logstash/ConvertedList.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import org.jruby.RubyArray;
 import org.jruby.runtime.builtin.IRubyObject;
@@ -15,7 +15,7 @@
 import java.util.function.UnaryOperator;
 import java.util.stream.Stream;
 
-import static com.logstash.Valuefier.convert;
+import static org.logstash.Valuefier.convert;
 
 public class ConvertedList<T> implements List<T>, Collection<T>, Iterable<T> {
     private final List<T> delegate;

File: logstash-core-event-java/src/main/java/org/logstash/ConvertedMap.java
Patch:
@@ -1,6 +1,6 @@
-package com.logstash;
+package org.logstash;
 
-import com.logstash.bivalues.BiValues;
+import org.logstash.bivalues.BiValues;
 import org.jruby.RubyHash;
 import org.jruby.runtime.builtin.IRubyObject;
 

File: logstash-core-event-java/src/main/java/org/logstash/DateNode.java
Patch:
@@ -1,10 +1,9 @@
-package com.logstash;
+package org.logstash;
 
 import org.joda.time.DateTimeZone;
 import org.joda.time.format.DateTimeFormat;
 import org.joda.time.format.DateTimeFormatter;
 
-import java.io.IOError;
 import java.io.IOException;
 
 /**

File: logstash-core-event-java/src/main/java/org/logstash/EpochNode.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import java.io.IOException;
 

File: logstash-core-event-java/src/main/java/org/logstash/FieldReference.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import java.util.ArrayList;
 import java.util.Arrays;

File: logstash-core-event-java/src/main/java/org/logstash/Javafier.java
Patch:
@@ -1,8 +1,8 @@
-package com.logstash;
+package org.logstash;
 
 
-import com.logstash.bivalues.BiValue;
-import com.logstash.bivalues.BiValues;
+import org.logstash.bivalues.BiValue;
+import org.logstash.bivalues.BiValues;
 
 public class Javafier {
     private static final String ERR_TEMPLATE = "Missing Ruby class handling for full class name=%s, simple name=%s";

File: logstash-core-event-java/src/main/java/org/logstash/KeyNode.java
Patch:
@@ -1,7 +1,7 @@
-package com.logstash;
+package org.logstash;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
-import com.logstash.bivalues.BiValue;
+import org.logstash.bivalues.BiValue;
 
 import java.io.IOException;
 import java.util.List;

File: logstash-core-event-java/src/main/java/org/logstash/PathCache.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import java.util.concurrent.ConcurrentHashMap;
 

File: logstash-core-event-java/src/main/java/org/logstash/Rubyfier.java
Patch:
@@ -1,7 +1,7 @@
-package com.logstash;
+package org.logstash;
 
-import com.logstash.bivalues.BiValue;
-import com.logstash.bivalues.BiValues;
+import org.logstash.bivalues.BiValue;
+import org.logstash.bivalues.BiValues;
 import org.jruby.Ruby;
 import org.jruby.RubyArray;
 import org.jruby.RubyHash;

File: logstash-core-event-java/src/main/java/org/logstash/StaticNode.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import java.io.IOException;
 

File: logstash-core-event-java/src/main/java/org/logstash/StringInterpolation.java
Patch:
@@ -1,9 +1,8 @@
-package com.logstash;
+package org.logstash;
 
 
 import java.io.IOException;
 import java.util.Map;
-import java.util.Objects;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;

File: logstash-core-event-java/src/main/java/org/logstash/Template.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import java.io.IOException;
 import java.util.ArrayList;

File: logstash-core-event-java/src/main/java/org/logstash/TemplateNode.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import java.io.IOException;
 

File: logstash-core-event-java/src/main/java/org/logstash/Timestamp.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import com.fasterxml.jackson.databind.annotation.JsonSerialize;
 import org.joda.time.DateTime;

File: logstash-core-event-java/src/main/java/org/logstash/TimestampSerializer.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.databind.JsonSerializer;

File: logstash-core-event-java/src/main/java/org/logstash/Util.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/BiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.runtime.builtin.IRubyObject;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/BiValueCommon.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import com.fasterxml.jackson.annotation.JsonValue;
 import org.jruby.Ruby;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/BigDecimalBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.ext.bigdecimal.RubyBigDecimal;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/BigIntegerBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.RubyBignum;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/BooleanBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.RubyBoolean;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/DoubleBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.RubyFloat;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/FloatBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.RubyFloat;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/IntegerBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.RubyInteger;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/JavaProxyBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.java.proxies.JavaProxy;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/LongBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.RubyInteger;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/NullBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import com.fasterxml.jackson.annotation.JsonValue;
 import org.jruby.Ruby;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/StringBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.RubyString;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/SymbolBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.jruby.Ruby;
 import org.jruby.RubySymbol;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/TimeBiValue.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 import org.joda.time.DateTime;
 import org.jruby.Ruby;

File: logstash-core-event-java/src/main/java/org/logstash/bivalues/TimestampBiValue.java
Patch:
@@ -1,7 +1,7 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
-import com.logstash.Timestamp;
-import com.logstash.ext.JrubyTimestampExtLibrary.RubyTimestamp;
+import org.logstash.Timestamp;
+import org.logstash.ext.JrubyTimestampExtLibrary.RubyTimestamp;
 import org.jruby.Ruby;
 
 import java.io.ObjectStreamException;

File: logstash-core-event-java/src/main/java/org/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -1,6 +1,6 @@
-package com.logstash.ext;
+package org.logstash.ext;
 
-import com.logstash.*;
+import org.logstash.*;
 import org.jruby.*;
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;

File: logstash-core-event-java/src/main/java/org/logstash/ext/JrubyTimestampExtLibrary.java
Patch:
@@ -1,6 +1,5 @@
-package com.logstash.ext;
+package org.logstash.ext;
 
-import com.logstash.*;
 import org.jruby.*;
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;
@@ -12,6 +11,7 @@
 import org.jruby.runtime.ThreadContext;
 import org.jruby.runtime.builtin.IRubyObject;
 import org.jruby.runtime.load.Library;
+import org.logstash.Timestamp;
 
 import java.io.IOException;
 

File: logstash-core-event-java/src/test/java/org/logstash/AccessorsTest.java
Patch:
@@ -1,6 +1,7 @@
-package com.logstash;
+package org.logstash;
 
 import org.junit.Test;
+
 import static org.junit.Assert.*;
 
 import java.util.ArrayList;

File: logstash-core-event-java/src/test/java/org/logstash/EventTest.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import org.junit.Test;
 

File: logstash-core-event-java/src/test/java/org/logstash/JavafierTest.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import org.jruby.RubyBignum;
 import org.junit.Test;

File: logstash-core-event-java/src/test/java/org/logstash/KeyNodeTest.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import org.junit.Test;
 

File: logstash-core-event-java/src/test/java/org/logstash/RubyfierTest.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 import org.jruby.RubyArray;
 import org.jruby.RubyBignum;
@@ -36,7 +36,7 @@ public void testDeepMapWithString()
     {
         Map data = new HashMap();
         data.put("foo", "bar");
-        RubyHash rubyHash = ((RubyHash)Rubyfier.deep(ruby, data));
+        RubyHash rubyHash = ((RubyHash) Rubyfier.deep(ruby, data));
 
         // Hack to be able to retrieve the original, unconverted Ruby object from Map
         // it seems the only method providing this is internalGet but it is declared protected.

File: logstash-core-event-java/src/test/java/org/logstash/StringInterpolationTest.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash;
+package org.logstash;
 
 
 import org.joda.time.DateTime;

File: logstash-core-event-java/src/test/java/org/logstash/TestBase.java
Patch:
@@ -1,6 +1,6 @@
-package com.logstash;
+package org.logstash;
 
-import com.logstash.ext.JrubyTimestampExtLibrary;
+import org.logstash.ext.JrubyTimestampExtLibrary;
 import org.jruby.CompatVersion;
 import org.jruby.Ruby;
 import org.jruby.RubyInstanceConfig;

File: logstash-core-event-java/src/test/java/org/logstash/TimestampTest.java
Patch:
@@ -1,8 +1,9 @@
-package com.logstash;
+package org.logstash;
 
 import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
 import org.junit.Test;
+
 import static org.junit.Assert.*;
 
 public class TimestampTest {

File: logstash-core-event-java/src/test/java/org/logstash/bivalues/BiValueTest.java
Patch:
@@ -1,6 +1,6 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
-import com.logstash.TestBase;
+import org.logstash.TestBase;
 import org.joda.time.DateTime;
 import org.jruby.RubyBignum;
 import org.jruby.RubyBoolean;

File: logstash-core-event-java/src/test/java/org/logstash/bivalues/SomeJavaObject.java
Patch:
@@ -1,4 +1,4 @@
-package com.logstash.bivalues;
+package org.logstash.bivalues;
 
 public class SomeJavaObject<T> {
     private T value;

File: logstash-core-event-java/src/main/java/com/logstash/Event.java
Patch:
@@ -189,7 +189,7 @@ public static Event[] fromJson(String json)
     }
 
     public Map toMap() {
-        return this.data;
+        return Cloner.deep(this.data);
     }
 
     public Event overwrite(Event e) {

File: logstash-core-event-java/src/main/java/com/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -245,7 +245,7 @@ public IRubyObject ruby_to_s(ThreadContext context)
         @JRubyMethod(name = "to_hash")
         public IRubyObject ruby_to_hash(ThreadContext context) throws IOException
         {
-            return Rubyfier.deep(context.runtime, this.event.toMap());
+            return Rubyfier.deep(context.runtime, this.event.getData());
         }
 
         @JRubyMethod(name = "to_hash_with_metadata")

File: logstash-core-event-java/src/main/java/com/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -140,14 +140,14 @@ public IRubyObject ruby_initialize(ThreadContext context, IRubyObject[] args)
             return context.nil;
         }
 
-        @JRubyMethod(name = "[]", required = 1)
+        @JRubyMethod(name = "get", required = 1)
         public IRubyObject ruby_get_field(ThreadContext context, RubyString reference)
         {
             Object value = this.event.getField(reference.asJavaString());
             return Rubyfier.deep(context.runtime, value);
         }
 
-        @JRubyMethod(name = "[]=", required = 2)
+        @JRubyMethod(name = "set", required = 2)
         public IRubyObject ruby_set_field(ThreadContext context, RubyString reference, IRubyObject value)
         {
             String r = reference.asJavaString();

File: logstash-core-event-java/src/main/java/com/logstash/Timestamp.java
Patch:
@@ -70,7 +70,9 @@ public String toString() {
     }
 
     public long usec() {
-        return new Duration(JAN_1_1970.toDateTime(DateTimeZone.UTC), this.time).getMillis();
+        // JodaTime only supports milliseconds precision we can only return usec at millisec precision.
+        // note that getMillis() return millis since epoch
+        return (new Duration(JAN_1_1970.toDateTime(DateTimeZone.UTC), this.time).getMillis() % 1000) * 1000;
     }
 
     @Override

File: logstash-core-event-java/src/main/java/com/logstash/KeyNode.java
Patch:
@@ -1,7 +1,6 @@
 package com.logstash;
 
-import org.codehaus.jackson.JsonGenerationException;
-import org.codehaus.jackson.map.ObjectMapper;
+import com.fasterxml.jackson.databind.ObjectMapper;
 
 import java.io.IOException;
 import java.util.List;

File: logstash-core-event-java/src/main/java/com/logstash/TemplateNode.java
Patch:
@@ -1,7 +1,5 @@
 package com.logstash;
 
-import org.codehaus.jackson.JsonGenerationException;
-
 import java.io.IOException;
 
 /**

File: logstash-core-event-java/src/main/java/com/logstash/Timestamp.java
Patch:
@@ -1,6 +1,6 @@
 package com.logstash;
 
-import org.codehaus.jackson.map.annotate.JsonSerialize;
+import com.fasterxml.jackson.databind.annotation.JsonSerialize;
 import org.joda.time.DateTime;
 import org.joda.time.DateTimeZone;
 import org.joda.time.LocalDateTime;

File: logstash-core-event-java/src/main/java/com/logstash/TimestampSerializer.java
Patch:
@@ -1,8 +1,8 @@
 package com.logstash;
 
-import org.codehaus.jackson.JsonGenerator;
-import org.codehaus.jackson.map.JsonSerializer;
-import org.codehaus.jackson.map.SerializerProvider;
+import com.fasterxml.jackson.core.JsonGenerator;
+import com.fasterxml.jackson.databind.JsonSerializer;
+import com.fasterxml.jackson.databind.SerializerProvider;
 
 import java.io.IOException;
 

File: logstash-core-event-java/src/main/java/com/logstash/ext/JrubyTimestampExtLibrary.java
Patch:
@@ -1,7 +1,6 @@
 package com.logstash.ext;
 
 import com.logstash.*;
-import org.codehaus.jackson.map.annotate.JsonSerialize;
 import org.jruby.*;
 import org.jruby.anno.JRubyClass;
 import org.jruby.anno.JRubyMethod;

File: logstash-core-event-java/src/main/java/com/logstash/FieldReference.java
Patch:
@@ -11,7 +11,7 @@ public class FieldReference {
     private List<String> path;
     private String key;
     private String reference;
-    private static List<String> EMPTY_STRINGS = new ArrayList(Arrays.asList(new String[]{""}));
+    private static List<String> EMPTY_STRINGS = Arrays.asList("");
 
     public FieldReference(List<String> path, String key, String reference) {
         this.path = path;

File: logstash-core-event-java/src/main/java/com/logstash/StringInterpolation.java
Patch:
@@ -40,10 +40,9 @@ public int cacheSize() {
     public String evaluate(Event event, String template) throws IOException {
         TemplateNode compiledTemplate = (TemplateNode) this.cache.get(template);
 
-        if(compiledTemplate == null) {
+        if (compiledTemplate == null) {
             compiledTemplate = this.compile(template);
-            TemplateNode set = (TemplateNode) this.cache.putIfAbsent(template, compiledTemplate);
-            compiledTemplate = (set != null) ? set : compiledTemplate;
+            this.cache.put(template, compiledTemplate);
         }
 
         return compiledTemplate.evaluate(event);

File: logstash-core-event-java/src/main/java/com/logstash/Timestamp.java
Patch:
@@ -7,8 +7,6 @@
 import org.joda.time.Duration;
 import org.joda.time.format.DateTimeFormatter;
 import org.joda.time.format.ISODateTimeFormat;
-import org.jruby.Ruby;
-import org.jruby.RubyString;
 
 import java.util.Date;
 

File: logstash-core-event-java/src/test/java/com/logstash/FieldReferenceTest.java
Patch:
@@ -27,14 +27,14 @@ public void testParseSingleFieldPath() throws Exception {
     @Test
     public void testParse2FieldsPath() throws Exception {
         FieldReference f = FieldReference.parse("[foo][bar]");
-        assertEquals(f.getPath().toArray(), new String[]{"foo"});
+        assertArrayEquals(f.getPath().toArray(), new String[]{"foo"});
         assertEquals(f.getKey(), "bar");
     }
 
     @Test
     public void testParse3FieldsPath() throws Exception {
         FieldReference f = FieldReference.parse("[foo][bar]]baz]");
-        assertEquals(f.getPath().toArray(), new String[]{"foo", "bar"});
+        assertArrayEquals(f.getPath().toArray(), new String[]{"foo", "bar"});
         assertEquals(f.getKey(), "baz");
     }
 }
\ No newline at end of file

File: logstash-core-event-java/src/main/java/com/logstash/Timestamp.java
Patch:
@@ -13,7 +13,9 @@
 @JsonSerialize(using = TimestampSerializer.class)
 public class Timestamp implements Cloneable {
 
+    // all methods setting the time object must set it in the UTC timezone
     private DateTime time;
+
     // TODO: is this DateTimeFormatter thread safe?
     private static DateTimeFormatter iso8601Formatter = ISODateTimeFormat.dateTime();
 
@@ -50,7 +52,7 @@ public DateTime getTime() {
     }
 
     public void setTime(DateTime time) {
-        this.time = time;
+        this.time = time.toDateTime(DateTimeZone.UTC);
     }
 
     public static Timestamp now() {

File: logstash-core-event-java/src/main/java/com/logstash/ext/JrubyEventExtLibrary.java
Patch:
@@ -155,6 +155,8 @@ public IRubyObject ruby_set_field(ThreadContext context, RubyString reference, I
                     this.event.setField(r, RubyToJavaConverter.convertToList((RubyArray) value));
                 } else if (value instanceof RubyHash) {
                     this.event.setField(r, RubyToJavaConverter.convertToMap((RubyHash) value));
+                } else if (value.isNil()) {
+                    this.event.setField(r, null);
                 } else {
                     throw context.runtime.newTypeError("wrong argument type " + value.getMetaClass());
                 }

File: logstash-core-event-java/src/main/java/com/logstash/StringInterpolation.java
Patch:
@@ -63,7 +63,7 @@ public TemplateNode compile(String template) {
                 pos = matcher.end();
             }
 
-            if(pos < template.length() - 1) {
+            if(pos <= template.length() - 1) {
                 compiledTemplate.add(new StaticNode(template.substring(pos)));
             }
         }

File: logstash-core-event-java/src/test/java/com/logstash/StringInterpolationTest.java
Patch:
@@ -2,6 +2,7 @@
 
 
 import org.joda.time.DateTime;
+import org.joda.time.DateTimeZone;
 import org.junit.Test;
 
 import java.io.IOException;
@@ -97,7 +98,7 @@ public void TestEpoch() throws IOException {
         Event event = getTestEvent();
         String path = "%{+%s}";
         StringInterpolation si = StringInterpolation.getInstance();
-        assertEquals("1443682800", si.evaluate(event, path));
+        assertEquals("1443657600", si.evaluate(event, path));
     }
 
     @Test
@@ -132,7 +133,7 @@ public Event getTestEvent() {
         data.put("bar", "foo");
         data.put("awesome", "logstash");
         data.put("j", inner);
-        data.put("@timestamp", new DateTime(2015, 10, 1, 0, 0, 0));
+        data.put("@timestamp", new DateTime(2015, 10, 1, 0, 0, 0, DateTimeZone.UTC));
 
 
         Event event = new Event(data);

File: java/logstash-event/src/main/java/com/logstash/ext/JrubyTimestampExtLibrary.java
Patch:
@@ -134,7 +134,7 @@ public static IRubyObject ruby_at(ThreadContext context, IRubyObject recv, IRuby
         }
 
         @JRubyMethod(name = "now", meta = true)
-        public static IRubyObject ruby_at(ThreadContext context, IRubyObject recv)
+        public static IRubyObject ruby_now(ThreadContext context, IRubyObject recv)
         {
             return RubyTimestamp.newRubyTimestamp(context.runtime);
         }

File: java/logstash-event/src/test/java/com/logstash/StringInterpolationTest.java
Patch:
@@ -97,7 +97,7 @@ public void TestEpoch() throws IOException {
         Event event = getTestEvent();
         String path = "%{+%s}";
         StringInterpolation si = StringInterpolation.getInstance();
-        assertEquals("1443672000", si.evaluate(event, path));
+        assertEquals("1443682800", si.evaluate(event, path));
     }
 
     @Test
@@ -135,7 +135,7 @@ public Event getTestEvent() {
         data.put("@timestamp", new DateTime(2015, 10, 1, 0, 0, 0));
 
 
-        Event event = new EventImpl(data);
+        Event event = new Event(data);
 
         return event;
     }

