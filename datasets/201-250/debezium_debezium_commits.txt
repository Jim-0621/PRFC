File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/testhelper/TestInfrastructureHelper.java
Patch:
@@ -208,7 +208,7 @@ public static void setupDebeziumContainer(String connectorVersion, String restEx
         final String registry = debeziumContainerImageVersion.startsWith("1.2") ? "" : "quay.io/";
         final String debeziumVersion = debeziumContainerImageVersion.startsWith("1.2") ? "1.2.5.Final" : connectorVersion;
         String baseImageName = registry + "debezium/connect:nightly";
-        DEBEZIUM_CONTAINER = new DebeziumContainer(new ImageFromDockerfile("debezium/connect-rest-test:" + debeziumVersion)
+        DEBEZIUM_CONTAINER = new DebeziumContainer(new ImageFromDockerfile("quay.io/debezium/connect-rest-test:" + debeziumVersion)
                 .withFileFromPath(".", Paths.get(System.getProperty("project.build.directory")))
                 .withFileFromPath("Dockerfile", Paths.get(System.getProperty("project.basedir") + "/src/test/resources/Dockerfile.rest.test"))
                 .withBuildArg("BASE_IMAGE", baseImageName)

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/FloatVectorType.java
Patch:
@@ -44,7 +44,7 @@ public List<ValueBindDescriptor> bind(int index, Schema schema, Object value) {
             return List.of(new ValueBindDescriptor(index, null));
         }
 
-        if (!(value instanceof Collection<?>values)) {
+        if (!(value instanceof Collection<?> values)) {
             throw new DebeziumException("Expected value should be a collection");
         }
 

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/junit/jupiter/e2e/source/SourcePipelineInvocationContextProvider.java
Patch:
@@ -42,7 +42,6 @@
 import org.testcontainers.containers.Network;
 import org.testcontainers.containers.OracleContainer;
 import org.testcontainers.containers.PostgreSQLContainer;
-import org.testcontainers.containers.output.Slf4jLogConsumer;
 import org.testcontainers.lifecycle.Startable;
 import org.testcontainers.lifecycle.Startables;
 import org.testcontainers.utility.DockerImageName;

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/MySqlDatabaseDialect.java
Patch:
@@ -117,6 +117,9 @@ protected void registerTypes() {
         registerType(PointType.INSTANCE);
         registerType(ZonedTimestampType.INSTANCE);
         registerType(ZonedTimeType.INSTANCE);
+
+        registerType(FloatVectorType.INSTANCE);
+        registerType(DoubleVectorType.INSTANCE);
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/GeneralDatabaseDialect.java
Patch:
@@ -477,7 +477,7 @@ public Type getSchemaType(Schema schema) {
         }
 
         switch (schema.name()) {
-            case "io.debezium.data.SparseVector", "io.debezium.data.FloatVector" ->
+            case "io.debezium.data.SparseVector", "io.debezium.data.FloatVector", "io.debezium.data.DoubleVector" ->
                 throw new ConnectException(
                         String.format(
                                 "Dialect does not support schema type %s. Please use the VectorToJsonConverter transform in " +

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/PostgresDatabaseDialect.java
Patch:
@@ -195,6 +195,7 @@ protected void registerTypes() {
 
         registerType(SparseVectorType.INSTANCE);
         registerType(FloatVectorType.INSTANCE);
+        registerType(DoubleVectorType.INSTANCE);
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/GeneralDatabaseDialect.java
Patch:
@@ -477,7 +477,7 @@ public Type getSchemaType(Schema schema) {
         }
 
         switch (schema.name()) {
-            case "io.debezium.data.SparseVector" ->
+            case "io.debezium.data.SparseVector", "io.debezium.data.FloatVector" ->
                 throw new ConnectException(
                         String.format(
                                 "Dialect does not support schema type %s. Please use the VectorToJsonConverter transform in " +

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/PostgresDatabaseDialect.java
Patch:
@@ -194,6 +194,7 @@ protected void registerTypes() {
         registerType(OidType.INSTANCE);
 
         registerType(SparseVectorType.INSTANCE);
+        registerType(FloatVectorType.INSTANCE);
     }
 
     @Override

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/junit/jupiter/e2e/source/SourcePipelineInvocationContextProvider.java
Patch:
@@ -341,7 +341,7 @@ public Object resolveParameter(ParameterContext parameterContext,
 
     @SuppressWarnings("resource")
     private KafkaContainer getKafkaContainer() {
-        return DebeziumKafkaContainer.defaultKafkaContainer(network).withNetworkAliases("kafka");
+        return DebeziumKafkaContainer.defaultKRaftContainer(network).withNetworkAliases("kafka");
     }
 
     @SuppressWarnings("resource")

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/PostgresDatabaseDialect.java
Patch:
@@ -192,6 +192,8 @@ protected void registerTypes() {
         registerType(InetType.INSTANCE);
         registerType(CaseInsensitiveTextType.INSTANCE);
         registerType(OidType.INSTANCE);
+
+        registerType(SparseVectorType.INSTANCE);
     }
 
     @Override

File: debezium-connector-binlog/src/test/java/io/debezium/connector/binlog/BinlogConnectorIT.java
Patch:
@@ -40,7 +40,6 @@
 import io.debezium.config.Configuration;
 import io.debezium.config.EnumeratedValue;
 import io.debezium.config.Field;
-import io.debezium.connector.binlog.BinlogConnectorConfig.SecureConnectionMode;
 import io.debezium.connector.binlog.BinlogConnectorConfig.SnapshotMode;
 import io.debezium.connector.binlog.util.BinlogTestConnection;
 import io.debezium.connector.binlog.util.TestHelper;
@@ -169,7 +168,6 @@ protected void assertInvalidConfiguration(Config result) {
         assertNoConfigurationErrors(result, BinlogConnectorConfig.SCHEMA_HISTORY);
         assertNoConfigurationErrors(result, BinlogConnectorConfig.INCLUDE_SCHEMA_CHANGES);
         assertNoConfigurationErrors(result, BinlogConnectorConfig.SNAPSHOT_MODE);
-        assertNoConfigurationErrors(result, BinlogConnectorConfig.SSL_MODE);
         assertNoConfigurationErrors(result, BinlogConnectorConfig.SSL_KEYSTORE);
         assertNoConfigurationErrors(result, BinlogConnectorConfig.SSL_KEYSTORE_PASSWORD);
         assertNoConfigurationErrors(result, BinlogConnectorConfig.SSL_TRUSTSTORE);
@@ -206,7 +204,6 @@ protected void assertValidConfiguration(Config result) {
         validateConfigField(result, BinlogConnectorConfig.SCHEMA_HISTORY, "io.debezium.storage.kafka.history.KafkaSchemaHistory");
         validateConfigField(result, BinlogConnectorConfig.INCLUDE_SCHEMA_CHANGES, Boolean.TRUE);
         validateConfigField(result, BinlogConnectorConfig.SNAPSHOT_MODE, SnapshotMode.INITIAL);
-        validateConfigField(result, BinlogConnectorConfig.SSL_MODE, SecureConnectionMode.PREFERRED);
         validateConfigField(result, BinlogConnectorConfig.SSL_KEYSTORE, null);
         validateConfigField(result, BinlogConnectorConfig.SSL_KEYSTORE_PASSWORD, null);
         validateConfigField(result, BinlogConnectorConfig.SSL_TRUSTSTORE, null);

File: debezium-connector-mariadb/src/test/java/io/debezium/connector/mariadb/MariaDbConnectorIT.java
Patch:
@@ -31,12 +31,14 @@ protected Config validateConfiguration(Configuration configuration) {
     protected void assertInvalidConfiguration(Config result) {
         super.assertInvalidConfiguration(result);
         assertNoConfigurationErrors(result, MariaDbConnectorConfig.SNAPSHOT_LOCKING_MODE);
+        assertNoConfigurationErrors(result, MariaDbConnectorConfig.SSL_MODE);
     }
 
     @Override
     protected void assertValidConfiguration(Config result) {
         super.assertValidConfiguration(result);
         validateConfigField(result, MariaDbConnectorConfig.SNAPSHOT_LOCKING_MODE, SnapshotLockingMode.MINIMAL);
+        validateConfigField(result, MariaDbConnectorConfig.SSL_MODE, MariaDbConnectorConfig.MariaDbSecureConnectionMode.DISABLE);
     }
 
     @Override

File: debezium-connector-mariadb/src/test/java/io/debezium/connector/mariadb/rest/DebeziumMariaDbConnectorResourceIT.java
Patch:
@@ -246,7 +246,7 @@ public static ConnectorConfiguration getMariaDbConnectorConfiguration(int id, St
                 .with(KafkaSchemaHistory.TOPIC.name(), "dbhistory.inventory")
                 .with(MariaDbConnectorConfig.SERVER_ID.name(), Long.valueOf(5555 + id - 1))
                 // basic container does not support SSL out of the box
-                .with(MariaDbConnectorConfig.SSL_MODE.name(), "disabled");
+                .with(MariaDbConnectorConfig.SSL_MODE.name(), "disable");
 
         if (options != null && options.length > 0) {
             for (int i = 0; i < options.length; i += 2) {

File: debezium-connector-mariadb/src/test/java/io/debezium/connector/mariadb/util/MariaDbTestConnection.java
Patch:
@@ -17,7 +17,7 @@
  */
 public class MariaDbTestConnection extends BinlogTestConnection {
 
-    protected static ConnectionFactory FACTORY = JdbcConnection.patternBasedFactory("jdbc:mariadb://${hostname}:${port}/${dbname}");
+    protected static ConnectionFactory FACTORY = JdbcConnection.patternBasedFactory("jdbc:mariadb://${hostname}:${port}/${dbname}?sslMode=${ssl.mode}");
 
     /**
      * Create a new instance with the given configuration.

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -69,12 +69,14 @@ protected Config validateConfiguration(Configuration configuration) {
     protected void assertInvalidConfiguration(Config result) {
         super.assertInvalidConfiguration(result);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_LOCKING_MODE);
+        assertNoConfigurationErrors(result, MySqlConnectorConfig.SSL_MODE);
     }
 
     @Override
     protected void assertValidConfiguration(Config result) {
         super.assertValidConfiguration(result);
         validateConfigField(result, MySqlConnectorConfig.SNAPSHOT_LOCKING_MODE, SnapshotLockingMode.MINIMAL);
+        validateConfigField(result, MySqlConnectorConfig.SSL_MODE, MySqlConnectorConfig.MySqlSecureConnectionMode.PREFERRED);
     }
 
     @Override

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/e2e/AbstractJdbcSinkPipelineIT.java
Patch:
@@ -2031,7 +2031,9 @@ public void testDateTime2WithPrecisionDataType(Source source, Sink sink) throws
 
         int dateTime7NanoSeconds = 456789000;
         if (source.getOptions().isColumnTypePropagated() && SinkType.SQLSERVER.is(sink.getType())) {
-            dateTime7NanoSeconds = 456789100;
+            if (source.getOptions().getTemporalPrecisionMode() != TemporalPrecisionMode.MICROSECONDS) {
+                dateTime7NanoSeconds = 456789100;
+            }
         }
 
         final boolean connect = TemporalPrecisionMode.CONNECT.equals(source.getOptions().getTemporalPrecisionMode());

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java
Patch:
@@ -217,7 +217,7 @@ private void cleanUpStreamingOnStop(PostgresOffsetContext offsetContext) {
         }
     }
 
-    private boolean hasStreamingStoppingLsn(PostgresOffsetContext offsetContext, Lsn lastCompletelyProcessedLsn) {
+    private boolean haveNotReceivedStreamingStoppingLsn(PostgresOffsetContext offsetContext, Lsn lastCompletelyProcessedLsn) {
         return offsetContext.getStreamingStoppingLsn() == null ||
                 (lastCompletelyProcessedLsn.compareTo(offsetContext.getStreamingStoppingLsn()) < 0);
     }
@@ -227,7 +227,7 @@ private void processMessages(ChangeEventSourceContext context, PostgresPartition
         LOGGER.info("Processing messages");
         int noMessageIterations = 0;
         while (context.isRunning()
-                && !hasStreamingStoppingLsn(offsetContext, lastCompletelyProcessedLsn)
+                && haveNotReceivedStreamingStoppingLsn(offsetContext, lastCompletelyProcessedLsn)
                 && !commitOffsetFailure) {
             boolean receivedMessage = stream.readPending(message -> processReplicationMessages(partition, offsetContext, stream, message));
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java
Patch:
@@ -439,6 +439,7 @@ public void commitOffset(Map<String, ?> partition, Map<String, ?> offset) {
             }
         }
         catch (SQLException e) {
+            errorHandler.setProducerThrowable(e);
             throw new ConnectException(e);
         }
     }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/Lsn.java
Patch:
@@ -22,6 +22,8 @@ public class Lsn implements Comparable<Lsn>, Nullable {
 
     public static final Lsn NULL = new Lsn(null);
 
+    public static final Lsn ZERO = valueOf(new byte[10]);
+
     private final byte[] binary;
     private int[] unsignedBinary;
 

File: debezium-core/src/main/java/io/debezium/time/IsoDate.java
Patch:
@@ -15,8 +15,6 @@
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
 
-// Fixed javadoc descriptions!
-
 /**
  * A utility for converting various Java temporal object representations into a UTC ISO 8601 string representation,
  * specifically focusing on dates (without time or timezone information).

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/DebeziumKafkaContainer.java
Patch:
@@ -27,7 +27,8 @@ public static KafkaContainer defaultKRaftContainer(Network network) {
 
     public static KafkaContainer defaultKafkaContainer(Network network) {
         try (
-                KafkaContainer kafka = new KafkaContainer(DockerImageName.parse(defaultImage))
+                KafkaContainer kafka = new KafkaContainer(DockerImageName.parse(defaultImage)
+                        .asCompatibleSubstituteFor("confluentinc/cp-kafka"))
                         .withNetwork(network)) {
             return kafka;
         }

File: debezium-storage/debezium-storage-tests/src/test/java/io/debezium/storage/s3/history/S3SchemaHistoryIT.java
Patch:
@@ -60,7 +60,8 @@ public static void startS3() {
         client = S3Client.builder()
                 .credentialsProvider(AnonymousCredentialsProvider.create())
                 .region(Region.AWS_GLOBAL)
-                .endpointOverride(URI.create(container.getHttpEndpoint())).build();
+                .endpointOverride(URI.create(container.getHttpEndpoint()))
+                .forcePathStyle(true).build();
     }
 
     @AfterClass
@@ -87,6 +88,7 @@ protected SchemaHistory createHistory() {
                 .with(S3SchemaHistory.OBJECT_NAME, OBJECT_NAME)
                 .with(S3SchemaHistory.REGION_CONFIG, Region.AWS_GLOBAL.id())
                 .with(S3SchemaHistory.ENDPOINT_CONFIG, container.getHttpEndpoint())
+                .with(S3SchemaHistory.FORCE_PATH_STYLE_CONFIG, true)
                 .build();
         history.configure(config, null, SchemaHistoryListener.NOOP, true);
         history.start();

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/rest/DebeziumSqlServerConnectorResourceIT.java
Patch:
@@ -43,6 +43,9 @@ public static void checkCondition() {
     @Before
     public void start() throws URISyntaxException, IOException, InterruptedException {
         TestInfrastructureHelper.setupDebeziumContainer(Module.version(), DebeziumSqlServerConnectRestExtension.class.getName());
+        TestInfrastructureHelper.copyIntoContainer(DATABASE.SQLSERVER,
+                "/setup-sqlserver-database-with-encryption.sql",
+                "/opt/mssql-tools18/bin/setup-sqlserver-database-with-encryption.sql");
         TestInfrastructureHelper.startContainers(DATABASE.SQLSERVER);
         TestInfrastructureHelper.setupSqlServerTDEncryption();
     }

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/testhelper/TestInfrastructureHelper.java
Patch:
@@ -99,8 +99,6 @@ public enum DATABASE {
             .build();
 
     private static final MSSQLServerContainer<?> SQL_SERVER_CONTAINER = new MSSQLServerContainer<>(DockerImageName.parse("mcr.microsoft.com/mssql/server:2019-latest"))
-            .withCopyToContainer(Transferable.of(readBytesFromResource("/setup-sqlserver-database-with-encryption.sql")),
-                    "/opt/mssql-tools18/bin/setup-sqlserver-database-with-encryption.sql")
             .withNetwork(NETWORK)
             .withNetworkAliases("sqlserver")
             .withEnv("SA_PASSWORD", "Password!")
@@ -234,6 +232,8 @@ public static void defaultDebeziumContainer(String debeziumContainerImageVersion
     }
 
     public static void setupSqlServerTDEncryption() throws IOException, InterruptedException {
+        SQL_SERVER_CONTAINER.withCopyToContainer(Transferable.of(readBytesFromResource("/setup-sqlserver-database-with-encryption.sql")),
+                "/opt/mssql-tools18/bin/setup-sqlserver-database-with-encryption.sql");
         SQL_SERVER_CONTAINER.execInContainer(
                 "/opt/mssql-tools18/bin/sqlcmd",
                 "-S", "localhost",

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleExtendedStringIT.java
Patch:
@@ -309,7 +309,7 @@ public void shouldStreamMultipleExtendedStringColumnsGreaterThan4k() throws Exce
     }
 
     @Test
-    @FixFor({"DBZ-8034", "DBZ-8200"})
+    @FixFor({ "DBZ-8034", "DBZ-8200" })
     public void testRelaxedQuoteDetectionForExtendedStrings() throws Exception {
         TestHelper.dropTable(connection, "dbz8034");
         try {

File: debezium-core/src/main/java/io/debezium/transforms/ConnectRecordUtil.java
Patch:
@@ -57,6 +57,7 @@ public static <R extends ConnectRecord<R>> InsertField<R> insertStaticValueDeleg
         Map<String, String> delegateConfig = new HashMap<>();
         delegateConfig.put("static.field", field);
         delegateConfig.put("static.value", value);
+        delegateConfig.put("replace.null.with.default", "false");
         insertDelegate.configure(delegateConfig);
         return insertDelegate;
     }

File: debezium-core/src/main/java/io/debezium/util/Strings.java
Patch:
@@ -25,7 +25,6 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 import java.util.regex.PatternSyntaxException;
-import java.util.stream.Collectors;
 
 import io.debezium.annotation.ThreadSafe;
 import io.debezium.text.ParsingException;

File: debezium-storage/debezium-storage-jdbc/src/main/java/io/debezium/storage/jdbc/offset/JdbcOffsetBackingStore.java
Patch:
@@ -152,6 +152,8 @@ private void load() {
                     }
                 }
                 data = tmpData;
+                // The commit will release the lock of the debezium_offset_storage table
+                conn.commit();
             }, "loading offset data", false);
         }
         catch (SQLException e) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -224,6 +224,7 @@ public SchemaBuilder schemaBuilder(Column column) {
             case PgOid.INT4RANGE_OID:
             case PgOid.NUM_RANGE_OID:
             case PgOid.INT8RANGE_OID:
+            case PgOid.BPCHAR:
                 return SchemaBuilder.string();
             case PgOid.UUID:
                 return Uuid.builder();
@@ -468,6 +469,7 @@ public ValueConverter converter(Column column, Field fieldDefn) {
             case PgOid.INT4RANGE_OID:
             case PgOid.NUM_RANGE_OID:
             case PgOid.INT8RANGE_OID:
+            case PgOid.BPCHAR:
                 return data -> convertString(column, fieldDefn, data);
             case PgOid.POINT:
                 return data -> convertPoint(column, fieldDefn, data);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/UnchangedToastedReplicationMessageColumn.java
Patch:
@@ -71,6 +71,8 @@ private void setUnchangedToastValue(String typeWithModifiers) {
             case "_text":
             case "character varying[]":
             case "_varchar":
+            case "character[]":
+            case "_bpchar":
             case "json[]":
             case "_json":
             case "jsonb[]":

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcSinkConnectorConfig.java
Patch:
@@ -25,6 +25,7 @@
 import io.debezium.config.Field.ValidationOutput;
 import io.debezium.connector.jdbc.naming.ColumnNamingStrategy;
 import io.debezium.connector.jdbc.naming.DefaultColumnNamingStrategy;
+import io.debezium.connector.jdbc.naming.TemporaryBackwardCompatibleCollectionNamingStrategyProxy;
 import io.debezium.sink.SinkConnectorConfig;
 import io.debezium.sink.filter.FieldFilterFactory;
 import io.debezium.sink.filter.FieldFilterFactory.FieldNameFilter;
@@ -384,7 +385,8 @@ public JdbcSinkConnectorConfig(Map<String, String> props) {
         this.primaryKeyFields = Strings.setOf(config.getString(PRIMARY_KEY_FIELDS_FIELD), String::new);
         this.schemaEvolutionMode = SchemaEvolutionMode.parse(config.getString(SCHEMA_EVOLUTION));
         this.quoteIdentifiers = config.getBoolean(QUOTE_IDENTIFIERS_FIELD);
-        this.collectionNamingStrategy = config.getInstance(COLLECTION_NAMING_STRATEGY_FIELD, CollectionNamingStrategy.class);
+        this.collectionNamingStrategy = new TemporaryBackwardCompatibleCollectionNamingStrategyProxy(
+                config.getInstance(COLLECTION_NAMING_STRATEGY_FIELD, CollectionNamingStrategy.class), this);
         this.columnNamingStrategy = config.getInstance(COLUMN_NAMING_STRATEGY_FIELD, ColumnNamingStrategy.class);
         this.databaseTimezone = config.getString(USE_TIME_ZONE_FIELD);
         this.postgresPostgisSchema = config.getString(POSTGRES_POSTGIS_SCHEMA_FIELD);

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/DatabaseDialect.java
Patch:
@@ -208,7 +208,7 @@ public interface DatabaseDialect {
 
     /**
      * Returns whether the user has specified a time zone JDBC property or whether the connector
-     * configuration property {@code database.time_zone} has been specified.
+     * configuration property {@code use.time.zone} has been specified.
      *
      * @return true if the properties have been specified; false otherwise.
      */

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/resources/ConnectorFactories.java
Patch:
@@ -206,7 +206,7 @@ public ConnectorConfigBuilder jdbcSink(SqlDatabaseController controller, String
                 .put("insert.mode", "upsert")
                 .put("primary.key.mode", "kafka")
                 .put("schema.evolution", "basic")
-                .put("database.time_zone", "UTC")
+                .put("use.time.zone", "UTC")
                 .put("topics", "jdbc_sink_test");
     }
 }

File: debezium-core/src/test/java/io/debezium/transforms/ExtractNewRecordStateTest.java
Patch:
@@ -945,7 +945,6 @@ public void testEnvelopeTimestampFieldsHandledCorrectly() {
         }
     }
 
-
     @Test
     @FixFor("DBZ-8393")
     public void testAddHeadersForNonEnvelopeRecord() {

File: debezium-embedded/src/test/java/io/debezium/pipeline/AbstractBlockingSnapshotTest.java
Patch:
@@ -301,7 +301,7 @@ public void aFailedBlockingSnapshotShouldNotCauseInitialSnapshotOnRestart() thro
                 .with(CommonConnectorConfig.SNAPSHOT_MODE_TABLES, String.join(",", tableDataCollectionIds())));
 
         sendAdHocSnapshotSignalWithAdditionalConditionsWithSurrogateKey(
-                Map.of(tableDataCollectionIds().get(0), String.format("SELECT * FROM %s", tableNames().get(0)),
+                Map.of(tableDataCollectionIds().get(0), String.format("SELECT * FROM %s ORDER BY PK ASC", tableNames().get(0)),
                         tableDataCollectionIds().get(1), "SELECT failing query"),
                 "", BLOCKING,
                 tableDataCollectionIds().get(0), tableDataCollectionIds().get(1));

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorIT.java
Patch:
@@ -1982,7 +1982,7 @@ public void testEmptySchemaWarningAfterApplyingFilters() throws Exception {
 
         start(SqlServerConnector.class, config);
         assertConnectorIsRunning();
-        waitForAvailableRecords(100, TimeUnit.MILLISECONDS);
+        waitForAvailableRecords(1, TimeUnit.SECONDS);
 
         stopConnector(value -> assertThat(logInterceptor.containsWarnMessage(DatabaseSchema.NO_CAPTURED_DATA_COLLECTIONS_WARNING)).isTrue());
     }

File: debezium-connector-binlog/src/main/java/io/debezium/connector/binlog/BinlogReadOnlyIncrementalSnapshotChangeEventSource.java
Patch:
@@ -146,8 +146,8 @@ public void addDataCollectionNamesToSnapshot(SignalPayload<P> signalPayload, Sna
     }
 
     @Override
-    public void stopSnapshot(P partition, OffsetContext offsetContext, Map<String, Object> additionalData, List<String> dataCollectionIds) {
-        super.stopSnapshot(partition, offsetContext, additionalData, dataCollectionIds);
+    public void requestStopSnapshot(P partition, OffsetContext offsetContext, Map<String, Object> additionalData, List<String> dataCollectionIds) {
+        super.requestStopSnapshot(partition, offsetContext, additionalData, dataCollectionIds);
         getContext().setSignalOffset((Long) additionalData.get(KafkaSignalChannel.CHANNEL_OFFSET));
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/IncrementalSnapshotIT.java
Patch:
@@ -612,7 +612,7 @@ public void stopCurrentIncrementalSnapshotWithoutCollectionsAndTakeNewNewIncreme
         // Consume any residual left-over events after stopping incremental snapshots such as open/close
         // and wait for the stop message in the connector logs
         assertThat(consumeAnyRemainingIncrementalSnapshotEventsAndCheckForStopMessage(
-                interceptor, "Stopping incremental snapshot")).isTrue();
+                interceptor, "Removed collections from incremental snapshot: ")).isTrue();
 
         // stop the connector
         stopConnector((r) -> interceptor.clear());

File: debezium-core/src/main/java/io/debezium/pipeline/signal/actions/snapshotting/StopSnapshot.java
Patch:
@@ -49,7 +49,7 @@ public boolean arrived(SignalPayload<P> signalPayload) throws InterruptedExcepti
         switch (type) {
             case INCREMENTAL:
                 dispatcher.getIncrementalSnapshotChangeEventSource()
-                        .stopSnapshot(signalPayload.partition, signalPayload.offsetContext, signalPayload.additionalData, dataCollections);
+                        .requestStopSnapshot(signalPayload.partition, signalPayload.offsetContext, signalPayload.additionalData, dataCollections);
                 break;
         }
 

File: debezium-core/src/main/java/io/debezium/pipeline/source/snapshot/incremental/IncrementalSnapshotChangeEventSource.java
Patch:
@@ -36,7 +36,7 @@ public interface IncrementalSnapshotChangeEventSource<P extends Partition, T ext
     void addDataCollectionNamesToSnapshot(SignalPayload<P> signalPayload, SnapshotConfiguration snapshotConfiguration)
             throws InterruptedException;
 
-    void stopSnapshot(P partition, OffsetContext offsetContext, Map<String, Object> additionalData, List<String> dataCollectionIds);
+    void requestStopSnapshot(P partition, OffsetContext offsetContext, Map<String, Object> additionalData, List<String> dataCollectionIds);
 
     default void processHeartbeat(P partition, OffsetContext offsetContext) throws InterruptedException {
     }

File: debezium-core/src/main/java/io/debezium/pipeline/source/snapshot/incremental/IncrementalSnapshotContext.java
Patch:
@@ -65,7 +65,7 @@ List<DataCollection<T>> addDataCollectionNamesToSnapshot(String correlationId, L
 
     void setSchemaVerificationPassed(boolean schemaVerificationPassed);
 
-    void stopSnapshot();
+    void requestSnapshotStop(List<String> dataCollectionIds);
 
     boolean removeDataCollectionFromSnapshot(String dataCollectionId);
 
@@ -75,4 +75,6 @@ List<DataCollection<T>> addDataCollectionNamesToSnapshot(String correlationId, L
 
     String getCorrelationId();
 
+    List<String> getDataCollectionsToStop();
+
 }

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/ConnectorConfigBuilder.java
Patch:
@@ -58,11 +58,13 @@ public ConnectorConfigBuilder addApicurioAvroSupport(String apicurioUrl) {
         config.put("key.converter.apicurio.registry.url", apicurioUrl);
         config.put("key.converter.apicurio.registry.auto-register", true);
         config.put("key.converter.apicurio.registry.find-latest", true);
+        config.put("key.converter.apicurio.registry.headers.enabled", false);
 
         config.put("value.converter", "io.apicurio.registry.utils.converter.AvroConverter");
         config.put("value.converter.apicurio.registry.url", apicurioUrl);
         config.put("value.converter.apicurio.registry.auto-register", true);
         config.put("value.converter.apicurio.registry.find-latest", true);
+        config.put("value.converter.apicurio.registry.headers.enabled", false);
 
         config.put("schema.name.adjustment.mode", "avro");
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleErrorHandler.java
Patch:
@@ -40,7 +40,8 @@ public class OracleErrorHandler extends ErrorHandler {
             "ORA-04030", // out of process memory
             "ORA-00310", // archived log contains sequence *; sequence * required
             "ORA-01343", // LogMiner encountered corruption in the logstream
-            "ORA-01371"); // Complete LogMiner dictionary not found
+            "ORA-01371", // Complete LogMiner dictionary not found
+            "ORA-01001"); // Invalid cursor
 
     /**
      * Contents of this set should be any type of error message text;

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConnection.java
Patch:
@@ -1659,13 +1659,13 @@ public String getQualifiedTableName(TableId tableId) {
         return tableId.schema() + "." + tableId.table();
     }
 
-    public Map<String, Object> reselectColumns(TableId tableId, List<String> columns, List<String> keyColumns, List<Object> keyValues, Struct source)
+    public Map<String, Object> reselectColumns(Table table, List<String> columns, List<String> keyColumns, List<Object> keyValues, Struct source)
             throws SQLException {
         final String query = String.format("SELECT %s FROM %s WHERE %s",
                 columns.stream().map(this::quotedColumnIdString).collect(Collectors.joining(",")),
-                quotedTableIdString(tableId),
+                quotedTableIdString(table.id()),
                 keyColumns.stream().map(key -> key + "=?").collect(Collectors.joining(" AND ")));
-        return reselectColumns(query, tableId, columns, keyValues);
+        return reselectColumns(query, table.id(), columns, keyValues);
     }
 
     protected Map<String, Object> reselectColumns(String query, TableId tableId, List<String> columns, List<Object> bindValues) throws SQLException {

File: debezium-core/src/main/java/io/debezium/processors/reselect/ReselectColumnsPostProcessor.java
Patch:
@@ -165,7 +165,7 @@ public void apply(Object messageKey, Struct value) {
 
         final Map<String, Object> selections;
         try {
-            selections = jdbcConnection.reselectColumns(tableId, requiredColumnSelections, keyColumns, keyValues, source);
+            selections = jdbcConnection.reselectColumns(table, requiredColumnSelections, keyColumns, keyValues, source);
             if (selections.isEmpty()) {
                 LOGGER.warn("Failed to find row in table {} with key {}.", tableId, key);
                 return;

File: debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java
Patch:
@@ -257,7 +257,7 @@ public void doBlockingSnapshot(P partition, OffsetContext offsetContext, Snapsho
 
                 }
                 catch (Exception e) {
-                    LOGGER.error("Error while executing requested blocking snapshot: {}", e.getMessage());
+                    LOGGER.warn("Error while executing requested blocking snapshot.", e);
                     resumeStreaming(partition);
                 }
             }

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/connectors/JsonConnectorDeployer.java
Patch:
@@ -43,7 +43,7 @@ public void deploy(ConnectorConfigBuilder config) {
         try (Response res = http.newCall(r).execute()) {
             if (!res.isSuccessful()) {
                 LOGGER.error(res.request().url().toString());
-                LOGGER.error(res.body().toString());
+                LOGGER.error(new String(res.body().bytes()));
                 throw new RuntimeException("Connector registration request returned status code '" + res.code() + "'");
             }
             LOGGER.info("Registered kafka connector '" + config.getConnectorName() + "'");

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SnapshotIsolationIT.java
Patch:
@@ -131,4 +131,3 @@ private void assertRecord(Struct record, List<SchemaAndValueField> expected) {
         expected.forEach(schemaAndValueField -> schemaAndValueField.assertFor(record));
     }
 }
- 
\ No newline at end of file

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SnapshotIsolationIT.java
Patch:
@@ -122,7 +122,7 @@ private void takeSnapshot(PostgresConnectorConfig.SnapshotIsolationMode lockingM
             assertThat(record1.sourceOffset())
                     .extracting("snapshot").containsExactly(true);
             assertThat(record1.sourceOffset())
-                    .extracting("snapshot_completed").containsExactly(i == 4 - 1);
+                    .extracting("last_snapshot_record").containsExactly(i == 4 - 1);
             assertNull(value1.get("before"));
         }
     }

File: debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java
Patch:
@@ -248,6 +248,7 @@ public void doBlockingSnapshot(P partition, OffsetContext offsetContext, Snapsho
 
                 SnapshottingTask snapshottingTask = snapshotSource.getBlockingSnapshottingTask(partition, (O) offsetContext, snapshotConfiguration);
                 SnapshotResult<O> snapshotResult = doSnapshot(snapshotSource, context, partition, (O) offsetContext, snapshottingTask);
+                eventDispatcher.setEventListener(streamingMetrics);
 
                 if (running && snapshotResult.isCompletedOrSkipped()) {
                     previousLogContext.set(taskContext.configureLoggingContext("streaming", partition));

File: debezium-embedded/src/main/java/io/debezium/embedded/async/AsyncEmbeddedEngine.java
Patch:
@@ -24,6 +24,8 @@
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.Future;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 import java.util.concurrent.atomic.AtomicReference;
@@ -152,7 +154,7 @@ private AsyncEmbeddedEngine(Properties config,
         taskService = Executors.newFixedThreadPool(this.config.getInteger(ConnectorConfig.TASKS_MAX_CONFIG, () -> 1));
         final String processingThreads = this.config.getString(AsyncEmbeddedEngine.RECORD_PROCESSING_THREADS);
         if (processingThreads == null || processingThreads.isBlank()) {
-            recordService = Executors.newCachedThreadPool();
+            recordService = new ThreadPoolExecutor(0, AsyncEngineConfig.AVAILABLE_CORES, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue());
         }
         else {
             recordService = Executors.newFixedThreadPool(computeRecordThreads(processingThreads));

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/ApicurioRegistryTest.java
Patch:
@@ -146,7 +146,8 @@ public void shouldConvertToAvro() throws Exception {
 
             debeziumContainer.registerConnector("my-connector-avro", getConfiguration(
                     2, "io.apicurio.registry.utils.converter.AvroConverter",
-                    "schema.name.adjustment.mode", "avro"));
+                    "schema.name.adjustment.mode", "avro",
+                    "key.converter.apicurio.registry.headers.enabled", "false"));
 
             consumer.subscribe(Arrays.asList("dbserver2.todo.todo"));
 

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/sqlserver/DockerSqlServerController.java
Patch:
@@ -45,7 +45,7 @@ public void initialize() throws InterruptedException {
         try {
             container.copyFileToContainer(Transferable.of(Files.readAllBytes(initScript)), DB_INIT_SCRIPT_PATH_CONTAINER);
             container.execInContainer(
-                    "/opt/mssql-tools/bin/sqlcmd", "-U", "sa", "-P", DATABASE_SQLSERVER_SA_PASSWORD, "-i", DB_INIT_SCRIPT_PATH_CONTAINER);
+                    "/opt/mssql-tools18/bin/sqlcmd", "-U", "sa", "-P", DATABASE_SQLSERVER_SA_PASSWORD, "-i", DB_INIT_SCRIPT_PATH_CONTAINER, "-C", "-N", "o");
         }
         catch (IOException e) {
             throw new RuntimeException(e);

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/sqlserver/OcpSqlServerController.java
Patch:
@@ -54,7 +54,7 @@ public void initialize() throws InterruptedException {
         ocp.pods().inNamespace(project).withName(pod.getMetadata().getName())
                 .file(DB_INIT_SCRIPT_PATH_CONTAINER)
                 .upload(initScript);
-        ocpUtils.executeCommand(deployment, project, true, "/opt/mssql-tools/bin/sqlcmd", "-U", "sa", "-P", DATABASE_SQLSERVER_SA_PASSWORD, "-i",
-                DB_INIT_SCRIPT_PATH_CONTAINER);
+        ocpUtils.executeCommand(deployment, project, true, "/opt/mssql-tools18/bin/sqlcmd", "-U", "sa", "-P", DATABASE_SQLSERVER_SA_PASSWORD, "-i",
+                DB_INIT_SCRIPT_PATH_CONTAINER, "-C", "-N", "o");
     }
 }

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -328,7 +328,7 @@ protected StructGenerator createValueGenerator(Schema schema, TableId tableId, L
                             result.put(fields[i], value);
                         }
                         catch (final Exception e) {
-                            Column col = columns.get(i);
+                            Column col = columnsThatShouldBeAdded.get(i);
                             String message = "Failed to properly convert data value for '{}.{}' of type {}";
                             if (eventConvertingFailureHandlingMode == null) {
                                 Loggings.logErrorAndTraceRecord(LOGGER, row,

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcChangeEventSink.java
Patch:
@@ -30,7 +30,7 @@
 import io.debezium.connector.jdbc.naming.TableNamingStrategy;
 import io.debezium.connector.jdbc.relational.TableDescriptor;
 import io.debezium.connector.jdbc.relational.TableId;
-import io.debezium.pipeline.sink.spi.ChangeEventSink;
+import io.debezium.pipeline.spi.ChangeEventSink;
 import io.debezium.util.Stopwatch;
 import io.debezium.util.Strings;
 
@@ -52,7 +52,6 @@ public class JdbcChangeEventSink implements ChangeEventSink {
     private final RecordWriter recordWriter;
 
     public JdbcChangeEventSink(JdbcSinkConnectorConfig config, StatelessSession session, DatabaseDialect dialect, RecordWriter recordWriter) {
-
         this.config = config;
         this.tableNamingStrategy = config.getTableNamingStrategy();
         this.dialect = dialect;

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcSinkConnectorTask.java
Patch:
@@ -28,7 +28,7 @@
 import io.debezium.DebeziumException;
 import io.debezium.connector.jdbc.dialect.DatabaseDialect;
 import io.debezium.connector.jdbc.dialect.DatabaseDialectResolver;
-import io.debezium.pipeline.sink.spi.ChangeEventSink;
+import io.debezium.pipeline.spi.ChangeEventSink;
 import io.debezium.util.Stopwatch;
 import io.debezium.util.Strings;
 

File: debezium-core/src/main/java/io/debezium/pipeline/spi/ChangeEventSink.java
Patch:
@@ -3,7 +3,7 @@
  *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
-package io.debezium.pipeline.sink.spi;
+package io.debezium.pipeline.spi;
 
 import java.util.Collection;
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleErrorHandler.java
Patch:
@@ -60,8 +60,8 @@ public class OracleErrorHandler extends ErrorHandler {
      */
     @Immutable
     private static final Set<String> RETRIABLE_ORA600_ERROR_MESSAGES = Collect.unmodifiableSet(
-            "krvrdGetUID" // Changes made to object identifier (schema change)
-    );
+            "krvrdGetUID", // Changes made to object identifier (schema change)
+            "krvrdccs10");
 
     public OracleErrorHandler(OracleConnectorConfig connectorConfig, ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {
         super(OracleConnector.class, connectorConfig, queue, replacedErrorHandler);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -653,7 +653,7 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
             .withDisplayName("Controls the maximum size of the object ID cache")
             .withType(Type.INT)
             .withWidth(Width.SHORT)
-            .withDefault(10)
+            .withDefault(256)
             .withImportance(Importance.LOW)
             .withValidation(OracleConnectorConfig::validateObjectIdCacheSize)
             .withDescription("The connector maintains a least-recently used cache of database table object ID to name mappings. "

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/olr/OpenLogReplicatorValueConverter.java
Patch:
@@ -115,7 +115,7 @@ protected Object convertTimestampWithZone(Column column, Field fieldDefn, Object
     @Override
     protected Object convertTimestampWithLocalZone(Column column, Field fieldDefn, Object value) {
         if (value instanceof Number) {
-            final Instant instant = Instant.ofEpochSecond(0, (Long) value);
+            final Instant instant = Instant.ofEpochSecond(0, ((Number) value).longValue());
             return getTimestampWithLocalTimeZoneFormatter(column).format(OffsetDateTime.ofInstant(instant, ZoneOffset.UTC));
         }
         return super.convertTimestampWithLocalZone(column, fieldDefn, value);
@@ -160,12 +160,12 @@ private Object convertTimestampValue(Column column, Object value) {
                 value = ((BigInteger) value).divide(BigInteger.valueOf(1_000_000L)).longValue();
             }
             else {
-                value = ((Long) value) / 1_000_000L;
+                value = ((Number) value).longValue() / 1_000_000L;
             }
         }
         else {
             // TIMESTAMP(n)
-            value = Instant.ofEpochSecond(0, (Long) value);
+            value = Instant.ofEpochSecond(0, ((Number) value).longValue());
         }
         return value;
     }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/processor/AbstractProcessorTest.java
Patch:
@@ -233,7 +233,7 @@ public void shouldLogAdditionalDetailsForAbandonedTransaction() throws Exception
 
             connection.commit();
 
-            assertThat(logInterceptor.containsMessage(", 1 tables [ORCLPDB1.DEBEZIUM.DBZ8044]")).isTrue();
+            assertThat(logInterceptor.containsMessage(String.format(", 1 tables [%s.DEBEZIUM.DBZ8044]", TestHelper.getDatabaseName()))).isTrue();
         }
         finally {
             TestHelper.dropTable(connection, "dbz8044");

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -190,6 +190,8 @@ protected DataTypeResolver initializeDataTypeResolver() {
                         .setDefaultLengthScaleDimension(10, 0),
                 new DataTypeEntry(Types.BIT, MySqlParser.BIT)
                         .setDefaultLengthDimension(1),
+                new DataTypeEntry(Types.OTHER, MySqlParser.VECTOR)
+                        .setDefaultLengthDimension(2048),
                 new DataTypeEntry(Types.TIME, MySqlParser.TIME),
                 new DataTypeEntry(Types.TIMESTAMP_WITH_TIMEZONE, MySqlParser.TIMESTAMP),
                 new DataTypeEntry(Types.TIMESTAMP, MySqlParser.DATETIME),

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -866,7 +866,9 @@ protected Object convertBits(Column column, Field fieldDefn, Object data, int nu
     }
 
     protected Object convertMoney(Column column, Field fieldDefn, Object data, DecimalMode mode) {
-        return convertValue(column, fieldDefn, data, BigDecimal.ZERO.setScale(moneyFractionDigits), (r) -> {
+        var fallback = decimalMode.equals(decimalMode.STRING) ? BigDecimal.ZERO.setScale(moneyFractionDigits).toString()
+                : decimalMode.equals(decimalMode.DOUBLE) ? BigDecimal.ZERO.setScale(moneyFractionDigits).doubleValue() : BigDecimal.ZERO.setScale(moneyFractionDigits);
+        return convertValue(column, fieldDefn, data, fallback, (r) -> {
             switch (mode) {
                 case DOUBLE:
                     if (data instanceof BigDecimal) {

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/sink/SinkConnectorIT.java
Patch:
@@ -77,7 +77,7 @@ private Configuration.Builder mongodbSinkConfig() {
     }
 
     default void startSink(Function<Configuration.Builder, Configuration.Builder> custConfig) {
-        TestInfrastructureHelper.setupDebeziumContainer(Module.version(), null);
+        TestInfrastructureHelper.setupDebeziumContainer(Module.version(), null, TestInfrastructureHelper.parseDebeziumVersion(Module.version()));
         TestInfrastructureHelper.startContainers(DATABASE.DEBEZIUM_ONLY);
         final Configuration config = custConfig.apply(mongodbSinkConfig()).build();
         TestInfrastructureHelper.getDebeziumContainer().registerConnector(SINK_CONNECTOR_NAME, ConnectorConfiguration.from(config.asMap()));

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/sink/SinkConnectorReplicaSetIT.java
Patch:
@@ -15,10 +15,12 @@
 
 import io.debezium.connector.mongodb.AbstractMongoConnectorIT;
 import io.debezium.connector.mongodb.sink.junit.NetworkIsolatedMongoDbDatabaseProvider;
+import io.debezium.junit.RequiresAssemblyProfile;
 import io.debezium.testing.testcontainers.MongoDbDeployment;
 import io.debezium.testing.testcontainers.testhelper.TestInfrastructureHelper;
 import io.debezium.testing.testcontainers.util.DockerUtils;
 
+@RequiresAssemblyProfile
 public class SinkConnectorReplicaSetIT extends AbstractMongoConnectorIT implements SinkConnectorIT {
 
     protected static MongoDbDeployment mongo;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/sink/SinkConnectorShardedClusterIT.java
Patch:
@@ -15,11 +15,13 @@
 
 import io.debezium.connector.mongodb.AbstractShardedMongoConnectorIT;
 import io.debezium.connector.mongodb.sink.junit.NetworkIsolatedMongoDbDatabaseProvider;
+import io.debezium.junit.RequiresAssemblyProfile;
 import io.debezium.testing.testcontainers.MongoDbDeployment;
 import io.debezium.testing.testcontainers.MongoDbShardedCluster;
 import io.debezium.testing.testcontainers.testhelper.TestInfrastructureHelper;
 import io.debezium.testing.testcontainers.util.DockerUtils;
 
+@RequiresAssemblyProfile
 public class SinkConnectorShardedClusterIT extends AbstractShardedMongoConnectorIT implements SinkConnectorIT {
 
     protected static MongoDbDeployment mongo;

File: debezium-core/src/test/java/io/debezium/junit/AnnotationBasedTestRule.java
Patch:
@@ -24,12 +24,12 @@ protected static Statement emptyStatement(final String reason, final Description
             @Override
             public void evaluate() throws Throwable {
                 StringBuilder messageBuilder = new StringBuilder(description.testCount());
-                messageBuilder.append("Skipped ").append(description.toString());
+                messageBuilder.append("Skipped ").append(description);
                 if (reason != null && !reason.trim().isEmpty()) {
                     messageBuilder.append(" because: ").append(reason);
                 }
 
-                System.out.println(messageBuilder.toString());
+                System.out.println(messageBuilder);
             }
         };
     }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -538,8 +538,9 @@ public Optional<SlotCreationResult> createReplicationSlot() throws SQLException
                     break;
                 }
                 catch (SQLException ex) {
-                    // intercept the statement timeout error and retry
-                    if (ex.getMessage().contains("canceling statement due to user request")) {
+                    // intercept the statement timeout error (due to query_canceled or lock_not_available) and retry
+                    // ref: https://www.postgresql.org/docs/current/errcodes-appendix.html
+                    if (ex.getSQLState().equals("57014") || ex.getSQLState().equals("55P03")) {
                         String message = "Creation of replication slot failed; " +
                                 "query to create replication slot timed out, please make sure that there are no long running queries on the database.";
                         if (++tryCount > maxRetries) {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/connection/ReplicationConnectionIT.java
Patch:
@@ -158,7 +158,7 @@ public void shouldRetryAndFailIfSlotCreationFailsWithTimeoutErrorOnLimitedRetrie
         }
         catch (Exception e) {
             assertTrue(interceptor.containsWarnMessage("and retrying, attempt number"));
-            assertTrue(e.getCause().getMessage().contains("ERROR: canceling statement due to user request"));
+            assertTrue(((SQLException) e.getCause()).getSQLState().equals("57014"));
             assertTrue(e.getMessage().contains("query to create replication slot timed out"));
             throw e;
         }
@@ -185,7 +185,7 @@ public void shouldSucceedIfSlotCreationSucceedsAfterTimeoutErrors() throws Excep
         }
         catch (Exception e) {
             assertTrue(interceptor.containsWarnMessage("and retrying, attempt number"));
-            assertTrue(e.getCause().getMessage().contains("ERROR: canceling statement due to user request"));
+            assertTrue(((SQLException) e.getCause()).getSQLState().equals("57014"));
             assertTrue(e.getMessage().contains("query to create replication slot timed out"));
         }
         finally {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/converters/PostgresCloudEventsMaker.java
Patch:
@@ -40,9 +40,9 @@ public PostgresCloudEventsMaker(RecordAndMetadata recordAndMetadata, SerializerT
     @Override
     public String ceId() {
         return "name:" + sourceField(AbstractSourceInfo.SERVER_NAME_KEY)
-                + ";lsn:" + sourceField(LSN_KEY).toString()
-                + ";txId:" + sourceField(TXID_KEY).toString()
-                + ";sequence:" + sourceField(SEQUENCE_KEY).toString();
+                + ";lsn:" + sourceField(LSN_KEY)
+                + ";txId:" + sourceField(TXID_KEY)
+                + ";sequence:" + sourceField(SEQUENCE_KEY);
     }
 
     @Override

File: debezium-connector-binlog/src/main/java/io/debezium/connector/binlog/BinlogConnectorConfig.java
Patch:
@@ -832,7 +832,7 @@ public String getPassword() {
      * @return the database cluster server unique identifier
      */
     public long getServerId() {
-        return config.getInteger(SERVER_ID);
+        return config.getLong(SERVER_ID);
     }
 
     /**

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcChangeEventSink.java
Patch:
@@ -9,7 +9,7 @@
 
 import java.sql.SQLException;
 import java.util.Collection;
-import java.util.HashMap;
+import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Optional;
@@ -65,8 +65,8 @@ public JdbcChangeEventSink(JdbcSinkConnectorConfig config, StatelessSession sess
     @Override
     public void execute(Collection<SinkRecord> records) {
 
-        final Map<TableId, Buffer> updateBufferByTable = new HashMap<>();
-        final Map<TableId, Buffer> deleteBufferByTable = new HashMap<>();
+        final Map<TableId, Buffer> updateBufferByTable = new LinkedHashMap<>();
+        final Map<TableId, Buffer> deleteBufferByTable = new LinkedHashMap<>();
 
         for (SinkRecord record : records) {
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/connection/ReplicationConnectionIT.java
Patch:
@@ -134,7 +134,7 @@ public void shouldNotRetryIfSlotCreationFailsWithoutTimeoutError() throws Except
             }
             catch (Exception e) {
                 assertFalse(interceptor.containsWarnMessage("and retrying, attempt number"));
-                assertTrue(e.getMessage().contains("ERROR: replication slot \"test1\" already exists"));
+                assertTrue(e.getMessage().contains("ERROR: replication slot \"testslot1\" already exists"));
                 throw e;
             }
         }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/transforms/timescaledb/TimescaleDbDatabaseTest.java
Patch:
@@ -168,7 +168,7 @@ public void shouldTransformCompressedChunks() throws Exception {
 
     private void dropPublication(PostgresConnection connection) {
         try {
-            connection.execute("DROP PUBLICATION dbz_publication");
+            connection.execute("DROP PUBLICATION IF EXISTS dbz_publication");
         }
         catch (Exception e) {
             LOGGER.debug("Error while dropping publication", e);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractTransactionCachingLogMinerEventProcessor.java
Patch:
@@ -367,10 +367,9 @@ protected Scn calculateNewStartScn(Scn endScn, Scn maxCommittedScn) throws Inter
                 endScn = getLastProcessedScn();
             }
 
-            // update offsets
-            offsetContext.setScn(endScn);
+            offsetContext.setScn(minCacheScn.isNull() ? endScn : minCacheScn.subtract(Scn.valueOf(1)));
             metrics.setOldestScnDetails(minCacheScn, minCacheScnChangeTime);
-            metrics.setOffsetScn(endScn);
+            metrics.setOffsetScn(offsetContext.getScn());
 
             // optionally dispatch a heartbeat event
             dispatcher.dispatchHeartbeatEvent(partition, offsetContext);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractTransactionCachingLogMinerEventProcessor.java
Patch:
@@ -107,7 +107,7 @@ protected Scn getTransactionCacheMinimumScn() {
 
     protected Optional<T> getOldestTransactionInCache() {
         return getTransactionCache().streamAndReturn(stream -> stream.map(LogMinerCache.Entry::getValue)
-                .min(this::compareStartScn));
+                .min(this::oldestTransactionComparison));
     }
 
     @Override

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -477,7 +477,9 @@ protected void handleCommit(OraclePartition partition, LogMinerEventRow row) thr
 
         final T transaction = getAndRemoveTransactionFromCache(transactionId);
         if (transaction == null) {
-            LOGGER.debug("Transaction {} not found in cache, no events to commit.", transactionId);
+            if (!offsetContext.getCommitScn().hasCommitAlreadyBeenHandled(row)) {
+                LOGGER.debug("Transaction {} not found in cache with SCN {}, no events to commit.", transactionId, row.getScn());
+            }
             handleCommitNotFoundInBuffer(row);
         }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -153,7 +153,7 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
 
     public static final Field LOG_MINING_STRATEGY = Field.create("log.mining.strategy")
             .withDisplayName("Log Mining Strategy")
-            .withEnum(LogMiningStrategy.class, LogMiningStrategy.CATALOG_IN_REDO)
+            .withEnum(LogMiningStrategy.class, LogMiningStrategy.ONLINE_CATALOG)
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.HIGH)
             .withGroup(Field.createGroupEntry(Field.Group.CONNECTION_ADVANCED, 8))

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/util/TestHelper.java
Patch:
@@ -162,9 +162,6 @@ else if (adapter().equals(ConnectorAdapter.OLR)) {
             builder.withDefault(OracleConnectorConfig.OLR_PORT, OPENLOGREPLICATOR_PORT);
         }
         else {
-            // Tests will always use the online catalog strategy due to speed.
-            builder.withDefault(OracleConnectorConfig.LOG_MINING_STRATEGY, "online_catalog");
-
             final Boolean readOnly = Boolean.parseBoolean(System.getProperty(OracleConnectorConfig.LOG_MINING_READ_ONLY.name()));
             if (readOnly) {
                 builder.with(OracleConnectorConfig.LOG_MINING_READ_ONLY, readOnly);

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/GeneralDatabaseDialect.java
Patch:
@@ -69,6 +69,7 @@
 import io.debezium.connector.jdbc.type.connect.ConnectTimeType;
 import io.debezium.connector.jdbc.type.connect.ConnectTimestampType;
 import io.debezium.connector.jdbc.type.debezium.DateType;
+import io.debezium.connector.jdbc.type.debezium.DebeziumZonedTimestampType;
 import io.debezium.connector.jdbc.type.debezium.MicroTimeType;
 import io.debezium.connector.jdbc.type.debezium.MicroTimestampType;
 import io.debezium.connector.jdbc.type.debezium.NanoTimeType;
@@ -77,7 +78,6 @@
 import io.debezium.connector.jdbc.type.debezium.TimestampType;
 import io.debezium.connector.jdbc.type.debezium.VariableScaleDecimalType;
 import io.debezium.connector.jdbc.type.debezium.ZonedTimeType;
-import io.debezium.connector.jdbc.type.debezium.ZonedTimestampType;
 import io.debezium.util.Strings;
 
 /**
@@ -636,7 +636,7 @@ protected void registerTypes() {
         registerType(NanoTimeType.INSTANCE);
         registerType(NanoTimestampType.INSTANCE);
         registerType(ZonedTimeType.INSTANCE);
-        registerType(ZonedTimestampType.INSTANCE);
+        registerType(DebeziumZonedTimestampType.INSTANCE);
         registerType(VariableScaleDecimalType.INSTANCE);
 
         // Supported connect data types

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/db2/ZonedTimestampType.java
Patch:
@@ -11,14 +11,15 @@
 
 import io.debezium.connector.jdbc.ValueBindDescriptor;
 import io.debezium.connector.jdbc.type.Type;
+import io.debezium.connector.jdbc.type.debezium.DebeziumZonedTimestampType;
 import io.debezium.time.ZonedTimestamp;
 
 /**
  * An implementation of {@link Type} for {@link ZonedTimestamp} values.
  *
  * @author Chris Cranford
  */
-public class ZonedTimestampType extends io.debezium.connector.jdbc.type.debezium.ZonedTimestampType {
+public class ZonedTimestampType extends DebeziumZonedTimestampType {
 
     public static final ZonedTimestampType INSTANCE = new ZonedTimestampType();
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/ZonedTimestampType.java
Patch:
@@ -8,14 +8,15 @@
 import java.sql.Types;
 
 import io.debezium.connector.jdbc.type.Type;
+import io.debezium.connector.jdbc.type.debezium.DebeziumZonedTimestampType;
 import io.debezium.time.ZonedTimestamp;
 
 /**
  * An implementation of {@link Type} for {@link ZonedTimestamp} values.
  *
  * @author Chris Cranford
  */
-public class ZonedTimestampType extends io.debezium.connector.jdbc.type.debezium.ZonedTimestampType {
+public class ZonedTimestampType extends DebeziumZonedTimestampType {
 
     public static final ZonedTimestampType INSTANCE = new ZonedTimestampType();
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/oracle/ZonedTimestampType.java
Patch:
@@ -10,14 +10,15 @@
 
 import io.debezium.connector.jdbc.ValueBindDescriptor;
 import io.debezium.connector.jdbc.type.Type;
+import io.debezium.connector.jdbc.type.debezium.DebeziumZonedTimestampType;
 import io.debezium.time.ZonedTimestamp;
 
 /**
  * An implementation of {@link Type} for {@link ZonedTimestamp} values.
  *
  * @author Chris Cranford
  */
-public class ZonedTimestampType extends io.debezium.connector.jdbc.type.debezium.ZonedTimestampType {
+public class ZonedTimestampType extends DebeziumZonedTimestampType {
 
     public static final ZonedTimestampType INSTANCE = new ZonedTimestampType();
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/PostgresDatabaseDialect.java
Patch:
@@ -5,8 +5,8 @@
  */
 package io.debezium.connector.jdbc.dialect.postgres;
 
-import static io.debezium.connector.jdbc.type.debezium.ZonedTimestampType.NEGATIVE_INFINITY;
-import static io.debezium.connector.jdbc.type.debezium.ZonedTimestampType.POSITIVE_INFINITY;
+import static io.debezium.connector.jdbc.type.debezium.DebeziumZonedTimestampType.NEGATIVE_INFINITY;
+import static io.debezium.connector.jdbc.type.debezium.DebeziumZonedTimestampType.POSITIVE_INFINITY;
 
 import java.sql.Connection;
 import java.sql.SQLException;

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/ZonedTimestampType.java
Patch:
@@ -13,14 +13,15 @@
 import io.debezium.connector.jdbc.ValueBindDescriptor;
 import io.debezium.connector.jdbc.relational.ColumnDescriptor;
 import io.debezium.connector.jdbc.type.Type;
+import io.debezium.connector.jdbc.type.debezium.DebeziumZonedTimestampType;
 import io.debezium.time.ZonedTimestamp;
 
 /**
  * An implementation of {@link Type} for {@link ZonedTimestamp} values specific to PostgreSQL.
  *
  * @author Mario Fiore Vitale
  */
-public class ZonedTimestampType extends io.debezium.connector.jdbc.type.debezium.ZonedTimestampType {
+public class ZonedTimestampType extends DebeziumZonedTimestampType {
 
     public static final ZonedTimestampType INSTANCE = new ZonedTimestampType();
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/DebeziumZonedTimestampType.java
Patch:
@@ -23,9 +23,9 @@
  *
  * @author Chris Cranford
  */
-public class ZonedTimestampType extends AbstractTimestampType {
+public class DebeziumZonedTimestampType extends AbstractTimestampType {
 
-    public static final ZonedTimestampType INSTANCE = new ZonedTimestampType();
+    public static final DebeziumZonedTimestampType INSTANCE = new DebeziumZonedTimestampType();
     public static final String POSITIVE_INFINITY = "infinity";
     public static final String NEGATIVE_INFINITY = "-infinity";
 

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/e2e/AbstractJdbcSinkPipelineIT.java
Patch:
@@ -36,7 +36,6 @@
 
 import org.apache.commons.lang3.RandomStringUtils;
 import org.apache.kafka.connect.sink.SinkRecord;
-import org.jetbrains.annotations.NotNull;
 import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.TestTemplate;
 import org.junit.jupiter.api.extension.ExtendWith;
@@ -2590,7 +2589,7 @@ public void testTimestampWithTimeZoneDataTypeWithInfinityValue(Source source, Si
                 (rs, index) -> rs.getTimestamp(index).toInstant().atZone(ZoneOffset.UTC));
     }
 
-    private static @NotNull List<ZonedDateTime> getExpectedZonedDateTimes(Sink sink) {
+    private static List<ZonedDateTime> getExpectedZonedDateTimes(Sink sink) {
 
         List<ZonedDateTime> expectedValues = List.of();
         if (sink.getType().is(SinkType.SQLSERVER) && sink.getType().is(SinkType.DB2)) {

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/testhelper/TestInfrastructureHelper.java
Patch:
@@ -191,8 +191,6 @@ private static void waitForDebeziumContainerIsStopped() {
                 .until(() -> !TestInfrastructureHelper.getDebeziumContainer().isRunning());
     }
 
-
-
     public static void setupDebeziumContainer(String connectorVersion, String restExtensionClasses, String debeziumContainerImageVersion) {
         if (null != DEBEZIUM_CONTAINER && DEBEZIUM_CONTAINER.isRunning()) {
             DEBEZIUM_CONTAINER.stop();

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/sink/MongoProcessedSinkRecordData.java
Patch:
@@ -16,8 +16,8 @@
 import com.mongodb.MongoNamespace;
 import com.mongodb.client.model.WriteModel;
 
-import io.debezium.connector.mongodb.sink.converters.SinkRecordConverter;
 import io.debezium.connector.mongodb.sink.converters.SinkDocument;
+import io.debezium.connector.mongodb.sink.converters.SinkRecordConverter;
 import io.debezium.connector.mongodb.sink.eventhandler.relational.RelationalEventHandler;
 
 public class MongoProcessedSinkRecordData {

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/sink/StartedMongoDbSinkTask.java
Patch:
@@ -12,7 +12,6 @@
 import java.util.OptionalLong;
 import java.util.stream.Collectors;
 
-import io.debezium.DebeziumException;
 import org.apache.kafka.connect.connector.ConnectRecord;
 import org.apache.kafka.connect.errors.DataException;
 import org.apache.kafka.connect.sink.SinkRecord;
@@ -25,6 +24,7 @@
 import com.mongodb.client.model.BulkWriteOptions;
 import com.mongodb.client.model.WriteModel;
 
+import io.debezium.DebeziumException;
 import io.debezium.dlq.ErrorReporter;
 
 final class StartedMongoDbSinkTask implements AutoCloseable {

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/sink/WriteModelStrategy.java
Patch:
@@ -11,6 +11,9 @@
 
 import io.debezium.connector.mongodb.sink.converters.SinkDocument;
 
+/**
+ * Strategy for different write models to MongoDB (replace, update, insert/append only, etc).
+ */
 public interface WriteModelStrategy {
 
     WriteModel<BsonDocument> createWriteModel(SinkDocument document);

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/DebeziumContainer.java
Patch:
@@ -142,7 +142,7 @@ public static int waitTimeForRecords() {
     }
 
     public String getTarget() {
-        return "http://" + getContainerIpAddress() + ":" + getMappedPort(KAFKA_CONNECT_PORT);
+        return "http://" + getHost() + ":" + getMappedPort(KAFKA_CONNECT_PORT);
     }
 
     /**
@@ -232,7 +232,7 @@ private void executePOSTRequestSuccessfully(final String payload, final String f
             }
         }
         catch (IOException e) {
-            throw new RuntimeException("Error connecting to Debezium container", e);
+            throw new RuntimeException("Error connecting to Debezium container on URL: " + fullUrl, e);
         }
     }
 

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/ApicurioRegistryTest.java
Patch:
@@ -63,8 +63,7 @@ public class ApicurioRegistryTest {
 
     private static final ApicurioRegistryContainer apicurioContainer = new ApicurioRegistryContainer().withNetwork(network);
 
-    private static final KafkaContainer kafkaContainer = new KafkaContainer()
-            .withNetwork(network);
+    private static final KafkaContainer kafkaContainer = DebeziumKafkaContainer.defaultKRaftContainer(network);
 
     public static final PostgreSQLContainer<?> postgresContainer = new PostgreSQLContainer<>(ImageNames.POSTGRES_DOCKER_IMAGE_NAME)
             .withNetwork(network)

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/DebeziumContainerTest.java
Patch:
@@ -50,8 +50,7 @@ public class DebeziumContainerTest {
 
     private static final Network network = Network.newNetwork();
 
-    private static final KafkaContainer kafkaContainer = new KafkaContainer()
-            .withNetwork(network);
+    private static final KafkaContainer kafkaContainer = DebeziumKafkaContainer.defaultKRaftContainer(network);
 
     public static PostgreSQLContainer<?> postgresContainer = new PostgreSQLContainer<>(ImageNames.POSTGRES_DOCKER_IMAGE_NAME)
             .withNetwork(network)

File: debezium-core/src/main/java/io/debezium/connector/common/BaseSourceTask.java
Patch:
@@ -343,7 +343,7 @@ private void updateLastOffset(Map<String, ?> partition, Map<String, ?> lastOffse
     protected void resetErrorHandlerRetriesIfNeeded(List<SourceRecord> records) {
         // When a connector throws a retriable error, the task is not re-created and instead the previous
         // error handler is passed into the new error handler, propagating the retry count. This method
-        // allows resetting that counter when a successful poll iteration step contains new records  so that when a
+        // allows resetting that counter when a successful poll iteration step contains new records so that when a
         // future failure is thrown, the maximum retry count can be utilized.
         if (!records.isEmpty() && coordinator.getErrorHandler().getRetries() > 0) {
             coordinator.getErrorHandler().resetRetries();

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorTask.java
Patch:
@@ -182,7 +182,7 @@ public List<SourceRecord> doPoll() throws InterruptedException {
     }
 
     @Override
-    protected void resetErrorHandlerRetriesIfNeeded() {
+    protected void resetErrorHandlerRetriesIfNeeded(List<SourceRecord> records) {
         // Reset the retries if all partitions have streamed without exceptions at least once after a restart
         if (coordinator.getErrorHandler().getRetries() > 0 && ((SqlServerChangeEventSourceCoordinator) coordinator).firstStreamingIterationCompletedSuccessfully()) {
             coordinator.getErrorHandler().resetRetries();

File: debezium-core/src/test/java/io/debezium/connector/common/BaseSourceTaskSnapshotModesValidationTest.java
Patch:
@@ -267,7 +267,7 @@ protected List<SourceRecord> doPoll() {
         }
 
         @Override
-        protected void resetErrorHandlerRetriesIfNeeded() {
+        protected void resetErrorHandlerRetriesIfNeeded(List<SourceRecord> records) {
             // do nothing as we don't have a coordinator mocked
         }
 

File: debezium-core/src/test/java/io/debezium/connector/common/BaseSourceTaskTest.java
Patch:
@@ -171,7 +171,7 @@ protected List<SourceRecord> doPoll() {
         }
 
         @Override
-        protected void resetErrorHandlerRetriesIfNeeded() {
+        protected void resetErrorHandlerRetriesIfNeeded(List<SourceRecord> records) {
             // do nothing as we don't have a coordinator mocked
         }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/GeneralDatabaseDialect.java
Patch:
@@ -514,8 +514,9 @@ public String getTypeName(int jdbcType) {
         if (ColumnTypeResolutionMode.LEGACY.equals(connectorConfig.getColumnTypeResolutionMode())) {
             switch (jdbcType) {
                 case Types.VARCHAR:
-                case Types.NVARCHAR:
                     return getTypeName(Types.LONGVARCHAR);
+                case Types.NVARCHAR:
+                    return getTypeName(Types.LONGNVARCHAR);
                 case Types.VARBINARY:
                     return getTypeName(Types.LONGVARBINARY);
                 default:

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/GeneralDatabaseDialect.java
Patch:
@@ -763,7 +763,7 @@ protected String getQualifiedTableName(TableId tableId) {
 
     private String columnNameEqualsBinding(String fieldName, TableDescriptor table, SinkRecordDescriptor record) {
         final FieldDescriptor field = record.getFields().get(fieldName);
-        final String columnName = columnNamingStrategy.resolveColumnName(field.getColumnName());
+        final String columnName = resolveColumnName(field);
         final ColumnDescriptor column = table.getColumnByName(columnName);
         return toIdentifier(columnName) + "=" + field.getQueryBinding(column, record.getAfterStruct());
     }

File: debezium-core/src/main/java/io/debezium/relational/mapping/TruncateColumn.java
Patch:
@@ -30,7 +30,7 @@ public class TruncateColumn implements ColumnMapper {
      */
     public TruncateColumn(int maxLength) {
         if (maxLength < 0) {
-            throw new IllegalArgumentException("Maximum length must be positive");
+            throw new IllegalArgumentException("Maximum length must be non-negative");
         }
         this.converter = new TruncatingValueConverter(maxLength);
     }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerChangeTablePointer.java
Patch:
@@ -68,7 +68,7 @@ protected int getOperation(ResultSet resultSet) throws SQLException {
     @Override
     protected Object getColumnData(ResultSet resultSet, int columnIndex) throws SQLException {
         if (resultSet.getMetaData().getColumnType(columnIndex) == Types.TIME) {
-            return resultSet.getTime(columnIndex);
+            return resultSet.getTimestamp(columnIndex);
         }
         return super.getColumnData(resultSet, columnIndex);
     }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerDefaultValueConverter.java
Patch:
@@ -149,7 +149,7 @@ private Map<String, DefaultValueMapper> createDefaultValueMappers() {
         });
         result.put("time", (c, v) -> { // Sample value: ('2019-01-01 00:00:00')
             String rawValue = v.substring(2, v.length() - 2);
-            return JdbcConnection.querySingleValue(connectionProvider.get(), "SELECT PARSE(? AS time)", st -> st.setString(1, rawValue), rs -> rs.getTime(1));
+            return JdbcConnection.querySingleValue(connectionProvider.get(), "SELECT PARSE(? AS time)", st -> st.setString(1, rawValue), rs -> rs.getTimestamp(1));
         });
 
         // Character strings

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorIT.java
Patch:
@@ -3281,6 +3281,7 @@ private void shouldStopRetriableRestartsAtConfiguredMaximum(SqlRunnable scenario
         final Configuration config1 = TestHelper.defaultConnectorConfig()
                 .with(SqlServerConnectorConfig.DATABASE_NAMES.name(), TestHelper.TEST_DATABASE_1 + "," + TestHelper.TEST_DATABASE_2)
                 .with("errors.max.retries", 1)
+                .with(SqlServerConnectorConfig.LOG_POSITION_CHECK_ENABLED, false)
                 .build();
         final LogInterceptor logInterceptor = new LogInterceptor(ErrorHandler.class);
 

File: debezium-connector-binlog/src/test/java/io/debezium/connector/binlog/BinlogSourceInfoTest.java
Patch:
@@ -659,8 +659,8 @@ public void schemaIsCorrect() {
                 .field("snapshot", AbstractSourceInfoStructMaker.SNAPSHOT_RECORD_SCHEMA)
                 .field("db", Schema.STRING_SCHEMA)
                 .field("sequence", Schema.OPTIONAL_STRING_SCHEMA)
-                .field("ts_us", Schema.INT64_SCHEMA)
-                .field("ts_ns", Schema.INT64_SCHEMA)
+                .field("ts_us", Schema.OPTIONAL_INT64_SCHEMA)
+                .field("ts_ns", Schema.OPTIONAL_INT64_SCHEMA)
                 .field("table", Schema.OPTIONAL_STRING_SCHEMA)
                 .field("server_id", Schema.INT64_SCHEMA)
                 .field("gtid", Schema.OPTIONAL_STRING_SCHEMA)

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcSinkConnectorConfig.java
Patch:
@@ -316,7 +316,8 @@ public class JdbcSinkConnectorConfig {
             .withWidth(ConfigDef.Width.SHORT)
             .withImportance(ConfigDef.Importance.MEDIUM)
             .withDefault(false)
-            .withDescription("A reduction buffer consolidates the execution of SQL statements by primary key to reduce the SQL load on the target database. When set to false (the default), each incoming event is applied as a logical SQL change. When set to true, incoming events that refer to the same row will be reduced to a single logical change based on the most recent row state.");
+            .withDescription(
+                    "A reduction buffer consolidates the execution of SQL statements by primary key to reduce the SQL load on the target database. When set to false (the default), each incoming event is applied as a logical SQL change. When set to true, incoming events that refer to the same row will be reduced to a single logical change based on the most recent row state.");
 
     protected static final ConfigDefinition CONFIG_DEFINITION = ConfigDefinition.editor()
             .connector(

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/RecordBuffer.java
Patch:
@@ -53,7 +53,6 @@ public List<SinkRecordDescriptor> add(SinkRecordDescriptor recordDescriptor) {
             return flushed;
         }
 
-
         if (records.size() >= connectorConfig.getBatchSize()) {
             flushed = flush();
         }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcChangeEventSink.java
Patch:
@@ -145,7 +145,7 @@ public void execute(Collection<SinkRecord> records) {
                 Stopwatch updateBufferStopwatch = Stopwatch.reusable();
                 updateBufferStopwatch.start();
 
-                Buffer tableIdBuffer = resolveBuffer(deleteBufferByTable, tableId);
+                Buffer tableIdBuffer = resolveBuffer(updateBufferByTable, tableId);
 
                 List<SinkRecordDescriptor> toFlush = tableIdBuffer.add(sinkRecordDescriptor);
                 updateBufferStopwatch.stop();

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -672,7 +672,7 @@ private Throwable handleRetries(final RetriableException e, final List<Map<Strin
                 startedSuccessfully = true;
             }
             catch (Exception ex) {
-                if (totalRetries >= maxRetries) {
+                if (maxRetries != EmbeddedEngineConfig.DEFAULT_ERROR_MAX_RETRIES && totalRetries >= maxRetries) {
                     LOGGER.error("Can't start the connector, max retries to connect exceeded; stopping connector...", ex);
                     return ex;
                 }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/TransactionCommitConsumer.java
Patch:
@@ -158,7 +158,7 @@ private void acceptDmlEvent(DmlEvent event) throws InterruptedException {
             return;
         }
 
-        if(table.primaryKeyColumnNames().isEmpty()){
+        if (table.primaryKeyColumnNames().isEmpty()) {
             LOGGER.debug("\tEvent for table {} has no primary key, dispatching.", table.id());
             dispatchChangeEvent(event);
             return;

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/FlushStrategyIT.java
Patch:
@@ -167,7 +167,7 @@ private void insertFlushTable(Configuration config, String scnValue) throws SQLE
     }
 
     private static String getFlushTableName() {
-        return TestHelper.getConnectorUserName() + "." + flushTableName;
+        return TestHelper.getConnectorUserName().toUpperCase() + "." + flushTableName;
     }
 
     private static TableId getFlushTableId() {

File: debezium-core/src/main/java/io/debezium/pipeline/EventDispatcher.java
Patch:
@@ -39,7 +39,7 @@
 import io.debezium.pipeline.spi.OffsetContext;
 import io.debezium.pipeline.spi.Partition;
 import io.debezium.pipeline.spi.SchemaChangeEventEmitter;
-import io.debezium.pipeline.txmetadata.BasicTransactionInfo;
+import io.debezium.pipeline.txmetadata.DefaultTransactionInfo;
 import io.debezium.pipeline.txmetadata.TransactionInfo;
 import io.debezium.pipeline.txmetadata.TransactionMonitor;
 import io.debezium.processors.PostProcessorRegistry;
@@ -351,7 +351,7 @@ public void dispatchTransactionCommittedEvent(P partition, OffsetContext offset,
     }
 
     public void dispatchTransactionStartedEvent(P partition, String transactionId, OffsetContext offset, Instant timestamp) throws InterruptedException {
-        dispatchTransactionStartedEvent(partition, new BasicTransactionInfo(transactionId), offset, timestamp);
+        dispatchTransactionStartedEvent(partition, new DefaultTransactionInfo(transactionId), offset, timestamp);
     }
 
     public void dispatchTransactionStartedEvent(P partition, TransactionInfo transactionInfo, OffsetContext offset, Instant timestamp) throws InterruptedException {

File: debezium-core/src/main/java/io/debezium/pipeline/source/spi/EventMetadataProvider.java
Patch:
@@ -11,7 +11,7 @@
 import org.apache.kafka.connect.data.Struct;
 
 import io.debezium.pipeline.spi.OffsetContext;
-import io.debezium.pipeline.txmetadata.BasicTransactionInfo;
+import io.debezium.pipeline.txmetadata.DefaultTransactionInfo;
 import io.debezium.pipeline.txmetadata.TransactionInfo;
 import io.debezium.spi.schema.DataCollectionId;
 
@@ -50,6 +50,6 @@ default String toSummaryString(DataCollectionId source, OffsetContext offset, Ob
     }
 
     default TransactionInfo getTransactionInfo(DataCollectionId source, OffsetContext offset, Object key, Struct value) {
-        return new BasicTransactionInfo(getTransactionId(source, offset, key, value));
+        return new DefaultTransactionInfo(getTransactionId(source, offset, key, value));
     }
 }

File: debezium-core/src/main/java/io/debezium/pipeline/txmetadata/DefaultTransactionInfo.java
Patch:
@@ -5,11 +5,11 @@
  */
 package io.debezium.pipeline.txmetadata;
 
-public class BasicTransactionInfo implements TransactionInfo {
+public class DefaultTransactionInfo implements TransactionInfo {
 
     private final String transactionId;
 
-    public BasicTransactionInfo(String transactionId) {
+    public DefaultTransactionInfo(String transactionId) {
         this.transactionId = transactionId;
     }
 

File: debezium-core/src/test/java/io/debezium/pipeline/txmetadata/DefaultTransactionInfoTest.java
Patch:
@@ -9,12 +9,12 @@
 
 import org.junit.Test;
 
-public class BasicTransactionInfoTest {
+public class DefaultTransactionInfoTest {
 
     @Test
     public void testGetId() {
         String expectedId = "id";
-        BasicTransactionInfo info = new BasicTransactionInfo(expectedId);
+        DefaultTransactionInfo info = new DefaultTransactionInfo(expectedId);
         assertThat(info.getTransactionId()).isEqualTo(expectedId);
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorTest.java
Patch:
@@ -38,7 +38,7 @@ protected static void assertConfigDefIsValid(Connector connector, io.debezium.co
             assertThat(key.importance).isEqualTo(expected.importance());
             assertThat(key.documentation).isEqualTo(expected.description());
             assertThat(key.type).isEqualTo(expected.type());
-            if (expected.type() == Type.CLASS) {
+            if (expected.type() == Type.CLASS && expected.defaultValue() != null) {
                 assertThat(((Class<?>) key.defaultValue).getName()).isEqualTo((String) expected.defaultValue());
             }
             else if (expected.type() == ConfigDef.Type.LIST && key.defaultValue != null) {

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -722,9 +722,10 @@ public static SnapshotQueryMode parse(String value, String defaultValue) {
     public static final Field PROVIDE_ORDERED_TRANSACTION_METADATA = Field.create("provide.ordered.transaction.metadata")
             .withDisplayName("Provide ordered transaction meatadata")
             .withType(Type.BOOLEAN)
-            .withDefault(false)
+            .withGroup(Field.createGroupEntry(Field.Group.CONNECTOR_ADVANCED, 19))
             .withWidth(Width.SHORT)
-            .withImportance(ConfigDef.Importance.LOW)
+            .withDefault(Boolean.FALSE)
+            .withImportance(Importance.LOW)
             .withDescription(
                     "Whether to provide order metadata on transactions");
 

File: debezium-connector-binlog/src/test/java/io/debezium/connector/binlog/BinlogCustomSnapshotterIT.java
Patch:
@@ -98,8 +98,8 @@ record = s2recs.get(0);
 
         config = DATABASE_CUSTOM_SNAPSHOT.defaultConfig()
                 .with(BinlogConnectorConfig.SNAPSHOT_MODE, BinlogConnectorConfig.SnapshotMode.CUSTOM.getValue())
-                .with(BinlogConnectorConfig.SNAPSHOT_MODE_CUSTOM_NAME, BinlogConnectorConfig.class.getName())
-                .with(BinlogConnectorConfig.SNAPSHOT_QUERY_MODE, BinlogConnectorConfig.SnapshotQueryMode.CUSTOM)
+                .with(BinlogConnectorConfig.SNAPSHOT_MODE_CUSTOM_NAME, getCustomSnapshotClassName())
+                .with(BinlogConnectorConfig.SNAPSHOT_QUERY_MODE, CommonConnectorConfig.SnapshotQueryMode.CUSTOM)
                 .with(BinlogConnectorConfig.SNAPSHOT_QUERY_MODE_CUSTOM_NAME, getCustomSnapshotClassName())
                 .build();
 

File: debezium-connector-mariadb/src/test/java/io/debezium/connector/mariadb/CustomTestSnapshot.java
Patch:
@@ -34,8 +34,8 @@ public String name() {
 
     @Override
     public void injectBeanRegistry(BeanRegistry beanRegistry) {
-        Offsets<MariaDbPartition, MariaDbOffsetContext> mySqlOffsetContext = beanRegistry.lookupByName(StandardBeanNames.OFFSETS, Offsets.class);
-        hasState = mySqlOffsetContext.getTheOnlyOffset() != null;
+        Offsets<MariaDbPartition, MariaDbOffsetContext> mariaDbOffsetContext = beanRegistry.lookupByName(StandardBeanNames.OFFSETS, Offsets.class);
+        hasState = mariaDbOffsetContext.getTheOnlyOffset() != null;
     }
 
     @Override

File: debezium-connector-binlog/src/test/java/io/debezium/connector/binlog/BinlogConnectorTest.java
Patch:
@@ -19,5 +19,7 @@ public interface BinlogConnectorTest<C extends SourceConnector> {
 
     BinlogTestConnection getTestDatabaseConnection(String databaseName);
 
+    BinlogTestConnection getTestReplicaDatabaseConnection(String databaseName);
+
     boolean isMariaDb();
 }

File: debezium-connector-binlog/src/test/java/io/debezium/connector/binlog/BinlogConvertingFailureIT.java
Patch:
@@ -362,7 +362,7 @@ private void alterTableWithSqlBinLogOff(String ddl, boolean replicaIsMaster) thr
 
         if (!replicaIsMaster) {
             // if it has replica, also apply the DDL because master didn't record DDL at binlog
-            try (BinlogTestConnection db = getTestDatabaseConnection(DATABASE.getDatabaseName())) {
+            try (BinlogTestConnection db = getTestReplicaDatabaseConnection(DATABASE.getDatabaseName())) {
                 try (JdbcConnection connection = db.connect()) {
                     connection.execute("SET SQL_LOG_BIN=OFF;");
                     connection.execute(ddl);

File: debezium-connector-binlog/src/test/java/io/debezium/connector/binlog/BinlogSchemaValidateIT.java
Patch:
@@ -400,7 +400,7 @@ private void alterTableWithSqlBinLogOff(String ddl, boolean replicaIsMaster) thr
 
         if (!replicaIsMaster) {
             // if has replica, also apply DDL because master didn't record DDL at binlog
-            try (BinlogTestConnection db = getTestDatabaseConnection(DATABASE.getDatabaseName())) {
+            try (BinlogTestConnection db = getTestReplicaDatabaseConnection(DATABASE.getDatabaseName())) {
                 try (JdbcConnection connection = db.connect()) {
                     connection.execute("SET SQL_LOG_BIN=OFF;");
                     connection.execute(ddl);

File: debezium-connector-binlog/src/main/java/io/debezium/connector/binlog/jdbc/BinlogConnectionConfiguration.java
Patch:
@@ -106,7 +106,7 @@ public char[] sslTrustStorePassword() {
     public abstract String getUrlPattern();
 
     protected Configuration.Builder getDatabaseConfiguration(Configuration configuration) {
-        return configuration.edit().with(BinlogConnectorConfig.PORT, BinlogConnectorConfig.PORT.defaultValue());
+        return configuration.edit().withDefault(BinlogConnectorConfig.PORT, BinlogConnectorConfig.PORT.defaultValue());
     }
 
     protected JdbcConfiguration getJdbcConfiguration(Configuration configuration) {

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/connection/MongoDbConnection.java
Patch:
@@ -208,11 +208,11 @@ private boolean isValidResumeToken(BsonDocument token, MongoDbTaskContext taskCo
 
                 try (var ignored = stream.cursor()) {
                     LOGGER.info("Valid resume token present, so no snapshot will be performed'");
-                    return false;
+                    return true;
                 }
                 catch (MongoCommandException | MongoChangeStreamException e) {
                     LOGGER.info("Invalid resume token present, snapshot will be performed'");
-                    return true;
+                    return false;
                 }
             });
         }

File: debezium-embedded/src/main/java/io/debezium/embedded/async/AsyncEngineConfig.java
Patch:
@@ -24,7 +24,9 @@ public interface AsyncEngineConfig extends EmbeddedEngineConfig {
      */
     Field RECORD_PROCESSING_THREADS = Field.create("record.processing.threads")
             .withDescription("The number of threads to be used for processing CDC records. If you want to use all available threads, you can use "
-                    + "'AVAILABLE_CORES' placeholder.");
+                    + "'AVAILABLE_CORES' placeholder. If the number of threads is not specified, the threads will be created as needed, using "
+                    + "Java 'Executors.newCachedThreadPool()' executor service.")
+            .withDefault(""); // We need to set some non-null value to avoid Kafka config validation failures.
 
     /**
      * An optional field that specifies maximum time in ms to wait for submitted records to finish processing when the task shut down is called.

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorConfig.java
Patch:
@@ -47,7 +47,7 @@ public class SqlServerConnectorConfig extends HistorizedRelationalDatabaseConnec
 
     public static final String MAX_TRANSACTIONS_PER_ITERATION_CONFIG_NAME = "max.iteration.transactions";
     protected static final int DEFAULT_PORT = 1433;
-    protected static final int DEFAULT_MAX_TRANSACTIONS_PER_ITERATION = 0;
+    protected static final int DEFAULT_MAX_TRANSACTIONS_PER_ITERATION = 500;
     private static final String READ_ONLY_INTENT = "ReadOnly";
     private static final String APPLICATION_INTENT_KEY = "database.applicationIntent";
     private static final int DEFAULT_QUERY_FETCH_SIZE = 10_000;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/connection/MongoDbConnectionContext.java
Patch:
@@ -111,12 +111,12 @@ public Optional<String> getRequiredReplicaSetName() {
     /**
      * Determines if RS name is specified when required
      *
-     * @return False if RS name is not specified, and we are connected to sharded cluster. True otherwise
+     * @return True if RS name is specified or not required. False otherwise.
      */
-    public boolean hasRequiredReplicaSetName() {
+    public boolean hasReplicaSetNameIfRequired() {
         if (getRequiredReplicaSetName().isPresent()) {
             return true;
         }
-        return getClusterDescription().getType() == ClusterType.SHARDED;
+        return getClusterDescription().getType() != ClusterType.REPLICA_SET;
     }
 }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/infinispan/EmbeddedInfinispanLogMinerEventProcessor.java
Patch:
@@ -148,8 +148,8 @@ protected Scn getTransactionCacheMinimumScn() {
     @Override
     protected Optional<InfinispanTransaction> getOldestTransactionInCache() {
         InfinispanTransaction transaction = null;
-        if (!transactionCache.isEmpty()) {
-            try (CloseableIterator<InfinispanTransaction> iterator = transactionCache.values().iterator()) {
+        try (CloseableIterator<InfinispanTransaction> iterator = transactionCache.values().iterator()) {
+            if (iterator.hasNext()) {
                 // Seed with the first element
                 transaction = iterator.next();
                 while (iterator.hasNext()) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/infinispan/RemoteInfinispanLogMinerEventProcessor.java
Patch:
@@ -15,6 +15,7 @@
 import java.util.Optional;
 import java.util.Properties;
 
+import org.checkerframework.checker.units.qual.C;
 import org.infinispan.client.hotrod.RemoteCache;
 import org.infinispan.client.hotrod.RemoteCacheManager;
 import org.infinispan.client.hotrod.configuration.Configuration;
@@ -159,8 +160,8 @@ protected Scn getTransactionCacheMinimumScn() {
     @Override
     protected Optional<InfinispanTransaction> getOldestTransactionInCache() {
         InfinispanTransaction transaction = null;
-        if (!transactionCache.isEmpty()) {
-            try (CloseableIterator<InfinispanTransaction> iterator = transactionCache.values().iterator()) {
+        try (CloseableIterator<InfinispanTransaction> iterator = transactionCache.values().iterator()) {
+            if (iterator.hasNext()) {
                 // Seed with the first element
                 transaction = iterator.next();
                 while (iterator.hasNext()) {

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorIT.java
Patch:
@@ -2446,7 +2446,7 @@ public void shouldNotStreamWhenUsingSnapshotModeInitialOnly() throws Exception {
         // should be no more records
         assertNoRecordsToConsume();
 
-        final String message = "Streaming is not enabled in current configuration";
+        final String message = "Streaming is disabled for snapshot mode initial_only";
         stopConnector(value -> assertThat(logInterceptor.containsMessage(message)).isTrue());
     }
 

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/ConfigProperties.java
Patch:
@@ -32,8 +32,8 @@ private ConfigProperties() {
     public static final String DOCKER_IMAGE_MYSQL_REPLICA = System.getProperty("test.docker.image.mysql.replica", "quay.io/debezium/example-mysql-replica:latest");
 
     public static final String DOCKER_IMAGE_POSTGRESQL = System.getProperty("test.docker.image.postgresql", "quay.io/debezium/example-postgres:latest");
-    public static final String DOCKER_IMAGE_MONGO = System.getProperty("test.docker.image.mongo", "quay.io/debezium/example-mongodb:latest");
-    public static final String DOCKER_IMAGE_MONGO_SHARDED = System.getProperty("test.docker.image.mongo.sharded", "quay.io/debezium/example-mongodb:latest");
+    public static final String DOCKER_IMAGE_MONGO = System.getProperty("test.docker.image.mongo", "quay.io/debezium/example-mongodb:2.6");
+    public static final String DOCKER_IMAGE_MONGO_SHARDED = System.getProperty("test.docker.image.mongo.sharded", "quay.io/debezium/example-mongodb:2.6");
     public static final String DOCKER_IMAGE_SQLSERVER = System.getProperty("test.docker.image.sqlserver", "mcr.microsoft.com/mssql/server:2019-latest");
     public static final String DOCKER_IMAGE_DB2 = System.getProperty("test.docker.image.db2", "quay.io/debezium/db2-cdc:latest");
     public static final String DOCKER_IMAGE_ORACLE = System.getProperty("test.docker.image.oracle", "quay.io/rh_integration/dbz-oracle:19.3.0");

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/assertions/KafkaAssertions.java
Patch:
@@ -71,5 +71,7 @@ default void assertMinimalRecordsCount(String topic, int count) {
 
     void assertRecordIsUnwrapped(String topic, int amount);
 
+    void assertDocumentIsUnwrapped(String topic, int amount);
+
     Consumer<K, V> getConsumer();
 }

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/Db2Tests.java
Patch:
@@ -152,7 +152,7 @@ public void shouldResumeStreamingAfterCrash() throws InterruptedException {
     @Order(90)
     public void shouldExtractNewRecordState(SqlDatabaseController dbController) throws Exception {
         connectController.undeployConnector(connectorConfig.getConnectorName());
-        connectorConfig = connectorConfig.addUnwrapSMT();
+        connectorConfig = connectorConfig.addJdbcUnwrapSMT();
         connectController.deployConnector(connectorConfig);
 
         insertCustomer(dbController, "Eaton", "Beaver", "ebeaver@test.com");

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mongodb/MongoTests.java
Patch:
@@ -163,13 +163,13 @@ public void shouldResumeStreamingAfterCrash() throws InterruptedException {
     @Order(90)
     public void shouldExtractNewRecordState(MongoDatabaseController dbController) throws Exception {
         connectController.undeployConnector(connectorConfig.getConnectorName());
-        connectorConfig = connectorConfig.addUnwrapSMT();
+        connectorConfig = connectorConfig.addMongoUnwrapSMT();
         connectController.deployConnector(connectorConfig);
 
         insertCustomer(dbController, "Eaton", "Beaver", "ebeaver@test.com");
 
         String topic = connectorConfig.getDbServerName() + ".inventory.customers";
         awaitAssert(() -> assertions.assertRecordsCount(topic, 8));
-        awaitAssert(() -> assertions.assertRecordIsUnwrapped(topic, 1));
+        awaitAssert(() -> assertions.assertDocumentIsUnwrapped(topic, 1));
     }
 }

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mysql/MySqlTests.java
Patch:
@@ -165,7 +165,7 @@ public void shouldResumeStreamingAfterCrash() throws InterruptedException {
     @Order(90)
     public void shouldExtractNewRecordState(MySqlController dbController) throws Exception {
         connectController.undeployConnector(connectorConfig.getConnectorName());
-        connectorConfig = connectorConfig.addUnwrapSMT();
+        connectorConfig = connectorConfig.addJdbcUnwrapSMT();
         connectController.deployConnector(connectorConfig);
 
         insertCustomer(dbController, "Eaton", "Beaver", "ebeaver@test.com");

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/oracle/OracleTests.java
Patch:
@@ -149,7 +149,7 @@ public void shouldResumeStreamingAfterCrash() throws InterruptedException {
     @Order(90)
     public void shouldExtractNewRecordState(SqlDatabaseController dbController) throws Exception {
         connectController.undeployConnector(connectorConfig.getConnectorName());
-        connectorConfig = connectorConfig.addUnwrapSMT();
+        connectorConfig = connectorConfig.addJdbcUnwrapSMT();
         connectController.deployConnector(connectorConfig);
 
         insertCustomer(dbController, "Eaton", "Beaver", "ebeaver@test.com");

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/postgresql/PostgreSqlTests.java
Patch:
@@ -153,7 +153,7 @@ public void shouldResumeStreamingAfterCrash() throws InterruptedException {
     @Order(90)
     public void shouldExtractNewRecordState(SqlDatabaseController dbController) throws Exception {
         connectController.undeployConnector(connectorConfig.getConnectorName());
-        connectorConfig = connectorConfig.addUnwrapSMT();
+        connectorConfig = connectorConfig.addJdbcUnwrapSMT();
         connectController.deployConnector(connectorConfig);
 
         insertCustomer(dbController, "Eaton", "Beaver", "ebeaver@test.com");

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/sqlserver/SqlServerTests.java
Patch:
@@ -161,7 +161,7 @@ public void shouldResumeStreamingAfterCrash() throws InterruptedException {
     @Order(90)
     public void shouldExtractNewRecordState(SqlDatabaseController dbController) throws Exception {
         connectController.undeployConnector(connectorConfig.getConnectorName());
-        connectorConfig = connectorConfig.addUnwrapSMT();
+        connectorConfig = connectorConfig.addJdbcUnwrapSMT();
         connectController.deployConnector(connectorConfig);
 
         insertCustomer(dbController, "Eaton", "Beaver", "ebeaver@test.com");

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/assertions/JdbcAssertions.java
Patch:
@@ -34,7 +34,7 @@ public void assertRowsCount(int expectedCount, String table) throws SQLException
                 return rs.getInt(1);
             }
             catch (SQLException e) {
-                throw new RuntimeException(e);
+                throw new AssertionError(e);
             }
         });
         assertThat(databaseCount).withFailMessage("Expecting table '%s' to have <%d> rows but it had <%d>.", table, expectedCount, databaseCount)
@@ -49,7 +49,7 @@ public void assertRowsContain(String table, String column, String content) throw
                 return rs.next();
             }
             catch (SQLException e) {
-                throw new RuntimeException(e);
+                throw new AssertionError(e);
             }
         });
         assertThat(containsContent).withFailMessage("Table '%s' does not contain row with column '%s' containing <%s>.", table, column, content).isTrue();

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/postgresql/PostgreSqlOcpTests.java
Patch:
@@ -39,11 +39,11 @@ public void shouldStreamFromReplica(OcpPostgreSqlReplicaController replicaContro
 
         String topic = connector.getDbServerName() + ".inventory.customers";
 
-        awaitAssert(() -> assertions.assertRecordsCount(topic, 7));
+        awaitAssert(() -> assertions.assertRecordsCount(topic, 8));
 
         insertCustomer(primaryController, "Arnold", "Test", "atest@test.com");
 
-        awaitAssert(() -> assertions.assertRecordsCount(topic, 8));
+        awaitAssert(() -> assertions.assertRecordsCount(topic, 9));
         awaitAssert(() -> assertions.assertRecordsContain(topic, "atest@test.com"));
     }
 }

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mysql/MySqlOcpTests.java
Patch:
@@ -46,7 +46,7 @@ public void shouldStreamFromReplica(MySqlReplicaController replicaController, My
         insertCustomer(masterController, "Arnold", "Test", "atest@test.com");
 
         String topic = connectorConfig.getDbServerName() + ".inventory.customers";
-        awaitAssert(() -> assertions.assertRecordsCount(topic, 8));
+        awaitAssert(() -> assertions.assertRecordsCount(topic, 9));
         awaitAssert(() -> assertions.assertRecordsContain(topic, "atest@test.com"));
     }
 
@@ -60,7 +60,7 @@ public void shouldStreamAfterMasterRestart(MySqlReplicaController replicaControl
         insertCustomer(masterController, "Alex", "master", "amaster@test.com");
 
         String topic = connectorConfig.getDbServerName() + ".inventory.customers";
-        awaitAssert(() -> assertions.assertRecordsCount(topic, 9));
+        awaitAssert(() -> assertions.assertRecordsCount(topic, 10));
         awaitAssert(() -> assertions.assertRecordsContain(topic, "amaster@test.com"));
 
         // restart only master after replication is complete, otherwise there is danger of duplicates in kafka topics
@@ -76,7 +76,7 @@ public void shouldStreamAfterMasterRestart(MySqlReplicaController replicaControl
 
         insertCustomer(masterController, "Tom", "Train", "ttrain@test.com");
 
-        awaitAssert(() -> assertions.assertRecordsCount(topic, 10));
+        awaitAssert(() -> assertions.assertRecordsCount(topic, 11));
         awaitAssert(() -> assertions.assertRecordsContain(topic, "ttrain@test.com"));
     }
 }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnection.java
Patch:
@@ -610,7 +610,7 @@ public Object getColumnValue(ResultSet rs, int columnIndex, Column column, Table
     }
 
     // NOTE: fix for DBZ-7359
-    // @Override
+    @Override
     public void setQueryColumnValue(PreparedStatement statement, Column column, int pos, Object value) throws SQLException {
         boolean isColumnValueSet = false;
 

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/OcpKafkaController.java
Patch:
@@ -189,7 +189,6 @@ public Properties getDefaultProducerProperties() {
         return kafkaProducerProps;
     }
 
-
     private File getKafkaCaCertificate() throws IOException {
         // get kafka cluster ca secret
         Secret secret = ocp.secrets().inNamespace(project).withName(KAFKA_CERT_SECRET).get();

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/assertions/JdbcAssertions.java
Patch:
@@ -11,11 +11,12 @@
 
 import java.sql.SQLException;
 
-import io.debezium.testing.system.tools.databases.SqlDatabaseClient;
-import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import io.debezium.testing.system.tools.databases.SqlDatabaseClient;
+import io.debezium.testing.system.tools.databases.SqlDatabaseController;
+
 public class JdbcAssertions {
     SqlDatabaseController databaseController;
     Logger LOGGER = LoggerFactory.getLogger(JdbcAssertions.class);

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/databases/ocp/OcpMySql.java
Patch:
@@ -5,9 +5,9 @@
  */
 package io.debezium.testing.system.fixtures.databases.ocp;
 
-import io.debezium.testing.system.assertions.JdbcAssertions;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
+import io.debezium.testing.system.assertions.JdbcAssertions;
 import io.debezium.testing.system.tools.ConfigProperties;
 import io.debezium.testing.system.tools.databases.mysql.MySqlController;
 import io.debezium.testing.system.tools.databases.mysql.OcpMySqlDeployer;

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/jdbc/sink/JdbcSinkTests.java
Patch:
@@ -22,6 +22,8 @@
 import org.apache.kafka.connect.sink.SinkRecord;
 import org.junit.jupiter.api.Order;
 import org.junit.jupiter.api.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 import io.debezium.connector.jdbc.util.DebeziumSinkRecordFactory;
 import io.debezium.connector.jdbc.util.SinkRecordBuilder;
@@ -33,8 +35,6 @@
 import okhttp3.OkHttpClient;
 import okhttp3.Request;
 import okhttp3.Response;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
 
 public abstract class JdbcSinkTests {
     protected final KafkaController kafkaController;
@@ -66,7 +66,7 @@ private void produceRecordToTopic(String topic, String fieldName, String fieldVa
     private String createRecord(String fieldName, String fieldValue) {
         DebeziumSinkRecordFactory factory = new DebeziumSinkRecordFactory();
 
-        SinkRecord record = SinkRecordBuilder.update() //TODO: Change to create when fixed in JDBC connector testsuite
+        SinkRecord record = SinkRecordBuilder.update() // TODO: Change to create when fixed in JDBC connector testsuite
                 .flat(false)
                 .name("jdbc-connector-test")
                 .recordSchema(SchemaBuilder.struct().field(fieldName, Schema.STRING_SCHEMA).build())

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -296,7 +296,7 @@ public void shouldValidateLockingModeNoneWithValidSnapshotModeConfiguration() {
             Config result = connector.validate(config.asMap());
             assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_LOCKING_MODE);
 
-            assertThat(new MySqlConnectorConfig(config).getSnapshotLockingMode()).isEqualTo(SnapshotLockingMode.NONE);
+            assertThat(new MySqlConnectorConfig(config).getSnapshotLockingMode().get()).isEqualTo(SnapshotLockingMode.NONE);
         }
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/strategy/AbstractHistoryRecordComparator.java
Patch:
@@ -97,12 +97,12 @@ else if (recordedGtidSetStr != null) {
 
         // Both positions are missing GTIDs. Look at the servers ...
         int recordedServerId = recorded.getInteger(SourceInfo.SERVER_ID_KEY, 0);
-        int desiredServerId = recorded.getInteger(SourceInfo.SERVER_ID_KEY, 0);
+        int desiredServerId = desired.getInteger(SourceInfo.SERVER_ID_KEY, 0);
         if (recordedServerId != desiredServerId) {
             // These are from different servers, and their binlog coordinates are not related. So the only thing we can do
             // is compare timestamps, and we have to assume that the server timestamps can be compared ...
             long recordedTimestamp = recorded.getLong(SourceInfo.TIMESTAMP_KEY, 0);
-            long desiredTimestamp = recorded.getLong(SourceInfo.TIMESTAMP_KEY, 0);
+            long desiredTimestamp = desired.getLong(SourceInfo.TIMESTAMP_KEY, 0);
             return recordedTimestamp <= desiredTimestamp;
         }
 

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/junit/jupiter/MySqlSinkDatabaseContextProvider.java
Patch:
@@ -18,7 +18,8 @@
  */
 public class MySqlSinkDatabaseContextProvider extends AbstractSinkDatabaseContextProvider {
 
-    private static final DockerImageName IMAGE_NAME = DockerImageName.parse("mysql");
+    private static final DockerImageName IMAGE_NAME = DockerImageName.parse("mysql:8.2")
+            .asCompatibleSubstituteFor("mysql");
 
     @SuppressWarnings("resource")
     public MySqlSinkDatabaseContextProvider() {

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/MongoDbReplicaSet.java
Patch:
@@ -78,12 +78,14 @@ public static Builder configServerReplicaSet() {
 
     public static class Builder {
 
+        private static final Network commonNetwork = Network.newNetwork();
+
         private String name = "rs0";
         private String namespace = "test-mongo";
         private int memberCount = 3;
         private boolean configServer = false;
 
-        private Network network = Network.newNetwork();
+        private Network network = commonNetwork;
         private PortResolver portResolver = new RandomPortResolver();
         private boolean skipDockerDesktopLogWarning = false;
         private DockerImageName imageName;

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/MongoDbShardedCluster.java
Patch:
@@ -58,11 +58,13 @@ public static Builder shardedCluster() {
 
     public static class Builder {
 
+        private static final Network commonNetwork = Network.newNetwork();
+
         private int shardCount = 1;
         private int replicaCount = 1;
         private int routerCount = 1;
 
-        private Network network = Network.newNetwork();
+        private Network network = commonNetwork;
         private PortResolver portResolver = new RandomPortResolver();
         private boolean skipDockerDesktopLogWarning = false;
         private DockerImageName imageName;

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SchemaHistoryTopicIT.java
Patch:
@@ -261,6 +261,7 @@ public void schemaChangeAfterSnapshot() throws Exception {
         final Configuration config = TestHelper.defaultConfig()
                 .with(SqlServerConnectorConfig.SNAPSHOT_MODE, SnapshotMode.INITIAL)
                 .with(SqlServerConnectorConfig.INCLUDE_SCHEMA_CHANGES, true)
+                .with(SqlServerConnectorConfig.STORE_ONLY_CAPTURED_TABLES_DDL, "true")
                 .with(SqlServerConnectorConfig.TABLE_INCLUDE_LIST, "dbo.tablec")
                 .build();
 

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorIT.java
Patch:
@@ -3052,6 +3052,7 @@ public void shouldProcessPurgedLogsWhenDownAndSnapshotNeeded() throws SQLExcepti
         Configuration config = TestHelper.defaultConfig()
                 .with(SqlServerConnectorConfig.SNAPSHOT_MODE, SnapshotMode.WHEN_NEEDED)
                 .with(SqlServerConnectorConfig.INCLUDE_SCHEMA_CHANGES, true)
+                .with(SqlServerConnectorConfig.STORE_ONLY_CAPTURED_TABLES_DDL, "true")
                 .with(SqlServerConnectorConfig.TABLE_INCLUDE_LIST, "dbo.tablea")
                 .build();
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -1162,6 +1162,9 @@ protected Object convertBinaryToBase64UrlSafe(Column column, Field fieldDefn, Ob
 
     @Override
     protected Object convertBinaryToHex(Column column, Field fieldDefn, Object data) {
+        if (data == UnchangedToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE) {
+            return unchangedToastedPlaceholder.getToastPlaceholderString();
+        }
         return super.convertBinaryToHex(column, fieldDefn, (data instanceof PGobject) ? ((PGobject) data).getValue() : data);
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -1084,7 +1084,7 @@ protected void handleDataEvent(LogMinerEventRow row) throws SQLException, Interr
         // so to be backward compatible, we only explicitly trigger this behavior if there is an
         // error reason for STATUS=2 in the INFO column as well as STATUS=2.
         if (row.getStatus() == 2 && !Strings.isNullOrBlank(row.getInfo())) {
-            if (!isUsingHybridStrategy() && !isTableKnown(row)) {
+            if (!isUsingHybridStrategy() || (isUsingHybridStrategy() && !isTableKnown(row))) {
                 // The SQL in the SQL_REDO column is not valid and cannot be parsed.
                 switch (connectorConfig.getEventProcessingFailureHandlingMode()) {
                     case FAIL:

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnection.java
Patch:
@@ -707,7 +707,6 @@ private <T> T optionallyDoInContainer(ContainerWork<T> work) throws SQLException
     }
 
     public Long getTableObjectId(TableId tableId) throws SQLException {
-        // todo: this assumes table type, but this won't work for materialized views or views
         return prepareQueryAndMap(
                 "SELECT OBJECT_ID FROM ALL_OBJECTS WHERE OBJECT_TYPE='TABLE' AND OWNER=? AND OBJECT_NAME=?",
                 ps -> {
@@ -717,7 +716,6 @@ public Long getTableObjectId(TableId tableId) throws SQLException {
     }
 
     public Long getTableDataObjectId(TableId tableId) throws SQLException {
-        // todo: this assumes table type, but this won't work for materialized views or views
         return prepareQueryAndMap(
                 "SELECT DATA_OBJECT_ID FROM ALL_OBJECTS WHERE OBJECT_TYPE='TABLE' AND OWNER=? AND OBJECT_NAME=?",
                 ps -> {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -1210,9 +1210,8 @@ private TableId getTableIdForDataEvent(LogMinerEventRow row) throws SQLException
             }
             else if (tableId.table().equalsIgnoreCase("UNKNOWN")) {
                 // Object has been dropped and purged.
-                // todo: only option is to resolve the lookup by table using object id
                 for (TableId schemaTableId : schema.tableIds()) {
-                    final Table table = schema.tableFor(tableId);
+                    final Table table = schema.tableFor(schemaTableId);
                     final Attribute objectId = table.attributeWithName("OBJECT_ID");
                     final Attribute dataObjectId = table.attributeWithName("DATA_OBJECT_ID");
                     if (objectId != null && dataObjectId != null) {

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/CloudEventsConverterIT.java
Patch:
@@ -28,7 +28,6 @@
 import io.debezium.converters.CloudEventsConverterTest;
 import io.debezium.data.Envelope;
 import io.debezium.doc.FixFor;
-import io.debezium.util.Testing;
 
 /**
  * Test to verify MongoDB connector behaviour with CloudEvents converter for all streaming events.
@@ -43,7 +42,7 @@ public class CloudEventsConverterIT extends AbstractMongoConnectorIT {
 
     @Before
     public void beforeEach() {
-        Testing.Print.enable();
+        // Testing.Print.enable();
         config = getConfiguration();
         context = new MongoDbTaskContext(config);
         TestHelper.cleanDatabase(mongo, DB_NAME);

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/TransactionMetadataIT.java
Patch:
@@ -17,7 +17,6 @@
 import io.debezium.doc.FixFor;
 import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Collect;
-import io.debezium.util.Testing;
 
 /**
  * Transaction metadata integration test for Debezium MongoDB connector.
@@ -28,7 +27,7 @@ public class TransactionMetadataIT extends AbstractMongoConnectorIT {
 
     @Test
     public void transactionMetadata() throws Exception {
-        Testing.Print.enable();
+        // Testing.Print.enable();
         config = TestHelper.getConfiguration(mongo)
                 .edit()
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, "dbA.c1")
@@ -80,7 +79,7 @@ public void transactionMetadata() throws Exception {
     @Test
     @FixFor("DBZ-4077")
     public void transactionMetadataWithCustomTopicName() throws Exception {
-        Testing.Print.enable();
+        // Testing.Print.enable();
         config = TestHelper.getConfiguration(mongo)
                 .edit()
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, "dbA.c1")

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/IncrementalSnapshotIT.java
Patch:
@@ -281,7 +281,7 @@ public void updates() throws Exception {
     @Test
     @FixFor("DBZ-4939")
     public void tableWithDatetime() throws Exception {
-        Testing.Print.enable();
+        // Testing.Print.enable();
         final int ROWS = 10;
 
         try (JdbcConnection connection = databaseConnection()) {
@@ -334,7 +334,7 @@ record -> {
     @Test
     @FixFor("DBZ-5099")
     public void tableWithZeroDate() throws Exception {
-        Testing.Print.enable();
+        // Testing.Print.enable();
         final LogInterceptor logInterceptor = new LogInterceptor(MySqlBinaryProtocolFieldReader.class);
 
         try (JdbcConnection connection = databaseConnection()) {

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlMetricsIT.java
Patch:
@@ -49,7 +49,7 @@ public class MySqlMetricsIT extends AbstractAsyncEngineConnectorTest {
 
     @Before
     public void before() throws Exception {
-        Testing.Print.enable();
+        // Testing.Print.enable();
         stopConnector();
         DATABASE.createAndInitialize();
         initializeConnectorTestFramework();
@@ -319,7 +319,7 @@ private void assertStreamingMetrics(long events) throws Exception {
 
         waitForAvailableRecords(30, TimeUnit.SECONDS);
 
-        Testing.Print.enable();
+        // Testing.Print.enable();
         int size = consumeAvailableRecords(VerifyRecord::print);
 
         // Check streaming metrics

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlParserIT.java
Patch:
@@ -94,7 +94,7 @@ public Configuration.Builder defaultConfig() {
     public void parseTableWithVisibleColumns() throws SQLException, InterruptedException {
         config = defaultConfig().build();
 
-        Testing.Print.enable();
+        // Testing.Print.enable();
 
         try (MySqlTestConnection db = MySqlTestConnection.forTestDatabase(DB_NAME, mySQLContainer.getUsername(), mySQLContainer.getPassword())) {
             try (JdbcConnection connection = db.connect()) {
@@ -128,7 +128,7 @@ public void parseTableWithVisibleColumns() throws SQLException, InterruptedExcep
     public void parseTableWithInVisibleColumns() throws SQLException, InterruptedException {
         config = defaultConfig().build();
 
-        Testing.Print.enable();
+        // Testing.Print.enable();
 
         try (MySqlTestConnection db = MySqlTestConnection.forTestDatabase(DB_NAME, mySQLContainer.getUsername(), mySQLContainer.getPassword())) {
             try (JdbcConnection connection = db.connect()) {

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MysqlNonUtfDatabaseCharsetIT.java
Patch:
@@ -57,7 +57,7 @@ public void useStringsDuringSnapshots() throws InterruptedException, SQLExceptio
                 .build();
         start(MySqlConnector.class, config);
 
-        Testing.Print.enable();
+        // Testing.Print.enable();
 
         AbstractConnectorTest.SourceRecords records = consumeRecordsByTopic(7);
         final SourceRecord record = records.recordsForTopic(DATABASE.topicForTable("DATA")).get(0);
@@ -90,7 +90,7 @@ public void useByteArrayDuringSnapshots() throws InterruptedException, SQLExcept
                 .build();
         start(MySqlConnector.class, config);
 
-        Testing.Print.enable();
+        // Testing.Print.enable();
 
         AbstractConnectorTest.SourceRecords records = consumeRecordsByTopic(7);
         final SourceRecord record = records.recordsForTopic(DATABASE.topicForTable("DATA")).get(0);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/IncrementalSnapshotIT.java
Patch:
@@ -193,7 +193,7 @@ protected String server() {
     @Test
     @FixFor("DBZ-6481")
     public void insertsEnumPk() throws Exception {
-        Testing.Print.enable();
+        // Testing.Print.enable();
         final var enumValues = List.of("UP", "DOWN", "LEFT", "RIGHT", "STORY");
 
         try (JdbcConnection connection = databaseConnection()) {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresShutdownIT.java
Patch:
@@ -31,7 +31,6 @@
 import io.debezium.heartbeat.Heartbeat;
 import io.debezium.jdbc.JdbcConfiguration;
 import io.debezium.testing.testcontainers.util.ContainerImageVersions;
-import io.debezium.util.Testing;
 
 /**
  * Integration test for {@link PostgresConnector} using an {@link EmbeddedEngine} and Testcontainers infrastructure for when Postgres is shutdown during streaming
@@ -109,7 +108,7 @@ public void shouldStopOnPostgresFastShutdown() throws Exception {
                 .with(Heartbeat.HEARTBEAT_INTERVAL, 500)
                 .with(DatabaseHeartbeatImpl.HEARTBEAT_ACTION_QUERY, "UPDATE s1.heartbeat SET ts=NOW();");
 
-        Testing.Print.enable();
+        // Testing.Print.enable();
         PostgresConnection postgresConnection = TestHelper.create();
         String initialHeartbeat = postgresConnection.queryAndMap(
                 "SELECT ts FROM s1.heartbeat;",

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/connection/PostgresConnectionIT.java
Patch:
@@ -151,7 +151,7 @@ private PgConnection getUnderlyingConnection(ReplicationConnection connection) t
 
     @Test
     public void shouldDetectRunningConncurrentTxOnInit() throws Exception {
-        Testing.Print.enable();
+        // Testing.Print.enable();
         // drop the slot from the previous connection
         final String slotName = "block";
         try (PostgresConnection connection = TestHelper.create()) {

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectionIT.java
Patch:
@@ -103,7 +103,7 @@ public void shouldEnableCdcWithWrapperFunctionsForTable() throws Exception {
             // and issue a test call to a CDC wrapper function
             Thread.sleep(5_000); // Need to wait to make sure the min_lsn is available
 
-            Testing.Print.enable();
+            // Testing.Print.enable();
             connection.query(
                     "select * from cdc.fn_cdc_get_all_changes_dbo_testTable(sys.fn_cdc_get_min_lsn('dbo_testTable'), sys.fn_cdc_get_max_lsn(), N'all')",
                     rs -> {

File: debezium-storage/debezium-storage-jdbc/src/test/java/io/debezium/storage/jdbc/history/JdbcSchemaHistoryIT.java
Patch:
@@ -172,7 +172,7 @@ public void shouldStreamChangesAfterRestart() throws InterruptedException, SQLEx
         start(MySqlConnector.class, config);
         waitForStreamingRunning("mysql", TOPIC_PREFIX);
 
-        Testing.Print.enable();
+        // Testing.Print.enable();
         SourceRecords records = consumeRecordsByTopic(4); // 4 DML changes
         assertThat(records.topics().size()).isEqualTo(1);
         assertThat(records.recordsForTopic(topicName())).hasSize(4);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleOffsetContext.java
Patch:
@@ -334,6 +334,7 @@ else if (getScnIndex() != null) {
         }
 
         sb.append(", commit_scn=").append(sourceInfo.getCommitScn().toLoggableFormat());
+        sb.append(", lcr_position=").append(sourceInfo.getLcrPosition());
 
         sb.append("]");
 

File: debezium-embedded/src/test/java/io/debezium/embedded/AbstractConnectorTest.java
Patch:
@@ -1225,7 +1225,7 @@ protected void storeOffsets(Configuration config, Map<Map<String, ?>, Map<String
     public void waitForEngineShutdown() {
         Awaitility.await()
                 .pollInterval(200, TimeUnit.MILLISECONDS)
-                .atMost(waitTimeForEngine() * 3, TimeUnit.MILLISECONDS)
+                .atMost(waitTimeForEngine(), TimeUnit.SECONDS)
                 .until(() -> !isEngineRunning.get());
     }
 
@@ -1273,7 +1273,7 @@ protected void assertRecordTransactionMetadata(SourceRecord record, String expec
     }
 
     public static int waitTimeForEngine() {
-        return Integer.parseInt(System.getProperty(TEST_PROPERTY_PREFIX + "engine.waittime", "1000"));
+        return Integer.parseInt(System.getProperty(TEST_PROPERTY_PREFIX + "engine.waittime", "5"));
     }
 
     public static int waitTimeForRecords() {

File: debezium-embedded/src/test/java/io/debezium/embedded/async/AsyncEmbeddedEngineTest.java
Patch:
@@ -298,7 +298,7 @@ public void testCompletionCallbackCalledUponFailure() throws Exception {
             engine.run();
         });
 
-        callbackLatch.await(2 * AbstractConnectorTest.waitTimeForEngine(), TimeUnit.MILLISECONDS);
+        callbackLatch.await(2 * AbstractConnectorTest.waitTimeForEngine(), TimeUnit.SECONDS);
         assertThat(callbackLatch.getCount()).isEqualTo(0);
     }
 
@@ -696,7 +696,7 @@ protected void waitForTasksToStart(int minRunningTasks) {
         Awaitility.await()
                 .alias("Engine haven't started on time")
                 .pollInterval(10, TimeUnit.MILLISECONDS)
-                .atMost(AbstractConnectorTest.waitTimeForEngine(), TimeUnit.MILLISECONDS)
+                .atMost(AbstractConnectorTest.waitTimeForEngine(), TimeUnit.SECONDS)
                 .until(() -> runningTasks.get() >= minRunningTasks);
     }
 

File: debezium-core/src/main/java/io/debezium/pipeline/notification/IncrementalSnapshotNotificationService.java
Patch:
@@ -10,6 +10,7 @@
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
+import java.util.Objects;
 import java.util.UUID;
 import java.util.stream.Collectors;
 
@@ -130,8 +131,8 @@ public <T extends DataCollectionId> void notifyInProgress(IncrementalSnapshotCon
                 Map.of(
                         DATA_COLLECTIONS, dataCollections,
                         CURRENT_COLLECTION_IN_PROGRESS, incrementalSnapshotContext.currentDataCollectionId().getId().identifier(),
-                        MAXIMUM_KEY, incrementalSnapshotContext.maximumKey().orElse(new Object[0])[0].toString(),
-                        LAST_PROCESSED_KEY, incrementalSnapshotContext.chunkEndPosititon()[0].toString()),
+                        MAXIMUM_KEY, Objects.toString(incrementalSnapshotContext.maximumKey().orElse(new Object[0])[0], "<null>"),
+                        LAST_PROCESSED_KEY, Objects.toString(incrementalSnapshotContext.chunkEndPosititon()[0], "<null>")),
                 offsetContext),
                 Offsets.of(partition, offsetContext));
     }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlStreamingChangeEventSource.java
Patch:
@@ -227,7 +227,7 @@ protected void onEvent(MySqlOffsetContext offsetContext, Event event) {
     }
 
     private void setEventTimestamp(Event event, long eventTs) {
-        if (connection.isMariaDb() || !isGtidModeEnabled) {
+        if (eventTimestamp == null || connection.isMariaDb() || !isGtidModeEnabled) {
             // Fallback to second resolution event timestamps
             eventTimestamp = Instant.ofEpochMilli(eventTs);
         }

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/mongodb/sharded/OcpMongoShardedController.java
Patch:
@@ -18,7 +18,7 @@
 import io.debezium.testing.system.tools.ConfigProperties;
 import io.debezium.testing.system.tools.databases.mongodb.MongoDatabaseClient;
 import io.debezium.testing.system.tools.databases.mongodb.MongoDatabaseController;
-import io.debezium.testing.system.tools.databases.mongodb.sharded.componentfactories.OcpMongosModelFactory;
+import io.debezium.testing.system.tools.databases.mongodb.sharded.componentfactories.OcpMongosModelProvider;
 import io.fabric8.kubernetes.api.model.Service;
 import io.fabric8.openshift.client.OpenShiftClient;
 
@@ -124,7 +124,7 @@ private Service getService() {
         return ocp
                 .services()
                 .inNamespace(project)
-                .withName(OcpMongosModelFactory.DEPLOYMENT_NAME)
+                .withName(OcpMongosModelProvider.DEPLOYMENT_NAME)
                 .get();
     }
 

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/mongodb/sharded/OcpShardedMongoReplica.java
Patch:
@@ -9,12 +9,14 @@
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.openshift.client.OpenShiftClient;
 
+import lombok.Builder;
 import lombok.Getter;
 
 @Getter
 public class OcpShardedMongoReplica extends OcpMongoShardedNode {
     private final int replicaNum;
 
+    @Builder(setterPrefix = "with")
     public OcpShardedMongoReplica(Deployment deployment, Service service, String serviceUrl, OpenShiftClient ocp, String project, int replicaNum) {
         super(deployment, service, serviceUrl, ocp, project);
         this.replicaNum = replicaNum;

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/mongodb/sharded/componentfactories/OcpConfigServerModelProvider.java
Patch:
@@ -30,7 +30,7 @@
 import io.fabric8.kubernetes.api.model.apps.DeploymentSpecBuilder;
 import io.fabric8.kubernetes.api.model.apps.DeploymentStrategyBuilder;
 
-public class OcpConfigServerModelFactory {
+public class OcpConfigServerModelProvider {
 
     public static String getConfigServerName(int num) {
         return OcpMongoShardedConstants.MONGO_CONFIG_DEPLOYMENT_NAME + num;

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/mongodb/sharded/componentfactories/OcpMongosModelProvider.java
Patch:
@@ -28,7 +28,7 @@
 import io.fabric8.kubernetes.api.model.apps.DeploymentSpecBuilder;
 import io.fabric8.kubernetes.api.model.apps.DeploymentStrategyBuilder;
 
-public class OcpMongosModelFactory {
+public class OcpMongosModelProvider {
     public static final String DEPLOYMENT_NAME = "mongo-mongos";
 
     public static Deployment mongosDeployment(String configServersRs) {

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/mongodb/sharded/componentfactories/OcpShardModelProvider.java
Patch:
@@ -31,7 +31,7 @@
 import io.fabric8.kubernetes.api.model.apps.DeploymentSpecBuilder;
 import io.fabric8.kubernetes.api.model.apps.DeploymentStrategyBuilder;
 
-public class OcpShardModelFactory {
+public class OcpShardModelProvider {
 
     public static Deployment shardDeployment(int shardNum, int replicaNum) {
         String name = getShardNodeName(shardNum, replicaNum);

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/oracle/OcpOracleController.java
Patch:
@@ -48,7 +48,7 @@ public void initialize() throws InterruptedException {
                 .file(DB_INIT_SCRIPT_PATH_CONTAINER)
                 .upload(initScript);
 
-        executeInitCommand(deployment, "sqlplus", "-S",
+        ocpUtils.executeCommand(deployment, project, true, "sqlplus", "-S",
                 DATABASE_ORACLE_USERNAME + "/" + DATABASE_ORACLE_PASSWORD + "@//localhost:1521/ORCLPDB1", "@" + DB_INIT_SCRIPT_PATH_CONTAINER);
     }
 

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/postgresql/OcpPostgreSqlReplicaController.java
Patch:
@@ -48,6 +48,7 @@ public void initialize() throws InterruptedException {
         ocp.pods().inNamespace(project).withName(pod.getMetadata().getName())
                 .file(INIT_SCRIPT_PATH_CONTAINER)
                 .upload(initScript);
-        executeInitCommand(deployment, "psql", "-U", DATABASE_POSTGRESQL_USERNAME, "-d", DATABASE_POSTGRESQL_DBZ_DBNAME, "-f", INIT_SCRIPT_PATH_CONTAINER);
+        ocpUtils.executeCommand(deployment, project, true, "psql", "-U", DATABASE_POSTGRESQL_USERNAME, "-d", DATABASE_POSTGRESQL_DBZ_DBNAME, "-f",
+                INIT_SCRIPT_PATH_CONTAINER);
     }
 }

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/sqlserver/OcpSqlServerController.java
Patch:
@@ -54,6 +54,7 @@ public void initialize() throws InterruptedException {
         ocp.pods().inNamespace(project).withName(pod.getMetadata().getName())
                 .file(DB_INIT_SCRIPT_PATH_CONTAINER)
                 .upload(initScript);
-        executeInitCommand(deployment, "/opt/mssql-tools/bin/sqlcmd", "-U", "sa", "-P", DATABASE_SQLSERVER_SA_PASSWORD, "-i", DB_INIT_SCRIPT_PATH_CONTAINER);
+        ocpUtils.executeCommand(deployment, project, true, "/opt/mssql-tools/bin/sqlcmd", "-U", "sa", "-P", DATABASE_SQLSERVER_SA_PASSWORD, "-i",
+                DB_INIT_SCRIPT_PATH_CONTAINER);
     }
 }

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mongodb/sharded/ShardedMongoTests.java
Patch:
@@ -26,7 +26,7 @@
 import io.debezium.testing.system.tools.databases.mongodb.sharded.MongoShardedUtil;
 import io.debezium.testing.system.tools.databases.mongodb.sharded.OcpMongoShardedController;
 import io.debezium.testing.system.tools.databases.mongodb.sharded.ShardKeyRange;
-import io.debezium.testing.system.tools.databases.mongodb.sharded.componentfactories.OcpShardModelFactory;
+import io.debezium.testing.system.tools.databases.mongodb.sharded.componentfactories.OcpShardModelProvider;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -93,7 +93,7 @@ protected void addAndRemoveShardTest(OcpMongoShardedController dbController, Str
 
         // add shard, restart connector, insert to that shard and verify that insert was captured by debezium
         var key = dbController.getMongo().getShardKey("inventory.customers");
-        var keyRange = new ShardKeyRange(OcpShardModelFactory.getShardReplicaSetName(3), "1100", "1105");
+        var keyRange = new ShardKeyRange(OcpShardModelProvider.getShardReplicaSetName(3), "1100", "1105");
         dbController.addShard(Map.of(key, keyRange));
         var sets = dbController.getMongo().getShardReplicaSets();
         sets.get(sets.size() - 1).executeMongosh(

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/ConfigProperties.java
Patch:
@@ -101,7 +101,7 @@ private ConfigProperties() {
     public static final String DATABASE_MONGO_DBZ_LOGIN_DBNAME = System.getProperty("test.database.mongo.dbz.login.dbname", "admin");
     public static final Optional<String> DATABASE_MONGO_HOST = stringOptionalProperty("test.database.mongo.host");
     public static final int DATABASE_MONGO_PORT = Integer.parseInt(System.getProperty("test.database.mongo.port", "27017"));
-    public static final boolean DATABASE_MONGO_ENABLE_INTERNAL_AUTH = Boolean.parseBoolean(System.getProperty("test.database.mongo.sharded.enable.internal.auth"));
+    public static final boolean DATABASE_MONGO_USE_KEYFILE = Boolean.parseBoolean(System.getProperty("test.database.mongo.use.keyfile"));
 
     public static final String DATABASE_MONGO_DOCKER_DESKTOP_PORTS = System.getProperty("database.mongo.docker.desktop.ports", "27017:27117");
     public static final int DATABASE_MONGO_DOCKER_REPLICA_SIZE = Integer.parseInt(System.getProperty("database.mongo.docker.replica.size", "1"));

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/mongodb/sharded/OcpMongoShardedNode.java
Patch:
@@ -41,8 +41,6 @@ public void start() {
     @Override
     public void stop() {
         ocpUtils.scaleDeploymentToZero(deployment);
-        // ocp.apps().deployments().inNamespace(project).delete(deployment);
-        // ocp.services().inNamespace(project).delete(service);
     }
 
     public void waitForStopped() {

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/mongodb/sharded/componentfactories/OcpConfigServerModelFactory.java
Patch:
@@ -83,7 +83,6 @@ public static Deployment configServerDeployment(int num) {
                                                 .withImage(ConfigProperties.DOCKER_IMAGE_MONGO_SHARDED)
                                                 .withCommand("mongod",
                                                         "--configsvr",
-                                                        "--auth",
                                                         "--replSet",
                                                         OcpMongoShardedConstants.MONGO_CONFIG_REPLICASET_NAME,
                                                         "--dbpath",

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/mongodb/sharded/componentfactories/OcpShardModelFactory.java
Patch:
@@ -82,7 +82,6 @@ public static Deployment shardDeployment(int shardNum, int replicaNum) {
                                                 .withImage(ConfigProperties.DOCKER_IMAGE_MONGO_SHARDED)
                                                 .withCommand("mongod",
                                                         "--shardsvr",
-                                                        "--auth",
                                                         "--replSet",
                                                         getShardReplicaSetName(shardNum),
                                                         "--dbpath",

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/databases/ocp/OcpMongoSharded.java
Patch:
@@ -35,7 +35,7 @@ protected OcpMongoShardedController databaseController() throws Exception {
                 .withShardCount(OcpMongoShardedConstants.SHARD_COUNT)
                 .withReplicaCount(OcpMongoShardedConstants.REPLICAS_IN_SHARD)
                 .withShardKeys(getTestShardKeys())
-                .withUseInternalAuth(ConfigProperties.DATABASE_MONGO_ENABLE_INTERNAL_AUTH)
+                .withUseInternalAuth(ConfigProperties.DATABASE_MONGO_USE_KEYFILE)
                 .withRootUser(ConfigProperties.DATABASE_MONGO_USERNAME, ConfigProperties.DATABASE_MONGO_SA_PASSWORD)
                 .build();
         controller = deployer.deploy();

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/rest/DebeziumMongoDbConnectorResource.java
Patch:
@@ -35,8 +35,7 @@
 @Path(DebeziumMongoDbConnectorResource.BASE_PATH)
 @Produces(MediaType.APPLICATION_JSON)
 @Consumes(MediaType.APPLICATION_JSON)
-public class DebeziumMongoDbConnectorResource
-        implements SchemaResource, ConnectionValidationResource<MongoDbConnector>, FilterValidationResource<MongoDbConnector>, MetricsResource {
+public class DebeziumMongoDbConnectorResource implements SchemaResource, ConnectionValidationResource, FilterValidationResource, MetricsResource {
 
     public static final String BASE_PATH = "/debezium/mongodb";
     public static final String VERSION_ENDPOINT = "/version";

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/rest/DebeziumMySqlConnectorResource.java
Patch:
@@ -35,8 +35,7 @@
 @Path(DebeziumMySqlConnectorResource.BASE_PATH)
 @Produces(MediaType.APPLICATION_JSON)
 @Consumes(MediaType.APPLICATION_JSON)
-public class DebeziumMySqlConnectorResource
-        implements SchemaResource, ConnectionValidationResource<MySqlConnector>, FilterValidationResource<MySqlConnector>, MetricsResource {
+public class DebeziumMySqlConnectorResource implements SchemaResource, ConnectionValidationResource, FilterValidationResource, MetricsResource {
 
     public static final String BASE_PATH = "/debezium/mysql";
     public static final String VERSION_ENDPOINT = "/version";

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/rest/DebeziumOracleConnectorResource.java
Patch:
@@ -35,8 +35,7 @@
 @Path(DebeziumOracleConnectorResource.BASE_PATH)
 @Produces(MediaType.APPLICATION_JSON)
 @Consumes(MediaType.APPLICATION_JSON)
-public class DebeziumOracleConnectorResource
-        implements SchemaResource, ConnectionValidationResource<OracleConnector>, FilterValidationResource<OracleConnector>, MetricsResource {
+public class DebeziumOracleConnectorResource implements SchemaResource, ConnectionValidationResource, FilterValidationResource, MetricsResource {
 
     public static final String BASE_PATH = "/debezium/oracle";
     public static final String VERSION_ENDPOINT = "/version";

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/rest/DebeziumPostgresConnectorResource.java
Patch:
@@ -35,8 +35,7 @@
 @Path(DebeziumPostgresConnectorResource.BASE_PATH)
 @Produces(MediaType.APPLICATION_JSON)
 @Consumes(MediaType.APPLICATION_JSON)
-public class DebeziumPostgresConnectorResource
-        implements SchemaResource, ConnectionValidationResource<PostgresConnector>, FilterValidationResource<PostgresConnector>, MetricsResource {
+public class DebeziumPostgresConnectorResource implements SchemaResource, ConnectionValidationResource, FilterValidationResource, MetricsResource {
 
     public static final String BASE_PATH = "/debezium/postgres";
     public static final String VERSION_ENDPOINT = "/version";

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/rest/DebeziumSqlServerConnectorResource.java
Patch:
@@ -35,8 +35,7 @@
 @Path(DebeziumSqlServerConnectorResource.BASE_PATH)
 @Produces(MediaType.APPLICATION_JSON)
 @Consumes(MediaType.APPLICATION_JSON)
-public class DebeziumSqlServerConnectorResource
-        implements SchemaResource, ConnectionValidationResource<SqlServerConnector>, FilterValidationResource<SqlServerConnector>, MetricsResource {
+public class DebeziumSqlServerConnectorResource implements SchemaResource, ConnectionValidationResource, FilterValidationResource, MetricsResource {
 
     public static final String BASE_PATH = "/debezium/sqlserver";
     public static final String VERSION_ENDPOINT = "/version";

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/metadata/MongoDbConnectorMetadata.java
Patch:
@@ -16,7 +16,7 @@ public class MongoDbConnectorMetadata implements ConnectorMetadata {
 
     @Override
     public ConnectorDescriptor getConnectorDescriptor() {
-        return new ConnectorDescriptor("mongodb", "Debezium MongoDB Connector", MongoDbConnector.class.getName(), Module.version());
+        return new ConnectorDescriptor(MongoDbConnector.class.getName(), Module.version());
     }
 
     @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/metadata/MySqlConnectorMetadata.java
Patch:
@@ -16,7 +16,7 @@ public class MySqlConnectorMetadata implements ConnectorMetadata {
 
     @Override
     public ConnectorDescriptor getConnectorDescriptor() {
-        return new ConnectorDescriptor("mysql", "Debezium MySQL Connector", MySqlConnector.class.getName(), Module.version());
+        return new ConnectorDescriptor(MySqlConnector.class.getName(), Module.version());
     }
 
     @Override

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/metadata/OracleConnectorMetadata.java
Patch:
@@ -16,7 +16,7 @@ public class OracleConnectorMetadata implements ConnectorMetadata {
 
     @Override
     public ConnectorDescriptor getConnectorDescriptor() {
-        return new ConnectorDescriptor("oracle", "Debezium Oracle Connector", OracleConnector.class.getName(), Module.version());
+        return new ConnectorDescriptor(OracleConnector.class.getName(), Module.version());
     }
 
     @Override

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/metadata/PostgresConnectorMetadata.java
Patch:
@@ -16,7 +16,7 @@ public class PostgresConnectorMetadata implements ConnectorMetadata {
 
     @Override
     public ConnectorDescriptor getConnectorDescriptor() {
-        return new ConnectorDescriptor("postgres", "Debezium PostgreSQL Connector", PostgresConnector.class.getName(), Module.version());
+        return new ConnectorDescriptor(PostgresConnector.class.getName(), Module.version());
     }
 
     @Override

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/metadata/SqlServerConnectorMetadata.java
Patch:
@@ -16,7 +16,7 @@ public class SqlServerConnectorMetadata implements ConnectorMetadata {
 
     @Override
     public ConnectorDescriptor getConnectorDescriptor() {
-        return new ConnectorDescriptor("sqlserver", "Debezium SQLServer Connector", SqlServerConnector.class.getName(), Module.version());
+        return new ConnectorDescriptor(SqlServerConnector.class.getName(), Module.version());
     }
 
     @Override

File: debezium-embedded/src/main/java/io/debezium/embedded/async/AsyncEmbeddedEngine.java
Patch:
@@ -431,7 +431,7 @@ private void startSourceTasks(final List<EngineSourceTask> tasks) throws Excepti
 
         // If at least one task failed to start, re-throw exception and abort the start of the connector.
         if (error != null) {
-            LOGGER.info("{} task(s) out of {} failed to start.", failedTasks, nTasks);
+            LOGGER.error("{} task(s) out of {} failed to start.", failedTasks, nTasks);
             throw error;
         }
         else {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SignalsIT.java
Patch:
@@ -72,7 +72,7 @@ private void signalLog(boolean includingEscapedCharacter) throws InterruptedExce
         final LogInterceptor logInterceptor = new LogInterceptor(Log.class);
 
         String signalTable = "s1.debezium_signal";
-        String signalTableWithEscapedCharacter = "s1.\"debezium_signal\\\"";
+        String signalTableWithEscapedCharacter = "s1.\"debezium_signal\"";
 
         TestHelper.dropDefaultReplicationSlot();
         TestHelper.execute(includingEscapedCharacter ? SETUP_TABLES_STMT.replace(signalTable, signalTableWithEscapedCharacter) : SETUP_TABLES_STMT);

File: debezium-embedded/src/main/java/io/debezium/embedded/async/AsyncEmbeddedEngine.java
Patch:
@@ -577,6 +577,7 @@ private void stopSourceTasks(final List<EngineSourceTask> tasks) {
             final long taskStopTimeout = config.getLong(AsyncEngineConfig.TASK_MANAGEMENT_TIMEOUT_MS);
             LOGGER.debug("Waiting max. for {} ms for individual source tasks to stop.", taskStopTimeout);
             final int nTasks = tasks.size();
+            final long startTime = System.nanoTime();
             for (int i = 0; i < nTasks; i++) {
                 final Future<Void> taskFuture = taskCompletionService.poll(taskStopTimeout, TimeUnit.MILLISECONDS);
                 if (taskFuture != null) {
@@ -585,7 +586,8 @@ private void stopSourceTasks(final List<EngineSourceTask> tasks) {
                 else {
                     throw new InterruptedException("Time out while waiting for source task to stop.");
                 }
-                LOGGER.debug("Stopped task #{} out of {} tasks.", i + 1, nTasks);
+                // TODO move back to debug level once we stabilize the testsuite (or add similar log on info level for starting the tasks)
+                LOGGER.info("Stopped task #{} out of {} tasks (it took {} ms to stop the task).", i + 1, nTasks, (System.nanoTime() - startTime) / 1_000_000);
                 LOGGER.debug("Calling connector callback after task is stopped.");
                 // TODO improve Debezium API and provide more info to the callback like id and config
                 connectorCallback.ifPresent(DebeziumEngine.ConnectorCallback::taskStopped);

File: debezium-embedded/src/test/java/io/debezium/embedded/async/AsyncEmbeddedEngineTest.java
Patch:
@@ -595,6 +595,7 @@ private void runEngineBasicLifecycleWithConsumer(final Properties props) throws
 
     protected void stopEngine() {
         try {
+            LOGGER.info("Stopping engine");
             engine.close();
             Awaitility.await().atMost(1, TimeUnit.SECONDS).until(() -> !isEngineRunning.get());
         }
@@ -612,15 +613,15 @@ protected void waitForEngineToStart() {
         Awaitility.await()
                 .alias("Engine haven't started on time")
                 .pollInterval(TEST_TASK_MANAGEMENT_TIMEOUT_MS, TimeUnit.MILLISECONDS)
-                .atMost(1, TimeUnit.SECONDS)
+                .atMost(5 * TEST_TASK_MANAGEMENT_TIMEOUT_MS, TimeUnit.SECONDS)
                 .until(() -> isEngineRunning.get());
     }
 
     protected void waitForEngineToStop() {
         Awaitility.await()
                 .alias("Engine haven't stopped on time")
                 .pollInterval(TEST_TASK_MANAGEMENT_TIMEOUT_MS, TimeUnit.MILLISECONDS)
-                .atMost(10, TimeUnit.SECONDS)
+                .atMost(5 * TEST_TASK_MANAGEMENT_TIMEOUT_MS, TimeUnit.SECONDS)
                 .until(() -> !isEngineRunning.get());
     }
 

File: debezium-core/src/main/java/io/debezium/processors/reselect/ReselectColumnsPostProcessor.java
Patch:
@@ -150,10 +150,9 @@ public void apply(Object messageKey, Struct value) {
             }
         }
 
-        Map<String, Object> selections;
+        final Map<String, Object> selections;
         try {
-            final String reselectQuery = jdbcConnection.buildReselectColumnQuery(tableId, requiredColumnSelections, keyColumns, source);
-            selections = jdbcConnection.reselectColumns(reselectQuery, tableId, requiredColumnSelections, keyValues, source);
+            selections = jdbcConnection.reselectColumns(tableId, requiredColumnSelections, keyColumns, keyValues, source);
             if (selections.isEmpty()) {
                 LOGGER.warn("Failed to find row in table {} with key {}.", tableId, key);
                 return;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/SourceInfoTest.java
Patch:
@@ -248,6 +248,8 @@ public void schemaIsCorrect() {
                 .field("snapshot", AbstractSourceInfoStructMaker.SNAPSHOT_RECORD_SCHEMA)
                 .field("db", Schema.STRING_SCHEMA)
                 .field("sequence", Schema.OPTIONAL_STRING_SCHEMA)
+                .field("ts_us", Schema.INT64_SCHEMA)
+                .field("ts_ns", Schema.INT64_SCHEMA)
                 .field("collection", Schema.STRING_SCHEMA)
                 .field("ord", Schema.INT32_SCHEMA)
                 .field("lsid", Schema.OPTIONAL_STRING_SCHEMA)

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SourceInfoTest.java
Patch:
@@ -656,6 +656,8 @@ public void schemaIsCorrect() {
                 .field("snapshot", AbstractSourceInfoStructMaker.SNAPSHOT_RECORD_SCHEMA)
                 .field("db", Schema.STRING_SCHEMA)
                 .field("sequence", Schema.OPTIONAL_STRING_SCHEMA)
+                .field("ts_us", Schema.INT64_SCHEMA)
+                .field("ts_ns", Schema.INT64_SCHEMA)
                 .field("table", Schema.OPTIONAL_STRING_SCHEMA)
                 .field("server_id", Schema.INT64_SCHEMA)
                 .field("gtid", Schema.OPTIONAL_STRING_SCHEMA)

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/SourceInfoTest.java
Patch:
@@ -57,6 +57,8 @@ public void schemaIsCorrect() {
                 .field("snapshot", AbstractSourceInfoStructMaker.SNAPSHOT_RECORD_SCHEMA)
                 .field("db", Schema.STRING_SCHEMA)
                 .field("sequence", Schema.OPTIONAL_STRING_SCHEMA)
+                .field("ts_us", Schema.INT64_SCHEMA)
+                .field("ts_ns", Schema.INT64_SCHEMA)
                 .field("schema", Schema.STRING_SCHEMA)
                 .field("table", Schema.STRING_SCHEMA)
                 .field("txId", Schema.OPTIONAL_STRING_SCHEMA)

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SourceInfoTest.java
Patch:
@@ -70,6 +70,8 @@ public void schemaIsCorrect() {
                 .field("snapshot", AbstractSourceInfoStructMaker.SNAPSHOT_RECORD_SCHEMA)
                 .field("db", Schema.STRING_SCHEMA)
                 .field("sequence", Schema.OPTIONAL_STRING_SCHEMA)
+                .field("ts_us", Schema.INT64_SCHEMA)
+                .field("ts_ns", Schema.INT64_SCHEMA)
                 .field("schema", Schema.STRING_SCHEMA)
                 .field("table", Schema.STRING_SCHEMA)
                 .field("txId", Schema.OPTIONAL_INT64_SCHEMA)

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SourceInfoTest.java
Patch:
@@ -97,6 +97,8 @@ public void schemaIsCorrect() {
                 .field("snapshot", AbstractSourceInfoStructMaker.SNAPSHOT_RECORD_SCHEMA)
                 .field("db", Schema.STRING_SCHEMA)
                 .field("sequence", Schema.OPTIONAL_STRING_SCHEMA)
+                .field("ts_us", Schema.INT64_SCHEMA)
+                .field("ts_ns", Schema.INT64_SCHEMA)
                 .field("schema", Schema.STRING_SCHEMA)
                 .field("table", Schema.STRING_SCHEMA)
                 .field("change_lsn", Schema.OPTIONAL_STRING_SCHEMA)

File: debezium-embedded/src/main/java/io/debezium/embedded/AsyncEmbeddedEngine.java
Patch:
@@ -702,6 +702,9 @@ public static final class AsyncEngineBuilder implements DebeziumEngine.Builder<S
         @Override
         public Builder<SourceRecord> notifying(final Consumer<SourceRecord> consumer) {
             this.consumer = consumer;
+            if (config.contains(AsyncEngineConfig.RECORD_PROCESSING_WITH_SERIAL_CONSUMER.name())) {
+                this.handler = buildDefaultChangeConsumer(consumer);
+            }
             return this;
         }
 

File: debezium-embedded/src/main/java/io/debezium/embedded/AsyncEmbeddedEngine.java
Patch:
@@ -702,7 +702,6 @@ public static final class AsyncEngineBuilder implements DebeziumEngine.Builder<S
         @Override
         public Builder<SourceRecord> notifying(final Consumer<SourceRecord> consumer) {
             this.consumer = consumer;
-            this.handler = buildDefaultChangeConsumer(consumer);
             return this;
         }
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/ReadOnlyIncrementalSnapshotIT.java
Patch:
@@ -300,7 +300,7 @@ public void shouldFailIfGtidModeIsOff() throws Exception {
         populateTable();
         AtomicReference<Throwable> exception = new AtomicReference<>();
         startConnector((success, message, error) -> exception.set(error));
-        waitForConnectorShutdown("mysql", DATABASE.getServerName());
+        waitForEngineShutdown();
         stopConnector();
         final Throwable e = exception.get();
         if (e != null) {

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/StreamingSourceIT.java
Patch:
@@ -53,7 +53,7 @@
 import io.debezium.data.SchemaChangeHistory;
 import io.debezium.data.VerifyRecord;
 import io.debezium.doc.FixFor;
-import io.debezium.embedded.AbstractConnectorTest;
+import io.debezium.embedded.AbstractAsyncEngineConnectorTest;
 import io.debezium.heartbeat.DatabaseHeartbeatImpl;
 import io.debezium.heartbeat.Heartbeat;
 import io.debezium.jdbc.JdbcConnection;
@@ -69,7 +69,7 @@
  *
  */
 @SkipWhenDatabaseIs(value = Type.MYSQL, versions = @SkipWhenDatabaseVersion(check = LESS_THAN, major = 5, minor = 6, reason = "DDL uses fractional second data types, not supported until MySQL 5.6"))
-public class StreamingSourceIT extends AbstractConnectorTest {
+public class StreamingSourceIT extends AbstractAsyncEngineConnectorTest {
 
     private static final Path SCHEMA_HISTORY_PATH = Testing.Files.createTestingPath("file-schema-history-binlog.txt").toAbsolutePath();
     private final UniqueDatabase DATABASE = new UniqueDatabase("logical_server_name", "connector_test_ro")
@@ -607,7 +607,7 @@ private void inconsistentSchema(EventProcessingFailureHandlingMode mode) throws
         if (mode == null) {
             Awaitility.await().atMost(Duration.ofSeconds(waitTimeForRecords()))
                     .until(() -> logInterceptor.containsMessage("Error during binlog processing."));
-            waitForConnectorShutdown("mysql", DATABASE.getServerName());
+            waitForEngineShutdown();
         }
         else {
             waitForStreamingRunning("mysql", DATABASE.getServerName(), "streaming");

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlRestartIT.java
Patch:
@@ -18,14 +18,14 @@
 
 import io.debezium.config.Configuration;
 import io.debezium.doc.FixFor;
-import io.debezium.embedded.AbstractConnectorTest;
+import io.debezium.embedded.AbstractAsyncEngineConnectorTest;
 import io.debezium.jdbc.JdbcConnection;
 import io.debezium.util.Testing;
 
 /**
  * @author Jiri Pechanec
  */
-public class MySqlRestartIT extends AbstractConnectorTest {
+public class MySqlRestartIT extends AbstractAsyncEngineConnectorTest {
     private static final Path SCHEMA_HISTORY_PATH = Testing.Files.createTestingPath("file-schema-history-restart.txt").toAbsolutePath();
     private final UniqueDatabase DATABASE = new UniqueDatabase("restart", "connector_test").withDbHistoryPath(SCHEMA_HISTORY_PATH);
 
@@ -91,6 +91,7 @@ public void shouldNotDuplicateEventsAfterRestart() throws Exception {
         assertThat(((Struct) ((SourceRecord) records.recordsForTopic(DATABASE.topicForTable("restart_table")).get(0)).value()).getStruct("after").getInt32("id"))
                 .isEqualTo(2);
 
+        waitForEngineShutdown();
         stopConnector();
 
         start(MySqlConnector.class, config);

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerChangeEventSourceCoordinator.java
Patch:
@@ -98,6 +98,9 @@ protected void executeChangeEventSources(CdcSourceTaskContext taskContext, Snaps
             initStreamEvents(entry.getKey(), entry.getValue());
         }
 
+        getSignalProcessor(previousOffsets).ifPresent(signalProcessor -> registerSignalActionsAndStartProcessor(signalProcessor,
+                eventDispatcher, this, connectorConfig));
+
         final Metronome metronome = Metronome.sleeper(pollInterval, clock);
 
         LOGGER.info("Starting streaming");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/NotificationsIT.java
Patch:
@@ -39,7 +39,7 @@ public void after() {
     }
 
     protected List<String> collections() {
-        return List.of("ORCLPDB1.DEBEZIUM.A");
+        return List.of(TestHelper.getDatabaseName() + ".DEBEZIUM.A");
     }
 
     @Override

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnection.java
Patch:
@@ -85,6 +85,7 @@ public OracleConnection(JdbcConfiguration config, ConnectionFactory connectionFa
 
     public OracleConnection(JdbcConfiguration config, ConnectionFactory connectionFactory, boolean showVersion) {
         super(config, connectionFactory, QUOTED_CHARACTER, QUOTED_CHARACTER);
+        LOGGER.trace("JDBC connection string: " + connectionString(config));
         this.databaseVersion = resolveOracleDatabaseVersion();
         if (showVersion) {
             LOGGER.info("Database Version: {}", databaseVersion.getBanner());
@@ -93,6 +94,7 @@ public OracleConnection(JdbcConfiguration config, ConnectionFactory connectionFa
 
     public OracleConnection(JdbcConfiguration config, boolean showVersion) {
         super(config, resolveConnectionFactory(config), QUOTED_CHARACTER, QUOTED_CHARACTER);
+        LOGGER.trace("JDBC connection string: " + connectionString(config));
         this.databaseVersion = resolveOracleDatabaseVersion();
         if (showVersion) {
             LOGGER.info("Database Version: {}", databaseVersion.getBanner());

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerEventRowTest.java
Patch:
@@ -195,15 +195,15 @@ public void testSqlRedo() throws Exception {
 
         row = LogMinerEventRow.fromResultSet(resultSet, CATALOG_NAME, true);
         assertThat(row.getRedoSql()).isNull();
-        verify(resultSet, times(13)).getInt(6);
+        verify(resultSet, times(14)).getInt(6);
         verify(resultSet, times(14)).getString(2);
 
         when(resultSet.getInt(6)).thenReturn(0);
         when(resultSet.getString(2)).thenThrow(SQLException.class);
 
         assertThrows(resultSet, SQLException.class);
 
-        verify(resultSet, times(13)).getInt(6);
+        verify(resultSet, times(15)).getInt(6);
         verify(resultSet, times(15)).getString(2);
     }
 

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -857,7 +857,7 @@ public static EventConvertingFailureHandlingMode parse(String value) {
     public static final Field SNAPSHOT_MODE_CUSTOM_NAME = Field.create("snapshot.mode.custom.name")
             .withDisplayName("Snapshot Mode Custom Name")
             .withType(Type.STRING)
-            .withGroup(Field.createGroupEntry(Field.Group.CONNECTOR_SNAPSHOT, 11))
+            .withGroup(Field.createGroupEntry(Field.Group.CONNECTOR_SNAPSHOT, 12))
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.MEDIUM)
             .withValidation((config, field, output) -> {

File: debezium-quarkus-outbox-common/deployment/src/main/java/io/debezium/outbox/quarkus/deployment/OutboxEventHbmWriter.java
Patch:
@@ -238,9 +238,7 @@ private static JaxbHbmBasicAttributeType createTracingSpanAttribute(DebeziumOutb
         column.setName(config.tracingSpan.name);
         column.setLength(256);
 
-        if (config.tracingSpan.columnDefinition.isPresent()) {
-            column.setSqlType(config.tracingSpan.columnDefinition.get());
-        }
+        config.tracingSpan.columnDefinition.ifPresent(column::setSqlType);
 
         attribute.getColumnOrFormula().add(column);
 

File: debezium-quarkus-outbox-reactive/integration-tests/src/test/java/io/debezium/outbox/reactive/quarkus/it/OutboxTest.java
Patch:
@@ -60,8 +60,8 @@ public void firedEventGetsPersistedInOutboxTable() {
         catch (JsonProcessingException e) {
             throw new RuntimeException(e);
         }
-        final Map row = (Map) sessionFactory.withSession(
-                session -> session.createQuery("FROM OutboxEvent").getSingleResult())
+        final Map row = sessionFactory.withSession(
+                session -> session.createSelectionQuery("FROM OutboxEvent", Map.class).getSingleResult())
                 .await().indefinitely();
         assertNotNull(row.get("id"));
         assertEquals(1L, row.get("aggregateId"));

File: debezium-quarkus-outbox-reactive/runtime/src/main/java/io/debezium/outbox/reactive/quarkus/internal/DebeziumOutboxHandler.java
Patch:
@@ -13,6 +13,7 @@
 import io.smallrye.mutiny.Uni;
 import io.vertx.core.eventbus.DeliveryOptions;
 import io.vertx.mutiny.core.eventbus.EventBus;
+import io.vertx.mutiny.core.eventbus.Message;
 
 @ApplicationScoped
 public class DebeziumOutboxHandler {
@@ -24,6 +25,6 @@ public class DebeziumOutboxHandler {
 
     public Uni<Object> persistToOutbox(ExportedEvent<?, ?> incomingEvent) {
         return bus.<Object> request("debezium-outbox", incomingEvent, options)
-                .onItem().transform(message -> message.body());
+                .onItem().transform(Message::body);
     }
 }

File: debezium-quarkus-outbox-reactive/runtime/src/main/java/io/debezium/outbox/reactive/quarkus/internal/DebeziumTracerEventDispatcher.java
Patch:
@@ -48,7 +48,7 @@ public class DebeziumTracerEventDispatcher extends AbstractEventDispatcher {
     @ConsumeEvent(value = "debezium-outbox", codec = DebeziumCustomCodec.class)
     public Uni<Void> onExportedEvent(Object incomingevent) {
         ExportedEvent<?, ?> event = (ExportedEvent<?, ?>) incomingevent;
-        LOGGER.debug("An exported event was found for type {}" + event.getType());
+        LOGGER.debug("An exported event was found for type {}", event.getType());
         final Tracer tracer = openTelemetry.getTracer(TRACING_COMPONENT);
         final SpanBuilder spanBuilder = tracer.spanBuilder(OPERATION_NAME);
         final DataMapTracingSetter exportedSpanData = DataMapTracingSetter.create();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlValueConverters.java
Patch:
@@ -163,7 +163,6 @@ public MySqlValueConverters(DecimalMode decimalMode, TemporalPrecisionMode tempo
         this(decimalMode, temporalPrecisionMode, bigIntUnsignedMode, binaryMode, adjuster, connectorAdapter, WARN);
     }
 
-
     private static ConnectorAdapter resolveDefaultAdapter() {
         Configuration config = Configuration.empty();
         MySqlConnectorConfig connectorConfig = new MySqlConnectorConfig(config);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDatabaseSchemaTest.java
Patch:
@@ -19,7 +19,6 @@
 import org.junit.Test;
 
 import io.debezium.config.CommonConnectorConfig.BinaryHandlingMode;
-import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import io.debezium.config.Configuration;
 import io.debezium.doc.FixFor;
 import io.debezium.jdbc.JdbcValueConverters.BigIntUnsignedMode;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlValueConvertersTest.java
Patch:
@@ -111,7 +111,7 @@ public void testJsonValues() {
     }
 
     @Test
-    @FixFor({"DBZ-2563", "DBZ-7143"})
+    @FixFor({ "DBZ-2563", "DBZ-7143" })
     public void testSkipInvalidJsonValues() {
         String sql = "CREATE TABLE JSON_TABLE (" + "    A JSON," + "    B JSON NOT NULL" + ");";
 
@@ -136,7 +136,7 @@ public void testSkipInvalidJsonValues() {
     }
 
     @Test(expected = DebeziumException.class)
-    @FixFor({"DBZ-2563", "DBZ-7143"})
+    @FixFor({ "DBZ-2563", "DBZ-7143" })
     public void testErrorOnInvalidJsonValues() {
         String sql = "CREATE TABLE JSON_TABLE (" + "    A JSON," + "    B JSON NOT NULL" + ");";
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlValueConverters.java
Patch:
@@ -336,6 +336,7 @@ public ValueConverter converter(Column column, Field fieldDefn) {
     protected Object handleUnknownData(Column column, Field fieldDefn, Object data) {
         Class<?> dataClass = data.getClass();
         String clazzName = dataClass.isArray() ? dataClass.getSimpleName() : dataClass.getName();
+        // exception will be handled in TableSchemaBuilder.createValueGenerator
         throw new IllegalArgumentException("Unexpected value for JDBC type " + column.jdbcType() + " and column " + column +
                 ": class=" + clazzName);
     }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorSchemaValidateIT.java
Patch:
@@ -13,12 +13,12 @@
 import java.util.List;
 import java.util.concurrent.atomic.AtomicReference;
 
-import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import org.apache.kafka.connect.source.SourceRecord;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mysql.MySqlConnectorConfig.SnapshotMode;
 import io.debezium.doc.FixFor;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDefaultValueTest.java
Patch:
@@ -17,13 +17,13 @@
 import java.util.Date;
 import java.util.Properties;
 
-import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
 import org.junit.Before;
 import org.junit.Test;
 
 import io.debezium.config.CommonConnectorConfig.BinaryHandlingMode;
+import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser;
 import io.debezium.doc.FixFor;
 import io.debezium.jdbc.JdbcValueConverters;

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectionIT.java
Patch:
@@ -20,13 +20,13 @@
 import java.util.Properties;
 import java.util.concurrent.TimeUnit;
 
-import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
 import org.awaitility.Awaitility;
 import org.junit.Before;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import io.debezium.connector.sqlserver.util.TestHelper;
 import io.debezium.doc.FixFor;
 import io.debezium.jdbc.JdbcValueConverters;
@@ -216,7 +216,7 @@ public void shouldProperlyGetDefaultColumnValues() throws Exception {
                     connection.getDefaultValueConverter(),
                     SchemaNameAdjuster.NO_OP, new CustomConverterRegistry(null), SchemaBuilder.struct().build(),
                     FieldNameSelector.defaultSelector(SchemaNameAdjuster.NO_OP), true,
-                    EventConvertingFailureHandlingMode.FAIL);
+                    EventConvertingFailureHandlingMode.WARN);
 
             assertColumnHasNotDefaultValue(table, "int_no_default_not_null");
             assertColumnHasDefaultValue(table, "int_no_default", null, tableSchemaBuilder);
@@ -388,7 +388,7 @@ public void shouldProperlyGetDefaultColumnNullValues() throws Exception {
                     connection.getDefaultValueConverter(),
                     SchemaNameAdjuster.NO_OP, new CustomConverterRegistry(null), SchemaBuilder.struct().build(),
                     FieldNameSelector.defaultSelector(SchemaNameAdjuster.NO_OP), true,
-                    EventConvertingFailureHandlingMode.FAIL);
+                    EventConvertingFailureHandlingMode.WARN);
 
             assertColumnHasNotDefaultValue(table, "int_no_default_not_null");
             assertColumnHasDefaultValue(table, "int_no_default", null, tableSchemaBuilder);

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -850,9 +850,9 @@ public static EventConvertingFailureHandlingMode parse(String value) {
             .withWidth(Width.SHORT)
             .withImportance(Importance.MEDIUM)
             .withDescription("Specify how failures during converting of event should be handled, including: "
-                + "'fail' throw an exception that the column of event conversion is failed with unmatched schema type, causing the connector to be stopped. it needs schema recovery to covert successfully; "
-                + "'warn' (the default) the value of column of event that conversion failed will be null and be logged with warn level; "
-                + "'skip' the value of column of event that conversion failed will be null and be logged with debug level.");
+                    + "'fail' throw an exception that the column of event conversion is failed with unmatched schema type, causing the connector to be stopped. it needs schema recovery to covert successfully; "
+                    + "'warn' (the default) the value of column of event that conversion failed will be null and be logged with warn level; "
+                    + "'skip' the value of column of event that conversion failed will be null and be logged with debug level.");
 
     protected static final ConfigDefinition CONFIG_DEFINITION = ConfigDefinition.editor()
             .connector(

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -12,7 +12,6 @@
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.stream.Collectors;
 
-import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import org.apache.kafka.connect.data.Field;
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
@@ -26,6 +25,7 @@
 import io.debezium.DebeziumException;
 import io.debezium.annotation.Immutable;
 import io.debezium.annotation.ThreadSafe;
+import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import io.debezium.data.Envelope;
 import io.debezium.data.SchemaUtil;
 import io.debezium.relational.Key.KeyMapper;
@@ -65,7 +65,6 @@ public class TableSchemaBuilder {
     private final boolean multiPartitionMode;
     private final EventConvertingFailureHandlingMode eventConvertingFailureHandlingMode;
 
-
     /**
      * Create a new instance of the builder.
      *

File: debezium-core/src/test/java/io/debezium/relational/TableSchemaBuilderTest.java
Patch:
@@ -14,7 +14,6 @@
 import java.util.Collections;
 import java.util.Properties;
 
-import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import org.apache.kafka.connect.data.Decimal;
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
@@ -23,6 +22,7 @@
 import org.junit.Before;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig.EventConvertingFailureHandlingMode;
 import io.debezium.config.Configuration;
 import io.debezium.data.VerifyRecord;
 import io.debezium.doc.FixFor;

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/DockerKafkaConnectController.java
Patch:
@@ -111,7 +111,7 @@ public HttpUrl getMetricsURL() {
     @Override
     public boolean undeploy() {
         container.stop();
-        return container.isRunning();
+        return !container.isRunning();
     }
 
     @Override

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/DockerKafkaController.java
Patch:
@@ -9,14 +9,15 @@
 import static java.util.concurrent.TimeUnit.MINUTES;
 import static org.awaitility.Awaitility.await;
 
-import lombok.Getter;
-import lombok.Setter;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import io.debezium.testing.system.tools.kafka.docker.KafkaContainer;
 import io.debezium.testing.system.tools.kafka.docker.ZookeeperContainer;
 
+import lombok.Getter;
+import lombok.Setter;
+
 /**
  * This class provides control over Kafka instance deployed as DockerContainer
  *

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/DockerKafkaDeployer.java
Patch:
@@ -34,7 +34,9 @@ public DockerKafkaController deploy() {
         container.withZookeeper(zookeeperContainer);
 
         Startables.deepStart(Stream.of(zookeeperContainer, container)).join();
-        return getController(container);
+        DockerKafkaController controller = getController(container);
+        controller.setZookeeperContainer(zookeeperContainer);
+        return controller;
     }
 
     public static class Builder

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/docker/KafkaContainer.java
Patch:
@@ -5,6 +5,7 @@
  */
 package io.debezium.testing.system.tools.kafka.docker;
 
+import java.time.Duration;
 import java.util.concurrent.atomic.AtomicInteger;
 
 import org.testcontainers.containers.GenericContainer;
@@ -13,6 +14,7 @@
 import com.github.dockerjava.api.command.InspectContainerResponse;
 
 import io.debezium.testing.system.tools.ConfigProperties;
+import io.debezium.testing.system.tools.WaitConditions;
 
 public class KafkaContainer extends GenericContainer<KafkaContainer> {
 
@@ -42,6 +44,7 @@ private void defaultConfig() {
         withEnv("KAFKA_ADVERTISED_LISTENERS", "PLAINTEXT://" + getPublicBootstrapAddress() + ",BROKER://" + getBootstrapAddress());
         withEnv("KAFKA_LISTENER_SECURITY_PROTOCOL_MAP", "BROKER:PLAINTEXT,PLAINTEXT:PLAINTEXT");
         withEnv("KAFKA_INTER_BROKER_LISTENER_NAME", "BROKER");
+        withStartupTimeout(Duration.ofMinutes(WaitConditions.scaled(1)));
     }
 
     public KafkaContainer withZookeeper(ZookeeperContainer zookeeper) {

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -673,9 +673,10 @@ else if (maxRetries < EmbeddedEngineConfig.DEFAULT_ERROR_MAX_RETRIES) {
                     startedSuccessfully = true;
                 }
                 catch (Exception ex) {
-                    if (totalRetries == maxRetries) {
+                    if (maxRetries > 0 && totalRetries >= maxRetries) {
                         LOGGER.error("Can't start the connector, max retries to connect exceeded; stopping connector...", ex);
                         retryError = ex;
+                        break;
                     }
                     else {
                         LOGGER.error("Can't start the connector, will retry later...", ex);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDecimalIT.java
Patch:
@@ -49,7 +49,7 @@ public void beforeEach() {
         DATABASE.createAndInitialize();
         initializeConnectorTestFramework();
         Testing.Files.delete(SCHEMA_HISTORY_PATH);
-        // TODO: remove once https://github.com/Apicurio/apicurio-registry/issues/2980 is fixed
+        // TODO: remove once we upgrade Apicurio version (DBZ-7357)
         if (VerifyRecord.isApucurioAvailable()) {
             skipAvroValidation();
         }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MysqlDefaultValueIT.java
Patch:
@@ -73,7 +73,7 @@ public void beforeEach() {
         DATABASE.createAndInitialize();
         initializeConnectorTestFramework();
         Testing.Files.delete(SCHEMA_HISTORY_PATH);
-        // TODO: remove once https://github.com/Apicurio/apicurio-registry/issues/2980 is fixed
+        // TODO: remove once we upgrade Apicurio version (DBZ-7357)
         if (VerifyRecord.isApucurioAvailable()) {
             skipAvroValidation();
         }
@@ -91,7 +91,7 @@ public void afterEach() {
 
     @Override
     protected void validate(SourceRecord record) {
-        // TODO: remove once https://github.com/Apicurio/apicurio-registry/issues/2980 is fixed
+        // TODO: remove once we upgrade Apicurio version (DBZ-7357)
         if (VerifyRecord.isApucurioAvailable()) {
             VerifyRecord.isValid(record, true);
         }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/IncrementalSnapshotCaseSensitiveIT.java
Patch:
@@ -197,7 +197,7 @@ protected String server() {
 
     @Test
     public void snapshotPreceededBySchemaChange() throws Exception {
-        // TODO: remove once https://github.com/Apicurio/apicurio-registry/issues/2980 is fixed
+        // TODO: remove once we upgrade Apicurio version (DBZ-7357)
         if (VerifyRecord.isApucurioAvailable()) {
             skipAvroValidation();
         }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/IncrementalSnapshotIT.java
Patch:
@@ -193,7 +193,7 @@ protected String server() {
 
     @Test
     public void snapshotPreceededBySchemaChange() throws Exception {
-        // TODO: remove once https://github.com/Apicurio/apicurio-registry/issues/2980 is fixed
+        // TODO: remove once we upgrade Apicurio version (DBZ-7357)
         if (VerifyRecord.isApucurioAvailable()) {
             skipAvroValidation();
         }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -1358,7 +1358,7 @@ public void shouldHandleIntervalTypesAsString() throws Exception {
     @Test
     @FixFor("DBZ-2624")
     public void shouldSnapshotAndStreamChangesFromTableWithNumericDefaultValues() throws Exception {
-        // TODO: remove once https://github.com/Apicurio/apicurio-registry/issues/2980 is fixed
+        // TODO: remove once we upgrade Apicurio version (DBZ-7357)
         if (VerifyRecord.isApucurioAvailable()) {
             skipAvroValidation();
         }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleDefaultValueIT.java
Patch:
@@ -70,7 +70,7 @@ public void after() throws Exception {
     @Test
     @FixFor("DBZ-3710")
     public void shouldHandleNumericDefaultTypes() throws Exception {
-        // TODO: remove once https://github.com/Apicurio/apicurio-registry/issues/2980 is fixed
+        // TODO: remove once we upgrade Apicurio version (DBZ-7357)
         if (VerifyRecord.isApucurioAvailable()) {
             skipAvroValidation();
         }
@@ -151,7 +151,7 @@ public void shouldHandleNumericDefaultTypes() throws Exception {
     @Test
     @FixFor("DBZ-3710")
     public void shouldHandleFloatPointDefaultTypes() throws Exception {
-        // TODO: remove once https://github.com/Apicurio/apicurio-registry/issues/2980 is fixed
+        // TODO: remove once we upgrade Apicurio version (DBZ-7357)
         if (VerifyRecord.isApucurioAvailable()) {
             skipAvroValidation();
         }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -1427,7 +1427,7 @@ public void abandonTransactions(Duration retention) throws InterruptedException
                                 if (first) {
                                     LOGGER.warn("All transactions with SCN <= {} will be abandoned.", thresholdScn);
                                     if (LOGGER.isDebugEnabled()) {
-                                        try (Stream s = getTransactionCache().keySet().stream()) {
+                                        try (Stream<String> s = getTransactionCache().keySet().stream()) {
                                             LOGGER.debug("List of transactions in the cache before transactions being abandoned: [{}]",
                                                     s.collect(Collectors.joining(",")));
                                         }
@@ -1452,7 +1452,7 @@ public void abandonTransactions(Duration retention) throws InterruptedException
                         }
                     }
                     if (LOGGER.isDebugEnabled()) {
-                        try (Stream s = getTransactionCache().keySet().stream()) {
+                        try (Stream<String> s = getTransactionCache().keySet().stream()) {
                             LOGGER.debug("List of transactions in the cache after transactions being abandoned: [{}]",
                                     s.collect(Collectors.joining(",")));
                         }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -1426,7 +1426,8 @@ public void abandonTransactions(Duration retention) throws InterruptedException
                             if (entry.getValue().getStartScn().compareTo(thresholdScn) <= 0) {
                                 if (first) {
                                     LOGGER.warn("All transactions with SCN <= {} will be abandoned.", thresholdScn);
-                                    LOGGER.debug("List of transactions in the cache before transactions being abandoned: [{}]", getTransactionCache().keySet().stream().collect(Collectors.joining(",")));
+                                    LOGGER.debug("List of transactions in the cache before transactions being abandoned: [{}]",
+                                            getTransactionCache().keySet().stream().collect(Collectors.joining(",")));
                                     first = false;
                                 }
                                 LOGGER.warn("Transaction {} (start SCN {}, change time {}, redo thread {}, {} events) is being abandoned.",

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbPartition.java
Patch:
@@ -49,7 +49,7 @@ public int hashCode() {
 
     @Override
     public String toString() {
-        return "ReplicaSetPartition [sourcePartition=" + getSourcePartition() + "]";
+        return "MongoDbPartition [sourcePartition=" + getSourcePartition() + "]";
     }
 
     public static class Provider implements Partition.Provider<MongoDbPartition> {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -771,8 +771,8 @@ public OracleConnectorConfig(Configuration config) {
         this.logMiningSleepTimeIncrement = Duration.ofMillis(config.getInteger(LOG_MINING_SLEEP_TIME_INCREMENT_MS));
         this.logMiningTransactionRetention = resolveLogMiningTransactionRetentionDuration(config);
         this.archiveLogOnlyMode = config.getBoolean(LOG_MINING_ARCHIVE_LOG_ONLY_MODE);
-        this.logMiningUsernameIncludes = Strings.setOf(config.getString(LOG_MINING_USERNAME_INCLUDE_LIST), String::new);
-        this.logMiningUsernameExcludes = Strings.setOf(config.getString(LOG_MINING_USERNAME_EXCLUDE_LIST), String::new);
+        this.logMiningUsernameIncludes = Strings.setOfTrimmed(config.getString(LOG_MINING_USERNAME_INCLUDE_LIST), String::new);
+        this.logMiningUsernameExcludes = Strings.setOfTrimmed(config.getString(LOG_MINING_USERNAME_EXCLUDE_LIST), String::new);
         this.logMiningArchiveDestinationName = config.getString(LOG_MINING_ARCHIVE_DESTINATION_NAME);
         this.logMiningBufferType = LogMiningBufferType.parse(config.getString(LOG_MINING_BUFFER_TYPE));
         this.logMiningBufferTransactionEventsThreshold = config.getLong(LOG_MINING_BUFFER_TRANSACTION_EVENTS_THRESHOLD);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/rest/DebeziumMySqlConnectorResourceIT.java
Patch:
@@ -217,7 +217,7 @@ public void testMetricsEndpoint() throws InterruptedException {
 
         RestExtensionTestInfrastructure.getDebeziumContainer().ensureConnectorState(connectorName, Connector.State.RUNNING);
         RestExtensionTestInfrastructure.waitForConnectorTaskStatus(connectorName, 0, Connector.State.RUNNING);
-        RestExtensionTestInfrastructure.waitForStreamingRunning("mysql", "dbserver1");
+        RestExtensionTestInfrastructure.getDebeziumContainer().waitForStreamingRunning("mysql", config.asProperties().getProperty("topic.prefix"));
 
         given()
                 .port(RestExtensionTestInfrastructure.getDebeziumContainer().getFirstMappedPort())
@@ -228,8 +228,8 @@ public void testMetricsEndpoint() throws InterruptedException {
                 .body("name", equalTo(connectorName))
                 .body("connector.metrics.Connected", equalTo("true"))
                 .body("tasks[0].id", equalTo(0))
-                .body("tasks[0].namespaces[0].metrics.MilliSecondsSinceLastEvent", equalTo("-1"))
-                .body("tasks[0].namespaces[0].metrics.TotalNumberOfEventsSeen", equalTo("0"));
+                .body("tasks[0].namespaces[0].metrics.MilliSecondsSinceLastEvent", equalTo("0"))
+                .body("tasks[0].namespaces[0].metrics.TotalNumberOfEventsSeen", equalTo("14234"));
     }
 
     public static ConnectorConfiguration getMySqlConnectorConfiguration(int id, String... options) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleDatabaseVersion.java
Patch:
@@ -15,9 +15,9 @@
  */
 public class OracleDatabaseVersion {
     private final static Pattern VERSION_PATTERN = Pattern
-            .compile("Oracle Database.*\\nVersion ([0-9]*)\\.([0-9]*)\\.([0-9]*)\\.([0-9]*)\\.([0-9]*)");
+            .compile("(?:.*)(?:Release )([0-9]+)\\.([0-9]+)\\.([0-9]+)\\.([0-9]+)\\.([0-9]+)(?:.*)");
     private final static Pattern VERSION_18_1_PATTERN = Pattern
-            .compile("(?:.*)(?:\\- Production(?:\\r\\n|\\r|\\n)(?:Version ))([0-9]+)\\.([0-9]+)\\.([0-9]+)\\.([0-9]+)\\.([0-9]+)");
+            .compile("^Oracle Database.*(?:\\r\\n|\\r|\\n)^(?:Version )([0-9]+)\\.([0-9]+)\\.([0-9]+)\\.([0-9]+)\\.([0-9]+)", Pattern.MULTILINE);
 
     private final int major;
     private final int maintenance;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSetDiscovery.java
Patch:
@@ -81,7 +81,7 @@ public ReplicaSets getReplicaSets(MongoClient client) {
             }
             else if (ConnectionMode.REPLICA_SET.equals(connectionMode)) {
                 LOGGER.info("ConnectionMode set to '{}, individual shard connections will be used", connectionMode.getValue());
-                readReplicaSetsFromShardedCluster(replicaSetSpecs, client, connectionContext);
+                readReplicaSetsFromShardedCluster(replicaSetSpecs, client);
             }
             else {
                 LOGGER.warn("Incompatible connection mode '{}' specified", connectionMode.getValue());
@@ -113,7 +113,7 @@ private void readReplicaSetsFromCluster(Set<ReplicaSet> replicaSetSpecs, Cluster
         replicaSetSpecs.add(new ReplicaSet(connectionString));
     }
 
-    private void readReplicaSetsFromShardedCluster(Set<ReplicaSet> replicaSetSpecs, MongoClient client, ConnectionContext connectionContext) {
+    public void readReplicaSetsFromShardedCluster(Set<ReplicaSet> replicaSetSpecs, MongoClient client) {
         try {
             var csParams = context.getConnectorConfig().getShardConnectionParameters();
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnection.java
Patch:
@@ -572,13 +572,14 @@ public NonRelationalTableException(String message) {
     @Override
     public String buildReselectColumnQuery(TableId tableId, List<String> columns, List<String> keyColumns, Struct source) {
         final String commitScn = source.getString(SourceInfo.COMMIT_SCN_KEY);
+        final TableId oracleTableId = new TableId(null, tableId.schema(), tableId.table());
         if (Strings.isNullOrEmpty(commitScn)) {
-            return super.buildReselectColumnQuery(tableId, columns, keyColumns, source);
+            return super.buildReselectColumnQuery(oracleTableId, columns, keyColumns, source);
         }
 
         return String.format("SELECT %s FROM (SELECT * FROM %s AS OF SCN %s) WHERE %s",
                 columns.stream().map(this::quotedColumnIdString).collect(Collectors.joining(",")),
-                quotedTableIdString(new TableId(null, tableId.schema(), tableId.table())),
+                quotedTableIdString(oracleTableId),
                 commitScn,
                 keyColumns.stream().map(key -> key + "=?").collect(Collectors.joining(" AND ")));
     }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -611,17 +611,17 @@ protected void handleRollbackNotFoundInBuffer(LogMinerEventRow row) {
     protected abstract T getAndRemoveTransactionFromCache(String transactionId);
 
     /**
-     * Removes the items associated with the transaction (e.g. events if they are stored independently.
+     * Removes the items associated with the transaction (e.g. events if they are stored independently).
      *
      * @param transaction the transaction instance, should never be {@code null}
      * @param isAbandoned whether the removal is because transaction is being abandoned
      */
     protected void cleanupAfterTransactionRemovedFromCache(T transaction, boolean isAbandoned) {
         if (isAbandoned) {
-            abandonedTransactionsCache.remove(transaction.getTransactionId());
+            abandonedTransactionsCache.add(transaction.getTransactionId());
         }
         else {
-            abandonedTransactionsCache.add(transaction.getTransactionId());
+            abandonedTransactionsCache.remove(transaction.getTransactionId());
         }
     }
 

File: debezium-core/src/main/java/io/debezium/converters/recordandmetadata/RecordAndMetadata.java
Patch:
@@ -19,8 +19,6 @@ public interface RecordAndMetadata {
 
     Struct record();
 
-    Schema dataSchema(String... dataFields);
-
     String id();
 
     String type();
@@ -32,4 +30,6 @@ public interface RecordAndMetadata {
     Struct transaction();
 
     SchemaAndValue timestamp();
+
+    Schema dataSchema(String... dataFields);
 }

File: debezium-core/src/main/java/io/debezium/converters/spi/CloudEventsMaker.java
Patch:
@@ -108,7 +108,7 @@ public String ceSpecversion() {
      * @return the type field of CloudEvents envelope
      */
     public String ceType() {
-        return "io.debezium." + recordParser.connectorType() + ".datachangeevent";
+        return "io.debezium.connector." + recordParser.connectorType() + ".DataChangeEvent";
     }
 
     /**

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -180,7 +180,8 @@ protected DataTypeResolver initializeDataTypeResolver() {
                 new DataTypeEntry(Types.NUMERIC, MySqlParser.NUMERIC)
                         .setSuffixTokens(MySqlParser.SIGNED, MySqlParser.UNSIGNED, MySqlParser.ZEROFILL)
                         .setDefaultLengthScaleDimension(10, 0),
-                new DataTypeEntry(Types.BIT, MySqlParser.BIT),
+                new DataTypeEntry(Types.BIT, MySqlParser.BIT)
+                        .setDefaultLengthDimension(1),
                 new DataTypeEntry(Types.TIME, MySqlParser.TIME),
                 new DataTypeEntry(Types.TIMESTAMP_WITH_TIMEZONE, MySqlParser.TIMESTAMP),
                 new DataTypeEntry(Types.TIMESTAMP, MySqlParser.DATETIME),

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcChangeEventSink.java
Patch:
@@ -15,7 +15,6 @@
 import java.util.Optional;
 import java.util.Set;
 
-import io.debezium.util.Stopwatch;
 import org.apache.kafka.connect.errors.ConnectException;
 import org.apache.kafka.connect.errors.DataException;
 import org.apache.kafka.connect.sink.SinkRecord;
@@ -32,6 +31,7 @@
 import io.debezium.connector.jdbc.relational.TableDescriptor;
 import io.debezium.connector.jdbc.relational.TableId;
 import io.debezium.pipeline.sink.spi.ChangeEventSink;
+import io.debezium.util.Stopwatch;
 import io.debezium.util.Strings;
 
 /**

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcSinkConnectorTask.java
Patch:
@@ -11,7 +11,6 @@
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.concurrent.locks.ReentrantLock;
 
-import io.debezium.util.Stopwatch;
 import org.apache.kafka.clients.consumer.OffsetAndMetadata;
 import org.apache.kafka.common.TopicPartition;
 import org.apache.kafka.connect.errors.ConnectException;
@@ -26,6 +25,7 @@
 import io.debezium.connector.jdbc.dialect.DatabaseDialect;
 import io.debezium.connector.jdbc.dialect.DatabaseDialectResolver;
 import io.debezium.pipeline.sink.spi.ChangeEventSink;
+import io.debezium.util.Stopwatch;
 import io.debezium.util.Strings;
 
 /**

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/RecordWriter.java
Patch:
@@ -11,16 +11,16 @@
 import java.util.List;
 import java.util.Objects;
 
-import io.debezium.util.Stopwatch;
 import org.apache.kafka.connect.data.Struct;
 import org.hibernate.SharedSessionContract;
 import org.hibernate.Transaction;
 import org.hibernate.jdbc.Work;
-
-import io.debezium.connector.jdbc.dialect.DatabaseDialect;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import io.debezium.connector.jdbc.dialect.DatabaseDialect;
+import io.debezium.util.Stopwatch;
+
 /**
  * Effectively writes the batches using Hibernate {@link Work}
  *

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresChangeRecordEmitter.java
Patch:
@@ -181,7 +181,7 @@ private Object[] columnValues(List<ReplicationMessage.Column> columns, TableId t
                     cachedOldToastedValues.put(columnName, value);
                 }
                 else {
-                    if (value == UnchangedToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE) {
+                    if (UnchangedToastedReplicationMessageColumn.isUnchangedToastedValue(value)) {
                         final Object candidate = cachedOldToastedValues.get(columnName);
                         if (candidate != null) {
                             value = candidate;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -104,7 +104,6 @@ public abstract class AbstractLogMinerEventProcessor<T extends AbstractTransacti
     private Scn lastProcessedScn = Scn.NULL;
     private boolean sequenceUnavailable = false;
 
-
     private final Set<String> abandonedTransactionsCache = new HashSet<>();
 
     public AbstractLogMinerEventProcessor(ChangeEventSourceContext context,
@@ -135,7 +134,6 @@ protected Set<String> getAbandonedTransactionsCache() {
         return abandonedTransactionsCache;
     }
 
-
     protected OracleConnectorConfig getConfig() {
         return connectorConfig;
     }
@@ -621,7 +619,8 @@ protected void handleRollbackNotFoundInBuffer(LogMinerEventRow row) {
     protected void cleanupAfterTransactionRemovedFromCache(T transaction, boolean isAbandoned) {
         if (isAbandoned) {
             abandonedTransactionsCache.remove(transaction.getTransactionId());
-        } else {
+        }
+        else {
             abandonedTransactionsCache.add(transaction.getTransactionId());
         }
     }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/LogMinerEventProcessor.java
Patch:
@@ -7,7 +7,6 @@
 
 import java.sql.SQLException;
 import java.time.Duration;
-import java.util.Set;
 
 import io.debezium.connector.oracle.Scn;
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/LogMinerEventProcessor.java
Patch:
@@ -33,5 +33,4 @@ public interface LogMinerEventProcessor extends AutoCloseable {
      */
     void abandonTransactions(Duration retention) throws InterruptedException;
 
-    Set<String> getAbandonedTransactionsCache();
 }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/LogMinerEventProcessor.java
Patch:
@@ -7,6 +7,7 @@
 
 import java.sql.SQLException;
 import java.time.Duration;
+import java.util.Set;
 
 import io.debezium.connector.oracle.Scn;
 
@@ -31,4 +32,6 @@ public interface LogMinerEventProcessor extends AutoCloseable {
      * @param retention the maximum duration in which long running transactions are allowed.
      */
     void abandonTransactions(Duration retention) throws InterruptedException;
+
+    Set<String> getAbandonedTransactionsCache();
 }

File: debezium-core/src/main/java/io/debezium/transforms/outbox/EventRouterDelegate.java
Patch:
@@ -188,8 +188,9 @@ public R apply(R r, RecordConverter<R> recordConverter) {
         AtomicReference<Integer> partition = new AtomicReference<>();
 
         additionalFields.forEach((additionalField -> {
-            if (!additionalFieldsErrorOnMissing && eventStruct.schema().field(additionalField.getField()) == null)
+            if (!additionalFieldsErrorOnMissing && eventStruct.schema().field(additionalField.getField()) == null) {
                 return;
+            }
             switch (additionalField.getPlacement()) {
                 case ENVELOPE:
                     structValue.put(

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/NotificationsIT.java
Patch:
@@ -39,7 +39,7 @@ public void after() {
     }
 
     protected List<String> collections() {
-        return List.of("a");
+        return List.of("A");
     }
 
     @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/rest/DebeziumMySqlConnectorResource.java
Patch:
@@ -22,9 +22,9 @@
 import io.debezium.DebeziumException;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mysql.Module;
-import io.debezium.connector.mysql.MySqlConnection;
 import io.debezium.connector.mysql.MySqlConnector;
 import io.debezium.connector.mysql.MySqlConnectorConfig;
+import io.debezium.connector.mysql.strategy.AbstractConnectorConnection;
 import io.debezium.relational.TableId;
 import io.debezium.rest.ConnectionValidationResource;
 import io.debezium.rest.FilterValidationResource;
@@ -56,8 +56,7 @@ public Connector getConnector() {
     @Override
     public List<DataCollection> getMatchingCollections(Configuration configuration) {
         final MySqlConnectorConfig config = new MySqlConnectorConfig(configuration);
-        final MySqlConnection.MySqlConnectionConfiguration connectionConfig = new MySqlConnection.MySqlConnectionConfiguration(configuration);
-        try (MySqlConnection connection = new MySqlConnection(connectionConfig)) {
+        try (AbstractConnectorConnection connection = config.getConnectorAdapter().createConnection(configuration)) {
             Set<TableId> tables;
 
             final List<String> databaseNames = new ArrayList<>();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlOffsetContext.java
Patch:
@@ -62,7 +62,6 @@ public MySqlOffsetContext(boolean snapshot, boolean snapshotCompleted, Transacti
     public MySqlOffsetContext(MySqlConnectorConfig connectorConfig, boolean snapshot, boolean snapshotCompleted, SourceInfo sourceInfo) {
         this(snapshot, snapshotCompleted, new TransactionContext(),
                 connectorConfig.getConnectorAdapter().getIncrementalSnapshotContext(),
-                // connectorConfig.isReadOnlyConnection() ? new MySqlReadOnlyIncrementalSnapshotContext<>() : new SignalBasedIncrementalSnapshotContext<>(),
                 sourceInfo);
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/strategy/mariadb/MariaDbConnection.java
Patch:
@@ -63,7 +63,9 @@ public GtidSet subtractGtidSet(GtidSet set1, GtidSet set2) {
 
     @Override
     public GtidSet purgedGtidSet() {
-        // todo: have an open question to the MariaDB community on this to understand can this be deduced
+        // The MariaDB community mentioned we could get the purged GTID values from the GTID_LIST_EVENT; however,
+        // this value is only available after we connect and would require a temporary binlog connection to get
+        // the data, so for now simply returning an empty set until we split the code base.
         return new MariaDbGtidSet("");
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/strategy/mariadb/MariaDbReadOnlyIncrementalSnapshotContext.java
Patch:
@@ -116,9 +116,7 @@ public void closeWindow() {
     }
 
     private MariaDbStreamSet getStreamSetForGtid(MariaDbGtid currentGtid) {
-        return highWatermark.isKnown(currentGtid)
-                ? highWatermark.forGtidStream(currentGtid)
-                : lowWatermark.forGtidStream(currentGtid);
+        return highWatermark.isEmpty() ? lowWatermark.forGtidStream(currentGtid) : highWatermark.forGtidStream(currentGtid);
     }
 
     public boolean serverStreamSetChanged() {

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/rest/DebeziumMongoDbConnectRestExtension.java
Patch:
@@ -14,8 +14,6 @@
 /**
  * A Kafka Connect REST extension that enables some advanced features over
  * Kafka Connect's REST interface:
- *   + report available transformations and their configuration
- *   + return if topic auto-creation is available and enabled
  *
  * To install this extension put the jar file into a separate Kafka Connect
  * plugin dir and configure your Kafka Connect properties file with:

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/rest/DebeziumMySqlConnectRestExtension.java
Patch:
@@ -13,9 +13,7 @@
 
 /**
  * A Kafka Connect REST extension that enables some advanced features over
- * Kafka Connect's REST interface:
- *   + report available transformations and their configuration
- *   + return if topic auto-creation is available and enabled
+ * Kafka Connect's REST interface.
  *
  * To install this extension put the jar file into a separate Kafka Connect
  * plugin dir and configure your Kafka Connect properties file with:

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/rest/DebeziumOracleConnectRestExtension.java
Patch:
@@ -13,9 +13,7 @@
 
 /**
  * A Kafka Connect REST extension that enables some advanced features over
- * Kafka Connect's REST interface:
- *   + report available transformations and their configuration
- *   + return if topic auto-creation is available and enabled
+ * Kafka Connect's REST interface.
  *
  * To install this extension put the jar file into a separate Kafka Connect
  * plugin dir and configure your Kafka Connect properties file with:

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -1174,7 +1174,7 @@ private static class SystemTablesPredicate implements TableFilter {
         protected static final List<String> SYSTEM_SCHEMAS = Arrays.asList("pg_catalog", "information_schema");
         // these are tables that may be placed in the user's schema but are system tables. This typically includes modules
         // that install system tables such as the GEO module
-        protected static final List<String> SYSTEM_TABLES = Arrays.asList("spatial_ref_sys");
+        protected static final List<String> SYSTEM_TABLES = List.of("spatial_ref_sys");
         protected static final String TEMP_TABLE_SCHEMA_PREFIX = "pg_temp";
 
         @Override

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/rest/DebeziumPostgresConnectRestExtension.java
Patch:
@@ -13,9 +13,7 @@
 
 /**
  * A Kafka Connect REST extension that enables some advanced features over
- * Kafka Connect's REST interface:
- *   + report available transformations and their configuration
- *   + return if topic auto-creation is available and enabled
+ * Kafka Connect's REST interface.
  *
  * To install this extension put the jar file into a separate Kafka Connect
  * plugin dir and configure your Kafka Connect properties file with:

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/rest/DebeziumSqlServerConnectRestExtension.java
Patch:
@@ -13,9 +13,7 @@
 
 /**
  * A Kafka Connect REST extension that enables some advanced features over
- * Kafka Connect's REST interface:
- *   + report available transformations and their configuration
- *   + return if topic auto-creation is available and enabled
+ * Kafka Connect's REST interface.
  *
  * To install this extension put the jar file into a separate Kafka Connect
  * plugin dir and configure your Kafka Connect properties file with:

File: debezium-core/src/main/java/io/debezium/rest/ConnectionValidationResource.java
Patch:
@@ -12,7 +12,7 @@
 
 import org.apache.kafka.connect.connector.Connector;
 
-import io.debezium.config.ValidationResults;
+import io.debezium.rest.model.ValidationResults;
 
 public interface ConnectionValidationResource {
 
@@ -24,10 +24,9 @@ public interface ConnectionValidationResource {
     @Path(VALIDATE_CONNECTION_ENDPOINT)
     default ValidationResults validateConnectionProperties(Map<String, ?> properties) {
         // switch classloader to the connector specific classloader in order to load dependencies required to validate the connector config
-        ValidationResults validationResults;
         ClassLoader originalClassLoader = Thread.currentThread().getContextClassLoader();
         Thread.currentThread().setContextClassLoader(getConnector().getClass().getClassLoader());
-        validationResults = new ValidationResults(getConnector(), properties);
+        ValidationResults validationResults = ConnectorConfigValidator.validateConfig(getConnector(), properties);
         Thread.currentThread().setContextClassLoader(originalClassLoader);
         return validationResults;
     }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/infinispan/AbstractInfinispanLogMinerEventProcessor.java
Patch:
@@ -139,7 +139,7 @@ protected void removeEventWithRowId(LogMinerEventRow row) {
                     if (event != null && event.getRowId().equals(row.getRowId())) {
                         Loggings.logDebugAndTraceRecord(LOGGER, row, "Undo change on table '{}' applied to transaction '{}'", row.getTableId(), eventKey);
                         getEventCache().remove(eventKey);
-                        inMemoryPendingTransactionsCache.remove(row.getTransactionId());
+                        inMemoryPendingTransactionsCache.decrement(row.getTransactionId());
                         return;
                     }
                 }
@@ -160,7 +160,7 @@ else if (!getConfig().isLobEnabled()) {
                 if (event != null && event.getRowId().equals(row.getRowId())) {
                     LOGGER.debug("Undo applied for event {}.", event);
                     getEventCache().remove(eventKey);
-                    inMemoryPendingTransactionsCache.remove(row.getTransactionId());
+                    inMemoryPendingTransactionsCache.decrement(row.getTransactionId());
                     return;
                 }
             }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/transforms/ExtractNewDocumentState.java
Patch:
@@ -178,9 +178,9 @@ public R doApply(R record) {
         BsonDocument keyDocument = BsonDocument.parse("{ \"id\" : " + keyRecord.key().toString() + "}");
         BsonDocument valueDocument = new BsonDocument();
 
-        // Tombstone message
+        // Handling tombstone record
         if (record.value() == null) {
-            R newRecord = extractRecordStrategy.handleTruncateRecord(record);
+            R newRecord = extractRecordStrategy.handleTombstoneRecord(record);
             if (newRecord == null) {
                 return null;
             }

File: debezium-core/src/main/java/io/debezium/transforms/AbstractExtractNewRecordState.java
Patch:
@@ -100,7 +100,7 @@ public void configure(final Map<String, ?> configs) {
             extractRecordStrategy = new LegacyDeleteHandlingStrategy<>(handleDeletes, dropTombstones);
             LOGGER.warn(
                     "The deleted record handling configs \"drop.tombstones\" and \"delete.handling.mode\" have been deprecated, " +
-                            "please use \"delete.tombstone.handling.mode\" instead of.");
+                            "please use \"delete.tombstone.handling.mode\" instead.");
         }
     }
 

File: debezium-core/src/main/java/io/debezium/transforms/ExtractNewRecordState.java
Patch:
@@ -110,17 +110,17 @@ public R doApply(final R record) {
 
         // Handling tombstone record
         if (record.value() == null) {
-            return extractRecordStrategy.handleTruncateRecord(record);
+            return extractRecordStrategy.handleTombstoneRecord(record);
         }
 
         if (!smtManager.isValidEnvelope(record)) {
             return record;
         }
 
         R newRecord = extractRecordStrategy.afterDelegate().apply(record);
+        // Handling truncate record
         if (newRecord.value() == null && extractRecordStrategy.beforeDelegate().apply(record).value() == null) {
-            LOGGER.trace("Truncate event arrived and requested to be dropped");
-            return null;
+            return extractRecordStrategy.handleTruncateRecord(record);
         }
 
         if (newRecord.value() == null) {

File: debezium-core/src/main/java/io/debezium/transforms/ExtractNewRecordStateConfigDefinition.java
Patch:
@@ -16,6 +16,7 @@ public class ExtractNewRecordStateConfigDefinition {
     public static final String DELETED_FIELD = "__deleted";
     public static final String METADATA_FIELD_PREFIX = "__";
 
+    @Deprecated
     public enum DeleteHandling implements EnumeratedValue {
         DROP("drop"),
         REWRITE("rewrite"),

File: debezium-core/src/main/java/io/debezium/transforms/extractnewstate/ExtractRecordStrategy.java
Patch:
@@ -21,6 +21,8 @@ public interface ExtractRecordStrategy<R extends ConnectRecord<R>> {
 
     R handleTruncateRecord(R record);
 
+    R handleTombstoneRecord(R record);
+
     R handleDeleteRecord(R record);
 
     R handleRecord(R record);

File: debezium-core/src/main/java/io/debezium/transforms/extractnewstate/LegacyDeleteHandlingStrategy.java
Patch:
@@ -31,7 +31,7 @@ public LegacyDeleteHandlingStrategy(DeleteHandling deleteHandling, boolean dropT
     }
 
     @Override
-    public R handleTruncateRecord(R record) {
+    public R handleTombstoneRecord(R record) {
         if (dropTombstones) {
             LOGGER.trace("Tombstone {} arrived and requested to be dropped", record.key());
             return null;
@@ -54,6 +54,7 @@ public R handleDeleteRecord(R record) {
             case REWRITE:
                 LOGGER.trace("Delete message {} requested to be rewritten", record.key());
                 R oldRecord = beforeDelegate.apply(record);
+                // need to add the rewrite "__deleted" field manually since mongodb's value is a string type
                 if (oldRecord.value() instanceof Struct) {
                     return removedDelegate.apply(oldRecord);
                 }
@@ -68,6 +69,7 @@ public R handleRecord(R record) {
         R newRecord = afterDelegate.apply(record);
         if (deleteHandling == DeleteHandling.REWRITE) {
             LOGGER.trace("Insert/update message {} requested to be rewritten", record.key());
+            // need to add the rewrite "__deleted" field manually since mongodb's value is a string type
             if (newRecord.value() instanceof Struct) {
                 return updatedDelegate.apply(newRecord);
             }

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/ExtractNewDocumentStateTestIT.java
Patch:
@@ -20,7 +20,6 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
-import io.debezium.config.CommonConnectorConfig;
 import org.apache.kafka.connect.data.Field;
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
@@ -37,6 +36,7 @@
 import com.mongodb.client.model.ChangeStreamPreAndPostImagesOptions;
 import com.mongodb.client.model.CreateCollectionOptions;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mongodb.Module;
 import io.debezium.connector.mongodb.MongoDbConnectorConfig;
@@ -2006,7 +2006,6 @@ public void shouldGenerateRecordForDeleteEventsDeleteHandlingRewrite() throws In
         assertThat(value.get("__deleted")).isEqualTo(true);
     }
 
-
     @Test
     @FixFor("DBZ-6809")
     public void testConnectorAndTransformAvroFieldNameAdjustment() throws InterruptedException, IOException {

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/NativeQueryBinder.java
Patch:
@@ -9,7 +9,6 @@
 import java.time.ZoneOffset;
 import java.time.ZonedDateTime;
 
-import org.hibernate.query.BindableType;
 import org.hibernate.query.NativeQuery;
 import org.hibernate.type.StandardBasicTypes;
 
@@ -26,7 +25,7 @@ public void bind(ValueBindDescriptor valueBindDescriptor) {
 
         if (valueBindDescriptor.getTargetSqlType() != null) {
             binder.setParameter(valueBindDescriptor.getIndex(), ZonedDateTime.ofInstant(Instant.now(), ZoneOffset.UTC),
-                    (BindableType) StandardBasicTypes.ZONED_DATE_TIME_WITH_TIMEZONE);
+                    StandardBasicTypes.ZONED_DATE_TIME_WITH_TIMEZONE);
         }
         else {
             binder.setParameter(valueBindDescriptor.getIndex(), valueBindDescriptor.getValue());

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/oracle/OracleDatabaseDialect.java
Patch:
@@ -74,6 +74,8 @@ protected void registerTypes() {
 
         registerType(NumberType.INSTANCE);
         registerType(BytesType.INSTANCE);
+        registerType(ZonedTimestampType.INSTANCE);
+        registerType(ZonedTimeType.INSTANCE);
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/AbstractTimeType.java
Patch:
@@ -42,5 +42,4 @@ protected int getTimePrecision(Schema schema) {
         final Optional<String> scale = getSourceColumnPrecision(schema);
         return scale.map(Integer::parseInt).orElseGet(() -> Integer.parseInt(length));
     }
-
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/connect/ConnectDateType.java
Patch:
@@ -43,7 +43,7 @@ public List<ValueBindDescriptor> bind(int index, Schema schema, Object value) {
             return List.of(new ValueBindDescriptor(index, null));
         }
         if (value instanceof java.util.Date) {
-            return List.of(new ValueBindDescriptor(index, getDialect().convertToCorrectDate(DateTimeUtils.toLocalDateFromDate((java.util.Date) value))));
+            return List.of(new ValueBindDescriptor(index, DateTimeUtils.toLocalDateFromDate((java.util.Date) value)));
         }
 
         throw new ConnectException(String.format("Unexpected %s value '%s' with type '%s'", getClass().getSimpleName(),

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/connect/ConnectTimestampType.java
Patch:
@@ -49,8 +49,8 @@ public List<ValueBindDescriptor> bind(int index, Schema schema, Object value) {
             final LocalDateTime localDateTime = DateTimeUtils.toLocalDateTimeFromDate((java.util.Date) value);
             if (getDialect().isTimeZoneSet()) {
                 return List.of(new ValueBindDescriptor(index,
-                        getDialect().convertToCorrectTimestamp(localDateTime.atZone(getDatabaseTimeZone().toZoneId())),
-                        getDialect().getTimestampType().orElse(null)));
+                        localDateTime.atZone(getDatabaseTimeZone().toZoneId()).toLocalDateTime(),
+                        getJdbcType()));
             }
             return List.of(new ValueBindDescriptor(index, localDateTime));
         }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/AbstractDebeziumTimestampType.java
Patch:
@@ -33,11 +33,11 @@ public List<ValueBindDescriptor> bind(int index, Schema schema, Object value) {
 
             if (getDialect().isTimeZoneSet()) {
                 return List.of(new ValueBindDescriptor(index,
-                        getDialect().convertToCorrectTimestamp(localDateTime.atZone(getDatabaseTimeZone().toZoneId())),
-                        getDialect().getTimestampType().orElse(null)));
+                        localDateTime.atZone(getDatabaseTimeZone().toZoneId()).toLocalDateTime(),
+                        getJdbcType()));
             }
 
-            return List.of(new ValueBindDescriptor(index, localDateTime));
+            return List.of(new ValueBindDescriptor(index, localDateTime, getJdbcType()));
         }
 
         throw new ConnectException(String.format("Unexpected %s value '%s' with type '%s'", getClass().getSimpleName(),

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/DateType.java
Patch:
@@ -43,7 +43,7 @@ public List<ValueBindDescriptor> bind(int index, Schema schema, Object value) {
             return List.of(new ValueBindDescriptor(index, null));
         }
         if (value instanceof Number) {
-            return List.of(new ValueBindDescriptor(index, getDialect().convertToCorrectDate(DateTimeUtils.toLocalDateOfEpochDays(((Number) value).longValue()))));
+            return List.of(new ValueBindDescriptor(index, DateTimeUtils.toLocalDateOfEpochDays(((Number) value).longValue())));
         }
 
         throw new ConnectException(String.format("Unexpected %s value '%s' with type '%s'", getClass().getSimpleName(),

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/ZonedTimestampType.java
Patch:
@@ -47,7 +47,7 @@ public List<ValueBindDescriptor> bind(int index, Schema schema, Object value) {
 
             final ZonedDateTime zdt = ZonedDateTime.parse((String) value, ZonedTimestamp.FORMATTER).withZoneSameInstant(getDatabaseTimeZone().toZoneId());
 
-            return List.of(new ValueBindDescriptor(index, getDialect().convertToCorrectZonedTimestamp(zdt), getDialect().getZonedTimestampType().orElse(null)));
+            return List.of(new ValueBindDescriptor(index, zdt.toOffsetDateTime(), getJdbcType()));
         }
 
         throw new ConnectException(String.format("Unexpected %s value '%s' with type '%s'", getClass().getSimpleName(),

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/PostgresDatabaseDialect.java
Patch:
@@ -224,11 +224,11 @@ public Temporal convertToCorrectDateTime(ZonedDateTime zonedTime) {
         //
         // When a timestamp with time zone value is output, it is always converted from UTC to the current timezone zone, and displayed as local time in that zone.
         // https://www.postgresql.org/docs/current/datatype-datetime.html
-        return zonedTime.toLocalDateTime();
+        return zonedTime.toOffsetDateTime();
     }
 
     @Override
     public Optional<Integer> getTimestampType() {
-        return Optional.of(Types.TIMESTAMP);
+        return Optional.of(Types.TIMESTAMP_WITH_TIMEZONE);
     }
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/connect/ConnectDateType.java
Patch:
@@ -43,7 +43,7 @@ public List<ValueBindDescriptor> bind(int index, Schema schema, Object value) {
             return List.of(new ValueBindDescriptor(index, null));
         }
         if (value instanceof java.util.Date) {
-            return List.of(new ValueBindDescriptor(index, DateTimeUtils.toLocalDateFromDate((java.util.Date) value))); // TODO add a get Date as for getFormattedDate
+            return List.of(new ValueBindDescriptor(index, getDialect().convertToCorrectDate(DateTimeUtils.toLocalDateFromDate((java.util.Date) value))));
         }
 
         throw new ConnectException(String.format("Unexpected %s value '%s' with type '%s'", getClass().getSimpleName(),

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/DateType.java
Patch:
@@ -43,7 +43,7 @@ public List<ValueBindDescriptor> bind(int index, Schema schema, Object value) {
             return List.of(new ValueBindDescriptor(index, null));
         }
         if (value instanceof Number) {
-            return List.of(new ValueBindDescriptor(index, DateTimeUtils.toLocalDateOfEpochDays(((Number) value).longValue())));
+            return List.of(new ValueBindDescriptor(index, getDialect().convertToCorrectDate(DateTimeUtils.toLocalDateOfEpochDays(((Number) value).longValue()))));
         }
 
         throw new ConnectException(String.format("Unexpected %s value '%s' with type '%s'", getClass().getSimpleName(),

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/ZonedTimeType.java
Patch:
@@ -77,10 +77,8 @@ public List<ValueBindDescriptor> bind(int index, Schema schema, Object value) {
                     return List.of(new ValueBindDescriptor(index, getDialect().convertToCorrectDateTime(zdt.withZoneSameInstant(getDatabaseTimeZone().toZoneId()))));
                 }
                 // TODO check if this works with PreparedStatement
-                if (getDialect().getTimestampType().isPresent()) {
 
-                    return List.of(new ValueBindDescriptor(index, getDialect().convertToCorrectDateTime(zdt), getDialect().getTimestampType().get()));
-                }
+                return List.of(new ValueBindDescriptor(index, getDialect().convertToCorrectDateTime(zdt), getDialect().getTimestampType().orElse(null)));
             }
             return List.of(new ValueBindDescriptor(index, getDialect().convertToCorrectDateTime(zdt)));
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/ZonedTimeType.java
Patch:
@@ -75,8 +75,7 @@ public List<ValueBindDescriptor> bind(int index, Schema schema, Object value) {
                     return List.of(new ValueBindDescriptor(index, zdt.withZoneSameInstant(getDatabaseTimeZone().toZoneId())));
                 }
                 // TODO check if this works with PreparedStatement
-                return List
-                        .of(new ValueBindDescriptor(index, zdt.withZoneSameInstant(getDatabaseTimeZone().toZoneId()), StandardBasicTypes.ZONED_DATE_TIME_WITH_TIMEZONE));
+                return List.of(new ValueBindDescriptor(index, zdt, StandardBasicTypes.ZONED_DATE_TIME_WITH_TIMEZONE));
             }
             return List.of(new ValueBindDescriptor(index, zdt));
         }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/TransactionCommitConsumerIT.java
Patch:
@@ -117,7 +117,7 @@ public void testShouldNotConsolidateEventsWhenTableHasNoLobColumns() throws Exce
             for (int i = 0, k = 0; i < emails.size(); i += 4, k++) {
                 VerifyRecord.isValidUpdate(emails.get(i), "ID", -1);
                 VerifyRecord.isValidInsert(emails.get(i + 1), "ID", k);
-                VerifyRecord.isValidUpdate(emails.get(i + 2), "ID", 0);
+                VerifyRecord.isValidUpdate(emails.get(i + 2), "ID", k);
                 VerifyRecord.isValidUpdate(emails.get(i + 3), "ID", -1);
             }
 

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/TransactionCommitConsumerIT.java
Patch:
@@ -5,6 +5,8 @@
  */
 package io.debezium.connector.oracle.logminer;
 
+import static org.assertj.core.api.Assertions.assertThat;
+
 import java.sql.SQLException;
 import java.util.List;
 
@@ -22,8 +24,6 @@
 import io.debezium.doc.FixFor;
 import io.debezium.embedded.AbstractConnectorTest;
 
-import static org.assertj.core.api.Assertions.assertThat;
-
 /**
  * @author Chris Cranford
  */

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlTestConnection.java
Patch:
@@ -139,7 +139,7 @@ private static JdbcConfiguration addDefaultSettings(JdbcConfiguration configurat
 
     }
 
-    protected static ConnectionFactory FACTORY = JdbcConnection.patternBasedFactory("jdbc:mysql://${hostname}:${port}/${dbname}");
+    protected static ConnectionFactory FACTORY = JdbcConnection.patternBasedFactory("${protocol}://${hostname}:${port}/${dbname}");
 
     /**
      * Create a new instance with the given configuration and connection factory.

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/integration/AbstractJdbcSinkSaveConvertedCloudEventTest.java
Patch:
@@ -25,7 +25,7 @@
 import io.debezium.connector.jdbc.junit.TestHelper;
 import io.debezium.connector.jdbc.junit.jupiter.Sink;
 import io.debezium.connector.jdbc.junit.jupiter.SinkRecordFactoryArgumentsProvider;
-import io.debezium.connector.jdbc.transform.ConvertCloudEventToSaveableForm;
+import io.debezium.connector.jdbc.transforms.ConvertCloudEventToSaveableForm;
 import io.debezium.connector.jdbc.util.SinkRecordFactory;
 
 /**

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSetDiscovery.java
Patch:
@@ -103,7 +103,7 @@ else if (ConnectionMode.REPLICA_SET.equals(connectionMode)) {
     private void readShardedClusterAsReplicaSet(Set<ReplicaSet> replicaSetSpecs, ConnectionContext connectionContext) {
         LOGGER.info("Using '{}' as sharded cluster connection", maskedConnectionSeed);
         var connectionString = connectionContext.connectionString();
-        replicaSetSpecs.add(ReplicaSet.forCluster(connectionString));
+        replicaSetSpecs.add(new ReplicaSet(connectionString));
     }
 
     private void readReplicaSetsFromCluster(Set<ReplicaSet> replicaSetSpecs, ClusterDescription clusterDescription, ConnectionContext connectionContext) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/infinispan/EmbeddedInfinispanLogMinerEventProcessor.java
Patch:
@@ -182,8 +182,8 @@ protected String getFirstActiveTransactionKey() {
 
     @Override
     protected void purgeCache(Scn minCacheScn) {
-        removeIf(processedTransactionsCache.entrySet().iterator(), entry -> Scn.valueOf(entry.getValue()).compareTo(minCacheScn) > 0);
-        removeIf(schemaChangesCache.entrySet().iterator(), entry -> Scn.valueOf(entry.getKey()).compareTo(minCacheScn) > 0);
+        removeIf(processedTransactionsCache.entrySet().iterator(), entry -> Scn.valueOf(entry.getValue()).compareTo(minCacheScn) < 0);
+        removeIf(schemaChangesCache.entrySet().iterator(), entry -> Scn.valueOf(entry.getKey()).compareTo(minCacheScn) < 0);
     }
 
     private <K, V> Cache<K, V> createCache(String cacheName, OracleConnectorConfig connectorConfig, Field field) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/infinispan/RemoteInfinispanLogMinerEventProcessor.java
Patch:
@@ -193,7 +193,7 @@ protected String getFirstActiveTransactionKey() {
 
     @Override
     protected void purgeCache(Scn minCacheScn) {
-        removeIf(processedTransactionsCache.entrySet().iterator(), entry -> Scn.valueOf(entry.getValue()).compareTo(minCacheScn) > 0);
+        removeIf(processedTransactionsCache.entrySet().iterator(), entry -> Scn.valueOf(entry.getValue()).compareTo(minCacheScn) < 0);
         removeIf(schemaChangesCache.entrySet().iterator(), entry -> Scn.valueOf(entry.getKey()).compareTo(minCacheScn) < 0);
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -237,7 +237,7 @@ public Scn process(Scn startScn, Scn endScn) throws SQLException, InterruptedExc
                         offsetContext.getCommitScn(), metrics.getNumberOfActiveTransactions(),
                         metrics.getSleepTimeInMilliseconds());
 
-                if (metrics.getNumberOfActiveTransactions() > 0) {
+                if (metrics.getNumberOfActiveTransactions() > 0 && LOGGER.isDebugEnabled()) {
                     // This is wrapped in try-with-resources specifically for Infinispan performance
                     try (Stream<T> stream = getTransactionCache().values().stream()) {
                         LOGGER.debug("All active transactions: {}",

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/ConfigProperties.java
Patch:
@@ -115,7 +115,7 @@ private ConfigProperties() {
 
     // Oracle Configuration
     public static final boolean DATABASE_ORACLE = booleanProperty("test.database.oracle", true);
-    public static final String DATABASE_ORACLE_USERNAME = System.getProperty("test.database.oracle..username", "debezium");
+    public static final String DATABASE_ORACLE_USERNAME = System.getProperty("test.database.oracle.username", "debezium");
     public static final String DATABASE_ORACLE_PASSWORD = System.getProperty("test.database.oracle.password", "dbz");
     public static final String DATABASE_ORACLE_DBZ_USERNAME = System.getProperty("test.database.oracle.dbz.username", "c##dbzuser");
     public static final String DATABASE_ORACLE_DBZ_PASSWORD = System.getProperty("test.database.oracle.dbz.password", "dbz");

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcSinkConnectorTask.java
Patch:
@@ -79,7 +79,9 @@ public void start(Map<String, String> props) {
 
     @Override
     public void put(Collection<SinkRecord> records) {
+
         if (previousPutException != null) {
+            LOGGER.error("JDBC sink connector failure", previousPutException);
             throw new ConnectException("JDBC sink connector failure", previousPutException);
         }
 
@@ -134,9 +136,6 @@ public Map<TopicPartition, OffsetAndMetadata> preCommit(Map<TopicPartition, Offs
     public void stop() {
         stateLock.lock();
         try {
-            if (previousPutException != null) {
-                throw new ConnectException("JDBC sink connector failure", previousPutException);
-            }
 
             if (changeEventSink != null) {
                 try {

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SnapshotParallelSourceIT.java
Patch:
@@ -21,6 +21,8 @@
 import io.debezium.junit.logging.LogInterceptor;
 import io.debezium.util.Collect;
 
+import ch.qos.logback.classic.Level;
+
 @SkipWhenDatabaseVersion(check = LESS_THAN, major = 5, minor = 6, reason = "DDL uses fractional second data types, not supported until MySQL 5.6")
 public class SnapshotParallelSourceIT extends SnapshotSourceIT {
 
@@ -74,6 +76,7 @@ public void shouldParallelCreateSnapshotSchema() throws Exception {
                 .with(MySqlConnectorConfig.DATABASE_INCLUDE_LIST, String.join(",", includeDatabases))
                 .build();
         LogInterceptor logInterceptor = new LogInterceptor(MySqlSnapshotChangeEventSource.class);
+        logInterceptor.setLoggerLevel(MySqlSnapshotChangeEventSource.class, Level.INFO);
 
         // Start the connector ...
         start(MySqlConnector.class, config);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/junit/SkipTestDependingOnGtidModeRule.java
Patch:
@@ -31,8 +31,9 @@ public Statement apply(Statement base, Description description) {
 
     public static SkipWhenGtidModeIs.GtidMode getGtidMode() {
         try (MySqlTestConnection db = MySqlTestConnection.forTestDatabase("emptydb")) {
+            String databaseOption = MySqlTestConnection.isMariaDB() ? "GTID_STRICT_MODE" : "GTID_MODE";
             return db.queryAndMap(
-                    "SHOW GLOBAL VARIABLES LIKE 'GTID_MODE'",
+                    "SHOW GLOBAL VARIABLES LIKE '" + databaseOption + "'",
                     rs -> {
                         if (rs.next()) {
                             return SkipWhenGtidModeIs.GtidMode.valueOf(rs.getString(2));

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -669,7 +669,7 @@ private void shouldConsumeAllEventsFromDatabaseUsingSnapshotByField(Field dbIncl
             assertThat(persistedOffsetSource.binlogFilename()).isEqualTo(positionBeforeInserts.binlogFilename());
             assertThat(persistedOffsetSource.binlogFilename()).isEqualTo(positionAfterInserts.binlogFilename());
             final MySqlVersion mysqlVersion = MySqlTestConnection.forTestDatabase(DATABASE.getDatabaseName()).getMySqlVersion();
-            if (mysqlVersion == MySqlVersion.MYSQL_5_5 || mysqlVersion == MySqlVersion.MYSQL_5_6) {
+            if (mysqlVersion == MySqlVersion.MYSQL_5_5 || mysqlVersion == MySqlVersion.MYSQL_5_6 || mysqlVersion == MySqlVersion.MARIADB_11) {
                 // todo: for some reason on MySQL 5.6, the binlog position does not behave like it does on MySQL 5.7 - why?
                 assertThat(persistedOffsetSource.binlogPosition()).isGreaterThanOrEqualTo(positionBeforeInserts.binlogPosition());
             }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlGeometryIT.java
Patch:
@@ -46,7 +46,7 @@ public class MySqlGeometryIT extends AbstractConnectorTest {
     @Before
     public void beforeEach() {
         stopConnector();
-        databaseDifferences = databaseGeoDifferences(MySqlTestConnection.isMySQL5());
+        databaseDifferences = databaseGeoDifferences(MySqlTestConnection.isMySQL5() || MySqlTestConnection.isMariaDb());
 
         DATABASE = new UniqueDatabase("geometryit", databaseDifferences.geometryDatabaseName())
                 .withDbHistoryPath(SCHEMA_HISTORY_PATH);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MysqlDefaultGeneratedValueIT.java
Patch:
@@ -5,6 +5,7 @@
  */
 package io.debezium.connector.mysql;
 
+import static io.debezium.junit.EqualityCheck.GREATER_THAN_OR_EQUAL;
 import static io.debezium.junit.EqualityCheck.LESS_THAN;
 import static org.assertj.core.api.Assertions.assertThat;
 
@@ -27,6 +28,7 @@
  * @author Chris Cranford
  */
 @SkipWhenDatabaseVersion(check = LESS_THAN, major = 5, minor = 7, reason = "Generated values were not added until MySQL 5.7")
+@SkipWhenDatabaseVersion(check = GREATER_THAN_OR_EQUAL, major = 11, reason = "MariaDB does not allow you to specify AS and NOT NULL")
 public class MysqlDefaultGeneratedValueIT extends AbstractConnectorTest {
 
     // 4 meta events (set character_set etc.) and then 15 tables with 3 events each (drop DDL, create DDL, insert)

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlTestConnection.java
Patch:
@@ -220,7 +220,7 @@ public DatabaseDifferences databaseAsserts() {
                 databaseAsserts = new DatabaseDifferences() {
                     @Override
                     public boolean isCurrentDateTimeDefaultGenerated() {
-                        return true;
+                        return false;
                     }
 
                     @Override

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/CloudEventsConverterIT.java
Patch:
@@ -168,8 +168,8 @@ public void shouldConvertToCloudEventsInJsonWithMetadataAndIdAndTypeInHeadersAft
     public void shouldConvertToCloudEventsInJsonWithGeneratedIdAndTypeFromHeader() throws Exception {
         InsertHeader<SourceRecord> insertHeader = new InsertHeader<>();
         Map<String, String> insertHeaderConfig = new LinkedHashMap<>();
-        insertHeaderConfig.put("header", "type");
-        insertHeaderConfig.put("value.literal", "someType");
+        insertHeaderConfig.put("header", "id");
+        insertHeaderConfig.put("value.literal", "77742efd-b015-44a9-9dde-cb36d9002425");
         insertHeader.configure(insertHeaderConfig);
 
         try (var client = connect()) {
@@ -188,7 +188,7 @@ public void shouldConvertToCloudEventsInJsonWithGeneratedIdAndTypeFromHeader() t
         assertThat(recordWithTypeInHeader).isNotNull();
         assertThat(recordWithTypeInHeader.value()).isInstanceOf(Struct.class);
 
-        CloudEventsConverterTest.shouldConvertToCloudEventsInJsonWithGeneratedIdAndTypeFromHeader(recordWithTypeInHeader, "mongodb", "mongo1");
+        CloudEventsConverterTest.shouldConvertToCloudEventsInJsonWithIdFromHeaderAndGeneratedType(recordWithTypeInHeader, "mongodb", "mongo1");
 
         insertHeader.close();
     }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/CloudEventsConverterIT.java
Patch:
@@ -44,7 +44,7 @@ public class CloudEventsConverterIT extends AbstractCloudEventsConverterTest<MyS
             "  id            varchar(36)  not null," +
             "  aggregatetype varchar(255) not null," +
             "  aggregateid   varchar(255) not null," +
-            "  type          varchar(255) not null," +
+            "  event_type          varchar(255) not null," +
             "  payload       json," +
             "  CONSTRAINT outbox_pk PRIMARY KEY (id));";
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/CloudEventsConverterIT.java
Patch:
@@ -36,7 +36,7 @@ public class CloudEventsConverterIT extends AbstractCloudEventsConverterTest<Pos
             "    constraint outbox_pk primary key," +
             "  aggregatetype varchar(255) not null," +
             "  aggregateid   varchar(255) not null," +
-            "  type          varchar(255) not null," +
+            "  event_type          varchar(255) not null," +
             "  payload       jsonb" +
             ");";
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresTaskContext.java
Patch:
@@ -76,7 +76,7 @@ Long getSlotXmin(PostgresConnection connection) throws SQLException {
         }
         assert (this.refreshXmin != null);
 
-        if (this.refreshXmin.hasElapsed()) {
+        if (this.refreshXmin.hasElapsed() || lastXmin == null) {
             lastXmin = getCurrentSlotState(connection).slotCatalogXmin();
             if (LOGGER.isDebugEnabled()) {
                 LOGGER.debug("Fetched new xmin from slot of {}", lastXmin);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -1390,7 +1390,6 @@ protected void clear() {
 
         protected void await(long timeout, TimeUnit unit) throws InterruptedException {
             final ElapsedTimeStrategy timer = ElapsedTimeStrategy.constant(Clock.SYSTEM, unit.toMillis(timeout));
-            timer.hasElapsed();
             while (!timer.hasElapsed()) {
                 final SourceRecord r = consumeRecord();
                 if (r != null) {

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerStreamingChangeEventSource.java
Patch:
@@ -108,7 +108,6 @@ public SqlServerStreamingChangeEventSource(SqlServerConnectorConfig connectorCon
                 DEFAULT_INTERVAL_BETWEEN_COMMITS.compareTo(intervalBetweenCommitsBasedOnPoll) > 0
                         ? DEFAULT_INTERVAL_BETWEEN_COMMITS.toMillis()
                         : intervalBetweenCommitsBasedOnPoll.toMillis());
-        this.pauseBetweenCommits.hasElapsed();
         this.streamingExecutionContexts = new HashMap<>();
         this.checkAgent = true;
     }

File: debezium-core/src/main/java/io/debezium/converters/CloudEventsConverterConfig.java
Patch:
@@ -27,7 +27,7 @@ public class CloudEventsConverterConfig extends ConverterConfig {
     public static final String CLOUDEVENTS_DATA_SERIALIZER_TYPE_DEFAULT = "json";
     private static final String CLOUDEVENTS_DATA_SERIALIZER_TYPE_DOC = "Specify a serializer to serialize the data field of CloudEvents values";
 
-    public static final String CLOUDEVENTS_EXTENSION_ATTRIBUTES_ENABLE_CONFIG = "extension-attributes.enable";
+    public static final String CLOUDEVENTS_EXTENSION_ATTRIBUTES_ENABLE_CONFIG = "extension.attributes.enable";
     public static final boolean CLOUDEVENTS_EXTENSION_ATTRIBUTES_ENABLE_DEFAULT = true;
     private static final String CLOUDEVENTS_EXTENSION_ATTRIBUTES_ENABLE_DOC = "Specify whether to include extension attributes to a cloud event";
 

File: debezium-core/src/test/java/io/debezium/converters/CloudEventsConverterTest.java
Patch:
@@ -391,7 +391,7 @@ public static void shouldConvertToCloudEventsInJsonWithoutExtensionAttributes(So
         Map<String, Object> config = new HashMap<>();
         config.put("serializer.type", "json");
         config.put("data.serializer.type", "json");
-        config.put("extension-attributes.enable", false);
+        config.put("extension.attributes.enable", false);
 
         CloudEventsConverter cloudEventsConverter = new CloudEventsConverter();
         cloudEventsConverter.configure(config, false);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -12,7 +12,7 @@
 import static io.debezium.connector.postgresql.TestHelper.TYPE_SCALE_PARAMETER_KEY;
 import static io.debezium.connector.postgresql.TestHelper.topicName;
 import static io.debezium.connector.postgresql.junit.SkipWhenDecoderPluginNameIs.DecoderPluginName.PGOUTPUT;
-import static io.debezium.junit.EqualityCheck.LESS_THAN_OR_EQUAL;
+import static io.debezium.junit.EqualityCheck.LESS_THAN;
 import static junit.framework.TestCase.assertEquals;
 import static junit.framework.TestCase.assertTrue;
 import static org.assertj.core.api.Assertions.assertThat;
@@ -1159,7 +1159,7 @@ public void shouldReceiveNumericTypeAsString() throws Exception {
 
     @Test
     @FixFor("DBZ-6758")
-    @SkipWhenDatabaseVersion(check = LESS_THAN_OR_EQUAL, major = 10, reason = "Database version less than or equal 10.0")
+    @SkipWhenDatabaseVersion(check = LESS_THAN, major = 14, reason = "Database version less than or equal 14.0")
     public void shouldReceiveChangesForInfinityNumericWithInfinity() throws Exception {
         TestHelper.executeDDL("postgres_create_tables.ddl");
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/AbstractMongoConnectorIT.java
Patch:
@@ -75,6 +75,7 @@ public void beforeEach() {
     @After
     public void afterEach() {
         stopConnector();
+        TestHelper.cleanDatabases(mongo);
     }
 
     @BeforeClass

File: debezium-connect-rest-extension/src/main/java/io/debezium/kcrestextension/DebeziumResource.java
Patch:
@@ -32,6 +32,7 @@
 import org.apache.kafka.connect.transforms.Transformation;
 import org.apache.kafka.connect.transforms.predicates.Predicate;
 
+import io.debezium.DebeziumException;
 import io.debezium.kcrestextension.entities.PredicateDefinition;
 import io.debezium.kcrestextension.entities.TransformDefinition;
 import io.debezium.metadata.ConnectorDescriptor;
@@ -151,14 +152,14 @@ private synchronized Herder getHerder() {
                 herderField = this.connectClusterState.getClass().getDeclaredField("herder");
             }
             catch (NoSuchFieldException e) {
-                throw new RuntimeException(e);
+                throw new DebeziumException(e);
             }
             herderField.setAccessible(true);
             try {
                 this.herder = (Herder) herderField.get(this.connectClusterState);
             }
             catch (IllegalAccessException e) {
-                throw new RuntimeException(e);
+                throw new DebeziumException(e);
             }
         }
         return this.herder;

File: debezium-connect-rest-extension/src/test/java/io/debezium/kcrestextension/DebeziumResourceIT.java
Patch:
@@ -39,6 +39,7 @@ public class DebeziumResourceIT {
             "io.debezium.transforms.Filter",
             "io.debezium.transforms.HeaderToValue",
             "io.debezium.transforms.SchemaChangeEventFilter",
+            "io.debezium.transforms.TimezoneConverter",
             "io.debezium.transforms.outbox.EventRouter",
             "io.debezium.transforms.partitions.ComputePartition",
             "io.debezium.transforms.partitions.PartitionRouting",

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnector.java
Patch:
@@ -216,17 +216,15 @@ public Config validate(Map<String, String> connectorConfigs) {
         if (userValue.errorMessages().isEmpty()
                 && passwordValue.errorMessages().isEmpty()
                 && connectionStringValue.errorMessages().isEmpty()) {
-
             // Try to connect to the database ...
             ConnectionContext connContext = new ConnectionContext(config);
             try (MongoClient client = connContext.connect()) {
-                client.listDatabaseNames();
+                client.listDatabaseNames().first(); // only when we try to fetch results a connection gets established
             }
             catch (MongoException e) {
                 connectionStringValue.addErrorMessage("Unable to connect: " + e.getMessage());
             }
         }
-
         return new Config(new ArrayList<>(results.values()));
     }
 }

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/junit/MongoDbDatabaseProvider.java
Patch:
@@ -17,7 +17,7 @@ public final class MongoDbDatabaseProvider {
     public static final String MONGO_SHARD_REPLICA_SIZE = "mongodb.shard.replica.size";
     public static final String MONGO_DOCKER_DESKTOP_PORT_PROPERTY = "mongodb.docker.desktop.ports";
 
-    // Should be aligned with definition in pom.xm
+    // Should be aligned with definition in pom.xml
     public static final String MONGO_DOCKER_DESKTOP_PORT_DEFAULT = "27017:27117";
 
     private static MongoDbReplicaSet.Builder dockerReplicaSetBuilder() {

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/MongoDbReplicaSet.java
Patch:
@@ -280,7 +280,7 @@ public void start() {
     public void stop() {
         LOGGER.info("[{}] Stopping...", name);
         MoreStartables.deepStopSync(members.stream());
-        network.close();
+        started = false;
     }
 
     private void initializeReplicaSet() {

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/MongoDbShardedCluster.java
Patch:
@@ -148,7 +148,6 @@ public void stop() {
         // Idempotent
         LOGGER.info("Stopping {} shard cluster...", shards.size());
         MoreStartables.deepStopSync(stream());
-        network.close();
     }
 
     public int size() {

File: debezium-schema-generator/src/main/java/io/debezium/schemagenerator/JsonSchemaCreatorService.java
Patch:
@@ -111,7 +111,7 @@ private static JsonSchemaType toJsonSchemaType(ConfigDef.Type type) {
     public Schema buildConnectorSchema() {
         Schema schema = new SchemaImpl(connectorName);
         String connectorVersion = connectorMetadata.getConnectorDescriptor().getVersion();
-        schema.setTitle(connectorMetadata.getConnectorDescriptor().getName());
+        schema.setTitle(connectorMetadata.getConnectorDescriptor().getDisplayName());
         schema.setType(Schema.SchemaType.OBJECT);
         schema.addExtension("connector-id", connectorBaseName);
         schema.addExtension("version", connectorVersion);

File: debezium-schema-generator/src/main/java/io/debezium/schemagenerator/SchemaGenerator.java
Patch:
@@ -56,7 +56,7 @@ private void run(String formatName, Path outputDirectory, boolean groupDirectory
         for (ConnectorMetadata connectorMetadata : allMetadata) {
             LOGGER.log(Logger.Level.INFO, "Creating \"" + format.getDescriptor().getName()
                     + "\" schema for connector: "
-                    + connectorMetadata.getConnectorDescriptor().getName() + "...");
+                    + connectorMetadata.getConnectorDescriptor().getDisplayName() + "...");
             JsonSchemaCreatorService jsonSchemaCreatorService = new JsonSchemaCreatorService(connectorMetadata, format.getFieldFilter());
             org.eclipse.microprofile.openapi.models.media.Schema buildConnectorSchema = jsonSchemaCreatorService.buildConnectorSchema();
             String spec = format.getSpec(buildConnectorSchema);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerOracleOffsetContextLoader.java
Patch:
@@ -36,7 +36,8 @@ public OracleOffsetContext load(Map<String, ?> offset) {
         CommitScn commitScn = CommitScn.load(offset);
         Map<String, Scn> snapshotPendingTransactions = OracleOffsetContext.loadSnapshotPendingTransactions(offset);
         Scn snapshotScn = OracleOffsetContext.loadSnapshotScn(offset);
-        return new OracleOffsetContext(connectorConfig, scn, commitScn, null, snapshotScn, snapshotPendingTransactions, snapshot, snapshotCompleted,
+        return new OracleOffsetContext(connectorConfig, scn, null, commitScn, null, snapshotScn,
+                snapshotPendingTransactions, snapshot, snapshotCompleted,
                 TransactionContext.load(offset),
                 SignalBasedIncrementalSnapshotContext.load(offset));
     }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/olr/OpenLogReplicatorOracleOffsetContextLoader.java
Patch:
@@ -35,8 +35,10 @@ public OracleOffsetContext load(Map<String, ?> offset) {
         boolean snapshotCompleted = Boolean.TRUE.equals(offset.get(OracleOffsetContext.SNAPSHOT_COMPLETED_KEY));
 
         Scn scn = OracleOffsetContext.getScnFromOffsetMapByKey(offset, SourceInfo.SCN_KEY);
+        Long scnIndex = (Long) offset.get(SourceInfo.SCN_INDEX_KEY);
         CommitScn commitScn = CommitScn.valueOf((String) null);
-        return new OracleOffsetContext(connectorConfig, scn, commitScn, null, null, null, snapshot, snapshotCompleted,
+        return new OracleOffsetContext(connectorConfig, scn, scnIndex, commitScn, null, null, null,
+                snapshot, snapshotCompleted,
                 TransactionContext.load(offset),
                 SignalBasedIncrementalSnapshotContext.load(offset));
     }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/xstream/XStreamOracleOffsetContextLoader.java
Patch:
@@ -45,7 +45,7 @@ public OracleOffsetContext load(Map<String, ?> offset) {
 
         final Map<String, Scn> snapshotPendingTransactions = OracleOffsetContext.loadSnapshotPendingTransactions(offset);
         final Scn snapshotScn = OracleOffsetContext.loadSnapshotScn(offset);
-        return new OracleOffsetContext(connectorConfig, scn, lcrPosition, snapshotScn, snapshotPendingTransactions,
+        return new OracleOffsetContext(connectorConfig, scn, null, lcrPosition, snapshotScn, snapshotPendingTransactions,
                 snapshot, snapshotCompleted, TransactionContext.load(offset), SignalBasedIncrementalSnapshotContext.load(offset));
     }
 }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleSchemaHistoryTest.java
Patch:
@@ -76,7 +76,8 @@ protected Offsets<Partition, OffsetContext> getOffsets() {
                 .with(CommonConnectorConfig.TOPIC_PREFIX, TestHelper.SERVER_NAME)
                 .build();
         final OracleOffsetContext position = new OracleOffsetContext(new OracleConnectorConfig(config), Scn.valueOf(999),
-                CommitScn.valueOf(999L), null, Scn.valueOf(999), Collections.emptyMap(), false, true, new TransactionContext(),
+                null, CommitScn.valueOf(999L), null, Scn.valueOf(999), Collections.emptyMap(), false, true,
+                new TransactionContext(),
                 new SignalBasedIncrementalSnapshotContext<>());
 
         return Offsets.of(source, position);

File: debezium-core/src/main/java/io/debezium/transforms/ExtractNewRecordState.java
Patch:
@@ -553,7 +553,7 @@ private static class NewRecordValueMetadata {
         private final Schema schema;
         private final String operation;
 
-        public NewRecordValueMetadata(Schema schema, String operation) {
+        NewRecordValueMetadata(Schema schema, String operation) {
             this.schema = schema;
             this.operation = operation;
         }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresOffsetContext.java
Patch:
@@ -31,7 +31,7 @@
 import io.debezium.util.Clock;
 
 public class PostgresOffsetContext extends CommonOffsetContext<SourceInfo> {
-    private static final Logger LOGGER = LoggerFactory.getLogger(PostgresSnapshotChangeEventSource.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(PostgresOffsetContext.class);
 
     public static final String LAST_COMPLETELY_PROCESSED_LSN_KEY = "lsn_proc";
     public static final String LAST_COMMIT_LSN_KEY = "lsn_commit";

File: debezium-storage/debezium-storage-redis/src/main/java/io/debezium/storage/redis/RedisConnection.java
Patch:
@@ -28,7 +28,7 @@ public class RedisConnection {
 
     public static final String DEBEZIUM_OFFSETS_CLIENT_NAME = "debezium:offsets";
     public static final String DEBEZIUM_SCHEMA_HISTORY = "debezium:schema_history";
-    private static final String HOST_PORT_ERROR = "Invalid host:port format in 'debezium.sink.redis.address' property.";
+    private static final String HOST_PORT_ERROR = "Invalid host:port format in '<...>.redis.address' property.";
 
     private String address;
     private int dbIndex;
@@ -116,7 +116,7 @@ else if (this.password != null) {
     private void validateHostPort(String address) {
         Pattern pattern = Pattern.compile("^[\\w.-]+:\\d{1,5}+$");
         if (!pattern.matcher(address).matches()) {
-            throw new IllegalArgumentException(HOST_PORT_ERROR);
+            throw new DebeziumException(HOST_PORT_ERROR);
         }
     }
 }

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MultiThreadIncrementalSnapshotIT.java
Patch:
@@ -12,7 +12,6 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
-import java.util.function.Function;
 
 import org.junit.Test;
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/olr/OpenLogReplicatorStreamingChangeEventSource.java
Patch:
@@ -135,7 +135,6 @@ public void execute(ChangeEventSourceContext context, OraclePartition partition,
                     // By the time the connector calls commitOffsets, the client will be disconnected.
                     // In this case, the last checkpoint SCN won't be flushable, so confirm it now.
                     confirmLastCheckpointScn();
-                    ;
                 }
 
                 client.disconnect();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -621,7 +621,7 @@ private OffsetDateTime getDatabaseSystemTime(OracleConnection connection) throws
      * @throws SQLException if mining session failed to start
      */
     public boolean startMiningSession(OracleConnection connection, Scn startScn, Scn endScn, int attempts) throws SQLException {
-        LOGGER.trace("Starting mining session startScn={}, endScn={}, strategy={}, continuous={}",
+        LOGGER.debug("Starting mining session startScn={}, endScn={}, strategy={}, continuous={}",
                 startScn, endScn, strategy, isContinuousMining);
         try {
             Instant start = Instant.now();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/events/LogMinerEventRow.java
Patch:
@@ -261,7 +261,8 @@ public String toString() {
                 ", rollbackFlag=" + rollbackFlag +
                 ", rsId=" + rsId +
                 ", ssn=" + ssn +
-                ", redoSql='" + redoSql + '\'' +
+                // Specifically log SQL only if TRACE is enabled; otherwise omit for others
+                ", redoSql='" + (LOGGER.isTraceEnabled() ? redoSql : "<omitted>") + '\'' +
                 '}';
     }
 }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/TransactionCommitConsumer.java
Patch:
@@ -135,7 +135,7 @@ private void acceptDmlEvent(DmlEvent event) throws InterruptedException {
 
         final Table table = schema.tableFor(event.getTableId());
         if (table == null) {
-            LOGGER.trace("Unable to locate table '{}' schema, ignoring event.", event.getTableId());
+            LOGGER.debug("Unable to locate table '{}' schema, ignoring event.", event.getTableId());
             return;
         }
 
@@ -176,7 +176,7 @@ else if (event instanceof XmlWriteEvent || event instanceof XmlEndEvent) {
     private void acceptLobManipulationEvent(LogMinerEvent event) {
         if (!currentLobDetails.isInitialized()) {
             // should only happen when we start streaming in the middle of a LOB transaction (DBZ-4367)
-            LOGGER.trace("Got LOB manipulation event without preceding LOB selector; ignoring {} {}.", event.getEventType(), event);
+            LOGGER.debug("Got LOB manipulation event without preceding LOB selector; ignoring {} {}.", event.getEventType(), event);
             return;
         }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/infinispan/AbstractInfinispanLogMinerEventProcessor.java
Patch:
@@ -128,7 +128,7 @@ else if (!getConfig().isLobEnabled()) {
             for (String eventKey : eventKeys) {
                 final LogMinerEvent event = getEventCache().get(eventKey);
                 if (event != null && event.getRowId().equals(row.getRowId())) {
-                    LOGGER.trace("Undo applied for event {}.", event);
+                    LOGGER.debug("Undo applied for event {}.", event);
                     getEventCache().remove(eventKey);
                     return;
                 }
@@ -146,7 +146,7 @@ private List<String> getTransactionKeysWithPrefix(String prefix) {
     protected void processRow(OraclePartition partition, LogMinerEventRow row) throws SQLException, InterruptedException {
         final String transactionId = row.getTransactionId();
         if (isRecentlyProcessed(transactionId)) {
-            LOGGER.trace("Transaction {} has been seen by connector, skipped.", transactionId);
+            LOGGER.debug("Transaction {} has been seen by connector, skipped.", transactionId);
             return;
         }
         super.processRow(partition, row);
@@ -196,7 +196,7 @@ public boolean hasNext() {
                 while (index < count) {
                     nextEvent = getEventCache().get(transaction.getEventId(index));
                     if (nextEvent == null) {
-                        LOGGER.trace("Event {} must have been undone, skipped.", index);
+                        LOGGER.debug("Event {} must have been undone, skipped.", index);
                         // There are situations where an event will be removed from the cache when it is
                         // undone by the undo-row flag. The event id isn't re-used in this use case so
                         // the iterator automatically detects null entries and skips them by advancing

File: debezium-core/src/test/java/io/debezium/config/ConfigurationTest.java
Patch:
@@ -397,6 +397,8 @@ public void defaultDdlFilterShouldFilterOutRdsSetStatements() {
         String defaultDdlFilter = Configuration.create().build().getString(SchemaHistory.DDL_FILTER);
         Predicate<String> ddlFilter = Predicates.includes(defaultDdlFilter, Pattern.CASE_INSENSITIVE | Pattern.DOTALL);
         assertThat(ddlFilter.test("SET STATEMENT max_statement_time=60 FOR DELETE FROM mysql.rds_sysinfo where name = 'innodb_txn_key'")).isTrue();
-        assertThat(ddlFilter.test("SET STATEMENT max_statement_time=60 FOR INSERT INTO mysql.rds_heartbeat2(id, value) values (1,1692866524004) ON DUPLICATE KEY UPDATE value = 1692866524004")).isTrue();
+        assertThat(ddlFilter.test(
+                "SET STATEMENT max_statement_time=60 FOR INSERT INTO mysql.rds_heartbeat2(id, value) values (1,1692866524004) ON DUPLICATE KEY UPDATE value = 1692866524004"))
+                .isTrue();
     }
 }

File: debezium-core/src/main/java/io/debezium/pipeline/signal/actions/snapshotting/ExecuteSnapshot.java
Patch:
@@ -72,7 +72,8 @@ public boolean arrived(SignalPayload<P> signalPayload) throws InterruptedExcepti
         switch (type) {
             case INCREMENTAL:
                 if (dispatcher.getIncrementalSnapshotChangeEventSource() == null) {
-                    throw new DebeziumException("Should enable relative incremental snapshot configuration");
+                    throw new DebeziumException(
+                            "Incremental snapshot is not properly configured, either sinalling data collection is not provided or connector-specific snapshotting not set");
                 }
                 dispatcher.getIncrementalSnapshotChangeEventSource().addDataCollectionNamesToSnapshot(
                         signalPayload, snapsthoConfigurationBuilder.build());

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/GeneralDatabaseDialect.java
Patch:
@@ -329,7 +329,7 @@ public String getInsertStatement(TableDescriptor table, SinkRecordDescriptor rec
 
         builder.appendLists(", ", record.getKeyFieldNames(), record.getNonKeyFieldNames(), (name) -> columnQueryBindingFromField(name, table, record));
 
-        builder.append(");");
+        builder.append(")");
 
         return builder.build();
     }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/sqlserver/SqlServerDatabaseDialect.java
Patch:
@@ -62,7 +62,7 @@ private String wrapWithIdentityInsert(TableDescriptor table, String sqlStatement
         String qualifiedTableName = getQualifiedTableName(table.getId());
         return new StringBuilder()
                 .append("SET IDENTITY_INSERT ").append(qualifiedTableName).append(" ON ;")
-                .append(sqlStatement)
+                .append(sqlStatement).append(";")
                 .append("SET IDENTITY_INSERT ").append(qualifiedTableName).append(" OFF ;")
                 .toString();
 

File: debezium-core/src/main/java/io/debezium/relational/RelationalChangeRecordEmitter.java
Patch:
@@ -73,7 +73,7 @@ protected void emitCreateRecord(Receiver<P> receiver, TableSchema tableSchema)
 
         if (skipEmptyMessages() && (newColumnValues == null || newColumnValues.length == 0)) {
             // This case can be hit on UPDATE / DELETE when there's no primary key defined while using certain decoders
-            LOGGER.warn("no new values found for table '{}' from create message at '{}'; skipping record", tableSchema, getOffset().getSourceInfo());
+            LOGGER.debug("no new values found for table '{}' from create message at '{}'; skipping record", tableSchema, getOffset().getSourceInfo());
             return;
         }
         receiver.changeRecord(getPartition(), tableSchema, Operation.CREATE, newKey, envelope, getOffset(), null);
@@ -136,7 +136,7 @@ protected void emitDeleteRecord(Receiver<P> receiver, TableSchema tableSchema) t
         Struct oldValue = tableSchema.valueFromColumnData(oldColumnValues);
 
         if (skipEmptyMessages() && (oldColumnValues == null || oldColumnValues.length == 0)) {
-            LOGGER.warn("no old values found for table '{}' from delete message at '{}'; skipping record", tableSchema, getOffset().getSourceInfo());
+            LOGGER.debug("no old values found for table '{}' from delete message at '{}'; skipping record", tableSchema, getOffset().getSourceInfo());
             return;
         }
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/CustomPostgresSourceInfoStructMaker.java
Patch:
@@ -37,7 +37,6 @@ public Schema schema() {
     @Override
     public Struct struct(SourceInfo sourceInfo) {
         Struct result = super.struct(sourceInfo);
-        Long lsn = result.getInt64(SourceInfo.LSN_KEY);
         result.put("newField", "newFieldValue");
         return result;
     }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDefaultValueConverter.java
Patch:
@@ -62,7 +62,7 @@ public class MySqlDefaultValueConverter implements DefaultValueConverter {
     @Immutable
     private static final Set<Integer> TRIM_DATA_TYPES = Collect.unmodifiableSet(Types.TINYINT, Types.INTEGER,
             Types.DATE, Types.TIMESTAMP, Types.TIMESTAMP_WITH_TIMEZONE, Types.TIME, Types.BOOLEAN, Types.BIT,
-            Types.NUMERIC, Types.DECIMAL, Types.FLOAT, Types.DOUBLE, Types.REAL);
+            Types.NUMERIC, Types.DECIMAL, Types.FLOAT, Types.DOUBLE, Types.REAL, Types.BIGINT, Types.SMALLINT);
 
     @Immutable
     private static final Set<Integer> NUMBER_DATA_TYPES = Collect.unmodifiableSet(Types.BIT, Types.TINYINT,

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -5528,7 +5528,7 @@ public void shouldPauseAndWaitForDeviationCalculationIfBeforeMiningRange() throw
 
     @Test
     @FixFor("DBZ-6660")
-    @SkipWhenAdapterNameIsNot(SkipWhenAdapterNameIsNot.AdapterName.LOGMINER)
+    @Ignore("Test can be flaky when using a brand new docker instance")
     public void shouldUseEndScnIfDeviationProducesScnOutsideOfUndoRetention() throws Exception {
         try {
             TestHelper.dropTable(connection, "dbz6660");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleSchemaMigrationIT.java
Patch:
@@ -20,6 +20,7 @@
 import org.awaitility.Awaitility;
 import org.junit.After;
 import org.junit.Before;
+import org.junit.Ignore;
 import org.junit.Test;
 
 import io.debezium.config.Configuration;
@@ -1050,6 +1051,7 @@ record = records.recordsForTopic(TestHelper.SERVER_NAME).get(0);
 
     @Test
     @FixFor("DBZ-2916")
+    @Ignore("Test can be flaky and cannot reproduce locally, ignoring to stablize test suite")
     public void shouldNotEmitDdlEventsForNonTableObjects() throws Exception {
         try {
             final LogInterceptor logminerlogInterceptor = new LogInterceptor(AbstractLogMinerEventProcessor.class);

File: debezium-core/src/main/java/io/debezium/transforms/ExtractNewRecordState.java
Patch:
@@ -62,8 +62,8 @@
  * The SMT by default drops the tombstone message created by Debezium and converts the delete message into
  * a tombstone message that can be dropped, too, if required.
  * <p>
- * The SMT also has the option to insert fields from the original record (e.g. 'op' or 'source.ts_ms' into the
- * unwrapped record or ad them as header attributes.
+ * The SMT also has the option to insert fields from the original record (e.g. 'op' or 'source.ts_ms') into the
+ * unwrapped record or add them as header attributes.
  *
  * @param <R> the subtype of {@link ConnectRecord} on which this transformation will operate
  * @author Jiri Pechanec

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -427,14 +427,13 @@ protected void handleCommit(OraclePartition partition, LogMinerEventRow row) thr
         final Scn smallestScn;
         if (oldestTransaction.isPresent()) {
             smallestScn = oldestTransaction.get().getStartScn();
-            metrics.setOldestScn(smallestScn);
             metrics.setOldestScnAge(oldestTransaction.get().getChangeTime());
         }
         else {
-            smallestScn = Scn.valueOf(-1);
-            metrics.setOldestScn(smallestScn);
+            smallestScn = Scn.NULL;
             metrics.setOldestScnAge(null);
         }
+        metrics.setOldestScn(smallestScn.isNull() ? Scn.valueOf(-1) : smallestScn);
 
         final Scn commitScn = row.getScn();
         if (offsetContext.getCommitScn().hasCommitAlreadyBeenHandled(row)) {

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/relational/TableDescriptor.java
Patch:
@@ -28,7 +28,6 @@ public class TableDescriptor {
     private final List<String> primaryKeyColumnNames;
     private final boolean autoGeneratedIdentityColumn;
 
-
     private TableDescriptor(TableId id, String tableType, List<ColumnDescriptor> columns, List<String> primaryKeyColumnNames) {
         this.id = id;
         this.tableType = tableType;
@@ -73,8 +72,6 @@ public boolean hasAutoGeneratedIdentityColumn() {
         return autoGeneratedIdentityColumn;
     }
 
-
-
     public static class Builder {
         private String catalogName;
         private String schemaName;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/UniqueDatabase.java
Patch:
@@ -196,7 +196,7 @@ public Configuration.Builder defaultJdbcConfigBuilder() {
                 .with(MySqlConnectorConfig.USER, "snapper")
                 .with(MySqlConnectorConfig.PASSWORD, "snapperpass");
 
-        String sslMode = System.getProperty("database.ssl.mode", "preferred");
+        String sslMode = System.getProperty("database.ssl.mode", "disabled");
 
         if (sslMode.equals("disabled")) {
             builder.with(MySqlConnectorConfig.SSL_MODE, MySqlConnectorConfig.SecureConnectionMode.DISABLED);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -750,7 +750,7 @@ public static AutoCreateMode parse(String value, String defaultValue) {
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.MEDIUM)
             .withValidation((config, field, output) -> {
-                if (config.getString(SNAPSHOT_MODE).toLowerCase().equals("custom") && config.getString(field, "").isEmpty()) {
+                if (config.getString(SNAPSHOT_MODE).equalsIgnoreCase("custom") && config.getString(field, "").isEmpty()) {
                     output.accept(field, "", "snapshot.custom_class cannot be empty when snapshot.mode 'custom' is defined");
                     return 1;
                 }

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/TestHelper.java
Patch:
@@ -14,6 +14,7 @@
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
+import org.apache.commons.lang3.math.NumberUtils;
 import org.apache.kafka.connect.data.Struct;
 import org.bson.Document;
 import org.bson.types.ObjectId;
@@ -52,6 +53,7 @@ private static List<Integer> getMongoVersion() {
         var parts = prop.split("\\.");
 
         return Stream.concat(Arrays.stream(parts), Stream.of("0", "0", "0"))
+                .filter(NumberUtils::isParsable)
                 .limit(3)
                 .map(Integer::parseInt)
                 .collect(Collectors.toList());

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/MongoDbReplicaSetTest.java
Patch:
@@ -14,6 +14,7 @@
 import java.util.Set;
 import java.util.stream.Collectors;
 
+import org.apache.commons.lang3.math.NumberUtils;
 import org.assertj.core.api.Assertions;
 import org.bson.BsonDocument;
 import org.bson.Document;
@@ -139,6 +140,7 @@ private void run(MongoDbReplicaSet cluster, MongoClient client, MongoCollection<
 
             // Ensure it's invalid
             var mongoVersions = Arrays.stream(MongoDbContainer.IMAGE_VERSION.split("\\."))
+                    .filter(NumberUtils::isParsable)
                     .map(Integer::parseInt)
                     .collect(Collectors.toList());
 

File: debezium-core/src/main/java/io/debezium/pipeline/signal/channels/jmx/JmxSignalChannel.java
Patch:
@@ -25,7 +25,7 @@ public class JmxSignalChannel implements SignalChannelReader, JmxSignalChannelMX
     private static final Logger LOGGER = LoggerFactory.getLogger(JmxSignalChannel.class);
     private static final String CHANNEL_NAME = "jmx";
 
-    private static final Queue<SignalRecord> SIGNALS = new ConcurrentLinkedQueue<>();
+    private final Queue<SignalRecord> signals = new ConcurrentLinkedQueue<>();
     private CommonConnectorConfig connectorConfig;
 
     @Override
@@ -49,7 +49,7 @@ public List<SignalRecord> read() {
 
         LOGGER.trace("Reading signaling events from queue");
 
-        SignalRecord signalRecord = SIGNALS.poll();
+        SignalRecord signalRecord = signals.poll();
         if (signalRecord == null) {
             return List.of();
         }
@@ -66,7 +66,7 @@ public void close() {
     @Override
     public void signal(String id, String type, String data) {
 
-        SIGNALS.add(new SignalRecord(id, type, data, Map.of()));
+        signals.add(new SignalRecord(id, type, data, Map.of()));
     }
 
 }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/UnchangedToastedPlaceholder.java
Patch:
@@ -24,7 +24,7 @@ public class UnchangedToastedPlaceholder {
     private final Map<Object, Object> placeholderValues = new HashMap<Object, Object>();
     private final byte[] toastPlaceholderBinary;
     private final String toastPlaceholderString;
-    private final Map toastPlaceholderHstore = new HashMap<String, String>();
+    private final Map<String, String> toastPlaceholderHstore = new HashMap<>();
 
     public UnchangedToastedPlaceholder(PostgresConnectorConfig connectorConfig) {
         toastPlaceholderBinary = connectorConfig.getUnavailableValuePlaceholder();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/UnchangedToastedReplicationMessageColumn.java
Patch:
@@ -61,6 +61,7 @@ private void setUnchangedToastValue(String typeWithModifiers) {
                 break;
             case "integer[]":
             case "_int4":
+            case "date[]":
             case "_date":
                 unchangedToastValue = UNCHANGED_INT_ARRAY_TOAST_VALUE;
                 break;

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -124,7 +124,7 @@ public static ReplicationConnection createForReplication(String slotName, boolea
      */
     public static PostgresConnectorConfig.LogicalDecoder decoderPlugin() {
         final String s = System.getProperty(PostgresConnectorConfig.PLUGIN_NAME.name());
-        return (s == null || s.length() == 0) ? PostgresConnectorConfig.LogicalDecoder.PGOUTPUT : PostgresConnectorConfig.LogicalDecoder.parse(s);
+        return (s == null || s.length() == 0) ? PostgresConnectorConfig.LogicalDecoder.DECODERBUFS : PostgresConnectorConfig.LogicalDecoder.parse(s);
     }
 
     /**

File: debezium-storage/debezium-storage-redis/src/main/java/io/debezium/storage/redis/RedisConnection.java
Patch:
@@ -73,7 +73,7 @@ public RedisClient getRedisClient(String clientName, boolean waitEnabled, long w
 
         Jedis client;
         try {
-            client = new Jedis(address, DefaultJedisClientConfig.builder().database(this.dbIndex) .connectionTimeoutMillis(this.connectionTimeout)
+            client = new Jedis(address, DefaultJedisClientConfig.builder().database(this.dbIndex).connectionTimeoutMillis(this.connectionTimeout)
                     .socketTimeoutMillis(this.socketTimeout).ssl(this.sslEnabled).build());
 
             if (this.user != null) {

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/MySqlDatabaseDialect.java
Patch:
@@ -38,7 +38,7 @@
 public class MySqlDatabaseDialect extends GeneralDatabaseDialect {
 
     private static final List<String> NO_DEFAULT_VALUE_TYPES = Arrays.asList(
-            "tinytext", "mediumtext", "longtext", "text", "tinyblob", "mediumblob", "lonblob");
+            "tinytext", "mediumtext", "longtext", "text", "tinyblob", "mediumblob", "longblob");
 
     private static final DateTimeFormatter ISO_LOCAL_DATE_TIME_WITH_SPACE = new DateTimeFormatterBuilder()
             .parseCaseInsensitive()

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleSchemaMigrationIT.java
Patch:
@@ -8,6 +8,7 @@
 import static org.assertj.core.api.Assertions.assertThat;
 
 import java.math.BigDecimal;
+import java.nio.ByteBuffer;
 import java.sql.SQLException;
 import java.util.Arrays;
 import java.util.List;
@@ -1188,8 +1189,8 @@ public void shouldParseSchemaChangeOnTableWithRawDataType() throws Exception {
             SourceRecord record = records.recordsForTopic(topicName("DEBEZIUM", "DBZ4037")).get(0);
             Struct after = ((Struct) record.value()).getStruct(Envelope.FieldName.AFTER);
             assertThat(after.get("ID")).isEqualTo(1);
-            assertThat(after.get("DATA")).isNull();
-            assertThat(after.get("DATA2")).isNull();
+            assertThat(after.get("DATA")).isEqualTo(ByteBuffer.wrap("Test".getBytes()));
+            assertThat(after.get("DATA2")).isEqualTo(ByteBuffer.wrap("T".getBytes()));
             assertThat(after.get("NAME")).isEqualTo("Acme 123");
 
             assertNoRecordsToConsume();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -68,7 +68,7 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
 
     protected final static int DEFAULT_TRANSACTION_EVENTS_THRESHOLD = 0;
 
-    protected final static int DEFAULT_QUERY_FETCH_SIZE = 2_000;
+    protected final static int DEFAULT_QUERY_FETCH_SIZE = 10_000;
 
     protected final static Duration MAX_SLEEP_TIME = Duration.ofMillis(3_000);
     protected final static Duration DEFAULT_SLEEP_TIME = Duration.ofMillis(1_000);
@@ -684,6 +684,7 @@ public OracleConnectorConfig(Configuration config) {
                 new SystemTablesPredicate(config),
                 x -> x.schema() + "." + x.table(),
                 true,
+                DEFAULT_QUERY_FETCH_SIZE,
                 ColumnFilterMode.SCHEMA,
                 false);
 

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorConfigTest.java
Patch:
@@ -157,7 +157,7 @@ public void validQueryFetchSizeDefaults() throws Exception {
                 Configuration.create()
                         .with(CommonConnectorConfig.TOPIC_PREFIX, "myserver")
                         .build());
-        assertEquals(connectorConfig.getQueryFetchSize(), 2_000);
+        assertEquals(connectorConfig.getQueryFetchSize(), 10_000);
     }
 
     @Test
@@ -166,9 +166,9 @@ public void validQueryFetchSizeAvailable() throws Exception {
         final OracleConnectorConfig connectorConfig = new OracleConnectorConfig(
                 Configuration.create()
                         .with(CommonConnectorConfig.TOPIC_PREFIX, "myserver")
-                        .with(OracleConnectorConfig.QUERY_FETCH_SIZE, 10_000)
+                        .with(OracleConnectorConfig.QUERY_FETCH_SIZE, 15_000)
                         .build());
-        assertEquals(connectorConfig.getQueryFetchSize(), 10_000);
+        assertEquals(connectorConfig.getQueryFetchSize(), 15_000);
     }
 
     @Test

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/SinkRecordDescriptor.java
Patch:
@@ -208,9 +208,9 @@ public String getTypeName() {
             return typeName;
         }
 
-        public String getQueryBinding(ColumnDescriptor column) {
+        public String getQueryBinding(ColumnDescriptor column, Object value) {
             if (queryBinding == null) {
-                queryBinding = type.getQueryBinding(column, schema);
+                queryBinding = type.getQueryBinding(column, schema, value);
             }
             return queryBinding;
         }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/GeometryType.java
Patch:
@@ -18,8 +18,8 @@ public class GeometryType extends AbstractGeoType {
     public static final Type INSTANCE = new GeometryType();
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
-        return "ST_GeomFromWKB(?, ?)";
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
+        return value == null ? "?" : "ST_GeomFromWKB(?, ?)";
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/JsonType.java
Patch:
@@ -28,7 +28,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as json)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/MapToJsonType.java
Patch:
@@ -32,8 +32,8 @@ class MapToJsonType extends AbstractConnectMapType {
     public static final MapToJsonType INSTANCE = new MapToJsonType();
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
-        return JsonType.INSTANCE.getQueryBinding(column, schema);
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
+        return JsonType.INSTANCE.getQueryBinding(column, schema, value);
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/BitType.java
Patch:
@@ -34,7 +34,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         if (isBitOne(schema)) {
             final Optional<String> columnType = getSourceColumnType(schema);
             if (columnType.isPresent() && "BIT".equals(columnType.get())) {

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/CaseInsensitiveTextType.java
Patch:
@@ -27,7 +27,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as citext)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/CidrType.java
Patch:
@@ -27,7 +27,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as cidr)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/GeometryType.java
Patch:
@@ -30,8 +30,8 @@ public void configure(JdbcSinkConnectorConfig config, DatabaseDialect dialect) {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
-        return String.format(GEO_FROM_WKB_FUNCTION, postgisSchema);
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
+        return value == null ? "?" : String.format(GEO_FROM_WKB_FUNCTION, postgisSchema);
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/InetType.java
Patch:
@@ -27,7 +27,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as inet)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/IntervalType.java
Patch:
@@ -29,7 +29,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as interval)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/JsonType.java
Patch:
@@ -29,7 +29,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         if (isHstore(schema)) {
             return "cast(? as hstore)";
             // return super.getQueryBinding(schema);

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/LtreeType.java
Patch:
@@ -27,7 +27,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as ltree)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/MacAddressType.java
Patch:
@@ -27,7 +27,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as macaddr)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/MapToHstoreType.java
Patch:
@@ -26,7 +26,7 @@ class MapToHstoreType extends AbstractConnectMapType {
     public static final MapToHstoreType INSTANCE = new MapToHstoreType();
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as hstore)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/MoneyType.java
Patch:
@@ -27,7 +27,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as money)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/PointType.java
Patch:
@@ -26,8 +26,8 @@ class PointType extends GeometryType {
     private static final String GEO_FROM_WKB_FUNCTION_AS_POINT = "cast(" + GEO_FROM_WKB_FUNCTION + " as point)";
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
-        return String.format(GEO_FROM_WKB_FUNCTION_AS_POINT, postgisSchema);
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
+        return value == null ? "?" : String.format(GEO_FROM_WKB_FUNCTION_AS_POINT, postgisSchema);
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/RangeType.java
Patch:
@@ -29,7 +29,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as " + getSourceColumnType(schema).orElseThrow() + ")";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/UuidType.java
Patch:
@@ -28,7 +28,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as uuid)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/XmlType.java
Patch:
@@ -28,7 +28,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as xml)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/sqlserver/BitType.java
Patch:
@@ -34,7 +34,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         if (Bits.LOGICAL_NAME.equals(schema.name())) {
             final int bitSize = Integer.parseInt(schema.parameters().get(Bits.LENGTH_FIELD));
             return String.format("cast(? as %s)", bitSize > 1 ? String.format("varbinary(%d)", bitSize) : "bit");

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/sqlserver/XmlType.java
Patch:
@@ -28,7 +28,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return "cast(? as xml)";
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/AbstractType.java
Patch:
@@ -35,7 +35,7 @@ public void configure(JdbcSinkConnectorConfig config, DatabaseDialect dialect) {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return getDialect().getQueryBindingWithValueCast(column, schema, this);
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/Type.java
Patch:
@@ -55,9 +55,10 @@ public interface Type {
      *
      * @param column column descriptor in the table relational model, never {@code null}
      * @param schema field schema, never {@code null}
+     * @param value value to be bound, may be {@code null}
      * @return query parameter argument binding SQL fragment
      */
-    String getQueryBinding(ColumnDescriptor column, Schema schema);
+    String getQueryBinding(ColumnDescriptor column, Schema schema, Object value);
 
     /**
      * Resolve the default value clause value.

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/connect/ConnectMapToConnectStringType.java
Patch:
@@ -25,8 +25,8 @@ public class ConnectMapToConnectStringType extends AbstractConnectMapType {
     public static final ConnectMapToConnectStringType INSTANCE = new ConnectMapToConnectStringType();
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
-        return ConnectStringType.INSTANCE.getQueryBinding(column, schema);
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
+        return ConnectStringType.INSTANCE.getQueryBinding(column, schema, value);
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/connect/ConnectTimeType.java
Patch:
@@ -35,7 +35,7 @@ public String[] getRegistrationKeys() {
     }
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return getDialect().getTimeQueryBinding();
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/AbstractDebeziumTimeType.java
Patch:
@@ -24,7 +24,7 @@
 public abstract class AbstractDebeziumTimeType extends AbstractTimeType {
 
     @Override
-    public String getQueryBinding(ColumnDescriptor column, Schema schema) {
+    public String getQueryBinding(ColumnDescriptor column, Schema schema, Object value) {
         return getDialect().getTimeQueryBinding();
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/PostgresDatabaseDialect.java
Patch:
@@ -158,6 +158,7 @@ protected void registerTypes() {
         registerType(EnumType.INSTANCE);
         registerType(PointType.INSTANCE);
         registerType(GeometryType.INSTANCE);
+        registerType(GeographyType.INSTANCE);
         registerType(MoneyType.INSTANCE);
         registerType(XmlType.INSTANCE);
         registerType(LtreeType.INSTANCE);

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/integration/mysql/JdbcSinkInsertModeIT.java
Patch:
@@ -85,6 +85,7 @@ public void testInsertModeInsertWithPrimaryKeyModeComplexRecordValue(SinkRecordF
         getSink().assertColumnType(tableAssert, "id", ValueType.NUMBER, (byte) 1);
 
         // ST_GeomFromText('POLYGON ((0 5, 2 5, 2 7, 0 7, 0 5))', 3187)
+
         getSink().assertColumnType(tableAssert, "geometry", ValueType.BYTES, DatatypeConverter
                 .parseHexBinary(
                         "730C000001030000000100000005000000000000000000000000000000000014400000000000000040000000000000144000000000000000400000000000001C4000000000000000000000000000001C4000000000000000000000000000001440"));

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/GeometryType.java
Patch:
@@ -3,7 +3,7 @@
  *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
-package io.debezium.connector.jdbc.type.debezium;
+package io.debezium.connector.jdbc.dialect.mysql;
 
 import java.util.Base64;
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/MySqlDatabaseDialect.java
Patch:
@@ -27,8 +27,6 @@
 import io.debezium.connector.jdbc.dialect.GeneralDatabaseDialect;
 import io.debezium.connector.jdbc.dialect.SqlStatementBuilder;
 import io.debezium.connector.jdbc.relational.TableDescriptor;
-import io.debezium.connector.jdbc.type.debezium.GeometryType;
-import io.debezium.connector.jdbc.type.debezium.PointType;
 import io.debezium.time.ZonedTimestamp;
 import io.debezium.util.Strings;
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/PointType.java
Patch:
@@ -3,7 +3,7 @@
  *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
-package io.debezium.connector.jdbc.type.debezium;
+package io.debezium.connector.jdbc.dialect.mysql;
 
 import org.apache.kafka.connect.data.Schema;
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/PostgresDatabaseDialect.java
Patch:
@@ -157,6 +157,7 @@ protected void registerTypes() {
         registerType(UuidType.INSTANCE);
         registerType(EnumType.INSTANCE);
         registerType(PointType.INSTANCE);
+        registerType(GeometryType.INSTANCE);
         registerType(MoneyType.INSTANCE);
         registerType(XmlType.INSTANCE);
         registerType(LtreeType.INSTANCE);

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/junit/PostgresExtensionUtils.java
Patch:
@@ -55,7 +55,6 @@ public static void createExtension(Sink sink, String extensionName) throws Excep
                 sink.execute("DROP SCHEMA IF EXISTS postgis CASCADE");
                 sink.execute("CREATE SCHEMA postgis");
                 sink.execute("CREATE EXTENSION IF NOT EXISTS postgis SCHEMA postgis");
-                sink.execute("CREATE TYPE geometry AS (udt postgis.geometry)");
             }
             else {
                 sink.execute("CREATE EXTENSION " + extensionName);

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/SinkRecordDescriptor.java
Patch:
@@ -215,8 +215,8 @@ public String getQueryBinding(ColumnDescriptor column) {
             return queryBinding;
         }
 
-        public void bind(NativeQuery<?> query, int startIndex, Object value) {
-            type.bind(query, startIndex, schema, value);
+        public int bind(NativeQuery<?> query, int startIndex, Object value) {
+            return type.bind(query, startIndex, schema, value);
         }
 
         @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/MapToJsonType.java
Patch:
@@ -42,7 +42,7 @@ public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value instanceof Map) {
             try {
                 value = OBJECT_MAPPER.writeValueAsString(value);
@@ -51,7 +51,7 @@ public void bind(Query<?> query, int index, Schema schema, Object value) {
                 throw new ConnectException("Failed to deserialize MAP data to JSON", e);
             }
         }
-        JsonType.INSTANCE.bind(query, index, schema, value);
+        return JsonType.INSTANCE.bind(query, index, schema, value);
     }
 
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/MySqlDatabaseDialect.java
Patch:
@@ -15,7 +15,6 @@
 import java.util.List;
 import java.util.Optional;
 
-import io.debezium.connector.jdbc.type.debezium.GeometryType;
 import org.hibernate.SessionFactory;
 import org.hibernate.StatelessSession;
 import org.hibernate.dialect.Dialect;
@@ -28,6 +27,8 @@
 import io.debezium.connector.jdbc.dialect.GeneralDatabaseDialect;
 import io.debezium.connector.jdbc.dialect.SqlStatementBuilder;
 import io.debezium.connector.jdbc.relational.TableDescriptor;
+import io.debezium.connector.jdbc.type.debezium.GeometryType;
+import io.debezium.connector.jdbc.type.debezium.PointType;
 import io.debezium.time.ZonedTimestamp;
 import io.debezium.util.Strings;
 
@@ -111,6 +112,7 @@ protected void registerTypes() {
         registerType(JsonType.INSTANCE);
         registerType(MapToJsonType.INSTANCE);
         registerType(GeometryType.INSTANCE);
+        registerType(PointType.INSTANCE);
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/BitType.java
Patch:
@@ -74,7 +74,7 @@ public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -91,6 +91,7 @@ else if (isBitOne(schema) && (value instanceof Boolean)) {
                 query.setParameter(index, Strings.justifyRight(binaryBitString, length, '0'));
             }
         }
+        return 1;
     }
 
     private boolean isBitOne(Schema schema) {

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/IntervalType.java
Patch:
@@ -49,13 +49,15 @@ public String getDefaultValueBinding(DatabaseDialect dialect, Schema schema, Obj
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value != null && Long.class.isAssignableFrom(value.getClass())) {
             final double doubleValue = ((Long) value).doubleValue() / 1_000_000d;
             query.setParameter(index, ((long) doubleValue) + " seconds");
         }
         else {
             query.setParameter(index, value);
         }
+
+        return 1;
     }
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/JsonType.java
Patch:
@@ -43,11 +43,11 @@ public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (isHstore(schema)) {
             value = HstoreConverter.jsonToString((String) value);
         }
-        super.bind(query, index, schema, value);
+        return super.bind(query, index, schema, value);
     }
 
     private String resolveType(Schema schema) {

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/MapToHstoreType.java
Patch:
@@ -38,8 +38,8 @@ public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {
 
     @Override
     @SuppressWarnings("unchecked")
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
-        super.bind(query, index, schema, HstoreConverter.mapToString((Map<String, String>) value));
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
+        return super.bind(query, index, schema, HstoreConverter.mapToString((Map<String, String>) value));
     }
 
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/PointType.java
Patch:
@@ -40,7 +40,7 @@ public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -50,5 +50,7 @@ public void bind(Query<?> query, int index, Schema schema, Object value) {
             final double y = struct.getFloat64(Point.Y_FIELD);
             query.setParameter(index, String.format("(%f,%f)", x, y));
         }
+
+        return 1;
     }
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/RangeType.java
Patch:
@@ -39,7 +39,9 @@ public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         query.setParameter(index, value == null ? null : ((String) value).replaceAll("\"", ""));
+
+        return 1;
     }
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/sqlserver/BitType.java
Patch:
@@ -60,7 +60,7 @@ public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -71,5 +71,6 @@ else if (value instanceof byte[]) {
         else {
             throwUnexpectedValue(value);
         }
+        return 1;
     }
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/Type.java
Patch:
@@ -76,6 +76,7 @@ public interface Type {
      * @param index parameter index to bind
      * @param schema field schema, never {@code null}
      * @param value value to be bound, may be {@code null}
+     * @return the number of bound parameters
      */
-    void bind(Query<?> query, int index, Schema schema, Object value);
+    int bind(Query<?> query, int index, Schema schema, Object value);
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/connect/ConnectDateType.java
Patch:
@@ -34,7 +34,7 @@ public String getDefaultValueBinding(DatabaseDialect dialect, Schema schema, Obj
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -44,6 +44,8 @@ else if (value instanceof java.util.Date) {
         else {
             throwUnexpectedValue(value);
         }
+
+        return 1;
     }
 
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/connect/ConnectMapToConnectStringType.java
Patch:
@@ -40,11 +40,12 @@ public String getDefaultValueBinding(DatabaseDialect dialect, Schema schema, Obj
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value instanceof Map) {
             value = mapToJsonString(value);
         }
         ConnectStringType.INSTANCE.bind(query, index, schema, value);
+        return 1;
     }
 
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/connect/ConnectTimeType.java
Patch:
@@ -45,7 +45,7 @@ public String getDefaultValueBinding(DatabaseDialect dialect, Schema schema, Obj
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -67,6 +67,7 @@ else if (value instanceof Date) {
         else {
             throwUnexpectedValue(value);
         }
+        return 1;
     }
 
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/connect/ConnectTimestampType.java
Patch:
@@ -38,7 +38,7 @@ public String getDefaultValueBinding(DatabaseDialect dialect, Schema schema, Obj
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -54,6 +54,7 @@ else if (value instanceof java.util.Date) {
         else {
             throwUnexpectedValue(value);
         }
+        return 1;
     }
 
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/AbstractDebeziumTimeType.java
Patch:
@@ -38,7 +38,7 @@ public String getDefaultValueBinding(DatabaseDialect dialect, Schema schema, Obj
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -55,6 +55,7 @@ else if (value instanceof Number) {
         else {
             throwUnexpectedValue(value);
         }
+        return 1;
     }
 
     protected abstract LocalTime getLocalTime(Number value);

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/AbstractDebeziumTimestampType.java
Patch:
@@ -20,7 +20,7 @@
 public abstract class AbstractDebeziumTimestampType extends AbstractTimestampType {
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -36,6 +36,8 @@ else if (value instanceof Number) {
         else {
             throwUnexpectedValue(value);
         }
+
+        return 1;
     }
 
     protected abstract LocalDateTime getLocalDateTime(long value);

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/DateType.java
Patch:
@@ -34,7 +34,7 @@ public String getDefaultValueBinding(DatabaseDialect dialect, Schema schema, Obj
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -44,6 +44,8 @@ else if (value instanceof Number) {
         else {
             throwUnexpectedValue(value);
         }
+
+        return 1;
     }
 
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/VariableScaleDecimalType.java
Patch:
@@ -41,7 +41,7 @@ public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -52,6 +52,7 @@ else if (value instanceof Struct) {
         else {
             throwUnexpectedValue(value);
         }
+        return 1;
     }
 
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/ZonedTimeType.java
Patch:
@@ -62,7 +62,7 @@ public String getDefaultValueBinding(DatabaseDialect dialect, Schema schema, Obj
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -83,6 +83,8 @@ else if (value instanceof String) {
         else {
             throwUnexpectedValue(value);
         }
+
+        return 1;
     }
 
     protected void bindWithNoTimeZoneDetails(Query<?> query, int index, ZonedDateTime zonedDateTime) {

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/debezium/ZonedTimestampType.java
Patch:
@@ -37,7 +37,7 @@ public String getDefaultValueBinding(DatabaseDialect dialect, Schema schema, Obj
     }
 
     @Override
-    public void bind(Query<?> query, int index, Schema schema, Object value) {
+    public int bind(Query<?> query, int index, Schema schema, Object value) {
         if (value == null) {
             query.setParameter(index, null);
         }
@@ -49,6 +49,8 @@ else if (value instanceof String) {
         else {
             throwUnexpectedValue(value);
         }
+
+        return 1;
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/MySqlDatabaseDialect.java
Patch:
@@ -15,6 +15,7 @@
 import java.util.List;
 import java.util.Optional;
 
+import io.debezium.connector.jdbc.type.debezium.GeometryType;
 import org.hibernate.SessionFactory;
 import org.hibernate.StatelessSession;
 import org.hibernate.dialect.Dialect;
@@ -109,6 +110,7 @@ protected void registerTypes() {
         registerType(YearType.INSTANCE);
         registerType(JsonType.INSTANCE);
         registerType(MapToJsonType.INSTANCE);
+        registerType(GeometryType.INSTANCE);
     }
 
     @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlValueConverters.java
Patch:
@@ -26,7 +26,6 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import org.apache.kafka.connect.data.Decimal;
 import org.apache.kafka.connect.data.Field;
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
@@ -43,6 +42,7 @@
 import io.debezium.config.CommonConnectorConfig.BinaryHandlingMode;
 import io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser;
 import io.debezium.data.Json;
+import io.debezium.data.SpecialValueDecimal;
 import io.debezium.jdbc.JdbcValueConverters;
 import io.debezium.jdbc.TemporalPrecisionMode;
 import io.debezium.relational.Column;
@@ -208,7 +208,7 @@ public SchemaBuilder schemaBuilder(Column column) {
                 case PRECISE:
                     // In order to capture unsigned INT 64-bit data source, org.apache.kafka.connect.data.Decimal:Byte will be required to safely capture all valid values with scale of 0
                     // Source: https://kafka.apache.org/0102/javadoc/org/apache/kafka/connect/data/Schema.Type.html
-                    return Decimal.builder(0);
+                    return SpecialValueDecimal.builder(DecimalMode.PRECISE, 20, 0);
             }
         }
         if ((matches(typeName, "FLOAT")

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorTask.java
Patch:
@@ -97,7 +97,7 @@ public ChangeEventSourceCoordinator<MongoDbPartition, MongoDbOffsetContext> star
                     .loggingContextSupplier(() -> taskContext.configureLoggingContext(CONTEXT_NAME))
                     .build();
 
-            errorHandler = new MongoDbErrorHandler(connectorConfig, queue);
+            errorHandler = new MongoDbErrorHandler(connectorConfig, queue, errorHandler);
 
             final MongoDbEventMetadataProvider metadataProvider = new MongoDbEventMetadataProvider();
 

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbErrorHandler.java
Patch:
@@ -21,8 +21,8 @@
  */
 public class MongoDbErrorHandler extends ErrorHandler {
 
-    public MongoDbErrorHandler(MongoDbConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {
-        super(MongoDbConnector.class, connectorConfig, queue);
+    public MongoDbErrorHandler(MongoDbConnectorConfig connectorConfig, ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {
+        super(MongoDbConnector.class, connectorConfig, queue, replacedErrorHandler);
     }
 
     @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -137,7 +137,7 @@ public ChangeEventSourceCoordinator<MySqlPartition, MySqlOffsetContext> start(Co
                 .buffering()
                 .build();
 
-        errorHandler = new MySqlErrorHandler(connectorConfig, queue);
+        errorHandler = new MySqlErrorHandler(connectorConfig, queue, errorHandler);
 
         final MySqlEventMetadataProvider metadataProvider = new MySqlEventMetadataProvider();
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlErrorHandler.java
Patch:
@@ -20,8 +20,8 @@
  */
 public class MySqlErrorHandler extends ErrorHandler {
 
-    public MySqlErrorHandler(MySqlConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {
-        super(MySqlConnector.class, connectorConfig, queue);
+    public MySqlErrorHandler(MySqlConnectorConfig connectorConfig, ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {
+        super(MySqlConnector.class, connectorConfig, queue, replacedErrorHandler);
     }
 
     @Override

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorTask.java
Patch:
@@ -95,7 +95,7 @@ public ChangeEventSourceCoordinator<OraclePartition, OracleOffsetContext> start(
                 .loggingContextSupplier(() -> taskContext.configureLoggingContext(CONTEXT_NAME))
                 .build();
 
-        errorHandler = new OracleErrorHandler(connectorConfig, queue);
+        errorHandler = new OracleErrorHandler(connectorConfig, queue, errorHandler);
 
         final OracleEventMetadataProvider metadataProvider = new OracleEventMetadataProvider();
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleErrorHandler.java
Patch:
@@ -52,8 +52,8 @@ public class OracleErrorHandler extends ErrorHandler {
             "failed to exclusively lock system dictionary" // nested ORA-01327
     );
 
-    public OracleErrorHandler(OracleConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {
-        super(OracleConnector.class, connectorConfig, queue);
+    public OracleErrorHandler(OracleConnectorConfig connectorConfig, ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {
+        super(OracleConnector.class, connectorConfig, queue, replacedErrorHandler);
     }
 
     @Override

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorTask.java
Patch:
@@ -64,6 +64,8 @@ public class PostgresConnectorTask extends BaseSourceTask<PostgresPartition, Pos
     private volatile ChangeEventQueue<DataChangeEvent> queue;
     private volatile PostgresConnection jdbcConnection;
     private volatile ReplicationConnection replicationConnection = null;
+
+    private volatile ErrorHandler errorHandler;
     private volatile PostgresSchema schema;
 
     @Override
@@ -172,7 +174,7 @@ public ChangeEventSourceCoordinator<PostgresPartition, PostgresOffsetContext> st
                     .loggingContextSupplier(() -> taskContext.configureLoggingContext(CONTEXT_NAME))
                     .build();
 
-            ErrorHandler errorHandler = new PostgresErrorHandler(connectorConfig, queue);
+            errorHandler = new PostgresErrorHandler(connectorConfig, queue, errorHandler);
 
             final PostgresEventMetadataProvider metadataProvider = new PostgresEventMetadataProvider();
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresErrorHandler.java
Patch:
@@ -20,8 +20,8 @@
  */
 public class PostgresErrorHandler extends ErrorHandler {
 
-    public PostgresErrorHandler(PostgresConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {
-        super(PostgresConnector.class, connectorConfig, queue);
+    public PostgresErrorHandler(PostgresConnectorConfig connectorConfig, ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {
+        super(PostgresConnector.class, connectorConfig, queue, replacedErrorHandler);
     }
 
     @Override

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresErrorHandlerTest.java
Patch:
@@ -24,7 +24,7 @@ public class PostgresErrorHandlerTest {
             new PostgresConnectorConfig(Configuration.create()
                     .with(CommonConnectorConfig.TOPIC_PREFIX, "postgres")
                     .build()),
-            new ChangeEventQueue.Builder<DataChangeEvent>().build());
+            new ChangeEventQueue.Builder<DataChangeEvent>().build(), null);
 
     @Test
     public void classifiedPSQLExceptionIsRetryable() {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/xstream/ChunkColumnValues.java
Patch:
@@ -124,6 +124,7 @@ private int calculateChunkSize(ChunkColumnValue chunkColumnValue) {
                 case ChunkColumnValue.NCLOB:
                 case ChunkColumnValue.XMLTYPE:
                     return chunkColumnValue.getColumnData().stringValue().length();
+                case ChunkColumnValue.RAW:
                 case ChunkColumnValue.BLOB:
                     return chunkColumnValue.getColumnData().getBytes().length;
                 default:

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/xstream/LcrEventHandler.java
Patch:
@@ -399,6 +399,7 @@ private void resolveAndDispatchCurrentChunkedRow() {
                         resolvedChunkValues.put(columnName, chunkValues.getXmlValue());
                         break;
 
+                    case ChunkColumnValue.RAW:
                     case ChunkColumnValue.BLOB:
                         resolvedChunkValues.put(columnName, chunkValues.getByteArray());
                         break;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerChangeRecordEmitter.java
Patch:
@@ -42,6 +42,7 @@ private static Operation getOperation(EventType eventType) {
                 return Operation.CREATE;
             case UPDATE:
             case SELECT_LOB_LOCATOR:
+            case XML_BEGIN:
                 return Operation.UPDATE;
             case DELETE:
                 return Operation.DELETE;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerQueryBuilder.java
Patch:
@@ -35,7 +35,7 @@ public class LogMinerQueryBuilder {
     private static final String UNKNOWN_USERNAME = "UNKNOWN";
     private static final String UNKNOWN_SCHEMA_NAME = "UNKNOWN";
     private static final String UNKNOWN_TABLE_NAME_PREFIX = "OBJ#";
-    private static final List<Integer> OPERATION_CODES_LOB = Arrays.asList(1, 2, 3, 6, 7, 9, 10, 11, 29, 34, 36, 255);
+    private static final List<Integer> OPERATION_CODES_LOB = Arrays.asList(1, 2, 3, 6, 7, 9, 10, 11, 29, 34, 36, 68, 70, 71, 255);
     private static final List<Integer> OPERATION_CODES_NO_LOB = Arrays.asList(1, 2, 3, 6, 7, 34, 36, 255);
 
     /**

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/events/EventType.java
Patch:
@@ -23,6 +23,9 @@ public enum EventType {
     LOB_ERASE(29),
     MISSING_SCN(34),
     ROLLBACK(36),
+    XML_BEGIN(68),
+    XML_WRITE(70),
+    XML_END(71),
     UNSUPPORTED(255);
 
     private static EventType[] types = new EventType[256];

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/parser/ParserUtils.java
Patch:
@@ -33,7 +33,7 @@ public static void setColumnUnavailableValues(Object[] columnValues, Table table
     /**
      * Resolve the column value for a given column value and column instance.
      * <p>
-     * If the column value is {@code null} and the column is an LOB-based column, this method will
+     * If the column value is {@code null} and the column is an LOB or XML-based column, this method will
      * resolve the final column value as {@link OracleValueConverters#UNAVAILABLE_VALUE}, a value
      * that represents that the column should be emitted with the unavailable value placeholder.
      * <p>
@@ -45,7 +45,7 @@ public static void setColumnUnavailableValues(Object[] columnValues, Table table
      * @return the resolved column's value
      */
     public static Object getColumnUnavailableValue(Object value, Column column) {
-        if (value == null && OracleDatabaseSchema.isLobColumn(column)) {
+        if (value == null && (OracleDatabaseSchema.isLobColumn(column) || OracleDatabaseSchema.isXmlColumn(column))) {
             return OracleValueConverters.UNAVAILABLE_VALUE;
         }
         return value;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/infinispan/marshalling/LogMinerEventMarshaller.java
Patch:
@@ -16,6 +16,7 @@
  * @author Chris Cranford
  */
 @AutoProtoSchemaBuilder(includeClasses = { LogMinerEventAdapter.class, DmlEventAdapter.class, SelectLobLocatorEventAdapter.class, LobWriteEventAdapter.class,
-        LobEraseEventAdapter.class, LogMinerDmlEntryImplAdapter.class, TruncateEventAdapter.class }, schemaFilePath = "/")
+        LobEraseEventAdapter.class, LogMinerDmlEntryImplAdapter.class, TruncateEventAdapter.class, XmlBeginEventAdapter.class, XmlWriteEventAdapter.class,
+        XmlEndEventAdapter.class }, schemaFilePath = "/")
 public interface LogMinerEventMarshaller extends SerializationContextInitializer {
 }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerQueryBuilderTest.java
Patch:
@@ -60,7 +60,7 @@ public class LogMinerQueryBuilderTest {
 
     private static final String PDB_PREDICATE = "SRC_CON_NAME = '${pdbName}'";
 
-    private static final String OPERATION_CODES_LOB_ENABLED = "1,2,3,6,7,9,10,11,29,34,36,255";
+    private static final String OPERATION_CODES_LOB_ENABLED = "1,2,3,6,7,9,10,11,29,34,36,68,70,71,255";
     private static final String OPERATION_CODES_LOB_DISABLED = "1,2,3,6,7,34,36,255";
 
     private static final String OPERATION_CODES_PREDICATE = "(OPERATION_CODE IN (${operationCodes})${operationDdl})";

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/ConfigProperties.java
Patch:
@@ -34,6 +34,7 @@ private ConfigProperties() {
 
     public static final String DOCKER_IMAGE_POSTGRESQL = System.getProperty("test.docker.image.postgresql", "quay.io/debezium/example-postgres:latest");
     public static final String DOCKER_IMAGE_MONGO = System.getProperty("test.docker.image.mongo", "quay.io/debezium/example-mongodb:latest");
+    public static final String DOCKER_IMAGE_MONGO_SHARDED = System.getProperty("test.docker.image.mongo.sharded", "quay.io/debezium/example-mongodb:latest");
     public static final String DOCKER_IMAGE_SQLSERVER = System.getProperty("test.docker.image.sqlserver", "mcr.microsoft.com/mssql/server:2019-latest");
     public static final String DOCKER_IMAGE_DB2 = System.getProperty("test.docker.image.db2", "quay.io/debezium/db2-cdc:latest");
     public static final String DOCKER_IMAGE_ORACLE = System.getProperty("test.docker.image.oracle", "quay.io/rh_integration/dbz-oracle:19.3.0");

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/assertions/PlainKafkaAssertions.java
Patch:
@@ -39,7 +39,7 @@ public void assertRecordsContain(String topic, String content) {
             consumer.subscribe(Collections.singleton(topic));
             consumer.seekToBeginning(consumer.assignment());
             ConsumerRecords<String, String> records = consumer.poll(Duration.of(10, ChronoUnit.SECONDS));
-            long matchingCount = StreamSupport.stream(records.records(topic).spliterator(), false).filter(r -> r.value().contains(content)).count();
+            long matchingCount = StreamSupport.stream(records.records(topic).spliterator(), false).filter(r -> r.value() != null && r.value().contains(content)).count();
             assertThat(matchingCount).withFailMessage("Topic '%s' doesn't have message containing <%s>.", topic, content).isGreaterThan(0);
         }
     }

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/databases/ocp/OcpMongo.java
Patch:
@@ -17,8 +17,8 @@
 @FixtureContext(requires = { OpenShiftClient.class }, provides = { MongoDatabaseController.class })
 public class OcpMongo extends OcpDatabaseFixture<MongoDatabaseController> {
 
-    public static final String DB_DEPLOYMENT_PATH = "/database-resources/mongodb/deployment.yaml";
-    public static final String DB_SERVICE_PATH = "/database-resources/mongodb/service.yaml";
+    public static final String DB_DEPLOYMENT_PATH = "/database-resources/mongodb/standalone/deployment.yaml";
+    public static final String DB_SERVICE_PATH = "/database-resources/mongodb/standalone/service.yaml";
 
     public OcpMongo(ExtensionContext.Store store) {
         super(MongoDatabaseController.class, store);

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mongodb/OcpMongoConnectorIT.java
Patch:
@@ -14,6 +14,7 @@
 import io.debezium.testing.system.fixtures.OcpClient;
 import io.debezium.testing.system.fixtures.connectors.MongoConnector;
 import io.debezium.testing.system.fixtures.databases.ocp.OcpMongo;
+import io.debezium.testing.system.fixtures.databases.ocp.OcpMongoSharded;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
 import io.debezium.testing.system.fixtures.operator.OcpStrimziOperator;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -31,9 +32,10 @@
 @Fixture(OcpStrimziOperator.class)
 @Fixture(OcpKafka.class)
 @Fixture(OcpMongo.class)
+@Fixture(OcpMongoSharded.class)
 @Fixture(MongoConnector.class)
 @ExtendWith(FixtureExtension.class)
-public class OcpMongoConnectorIT extends MongoTests {
+public class OcpMongoConnectorIT extends OcpMongoTests {
 
     public OcpMongoConnectorIT(KafkaController kafkaController,
                                KafkaConnectController connectController,

File: debezium-core/src/main/java/io/debezium/config/Configuration.java
Patch:
@@ -1444,7 +1444,7 @@ default Boolean getBoolean(Field field, BooleanSupplier defaultValueSupplier) {
     }
 
     /**
-     * Get the boolean value associated with the given key, using the given supplier to obtain a default value if there is no such
+     * Get the string value associated with the given key, using the given supplier to obtain a default value if there is no such
      * key-value pair.
      *
      * @param field the field

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleErrorHandler.java
Patch:
@@ -48,7 +48,8 @@ public class OracleErrorHandler extends ErrorHandler {
     @Immutable
     private static final Set<String> RETRIABLE_ERROR_MESSAGES = Collect.unmodifiableSet(
             "No more data to read from socket",
-            "immediate shutdown or close in progress" // nested ORA-01089
+            "immediate shutdown or close in progress", // nested ORA-01089
+            "failed to exclusively lock system dictionary" // nested ORA-01327
     );
 
     public OracleErrorHandler(OracleConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {

File: debezium-core/src/main/java/io/debezium/pipeline/notification/IncrementalSnapshotNotificationService.java
Patch:
@@ -23,6 +23,7 @@ public class IncrementalSnapshotNotificationService<P extends Partition, O exten
 
     public static final String INCREMENTAL_SNAPSHOT = "Incremental Snapshot";
     public static final String DATA_COLLECTIONS = "data_collections";
+    public static final String SCANNED_COLLECTION = "scanned_collection";
     public static final String CURRENT_COLLECTION_IN_PROGRESS = "current_collection_in_progress";
     public static final String MAXIMUM_KEY = "maximum_key";
     public static final String LAST_PROCESSED_KEY = "last_processed_key";
@@ -99,13 +100,15 @@ public <T extends DataCollectionId> void notifyAborted(IncrementalSnapshotContex
     public <T extends DataCollectionId> void notifyTableScanCompleted(IncrementalSnapshotContext<T> incrementalSnapshotContext, P partition, OffsetContext offsetContext,
                                                                       long totalRowsScanned, TableScanCompletionStatus status) {
 
+        String scannedCollection = incrementalSnapshotContext.currentDataCollectionId().getId().identifier();
         String dataCollections = incrementalSnapshotContext.getDataCollections().stream().map(DataCollection::getId)
                 .map(DataCollectionId::identifier)
                 .collect(Collectors.joining(LIST_DELIMITER));
 
         notificationService.notify(buildNotificationWith(incrementalSnapshotContext, SnapshotStatus.TABLE_SCAN_COMPLETED,
                 Map.of(
                         DATA_COLLECTIONS, dataCollections,
+                        SCANNED_COLLECTION, scannedCollection,
                         TOTAL_ROWS_SCANNED, String.valueOf(totalRowsScanned),
                         STATUS, status.name()),
                 offsetContext),

File: debezium-core/src/test/java/io/debezium/pipeline/notification/IncrementalSnapshotNotificationServiceTest.java
Patch:
@@ -126,6 +126,7 @@ public void notifyTableScanCompleted() {
         Notification expectedNotification = new Notification("12345", "Incremental Snapshot", "TABLE_SCAN_COMPLETED", Map.of(
                 "connector_name", "connector-test",
                 "data_collections", "db.inventory.product,db.inventory.customer",
+                "scanned_collection", "db.inventory.product",
                 "total_rows_scanned", "100",
                 "status", "SUCCEEDED"));
 

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectionIT.java
Patch:
@@ -453,8 +453,7 @@ public void testAccessToCDCTableBasedOnUserRoleAccess() throws Exception {
         }
 
         // Re-connect with the newly created user
-        try (SqlServerConnection connection = TestHelper.testConnection(
-                TestHelper.jdbcConfig("test_user", "Password!"))) {
+        try (SqlServerConnection connection = TestHelper.testConnection("test_user", "Password!")) {
             // This user shouldn't have access to CDC table
             connection.execute("USE testDB1");
             assertThat(connection.checkIfConnectedUserHasAccessToCDCTable(TestHelper.TEST_DATABASE_1)).isFalse();

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnection.java
Patch:
@@ -33,7 +33,6 @@
 import com.microsoft.sqlserver.jdbc.SQLServerDriver;
 
 import io.debezium.annotation.VisibleForTesting;
-import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.config.Field;
 import io.debezium.data.Envelope;
@@ -132,7 +131,7 @@ public SqlServerConnection(SqlServerJdbcConfiguration config, SqlServerValueConv
         super(config, createConnectionFactory(config, useSingleDatabase), OPENING_QUOTING_CHARACTER, CLOSING_QUOTING_CHARACTER);
 
         defaultValueConverter = new SqlServerDefaultValueConverter(this::connection, valueConverters);
-        this.queryFetchSize = config().getInteger(CommonConnectorConfig.QUERY_FETCH_SIZE);
+        this.queryFetchSize = config().getInteger(SqlServerConnectorConfig.QUERY_FETCH_SIZE);
 
         if (hasSkippedOperations(skippedOperations)) {
             Set<String> skippedOps = new HashSet<>();

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/AbstractTimeType.java
Patch:
@@ -6,6 +6,7 @@
 package io.debezium.connector.jdbc.type;
 
 import java.sql.Types;
+import java.time.LocalTime;
 import java.util.Optional;
 
 import org.apache.kafka.connect.data.Schema;
@@ -32,9 +33,9 @@ public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {
         // We use TIMESTAMP here even for source TIME types as Oracle will use DATE types for
         // such columns, and it only supports second-based precision.
         if (precision > 0 && precision <= dialect.getDefaultTimestampPrecision()) {
-            return dialect.getTypeName(Types.TIMESTAMP, Size.precision(precision));
+            return dialect.getTypeName(Types.TIME, Size.precision(precision));
         }
-        return dialect.getTypeName(Types.TIMESTAMP);
+        return dialect.getTypeName(Types.TIME);
     }
 
     protected int getTimePrecision(Schema schema) {

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/Type.java
Patch:
@@ -24,8 +24,9 @@ public interface Type {
      * Allows a type to perform initialization/configuration tasks based on user configs.
      *
      * @param config the JDBC sink connector's configuration, should not be {@code null}
+     * @param dialect the database dialect, should not be {@code null}
      */
-    void configure(JdbcSinkConnectorConfig config);
+    void configure(JdbcSinkConnectorConfig config, DatabaseDialect dialect);
 
     /**
      * Returns the names that this type will be mapped as.

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/e2e/JdbcSinkPipelineToDb2IT.java
Patch:
@@ -151,7 +151,7 @@ protected String getDateType() {
 
     @Override
     protected String getTimeType(Source source, boolean key, int precision) {
-        return "TIMESTAMP";
+        return "TIME";
     }
 
     @Override

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/e2e/JdbcSinkPipelineToOracleIT.java
Patch:
@@ -172,8 +172,7 @@ protected String getDateType() {
 
     @Override
     protected String getTimeType(Source source, boolean key, int precision) {
-        // Since precision data is not passed for keys; we'll use the default timestamp precision.
-        return String.format("TIMESTAMP(%d)", key || !source.getOptions().isColumnTypePropagated() ? 6 : precision);
+        return "DATE";
     }
 
     @Override

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/e2e/JdbcSinkPipelineToPostgresIT.java
Patch:
@@ -162,7 +162,7 @@ protected String getDateType() {
 
     @Override
     protected String getTimeType(Source source, boolean key, int precision) {
-        return "TIMESTAMP";
+        return "TIME";
     }
 
     @Override

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/e2e/JdbcSinkPipelineToSqlServerIT.java
Patch:
@@ -152,12 +152,12 @@ protected String getDateType() {
 
     @Override
     protected String getTimeType(Source source, boolean key, int precision) {
-        return "DATETIME2";
+        return "TIME";
     }
 
     @Override
     protected String getTimeWithTimezoneType() {
-        return "DATETIME";
+        return "DATETIMEOFFSET";
     }
 
     @Override

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/junit/jupiter/PostgresSinkDatabaseContextProvider.java
Patch:
@@ -35,7 +35,8 @@ public PostgresSinkDatabaseContextProvider() {
                 new PostgreSQLContainer<>(IMAGE_NAME)
                         .withNetwork(Network.newNetwork())
                         .withDatabaseName("test")
-                        .withEnv("TZ", TestHelper.getSinkTimeZone()));
+                        .withEnv("TZ", TestHelper.getSinkTimeZone())
+                        .withEnv("PGTZ", TestHelper.getSinkTimeZone()));
     }
 
     @Override

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/e2e/AbstractJdbcSinkPipelineIT.java
Patch:
@@ -15,7 +15,6 @@
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Timestamp;
-import java.time.LocalTime;
 import java.time.OffsetDateTime;
 import java.time.OffsetTime;
 import java.time.ZoneOffset;
@@ -1870,6 +1869,7 @@ public void testTimestampWithLocalTimeZoneDataType(Source source, Sink sink) thr
     @TestTemplate
     @SkipWhenSource(value = { SourceType.MYSQL, SourceType.ORACLE, SourceType.SQLSERVER }, reason = "No TIME(n) WITH TIME ZONE data type support")
     @SkipWhenSink(value = { SinkType.MYSQL }, reason = "MySQL has no support for TIME(n) with TIME ZONE support")
+    @SkipWhenSink(value = { SinkType.DB2 }, reason = "There is an issue with Daylight Savings Time")
     @WithTemporalPrecisionMode
     public void testTimeWithTimeZoneDataType(Source source, Sink sink) throws Exception {
         // Only test non-keys because Oracle does not permit timestamp with timezone as primary key columns

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/junit/jupiter/e2e/SkipWhenSink.java
Patch:
@@ -6,6 +6,7 @@
 package io.debezium.connector.jdbc.junit.jupiter.e2e;
 
 import java.lang.annotation.ElementType;
+import java.lang.annotation.Repeatable;
 import java.lang.annotation.Retention;
 import java.lang.annotation.RetentionPolicy;
 import java.lang.annotation.Target;
@@ -20,6 +21,7 @@
  */
 @Target({ ElementType.METHOD })
 @Retention(RetentionPolicy.RUNTIME)
+@Repeatable(SkipWhenSinks.class)
 public @interface SkipWhenSink {
     /**
      * Returns the connector types that will be excluded from the test template invocation matrix.

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcSinkConnectorTask.java
Patch:
@@ -94,7 +94,7 @@ public void put(Collection<SinkRecord> records) {
                 markNotProcessed(record);
 
                 // Capture failure
-                LOGGER.error("Failed to process record: {}", throwable.getMessage());
+                LOGGER.error("Failed to process record: {}", throwable.getMessage(), throwable);
                 previousPutException = throwable;
 
                 // Stash any remaining records

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/GeneralDatabaseDialect.java
Patch:
@@ -535,6 +535,7 @@ protected void registerTypes() {
     }
 
     protected void registerType(Type type) {
+        type.configure(connectorConfig);
         for (String key : type.getRegistrationKeys()) {
             final Type existing = typeRegistry.put(key, type);
             if (existing != null) {

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/AbstractTimeType.java
Patch:
@@ -18,7 +18,7 @@
  *
  * @author Chris Cranford
  */
-public abstract class AbstractTimeType extends AbstractType {
+public abstract class AbstractTimeType extends AbstractTemporalType {
 
     @Override
     public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/AbstractTimestampType.java
Patch:
@@ -14,7 +14,7 @@
  *
  * @author Chris Cranford
  */
-public abstract class AbstractTimestampType extends AbstractType {
+public abstract class AbstractTimestampType extends AbstractTemporalType {
     protected int getTimePrecision(Schema schema) {
         final String length = getSourceColumnSize(schema).orElse("0");
         final Optional<String> scale = getSourceColumnPrecision(schema);

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/junit/jupiter/PostgresSinkDatabaseContextProvider.java
Patch:
@@ -15,6 +15,7 @@
 import org.testcontainers.utility.DockerImageName;
 
 import io.debezium.connector.jdbc.junit.PostgresExtensionUtils;
+import io.debezium.connector.jdbc.junit.TestHelper;
 
 /**
  * An implementation of {@link AbstractSinkDatabaseContextProvider} for PostgreSQL.
@@ -33,7 +34,8 @@ public PostgresSinkDatabaseContextProvider() {
         super(SinkType.POSTGRES,
                 new PostgreSQLContainer<>(IMAGE_NAME)
                         .withNetwork(Network.newNetwork())
-                        .withDatabaseName("test"));
+                        .withDatabaseName("test")
+                        .withEnv("TZ", TestHelper.getSinkTimeZone()));
     }
 
     @Override

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleValueConverters.java
Patch:
@@ -746,8 +746,8 @@ private void convertOracleIntervalDaySecond(Object data, ResultReceiver r) {
         if (m.matches()) {
             final int sign = "-".equals(m.group(1)) ? -1 : 1;
             if (intervalHandlingMode == OracleConnectorConfig.IntervalHandlingMode.STRING) {
-                double seconds = (double) (sign * Integer.parseInt(m.group(5)))
-                        + (double) Integer.parseInt(Strings.pad(m.group(6), 6, '0')) / 1_000_000D;
+                double seconds = sign * ((double) (Integer.parseInt(m.group(5)))
+                        + (double) Integer.parseInt(Strings.pad(m.group(6), 6, '0')) / 1_000_000D);
                 r.deliver(Interval.toIsoString(
                         0,
                         0,

File: debezium-core/src/main/java/io/debezium/transforms/partitions/PartitionRouting.java
Patch:
@@ -189,7 +189,7 @@ private Optional<Object> toValue(String fieldName, Struct envelope) {
             String[] subFields = Arrays.stream(fieldName.split(NESTING_SEPARATOR)).map(String::trim).toArray(String[]::new);
 
             if (subFields.length == 1) {
-                return Optional.of(envelope.get(subFields[0]));
+                return Optional.ofNullable(envelope.get(subFields[0]));
             }
 
             Struct lastStruct = getLastStruct(envelope, subFields);

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcSinkConnectorTask.java
Patch:
@@ -12,7 +12,6 @@
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.concurrent.locks.ReentrantLock;
 
-import io.debezium.util.Strings;
 import org.apache.kafka.clients.consumer.OffsetAndMetadata;
 import org.apache.kafka.common.TopicPartition;
 import org.apache.kafka.connect.errors.ConnectException;
@@ -23,6 +22,7 @@
 import org.slf4j.LoggerFactory;
 
 import io.debezium.pipeline.sink.spi.ChangeEventSink;
+import io.debezium.util.Strings;
 
 /**
  * The main task executing streaming from sink connector.
@@ -194,7 +194,7 @@ private String getOriginalTopicName(SinkRecord record) {
         if (record instanceof InternalSinkRecord) {
             return ((InternalSinkRecord) record).originalRecord().topic();
         }
-        return  null;
+        return null;
     }
 
 }

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/GeneralDatabaseDialect.java
Patch:
@@ -137,9 +137,8 @@ else if (parts.length == 1) {
     @Override
     public boolean tableExists(Connection connection, TableId tableId) throws SQLException {
         if (isIdentifierUppercaseWhenNotQuoted() && !getConfig().isQuoteIdentifiers()) {
-            tableId.toUpperCase();
+            tableId = tableId.toUpperCase();
         }
-
         final DatabaseMetaData metadata = connection.getMetaData();
         try (ResultSet rs = metadata.getTables(tableId.getCatalogName(), tableId.getSchemaName(), tableId.getTableName(), null)) {
             return rs.next();

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SnapshotSourceIT.java
Patch:
@@ -665,7 +665,7 @@ public void shouldCreateSnapshotSchemaOnlyRecovery() throws Exception {
     public void shouldSnapshotTablesInOrderSpecifiedInTableIncludeList() throws Exception {
         config = simpleConfig()
                 .with(MySqlConnectorConfig.TABLE_INCLUDE_LIST,
-                        "connector_test_ro_(.*).orders,connector_test_ro_(.*).Products,connector_test_ro_(.*).products_on_hand,connector_test_ro_(.*).dbz_342_timetest")
+                        "connector_test_ro_(.*).orders,connector_test_ro_(.*).Products,connector_test_ro_(.*).products_on_hand,connector_test_ro_(.*).dbz_342_timetest,connector_test_ro_(.*).orders_with_postfix")
                 .build();
         // Start the connector ...
         start(MySqlConnector.class, config);
@@ -674,7 +674,7 @@ public void shouldSnapshotTablesInOrderSpecifiedInTableIncludeList() throws Exce
         // Poll for records ...
         // Testing.Print.enable();
         LinkedHashSet<String> tablesInOrder = new LinkedHashSet<>();
-        LinkedHashSet<String> tablesInOrderExpected = getTableNamesInSpecifiedOrder("orders", "Products", "products_on_hand", "dbz_342_timetest");
+        LinkedHashSet<String> tablesInOrderExpected = getTableNamesInSpecifiedOrder("orders", "Products", "products_on_hand", "dbz_342_timetest", "orders_with_postfix");
         SourceRecords sourceRecords = consumeRecordsByTopic(9 + 9 + 5 + 1);
         sourceRecords.allRecordsInOrder().forEach(record -> {
             VerifyRecord.isValid(record);

File: debezium-core/src/main/java/io/debezium/relational/RelationalSnapshotChangeEventSource.java
Patch:
@@ -235,7 +235,7 @@ protected void connectionPoolConnectionCreated(RelationalSnapshotContext<P, O> s
     private Stream<TableId> toTableIds(Set<TableId> tableIds, Pattern pattern) {
         return tableIds
                 .stream()
-                .filter(tid -> pattern.asPredicate().test(connectorConfig.getTableIdMapper().toString(tid)))
+                .filter(tid -> pattern.asMatchPredicate().test(connectorConfig.getTableIdMapper().toString(tid)))
                 .sorted();
     }
 

File: debezium-core/src/main/java/io/debezium/transforms/partitions/PartitionRouting.java
Patch:
@@ -194,7 +194,7 @@ private Optional<Object> toValue(String fieldName, Struct envelope) {
 
             Struct lastStruct = getLastStruct(envelope, subFields);
 
-            return Optional.of(lastStruct.get(subFields[subFields.length - 1]));
+            return Optional.ofNullable(lastStruct.get(subFields[subFields.length - 1]));
         }
         catch (DataException e) {
             LOGGER.trace("Field {} not found on payload {}. It will not be considered", fieldName, envelope);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ReplicationMessageColumnValueResolver.java
Patch:
@@ -168,6 +168,8 @@ public static Object resolveValue(String columnName, PostgresType type, String f
             case "int4range":
             case "numrange":
             case "int8range":
+            case "ltree":
+            case "isbn":
                 return value.asString();
 
             // catch-all for other known/builtin PG types

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -918,7 +918,7 @@ protected List<SchemaAndValueField> schemasAndValuesForCustomTypes() {
         final Schema ltreeSchema = Ltree.builder().optional().build();
         final Schema ltreeArraySchema = SchemaBuilder.array(ltreeSchema).optional().build();
         return Arrays.asList(new SchemaAndValueField("lt", ltreeSchema, "Top.Collections.Pictures.Astronomy.Galaxies"),
-                new SchemaAndValueField("i", Schema.BYTES_SCHEMA, ByteBuffer.wrap("0-393-04002-X".getBytes())),
+                new SchemaAndValueField("i", Schema.STRING_SCHEMA, "0-393-04002-X"),
                 new SchemaAndValueField("n", Schema.OPTIONAL_STRING_SCHEMA, null),
                 new SchemaAndValueField("lt_array", ltreeArraySchema, Arrays.asList("Ship.Frigate", "Ship.Destroyer")));
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -1492,7 +1492,7 @@ public void shouldCloseTxAfterTypeQuery() throws Exception {
 
         SourceRecord record = records.get(0);
         VerifyRecord.isValidInsert(record, PK_FIELD, 1);
-        final String isbn = new String(((Struct) record.value()).getStruct("after").getBytes("aa"));
+        final String isbn = new String(((Struct) record.value()).getStruct("after").getString("aa"));
         assertThat(isbn).isEqualTo("0-393-04002-X");
 
         TestHelper.assertNoOpenTransactions();

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -172,7 +172,7 @@ public void shouldLoadSchemaForExtensionPostgresTypes() throws Exception {
             schema.refresh(connection, false);
             assertTablesIncluded(TEST_TABLES);
             assertTableSchema("public.custom_table", "lt", Ltree.builder().optional().build());
-            assertTableSchema("public.custom_table", "i", Schema.BYTES_SCHEMA);
+            assertTableSchema("public.custom_table", "i", Schema.STRING_SCHEMA);
         }
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnection.java
Patch:
@@ -10,7 +10,6 @@
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.time.Instant;
-import java.time.OffsetDateTime;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -450,10 +449,10 @@ protected boolean isArchiveLogMode() {
      * @return an optional timestamp when the system change number occurred
      * @throws SQLException if a database exception occurred
      */
-    public Optional<OffsetDateTime> getScnToTimestamp(Scn scn) throws SQLException {
+    public Optional<Instant> getScnToTimestamp(Scn scn) throws SQLException {
         try {
             return queryAndMap("SELECT scn_to_timestamp('" + scn + "') FROM DUAL", rs -> rs.next()
-                    ? Optional.of(rs.getObject(1, OffsetDateTime.class))
+                    ? Optional.of(rs.getTimestamp(1).toInstant())
                     : Optional.empty());
         }
         catch (SQLException e) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSnapshotChangeEventSource.java
Patch:
@@ -9,7 +9,6 @@
 import java.sql.Savepoint;
 import java.sql.Statement;
 import java.time.Instant;
-import java.time.OffsetDateTime;
 import java.util.Collection;
 import java.util.List;
 import java.util.Optional;
@@ -228,12 +227,12 @@ protected SchemaChangeEvent getCreateTableEvent(RelationalSnapshotContext<Oracle
     @Override
     protected Instant getSnapshotSourceTimestamp(JdbcConnection jdbcConnection, OracleOffsetContext offset, TableId tableId) {
         try {
-            Optional<OffsetDateTime> snapshotTs = ((OracleConnection) jdbcConnection).getScnToTimestamp(offset.getScn());
+            Optional<Instant> snapshotTs = ((OracleConnection) jdbcConnection).getScnToTimestamp(offset.getScn());
             if (snapshotTs.isEmpty()) {
                 throw new ConnectException("Failed reading SCN timestamp from source database");
             }
 
-            return snapshotTs.get().toInstant();
+            return snapshotTs.get();
         }
         catch (SQLException e) {
             throw new ConnectException("Failed reading SCN timestamp from source database", e);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -701,9 +701,9 @@ private Scn calculateEndScn(OracleConnection connection, Scn startScn, Scn prevE
             if (prevEndScn != null) {
                 final Scn deltaScn = currentScn.subtract(prevEndScn);
                 if (deltaScn.compareTo(Scn.valueOf(connectorConfig.getLogMiningScnGapDetectionGapSizeMin())) > 0) {
-                    Optional<OffsetDateTime> prevEndScnTimestamp = connection.getScnToTimestamp(prevEndScn);
+                    Optional<Instant> prevEndScnTimestamp = connection.getScnToTimestamp(prevEndScn);
                     if (prevEndScnTimestamp.isPresent()) {
-                        Optional<OffsetDateTime> currentScnTimestamp = connection.getScnToTimestamp(currentScn);
+                        Optional<Instant> currentScnTimestamp = connection.getScnToTimestamp(currentScn);
                         if (currentScnTimestamp.isPresent()) {
                             long timeDeltaMs = ChronoUnit.MILLIS.between(prevEndScnTimestamp.get(), currentScnTimestamp.get());
                             if (timeDeltaMs < connectorConfig.getLogMiningScnGapDetectionTimeIntervalMaxMs()) {

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -627,7 +627,7 @@ public static FieldNameAdjustmentMode parse(String value) {
             .withType(Type.LONG)
             .withWidth(Width.SHORT)
             .withImportance(Importance.MEDIUM)
-            .withDefault(5L)
+            .withDefault(5000L)
             .withValidation(Field::isPositiveInteger)
             .withDescription("Interval for looking for new signals in registered channels, given in milliseconds. Defaults to 5 seconds.");
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSnapshotChangeEventSource.java
Patch:
@@ -98,7 +98,8 @@ protected SnapshotContext<OraclePartition, OracleOffsetContext> prepare(OraclePa
 
     @Override
     protected void connectionPoolConnectionCreated(RelationalSnapshotContext<OraclePartition, OracleOffsetContext> snapshotContext,
-                                                   JdbcConnection connection) throws SQLException {
+                                                   JdbcConnection connection)
+            throws SQLException {
         if (connectorConfig.getPdbName() != null) {
             ((OracleConnection) connection).setSessionToPdb(connectorConfig.getPdbName());
         }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -600,12 +600,14 @@ public boolean startMiningSession(OracleConnection connection, Scn startScn, Scn
             return true;
         }
         catch (SQLException e) {
+            LogMinerDatabaseStateWriter.writeLogMinerStartParameters(connection);
             if (e.getErrorCode() == 1291 || e.getMessage().startsWith("ORA-01291")) {
                 if (attempts <= MINING_START_RETRIES) {
                     LOGGER.warn("Failed to start Oracle LogMiner session, retrying...");
                     return false;
                 }
                 LOGGER.error("Failed to start Oracle LogMiner after '{}' attempts.", MINING_START_RETRIES, e);
+                LogMinerDatabaseStateWriter.writeLogMinerLogFailures(connection);
             }
             LOGGER.error("Got exception when starting mining session.", e);
             // Capture the database state before throwing the exception up

File: debezium-storage/debezium-storage-jdbc/src/main/java/io/debezium/storage/jdbc/history/JdbcSchemaHistoryConfig.java
Patch:
@@ -69,7 +69,7 @@ public class JdbcSchemaHistoryConfig extends JdbcCommonConfig {
             .withDescription("SELECT statement to check existence of the storage table")
             .withDefault(DEFAULT_TABLE_DATA_EXISTS_SELECT);
 
-    private static final String DEFAULT_TABLE_DATA_INSERT = "INSERT INTO %s VALUES ( ?, ?, ?, ?, ? )";
+    private static final String DEFAULT_TABLE_DATA_INSERT = "INSERT INTO %s(id, history_data, history_data_seq, record_insert_ts, record_insert_seq) VALUES ( ?, ?, ?, ?, ? )";
 
     public static final Field PROP_TABLE_DATA_INSERT = Field.create(CONFIGURATION_FIELD_PREFIX_STRING + "schema.history.table.insert")
             .withDescription("INSERT statement to add new records to the schema storage table")
@@ -96,7 +96,8 @@ protected void init(Configuration config) {
 
     @Override
     protected List<Field> getAllConfigurationFields() {
-        List<Field> fields = Collect.arrayListOf(PROP_TABLE_NAME, PROP_TABLE_DDL, PROP_TABLE_SELECT, PROP_TABLE_DATA_EXISTS_SELECT, PROP_TABLE_DATA_INSERT);
+        List<Field> fields = Collect.arrayListOf(PROP_TABLE_NAME, PROP_TABLE_DDL, PROP_TABLE_SELECT,
+                PROP_TABLE_DATA_EXISTS_SELECT, PROP_TABLE_DATA_INSERT);
         fields.addAll(super.getAllConfigurationFields());
         return fields;
     }

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/ShardedMongoDbConnectorIT.java
Patch:
@@ -23,7 +23,7 @@
 import io.debezium.connector.mongodb.MongoDbConnectorConfig.ConnectionMode;
 import io.debezium.data.Envelope;
 
-public class ShardedMongoConnectorIT extends AbstractShardedMongoConnectorIT {
+public class ShardedMongoDbConnectorIT extends AbstractShardedMongoConnectorIT {
 
     public static final String TOPIC_PREFIX = "mongo";
     private static final int INIT_DOCUMENT_COUNT = 1000;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/IncrementalSnapshotIT.java
Patch:
@@ -72,6 +72,7 @@ protected Configuration.Builder config() {
                 .with(MySqlConnectorConfig.SNAPSHOT_MODE, SnapshotMode.SCHEMA_ONLY.getValue())
                 .with(MySqlConnectorConfig.INCLUDE_SCHEMA_CHANGES, false)
                 .with(MySqlConnectorConfig.SIGNAL_DATA_COLLECTION, DATABASE.qualifiedTableName("debezium_signal"))
+                .with(CommonConnectorConfig.SIGNAL_POLL_INTERVAL_MS, 1)
                 .with(MySqlConnectorConfig.INCREMENTAL_SNAPSHOT_CHUNK_SIZE, 10)
                 .with(MySqlConnectorConfig.INCREMENTAL_SNAPSHOT_ALLOW_SCHEMA_CHANGES, true)
                 .with(CommonConnectorConfig.SCHEMA_NAME_ADJUSTMENT_MODE, SchemaNameAdjustmentMode.AVRO);
@@ -93,6 +94,7 @@ protected Configuration.Builder mutableConfig(boolean signalTableOnly, boolean s
                 .with(MySqlConnectorConfig.SNAPSHOT_MODE, SnapshotMode.INITIAL.getValue())
                 .with(MySqlConnectorConfig.INCLUDE_SCHEMA_CHANGES, false)
                 .with(MySqlConnectorConfig.SIGNAL_DATA_COLLECTION, DATABASE.qualifiedTableName("debezium_signal"))
+                .with(CommonConnectorConfig.SIGNAL_POLL_INTERVAL_MS, 5)
                 .with(MySqlConnectorConfig.TABLE_INCLUDE_LIST, tableIncludeList)
                 .with(MySqlConnectorConfig.INCREMENTAL_SNAPSHOT_CHUNK_SIZE, 10)
                 .with(MySqlConnectorConfig.INCREMENTAL_SNAPSHOT_ALLOW_SCHEMA_CHANGES, true)

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlMetricsIT.java
Patch:
@@ -152,6 +152,7 @@ public void testPauseResumeSnapshotMetrics() throws Exception {
                         .with(MySqlConnectorConfig.TABLE_INCLUDE_LIST, String.format("%s", TABLE_NAME))
                         .with(SchemaHistory.STORE_ONLY_CAPTURED_TABLES_DDL, Boolean.TRUE)
                         .with(CommonConnectorConfig.INCREMENTAL_SNAPSHOT_CHUNK_SIZE, 1)
+                        .with(CommonConnectorConfig.SIGNAL_POLL_INTERVAL_MS, 5)
                         .with(MySqlConnectorConfig.SIGNAL_DATA_COLLECTION, SIGNAL_TABLE_NAME)
                         .build());
 

File: debezium-core/src/main/java/io/debezium/pipeline/signal/actions/AbstractSnapshotSignal.java
Patch:
@@ -3,7 +3,7 @@
  *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
-package io.debezium.pipeline.signal;
+package io.debezium.pipeline.signal.actions;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -14,7 +14,7 @@
 /**
  * @author Chris Cranford
  */
-public abstract class AbstractSnapshotSignal<P extends Partition> implements Signal.Action<P> {
+public abstract class AbstractSnapshotSignal<P extends Partition> implements SignalAction<P> {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(AbstractSnapshotSignal.class);
     protected static final String FIELD_DATA_COLLECTIONS = "data-collections";

File: debezium-core/src/main/java/io/debezium/pipeline/source/snapshot/incremental/SignalBasedIncrementalSnapshotChangeEventSource.java
Patch:
@@ -13,6 +13,8 @@
 import io.debezium.annotation.NotThreadSafe;
 import io.debezium.jdbc.JdbcConnection;
 import io.debezium.pipeline.EventDispatcher;
+import io.debezium.pipeline.signal.actions.snapshotting.CloseIncrementalSnapshotWindow;
+import io.debezium.pipeline.signal.actions.snapshotting.OpenIncrementalSnapshotWindow;
 import io.debezium.pipeline.source.spi.DataChangeEventListener;
 import io.debezium.pipeline.source.spi.SnapshotProgressListener;
 import io.debezium.pipeline.spi.OffsetContext;

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSchema.java
Patch:
@@ -21,7 +21,7 @@
 import io.debezium.annotation.NotThreadSafe;
 import io.debezium.connector.postgresql.connection.PostgresConnection;
 import io.debezium.connector.postgresql.connection.PostgresDefaultValueConverter;
-import io.debezium.connector.postgresql.connection.ServerInfo;
+import io.debezium.connector.postgresql.connection.ReplicaIdentityInfo;
 import io.debezium.jdbc.JdbcConnection;
 import io.debezium.relational.RelationalDatabaseSchema;
 import io.debezium.relational.Table;
@@ -96,7 +96,7 @@ protected PostgresSchema refresh(PostgresConnection connection, boolean printRep
 
     private void printReplicaIdentityInfo(PostgresConnection connection, TableId tableId) {
         try {
-            ServerInfo.ReplicaIdentity replicaIdentity = connection.readReplicaIdentityInfo(tableId);
+            ReplicaIdentityInfo replicaIdentity = connection.readReplicaIdentityInfo(tableId);
             LOGGER.info("REPLICA IDENTITY for '{}' is '{}'; {}", tableId, replicaIdentity, replicaIdentity.description());
         }
         catch (SQLException e) {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/connection/PostgresConnectionIT.java
Patch:
@@ -97,7 +97,7 @@ public void shouldPrintReplicateIdentityInfo() throws Exception {
                 "CREATE TABLE test(pk serial, PRIMARY KEY (pk));";
         TestHelper.execute(statement);
         try (PostgresConnection connection = TestHelper.create()) {
-            assertEquals(ServerInfo.ReplicaIdentity.DEFAULT, connection.readReplicaIdentityInfo(TableId.parse("public.test")));
+            assertEquals(ReplicaIdentityInfo.ReplicaIdentity.DEFAULT.toString(), connection.readReplicaIdentityInfo(TableId.parse("public.test")).toString());
         }
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -128,6 +128,7 @@ protected DataTypeResolver initializeDataTypeResolver() {
         dataTypeResolverBuilder.registerDataTypes(MySqlParser.NationalStringDataTypeContext.class.getCanonicalName(), Arrays.asList(
                 new DataTypeEntry(Types.NVARCHAR, MySqlParser.NATIONAL, MySqlParser.VARCHAR).setSuffixTokens(MySqlParser.BINARY),
                 new DataTypeEntry(Types.NCHAR, MySqlParser.NATIONAL, MySqlParser.CHARACTER).setSuffixTokens(MySqlParser.BINARY),
+                new DataTypeEntry(Types.NCHAR, MySqlParser.NATIONAL, MySqlParser.CHAR).setSuffixTokens(MySqlParser.BINARY),
                 new DataTypeEntry(Types.NVARCHAR, MySqlParser.NCHAR, MySqlParser.VARCHAR).setSuffixTokens(MySqlParser.BINARY)));
         dataTypeResolverBuilder.registerDataTypes(MySqlParser.NationalVaryingStringDataTypeContext.class.getCanonicalName(), Arrays.asList(
                 new DataTypeEntry(Types.NVARCHAR, MySqlParser.NATIONAL, MySqlParser.CHAR, MySqlParser.VARYING),

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/memory/MemoryLogMinerEventProcessor.java
Patch:
@@ -149,7 +149,7 @@ public void abandonTransactions(Duration retention) throws InterruptedException
                         Map.Entry<String, MemoryTransaction> entry = iterator.next();
                         if (entry.getValue().getStartScn().compareTo(thresholdScn) <= 0) {
                             LOGGER.warn("Transaction {} with start SCN {} is being abandoned.",
-                                    entry.getKey(),entry.getValue().getStartScn());
+                                    entry.getKey(), entry.getValue().getStartScn());
 
                             abandonedTransactionsCache.add(entry.getKey());
                             iterator.remove();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/memory/MemoryLogMinerEventProcessor.java
Patch:
@@ -148,7 +148,9 @@ public void abandonTransactions(Duration retention) throws InterruptedException
                     while (iterator.hasNext()) {
                         Map.Entry<String, MemoryTransaction> entry = iterator.next();
                         if (entry.getValue().getStartScn().compareTo(thresholdScn) <= 0) {
-                            LOGGER.warn("Transaction {} is being abandoned, started at {} ({}).", entry.getKey(), entry.getValue().getChangeTime(), entry.getValue().getStartScn());
+                            LOGGER.warn("Transaction {} with start SCN {} is being abandoned.",
+                                    entry.getKey(),entry.getValue().getStartScn());
+
                             abandonedTransactionsCache.add(entry.getKey());
                             iterator.remove();
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -177,8 +177,8 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
             .withType(Type.DOUBLE)
             .withWidth(Width.SHORT)
             .withImportance(Importance.MEDIUM)
-            .withDefault(0)
-            .withValidation(Field::isNonNegativeInteger)
+            .withDefault(0.0)
+            .withValidation(Field::isNonNegativeDouble)
             .withGroup(Field.createGroupEntry(Field.Group.CONNECTION_ADVANCED, 18))
             .withDescription("Hours to keep long running transactions in transaction buffer between log mining " +
                     "sessions. By default, all transactions are retained.");

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -230,7 +230,7 @@ public void shouldValidateConfiguration() throws Exception {
         validateConfigField(validatedConfig, PostgresConnectorConfig.MAX_BATCH_SIZE, PostgresConnectorConfig.DEFAULT_MAX_BATCH_SIZE);
         validateConfigField(validatedConfig, PostgresConnectorConfig.SNAPSHOT_FETCH_SIZE, null);
         validateConfigField(validatedConfig, PostgresConnectorConfig.POLL_INTERVAL_MS, PostgresConnectorConfig.DEFAULT_POLL_INTERVAL_MILLIS);
-        validateConfigField(validatedConfig, PostgresConnectorConfig.SSL_MODE, PostgresConnectorConfig.SecureConnectionMode.DISABLED);
+        validateConfigField(validatedConfig, PostgresConnectorConfig.SSL_MODE, PostgresConnectorConfig.SecureConnectionMode.PREFER);
         validateConfigField(validatedConfig, PostgresConnectorConfig.SSL_CLIENT_CERT, null);
         validateConfigField(validatedConfig, PostgresConnectorConfig.SSL_CLIENT_KEY, null);
         validateConfigField(validatedConfig, PostgresConnectorConfig.SSL_CLIENT_KEY_PASSWORD, null);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -562,13 +562,13 @@ public static SecureConnectionMode parse(String value, String defaultValue) {
 
     public static final Field SSL_MODE = Field.create("database.ssl.mode")
             .withDisplayName("SSL mode")
-            .withEnum(SecureConnectionMode.class, SecureConnectionMode.DISABLED)
+            .withEnum(SecureConnectionMode.class, SecureConnectionMode.PREFERRED)
             .withGroup(Field.createGroupEntry(Field.Group.CONNECTION_ADVANCED_SSL, 0))
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.MEDIUM)
             .withDescription("Whether to use an encrypted connection to MySQL. Options include: "
-                    + "'disabled' (the default) to use an unencrypted connection; "
-                    + "'preferred' to establish a secure (encrypted) connection if the server supports secure connections, "
+                    + "'disabled' to use an unencrypted connection; "
+                    + "'preferred' (the default) to establish a secure (encrypted) connection if the server supports secure connections, "
                     + "but fall back to an unencrypted connection otherwise; "
                     + "'required' to use a secure (encrypted) connection, and fail if one cannot be established; "
                     + "'verify_ca' like 'required' but additionally verify the server TLS certificate against the configured Certificate Authority "

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/UniqueDatabase.java
Patch:
@@ -196,7 +196,7 @@ public Configuration.Builder defaultJdbcConfigBuilder() {
                 .with(MySqlConnectorConfig.USER, "snapper")
                 .with(MySqlConnectorConfig.PASSWORD, "snapperpass");
 
-        String sslMode = System.getProperty("database.ssl.mode", "disabled");
+        String sslMode = System.getProperty("database.ssl.mode", "preferred");
 
         if (sslMode.equals("disabled")) {
             builder.with(MySqlConnectorConfig.SSL_MODE, MySqlConnectorConfig.SecureConnectionMode.DISABLED);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -685,6 +685,9 @@ else if (data instanceof byte[]) {
             else if (data instanceof PGobject) {
                 r.deliver(HStoreConverter.fromString(data.toString()));
             }
+            else if (data instanceof Map) {
+                r.deliver(data);
+            }
         });
     }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/UnchangedToastedPlaceholder.java
Patch:
@@ -24,6 +24,7 @@ public class UnchangedToastedPlaceholder {
     private final Map<Object, Object> placeholderValues = new HashMap<Object, Object>();
     private final byte[] toastPlaceholderBinary;
     private final String toastPlaceholderString;
+    private final Map toastPlaceholderHstore = new HashMap<String, String>();
 
     public UnchangedToastedPlaceholder(PostgresConnectorConfig connectorConfig) {
         toastPlaceholderBinary = connectorConfig.getUnavailableValuePlaceholder();
@@ -39,6 +40,8 @@ public UnchangedToastedPlaceholder(PostgresConnectorConfig connectorConfig) {
         }
         placeholderValues.put(UnchangedToastedReplicationMessageColumn.UNCHANGED_INT_ARRAY_TOAST_VALUE, toastedIntArrayPlaceholder);
         placeholderValues.put(UnchangedToastedReplicationMessageColumn.UNCHANGED_BIGINT_ARRAY_TOAST_VALUE, toastedLongArrayPlaceholder);
+        toastPlaceholderHstore.put(toastPlaceholderString, toastPlaceholderString);
+        placeholderValues.put(UnchangedToastedReplicationMessageColumn.UNCHANGED_HSTORE_TOAST_VALUE, toastPlaceholderHstore);
     }
 
     public Optional<Object> getValue(Object obj) {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/signal/KafkaSignalThread.java
Patch:
@@ -81,7 +81,7 @@ public class KafkaSignalThread<T extends DataCollectionId> {
             .withValidation(Field::isRequired);
 
     public static final Field SIGNAL_POLL_TIMEOUT_MS = Field.create(CONFIGURATION_FIELD_PREFIX_STRING
-            + "signal.kafka.poll.timeout.ms")
+            + "kafka.poll.timeout.ms")
             .withDisplayName("Poll timeout for kafka signals (ms)")
             .withType(ConfigDef.Type.INT)
             .withWidth(ConfigDef.Width.SHORT)

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -309,6 +309,8 @@ public void shouldTakeSnapshot() throws Exception {
     }
 
     @Test
+    @FixFor("DBZ-6276")
+    @Ignore("Requires database to be configured without ARCHIVELOG_MODE enabled; which conflicts with dbz-oracle images")
     public void shouldSkipCheckingArchiveLogIfNoCdc() throws Exception {
         Configuration config = TestHelper.defaultConfig()
                 .with(OracleConnectorConfig.SNAPSHOT_MODE, SnapshotMode.INITIAL_ONLY)
@@ -320,6 +322,7 @@ public void shouldSkipCheckingArchiveLogIfNoCdc() throws Exception {
 
         start(OracleConnector.class, config);
         assertConnectorIsRunning();
+        waitForSnapshotToBeCompleted(TestHelper.CONNECTOR_NAME, TestHelper.SERVER_NAME);
         stopConnector();
 
         assertThat(logInterceptor.containsWarnMessage("Failed the archive log check but continuing as redo log isn't strictly required")).isTrue();

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorConfig.java
Patch:
@@ -26,6 +26,7 @@
 import io.debezium.connector.SourceInfoStructMaker;
 import io.debezium.document.Document;
 import io.debezium.jdbc.JdbcConfiguration;
+import io.debezium.pipeline.ErrorHandler;
 import io.debezium.relational.ColumnFilterMode;
 import io.debezium.relational.HistorizedRelationalDatabaseConnectorConfig;
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
@@ -47,7 +48,7 @@ public class SqlServerConnectorConfig extends HistorizedRelationalDatabaseConnec
     public static final String ERRORS_MAX_RETRIES = "errors.max.retries";
     protected static final int DEFAULT_PORT = 1433;
     protected static final int DEFAULT_MAX_TRANSACTIONS_PER_ITERATION = 0;
-    protected static final int DEFAULT_MAX_RETRIES = -1;
+    protected static final int DEFAULT_MAX_RETRIES = ErrorHandler.RETRIES_UNLIMITED;
     private static final String READ_ONLY_INTENT = "ReadOnly";
     private static final String APPLICATION_INTENT_KEY = "database.applicationIntent";
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerErrorHandler.java
Patch:
@@ -20,8 +20,8 @@
  */
 public class SqlServerErrorHandler extends ErrorHandler {
 
-    public SqlServerErrorHandler(SqlServerConnectorConfig connectorConfig, ChangeEventQueue<?> queue, int retries, int maxRetries) {
-        super(SqlServerConnector.class, connectorConfig, queue, retries, maxRetries);
+    public SqlServerErrorHandler(SqlServerConnectorConfig connectorConfig, ChangeEventQueue<?> queue, int maxRetries) {
+        super(SqlServerConnector.class, connectorConfig, queue, maxRetries);
     }
 
     @Override

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -652,11 +652,12 @@ private Scn calculateEndScn(OracleConnection connection, Scn startScn, Scn prevE
 
         // Control adjusting batch size
         boolean topMiningScnInFarFuture = false;
-        if (topScnToMine.subtract(currentScn).compareTo(currentBatchSizeScn) > 0) {
+        final Scn defaultBatchScn = Scn.valueOf(connectorConfig.getLogMiningBatchSizeDefault());
+        if (topScnToMine.subtract(currentScn).compareTo(defaultBatchScn) > 0) {
             streamingMetrics.changeBatchSize(false, connectorConfig.isLobEnabled());
             topMiningScnInFarFuture = true;
         }
-        if (currentScn.subtract(topScnToMine).compareTo(currentBatchSizeScn) > 0) {
+        if (currentScn.subtract(topScnToMine).compareTo(defaultBatchScn) > 0) {
             streamingMetrics.changeBatchSize(true, connectorConfig.isLobEnabled());
         }
 

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -55,6 +55,7 @@ public abstract class CommonConnectorConfig {
     public static final String TASK_ID = "task.id";
     public static final Pattern TOPIC_NAME_PATTERN = Pattern.compile("^[a-zA-Z0-9_.\\-]+$");
     public static final String MULTI_PARTITION_MODE = "multi.partition.mode";
+
     private static final Logger LOGGER = LoggerFactory.getLogger(CommonConnectorConfig.class);
 
     /**

File: debezium-core/src/main/java/io/debezium/config/Field.java
Patch:
@@ -1367,21 +1367,21 @@ public static int notContainEmptyElements(Configuration config, Field field, Val
 
         List<String> values = config.getList(field);
         if (values.contains(EMPTY_STRING)) {
-            problems.accept(field, values, "not permitted empty string");
+            problems.accept(field, values, "Empty string element(s) not permitted");
             return 1;
         }
         return 0;
     }
 
-    public static int notContainSpaceInAnyElements(Configuration config, Field field, ValidationOutput problems) {
+    public static int notContainSpaceInAnyElement(Configuration config, Field field, ValidationOutput problems) {
 
         if (!config.hasKey(field)) {
             return 0;
         }
 
         List<String> values = config.getList(field);
         if (values.stream().anyMatch(h -> h.contains(SPACE))) {
-            problems.accept(field, values, "some elements with not permitted space");
+            problems.accept(field, values, "Element(s) containing space not permitted");
             return 1;
         }
         return 0;

File: debezium-core/src/main/java/io/debezium/transforms/HeaderToValue.java
Patch:
@@ -76,7 +76,7 @@ public String toString() {
             .withType(ConfigDef.Type.LIST)
             .withImportance(ConfigDef.Importance.HIGH)
             .withValidation(
-                    Field::notContainSpaceInAnyElements,
+                    Field::notContainSpaceInAnyElement,
                     Field::notContainEmptyElements)
             .withDescription("Header names in the record whose values are to be copied or moved to record value.")
             .required();
@@ -86,7 +86,7 @@ public String toString() {
             .withType(ConfigDef.Type.LIST)
             .withImportance(ConfigDef.Importance.HIGH)
             .withValidation(
-                    Field::notContainSpaceInAnyElements,
+                    Field::notContainSpaceInAnyElement,
                     Field::notContainEmptyElements)
             .withDescription(
                     "Field names, in the same order as the header names listed in the headers configuration property. Supports Struct nesting using dot notation.")

File: debezium-core/src/main/java/io/debezium/transforms/partitions/PartitionRouting.java
Patch:
@@ -64,6 +64,7 @@ public class PartitionRouting<R extends ConnectRecord<R>> implements Transformat
             .withImportance(ConfigDef.Importance.HIGH)
             .withDescription("Number of partition for the topic on which this SMT act. Use TopicNameMatches predicate to filter records by topic")
             .required();
+
     private SmtManager<R> smtManager;
     private List<String> payloadFields;
     private int partitionNumber;
@@ -124,7 +125,6 @@ public R apply(R originalRecord) {
 
         }
         catch (Exception e) {
-            LOGGER.error("Error occurred while processing message {}. Skipping SMT", envelope);
             throw new DebeziumException(String.format("Unprocessable message %s", envelope), e);
         }
     }

File: debezium-core/src/test/java/io/debezium/transforms/partitions/PartitionRoutingTest.java
Patch:
@@ -64,7 +64,7 @@ public void whenPartitionPayloadFieldContainsEmptyElementAConfigExceptionIsThrew
                 "partition.topic.num", 2)))
                 .isInstanceOf(ConfigException.class)
                 .hasMessageContaining(
-                        "Invalid value ,source.table for configuration partition.payload.fields: The 'partition.payload.fields' value is invalid: not permitted empty string");
+                        "Invalid value ,source.table for configuration partition.payload.fields: The 'partition.payload.fields' value is invalid: Empty string element(s) not permitted");
     }
 
     @Test

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnector.java
Patch:
@@ -141,7 +141,7 @@ private static void checkWalLevel(PostgresConnection connection, PostgresConnect
                     "SHOW wal_level",
                     connection.singleResultMapper(rs -> rs.getString("wal_level"), "Could not fetch wal_level"));
             if (!"logical".equals(walLevel)) {
-                throw new SQLException("Postgres server wal_level property must be \\\"logical\\\" but is: \" + walLevel");
+                throw new SQLException("Postgres server wal_level property must be 'logical' but is: '" + walLevel + "'");
             }
         }
         else {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/infinispan/marshalling/LogMinerEventAdapter.java
Patch:
@@ -89,7 +89,7 @@ public String getScn(LogMinerEvent event) {
      */
     @ProtoField(number = 3, required = true)
     public String getTableId(LogMinerEvent event) {
-        return event.getTableId().identifier();
+        return event.getTableId().toDoubleQuotedString();
     }
 
     /**

File: debezium-connector-jdbc/src/test/java/io/debezium/connector/jdbc/junit/jupiter/Sink.java
Patch:
@@ -167,7 +167,7 @@ private static class SinkConnectionInitializer implements ConnectionInitializer
 
         private final SinkType type;
 
-        public SinkConnectionInitializer(SinkType type) {
+        SinkConnectionInitializer(SinkType type) {
             this.type = type;
         }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/JsonType.java
Patch:
@@ -28,7 +28,7 @@ public String[] getRegistrationKeys() {
 
     @Override
     public String getQueryBinding(Schema schema) {
-        return String.format("cast(? as json)");
+        return "cast(? as json)";
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/mysql/MySqlDatabaseDialect.java
Patch:
@@ -78,6 +78,7 @@ protected void registerTypes() {
         registerType(YearType.INSTANCE);
         registerType(JsonType.INSTANCE);
         registerType(ZonedTimestampWithoutTimezoneType.INSTANCE);
+        registerType(MapToJsonType.INSTANCE);
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/dialect/postgres/PostgresDatabaseDialect.java
Patch:
@@ -134,13 +134,15 @@ protected void registerTypes() {
         registerType(MoneyType.INSTANCE);
         registerType(XmlType.INSTANCE);
         registerType(LtreeType.INSTANCE);
+        registerType(MapToHstoreType.INSTANCE);
 
         // Allows binding string-based types if column type propagation is enabled
         registerType(RangeType.INSTANCE);
         registerType(CidrType.INSTANCE);
         registerType(MacAddressType.INSTANCE);
         registerType(InetType.INSTANCE);
         registerType(CaseInsensitiveTextType.INSTANCE);
+        registerType(OidType.INSTANCE);
     }
 
     @Override

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/type/connect/ConnectBytesType.java
Patch:
@@ -39,6 +39,9 @@ public String getTypeName(DatabaseDialect dialect, Schema schema, boolean key) {
         if (columnSize > 0) {
             return dialect.getTypeName(Types.VARBINARY, Size.length(columnSize));
         }
+        else if (key) {
+            return dialect.getTypeName(Types.VARBINARY, Size.length(dialect.getMaxVarbinaryLength()));
+        }
         return dialect.getTypeName(Types.VARBINARY);
     }
 

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/JdbcSinkConnectorTask.java
Patch:
@@ -148,7 +148,9 @@ private void markNotProcessed(Iterator<SinkRecord> records) {
         while (records.hasNext()) {
             markNotProcessed(records.next());
         }
-        context.requestCommit();
+        if (context != null) {
+            context.requestCommit();
+        }
     }
 
     /**

File: debezium-connector-jdbc/src/main/java/io/debezium/connector/jdbc/util/ByteArrayUtils.java
Patch:
@@ -19,13 +19,13 @@ public static String getByteArrayAsHex(Object value) {
     }
 
     public static byte[] getByteArrayFromValue(Object value) {
-        final byte[] byteArray;
+        byte[] byteArray = null;
         if (value instanceof ByteBuffer) {
             final ByteBuffer buffer = ((ByteBuffer) value).slice();
             byteArray = new byte[buffer.remaining()];
             buffer.get(byteArray);
         }
-        else {
+        else if (value instanceof byte[]) {
             byteArray = (byte[]) value;
         }
         return byteArray;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSchemaChangeEventEmitter.java
Patch:
@@ -90,6 +90,9 @@ public void emitSchemaChangeEvent(Receiver receiver) throws InterruptedException
                 streamingMetrics.incrementUnparsableDdlCount();
             }
             else {
+                if (e instanceof MultipleParsingExceptions) {
+                    ((MultipleParsingExceptions) e).forEachError(ParsingException::printStackTrace);
+                }
                 throw e;
             }
         }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/antlr/listener/ColumnDefinitionParserListener.java
Patch:
@@ -194,7 +194,8 @@ else if (ctx.native_datatype_element().NVARCHAR2() != null) {
                     setPrecision(precisionPart, columnEditor);
                 }
             }
-            else if (ctx.native_datatype_element().CHAR() != null) {
+            else if (ctx.native_datatype_element().CHAR() != null ||
+                    ctx.native_datatype_element().CHARACTER() != null) {
                 columnEditor
                         .jdbcType(Types.CHAR)
                         .type("CHAR")

File: debezium-core/src/main/java/io/debezium/time/ZonedTimestamp.java
Patch:
@@ -48,13 +48,13 @@ public class ZonedTimestamp {
     /**
      * Returns a {@link DateTimeFormatter} that ensures that exactly fractionalWidth number of digits are present
      * in the nanosecond part of the datetime. If fractionWidth is null, then
-     * {@link DateTimeFormatter.ISO_OFFSET_DATE_TIME} formatter is used, which can have anywhere from 0-9 digits in the
+     * {@link DateTimeFormatter#ISO_OFFSET_DATE_TIME} formatter is used, which can have anywhere from 0-9 digits in the
      * nanosecond part.
      *
      * @param fractionalWidth the optional component that specifies the exact number of digits to be present in a zoneddatetime
      *                        formatted string.
      * @return {@link DateTimeFormatter} containing exactly fractionalWidth number of digits in nanosecond part of the
-     * datetime. If null, {@link DateTimeFormatter.ISO_OFFSET_DATE_TIME} formatter is used, which can have anywhere
+     * datetime. If null, {@link DateTimeFormatter#ISO_OFFSET_DATE_TIME} formatter is used, which can have anywhere
      * from 0-9 digits in the nanosecond part.
      */
     private static DateTimeFormatter getDateTimeFormatter(Integer fractionalWidth) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -711,7 +711,7 @@ public static AutoCreateMode parse(String value, String defaultValue) {
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.MEDIUM)
             .withValidation((config, field, output) -> {
-                if (config.getString(SNAPSHOT_MODE).toLowerCase().equals("custom") && config.getString(field).isEmpty()) {
+                if (config.getString(SNAPSHOT_MODE).toLowerCase().equals("custom") && config.getString(field, "").isEmpty()) {
                     output.accept(field, "", "snapshot.custom_class cannot be empty when snapshot.mode 'custom' is defined");
                     return 1;
                 }

File: debezium-core/src/main/java/io/debezium/transforms/SmtManager.java
Patch:
@@ -66,7 +66,7 @@ public void validate(Configuration configuration, Field.Set fields) {
         for (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {
             if (!entry.getValue().errorMessages().isEmpty()) {
                 final ConfigValue value = entry.getValue();
-                throw new ConfigException(value.name(), value.value(), value.errorMessages().get(0));
+                throw new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));
             }
         }
     }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/SourceInfo.java
Patch:
@@ -294,8 +294,9 @@ public void changeStreamEvent(String replicaSetName, ChangeStreamDocument<BsonDo
         String namespace = "";
         long wallTime = 0L;
         if (changeStreamEvent != null) {
-            BsonTimestamp ts = changeStreamEvent.getClusterTime();
             String resumeToken = ResumeTokens.getDataString(changeStreamEvent.getResumeToken());
+            // > Decode timestamp from resume token to be consistent with other events
+            BsonTimestamp ts = ResumeTokens.getTimestamp(changeStreamEvent.getResumeToken());
             position = Position.changeStreamPosition(ts, resumeToken, MongoUtil.getChangeStreamSessionTransactionId(changeStreamEvent));
             namespace = changeStreamEvent.getNamespace().getFullName();
             if (changeStreamEvent.getWallTime() != null) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/WalPositionLocator.java
Patch:
@@ -77,7 +77,7 @@ public Optional<Lsn> resumeFromLsn(Lsn currentLsn, ReplicationMessage message) {
                 // BEGIN and first message after change have the same LSN
                 if (txStartLsn != null
                         && (lastProcessedMessageType == null || lastProcessedMessageType == Operation.BEGIN || lastProcessedMessageType == Operation.COMMIT)) {
-                    // start from the BEGIN tx; prevent skipping of unprocessed event after BEGIN or previsou tx COMMIT
+                    // start from the BEGIN tx; prevent skipping of unprocessed event after BEGIN or previous tx COMMIT
                     LOGGER.info("Will restart from LSN '{}' corresponding to the event following the BEGIN event", txStartLsn);
                     startStreamingLsn = txStartLsn;
                     return Optional.of(startStreamingLsn);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/WalPositionLocator.java
Patch:
@@ -75,8 +75,9 @@ public Optional<Lsn> resumeFromLsn(Lsn currentLsn, ReplicationMessage message) {
             // We can resume streaming from it
             if (currentLsn.equals(lastEventStoredLsn)) {
                 // BEGIN and first message after change have the same LSN
-                if (txStartLsn != null && (lastProcessedMessageType == null || lastProcessedMessageType == Operation.BEGIN)) {
-                    // start from the BEGIN tx; prevent skipping of unprocessed event after BEGIN
+                if (txStartLsn != null
+                        && (lastProcessedMessageType == null || lastProcessedMessageType == Operation.BEGIN || lastProcessedMessageType == Operation.COMMIT)) {
+                    // start from the BEGIN tx; prevent skipping of unprocessed event after BEGIN or previsou tx COMMIT
                     LOGGER.info("Will restart from LSN '{}' corresponding to the event following the BEGIN event", txStartLsn);
                     startStreamingLsn = txStartLsn;
                     return Optional.of(startStreamingLsn);

File: debezium-storage/debezium-storage-rocketmq/src/main/java/io/debezium/storage/rocketmq/RocketMqConfig.java
Patch:
@@ -9,7 +9,7 @@
 import java.util.Objects;
 
 /**
- * Configuration for connecting RocketMq
+ * Configuration for connecting RocketMQ
  */
 public class RocketMqConfig {
     private String namesrvAddr;

File: debezium-core/src/main/java/io/debezium/relational/HistorizedRelationalDatabaseConnectorConfig.java
Patch:
@@ -106,6 +106,7 @@ public SchemaHistory getSchemaHistory() {
         // Do not remove the prefix from the subset of config properties ...
         Configuration schemaHistoryConfig = config.subset(SchemaHistory.CONFIGURATION_FIELD_PREFIX_STRING, false)
                 .edit()
+                .with(config.subset(Field.INTERNAL_PREFIX + SchemaHistory.CONFIGURATION_FIELD_PREFIX_STRING, false))
                 .withDefault(SchemaHistory.NAME, getLogicalName() + "-schemahistory")
                 .withDefault(AbstractSchemaHistory.INTERNAL_CONNECTOR_CLASS, connectorClass.getName())
                 .withDefault(AbstractSchemaHistory.INTERNAL_CONNECTOR_ID, logicalName)

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -75,8 +75,9 @@ public ChangeEventSourceCoordinator<MySqlPartition, MySqlOffsetContext> start(Co
                 .withDefault("database.useCursorFetch", connectorConfig.useCursorFetch())
                 .build();
 
-        MainConnectionProvidingConnectionFactory<MySqlConnection> connectionFactory = new DefaultMainConnectionProvidingConnectionFactory<>(() -> new MySqlConnection(new MySqlConnectionConfiguration(config),
-                connectorConfig.useCursorFetch() ? new MySqlBinaryProtocolFieldReader(connectorConfig) : new MySqlTextProtocolFieldReader(connectorConfig)));
+        MainConnectionProvidingConnectionFactory<MySqlConnection> connectionFactory = new DefaultMainConnectionProvidingConnectionFactory<>(
+                () -> new MySqlConnection(new MySqlConnectionConfiguration(config),
+                        connectorConfig.useCursorFetch() ? new MySqlBinaryProtocolFieldReader(connectorConfig) : new MySqlTextProtocolFieldReader(connectorConfig)));
 
         connection = connectionFactory.mainConnection();
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorTask.java
Patch:
@@ -57,7 +57,8 @@ public ChangeEventSourceCoordinator<OraclePartition, OracleOffsetContext> start(
         SchemaNameAdjuster schemaNameAdjuster = connectorConfig.schemaNameAdjuster();
 
         JdbcConfiguration jdbcConfig = connectorConfig.getJdbcConfig();
-        MainConnectionProvidingConnectionFactory<OracleConnection> connectionFactory = new DefaultMainConnectionProvidingConnectionFactory<>(() -> new OracleConnection(jdbcConfig));
+        MainConnectionProvidingConnectionFactory<OracleConnection> connectionFactory = new DefaultMainConnectionProvidingConnectionFactory<>(
+                () -> new OracleConnection(jdbcConfig));
         jdbcConnection = connectionFactory.mainConnection();
 
         validateRedoLogConfiguration();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresChangeEventSourceFactory.java
Patch:
@@ -39,7 +39,8 @@ public class PostgresChangeEventSourceFactory implements ChangeEventSourceFactor
     private final SlotCreationResult slotCreatedInfo;
     private final SlotState startingSlotInfo;
 
-    public PostgresChangeEventSourceFactory(PostgresConnectorConfig configuration, Snapshotter snapshotter, MainConnectionProvidingConnectionFactory<PostgresConnection> connectionFactory,
+    public PostgresChangeEventSourceFactory(PostgresConnectorConfig configuration, Snapshotter snapshotter,
+                                            MainConnectionProvidingConnectionFactory<PostgresConnection> connectionFactory,
                                             ErrorHandler errorHandler, PostgresEventDispatcher<TableId> dispatcher, Clock clock, PostgresSchema schema,
                                             PostgresTaskContext taskContext, ReplicationConnection replicationConnection, SlotCreationResult slotCreatedInfo,
                                             SlotState startingSlotInfo) {

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorTask.java
Patch:
@@ -71,8 +71,9 @@ public ChangeEventSourceCoordinator<SqlServerPartition, SqlServerOffsetContext>
         final SqlServerValueConverters valueConverters = new SqlServerValueConverters(connectorConfig.getDecimalMode(),
                 connectorConfig.getTemporalPrecisionMode(), connectorConfig.binaryHandlingMode());
 
-        MainConnectionProvidingConnectionFactory<SqlServerConnection> connectionFactory = new DefaultMainConnectionProvidingConnectionFactory<>(() -> new SqlServerConnection(connectorConfig.getJdbcConfig(),
-                valueConverters, connectorConfig.getSkippedOperations(), connectorConfig.useSingleDatabase(), connectorConfig.getOptionRecompile()));
+        MainConnectionProvidingConnectionFactory<SqlServerConnection> connectionFactory = new DefaultMainConnectionProvidingConnectionFactory<>(
+                () -> new SqlServerConnection(connectorConfig.getJdbcConfig(),
+                        valueConverters, connectorConfig.getSkippedOperations(), connectorConfig.useSingleDatabase(), connectorConfig.getOptionRecompile()));
         dataConnection = connectionFactory.mainConnection();
         metadataConnection = new SqlServerConnection(connectorConfig.getJdbcConfig(), valueConverters,
                 connectorConfig.getSkippedOperations(), connectorConfig.useSingleDatabase());

File: debezium-core/src/main/java/io/debezium/jdbc/ConnectionFactory.java
Patch:
@@ -11,7 +11,7 @@
  * @param <T>
  */
 @FunctionalInterface
-public interface ConnectionFactory<T> {
+public interface ConnectionFactory<T extends JdbcConnection> {
 
     T newConnection();
 }

File: debezium-core/src/main/java/io/debezium/jdbc/DefaultMainConnectionProvidingConnectionFactory.java
Patch:
@@ -5,7 +5,7 @@
  */
 package io.debezium.jdbc;
 
-public class DefaultMainConnectionProvidingConnectionFactory<T> implements MainConnectionProvidingConnectionFactory<T> {
+public class DefaultMainConnectionProvidingConnectionFactory<T extends JdbcConnection> implements MainConnectionProvidingConnectionFactory<T> {
 
     private ConnectionFactory<T> delegate;
 

File: debezium-core/src/main/java/io/debezium/jdbc/MainConnectionProvidingConnectionFactory.java
Patch:
@@ -12,7 +12,7 @@
  *
  * @param <T>
  */
-public interface MainConnectionProvidingConnectionFactory<T> extends ConnectionFactory<T> {
+public interface MainConnectionProvidingConnectionFactory<T extends JdbcConnection> extends ConnectionFactory<T> {
 
     T mainConnection();
 }

File: debezium-core/src/main/java/io/debezium/relational/RelationalSnapshotChangeEventSource.java
Patch:
@@ -81,7 +81,8 @@ public abstract class RelationalSnapshotChangeEventSource<P extends Partition, O
     protected final Clock clock;
     private final SnapshotProgressListener<P> snapshotProgressListener;
 
-    public RelationalSnapshotChangeEventSource(RelationalDatabaseConnectorConfig connectorConfig, MainConnectionProvidingConnectionFactory<? extends JdbcConnection> jdbcConnectionFactory,
+    public RelationalSnapshotChangeEventSource(RelationalDatabaseConnectorConfig connectorConfig,
+                                               MainConnectionProvidingConnectionFactory<? extends JdbcConnection> jdbcConnectionFactory,
                                                RelationalDatabaseSchema schema, EventDispatcher<P, TableId> dispatcher, Clock clock,
                                                SnapshotProgressListener<P> snapshotProgressListener) {
         super(connectorConfig, snapshotProgressListener);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -959,6 +959,7 @@ private Table dispatchSchemaChangeEventAndGetTableForNewCapturedTable(TableId ta
                                                                           EventDispatcher<OraclePartition, TableId> dispatcher)
             throws SQLException, InterruptedException {
 
+        LOGGER.warn("Obtaining schema for table {}, which should be already loaded, this may signal potential bug in fetching table schemas.", tableId);
         final String tableDdl;
         try {
             tableDdl = getTableMetadataDdl(tableId);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/xstream/LcrEventHandler.java
Patch:
@@ -168,6 +168,7 @@ private void dispatchDataChangeEvent(RowLCR lcr, Map<String, Object> chunkValues
                 return;
             }
 
+            LOGGER.warn("Obtaining schema for table {}, which should be already loaded, this may signal potential bug in fetching table schemas.", tableId);
             final String tableDdl;
             try {
                 tableDdl = getTableMetadataDdl(tableId);

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbIncrementalSnapshotChangeEventSource.java
Patch:
@@ -521,6 +521,9 @@ private Object[] keyFromRow(Object[] row) {
             case OBJECT_ID:
                 key = documentId.asObjectId().getValue();
                 break;
+            case STRING:
+                key = documentId.asString().getValue();
+                break;
             default:
                 throw new IllegalStateException("Unsupported type of document id");
         }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorConfigTest.java
Patch:
@@ -157,7 +157,7 @@ public void validQueryFetchSizeDefaults() throws Exception {
                 Configuration.create()
                         .with(CommonConnectorConfig.TOPIC_PREFIX, "myserver")
                         .build());
-        assertEquals(connectorConfig.getQueryFetchSize(), 0);
+        assertEquals(connectorConfig.getQueryFetchSize(), 2_000);
     }
 
     @Test

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleOffsetContext.java
Patch:
@@ -273,7 +273,7 @@ public void setRsId(String rsId) {
         sourceInfo.setRsId(rsId);
     }
 
-    public void setSsn(int ssn) {
+    public void setSsn(long ssn) {
         sourceInfo.setSsn(ssn);
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSourceInfoStructMaker.java
Patch:
@@ -26,7 +26,7 @@ public OracleSourceInfoStructMaker(String connector, String version, CommonConne
                 .field(SourceInfo.COMMIT_SCN_KEY, Schema.OPTIONAL_STRING_SCHEMA)
                 .field(SourceInfo.LCR_POSITION_KEY, Schema.OPTIONAL_STRING_SCHEMA)
                 .field(CommitScn.ROLLBACK_SEGMENT_ID_KEY, Schema.OPTIONAL_STRING_SCHEMA)
-                .field(CommitScn.SQL_SEQUENCE_NUMBER_KEY, Schema.OPTIONAL_INT32_SCHEMA))
+                .field(CommitScn.SQL_SEQUENCE_NUMBER_KEY, Schema.OPTIONAL_INT64_SCHEMA))
                 .field(SourceInfo.USERNAME_KEY, Schema.OPTIONAL_STRING_SCHEMA).build();
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/SourceInfo.java
Patch:
@@ -36,7 +36,7 @@ public class SourceInfo extends BaseSourceInfo {
     private Set<TableId> tableIds;
     private Integer redoThread;
     private String rsId;
-    private int ssn;
+    private long ssn;
 
     protected SourceInfo(OracleConnectorConfig connectorConfig) {
         super(connectorConfig);
@@ -98,11 +98,11 @@ public void setRsId(String rsId) {
         this.rsId = rsId;
     }
 
-    public int getSsn() {
+    public long getSsn() {
         return ssn;
     }
 
-    public void setSsn(int ssn) {
+    public void setSsn(long ssn) {
         this.ssn = ssn;
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/events/LogMinerEventRow.java
Patch:
@@ -65,7 +65,7 @@ public class LogMinerEventRow {
     private String redoSql;
     private int status;
     private String info;
-    private int ssn;
+    private long ssn;
     private int thread;
 
     public Scn getScn() {
@@ -128,7 +128,7 @@ public String getInfo() {
         return info;
     }
 
-    public int getSsn() {
+    public long getSsn() {
         return ssn;
     }
 
@@ -179,7 +179,7 @@ private void initializeFromResultSet(ResultSet resultSet, String catalogName, bo
         this.redoSql = getSqlRedo(resultSet);
         this.status = resultSet.getInt(STATUS);
         this.info = resultSet.getString(INFO);
-        this.ssn = resultSet.getInt(SSN);
+        this.ssn = resultSet.getLong(SSN);
         this.thread = resultSet.getInt(THREAD);
         if (this.tableName != null) {
             this.tableId = new TableId(catalogName, tablespaceName, tableName);

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/SourceInfoTest.java
Patch:
@@ -64,7 +64,7 @@ public void schemaIsCorrect() {
                 .field("commit_scn", Schema.OPTIONAL_STRING_SCHEMA)
                 .field("lcr_position", Schema.OPTIONAL_STRING_SCHEMA)
                 .field("rs_id", Schema.OPTIONAL_STRING_SCHEMA)
-                .field("ssn", Schema.OPTIONAL_INT32_SCHEMA)
+                .field("ssn", Schema.OPTIONAL_INT64_SCHEMA)
                 .field("redo_thread", Schema.OPTIONAL_INT32_SCHEMA)
                 .field("user_name", Schema.OPTIONAL_STRING_SCHEMA)
                 .build();

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/OperatorController.java
Patch:
@@ -162,7 +162,7 @@ public Optional<String> getPullSecretName() {
         return getPullSecret().map(ps -> ps.getMetadata().getName());
     }
 
-    private Deployment waitForAvailable() {
+    public Deployment waitForAvailable() {
         return ocp.apps().deployments().inNamespace(project).withName(name)
                 .waitUntilCondition(WaitConditions::deploymentAvailableCondition, scaled(5), MINUTES);
     }

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/OcpDb2ConnectorIT.java
Patch:
@@ -15,6 +15,7 @@
 import io.debezium.testing.system.fixtures.connectors.Db2Connector;
 import io.debezium.testing.system.fixtures.databases.ocp.OcpDb2;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.fixtures.operator.OcpStrimziOperator;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -27,6 +28,7 @@
 @Tag("db2")
 @Tag("openshift")
 @Fixture(OcpClient.class)
+@Fixture(OcpStrimziOperator.class)
 @Fixture(OcpKafka.class)
 @Fixture(OcpDb2.class)
 @Fixture(Db2Connector.class)

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mongodb/OcpMongoConnectorIT.java
Patch:
@@ -15,6 +15,7 @@
 import io.debezium.testing.system.fixtures.connectors.MongoConnector;
 import io.debezium.testing.system.fixtures.databases.ocp.OcpMongo;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.fixtures.operator.OcpStrimziOperator;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -27,6 +28,7 @@
 @Tag("mongo")
 @Tag("openshift")
 @Fixture(OcpClient.class)
+@Fixture(OcpStrimziOperator.class)
 @Fixture(OcpKafka.class)
 @Fixture(OcpMongo.class)
 @Fixture(MongoConnector.class)

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mysql/OcpMySqlConnectorIT.java
Patch:
@@ -15,6 +15,7 @@
 import io.debezium.testing.system.fixtures.connectors.MySqlConnector;
 import io.debezium.testing.system.fixtures.databases.ocp.OcpMySql;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.fixtures.operator.OcpStrimziOperator;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -27,6 +28,7 @@
 @Tag("mysql")
 @Tag("openshift")
 @Fixture(OcpClient.class)
+@Fixture(OcpStrimziOperator.class)
 @Fixture(OcpKafka.class)
 @Fixture(OcpMySql.class)
 @Fixture(MySqlConnector.class)

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/oracle/OcpOracleConnectorIT.java
Patch:
@@ -15,6 +15,7 @@
 import io.debezium.testing.system.fixtures.connectors.OracleConnector;
 import io.debezium.testing.system.fixtures.databases.ocp.OcpOracle;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.fixtures.operator.OcpStrimziOperator;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -27,6 +28,7 @@
 @Tag("oracle")
 @Tag("openshift")
 @Fixture(OcpClient.class)
+@Fixture(OcpStrimziOperator.class)
 @Fixture(OcpKafka.class)
 @Fixture(OcpOracle.class)
 @Fixture(OracleConnector.class)

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/postgresql/OcpPostgreSqlConnectorIT.java
Patch:
@@ -15,6 +15,7 @@
 import io.debezium.testing.system.fixtures.connectors.PostgreSqlConnector;
 import io.debezium.testing.system.fixtures.databases.ocp.OcpPostgreSql;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.fixtures.operator.OcpStrimziOperator;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -27,6 +28,7 @@
 @Tag("postgresql")
 @Tag("openshift")
 @Fixture(OcpClient.class)
+@Fixture(OcpStrimziOperator.class)
 @Fixture(OcpKafka.class)
 @Fixture(OcpPostgreSql.class)
 @Fixture(PostgreSqlConnector.class)

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/sqlserver/OcpSqlServerConnectorIT.java
Patch:
@@ -15,6 +15,7 @@
 import io.debezium.testing.system.fixtures.connectors.SqlServerConnector;
 import io.debezium.testing.system.fixtures.databases.ocp.OcpSqlServer;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.fixtures.operator.OcpStrimziOperator;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -27,6 +28,7 @@
 @Tag("sqlserver")
 @Tag("openshift")
 @Fixture(OcpClient.class)
+@Fixture(OcpStrimziOperator.class)
 @Fixture(OcpKafka.class)
 @Fixture(OcpSqlServer.class)
 @Fixture(SqlServerConnector.class)

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/IncrementalSnapshotIT.java
Patch:
@@ -23,6 +23,7 @@
 import io.debezium.util.Testing;
 
 public class IncrementalSnapshotIT extends AbstractIncrementalSnapshotWithSchemaChangesSupportTest<SqlServerConnector> {
+    private static final int POLLING_INTERVAL = 1;
 
     private SqlServerConnection connection;
 
@@ -38,6 +39,7 @@ public void before() throws SQLException {
                 "CREATE TABLE b (pk int primary key, aa int)",
                 "CREATE TABLE debezium_signal (id varchar(64), type varchar(32), data varchar(2048))");
         TestHelper.enableTableCdc(connection, "debezium_signal");
+        TestHelper.adjustCdcPollingInterval(connection, POLLING_INTERVAL);
 
         initializeConnectorTestFramework();
         Testing.Files.delete(TestHelper.SCHEMA_HISTORY_PATH);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDatabaseSchema.java
Patch:
@@ -305,7 +305,7 @@ private void emitChangeEvent(MySqlPartition partition, MySqlOffsetContext offset
                     sanitizedDbName,
                     null,
                     event.statement(),
-                    tableId != null ? tableFor(tableId) : null,
+                    tableId != null ? tables().forTable(tableId) : null,
                     ((TableAlteredEvent) event).previousTableId());
         }
         else {
@@ -316,7 +316,7 @@ private void emitChangeEvent(MySqlPartition partition, MySqlOffsetContext offset
                     sanitizedDbName,
                     null,
                     event.statement(),
-                    tableId != null ? tableFor(tableId) : null,
+                    tableId != null ? tables().forTable(tableId) : null,
                     snapshot);
         }
         schemaChangeEvents.add(schemaChangeEvent);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -1736,8 +1736,10 @@ public void shouldPerformSnapshotOnceForInitialOnlySnapshotMode() throws Excepti
         start(PostgresConnector.class, config);
         assertConnectorIsRunning();
 
+        waitForConnectorShutdown("postgres", TestHelper.TEST_SERVER);
+
         // Stop the connector, verify that no snapshot was performed
-        stopConnector(value -> assertThat(logInterceptor.containsMessage("Previous initial snapshot completed, no snapshot will be performed")).isTrue());
+        assertThat(logInterceptor.containsMessage("Previous initial snapshot completed, no snapshot will be performed")).isTrue();
     }
 
     @Test

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorIT.java
Patch:
@@ -2080,7 +2080,7 @@ public void shouldDetectPurgedHistory() throws Exception {
 
         final LogInterceptor logInterceptor = new LogInterceptor(SqlServerConnectorIT.class);
         start(SqlServerConnector.class, config);
-        assertConnectorNotRunning();
+        waitForConnectorShutdown("sqlserver", TestHelper.TEST_SERVER_NAME);
         assertThat(logInterceptor.containsStacktraceElement(
                 "The db history topic or its content is fully or partially missing. Please check database schema history topic configuration and re-execute the snapshot."))
                 .isTrue();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -796,7 +796,7 @@ else if (data instanceof Number) {
                     break;
                 case PRECISE:
                     if (data instanceof BigDecimal) {
-                        r.deliver(data);
+                        r.deliver(((BigDecimal) data).setScale(moneyFractionDigits, RoundingMode.HALF_UP));
                     }
                     else if (data instanceof Double) {
                         r.deliver(BigDecimal.valueOf((Double) data).setScale(moneyFractionDigits, RoundingMode.HALF_UP));

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoColumnValue.java
Patch:
@@ -19,7 +19,6 @@
 
 import org.postgresql.geometric.PGpoint;
 import org.postgresql.jdbc.PgArray;
-import org.postgresql.util.PGmoney;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -243,9 +242,9 @@ public Object asInterval() {
     }
 
     @Override
-    public PGmoney asMoney() {
+    public Object asMoney() {
         if (value.hasDatumInt64()) {
-            return new PGmoney(value.getDatumInt64() / 100.0);
+            return new BigDecimal(value.getDatumInt64()).divide(new BigDecimal(100.0));
         }
         return super.asMoney();
     }

File: debezium-server/debezium-server-rocketmq/src/main/java/io/debezium/server/rocketmq/RocketMqChangeConsumer.java
Patch:
@@ -153,7 +153,7 @@ public void onException(Throwable throwable) {
                 throw new DebeziumException(e);
             }
         }
-        
+
         // Messages have set default send timeout, so this will not block forever.
         latch.await();
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorRegressionIT.java
Patch:
@@ -349,14 +349,14 @@ else if (record.topic().endsWith("dbz_342_timetest")) {
         assertThat(rec1.get("c1")).isNull();
         assertThat(rec1.get("c2")).isEqualTo(0L);
         assertThat(rec1.get("c3")).isNull();
-        assertThat(rec1.get("c4")).isEqualTo("1970-01-01T00:00:00Z");
+        assertThat(rec1.get("c4")).isEqualTo("1970-01-01T00:00:00.00Z");
         assertThat(rec1.get("nnc1")).isEqualTo(0);
         assertThat(rec1.get("nnc2")).isEqualTo(0L);
         assertThat(rec1.get("nnc3")).isEqualTo(0L);
         assertThat(rec2.get("c1")).isNull();
         assertThat(rec2.get("c2")).isEqualTo(60_000_000L); // 1 minute
         assertThat(rec2.get("c3")).isNull();
-        assertThat(rec2.get("c4")).isEqualTo("1970-01-01T00:00:00Z");
+        assertThat(rec2.get("c4")).isEqualTo("1970-01-01T00:00:00.00Z");
         assertThat(rec2.get("nnc1")).isEqualTo(0);
         assertThat(rec2.get("nnc2")).isEqualTo(60_000_000L); // 1 minute
         assertThat(rec2.get("nnc3")).isEqualTo(0L);

File: debezium-core/src/main/java/io/debezium/time/ZonedTimestamp.java
Patch:
@@ -59,6 +59,7 @@ public class ZonedTimestamp {
      */
     private static DateTimeFormatter getDateTimeFormatter(Integer fractionalWidth) {
         // TIMESTAMP type passes fractionalWidth as -1.
+        // Java DateTimeFormatter supports 9 as maximum fraction
         if (fractionalWidth == null || fractionalWidth <= 0 || fractionalWidth > 9) {
             return FORMATTER;
         }

File: debezium-core/src/main/java/io/debezium/time/ZonedTimestamp.java
Patch:
@@ -59,7 +59,7 @@ public class ZonedTimestamp {
      */
     private static DateTimeFormatter getDateTimeFormatter(Integer fractionalWidth) {
         // TIMESTAMP type passes fractionalWidth as -1.
-        if (fractionalWidth == null || fractionalWidth <= 0) {
+        if (fractionalWidth == null || fractionalWidth <= 0 || fractionalWidth > 9) {
             return FORMATTER;
         }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSnapshotChangeEventSource.java
Patch:
@@ -145,7 +145,7 @@ private void updateOffsetForSnapshot(PostgresOffsetContext offset) throws SQLExc
         LOGGER.info("Read xlogStart at '{}' from transaction '{}'", xlogStart, txId);
 
         // use the old xmin, as we don't want to update it if in xmin recovery
-        offset.updateWalPosition(xlogStart, offset.lastCompletelyProcessedLsn(), clock.currentTime(), txId, offset.xmin(), null);
+        offset.updateWalPosition(xlogStart, offset.lastCompletelyProcessedLsn(), clock.currentTime(), txId, offset.xmin(), null, null);
     }
 
     protected void updateOffsetForPreSnapshotCatchUpStreaming(PostgresOffsetContext offset) throws SQLException {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SourceInfoTest.java
Patch:
@@ -51,7 +51,7 @@ public void connectorIsPresent() {
     @Test
     @FixFor("DBZ-934")
     public void canHandleNullValues() {
-        source.update(null, null, null, null, null);
+        source.update(null, null, null, null, null, null);
     }
 
     @Test

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/MongoDbShardedClusterTest.java
Patch:
@@ -15,6 +15,7 @@
 import org.bson.Document;
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -31,6 +32,7 @@
 /**
  * @see <a href="https://issues.redhat.com/browse/DBZ-5857">DBZ-5857</a>
  */
+@Disabled
 public class MongoDbShardedClusterTest {
 
     private final static Logger LOGGER = LoggerFactory.getLogger(MongoDbShardedClusterTest.class);

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/junit/MongoDbDatabaseProvider.java
Patch:
@@ -10,6 +10,7 @@
 
 public final class MongoDbDatabaseProvider {
 
+    public static final String MONGO_REPLICA_SIZE = "mongodb.replica.size";
     public static final String MONGO_DOCKER_DESKTOP_PORT_PROPERTY = "mongodb.docker.desktop.ports";
 
     // Should be aligned with definition in pom.xm
@@ -23,9 +24,10 @@ public final class MongoDbDatabaseProvider {
     public static MongoDbReplicaSet mongoDbReplicaSet() {
         // will be used only in environment with docker desktop
         var portResolver = ParsingPortResolver.parseProperty(MONGO_DOCKER_DESKTOP_PORT_PROPERTY, MONGO_DOCKER_DESKTOP_PORT_DEFAULT);
+        var replicaSize = Integer.parseInt(System.getProperty(MONGO_REPLICA_SIZE, "1"));
 
         return MongoDbReplicaSet.replicaSet()
-                .memberCount(3)
+                .memberCount(replicaSize)
                 .portResolver(portResolver)
                 .build();
     }

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/PortForwardableDatabaseController.java
Patch:
@@ -8,7 +8,7 @@
 import java.io.IOException;
 
 public interface PortForwardableDatabaseController {
-    void forwardDatabasePorts();
+    void forwardDatabasePorts() throws IOException;
 
     void closeDatabasePortForwards() throws IOException;
 }

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/db2/OcpDB2Controller.java
Patch:
@@ -9,7 +9,6 @@
 import static io.debezium.testing.system.tools.ConfigProperties.DATABASE_DB2_DBZ_USERNAME;
 import static io.debezium.testing.system.tools.OpenShiftUtils.isRunningFromOcp;
 
-import java.io.IOException;
 import java.sql.Connection;
 import java.util.List;
 
@@ -37,7 +36,7 @@ public OcpDB2Controller(Deployment deployment, List<Service> services, OpenShift
     }
 
     @Override
-    public void initialize() throws IOException {
+    public void initialize() {
         if (!isRunningFromOcp()) {
             forwardDatabasePorts();
         }

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/KafkaController.java
Patch:
@@ -10,7 +10,6 @@
 import static org.apache.kafka.clients.consumer.ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG;
 import static org.apache.kafka.clients.consumer.ConsumerConfig.GROUP_ID_CONFIG;
 
-import java.io.IOException;
 import java.util.Properties;
 
 /**
@@ -47,7 +46,7 @@ public interface KafkaController {
     /**
      * @return default kafka consumer configuration
      */
-    default Properties getDefaultConsumerProperties() throws IOException {
+    default Properties getDefaultConsumerProperties() {
         Properties consumerProps = new Properties();
         consumerProps.put(BOOTSTRAP_SERVERS_CONFIG, getPublicBootstrapAddress());
         consumerProps.put(GROUP_ID_CONFIG, "DEBEZIUM_IT_01");

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/kafka/DockerKafka.java
Patch:
@@ -5,8 +5,6 @@
  */
 package io.debezium.testing.system.fixtures.kafka;
 
-import java.io.IOException;
-
 import org.jetbrains.annotations.NotNull;
 import org.junit.jupiter.api.extension.ExtensionContext;
 import org.testcontainers.containers.Network;
@@ -35,7 +33,7 @@ public DockerKafka(@NotNull ExtensionContext.Store store) {
     }
 
     @Override
-    public void setup() throws IOException {
+    public void setup() {
         DockerKafkaDeployer kafkaDeployer = new DockerKafkaDeployer.Builder()
                 .withNetwork(network)
                 .build();

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/Db2Tests.java
Patch:
@@ -16,7 +16,7 @@
 import org.junit.jupiter.api.Test;
 
 import io.debezium.testing.system.assertions.KafkaAssertions;
-import io.debezium.testing.system.tests.SqlConnectorTest;
+import io.debezium.testing.system.tests.ConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseClient;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -27,7 +27,7 @@
 import okhttp3.Request;
 import okhttp3.Response;
 
-public abstract class Db2Tests extends SqlConnectorTest {
+public abstract class Db2Tests extends ConnectorTest {
 
     public Db2Tests(
                     KafkaController kafkaController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mongodb/DockerRhelMongoConnectorIT.java
Patch:
@@ -25,7 +25,7 @@
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @Tag("acceptance")
 @Tag("mongo")
-@Tag("openshift")
+@Tag("rhel")
 @Tag("docker")
 @Fixture(DockerNetwork.class)
 @Fixture(DockerKafka.class)

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mongodb/MongoTests.java
Patch:
@@ -22,7 +22,7 @@
 import com.mongodb.client.model.Updates;
 
 import io.debezium.testing.system.assertions.KafkaAssertions;
-import io.debezium.testing.system.tests.MongoConnectorTest;
+import io.debezium.testing.system.tests.ConnectorTest;
 import io.debezium.testing.system.tools.databases.mongodb.MongoDatabaseClient;
 import io.debezium.testing.system.tools.databases.mongodb.MongoDatabaseController;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -33,7 +33,7 @@
 import okhttp3.Request;
 import okhttp3.Response;
 
-public abstract class MongoTests extends MongoConnectorTest {
+public abstract class MongoTests extends ConnectorTest {
 
     public MongoTests(
                       KafkaController kafkaController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mysql/MySqlTests.java
Patch:
@@ -16,7 +16,7 @@
 import org.junit.jupiter.api.Test;
 
 import io.debezium.testing.system.assertions.KafkaAssertions;
-import io.debezium.testing.system.tests.SqlConnectorTest;
+import io.debezium.testing.system.tests.ConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseClient;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -27,7 +27,7 @@
 import okhttp3.Request;
 import okhttp3.Response;
 
-public abstract class MySqlTests extends SqlConnectorTest {
+public abstract class MySqlTests extends ConnectorTest {
 
     public MySqlTests(
                       KafkaController kafkaController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/oracle/OracleTests.java
Patch:
@@ -16,7 +16,7 @@
 import org.junit.jupiter.api.Test;
 
 import io.debezium.testing.system.assertions.KafkaAssertions;
-import io.debezium.testing.system.tests.SqlConnectorTest;
+import io.debezium.testing.system.tests.ConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseClient;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -27,7 +27,7 @@
 import okhttp3.Request;
 import okhttp3.Response;
 
-public abstract class OracleTests extends SqlConnectorTest {
+public abstract class OracleTests extends ConnectorTest {
 
     public OracleTests(
                        KafkaController kafkaController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/postgresql/PostgreSqlTests.java
Patch:
@@ -17,7 +17,7 @@
 import org.junit.jupiter.api.Test;
 
 import io.debezium.testing.system.assertions.KafkaAssertions;
-import io.debezium.testing.system.tests.SqlConnectorTest;
+import io.debezium.testing.system.tests.ConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseClient;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -28,7 +28,7 @@
 import okhttp3.Request;
 import okhttp3.Response;
 
-public abstract class PostgreSqlTests extends SqlConnectorTest {
+public abstract class PostgreSqlTests extends ConnectorTest {
 
     public PostgreSqlTests(
                            KafkaController kafkaController,

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/DatabaseController.java
Patch:
@@ -5,6 +5,8 @@
  */
 package io.debezium.testing.system.tools.databases;
 
+import java.io.IOException;
+
 public interface DatabaseController<C extends DatabaseClient<?, ?>> {
 
     /**
@@ -52,7 +54,7 @@ public interface DatabaseController<C extends DatabaseClient<?, ?>> {
      * Database initialisation
      * @throws InterruptedException on timing issue
      */
-    default void initialize() throws InterruptedException {
+    default void initialize() throws InterruptedException, IOException {
         // no-op
     }
 

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/databases/ocp/OcpMongo.java
Patch:
@@ -18,7 +18,6 @@
 public class OcpMongo extends OcpDatabaseFixture<MongoDatabaseController> {
 
     public static final String DB_DEPLOYMENT_PATH = "/database-resources/mongodb/deployment.yaml";
-    public static final String DB_SERVICE_PATH_LB = "/database-resources/mongodb/service-lb.yaml";
     public static final String DB_SERVICE_PATH = "/database-resources/mongodb/service.yaml";
 
     public OcpMongo(ExtensionContext.Store store) {

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/resources/ConnectorFactories.java
Patch:
@@ -92,7 +92,7 @@ public ConnectorConfigBuilder mongo(MongoDatabaseController controller, String c
         int dbPort = controller.getDatabasePort();
 
         return cb
-                .put("mongodb.name", cb.getDbServerName())
+                .put("topic.prefix", cb.getDbServerName())
                 .put("connector.class", "io.debezium.connector.mongodb.MongoDbConnector")
                 .put("task.max", 1)
                 .put("mongodb.hosts", "rs0/" + dbHost + ":" + dbPort)

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/Db2Tests.java
Patch:
@@ -16,7 +16,7 @@
 import org.junit.jupiter.api.Test;
 
 import io.debezium.testing.system.assertions.KafkaAssertions;
-import io.debezium.testing.system.tests.ConnectorTest;
+import io.debezium.testing.system.tests.SqlConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseClient;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -27,7 +27,7 @@
 import okhttp3.Request;
 import okhttp3.Response;
 
-public abstract class Db2Tests extends ConnectorTest {
+public abstract class Db2Tests extends SqlConnectorTest {
 
     public Db2Tests(
                     KafkaController kafkaController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mongodb/MongoTests.java
Patch:
@@ -22,7 +22,7 @@
 import com.mongodb.client.model.Updates;
 
 import io.debezium.testing.system.assertions.KafkaAssertions;
-import io.debezium.testing.system.tests.ConnectorTest;
+import io.debezium.testing.system.tests.MongoConnectorTest;
 import io.debezium.testing.system.tools.databases.mongodb.MongoDatabaseClient;
 import io.debezium.testing.system.tools.databases.mongodb.MongoDatabaseController;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -33,7 +33,7 @@
 import okhttp3.Request;
 import okhttp3.Response;
 
-public abstract class MongoTests extends ConnectorTest {
+public abstract class MongoTests extends MongoConnectorTest {
 
     public MongoTests(
                       KafkaController kafkaController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mysql/MySqlTests.java
Patch:
@@ -16,7 +16,7 @@
 import org.junit.jupiter.api.Test;
 
 import io.debezium.testing.system.assertions.KafkaAssertions;
-import io.debezium.testing.system.tests.ConnectorTest;
+import io.debezium.testing.system.tests.SqlConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseClient;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -27,7 +27,7 @@
 import okhttp3.Request;
 import okhttp3.Response;
 
-public abstract class MySqlTests extends ConnectorTest {
+public abstract class MySqlTests extends SqlConnectorTest {
 
     public MySqlTests(
                       KafkaController kafkaController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/oracle/OracleTests.java
Patch:
@@ -16,7 +16,7 @@
 import org.junit.jupiter.api.Test;
 
 import io.debezium.testing.system.assertions.KafkaAssertions;
-import io.debezium.testing.system.tests.ConnectorTest;
+import io.debezium.testing.system.tests.SqlConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseClient;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -27,7 +27,7 @@
 import okhttp3.Request;
 import okhttp3.Response;
 
-public abstract class OracleTests extends ConnectorTest {
+public abstract class OracleTests extends SqlConnectorTest {
 
     public OracleTests(
                        KafkaController kafkaController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/postgresql/PostgreSqlTests.java
Patch:
@@ -17,7 +17,7 @@
 import org.junit.jupiter.api.Test;
 
 import io.debezium.testing.system.assertions.KafkaAssertions;
-import io.debezium.testing.system.tests.ConnectorTest;
+import io.debezium.testing.system.tests.SqlConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseClient;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -28,7 +28,7 @@
 import okhttp3.Request;
 import okhttp3.Response;
 
-public abstract class PostgreSqlTests extends ConnectorTest {
+public abstract class PostgreSqlTests extends SqlConnectorTest {
 
     public PostgreSqlTests(
                            KafkaController kafkaController,

File: debezium-core/src/test/java/io/debezium/data/VerifyRecord.java
Patch:
@@ -105,6 +105,7 @@ public static interface RecordValueComparator {
             config.put("apicurio.registry.url", APICURIO_URL);
             config.put("apicurio.registry.auto-register", true);
             config.put("apicurio.registry.find-latest", true);
+            config.put("apicurio.registry.check-period-ms", 1000);
         }
         else {
             config.put("schema.registry.url", "http://fake-url");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleBinaryModeIT.java
Patch:
@@ -15,7 +15,6 @@
 
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
-
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/SignalsIT.java
Patch:
@@ -13,7 +13,6 @@
 
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
-
 import org.junit.AfterClass;
 import org.junit.Before;
 import org.junit.BeforeClass;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/IncrementalSnapshotIT.java
Patch:
@@ -6,6 +6,7 @@
 
 package io.debezium.connector.mysql;
 
+import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.entry;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
@@ -24,7 +25,6 @@
 
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
-import org.assertj.core.api.Assertions;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
@@ -297,7 +297,7 @@ record -> {
             LocalDate dt = dateTime.toLocalDate();
             LocalDate d = LocalDate.parse(String.format("%s-05-01", 2000 + i));
             LocalTime t = LocalTime.parse(String.format("0%s:00:00", i));
-            Assertions.assertThat(dbChanges).contains(entry(i + 1, List.of(dt, d, t)));
+            assertThat(dbChanges).contains(entry(i + 1, List.of(dt, d, t)));
         }
     }
 
@@ -332,7 +332,7 @@ record -> {
                 },
                 DATABASE.topicForTable("a_date"),
                 null);
-        Assertions.assertThat(dbChanges).contains(entry(1, Arrays.asList(0, null)));
+        assertThat(dbChanges).contains(entry(1, Arrays.asList(0, null)));
         assertFalse(logInterceptor.containsWarnMessage("Invalid length when read MySQL DATE value. BIN_LEN_DATE is 0."));
     }
 }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlSchemaNameAdjustmentModeIT.java
Patch:
@@ -13,7 +13,6 @@
 
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
-import org.assertj.core.api.Assertions;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
@@ -75,7 +74,7 @@ private Struct consume(SchemaNameAdjustmentMode adjustmentMode) throws Interrupt
 
         SourceRecords records = consumeRecordsByTopic(6 + 1); // 6 DDL changes, 1 INSERT
         final List<SourceRecord> results = records.recordsForTopic(DATABASE.topicForTable("name-adjustment"));
-        Assertions.assertThat(results).hasSize(1);
+        assertThat(results).hasSize(1);
 
         return (Struct) results.get(0).value();
     }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/zzz/ZZZGtidSetIT.java
Patch:
@@ -16,7 +16,6 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import org.assertj.core.api.Assertions;
 import org.awaitility.Awaitility;
 import org.junit.After;
 import org.junit.Before;
@@ -127,7 +126,7 @@ public void shouldProcessPurgedGtidSet() throws SQLException, InterruptedExcepti
             final Pattern p = Pattern.compile(".*:(.*)-.*");
             final Matcher m = p.matcher(gtids);
             m.matches();
-            Assertions.assertThat(m.group(1)).isNotEqualTo("1");
+            assertThat(m.group(1)).isNotEqualTo("1");
         });
 
         stopConnector();

File: debezium-connector-mysql/src/test/java/io/debezium/relational/history/KafkaSchemaHistoryTest.java
Patch:
@@ -20,7 +20,6 @@
 import org.apache.kafka.clients.producer.ProducerRecord;
 import org.apache.kafka.common.config.ConfigValue;
 import org.apache.kafka.common.serialization.StringSerializer;
-import org.assertj.core.api.Assertions;
 import org.junit.After;
 import org.junit.AfterClass;
 import org.junit.Before;
@@ -374,7 +373,7 @@ public void shouldValidateMandatoryValues() {
                 .build();
 
         final Map<String, ConfigValue> issues = config.validate(KafkaSchemaHistory.ALL_FIELDS);
-        Assertions.assertThat(issues.keySet()).isEqualTo(Collect.unmodifiableSet(
+        assertThat(issues.keySet()).isEqualTo(Collect.unmodifiableSet(
                 "schema.history.internal.name",
                 "schema.history.internal.connector.class",
                 "schema.history.internal.kafka.topic",

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleBinaryModeIT.java
Patch:
@@ -5,6 +5,7 @@
  */
 package io.debezium.connector.oracle;
 
+import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.Assert.assertEquals;
 
 import java.nio.ByteBuffer;
@@ -14,7 +15,7 @@
 
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
-import org.assertj.core.api.Assertions;
+
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
@@ -101,7 +102,7 @@ private Struct consume(BinaryHandlingMode binaryMode) throws InterruptedExceptio
 
         SourceRecords records = consumeRecordsByTopic(1);
         final List<SourceRecord> results = records.recordsForTopic("server1.DEBEZIUM.BINARY_MODE_TEST");
-        Assertions.assertThat(results).hasSize(1);
+        assertThat(results).hasSize(1);
 
         return (Struct) ((Struct) results.get(0).value()).get("after");
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsSnapshotProducerIT.java
Patch:
@@ -31,7 +31,6 @@
 import org.apache.kafka.connect.data.SchemaBuilder;
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
-import org.assertj.core.api.Assertions;
 import org.junit.Before;
 import org.junit.Rule;
 import org.junit.Test;
@@ -426,7 +425,7 @@ public void shouldGenerateSnapshotsForPartitionedTables() throws Exception {
         int expectedTotalCount = expectedTopicCounts.values().stream().mapToInt(Integer::intValue).sum();
 
         TestConsumer consumer = testConsumer(expectedTotalCount);
-        consumer.await(TestHelper.waitTimeForRecords() * 30, TimeUnit.SECONDS);
+        consumer.await(TestHelper.waitTimeForRecords() * 30L, TimeUnit.SECONDS);
 
         Map<String, Integer> actualTopicCounts = new HashMap<>();
         AtomicInteger actualTotalCount = new AtomicInteger(0);
@@ -436,7 +435,7 @@ public void shouldGenerateSnapshotsForPartitionedTables() throws Exception {
             Struct key = (Struct) record.key();
             if (key != null) {
                 final Integer id = key.getInt32("pk");
-                Assertions.assertThat(ids).doesNotContain(id);
+                assertThat(ids).doesNotContain(id);
                 ids.add(id);
             }
 

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerBinaryModeIT.java
Patch:
@@ -5,6 +5,7 @@
  */
 package io.debezium.connector.sqlserver;
 
+import static org.assertj.core.api.Assertions.assertThat;
 import static org.junit.Assert.assertEquals;
 
 import java.nio.ByteBuffer;
@@ -13,7 +14,6 @@
 
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
-import org.assertj.core.api.Assertions;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
@@ -100,7 +100,7 @@ private Struct consume(BinaryHandlingMode binaryMode) throws InterruptedExceptio
 
         SourceRecords records = consumeRecordsByTopic(1);
         final List<SourceRecord> results = records.recordsForTopic("server1.testDB1.dbo.binary_mode_test");
-        Assertions.assertThat(results).hasSize(1);
+        assertThat(results).hasSize(1);
 
         return (Struct) ((Struct) results.get(0).value()).get("after");
     }

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerSchemaNameAdjustmentModeIT.java
Patch:
@@ -12,7 +12,6 @@
 
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
-import org.assertj.core.api.Assertions;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
@@ -77,7 +76,7 @@ private Struct consume(SchemaNameAdjustmentMode adjustmentMode) throws Interrupt
 
         SourceRecords records = consumeRecordsByTopic(1);
         final List<SourceRecord> results = records.recordsForTopic("server1.testDB1.dbo.name-adjustment");
-        Assertions.assertThat(results).hasSize(1);
+        assertThat(results).hasSize(1);
 
         return (Struct) results.get(0).value();
     }

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/MongoDbShardedClusterTest.java
Patch:
@@ -11,7 +11,6 @@
 import static java.util.stream.StreamSupport.stream;
 import static org.assertj.core.api.Assertions.assertThat;
 
-import org.assertj.core.api.Assertions;
 import org.assertj.core.api.ListAssert;
 import org.bson.Document;
 import org.junit.jupiter.api.Test;

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/MongoDbReplicaSet.java
Patch:
@@ -27,6 +27,7 @@
 import org.testcontainers.shaded.com.fasterxml.jackson.databind.JsonNode;
 
 import io.debezium.testing.testcontainers.MongoDbContainer.Address;
+import io.debezium.testing.testcontainers.util.MoreStartables;
 
 /**
  * A MongoDB replica set.
@@ -146,7 +147,7 @@ public void start() {
 
         // Start all containers in parallel
         LOGGER.info("[{}] Starting {} node replica set...", name, memberCount);
-        MongoDbStartables.deepStart(getDependencies().stream());
+        MoreStartables.deepStartSync(getDependencies().stream());
 
         // Initialize the configured replica set to contain all the cluster's members
         LOGGER.info("[{}] Initializing replica set...", name);
@@ -165,7 +166,7 @@ public void start() {
     @Override
     public void stop() {
         LOGGER.info("[{}] Stopping...", name);
-        MongoDbStartables.deepStop(members.stream());
+        MoreStartables.deepStopSync(members.stream());
         network.close();
     }
 

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/MongoDbReplicaSetTest.java
Patch:
@@ -12,7 +12,7 @@
 
 import org.bson.BsonDocument;
 import org.bson.Document;
-import org.junit.Test;
+import org.junit.jupiter.api.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/MongoDbShardedClusterTest.java
Patch:
@@ -14,7 +14,7 @@
 import org.assertj.core.api.Assertions;
 import org.assertj.core.api.ListAssert;
 import org.bson.Document;
-import org.junit.Test;
+import org.junit.jupiter.api.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -80,7 +80,7 @@ private static ListAssert<Document> assertThatCollection(MongoCollection<Documen
     }
 
     private static ListAssert<Document> assertThatShards(MongoClient client) {
-        return Assertions.assertThat(client
+        return assertThat(client
                 .getDatabase("admin")
                 .runCommand(new BasicDBObject("listShards", 1))
                 .getList("shards", Document.class));

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/cluster/MongoDbShardedCluster.java
Patch:
@@ -27,8 +27,6 @@
 
 /**
  * A MongoDB sharded cluster.
- *
- * @see <a href="https://issues.redhat.com/browse/DBZ-5857">DBZ-5857</a>
  */
 public class MongoDbShardedCluster implements Startable {
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -368,6 +368,9 @@ protected void validateSlotIsInExpectedState(WalPositionLocator walPosition) thr
             if (e.getMessage().matches("ERROR: function pg_replication_slot_advance.*does not exist(.|\\n)*")) {
                 LOGGER.info("Postgres server doesn't support the command pg_replication_slot_advance(). Not seeking to last known offset.");
             }
+            else if (e.getMessage().matches("ERROR: must be superuser or replication role to use replication slots(.|\\n)*")) {
+                LOGGER.warn("Unable to use pg_replication_slot_advance() function. The Postgres server is likely on an old RDS version: " + e.getMessage());
+            }
             else if (e.getMessage().matches("ERROR: cannot advance replication slot to.*")) {
                 throw new DebeziumException(
                         String.format("Cannot seek to the last known offset '%s' on replication slot '%s'. Error from server: %s", lsn.asString(), slotName,

File: debezium-server/debezium-server-nats-jetstream/src/main/java/io/debezium/server/nats/jetstream/NatsJetStreamChangeConsumer.java
Patch:
@@ -14,7 +14,6 @@
 import javax.inject.Inject;
 import javax.inject.Named;
 
-import io.debezium.server.CustomConsumerBuilder;
 import org.eclipse.microprofile.config.Config;
 import org.eclipse.microprofile.config.ConfigProvider;
 import org.eclipse.microprofile.config.inject.ConfigProperty;
@@ -26,6 +25,7 @@
 import io.debezium.engine.DebeziumEngine;
 import io.debezium.engine.DebeziumEngine.RecordCommitter;
 import io.debezium.server.BaseChangeConsumer;
+import io.debezium.server.CustomConsumerBuilder;
 import io.nats.client.Connection;
 import io.nats.client.JetStream;
 import io.nats.client.JetStreamManagement;
@@ -57,7 +57,6 @@ public class NatsJetStreamChangeConsumer extends BaseChangeConsumer
     @ConfigProperty(name = PROP_CREATE_STREAM, defaultValue = "false")
     boolean createStream;
 
-
     @Inject
     @CustomConsumerBuilder
     Instance<JetStream> customStreamingConnection;

File: debezium-server/debezium-server-nats-jetstream/src/test/java/io/debezium/server/nats/jetstream/NatsJetStreamTestConfigSource.java
Patch:
@@ -20,7 +20,6 @@ public NatsJetStreamTestConfigSource() {
         natsJetStreamTest.put("debezium.sink.nats-jetstream.url",
                 NatsJetStreamTestResourceLifecycleManager.getNatsContainerUrl());
         natsJetStreamTest.put("debezium.sink.nats-jetstream.create-stream", "true");
-        natsJetStreamTest.put("debezium.sink.nats-jetstream.subjects", "asd,asd");
         natsJetStreamTest.put("debezium.source.connector.class", "io.debezium.connector.postgresql.PostgresConnector");
         natsJetStreamTest.put("debezium.source.topic.prefix", "testc");
         natsJetStreamTest.put("debezium.source.schema.include.list", "inventory");

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/connection/ReplicationConnectionIT.java
Patch:
@@ -86,7 +86,6 @@ public void shouldCreateAndDropReplicationSlots() throws Exception {
 
     @Test(expected = DebeziumException.class)
     public void shouldNotAllowMultipleReplicationSlotsOnTheSameDBSlotAndPlugin() throws Exception {
-        LogInterceptor interceptor = new LogInterceptor(PostgresReplicationConnection.class);
         // create a replication connection which should be dropped once it's closed
         try (ReplicationConnection conn1 = TestHelper.createForReplication("test1", true)) {
             conn1.startStreaming(new WalPositionLocator());
@@ -95,7 +94,7 @@ public void shouldNotAllowMultipleReplicationSlotsOnTheSameDBSlotAndPlugin() thr
                 fail("Should not be able to create 2 replication connections on the same db, plugin and slot");
             }
             catch (Exception e) {
-                assertTrue(interceptor.containsWarnMessage("and retrying, attempt number 2 over 2"));
+                assertTrue(e.getCause().getMessage().contains("ERROR: replication slot \"test1\" is active"));
                 throw e;
             }
         }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -351,7 +351,7 @@ public ReplicationStream startStreaming(Lsn offset, WalPositionLocator walPositi
         }
     }
 
-    protected void validateSlotIsInExpectedState(Lsn lsn) throws SQLException, PSQLException {
+    protected void validateSlotIsInExpectedState(Lsn lsn) throws SQLException {
         try (Statement stmt = pgConnection().createStatement()) {
             String seekCommand = String.format(
                     "SELECT pg_replication_slot_advance('%s', '%s')",
@@ -370,7 +370,7 @@ else if (e.getMessage().matches("ERROR: cannot advance replication slot to.*"))
                                 e.getMessage()));
             }
             else {
-                throw e;
+                throw new DebeziumException(e);
             }
         }
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -256,6 +256,7 @@ public void shouldReceiveChangesAfterConnectionRestart() throws Exception {
 
         startConnector(config -> config
                 .with(PostgresConnectorConfig.INCLUDE_UNKNOWN_DATATYPES, true)
+                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE)
                 .with(PostgresConnectorConfig.SCHEMA_EXCLUDE_LIST, "postgis"));
 
         TestHelper.execute("CREATE TABLE t0 (pk SERIAL, d INTEGER, PRIMARY KEY(pk));");

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -1372,7 +1372,7 @@ public void shouldRegularlyFlushLsnWithTxMonitoring() throws InterruptedExceptio
         TestHelper.execute(SETUP_TABLES_STMT);
         Configuration config = TestHelper.defaultConfig()
                 .with(PostgresConnectorConfig.SNAPSHOT_MODE, SnapshotMode.NEVER.getValue())
-                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.TRUE)
+                .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE)
                 .with(PostgresConnectorConfig.TABLE_INCLUDE_LIST, "s1.a")
                 .with(PostgresConnectorConfig.PROVIDE_TRANSACTION_METADATA, true)
                 .build();

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/DebeziumEngineIT.java
Patch:
@@ -68,6 +68,7 @@ public class DebeziumEngineIT {
     public void before() throws SQLException {
         OFFSET_STORE_PATH.getParent().toFile().mkdirs();
         OFFSET_STORE_PATH.toFile().delete();
+        TestHelper.dropDefaultReplicationSlot();
         TestHelper.dropAllSchemas();
         TestHelper.execute(
                 "CREATE SCHEMA engine;",
@@ -244,6 +245,7 @@ public void testOffsetsCommitAfterStop() throws Exception {
                 OFFSET_STORE_PATH.toAbsolutePath().toString());
         props.setProperty("offset.flush.interval.ms", "3000");
         props.setProperty("converter.schemas.enable", "false");
+        props.setProperty("slot.drop.on.stop", "false");
         props.setProperty("offset.storage",
                 TestOffsetStore.class.getName());
 

File: debezium-core/src/test/java/io/debezium/transforms/outbox/JsonSchemaDataTest.java
Patch:
@@ -100,7 +100,7 @@ private String getFile(String fileName) throws IOException, URISyntaxException {
     }
 
     @Test
-    @FixFor("DBZ-DBZ-5796")
+    @FixFor("DBZ-5796")
     public void shouldConvertNullNodeToOptionalBytes() throws Exception {
         jsonSchemaData = new JsonSchemaData(JsonPayloadNullFieldBehavior.OPTIONAL_BYTES);
         String json = "{\"heartbeat\": 1, \"email\": null}";

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDecimalIT.java
Patch:
@@ -48,7 +48,6 @@ public void beforeEach() {
         DATABASE.createAndInitialize();
         initializeConnectorTestFramework();
         Testing.Files.delete(SCHEMA_HISTORY_PATH);
-        skipAvroValidation(); // https://github.com/confluentinc/schema-registry/issues/1693
     }
 
     @After

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MysqlDefaultValueIT.java
Patch:
@@ -72,7 +72,6 @@ public void beforeEach() {
         DATABASE.createAndInitialize();
         initializeConnectorTestFramework();
         Testing.Files.delete(SCHEMA_HISTORY_PATH);
-        skipAvroValidation(); // https://github.com/confluentinc/schema-registry/issues/1693
     }
 
     @After

File: debezium-embedded/src/test/java/io/debezium/embedded/AbstractConnectorTest.java
Patch:
@@ -891,7 +891,6 @@ protected boolean waitForAvailableRecords(long timeout, TimeUnit unit) {
 
     /**
      * Disable record validation using Avro converter.
-     * Introduced to workaround https://github.com/confluentinc/schema-registry/issues/1693
      */
     protected void skipAvroValidation() {
         skipAvroValidation = true;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorTask.java
Patch:
@@ -178,7 +178,7 @@ private void validateRedoLogConfiguration() {
 
     private void validateAndLoadSchemaHistory(OracleConnectorConfig config, OraclePartition partition, OracleOffsetContext offset, OracleDatabaseSchema schema) {
         if (offset == null) {
-            if (config.getSnapshotMode().shouldSnapshotOnSchemaError()) {
+            if (config.getSnapshotMode().shouldSnapshotOnSchemaError() && config.getSnapshotMode() != OracleConnectorConfig.SnapshotMode.ALWAYS) {
                 // We are in schema only recovery mode, use the existing redo log position
                 // would like to also verify redo log position exists, but it defaults to 0 which is technically valid
                 throw new DebeziumException("Could not find existing redo log information while attempting schema only recovery snapshot");

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -731,7 +731,7 @@ public enum SnapshotMode implements EnumeratedValue {
         /**
          * Performs a snapshot of data and schema upon each connector start.
          */
-        ALWAYS("always", true, true, false),
+        ALWAYS("always", true, true, true),
 
         /**
          * Perform a snapshot of data and schema upon initial startup of a connector.

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/databases/docker/DockerSqlServer.java
Patch:
@@ -22,7 +22,7 @@ public DockerSqlServer(ExtensionContext.Store store) {
 
     @Override
     protected SqlDatabaseController databaseController() throws Exception {
-        Class.forName("org.postgresql.Driver");
+        Class.forName("com.microsoft.sqlserver.jdbc.SQLServerDriver");
         DockerSqlServerDeployer deployer = new DockerSqlServerDeployer.Builder()
                 .withNetwork(network)
                 .build();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerHelper.java
Patch:
@@ -125,8 +125,8 @@ public static List<LogFile> getLogFilesForOffsetScn(OracleConnection connection,
         LOGGER.trace("Getting logs to be mined for offset scn {}", offsetScn);
 
         final List<LogFile> logFiles = new ArrayList<>();
-        final Set<LogFile> onlineLogFiles = new HashSet<>();
-        final Set<LogFile> archivedLogFiles = new HashSet<>();
+        final Set<LogFile> onlineLogFiles = new LinkedHashSet<>();
+        final Set<LogFile> archivedLogFiles = new LinkedHashSet<>();
 
         connection.query(SqlUtils.allMinableLogsQuery(offsetScn, archiveLogRetention, archiveLogOnlyMode, archiveDestinationName), rs -> {
             while (rs.next()) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/SqlUtils.java
Patch:
@@ -110,7 +110,7 @@ public static String allMinableLogsQuery(Scn scn, Duration archiveLogRetention,
         // ON A.FIRST_CHANGE# = L.FIRST_CHANGE# AND A.NEXT_CHANGE# = L.NEXT_CHANGE#
         // WHERE (A.FIRST_CHANGE# IS NULL OR A.STATUS <> 'A')
         // AND F.GROUP# = L.GROUP#
-        // GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, L.STATUS, L.ARCHIVED, L.SEQUENCE#
+        // GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, L.STATUS, L.ARCHIVED, L.SEQUENCE#, L.THREAD#
         //
         // The above query joins the redo logs view with the archived logs view, excluding any redo log that has
         // already been archived and has a matching redo log SCN range in the archive logs view. This allows
@@ -151,7 +151,7 @@ public static String allMinableLogsQuery(Scn scn, Duration archiveLogRetention,
             sb.append("ON A.FIRST_CHANGE# = L.FIRST_CHANGE# AND A.NEXT_CHANGE# = L.NEXT_CHANGE# ");
             sb.append("WHERE (A.STATUS <> 'A' OR A.FIRST_CHANGE# IS NULL) ");
             sb.append("AND F.GROUP# = L.GROUP# ");
-            sb.append("GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, L.STATUS, L.ARCHIVED, L.SEQUENCE# ");
+            sb.append("GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, L.STATUS, L.ARCHIVED, L.SEQUENCE#, L.THREAD# ");
             sb.append("UNION ");
         }
         sb.append("SELECT A.NAME AS FILE_NAME, A.FIRST_CHANGE# FIRST_CHANGE, A.NEXT_CHANGE# NEXT_CHANGE, 'YES', ");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/SqlUtilsTest.java
Patch:
@@ -99,7 +99,7 @@ public void testStatements() {
                 "L.STATUS, 'ONLINE' AS TYPE, L.SEQUENCE# AS SEQ, 'NO' AS DICT_START, 'NO' AS DICT_END, L.THREAD# AS THREAD FROM V$LOGFILE F, " +
                 "V$LOG L LEFT JOIN V$ARCHIVED_LOG A ON A.FIRST_CHANGE# = L.FIRST_CHANGE# AND A.NEXT_CHANGE# = L.NEXT_CHANGE# " +
                 "WHERE (A.STATUS <> 'A' OR A.FIRST_CHANGE# IS NULL) AND F.GROUP# = L.GROUP# GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, " +
-                "L.STATUS, L.ARCHIVED, L.SEQUENCE# UNION SELECT A.NAME AS FILE_NAME, A.FIRST_CHANGE# FIRST_CHANGE, " +
+                "L.STATUS, L.ARCHIVED, L.SEQUENCE#, L.THREAD# UNION SELECT A.NAME AS FILE_NAME, A.FIRST_CHANGE# FIRST_CHANGE, " +
                 "A.NEXT_CHANGE# NEXT_CHANGE, 'YES', NULL, 'ARCHIVED', A.SEQUENCE# AS SEQ, A.DICTIONARY_BEGIN, " +
                 "A.DICTIONARY_END, A.THREAD# AS THREAD FROM V$ARCHIVED_LOG A WHERE A.NAME IS NOT NULL AND A.ARCHIVED = 'YES' AND A.STATUS = 'A' " +
                 "AND A.NEXT_CHANGE# > 10 AND A.DEST_ID IN (SELECT DEST_ID FROM V$ARCHIVE_DEST_STATUS WHERE STATUS='VALID' " +
@@ -111,7 +111,7 @@ public void testStatements() {
                 "L.STATUS, 'ONLINE' AS TYPE, L.SEQUENCE# AS SEQ, 'NO' AS DICT_START, 'NO' AS DICT_END, L.THREAD# AS THREAD FROM V$LOGFILE F, " +
                 "V$LOG L LEFT JOIN V$ARCHIVED_LOG A ON A.FIRST_CHANGE# = L.FIRST_CHANGE# AND A.NEXT_CHANGE# = L.NEXT_CHANGE# " +
                 "WHERE (A.STATUS <> 'A' OR A.FIRST_CHANGE# IS NULL) AND F.GROUP# = L.GROUP# GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, " +
-                "L.STATUS, L.ARCHIVED, L.SEQUENCE# UNION SELECT A.NAME AS FILE_NAME, A.FIRST_CHANGE# FIRST_CHANGE, " +
+                "L.STATUS, L.ARCHIVED, L.SEQUENCE#, L.THREAD# UNION SELECT A.NAME AS FILE_NAME, A.FIRST_CHANGE# FIRST_CHANGE, " +
                 "A.NEXT_CHANGE# NEXT_CHANGE, 'YES', NULL, 'ARCHIVED', A.SEQUENCE# AS SEQ, A.DICTIONARY_BEGIN, " +
                 "A.DICTIONARY_END, A.THREAD# AS THREAD FROM V$ARCHIVED_LOG A WHERE A.NAME IS NOT NULL AND A.ARCHIVED = 'YES' AND A.STATUS = 'A' " +
                 "AND A.NEXT_CHANGE# > 10 AND A.DEST_ID IN (SELECT DEST_ID FROM V$ARCHIVE_DEST_STATUS WHERE STATUS='VALID' " +
@@ -131,7 +131,7 @@ public void testStatements() {
                 "L.STATUS, 'ONLINE' AS TYPE, L.SEQUENCE# AS SEQ, 'NO' AS DICT_START, 'NO' AS DICT_END, L.THREAD# AS THREAD FROM V$LOGFILE F, " +
                 "V$LOG L LEFT JOIN V$ARCHIVED_LOG A ON A.FIRST_CHANGE# = L.FIRST_CHANGE# AND A.NEXT_CHANGE# = L.NEXT_CHANGE# " +
                 "WHERE (A.STATUS <> 'A' OR A.FIRST_CHANGE# IS NULL) AND F.GROUP# = L.GROUP# GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, " +
-                "L.STATUS, L.ARCHIVED, L.SEQUENCE# UNION SELECT A.NAME AS FILE_NAME, A.FIRST_CHANGE# FIRST_CHANGE, " +
+                "L.STATUS, L.ARCHIVED, L.SEQUENCE#, L.THREAD# UNION SELECT A.NAME AS FILE_NAME, A.FIRST_CHANGE# FIRST_CHANGE, " +
                 "A.NEXT_CHANGE# NEXT_CHANGE, 'YES', NULL, 'ARCHIVED', A.SEQUENCE# AS SEQ, A.DICTIONARY_BEGIN, " +
                 "A.DICTIONARY_END, A.THREAD# AS THREAD FROM V$ARCHIVED_LOG A WHERE A.NAME IS NOT NULL AND A.ARCHIVED = 'YES' AND A.STATUS = 'A' " +
                 "AND A.NEXT_CHANGE# > 10 AND A.DEST_ID IN (SELECT DEST_ID FROM V$ARCHIVE_DEST_STATUS WHERE STATUS='VALID' " +

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/AbstractMongoIT.java
Patch:
@@ -8,6 +8,7 @@
 import static org.fest.assertions.Assertions.assertThat;
 
 import java.util.Map;
+
 import org.junit.After;
 import org.junit.Before;
 import org.slf4j.Logger;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorIT.java
Patch:
@@ -27,8 +27,6 @@
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.concurrent.atomic.AtomicReference;
 
-import com.mongodb.client.model.ChangeStreamPreAndPostImagesOptions;
-import com.mongodb.client.model.CreateCollectionOptions;
 import org.apache.kafka.common.config.Config;
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.errors.ConnectException;
@@ -46,6 +44,8 @@
 import com.mongodb.client.MongoCollection;
 import com.mongodb.client.MongoCursor;
 import com.mongodb.client.MongoDatabase;
+import com.mongodb.client.model.ChangeStreamPreAndPostImagesOptions;
+import com.mongodb.client.model.CreateCollectionOptions;
 import com.mongodb.client.model.InsertOneOptions;
 
 import io.debezium.config.CommonConnectorConfig;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/junit/MongoDbDatabaseVersionResolver.java
Patch:
@@ -3,7 +3,7 @@
  *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
-package io.debezium.connector.mysql.junit;
+package io.debezium.connector.mongodb.junit;
 
 import java.util.List;
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorTask.java
Patch:
@@ -59,8 +59,8 @@ public ChangeEventSourceCoordinator<SqlServerPartition, SqlServerOffsetContext>
 
         // By default do not load whole result sets into memory
         config = config.edit()
-                .withDefault("database.responseBuffering", "adaptive")
-                .withDefault("database.fetchSize", 10_000)
+                .withDefault(CommonConnectorConfig.DRIVER_CONFIG_PREFIX + "responseBuffering", "adaptive")
+                .withDefault(CommonConnectorConfig.DRIVER_CONFIG_PREFIX + "fetchSize", 10_000)
                 .build();
 
         final SqlServerConnectorConfig connectorConfig = new SqlServerConnectorConfig(config);

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -512,8 +512,8 @@ public static SchemaNameAdjustmentMode parse(String value) {
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.LOW)
             .withDescription("Specify how schema names should be adjusted for compatibility with the message converter used by the connector, including: "
-                    + "'avro' replaces the characters that cannot be used in the Avro type name with underscore (default); "
-                    + "'none' does not apply any adjustment");
+                    + "'avro' replaces the characters that cannot be used in the Avro type name with underscore; "
+                    + "'none' does not apply any adjustment (default)");
 
     public static final Field QUERY_FETCH_SIZE = Field.create("query.fetch.size")
             .withDisplayName("Query fetch size")

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FieldExcludeListIT.java
Patch:
@@ -23,6 +23,7 @@
 import com.mongodb.client.model.InsertOneOptions;
 
 import io.debezium.config.CommonConnectorConfig;
+import io.debezium.config.CommonConnectorConfig.SchemaNameAdjustmentMode;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mongodb.FieldBlacklistIT.ExpectedUpdate;
 import io.debezium.doc.FixFor;
@@ -1597,6 +1598,7 @@ private Configuration getConfiguration(String fieldExcludeList, String database,
                 .with(MongoDbConnectorConfig.FIELD_EXCLUDE_LIST, fieldExcludeList)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, database + "." + collection)
                 .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
+                .with(CommonConnectorConfig.SCHEMA_NAME_ADJUSTMENT_MODE, SchemaNameAdjustmentMode.AVRO)
                 .build();
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FieldRenamesIT.java
Patch:
@@ -23,6 +23,7 @@
 import org.junit.Test;
 
 import io.debezium.config.CommonConnectorConfig;
+import io.debezium.config.CommonConnectorConfig.SchemaNameAdjustmentMode;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mongodb.FieldBlacklistIT.ExpectedUpdate;
 import io.debezium.doc.FixFor;
@@ -1827,7 +1828,8 @@ private static Configuration getConfiguration(String fieldRenames) {
     private static Configuration getConfiguration(String fieldRenames, String database, String collection) {
         Configuration.Builder builder = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, database + "." + collection)
-                .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME);
+                .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
+                .with(CommonConnectorConfig.SCHEMA_NAME_ADJUSTMENT_MODE, SchemaNameAdjustmentMode.AVRO);
 
         if (fieldRenames != null && !"".equals(fieldRenames.trim())) {
             builder = builder.with(MongoDbConnectorConfig.FIELD_RENAMES, fieldRenames);

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SpecialCharsInNamesIT.java
Patch:
@@ -17,6 +17,8 @@
 import org.junit.After;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig;
+import io.debezium.config.CommonConnectorConfig.SchemaNameAdjustmentMode;
 import io.debezium.config.Configuration;
 import io.debezium.connector.sqlserver.SqlServerConnectorConfig.SnapshotMode;
 import io.debezium.connector.sqlserver.util.TestHelper;
@@ -260,6 +262,7 @@ public void shouldHandleSpecialCharactersInDatabaseNames() throws Exception {
         final Configuration config = TestHelper.defaultConfig(databaseName)
                 .with(SqlServerConnectorConfig.SNAPSHOT_MODE, SnapshotMode.INITIAL)
                 .with(SqlServerConnectorConfig.SANITIZE_FIELD_NAMES, false)
+                .with(CommonConnectorConfig.SCHEMA_NAME_ADJUSTMENT_MODE, SchemaNameAdjustmentMode.AVRO)
                 .build();
         connection.execute(
                 "CREATE TABLE tablea (id int primary key, cola varchar(30))",

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -508,7 +508,7 @@ public static SchemaNameAdjustmentMode parse(String value) {
     public static final Field SCHEMA_NAME_ADJUSTMENT_MODE = Field.create("schema.name.adjustment.mode")
             .withDisplayName("Schema Name Adjustment")
             .withGroup(Field.createGroupEntry(Field.Group.CONNECTOR, 7))
-            .withEnum(SchemaNameAdjustmentMode.class, SchemaNameAdjustmentMode.AVRO)
+            .withEnum(SchemaNameAdjustmentMode.class, SchemaNameAdjustmentMode.NONE)
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.LOW)
             .withDescription("Specify how schema names should be adjusted for compatibility with the message converter used by the connector, including: "

File: debezium-core/src/main/java/io/debezium/transforms/ByLogicalTableRouter.java
Patch:
@@ -114,7 +114,7 @@ public class ByLogicalTableRouter<R extends ConnectRecord<R>> implements Transfo
                     ". This will be used to create the physical table identifier in the record's key.");
     private static final Field SCHEMA_NAME_ADJUSTMENT_MODE = Field.create("schema.name.adjustment.mode")
             .withDisplayName("Schema Name Adjustment")
-            .withEnum(SchemaNameAdjustmentMode.class, SchemaNameAdjustmentMode.AVRO)
+            .withEnum(SchemaNameAdjustmentMode.class, SchemaNameAdjustmentMode.NONE)
             .withWidth(ConfigDef.Width.MEDIUM)
             .withImportance(ConfigDef.Importance.LOW)
             .withDescription(

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/ConnectorConfigBuilder.java
Patch:
@@ -61,6 +61,8 @@ public ConnectorConfigBuilder addApicurioAvroSupport(String apicurioUrl) {
         config.put("value.converter.apicurio.registry.auto-register", true);
         config.put("value.converter.apicurio.registry.find-latest", true);
 
+        config.put("schema.name.adjustment.mode", "avro");
+
         return this;
     }
 

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/ApicurioRegistryTest.java
Patch:
@@ -127,7 +127,8 @@ public void shouldConvertToAvro() throws Exception {
             statement.execute("insert into todo.Todo values (1, 'Be Awesome')");
 
             debeziumContainer.registerConnector("my-connector-avro", getConfiguration(
-                    2, "io.apicurio.registry.utils.converter.AvroConverter"));
+                    2, "io.apicurio.registry.utils.converter.AvroConverter",
+                    "schema.name.adjustment.mode", "avro"));
 
             consumer.subscribe(Arrays.asList("dbserver2.todo.todo"));
 

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/DebeziumContainer.java
Patch:
@@ -44,7 +44,7 @@ public class DebeziumContainer extends GenericContainer<DebeziumContainer> {
     private static final String DEBEZIUM_NIGHTLY_TAG = "nightly";
 
     private static final int KAFKA_CONNECT_PORT = 8083;
-    private static final Duration DEBEZIUM_CONTAINER_STARTUP_TIMEOUT = Duration.ofMinutes(5);
+    private static final Duration DEBEZIUM_CONTAINER_STARTUP_TIMEOUT = Duration.ofSeconds(waitTimeForRecords() * 30);
     private static final String TEST_PROPERTY_PREFIX = "debezium.test.";
     public static final MediaType JSON = MediaType.get("application/json; charset=utf-8");
     protected static final ObjectMapper MAPPER = new ObjectMapper();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/DefaultValueParserListener.java
Patch:
@@ -94,7 +94,8 @@ public void exitDefaultValue(boolean skipIfUnknownOptional) {
     }
 
     private String unquote(String stringLiteral) {
-        if (stringLiteral != null && stringLiteral.startsWith("'") && stringLiteral.endsWith("'")) {
+        if (stringLiteral != null && ((stringLiteral.startsWith("'") && stringLiteral.endsWith("'"))
+                || (stringLiteral.startsWith("\"") && stringLiteral.endsWith("\"")))) {
             return stringLiteral.substring(1, stringLiteral.length() - 1);
         }
         return stringLiteral;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDefaultValueTest.java
Patch:
@@ -597,6 +597,7 @@ public void parseNumericAndDecimalToIntDefaultValue() {
                 + "c3 bigint not null default .12345,\n"
                 + "c4 smallint not null default 100.52345,\n"
                 + "c5 int not null default '-.789',\n"
+                + "c6 decimal(26,6) default \"1\",\n"
                 + "PRIMARY KEY (`id`)\n"
                 + ")";
         parser.parse(ddl, tables);
@@ -611,6 +612,7 @@ public void parseNumericAndDecimalToIntDefaultValue() {
         assertThat(getColumnSchema(schema, "c3").defaultValue()).isEqualTo(0L);
         assertThat(getColumnSchema(schema, "c4").defaultValue()).isEqualTo(Short.valueOf("101"));
         assertThat(getColumnSchema(schema, "c5").defaultValue()).isEqualTo(-1);
+        assertThat(getColumnSchema(schema, "c6").defaultValue()).isEqualTo(1.0);
     }
 
     private Schema getColumnSchema(Table table, String column) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/parser/SelectLobParser.java
Patch:
@@ -74,6 +74,8 @@ public LogMinerDmlEntry parse(String sql, Table table) {
                                 }
                             }
                         }
+
+                        ParserUtils.setColumnUnavailableValues(columnValues, table);
                     }
                 }
             }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/antlr/listener/ColumnDefinitionParserListener.java
Patch:
@@ -83,7 +83,7 @@ private void resolveColumnDataType(PlSqlParser.Column_definitionContext ctx) {
         columnEditor.optional(!hasNotNullConstraint);
 
         if (ctx.datatype() == null) {
-            if (ctx.type_name() != null && "\"MDSYS\".\"SDO_GEOMETRY\"".equalsIgnoreCase(ctx.type_name().getText())) {
+            if (ctx.type_name() != null && "MDSYS.SDO_GEOMETRY".equalsIgnoreCase(ctx.type_name().getText().replace("\"", ""))) {
                 columnEditor.jdbcType(Types.STRUCT).type("MDSYS.SDO_GEOMETRY");
             }
         }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorConfig.java
Patch:
@@ -491,6 +491,7 @@ public boolean isFullUpdate() {
     private static final ConfigDefinition CONFIG_DEFINITION = CommonConnectorConfig.CONFIG_DEFINITION.edit()
             .name("MongoDB")
             .type(
+                    TOPIC_PREFIX,
                     CONNECTION_STRING,
                     HOSTS,
                     USER,

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -319,10 +319,12 @@ public static SchemaNameAdjustmentMode parse(String value) {
     public static final Field TOPIC_PREFIX = Field.create("topic.prefix")
             .withDisplayName("Topic prefix")
             .withType(Type.STRING)
+            .withGroup(Field.createGroupEntry(Field.Group.CONNECTION, 0))
             .withWidth(Width.MEDIUM)
-            .withImportance(Importance.LOW)
+            .withImportance(Importance.HIGH)
             .withDefault(LOGIC_NAME_PLACEHOLDER)
             .withValidation(CommonConnectorConfig::validateTopicName)
+            .required()
             .withDescription("The name of the prefix to be used for all topics, the placeholder " + LOGIC_NAME_PLACEHOLDER +
                     " can be used for referring to the connector's logical name as default value.");
 

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnector.java
Patch:
@@ -67,7 +67,7 @@
  * <h2>Use of Topics</h2>
  * The connector will write to a separate topic all of the source records that correspond to a single collection. The topic will
  * be named "{@code <logicalName>.<databaseName>.<collectionName>}", where {@code <logicalName>} is set via the
- * "{@link AbstractTopicNamingStrategy.TOPIC_PREFIX topic.prefix}" configuration property.
+ * "{@link io.debezium.config.CommonConnectorConfig.TOPIC_PREFIX topic.prefix}" configuration property.
  *
  * <h2>Configuration</h2>
  * <p>

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorConfig.java
Patch:
@@ -32,7 +32,6 @@
 import io.debezium.connector.AbstractSourceInfo;
 import io.debezium.connector.SourceInfoStructMaker;
 import io.debezium.data.Envelope;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.schema.DefaultTopicNamingStrategy;
 import io.debezium.spi.schema.DataCollectionId;
 
@@ -539,7 +538,7 @@ public static ConfigDef configDef() {
     private final int cursorMaxAwaitTimeMs;
 
     public MongoDbConnectorConfig(Configuration config) {
-        super(config, config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX), DEFAULT_SNAPSHOT_FETCH_SIZE);
+        super(config, config.getString(CommonConnectorConfig.TOPIC_PREFIX), DEFAULT_SNAPSHOT_FETCH_SIZE);
 
         String snapshotModeValue = config.getString(MongoDbConnectorConfig.SNAPSHOT_MODE);
         this.snapshotMode = SnapshotMode.parse(snapshotModeValue, MongoDbConnectorConfig.SNAPSHOT_MODE.defaultValueAsString());

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbTaskContext.java
Patch:
@@ -7,10 +7,10 @@
 
 import java.util.Collections;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.common.CdcSourceTaskContext;
 import io.debezium.connector.mongodb.MongoDbConnectorConfig.CaptureMode;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.spi.topic.TopicNamingStrategy;
 
 /**
@@ -29,13 +29,13 @@ public class MongoDbTaskContext extends CdcSourceTaskContext {
      * @param config the configuration
      */
     public MongoDbTaskContext(Configuration config) {
-        super(Module.contextName(), config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX), Collections::emptySet);
+        super(Module.contextName(), config.getString(CommonConnectorConfig.TOPIC_PREFIX), Collections::emptySet);
 
         this.filters = new Filters(config);
         this.connectorConfig = new MongoDbConnectorConfig(config);
         this.source = new SourceInfo(connectorConfig);
         this.topicNamingStrategy = connectorConfig.getTopicNamingStrategy(MongoDbConnectorConfig.TOPIC_NAMING_STRATEGY);
-        this.serverName = config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX);
+        this.serverName = config.getString(CommonConnectorConfig.TOPIC_PREFIX);
         this.connectionContext = new ConnectionContext(config);
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/Configurator.java
Patch:
@@ -5,9 +5,9 @@
  */
 package io.debezium.connector.mongodb;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.config.Field;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Testing;
 
 /**
@@ -35,7 +35,7 @@ public Configurator with(Field field, int value) {
     }
 
     public Configurator serverName(String serverName) {
-        return with(AbstractTopicNamingStrategy.TOPIC_PREFIX, serverName);
+        return with(CommonConnectorConfig.TOPIC_PREFIX, serverName);
     }
 
     public Configurator hosts(String hosts) {

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FieldBlacklistIT.java
Patch:
@@ -23,8 +23,8 @@
 import com.mongodb.client.MongoDatabase;
 import com.mongodb.client.model.InsertOneOptions;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Testing;
 
 public class FieldBlacklistIT extends AbstractMongoConnectorIT {
@@ -1455,7 +1455,7 @@ private Configuration getConfiguration(String excludeList) {
         return TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.FIELD_EXCLUDE_LIST, excludeList)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, "dbA.c1")
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
+                .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
                 .build();
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FieldExcludeListIT.java
Patch:
@@ -22,10 +22,10 @@
 import com.mongodb.client.MongoDatabase;
 import com.mongodb.client.model.InsertOneOptions;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mongodb.FieldBlacklistIT.ExpectedUpdate;
 import io.debezium.doc.FixFor;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Testing;
 
 public class FieldExcludeListIT extends AbstractMongoConnectorIT {
@@ -1565,7 +1565,7 @@ public void shouldExcludeFieldsIncludingSameNamesForReadEvent() throws Interrupt
         config = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.FIELD_EXCLUDE_LIST, "*.c1.name,*.c1.active,*.c2.name,*.c2.active")
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, "dbA.c1,dbA.c2")
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
+                .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
                 .build();
         context = new MongoDbTaskContext(config);
 
@@ -1596,7 +1596,7 @@ private Configuration getConfiguration(String fieldExcludeList, String database,
         return TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.FIELD_EXCLUDE_LIST, fieldExcludeList)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, database + "." + collection)
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
+                .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
                 .build();
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FieldRenamesIT.java
Patch:
@@ -22,11 +22,11 @@
 import org.bson.types.ObjectId;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mongodb.FieldBlacklistIT.ExpectedUpdate;
 import io.debezium.doc.FixFor;
 import io.debezium.junit.logging.LogInterceptor;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * @author Chris Cranford
@@ -1827,7 +1827,7 @@ private static Configuration getConfiguration(String fieldRenames) {
     private static Configuration getConfiguration(String fieldRenames, String database, String collection) {
         Configuration.Builder builder = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, database + "." + collection)
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME);
+                .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME);
 
         if (fieldRenames != null && !"".equals(fieldRenames.trim())) {
             builder = builder.with(MongoDbConnectorConfig.FIELD_RENAMES, fieldRenames);

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorWithConnectionStringIT.java
Patch:
@@ -30,11 +30,11 @@
 import com.mongodb.client.MongoDatabase;
 import com.mongodb.client.model.InsertOneOptions;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;
 import io.debezium.data.Envelope;
 import io.debezium.data.Envelope.Operation;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.IoUtil;
 import io.debezium.util.Testing;
 
@@ -64,7 +64,7 @@ public void shouldConsumeAllEventsFromDatabase(String connectionString, boolean
         config = Configuration.from(properties).edit()
                 .with(MongoDbConnectorConfig.POLL_INTERVAL_MS, 10)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, "dbit.*")
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "mongo")
+                .with(CommonConnectorConfig.TOPIC_PREFIX, "mongo")
                 .with(MongoDbConnectorConfig.CONNECTION_STRING, connectionString)
                 .with(MongoDbConnectorConfig.SSL_ENABLED, ssl)
                 .with(MongoDbConnectorConfig.AUTO_DISCOVER_MEMBERS, true)

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/SourceInfoTest.java
Patch:
@@ -20,9 +20,9 @@
 import org.junit.Before;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.AbstractSourceInfoStructMaker;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * @author Randall Hauch
@@ -37,7 +37,7 @@ public class SourceInfoTest {
     public void beforeEach() {
         source = new SourceInfo(new MongoDbConnectorConfig(
                 Configuration.create()
-                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "serverX")
+                        .with(CommonConnectorConfig.TOPIC_PREFIX, "serverX")
                         .build()));
     }
 
@@ -86,7 +86,7 @@ public void shouldSetAndReturnRecordedOffset() {
         Map<String, String> partition = source.partition(REPLICA_SET_NAME);
         source = new SourceInfo(new MongoDbConnectorConfig(
                 Configuration.create()
-                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "serverX")
+                        .with(CommonConnectorConfig.TOPIC_PREFIX, "serverX")
                         .build()));
         source.setOffsetFor(partition, offset);
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/TestHelper.java
Patch:
@@ -25,10 +25,10 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import com.mongodb.client.MongoDatabase;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.config.Configuration.Builder;
 import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * A common test configuration options
@@ -46,7 +46,7 @@ public static Configuration getConfiguration() {
         final Builder cfgBuilder = Configuration.fromSystemProperties("connector.").edit()
                 .withDefault(MongoDbConnectorConfig.HOSTS, "rs0/localhost:27017")
                 .withDefault(MongoDbConnectorConfig.AUTO_DISCOVER_MEMBERS, false)
-                .withDefault(AbstractTopicNamingStrategy.TOPIC_PREFIX, "mongo1");
+                .withDefault(CommonConnectorConfig.TOPIC_PREFIX, "mongo1");
         return cfgBuilder.build();
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/AbstractExtractNewDocumentStateTestIT.java
Patch:
@@ -14,14 +14,14 @@
 import org.junit.After;
 import org.junit.Before;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mongodb.AbstractMongoConnectorIT;
 import io.debezium.connector.mongodb.MongoDbConnector;
 import io.debezium.connector.mongodb.MongoDbConnectorConfig;
 import io.debezium.connector.mongodb.MongoDbTaskContext;
 import io.debezium.connector.mongodb.TestHelper;
 import io.debezium.data.Envelope;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * Baseline for all integrations tests regarding MongoDB Update Operations
@@ -47,7 +47,7 @@ public void beforeEach() {
         Configuration config = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.POLL_INTERVAL_MS, 10)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, DB_NAME + "." + this.getCollectionName())
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
+                .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
                 .build();
 
         beforeEach(config);
@@ -83,7 +83,7 @@ protected void restartConnectorWithoutEmittingTombstones() {
         Configuration config = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.POLL_INTERVAL_MS, 10)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, DB_NAME + "." + this.getCollectionName())
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
+                .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
                 .with(MongoDbConnectorConfig.TOMBSTONES_ON_DELETE, false)
                 .build();
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/ExtractNewDocumentStateTest.java
Patch:
@@ -26,6 +26,7 @@
 import org.junit.rules.ExpectedException;
 import org.junit.rules.TestRule;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.AbstractSourceInfo;
 import io.debezium.connector.mongodb.Configurator;
@@ -35,7 +36,6 @@
 import io.debezium.doc.FixFor;
 import io.debezium.junit.SkipTestRule;
 import io.debezium.junit.SkipWhenKafkaVersion;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.schema.DefaultTopicNamingStrategy;
 import io.debezium.spi.topic.TopicNamingStrategy;
 
@@ -66,7 +66,7 @@ public void setup() {
         filters = new Configurator().createFilters();
         MongoDbConnectorConfig connectorConfig = new MongoDbConnectorConfig(
                 Configuration.create()
-                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
+                        .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
                         .build());
         source = new SourceInfo(connectorConfig);
         topicNamingStrategy = DefaultTopicNamingStrategy.create(connectorConfig);

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/outbox/MongoEventRouterTestIT.java
Patch:
@@ -25,13 +25,13 @@
 import org.junit.Before;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mongodb.AbstractMongoConnectorIT;
 import io.debezium.connector.mongodb.MongoDbConnector;
 import io.debezium.connector.mongodb.MongoDbConnectorConfig;
 import io.debezium.connector.mongodb.MongoDbTaskContext;
 import io.debezium.connector.mongodb.TestHelper;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * Integration tests for {@link MongoEventRouter}
@@ -50,7 +50,7 @@ public void beforeEach() {
         Configuration config = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.POLL_INTERVAL_MS, 10)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, DB_NAME + "." + this.getCollectionName())
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
+                .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
                 .build();
 
         beforeEach(config);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -17,6 +17,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.ConfigDefinition;
 import io.debezium.config.Configuration;
 import io.debezium.config.EnumeratedValue;
@@ -34,7 +35,6 @@
 import io.debezium.relational.Tables.TableFilter;
 import io.debezium.relational.history.HistoryRecordComparator;
 import io.debezium.relational.history.SchemaHistory;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.schema.DefaultTopicNamingStrategy;
 import io.debezium.storage.kafka.history.KafkaSchemaHistory;
 import io.debezium.util.Collect;
@@ -963,7 +963,7 @@ public MySqlConnectorConfig(Configuration config) {
         super(
                 MySqlConnector.class,
                 config,
-                config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX),
+                config.getString(CommonConnectorConfig.TOPIC_PREFIX),
                 TableFilter.fromPredicate(MySqlConnectorConfig::isNotBuiltInTable),
                 true,
                 DEFAULT_SNAPSHOT_FETCH_SIZE,

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlParserIT.java
Patch:
@@ -28,7 +28,6 @@
 import io.debezium.embedded.AbstractConnectorTest;
 import io.debezium.jdbc.JdbcConfiguration;
 import io.debezium.jdbc.JdbcConnection;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.ContainerImageVersions;
 import io.debezium.util.Testing;
 
@@ -76,7 +75,7 @@ public void afterEach() {
 
     public Configuration.Builder defaultConfig() {
         return Configuration.create()
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "myServer1")
+                .with(CommonConnectorConfig.TOPIC_PREFIX, "myServer1")
                 .with(MySqlConnectorConfig.HOSTNAME, System.getProperty("database.hostname", "localhost"))
                 .with(CommonConnectorConfig.DATABASE_CONFIG_PREFIX + JdbcConfiguration.PORT, mySQLContainer.getMappedPort(3306))
                 .with(MySqlConnectorConfig.USER, "debezium")

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlTopicNamingStrategyIT.java
Patch:
@@ -64,7 +64,7 @@ public void testSpecifyDelimiterAndPrefixStrategy() throws SQLException, Interru
                 .with(MySqlConnectorConfig.SNAPSHOT_MODE, MySqlConnectorConfig.SnapshotMode.INITIAL)
                 .with(MySqlConnectorConfig.TABLE_INCLUDE_LIST, DATABASE.qualifiedTableName(TABLE_NAME))
                 .with(RelationalDatabaseConnectorConfig.INCLUDE_SCHEMA_CHANGES, "true")
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "my_prefix")
+                .with(CommonConnectorConfig.TOPIC_PREFIX, "my_prefix")
                 .with(AbstractTopicNamingStrategy.TOPIC_DELIMITER, "_")
                 .build();
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlTopicNamingStrategyTest.java
Patch:
@@ -5,9 +5,9 @@
  */
 package io.debezium.connector.mysql;
 
+import static io.debezium.config.CommonConnectorConfig.TOPIC_PREFIX;
 import static io.debezium.schema.AbstractTopicNamingStrategy.TOPIC_DELIMITER;
 import static io.debezium.schema.AbstractTopicNamingStrategy.TOPIC_HEARTBEAT_PREFIX;
-import static io.debezium.schema.AbstractTopicNamingStrategy.TOPIC_PREFIX;
 import static io.debezium.schema.AbstractTopicNamingStrategy.TOPIC_TRANSACTION;
 import static org.fest.assertions.Assertions.assertThat;
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SourceInfoTest.java
Patch:
@@ -22,12 +22,12 @@
 import org.junit.Test;
 
 import io.confluent.connect.avro.AvroData;
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.AbstractSourceInfoStructMaker;
 import io.debezium.data.VerifyRecord;
 import io.debezium.doc.FixFor;
 import io.debezium.document.Document;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class SourceInfoTest {
 
@@ -46,7 +46,7 @@ public class SourceInfoTest {
     @Before
     public void beforeEach() {
         offsetContext = MySqlOffsetContext.initial(new MySqlConnectorConfig(Configuration.create()
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "server")
+                .with(CommonConnectorConfig.TOPIC_PREFIX, "server")
                 .build()));
         source = offsetContext.getSource();
         inTxn = false;
@@ -446,7 +446,7 @@ protected Map<String, String> offset(String gtidSet, long position, int row, boo
 
     protected SourceInfo sourceWith(Map<String, String> offset) {
         offsetContext = (MySqlOffsetContext) new MySqlOffsetContext.Loader(new MySqlConnectorConfig(Configuration.create()
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
+                .with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
                 .build())).load(offset);
         source = offsetContext.getSource();
         source.databaseEvent("mysql");

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/UniqueDatabase.java
Patch:
@@ -22,9 +22,9 @@
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.config.Configuration.Builder;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.file.history.FileSchemaHistory;
 
 /**
@@ -237,7 +237,7 @@ public Configuration.Builder defaultConfigWithoutDatabaseFilter() {
                 .with(MySqlConnectorConfig.POLL_INTERVAL_MS, 10)
                 .with(MySqlConnectorConfig.SCHEMA_HISTORY, FileSchemaHistory.class)
                 .with(MySqlConnectorConfig.BUFFER_SIZE_FOR_BINLOG_READER, 10_000)
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, getServerName());
+                .with(CommonConnectorConfig.TOPIC_PREFIX, getServerName());
     }
 
     /**

File: debezium-connector-mysql/src/test/java/io/debezium/relational/history/KafkaSchemaHistoryTest.java
Patch:
@@ -27,6 +27,7 @@
 import org.junit.BeforeClass;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mysql.MySqlConnectorConfig;
 import io.debezium.connector.mysql.MySqlOffsetContext;
@@ -41,7 +42,6 @@
 import io.debezium.pipeline.txmetadata.TransactionContext;
 import io.debezium.relational.Tables;
 import io.debezium.relational.ddl.DdlParser;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.kafka.history.KafkaSchemaHistory;
 import io.debezium.text.ParsingException;
 import io.debezium.util.Collect;
@@ -88,7 +88,7 @@ public void beforeEach() throws Exception {
         MySqlPartition source = new MySqlPartition("my-server", "my-db");
         Configuration config = Configuration.empty()
                 .edit()
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "dbserver1").build();
+                .with(CommonConnectorConfig.TOPIC_PREFIX, "dbserver1").build();
 
         position = new MySqlOffsetContext(false, true, new TransactionContext(), new MySqlReadOnlyIncrementalSnapshotContext<>(),
                 new SourceInfo(new MySqlConnectorConfig(config)));

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -22,6 +22,7 @@
 import org.slf4j.LoggerFactory;
 
 import io.debezium.DebeziumException;
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.ConfigDefinition;
 import io.debezium.config.Configuration;
 import io.debezium.config.EnumeratedValue;
@@ -44,7 +45,6 @@
 import io.debezium.relational.TableId;
 import io.debezium.relational.Tables.TableFilter;
 import io.debezium.relational.history.HistoryRecordComparator;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Strings;
 
 /**
@@ -573,7 +573,7 @@ public static ConfigDef configDef() {
     private final TransactionSnapshotBoundaryMode logMiningTransactionSnapshotBoundaryMode;
 
     public OracleConnectorConfig(Configuration config) {
-        super(OracleConnector.class, config, config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX), new SystemTablesPredicate(config),
+        super(OracleConnector.class, config, config.getString(CommonConnectorConfig.TOPIC_PREFIX), new SystemTablesPredicate(config),
                 x -> x.schema() + "." + x.table(), true, ColumnFilterMode.SCHEMA, false);
 
         this.databaseName = toUpperCase(config.getString(DATABASE_NAME));

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorTest.java
Patch:
@@ -20,7 +20,6 @@
 import org.junit.Test;
 
 import io.debezium.config.CommonConnectorConfig;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class OracleConnectorTest {
     OracleConnector connector;
@@ -33,7 +32,7 @@ public void before() {
     @Test
     public void testValidateUnableToConnectNoThrow() {
         Map<String, String> config = new HashMap<>();
-        config.put(AbstractTopicNamingStrategy.TOPIC_PREFIX.name(), "dbserver1");
+        config.put(CommonConnectorConfig.TOPIC_PREFIX.name(), "dbserver1");
         config.put(OracleConnectorConfig.HOSTNAME.name(), "narnia");
         config.put(OracleConnectorConfig.PORT.name(), "4321");
         config.put(OracleConnectorConfig.DATABASE_NAME.name(), "oracle");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleSchemaHistoryTest.java
Patch:
@@ -9,6 +9,7 @@
 import java.util.Collections;
 import java.util.Map;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.oracle.antlr.OracleDdlParser;
 import io.debezium.connector.oracle.util.TestHelper;
@@ -24,7 +25,6 @@
 import io.debezium.relational.history.AbstractSchemaHistoryTest;
 import io.debezium.relational.history.HistoryRecord;
 import io.debezium.relational.history.TableChanges;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 import oracle.jdbc.OracleTypes;
 
@@ -73,7 +73,7 @@ protected Offsets<Partition, OffsetContext> getOffsets() {
         final OraclePartition source = new OraclePartition(TestHelper.SERVER_NAME, TestHelper.getDatabaseName());
         final Configuration config = Configuration.empty()
                 .edit()
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, TestHelper.SERVER_NAME)
+                .with(CommonConnectorConfig.TOPIC_PREFIX, TestHelper.SERVER_NAME)
                 .build();
         final OracleOffsetContext position = new OracleOffsetContext(new OracleConnectorConfig(config), Scn.valueOf(999),
                 CommitScn.valueOf(999L), null, Scn.valueOf(999), Collections.emptyMap(), false, true, new TransactionContext(),

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/SourceInfoTest.java
Patch:
@@ -14,11 +14,11 @@
 import org.junit.Before;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.AbstractSourceInfoStructMaker;
 import io.debezium.data.VerifyRecord;
 import io.debezium.relational.TableId;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class SourceInfoTest {
 
@@ -28,7 +28,7 @@ public class SourceInfoTest {
     public void beforeEach() {
         final OracleConnectorConfig connectorConfig = new OracleConnectorConfig(
                 Configuration.create()
-                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "serverX")
+                        .with(CommonConnectorConfig.TOPIC_PREFIX, "serverX")
                         .with(OracleConnectorConfig.DATABASE_NAME, "mydb")
                         .build());
         source = new SourceInfo(connectorConfig);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -42,7 +42,6 @@
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
 import io.debezium.relational.TableId;
 import io.debezium.relational.Tables.TableFilter;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Strings;
 
 /**
@@ -852,7 +851,7 @@ public static AutoCreateMode parse(String value, String defaultValue) {
     public PostgresConnectorConfig(Configuration config) {
         super(
                 config,
-                config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX),
+                config.getString(CommonConnectorConfig.TOPIC_PREFIX),
                 new SystemTablesPredicate(),
                 x -> x.schema() + "." + x.table(),
                 DEFAULT_SNAPSHOT_FETCH_SIZE,

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -93,7 +93,6 @@
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
 import io.debezium.relational.RelationalDatabaseSchema;
 import io.debezium.relational.RelationalSnapshotChangeEventSource;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.schema.DatabaseSchema;
 import io.debezium.util.Strings;
 import io.debezium.util.Testing;
@@ -215,7 +214,7 @@ public void shouldValidateConfiguration() throws Exception {
         assertConfigurationErrors(validatedConfig, PostgresConnectorConfig.HOSTNAME, 1);
         assertConfigurationErrors(validatedConfig, PostgresConnectorConfig.USER, 1);
         assertConfigurationErrors(validatedConfig, PostgresConnectorConfig.DATABASE_NAME, 1);
-        assertNoConfigurationErrors(validatedConfig, AbstractTopicNamingStrategy.TOPIC_PREFIX);
+        assertNoConfigurationErrors(validatedConfig, CommonConnectorConfig.TOPIC_PREFIX);
 
         // validate the non required fields
         validateConfigField(validatedConfig, PostgresConnectorConfig.PLUGIN_NAME, LogicalDecoder.DECODERBUFS.getValue());

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresErrorHandlerTest.java
Patch:
@@ -11,17 +11,17 @@
 import org.postgresql.util.PSQLState;
 
 import io.debezium.DebeziumException;
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.base.ChangeEventQueue;
 import io.debezium.pipeline.DataChangeEvent;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class PostgresErrorHandlerTest {
     private static final String A_CLASSIFIED_EXCEPTION = "Database connection failed when writing to copy";
 
     private final PostgresErrorHandler errorHandler = new PostgresErrorHandler(
             new PostgresConnectorConfig(Configuration.create()
-                    .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "postgres")
+                    .with(CommonConnectorConfig.TOPIC_PREFIX, "postgres")
                     .build()),
             new ChangeEventQueue.Builder<DataChangeEvent>().build());
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SourceInfoTest.java
Patch:
@@ -12,12 +12,12 @@
 import org.junit.Before;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.AbstractSourceInfoStructMaker;
 import io.debezium.data.VerifyRecord;
 import io.debezium.doc.FixFor;
 import io.debezium.relational.TableId;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.time.Conversions;
 
 /**
@@ -32,7 +32,7 @@ public class SourceInfoTest {
     public void beforeEach() {
         source = new SourceInfo(new PostgresConnectorConfig(
                 Configuration.create()
-                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "serverX")
+                        .with(CommonConnectorConfig.TOPIC_PREFIX, "serverX")
                         .with(PostgresConnectorConfig.DATABASE_NAME, "serverX")
                         .build()));
         source.update(Conversions.toInstantFromMicros(123_456_789L), new TableId("catalogNameX", "schemaNameX", "tableNameX"));

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorConfig.java
Patch:
@@ -18,6 +18,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.ConfigDefinition;
 import io.debezium.config.Configuration;
 import io.debezium.config.EnumeratedValue;
@@ -31,7 +32,6 @@
 import io.debezium.relational.TableId;
 import io.debezium.relational.Tables.TableFilter;
 import io.debezium.relational.history.HistoryRecordComparator;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * The list of configuration options for SQL Server connector
@@ -334,7 +334,7 @@ public static ConfigDef configDef() {
     private final boolean optionRecompile;
 
     public SqlServerConnectorConfig(Configuration config) {
-        super(SqlServerConnector.class, config, config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX), new SystemTablesPredicate(),
+        super(SqlServerConnector.class, config, config.getString(CommonConnectorConfig.TOPIC_PREFIX), new SystemTablesPredicate(),
                 x -> x.schema() + "." + x.table(), true,
                 ColumnFilterMode.SCHEMA, true);
 

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SourceInfoTest.java
Patch:
@@ -14,11 +14,11 @@
 import org.junit.Before;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.AbstractSourceInfoStructMaker;
 import io.debezium.connector.SnapshotRecord;
 import io.debezium.relational.TableId;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class SourceInfoTest {
 
@@ -28,7 +28,7 @@ public class SourceInfoTest {
     public void beforeEach() {
         final SqlServerConnectorConfig connectorConfig = new SqlServerConnectorConfig(
                 Configuration.create()
-                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "serverX")
+                        .with(CommonConnectorConfig.TOPIC_PREFIX, "serverX")
                         .build());
         source = new SourceInfo(connectorConfig);
         source.setChangeLsn(Lsn.valueOf(new byte[]{ 0x01 }));

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorConfigTest.java
Patch:
@@ -12,8 +12,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.kafka.history.KafkaSchemaHistory;
 
 public class SqlServerConnectorConfigTest {
@@ -38,7 +38,7 @@ public void nonEmptyDatabaseNames() {
 
     private Configuration.Builder defaultConfig() {
         return Configuration.create()
-                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "server")
+                .with(CommonConnectorConfig.TOPIC_PREFIX, "server")
                 .with(SqlServerConnectorConfig.HOSTNAME, "localhost")
                 .with(SqlServerConnectorConfig.USER, "debezium")
                 .with(KafkaSchemaHistory.BOOTSTRAP_SERVERS, "localhost:9092")

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorTest.java
Patch:
@@ -21,7 +21,6 @@
 import org.junit.Test;
 
 import io.debezium.config.CommonConnectorConfig;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class SqlServerConnectorTest {
     SqlServerConnector connector;
@@ -34,7 +33,7 @@ public void before() {
     @Test
     public void testValidateUnableToConnectNoThrow() {
         Map<String, String> config = new HashMap<>();
-        config.put(AbstractTopicNamingStrategy.TOPIC_PREFIX.name(), "dbserver1");
+        config.put(CommonConnectorConfig.TOPIC_PREFIX.name(), "dbserver1");
         config.put(SqlServerConnectorConfig.HOSTNAME.name(), "narnia");
         config.put(SqlServerConnectorConfig.PORT.name(), "4321");
         config.put(SqlServerConnectorConfig.DATABASE_NAMES.name(), "sqlserver");

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/util/TestHelper.java
Patch:
@@ -29,6 +29,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.sqlserver.Lsn;
 import io.debezium.connector.sqlserver.SqlServerChangeTable;
@@ -41,7 +42,6 @@
 import io.debezium.jdbc.TemporalPrecisionMode;
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
 import io.debezium.relational.TableId;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.file.history.FileSchemaHistory;
 import io.debezium.util.Collect;
 import io.debezium.util.IoUtil;
@@ -125,7 +125,7 @@ public static Configuration.Builder defaultConnectorConfig() {
         jdbcConfiguration.forEach(
                 (field, value) -> builder.with(SqlServerConnectorConfig.DATABASE_CONFIG_PREFIX + field, value));
 
-        return builder.with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "server1")
+        return builder.with(CommonConnectorConfig.TOPIC_PREFIX, "server1")
                 .with(SqlServerConnectorConfig.SCHEMA_HISTORY, FileSchemaHistory.class)
                 .with(FileSchemaHistory.FILE_PATH, SCHEMA_HISTORY_PATH)
                 .with(RelationalDatabaseConnectorConfig.INCLUDE_SCHEMA_CHANGES, false);

File: debezium-core/src/main/java/io/debezium/connector/common/RelationalBaseSourceConnector.java
Patch:
@@ -14,9 +14,9 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Strings;
 
 /**
@@ -34,7 +34,7 @@ public Config validate(Map<String, String> connectorConfigs) {
         // Validate all of the individual fields, which is easy since don't make any of the fields invisible ...
         Map<String, ConfigValue> results = validateAllFields(config);
 
-        ConfigValue logicalName = results.get(AbstractTopicNamingStrategy.TOPIC_PREFIX.name());
+        ConfigValue logicalName = results.get(CommonConnectorConfig.TOPIC_PREFIX.name());
         // Get the config values for each of the connection-related fields ...
         ConfigValue hostnameValue = results.get(RelationalDatabaseConnectorConfig.HOSTNAME.name());
         ConfigValue portValue = results.get(RelationalDatabaseConnectorConfig.PORT.name());

File: debezium-core/src/main/java/io/debezium/relational/RelationalDatabaseConnectorConfig.java
Patch:
@@ -37,7 +37,6 @@
 import io.debezium.relational.Tables.ColumnNameFilter;
 import io.debezium.relational.Tables.ColumnNameFilterFactory;
 import io.debezium.relational.Tables.TableFilter;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.spi.topic.TopicNamingStrategy;
 import io.debezium.util.SchemaNameAdjuster;
 import io.debezium.util.Strings;
@@ -467,7 +466,7 @@ public static DecimalHandlingMode parse(String value, String defaultValue) {
 
     protected static final ConfigDefinition CONFIG_DEFINITION = CommonConnectorConfig.CONFIG_DEFINITION.edit()
             .type(
-                    AbstractTopicNamingStrategy.TOPIC_PREFIX)
+                    CommonConnectorConfig.TOPIC_PREFIX)
             .connector(
                     DECIMAL_HANDLING_MODE,
                     TIME_PRECISION_MODE,

File: debezium-core/src/test/java/io/debezium/config/ConfigurationTest.java
Patch:
@@ -5,10 +5,10 @@
  */
 package io.debezium.config;
 
+import static io.debezium.config.CommonConnectorConfig.TOPIC_PREFIX;
 import static io.debezium.relational.RelationalDatabaseConnectorConfig.COLUMN_EXCLUDE_LIST;
 import static io.debezium.relational.RelationalDatabaseConnectorConfig.COLUMN_INCLUDE_LIST;
 import static io.debezium.relational.RelationalDatabaseConnectorConfig.MSG_KEY_COLUMNS;
-import static io.debezium.schema.AbstractTopicNamingStrategy.TOPIC_PREFIX;
 import static org.fest.assertions.Assertions.assertThat;
 
 import java.util.List;

File: debezium-microbenchmark-oracle/src/main/java/io/debezium/performance/connector/oracle/EndToEndPerf.java
Patch:
@@ -43,6 +43,7 @@
 import org.openjdk.jmh.annotations.TearDown;
 import org.openjdk.jmh.annotations.Warmup;
 
+import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.oracle.OracleConnection;
 import io.debezium.connector.oracle.OracleConnector;
@@ -52,7 +53,6 @@
 import io.debezium.connector.oracle.OracleConnectorConfig.SnapshotMode;
 import io.debezium.embedded.EmbeddedEngine;
 import io.debezium.jdbc.JdbcConfiguration;
-import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.file.history.FileSchemaHistory;
 import io.debezium.util.IoUtil;
 
@@ -236,7 +236,7 @@ private Configuration.Builder defaultConnectorConfig() {
             Configuration.Builder builder = Configuration.create();
             jdbcConfiguration.forEach((f, v) -> builder.with(OracleConnectorConfig.DATABASE_CONFIG_PREFIX + f, v));
 
-            return builder.with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
+            return builder.with(CommonConnectorConfig.TOPIC_PREFIX, SERVER_NAME)
                     .with(OracleConnectorConfig.PDB_NAME, "ORCLPDB1")
                     .with(OracleConnectorConfig.INCLUDE_SCHEMA_CHANGES, false)
                     .with(OracleConnectorConfig.CONNECTOR_ADAPTER, ConnectorAdapter.LOG_MINER)

File: debezium-core/src/main/java/io/debezium/connector/SnapshotRecord.java
Patch:
@@ -45,7 +45,7 @@ public enum SnapshotRecord {
 
     public static SnapshotRecord fromSource(Struct source) {
         if (source.schema().field(AbstractSourceInfo.SNAPSHOT_KEY) != null
-                && io.debezium.data.Enum.ENUM_SCHEMA_NAME.equals(source.schema().field(AbstractSourceInfo.SNAPSHOT_KEY).schema().name())) {
+                && io.debezium.data.Enum.LOGICAL_NAME.equals(source.schema().field(AbstractSourceInfo.SNAPSHOT_KEY).schema().name())) {
             final String snapshotString = source.getString(AbstractSourceInfo.SNAPSHOT_KEY);
             if (snapshotString != null) {
                 return SnapshotRecord.valueOf(snapshotString.toUpperCase());

File: debezium-core/src/main/java/io/debezium/data/Bits.java
Patch:
@@ -19,8 +19,9 @@
  */
 public class Bits {
 
-    public static final String BITS_SCHEMA_NAME = "io.debezium.data.Bits";
-    public static final String BITS_LENGTH_FIELD = "length";
+    public static final String LOGICAL_NAME = "io.debezium.data.Bits";
+    public static final String LENGTH_FIELD = "length";
+    public static final int SCHEMA_VERSION = 1;
 
     private static final SchemaFactory schemaFactoryObject = SchemaFactory.get();
 

File: debezium-core/src/main/java/io/debezium/data/Enum.java
Patch:
@@ -20,8 +20,9 @@
  */
 public class Enum {
 
-    public static final String ENUM_SCHEMA_NAME = "io.debezium.data.Enum";
-    public static final String ENUM_VALUES_FIELD = "allowed";
+    public static final String LOGICAL_NAME = "io.debezium.data.Enum";
+    public static final String VALUES_FIELD = "allowed";
+    public static final int SCHEMA_VERSION = 1;
 
     private static final SchemaFactory schemaFactoryObject = SchemaFactory.get();
 

File: debezium-core/src/main/java/io/debezium/data/EnumSet.java
Patch:
@@ -20,8 +20,9 @@
  */
 public class EnumSet {
 
-    public static final String ENUM_SET_SCHEMA_NAME = "io.debezium.data.EnumSet";
-    public static final String ENUM_SET_VALUES_FIELD = "allowed";
+    public static final String LOGICAL_NAME = "io.debezium.data.EnumSet";
+    public static final String VALUES_FIELD = "allowed";
+    public static final int SCHEMA_VERSION = 1;
 
     private static final SchemaFactory schemaFactoryObject = SchemaFactory.get();
 

File: debezium-core/src/main/java/io/debezium/data/Json.java
Patch:
@@ -17,7 +17,8 @@
  */
 public class Json {
 
-    public static final String JSON_SCHEMA_NAME = "io.debezium.data.Json";
+    public static final String LOGICAL_NAME = "io.debezium.data.Json";
+    public static final int SCHEMA_VERSION = 1;
 
     private static final SchemaFactory schemaFactoryObject = SchemaFactory.get();
 

File: debezium-core/src/main/java/io/debezium/data/Uuid.java
Patch:
@@ -18,7 +18,8 @@
  */
 public class Uuid {
 
-    public static final String UUID_SCHEMA_NAME = "io.debezium.data.Uuid";
+    public static final String LOGICAL_NAME = "io.debezium.data.Uuid";
+    public static final int SCHEMA_VERSION = 1;
 
     private static final SchemaFactory schemaFactoryObject = SchemaFactory.get();
 

File: debezium-core/src/main/java/io/debezium/data/Xml.java
Patch:
@@ -18,7 +18,8 @@
  */
 public class Xml {
 
-    public static final String XML_SCHEMA_NAME = "io.debezium.data.Xml";
+    public static final String LOGICAL_NAME = "io.debezium.data.Xml";
+    public static final int SCHEMA_VERSION = 1;
 
     private static final SchemaFactory schemaFactoryObject = SchemaFactory.get();
 

File: debezium-core/src/main/java/io/debezium/pipeline/EventDispatcher.java
Patch:
@@ -44,9 +44,9 @@
 import io.debezium.schema.DatabaseSchema;
 import io.debezium.schema.HistorizedDatabaseSchema;
 import io.debezium.schema.SchemaChangeEvent;
+import io.debezium.schema.SchemaFactory;
 import io.debezium.spi.schema.DataCollectionId;
 import io.debezium.spi.topic.TopicNamingStrategy;
-import io.debezium.schema.SchemaFactory;
 import io.debezium.util.SchemaNameAdjuster;
 
 /**

File: debezium-core/src/main/java/io/debezium/pipeline/txmetadata/TransactionMonitor.java
Patch:
@@ -26,8 +26,8 @@
 import io.debezium.pipeline.source.spi.EventMetadataProvider;
 import io.debezium.pipeline.spi.OffsetContext;
 import io.debezium.pipeline.spi.Partition;
-import io.debezium.spi.schema.DataCollectionId;
 import io.debezium.schema.SchemaFactory;
+import io.debezium.spi.schema.DataCollectionId;
 import io.debezium.util.SchemaNameAdjuster;
 
 /**

File: debezium-core/src/test/java/io/debezium/data/EnumSetTest.java
Patch:
@@ -35,12 +35,12 @@ public void shouldCreateSchemaFromValues() {
     private void assertBuilder(SchemaBuilder builder, String expectedAllowedValues) {
         assertThat(builder).isNotNull();
         assertThat(builder.parameters()).isNotNull();
-        assertThat(builder.parameters().get(EnumSet.ENUM_SET_VALUES_FIELD)).isEqualTo(expectedAllowedValues);
+        assertThat(builder.parameters().get(EnumSet.VALUES_FIELD)).isEqualTo(expectedAllowedValues);
     }
 
     private void assertSchema(Schema schema, String expectedAllowedValues) {
         assertThat(schema).isNotNull();
         assertThat(schema.parameters()).isNotNull();
-        assertThat(schema.parameters().get(EnumSet.ENUM_SET_VALUES_FIELD)).isEqualTo(expectedAllowedValues);
+        assertThat(schema.parameters().get(EnumSet.VALUES_FIELD)).isEqualTo(expectedAllowedValues);
     }
 }
\ No newline at end of file

File: debezium-core/src/test/java/io/debezium/data/EnumTest.java
Patch:
@@ -36,12 +36,12 @@ public void shouldCreateSchemaFromValues() {
     private void assertBuilder(SchemaBuilder builder, String expectedAllowedValues) {
         assertThat(builder).isNotNull();
         assertThat(builder.parameters()).isNotNull();
-        assertThat(builder.parameters().get(Enum.ENUM_VALUES_FIELD)).isEqualTo(expectedAllowedValues);
+        assertThat(builder.parameters().get(Enum.VALUES_FIELD)).isEqualTo(expectedAllowedValues);
     }
 
     private void assertSchema(Schema schema, String expectedAllowedValues) {
         assertThat(schema).isNotNull();
         assertThat(schema.parameters()).isNotNull();
-        assertThat(schema.parameters().get(Enum.ENUM_VALUES_FIELD)).isEqualTo(expectedAllowedValues);
+        assertThat(schema.parameters().get(Enum.VALUES_FIELD)).isEqualTo(expectedAllowedValues);
     }
 }

File: debezium-core/src/main/java/io/debezium/connector/SnapshotRecord.java
Patch:
@@ -45,7 +45,7 @@ public enum SnapshotRecord {
 
     public static SnapshotRecord fromSource(Struct source) {
         if (source.schema().field(AbstractSourceInfo.SNAPSHOT_KEY) != null
-                && io.debezium.data.Enum.LOGICAL_NAME.equals(source.schema().field(AbstractSourceInfo.SNAPSHOT_KEY).schema().name())) {
+                && io.debezium.data.Enum.ENUM_SCHEMA_NAME.equals(source.schema().field(AbstractSourceInfo.SNAPSHOT_KEY).schema().name())) {
             final String snapshotString = source.getString(AbstractSourceInfo.SNAPSHOT_KEY);
             if (snapshotString != null) {
                 return SnapshotRecord.valueOf(snapshotString.toUpperCase());

File: debezium-core/src/test/java/io/debezium/data/EnumSetTest.java
Patch:
@@ -35,12 +35,12 @@ public void shouldCreateSchemaFromValues() {
     private void assertBuilder(SchemaBuilder builder, String expectedAllowedValues) {
         assertThat(builder).isNotNull();
         assertThat(builder.parameters()).isNotNull();
-        assertThat(builder.parameters().get(EnumSet.VALUES_FIELD)).isEqualTo(expectedAllowedValues);
+        assertThat(builder.parameters().get(EnumSet.ENUM_SET_VALUES_FIELD)).isEqualTo(expectedAllowedValues);
     }
 
     private void assertSchema(Schema schema, String expectedAllowedValues) {
         assertThat(schema).isNotNull();
         assertThat(schema.parameters()).isNotNull();
-        assertThat(schema.parameters().get(EnumSet.VALUES_FIELD)).isEqualTo(expectedAllowedValues);
+        assertThat(schema.parameters().get(EnumSet.ENUM_SET_VALUES_FIELD)).isEqualTo(expectedAllowedValues);
     }
 }
\ No newline at end of file

File: debezium-core/src/test/java/io/debezium/data/EnumTest.java
Patch:
@@ -36,12 +36,12 @@ public void shouldCreateSchemaFromValues() {
     private void assertBuilder(SchemaBuilder builder, String expectedAllowedValues) {
         assertThat(builder).isNotNull();
         assertThat(builder.parameters()).isNotNull();
-        assertThat(builder.parameters().get(Enum.VALUES_FIELD)).isEqualTo(expectedAllowedValues);
+        assertThat(builder.parameters().get(Enum.ENUM_VALUES_FIELD)).isEqualTo(expectedAllowedValues);
     }
 
     private void assertSchema(Schema schema, String expectedAllowedValues) {
         assertThat(schema).isNotNull();
         assertThat(schema.parameters()).isNotNull();
-        assertThat(schema.parameters().get(Enum.VALUES_FIELD)).isEqualTo(expectedAllowedValues);
+        assertThat(schema.parameters().get(Enum.ENUM_VALUES_FIELD)).isEqualTo(expectedAllowedValues);
     }
 }

File: debezium-core/src/main/java/io/debezium/schema/SchemaFactory.java
Patch:
@@ -130,7 +130,8 @@ public Schema transactionValueSchema(SchemaNameAdjuster adjuster) {
                 .field(TransactionMonitor.DEBEZIUM_TRANSACTION_STATUS_KEY, Schema.STRING_SCHEMA)
                 .field(TransactionMonitor.DEBEZIUM_TRANSACTION_ID_KEY, Schema.STRING_SCHEMA)
                 .field(TransactionMonitor.DEBEZIUM_TRANSACTION_EVENT_COUNT_KEY, Schema.OPTIONAL_INT64_SCHEMA)
-                .field(TransactionMonitor.DEBEZIUM_TRANSACTION_DATA_COLLECTIONS_KEY, SchemaBuilder.array(transactionEventCountPerDataCollectionSchema()))
+                .field(TransactionMonitor.DEBEZIUM_TRANSACTION_DATA_COLLECTIONS_KEY,
+                        SchemaBuilder.array(transactionEventCountPerDataCollectionSchema()).optional().build())
                 .field(TransactionMonitor.DEBEZIUM_TRANSACTION_TS_MS, Schema.INT64_SCHEMA)
                 .build();
     }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -211,7 +211,7 @@ public boolean shouldStream() {
         }
 
         /**
-         * Whether the schema can be recovered if database history is corrupted.
+         * Whether the schema can be recovered if database schema history is corrupted.
          */
         public boolean shouldSnapshotOnSchemaError() {
             return shouldSnapshotOnSchemaError;
@@ -733,11 +733,11 @@ public static SecureConnectionMode parse(String value, String defaultValue) {
             .withValidation(Field::isNonNegativeInteger);
 
     /**
-     * The database history class is hidden in the {@link #configDef()} since that is designed to work with a user interface,
+     * The database schema history class is hidden in the {@link #configDef()} since that is designed to work with a user interface,
      * and in these situations using Kafka is the only way to go.
      */
     public static final Field SCHEMA_HISTORY = Field.create("schema.history")
-            .withDisplayName("Database history class")
+            .withDisplayName("Database schema history class")
             .withType(Type.CLASS)
             .withWidth(Width.LONG)
             .withImportance(Importance.LOW)

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -321,12 +321,12 @@ private boolean validateAndLoadSchemaHistory(MySqlConnectorConfig config, MySqlP
                 // would like to also verify binlog position exists, but it defaults to 0 which is technically valid
                 throw new DebeziumException("Could not find existing binlog information while attempting schema only recovery snapshot");
             }
-            LOGGER.info("Connector started for the first time, database history recovery will not be executed");
+            LOGGER.info("Connector started for the first time, database schema history recovery will not be executed");
             schema.initializeStorage();
             return false;
         }
         if (!schema.historyExists()) {
-            LOGGER.warn("Database history was not found but was expected");
+            LOGGER.warn("Database schema history was not found but was expected");
             if (config.getSnapshotMode().shouldSnapshotOnSchemaError()) {
                 // But check to see if the server still has those binlog coordinates ...
                 if (!isBinlogAvailable(config, offset)) {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDatabaseSchema.java
Patch:
@@ -283,7 +283,7 @@ else if (event instanceof SetVariableEvent) {
             }
         }
         else {
-            LOGGER.debug("Changes for DDL '{}' were filtered and not recorded in database history", ddlStatements);
+            LOGGER.debug("Changes for DDL '{}' were filtered and not recorded in database schema history", ddlStatements);
         }
         return schemaChangeEvents;
     }
@@ -340,7 +340,7 @@ protected DdlParser getDdlParser() {
     }
 
     /**
-     * Return true if the database history entity exists
+     * Return true if the database schema history entity exists
      */
     public boolean historyExists() {
         return schemaHistory.exists();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlStreamingChangeEventSource.java
Patch:
@@ -684,7 +684,7 @@ private void informAboutUnknownTableIfRequired(MySqlPartition partition, MySqlOf
 
             if (inconsistentSchemaHandlingMode == EventProcessingFailureHandlingMode.FAIL) {
                 LOGGER.error(
-                        "Encountered change event '{}' at offset {} for table {} whose schema isn't known to this connector. One possible cause is an incomplete database history topic. Take a new snapshot in this case.{}"
+                        "Encountered change event '{}' at offset {} for table {} whose schema isn't known to this connector. One possible cause is an incomplete database schema history topic. Take a new snapshot in this case.{}"
                                 + "Use the mysqlbinlog tool to view the problematic event: mysqlbinlog --start-position={} --stop-position={} --verbose {}",
                         event, offsetContext.getOffset(), tableId, System.lineSeparator(), eventHeader.getPosition(),
                         eventHeader.getNextPosition(), offsetContext.getSource().binlogFilename());
@@ -693,15 +693,15 @@ private void informAboutUnknownTableIfRequired(MySqlPartition partition, MySqlOf
             }
             else if (inconsistentSchemaHandlingMode == EventProcessingFailureHandlingMode.WARN) {
                 LOGGER.warn(
-                        "Encountered change event '{}' at offset {} for table {} whose schema isn't known to this connector. One possible cause is an incomplete database history topic. Take a new snapshot in this case.{}"
+                        "Encountered change event '{}' at offset {} for table {} whose schema isn't known to this connector. One possible cause is an incomplete database schema history topic. Take a new snapshot in this case.{}"
                                 + "The event will be ignored.{}"
                                 + "Use the mysqlbinlog tool to view the problematic event: mysqlbinlog --start-position={} --stop-position={} --verbose {}",
                         event, offsetContext.getOffset(), tableId, System.lineSeparator(), System.lineSeparator(),
                         eventHeader.getPosition(), eventHeader.getNextPosition(), offsetContext.getSource().binlogFilename());
             }
             else {
                 LOGGER.debug(
-                        "Encountered change event '{}' at offset {} for table {} whose schema isn't known to this connector. One possible cause is an incomplete database history topic. Take a new snapshot in this case.{}"
+                        "Encountered change event '{}' at offset {} for table {} whose schema isn't known to this connector. One possible cause is an incomplete database schema history topic. Take a new snapshot in this case.{}"
                                 + "The event will be ignored.{}"
                                 + "Use the mysqlbinlog tool to view the problematic event: mysqlbinlog --start-position={} --stop-position={} --verbose {}",
                         event, offsetContext.getOffset(), tableId, System.lineSeparator(), System.lineSeparator(),

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlSchemaHistoryIT.java
Patch:
@@ -23,7 +23,7 @@
 
 /**
 *
-* The test to verify whether DDL is stored correctly in database history.
+* The test to verify whether DDL is stored correctly in database schema history.
 *
 * @author Jiri Pechanec
 */

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -779,7 +779,7 @@ public boolean shouldStream() {
         }
 
         /**
-         * Whether the schema can be recovered if database history is corrupted.
+         * Whether the schema can be recovered if database schema history is corrupted.
          */
         public boolean shouldSnapshotOnSchemaError() {
             return shouldSnapshotOnSchemaError;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorTask.java
Patch:
@@ -183,12 +183,12 @@ private void validateAndLoadSchemaHistory(OracleConnectorConfig config, OraclePa
                 // would like to also verify redo log position exists, but it defaults to 0 which is technically valid
                 throw new DebeziumException("Could not find existing redo log information while attempting schema only recovery snapshot");
             }
-            LOGGER.info("Connector started for the first time, database history recovery will not be executed");
+            LOGGER.info("Connector started for the first time, database schema history recovery will not be executed");
             schema.initializeStorage();
             return;
         }
         if (!schema.historyExists()) {
-            LOGGER.warn("Database history was not found but was expected");
+            LOGGER.warn("Database schema history was not found but was expected");
             if (config.getSnapshotMode().shouldSnapshotOnSchemaError()) {
                 LOGGER.info("The db-history topic is missing but we are in {} snapshot mode. " +
                         "Attempting to snapshot the current schema and then begin reading the redo log from the last recorded offset.",

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleDatabaseSchema.java
Patch:
@@ -119,7 +119,7 @@ public boolean isStorageInitializationExecuted() {
     }
 
     /**
-     * Return true if the database history entity exists
+     * Return true if the database schema history entity exists
      */
     public boolean historyExists() {
         return schemaHistory.exists();

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleDefaultValueIT.java
Patch:
@@ -444,7 +444,7 @@ private void shouldHandleDefaultValuesCommon(List<ColumnDefinition> columnDefini
     }
 
     /**
-     * Restarts the connector and verifies when the database history topic is loaded that we can parse
+     * Restarts the connector and verifies when the database schema history topic is loaded that we can parse
      * all the loaded history statements without failures.
      */
     private void TestDefaultValuesByRestartAndLoadingHistoryTopic() throws Exception {

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleSchemaHistoryTest.java
Patch:
@@ -29,7 +29,7 @@
 import oracle.jdbc.OracleTypes;
 
 /**
- * Unit tests for Oracle's database history.
+ * Unit tests for Oracle's database schema history.
  * 
  * @author Chris Cranford
  */

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorIT.java
Patch:
@@ -2074,7 +2074,7 @@ public void shouldDetectPurgedHistory() throws Exception {
         start(SqlServerConnector.class, config);
         assertConnectorNotRunning();
         assertThat(logInterceptor.containsStacktraceElement(
-                "The db history topic or its content is fully or partially missing. Please check database history topic configuration and re-execute the snapshot."))
+                "The db history topic or its content is fully or partially missing. Please check database schema history topic configuration and re-execute the snapshot."))
                         .isTrue();
     }
 

File: debezium-core/src/main/java/io/debezium/relational/HistorizedRelationalDatabaseSchema.java
Patch:
@@ -55,7 +55,7 @@ public void recover(Offsets<?, ?> offsets) {
         }
 
         if (!schemaHistory.exists()) {
-            String msg = "The db history topic or its content is fully or partially missing. Please check database history topic configuration and re-execute the snapshot.";
+            String msg = "The db history topic or its content is fully or partially missing. Please check database schema history topic configuration and re-execute the snapshot.";
             throw new DebeziumException(msg);
         }
 

File: debezium-core/src/main/java/io/debezium/relational/RelationalDatabaseConnectorConfig.java
Patch:
@@ -388,7 +388,7 @@ public static DecimalHandlingMode parse(String value, String defaultValue) {
             .withDescription("Whether the connector should publish changes in the database schema to a Kafka topic with "
                     + "the same name as the database server ID. Each schema change will be recorded using a key that "
                     + "contains the database name and whose value include logical description of the new schema and optionally the DDL statement(s). "
-                    + "The default is 'true'. This is independent of how the connector internally records database history.")
+                    + "The default is 'true'. This is independent of how the connector internally records database schema history.")
             .withDefault(true);
 
     public static final Field INCLUDE_SCHEMA_COMMENTS = Field.create("include.schema.comments")

File: debezium-core/src/main/java/io/debezium/relational/history/AbstractSchemaHistory.java
Patch:
@@ -177,7 +177,7 @@ else if (ddl != null && ddlParser != null) {
                     }
                     catch (final ParsingException | MultipleParsingExceptions e) {
                         if (skipUnparseableDDL) {
-                            logger.warn("Ignoring unparseable statements '{}' stored in database history: {}", ddl, e);
+                            logger.warn("Ignoring unparseable statements '{}' stored in database schema history: {}", ddl, e);
                         }
                         else {
                             throw e;

File: debezium-embedded/src/test/java/io/debezium/relational/history/AbstractSchemaHistoryTest.java
Patch:
@@ -24,7 +24,7 @@
 import io.debezium.relational.ddl.DdlParser;
 
 /**
- * An abstract database history class, allowing each connector to extend to offer a common set of tests
+ * An abstract database schema history class, allowing each connector to extend to offer a common set of tests
  *
  * @author Chris Cranford
  */

File: debezium-storage/debezium-storage-file/src/main/java/io/debezium/storage/file/history/FileSchemaHistory.java
Patch:
@@ -44,7 +44,7 @@
 public final class FileSchemaHistory extends AbstractSchemaHistory {
 
     public static final Field FILE_PATH = Field.create(SchemaHistory.CONFIGURATION_FIELD_PREFIX_STRING + "file.filename")
-            .withDescription("The path to the file that will be used to record the database history")
+            .withDescription("The path to the file that will be used to record the database schema history")
             .required();
 
     public static Collection<Field> ALL_FIELDS = Collect.arrayListOf(FILE_PATH);
@@ -64,7 +64,7 @@ public void configure(Configuration config, HistoryRecordComparator comparator,
         }
         config.validateAndRecord(ALL_FIELDS, logger::error);
         if (running.get()) {
-            throw new IllegalStateException("Database history file already initialized to " + path);
+            throw new IllegalStateException("Database schema history file already initialized to " + path);
         }
         super.configure(config, comparator, listener, useCatalogBeforeSchema);
         path = Paths.get(config.getString(FILE_PATH));

File: debezium-core/src/main/java/io/debezium/relational/HistorizedRelationalDatabaseConnectorConfig.java
Patch:
@@ -97,15 +97,15 @@ public SchemaHistory getSchemaHistory() {
         }
 
         // Do not remove the prefix from the subset of config properties ...
-        Configuration dbHistoryConfig = config.subset(SchemaHistory.CONFIGURATION_FIELD_PREFIX_STRING, false)
+        Configuration schemaHistoryConfig = config.subset(SchemaHistory.CONFIGURATION_FIELD_PREFIX_STRING, false)
                 .edit()
-                .withDefault(SchemaHistory.NAME, getLogicalName() + "-dbhistory")
+                .withDefault(SchemaHistory.NAME, getLogicalName() + "-schemahistory")
                 .withDefault(AbstractSchemaHistory.INTERNAL_CONNECTOR_CLASS, connectorClass.getName())
                 .withDefault(AbstractSchemaHistory.INTERNAL_CONNECTOR_ID, logicalName)
                 .build();
 
         HistoryRecordComparator historyComparator = getHistoryRecordComparator();
-        schemaHistory.configure(dbHistoryConfig, historyComparator,
+        schemaHistory.configure(schemaHistoryConfig, historyComparator,
                 new SchemaHistoryMetrics(this, multiPartitionMode()), useCatalogBeforeSchema()); // validates
 
         return schemaHistory;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnector.java
Patch:
@@ -67,7 +67,7 @@
  * <h2>Use of Topics</h2>
  * The connector will write to a separate topic all of the source records that correspond to a single collection. The topic will
  * be named "{@code <logicalName>.<databaseName>.<collectionName>}", where {@code <logicalName>} is set via the
- * "{@link MongoDbConnectorConfig#LOGICAL_NAME mongodb.name}" configuration property.
+ * "{@link AbstractTopicNamingStrategy.TOPIC_PREFIX topic.prefix}" configuration property.
  *
  * <h2>Configuration</h2>
  * <p>

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbTaskContext.java
Patch:
@@ -10,6 +10,7 @@
 import io.debezium.config.Configuration;
 import io.debezium.connector.common.CdcSourceTaskContext;
 import io.debezium.connector.mongodb.MongoDbConnectorConfig.CaptureMode;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.spi.topic.TopicNamingStrategy;
 
 /**
@@ -28,13 +29,13 @@ public class MongoDbTaskContext extends CdcSourceTaskContext {
      * @param config the configuration
      */
     public MongoDbTaskContext(Configuration config) {
-        super(Module.contextName(), config.getString(MongoDbConnectorConfig.LOGICAL_NAME), Collections::emptySet);
+        super(Module.contextName(), config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX), Collections::emptySet);
 
         this.filters = new Filters(config);
         this.connectorConfig = new MongoDbConnectorConfig(config);
         this.source = new SourceInfo(connectorConfig);
         this.topicNamingStrategy = connectorConfig.getTopicNamingStrategy(MongoDbConnectorConfig.TOPIC_NAMING_STRATEGY);
-        this.serverName = config.getString(MongoDbConnectorConfig.LOGICAL_NAME);
+        this.serverName = config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX);
         this.connectionContext = new ConnectionContext(config);
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/Configurator.java
Patch:
@@ -7,6 +7,7 @@
 
 import io.debezium.config.Configuration;
 import io.debezium.config.Field;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Testing;
 
 /**
@@ -34,7 +35,7 @@ public Configurator with(Field field, int value) {
     }
 
     public Configurator serverName(String serverName) {
-        return with(MongoDbConnectorConfig.LOGICAL_NAME, serverName);
+        return with(AbstractTopicNamingStrategy.TOPIC_PREFIX, serverName);
     }
 
     public Configurator hosts(String hosts) {

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FieldBlacklistIT.java
Patch:
@@ -24,6 +24,7 @@
 import com.mongodb.client.model.InsertOneOptions;
 
 import io.debezium.config.Configuration;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Testing;
 
 public class FieldBlacklistIT extends AbstractMongoConnectorIT {
@@ -1454,7 +1455,7 @@ private Configuration getConfiguration(String excludeList) {
         return TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.FIELD_EXCLUDE_LIST, excludeList)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, "dbA.c1")
-                .with(MongoDbConnectorConfig.LOGICAL_NAME, SERVER_NAME)
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
                 .build();
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FieldExcludeListIT.java
Patch:
@@ -25,6 +25,7 @@
 import io.debezium.config.Configuration;
 import io.debezium.connector.mongodb.FieldBlacklistIT.ExpectedUpdate;
 import io.debezium.doc.FixFor;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Testing;
 
 public class FieldExcludeListIT extends AbstractMongoConnectorIT {
@@ -1564,7 +1565,7 @@ public void shouldExcludeFieldsIncludingSameNamesForReadEvent() throws Interrupt
         config = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.FIELD_EXCLUDE_LIST, "*.c1.name,*.c1.active,*.c2.name,*.c2.active")
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, "dbA.c1,dbA.c2")
-                .with(MongoDbConnectorConfig.LOGICAL_NAME, SERVER_NAME)
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
                 .build();
         context = new MongoDbTaskContext(config);
 
@@ -1595,7 +1596,7 @@ private Configuration getConfiguration(String fieldExcludeList, String database,
         return TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.FIELD_EXCLUDE_LIST, fieldExcludeList)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, database + "." + collection)
-                .with(MongoDbConnectorConfig.LOGICAL_NAME, SERVER_NAME)
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
                 .build();
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FieldRenamesIT.java
Patch:
@@ -26,6 +26,7 @@
 import io.debezium.connector.mongodb.FieldBlacklistIT.ExpectedUpdate;
 import io.debezium.doc.FixFor;
 import io.debezium.junit.logging.LogInterceptor;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * @author Chris Cranford
@@ -1826,7 +1827,7 @@ private static Configuration getConfiguration(String fieldRenames) {
     private static Configuration getConfiguration(String fieldRenames, String database, String collection) {
         Configuration.Builder builder = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, database + "." + collection)
-                .with(MongoDbConnectorConfig.LOGICAL_NAME, SERVER_NAME);
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME);
 
         if (fieldRenames != null && !"".equals(fieldRenames.trim())) {
             builder = builder.with(MongoDbConnectorConfig.FIELD_RENAMES, fieldRenames);

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorWithConnectionStringIT.java
Patch:
@@ -34,6 +34,7 @@
 import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;
 import io.debezium.data.Envelope;
 import io.debezium.data.Envelope.Operation;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.IoUtil;
 import io.debezium.util.Testing;
 
@@ -63,7 +64,7 @@ public void shouldConsumeAllEventsFromDatabase(String connectionString, boolean
         config = Configuration.from(properties).edit()
                 .with(MongoDbConnectorConfig.POLL_INTERVAL_MS, 10)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, "dbit.*")
-                .with(MongoDbConnectorConfig.LOGICAL_NAME, "mongo")
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "mongo")
                 .with(MongoDbConnectorConfig.CONNECTION_STRING, connectionString)
                 .with(MongoDbConnectorConfig.SSL_ENABLED, ssl)
                 .with(MongoDbConnectorConfig.AUTO_DISCOVER_MEMBERS, true)

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/SourceInfoTest.java
Patch:
@@ -22,6 +22,7 @@
 
 import io.debezium.config.Configuration;
 import io.debezium.connector.AbstractSourceInfoStructMaker;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * @author Randall Hauch
@@ -36,7 +37,7 @@ public class SourceInfoTest {
     public void beforeEach() {
         source = new SourceInfo(new MongoDbConnectorConfig(
                 Configuration.create()
-                        .with(MongoDbConnectorConfig.LOGICAL_NAME, "serverX")
+                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "serverX")
                         .build()));
     }
 
@@ -85,7 +86,7 @@ public void shouldSetAndReturnRecordedOffset() {
         Map<String, String> partition = source.partition(REPLICA_SET_NAME);
         source = new SourceInfo(new MongoDbConnectorConfig(
                 Configuration.create()
-                        .with(MongoDbConnectorConfig.LOGICAL_NAME, "serverX")
+                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "serverX")
                         .build()));
         source.setOffsetFor(partition, offset);
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/TestHelper.java
Patch:
@@ -28,6 +28,7 @@
 import io.debezium.config.Configuration;
 import io.debezium.config.Configuration.Builder;
 import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * A common test configuration options
@@ -45,7 +46,7 @@ public static Configuration getConfiguration() {
         final Builder cfgBuilder = Configuration.fromSystemProperties("connector.").edit()
                 .withDefault(MongoDbConnectorConfig.HOSTS, "rs0/localhost:27017")
                 .withDefault(MongoDbConnectorConfig.AUTO_DISCOVER_MEMBERS, false)
-                .withDefault(MongoDbConnectorConfig.LOGICAL_NAME, "mongo1");
+                .withDefault(AbstractTopicNamingStrategy.TOPIC_PREFIX, "mongo1");
         return cfgBuilder.build();
     }
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/AbstractExtractNewDocumentStateTestIT.java
Patch:
@@ -21,6 +21,7 @@
 import io.debezium.connector.mongodb.MongoDbTaskContext;
 import io.debezium.connector.mongodb.TestHelper;
 import io.debezium.data.Envelope;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * Baseline for all integrations tests regarding MongoDB Update Operations
@@ -46,7 +47,7 @@ public void beforeEach() {
         Configuration config = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.POLL_INTERVAL_MS, 10)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, DB_NAME + "." + this.getCollectionName())
-                .with(MongoDbConnectorConfig.LOGICAL_NAME, SERVER_NAME)
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
                 .build();
 
         beforeEach(config);
@@ -82,7 +83,7 @@ protected void restartConnectorWithoutEmittingTombstones() {
         Configuration config = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.POLL_INTERVAL_MS, 10)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, DB_NAME + "." + this.getCollectionName())
-                .with(MongoDbConnectorConfig.LOGICAL_NAME, SERVER_NAME)
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
                 .with(MongoDbConnectorConfig.TOMBSTONES_ON_DELETE, false)
                 .build();
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/ExtractNewDocumentStateTest.java
Patch:
@@ -35,6 +35,7 @@
 import io.debezium.doc.FixFor;
 import io.debezium.junit.SkipTestRule;
 import io.debezium.junit.SkipWhenKafkaVersion;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.schema.DefaultTopicNamingStrategy;
 import io.debezium.spi.topic.TopicNamingStrategy;
 
@@ -65,7 +66,7 @@ public void setup() {
         filters = new Configurator().createFilters();
         MongoDbConnectorConfig connectorConfig = new MongoDbConnectorConfig(
                 Configuration.create()
-                        .with(MongoDbConnectorConfig.LOGICAL_NAME, SERVER_NAME)
+                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
                         .build());
         source = new SourceInfo(connectorConfig);
         topicNamingStrategy = DefaultTopicNamingStrategy.create(connectorConfig);

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/outbox/MongoEventRouterTestIT.java
Patch:
@@ -31,6 +31,7 @@
 import io.debezium.connector.mongodb.MongoDbConnectorConfig;
 import io.debezium.connector.mongodb.MongoDbTaskContext;
 import io.debezium.connector.mongodb.TestHelper;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 /**
  * Integration tests for {@link MongoEventRouter}
@@ -49,7 +50,7 @@ public void beforeEach() {
         Configuration config = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.POLL_INTERVAL_MS, 10)
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, DB_NAME + "." + this.getCollectionName())
-                .with(MongoDbConnectorConfig.LOGICAL_NAME, SERVER_NAME)
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
                 .build();
 
         beforeEach(config);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlParserIT.java
Patch:
@@ -28,6 +28,7 @@
 import io.debezium.embedded.AbstractConnectorTest;
 import io.debezium.jdbc.JdbcConfiguration;
 import io.debezium.jdbc.JdbcConnection;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.ContainerImageVersions;
 import io.debezium.util.Testing;
 
@@ -75,7 +76,7 @@ public void afterEach() {
 
     public Configuration.Builder defaultConfig() {
         return Configuration.create()
-                .with(MySqlConnectorConfig.SERVER_NAME, "myServer1")
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "myServer1")
                 .with(MySqlConnectorConfig.HOSTNAME, System.getProperty("database.hostname", "localhost"))
                 .with(CommonConnectorConfig.DATABASE_CONFIG_PREFIX + JdbcConfiguration.PORT, mySQLContainer.getMappedPort(3306))
                 .with(MySqlConnectorConfig.USER, "debezium")

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SourceInfoTest.java
Patch:
@@ -27,6 +27,7 @@
 import io.debezium.data.VerifyRecord;
 import io.debezium.doc.FixFor;
 import io.debezium.document.Document;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class SourceInfoTest {
 
@@ -45,7 +46,7 @@ public class SourceInfoTest {
     @Before
     public void beforeEach() {
         offsetContext = MySqlOffsetContext.initial(new MySqlConnectorConfig(Configuration.create()
-                .with(MySqlConnectorConfig.SERVER_NAME, "server")
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "server")
                 .build()));
         source = offsetContext.getSource();
         inTxn = false;
@@ -445,7 +446,7 @@ protected Map<String, String> offset(String gtidSet, long position, int row, boo
 
     protected SourceInfo sourceWith(Map<String, String> offset) {
         offsetContext = (MySqlOffsetContext) new MySqlOffsetContext.Loader(new MySqlConnectorConfig(Configuration.create()
-                .with(MySqlConnectorConfig.SERVER_NAME, SERVER_NAME)
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
                 .build())).load(offset);
         source = offsetContext.getSource();
         source.databaseEvent("mysql");

File: debezium-connector-mysql/src/test/java/io/debezium/relational/history/KafkaDatabaseHistoryTest.java
Patch:
@@ -39,9 +39,9 @@
 import io.debezium.pipeline.spi.Offsets;
 import io.debezium.pipeline.spi.Partition;
 import io.debezium.pipeline.txmetadata.TransactionContext;
-import io.debezium.relational.RelationalDatabaseConnectorConfig;
 import io.debezium.relational.Tables;
 import io.debezium.relational.ddl.DdlParser;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.kafka.history.KafkaDatabaseHistory;
 import io.debezium.text.ParsingException;
 import io.debezium.util.Collect;
@@ -88,7 +88,7 @@ public void beforeEach() throws Exception {
         MySqlPartition source = new MySqlPartition("my-server", "my-db");
         Configuration config = Configuration.empty()
                 .edit()
-                .with(RelationalDatabaseConnectorConfig.SERVER_NAME, "dbserver1").build();
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "dbserver1").build();
 
         position = new MySqlOffsetContext(false, true, new TransactionContext(), new MySqlReadOnlyIncrementalSnapshotContext<>(),
                 new SourceInfo(new MySqlConnectorConfig(config)));

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorTest.java
Patch:
@@ -20,6 +20,7 @@
 import org.junit.Test;
 
 import io.debezium.config.CommonConnectorConfig;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class OracleConnectorTest {
     OracleConnector connector;
@@ -32,7 +33,7 @@ public void before() {
     @Test
     public void testValidateUnableToConnectNoThrow() {
         Map<String, String> config = new HashMap<>();
-        config.put(OracleConnectorConfig.SERVER_NAME.name(), "dbserver1");
+        config.put(AbstractTopicNamingStrategy.TOPIC_PREFIX.name(), "dbserver1");
         config.put(OracleConnectorConfig.HOSTNAME.name(), "narnia");
         config.put(OracleConnectorConfig.PORT.name(), "4321");
         config.put(OracleConnectorConfig.DATABASE_NAME.name(), "oracle");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleDatabaseHistoryTest.java
Patch:
@@ -18,13 +18,13 @@
 import io.debezium.pipeline.spi.Partition;
 import io.debezium.pipeline.txmetadata.TransactionContext;
 import io.debezium.relational.Column;
-import io.debezium.relational.RelationalDatabaseConnectorConfig;
 import io.debezium.relational.Table;
 import io.debezium.relational.TableId;
 import io.debezium.relational.ddl.DdlParser;
 import io.debezium.relational.history.AbstractDatabaseHistoryTest;
 import io.debezium.relational.history.HistoryRecord;
 import io.debezium.relational.history.TableChanges;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 import oracle.jdbc.OracleTypes;
 
@@ -73,7 +73,7 @@ protected Offsets<Partition, OffsetContext> getOffsets() {
         final OraclePartition source = new OraclePartition(TestHelper.SERVER_NAME, TestHelper.getDatabaseName());
         final Configuration config = Configuration.empty()
                 .edit()
-                .with(RelationalDatabaseConnectorConfig.SERVER_NAME, TestHelper.SERVER_NAME)
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, TestHelper.SERVER_NAME)
                 .build();
         final OracleOffsetContext position = new OracleOffsetContext(new OracleConnectorConfig(config), Scn.valueOf(999),
                 CommitScn.valueOf(999L), null, Scn.valueOf(999), Collections.emptyMap(), false, true, new TransactionContext(),

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/SourceInfoTest.java
Patch:
@@ -18,6 +18,7 @@
 import io.debezium.connector.AbstractSourceInfoStructMaker;
 import io.debezium.data.VerifyRecord;
 import io.debezium.relational.TableId;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class SourceInfoTest {
 
@@ -27,7 +28,7 @@ public class SourceInfoTest {
     public void beforeEach() {
         final OracleConnectorConfig connectorConfig = new OracleConnectorConfig(
                 Configuration.create()
-                        .with(OracleConnectorConfig.SERVER_NAME, "serverX")
+                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "serverX")
                         .with(OracleConnectorConfig.DATABASE_NAME, "mydb")
                         .build());
         source = new SourceInfo(connectorConfig);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -93,6 +93,7 @@
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
 import io.debezium.relational.RelationalDatabaseSchema;
 import io.debezium.relational.RelationalSnapshotChangeEventSource;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.schema.DatabaseSchema;
 import io.debezium.util.Strings;
 import io.debezium.util.Testing;
@@ -214,7 +215,7 @@ public void shouldValidateConfiguration() throws Exception {
         assertConfigurationErrors(validatedConfig, PostgresConnectorConfig.HOSTNAME, 1);
         assertConfigurationErrors(validatedConfig, PostgresConnectorConfig.USER, 1);
         assertConfigurationErrors(validatedConfig, PostgresConnectorConfig.DATABASE_NAME, 1);
-        assertConfigurationErrors(validatedConfig, PostgresConnectorConfig.SERVER_NAME, 1);
+        assertNoConfigurationErrors(validatedConfig, AbstractTopicNamingStrategy.TOPIC_PREFIX);
 
         // validate the non required fields
         validateConfigField(validatedConfig, PostgresConnectorConfig.PLUGIN_NAME, LogicalDecoder.DECODERBUFS.getValue());

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresErrorHandlerTest.java
Patch:
@@ -14,13 +14,14 @@
 import io.debezium.config.Configuration;
 import io.debezium.connector.base.ChangeEventQueue;
 import io.debezium.pipeline.DataChangeEvent;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class PostgresErrorHandlerTest {
     private static final String A_CLASSIFIED_EXCEPTION = "Database connection failed when writing to copy";
 
     private final PostgresErrorHandler errorHandler = new PostgresErrorHandler(
             new PostgresConnectorConfig(Configuration.create()
-                    .with(PostgresConnectorConfig.SERVER_NAME, "postgres")
+                    .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "postgres")
                     .build()),
             new ChangeEventQueue.Builder<DataChangeEvent>().build());
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SourceInfoTest.java
Patch:
@@ -17,6 +17,7 @@
 import io.debezium.data.VerifyRecord;
 import io.debezium.doc.FixFor;
 import io.debezium.relational.TableId;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.time.Conversions;
 
 /**
@@ -31,7 +32,7 @@ public class SourceInfoTest {
     public void beforeEach() {
         source = new SourceInfo(new PostgresConnectorConfig(
                 Configuration.create()
-                        .with(PostgresConnectorConfig.SERVER_NAME, "serverX")
+                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "serverX")
                         .with(PostgresConnectorConfig.DATABASE_NAME, "serverX")
                         .build()));
         source.update(Conversions.toInstantFromMicros(123_456_789L), new TableId("catalogNameX", "schemaNameX", "tableNameX"));

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SourceInfoTest.java
Patch:
@@ -18,6 +18,7 @@
 import io.debezium.connector.AbstractSourceInfoStructMaker;
 import io.debezium.connector.SnapshotRecord;
 import io.debezium.relational.TableId;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class SourceInfoTest {
 
@@ -27,7 +28,7 @@ public class SourceInfoTest {
     public void beforeEach() {
         final SqlServerConnectorConfig connectorConfig = new SqlServerConnectorConfig(
                 Configuration.create()
-                        .with(SqlServerConnectorConfig.SERVER_NAME, "serverX")
+                        .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "serverX")
                         .build());
         source = new SourceInfo(connectorConfig);
         source.setChangeLsn(Lsn.valueOf(new byte[]{ 0x01 }));

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorConfigTest.java
Patch:
@@ -13,6 +13,7 @@
 import org.slf4j.LoggerFactory;
 
 import io.debezium.config.Configuration;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.kafka.history.KafkaDatabaseHistory;
 
 public class SqlServerConnectorConfigTest {
@@ -37,7 +38,7 @@ public void nonEmptyDatabaseNames() {
 
     private Configuration.Builder defaultConfig() {
         return Configuration.create()
-                .with(SqlServerConnectorConfig.SERVER_NAME, "server")
+                .with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "server")
                 .with(SqlServerConnectorConfig.HOSTNAME, "localhost")
                 .with(SqlServerConnectorConfig.USER, "debezium")
                 .with(KafkaDatabaseHistory.BOOTSTRAP_SERVERS, "localhost:9092")

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorTest.java
Patch:
@@ -21,6 +21,7 @@
 import org.junit.Test;
 
 import io.debezium.config.CommonConnectorConfig;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 
 public class SqlServerConnectorTest {
     SqlServerConnector connector;
@@ -33,7 +34,7 @@ public void before() {
     @Test
     public void testValidateUnableToConnectNoThrow() {
         Map<String, String> config = new HashMap<>();
-        config.put(SqlServerConnectorConfig.SERVER_NAME.name(), "dbserver1");
+        config.put(AbstractTopicNamingStrategy.TOPIC_PREFIX.name(), "dbserver1");
         config.put(SqlServerConnectorConfig.HOSTNAME.name(), "narnia");
         config.put(SqlServerConnectorConfig.PORT.name(), "4321");
         config.put(SqlServerConnectorConfig.DATABASE_NAMES.name(), "sqlserver");

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/util/TestHelper.java
Patch:
@@ -41,6 +41,7 @@
 import io.debezium.jdbc.TemporalPrecisionMode;
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
 import io.debezium.relational.TableId;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.file.history.FileDatabaseHistory;
 import io.debezium.util.Collect;
 import io.debezium.util.IoUtil;
@@ -124,7 +125,7 @@ public static Configuration.Builder defaultConnectorConfig() {
         jdbcConfiguration.forEach(
                 (field, value) -> builder.with(SqlServerConnectorConfig.DATABASE_CONFIG_PREFIX + field, value));
 
-        return builder.with(RelationalDatabaseConnectorConfig.SERVER_NAME, "server1")
+        return builder.with(AbstractTopicNamingStrategy.TOPIC_PREFIX, "server1")
                 .with(SqlServerConnectorConfig.DATABASE_HISTORY, FileDatabaseHistory.class)
                 .with(FileDatabaseHistory.FILE_PATH, DB_HISTORY_PATH)
                 .with(RelationalDatabaseConnectorConfig.INCLUDE_SCHEMA_CHANGES, false);

File: debezium-core/src/main/java/io/debezium/connector/common/RelationalBaseSourceConnector.java
Patch:
@@ -16,6 +16,7 @@
 
 import io.debezium.config.Configuration;
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Strings;
 
 /**
@@ -33,7 +34,7 @@ public Config validate(Map<String, String> connectorConfigs) {
         // Validate all of the individual fields, which is easy since don't make any of the fields invisible ...
         Map<String, ConfigValue> results = validateAllFields(config);
 
-        ConfigValue logicalName = results.get(RelationalDatabaseConnectorConfig.SERVER_NAME.name());
+        ConfigValue logicalName = results.get(AbstractTopicNamingStrategy.TOPIC_PREFIX.name());
         // Get the config values for each of the connection-related fields ...
         ConfigValue hostnameValue = results.get(RelationalDatabaseConnectorConfig.HOSTNAME.name());
         ConfigValue portValue = results.get(RelationalDatabaseConnectorConfig.PORT.name());

File: debezium-microbenchmark-oracle/src/main/java/io/debezium/performance/connector/oracle/EndToEndPerf.java
Patch:
@@ -52,6 +52,7 @@
 import io.debezium.connector.oracle.OracleConnectorConfig.SnapshotMode;
 import io.debezium.embedded.EmbeddedEngine;
 import io.debezium.jdbc.JdbcConfiguration;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.file.history.FileDatabaseHistory;
 import io.debezium.util.IoUtil;
 
@@ -235,7 +236,7 @@ private Configuration.Builder defaultConnectorConfig() {
             Configuration.Builder builder = Configuration.create();
             jdbcConfiguration.forEach((f, v) -> builder.with(OracleConnectorConfig.DATABASE_CONFIG_PREFIX + f, v));
 
-            return builder.with(OracleConnectorConfig.SERVER_NAME, SERVER_NAME)
+            return builder.with(AbstractTopicNamingStrategy.TOPIC_PREFIX, SERVER_NAME)
                     .with(OracleConnectorConfig.PDB_NAME, "ORCLPDB1")
                     .with(OracleConnectorConfig.INCLUDE_SCHEMA_CHANGES, false)
                     .with(OracleConnectorConfig.CONNECTOR_ADAPTER, ConnectorAdapter.LOG_MINER)

File: debezium-server/debezium-server-core/src/test/java/io/debezium/server/TestConfigSource.java
Patch:
@@ -36,7 +36,7 @@ public TestConfigSource() {
         integrationTest.put("debezium.source.connector.class", "io.debezium.connector.postgresql.PostgresConnector");
         integrationTest.put("debezium.source." + StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, OFFSET_STORE_PATH.toAbsolutePath().toString());
         integrationTest.put("debezium.source.offset.flush.interval.ms", "0");
-        integrationTest.put("debezium.source.database.server.name", "testc");
+        integrationTest.put("debezium.source.topic.prefix", "testc");
         integrationTest.put("debezium.source.schema.include.list", "inventory");
         integrationTest.put("debezium.source.table.include.list", "inventory.customers");
 

File: debezium-server/debezium-server-eventhubs/src/test/java/io/debezium/server/eventhubs/EventHubsTestConfigSource.java
Patch:
@@ -33,7 +33,7 @@ public EventHubsTestConfigSource() {
         eventHubsTest.put("debezium.source." + StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG,
                 OFFSET_STORE_PATH.toAbsolutePath().toString());
         eventHubsTest.put("debezium.source.offset.flush.interval.ms", "0");
-        eventHubsTest.put("debezium.source.database.server.name", "testc");
+        eventHubsTest.put("debezium.source.topic.prefix", "testc");
         eventHubsTest.put("debezium.source.schema.include.list", "inventory");
         eventHubsTest.put("debezium.source.table.include.list", "inventory.customers");
 

File: debezium-server/debezium-server-http/src/test/java/io/debezium/server/http/HttpTestConfigSource.java
Patch:
@@ -23,7 +23,7 @@ public HttpTestConfigSource() {
         httpTest.put("debezium.source.connector.class", "io.debezium.connector.postgresql.PostgresConnector");
         httpTest.put("debezium.source." + StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, OFFSET_STORE_PATH.toAbsolutePath().toString());
         httpTest.put("debezium.source.offset.flush.interval.ms", "0");
-        httpTest.put("debezium.source.database.server.name", "testc");
+        httpTest.put("debezium.source.topic.prefix", "testc");
         httpTest.put("debezium.source.schema.include.list", "inventory");
         httpTest.put("debezium.source.table.include.list", "inventory.customers");
 

File: debezium-server/debezium-server-kafka/src/test/java/io/debezium/server/kafka/KafkaTestConfigSource.java
Patch:
@@ -26,7 +26,7 @@ public KafkaTestConfigSource() {
         kafkaConfig.put("debezium.source." + StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, OFFSET_STORE_PATH.toAbsolutePath().toString());
 
         kafkaConfig.put("debezium.source.offset.flush.interval.ms", "0");
-        kafkaConfig.put("debezium.source.database.server.name", "testc");
+        kafkaConfig.put("debezium.source.topic.prefix", "testc");
         kafkaConfig.put("debezium.source.schema.include.list", "inventory");
         kafkaConfig.put("debezium.source.table.include.list", "inventory.customers");
         // DBZ-5105

File: debezium-server/debezium-server-kinesis/src/test/java/io/debezium/server/kinesis/KinesisTestConfigSource.java
Patch:
@@ -24,7 +24,7 @@ public KinesisTestConfigSource() {
         kinesisTest.put("debezium.source.connector.class", "io.debezium.connector.postgresql.PostgresConnector");
         kinesisTest.put("debezium.source." + StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, OFFSET_STORE_PATH.toAbsolutePath().toString());
         kinesisTest.put("debezium.source.offset.flush.interval.ms", "0");
-        kinesisTest.put("debezium.source.database.server.name", "testc");
+        kinesisTest.put("debezium.source.topic.prefix", "testc");
         kinesisTest.put("debezium.source.schema.include.list", "inventory");
         kinesisTest.put("debezium.source.table.include.list", "inventory.customers");
 

File: debezium-server/debezium-server-nats-streaming/src/test/java/io/debezium/server/nats/streaming/NatsStreamingTestConfigSource.java
Patch:
@@ -23,7 +23,7 @@ public NatsStreamingTestConfigSource() {
         natsStreamingTest.put("debezium.sink.nats-streaming.cluster.id", "debezium");
         natsStreamingTest.put("debezium.sink.nats-streaming.client.id", "debezium-sink");
         natsStreamingTest.put("debezium.source.connector.class", "io.debezium.connector.postgresql.PostgresConnector");
-        natsStreamingTest.put("debezium.source.database.server.name", "testc");
+        natsStreamingTest.put("debezium.source.topic.prefix", "testc");
         natsStreamingTest.put("debezium.source.schema.include.list", "inventory");
         natsStreamingTest.put("debezium.source.table.include.list", "inventory.customers");
         natsStreamingTest.put("debezium.source." + StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG,

File: debezium-server/debezium-server-pubsub/src/test/java/io/debezium/server/pubsub/PubSubLiteTestConfigSource.java
Patch:
@@ -22,7 +22,7 @@ public PubSubLiteTestConfigSource() {
         pubsubLiteTest.put("debezium.source." + StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG,
                 OFFSET_STORE_PATH.toAbsolutePath().toString());
         pubsubLiteTest.put("debezium.source.offset.flush.interval.ms", "0");
-        pubsubLiteTest.put("debezium.source.database.server.name", "testc");
+        pubsubLiteTest.put("debezium.source.topic.prefix", "testc");
         pubsubLiteTest.put("debezium.source.schema.include.list", "inventory");
         pubsubLiteTest.put("debezium.source.table.include.list", "inventory.customers");
 

File: debezium-server/debezium-server-pubsub/src/test/java/io/debezium/server/pubsub/PubSubTestConfigSource.java
Patch:
@@ -22,7 +22,7 @@ public PubSubTestConfigSource() {
         pubsubTest.put("debezium.source." + StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG,
                 OFFSET_STORE_PATH.toAbsolutePath().toString());
         pubsubTest.put("debezium.source.offset.flush.interval.ms", "0");
-        pubsubTest.put("debezium.source.database.server.name", "testc");
+        pubsubTest.put("debezium.source.topic.prefix", "testc");
         pubsubTest.put("debezium.source.schema.include.list", "inventory");
         pubsubTest.put("debezium.source.table.include.list", "inventory.customers");
 

File: debezium-server/debezium-server-pulsar/src/test/java/io/debezium/server/pulsar/PulsarTestConfigSource.java
Patch:
@@ -22,7 +22,7 @@ public PulsarTestConfigSource() {
         pulsarTest.put("debezium.source." + StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG,
                 OFFSET_STORE_PATH.toAbsolutePath().toString());
         pulsarTest.put("debezium.source.offset.flush.interval.ms", "0");
-        pulsarTest.put("debezium.source.database.server.name", "testc");
+        pulsarTest.put("debezium.source.topic.prefix", "testc");
         pulsarTest.put("debezium.source.schema.include.list", "inventory");
         pulsarTest.put("debezium.source.table.include.list", "inventory.customers,inventory.nokey");
 

File: debezium-server/debezium-server-redis/src/test/java/io/debezium/server/redis/RedisSSLTestResourceLifecycleManager.java
Patch:
@@ -49,7 +49,7 @@ public Map<String, String> start() {
         params.put("debezium.sink.redis.ssl.enabled", "true");
         params.put("debezium.source.connector.class", "io.debezium.connector.postgresql.PostgresConnector");
         params.put("debezium.source.offset.flush.interval.ms", "0");
-        params.put("debezium.source.database.server.name", "testc");
+        params.put("debezium.source.topic.prefix", "testc");
         params.put("debezium.source.schema.include.list", "inventory");
         params.put("debezium.source.table.include.list", "inventory.customers,inventory.redis_test,inventory.redis_test2");
 

File: debezium-server/debezium-server-redis/src/test/java/io/debezium/server/redis/RedisTestResourceLifecycleManager.java
Patch:
@@ -42,7 +42,7 @@ public Map<String, String> start() {
         params.put("debezium.sink.redis.address", RedisTestResourceLifecycleManager.getRedisContainerAddress());
         params.put("debezium.source.connector.class", "io.debezium.connector.postgresql.PostgresConnector");
         params.put("debezium.source.offset.flush.interval.ms", "0");
-        params.put("debezium.source.database.server.name", "testc");
+        params.put("debezium.source.topic.prefix", "testc");
         params.put("debezium.source.schema.include.list", "inventory");
         params.put("debezium.source.table.include.list", "inventory.customers,inventory.redis_test,inventory.redis_test2");
 

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/DebeziumContainer.java
Patch:
@@ -375,7 +375,7 @@ public void ensureConnectorConfigProperty(String connectorName, String propertyN
 
     public static ConnectorConfiguration getPostgresConnectorConfiguration(PostgreSQLContainer<?> postgresContainer, int id, String... options) {
         final ConnectorConfiguration config = ConnectorConfiguration.forJdbcContainer(postgresContainer)
-                .with("database.server.name", "dbserver" + id)
+                .with("topic.prefix", "dbserver" + id)
                 .with("slot.name", "debezium_" + id);
 
         if (options != null && options.length > 0) {

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/ApicurioRegistryTest.java
Patch:
@@ -158,7 +158,7 @@ public void shouldConvertToCloudEventWithDataAsAvro() throws Exception {
 
             // host, database, user etc. are obtained from the container
             final ConnectorConfiguration config = ConnectorConfiguration.forJdbcContainer(postgresContainer)
-                    .with("database.server.name", "dbserver" + id)
+                    .with("topic.prefix", "dbserver" + id)
                     .with("slot.name", "debezium_" + id)
                     .with("key.converter", "org.apache.kafka.connect.json.JsonConverter")
                     .with("value.converter", "io.debezium.converters.CloudEventsConverter")
@@ -231,7 +231,7 @@ private ConnectorConfiguration getConfiguration(int id, String converter, String
 
         // host, database, user etc. are obtained from the container
         final ConnectorConfiguration config = ConnectorConfiguration.forJdbcContainer(postgresContainer)
-                .with("database.server.name", "dbserver" + id)
+                .with("topic.prefix", "dbserver" + id)
                 .with("slot.name", "debezium_" + id)
                 .with("key.converter", converter)
                 .with("key.converter.apicurio.registry.url", apicurioUrl)

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/DebeziumContainerTest.java
Patch:
@@ -158,7 +158,7 @@ private List<ConsumerRecord<String, String>> drain(KafkaConsumer<String, String>
     private ConnectorConfiguration getConfiguration(int id) {
         // host, database, user etc. are obtained from the container
         return ConnectorConfiguration.forJdbcContainer(postgresContainer)
-                .with("database.server.name", "dbserver" + id)
+                .with("topic.prefix", "dbserver" + id)
                 .with("slot.name", "debezium_" + id);
     }
 

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorConfig.java
Patch:
@@ -32,6 +32,7 @@
 import io.debezium.connector.AbstractSourceInfo;
 import io.debezium.connector.SourceInfoStructMaker;
 import io.debezium.data.Envelope;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.schema.DefaultTopicNamingStrategy;
 import io.debezium.spi.schema.DataCollectionId;
 
@@ -551,7 +552,7 @@ public static ConfigDef configDef() {
     private final int cursorMaxAwaitTimeMs;
 
     public MongoDbConnectorConfig(Configuration config) {
-        super(config, config.getString(LOGICAL_NAME), DEFAULT_SNAPSHOT_FETCH_SIZE);
+        super(config, config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX), DEFAULT_SNAPSHOT_FETCH_SIZE);
 
         String snapshotModeValue = config.getString(MongoDbConnectorConfig.SNAPSHOT_MODE);
         this.snapshotMode = SnapshotMode.parse(snapshotModeValue, MongoDbConnectorConfig.SNAPSHOT_MODE.defaultValueAsString());

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -34,6 +34,7 @@
 import io.debezium.relational.Tables.TableFilter;
 import io.debezium.relational.history.DatabaseHistory;
 import io.debezium.relational.history.HistoryRecordComparator;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.schema.DefaultTopicNamingStrategy;
 import io.debezium.storage.kafka.history.KafkaDatabaseHistory;
 import io.debezium.storage.kafka.history.KafkaStorageConfiguration;
@@ -968,7 +969,7 @@ public MySqlConnectorConfig(Configuration config) {
         super(
                 MySqlConnector.class,
                 config,
-                config.getString(SERVER_NAME),
+                config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX),
                 TableFilter.fromPredicate(MySqlConnectorConfig::isNotBuiltInTable),
                 true,
                 DEFAULT_SNAPSHOT_FETCH_SIZE,

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -44,6 +44,7 @@
 import io.debezium.relational.TableId;
 import io.debezium.relational.Tables.TableFilter;
 import io.debezium.relational.history.HistoryRecordComparator;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.kafka.history.KafkaStorageConfiguration;
 import io.debezium.util.Strings;
 
@@ -578,7 +579,7 @@ public static ConfigDef configDef() {
     private final TransactionSnapshotBoundaryMode logMiningTransactionSnapshotBoundaryMode;
 
     public OracleConnectorConfig(Configuration config) {
-        super(OracleConnector.class, config, config.getString(SERVER_NAME), new SystemTablesPredicate(config),
+        super(OracleConnector.class, config, config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX), new SystemTablesPredicate(config),
                 x -> x.schema() + "." + x.table(), true, ColumnFilterMode.SCHEMA, false);
 
         this.databaseName = toUpperCase(config.getString(DATABASE_NAME));

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -42,6 +42,7 @@
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
 import io.debezium.relational.TableId;
 import io.debezium.relational.Tables.TableFilter;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.util.Strings;
 
 /**
@@ -851,7 +852,7 @@ public static AutoCreateMode parse(String value, String defaultValue) {
     public PostgresConnectorConfig(Configuration config) {
         super(
                 config,
-                config.getString(RelationalDatabaseConnectorConfig.SERVER_NAME),
+                config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX),
                 new SystemTablesPredicate(),
                 x -> x.schema() + "." + x.table(),
                 DEFAULT_SNAPSHOT_FETCH_SIZE,

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorConfig.java
Patch:
@@ -31,6 +31,7 @@
 import io.debezium.relational.TableId;
 import io.debezium.relational.Tables.TableFilter;
 import io.debezium.relational.history.HistoryRecordComparator;
+import io.debezium.schema.AbstractTopicNamingStrategy;
 import io.debezium.storage.kafka.history.KafkaStorageConfiguration;
 
 /**
@@ -337,7 +338,8 @@ public static ConfigDef configDef() {
     private final boolean optionRecompile;
 
     public SqlServerConnectorConfig(Configuration config) {
-        super(SqlServerConnector.class, config, config.getString(SERVER_NAME), new SystemTablesPredicate(), x -> x.schema() + "." + x.table(), true,
+        super(SqlServerConnector.class, config, config.getString(AbstractTopicNamingStrategy.TOPIC_PREFIX), new SystemTablesPredicate(),
+                x -> x.schema() + "." + x.table(), true,
                 ColumnFilterMode.SCHEMA, true);
 
         final String databaseNames = config.getString(DATABASE_NAMES.name());

File: debezium-core/src/main/java/io/debezium/config/Field.java
Patch:
@@ -1247,7 +1247,7 @@ public static int isPositiveInteger(Configuration config, Field field, Validatio
         }
         catch (Throwable e) {
         }
-        problems.accept(field, value, "A positive integer is expected");
+        problems.accept(field, value, "A positive, non-zero integer value is expected");
         return 1;
     }
 
@@ -1294,7 +1294,7 @@ public static int isPositiveLong(Configuration config, Field field, ValidationOu
         }
         catch (Throwable e) {
         }
-        problems.accept(field, value, "A positive long value is expected");
+        problems.accept(field, value, "A positive, non-zero long value is expected");
         return 1;
     }
 

File: debezium-server/debezium-server-redis/src/test/java/io/debezium/server/redis/RedisStreamMessageTestProfile.java
Patch:
@@ -15,7 +15,7 @@
 import io.debezium.util.Testing;
 import io.quarkus.test.junit.QuarkusTestProfile;
 
-public class RedisStreamCompactMessageTestProfile implements QuarkusTestProfile {
+public class RedisStreamMessageTestProfile implements QuarkusTestProfile {
 
     public static final String OFFSETS_FILE = "file-connector-offsets.txt";
     public static final Path OFFSET_STORE_PATH = Testing.Files.createTestingPath(OFFSETS_FILE).toAbsolutePath();
@@ -29,7 +29,7 @@ public List<TestResourceEntry> testResources() {
     public Map<String, String> getConfigOverrides() {
         Map<String, String> config = new HashMap<String, String>();
         config.put("debezium.source." + OFFSET_STORAGE_FILE_FILENAME_CONFIG, OFFSET_STORE_PATH.toAbsolutePath().toString());
-        config.put("debezium.sink.redis.message.format", "compact");
+        config.put("debezium.sink.redis.message.format", "extended");
         return config;
     }
 

File: debezium-server/debezium-server-redis/src/main/java/io/debezium/server/redis/RedisStreamChangeConsumer.java
Patch:
@@ -103,7 +103,7 @@ void connect() {
         connectionTimeout = config.getOptionalValue(PROP_CONNECTION_TIMEOUT, Integer.class).orElse(2000);
         socketTimeout = config.getOptionalValue(PROP_SOCKET_TIMEOUT, Integer.class).orElse(2000);
 
-        String messageFormat = config.getOptionalValue(PROP_MESSAGE_FORMAT, String.class).orElse(MESSAGE_FORMAT_EXTENDED);
+        String messageFormat = config.getOptionalValue(PROP_MESSAGE_FORMAT, String.class).orElse(MESSAGE_FORMAT_COMPACT);
         LOGGER.info("Property {}={}", PROP_MESSAGE_FORMAT, messageFormat);
         if (MESSAGE_FORMAT_EXTENDED.equals(messageFormat)) {
             recordMapFunction = (key, value) -> {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/CommitScn.java
Patch:
@@ -14,13 +14,13 @@
 import java.util.TreeMap;
 import java.util.stream.Collectors;
 
-import io.debezium.util.Strings;
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
 import org.apache.kafka.connect.data.Struct;
 
 import io.debezium.DebeziumException;
 import io.debezium.connector.oracle.logminer.events.LogMinerEventRow;
+import io.debezium.util.Strings;
 
 /**
  * Represents either a single or a collection of commit {@link Scn} positions that collectively

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleOffsetContextTest.java
Patch:
@@ -95,7 +95,7 @@ public void shouldCorrectlySerializeOffsetsWithSnapshotBasedKeysFromOlderOffsets
         // Write values out as Debezium 1.9
         Map<String, ?> writeValues = offsetContext.getOffset();
         assertThat(writeValues.get(SourceInfo.SCN_KEY)).isEqualTo("745688898023");
-        assertThat(writeValues.get(SourceInfo.COMMIT_SCN_KEY)).isEqualTo("745688898024::0:1");
+        assertThat(writeValues.get(SourceInfo.COMMIT_SCN_KEY)).isEqualTo("745688898024::0:1:");
         assertThat(writeValues.get(OracleOffsetContext.SNAPSHOT_PENDING_TRANSACTIONS_KEY)).isNull();
         assertThat(writeValues.get(OracleOffsetContext.SNAPSHOT_SCN_KEY)).isNull();
 
@@ -105,7 +105,7 @@ public void shouldCorrectlySerializeOffsetsWithSnapshotBasedKeysFromOlderOffsets
         // Write values out as Debezium 1.9
         writeValues = offsetContext.getOffset();
         assertThat(writeValues.get(SourceInfo.SCN_KEY)).isEqualTo("745688898023");
-        assertThat(writeValues.get(SourceInfo.COMMIT_SCN_KEY)).isEqualTo("745688898024::0:1");
+        assertThat(writeValues.get(SourceInfo.COMMIT_SCN_KEY)).isEqualTo("745688898024::0:1:");
         assertThat(writeValues.get(OracleOffsetContext.SNAPSHOT_PENDING_TRANSACTIONS_KEY)).isNull();
         assertThat(writeValues.get(OracleOffsetContext.SNAPSHOT_SCN_KEY)).isNull();
     }

File: debezium-core/src/main/java/io/debezium/util/Collect.java
Patch:
@@ -77,7 +77,7 @@ public static <T> Set<T> unmodifiableSet(Set<T> values, T... additionalValues) {
         return Collections.unmodifiableSet(newSet);
     }
 
-    @SuppressWarnings("unchecked")
+    @SafeVarargs
     public static <T> Set<T> unmodifiableSet(T... values) {
         return unmodifiableSet(arrayListOf(values));
     }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlUnsignedIntegerConverter.java
Patch:
@@ -71,7 +71,7 @@ public static int convertUnsignedSmallint(int originalNumber) {
 
     /**
      * Convert original value insertion of type 'MEDIUMINT' into the correct MEDIUMINT UNSIGNED representation
-     * Note: Unsigned MEDIUMINT (32-bit) is represented in 'Integer' 32-bit data type since the MAX value of Unsigned MEDIUMINT 16777215 < Max value of Integer 2147483647
+     * Note: Unsigned MEDIUMINT (24-bit) is represented in 'Integer' 32-bit data type since the MAX value of Unsigned MEDIUMINT 16777215 < Max value of Integer 2147483647
      *
      * @param originalNumber {@link Integer} the original insertion value
      * @return {@link Integer} the correct representation of the original insertion value
@@ -103,7 +103,7 @@ public static long convertUnsignedInteger(long originalNumber) {
 
     /**
      * Convert original value insertion of type 'BIGINT' into the correct BIGINT UNSIGNED representation
-     * Note: Unsigned BIGINT (16-bit) is represented in 'BigDecimal' data type. Reference: https://kafka.apache.org/0102/javadoc/org/apache/kafka/connect/data/Schema.Type.html
+     * Note: Unsigned BIGINT (64-bit) is represented in 'BigDecimal' data type. Reference: https://kafka.apache.org/0102/javadoc/org/apache/kafka/connect/data/Schema.Type.html
      *
      * @param originalNumber {@link BigDecimal} the original insertion value
      * @return {@link BigDecimal} the correct representation of the original insertion value

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDatabaseSchemaTest.java
Patch:
@@ -398,7 +398,7 @@ public void addCommentToSchemaTest() {
                 offset, Instant.now()).forEach(x -> mysql.applySchemaChange(x));
         mysql.close();
 
-        assertTableSchemaComments("captured.ct", "id", "");
+        assertTableSchemaComments("captured.ct", "id", null);
         assertTableSchemaComments("captured.ct", "code", "order code");
     }
 

File: debezium-core/src/main/java/io/debezium/pipeline/EventDispatcher.java
Patch:
@@ -248,12 +248,12 @@ public void changeRecord(P partition,
                 case WARN:
                     LOGGER.warn(
                             "Error while processing event at offset {}",
-                            changeRecordEmitter.getOffset().getOffset());
+                            changeRecordEmitter.getOffset().getOffset(), e);
                     break;
                 case SKIP:
                     LOGGER.debug(
                             "Error while processing event at offset {}",
-                            changeRecordEmitter.getOffset().getOffset());
+                            changeRecordEmitter.getOffset().getOffset(), e);
                     break;
             }
             return false;

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/IncrementalSnapshotCaseSensitiveIT.java
Patch:
@@ -38,6 +38,7 @@ public void before() throws Exception {
         connection = TestHelper.testConnection();
 
         TestHelper.dropTable(connection, "a");
+        TestHelper.dropTable(connection, "b");
         connection.execute("CREATE TABLE a (\"Pk\" numeric(9,0) primary key, aa numeric(9,0))");
         connection.execute("CREATE TABLE b (\"Pk\" numeric(9,0) primary key, aa numeric(9,0))");
 

File: debezium-embedded/src/test/java/io/debezium/pipeline/source/snapshot/incremental/AbstractIncrementalSnapshotTest.java
Patch:
@@ -887,7 +887,7 @@ public void testPauseDuringSnapshot() throws Exception {
     public void snapshotWithAdditionalCondition() throws Exception {
         // Testing.Print.enable();
 
-        int expectedCount = 10, expectedValue = Integer.MAX_VALUE;
+        int expectedCount = 10, expectedValue = 12345678;
         populateTable();
         populateTableWithSpecificValue(2000, expectedCount, expectedValue);
         final Configuration config = config().build();
@@ -928,7 +928,7 @@ public void shouldExecuteRegularSnapshotWhenAdditionalConditionEmpty() throws Ex
     public void snapshotWithAdditionalConditionWithRestart() throws Exception {
         // Testing.Print.enable();
 
-        int expectedCount = 1000, expectedValue = Integer.MAX_VALUE;
+        int expectedCount = 1000, expectedValue = 12345678;
         populateTable();
         populateTableWithSpecificValue(2000, expectedCount, expectedValue);
         final Configuration config = config().build();

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -996,6 +996,7 @@ public void shouldTruncate() throws Exception {
 
             final Configuration config = TestHelper.defaultConfig()
                     .with(OracleConnectorConfig.TABLE_INCLUDE_LIST, "DEBEZIUM.TRUNCATE_DDL")
+                    .with(OracleConnectorConfig.SKIPPED_OPERATIONS, "none") // do not skip truncates
                     .build();
 
             // Perform a basic startup & initial snapshot of data
@@ -1056,7 +1057,6 @@ public void shouldNotTruncateWhenSkipped() throws Exception {
 
             final Configuration config = TestHelper.defaultConfig()
                     .with(OracleConnectorConfig.TABLE_INCLUDE_LIST, "DEBEZIUM.TRUNCATE_DDL")
-                    .with(OracleConnectorConfig.SKIPPED_OPERATIONS, "t") // Filter out truncate operations.
                     .build();
 
             // Perform a basic startup & initial snapshot of data
@@ -3750,6 +3750,7 @@ public void shouldStreamTruncateEventWhenLobIsEnabled() throws Exception {
             Configuration config = TestHelper.defaultConfig()
                     .with(OracleConnectorConfig.TABLE_INCLUDE_LIST, "DEBEZIUM\\.DBZ4953")
                     .with(OracleConnectorConfig.LOB_ENABLED, true)
+                    .with(OracleConnectorConfig.SKIPPED_OPERATIONS, "none") // do not skip truncates
                     .build();
 
             start(OracleConnector.class, config);

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -469,9 +469,10 @@ public static SchemaNameAdjustmentMode parse(String value) {
             .withWidth(Width.SHORT)
             .withImportance(Importance.LOW)
             .withValidation(CommonConnectorConfig::validateSkippedOperation)
+            .withDefault("t")
             .withDescription(
                     "The comma-separated list of operations to skip during streaming, defined as: 'c' for inserts/create; 'u' for updates; 'd' for deletes, 't' for truncates, and 'none' to indicate nothing skipped. "
-                            + "By default, no operations will be skipped.");
+                            + "By default, only truncate operations will be skipped.");
 
     public static final Field BINARY_HANDLING_MODE = Field.create("binary.handling.mode")
             .withDisplayName("Binary Handling")

File: debezium-server/debezium-server-core/src/main/java/io/debezium/server/DebeziumServer.java
Patch:
@@ -68,6 +68,7 @@ public class DebeziumServer {
     private static final String PROP_TRANSFORMS_PREFIX = PROP_PREFIX + "transforms.";
     private static final String PROP_KEY_FORMAT_PREFIX = PROP_FORMAT_PREFIX + "key.";
     private static final String PROP_VALUE_FORMAT_PREFIX = PROP_FORMAT_PREFIX + "value.";
+    private static final String PROP_OFFSET_STORAGE_PREFIX = "offset.storage.";
 
     private static final String PROP_TRANSFORMS = PROP_PREFIX + "transforms";
     private static final String PROP_SINK_TYPE = PROP_SINK_PREFIX + "type";
@@ -129,7 +130,7 @@ else if (beans.size() > 1) {
         configToProperties(config, props, PROP_KEY_FORMAT_PREFIX, "key.converter.", true);
         configToProperties(config, props, PROP_VALUE_FORMAT_PREFIX, "value.converter.", true);
         configToProperties(config, props, PROP_SINK_PREFIX + name + ".", DatabaseHistory.CONFIGURATION_FIELD_PREFIX_STRING + name + ".", false);
-        configToProperties(config, props, PROP_SINK_PREFIX + name + ".", "offset.storage." + name + ".", false);
+        configToProperties(config, props, PROP_SINK_PREFIX + name + ".", PROP_OFFSET_STORAGE_PREFIX + name + ".", false);
         final Optional<String> transforms = config.getOptionalValue(PROP_TRANSFORMS, String.class);
         if (transforms.isPresent()) {
             props.setProperty("transforms", transforms.get());

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlStreamingChangeEventSource.java
Patch:
@@ -53,9 +53,9 @@
 import com.github.shyiko.mysql.binlog.event.RotateEventData;
 import com.github.shyiko.mysql.binlog.event.RowsQueryEventData;
 import com.github.shyiko.mysql.binlog.event.TableMapEventData;
+import com.github.shyiko.mysql.binlog.event.TransactionPayloadEventData;
 import com.github.shyiko.mysql.binlog.event.UpdateRowsEventData;
 import com.github.shyiko.mysql.binlog.event.WriteRowsEventData;
-import com.github.shyiko.mysql.binlog.event.TransactionPayloadEventData;
 import com.github.shyiko.mysql.binlog.event.deserialization.EventDataDeserializationException;
 import com.github.shyiko.mysql.binlog.event.deserialization.EventDeserializer;
 import com.github.shyiko.mysql.binlog.event.deserialization.GtidEventDataDeserializer;

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/OpenShiftUtils.java
Patch:
@@ -253,9 +253,7 @@ public void waitForPods(String project, Map<String, String> labels) {
     }
 
     public static boolean isRunningFromOcp() {
-        return ConfigProperties.OCP_URL.isEmpty() ||
-                ConfigProperties.OCP_USERNAME.isEmpty() ||
-                ConfigProperties.OCP_PASSWORD.isEmpty();
+        return ConfigProperties.OCP_URL.isEmpty();
     }
 
     /**

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/AbstractOcpDatabaseController.java
Patch:
@@ -99,7 +99,7 @@ public int getDatabasePort() {
     @Override
     public String getPublicDatabaseHostname() {
         if (isRunningFromOcp()) {
-            LOGGER.info("Running from OCP, using local database hostname");
+            LOGGER.info("Running from OCP, using internal database hostname");
             return getDatabaseHostname();
         }
         awaitIngress();
@@ -110,7 +110,7 @@ public String getPublicDatabaseHostname() {
     @Override
     public int getPublicDatabasePort() {
         if (isRunningFromOcp()) {
-            LOGGER.info("Running from OCP, using local database port");
+            LOGGER.info("Running from OCP, using internal database port");
             return getDatabasePort();
         }
         awaitIngress();

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/AbstractOcpDatabaseDeployer.java
Patch:
@@ -139,7 +139,8 @@ public B withPullSecrets(String yamlPath) {
         }
 
         private boolean isLbService(String yamlPath) {
-            return yamlPath.contains("-lb.");
+            Service service = YAML.fromResource(yamlPath, Service.class);
+            return "LoadBalancer".equals(service.getSpec().getType());
         }
     }
 }

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/OcpKafkaConnectController.java
Patch:
@@ -18,8 +18,6 @@
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
-import io.debezium.testing.system.tools.ConfigProperties;
-import io.fabric8.kubernetes.api.model.Secret;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/OperatorController.java
Patch:
@@ -148,8 +148,6 @@ public Secret deployPullSecret(String yamlPath) {
     }
 
     public Secret loadExistingPullSecret(String secretName) {
-        LOGGER.info("~~~~~ Loading existing pull secret ~~~~~");
-
         this.pullSecret = ocp.secrets()
                 .inNamespace(project)
                 .withName(secretName)

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/databases/ocp/OcpDb2.java
Patch:
@@ -6,6 +6,7 @@
 package io.debezium.testing.system.fixtures.databases.ocp;
 
 import static io.debezium.testing.system.tools.ConfigProperties.OCP_PULL_SECRET_PATH;
+import static io.debezium.testing.system.tools.OpenShiftUtils.isRunningFromOcp;
 
 import org.junit.jupiter.api.extension.ExtensionContext;
 
@@ -30,11 +31,12 @@ public OcpDb2(ExtensionContext.Store store) {
     @Override
     protected SqlDatabaseController databaseController() throws Exception {
         Class.forName("com.ibm.db2.jcc.DB2Driver");
+        String[] services = isRunningFromOcp() ? new String[]{DB_SERVICE_PATH} : new String[]{DB_SERVICE_PATH, DB_SERVICE_PATH_LB};
         OcpDB2Deployer deployer = new OcpDB2Deployer.Builder()
                 .withOcpClient(ocp)
                 .withProject(ConfigProperties.OCP_PROJECT_DB2)
                 .withDeployment(DB_DEPLOYMENT_PATH)
-                .withServices(DB_SERVICE_PATH, DB_SERVICE_PATH_LB)
+                .withServices(services)
                 .withPullSecrets(OCP_PULL_SECRET_PATH.get())
                 .build();
         return deployer.deploy();

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/databases/ocp/OcpMySql.java
Patch:
@@ -30,9 +30,7 @@ public OcpMySql(ExtensionContext.Store store) {
     @Override
     protected SqlDatabaseController databaseController() throws Exception {
         Class.forName("com.mysql.cj.jdbc.Driver");
-//        String[] services = isRunningFromOcp() ? new String[]{DB_SERVICE_PATH} : new String[]{DB_SERVICE_PATH, DB_SERVICE_PATH_LB};
-        String[] services = new String[]{DB_SERVICE_PATH, DB_SERVICE_PATH_LB};
-
+        String[] services = isRunningFromOcp() ? new String[]{DB_SERVICE_PATH} : new String[]{DB_SERVICE_PATH, DB_SERVICE_PATH_LB};
         OcpMySqlDeployer deployer = new OcpMySqlDeployer.Deployer()
                 .withOcpClient(ocp)
                 .withProject(ConfigProperties.OCP_PROJECT_MYSQL)

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/ExtractNewDocumentStateTestIT.java
Patch:
@@ -1689,6 +1689,8 @@ public void testMatrixArrayAsDocumentType() throws InterruptedException, IOExcep
     @Test
     @FixFor("DBZ-5434")
     public void shouldSupportNestedArrays() throws InterruptedException {
+        waitForStreamingRunning();
+
         // Test insert
         primary().execute("insert", client -> {
             client.getDatabase(DB_NAME).getCollection(this.getCollectionName())

File: debezium-core/src/test/java/io/debezium/pipeline/source/snapshot/incremental/SignalBasedSnapshotChangeEventSourceTest.java
Patch:
@@ -96,7 +96,7 @@ AND NOT ((\"pk1\" > ?) OR (\"pk1\" = ? AND \"pk2\" > ?)
                         OR (\"pk1\" = ? AND \"pk2\" = ? AND \"pk3\" > ?))
                         ORDER BY \"pk1\", \"pk2\", \"pk3\"
                         LIMIT 1024
-                """.replace(System.getProperty("line.separator"), "").replace("        ", " ").trim());
+                """.replace("\n", "").replace("        ", " ").trim());
     }
 
     @Test

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/EventProcessingFailureHandlingIT.java
Patch:
@@ -89,7 +89,7 @@ public void warn() throws Exception {
 
         Awaitility.await()
                 .alias("Found warning message in logs")
-                .atMost(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS).until(() -> {
+                .atMost(TestHelper.waitTimeForLogEntries(), TimeUnit.SECONDS).until(() -> {
                     return logInterceptor.containsWarnMessage("Error while processing event at offset {");
                 });
     }
@@ -151,7 +151,7 @@ public void fail() throws Exception {
 
         Awaitility.await()
                 .alias("Found error message in logs")
-                .atMost(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS).until(() -> {
+                .atMost(TestHelper.waitTimeForLogEntries(), TimeUnit.SECONDS).until(() -> {
                     boolean foundErrorMessageInLogs = logInterceptor.containsStacktraceElement("Error while processing event at offset {");
                     return foundErrorMessageInLogs && !engine.isRunning();
                 });

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleSchemaMigrationIT.java
Patch:
@@ -1608,7 +1608,7 @@ private static void assertTableChangeColumn(Struct change, int index, String col
 
     private static void assertSourceTableInfo(SourceRecord record, String schema, String table) {
         final Struct source = ((Struct) record.value()).getStruct("source");
-        assertThat(source.get("db")).isEqualTo(TestHelper.DATABASE);
+        assertThat(source.get("db")).isEqualTo(TestHelper.getDatabaseName());
         assertThat(source.get("schema")).isEqualTo(schema);
         assertThat(source.get("table")).isEqualTo(table);
     }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresDefaultValueConverter.java
Patch:
@@ -8,6 +8,7 @@
 
 import java.math.BigDecimal;
 import java.math.RoundingMode;
+import java.time.ZoneOffset;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Optional;
@@ -171,7 +172,7 @@ private static Map<String, DefaultValueMapper> createDefaultValueMappers(Timesta
         result.put("date", (c, v) -> timestampUtils.toLocalDateTime(extractDefault(v, "1970-01-01")));
         result.put("time", (c, v) -> timestampUtils.toLocalTime(extractDefault(v, "00:00")));
         result.put("timestamp", (c, v) -> timestampUtils.toOffsetDateTime(extractDefault(v, "1970-01-01")));
-        result.put("timestamptz", (c, v) -> timestampUtils.toOffsetDateTime(extractDefault(v, "1970-01-01")));
+        result.put("timestamptz", (c, v) -> timestampUtils.toOffsetDateTime(extractDefault(v, "1970-01-01")).atZoneSameInstant(ZoneOffset.UTC));
         result.put("interval", (c, v) -> new PGInterval(extractDefault(v, "epoch")));
 
         // Register any existing enum types

File: debezium-microbenchmark-oracle/src/main/java/io/debezium/performance/connector/oracle/EndToEndPerf.java
Patch:
@@ -52,7 +52,7 @@
 import io.debezium.connector.oracle.OracleConnectorConfig.SnapshotMode;
 import io.debezium.embedded.EmbeddedEngine;
 import io.debezium.jdbc.JdbcConfiguration;
-import io.debezium.storage.file.history.FileDatabaseHistory
+import io.debezium.storage.file.history.FileDatabaseHistory;
 import io.debezium.util.IoUtil;
 
 /**

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresDefaultValueConverter.java
Patch:
@@ -44,6 +44,8 @@ public class PostgresDefaultValueConverter implements DefaultValueConverter {
 
     private static final Pattern LITERAL_DEFAULT_PATTERN = Pattern.compile("'(.*?)'");
     private static final Pattern FUNCTION_DEFAULT_PATTERN = Pattern.compile("^[(]?[A-Za-z0-9_.]+\\((?:.+(?:, ?.+)*)?\\)");
+    private static final Set<String> CURRENT_DATE_TIMES = Collect.unmodifiableSet("current_timestamp",
+            "current_time", "current_date", "localtime", "localtimestamp");
     private static final Set<String> TRIM_DATA_TYPES = Collect.unmodifiableSet("bit", "varbit", "bool", "numeric",
             "float4", "float8", "int2", "int4", "serial", "int8", "bigserial", "smallserial", "uuid", "date", "time",
             "timestamp", "timestamptz", "interval");
@@ -201,7 +203,7 @@ private static String extractDefault(String defaultValue) {
     // If the default value is generated by a function, map a placeholder value for the schema
     private static String extractDefault(String defaultValue, String generatedValuePlaceholder) {
         final Matcher functionMatcher = FUNCTION_DEFAULT_PATTERN.matcher(defaultValue);
-        if (functionMatcher.find()) {
+        if (functionMatcher.find() || CURRENT_DATE_TIMES.contains(defaultValue.toLowerCase())) {
             return generatedValuePlaceholder;
         }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleDatabaseSchema.java
Patch:
@@ -26,6 +26,7 @@
 import io.debezium.schema.SchemaChangeEvent;
 import io.debezium.schema.TopicSelector;
 import io.debezium.util.SchemaNameAdjuster;
+
 import oracle.jdbc.OracleTypes;
 
 /**

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerChangeRecordEmitter.java
Patch:
@@ -7,7 +7,6 @@
 
 import io.debezium.DebeziumException;
 import io.debezium.connector.oracle.BaseChangeRecordEmitter;
-
 import io.debezium.connector.oracle.OracleConnectorConfig;
 import io.debezium.connector.oracle.OracleDatabaseSchema;
 import io.debezium.connector.oracle.logminer.events.EventType;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/xstream/XStreamChangeRecordEmitter.java
Patch:
@@ -32,7 +32,7 @@ public XStreamChangeRecordEmitter(OracleConnectorConfig connectorConfig, Partiti
                                       Map<String, Object> oldChunkValues, Map<String, Object> newChunkValues,
                                       Table table, OracleDatabaseSchema schema, Clock clock) {
         super(connectorConfig, partition, offset, schema, table, clock, getColumnValues(table, lcr.getOldValues(), oldChunkValues),
-              getColumnValues(table, lcr.getNewValues(), newChunkValues));
+                getColumnValues(table, lcr.getNewValues(), newChunkValues));
         this.lcr = lcr;
     }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresDefaultValueConverter.java
Patch:
@@ -43,7 +43,7 @@ public class PostgresDefaultValueConverter implements DefaultValueConverter {
     private static Logger LOGGER = LoggerFactory.getLogger(PostgresDefaultValueConverter.class);
 
     private static final Pattern LITERAL_DEFAULT_PATTERN = Pattern.compile("'(.*?)'");
-    private static final Pattern FUNCTION_DEFAULT_PATTERN = Pattern.compile("^[(]?[A-Za-z0-9_]+\\((?:.+(?:, ?.+)*)?\\)");
+    private static final Pattern FUNCTION_DEFAULT_PATTERN = Pattern.compile("^[(]?[A-Za-z0-9_.]+\\((?:.+(?:, ?.+)*)?\\)");
     private static final Set<String> TRIM_DATA_TYPES = Collect.unmodifiableSet("bit", "varbit", "bool", "numeric",
             "float4", "float8", "int2", "int4", "serial", "int8", "bigserial", "smallserial", "uuid", "date", "time",
             "timestamp", "timestamptz", "interval");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerQueryBuilderTest.java
Patch:
@@ -52,7 +52,7 @@ public class LogMinerQueryBuilderTest {
     public TestRule skipRule = new SkipTestDependingOnAdapterNameRule();
 
     private static final String OPERATION_CODES_LOB_ENABLED = "(1,2,3,9,10,11,29)";
-    private static final String OPERATION_CODES_LOB_DISABLED = "(1,2,3)";
+    private static final String OPERATION_CODES_LOB_DISABLED = "(1,2,3,255)";
 
     private OracleDatabaseSchema schema;
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/spi/Snapshotter.java
Patch:
@@ -69,7 +69,7 @@ default boolean shouldStreamEventsStartingFromSnapshot() {
     /**
      * Return a new string that set up the transaction for snapshotting
      *
-     * @param newSlotInfo if a new slow was created for snapshotting, this contains information from
+     * @param newSlotInfo if a new slot was created for snapshotting, this contains information from
      *                    the `create_replication_slot` command
      */
     default String snapshotTransactionIsolationLevelStatement(SlotCreationResult newSlotInfo) {

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/IncrementalSnapshotCaseSensitiveIT.java
Patch:
@@ -152,7 +152,7 @@ protected Configuration.Builder mutableConfig(boolean signalTableOnly, boolean s
         }
         return TestHelper.defaultConfig()
                 .with(OracleConnectorConfig.SNAPSHOT_MODE, OracleConnectorConfig.SnapshotMode.INITIAL)
-                .with(OracleConnectorConfig.SIGNAL_DATA_COLLECTION, "ORCLPDB1.DEBEZIUM.DEBEZIUM_SIGNAL")
+                .with(OracleConnectorConfig.SIGNAL_DATA_COLLECTION, TestHelper.getDatabaseName() + ".DEBEZIUM.DEBEZIUM_SIGNAL")
                 .with(OracleConnectorConfig.TABLE_INCLUDE_LIST, tableIncludeList)
                 .with(DatabaseHistory.STORE_ONLY_CAPTURED_TABLES_DDL, storeOnlyCapturedDdl);
     }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/IncrementalSnapshotIT.java
Patch:
@@ -148,7 +148,7 @@ protected Configuration.Builder mutableConfig(boolean signalTableOnly, boolean s
         }
         return TestHelper.defaultConfig()
                 .with(OracleConnectorConfig.SNAPSHOT_MODE, OracleConnectorConfig.SnapshotMode.INITIAL)
-                .with(OracleConnectorConfig.SIGNAL_DATA_COLLECTION, "ORCLPDB1.DEBEZIUM.DEBEZIUM_SIGNAL")
+                .with(OracleConnectorConfig.SIGNAL_DATA_COLLECTION, TestHelper.getDatabaseName() + ".DEBEZIUM.DEBEZIUM_SIGNAL")
                 .with(OracleConnectorConfig.TABLE_INCLUDE_LIST, tableIncludeList)
                 .with(DatabaseHistory.STORE_ONLY_CAPTURED_TABLES_DDL, storeOnlyCapturedDdl);
     }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorConfig.java
Patch:
@@ -251,7 +251,7 @@ public boolean isFullUpdate() {
             .withImportance(Importance.MEDIUM)
             .withDefault(30_000L)
             .withValidation(Field::isPositiveInteger)
-            .withDescription("Interval for looking for new, removed, or changed replica sets, given in milliseconds.  Defaults to 30 seconds (30,000 ms).");
+            .withDescription("Interval for looking for new, removed, or changed replica sets, given in milliseconds. Defaults to 30 seconds (30,000 ms).");
 
     public static final Field SSL_ENABLED = Field.create("mongodb.ssl.enabled")
             .withDisplayName("Enable SSL connection to MongoDB")

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorConfig.java
Patch:
@@ -269,8 +269,8 @@ public static SnapshotIsolationMode parse(String value, String defaultValue) {
             .withGroup(Field.createGroupEntry(Field.Group.CONNECTOR_ADVANCED, 0))
             .withWidth(Width.SHORT)
             .withImportance(Importance.LOW)
-            .withDescription("Configures the criteria of the attached timestamp within the source record (ts_ms)." +
-                    "Options include:" +
+            .withDescription("Configures the criteria of the attached timestamp within the source record (ts_ms). " +
+                    "Options include: " +
                     "'" + SourceTimestampMode.COMMIT.getValue()
                     + "', (default) the source timestamp is set to the instant where the record was committed in the database.");
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerHelper.java
Patch:
@@ -61,7 +61,7 @@ public static List<LogFile> setLogFilesForMining(OracleConnection connection, Sc
         // Restrict max attempts to 0 or greater values (sanity-check)
         // the code will do at least 1 attempt and up to maxAttempts extra polls based on configuration
         final int maxAttempts = Math.max(maxRetries, 0);
-        final DelayStrategy retryStrategy = DelayStrategy.exponential(initialDelay.toMillis(), maxDelay.toMillis());
+        final DelayStrategy retryStrategy = DelayStrategy.exponential(initialDelay, maxDelay);
 
         // We perform a retry algorithm here as there is a race condition where Oracle may update the V$LOG table
         // but the V$ARCHIVED_LOG lags behind and a single-shot SQL query may return an inconsistent set of results

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSchemaChangeEventEmitter.java
Patch:
@@ -94,7 +94,7 @@ public void emitSchemaChangeEvent(Receiver receiver) throws InterruptedException
             }
         }
 
-        if (!ddlChanges.isEmpty() && filters.isIncluded(tableId)) {
+        if (!ddlChanges.isEmpty() && (filters.isIncluded(tableId) || !schema.storeOnlyCapturedTables())) {
             List<SchemaChangeEvent> changeEvents = new ArrayList<>();
             ddlChanges.getEventsByDatabase((String dbName, List<DdlParserListener.Event> events) -> {
                 events.forEach(event -> {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/ColumnDefinitionParserListener.java
Patch:
@@ -90,8 +90,8 @@ public void exitColumnDefinition(MySqlParser.ColumnDefinitionContext ctx) {
             tableEditor.addColumn(columnEditor.create());
             tableEditor.setPrimaryKeyNames(columnEditor.name());
         }
-        defaultValueListener.exitDefaultValue(false);
         parser.runIfNotNull(() -> {
+            defaultValueListener.exitDefaultValue(false);
             listeners.remove(defaultValueListener);
         }, tableEditor);
         super.exitColumnDefinition(ctx);

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/IncrementalSnapshotCaseSensitiveIT.java
Patch:
@@ -145,7 +145,7 @@ protected Configuration.Builder config() {
     protected Configuration.Builder mutableConfig(boolean signalTableOnly, boolean storeOnlyCapturedDdl) {
         final String tableIncludeList;
         if (signalTableOnly) {
-            tableIncludeList = "DEBEZIUM\\.DEBEZIUM_SIGNAL";
+            tableIncludeList = "DEBEZIUM\\.B,DEBEZIUM\\.DEBEZIUM_SIGNAL";
         }
         else {
             tableIncludeList = "DEBEZIUM\\.A,DEBEZIUM\\.B,DEBEZIUM\\.DEBEZIUM_SIGNAL";

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/util/TestHelper.java
Patch:
@@ -162,8 +162,7 @@ public static Configuration.Builder defaultConfig() {
         return builder.with(OracleConnectorConfig.SERVER_NAME, SERVER_NAME)
                 .with(OracleConnectorConfig.DATABASE_HISTORY, FileDatabaseHistory.class)
                 .with(FileDatabaseHistory.FILE_PATH, DB_HISTORY_PATH)
-                .with(OracleConnectorConfig.INCLUDE_SCHEMA_CHANGES, false)
-                .with(OracleConnectorConfig.LOG_MINING_QUERY_LOGS_FOR_SNAPSHOT_OFFSET, false);
+                .with(OracleConnectorConfig.INCLUDE_SCHEMA_CHANGES, false);
     }
 
     /**

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleDatabaseSchema.java
Patch:
@@ -83,7 +83,8 @@ public void applySchemaChange(SchemaChangeEvent schemaChange) {
             default:
         }
 
-        if (schemaChange.getTables().stream().map(Table::id).anyMatch(getTableFilter()::isIncluded)) {
+        if (!databaseHistory.storeOnlyCapturedTables() ||
+                schemaChange.getTables().stream().map(Table::id).anyMatch(getTableFilter()::isIncluded)) {
             LOGGER.debug("Recorded DDL statements for database '{}': {}", schemaChange.getDatabase(), schemaChange.getDdl());
             record(schemaChange, schemaChange.getTableChanges());
         }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/IncrementalSnapshotCaseSensitiveIT.java
Patch:
@@ -119,12 +119,12 @@ protected List<String> tableNames() {
 
     @Override
     protected String tableDataCollectionId() {
-        return "ORCLPDB1.DEBEZIUM.A";
+        return TestHelper.getDatabaseName() + ".DEBEZIUM.A";
     }
 
     @Override
     protected List<String> tableDataCollectionIds() {
-        return List.of("ORCLPDB1.DEBEZIUM.A", "ORCLPDB1.DEBEZIUM.B");
+        return List.of(TestHelper.getDatabaseName() + ".DEBEZIUM.A", TestHelper.getDatabaseName() + ".DEBEZIUM.B");
     }
 
     @Override
@@ -136,7 +136,7 @@ protected String signalTableName() {
     protected Configuration.Builder config() {
         return TestHelper.defaultConfig()
                 .with(OracleConnectorConfig.SNAPSHOT_MODE, OracleConnectorConfig.SnapshotMode.SCHEMA_ONLY)
-                .with(OracleConnectorConfig.SIGNAL_DATA_COLLECTION, "ORCLPDB1.DEBEZIUM.DEBEZIUM_SIGNAL")
+                .with(OracleConnectorConfig.SIGNAL_DATA_COLLECTION, TestHelper.getDatabaseName() + ".DEBEZIUM.DEBEZIUM_SIGNAL")
                 .with(OracleConnectorConfig.TABLE_INCLUDE_LIST, "DEBEZIUM\\.A,DEBEZIUM\\.B,DEBEZIUM\\.DEBEZIUM_SIGNAL")
                 .with(DatabaseHistory.STORE_ONLY_CAPTURED_TABLES_DDL, true);
     }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/IncrementalSnapshotIT.java
Patch:
@@ -120,12 +120,12 @@ protected List<String> tableNames() {
 
     @Override
     protected String tableDataCollectionId() {
-        return "ORCLPDB1.DEBEZIUM.A";
+        return TestHelper.getDatabaseName() + ".DEBEZIUM.A";
     }
 
     @Override
     protected List<String> tableDataCollectionIds() {
-        return List.of("ORCLPDB1.DEBEZIUM.A", "ORCLPDB1.DEBEZIUM.B");
+        return List.of(TestHelper.getDatabaseName() + ".DEBEZIUM.A", TestHelper.getDatabaseName() + ".DEBEZIUM.B");
     }
 
     @Override
@@ -137,7 +137,7 @@ protected String signalTableName() {
     protected Configuration.Builder config() {
         return TestHelper.defaultConfig()
                 .with(OracleConnectorConfig.SNAPSHOT_MODE, OracleConnectorConfig.SnapshotMode.SCHEMA_ONLY)
-                .with(OracleConnectorConfig.SIGNAL_DATA_COLLECTION, "ORCLPDB1.DEBEZIUM.DEBEZIUM_SIGNAL")
+                .with(OracleConnectorConfig.SIGNAL_DATA_COLLECTION, TestHelper.getDatabaseName() + ".DEBEZIUM.DEBEZIUM_SIGNAL")
                 .with(OracleConnectorConfig.TABLE_INCLUDE_LIST, "DEBEZIUM\\.A,DEBEZIUM\\.B,DEBEZIUM\\.DEBEZIUM_SIGNAL")
                 .with(DatabaseHistory.STORE_ONLY_CAPTURED_TABLES_DDL, true);
     }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleSchemaMigrationIT.java
Patch:
@@ -1122,16 +1122,17 @@ public void shouldParseSchemaChangeWithoutErrorOnFilteredTableWithRawDataType()
             assertNoRecordsToConsume();
 
             // Verify Oracle DDL parser ignores CREATE TABLE with RAW data types
+            final String ignoredTable = TestHelper.getDatabaseName() + ".DEBEZIUM.DBZ4037B";
             connection.execute("CREATE TABLE dbz4037b (id number(9,0), data raw(8), primary key(id))");
             Awaitility.await()
                     .atMost(TestHelper.defaultMessageConsumerPollTimeout(), TimeUnit.SECONDS)
-                    .until(() -> createTableinterceptor.containsMessage(getIgnoreCreateTable("ORCLPDB1.DEBEZIUM.DBZ4037B")));
+                    .until(() -> createTableinterceptor.containsMessage(getIgnoreCreateTable(ignoredTable)));
 
             // Verify Oracle DDL parser ignores ALTER TABLE with RAW data types
             connection.execute("ALTER TABLE dbz4037b ADD data2 raw(10)");
             Awaitility.await()
                     .atMost(TestHelper.defaultMessageConsumerPollTimeout(), TimeUnit.SECONDS)
-                    .until(() -> alterTableinterceptor.containsMessage(getIgnoreAlterTable("ORCLPDB1.DEBEZIUM.DBZ4037B")));
+                    .until(() -> alterTableinterceptor.containsMessage(getIgnoreAlterTable(ignoredTable)));
 
             // Capture a simple change on different table
             connection.execute("INSERT INTO dbz4037a (id,data) values (1, 'Test')");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/SignalsIT.java
Patch:
@@ -97,7 +97,7 @@ public void signalSchemaChange() throws Exception {
 
         Configuration config = TestHelper.defaultConfig()
                 .with(OracleConnectorConfig.TABLE_INCLUDE_LIST, "DEBEZIUM\\.CUSTOMER,DEBEZIUM\\.DEBEZIUM_SIGNAL")
-                .with(OracleConnectorConfig.SIGNAL_DATA_COLLECTION, "ORCLPDB1.DEBEZIUM.DEBEZIUM_SIGNAL")
+                .with(OracleConnectorConfig.SIGNAL_DATA_COLLECTION, TestHelper.getDatabaseName() + ".DEBEZIUM.DEBEZIUM_SIGNAL")
                 .with(OracleConnectorConfig.SNAPSHOT_MODE, SnapshotMode.SCHEMA_ONLY)
                 .with(OracleConnectorConfig.INCLUDE_SCHEMA_CHANGES, true)
                 .with(OracleConnectorConfig.LOG_MINING_STRATEGY, OracleConnectorConfig.LogMiningStrategy.ONLINE_CATALOG)

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/ColumnDefinitionParserListener.java
Patch:
@@ -227,7 +227,7 @@ else if (dataTypeContext instanceof MySqlParser.CollectionDataTypeContext) {
                 charsetName = collectionDataTypeContext.charsetName().getText();
             }
 
-            if (dataType.name().toUpperCase().equals("SET")) {
+            if (dataType.name().equalsIgnoreCase("SET")) {
                 // After DBZ-132, it will always be comma separated
                 int optionsSize = collectionDataTypeContext.collectionOptions().collectionOption().size();
                 columnEditor.length(Math.max(0, optionsSize * 2 - 1)); // number of options + number of commas

File: debezium-core/src/test/java/io/debezium/transforms/outbox/EventRouterTest.java
Patch:
@@ -409,7 +409,7 @@ public void canConfigureEveryTableField() {
         final EventRouter<SourceRecord> router = new EventRouter<>();
         final Map<String, String> config = new HashMap<>();
         config.put(EventRouterConfigDefinition.FIELD_EVENT_ID.name(), "event_id");
-        config.put(EventRouterConfigDefinition.FIELD_PAYLOAD_ID.name(), "payload_id");
+        config.put(EventRouterConfigDefinition.FIELD_EVENT_KEY.name(), "payload_id");
         config.put(EventRouterConfigDefinition.FIELD_EVENT_TYPE.name(), "event_type");
         config.put(EventRouterConfigDefinition.FIELD_PAYLOAD.name(), "payload_body");
         config.put(EventRouterConfigDefinition.ROUTE_BY_FIELD.name(), "payload_id");
@@ -454,7 +454,7 @@ public void canInfluenceTableColumnTypes() {
         final EventRouter<SourceRecord> router = new EventRouter<>();
         final Map<String, String> config = new HashMap<>();
         config.put(EventRouterConfigDefinition.FIELD_EVENT_ID.name(), "event_id");
-        config.put(EventRouterConfigDefinition.FIELD_PAYLOAD_ID.name(), "payload_id");
+        config.put(EventRouterConfigDefinition.FIELD_EVENT_KEY.name(), "payload_id");
         config.put(EventRouterConfigDefinition.FIELD_EVENT_TYPE.name(), "event_type");
         config.put(EventRouterConfigDefinition.FIELD_PAYLOAD.name(), "payload_body");
         config.put(EventRouterConfigDefinition.ROUTE_BY_FIELD.name(), "my_route_field");
@@ -667,7 +667,7 @@ public void canSetPartitionWithAdditionalFields() {
         final EventRouter<SourceRecord> router = new EventRouter<>();
         final Map<String, String> config = new HashMap<>();
         config.put(EventRouterConfigDefinition.FIELD_EVENT_ID.name(), "event_id");
-        config.put(EventRouterConfigDefinition.FIELD_PAYLOAD_ID.name(), "payload_id");
+        config.put(EventRouterConfigDefinition.FIELD_EVENT_KEY.name(), "payload_id");
         config.put(EventRouterConfigDefinition.FIELD_EVENT_TYPE.name(), "event_type");
         config.put(EventRouterConfigDefinition.FIELD_PAYLOAD.name(), "payload_body");
         config.put(EventRouterConfigDefinition.ROUTE_BY_FIELD.name(), "my_route_field");

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SourceTimestampModeTest.java
Patch:
@@ -22,7 +22,7 @@ public void shouldConfigureDefaultMode() {
     @Test
     @FixFor("DBZ-1988")
     public void shouldReturnOptionFromValidMode() {
-        assertThat(SourceTimestampMode.fromMode("processing")).isEqualTo(SourceTimestampMode.PROCESSING);
+        assertThat(SourceTimestampMode.fromMode("processing")).isEqualTo(SourceTimestampMode.COMMIT);
     }
 
     @Test

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSnapshotChangeEventSource.java
Patch:
@@ -31,6 +31,7 @@
 import com.mongodb.client.MongoCursor;
 import com.mongodb.client.MongoDatabase;
 
+import io.debezium.connector.SnapshotRecord;
 import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;
 import io.debezium.pipeline.ErrorHandler;
 import io.debezium.pipeline.EventDispatcher;
@@ -464,7 +465,7 @@ private void createDataEventsForCollection(ChangeEventSourceContext sourceContex
                         snapshotContext.lastRecordInCollection = !cursor.hasNext();
 
                         if (snapshotContext.lastCollection && snapshotContext.lastRecordInCollection) {
-                            snapshotContext.offset.markLastSnapshotRecord();
+                            snapshotContext.offset.markSnapshotRecord(SnapshotRecord.LAST);
                         }
 
                         dispatcher.dispatchSnapshotEvent(snapshotContext.partition, collectionId,
@@ -474,7 +475,7 @@ private void createDataEventsForCollection(ChangeEventSourceContext sourceContex
                 }
                 else if (snapshotContext.lastCollection) {
                     // if the last collection does not contain any records we still need to mark the last processed event as last one
-                    snapshotContext.offset.markLastSnapshotRecord();
+                    snapshotContext.offset.markSnapshotRecord(SnapshotRecord.LAST);
                 }
 
                 LOGGER.info("\t Finished snapshotting {} records for collection '{}'; total duration '{}'", docs, collectionId,

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PublicGeometryIT.java
Patch:
@@ -21,6 +21,7 @@
 import org.junit.rules.TestRule;
 
 import io.debezium.config.Configuration;
+import io.debezium.connector.SnapshotRecord;
 import io.debezium.connector.postgresql.PostgresConnectorConfig.SnapshotMode;
 import io.debezium.connector.postgresql.connection.PostgresConnection;
 import io.debezium.connector.postgresql.connection.ReplicationConnection;
@@ -103,7 +104,7 @@ private void assertInsert(String statement, Integer pk, List<SchemaAndValueField
         try {
             executeAndWait(statement);
             SourceRecord record = assertRecordInserted(expectedTopicName, pk != null ? PK_FIELD : null, pk);
-            assertRecordOffsetAndSnapshotSource(record, false, false);
+            assertRecordOffsetAndSnapshotSource(record, SnapshotRecord.FALSE);
             assertSourceInfo(record, "postgres", table.schema(), table.table());
             assertRecordSchemaAndValues(expectedSchemaAndValuesByColumn, record, Envelope.FieldName.AFTER);
         }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -60,6 +60,7 @@
 import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.CommonConnectorConfig.BinaryHandlingMode;
 import io.debezium.config.Configuration;
+import io.debezium.connector.SnapshotRecord;
 import io.debezium.connector.postgresql.PostgresConnectorConfig.IntervalHandlingMode;
 import io.debezium.connector.postgresql.PostgresConnectorConfig.SchemaRefreshMode;
 import io.debezium.connector.postgresql.PostgresConnectorConfig.SnapshotMode;
@@ -2923,7 +2924,7 @@ private void assertInsert(String statement, Integer pk, List<SchemaAndValueField
         try {
             executeAndWait(statement);
             SourceRecord record = assertRecordInserted(expectedTopicName, pk != null ? PK_FIELD : null, pk);
-            assertRecordOffsetAndSnapshotSource(record, false, false);
+            assertRecordOffsetAndSnapshotSource(record, SnapshotRecord.FALSE);
             assertSourceInfo(record, "postgres", table.schema(), table.table());
             assertRecordSchemaAndValues(expectedSchemaAndValuesByColumn, record, Envelope.FieldName.AFTER);
         }
@@ -2941,7 +2942,7 @@ private void assertDelete(String statement, Integer pk,
         try {
             executeAndWait(statement);
             SourceRecord record = assertRecordDeleted(expectedTopicName, pk != null ? PK_FIELD : null, pk);
-            assertRecordOffsetAndSnapshotSource(record, false, false);
+            assertRecordOffsetAndSnapshotSource(record, SnapshotRecord.FALSE);
             assertSourceInfo(record, "postgres", table.schema(), table.table());
             assertRecordSchemaAndValues(expectedSchemaAndValuesByColumn, record, Envelope.FieldName.BEFORE);
             assertRecordSchemaAndValues(null, record, Envelope.FieldName.AFTER);

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SnapshotIT.java
Patch:
@@ -155,7 +155,8 @@ public void takeSnapshotAndStartStreaming() throws Exception {
         // Ignore initial records
         final SourceRecords records = consumeRecordsByTopic(INITIAL_RECORDS_PER_TABLE);
         final List<SourceRecord> table1 = records.recordsForTopic("server1.dbo.table1");
-        table1.subList(0, INITIAL_RECORDS_PER_TABLE - 1).forEach(record -> {
+        assertThat(((Struct) table1.get(0).value()).getStruct("source").getString("snapshot")).isEqualTo("first");
+        table1.subList(1, INITIAL_RECORDS_PER_TABLE - 1).forEach(record -> {
             assertThat(((Struct) record.value()).getStruct("source").getString("snapshot")).isEqualTo("true");
         });
         assertThat(((Struct) table1.get(INITIAL_RECORDS_PER_TABLE - 1).value()).getStruct("source").getString("snapshot")).isEqualTo("last");

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleOffsetContext.java
Patch:
@@ -16,6 +16,7 @@
 import org.apache.kafka.connect.data.Struct;
 
 import io.debezium.connector.SnapshotRecord;
+import io.debezium.connector.common.BaseSourceInfo;
 import io.debezium.pipeline.source.snapshot.incremental.IncrementalSnapshotContext;
 import io.debezium.pipeline.txmetadata.TransactionContext;
 import io.debezium.relational.CommonOffsetContext;

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/connectors/Db2Connector.java
Patch:
@@ -26,7 +26,7 @@ public Db2Connector(ExtensionContext.Store store) {
 
     @Override
     public ConnectorConfigBuilder connectorConfig(String connectorName) {
-        return new ConnectorFactories(kafkaController).sqlserver(dbController, connectorName);
+        return new ConnectorFactories(kafkaController).db2(dbController, connectorName);
     }
 
 }

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/databases/ocp/OcpDb2.java
Patch:
@@ -17,13 +17,13 @@
 import fixture5.annotations.FixtureContext;
 
 @FixtureContext(requires = { OpenShiftClient.class }, provides = { SqlDatabaseController.class })
-public class OcpDb2Fixture extends OcpDatabaseFixture<SqlDatabaseController> {
+public class OcpDb2 extends OcpDatabaseFixture<SqlDatabaseController> {
 
     public static final String DB_DEPLOYMENT_PATH = "/database-resources/db2/deployment.yaml";
     public static final String DB_SERVICE_PATH_LB = "/database-resources/db2/service-lb.yaml";
     public static final String DB_SERVICE_PATH = "/database-resources/db2/service.yaml";
 
-    public OcpDb2Fixture(ExtensionContext.Store store) {
+    public OcpDb2(ExtensionContext.Store store) {
         super(SqlDatabaseController.class, store);
     }
 

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/Db2Tests.java
Patch:
@@ -6,8 +6,8 @@
 package io.debezium.testing.system.tests.db2;
 
 import static io.debezium.testing.system.assertions.KafkaAssertions.awaitAssert;
-import static io.debezium.testing.system.tools.ConfigProperties.DATABASE_MYSQL_PASSWORD;
-import static io.debezium.testing.system.tools.ConfigProperties.DATABASE_MYSQL_USERNAME;
+import static io.debezium.testing.system.tools.ConfigProperties.DATABASE_DB2_DBZ_PASSWORD;
+import static io.debezium.testing.system.tools.ConfigProperties.DATABASE_DB2_USERNAME;
 import static org.assertj.core.api.Assertions.assertThat;
 
 import java.sql.SQLException;
@@ -42,7 +42,7 @@ public void insertCustomer(
                                String firstName, String lastName,
                                String email)
             throws SQLException {
-        SqlDatabaseClient client = dbController.getDatabaseClient(DATABASE_MYSQL_USERNAME, DATABASE_MYSQL_PASSWORD);
+        SqlDatabaseClient client = dbController.getDatabaseClient(DATABASE_DB2_USERNAME, DATABASE_DB2_DBZ_PASSWORD);
         String sql = "INSERT INTO DB2INST1.CUSTOMERS(first_name,last_name,email) VALUES  ('" + firstName + "', '" + lastName + "', '" + email + "')";
         client.execute("inventory", sql);
     }

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/OcpAvroDb2ConnectorIT.java
Patch:
@@ -13,7 +13,7 @@
 import io.debezium.testing.system.assertions.KafkaAssertions;
 import io.debezium.testing.system.fixtures.OcpClient;
 import io.debezium.testing.system.fixtures.connectors.Db2Connector;
-import io.debezium.testing.system.fixtures.databases.ocp.OcpDb2Fixture;
+import io.debezium.testing.system.fixtures.databases.ocp.OcpDb2;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
 import io.debezium.testing.system.fixtures.registry.OcpApicurio;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
@@ -31,7 +31,7 @@
 @Fixture(OcpClient.class)
 @Fixture(OcpKafka.class)
 @Fixture(OcpApicurio.class)
-@Fixture(OcpDb2Fixture.class)
+@Fixture(OcpDb2.class)
 @Fixture(Db2Connector.class)
 @ExtendWith(FixtureExtension.class)
 public class OcpAvroDb2ConnectorIT extends Db2Tests {

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/OcpDb2ConnectorIT.java
Patch:
@@ -13,7 +13,7 @@
 import io.debezium.testing.system.assertions.KafkaAssertions;
 import io.debezium.testing.system.fixtures.OcpClient;
 import io.debezium.testing.system.fixtures.connectors.Db2Connector;
-import io.debezium.testing.system.fixtures.databases.ocp.OcpDb2Fixture;
+import io.debezium.testing.system.fixtures.databases.ocp.OcpDb2;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
@@ -28,7 +28,7 @@
 @Tag("openshift")
 @Fixture(OcpClient.class)
 @Fixture(OcpKafka.class)
-@Fixture(OcpDb2Fixture.class)
+@Fixture(OcpDb2.class)
 @Fixture(Db2Connector.class)
 @ExtendWith(FixtureExtension.class)
 public class OcpDb2ConnectorIT extends Db2Tests {

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/ConfigProperties.java
Patch:
@@ -57,7 +57,7 @@ private ConfigProperties() {
     public static final String STRIMZI_KC_IMAGE = System.getProperty("test.strimzi.kc.image");
 
     // Apicurio Registry configuration
-    public static final String APICURIO_CRD_VERSION = System.getProperty("test.apicurio.crd.version", "v1");
+    public static final String APICURIO_LOG_LEVEL = System.getProperty("test.apicurio.log.level", "INFO");
 
     // MySql Configuration
     public static final String DATABASE_MYSQL_USERNAME = System.getProperty("test.database.mysql.username", "mysqluser");

File: debezium-core/src/main/java/io/debezium/transforms/outbox/EventRouterConfigDefinition.java
Patch:
@@ -65,7 +65,8 @@ public static InvalidOperationBehavior parse(String value) {
 
     public enum AdditionalFieldPlacement implements EnumeratedValue {
         HEADER("header"),
-        ENVELOPE("envelope");
+        ENVELOPE("envelope"),
+        PARTITION("partition");
 
         private final String value;
 
@@ -188,7 +189,7 @@ public String getAlias() {
             .withImportance(ConfigDef.Importance.HIGH)
             .withDescription("Extra fields can be added as part of the event envelope or a message header, format" +
                     " is a list of colon-delimited pairs or trios when you desire to have aliases," +
-                    " e.g. <code>id:header,field_name:envelope:alias</code> ");
+                    " e.g. <code>id:header,field_name:envelope:alias,field_name:partition</code> ");
 
     public static final Field FIELD_SCHEMA_VERSION = Field.create("table.field.event.schema.version")
             .withDisplayName("Event Schema Version Field")

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerQueryBuilder.java
Patch:
@@ -54,7 +54,7 @@ public class LogMinerQueryBuilder {
     public static String build(OracleConnectorConfig connectorConfig, OracleDatabaseSchema schema) {
         final StringBuilder query = new StringBuilder(1024);
         query.append("SELECT SCN, SQL_REDO, OPERATION_CODE, TIMESTAMP, XID, CSF, TABLE_NAME, SEG_OWNER, OPERATION, ");
-        query.append("USERNAME, ROW_ID, ROLLBACK, RS_ID, STATUS ");
+        query.append("USERNAME, ROW_ID, ROLLBACK, RS_ID, STATUS, INFO ");
         query.append("FROM ").append(LOGMNR_CONTENTS_VIEW).append(" ");
 
         // These bind parameters will be bound when the query is executed by the caller.

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -3784,8 +3784,6 @@ public void shouldStopWhenErrorProcessingFailureHandlingModeIsDefault() throws E
             start(OracleConnector.class, config);
             assertConnectorIsRunning();
 
-            waitForStreamingRunning(TestHelper.CONNECTOR_NAME, TestHelper.SERVER_NAME);
-
             // wait and confirm that the exception is thrown.
             Awaitility.await()
                     .atMost(60, TimeUnit.SECONDS)

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerQueryBuilderTest.java
Patch:
@@ -60,7 +60,7 @@ public class LogMinerQueryBuilderTest {
      * {@code database.history.store.only.captured.tables.ddl} is {@code false}.
      */
     private static final String LOG_MINER_CONTENT_QUERY_TEMPLATE1 = "SELECT SCN, SQL_REDO, OPERATION_CODE, TIMESTAMP, " +
-            "XID, CSF, TABLE_NAME, SEG_OWNER, OPERATION, USERNAME, ROW_ID, ROLLBACK, RS_ID, STATUS " +
+            "XID, CSF, TABLE_NAME, SEG_OWNER, OPERATION, USERNAME, ROW_ID, ROLLBACK, RS_ID, STATUS, INFO " +
             "FROM V$LOGMNR_CONTENTS WHERE SCN > ? AND SCN <= ? " +
             "${systemTablePredicate}" +
             "AND ((" +
@@ -81,7 +81,7 @@ public class LogMinerQueryBuilderTest {
      * {@code database.history.store.only.captured.tables.ddl} is {@code true}.
      */
     private static final String LOG_MINER_CONTENT_QUERY_TEMPLATE2 = "SELECT SCN, SQL_REDO, OPERATION_CODE, TIMESTAMP, " +
-            "XID, CSF, TABLE_NAME, SEG_OWNER, OPERATION, USERNAME, ROW_ID, ROLLBACK, RS_ID, STATUS " +
+            "XID, CSF, TABLE_NAME, SEG_OWNER, OPERATION, USERNAME, ROW_ID, ROLLBACK, RS_ID, STATUS, INFO " +
             "FROM V$LOGMNR_CONTENTS WHERE SCN > ? AND SCN <= ? " +
             "${systemTablePredicate}" +
             "AND ((" +

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/DockerRhelDb2ConnectorIT.java
Patch:
@@ -15,7 +15,6 @@
 import io.debezium.testing.system.fixtures.connectors.Db2Connector;
 import io.debezium.testing.system.fixtures.databases.docker.DockerDb2;
 import io.debezium.testing.system.fixtures.kafka.DockerKafka;
-import io.debezium.testing.system.tests.mysql.MySqlTests;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -33,7 +32,7 @@
 @Fixture(DockerDb2.class)
 @Fixture(Db2Connector.class)
 @ExtendWith(FixtureExtension.class)
-public class DockerRhelDb2ConnectorIT extends MySqlTests {
+public class DockerRhelDb2ConnectorIT extends Db2Tests {
 
     public DockerRhelDb2ConnectorIT(KafkaController kafkaController,
                                     KafkaConnectController connectController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/oracle/DockerRhelOracleConnectorIT.java
Patch:
@@ -15,7 +15,6 @@
 import io.debezium.testing.system.fixtures.connectors.OracleConnector;
 import io.debezium.testing.system.fixtures.databases.docker.DockerOracle;
 import io.debezium.testing.system.fixtures.kafka.DockerKafka;
-import io.debezium.testing.system.tests.mysql.MySqlTests;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -33,7 +32,7 @@
 @Fixture(DockerOracle.class)
 @Fixture(OracleConnector.class)
 @ExtendWith(FixtureExtension.class)
-public class DockerRhelOracleConnectorIT extends MySqlTests {
+public class DockerRhelOracleConnectorIT extends OracleTests {
 
     public DockerRhelOracleConnectorIT(KafkaController kafkaController,
                                        KafkaConnectController connectController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/postgresql/DockerRhelPostgreSqlConnectorIT.java
Patch:
@@ -15,7 +15,6 @@
 import io.debezium.testing.system.fixtures.connectors.PostgreSqlConnector;
 import io.debezium.testing.system.fixtures.databases.docker.DockerPostgreSql;
 import io.debezium.testing.system.fixtures.kafka.DockerKafka;
-import io.debezium.testing.system.tests.mysql.MySqlTests;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -33,7 +32,7 @@
 @Fixture(DockerPostgreSql.class)
 @Fixture(PostgreSqlConnector.class)
 @ExtendWith(FixtureExtension.class)
-public class DockerRhelPostgreSqlConnectorIT extends MySqlTests {
+public class DockerRhelPostgreSqlConnectorIT extends PostgreSqlTests {
 
     public DockerRhelPostgreSqlConnectorIT(KafkaController kafkaController,
                                            KafkaConnectController connectController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/postgresql/OcpAvroPostgreSqlConnectorIT.java
Patch:
@@ -16,7 +16,6 @@
 import io.debezium.testing.system.fixtures.databases.ocp.OcpPostgreSql;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
 import io.debezium.testing.system.fixtures.registry.OcpApicurio;
-import io.debezium.testing.system.tests.mysql.MySqlTests;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -35,7 +34,7 @@
 @Fixture(OcpPostgreSql.class)
 @Fixture(PostgreSqlConnector.class)
 @ExtendWith(FixtureExtension.class)
-public class OcpAvroPostgreSqlConnectorIT extends MySqlTests {
+public class OcpAvroPostgreSqlConnectorIT extends PostgreSqlTests {
 
     public OcpAvroPostgreSqlConnectorIT(KafkaController kafkaController,
                                         KafkaConnectController connectController,

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/sqlserver/DockerRhelSqlServerConnectorIT.java
Patch:
@@ -15,7 +15,6 @@
 import io.debezium.testing.system.fixtures.connectors.SqlServerConnector;
 import io.debezium.testing.system.fixtures.databases.docker.DockerSqlServer;
 import io.debezium.testing.system.fixtures.kafka.DockerKafka;
-import io.debezium.testing.system.tests.mysql.MySqlTests;
 import io.debezium.testing.system.tools.kafka.ConnectorConfigBuilder;
 import io.debezium.testing.system.tools.kafka.KafkaConnectController;
 import io.debezium.testing.system.tools.kafka.KafkaController;
@@ -33,7 +32,7 @@
 @Fixture(DockerSqlServer.class)
 @Fixture(SqlServerConnector.class)
 @ExtendWith(FixtureExtension.class)
-public class DockerRhelSqlServerConnectorIT extends MySqlTests {
+public class DockerRhelSqlServerConnectorIT extends SqlServerTests {
 
     public DockerRhelSqlServerConnectorIT(KafkaController kafkaController,
                                           KafkaConnectController connectController,

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/ConfigProperties.java
Patch:
@@ -51,7 +51,7 @@ private ConfigProperties() {
     // Strimzi configuration
     public static final boolean STRIMZI_OPERATOR_CONNECTORS = booleanProperty("test.strimzi.operator.connectors", true);
     public static final String STRIMZI_CRD_VERSION = System.getProperty("test.strimzi.crd.version", "v1beta2");
-    public static final String STRIMZI_VERSION_KAFKA = System.getProperty("test.strimzi.version.kafka", "v1beta2");
+    public static final String STRIMZI_VERSION_KAFKA = System.getProperty("test.strimzi.version.kafka", "3.1.0");
     public static final boolean STRIMZI_KC_BUILD = booleanProperty("test.strimzi.kc.build", true);
     public static final String STRIMZI_KC_IMAGE = System.getProperty("test.strimzi.kc.image");
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -2522,7 +2522,7 @@ public void shouldStreamTimeArrayTypesAsKnownTypes() throws Exception {
     }
 
     @Test
-    @FixFor("DBZ-1680")
+    @FixFor({ "DBZ-1680", "DBZ-5038" })
     public void shouldStreamEnumsWhenIncludeUnknownDataTypesDisabled() throws Exception {
         // Specifically enable `column.propagate.source.type` here to validate later that the actual
         // type, length, and scale values are resolved correctly when paired with Enum types.
@@ -2549,6 +2549,7 @@ public void shouldStreamEnumsWhenIncludeUnknownDataTypesDisabled() throws Except
                         .parameter(TestHelper.TYPE_NAME_PARAMETER_KEY, "TEST_TYPE")
                         .parameter(TestHelper.TYPE_LENGTH_PARAMETER_KEY, String.valueOf(Integer.MAX_VALUE))
                         .parameter(TestHelper.TYPE_SCALE_PARAMETER_KEY, "0")
+                        .defaultValue("V1")
                         .build(), "V1"));
 
         assertRecordSchemaAndValues(expected, rec, Envelope.FieldName.AFTER);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresConnection.java
Patch:
@@ -102,7 +102,7 @@ public PostgresConnection(JdbcConfiguration config, PostgresValueConverterBuilde
             this.typeRegistry = new TypeRegistry(this);
 
             final PostgresValueConverter valueConverter = valueConverterBuilder.build(this.typeRegistry);
-            this.defaultValueConverter = new PostgresDefaultValueConverter(valueConverter, this.getTimestampUtils());
+            this.defaultValueConverter = new PostgresDefaultValueConverter(valueConverter, this.getTimestampUtils(), typeRegistry);
         }
     }
 
@@ -121,7 +121,7 @@ public PostgresConnection(PostgresConnectorConfig config, TypeRegistry typeRegis
         else {
             this.typeRegistry = typeRegistry;
             final PostgresValueConverter valueConverter = PostgresValueConverter.of(config, this.getDatabaseCharset(), typeRegistry);
-            this.defaultValueConverter = new PostgresDefaultValueConverter(valueConverter, this.getTimestampUtils());
+            this.defaultValueConverter = new PostgresDefaultValueConverter(valueConverter, this.getTimestampUtils(), typeRegistry);
         }
     }
 

File: debezium-core/src/main/java/io/debezium/metrics/Metrics.java
Patch:
@@ -83,6 +83,7 @@ public synchronized void register() {
             for (int attempt = 1; attempt <= REGISTRATION_RETRIES; attempt++) {
                 try {
                     mBeanServer.registerMBean(this, name);
+                    registered = true;
                     break;
                 }
                 catch (InstanceAlreadyExistsException e) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -206,7 +206,6 @@ private void createOrUpdatePublicationModeFilterted(String tableFilterString, St
             createOrUpdatePublicationStmt = isUpdate ? String.format("ALTER PUBLICATION %s SET TABLE %s;", publicationName, tableFilterString)
                     : String.format("CREATE PUBLICATION %s FOR TABLE %s;", publicationName, tableFilterString);
             LOGGER.info(isUpdate ? "Updating Publication with statement '{}'" : "Creating Publication with statement '{}'", createOrUpdatePublicationStmt);
-            // Publication doesn't exist, create it but restrict to the tableFilter.
             stmt.execute(createOrUpdatePublicationStmt);
         }
         catch (Exception e) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -210,7 +210,7 @@ private void createOrUpdatePublicationModeFilterted(String tableFilterString, St
             stmt.execute(createOrUpdatePublicationStmt);
         }
         catch (Exception e) {
-            throw new ConnectException(String.format("Unable to create filtered publication %s for %s", publicationName, tableFilterString),
+            throw new ConnectException(String.format("Unable to %s filtered publication %s for %s", isUpdate ? "update" : "create", publicationName, tableFilterString),
                     e);
         }
     }

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/kafka/OcpKafka.java
Patch:
@@ -5,7 +5,9 @@
  */
 package io.debezium.testing.system.fixtures.kafka;
 
-import static io.debezium.testing.system.tools.ConfigProperties.*;
+import static io.debezium.testing.system.tools.ConfigProperties.STRIMZI_KC_BUILD;
+import static io.debezium.testing.system.tools.ConfigProperties.STRIMZI_KC_IMAGE;
+import static io.debezium.testing.system.tools.ConfigProperties.STRIMZI_OPERATOR_CONNECTORS;
 
 import org.jetbrains.annotations.NotNull;
 import org.junit.jupiter.api.extension.ExtensionContext;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -129,7 +129,7 @@ public void shouldFailToValidateInvalidConfiguration() {
         assertNoConfigurationErrors(result, MySqlConnectorConfig.PORT);
         assertConfigurationErrors(result, MySqlConnectorConfig.USER, 1);
         assertConfigurationErrors(result, MySqlConnectorConfig.SERVER_NAME, 2);
-        assertNoConfigurationErrors(result, MySqlConnectorConfig.SERVER_ID);
+        assertConfigurationErrors(result, MySqlConnectorConfig.SERVER_ID);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.TABLES_IGNORE_BUILTIN);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.DATABASE_WHITELIST);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.DATABASE_INCLUDE_LIST);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnector.java
Patch:
@@ -84,7 +84,7 @@ protected void validateConnection(Map<String, ConfigValue> configValues, Configu
         final PostgresConnectorConfig postgresConfig = new PostgresConnectorConfig(config);
         final ConfigValue hostnameValue = configValues.get(RelationalDatabaseConnectorConfig.HOSTNAME.name());
         // Try to connect to the database ...
-        try (PostgresConnection connection = new PostgresConnection(postgresConfig.getJdbcConfig())) {
+        try (PostgresConnection connection = new PostgresConnection(postgresConfig.getJdbcConfig(), PostgresConnection.CONNECTION_VALIDATE_CONNECTION)) {
             try {
                 // Prepare connection without initial statement execution
                 connection.connection(false);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -125,15 +125,15 @@ private PostgresReplicationConnection(PostgresConnectorConfig config,
     private static JdbcConfiguration addDefaultSettings(JdbcConfiguration configuration) {
         // first copy the parent's default settings...
         // then set some additional replication specific settings
-        return JdbcConfiguration.adapt(PostgresConnection.addDefaultSettings(configuration)
+        return JdbcConfiguration.adapt(PostgresConnection.addDefaultSettings(configuration, PostgresConnection.CONNECTION_STREAMING)
                 .edit()
                 .with("replication", "database")
                 .with("preferQueryMode", "simple") // replication protocol only supports simple query mode
                 .build());
     }
 
     private ServerInfo.ReplicationSlot getSlotInfo() throws SQLException, InterruptedException {
-        try (PostgresConnection connection = new PostgresConnection(connectorConfig.getJdbcConfig())) {
+        try (PostgresConnection connection = new PostgresConnection(connectorConfig.getJdbcConfig(), PostgresConnection.CONNECTION_SLOT_INFO)) {
             return connection.readReplicationSlotInfo(slotName, plugin.getPostgresPluginName());
         }
     }
@@ -622,7 +622,7 @@ public synchronized void close(boolean dropSlot) {
         }
         if (dropSlotOnClose && dropSlot) {
             // we're dropping the replication slot via a regular - i.e. not a replication - connection
-            try (PostgresConnection connection = new PostgresConnection(connectorConfig.getJdbcConfig())) {
+            try (PostgresConnection connection = new PostgresConnection(connectorConfig.getJdbcConfig(), PostgresConnection.CONNECTION_DROP_SLOT)) {
                 connection.dropReplicationSlot(slotName);
             }
             catch (Throwable e) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgoutput/PgOutputMessageDecoder.java
Patch:
@@ -119,7 +119,7 @@ public static MessageType forType(char type) {
 
     public PgOutputMessageDecoder(MessageDecoderContext decoderContext) {
         this.decoderContext = decoderContext;
-        this.connection = new PostgresConnection(decoderContext.getConfig(), decoderContext.getSchema().getTypeRegistry());
+        this.connection = new PostgresConnection(decoderContext.getConfig(), decoderContext.getSchema().getTypeRegistry(), "Debezium pgoutput");
     }
 
     @Override

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -1376,6 +1376,7 @@ public void shouldReceiveHeartbeatAlsoWhenChangingNonWhitelistedTable() throws E
         catch (ConditionTimeoutException e) {
             fail("Failed to detect at least 2 LSN changes", e);
         }
+        Testing.print("Done");
     }
 
     @Test

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/connection/PostgresConnectionIT.java
Patch:
@@ -233,7 +233,7 @@ public void shouldSupportPG95RestartLsn() throws Exception {
 
     // "fake" a pg95 response by not returning confirmed_flushed_lsn
     private PostgresConnection buildPG95PGConn(String name) {
-        return new PostgresConnection(JdbcConfiguration.adapt(TestHelper.defaultJdbcConfig().edit().with("ApplicationName", name).build())) {
+        return new PostgresConnection(JdbcConfiguration.adapt(TestHelper.defaultJdbcConfig()), name) {
             @Override
             protected ServerInfo.ReplicationSlot queryForSlot(String slotName, String database, String pluginName,
                                                               ResultSetMapper<ServerInfo.ReplicationSlot> map)

File: debezium-server/debezium-server-pulsar/src/test/java/io/debezium/server/pulsar/PulsarIT.java
Patch:
@@ -100,7 +100,7 @@ public void testPulsar() throws Exception {
                 .with("password", dbPassword)
                 .with("dbname", dbName)
                 .build();
-        try (final PostgresConnection connection = new PostgresConnection(config)) {
+        try (final PostgresConnection connection = new PostgresConnection(config, "Debezium Pulsar Test")) {
             connection.execute(
                     "CREATE TABLE inventory.nokey (val INT);",
                     "INSERT INTO inventory.nokey VALUES (1)",

File: debezium-server/debezium-server-redis/src/test/java/io/debezium/server/redis/RedisOffsetIT.java
Patch:
@@ -51,7 +51,7 @@ private PostgresConnection getPostgresConnection() {
                 .with("dbname", PostgresTestResourceLifecycleManager.POSTGRES_DBNAME)
                 .with("hostname", PostgresTestResourceLifecycleManager.POSTGRES_HOST)
                 .with("port", PostgresTestResourceLifecycleManager.getContainer().getMappedPort(PostgresTestResourceLifecycleManager.POSTGRES_PORT))
-                .build());
+                .build(), "Debezium Redis Test");
     }
 
     @Test

File: debezium-server/debezium-server-redis/src/test/java/io/debezium/server/redis/RedisStreamIT.java
Patch:
@@ -44,7 +44,7 @@ private PostgresConnection getPostgresConnection() {
                 .with("dbname", PostgresTestResourceLifecycleManager.POSTGRES_DBNAME)
                 .with("hostname", PostgresTestResourceLifecycleManager.POSTGRES_HOST)
                 .with("port", PostgresTestResourceLifecycleManager.getContainer().getMappedPort(PostgresTestResourceLifecycleManager.POSTGRES_PORT))
-                .build());
+                .build(), "Debezium Redis Test");
     }
 
     private Long getStreamLength(Jedis jedis, String streamName, int expectedLength) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresErrorHandler.java
Patch:
@@ -28,7 +28,9 @@ public class PostgresErrorHandler extends ErrorHandler {
             "Database connection failed when reading from copy",
             "An I/O error occurred while sending to the backend",
             "ERROR: could not open relation with OID",
-            "This connection has been closed");
+            "This connection has been closed",
+            "terminating connection due to unexpected postmaster exit",
+            "terminating connection due to administrator command");
 
     public PostgresErrorHandler(PostgresConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {
         super(PostgresConnector.class, connectorConfig, queue);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDatabaseSchema.java
Patch:
@@ -80,7 +80,7 @@ public class MySqlDatabaseSchema extends HistorizedRelationalDatabaseSchema {
     private final DdlChanges ddlChanges;
     private final Map<Long, TableId> tableIdsByTableNumber = new ConcurrentHashMap<>();
     private final Map<Long, TableId> excludeTableIdsByTableNumber = new ConcurrentHashMap<>();
-    private boolean storageInitialiationExecuted = false;
+    private boolean storageInitializationExecuted = false;
     private final MySqlConnectorConfig connectorConfig;
 
     /**
@@ -395,11 +395,11 @@ public void clearTableMappings() {
     @Override
     public void initializeStorage() {
         super.initializeStorage();
-        storageInitialiationExecuted = true;
+        storageInitializationExecuted = true;
     }
 
     public boolean isStorageInitializationExecuted() {
-        return storageInitialiationExecuted;
+        return storageInitializationExecuted;
     }
 
     public boolean skipSchemaChangeEvent(SchemaChangeEvent event) {

File: debezium-server/debezium-server-pubsub/src/main/java/io/debezium/server/pubsub/PubSubLiteChangeConsumer.java
Patch:
@@ -18,6 +18,7 @@
 import javax.inject.Inject;
 import javax.inject.Named;
 
+import com.google.cloud.ServiceOptions;
 import org.eclipse.microprofile.config.Config;
 import org.eclipse.microprofile.config.ConfigProvider;
 import org.eclipse.microprofile.config.inject.ConfigProperty;
@@ -75,7 +76,7 @@ public static interface PublisherBuilder {
     @PostConstruct
     void connect() {
         final Config config = ConfigProvider.getConfig();
-        String projectId = config.getValue(PROP_PROJECT_ID, String.class);
+        String projectId = config.getOptionalValue(PROP_PROJECT_ID, String.class).orElse(ServiceOptions.getDefaultProjectId());
         String region = config.getValue(PROP_REGION, String.class);
 
         if (customPublisherBuilder.isResolvable()) {
@@ -109,7 +110,7 @@ void close() {
                 publisher.stopAsync().awaitTerminated();
             }
             catch (Exception e) {
-                LOGGER.warn("Exception while closing publisher: {}", e);
+                LOGGER.warn("Exception while closing publisher: " + e);
             }
         });
     }

File: debezium-server/debezium-server-pubsub/src/main/java/io/debezium/server/pubsub/PubSubLiteChangeConsumer.java
Patch:
@@ -147,7 +147,6 @@ else if (record.value() instanceof byte[]) {
             deliveries.add(publisher.publish(pubsubMessage.build()));
             committer.markProcessed(record);
         }
-        ;
         List<String> messageIds;
         try {
             messageIds = ApiFutures.allAsList(deliveries).get();

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/metadata/SqlServerConnectorMetadata.java
Patch:
@@ -16,7 +16,7 @@ public class SqlServerConnectorMetadata implements ConnectorMetadata {
 
     @Override
     public ConnectorDescriptor getConnectorDescriptor() {
-        return new ConnectorDescriptor("sqlserver", "Debezium SqlSever Connector", SqlServerConnector.class.getName(), Module.version());
+        return new ConnectorDescriptor("sqlserver", "Debezium SQLServer Connector", SqlServerConnector.class.getName(), Module.version());
     }
 
     @Override

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -3195,6 +3195,7 @@ public void shouldRestartAfterCapturedTableIsDroppedWhileConnectorDown() throws
 
     @Test
     @FixFor("DBZ-4852")
+    @SkipWhenAdapterNameIsNot(value = SkipWhenAdapterNameIsNot.AdapterName.LOGMINER, reason = "User-defined types not supported")
     public void shouldCaptureChangeForTableWithUnsupportedColumnType() throws Exception {
         TestHelper.dropTable(connection, "dbz4852");
         try {
@@ -3305,6 +3306,7 @@ public void shouldCaptureChangeForTableWithUnsupportedColumnTypeLong() throws Ex
 
     @Test
     @FixFor("DBZ-4907")
+    @SkipWhenAdapterNameIsNot(value = SkipWhenAdapterNameIsNot.AdapterName.LOGMINER, reason = "Only LogMiner performs flushes")
     public void shouldContinueToUpdateOffsetsEvenWhenTableIsNotChanged() throws Exception {
         TestHelper.dropTable(connection, "dbz4907");
         try {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -9,6 +9,7 @@
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
+import java.util.Optional;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;
@@ -1403,8 +1404,8 @@ public Duration getLogMiningMaxDelay() {
     /**
      * @return the maximum duration for a LogMiner session
      */
-    public Duration getLogMiningMaximumSession() {
-        return logMiningMaximumSession;
+    public Optional<Duration> getLogMiningMaximumSession() {
+        return logMiningMaximumSession.toMillis() == 0L ? Optional.empty() : Optional.of(logMiningMaximumSession);
     }
 
     @Override

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -49,6 +49,7 @@
 import org.junit.AfterClass;
 import org.junit.Before;
 import org.junit.BeforeClass;
+import org.junit.Ignore;
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.TestRule;
@@ -3520,6 +3521,7 @@ public void shouldRestartLogMiningSessionAfterMaxSessionElapses() throws Excepti
 
     @Test
     @FixFor("DBZ-4963")
+    @Ignore("Waits 60 seconds by default, so disabled by default")
     public void shouldNotRestartLogMiningSessionWithMaxSessionZero() throws Exception {
         TestHelper.dropTable(connection, "dbz4963");
         try {

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorConfig.java
Patch:
@@ -835,7 +835,8 @@ public Optional<String[]> parseSignallingMessage(Struct value) {
         for (Object fieldValue : fields.values()) {
             if (fieldValue instanceof Document) {
                 result[idx++] = ((Document) fieldValue).toJson();
-            } else {
+            }
+            else {
                 result[idx++] = fieldValue.toString();
             }
         }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/parser/SelectLobParser.java
Patch:
@@ -150,7 +150,7 @@ else if (c == ')' && !inSingleQuotes) {
             else if (c == '\'') {
                 // skip over double single quote
                 if (inSingleQuotes && lookAhead == '\'') {
-                    i += 2;
+                    i += 1;
                     continue;
                 }
                 if (inSingleQuotes) {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnection.java
Patch:
@@ -16,10 +16,11 @@
 import java.util.Map;
 import java.util.OptionalLong;
 
-import com.mysql.cj.CharsetMapping;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import com.mysql.cj.CharsetMapping;
+
 import io.debezium.DebeziumException;
 import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.CommonConnectorConfig.EventProcessingFailureHandlingMode;

File: debezium-server/debezium-server-redis/src/test/java/io/debezium/server/redis/RedisOffsetIT.java
Patch:
@@ -23,7 +23,6 @@
 import io.quarkus.test.common.QuarkusTestResource;
 import io.quarkus.test.junit.QuarkusIntegrationTest;
 import io.quarkus.test.junit.TestProfile;
-
 import redis.clients.jedis.HostAndPort;
 import redis.clients.jedis.Jedis;
 import redis.clients.jedis.StreamEntryID;
@@ -39,7 +38,6 @@
 @QuarkusTestResource(RedisTestResourceLifecycleManager.class)
 
 public class RedisOffsetIT {
-
     private static final int MESSAGE_COUNT = 4;
     private static final String STREAM_NAME = "testc.inventory.customers";
 
@@ -59,7 +57,6 @@ private PostgresConnection getPostgresConnection() {
     @FixFor("DBZ-4509")
     public void testRedisStream() throws Exception {
         jedis = new Jedis(HostAndPort.from(RedisTestResourceLifecycleManager.getRedisContainerAddress()));
-        Testing.Print.enable();
         final List<StreamEntry> entries = new ArrayList<>();
         Awaitility.await().atMost(Duration.ofSeconds(TestConfigSource.waitForSeconds())).until(() -> {
             final List<StreamEntry> response = jedis.xrange(STREAM_NAME, (StreamEntryID) null, (StreamEntryID) null, MESSAGE_COUNT);
@@ -80,6 +77,8 @@ public void testRedisStream() throws Exception {
     @Test
     @FixFor("DBZ-4509")
     public void testRedisConnectionRetry() throws Exception {
+        Testing.Print.enable();
+
         Jedis jedis = new Jedis(HostAndPort.from(RedisTestResourceLifecycleManager.getRedisContainerAddress()));
         // wait until the offsets are written for the first time
         Awaitility.await().atMost(Duration.ofSeconds(10)).until(() -> {

File: debezium-server/debezium-server-redis/src/test/java/io/debezium/server/redis/RedisSSLStreamIT.java
Patch:
@@ -59,7 +59,5 @@ public void testRedisStream() throws Exception {
         assertTrue(redisOffsets.size() > 0);
 
         jedis.close();
-
     }
-
 }

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/OcpKafkaConnectDeployer.java
Patch:
@@ -204,7 +204,7 @@ private void configurePullSecret(KafkaConnectBuilder kcBuilder, Build kcBuild) {
         KafkaConnectTemplateBuilder templateBuilder = new KafkaConnectTemplateBuilder(template);
 
         if (kcBuild == null) {
-            templateBuilder.withNewPod().addNewImagePullSecret(pullSecretName);
+            templateBuilder.withNewPod().addNewImagePullSecret(pullSecretName).endPod();
         }
         else {
             templateBuilder.withNewBuildConfig().withPullSecret(pullSecretName).endBuildConfig();

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mongodb/MongoTests.java
Patch:
@@ -75,7 +75,6 @@ public void shouldCreateKafkaTopics() {
                 prefix + ".inventory.customers",
                 prefix + ".inventory.orders",
                 prefix + ".inventory.products");
-        ;
     }
 
     @Test

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -626,9 +626,8 @@ private void checkDatabaseAndTableState(OracleConnection connection, String pdbN
                         LOGGER.warn("Database table '{}' no longer exists, supplemental log check skipped", tableId);
                     }
                     else if (!isTableAllColumnsSupplementalLoggingEnabled(connection, tableId)) {
-                        throw new DebeziumException("Supplemental logging not properly configured for table " + tableId + ". "
-                                + "Use: ALTER TABLE " + tableId.schema() + "." + tableId.table()
-                                + " ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS");
+                        LOGGER.warn("Database table '{}' not configured with supplemental logging \"(ALL) COLUMNS\"; " +
+                                "only explicitly changed columns will be captured", tableId);
                     }
                     final Table table = schema.tableFor(tableId);
                     if (table == null) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/SqlUtils.java
Patch:
@@ -57,7 +57,7 @@ static String currentRedoNameQuery() {
     }
 
     static String currentRedoLogSequenceQuery() {
-        return String.format("SELECT SEQUENCE# FROM %s WHERE STATUS = 'CURRENT'", LOG_VIEW);
+        return String.format("SELECT SEQUENCE# FROM %s WHERE STATUS = 'CURRENT' ORDER BY SEQUENCE#", LOG_VIEW);
     }
 
     static String databaseSupplementalLoggingAllCheckQuery() {

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/SqlUtilsTest.java
Patch:
@@ -75,7 +75,7 @@ public void testStatements() {
         assertThat(result).isEqualTo(expected);
 
         result = SqlUtils.currentRedoLogSequenceQuery();
-        expected = "SELECT SEQUENCE# FROM V$LOG WHERE STATUS = 'CURRENT'";
+        expected = "SELECT SEQUENCE# FROM V$LOG WHERE STATUS = 'CURRENT' ORDER BY SEQUENCE#";
         assertThat(result).isEqualTo(expected);
 
         result = SqlUtils.databaseSupplementalLoggingAllCheckQuery();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleDefaultValueConverter.java
Patch:
@@ -238,6 +238,9 @@ else if (value.toUpperCase().startsWith("TO_DATE")) {
     }
 
     private static String unquote(String value) {
+        if (value.startsWith("('") && value.endsWith("')")) {
+            return value.substring(2, value.length() - 2);
+        }
         return value.substring(1, value.length() - 1);
     }
 }

File: debezium-core/src/main/java/io/debezium/relational/history/DatabaseHistory.java
Patch:
@@ -88,7 +88,8 @@ public interface DatabaseHistory {
                             "DELETE FROM mysql.rds_monitor.*," +
                             "FLUSH RELAY LOGS.*," +
                             "flush relay logs.*," +
-                            "SAVEPOINT .*")
+                            "SAVEPOINT .*," +
+                            "^\\s*#.*")
             .withWidth(Width.LONG)
             .withImportance(Importance.LOW)
             .withDescription("A regular expression to filter out a subset of incoming DDL statements "

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlStreamingChangeEventSource.java
Patch:
@@ -685,7 +685,7 @@ else if (eventData instanceof DeleteRowsEventData) {
                     tableId = taskContext.getSchema().getExcludeTableId(((DeleteRowsEventData) eventData).getTableId());
                 }
             }
-            LOGGER.trace("Filtered data change event for {}", tableId);
+            LOGGER.trace("Filtered {} event for {}", event.getHeader().getEventType(), tableId);
             metrics.onFilteredEvent(partition, "source = " + tableId, operation);
             eventDispatcher.dispatchFilteredEvent(partition, offsetContext);
         }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/SqlUtilsTest.java
Patch:
@@ -98,7 +98,7 @@ public void testStatements() {
         expected = "SELECT MIN(F.MEMBER) AS FILE_NAME, L.FIRST_CHANGE# FIRST_CHANGE, L.NEXT_CHANGE# NEXT_CHANGE, L.ARCHIVED, " +
                 "L.STATUS, 'ONLINE' AS TYPE, L.SEQUENCE# AS SEQ, 'NO' AS DICT_START, 'NO' AS DICT_END FROM V$LOGFILE F, " +
                 "V$LOG L LEFT JOIN V$ARCHIVED_LOG A ON A.FIRST_CHANGE# = L.FIRST_CHANGE# AND A.NEXT_CHANGE# = L.NEXT_CHANGE# " +
-                "WHERE A.FIRST_CHANGE# IS NULL AND F.GROUP# = L.GROUP# GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, " +
+                "WHERE (A.STATUS <> 'A' OR A.FIRST_CHANGE# IS NULL) AND F.GROUP# = L.GROUP# GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, " +
                 "L.STATUS, L.ARCHIVED, L.SEQUENCE# UNION SELECT A.NAME AS FILE_NAME, A.FIRST_CHANGE# FIRST_CHANGE, " +
                 "A.NEXT_CHANGE# NEXT_CHANGE, 'YES', NULL, 'ARCHIVED', A.SEQUENCE# AS SEQ, A.DICTIONARY_BEGIN, " +
                 "A.DICTIONARY_END FROM V$ARCHIVED_LOG A WHERE A.NAME IS NOT NULL AND A.ARCHIVED = 'YES' AND A.STATUS = 'A' " +
@@ -110,7 +110,7 @@ public void testStatements() {
         expected = "SELECT MIN(F.MEMBER) AS FILE_NAME, L.FIRST_CHANGE# FIRST_CHANGE, L.NEXT_CHANGE# NEXT_CHANGE, L.ARCHIVED, " +
                 "L.STATUS, 'ONLINE' AS TYPE, L.SEQUENCE# AS SEQ, 'NO' AS DICT_START, 'NO' AS DICT_END FROM V$LOGFILE F, " +
                 "V$LOG L LEFT JOIN V$ARCHIVED_LOG A ON A.FIRST_CHANGE# = L.FIRST_CHANGE# AND A.NEXT_CHANGE# = L.NEXT_CHANGE# " +
-                "WHERE A.FIRST_CHANGE# IS NULL AND F.GROUP# = L.GROUP# GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, " +
+                "WHERE (A.STATUS <> 'A' OR A.FIRST_CHANGE# IS NULL) AND F.GROUP# = L.GROUP# GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, " +
                 "L.STATUS, L.ARCHIVED, L.SEQUENCE# UNION SELECT A.NAME AS FILE_NAME, A.FIRST_CHANGE# FIRST_CHANGE, " +
                 "A.NEXT_CHANGE# NEXT_CHANGE, 'YES', NULL, 'ARCHIVED', A.SEQUENCE# AS SEQ, A.DICTIONARY_BEGIN, " +
                 "A.DICTIONARY_END FROM V$ARCHIVED_LOG A WHERE A.NAME IS NOT NULL AND A.ARCHIVED = 'YES' AND A.STATUS = 'A' " +
@@ -130,7 +130,7 @@ public void testStatements() {
         expected = "SELECT MIN(F.MEMBER) AS FILE_NAME, L.FIRST_CHANGE# FIRST_CHANGE, L.NEXT_CHANGE# NEXT_CHANGE, L.ARCHIVED, " +
                 "L.STATUS, 'ONLINE' AS TYPE, L.SEQUENCE# AS SEQ, 'NO' AS DICT_START, 'NO' AS DICT_END FROM V$LOGFILE F, " +
                 "V$LOG L LEFT JOIN V$ARCHIVED_LOG A ON A.FIRST_CHANGE# = L.FIRST_CHANGE# AND A.NEXT_CHANGE# = L.NEXT_CHANGE# " +
-                "WHERE A.FIRST_CHANGE# IS NULL AND F.GROUP# = L.GROUP# GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, " +
+                "WHERE (A.STATUS <> 'A' OR A.FIRST_CHANGE# IS NULL) AND F.GROUP# = L.GROUP# GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, " +
                 "L.STATUS, L.ARCHIVED, L.SEQUENCE# UNION SELECT A.NAME AS FILE_NAME, A.FIRST_CHANGE# FIRST_CHANGE, " +
                 "A.NEXT_CHANGE# NEXT_CHANGE, 'YES', NULL, 'ARCHIVED', A.SEQUENCE# AS SEQ, A.DICTIONARY_BEGIN, " +
                 "A.DICTIONARY_END FROM V$ARCHIVED_LOG A WHERE A.NAME IS NOT NULL AND A.ARCHIVED = 'YES' AND A.STATUS = 'A' " +

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/SqlUtils.java
Patch:
@@ -108,7 +108,7 @@ public static String allMinableLogsQuery(Scn scn, Duration archiveLogRetention,
         // FROM V$LOGFILE F, V$LOG L
         // LEFT JOIN V$ARCHIVED_LOG A
         // ON A.FIRST_CHANGE# = L.FIRST_CHANGE# AND A.NEXT_CHANGE# = L.NEXT_CHANGE#
-        // WHERE A.FIRST_CHANGE# IS NULL
+        // WHERE (A.FIRST_CHANGE# IS NULL OR A.STATUS <> 'A')
         // AND F.GROUP# = L.GROUP#
         // GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, L.STATUS, L.ARCHIVED, L.SEQUENCE#
         //
@@ -149,7 +149,7 @@ public static String allMinableLogsQuery(Scn scn, Duration archiveLogRetention,
             sb.append("FROM ").append(LOGFILE_VIEW).append(" F, ").append(LOG_VIEW).append(" L ");
             sb.append("LEFT JOIN ").append(ARCHIVED_LOG_VIEW).append(" A ");
             sb.append("ON A.FIRST_CHANGE# = L.FIRST_CHANGE# AND A.NEXT_CHANGE# = L.NEXT_CHANGE# ");
-            sb.append("WHERE A.FIRST_CHANGE# IS NULL ");
+            sb.append("WHERE (A.STATUS <> 'A' OR A.FIRST_CHANGE# IS NULL) ");
             sb.append("AND F.GROUP# = L.GROUP# ");
             sb.append("GROUP BY F.GROUP#, L.FIRST_CHANGE#, L.NEXT_CHANGE#, L.STATUS, L.ARCHIVED, L.SEQUENCE# ");
             sb.append("UNION ");

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -359,6 +359,8 @@ protected void handleCommit(LogMinerEventRow row) throws InterruptedException {
         LOGGER.trace("Commit (smallest SCN {}) {}", smallestScn, row);
         LOGGER.trace("Transaction {} has {} events", transactionId, numEvents);
 
+        final long databaseOffsetSeconds = metrics.getDatabaseOffsetSeconds();
+
         final boolean skipExcludedUserName = isTransactionUserExcluded(transaction);
         BlockingConsumer<LogMinerEvent> delegate = new BlockingConsumer<LogMinerEvent>() {
             private int numEvents = getTransactionEventCount(transaction);
@@ -372,7 +374,7 @@ public void accept(LogMinerEvent event) throws InterruptedException {
                 }
 
                 offsetContext.setTransactionId(transactionId);
-                offsetContext.setSourceTime(event.getChangeTime());
+                offsetContext.setSourceTime(event.getChangeTime().minusSeconds(databaseOffsetSeconds));
                 offsetContext.setTableId(event.getTableId());
                 if (--numEvents == 0) {
                     // reached the last event update the commit scn in the offsets

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresDefaultValueConverter.java
Patch:
@@ -178,7 +178,7 @@ private static String extractDefault(String defaultValue) {
         // If the value does NOT contain a single quote it is assumed to be a raw value. Otherwise the value is
         // extracted from inside the single quotes.
         if (!defaultValue.contains("'")) {
-            return defaultValue;
+            return defaultValue.startsWith("NULL::") ? null : defaultValue;
         }
 
         final Matcher matcher = LITERAL_DEFAULT_PATTERN.matcher(defaultValue);

File: debezium-core/src/main/java/io/debezium/data/SchemaUtil.java
Patch:
@@ -148,6 +148,7 @@ else if (obj instanceof Schema) {
                     appendFirst("type", schema.type());
                 }
                 appendAdditional("optional", schema.isOptional());
+                appendAdditional("default", schema.defaultValue());
                 if (schema.doc() != null) {
                     appendAdditional("doc", schema.doc());
                 }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/AbstractLogMinerEventProcessor.java
Patch:
@@ -174,7 +174,7 @@ public Scn process(Scn startScn, Scn endScn) throws SQLException, InterruptedExc
 
         try (PreparedStatement statement = createQueryStatement()) {
             LOGGER.debug("Fetching results for SCN [{}, {}]", startScn, endScn);
-            statement.setFetchSize(getConfig().getMaxQueueSize());
+            statement.setFetchSize(getConfig().getLogMiningViewFetchSize());
             statement.setFetchDirection(ResultSet.FETCH_FORWARD);
             statement.setString(1, startScn.toString());
             statement.setString(2, endScn.toString());

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorConfig.java
Patch:
@@ -224,7 +224,7 @@ public boolean isFullUpdate() {
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.HIGH)
             .required()
-            .withDescription("Unique name that identifies the MongoDB replica set or cluster and all recorded offsets, and"
+            .withDescription("Unique name that identifies the MongoDB replica set or cluster and all recorded offsets, and "
                     + "that is used as a prefix for all schemas and topics. "
                     + "Each distinct MongoDB installation should have a separate namespace and monitored by "
                     + "at most one Debezium connector.");

File: debezium-server/debezium-server-redis/src/test/java/io/debezium/server/redis/RedisTestConfigSource.java
Patch:
@@ -25,7 +25,7 @@ public RedisTestConfigSource() {
         redisTest.put("debezium.source.offset.flush.interval.ms", "0");
         redisTest.put("debezium.source.database.server.name", "testc");
         redisTest.put("debezium.source.schema.include.list", "inventory");
-        redisTest.put("debezium.source.table.include.list", "inventory.customers");
+        redisTest.put("debezium.source.table.include.list", "inventory.customers,inventory.redis_test,inventory.redis_test2");
 
         config = redisTest;
     }

File: debezium-schema-generator/src/main/java/io/debezium/schemagenerator/JsonSchemaCreatorService.java
Patch:
@@ -19,7 +19,7 @@
 
 import io.debezium.config.Field;
 import io.debezium.metadata.ConnectorMetadata;
-import io.debezium.schemagenerator.formats.ApiFormat.FieldFilter;
+import io.debezium.schemagenerator.schema.Schema.FieldFilter;
 import io.smallrye.openapi.api.models.media.SchemaImpl;
 
 public class JsonSchemaCreatorService {

File: debezium-schema-generator/src/main/java/io/debezium/schemagenerator/schema/SchemaDescriptor.java
Patch:
@@ -3,9 +3,9 @@
  *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
-package io.debezium.schemagenerator.formats;
+package io.debezium.schemagenerator.schema;
 
-public interface ApiFormatDescriptor {
+public interface SchemaDescriptor {
 
     String getId();
 

File: debezium-schema-generator/src/main/java/io/debezium/schemagenerator/schema/SchemaName.java
Patch:
@@ -3,12 +3,12 @@
  *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
-package io.debezium.schemagenerator.formats;
+package io.debezium.schemagenerator.schema;
 
 import java.lang.annotation.Retention;
 import java.lang.annotation.RetentionPolicy;
 
 @Retention(RetentionPolicy.RUNTIME)
-public @interface ApiFormatName {
+public @interface SchemaName {
     String value();
 }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -285,7 +285,7 @@ protected static void executeDDL(String ddlFile) throws Exception {
                 .stream()
                 .collect(Collectors.joining(System.lineSeparator()));
         try (PostgresConnection connection = create()) {
-            connection.executeWithoutCommitting(statements);
+            connection.execute(statements);
         }
     }
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlAntlrDdlParserTest.java
Patch:
@@ -875,7 +875,7 @@ public void shouldParseAlterTableMultiTableOptions() {
     }
 
     @Test
-    @FixFor({ "DBZ-1150", "DBZ-4174" })
+    @FixFor({ "DBZ-1150", "DBZ-4174", "DBZ-4640" })
     public void shouldParseCheckTableKeywords() {
         String ddl = "CREATE TABLE my_table (\n" +
                 "  user_id varchar(64) NOT NULL,\n" +
@@ -890,6 +890,7 @@ public void shouldParseCheckTableKeywords() {
                 "  usa VARCHAR(100),\n" +
                 "  jis VARCHAR(100),\n" +
                 "  internal INT,\n" +
+                "  instant BIT,\n" +
                 "  UNIQUE KEY call_states_userid (user_id)\n" +
                 ") ENGINE=InnoDB DEFAULT CHARSET=utf8";
         parser.parse(ddl, tables);
@@ -902,6 +903,7 @@ public void shouldParseCheckTableKeywords() {
         assertThat(table.columnWithName("medium")).isNotNull();
         assertThat(table.columnWithName("extended")).isNotNull();
         assertThat(table.columnWithName("changed")).isNotNull();
+        assertThat(table.columnWithName("instant")).isNotNull();
     }
 
     @Test

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleValueConverters.java
Patch:
@@ -150,6 +150,8 @@ public SchemaBuilder schemaBuilder(Column column) {
                 return intervalHandlingMode == OracleConnectorConfig.IntervalHandlingMode.STRING ? Interval.builder() : MicroDuration.builder();
             case Types.STRUCT:
                 return SchemaBuilder.string();
+            case OracleTypes.ROWID:
+                return SchemaBuilder.string();
             default: {
                 SchemaBuilder builder = super.schemaBuilder(column);
                 logger.debug("JdbcValueConverters returned '{}' for column '{}'", builder != null ? builder.getClass().getName() : null, column.name());
@@ -204,6 +206,7 @@ public ValueConverter converter(Column column, Field fieldDefn) {
             case Types.NVARCHAR:
             case Types.STRUCT:
             case Types.CLOB:
+            case OracleTypes.ROWID:
                 return data -> convertString(column, fieldDefn, data);
             case Types.BLOB:
                 return data -> convertBinary(column, fieldDefn, data, binaryMode);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -2034,7 +2034,9 @@ public void shouldProcessTruncateMessages() throws Exception {
     @SkipWhenDatabaseVersion(check = EqualityCheck.LESS_THAN, major = 11, reason = "TRUNCATE events only supported in PG11+ PGOUTPUT Plugin")
     @SkipWhenDecoderPluginNameIsNot(value = SkipWhenDecoderPluginNameIsNot.DecoderPluginName.PGOUTPUT, reason = "Tests specifically that pgoutput handles TRUNCATE messages")
     public void shouldProcessTruncateMessagesWhenSkippedOperationsIsSuppliedWithoutTruncate() throws Exception {
-        startConnector(builder -> builder.with(PostgresConnectorConfig.SKIPPED_OPERATIONS, "u"));
+        startConnector(builder -> builder
+                .with(PostgresConnectorConfig.SKIPPED_OPERATIONS, "u")
+                .with(PostgresConnectorConfig.TRUNCATE_HANDLING_MODE, PostgresConnectorConfig.TruncateHandlingMode.INCLUDE));
         waitForStreamingToStart();
 
         consumer = testConsumer(1);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -2905,7 +2905,7 @@ private void validateFieldDef(Field expected) {
         assertThat(key.importance).isEqualTo(expected.importance());
         assertThat(key.documentation).isEqualTo(expected.description());
         assertThat(key.type).isEqualTo(expected.type());
-        assertThat(key.defaultValue).isEqualTo(expected.defaultValue());
+        assertThat(key.defaultValue).isEqualTo(ConfigDef.parseType(expected.name(), expected.defaultValue(), expected.type()));
         assertThat(key.dependents).isEqualTo(expected.dependents());
         assertThat(key.width).isNotNull();
         assertThat(key.group).isNotNull();

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorTask.java
Patch:
@@ -125,7 +125,7 @@ else if (!changeStreamBasedOffsets.isEmpty() && !taskContext.getCaptureMode().is
                     .loggingContextSupplier(() -> taskContext.configureLoggingContext(CONTEXT_NAME))
                     .build();
 
-            errorHandler = new MongoDbErrorHandler(connectorConfig.getLogicalName(), queue);
+            errorHandler = new MongoDbErrorHandler(connectorConfig, queue);
 
             final MongoDbEventMetadataProvider metadataProvider = new MongoDbEventMetadataProvider();
 

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbErrorHandler.java
Patch:
@@ -15,8 +15,8 @@
  */
 public class MongoDbErrorHandler extends ErrorHandler {
 
-    public MongoDbErrorHandler(String logicalName, ChangeEventQueue<?> queue) {
-        super(MongoDbConnector.class, logicalName, queue);
+    public MongoDbErrorHandler(MongoDbConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {
+        super(MongoDbConnector.class, connectorConfig, queue);
     }
 
     @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -133,7 +133,7 @@ public ChangeEventSourceCoordinator<MySqlPartition, MySqlOffsetContext> start(Co
                 .buffering()
                 .build();
 
-        errorHandler = new MySqlErrorHandler(connectorConfig.getLogicalName(), queue);
+        errorHandler = new MySqlErrorHandler(connectorConfig, queue);
 
         final MySqlEventMetadataProvider metadataProvider = new MySqlEventMetadataProvider();
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlErrorHandler.java
Patch:
@@ -22,8 +22,8 @@ public class MySqlErrorHandler extends ErrorHandler {
 
     private static final String SQL_CODE_TOO_MANY_CONNECTIONS = "08004";
 
-    public MySqlErrorHandler(String logicalName, ChangeEventQueue<?> queue) {
-        super(MySqlConnector.class, logicalName, queue);
+    public MySqlErrorHandler(MySqlConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {
+        super(MySqlConnector.class, connectorConfig, queue);
     }
 
     @Override

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorTask.java
Patch:
@@ -82,7 +82,7 @@ public ChangeEventSourceCoordinator<OraclePartition, OracleOffsetContext> start(
                 .loggingContextSupplier(() -> taskContext.configureLoggingContext(CONTEXT_NAME))
                 .build();
 
-        errorHandler = new OracleErrorHandler(connectorConfig.getLogicalName(), queue);
+        errorHandler = new OracleErrorHandler(connectorConfig, queue);
 
         final OracleEventMetadataProvider metadataProvider = new OracleEventMetadataProvider();
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleErrorHandler.java
Patch:
@@ -41,8 +41,8 @@ public class OracleErrorHandler extends ErrorHandler {
         retryOracleMessageContainsTexts.add("No more data to read from socket");
     }
 
-    public OracleErrorHandler(String logicalName, ChangeEventQueue<?> queue) {
-        super(OracleConnector.class, logicalName, queue);
+    public OracleErrorHandler(OracleConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {
+        super(OracleConnector.class, connectorConfig, queue);
     }
 
     @Override

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorTask.java
Patch:
@@ -163,7 +163,7 @@ public ChangeEventSourceCoordinator<PostgresPartition, PostgresOffsetContext> st
                     .loggingContextSupplier(() -> taskContext.configureLoggingContext(CONTEXT_NAME))
                     .build();
 
-            ErrorHandler errorHandler = new PostgresErrorHandler(connectorConfig.getLogicalName(), queue);
+            ErrorHandler errorHandler = new PostgresErrorHandler(connectorConfig, queue);
 
             final PostgresEventMetadataProvider metadataProvider = new PostgresEventMetadataProvider();
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresErrorHandler.java
Patch:
@@ -17,8 +17,8 @@
  */
 public class PostgresErrorHandler extends ErrorHandler {
 
-    public PostgresErrorHandler(String logicalName, ChangeEventQueue<?> queue) {
-        super(PostgresConnector.class, logicalName, queue);
+    public PostgresErrorHandler(PostgresConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {
+        super(PostgresConnector.class, connectorConfig, queue);
     }
 
     @Override

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorTask.java
Patch:
@@ -101,7 +101,7 @@ public ChangeEventSourceCoordinator<SqlServerPartition, SqlServerOffsetContext>
                 .loggingContextSupplier(() -> taskContext.configureLoggingContext(CONTEXT_NAME))
                 .build();
 
-        errorHandler = new SqlServerErrorHandler(connectorConfig.getLogicalName(), queue);
+        errorHandler = new SqlServerErrorHandler(connectorConfig, queue);
 
         final SqlServerEventMetadataProvider metadataProvider = new SqlServerEventMetadataProvider();
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerErrorHandler.java
Patch:
@@ -17,8 +17,8 @@
  */
 public class SqlServerErrorHandler extends ErrorHandler {
 
-    public SqlServerErrorHandler(String logicalName, ChangeEventQueue<?> queue) {
-        super(SqlServerConnector.class, logicalName, queue);
+    public SqlServerErrorHandler(SqlServerConnectorConfig connectorConfig, ChangeEventQueue<?> queue) {
+        super(SqlServerConnector.class, connectorConfig, queue);
     }
 
     @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnection.java
Patch:
@@ -75,7 +75,7 @@ public MySqlConnection(MySqlConnectionConfiguration connectionConfig, MysqlField
      * @param connectionConfig {@link MySqlConnectionConfiguration} instance, may not be null.
      */
     public MySqlConnection(MySqlConnectionConfiguration connectionConfig) {
-        this(connectionConfig, new MysqlTextProtocolFieldReader());
+        this(connectionConfig, new MysqlTextProtocolFieldReader(null));
     }
 
     @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/legacy/SnapshotReader.java
Patch:
@@ -95,7 +95,9 @@ public SnapshotReader(String name, MySqlTaskContext context) {
         recorder = this::recordRowAsRead;
         metrics = new SnapshotReaderMetrics(context, context.dbSchema(), changeEventQueueMetrics);
         this.useGlobalLock = useGlobalLock;
-        this.mysqlFieldReader = context.getConnectorConfig().useCursorFetch() ? new MysqlBinaryProtocolFieldReader() : new MysqlTextProtocolFieldReader();
+        this.mysqlFieldReader = context.getConnectorConfig().useCursorFetch()
+                ? new MysqlBinaryProtocolFieldReader(context.getConnectorConfig())
+                : new MysqlTextProtocolFieldReader(context.getConnectorConfig());
     }
 
     /**

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/LogMinerHelperIT.java
Patch:
@@ -51,6 +51,8 @@ public static void beforeSuperClass() throws SQLException {
 
         conn = TestHelper.defaultConnection();
         conn.resetSessionToCdb();
+
+        TestHelper.forceFlushOfRedoLogsToArchiveLogs();
     }
 
     @AfterClass

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/metrics/MongoDbSnapshotChangeEventSourceMetrics.java
Patch:
@@ -12,14 +12,14 @@
 import io.debezium.connector.common.CdcSourceTaskContext;
 import io.debezium.connector.mongodb.DisconnectEvent;
 import io.debezium.pipeline.ConnectorEvent;
-import io.debezium.pipeline.metrics.SnapshotChangeEventSourceMetrics;
+import io.debezium.pipeline.metrics.DefaultSnapshotChangeEventSourceMetrics;
 import io.debezium.pipeline.source.spi.EventMetadataProvider;
 
 /**
  * @author Chris Cranford
  */
 @ThreadSafe
-public class MongoDbSnapshotChangeEventSourceMetrics extends SnapshotChangeEventSourceMetrics implements MongoDbSnapshotChangeEventSourceMetricsMBean {
+public class MongoDbSnapshotChangeEventSourceMetrics extends DefaultSnapshotChangeEventSourceMetrics implements MongoDbSnapshotChangeEventSourceMetricsMBean {
 
     private AtomicLong numberOfDisconnects = new AtomicLong();
 

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/metrics/MongoDbStreamingChangeEventSourceMetrics.java
Patch:
@@ -13,14 +13,14 @@
 import io.debezium.connector.mongodb.DisconnectEvent;
 import io.debezium.connector.mongodb.PrimaryElectionEvent;
 import io.debezium.pipeline.ConnectorEvent;
-import io.debezium.pipeline.metrics.StreamingChangeEventSourceMetrics;
+import io.debezium.pipeline.metrics.DefaultStreamingChangeEventSourceMetrics;
 import io.debezium.pipeline.source.spi.EventMetadataProvider;
 
 /**
  * @author Chris Cranford
  */
 @ThreadSafe
-public class MongoDbStreamingChangeEventSourceMetrics extends StreamingChangeEventSourceMetrics implements MongoDbStreamingChangeEventSourceMetricsMBean {
+public class MongoDbStreamingChangeEventSourceMetrics extends DefaultStreamingChangeEventSourceMetrics implements MongoDbStreamingChangeEventSourceMetricsMBean {
 
     private AtomicLong numberOfPrimaryElections = new AtomicLong();
     private AtomicLong numberOfDisconnects = new AtomicLong();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlSnapshotChangeEventSourceMetrics.java
Patch:
@@ -8,14 +8,14 @@
 import java.util.concurrent.atomic.AtomicBoolean;
 
 import io.debezium.connector.base.ChangeEventQueueMetrics;
-import io.debezium.pipeline.metrics.SnapshotChangeEventSourceMetrics;
+import io.debezium.pipeline.metrics.DefaultSnapshotChangeEventSourceMetrics;
 import io.debezium.pipeline.source.spi.EventMetadataProvider;
 
 /**
  * @author Randall Hauch
  *
  */
-class MySqlSnapshotChangeEventSourceMetrics extends SnapshotChangeEventSourceMetrics implements MySqlSnapshotChangeEventSourceMetricsMXBean {
+class MySqlSnapshotChangeEventSourceMetrics extends DefaultSnapshotChangeEventSourceMetrics implements MySqlSnapshotChangeEventSourceMetricsMXBean {
 
     private final AtomicBoolean holdingGlobalLock = new AtomicBoolean();
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlStreamingChangeEventSourceMetrics.java
Patch:
@@ -14,14 +14,14 @@
 import com.github.shyiko.mysql.binlog.jmx.BinaryLogClientStatistics;
 
 import io.debezium.connector.base.ChangeEventQueueMetrics;
-import io.debezium.pipeline.metrics.StreamingChangeEventSourceMetrics;
+import io.debezium.pipeline.metrics.DefaultStreamingChangeEventSourceMetrics;
 import io.debezium.pipeline.source.spi.EventMetadataProvider;
 import io.debezium.util.Collect;
 
 /**
  * @author Randall Hauch
  */
-public class MySqlStreamingChangeEventSourceMetrics extends StreamingChangeEventSourceMetrics implements MySqlStreamingChangeEventSourceMetricsMXBean {
+public class MySqlStreamingChangeEventSourceMetrics extends DefaultStreamingChangeEventSourceMetrics implements MySqlStreamingChangeEventSourceMetricsMXBean {
 
     private final BinaryLogClient client;
     private final BinaryLogClientStatistics stats;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/legacy/SnapshotReaderMetrics.java
Patch:
@@ -8,13 +8,13 @@
 import java.util.concurrent.atomic.AtomicBoolean;
 
 import io.debezium.connector.base.ChangeEventQueueMetrics;
-import io.debezium.pipeline.metrics.SnapshotChangeEventSourceMetrics;
+import io.debezium.pipeline.metrics.DefaultSnapshotChangeEventSourceMetrics;
 
 /**
  * @author Randall Hauch
  *
  */
-class SnapshotReaderMetrics extends SnapshotChangeEventSourceMetrics implements SnapshotReaderMetricsMXBean {
+class SnapshotReaderMetrics extends DefaultSnapshotChangeEventSourceMetrics implements SnapshotReaderMetricsMXBean {
 
     private final AtomicBoolean holdingGlobalLock = new AtomicBoolean();
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleStreamingChangeEventSourceMetrics.java
Patch:
@@ -24,14 +24,14 @@
 import io.debezium.annotation.VisibleForTesting;
 import io.debezium.connector.base.ChangeEventQueueMetrics;
 import io.debezium.connector.common.CdcSourceTaskContext;
-import io.debezium.pipeline.metrics.StreamingChangeEventSourceMetrics;
+import io.debezium.pipeline.metrics.DefaultStreamingChangeEventSourceMetrics;
 import io.debezium.pipeline.source.spi.EventMetadataProvider;
 
 /**
  * The metrics implementation for Oracle connector streaming phase.
  */
 @ThreadSafe
-public class OracleStreamingChangeEventSourceMetrics extends StreamingChangeEventSourceMetrics implements OracleStreamingChangeEventSourceMetricsMXBean {
+public class OracleStreamingChangeEventSourceMetrics extends DefaultStreamingChangeEventSourceMetrics implements OracleStreamingChangeEventSourceMetricsMXBean {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(OracleStreamingChangeEventSourceMetrics.class);
 

File: debezium-core/src/main/java/io/debezium/pipeline/metrics/DefaultChangeEventSourceMetricsFactory.java
Patch:
@@ -18,13 +18,13 @@ public class DefaultChangeEventSourceMetricsFactory implements ChangeEventSource
     public <T extends CdcSourceTaskContext> SnapshotChangeEventSourceMetrics getSnapshotMetrics(T taskContext,
                                                                                                 ChangeEventQueueMetrics changeEventQueueMetrics,
                                                                                                 EventMetadataProvider eventMetadataProvider) {
-        return new SnapshotChangeEventSourceMetrics(taskContext, changeEventQueueMetrics, eventMetadataProvider);
+        return new DefaultSnapshotChangeEventSourceMetrics(taskContext, changeEventQueueMetrics, eventMetadataProvider);
     }
 
     @Override
     public <T extends CdcSourceTaskContext> StreamingChangeEventSourceMetrics getStreamingMetrics(T taskContext,
                                                                                                   ChangeEventQueueMetrics changeEventQueueMetrics,
                                                                                                   EventMetadataProvider eventMetadataProvider) {
-        return new StreamingChangeEventSourceMetrics(taskContext, changeEventQueueMetrics, eventMetadataProvider);
+        return new DefaultStreamingChangeEventSourceMetrics(taskContext, changeEventQueueMetrics, eventMetadataProvider);
     }
 }

File: debezium-core/src/main/java/io/debezium/pipeline/source/spi/SnapshotProgressListener.java
Patch:
@@ -9,7 +9,7 @@
 import io.debezium.schema.DataCollectionId;
 
 /**
- * A class invoked by {@link SnapshotChangeEventSource} whenever an important event or change of state happens.
+ * Invoked whenever an important event or change of state happens during the snapshot phase.
  *
  * @author Jiri Pechanec
  */

File: debezium-schema-generator/src/main/java/io/debezium/schemagenerator/maven/OpenApiGeneratorMojo.java
Patch:
@@ -42,10 +42,10 @@
 @Mojo(name = "generate-openapi-spec", defaultPhase = LifecyclePhase.PREPARE_PACKAGE)
 public class OpenApiGeneratorMojo extends AbstractMojo {
 
-    @Parameter(property = "openapi.generator.format")
+    @Parameter(defaultValue = "openapi", property = "openapi.generator.format")
     private String format;
 
-    @Parameter(defaultValue = "${project.build.outputDirectory}", required = true)
+    @Parameter(defaultValue = "${project.build.directory}/generated-sources", required = true)
     private File outputDirectory;
 
     /**

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -720,6 +720,6 @@ private boolean isStartScnInArchiveLogs(Scn startScn) throws SQLException {
 
     @Override
     public void commitOffset(Map<String, ?> offset) {
-        //do nothing
+        // nothing to do
     }
 }

File: debezium-quarkus-outbox/deployment/src/main/java/io/debezium/outbox/quarkus/deployment/DebeziumOutboxConfig.java
Patch:
@@ -201,10 +201,10 @@ public static class DebeziumOutboxConfigPayload {
         public Optional<String> converter;
 
         /**
-         * The column's explicit type definition class
+         * The column's type definition class
          */
         @ConfigItem
-        public Optional<String> explicitType;
+        public Optional<String> type;
     }
 
     @ConfigGroup

File: debezium-quarkus-outbox/deployment/src/main/java/io/debezium/outbox/quarkus/deployment/OutboxEventHbmWriter.java
Patch:
@@ -162,9 +162,9 @@ private static JaxbHbmBasicAttributeType createPayloadAttribute(DebeziumOutboxCo
         attribute.setName("payload");
         attribute.setNotNull(false);
 
-        if (config.payload.explicitType.isPresent()) {
-            LOGGER.infof("Using payload explicit type: %s", config.payload.explicitType.get());
-            attribute.setTypeAttribute(config.payload.explicitType.get());
+        if (config.payload.type.isPresent()) {
+            LOGGER.infof("Using payload type: %s", config.payload.type.get());
+            attribute.setTypeAttribute(config.payload.type.get());
         }
         else if (config.payload.converter.isPresent()) {
             LOGGER.infof("Using payload attribute converter: %s", config.payload.converter.get());

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorConfig.java
Patch:
@@ -521,9 +521,9 @@ public boolean isFullUpdate() {
             .withImportance(Importance.MEDIUM)
             .withDescription("The method used to capture changes from MongoDB server. "
                     + "Options include: "
-                    + "'oplog' to capture changes from oplog, this is the original method; "
-                    + "'change_streams' to capture via MongoDB Change Streams mechanism, update message do not contain full message; "
-                    + "'change_streams_update_full' (the default) to capture  via MongoDB Change Streams mechanism, update message contains full message");
+                    + "'oplog' to capture changes from the oplog; "
+                    + "'change_streams' to capture changes via MongoDB Change Streams, update events do not contain full documents; "
+                    + "'change_streams_update_full' (the default) to capture changes via MongoDB Change Streams, update events contain full documents");
 
     public static final Field CONNECT_TIMEOUT_MS = Field.create("mongodb.connect.timeout.ms")
             .withDisplayName("Connect Timeout MS")

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorIT.java
Patch:
@@ -8,6 +8,7 @@
 import static io.debezium.connector.mongodb.JsonSerialization.COMPACT_JSON_SETTINGS;
 import static java.time.format.DateTimeFormatter.ISO_OFFSET_DATE_TIME;
 import static org.fest.assertions.Assertions.assertThat;
+import static org.junit.Assert.assertThat;
 import static org.junit.Assert.fail;
 
 import java.io.IOException;
@@ -1469,7 +1470,6 @@ public void shouldGenerateRecordForInsertEvent() throws Exception {
 
     @Test
     public void shouldGenerateRecordForUpdateEvent() throws Exception {
-        Testing.Print.enable();
         config = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.COLLECTION_INCLUDE_LIST, "dbit.*")
                 .with(MongoDbConnectorConfig.LOGICAL_NAME, "mongo")

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/SkipForOplogTestRule.java
Patch:
@@ -12,7 +12,7 @@
 /**
  * JUnit rule that skips tests not intended for oplog capture mode.
  *
- * @author Horia Chiorean
+ * @author Jiri Pechanec
  */
 public class SkipForOplogTestRule implements TestRule {
 
@@ -30,4 +30,4 @@ public void evaluate() throws Throwable {
 
         return base;
     }
-}
\ No newline at end of file
+}

File: debezium-core/src/main/java/io/debezium/util/Strings.java
Patch:
@@ -748,9 +748,9 @@ public static Duration asDuration(String timeString) {
      * <dt>HHH</dt>
      * <dd>is the number of hours written in at least 2 digits (e.g., "03")</dd>
      * <dt>MM</dt>
-     * <dd>is the number of hours written in at least 2 digits (e.g., "05")</dd>
+     * <dd>is the number of minutes written in 2 digits (e.g., "05")</dd>
      * <dt>SS</dt>
-     * <dd>is the number of hours written in at least 2 digits (e.g., "09")</dd>
+     * <dd>is the number of seconds written in 2 digits (e.g., "09")</dd>
      * <dt>mmm</dt>
      * <dd>is the fractional part of seconds, written with 1-3 digits (any trailing zeros are dropped)</dd>
      * </dl>

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnection.java
Patch:
@@ -264,7 +264,7 @@ public void readSchemaForCapturedTables(Tables tables, String databaseCatalog, S
     @Override
     protected String resolveCatalogName(String catalogName) {
         final String pdbName = config().getString("pdb.name");
-        return !Strings.isNullOrEmpty(pdbName) ? pdbName : config().getString("dbname");
+        return (!Strings.isNullOrEmpty(pdbName) ? pdbName : config().getString("dbname")).toUpperCase();
     }
 
     @Override

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleDefaultValueConverter.java
Patch:
@@ -63,7 +63,7 @@ public Optional<Object> parseDefaultValue(Column column, String defaultValue) {
         }
 
         try {
-            Object rawDefaultValue = mapper.parse(column, defaultValue);
+            Object rawDefaultValue = mapper.parse(column, defaultValue != null ? defaultValue.trim() : defaultValue);
             Object convertedDefaultValue = convertDefaultValue(rawDefaultValue, column);
             if (convertedDefaultValue instanceof Struct) {
                 // Workaround for KAFKA-12694

File: debezium-core/src/test/java/io/debezium/data/VerifyRecord.java
Patch:
@@ -717,6 +717,7 @@ else if (ZonedTimestamp.SCHEMA_NAME.equals(schemaName)) {
      * @param record the record to validate; may not be null
      */
     public static void isValid(SourceRecord record) {
+        isValid(record, false);
     }
 
     /**

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/ConfigProperties.java
Patch:
@@ -25,7 +25,7 @@ private ConfigProperties() {
     public static final long WAIT_SCALE_FACTOR = longProperty("test.wait.scale", 1);
 
     // DockerConfiguration configuration
-    public static final String DOCKER_IMAGE_KAFKA_RHEL = System.getProperty("test.docker.image.rhel.kafka");
+    public static final String DOCKER_IMAGE_KAFKA_RHEL = System.getProperty("test.docker.image.kc");
     public static final String DOCKER_IMAGE_MYSQL = System.getProperty("test.docker.image.mysql", "quay.io/debezium/example-mysql:latest");
     public static final String DOCKER_IMAGE_POSTGRESQL = System.getProperty("test.docker.image.postgresql", "quay.io/debezium/example-postgres:latest");
     public static final String DOCKER_IMAGE_MONGO = System.getProperty("test.docker.image.mongo", "quay.io/debezium/example-mongodb:latest");

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/db2/OcpDB2Controller.java
Patch:
@@ -9,7 +9,6 @@
 import static io.debezium.testing.system.tools.ConfigProperties.DATABASE_DB2_DBZ_USERNAME;
 
 import java.sql.Connection;
-import java.sql.SQLException;
 import java.util.List;
 
 import org.slf4j.Logger;
@@ -39,10 +38,11 @@ public OcpDB2Controller(Deployment deployment, List<Service> services, OpenShift
     public void initialize() {
         LOGGER.info("Waiting until DB2 instance is ready");
         SqlDatabaseClient client = getDatabaseClient(DATABASE_DB2_DBZ_USERNAME, DATABASE_DB2_DBZ_PASSWORD);
-        try (Connection connection = client.connect()) {
+        try (Connection connection = client.connectWithRetries()) {
             LOGGER.info("Database connection established successfully!");
         }
-        catch (SQLException e) {
+        catch (Throwable e) {
+            LOGGER.error(e.getMessage());
             throw new RuntimeException(e);
         }
     }

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/oracle/OcpOracleConnectorIT.java
Patch:
@@ -18,7 +18,7 @@
 
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @Tag("acceptance")
-@Tag("oracle ")
+@Tag("oracle")
 @Tag("openshift")
 @TestInstance(TestInstance.Lifecycle.PER_CLASS)
 public class OcpOracleConnectorIT

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSnapshotChangeEventSource.java
Patch:
@@ -9,7 +9,6 @@
 import java.time.Duration;
 import java.util.List;
 import java.util.Optional;
-import java.util.OptionalLong;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -141,11 +140,11 @@ protected void determineSnapshotOffset(RelationalSnapshotContext<PostgresPartiti
 
     private void updateOffsetForSnapshot(PostgresOffsetContext offset) throws SQLException {
         final Lsn xlogStart = getTransactionStartLsn();
-        final OptionalLong txId = OptionalLong.of(jdbcConnection.currentTransactionId().longValue());
+        final long txId = jdbcConnection.currentTransactionId().longValue();
         LOGGER.info("Read xlogStart at '{}' from transaction '{}'", xlogStart, txId);
 
         // use the old xmin, as we don't want to update it if in xmin recovery
-        offset.updateWalPosition(xlogStart, offset.lastCompletelyProcessedLsn(), clock.currentTime(), txId, null, offset.xmin());
+        offset.updateWalPosition(xlogStart, offset.lastCompletelyProcessedLsn(), clock.currentTime(), txId, offset.xmin(), null);
     }
 
     protected void updateOffsetForPreSnapshotCatchUpStreaming(PostgresOffsetContext offset) throws SQLException {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/LogicalDecodingMessageMonitor.java
Patch:
@@ -43,7 +43,6 @@ public class LogicalDecodingMessageMonitor {
     public static final String DEBEZIUM_LOGICAL_DECODING_MESSAGE_KEY = "message";
     public static final String DEBEZIUM_LOGICAL_DECODING_MESSAGE_PREFIX_KEY = "prefix";
     public static final String DEBEZIUM_LOGICAL_DECODING_MESSAGE_CONTENT_KEY = "content";
-    public static final String DEBEZIUM_LOGICAL_DECODING_MESSAGE_TRANSACTIONAL_KEY = "transactional";
 
     private final BlockingConsumer<SourceRecord> sender;
     private final String topicName;
@@ -59,7 +58,6 @@ public LogicalDecodingMessageMonitor(PostgresConnectorConfig connectorConfig, Bl
         this.base64Encoder = Base64.getEncoder();
 
         this.blockSchema = SchemaBuilder.struct().optional()
-                .field(DEBEZIUM_LOGICAL_DECODING_MESSAGE_TRANSACTIONAL_KEY, Schema.BOOLEAN_SCHEMA)
                 .field(DEBEZIUM_LOGICAL_DECODING_MESSAGE_PREFIX_KEY, Schema.OPTIONAL_STRING_SCHEMA)
                 .field(DEBEZIUM_LOGICAL_DECODING_MESSAGE_CONTENT_KEY, binaryMode.getSchema().build())
                 .build();
@@ -76,7 +74,6 @@ public void logicalDecodingMessageEvent(Partition partition, OffsetContext offse
                                             LogicalDecodingMessage message)
             throws InterruptedException {
         final Struct logicalMsgStruct = new Struct(blockSchema);
-        logicalMsgStruct.put(DEBEZIUM_LOGICAL_DECODING_MESSAGE_TRANSACTIONAL_KEY, message.isTransactional());
         logicalMsgStruct.put(DEBEZIUM_LOGICAL_DECODING_MESSAGE_PREFIX_KEY, message.getPrefix());
         logicalMsgStruct.put(DEBEZIUM_LOGICAL_DECODING_MESSAGE_CONTENT_KEY, convertContent(message.getContent()));
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSnapshotChangeEventSource.java
Patch:
@@ -9,6 +9,7 @@
 import java.time.Duration;
 import java.util.List;
 import java.util.Optional;
+import java.util.OptionalLong;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -140,7 +141,7 @@ protected void determineSnapshotOffset(RelationalSnapshotContext<PostgresPartiti
 
     private void updateOffsetForSnapshot(PostgresOffsetContext offset) throws SQLException {
         final Lsn xlogStart = getTransactionStartLsn();
-        final long txId = jdbcConnection.currentTransactionId().longValue();
+        final OptionalLong txId = OptionalLong.of(jdbcConnection.currentTransactionId().longValue());
         LOGGER.info("Read xlogStart at '{}' from transaction '{}'", xlogStart, txId);
 
         // use the old xmin, as we don't want to update it if in xmin recovery

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresTaskContext.java
Patch:
@@ -111,7 +111,7 @@ protected ReplicationConnection createReplicationConnection(boolean doSnapshot)
                 .withPublicationAutocreateMode(config.publicationAutocreateMode())
                 .withPlugin(config.plugin())
                 .withTruncateHandlingMode(config.truncateHandlingMode())
-                .withLogicalDecodingMessageHandlingMode(config.logicalDecodingMessageHandlingMode())
+                .withLogicalDecodingMessageFilter(config.getMessageFilter())
                 .dropSlotOnClose(dropSlotOnStop)
                 .streamParams(config.streamParams())
                 .statusUpdateInterval(config.statusUpdateInterval())

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoReplicationMessage.java
Patch:
@@ -9,6 +9,7 @@
 import java.time.Instant;
 import java.util.List;
 import java.util.Optional;
+import java.util.OptionalLong;
 import java.util.stream.Collectors;
 import java.util.stream.IntStream;
 
@@ -67,8 +68,8 @@ public Instant getCommitTime() {
     }
 
     @Override
-    public long getTransactionId() {
-        return Integer.toUnsignedLong(rawMessage.getTransactionId());
+    public OptionalLong getTransactionId() {
+        return OptionalLong.of(Integer.toUnsignedLong(rawMessage.getTransactionId()));
     }
 
     @Override

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/StreamingWal2JsonMessageDecoder.java
Patch:
@@ -104,7 +104,7 @@ public class StreamingWal2JsonMessageDecoder extends AbstractMessageDecoder {
      */
     private byte[] currentChunk;
 
-    private long txId;
+    private Long txId;
 
     private Instant commitTime;
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresErrorHandler.java
Patch:
@@ -24,9 +24,10 @@ public PostgresErrorHandler(String logicalName, ChangeEventQueue<?> queue) {
     @Override
     protected boolean isRetriable(Throwable throwable) {
         if (throwable instanceof PSQLException
+                && throwable.getMessage() != null
                 && (throwable.getMessage().contains("Database connection failed when writing to copy")
-                        || throwable.getMessage().contains("Database connection failed when reading from copy"))
-                || throwable.getMessage().contains("FATAL: terminating connection due to administrator command")) {
+                        || throwable.getMessage().contains("Database connection failed when reading from copy")
+                        || throwable.getMessage().contains("FATAL: terminating connection due to administrator command"))) {
             return true;
         }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -570,7 +570,7 @@ private PGReplicationStream startPgReplicationStream(final Lsn lsn, Function<Cha
                 .getReplicationAPI()
                 .replicationStream()
                 .logical()
-                .withSlotName(slotName)
+                .withSlotName("\"" + slotName + "\"")
                 .withStartPosition(lsn.asLogSequenceNumber())
                 .withSlotOptions(streamParams);
         streamBuilder = configurator.apply(streamBuilder);

File: debezium-core/src/main/java/io/debezium/transforms/outbox/EventRouter.java
Patch:
@@ -5,8 +5,6 @@
  */
 package io.debezium.transforms.outbox;
 
-import static java.util.function.Function.identity;
-
 import java.util.Map;
 
 import org.apache.kafka.common.config.ConfigDef;
@@ -27,7 +25,7 @@ public class EventRouter<R extends ConnectRecord<R>> implements Transformation<R
 
     @Override
     public R apply(R r) {
-        return eventRouterDelegate.apply(r, identity());
+        return eventRouterDelegate.apply(r, rec -> rec);
     }
 
     @Override

File: debezium-core/src/test/java/io/debezium/transforms/outbox/EventRouterTest.java
Patch:
@@ -898,7 +898,7 @@ public void noTombstoneIfNotConfigured() {
     }
 
     @Test
-    public void canExpandJSONPayloadIfConfigured() {
+    public void canExpandJsonPayloadIfConfigured() {
         final EventRouter<SourceRecord> router = new EventRouter<>();
         final Map<String, String> config = new HashMap<>();
         config.put(

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -408,6 +408,7 @@ private static PostgresValueConverterBuilder getPostgresValueConverterBuilder(Po
                 config.hStoreHandlingMode(),
                 config.binaryHandlingMode(),
                 config.intervalHandlingMode(),
-                config.getUnavailableValuePlaceholder());
+                config.getUnavailableValuePlaceholder(),
+                config.moneyFractionDigits());
     }
 }

File: debezium-core/src/main/java/io/debezium/relational/history/AbstractDatabaseHistory.java
Patch:
@@ -45,7 +45,7 @@ public abstract class AbstractDatabaseHistory implements DatabaseHistory {
             .withDefault(false)
             .withWidth(Width.SHORT)
             .withImportance(Importance.LOW)
-            .withDescription("Prefer DDL for schema reovery in case logica schema is present")
+            .withDescription("Prefer DDL for schema recovery in case logical schema is present")
             .withInvisibleRecommender()
             .withNoValidation();
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorTask.java
Patch:
@@ -57,8 +57,10 @@ public ChangeEventSourceCoordinator<OraclePartition, OracleOffsetContext> start(
         validateRedoLogConfiguration();
 
         OracleValueConverters valueConverters = new OracleValueConverters(connectorConfig, jdbcConnection);
+        OracleDefaultValueConverter defaultValueConverter = new OracleDefaultValueConverter(valueConverters, jdbcConnection);
         TableNameCaseSensitivity tableNameCaseSensitivity = connectorConfig.getAdapter().getTableNameCaseSensitivity(jdbcConnection);
-        this.schema = new OracleDatabaseSchema(connectorConfig, valueConverters, schemaNameAdjuster, topicSelector, tableNameCaseSensitivity);
+        this.schema = new OracleDatabaseSchema(connectorConfig, valueConverters, defaultValueConverter, schemaNameAdjuster,
+                topicSelector, tableNameCaseSensitivity);
 
         Offsets<OraclePartition, OracleOffsetContext> previousOffsets = getPreviousOffsets(new OraclePartition.Provider(connectorConfig),
                 connectorConfig.getAdapter().getOffsetContextLoader());

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerQueryBuilderTest.java
Patch:
@@ -25,6 +25,7 @@
 import io.debezium.connector.oracle.OracleConnection;
 import io.debezium.connector.oracle.OracleConnectorConfig;
 import io.debezium.connector.oracle.OracleDatabaseSchema;
+import io.debezium.connector.oracle.OracleDefaultValueConverter;
 import io.debezium.connector.oracle.OracleTopicSelector;
 import io.debezium.connector.oracle.OracleValueConverters;
 import io.debezium.connector.oracle.StreamingAdapter.TableNameCaseSensitivity;
@@ -269,11 +270,12 @@ private String resolveLogMineryContentQueryFromTemplate(OracleConnectorConfig co
     private OracleDatabaseSchema createSchema(OracleConnectorConfig connectorConfig) {
         OracleConnection connection = Mockito.mock(OracleConnection.class);
         OracleValueConverters converters = new OracleValueConverters(connectorConfig, connection);
+        OracleDefaultValueConverter defaultValueConverter = new OracleDefaultValueConverter(converters, connection);
         TableNameCaseSensitivity tableNameSensitivity = connectorConfig.getAdapter().getTableNameCaseSensitivity(connection);
 
         TopicSelector<TableId> topicSelector = OracleTopicSelector.defaultSelector(connectorConfig);
         SchemaNameAdjuster schemaNameAdjuster = SchemaNameAdjuster.create();
 
-        return new OracleDatabaseSchema(connectorConfig, converters, schemaNameAdjuster, topicSelector, tableNameSensitivity);
+        return new OracleDatabaseSchema(connectorConfig, converters, defaultValueConverter, schemaNameAdjuster, topicSelector, tableNameSensitivity);
     }
 }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/processor/AbstractProcessorUnitTest.java
Patch:
@@ -29,6 +29,7 @@
 import io.debezium.connector.oracle.OracleConnection;
 import io.debezium.connector.oracle.OracleConnectorConfig;
 import io.debezium.connector.oracle.OracleDatabaseSchema;
+import io.debezium.connector.oracle.OracleDefaultValueConverter;
 import io.debezium.connector.oracle.OracleOffsetContext;
 import io.debezium.connector.oracle.OraclePartition;
 import io.debezium.connector.oracle.OracleStreamingChangeEventSourceMetrics;
@@ -255,10 +256,12 @@ private OracleDatabaseSchema createOracleDatabaseSchema() throws Exception {
         final TopicSelector<TableId> topicSelector = OracleTopicSelector.defaultSelector(connectorConfig);
         final SchemaNameAdjuster schemaNameAdjuster = SchemaNameAdjuster.create();
         final OracleValueConverters converters = new OracleValueConverters(connectorConfig, connection);
+        final OracleDefaultValueConverter defaultValueConverter = new OracleDefaultValueConverter(converters, connection);
         final TableNameCaseSensitivity sensitivity = connectorConfig.getAdapter().getTableNameCaseSensitivity(connection);
 
         final OracleDatabaseSchema schema = new OracleDatabaseSchema(connectorConfig,
                 converters,
+                defaultValueConverter,
                 schemaNameAdjuster,
                 topicSelector,
                 sensitivity);

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerErrorHandler.java
Patch:
@@ -32,6 +32,8 @@ protected boolean isRetriable(Throwable throwable) {
                         || throwable.getMessage().contains("Connection timed out (Write failed)")
                         || throwable.getMessage().contains("The connection has been closed.")
                         || throwable.getMessage().contains("The connection is closed.")
+                        || throwable.getMessage().contains("The login failed.")
+                        || throwable.getMessage().contains("Try the statement later.")
                         || throwable.getMessage().contains("Connection reset")
                         || throwable.getMessage().contains("SHUTDOWN is in progress")
                         || throwable.getMessage().contains("The server failed to resume the transaction")

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/legacy/BinlogReader.java
Patch:
@@ -19,7 +19,6 @@
 import java.security.cert.X509Certificate;
 import java.time.Duration;
 import java.time.Instant;
-import java.time.temporal.ChronoUnit;
 import java.util.BitSet;
 import java.util.EnumMap;
 import java.util.HashMap;
@@ -315,7 +314,7 @@ public Event nextEvent(ByteArrayInputStream inputStream) throws IOException {
 
         // Set up for JMX ...
         metrics = new BinlogReaderMetrics(client, context, name, changeEventQueueMetrics);
-        heartbeat = Heartbeat.create(configuration.getDuration(Heartbeat.HEARTBEAT_INTERVAL, ChronoUnit.MILLIS),
+        heartbeat = Heartbeat.create(context.getConnectorConfig().getHeartbeatInterval(),
                 context.topicSelector().getHeartbeatTopic(), context.getConnectorConfig().getLogicalName());
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/legacy/SnapshotReader.java
Patch:
@@ -10,7 +10,6 @@
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.time.Instant;
-import java.time.temporal.ChronoUnit;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Comparator;
@@ -737,7 +736,7 @@ protected void execute() {
                     source.completeSnapshot();
                     Heartbeat
                             .create(
-                                    configuration.getDuration(Heartbeat.HEARTBEAT_INTERVAL, ChronoUnit.MILLIS),
+                                    context.getConnectorConfig().getHeartbeatInterval(),
                                     context.topicSelector().getHeartbeatTopic(),
                                     context.getConnectorConfig().getLogicalName())
                             .forcedBeat(source.partition(), source.offset(), this::enqueueRecord);

File: debezium-core/src/main/java/io/debezium/relational/RelationalDatabaseConnectorConfig.java
Patch:
@@ -609,6 +609,7 @@ public static DecimalHandlingMode parse(String value, String defaultValue) {
     private final KeyMapper keyMapper;
     private final TableIdToStringMapper tableIdMapper;
     private final Configuration jdbcConfig;
+    private final String heartbeatActionQuery;
 
     protected RelationalDatabaseConnectorConfig(Configuration config, String logicalName, TableFilter systemTablesFilter,
                                                 TableIdToStringMapper tableIdMapper, int defaultSnapshotFetchSize,
@@ -676,8 +677,6 @@ public Configuration getJdbcConfig() {
         return jdbcConfig;
     }
 
-    public String heartbeatActionQuery;
-
     public String getHeartbeatActionQuery() {
         return heartbeatActionQuery;
     }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -308,7 +308,7 @@ public void parsePrimaryIndexColumnNames(MySqlParser.IndexColumnNamesContext ind
                     Column column = tableEditor.columnWithName(columnName);
                     if (column != null && column.isOptional()) {
                         final ColumnEditor ce = column.edit().optional(false);
-                        if (ce.hasDefaultValue() && ce.defaultValueExpression() == null) {
+                        if (ce.hasDefaultValue() && !ce.defaultValueExpression().isPresent()) {
                             ce.unsetDefaultValueExpression();
                         }
                         tableEditor.addColumn(ce.create());

File: debezium-core/src/main/java/io/debezium/relational/ColumnEditor.java
Patch:
@@ -119,7 +119,7 @@ public interface ColumnEditor {
      *
      * @return the complete type expression
      */
-    String defaultValueExpression();
+    Optional<String> defaultValueExpression();
 
     /**
      * Determine whether this column's has a default value set

File: debezium-core/src/main/java/io/debezium/relational/ColumnEditorImpl.java
Patch:
@@ -98,8 +98,8 @@ public boolean isGenerated() {
     }
 
     @Override
-    public String defaultValueExpression() {
-        return defaultValueExpression;
+    public Optional<String> defaultValueExpression() {
+        return Optional.ofNullable(defaultValueExpression);
     }
 
     @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -308,8 +308,8 @@ public void parsePrimaryIndexColumnNames(MySqlParser.IndexColumnNamesContext ind
                     Column column = tableEditor.columnWithName(columnName);
                     if (column != null && column.isOptional()) {
                         final ColumnEditor ce = column.edit().optional(false);
-                        if (ce.hasDefaultValue() && ce.defaultValue() == null) {
-                            ce.unsetDefaultValue();
+                        if (ce.hasDefaultValue() && ce.defaultValueExpression() == null) {
+                            ce.unsetDefaultValueExpression();
                         }
                         tableEditor.addColumn(ce.create());
                     }

File: debezium-connector-mysql/src/test/java/io/debezium/relational/history/AbstractDatabaseHistoryTest.java
Patch:
@@ -15,7 +15,6 @@
 import org.junit.Test;
 
 import io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser;
-import io.debezium.relational.DefaultValueConverter;
 import io.debezium.relational.Tables;
 import io.debezium.relational.ddl.DdlParser;
 import io.debezium.util.Collect;
@@ -38,7 +37,6 @@ public abstract class AbstractDatabaseHistoryTest {
     protected Tables t4;
     protected Tables all;
     protected DdlParser parser;
-    protected DefaultValueConverter defaultValueConverter;
 
     @Before
     public void beforeEach() {
@@ -89,7 +87,7 @@ protected void record(long pos, int entry, String ddl, Tables... update) {
 
     protected Tables recover(long pos, int entry) {
         Tables result = new Tables();
-        history.recover(source1, position("a.log", pos, entry), result, parser, defaultValueConverter);
+        history.recover(source1, position("a.log", pos, entry), result, parser);
         return result;
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/antlr/listener/ColumnDefinitionParserListener.java
Patch:
@@ -86,7 +86,6 @@ private void resolveColumnDataType(PlSqlParser.Column_definitionContext ctx) {
             if (ctx.DEFAULT() != null) {
                 String defaultValue = ctx.expression().getText();
                 columnEditor.defaultValueExpression(defaultValue);
-                columnEditor.defaultValue(defaultValue);
             }
         }
 

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleDdlParserTest.java
Patch:
@@ -369,8 +369,8 @@ private void testColumn(@NotNull Table table, @NotNull String name, boolean isOp
             assertThat(oScale.get()).isEqualTo(scale);
         }
         assertThat(column.hasDefaultValue()).isEqualTo(hasDefault);
-        if (column.hasDefaultValue() && column.defaultValue() != null) {
-            assertThat(defaultValue.equals(column.defaultValue()));
+        if (column.hasDefaultValue() && column.defaultValueExpression().isPresent()) {
+            assertThat(defaultValue.equals(column.defaultValueExpression().get()));
         }
     }
 }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorTask.java
Patch:
@@ -26,6 +26,7 @@
 import io.debezium.connector.common.BaseSourceTask;
 import io.debezium.connector.postgresql.connection.PostgresConnection;
 import io.debezium.connector.postgresql.connection.PostgresConnection.PostgresValueConverterBuilder;
+import io.debezium.connector.postgresql.connection.PostgresDefaultValueConverter;
 import io.debezium.connector.postgresql.connection.ReplicationConnection;
 import io.debezium.connector.postgresql.spi.SlotCreationResult;
 import io.debezium.connector.postgresql.spi.SlotState;
@@ -92,8 +93,9 @@ public ChangeEventSourceCoordinator<PostgresPartition, PostgresOffsetContext> st
         }
 
         final TypeRegistry typeRegistry = jdbcConnection.getTypeRegistry();
+        final PostgresDefaultValueConverter defaultValueConverter = jdbcConnection.getDefaultValueConverter();
 
-        schema = new PostgresSchema(connectorConfig, typeRegistry, topicSelector, valueConverterBuilder.build(typeRegistry));
+        schema = new PostgresSchema(connectorConfig, typeRegistry, defaultValueConverter, topicSelector, valueConverterBuilder.build(typeRegistry));
         this.taskContext = new PostgresTaskContext(connectorConfig, schema, topicSelector);
         final Offsets<PostgresPartition, PostgresOffsetContext> previousOffsets = getPreviousOffsets(
                 new PostgresPartition.Provider(connectorConfig), new PostgresOffsetContext.Loader(connectorConfig));

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorTaskIT.java
Patch:
@@ -48,6 +48,7 @@ public void retryOnFailureToCreateConnection() throws Exception {
         postgresConnectorTask.createReplicationConnection(new FakeContext(config, new PostgresSchema(
                 config,
                 null,
+                null,
                 PostgresTopicSelector.create(config), null)), true, 3, Duration.ofSeconds(2));
 
         // Verify retry happened for 10 seconds

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorTask.java
Patch:
@@ -77,7 +77,7 @@ public ChangeEventSourceCoordinator<SqlServerPartition, SqlServerOffsetContext>
         metadataConnection = new SqlServerConnection(jdbcConfig, connectorConfig.getSourceTimestampMode(), valueConverters, () -> getClass().getClassLoader(),
                 connectorConfig.getSkippedOperations(), connectorConfig.isMultiPartitionModeEnabled());
 
-        this.schema = new SqlServerDatabaseSchema(connectorConfig, metadataConnection::getDefaultValue, valueConverters, topicSelector, schemaNameAdjuster);
+        this.schema = new SqlServerDatabaseSchema(connectorConfig, metadataConnection.getDefaultValueConverter(), valueConverters, topicSelector, schemaNameAdjuster);
         this.schema.initializeStorage();
 
         Offsets<SqlServerPartition, SqlServerOffsetContext> offsets = getPreviousOffsets(

File: debezium-core/src/main/java/io/debezium/relational/CustomConverterRegistry.java
Patch:
@@ -54,7 +54,7 @@ public CustomConverterRegistry(List<CustomConverter<SchemaBuilder, ConvertedFiel
      * @param column the column metadata
      * @return the schema of the value generated by the converter or empty if converter does not support the column
      */
-    public synchronized Optional<SchemaBuilder> registerConverterFor(TableId table, Column column) {
+    public synchronized Optional<SchemaBuilder> registerConverterFor(TableId table, Column column, Object defaultValue) {
         final String fullColumnName = fullColumnName(table, column);
 
         for (CustomConverter<SchemaBuilder, ConvertedField> converter : converters) {
@@ -113,7 +113,7 @@ public boolean hasDefaultValue() {
 
                 @Override
                 public Object defaultValue() {
-                    return column.defaultValue();
+                    return defaultValue;
                 }
             },
                     new CustomConverter.ConverterRegistration<SchemaBuilder>() {

File: debezium-core/src/main/java/io/debezium/relational/history/ConnectTableChangeSerializer.java
Patch:
@@ -16,7 +16,6 @@
 import org.slf4j.LoggerFactory;
 
 import io.debezium.relational.Column;
-import io.debezium.relational.DefaultValueConverter;
 import io.debezium.relational.Table;
 import io.debezium.relational.history.TableChanges.TableChange;
 import io.debezium.util.SchemaNameAdjuster;
@@ -145,7 +144,7 @@ private Struct toStruct(Column column) {
     }
 
     @Override
-    public TableChanges deserialize(List<Struct> data, boolean useCatalogBeforeSchema, DefaultValueConverter defaultValueConverter) {
+    public TableChanges deserialize(List<Struct> data, boolean useCatalogBeforeSchema) {
         throw new UnsupportedOperationException("Deserialization from Connect Struct is not supported");
     }
 }

File: debezium-core/src/main/java/io/debezium/relational/history/TableChanges.java
Patch:
@@ -9,7 +9,6 @@
 import java.util.Iterator;
 import java.util.List;
 
-import io.debezium.relational.DefaultValueConverter;
 import io.debezium.relational.Table;
 import io.debezium.relational.TableId;
 import io.debezium.relational.history.TableChanges.TableChange;
@@ -164,7 +163,7 @@ public static interface TableChangesSerializer<T> {
          * the catalog and the second as the table name, or false if the first should be used as the schema and the
          * second as the table name
          */
-        TableChanges deserialize(T data, boolean useCatalogBeforeSchema, DefaultValueConverter defaultValueConverter);
+        TableChanges deserialize(T data, boolean useCatalogBeforeSchema);
     }
 
     public enum TableChangeType {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/AlterTableParserListener.java
Patch:
@@ -165,6 +165,7 @@ public void enterAlterByChangeColumn(MySqlParser.AlterByChangeColumnContext ctx)
                 // definition; so in fact it's arguably not correct to use edit() on the existing column to begin with, but
                 // I'm going to leave this as is for now, to be prepared for the ability of updating column definitions in 8.0
                 ColumnEditor columnEditor = existingColumn.edit();
+                columnEditor.unsetDefaultValueExpression();
                 columnEditor.unsetDefaultValue();
 
                 columnDefinitionListener = new ColumnDefinitionParserListener(tableEditor, columnEditor, parser, listeners);
@@ -271,6 +272,7 @@ public void enterAlterByChangeDefault(MySqlParser.AlterByChangeDefaultContext ct
                     listeners.add(defaultValueListener);
                 }
                 else if (ctx.DROP() != null) {
+                    defaultValueColumnEditor.unsetDefaultValueExpression();
                     defaultValueColumnEditor.unsetDefaultValue();
                 }
             }

File: debezium-connector-mysql/src/test/java/io/debezium/relational/history/AbstractDatabaseHistoryTest.java
Patch:
@@ -15,6 +15,7 @@
 import org.junit.Test;
 
 import io.debezium.connector.mysql.antlr.MySqlAntlrDdlParser;
+import io.debezium.relational.DefaultValueConverter;
 import io.debezium.relational.Tables;
 import io.debezium.relational.ddl.DdlParser;
 import io.debezium.util.Collect;
@@ -37,6 +38,7 @@ public abstract class AbstractDatabaseHistoryTest {
     protected Tables t4;
     protected Tables all;
     protected DdlParser parser;
+    protected DefaultValueConverter defaultValueConverter;
 
     @Before
     public void beforeEach() {
@@ -87,7 +89,7 @@ protected void record(long pos, int entry, String ddl, Tables... update) {
 
     protected Tables recover(long pos, int entry) {
         Tables result = new Tables();
-        history.recover(source1, position("a.log", pos, entry), result, parser);
+        history.recover(source1, position("a.log", pos, entry), result, parser, defaultValueConverter);
         return result;
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/antlr/listener/ColumnDefinitionParserListener.java
Patch:
@@ -85,6 +85,7 @@ private void resolveColumnDataType(PlSqlParser.Column_definitionContext ctx) {
             // todo move to enterExpression and apply type conversion
             if (ctx.DEFAULT() != null) {
                 String defaultValue = ctx.expression().getText();
+                columnEditor.defaultValueExpression(defaultValue);
                 columnEditor.defaultValue(defaultValue);
             }
         }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresConnection.java
Patch:
@@ -569,6 +569,7 @@ private Optional<ColumnEditor> doReadTableColumn(ResultSet columnMetadata, Table
 
             final String defaultValue = columnMetadata.getString(13);
             if (defaultValue != null) {
+                column.defaultValueExpression(defaultValue);
                 getDefaultValue(column.create(), defaultValue).ifPresent(column::defaultValue);
             }
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorTask.java
Patch:
@@ -77,7 +77,7 @@ public ChangeEventSourceCoordinator<SqlServerPartition, SqlServerOffsetContext>
         metadataConnection = new SqlServerConnection(jdbcConfig, connectorConfig.getSourceTimestampMode(), valueConverters, () -> getClass().getClassLoader(),
                 connectorConfig.getSkippedOperations(), connectorConfig.isMultiPartitionModeEnabled());
 
-        this.schema = new SqlServerDatabaseSchema(connectorConfig, valueConverters, topicSelector, schemaNameAdjuster);
+        this.schema = new SqlServerDatabaseSchema(connectorConfig, metadataConnection::getDefaultValue, valueConverters, topicSelector, schemaNameAdjuster);
         this.schema.initializeStorage();
 
         Offsets<SqlServerPartition, SqlServerOffsetContext> offsets = getPreviousOffsets(

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConnection.java
Patch:
@@ -1282,6 +1282,7 @@ protected Optional<ColumnEditor> readTableColumn(ResultSet columnMetadata, Table
             column.nativeType(resolveNativeType(column.typeName()));
             column.jdbcType(resolveJdbcType(columnMetadata.getInt(5), column.nativeType()));
             if (defaultValue != null) {
+                column.defaultValueExpression(defaultValue);
                 getDefaultValue(column.create(), defaultValue).ifPresent(column::defaultValue);
             }
             return Optional.of(column);

File: debezium-core/src/main/java/io/debezium/relational/history/ConnectTableChangeSerializer.java
Patch:
@@ -16,6 +16,7 @@
 import org.slf4j.LoggerFactory;
 
 import io.debezium.relational.Column;
+import io.debezium.relational.DefaultValueConverter;
 import io.debezium.relational.Table;
 import io.debezium.relational.history.TableChanges.TableChange;
 import io.debezium.util.SchemaNameAdjuster;
@@ -144,7 +145,7 @@ private Struct toStruct(Column column) {
     }
 
     @Override
-    public TableChanges deserialize(List<Struct> data, boolean useCatalogBeforeSchema) {
+    public TableChanges deserialize(List<Struct> data, boolean useCatalogBeforeSchema, DefaultValueConverter defaultValueConverter) {
         throw new UnsupportedOperationException("Deserialization from Connect Struct is not supported");
     }
 }

File: debezium-core/src/main/java/io/debezium/relational/history/TableChanges.java
Patch:
@@ -9,6 +9,7 @@
 import java.util.Iterator;
 import java.util.List;
 
+import io.debezium.relational.DefaultValueConverter;
 import io.debezium.relational.Table;
 import io.debezium.relational.TableId;
 import io.debezium.relational.history.TableChanges.TableChange;
@@ -163,7 +164,7 @@ public static interface TableChangesSerializer<T> {
          * the catalog and the second as the table name, or false if the first should be used as the schema and the
          * second as the table name
          */
-        TableChanges deserialize(T data, boolean useCatalogBeforeSchema);
+        TableChanges deserialize(T data, boolean useCatalogBeforeSchema, DefaultValueConverter defaultValueConverter);
     }
 
     public enum TableChangeType {

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/util/TestHelper.java
Patch:
@@ -183,6 +183,7 @@ private static Configuration.Builder testConfig() {
         jdbcConfiguration.forEach(
                 (field, value) -> builder.with(OracleConnectorConfig.DATABASE_CONFIG_PREFIX + field, value));
 
+        builder.with(OracleConnectorConfig.SERVER_NAME, SERVER_NAME);
         return builder;
     }
 
@@ -196,6 +197,7 @@ private static Configuration.Builder adminConfig() {
         jdbcConfiguration.forEach(
                 (field, value) -> builder.with(OracleConnectorConfig.DATABASE_CONFIG_PREFIX + field, value));
 
+        builder.with(OracleConnectorConfig.SERVER_NAME, SERVER_NAME);
         return builder;
     }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgoutput/PgOutputMessageDecoder.java
Patch:
@@ -110,7 +110,7 @@ public static MessageType forType(char type) {
 
     public PgOutputMessageDecoder(MessageDecoderContext decoderContext) {
         this.decoderContext = decoderContext;
-        this.connection = new PostgresConnection(decoderContext.getConfig().getJdbcConfig(), decoderContext.getSchema().getTypeRegistry());
+        this.connection = new PostgresConnection(decoderContext.getConfig(), decoderContext.getSchema().getTypeRegistry());
     }
 
     @Override

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/oracle/OcpOracleController.java
Patch:
@@ -59,7 +59,7 @@ public void initialize() throws InterruptedException {
                 .writingOutput(System.out) // CHECKSTYLE IGNORE RegexpSinglelineJava FOR NEXT 2 LINES
                 .writingError(System.err)
                 .usingListener(new DatabaseInitListener("oracle", latch))
-                .exec("" + "sqlplus", "-S",
+                .exec("sqlplus", "-S",
                         DATABASE_ORACLE_USERNAME + "/" + DATABASE_ORACLE_PASSWORD + "@//localhost:1521/ORCLPDB1", "@" + DB_INIT_SCRIPT_PATH_CONTAINER)) {
             LOGGER.info("Waiting until database is initialized");
             latch.await(WaitConditions.scaled(1), TimeUnit.MINUTES);

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/databases/db2/OcpDB2Deployer.java
Patch:
@@ -35,7 +35,7 @@ public OcpDB2Controller getController(Deployment deployment, List<Service> servi
         return new OcpDB2Controller(deployment, services, ocp);
     }
 
-    public static class Deployer extends DatabaseBuilder<OcpDB2Deployer.Deployer, OcpDB2Deployer> {
+    public static class Builder extends DatabaseBuilder<Builder, OcpDB2Deployer> {
         @Override
         public OcpDB2Deployer build() {
             return new OcpDB2Deployer(

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/fixtures/databases/OcpDB2.java
Patch:
@@ -19,7 +19,7 @@ public interface OcpDB2 extends TestSetupFixture, SqlDatabaseFixture, OcpClient
 
     default void setupDatabase() throws Exception {
         Class.forName("com.ibm.db2.jcc.DB2Driver");
-        OcpDB2Deployer deployer = new OcpDB2Deployer.Deployer()
+        OcpDB2Deployer deployer = new OcpDB2Deployer.Builder()
                 .withOcpClient(getOcpClient())
                 .withProject(ConfigProperties.OCP_PROJECT_DB2)
                 .withDeployment(DB_DEPLOYMENT_PATH)

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/SnapshotDatatypesIT.java
Patch:
@@ -39,6 +39,7 @@ public static void beforeClass() throws SQLException {
         insertIntTypes();
         insertTimeTypes();
         insertClobTypes();
+        insertGeometryTypes();
     }
 
     @Before
@@ -85,6 +86,8 @@ private String getTableIncludeList() {
                 return "debezium.type_time";
             case "clobTypes":
                 return "debezium.type_clob";
+            case "geometryTypes":
+                return "debezium.type_geometry";
             default:
                 throw new IllegalArgumentException("Unexpected test method: " + name.getMethodName());
         }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbChangeSnapshotOplogRecordEmitter.java
Patch:
@@ -12,7 +12,7 @@
 import org.apache.kafka.connect.data.Struct;
 import org.bson.Document;
 
-import io.debezium.annotation.ThreadSafe;
+import io.debezium.annotation.Immutable;
 import io.debezium.data.Envelope.FieldName;
 import io.debezium.data.Envelope.Operation;
 import io.debezium.pipeline.AbstractChangeRecordEmitter;
@@ -34,7 +34,7 @@ public class MongoDbChangeSnapshotOplogRecordEmitter extends AbstractChangeRecor
      */
     private final boolean isSnapshot;
 
-    @ThreadSafe
+    @Immutable
     private static final Map<String, Operation> OPERATION_LITERALS;
 
     static {

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/FieldSelector.java
Patch:
@@ -644,8 +644,7 @@ FieldNameAndValue generateNewFieldName(String[] fieldNodes, Object value) {
 
         @Override
         String generateNewFieldName(String fieldName) {
-            return replaceLastNameNode(
-                    FieldSelectorBuilder.parseIntoParts(fieldName, fieldName, length -> length < 1, DOT), newFieldNode);
+            return rename(FieldSelectorBuilder.parseIntoParts(fieldName, fieldName, length -> length < 1, DOT));
         }
 
         /**

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/DockerRhelDB2ConnectorIT.java
Patch:
@@ -21,7 +21,7 @@
  */
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @Tag("acceptance")
-@Tag("db2 ")
+@Tag("db2")
 @Tag("docker")
 @Tag("rhel")
 @TestInstance(TestInstance.Lifecycle.PER_CLASS)

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/OcpAvroDB2ConnectorIT.java
Patch:
@@ -22,7 +22,7 @@
  * @author Jakub Cechacek
  */
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
-@Tag("db2 ")
+@Tag("db2")
 @Tag("openshift")
 @Tag("avro")
 @Tag("apicurio")

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/OcpDB2ConnectorIT.java
Patch:
@@ -21,7 +21,7 @@
  */
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @Tag("acceptance")
-@Tag("db2 ")
+@Tag("db2")
 @Tag("openshift")
 @TestInstance(TestInstance.Lifecycle.PER_CLASS)
 public class OcpDB2ConnectorIT

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -52,7 +52,7 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
     protected final static int MIN_BATCH_SIZE = 1_000;
     protected final static int MAX_BATCH_SIZE = 100_000;
 
-    protected final static int DEFAULT_SCN_GAP_SIZE = 10_000_000;
+    protected final static int DEFAULT_SCN_GAP_SIZE = 1_000_000;
     protected final static int DEFAULT_SCN_GAP_TIME_INTERVAL = 20_000;
 
     protected final static Duration MAX_SLEEP_TIME = Duration.ofMillis(3_000);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlTableAndColumnCommentIT.java
Patch:
@@ -27,7 +27,7 @@
 import io.debezium.embedded.AbstractConnectorTest;
 import io.debezium.util.Testing;
 
-public class MysqlTableAndColumnCommentIT extends AbstractConnectorTest {
+public class MySqlTableAndColumnCommentIT extends AbstractConnectorTest {
 
     private static final String COLUMN_COMMENT_PARAMETER_KEY = "__debezium.source.column.comment";
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnection.java
Patch:
@@ -59,7 +59,7 @@ public class SqlServerConnection extends JdbcConnection {
     private static final Logger LOGGER = LoggerFactory.getLogger(SqlServerConnection.class);
 
     private static final String STATEMENTS_PLACEHOLDER = "#";
-    private static final String DATABASE_NAME_PLACEHOLDER = "[#db]";
+    private static final String DATABASE_NAME_PLACEHOLDER = "#db";
     private static final String GET_MAX_LSN = "SELECT [#db].sys.fn_cdc_get_max_lsn()";
     private static final String GET_MAX_TRANSACTION_LSN = "SELECT MAX(start_lsn) FROM [#db].cdc.lsn_time_mapping WHERE tran_id <> 0x00";
     private static final String GET_NTH_TRANSACTION_LSN_FROM_BEGINNING = "SELECT MAX(start_lsn) FROM (SELECT TOP (?) start_lsn FROM [#db].cdc.lsn_time_mapping WHERE tran_id <> 0x00 ORDER BY start_lsn) as next_lsns";

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerEventRowTest.java
Patch:
@@ -143,10 +143,8 @@ public void testTableId() throws Exception {
         assertThat(row.getTableId().toString()).isEqualTo("DEBEZIUM.SCHEMA.TABLE");
         verify(resultSet).getString(8);
 
-        row = new LogMinerEventRow();
         when(resultSet.getString(8)).thenThrow(SQLException.class);
         assertThrows(resultSet, SQLException.class);
-        assertThat(row.getTableId()).isNull();
     }
 
     @Test
@@ -161,7 +159,6 @@ public void tesetTableIdWithVariedCase() throws Exception {
 
         when(resultSet.getString(8)).thenThrow(SQLException.class);
         assertThrows(resultSet, SQLException.class);
-        assertThat(row.getTableId()).isNull();
     }
 
     @Test

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/memory/MemoryLogMinerEventProcessor.java
Patch:
@@ -327,7 +327,7 @@ protected void handleRollback(LogMinerEventRow row) {
     @Override
     protected void handleSchemaChange(LogMinerEventRow row) throws InterruptedException {
         super.handleSchemaChange(row);
-        if (row.getTableName() != null) {
+        if (row.getTableName() != null && getConfig().isLobEnabled()) {
             schemaChangesCache.add(row.getScn());
         }
     }

File: debezium-core/src/main/java/io/debezium/util/JvmVersionUtil.java
Patch:
@@ -1,10 +1,9 @@
-package io.debezium.util;
-
 /*
  * Copyright Debezium Authors.
  *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
+package io.debezium.util;
 
 /**
  * Utility class dealing with Java version information.

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -950,7 +950,9 @@ private Object resolveArrayValue(Object value, PostgresType elementType) {
     }
 
     private boolean isVariableScaleDecimal(final Column column) {
-        return column.length() == VARIABLE_SCALE_DECIMAL_LENGTH &&
+        // TODO: Remove VARIABLE_SCALE_DECIMAL_LENGTH when https://github.com/pgjdbc/pgjdbc/issues/2275
+        // is closed.
+        return (column.length() == 0 || column.length() == VARIABLE_SCALE_DECIMAL_LENGTH) &&
                 column.scale().orElseGet(() -> 0) == 0;
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/infinispan/InfinispanLogMinerEventProcessor.java
Patch:
@@ -255,7 +255,6 @@ else if (getConfig().getLogMiningUsernameExcludes().contains(transaction.getUser
             skipExcludedUserName = true;
         }
 
-
         final Scn smallestScn = transactionCache.getMinimumScn();
         metrics.setOldestScn(smallestScn.isNull() ? Scn.valueOf(-1) : smallestScn);
 
@@ -299,7 +298,7 @@ else if (getConfig().getLogMiningUsernameExcludes().contains(transaction.getUser
             // after reconciliation all events should be DML
             // todo: do we want to move dml entry up and just let it be null to avoid cast?
             final DmlEvent dmlEvent = (DmlEvent) event;
-            if(!skipExcludedUserName) {
+            if (!skipExcludedUserName) {
                 dispatcher.dispatchDataChangeEvent(event.getTableId(),
                         new LogMinerChangeRecordEmitter(
                                 partition,

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/processor/memory/MemoryLogMinerEventProcessor.java
Patch:
@@ -269,7 +269,7 @@ else if (getConfig().getLogMiningUsernameExcludes().contains(transaction.getUser
 
             // after reconciliation all events should be DML
             final DmlEvent dmlEvent = (DmlEvent) event;
-            if(!skipExcludedUserName) {
+            if (!skipExcludedUserName) {
                 dispatcher.dispatchDataChangeEvent(event.getTableId(),
                         new LogMinerChangeRecordEmitter(
                                 partition,

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -2297,7 +2297,7 @@ private <T> T getStreamingMetric(String metricName) throws JMException {
         final ObjectName objectName = getStreamingMetricsObjectName(TestHelper.CONNECTOR_NAME, TestHelper.SERVER_NAME);
         return (T) mbeanServer.getAttribute(objectName, metricName);
     }
-    
+
     private String generateAlphaNumericStringColumn(int size) {
         final String alphaNumericString = "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789abcdefghijklmnopqrstuvwxyz";
         final StringBuilder sb = new StringBuilder(size);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresDefaultValueConverter.java
Patch:
@@ -141,6 +141,7 @@ private static Map<String, DefaultValueMapper> createDefaultValueMappers(Timesta
         result.put("serial", v -> Integer.parseInt(extractDefault(v, "0")));
         result.put("int8", v -> Long.parseLong(extractDefault(v, "0"))); // Sample values: `123`, `'9223372036854775807'::bigint`
         result.put("bigserial", v -> Long.parseLong(extractDefault(v, "0")));
+        result.put("smallserial", v -> Short.parseShort(extractDefault(v, "0")));
 
         result.put("json", v -> extractDefault(v, "{}")); // Sample value: '{}'::json
         result.put("jsonb", v -> extractDefault(v, "{}")); // Sample value: '{}'::jsonb

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerErrorHandler.java
Patch:
@@ -31,6 +31,7 @@ protected boolean isRetriable(Throwable throwable) {
                 && (throwable.getMessage().contains("Connection timed out (Read failed)")
                         || throwable.getMessage().contains("Connection timed out (Write failed)")
                         || throwable.getMessage().contains("The connection has been closed.")
+                        || throwable.getMessage().contains("The connection is closed.")
                         || throwable.getMessage().contains("Connection reset")
                         || throwable.getMessage().contains("SHUTDOWN is in progress")
                         || throwable.getMessage().contains("The server failed to resume the transaction")

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleValueConverters.java
Patch:
@@ -210,6 +210,9 @@ public ValueConverter converter(Column column, Field fieldDefn) {
                 return (data) -> convertIntervalYearMonth(column, fieldDefn, data);
             case OracleTypes.INTERVALDS:
                 return (data) -> convertIntervalDaySecond(column, fieldDefn, data);
+            case OracleTypes.RAW:
+                // Raw data types are not supported
+                return null;
         }
 
         return super.converter(column, fieldDefn);

File: debezium-embedded/src/test/java/io/debezium/pipeline/source/snapshot/incremental/AbstractIncrementalSnapshotTest.java
Patch:
@@ -189,7 +189,7 @@ public void invalidTablesInTheList() throws Exception {
         populateTable();
         startConnector();
 
-        sendAdHocSnapshotSignal("invalid1", tableName(), "invalid2");
+        sendAdHocSnapshotSignal("invalid1", tableDataCollectionId(), "invalid2");
 
         final int expectedRecordCount = ROW_COUNT;
         final Map<Integer, Integer> dbChanges = consumeMixedWithIncrementalSnapshot(expectedRecordCount);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerDatabaseStateWriter.java
Patch:
@@ -35,7 +35,7 @@ public static void write(OracleConnection connection) {
             }
             LOGGER.debug("Archive logs for last 48 hours:");
             try {
-                logQueryResults(connection, "SELECT * FROM V$ARCHIVED_LOG WHERE FIST_TIME >= SYSDATE - 2");
+                logQueryResults(connection, "SELECT * FROM V$ARCHIVED_LOG WHERE FIRST_TIME >= SYSDATE - 2");
             }
             catch (SQLException e) {
                 LOGGER.debug("Failed to obtain archive log table entries", e);

File: debezium-core/src/main/java/io/debezium/config/ConfigDefinition.java
Patch:
@@ -101,7 +101,7 @@ private void addToList(List<Field> list, List<Field> fields) {
 
     private void addToConfigDef(ConfigDef configDef, String group, List<Field> fields) {
         if (!fields.isEmpty()) {
-            Field.group(configDef, group, fields.toArray(new Field[fields.size()]));
+            Field.group(configDef, group, fields.toArray(new Field[0]));
         }
     }
 }

File: debezium-core/src/main/java/io/debezium/config/Configuration.java
Patch:
@@ -832,7 +832,7 @@ public static Configuration from(Map<String, ?> properties) {
      * @return the configuration; never null
      */
     public static <T> Configuration from(Map<String, T> properties, Function<T, String> conversion) {
-        Map<String, Object> props = new HashMap<>();
+        Map<String, T> props = new HashMap<>();
         if (properties != null) {
             props.putAll(properties);
         }

File: debezium-core/src/main/java/io/debezium/heartbeat/DatabaseHeartbeatImpl.java
Patch:
@@ -29,6 +29,7 @@ public class DatabaseHeartbeatImpl extends HeartbeatImpl {
     public static final Field HEARTBEAT_ACTION_QUERY = Field.create(HEARTBEAT_ACTION_QUERY_PROPERTY_NAME)
             .withDisplayName("An optional query to execute with every heartbeat")
             .withType(ConfigDef.Type.STRING)
+            .withGroup(Field.createGroupEntry(Field.Group.ADVANCED_HEARTBEAT, 2))
             .withWidth(ConfigDef.Width.MEDIUM)
             .withImportance(ConfigDef.Importance.LOW)
             .withDescription("The query executed with every heartbeat.");

File: debezium-core/src/main/java/io/debezium/heartbeat/Heartbeat.java
Patch:
@@ -41,6 +41,7 @@ interface OffsetProducer {
     Field HEARTBEAT_INTERVAL = Field.create(HEARTBEAT_INTERVAL_PROPERTY_NAME)
             .withDisplayName("Connector heartbeat interval (milli-seconds)")
             .withType(Type.INT)
+            .withGroup(Field.createGroupEntry(Field.Group.ADVANCED_HEARTBEAT, 0))
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.MEDIUM)
             .withDescription("Length of an interval in milli-seconds in in which the connector periodically sends heartbeat messages "
@@ -53,6 +54,7 @@ interface OffsetProducer {
     Field HEARTBEAT_TOPICS_PREFIX = Field.create("heartbeat.topics.prefix")
             .withDisplayName("A prefix used for naming of heartbeat topics")
             .withType(Type.STRING)
+            .withGroup(Field.createGroupEntry(Field.Group.ADVANCED_HEARTBEAT, 1))
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.LOW)
             .withDescription("The prefix that is used to name heartbeat topics."

File: debezium-core/src/main/java/io/debezium/relational/history/FileDatabaseHistory.java
Patch:
@@ -38,7 +38,7 @@ public final class FileDatabaseHistory extends AbstractDatabaseHistory {
 
     public static final Field FILE_PATH = Field.create(CONFIGURATION_FIELD_PREFIX_STRING + "file.filename")
             .withDescription("The path to the file that will be used to record the database history")
-            .withValidation(Field::isRequired);
+            .required();
 
     public static Collection<Field> ALL_FIELDS = Collect.arrayListOf(FILE_PATH);
 

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -85,14 +85,14 @@ public final class EmbeddedEngine implements DebeziumEngine<SourceRecord> {
      */
     public static final Field ENGINE_NAME = Field.create("name")
             .withDescription("Unique name for this connector instance.")
-            .withValidation(Field::isRequired);
+            .required();
 
     /**
      * A required field for an embedded connector that specifies the name of the normal Debezium connector's Java class.
      */
     public static final Field CONNECTOR_CLASS = Field.create("connector.class")
             .withDescription("The Java class for the connector")
-            .withValidation(Field::isRequired);
+            .required();
 
     /**
      * An optional field that specifies the name of the class that implements the {@link OffsetBackingStore} interface,

File: debezium-scripting/src/main/java/io/debezium/transforms/ContentBasedRouter.java
Patch:
@@ -27,7 +27,7 @@ public class ContentBasedRouter<R extends ConnectRecord<R>> extends ScriptingTra
             .withType(ConfigDef.Type.STRING)
             .withWidth(ConfigDef.Width.MEDIUM)
             .withImportance(ConfigDef.Importance.HIGH)
-            .withValidation(Field::isRequired)
+            .required()
             .withDescription("An expression determining the new name of the topic the record should use. When null the record is delivered to the original topic.");
 
     @Override

File: debezium-scripting/src/main/java/io/debezium/transforms/Filter.java
Patch:
@@ -25,7 +25,7 @@ public class Filter<R extends ConnectRecord<R>> extends ScriptingTransformation<
             .withType(ConfigDef.Type.STRING)
             .withWidth(ConfigDef.Width.MEDIUM)
             .withImportance(ConfigDef.Importance.HIGH)
-            .withValidation(Field::isRequired)
+            .required()
             .withDescription("An expression determining whether the record should be filtered out. When evaluated to true the record is removed.");
 
     @Override

File: debezium-scripting/src/main/java/io/debezium/transforms/ScriptingTransformation.java
Patch:
@@ -108,7 +108,7 @@ public static NullHandling parse(String value, String defaultValue) {
             .withType(ConfigDef.Type.STRING)
             .withWidth(ConfigDef.Width.MEDIUM)
             .withImportance(ConfigDef.Importance.HIGH)
-            .withValidation(Field::isRequired)
+            .required()
             .withDescription("An expression language used to evaluate the expression. Must begin with 'jsr223.', e.g.  'jsr223.groovy' or 'jsr223.graal.js'.");
 
     public static final Field NULL_HANDLING = Field.create("null.handling.mode")

File: debezium-server/debezium-server-core/src/main/java/io/debezium/server/DebeziumServer.java
Patch:
@@ -154,7 +154,7 @@ else if (beans.size() > 1) {
     private void configToProperties(Config config, Properties props, String oldPrefix, String newPrefix) {
         for (String name : config.getPropertyNames()) {
             String updatedPropertyName = null;
-            if (SHELL_PROPERTY_NAME_PATTERN.asPredicate().test(name)) {
+            if (SHELL_PROPERTY_NAME_PATTERN.matcher(name).matches()) {
                 updatedPropertyName = name.replace("_", ".").toLowerCase();
             }
             if (updatedPropertyName != null && updatedPropertyName.startsWith(oldPrefix)) {

File: debezium-server/debezium-server-core/src/test/java/io/debezium/server/DebeziumServerTest.java
Patch:
@@ -54,6 +54,9 @@ public void testProps() {
         Assertions.assertThat(properties.getProperty("table.whitelist")).isNotNull();
         Assertions.assertThat(properties.getProperty("table.whitelist")).isEqualTo("public.table_name");
 
+        Assertions.assertThat(properties.getProperty("offset.flush.interval.ms.test")).isNotNull();
+        Assertions.assertThat(properties.getProperty("offset.flush.interval.ms.test")).isEqualTo("0");
+
         Assertions.assertThat(properties.getProperty("snapshot.select.statement.overrides.public.table_name")).isNotNull();
         Assertions.assertThat(properties.getProperty("snapshot.select.statement.overrides.public.table_name")).isEqualTo("SELECT * FROM table_name WHERE 1>2");
 

File: debezium-server/debezium-server-core/src/test/java/io/debezium/server/TestConfigSource.java
Patch:
@@ -69,6 +69,7 @@ public TestConfigSource() {
 
         // DBZ-2622 For testing properties passed via smallrye/microprofile environment variables
         unitTest.put("DEBEZIUM_SOURCE_TABLE_WHITELIST", "public.table_name");
+        unitTest.put("debezium_source_offset_flush_interval_ms_Test", "0");
         unitTest.put("debezium.source.snapshot.select.statement.overrides.public.table_name", "SELECT * FROM table_name WHERE 1>2");
         unitTest.put("debezium.source.database.allowPublicKeyRetrieval", "true");
 

File: debezium-server/debezium-server-core/src/main/java/io/debezium/server/DebeziumServer.java
Patch:
@@ -75,7 +75,7 @@ public class DebeziumServer {
     private static final String FORMAT_AVRO = Avro.class.getSimpleName().toLowerCase();
     private static final String FORMAT_PROTOBUF = Protobuf.class.getSimpleName().toLowerCase();
 
-    private static final Pattern PROPERTY_NAME_PATTERN = Pattern.compile("([a-z]*\\.[a-z]*)+$");
+    private static final Pattern SHELL_PROPERTY_NAME_PATTERN = Pattern.compile("^\\w+_+\\w+$");
 
     private ExecutorService executor = Executors.newSingleThreadExecutor();
 
@@ -154,7 +154,7 @@ else if (beans.size() > 1) {
     private void configToProperties(Config config, Properties props, String oldPrefix, String newPrefix) {
         for (String name : config.getPropertyNames()) {
             String updatedPropertyName = null;
-            if (!PROPERTY_NAME_PATTERN.asPredicate().test(name)) {
+            if (SHELL_PROPERTY_NAME_PATTERN.asPredicate().test(name)) {
                 updatedPropertyName = name.replace("_", ".").toLowerCase();
             }
             if (updatedPropertyName != null && updatedPropertyName.startsWith(oldPrefix)) {

File: debezium-server/debezium-server-core/src/test/java/io/debezium/server/TestConfigSource.java
Patch:
@@ -69,6 +69,8 @@ public TestConfigSource() {
 
         // DBZ-2622 For testing properties passed via smallrye/microprofile environment variables
         unitTest.put("DEBEZIUM_SOURCE_TABLE_WHITELIST", "public.table_name");
+        unitTest.put("debezium.source.snapshot.select.statement.overrides.public.table_name", "SELECT * FROM table_name WHERE 1>2");
+        unitTest.put("debezium.source.database.allowPublicKeyRetrieval", "true");
 
         if (isItTest()) {
             config = integrationTest;

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerErrorHandler.java
Patch:
@@ -34,7 +34,7 @@ protected boolean isRetriable(Throwable throwable) {
                         || throwable.getMessage().contains("Connection reset")
                         || throwable.getMessage().contains("SHUTDOWN is in progress")
                         || throwable.getMessage().contains("The server failed to resume the transaction")
-                        || throwable.getMessage().contains("Connection refused (Connection refused)")
+                        || throwable.getMessage().contains("Verify the connection properties")
                         || throwable.getMessage()
                                 .startsWith("An insufficient number of arguments were supplied for the procedure or function cdc.fn_cdc_get_all_changes_")
                         || throwable.getMessage()

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerSnapshotChangeEventSource.java
Patch:
@@ -81,7 +81,7 @@ protected SnapshottingTask getSnapshottingTask(SqlServerOffsetContext previousOf
     @Override
     protected SnapshotContext<SqlServerPartition, SqlServerOffsetContext> prepare(SqlServerPartition partition)
             throws Exception {
-        return new SqlServerSnapshotContext(partition, jdbcConnection.getRealDatabaseName());
+        return new SqlServerSnapshotContext(partition, jdbcConnection.getDatabaseName());
     }
 
     @Override

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerStreamingChangeEventSource.java
Patch:
@@ -71,8 +71,7 @@ public class SqlServerStreamingChangeEventSource implements StreamingChangeEvent
     private final SqlServerConnection dataConnection;
 
     /**
-     * A separate connection for retrieving timestamps; without it, adaptive
-     * buffering will not work.
+     * A separate connection for retrieving details of the schema changes; without it, adaptive buffering will not work.
      *
      * @link https://docs.microsoft.com/en-us/sql/connect/jdbc/using-adaptive-buffering?view=sql-server-2017#guidelines-for-using-adaptive-buffering
      */
@@ -264,7 +263,7 @@ public void execute(ChangeEventSourceContext context, SqlServerPartition partiti
                             offsetContext.event(
                                     tableWithSmallestLsn.getChangeTable().getSourceTableId(),
                                     connectorConfig.getSourceTimestampMode().getTimestamp(
-                                            metadataConnection, clock, tableWithSmallestLsn.getResultSet()));
+                                            clock, tableWithSmallestLsn.getResultSet()));
 
                             dispatcher
                                     .dispatchDataChangeEvent(
@@ -300,6 +299,7 @@ private void commitTransaction() throws SQLException {
         // For R/W database it is important to execute regular commits to maintain the size of TempDB
         if (connectorConfig.isReadOnlyDatabaseConnection() || pauseBetweenCommits.hasElapsed()) {
             dataConnection.commit();
+            metadataConnection.commit();
         }
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -1099,7 +1099,7 @@ public static int validateRacNodes(Configuration config, Field field, Validation
                 for (String racNode : racNodes) {
                     String[] parts = racNode.split(":");
                     if (parts.length == 1) {
-                        problems.accept(field, racNode, "Must be specified as 'ip:port' since no 'database.port' is provided");
+                        problems.accept(field, racNode, "Must be specified as 'ip/hostname:port' since no 'database.port' is provided");
                         errors++;
                     }
                 }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -416,7 +416,7 @@ public OracleConnectorConfig(Configuration config) {
 
         // LogMiner
         this.logMiningStrategy = LogMiningStrategy.parse(config.getString(LOG_MINING_STRATEGY));
-        this.racNodes = resovleRacNodes(config);
+        this.racNodes = resolveRacNodes(config);
         this.logMiningContinuousMine = config.getBoolean(CONTINUOUS_MINE);
         this.logMiningArchiveLogRetention = Duration.ofHours(config.getLong(LOG_MINING_ARCHIVE_LOG_HOURS));
         this.logMiningBatchSizeMin = config.getInteger(LOG_MINING_BATCH_SIZE_MIN);
@@ -1038,7 +1038,7 @@ public String getConnectorName() {
         return Module.name();
     }
 
-    private Set<String> resovleRacNodes(Configuration config) {
+    private Set<String> resolveRacNodes(Configuration config) {
         final boolean portProvided = config.hasKey(PORT.name());
         final Set<String> nodes = Strings.setOf(config.getString(RAC_NODES), String::new);
         return nodes.stream().map(node -> {

File: debezium-server/debezium-server-pravega/src/main/java/io/debezium/server/pravega/PravegaChangeConsumer.java
Patch:
@@ -15,6 +15,7 @@
 import javax.enterprise.context.Dependent;
 import javax.inject.Named;
 
+import org.eclipse.microprofile.config.ConfigProvider;
 import org.eclipse.microprofile.config.inject.ConfigProperty;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -46,8 +47,7 @@ public class PravegaChangeConsumer extends BaseChangeConsumer implements ChangeC
     @ConfigProperty(name = PROP_CONTROLLER, defaultValue = "tcp://localhost:9090")
     URI controllerUri;
 
-    @ConfigProperty(name = PROP_SCOPE)
-    String scope;
+    private String scope;
 
     @ConfigProperty(name = PROP_TXN, defaultValue = "false")
     boolean txn;
@@ -58,6 +58,7 @@ public class PravegaChangeConsumer extends BaseChangeConsumer implements ChangeC
 
     @PostConstruct
     void constructor() {
+        scope = ConfigProvider.getConfig().getValue(PROP_SCOPE, String.class);
         clientConfig = ClientConfig.builder()
                 .controllerURI(controllerUri)
                 .build();

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/OcpAvroDB2ConnectorIT.java
Patch:
@@ -22,12 +22,12 @@
  * @author Jakub Cechacek
  */
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
-@Tag("acceptance")
 @Tag("db2 ")
+@Tag("openshift")
 @Tag("avro")
 @Tag("apicurio")
 @TestInstance(TestInstance.Lifecycle.PER_CLASS)
 public class OcpAvroDB2ConnectorIT
         extends OcpConnectorTest<SqlDatabaseController>
         implements OcpKafka, OcpDB2, DB2Connector, OcpApicurio, ApicurioAvroConnectorDecorator, DB2TestCases {
-}
+}
\ No newline at end of file

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -414,6 +414,7 @@ public void shouldProperlyGetDefaultColumnValues() throws Exception {
                 // macaddr8
                 // money
                 "numeric NUMERIC(10, 5) default 12345.67891, " +
+                "numeric_var NUMERIC default 0, " +
                 // path
                 // pg_lsn
                 // point
@@ -478,6 +479,7 @@ public void shouldProperlyGetDefaultColumnValues() throws Exception {
             assertColumnDefault("jsonb", "{}", columns);
 
             assertColumnDefault("numeric", new BigDecimal("12345.67891"), columns);
+            assertColumnDefault("numeric_var", null, columns);
             assertColumnDefault("real", 1234567890.5f, columns);
             assertColumnDefault("smallint", (short) 32767, columns);
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/LegacyV1SourceInfoTest.java
Patch:
@@ -50,7 +50,8 @@ public void connectorIsPresent() {
     @Test
     @FixFor("DBZ-934")
     public void canHandleNullValues() {
-        source.update(null, null, null, null, null);
+        source.update(null, null, null, null, null, false);
+        source.update(null, null, null, null, null, true);
     }
 
     @Test

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SourceInfoTest.java
Patch:
@@ -50,7 +50,8 @@ public void connectorIsPresent() {
     @Test
     @FixFor("DBZ-934")
     public void canHandleNullValues() {
-        source.update(null, null, null, null, null);
+        source.update(null, null, null, null, null, false);
+        source.update(null, null, null, null, null, true);
     }
 
     @Test

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/processor/AbstractProcessorUnitTest.java
Patch:
@@ -41,7 +41,6 @@
 import io.debezium.connector.oracle.logminer.events.LogMinerEventRow;
 import io.debezium.connector.oracle.util.TestHelper;
 import io.debezium.embedded.AbstractConnectorTest;
-import io.debezium.jdbc.JdbcConnection;
 import io.debezium.pipeline.DataChangeEvent;
 import io.debezium.pipeline.EventDispatcher;
 import io.debezium.pipeline.source.spi.ChangeEventSource.ChangeEventSourceContext;

File: debezium-connector-mysql/src/test/java/io/debezium/relational/history/KafkaDatabaseHistoryTest.java
Patch:
@@ -232,7 +232,7 @@ public void shouldIgnoreUnparseableMessages() throws Exception {
         final ProducerRecord<String, String> invalidSQL = new ProducerRecord<>(topicName, PARTITION_NO, null,
                 "{\"source\":{\"server\":\"my-server\"},\"position\":{\"filename\":\"my-txn-file.log\",\"position\":39},\"databaseName\":\"db1\",\"ddl\":\"xxxDROP TABLE foo;\"}");
         final ProducerRecord<String, String> invalidSQLProcedure = new ProducerRecord<>(topicName, PARTITION_NO, null,
-               "{\"source\":{\"server\":\"my-server\"},\"position\":{\"filename\":\"my-txn-file.log\",\"position\":39},\"databaseName\":\"db1\",\"ddl\":\"CREATE DEFINER=`myUser`@`%` PROCEDURE `tableAFetchCount`(        in p_uniqueID int        )BEGINselect count(*) into @propCount from tableA  where uniqueID = p_uniqueID;    select count(*) into @completeCount from tableA  where uniqueID = p_uniqueID and isComplete = 1;       select  uniqueID,   @propCount as propCount, @completeCount as completeCount, @completeCount/ @propCount * 100 as completePct        where uniqueID = p_uniqueID;END\"}");
+                "{\"source\":{\"server\":\"my-server\"},\"position\":{\"filename\":\"my-txn-file.log\",\"position\":39},\"databaseName\":\"db1\",\"ddl\":\"CREATE DEFINER=`myUser`@`%` PROCEDURE `tableAFetchCount`(        in p_uniqueID int        )BEGINselect count(*) into @propCount from tableA  where uniqueID = p_uniqueID;    select count(*) into @completeCount from tableA  where uniqueID = p_uniqueID and isComplete = 1;       select  uniqueID,   @propCount as propCount, @completeCount as completeCount, @completeCount/ @propCount * 100 as completePct        where uniqueID = p_uniqueID;END\"}");
 
         final Configuration intruderConfig = Configuration.create()
                 .withDefault(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafka.brokerList())

File: debezium-core/src/main/java/io/debezium/relational/history/AbstractDatabaseHistory.java
Patch:
@@ -25,6 +25,7 @@
 import io.debezium.relational.ddl.DdlParser;
 import io.debezium.relational.history.TableChanges.TableChange;
 import io.debezium.relational.history.TableChanges.TableChangeType;
+import io.debezium.text.MultipleParsingExceptions;
 import io.debezium.text.ParsingException;
 
 /**
@@ -135,7 +136,7 @@ else if (ddl != null && ddlParser != null) {
                         ddlParser.parse(ddl, schema);
                         listener.onChangeApplied(recovered);
                     }
-                    catch (final ParsingException e) {
+                    catch (final ParsingException | MultipleParsingExceptions e) {
                         if (skipUnparseableDDL) {
                             logger.warn("Ignoring unparseable statements '{}' stored in database history: {}", ddl, e);
                         }

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/OcpKafkaConnectController.java
Patch:
@@ -71,7 +71,8 @@ public class OcpKafkaConnectController implements KafkaConnectController {
 
     public OcpKafkaConnectController(
                                      KafkaConnect kafkaConnect,
-                                     StrimziOperatorController operatorController, OpenShiftClient ocp,
+                                     StrimziOperatorController operatorController,
+                                     OpenShiftClient ocp,
                                      OkHttpClient http,
                                      boolean connectorResources) {
         this.kafkaConnect = kafkaConnect;

File: debezium-testing/debezium-testing-system/src/main/java/io/debezium/testing/system/tools/kafka/OcpKafkaConnectDeployer.java
Patch:
@@ -117,7 +117,8 @@ private OcpKafkaConnectDeployer(
                                     String yamlPath,
                                     String cfgYamlPath,
                                     boolean connectorResources,
-                                    StrimziOperatorController operatorController, boolean exposedApi,
+                                    StrimziOperatorController operatorController,
+                                    boolean exposedApi,
                                     boolean exposedMetrics,
                                     OpenShiftClient ocp,
                                     OkHttpClient http) {

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/TestUtils.java
Patch:
@@ -9,7 +9,7 @@
  * Utility functions used in tests
  * @author Jakub Cechacek
  */
-public class TestUtils {
+public final class TestUtils {
 
     private TestUtils() {
         // intentionally private

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/db2/DB2ConnectorIT.java
Patch:
@@ -10,10 +10,10 @@
 import org.junit.jupiter.api.TestInstance;
 import org.junit.jupiter.api.TestMethodOrder;
 
-import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.fixtures.connectors.Db2Connector;
 import io.debezium.testing.system.fixtures.databases.OcpDb2;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 
 /**

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mongodb/OcpMongoConnectorIT.java
Patch:
@@ -10,10 +10,10 @@
 import org.junit.jupiter.api.TestInstance;
 import org.junit.jupiter.api.TestMethodOrder;
 
-import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.fixtures.connectors.MongoConnector;
 import io.debezium.testing.system.fixtures.databases.OcpMongo;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.tools.databases.mongodb.MongoDatabaseController;
 
 /**

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mysql/OcpAvroMySqlConnectorIT.java
Patch:
@@ -10,11 +10,11 @@
 import org.junit.jupiter.api.TestInstance;
 import org.junit.jupiter.api.TestMethodOrder;
 
-import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.fixtures.connectors.MySqlConnector;
 import io.debezium.testing.system.fixtures.databases.OcpMySql;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
 import io.debezium.testing.system.fixtures.registry.OcpApicurio;
+import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 
 /**

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/mysql/OcpMySqlConnectorIT.java
Patch:
@@ -10,10 +10,10 @@
 import org.junit.jupiter.api.TestInstance;
 import org.junit.jupiter.api.TestMethodOrder;
 
-import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.fixtures.connectors.MySqlConnector;
 import io.debezium.testing.system.fixtures.databases.OcpMySql;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 
 /**

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/postgresql/OcpPostgreSqlConnectorIT.java
Patch:
@@ -10,10 +10,10 @@
 import org.junit.jupiter.api.TestInstance;
 import org.junit.jupiter.api.TestMethodOrder;
 
-import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.fixtures.connectors.PostgreSqlConnector;
 import io.debezium.testing.system.fixtures.databases.OcpPostgreSql;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 
 /**

File: debezium-testing/debezium-testing-system/src/test/java/io/debezium/testing/system/tests/sqlserver/OcpSqlServerConnectorIT.java
Patch:
@@ -10,10 +10,10 @@
 import org.junit.jupiter.api.TestInstance;
 import org.junit.jupiter.api.TestMethodOrder;
 
-import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.fixtures.connectors.SqlServerConnector;
 import io.debezium.testing.system.fixtures.databases.OcpSqlServer;
 import io.debezium.testing.system.fixtures.kafka.OcpKafka;
+import io.debezium.testing.system.tests.OcpConnectorTest;
 import io.debezium.testing.system.tools.databases.SqlDatabaseController;
 
 /**

File: debezium-testing/debezium-testing-openshift/src/main/java/io/debezium/testing/openshift/tools/kafka/OcpKafkaController.java
Patch:
@@ -37,14 +37,16 @@ public class OcpKafkaController implements KafkaController {
     private final OpenShiftClient ocp;
     private final String project;
     private final String name;
+    private final StrimziOperatorController operatorController;
 
     private Kafka kafka;
 
-    public OcpKafkaController(Kafka kafka, OpenShiftClient ocp) {
+    public OcpKafkaController(Kafka kafka, StrimziOperatorController operatorController, OpenShiftClient ocp) {
         this.kafka = kafka;
         this.name = kafka.getMetadata().getName();
         this.ocp = ocp;
         this.project = kafka.getMetadata().getNamespace();
+        this.operatorController = operatorController;
     }
 
     @Override

File: debezium-testing/debezium-testing-openshift/src/main/java/io/debezium/testing/openshift/tools/databases/SqlDatabaseClient.java
Patch:
@@ -23,7 +23,7 @@
  */
 public class SqlDatabaseClient implements DatabaseClient<Connection, SQLException> {
 
-    private static final Logger LOGGER = LoggerFactory.getLogger(AbstractOcpDatabaseController.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(SqlDatabaseClient.class);
 
     private final String url;
     private final String username;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/converters/OracleCloudEventsProvider.java
Patch:
@@ -10,9 +10,9 @@
 
 import io.debezium.connector.oracle.Module;
 import io.debezium.converters.CloudEventsMaker;
+import io.debezium.converters.CloudEventsProvider;
 import io.debezium.converters.RecordParser;
 import io.debezium.converters.SerializerType;
-import io.debezium.converters.CloudEventsProvider;
 
 /**
  * An implementation of {@link CloudEventsProvider} for Oracle.

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleSchemaMigrationIT.java
Patch:
@@ -49,13 +49,13 @@ public void beforeEach() throws Exception {
         initializeConnectorTestFramework();
         Testing.Files.delete(TestHelper.DB_HISTORY_PATH);
 
-        TestHelper.dropTables(connection, "debezium_signal", "tablea", "tableb", "\"tableC\"");
+        TestHelper.dropAllTables();
     }
 
     @After
     public void afterEach() throws Exception {
         if (connection != null) {
-            TestHelper.dropTables(connection, "tablea", "tableb", "\"tableC\"");
+            TestHelper.dropAllTables();
             connection.close();
         }
     }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleStreamingChangeEventSourceMetrics.java
Patch:
@@ -474,7 +474,8 @@ else if (currentBatchSize > batchSizeMin) {
 
         if (currentBatchSize == batchSizeMax) {
             if (!lobEnabled) {
-                LOGGER.info("The connector is now using the maximum batch size {} when querying the LogMiner view. This could be indicative of large SCN gaps", currentBatchSize);
+                LOGGER.info("The connector is now using the maximum batch size {} when querying the LogMiner view. This could be indicative of large SCN gaps",
+                        currentBatchSize);
             }
             else {
                 LOGGER.debug("The connector is now using the maximum batch size {} when querying the LogMiner view.", currentBatchSize);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleStreamingChangeEventSourceMetrics.java
Patch:
@@ -474,10 +474,10 @@ else if (currentBatchSize > batchSizeMin) {
 
         if (currentBatchSize == batchSizeMax) {
             if (!lobEnabled) {
-                LOGGER.info("LogMiner is now using the maximum batch size {}. This could be indicative of large SCN gaps", currentBatchSize);
+                LOGGER.info("The connector is now using the maximum batch size {} when querying the LogMiner view. This could be indicative of large SCN gaps", currentBatchSize);
             }
             else {
-                LOGGER.debug("LogMiner is now using the maximum batch size {}.", currentBatchSize);
+                LOGGER.debug("The connector is now using the maximum batch size {} when querying the LogMiner view.", currentBatchSize);
             }
         }
         else {

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleBlobDataTypesIT.java
Patch:
@@ -1124,7 +1124,7 @@ record = table.get(1);
             // Get streaming records
             sourceRecords = consumeRecordsByTopic(logMinerAdapter ? 3 : 2);
             table = sourceRecords.recordsForTopic(topicName("DBZ3645"));
-            assertThat(table).hasSize(3);
+            assertThat(table).hasSize(logMinerAdapter ? 3 : 2);
 
             record = table.get(0);
             after = ((Struct) record.value()).getStruct(Envelope.FieldName.AFTER);

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleClobDataTypeIT.java
Patch:
@@ -1508,7 +1508,7 @@ record = table.get(1);
             // Get streaming records
             sourceRecords = consumeRecordsByTopic(logMinerAdapter ? 3 : 2);
             table = sourceRecords.recordsForTopic(topicName("DBZ3645"));
-            assertThat(table).hasSize(3);
+            assertThat(table).hasSize(logMinerAdapter ? 3 : 2);
 
             record = table.get(0);
             after = ((Struct) record.value()).getStruct(Envelope.FieldName.AFTER);

File: debezium-testing/debezium-testing-openshift/src/main/java/io/debezium/testing/openshift/tools/databases/mongodb/OcpMongoController.java
Patch:
@@ -26,7 +26,9 @@
  *
  * @author Jakub Cechacek
  */
-public class OcpMongoController extends AbstractOcpDatabaseController<MongoDatabaseClient> {
+public class OcpMongoController
+        extends AbstractOcpDatabaseController<MongoDatabaseClient>
+        implements MongoDatabaseController {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(OcpMongoController.class);
     private static final String DB_INIT_SCRIPT_PATH_CONTAINER = "/usr/local/bin/init-inventory.sh";

File: debezium-testing/debezium-testing-openshift/src/test/java/io/debezium/testing/openshift/db2/DB2ConnectorIT.java
Patch:
@@ -25,7 +25,7 @@
 import io.debezium.testing.openshift.ConnectorTestBase;
 import io.debezium.testing.openshift.tools.ConfigProperties;
 import io.debezium.testing.openshift.tools.databases.SqlDatabaseClient;
-import io.debezium.testing.openshift.tools.databases.db2.OcpDB2Controller;
+import io.debezium.testing.openshift.tools.databases.SqlDatabaseController;
 import io.debezium.testing.openshift.tools.databases.db2.OcpDB2Deployer;
 import io.debezium.testing.openshift.tools.kafka.ConnectorConfigBuilder;
 
@@ -47,7 +47,7 @@ public class DB2ConnectorIT extends ConnectorTestBase {
 
     public static final String CONNECTOR_NAME = "inventory-connector-db2";
 
-    private static OcpDB2Controller dbController;
+    private static SqlDatabaseController dbController;
     private static OkHttpClient httpClient = new OkHttpClient();
     private static ConnectorConfigBuilder connectorConfig;
     private static String connectorName;

File: debezium-testing/debezium-testing-openshift/src/test/java/io/debezium/testing/openshift/mongodb/MongoConnectorIT.java
Patch:
@@ -25,8 +25,8 @@
 
 import io.debezium.testing.openshift.ConnectorTestBase;
 import io.debezium.testing.openshift.tools.ConfigProperties;
-import io.debezium.testing.openshift.tools.databases.mongodb.OcpMongoController;
 import io.debezium.testing.openshift.tools.databases.mongodb.MongoDatabaseClient;
+import io.debezium.testing.openshift.tools.databases.mongodb.MongoDatabaseController;
 import io.debezium.testing.openshift.tools.databases.mongodb.OcpMongoDeployer;
 import io.debezium.testing.openshift.tools.kafka.ConnectorConfigBuilder;
 
@@ -47,7 +47,7 @@ public class MongoConnectorIT extends ConnectorTestBase {
 
     public static final String CONNECTOR_NAME = "inventory-connector-mongo";
 
-    private static OcpMongoController dbController;
+    private static MongoDatabaseController dbController;
     private static ConnectorConfigBuilder connectorConfig;
     private static String connectorName;
     private static String dbServerName;

File: debezium-testing/debezium-testing-openshift/src/test/java/io/debezium/testing/openshift/mysql/MySqlConnectorIT.java
Patch:
@@ -23,8 +23,8 @@
 
 import io.debezium.testing.openshift.ConnectorTestBase;
 import io.debezium.testing.openshift.tools.ConfigProperties;
-import io.debezium.testing.openshift.tools.databases.OcpSqlDatabaseController;
 import io.debezium.testing.openshift.tools.databases.SqlDatabaseClient;
+import io.debezium.testing.openshift.tools.databases.SqlDatabaseController;
 import io.debezium.testing.openshift.tools.databases.mysql.OcpMySqlDeployer;
 import io.debezium.testing.openshift.tools.kafka.ConnectorConfigBuilder;
 
@@ -45,7 +45,7 @@ public class MySqlConnectorIT extends ConnectorTestBase {
 
     public static final String CONNECTOR_NAME = "inventory-connector-mysql";
 
-    private static OcpSqlDatabaseController dbController;
+    private static SqlDatabaseController dbController;
     private static ConnectorConfigBuilder connectorConfig;
     private static String connectorName;
     private static String dbServerName;

File: debezium-testing/debezium-testing-openshift/src/test/java/io/debezium/testing/openshift/postgresql/PostgreSqlConnectorIT.java
Patch:
@@ -24,8 +24,8 @@
 
 import io.debezium.testing.openshift.ConnectorTestBase;
 import io.debezium.testing.openshift.tools.ConfigProperties;
-import io.debezium.testing.openshift.tools.databases.OcpSqlDatabaseController;
 import io.debezium.testing.openshift.tools.databases.SqlDatabaseClient;
+import io.debezium.testing.openshift.tools.databases.SqlDatabaseController;
 import io.debezium.testing.openshift.tools.databases.postgresql.OcpPostgreSqlDeployer;
 import io.debezium.testing.openshift.tools.kafka.ConnectorConfigBuilder;
 
@@ -46,7 +46,7 @@ public class PostgreSqlConnectorIT extends ConnectorTestBase {
 
     public static final String CONNECTOR_NAME = "inventory-connector-postgresql";
 
-    private static OcpSqlDatabaseController dbController;
+    private static SqlDatabaseController dbController;
     private static ConnectorConfigBuilder connectorConfig;
     private static String connectorName;
     private static String dbServerName;

File: debezium-testing/debezium-testing-openshift/src/test/java/io/debezium/testing/openshift/sqlserver/SqlServerConnectorIT.java
Patch:
@@ -25,8 +25,8 @@
 import io.debezium.testing.openshift.ConnectorTestBase;
 import io.debezium.testing.openshift.tools.ConfigProperties;
 import io.debezium.testing.openshift.tools.databases.SqlDatabaseClient;
+import io.debezium.testing.openshift.tools.databases.SqlDatabaseController;
 import io.debezium.testing.openshift.tools.databases.sqlserver.OcpSqlServerDeployer;
-import io.debezium.testing.openshift.tools.databases.sqlserver.SqlServerController;
 import io.debezium.testing.openshift.tools.kafka.ConnectorConfigBuilder;
 
 import okhttp3.Request;
@@ -46,7 +46,7 @@ public class SqlServerConnectorIT extends ConnectorTestBase {
 
     public static final String CONNECTOR_NAME = "inventory-connector-sqlserver";
 
-    private static SqlServerController dbController;
+    private static SqlDatabaseController dbController;
     private static ConnectorConfigBuilder connectorConfig;
     private static String connectorName;
     private static String dbServerName;

File: debezium-server/debezium-server-pravega/src/main/java/io/debezium/server/pravega/PravegaChangeConsumer.java
Patch:
@@ -49,7 +49,7 @@ public class PravegaChangeConsumer extends BaseChangeConsumer implements ChangeC
     @ConfigProperty(name = PROP_SCOPE)
     String scope;
 
-    @ConfigProperty(name = PROP_TXN)
+    @ConfigProperty(name = PROP_TXN, defaultValue = "false")
     boolean txn;
 
     private ClientConfig clientConfig;

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/junit/PostgresDatabaseVersionResolver.java
Patch:
@@ -21,7 +21,7 @@ public class PostgresDatabaseVersionResolver implements DatabaseVersionResolver
     public DatabaseVersion getVersion() {
         try {
             final DatabaseMetaData metadata = TestHelper.create().connection().getMetaData();
-            return new DatabaseVersion(metadata.getDatabaseMajorVersion(), metadata.getDatabaseMajorVersion(), 0);
+            return new DatabaseVersion(metadata.getDatabaseMajorVersion(), metadata.getDatabaseMinorVersion(), 0);
         }
         catch (SQLException e) {
             throw new RuntimeException(e);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerHelper.java
Patch:
@@ -354,7 +354,8 @@ private static void flushRacLogWriters(Scn currentScn, JdbcConfiguration config,
 
     // todo use pool
     private static OracleConnection createFlushConnection(JdbcConfiguration config, String host) throws SQLException {
-        JdbcConfiguration hostConfig = JdbcConfiguration.adapt(config.edit().with(JdbcConfiguration.DATABASE, host).build());
+        JdbcConfiguration hostConfig = JdbcConfiguration.adapt(config.edit().with(JdbcConfiguration.HOSTNAME, host).build());
+        LOGGER.debug("Creating RAC flush connection to '{}:{}'", hostConfig.getHostname(), hostConfig.getPort());
         OracleConnection connection = new OracleConnection(hostConfig, () -> LogMinerHelper.class.getClassLoader());
         connection.setAutoCommit(false);
         return connection;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -88,7 +88,7 @@ public ChangeEventSourceCoordinator<MySqlOffsetContext> start(Configuration conf
 
         validateBinlogConfiguration(connectorConfig);
 
-        MySqlOffsetContext previousOffset = (MySqlOffsetContext) getPreviousOffset(new MySqlOffsetContext.Loader(connectorConfig));
+        MySqlOffsetContext previousOffset = getPreviousOffset(new MySqlOffsetContext.Loader(connectorConfig));
         if (previousOffset == null) {
             LOGGER.info("No previous offset found");
         }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlOffsetContext.java
Patch:
@@ -186,7 +186,7 @@ public static MySqlOffsetContext initial(MySqlConnectorConfig config) {
         return offset;
     }
 
-    public static class Loader implements OffsetContext.Loader {
+    public static class Loader implements OffsetContext.Loader<MySqlOffsetContext> {
 
         private final MySqlConnectorConfig connectorConfig;
 
@@ -200,7 +200,7 @@ public Loader(MySqlConnectorConfig connectorConfig) {
         }
 
         @Override
-        public OffsetContext load(Map<String, ?> offset) {
+        public MySqlOffsetContext load(Map<String, ?> offset) {
             boolean snapshot = Boolean.TRUE.equals(offset.get(SourceInfo.SNAPSHOT_KEY)) || "true".equals(offset.get(SourceInfo.SNAPSHOT_KEY));
             boolean snapshotCompleted = Boolean.TRUE.equals(offset.get(SNAPSHOT_COMPLETED_KEY)) || "true".equals(offset.get(SNAPSHOT_COMPLETED_KEY));
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/StreamingAdapter.java
Patch:
@@ -46,7 +46,7 @@ enum TableNameCaseSensitivity {
 
     HistoryRecordComparator getHistoryRecordComparator();
 
-    OffsetContext.Loader getOffsetContextLoader();
+    OffsetContext.Loader<OracleOffsetContext> getOffsetContextLoader();
 
     StreamingChangeEventSource<OracleOffsetContext> getSource(OracleConnection connection, EventDispatcher<TableId> dispatcher,
                                                               ErrorHandler errorHandler, Clock clock, OracleDatabaseSchema schema,

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerAdapter.java
Patch:
@@ -49,7 +49,7 @@ protected boolean isPositionAtOrBefore(Document recorded, Document desired) {
     }
 
     @Override
-    public OffsetContext.Loader getOffsetContextLoader() {
+    public OffsetContext.Loader<OracleOffsetContext> getOffsetContextLoader() {
         return new LogMinerOracleOffsetContextLoader(connectorConfig);
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerOracleOffsetContextLoader.java
Patch:
@@ -18,7 +18,7 @@
 /**
  * @author Chris Cranford
  */
-public class LogMinerOracleOffsetContextLoader implements OffsetContext.Loader {
+public class LogMinerOracleOffsetContextLoader implements OffsetContext.Loader<OracleOffsetContext> {
 
     private final OracleConnectorConfig connectorConfig;
 
@@ -32,7 +32,7 @@ public LogMinerOracleOffsetContextLoader(OracleConnectorConfig connectorConfig)
     }
 
     @Override
-    public OffsetContext load(Map<String, ?> offset) {
+    public OracleOffsetContext load(Map<String, ?> offset) {
         boolean snapshot = Boolean.TRUE.equals(offset.get(SourceInfo.SNAPSHOT_KEY));
         boolean snapshotCompleted = Boolean.TRUE.equals(offset.get(OracleOffsetContext.SNAPSHOT_COMPLETED_KEY));
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/xstream/XStreamAdapter.java
Patch:
@@ -60,7 +60,7 @@ public boolean isPositionAtOrBefore(Document recorded, Document desired) {
     }
 
     @Override
-    public OffsetContext.Loader getOffsetContextLoader() {
+    public OffsetContext.Loader<OracleOffsetContext> getOffsetContextLoader() {
         return new XStreamOracleOffsetContextLoader(connectorConfig);
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/xstream/XStreamOracleOffsetContextLoader.java
Patch:
@@ -20,7 +20,7 @@
  *
  * @author Chris Cranford
  */
-public class XStreamOracleOffsetContextLoader implements OffsetContext.Loader {
+public class XStreamOracleOffsetContextLoader implements OffsetContext.Loader<OracleOffsetContext> {
 
     private final OracleConnectorConfig connectorConfig;
 
@@ -34,7 +34,7 @@ public XStreamOracleOffsetContextLoader(OracleConnectorConfig connectorConfig) {
     }
 
     @Override
-    public OffsetContext load(Map<String, ?> offset) {
+    public OracleOffsetContext load(Map<String, ?> offset) {
         boolean snapshot = Boolean.TRUE.equals(offset.get(SourceInfo.SNAPSHOT_KEY));
         boolean snapshotCompleted = Boolean.TRUE.equals(offset.get(OracleOffsetContext.SNAPSHOT_COMPLETED_KEY));
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorTask.java
Patch:
@@ -93,7 +93,7 @@ public ChangeEventSourceCoordinator<PostgresOffsetContext> start(Configuration c
 
         schema = new PostgresSchema(connectorConfig, typeRegistry, topicSelector, valueConverterBuilder.build(typeRegistry));
         this.taskContext = new PostgresTaskContext(connectorConfig, schema, topicSelector);
-        final PostgresOffsetContext previousOffset = (PostgresOffsetContext) getPreviousOffset(new PostgresOffsetContext.Loader(connectorConfig));
+        final PostgresOffsetContext previousOffset = getPreviousOffset(new PostgresOffsetContext.Loader(connectorConfig));
         final Clock clock = Clock.system();
 
         LoggingContext.PreviousContext previousContext = taskContext.configureLoggingContext(CONTEXT_NAME);
@@ -197,7 +197,7 @@ public ChangeEventSourceCoordinator<PostgresOffsetContext> start(Configuration c
                     schemaNameAdjuster,
                     jdbcConnection);
 
-            ChangeEventSourceCoordinator coordinator = new PostgresChangeEventSourceCoordinator(
+            ChangeEventSourceCoordinator<PostgresOffsetContext> coordinator = new PostgresChangeEventSourceCoordinator (
                     previousOffset,
                     errorHandler,
                     PostgresConnector.class,

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresOffsetContext.java
Patch:
@@ -187,7 +187,7 @@ Long xmin() {
         return sourceInfo.xmin();
     }
 
-    public static class Loader implements OffsetContext.Loader {
+    public static class Loader implements OffsetContext.Loader<PostgresOffsetContext> {
 
         private final PostgresConnectorConfig connectorConfig;
 
@@ -207,7 +207,7 @@ private Long readOptionalLong(Map<String, ?> offset, String key) {
 
         @SuppressWarnings("unchecked")
         @Override
-        public OffsetContext load(Map<String, ?> offset) {
+        public PostgresOffsetContext load(Map<String, ?> offset) {
             final Lsn lsn = Lsn.valueOf(readOptionalLong(offset, SourceInfo.LSN_KEY));
             final Lsn lastCompletelyProcessedLsn = Lsn.valueOf(readOptionalLong(offset, LAST_COMPLETELY_PROCESSED_LSN_KEY));
             final Lsn lastCommitLsn = Lsn.valueOf(readOptionalLong(offset, LAST_COMPLETELY_PROCESSED_LSN_KEY));

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorTask.java
Patch:
@@ -83,7 +83,7 @@ public ChangeEventSourceCoordinator<SqlServerOffsetContext> start(Configuration
         this.schema = new SqlServerDatabaseSchema(connectorConfig, valueConverters, topicSelector, schemaNameAdjuster);
         this.schema.initializeStorage();
 
-        final SqlServerOffsetContext previousOffset = (SqlServerOffsetContext) getPreviousOffset(new SqlServerOffsetContext.Loader(connectorConfig));
+        final SqlServerOffsetContext previousOffset = getPreviousOffset(new SqlServerOffsetContext.Loader(connectorConfig));
         if (previousOffset != null) {
             schema.recover(previousOffset);
         }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerOffsetContext.java
Patch:
@@ -140,7 +140,7 @@ public void postSnapshotCompletion() {
         sourceInfo.setSnapshot(SnapshotRecord.FALSE);
     }
 
-    public static class Loader implements OffsetContext.Loader {
+    public static class Loader implements OffsetContext.Loader<SqlServerOffsetContext> {
 
         private final SqlServerConnectorConfig connectorConfig;
 
@@ -154,7 +154,7 @@ public Loader(SqlServerConnectorConfig connectorConfig) {
         }
 
         @Override
-        public OffsetContext load(Map<String, ?> offset) {
+        public SqlServerOffsetContext load(Map<String, ?> offset) {
             final Lsn changeLsn = Lsn.valueOf((String) offset.get(SourceInfo.CHANGE_LSN_KEY));
             final Lsn commitLsn = Lsn.valueOf((String) offset.get(SourceInfo.COMMIT_LSN_KEY));
             boolean snapshot = Boolean.TRUE.equals(offset.get(SourceInfo.SNAPSHOT_KEY));

File: debezium-core/src/main/java/io/debezium/connector/common/BaseSourceTask.java
Patch:
@@ -298,11 +298,11 @@ public void commit() throws InterruptedException {
     /**
      * Loads the connector's persistent offset (if present) via the given loader.
      */
-    protected OffsetContext getPreviousOffset(OffsetContext.Loader loader) {
+    protected O getPreviousOffset(OffsetContext.Loader<O> loader) {
         Map<String, ?> partition = loader.getPartition();
 
         if (lastOffset != null) {
-            OffsetContext offsetContext = loader.load(lastOffset);
+            O offsetContext = loader.load(lastOffset);
             LOGGER.info("Found previous offset after restart {}", offsetContext);
             return offsetContext;
         }
@@ -312,7 +312,7 @@ protected OffsetContext getPreviousOffset(OffsetContext.Loader loader) {
                 .get(partition);
 
         if (previousOffset != null) {
-            OffsetContext offsetContext = loader.load(previousOffset);
+            O offsetContext = loader.load(previousOffset);
             LOGGER.info("Found previous offset {}", offsetContext);
             return offsetContext;
         }

File: debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java
Patch:
@@ -82,7 +82,7 @@ public ChangeEventSourceCoordinator(O previousOffset, ErrorHandler errorHandler,
         this.schema = schema;
     }
 
-    public synchronized <T extends CdcSourceTaskContext> void start(T taskContext, ChangeEventQueueMetrics changeEventQueueMetrics,
+    public synchronized void start(CdcSourceTaskContext taskContext, ChangeEventQueueMetrics changeEventQueueMetrics,
                                                                     EventMetadataProvider metadataProvider) {
         AtomicReference<LoggingContext.PreviousContext> previousLogContext = new AtomicReference<>();
         try {
@@ -141,7 +141,7 @@ public synchronized <T extends CdcSourceTaskContext> void start(T taskContext, C
         }
     }
 
-    protected CatchUpStreamingResult executeCatchUpStreaming(OffsetContext previousOffset, ChangeEventSourceContext context,
+    protected CatchUpStreamingResult executeCatchUpStreaming(O previousOffset, ChangeEventSourceContext context,
                                                              SnapshotChangeEventSource<O> snapshotSource)
             throws InterruptedException {
         return new CatchUpStreamingResult(false);

File: debezium-quarkus-outbox/deployment/src/main/java/io/debezium/outbox/quarkus/deployment/DebeziumOutboxConfig.java
Patch:
@@ -71,9 +71,9 @@ public class DebeziumOutboxConfig {
     public DebeziumOutboxConfigTracingSpan tracingSpan;
 
     /**
-     * Whether or not smallrye-opentracing extension is present.
+     * smallrye-opentracing configuration option
      */
-    @ConfigItem(name = "tracing.enabled", defaultValue = "false")
+    @ConfigItem(name = "tracing.enabled", defaultValue = "true")
     public boolean tracingEnabled;
 
     @ConfigGroup

File: debezium-quarkus-outbox/deployment/src/main/java/io/debezium/outbox/quarkus/deployment/OutboxProcessor.java
Patch:
@@ -145,11 +145,9 @@ public void build(OutboxEventEntityBuildItem outboxBuildItem,
                       BuildProducer<AdditionalBeanBuildItem> additionalBeanProducer,
                       BuildProducer<GeneratedResourceBuildItem> generatedResourcesProducer,
                       BuildProducer<ReflectiveClassBuildItem> reflectiveClassProducer,
-                      BuildProducer<OutboxOpenTracingBuildItem> buildItemBuildProducer,
                       Capabilities capabilities) {
         if (debeziumOutboxConfig.tracingEnabled && capabilities.isPresent(Capability.OPENTRACING)) {
             additionalBeanProducer.produce(AdditionalBeanBuildItem.unremovableOf(DebeziumTracerEventDispatcher.class));
-            buildItemBuildProducer.produce(new OutboxOpenTracingBuildItem(true));
         }
         else {
             additionalBeanProducer.produce(AdditionalBeanBuildItem.unremovableOf(DefaultEventDispatcher.class));

File: debezium-quarkus-outbox/integration-tests/src/test/java/io/debezium/outbox/quarkus/it/OutboxProfiles.java
Patch:
@@ -23,12 +23,12 @@ public static class Default implements QuarkusTestProfile {
     }
 
     /**
-     * Enables OpenTracing support that is disabled by default.
+     * Disables OpenTracing support that is enabled by default.
      */
-    public static class OpenTracing implements QuarkusTestProfile {
+    public static class OpenTracingDisabled implements QuarkusTestProfile {
         @Override
         public Map<String, String> getConfigOverrides() {
-            return Collections.singletonMap("quarkus.debezium-outbox.tracing.enabled", "true");
+            return Collections.singletonMap("quarkus.debezium-outbox.tracing.enabled", "false");
         }
     }
 }

File: debezium-quarkus-outbox/runtime/src/main/java/io/debezium/outbox/quarkus/internal/AbstractEventDispatcher.java
Patch:
@@ -66,4 +66,4 @@ protected Map<String, Object> getDataMapFromEvent(ExportedEvent<?, ?> event) {
         dataMap.put(TIMESTAMP, event.getTimestamp());
         return dataMap;
     }
-}
\ No newline at end of file
+}

File: debezium-quarkus-outbox/runtime/src/main/java/io/debezium/outbox/quarkus/internal/DebeziumTracerEventDispatcher.java
Patch:
@@ -68,4 +68,4 @@ public void onExportedEvent(@Observes ExportedEvent<?, ?> event) {
             persist(dataMap);
         }
     }
-}
\ No newline at end of file
+}

File: debezium-quarkus-outbox/runtime/src/main/java/io/debezium/outbox/quarkus/internal/EventDispatcher.java
Patch:
@@ -1,4 +1,3 @@
-
 /*
  * Copyright Debezium Authors.
  *
@@ -24,4 +23,4 @@ public interface EventDispatcher {
      *            the exported event
      */
     void onExportedEvent(@Observes ExportedEvent<?, ?> event);
-}
\ No newline at end of file
+}

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -234,8 +234,8 @@ protected List<SchemaAndValueField> schemasAndValuesForNumericType() {
                 new SchemaAndValueField("db", Schema.OPTIONAL_FLOAT64_SCHEMA, 4.44d),
                 new SchemaAndValueField("r_int", Schema.OPTIONAL_FLOAT32_SCHEMA, 3.0f),
                 new SchemaAndValueField("db_int", Schema.OPTIONAL_FLOAT64_SCHEMA, 4.0d),
-                new SchemaAndValueField("ss", Schema.INT16_SCHEMA, (short) 1),
-                new SchemaAndValueField("bs", Schema.INT64_SCHEMA, 123L),
+                new SchemaAndValueField("ss", SchemaBuilder.int16().defaultValue((short) 0).build(), (short) 1),
+                new SchemaAndValueField("bs", SchemaBuilder.int64().defaultValue(0L).build(), 123L),
                 new SchemaAndValueField("b", Schema.OPTIONAL_BOOLEAN_SCHEMA, Boolean.TRUE),
                 new SchemaAndValueField("o", Schema.OPTIONAL_INT64_SCHEMA, 4_000_000_000L)));
         if (!DecoderDifferences.areSpecialFPValuesUnsupported()) {
@@ -923,7 +923,7 @@ protected List<SchemaAndValueField> schemasAndValuesForDomainAliasTypes(boolean
         final ByteBuffer polygonByteBuffer = ByteBuffer.wrap("((0.0,0.0),(0.0,1.0),(1.0,0.0),(0.0,0.0))".getBytes());
 
         return Arrays.asList(
-                new SchemaAndValueField(PK_FIELD, SchemaBuilder.INT32_SCHEMA, 1),
+                new SchemaAndValueField(PK_FIELD, SchemaBuilder.int32().defaultValue(0).build(), 1),
                 new SchemaAndValueField("bit_base", Bits.builder(3).build(), new byte[]{ 5 }),
                 new SchemaAndValueField("bit_alias", Bits.builder(3).build(), new byte[]{ 5 }),
                 new SchemaAndValueField("smallint_base", SchemaBuilder.INT16_SCHEMA, (short) 1),

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/OutboxEventRouterIT.java
Patch:
@@ -275,7 +275,7 @@ public void shouldSupportAllFeatures() throws Exception {
                 .field("eventVersion", Schema.INT32_SCHEMA)
                 .field("aggregateType", Schema.STRING_SCHEMA)
                 .field("someBoolType", Schema.BOOLEAN_SCHEMA)
-                .field("deleted", Schema.OPTIONAL_BOOLEAN_SCHEMA)
+                .field("deleted", SchemaBuilder.bool().optional().defaultValue(false).build())
                 .build();
 
         assertConnectSchemasAreEqual(null, eventRouted.valueSchema(), expectedSchema);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsSnapshotProducerIT.java
Patch:
@@ -480,7 +480,7 @@ public void shouldGenerateSnapshotForATableWithoutPrimaryKey() throws Exception
         consumer.await(TestHelper.waitTimeForRecords() * 30, TimeUnit.SECONDS);
 
         List<SchemaAndValueField> schemaAndValueFields = Arrays.asList(
-                new SchemaAndValueField("id", Schema.INT32_SCHEMA, 1),
+                new SchemaAndValueField("id", SchemaBuilder.int32().defaultValue(0).build(), 1),
                 new SchemaAndValueField("val", Schema.OPTIONAL_INT32_SCHEMA, 1000));
 
         consumer.process(record -> {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresDefaultValueConverter.java
Patch:
@@ -141,7 +141,7 @@ private static Map<String, DefaultValueMapper> createDefaultValueMappers() {
         return result;
     }
 
-    private String extractDefault(String defaultValue) {
+    private static String extractDefault(String defaultValue) {
         // Values are either "raw", such as `1234`, or "type casted", such as `'9223372036854775807'::bigint`.
         // If the value does NOT contain a single quote it is assumed to be a raw value. Otherwise the value is
         // extracted from inside the single quotes.

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresDefaultValueConverter.java
Patch:
@@ -107,7 +107,7 @@ private Object convertDefaultValue(Object defaultValue, Column column) {
         return defaultValue;
     }
 
-    private Map<String, DefaultValueMapper> createDefaultValueMappers() {
+    private static Map<String, DefaultValueMapper> createDefaultValueMappers() {
         final Map<String, DefaultValueMapper> result = new HashMap<>();
 
         result.put("bit", v -> {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorTaskIT.java
Patch:
@@ -6,7 +6,6 @@
 
 package io.debezium.connector.postgresql;
 
-import java.nio.charset.Charset;
 import java.sql.SQLException;
 import java.time.Duration;
 
@@ -49,8 +48,7 @@ public void retryOnFailureToCreateConnection() throws Exception {
         postgresConnectorTask.createReplicationConnection(new FakeContext(config, new PostgresSchema(
                 config,
                 null,
-                Charset.forName("UTF-8"),
-                PostgresTopicSelector.create(config))), true, true, 3, Duration.ofSeconds(2));
+                PostgresTopicSelector.create(config), null)), true, true, 3, Duration.ofSeconds(2));
 
         // Verify retry happened for 10 seconds
         long endTime = System.currentTimeMillis();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/SqlUtils.java
Patch:
@@ -290,13 +290,13 @@ static String logMinerContentsQuery(OracleConnectorConfig connectorConfig, Strin
         // MISSING_SCN/DDL only when not performed by excluded users
         // For DDL, the `INTERNAL DDL%` info rows should be excluded as these are commands executed by the database that
         // typically perform operations such as renaming a deleted object when dropped if the drop doesn't specify PURGE
-        query.append("(OPERATION_CODE IN (5,9,10,11,29,34) AND USERNAME NOT IN (").append(getExcludedUsers(logMinerUser)).append(") AND INFO NOT LIKE 'INTERNAL DDL%' ");
+        query.append("(OPERATION_CODE IN (5,11,34) AND USERNAME NOT IN (").append(getExcludedUsers(logMinerUser)).append(") AND INFO NOT LIKE 'INTERNAL DDL%' ");
         query.append("AND " + getExcludedDdlTables() + ") ");
         // COMMIT/ROLLBACK
         query.append("OR (OPERATION_CODE IN (6,7,36)) ");
         // INSERT/UPDATE/DELETE
         query.append("OR ");
-        query.append("(OPERATION_CODE IN (1,2,3) ");
+        query.append("(OPERATION_CODE IN (1,2,3,9,10,29) ");
         query.append("AND TABLE_NAME != '").append(LOGMNR_FLUSH_TABLE).append("' ");
 
         // There are some common schemas that we automatically ignore when building the filter predicates

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/SqlUtilsTest.java
Patch:
@@ -36,10 +36,10 @@ public class SqlUtilsTest {
             "XID, CSF, TABLE_NAME, SEG_OWNER, OPERATION, USERNAME, ROW_ID, ROLLBACK, RS_ID, " +
             "ORA_HASH(SCN||OPERATION||RS_ID||SEQUENCE#||RTRIM(SUBSTR(SQL_REDO,1,256))) " +
             "FROM V$LOGMNR_CONTENTS WHERE SCN > ? AND SCN <= ? AND ((" +
-            "OPERATION_CODE IN (5,9,10,11,29,34) AND USERNAME NOT IN ('SYS','SYSTEM','${user}') AND INFO NOT LIKE 'INTERNAL DDL%' " +
+            "OPERATION_CODE IN (5,11,34) AND USERNAME NOT IN ('SYS','SYSTEM','${user}') AND INFO NOT LIKE 'INTERNAL DDL%' " +
             "AND (TABLE_NAME IS NULL OR TABLE_NAME NOT LIKE 'ORA_TEMP_%')) " +
             "OR (OPERATION_CODE IN (6,7,36)) " +
-            "OR (OPERATION_CODE IN (1,2,3) " +
+            "OR (OPERATION_CODE IN (1,2,3,9,10,29) " +
             "AND TABLE_NAME != '" + SqlUtils.LOGMNR_FLUSH_TABLE + "' " +
             "${systemTablePredicate}" +
             "${schemaPredicate}" +

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleValueConverters.java
Patch:
@@ -140,7 +140,7 @@ public SchemaBuilder schemaBuilder(Column column) {
                 return SchemaBuilder.string();
             default: {
                 SchemaBuilder builder = super.schemaBuilder(column);
-                logger.debug("JdbcValueConverters returned '{}' for column '{}'", builder.getClass().getName(), column.name());
+                logger.debug("JdbcValueConverters returned '{}' for column '{}'", builder != null ? builder.getClass().getName() : null, column.name());
                 return builder;
             }
         }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -100,7 +100,7 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
                     + "which means the connector will hold an exclusive table lock (prevents any updates) for just the initial portion of the snapshot "
                     + "while the database schemas and other metadata are being read. The remaining work in a snapshot involves selecting all rows from "
                     + "each table, and this is done using a flashback query that requires no locks. However, in some cases it may be desirable to allow "
-                    + "concurrent access to the table but prevent locking the entire table; in such ases set this property to 'shared'. Using a value of "
+                    + "concurrent access to the table but prevent locking the entire table; in such cases set this property to 'shared'. Using a value of "
                     + "'none' will prevent the connector from acquiring any locks during the snapshot process. This mode is only safe to use if no schema "
                     + "changes are happening while the snapshot is taken.");
 

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/TransactionalBufferTest.java
Patch:
@@ -64,7 +64,7 @@ public class TransactionalBufferTest {
     private static final TableId TABLE_ID = new TableId(TestHelper.SERVER_NAME, "DEBEZIUM", "TEST");
     private static final String ROW_ID = "AAABCD871DFAA";
     private static final String OTHER_ROW_ID = "BAABCD871DFAA";
-    private static final LogMinerDmlEntry DML_ENTRY = new LogMinerDmlEntryImpl(RowMapper.INSERT, Collections.emptyList(), Collections.emptyList());
+    private static final LogMinerDmlEntry DML_ENTRY = LogMinerDmlEntryImpl.forInsert(Collections.emptyList());
 
     private static final Configuration config = new Configuration() {
         @Override

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/ValueHolderTest.java
Patch:
@@ -11,7 +11,6 @@
 import java.math.BigInteger;
 import java.sql.Timestamp;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.List;
 
 import org.junit.Before;
@@ -75,7 +74,7 @@ public void testValueHolders() throws Exception {
         List<LogMinerColumnValue> newValues = new ArrayList<>();
         newValues.add(column1);
         newValues.add(column2);
-        LogMinerDmlEntryImpl dmlEntryExpected = new LogMinerDmlEntryImpl(RowMapper.INSERT, newValues, Collections.emptyList());
+        LogMinerDmlEntry dmlEntryExpected = LogMinerDmlEntryImpl.forInsert(newValues);
         dmlEntryExpected.setTransactionId("transaction_id");
         dmlEntryExpected.setObjectName(TABLE_NAME);
         dmlEntryExpected.setObjectOwner(SCHEMA_NAME);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -152,7 +152,8 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
             .withWidth(Width.SHORT)
             .withImportance(Importance.MEDIUM)
             .withDefault(0)
-            .withDescription("When supplying a log.mining.history.recorder.class, this option specifies the number of hours the recorder should keep the history recorder.  The default, 0, indicates that no history should be retained.");
+            .withDescription(
+                    "When supplying a log.mining.history.recorder.class, this option specifies the number of hours the recorder should keep the history.  The default, 0, indicates that no history should be retained.");
 
     public static final Field LOG_MINING_TRANSACTION_RETENTION = Field.create("log.mining.transaction.retention.hours")
             .withDisplayName("Log Mining long running transaction retention")

File: debezium-microbenchmark-oracle/src/main/java/io/debezium/performance/connector/oracle/EndToEndPerf.java
Patch:
@@ -105,6 +105,7 @@ public void doSetup() {
             }
             try {
                 connection.execute("CREATE TABLE debezium.test (id numeric(9,0) primary key, name varchar2(50))");
+                connection.execute("ALTER TABLE debezium.test add supplemental log data (all) columns");
             }
             catch (SQLException e) {
                 throw new RuntimeException("Failed to create table", e);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/xstream/LcrEventHandler.java
Patch:
@@ -256,7 +256,8 @@ public void processChunk(ChunkColumnValue chunk) throws StreamsException {
                             break;
 
                         default:
-                            throw new DebeziumException("An unsupported chunk type '" + type + "' for column '" + columnName + "'");
+                            LOGGER.trace("Received an unsupported chunk type '{}' for column '{}', ignored.", type, columnName);
+                            break;
                     }
                 }
 

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/AbstractOracleDatatypesTest.java
Patch:
@@ -233,8 +233,8 @@ public abstract class AbstractOracleDatatypesTest extends AbstractConnectorTest
             new SchemaAndValueField("VAL_INT_YTM", MicroDuration.builder().optional().build(), -110451600_000_000L),
             new SchemaAndValueField("VAL_INT_DTS", MicroDuration.builder().optional().build(), -93784_560_000L));
 
-    private static final String CLOB_JSON = Testing.Files.readResourceAsString("data/test_clob_data.json");
-    private static final String NCLOB_JSON = Testing.Files.readResourceAsString("data/test_clob_data2.json");
+    private static final String CLOB_JSON = Testing.Files.readResourceAsString("data/test_lob_data.json");
+    private static final String NCLOB_JSON = Testing.Files.readResourceAsString("data/test_lob_data2.json");
 
     private static final List<SchemaAndValueField> EXPECTED_CLOB = Arrays.asList(
             new SchemaAndValueField("VAL_CLOB_INLINE", Schema.OPTIONAL_STRING_SCHEMA, "TestClob123"),

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/ValueHolderTest.java
Patch:
@@ -10,7 +10,6 @@
 import java.math.BigDecimal;
 import java.math.BigInteger;
 import java.sql.Timestamp;
-import java.sql.Types;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;

File: debezium-core/src/test/java/io/debezium/pipeline/source/snapshot/incremental/SignalBasedSnapshotChangeEventSourceTest.java
Patch:
@@ -53,11 +53,11 @@ public void testBuildQuery() {
         final Column val2 = Column.editor().name("val2").create();
         final Table table = Table.editor().tableId(new TableId(null, "s1", "table1")).addColumn(pk1).addColumn(pk2)
                 .addColumn(val1).addColumn(val2).setPrimaryKeyNames("pk1", "pk2").create();
-        Assertions.assertThat(source.buildChunkQuery(table)).isEqualTo("SELECT * FROM s1.table1 ORDER BY pk1, pk2 LIMIT 1024");
+        Assertions.assertThat(source.buildChunkQuery(table)).isEqualTo("SELECT * FROM \"s1\".\"table1\" ORDER BY pk1, pk2 LIMIT 1024");
         context.nextChunkPosition(new Object[]{ 1, 5 });
         context.maximumKey(new Object[]{ 10, 50 });
         Assertions.assertThat(source.buildChunkQuery(table)).isEqualTo(
-                "SELECT * FROM s1.table1 WHERE pk1 >= ? AND pk2 >= ? AND NOT (pk1 = ? AND pk2 = ?) AND pk1 <= ? AND pk2 <= ? ORDER BY pk1, pk2 LIMIT 1024");
+                "SELECT * FROM \"s1\".\"table1\" WHERE pk1 >= ? AND pk2 >= ? AND NOT (pk1 = ? AND pk2 = ?) AND pk1 <= ? AND pk2 <= ? ORDER BY pk1, pk2 LIMIT 1024");
     }
 
     @Test
@@ -70,6 +70,6 @@ public void testMaxQuery() {
         final Column val2 = Column.editor().name("val2").create();
         final Table table = Table.editor().tableId(new TableId(null, "s1", "table1")).addColumn(pk1).addColumn(pk2)
                 .addColumn(val1).addColumn(val2).setPrimaryKeyNames("pk1", "pk2").create();
-        Assertions.assertThat(source.buildMaxPrimaryKeyQuery(table)).isEqualTo("SELECT * FROM s1.table1 ORDER BY pk1 DESC, pk2 DESC LIMIT 1");
+        Assertions.assertThat(source.buildMaxPrimaryKeyQuery(table)).isEqualTo("SELECT * FROM \"s1\".\"table1\" ORDER BY pk1 DESC, pk2 DESC LIMIT 1");
     }
 }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleSchemaMigrationIT.java
Patch:
@@ -1076,7 +1076,7 @@ public void shouldNotEmitDdlEventsForNonTableObjects() throws Exception {
                 Awaitility.await()
                         .atMost(TestHelper.defaultMessageConsumerPollTimeout(), TimeUnit.SECONDS)
                         .until(() -> {
-                            if (logInterceptor.countOccurrences("Processing DDL event ") == expected) {
+                            if (logInterceptor.countOccurrences("DDL: ") == expected) {
                                 return true;
                             }
                             return false;

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorFilterIT.java
Patch:
@@ -278,7 +278,7 @@ public void shouldApplyColumnExcludeListConfiguration() throws Exception {
             // Start streaming & wait for it
             waitForStreamingRunning(TestHelper.CONNECTOR_NAME, TestHelper.SERVER_NAME);
 
-            connection.execute("INSERT INTO debezium.table4 VALUES (2, 'Text-2', TO_DATE('1990-12-31'))");
+            connection.execute("INSERT INTO debezium.table4 VALUES (2, 'Text-2', TO_DATE('1990-12-31', 'yyyy-mm-dd'))");
             connection.execute("COMMIT");
 
             records = consumeRecordsByTopic(1);

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/TransactionMetadataIT.java
Patch:
@@ -103,7 +103,7 @@ public void transactionMetadata() throws Exception {
         waitForSnapshotToBeCompleted(TestHelper.CONNECTOR_NAME, TestHelper.SERVER_NAME);
 
         connection.executeWithoutCommitting("INSERT INTO debezium.customer VALUES (1, 'Billie-Bob', 1234.56, TO_DATE('2018/02/22', 'yyyy-mm-dd'))");
-        connection.executeWithoutCommitting("INSERT INTO debezium.orders VALUES (1, '01-FEB-2021', 1001, 1, 102)");
+        connection.executeWithoutCommitting("INSERT INTO debezium.orders VALUES (1, TO_DATE('2021-02-01', 'yyyy-mm-dd'), 1001, 1, 102)");
         connection.execute("COMMIT");
 
         // TX BEGIN, insert x2, TX END
@@ -163,8 +163,8 @@ public void transactionMetadataMultipleTransactions() throws Exception {
 
             // Create multiple transaction commits, notice commit order
             connection.executeWithoutCommitting("INSERT INTO debezium.customer VALUES (1, 'Billie-Bob', 1234.56, TO_DATE('2018/02/22', 'yyyy-mm-dd'))");
-            connection.executeWithoutCommitting("INSERT INTO debezium.orders VALUES (2, '01-FEB-2021', 1001, 2, 102)");
-            secondaryConn.executeWithoutCommitting("INSERT INTO debezium.orders VALUES (1, '01-FEB-2021', 1001, 1, 102)");
+            connection.executeWithoutCommitting("INSERT INTO debezium.orders VALUES (2, TO_DATE('2021-02-01', 'yyyy-mm-dd'), 1001, 2, 102)");
+            secondaryConn.executeWithoutCommitting("INSERT INTO debezium.orders VALUES (1, TO_DATE('2021-02-01', 'yyyy-mm-dd'), 1001, 1, 102)");
             secondaryConn.execute("COMMIT");
             connection.execute("COMMIT");
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -1124,7 +1124,8 @@ protected SourceInfoStructMaker<? extends AbstractSourceInfo> getSourceInfoStruc
                     HSTORE_HANDLING_MODE,
                     BINARY_HANDLING_MODE,
                     INTERVAL_HANDLING_MODE,
-                    SCHEMA_REFRESH_MODE)
+                    SCHEMA_REFRESH_MODE,
+                    INCREMENTAL_SNAPSHOT_CHUNK_SIZE)
             .excluding(INCLUDE_SCHEMA_CHANGES)
             .create();
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorTask.java
Patch:
@@ -187,7 +187,8 @@ public ChangeEventSourceCoordinator start(Configuration config) {
                     PostgresChangeRecordEmitter::updateSchema,
                     metadataProvider,
                     heartbeat,
-                    schemaNameAdjuster);
+                    schemaNameAdjuster,
+                    jdbcConnection);
 
             ChangeEventSourceCoordinator coordinator = new PostgresChangeEventSourceCoordinator(
                     previousOffset,

File: debezium-core/src/main/java/io/debezium/relational/RelationalSnapshotChangeEventSource.java
Patch:
@@ -57,7 +57,7 @@ public abstract class RelationalSnapshotChangeEventSource extends AbstractSnapsh
     /**
      * Interval for showing a log statement with the progress while scanning a single table.
      */
-    private static final Duration LOG_INTERVAL = Duration.ofMillis(10_000);
+    public static final Duration LOG_INTERVAL = Duration.ofMillis(10_000);
 
     private final RelationalDatabaseConnectorConfig connectorConfig;
     private final OffsetContext previousOffset;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -566,6 +566,7 @@ public String getImplementationName() {
         };
 
         public abstract String getConnectionUrl();
+
         public abstract String getImplementationName();
 
         private final String value;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSnapshotChangeEventSource.java
Patch:
@@ -17,7 +17,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import io.debezium.connector.oracle.logminer.LogMinerHelper;
 import io.debezium.pipeline.EventDispatcher;
 import io.debezium.pipeline.source.spi.SnapshotProgressListener;
 import io.debezium.pipeline.source.spi.StreamingChangeEventSource;

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/SourceInfoTest.java
Patch:
@@ -55,6 +55,7 @@ public void schemaIsCorrect() {
                 .field("ts_ms", Schema.INT64_SCHEMA)
                 .field("snapshot", AbstractSourceInfoStructMaker.SNAPSHOT_RECORD_SCHEMA)
                 .field("db", Schema.STRING_SCHEMA)
+                .field("sequence", Schema.OPTIONAL_STRING_SCHEMA)
                 .field("schema", Schema.STRING_SCHEMA)
                 .field("table", Schema.STRING_SCHEMA)
                 .field("txId", Schema.OPTIONAL_STRING_SCHEMA)

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -1372,6 +1372,7 @@ public void shouldReadTableUniqueIndicesWithCharactersThatRequireExplicitQuotes(
 
             final Configuration config = TestHelper.defaultConfig()
                     .with(OracleConnectorConfig.SNAPSHOT_MODE, OracleConnectorConfig.SnapshotMode.INITIAL)
+                    .with(OracleConnectorConfig.TABLE_INCLUDE_LIST, "DEBEZIUM\\.\\#T70_Sid\\:582003931_1_ConnConne")
                     .build();
 
             start(OracleConnector.class, config);
@@ -1399,6 +1400,7 @@ public void testSnapshotCompletesWithSystemGeneratedUniqueIndexOnKeylessTable()
 
             final Configuration config = TestHelper.defaultConfig()
                     .with(OracleConnectorConfig.SNAPSHOT_MODE, SnapshotMode.INITIAL)
+                    .with(OracleConnectorConfig.TABLE_INCLUDE_LIST, "DEBEZIUM\\.XML_TABLE")
                     .build();
 
             start(OracleConnector.class, config);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleValueConverters.java
Patch:
@@ -243,7 +243,7 @@ protected Object convertString(Column column, Field fieldDefn, Object data) {
             try {
                 Clob clob = (Clob) data;
                 // Note that java.sql.Clob specifies that the first character starts at 1
-                // and that length must be greater-than or equal to 0.  So for an empty
+                // and that length must be greater-than or equal to 0. So for an empty
                 // clob field, a call to getSubString(1, 0) is perfectly valid.
                 return clob.getSubString(1, (int) clob.length());
             }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/HistoryRecorder.java
Patch:
@@ -8,6 +8,7 @@
 import java.sql.Timestamp;
 
 import io.debezium.common.annotation.Incubating;
+import io.debezium.connector.oracle.OracleStreamingChangeEventSourceMetrics;
 import io.debezium.connector.oracle.Scn;
 import io.debezium.jdbc.JdbcConfiguration;
 
@@ -19,11 +20,11 @@ public interface HistoryRecorder extends AutoCloseable {
     /**
      * Prepares the history recorder
      *
-     * @param metrics the LogMiner jmx metrics
+     * @param streamingMetrics the streaming metrics
      * @param jdbcConfiguration the jdbc configuration
      * @param retentionHours the history retention hours
      */
-    void prepare(LogMinerMetrics metrics, JdbcConfiguration jdbcConfiguration, long retentionHours);
+    void prepare(OracleStreamingChangeEventSourceMetrics streamingMetrics, JdbcConfiguration jdbcConfiguration, long retentionHours);
 
     /**
      * Records the LogMiner entry.

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/NeverHistoryRecorder.java
Patch:
@@ -7,6 +7,7 @@
 
 import java.sql.Timestamp;
 
+import io.debezium.connector.oracle.OracleStreamingChangeEventSourceMetrics;
 import io.debezium.connector.oracle.Scn;
 import io.debezium.jdbc.JdbcConfiguration;
 
@@ -17,7 +18,7 @@
  */
 public class NeverHistoryRecorder implements HistoryRecorder {
     @Override
-    public void prepare(LogMinerMetrics metrics, JdbcConfiguration jdbcConfiguration, long retentionHours) {
+    public void prepare(OracleStreamingChangeEventSourceMetrics streamingMetrics, JdbcConfiguration jdbcConfiguration, long retentionHours) {
     }
 
     @Override

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/ValueHolderTest.java
Patch:
@@ -86,7 +86,7 @@ public void testValueHolders() throws Exception {
         ddlParser.parse(createStatement, tables);
 
         String dml = "insert into \"" + FULL_TABLE_NAME + "\"  (\"column1\",\"column2\") values ('5','Text');";
-        LogMinerDmlEntry dmlEntryParsed = sqlDmlParser.parse(dml, tables, TABLE_ID, "1");
+        LogMinerDmlEntry dmlEntryParsed = sqlDmlParser.parse(dml, tables.forTable(TABLE_ID), "1");
 
         assertThat(dmlEntryParsed.equals(dmlEntryExpected)).isTrue();
         assertThat(dmlEntryExpected.getCommandType() == Envelope.Operation.CREATE).isTrue();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSnapshotChangeEventSource.java
Patch:
@@ -244,7 +244,7 @@ protected void readTableStructure(ChangeEventSourceContext sourceContext, Relati
 
     @Override
     protected String enhanceOverriddenSelect(RelationalSnapshotContext snapshotContext, String overriddenSelect, TableId tableId) {
-        long snapshotOffset = (Long) snapshotContext.offset.getOffset().get("scn");
+        String snapshotOffset = (String) snapshotContext.offset.getOffset().get(SourceInfo.SCN_KEY);
         String token = connectorConfig.getTokenToReplaceInSnapshotPredicate();
         if (token != null) {
             return overriddenSelect.replaceAll(token, " AS OF SCN " + snapshotOffset);

File: debezium-core/src/test/java/io/debezium/relational/TableSchemaBuilderTest.java
Patch:
@@ -61,7 +61,7 @@ public class TableSchemaBuilderTest {
 
     @Before
     public void beforeEach() {
-        adjuster = SchemaNameAdjuster.create((original, replacement, conflict) -> {
+        adjuster = SchemaNameAdjuster.create("_", (original, replacement, conflict) -> {
             fail("Should not have come across an invalid schema name");
         });
         schema = null;

File: debezium-core/src/test/java/io/debezium/util/SchemaNameAdjusterTest.java
Patch:
@@ -56,7 +56,7 @@ public void shouldReportReplacementEveryTime() {
             }
             counter.incrementAndGet();
         };
-        SchemaNameAdjuster adjuster = SchemaNameAdjuster.create(handler);
+        SchemaNameAdjuster adjuster = SchemaNameAdjuster.create("_", handler);
         for (int i = 0; i != 20; ++i) {
             adjuster.adjust("some-invalid-fullname$");
         }
@@ -74,7 +74,7 @@ public void shouldReportReplacementOnlyOnce() {
             }
             counter.incrementAndGet();
         };
-        SchemaNameAdjuster adjuster = SchemaNameAdjuster.create(handler.firstTimeOnly());
+        SchemaNameAdjuster adjuster = SchemaNameAdjuster.create("_", handler.firstTimeOnly());
         for (int i = 0; i != 20; ++i) {
             adjuster.adjust("some-invalid-fullname$");
         }
@@ -92,7 +92,7 @@ public void shouldReportConflictReplacement() {
             }
             counter.incrementAndGet();
         };
-        SchemaNameAdjuster adjuster = SchemaNameAdjuster.create(handler.firstTimeOnly());
+        SchemaNameAdjuster adjuster = SchemaNameAdjuster.create("_", handler.firstTimeOnly());
         adjuster.adjust("some-invalid-fullname$");
         adjuster.adjust("some-invalid%fullname_");
         assertThat(counter.get()).isEqualTo(2);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -994,6 +994,7 @@ public MySqlConnectorConfig(Configuration config) {
                 config.getString(SERVER_NAME),
                 TableFilter.fromPredicate(MySqlConnectorConfig::isNotBuiltInTable),
                 true,
+                DEFAULT_SNAPSHOT_FETCH_SIZE,
                 ColumnFilterMode.CATALOG);
 
         this.config = config;

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -681,7 +681,7 @@ private static boolean isUsingAvroConverter(Configuration config) {
                 || APICURIO_AVRO_CONVERTER.equals(keyConverter) || APICURIO_AVRO_CONVERTER.equals(valueConverter);
     }
 
-    protected static int validateServerNameIsDifferentFromHistoryTopicName(Configuration config, Field field, ValidationOutput problems) {
+    public static int validateServerNameIsDifferentFromHistoryTopicName(Configuration config, Field field, ValidationOutput problems) {
         String serverName = config.getString(field);
         String historyTopicName = config.getString(KafkaDatabaseHistory.TOPIC);
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/parser/LogMinerDmlParser.java
Patch:
@@ -410,7 +410,7 @@ else if (inColumnValue && !inSingleQuote) {
                 else if (c == ')' && nested > 0) {
                     nested--;
                 }
-                else if ((c == ',' || c == ' ') && nested == 0) {
+                else if ((c == ',' || c == ' ' || c == ';') && nested == 0) {
                     String value = sql.substring(start, index);
                     if (value.equals(NULL) || value.equals(UNSUPPORTED_TYPE)) {
                         columnValues.add(null);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/SqlUtils.java
Patch:
@@ -230,7 +230,7 @@ static String logMinerContentsQuery(OracleConnectorConfig connectorConfig, Strin
         query.append("(OPERATION_CODE IN (5,34) AND USERNAME NOT IN (").append(getExcludedUsers(logMinerUser)).append(")) ");
         // COMMIT/ROLLBACK
         query.append("OR (OPERATION_CODE IN (7,36)) ");
-        // INSERT/UPDATE/DELETE/DDL
+        // INSERT/UPDATE/DELETE
         query.append("OR ");
         query.append("(OPERATION_CODE IN (1,2,3) ");
         query.append("AND TABLE_NAME != '").append(LOGMNR_FLUSH_TABLE).append("' ");

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbErrorHandler.java
Patch:
@@ -24,7 +24,9 @@ protected boolean isRetriable(Throwable throwable) {
         if (throwable instanceof org.apache.kafka.connect.errors.ConnectException) {
             Throwable cause = throwable.getCause();
             while ((cause != null) && (cause != throwable)) {
-                if (cause instanceof com.mongodb.MongoSocketException) {
+                if (cause instanceof com.mongodb.MongoSocketException ||
+                        cause instanceof com.mongodb.MongoTimeoutException ||
+                        cause instanceof com.mongodb.MongoExecutionTimeoutException) {
                     return true;
                 }
                 else {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerQueryResultProcessor.java
Patch:
@@ -209,7 +209,7 @@ int processResult(ResultSet resultSet) {
                         // update SCN in offset context only if processed SCN less than SCN among other transactions
                         if (smallestScn == null || scn.compareTo(smallestScn) < 0) {
                             offsetContext.setScn(scn.longValue());
-                            transactionalBufferMetrics.setOldestScn(scn.longValue());
+                            transactionalBufferMetrics.setOldestScn(scn);
                         }
                         offsetContext.setTransactionId(txId);
                         offsetContext.setSourceTime(timestamp.toInstant());

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/SqlUtils.java
Patch:
@@ -160,7 +160,7 @@ public static String allOnlineLogsQuery() {
      * @param archiveLogRetention duration archive logs will be mined
      * @return query
      */
-    public static String archiveLogsQuery(Long scn, Duration archiveLogRetention) {
+    public static String archiveLogsQuery(Scn scn, Duration archiveLogRetention) {
         if (!archiveLogRetention.isNegative() && !archiveLogRetention.isZero()) {
             return String.format("SELECT NAME AS FILE_NAME, NEXT_CHANGE# AS NEXT_CHANGE, FIRST_CHANGE# AS FIRST_CHANGE FROM %s " +
                     " WHERE NAME IS NOT NULL AND FIRST_TIME >= SYSDATE - (%d/24) AND ARCHIVED = 'YES' " +
@@ -179,7 +179,7 @@ public static String archiveLogsQuery(Long scn, Duration archiveLogRetention) {
      * @param strategy Log Mining strategy
      * @return statement todo: handle corruption. STATUS (Double) — value of 0 indicates it is executable
      */
-    static String startLogMinerStatement(Long startScn, Long endScn, OracleConnectorConfig.LogMiningStrategy strategy, boolean isContinuousMining) {
+    static String startLogMinerStatement(Scn startScn, Scn endScn, OracleConnectorConfig.LogMiningStrategy strategy, boolean isContinuousMining) {
         String miningStrategy;
         if (strategy.equals(OracleConnectorConfig.LogMiningStrategy.CATALOG_IN_REDO)) {
             miningStrategy = "DBMS_LOGMNR.DICT_FROM_REDO_LOGS + DBMS_LOGMNR.DDL_DICT_TRACKING ";

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/TransactionalBuffer.java
Patch:
@@ -181,8 +181,8 @@ private void commit(ChangeEventSource.ChangeEventSourceContext context, OracleOf
             metrics.incrementCommittedTransactions();
             metrics.setActiveTransactions(transactions.size());
             metrics.incrementCommittedDmlCounter(commitCallbacks.size());
-            metrics.setCommittedScn(scn.longValue());
-            metrics.setOffsetScn(offsetContext.getScn());
+            metrics.setCommittedScn(scn);
+            metrics.setOffsetScn(Scn.valueOf(offsetContext.getScn()));
             metrics.setLastCommitDuration(Duration.between(start, Instant.now()).toMillis());
         }
     }
@@ -261,7 +261,7 @@ private Scn calculateSmallestScn() {
                         .map(transaction -> transaction.firstScn)
                         .min(Scn::compareTo)
                         .orElseThrow(() -> new DataException("Cannot calculate smallest SCN"));
-        metrics.setOldestScn(scn == null ? -1 : scn.longValue());
+        metrics.setOldestScn(scn == null ? Scn.INVALID : scn);
         return scn;
     }
 

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerMetricsTest.java
Patch:
@@ -48,7 +48,7 @@ public void testMetrics() {
         metrics.setLastCapturedDmlCount(1);
         assertThat(metrics.getTotalCapturedDmlCount() == 1).isTrue();
 
-        metrics.setCurrentScn(1000L);
+        metrics.setCurrentScn(Scn.valueOf(1000L));
         assertThat(metrics.getCurrentScn()).isEqualTo(1000L);
 
         metrics.setBatchSize(10);

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/TransactionalBufferMetricsTest.java
Patch:
@@ -132,10 +132,10 @@ public void testOtherMetrics() {
         assertThat(metrics.getAbandonedTransactionIds().size()).isEqualTo(1);
         assertThat(metrics.getAbandonedTransactionIds().contains("abandoned id")).isTrue();
 
-        metrics.setOldestScn(10L);
+        metrics.setOldestScn(Scn.valueOf(10L));
         assertThat(metrics.getOldestScn()).isEqualTo(10);
 
-        metrics.setCommittedScn(10L);
+        metrics.setCommittedScn(Scn.valueOf(10L));
         assertThat(metrics.getCommittedScn()).isEqualTo(10);
 
         assertThat(metrics.toString().contains("registeredDmlCounter=1000")).isTrue();
@@ -146,7 +146,7 @@ public void testOtherMetrics() {
         metrics.setLastCommitDuration(50L);
         assertThat(metrics.getMaxCommitDuration()).isEqualTo(100L);
 
-        metrics.setOffsetScn(10L);
+        metrics.setOffsetScn(Scn.valueOf(10L));
         assertThat(metrics.getOldestScn() == 10).isTrue();
     }
 }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/ValueHolderTest.java
Patch:
@@ -39,6 +39,7 @@
 
 @SkipWhenAdapterNameIsNot(value = AdapterName.LOGMINER)
 public class ValueHolderTest {
+    private static final Scn SCN_ONE = new Scn(BigDecimal.ONE);
     private static final String TABLE_NAME = "TEST";
     private static final String CATALOG_NAME = "CATALOG";
     private static final String SCHEMA_NAME = "DEBEZIUM";
@@ -76,7 +77,7 @@ public void testValueHolders() throws Exception {
         dmlEntryExpected.setTransactionId("transaction_id");
         dmlEntryExpected.setObjectName(TABLE_NAME);
         dmlEntryExpected.setObjectOwner(SCHEMA_NAME);
-        dmlEntryExpected.setScn(Scn.ONE);
+        dmlEntryExpected.setScn(SCN_ONE);
         dmlEntryExpected.setSourceTime(new Timestamp(1000));
 
         String createStatement = IoUtil.read(IoUtil.getResourceAsStream("ddl/create_small_table.sql", null, getClass(), null, null));
@@ -87,7 +88,7 @@ public void testValueHolders() throws Exception {
 
         assertThat(dmlEntryParsed.equals(dmlEntryExpected)).isTrue();
         assertThat(dmlEntryExpected.getCommandType() == Envelope.Operation.CREATE).isTrue();
-        assertThat(dmlEntryExpected.getScn().equals(Scn.ONE)).isTrue();
+        assertThat(dmlEntryExpected.getScn().equals(SCN_ONE)).isTrue();
         assertThat(dmlEntryExpected.getSourceTime().equals(new Timestamp(1000))).isTrue();
         assertThat(dmlEntryExpected.getTransactionId().equals("transaction_id")).isTrue();
         assertThat(dmlEntryExpected.getObjectOwner().equals(SCHEMA_NAME)).isTrue();

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/SignalsIT.java
Patch:
@@ -26,7 +26,7 @@
 import io.debezium.util.Testing;
 
 /**
- * Integration test to check transaction metadata.
+ * Integration test for signaling schema changes.
  *
  * @author Jiri Pechanec
  */

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -157,6 +157,9 @@ protected void initPublication() {
                                     try {
                                         Set<TableId> tablesToCapture = determineCapturedTables();
                                         tableFilterString = tablesToCapture.stream().map(TableId::toDoubleQuotedString).collect(Collectors.joining(", "));
+                                        if (tableFilterString.isEmpty()) {
+                                            throw new DebeziumException(String.format("No table filters found for filtered publication %s", publicationName));
+                                        }
                                         createPublicationStmt = String.format("CREATE PUBLICATION %s FOR TABLE %s;", publicationName, tableFilterString);
                                         LOGGER.info("Creating Publication with statement '{}'", createPublicationStmt);
                                         // Publication doesn't exist, create it but restrict to the tableFilter.

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/util/TestHelper.java
Patch:
@@ -335,6 +335,6 @@ public static int defaultMessageConsumerPollTimeout() {
 
     public static OracleConnectorConfig.ConnectorAdapter adapter() {
         final String s = System.getProperty(OracleConnectorConfig.CONNECTOR_ADAPTER.name());
-        return (s == null || s.length() == 0) ? OracleConnectorConfig.ConnectorAdapter.XSTREAM : OracleConnectorConfig.ConnectorAdapter.parse(s);
+        return (s == null || s.length() == 0) ? OracleConnectorConfig.ConnectorAdapter.LOG_MINER : OracleConnectorConfig.ConnectorAdapter.parse(s);
     }
 }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerMetricsTest.java
Patch:
@@ -111,7 +111,7 @@ public void testMetrics() {
         metrics.setLastDurationOfBatchProcessing(Duration.ZERO);
         assertThat(metrics.getLastBatchProcessingThroughput()).isEqualTo(0);
 
-        assertThat(metrics.getHoursToKeepTransactionInBuffer()).isEqualTo(4);
+        assertThat(metrics.getHoursToKeepTransactionInBuffer()).isEqualTo(0);
 
         metrics.setRedoLogStatus(Collections.singletonMap("name", "current"));
         assertThat(metrics.getRedoLogStatus()[0].equals("name | current")).isTrue();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleDatabaseSchema.java
Patch:
@@ -32,7 +32,7 @@ public class OracleDatabaseSchema extends HistorizedRelationalDatabaseSchema {
 
     public OracleDatabaseSchema(OracleConnectorConfig connectorConfig, SchemaNameAdjuster schemaNameAdjuster, TopicSelector<TableId> topicSelector,
                                 OracleConnection connection) {
-        super(connectorConfig, topicSelector, connectorConfig.getTableFilters().dataCollectionFilter(), null,
+        super(connectorConfig, topicSelector, connectorConfig.getTableFilters().dataCollectionFilter(), connectorConfig.getColumnFilter(),
                 new TableSchemaBuilder(
                         new OracleValueConverters(connectorConfig, connection),
                         schemaNameAdjuster,

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/xstream/LcrEventHandler.java
Patch:
@@ -128,12 +128,11 @@ private void dispatchSchemaChangeEvent(DDLLCR ddlLcr) throws InterruptedExceptio
     }
 
     private TableId getTableId(LCR lcr) {
-        final String sourceDatabaseName = lcr.getSourceDatabaseName().split("\\.")[0];
         if (!this.tablenameCaseInsensitive) {
-            return new TableId(sourceDatabaseName, lcr.getObjectOwner(), lcr.getObjectName());
+            return new TableId(lcr.getSourceDatabaseName(), lcr.getObjectOwner(), lcr.getObjectName());
         }
         else {
-            return new TableId(sourceDatabaseName.toLowerCase(), lcr.getObjectOwner(), lcr.getObjectName().toLowerCase());
+            return new TableId(lcr.getSourceDatabaseName().toLowerCase(), lcr.getObjectOwner(), lcr.getObjectName().toLowerCase());
         }
     }
 

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/AbstractOracleDatatypesTest.java
Patch:
@@ -174,7 +174,7 @@ public abstract class AbstractOracleDatatypesTest extends AbstractConnectorTest
             new SchemaAndValueField("VAL_NUMBER_18_NEGATIVE_SCALE", Schema.OPTIONAL_INT64_SCHEMA, 999_99999_99999_99900L),
             new SchemaAndValueField("VAL_DECIMAL", Schema.OPTIONAL_INT64_SCHEMA, 99999_99999L),
             new SchemaAndValueField("VAL_NUMERIC", Schema.OPTIONAL_INT64_SCHEMA, 99999_99999L),
-            new SchemaAndValueField("VAL_NUMBER_1", Schema.OPTIONAL_BOOLEAN_SCHEMA, true));
+            new SchemaAndValueField("VAL_NUMBER_1", Schema.OPTIONAL_INT8_SCHEMA, (byte) 1));
 
     private static final List<SchemaAndValueField> EXPECTED_TIME = Arrays.asList(
             new SchemaAndValueField("VAL_DATE", Timestamp.builder().optional().build(), 1522108800_000l),

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/OracleDmlParserTest.java
Patch:
@@ -423,8 +423,8 @@ private void verifyUpdate(LogMinerDmlEntry record, boolean checkGeometry, boolea
                     }
                     break;
                 case "COL12":
-                    assertThat(newValue.getColumnData()).isInstanceOf(Boolean.class);
-                    assertThat(newValue.getColumnData()).isEqualTo(true);
+                    assertThat(newValue.getColumnData()).isInstanceOf(Byte.class);
+                    assertThat(newValue.getColumnData()).isEqualTo(Byte.valueOf("1"));
                     break;
             }
         }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleErrorHandler.java
Patch:
@@ -35,6 +35,7 @@ protected boolean isRetriable(Throwable throwable) {
                 throwable.getMessage().startsWith("ORA-00604") || // error occurred at recursive SQL level 1
                 throwable.getMessage().startsWith("ORA-01089") || // Oracle immediate shutdown in progress
                 throwable.getMessage().startsWith("ORA-01333") || // Failed to establish LogMiner dictionary
+                throwable.getMessage().startsWith("ORA-01284") || // Redo/Archive log cannot be opened, likely locked
                 throwable.getCause() instanceof IOException ||
                 throwable instanceof SQLRecoverableException ||
                 throwable.getMessage().toUpperCase().startsWith("NO MORE DATA TO READ FROM SOCKET") ||

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/TransactionalBufferMetrics.java
Patch:
@@ -185,8 +185,8 @@ public long getNumberOfCommittedTransactions() {
 
     @Override
     public long getCommitThroughput() {
-        long timeSpent = Duration.between(startTime, Instant.now()).isZero() ? 1 : Duration.between(startTime, Instant.now()).toMillis();
-        return committedTransactions.get() * MILLIS_PER_SECOND / timeSpent;
+        long timeSpent = Duration.between(startTime, Instant.now()).toMillis();
+        return committedTransactions.get() * MILLIS_PER_SECOND / (timeSpent != 0 ? timeSpent : 1);
     }
 
     @Override

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerMetricsTest.java
Patch:
@@ -119,7 +119,6 @@ public void testMetrics() {
         assertThat(metrics.toString().contains("logMinerQueryCount"));
 
         assertThat(metrics.getRecordMiningHistory()).isFalse();
-        assertThat(metrics.getRecordMiningHistory()).isTrue();
 
         metrics.incrementNetworkConnectionProblemsCounter();
         assertThat(metrics.getNetworkConnectionProblemsCounter()).isEqualTo(1);

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerMetricsTest.java
Patch:
@@ -119,7 +119,6 @@ public void testMetrics() {
         assertThat(metrics.toString().contains("logMinerQueryCount"));
 
         assertThat(metrics.getRecordMiningHistory()).isFalse();
-        metrics.setRecordMiningHistory(true);
         assertThat(metrics.getRecordMiningHistory()).isTrue();
 
         metrics.incrementNetworkConnectionProblemsCounter();

File: debezium-microbenchmark-oracle/src/main/java/io/debezium/performance/connector/oracle/parser/LogMinerDmlParserPerf.java
Patch:
@@ -101,7 +101,7 @@ private String getColumnValue(int length) {
     @Warmup(iterations = 10, time = 1, timeUnit = TimeUnit.SECONDS)
     @Measurement(iterations = 3, time = 2, timeUnit = TimeUnit.SECONDS)
     public void testInserts(ParserState state) {
-        state.dmlParser.parse(state.insertDml, null, state.txId);
+        state.dmlParser.parse(state.insertDml, null, null, state.txId);
     }
 
     @Benchmark
@@ -111,7 +111,7 @@ public void testInserts(ParserState state) {
     @Warmup(iterations = 10, time = 1, timeUnit = TimeUnit.SECONDS)
     @Measurement(iterations = 3, time = 2, timeUnit = TimeUnit.SECONDS)
     public void testUpdates(ParserState state) {
-        state.dmlParser.parse(state.deleteDml, null, state.txId);
+        state.dmlParser.parse(state.deleteDml, null, null, state.txId);
     }
 
     @Benchmark
@@ -121,6 +121,6 @@ public void testUpdates(ParserState state) {
     @Warmup(iterations = 10, time = 1, timeUnit = TimeUnit.SECONDS)
     @Measurement(iterations = 3, time = 2, timeUnit = TimeUnit.SECONDS)
     public void testDeletes(ParserState state) {
-        state.dmlParser.parse(state.deleteDml, null, state.txId);
+        state.dmlParser.parse(state.deleteDml, null, null, state.txId);
     }
 }

File: debezium-microbenchmark-oracle/src/main/java/io/debezium/performance/connector/oracle/EndToEndPerf.java
Patch:
@@ -241,7 +241,6 @@ private Configuration.Builder defaultConnectorConfig() {
 
             return builder.with(OracleConnectorConfig.SERVER_NAME, SERVER_NAME)
                     .with(OracleConnectorConfig.PDB_NAME, "ORCLPDB1")
-                    .with(OracleConnectorConfig.SCHEMA_NAME, SCHEMA_USER)
                     .with(OracleConnectorConfig.INCLUDE_SCHEMA_CHANGES, false)
                     .with(OracleConnectorConfig.CONNECTOR_ADAPTER, ConnectorAdapter.LOG_MINER)
                     .with(OracleConnectorConfig.DATABASE_HISTORY, FileDatabaseHistory.class)

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/RowMapperTest.java
Patch:
@@ -108,7 +108,7 @@ public void testGetScn() throws SQLException {
     public void testGetTransactionId() throws SQLException {
         Mockito.when(rs.getBytes(5)).thenReturn("tr_id".getBytes());
         String transactionId = RowMapper.getTransactionId(metrics, rs);
-        assertThat(transactionId.equals("74725F6964")).isTrue();
+        assertThat(transactionId).isEqualToIgnoringCase("74725F6964");
         verify(rs).getBytes(5);
         Mockito.when(rs.getBytes(5)).thenThrow(SQLException.class);
         transactionId = RowMapper.getTransactionId(metrics, rs);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -121,7 +121,7 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
 
     public static final Field LOG_MINING_STRATEGY = Field.create("log.mining.strategy")
             .withDisplayName("Log Mining Strategy")
-            .withEnum(LogMiningStrategy.class, LogMiningStrategy.ONLINE_CATALOG)
+            .withEnum(LogMiningStrategy.class, LogMiningStrategy.CATALOG_IN_REDO)
             .withWidth(Width.MEDIUM)
             .withImportance(Importance.HIGH)
             .withDescription("There are strategies: Online catalog with faster mining but no captured DDL. Another - with data dictionary loaded into REDO LOG files");

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/SqlUtils.java
Patch:
@@ -228,6 +228,8 @@ static String logMinerContentsQuery(OracleConnectorConfig connectorConfig, Strin
         query.append("AND SCN < ? ");
         query.append("AND TABLE_NAME != '").append(LOGMNR_FLUSH_TABLE).append("' ");
 
+        // There are some common schemas that we automatically ignore when building the filter predicates
+        // and we pull that same list of schemas in here and apply those exclusions in the generated SQL.
         List<String> excludedSchemas = OracleConnectorConfig.getExcludedSchemaNames();
         if (!excludedSchemas.isEmpty()) {
             query.append("AND SEG_OWNER NOT IN (");

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -1725,7 +1725,7 @@ public void customSnapshotterSkipsTablesOnRestart() throws Exception {
 
     @Test
     @FixFor("DBZ-2094")
-    public void customSnapshotterSkipsTablesOnRestartWithConncurrentTx() throws Exception {
+    public void customSnapshotterSkipsTablesOnRestartWithConcurrentTx() throws Exception {
         final LogInterceptor logInterceptor = new LogInterceptor();
 
         Testing.Print.enable();
@@ -1767,7 +1767,7 @@ public void customSnapshotterSkipsTablesOnRestartWithConncurrentTx() throws Exce
                 .atMost(waitTimeForRecords() * 30, TimeUnit.SECONDS)
                 .ignoreException(InstanceNotFoundException.class)
                 .until(() -> {
-                    // Requested due to DBZ-3158, creates empty transaction
+                    // Required due to DBZ-3158, creates empty transaction
                     TestHelper.create().execute("vacuum full").close();
                     return (boolean) ManagementFactory.getPlatformMBeanServer()
                             .getAttribute(getSnapshotMetricsObjectName("postgres", TestHelper.TEST_SERVER), "SnapshotCompleted");

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -202,7 +202,7 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
             .withDescription("Complete JDBC URL as an alternative to specifying hostname, port and database provided "
                     + "as a way to support alternative connection scenarios.");
 
-    public static final Field LOG_MINING_DML_PARSER = Field.create("log.mining.dml.parser")
+    public static final Field LOG_MINING_DML_PARSER = Field.createInternal("log.mining.dml.parser")
             .withDisplayName("Log Mining DML parser implementation")
             .withEnum(LogMiningDmlParser.class, LogMiningDmlParser.FAST)
             .withWidth(Width.SHORT)

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/antlr/listener/BaseDmlParserListener.java
Patch:
@@ -10,8 +10,8 @@
 import java.util.LinkedHashMap;
 import java.util.Map;
 
+import io.debezium.connector.oracle.OracleValueConverters;
 import io.debezium.connector.oracle.antlr.OracleDmlParser;
-import io.debezium.connector.oracle.logminer.OracleChangeRecordValueConverter;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerColumnValueImpl;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerColumnValueWrapper;
 import io.debezium.ddl.parser.oracle.generated.PlSqlParser;
@@ -28,7 +28,7 @@ abstract class BaseDmlParserListener<T> extends PlSqlParserBaseListener {
     protected String catalogName;
     protected String schemaName;
     protected Table table;
-    final OracleChangeRecordValueConverter converter;
+    final OracleValueConverters converter;
     String alias;
 
     protected OracleDmlParser parser;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/antlr/listener/ParserUtils.java
Patch:
@@ -11,7 +11,7 @@
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
 
-import io.debezium.connector.oracle.logminer.OracleChangeRecordValueConverter;
+import io.debezium.connector.oracle.OracleValueConverters;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerColumnValueWrapper;
 import io.debezium.ddl.parser.oracle.generated.PlSqlParser;
 import io.debezium.relational.Column;
@@ -89,7 +89,7 @@ public static void cloneOldToNewColumnValues(Map<String, LogMinerColumnValueWrap
      * @return object as the result of this conversion. It could be null if converter cannot build the schema
      * or if converter or value are null
      */
-    public static Object convertValueToSchemaType(Column column, Object value, OracleChangeRecordValueConverter converters) {
+    public static Object convertValueToSchemaType(Column column, Object value, OracleValueConverters converters) {
         if (converters != null && value != null) {
             final SchemaBuilder schemaBuilder = converters.schemaBuilder(column);
             if (schemaBuilder == null) {

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/StreamingDatatypesIT.java
Patch:
@@ -16,7 +16,6 @@
 import io.debezium.config.Configuration.Builder;
 import io.debezium.connector.oracle.OracleConnectorConfig.SnapshotMode;
 import io.debezium.connector.oracle.junit.SkipTestDependingOnAdapterNameRule;
-import io.debezium.connector.oracle.junit.SkipWhenAdapterNameIs;
 import io.debezium.connector.oracle.util.TestHelper;
 import io.debezium.util.Testing;
 
@@ -25,7 +24,6 @@
  *
  * @author Jiri Pechanec
  */
-@SkipWhenAdapterNameIs(value = SkipWhenAdapterNameIs.AdapterName.LOGMINER, reason = "Implementation does not support creating/updating schema during streaming")
 public class StreamingDatatypesIT extends AbstractOracleDatatypesTest {
 
     @Rule
@@ -41,11 +39,12 @@ public void before() throws Exception {
         Configuration config = connectorConfig()
                 .build();
 
+        createTables();
+
         start(OracleConnector.class, config);
         assertConnectorIsRunning();
 
         waitForSnapshotToBeCompleted(TestHelper.CONNECTOR_NAME, TestHelper.SERVER_NAME);
-        createTables();
     }
 
     protected Builder connectorConfig() {

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/ValueHolderTest.java
Patch:
@@ -20,11 +20,12 @@
 import org.junit.rules.TestRule;
 
 import io.debezium.connector.oracle.OracleConnectorConfig;
+import io.debezium.connector.oracle.OracleValueConverters;
 import io.debezium.connector.oracle.antlr.OracleDdlParser;
-import io.debezium.connector.oracle.jsqlparser.SimpleDmlParser;
 import io.debezium.connector.oracle.junit.SkipTestDependingOnAdapterNameRule;
 import io.debezium.connector.oracle.junit.SkipWhenAdapterNameIsNot;
 import io.debezium.connector.oracle.junit.SkipWhenAdapterNameIsNot.AdapterName;
+import io.debezium.connector.oracle.logminer.parser.SimpleDmlParser;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerColumnValue;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerColumnValueImpl;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerColumnValueWrapper;
@@ -50,7 +51,7 @@ public class ValueHolderTest {
 
     @Before
     public void setUp() {
-        OracleChangeRecordValueConverter converters = new OracleChangeRecordValueConverter(new OracleConnectorConfig(TestHelper.defaultConfig().build()), null);
+        OracleValueConverters converters = new OracleValueConverters(new OracleConnectorConfig(TestHelper.defaultConfig().build()), null);
         ddlParser = new OracleDdlParser(true, CATALOG_NAME, SCHEMA_NAME);
         sqlDmlParser = new SimpleDmlParser(CATALOG_NAME, SCHEMA_NAME, converters);
         tables = new Tables();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerQueryResultProcessor.java
Patch:
@@ -120,7 +120,7 @@ int processResult(ResultSet resultSet) {
                 if (transactionalBuffer.isTransactionRegistered(txId)) {
                     historyRecorder.record(scn, tableName, segOwner, operationCode, changeTime, txId, 0, redoSql);
                 }
-                if (transactionalBuffer.commit(txId, scn, offsetContext, changeTime, context, logMessage)) {
+                if (transactionalBuffer.commit(txId, scn, offsetContext, changeTime, context, logMessage, dispatcher)) {
                     LOGGER.trace("COMMIT, {}", logMessage);
                     commitCounter++;
                 }

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorTest.java
Patch:
@@ -9,6 +9,7 @@
 
 import java.util.HashMap;
 import java.util.Map;
+
 import org.apache.kafka.common.config.Config;
 import org.apache.kafka.common.config.ConfigDef;
 import org.apache.kafka.common.config.ConfigDef.ConfigKey;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlStreamingChangeEventSource.java
Patch:
@@ -116,6 +116,7 @@ public class MySqlStreamingChangeEventSource implements StreamingChangeEventSour
     private final EventDispatcher<TableId> eventDispatcher;
     private final MySqlOffsetContext offsetContext;
     private final ErrorHandler errorHandler;
+
     @SingleThreadAccess("binlog client thread")
     private Instant eventTimestamp;
 

File: debezium-core/src/main/java/io/debezium/connector/common/BaseSourceTask.java
Patch:
@@ -81,8 +81,10 @@ protected static enum State {
 
     private final ElapsedTimeStrategy pollOutputDelay;
     private final Clock clock = Clock.system();
+
     @SingleThreadAccess("polling thread")
     private long recordCounter = 0L;
+
     @SingleThreadAccess("polling thread")
     private Instant previousOutputInstant;
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -1431,7 +1431,7 @@ boolean legacy() {
      * Intended for testing only
      */
     boolean useGlobalLock() {
-        return !"true".equals(TEST_DISABLE_GLOBAL_LOCKING);
+        return !"true".equals(config.getString(TEST_DISABLE_GLOBAL_LOCKING));
     }
 
     @SuppressWarnings("unchecked")

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlStreamingChangeEventSource.java
Patch:
@@ -719,11 +719,11 @@ private <T extends EventData, U> void handleChange(Event event, String changeTyp
                 }
                 if (LOGGER.isDebugEnabled()) {
                     if (startingRowNumber != 0) {
-                        LOGGER.debug("Emited {} {} record(s) for last {} row(s) in event: {}",
+                        LOGGER.debug("Emitted {} {} record(s) for last {} row(s) in event: {}",
                                 count, changeType, numRows - startingRowNumber, event);
                     }
                     else {
-                        LOGGER.debug("Emited {} {} record(s) for event: {}", count, changeType, event);
+                        LOGGER.debug("Emitted {} {} record(s) for event: {}", count, changeType, event);
                     }
                 }
                 offsetContext.changeEventCompleted();

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/UniqueDatabase.java
Patch:
@@ -203,7 +203,7 @@ public Configuration.Builder defaultConfig() {
                 .with(MySqlConnectorConfig.DATABASE_INCLUDE_LIST, getDatabaseName())
                 .with(MySqlConnectorConfig.DATABASE_HISTORY, FileDatabaseHistory.class)
                 .with(MySqlConnectorConfig.BUFFER_SIZE_FOR_BINLOG_READER, 10_000)
-                .with("internal.implementation", "new");
+                .with(MySqlConnector.IMPLEMENTATION_PROP, System.getProperty(MySqlConnector.IMPLEMENTATION_PROP, "new"));
 
         if (dbHistoryPath != null) {
             builder.with(FileDatabaseHistory.FILE_PATH, dbHistoryPath);

File: debezium-core/src/main/java/io/debezium/relational/history/MemoryDatabaseHistory.java
Patch:
@@ -46,7 +46,7 @@ public boolean storageExists() {
 
     @Override
     public boolean exists() {
-        return records != null;
+        return !records.isEmpty();
     }
 
     @Override

File: debezium-core/src/test/java/io/debezium/relational/TableIdTest.java
Patch:
@@ -5,12 +5,12 @@
  */
 package io.debezium.relational;
 
+import static org.fest.assertions.Assertions.assertThat;
+
 import org.junit.Test;
 
 import io.debezium.doc.FixFor;
 
-import static org.fest.assertions.Assertions.assertThat;
-
 public class TableIdTest {
 
     @Test

File: debezium-testing/debezium-testing-openshift/src/main/java/io/debezium/testing/openshift/tools/ConfigProperties.java
Patch:
@@ -74,7 +74,7 @@ public class ConfigProperties {
     public static final String DATABASE_DB2_CDC_SCHEMA = System.getProperty("test.database.db2.cdc.schema", "ASNCDC");
     public static final Optional<String> DATABASE_DB2_HOST = stringOptionalProperty("test.database.sqlserver.host");
 
-    public static final boolean TEST_AVRO_SERIALISATION = booleanProperty("test.avro.serialisation", "true");
+    public static final boolean TEST_AVRO_SERIALISATION = booleanProperty("test.avro.serialisation", "false");
     public static final boolean DEPLOY_SERVICE_REGISTRY = booleanProperty("test.registry.deploy", String.valueOf(TEST_AVRO_SERIALISATION));
 
     private static boolean booleanProperty(String key) {

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConnection.java
Patch:
@@ -1276,7 +1276,7 @@ protected Optional<Object> getDefaultValue(Column column, String defaultValue) {
         return Optional.empty();
     }
 
-    protected List<String> readPrimaryKeyNames(DatabaseMetaData metadata, TableId id) throws SQLException {
+    public List<String> readPrimaryKeyNames(DatabaseMetaData metadata, TableId id) throws SQLException {
         final List<String> pkColumnNames = new ArrayList<>();
         try (ResultSet rs = metadata.getPrimaryKeys(id.catalog(), id.schema(), id.table())) {
             while (rs.next()) {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/CreateTableParserListener.java
Patch:
@@ -136,8 +136,9 @@ public void enterUniqueKeyTableConstraint(MySqlParser.UniqueKeyTableConstraintCo
     @Override
     public void enterTableOptionCharset(MySqlParser.TableOptionCharsetContext ctx) {
         parser.runIfNotNull(() -> {
-            String charsetName = parser.withoutQuotes(ctx.charsetName());
-            tableEditor.setDefaultCharsetName(charsetName);
+            if (ctx.charsetName() != null) {
+                tableEditor.setDefaultCharsetName(parser.withoutQuotes(ctx.charsetName()));
+            }
         }, tableEditor);
         super.enterTableOptionCharset(ctx);
     }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerHelper.java
Patch:
@@ -256,7 +256,6 @@ static void startLogMining(Connection connection, Long startScn, Long endScn,
             throws SQLException {
         LOGGER.trace("Starting log mining startScn={}, endScn={}, strategy={}, continuous={}", startScn, endScn, strategy, isContinuousMining);
         String statement = SqlUtils.startLogMinerStatement(startScn, endScn, strategy, isContinuousMining);
-        executeCallableStatement(connection, statement);
         try {
             executeCallableStatement(connection, statement);
         }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerQueryResultProcessor.java
Patch:
@@ -232,7 +232,7 @@ int processResult(ResultSet resultSet) {
             }
             LOGGER.debug("{} DMLs, {} Commits, {} Rollbacks, {} Inserts, {} Updates, {} Deletes. Processed in {} millis. " +
                     "Lag:{}. Offset scn:{}. Offset commit scn:{}. Active transactions:{}. Sleep time:{}",
-                    dmlCounter, insertCounter, updateCounter, deleteCounter, commitCounter, rollbackCounter, totalTime.toMillis(),
+                    dmlCounter, commitCounter, rollbackCounter, insertCounter, updateCounter, deleteCounter, totalTime.toMillis(),
                     transactionalBufferMetrics.getLagFromSource(), offsetContext.getScn(), offsetContext.getCommitScn(),
                     transactionalBufferMetrics.getNumberOfActiveTransactions(), metrics.getMillisecondToSleepBetweenMiningQuery());
         }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerMetrics.java
Patch:
@@ -267,8 +267,8 @@ public void setBatchSize(int size) {
     }
 
     @Override
-    public void setMillisecondToSleepBetweenMiningQuery(Integer milliseconds) {
-        if (milliseconds != null && milliseconds >= sleepTimeMin && milliseconds < sleepTimeMax) {
+    public void setMillisecondToSleepBetweenMiningQuery(long milliseconds) {
+        if (milliseconds >= sleepTimeMin && milliseconds < sleepTimeMax) {
             millisecondToSleepBetweenMiningQuery.set(milliseconds);
         }
     }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerMetricsMXBean.java
Patch:
@@ -97,7 +97,7 @@ public interface LogMinerMetricsMXBean {
      * sets number of milliseconds for connector to sleep before fetching another batch from the LogMiner view
      * @param milliseconds to sleep
      */
-    void setMillisecondToSleepBetweenMiningQuery(Integer milliseconds);
+    void setMillisecondToSleepBetweenMiningQuery(long milliseconds);
 
     /**
      * change sleeping time

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/LogMinerMetricsTest.java
Patch:
@@ -65,11 +65,11 @@ public void testMetrics() {
         assertThat(metrics.getMillisecondToSleepBetweenMiningQuery()).isEqualTo(1200);
         metrics.changeSleepingTime(false);
         assertThat(metrics.getMillisecondToSleepBetweenMiningQuery()).isEqualTo(1000);
-        metrics.setMillisecondToSleepBetweenMiningQuery(-1);
+        metrics.setMillisecondToSleepBetweenMiningQuery(-1L);
         assertThat(metrics.getMillisecondToSleepBetweenMiningQuery()).isEqualTo(1000);
-        metrics.setMillisecondToSleepBetweenMiningQuery(4000);
+        metrics.setMillisecondToSleepBetweenMiningQuery(4000L);
         assertThat(metrics.getMillisecondToSleepBetweenMiningQuery()).isEqualTo(1000);
-        metrics.setMillisecondToSleepBetweenMiningQuery(2000);
+        metrics.setMillisecondToSleepBetweenMiningQuery(2000L);
         assertThat(metrics.getMillisecondToSleepBetweenMiningQuery()).isEqualTo(2000);
 
         metrics.setLastDurationOfBatchCapturing(Duration.ofMillis(100));

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerHelper.java
Patch:
@@ -273,8 +273,8 @@ static Set<String> getCurrentRedoLogFiles(Connection connection, LogMinerMetrics
         try (PreparedStatement st = connection.prepareStatement(SqlUtils.currentRedoNameQuery()); ResultSet result = st.executeQuery()) {
             while (result.next()) {
                 fileNames.add(result.getString(1));
-                LOGGER.trace(" Current Redo log fileName: {} ", fileNames);
             }
+            LOGGER.trace(" Current Redo log fileNames: {} ", fileNames);
         }
 
         updateRedoLogMetrics(connection, metrics, fileNames);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -50,7 +50,7 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
     public static final String DATABASE_CONFIG_PREFIX = "database.";
 
     protected static final int DEFAULT_PORT = 1528;
-    
+
     protected static final int DEFAULT_VIEW_FETCH_SIZE = 10_000;
 
     protected final static int DEFAULT_BATCH_SIZE = 20_000;

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/DebeziumContainerTest.java
Patch:
@@ -79,7 +79,7 @@ public void canRegisterConnector() throws Exception {
                 .atMost(Duration.ofSeconds(30))
                 .untilAsserted(
                         () -> {
-                            String status = executeHttpRequest(debeziumContainer.getConnectorStatusURI("my-connector-1"));
+                            String status = executeHttpRequest(debeziumContainer.getConnectorStatusUri("my-connector-1"));
 
                             assertThat(JsonPath.<String> read(status, "$.name")).isEqualTo("my-connector-1");
                             assertThat(JsonPath.<String> read(status, "$.connector.state")).isEqualTo("RUNNING");

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresTaskContext.java
Patch:
@@ -110,6 +110,7 @@ protected ReplicationConnection createReplicationConnection(boolean exportSnapsh
                 .withTableFilter(config.getTableFilters())
                 .withPublicationAutocreateMode(config.publicationAutocreateMode())
                 .withPlugin(config.plugin())
+                .withTruncateHandlingMode(config.truncateHandlingMode())
                 .dropSlotOnClose(dropSlotOnStop)
                 .streamParams(config.streamParams())
                 .statusUpdateInterval(config.statusUpdateInterval())

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ReplicationMessage.java
Patch:
@@ -43,6 +43,7 @@ public enum Operation {
         INSERT,
         UPDATE,
         DELETE,
+        TRUNCATE,
         BEGIN,
         COMMIT,
         NOOP

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerHelper.java
Patch:
@@ -47,7 +47,7 @@ public class LogMinerHelper {
     private static final String TOTAL = "TOTAL";
     private final static Logger LOGGER = LoggerFactory.getLogger(LogMinerHelper.class);
 
-    public final static String MAX_SCN_S = "1844674407370955161";
+    public final static String MAX_SCN_S = "18446744073709551615";
     public final static BigInteger MAX_SCN_BI = new BigInteger(MAX_SCN_S);
 
     public enum DATATYPE {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleValueConverters.java
Patch:
@@ -23,7 +23,6 @@
 import io.debezium.data.SpecialValueDecimal;
 import io.debezium.data.VariableScaleDecimal;
 import io.debezium.jdbc.JdbcValueConverters;
-import io.debezium.jdbc.JdbcValueConverters.DecimalMode;
 import io.debezium.jdbc.TemporalPrecisionMode;
 import io.debezium.relational.Column;
 import io.debezium.relational.ValueConverter;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -95,7 +95,7 @@ public LogMinerStreamingChangeEventSource(OracleConnectorConfig connectorConfig,
         this.clock = clock;
         this.schema = schema;
         this.offsetContext = offsetContext;
-        OracleChangeRecordValueConverter converters = new OracleChangeRecordValueConverter(jdbcConnection);
+        OracleChangeRecordValueConverter converters = new OracleChangeRecordValueConverter(connectorConfig, jdbcConnection);
         this.connectorConfig = connectorConfig;
         this.catalogName = (connectorConfig.getPdbName() != null) ? connectorConfig.getPdbName() : connectorConfig.getDatabaseName();
         this.dmlParser = new SimpleDmlParser(catalogName, connectorConfig.getSchemaName(), converters);

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/OracleDmlParserTest.java
Patch:
@@ -22,6 +22,7 @@
 import org.junit.rules.TestRule;
 import org.mockito.Mockito;
 
+import io.debezium.connector.oracle.OracleConnectorConfig;
 import io.debezium.connector.oracle.antlr.OracleDdlParser;
 import io.debezium.connector.oracle.antlr.OracleDmlParser;
 import io.debezium.connector.oracle.jsqlparser.SimpleDmlParser;
@@ -30,6 +31,7 @@
 import io.debezium.connector.oracle.junit.SkipWhenAdapterNameIsNot.AdapterName;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerColumnValue;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerDmlEntry;
+import io.debezium.connector.oracle.util.TestHelper;
 import io.debezium.data.Envelope;
 import io.debezium.doc.FixFor;
 import io.debezium.relational.Tables;
@@ -62,7 +64,7 @@ public class OracleDmlParserTest {
 
     @Before
     public void setUp() {
-        OracleChangeRecordValueConverter converters = new OracleChangeRecordValueConverter(null);
+        OracleChangeRecordValueConverter converters = new OracleChangeRecordValueConverter(new OracleConnectorConfig(TestHelper.defaultConfig().build()), null);
 
         ddlParser = new OracleDdlParser(true, CATALOG_NAME, SCHEMA_NAME);
         antlrDmlParser = new OracleDmlParser(true, CATALOG_NAME, SCHEMA_NAME, converters);

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/ValueHolderTest.java
Patch:
@@ -19,6 +19,7 @@
 import org.junit.Test;
 import org.junit.rules.TestRule;
 
+import io.debezium.connector.oracle.OracleConnectorConfig;
 import io.debezium.connector.oracle.antlr.OracleDdlParser;
 import io.debezium.connector.oracle.jsqlparser.SimpleDmlParser;
 import io.debezium.connector.oracle.junit.SkipTestDependingOnAdapterNameRule;
@@ -29,6 +30,7 @@
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerColumnValueWrapper;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerDmlEntry;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerDmlEntryImpl;
+import io.debezium.connector.oracle.util.TestHelper;
 import io.debezium.data.Envelope;
 import io.debezium.relational.Tables;
 import io.debezium.util.IoUtil;
@@ -48,7 +50,7 @@ public class ValueHolderTest {
 
     @Before
     public void setUp() {
-        OracleChangeRecordValueConverter converters = new OracleChangeRecordValueConverter(null);
+        OracleChangeRecordValueConverter converters = new OracleChangeRecordValueConverter(new OracleConnectorConfig(TestHelper.defaultConfig().build()), null);
         ddlParser = new OracleDdlParser(true, CATALOG_NAME, SCHEMA_NAME);
         sqlDmlParser = new SimpleDmlParser(CATALOG_NAME, SCHEMA_NAME, converters);
         tables = new Tables();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/HistoryRecorder.java
Patch:
@@ -5,7 +5,6 @@
  */
 package io.debezium.connector.oracle.logminer;
 
-import java.math.BigDecimal;
 import java.sql.Timestamp;
 
 import io.debezium.common.annotation.Incubating;
@@ -37,7 +36,7 @@ public interface HistoryRecorder extends AutoCloseable {
      * @param csf the continuation sequence flag
      * @param redoSql the redo SQL that performed the operation
      */
-    void record(BigDecimal scn, String tableName, String segOwner, int operationCode, Timestamp changeTime,
+    void record(Scn scn, String tableName, String segOwner, int operationCode, Timestamp changeTime,
                 String transactionId, int csf, String redoSql);
 
     /**

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerQueryResultProcessor.java
Patch:
@@ -5,7 +5,6 @@
  */
 package io.debezium.connector.oracle.logminer;
 
-import java.math.BigDecimal;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Timestamp;
@@ -91,7 +90,7 @@ int processResult(ResultSet resultSet) {
                 return 0;
             }
 
-            BigDecimal scn = RowMapper.getScn(transactionalBufferMetrics, resultSet);
+            Scn scn = RowMapper.getScn(transactionalBufferMetrics, resultSet);
             String tableName = RowMapper.getTableName(transactionalBufferMetrics, resultSet);
             String segOwner = RowMapper.getSegOwner(transactionalBufferMetrics, resultSet);
             int operationCode = RowMapper.getOperationCode(transactionalBufferMetrics, resultSet);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -22,7 +22,6 @@
 import static io.debezium.connector.oracle.logminer.LogMinerHelper.setRedoLogFilesForMining;
 import static io.debezium.connector.oracle.logminer.LogMinerHelper.startLogMining;
 
-import java.math.BigDecimal;
 import java.sql.Connection;
 import java.sql.PreparedStatement;
 import java.sql.ResultSet;
@@ -267,7 +266,7 @@ private void abandonOldTransactionsIfExist(Connection connection) {
     // TODO computing the largest scn in the buffer is a left-over from previous incarnations, remove it.
     // TODO We don't need to keep largestScn in the buffer at all. clean it
     private void updateStartScn() {
-        long nextStartScn = transactionalBuffer.getLargestScn().equals(BigDecimal.ZERO) ? endScn : transactionalBuffer.getLargestScn().longValue();
+        long nextStartScn = transactionalBuffer.getLargestScn().equals(Scn.ZERO) ? endScn : transactionalBuffer.getLargestScn().longValue();
         if (nextStartScn <= startScn) {
             // When system is idle, largest SCN may stay unchanged, move it forward then
             transactionalBuffer.resetLargestScn(endScn);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/NeverHistoryRecorder.java
Patch:
@@ -5,7 +5,6 @@
  */
 package io.debezium.connector.oracle.logminer;
 
-import java.math.BigDecimal;
 import java.sql.Timestamp;
 
 import io.debezium.jdbc.JdbcConfiguration;
@@ -21,7 +20,7 @@ public void prepare(LogMinerMetrics metrics, JdbcConfiguration jdbcConfiguration
     }
 
     @Override
-    public void record(BigDecimal scn, String tableName, String segOwner, int operationCode, Timestamp changeTime,
+    public void record(Scn scn, String tableName, String segOwner, int operationCode, Timestamp changeTime,
                        String transactionId, int csf, String redoSql) {
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/valueholder/LogMinerDmlEntry.java
Patch:
@@ -5,10 +5,10 @@
  */
 package io.debezium.connector.oracle.logminer.valueholder;
 
-import java.math.BigDecimal;
 import java.sql.Timestamp;
 import java.util.List;
 
+import io.debezium.connector.oracle.logminer.Scn;
 import io.debezium.data.Envelope;
 
 public interface LogMinerDmlEntry {
@@ -38,7 +38,7 @@ public interface LogMinerDmlEntry {
      * The actual SCN will be assigned after commit
      * @return it's value
      */
-    BigDecimal getScn();
+    Scn getScn();
 
     /**
      * @return transaction ID
@@ -64,7 +64,7 @@ public interface LogMinerDmlEntry {
      * sets scn obtained from a Log Miner entry
      * @param scn it's value
      */
-    void setScn(BigDecimal scn);
+    void setScn(Scn scn);
 
     /**
      * Sets table name

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/ValueHolderTest.java
Patch:
@@ -71,7 +71,7 @@ public void testValueHolders() throws Exception {
         dmlEntryExpected.setTransactionId("transaction_id");
         dmlEntryExpected.setObjectName(TABLE_NAME);
         dmlEntryExpected.setObjectOwner(SCHEMA_NAME);
-        dmlEntryExpected.setScn(BigDecimal.ONE);
+        dmlEntryExpected.setScn(Scn.ONE);
         dmlEntryExpected.setSourceTime(new Timestamp(1000));
 
         String createStatement = IoUtil.read(IoUtil.getResourceAsStream("ddl/create_small_table.sql", null, getClass(), null, null));
@@ -82,7 +82,7 @@ public void testValueHolders() throws Exception {
 
         assertThat(dmlEntryParsed.equals(dmlEntryExpected)).isTrue();
         assertThat(dmlEntryExpected.getCommandType() == Envelope.Operation.CREATE).isTrue();
-        assertThat(dmlEntryExpected.getScn().equals(BigDecimal.ONE)).isTrue();
+        assertThat(dmlEntryExpected.getScn().equals(Scn.ONE)).isTrue();
         assertThat(dmlEntryExpected.getSourceTime().equals(new Timestamp(1000))).isTrue();
         assertThat(dmlEntryExpected.getTransactionId().equals("transaction_id")).isTrue();
         assertThat(dmlEntryExpected.getObjectOwner().equals(SCHEMA_NAME)).isTrue();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/SqlUtils.java
Patch:
@@ -208,7 +208,6 @@ static String startLogMinerStatement(Long startScn, Long endScn, OracleConnector
     static String logMinerContentsQuery(String schemaName, String logMinerUser, OracleDatabaseSchema schema) {
         List<String> whiteListTableNames = schema.tableIds().stream().map(TableId::table).collect(Collectors.toList());
 
-        String sorting = "ORDER BY SCN";
         // todo: add ROW_ID, SESSION#, SERIAL#, RS_ID, and SSN
         return "SELECT SCN, SQL_REDO, OPERATION_CODE, TIMESTAMP, XID, CSF, TABLE_NAME, SEG_OWNER, OPERATION, USERNAME " +
                 " FROM " + LOGMNR_CONTENTS_VIEW + " WHERE  OPERATION_CODE in (1,2,3,5) " + // 5 - DDL
@@ -218,8 +217,7 @@ static String logMinerContentsQuery(String schemaName, String logMinerUser, Orac
                 // Capture DDL and MISSING_SCN rows only hwne not performed by SYS, SYSTEM, and LogMiner user
                 " OR (OPERATION_CODE IN (5,34) AND USERNAME NOT IN ('SYS','SYSTEM','" + logMinerUser.toUpperCase() + "')) " +
                 // Capture all COMMIT and ROLLBACK operations performed by the database
-                " OR (OPERATION_CODE IN (7,36)) " +
-                sorting; // todo username = schemaName?
+                " OR (OPERATION_CODE IN (7,36))"; // todo username = schemaName?
     }
 
     static String addLogFileStatement(String option, String fileName) {

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/SqlUtilsTest.java
Patch:
@@ -50,7 +50,7 @@ public void testStatements() {
         expected = "SELECT SCN, SQL_REDO, OPERATION_CODE, TIMESTAMP, XID, CSF, TABLE_NAME, SEG_OWNER, OPERATION, USERNAME  " +
                 "FROM V$LOGMNR_CONTENTS WHERE  OPERATION_CODE in (1,2,3,5)  AND SEG_OWNER = 'DATABASE'  AND SCN >= ? AND SCN < ?  " +
                 "OR (OPERATION_CODE IN (5,34) AND USERNAME NOT IN ('SYS','SYSTEM','SCHEMA')) " +
-                " OR (OPERATION_CODE IN (7,36)) ORDER BY SCN";
+                " OR (OPERATION_CODE IN (7,36))";
         assertThat(result).isEqualTo(expected);
 
         tables.add(table1);
@@ -60,7 +60,7 @@ public void testStatements() {
                 "FROM V$LOGMNR_CONTENTS WHERE  OPERATION_CODE in (1,2,3,5)  " +
                 "AND SEG_OWNER = 'DATABASE'  AND table_name IN ('table1','table2')  " +
                 "AND SCN >= ? AND SCN < ?  OR (OPERATION_CODE IN (5,34) AND USERNAME NOT IN ('SYS','SYSTEM','SCHEMA')) " +
-                " OR (OPERATION_CODE IN (7,36)) ORDER BY SCN";
+                " OR (OPERATION_CODE IN (7,36))";
         assertThat(result).isEqualTo(expected);
 
         result = SqlUtils.startLogMinerStatement(10L, 20L, OracleConnectorConfig.LogMiningStrategy.ONLINE_CATALOG, true);

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -379,7 +379,7 @@ public static BinaryHandlingMode parse(String value, String defaultValue) {
             .withWidth(Width.SHORT)
             .withImportance(Importance.LOW)
             .withValidation(CommonConnectorConfig::validateSkippedOperation)
-            .withDescription("The comma-separated list of operations to skip during streaming, defined as: 'i' for inserts; 'u' for updates; 'd' for deletes. "
+            .withDescription("The comma-separated list of operations to skip during streaming, defined as: 'c' for inserts/create; 'u' for updates; 'd' for deletes. "
                     + "By default, no operations will be skipped.");
 
     public static final Field BINARY_HANDLING_MODE = Field.create("binary.handling.mode")

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/util/TestHelper.java
Patch:
@@ -209,7 +209,7 @@ public static void forceLogfileSwitch() {
         Configuration config = adminConfig().build();
         Configuration jdbcConfig = config.subset("database.", true);
 
-        try(OracleConnection jdbcConnection = new OracleConnection(jdbcConfig, TestHelper.class::getClassLoader)) {
+        try (OracleConnection jdbcConnection = new OracleConnection(jdbcConfig, TestHelper.class::getClassLoader)) {
             jdbcConnection.resetSessionToCdb();
             jdbcConnection.execute("ALTER SYSTEM SWITCH LOGFILE");
         }
@@ -222,7 +222,7 @@ public static int getNumberOfOnlineLogGroups() {
         Configuration config = adminConfig().build();
         Configuration jdbcConfig = config.subset("database.", true);
 
-        try(OracleConnection jdbcConnection = new OracleConnection(jdbcConfig, TestHelper.class::getClassLoader)) {
+        try (OracleConnection jdbcConnection = new OracleConnection(jdbcConfig, TestHelper.class::getClassLoader)) {
             jdbcConnection.resetSessionToCdb();
             return jdbcConnection.queryAndMap("SELECT COUNT(GROUP#) FROM V$LOG", rs -> {
                 rs.next();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -212,7 +212,7 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
             .withImportance(Importance.HIGH)
             .withValidation(OracleConnectorConfig::requiredWhenNoHostname)
             .withDescription("Complete JDBC URL as an alternative to specifying hostname, port and database provided "
-                     + "as a way to support alternative connection scenarios.");
+                    + "as a way to support alternative connection scenarios.");
 
     public static final Field LOG_MINING_ARCHIVE_LOG_HOURS = Field.create("log.mining.archive.log.hours")
             .withDisplayName("Log Mining Archive Log Hours")
@@ -335,7 +335,7 @@ public static ConfigDef configDef() {
         Field.group(config, "Connector", CommonConnectorConfig.POLL_INTERVAL_MS, CommonConnectorConfig.MAX_BATCH_SIZE,
                 CommonConnectorConfig.MAX_QUEUE_SIZE, CommonConnectorConfig.SNAPSHOT_DELAY_MS, CommonConnectorConfig.SNAPSHOT_FETCH_SIZE,
                 SNAPSHOT_ENHANCEMENT_TOKEN, LOG_MINING_HISTORY_RECORDER_CLASS, LOG_MINING_HISTORY_RETENTION, RAC_SYSTEM, RAC_NODES,
-                    LOG_MINING_ARCHIVE_LOG_HOURS);
+                LOG_MINING_ARCHIVE_LOG_HOURS);
 
         return config;
     }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -135,7 +135,8 @@ public void execute(ChangeEventSourceContext context) {
                 createFlushTable(connection);
 
                 if (!isContinuousMining && startScn < getFirstOnlineLogScn(connection, archiveLogHours)) {
-                    throw new DebeziumException("Online REDO LOG files or archive log files do not contain the offset scn " + startScn + ".  Please perform a new snapshot.");
+                    throw new DebeziumException(
+                            "Online REDO LOG files or archive log files do not contain the offset scn " + startScn + ".  Please perform a new snapshot.");
                 }
 
                 setNlsSessionParameters(jdbcConnection);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -133,8 +133,8 @@ public void execute(ChangeEventSourceContext context) {
                 createFlushTable(connection);
 
                 if (!isContinuousMining && startScn < getFirstOnlineLogScn(connection)) {
-                    LOGGER.error("Online REDO LOG files do not contain the offset scn {}", startScn);
-                    throw new DebeziumException("Online REDO LOG files do not contain the offset scn.  Please perform a new snapshot.");
+                    LOGGER.error("Online REDO LOG files or Archive files do not contain the offset scn {}", startScn);
+                    throw new DebeziumException("Online REDO LOG files or Archive files do not contain the offset scn.  Please perform a new snapshot.");
                 }
 
                 setNlsSessionParameters(jdbcConnection);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/SqlUtils.java
Patch:
@@ -128,7 +128,9 @@ static String currentScnQuery() {
     }
 
     static String oldestFirstChangeQuery() {
-        return String.format("SELECT MIN(FIRST_CHANGE#) FROM %s", LOG_VIEW);
+        return String.format(
+                "SELECT MIN(FIRST_CHANGE#) FROM (SELECT MIN(FIRST_CHANGE#) AS FIRST_CHANGE# FROM %s UNION SELECT MIN(FIRST_CHANGE#) AS FIRST_CHANGE# FROM %s)", LOG_VIEW,
+                ARCHIVED_LOG_VIEW);
     }
 
     public static String allOnlineLogsQuery() {

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -318,7 +318,7 @@ protected ValueConverter[] convertersForColumns(Schema schema, TableId tableId,
         for (int i = 0; i < columns.size(); i++) {
             Column column = columns.get(i);
 
-            ValueConverter converter = createValueConverterFor(tableId, column, schema.field(column.name()));
+            ValueConverter converter = createValueConverterFor(tableId, column, schema.field(fieldNamer.fieldNameFor(column)));
             converter = wrapInMappingConverterIfNeeded(mappers, tableId, column, converter);
 
             if (converter == null) {

File: debezium-ddl-parser/src/main/java/io/debezium/antlr/AntlrDdlParser.java
Patch:
@@ -74,7 +74,7 @@ public void parse(String ddlContent, Tables databaseTables) {
         // remove default console output printing error listener
         parser.removeErrorListener(ConsoleErrorListener.INSTANCE);
 
-        ParsingErrorListener parsingErrorListener = new ParsingErrorListener(AbstractDdlParser::accumulateParsingFailure);
+        ParsingErrorListener parsingErrorListener = new ParsingErrorListener(ddlContent, AbstractDdlParser::accumulateParsingFailure);
         parser.addErrorListener(parsingErrorListener);
 
         ParseTree parseTree = parseTree(parser);

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/logminer/OracleDmlParserTest.java
Patch:
@@ -26,6 +26,7 @@
 import io.debezium.connector.oracle.antlr.OracleDmlParser;
 import io.debezium.connector.oracle.jsqlparser.SimpleDmlParser;
 import io.debezium.connector.oracle.junit.SkipTestDependingOnAdapterNameRule;
+import io.debezium.connector.oracle.junit.SkipWhenAdapterNameIs;
 import io.debezium.connector.oracle.junit.SkipWhenAdapterNameIsNot;
 import io.debezium.connector.oracle.junit.SkipWhenAdapterNameIsNot.AdapterName;
 import io.debezium.connector.oracle.logminer.valueholder.LogMinerColumnValue;
@@ -94,6 +95,7 @@ record = sqlDmlParser.parse(dml, tables, "1");
     }
 
     @Test
+    @SkipWhenAdapterNameIs(value = SkipWhenAdapterNameIs.AdapterName.LOGMINER, reason = "Validation fails, will be fixed in DBZ-2784")
     public void shouldParseTimestampFormats() throws Exception {
         String createStatement = IoUtil.read(IoUtil.getResourceAsStream("ddl/create_table.sql", null, getClass(), null, null));
         ddlParser.parse(createStatement, tables);

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoUtil.java
Patch:
@@ -341,7 +341,8 @@ protected static ServerAddress getPrimaryAddress(MongoClient client) {
         if (serverDescriptions == null || serverDescriptions.size() == 0) {
             throw new DebeziumException("Unable to read server descriptions from MongoDB connection, got '" + serverDescriptions + "'");
         }
-        return new ServerAddress(serverDescriptions.get(0).getPrimary());
+        ServerAddress serverAddress = serverDescriptions.get(0).getAddress();
+        return new ServerAddress(serverAddress.getHost(), serverAddress.getPort());
     }
 
     private MongoUtil() {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -727,7 +727,7 @@ public static int validateDatabaseSchema(Configuration config, Field field, Vali
     }
 
     public static int validateOutServerName(Configuration config, Field field, ValidationOutput problems) {
-        if (ConnectorAdapter.XSTREAM.equals(ConnectorAdapter.parse(config.getString(XSTREAM_SERVER_NAME)))) {
+        if (ConnectorAdapter.XSTREAM.equals(ConnectorAdapter.parse(config.getString(CONNECTOR_ADAPTER)))) {
             return Field.isRequired(config, field, problems);
         }
         return 0;

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/CassandraConnectorTask.java
Patch:
@@ -192,7 +192,6 @@ void addProcessor(AbstractProcessor processor) {
 
         void start() {
             executorService = Executors.newFixedThreadPool(processors.size());
-            LOGGER.info("Starting processor group {}", getName());
             for (AbstractProcessor processor : processors) {
                 Runnable runnable = () -> {
                     try {
@@ -216,7 +215,7 @@ void start() {
         void terminate() throws Exception {
             stopProcessors();
             LOGGER.info("Terminating processor group {}", getName());
-            if (!executorService.isShutdown()) {
+            if (executorService != null && !executorService.isShutdown()) {
                 executorService.shutdown();
                 if (!executorService.awaitTermination(1, TimeUnit.SECONDS)) {
                     executorService.shutdownNow();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -186,8 +186,8 @@ public class OracleConnectorConfig extends HistorizedRelationalDatabaseConnector
             .withType(Type.LONG)
             .withWidth(Width.SHORT)
             .withImportance(Importance.MEDIUM)
-            .withDefault(4)
-            .withDescription("Hours to keep Log Mining history");
+            .withDefault(0)
+            .withDescription("Hours to keep Log Mining history.  By default, no history is retained.");
 
     public static final Field RAC_SYSTEM = Field.create("database.rac")
             .withDisplayName("Oracle RAC")

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -1686,7 +1686,7 @@ public void testCustomSnapshotterSnapshotCompleteLifecycleHook() throws Exceptio
                         }
                         return ret;
                     });
-            assertEquals(snapshotCompleteState, Collections.singletonList("complete"));
+            assertEquals(Collections.singletonList("complete"), snapshotCompleteState);
         }
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnection.java
Patch:
@@ -18,7 +18,6 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
-import java.util.Optional;
 import java.util.Set;
 import java.util.function.Supplier;
 import java.util.stream.Collectors;
@@ -30,7 +29,6 @@
 import io.debezium.connector.oracle.OracleConnectorConfig.ConnectorAdapter;
 import io.debezium.jdbc.JdbcConnection;
 import io.debezium.relational.Column;
-import io.debezium.relational.ColumnEditor;
 import io.debezium.relational.TableEditor;
 import io.debezium.relational.TableId;
 import io.debezium.relational.Tables;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerHistoryRecorder.java
Patch:
@@ -88,8 +88,8 @@ public LogMinerHistoryRecorder(LogMinerMetrics metrics, JdbcConfiguration config
      * todo check if set "_optimizer_gather_stats_on_conventional_dml"=FALSE will eliminate occasional ORA-01438
      */
     @Override
-    public void insertIntoTempTable(BigDecimal scn, String tableName, String segOwner, int operationCode, Timestamp changeTime,
-                                    String transactionId, int csf, String redoSql) {
+    public void record(BigDecimal scn, String tableName, String segOwner, int operationCode, Timestamp changeTime,
+                       String transactionId, int csf, String redoSql) {
         if (metrics.getRecordMiningHistory() && executor != null) {
             executor.execute(() -> {
                 try {
@@ -144,7 +144,7 @@ public void insertIntoTempTable(BigDecimal scn, String tableName, String segOwne
      * This approach helps in possible performance degradation of inserting into a large table record by record.
      */
     @Override
-    public void doBulkHistoryInsert() {
+    public void flush() {
         if (metrics.getRecordMiningHistory() && executor != null) {
             executor.execute(() -> {
                 Instant now = Instant.now();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/RowMapper.java
Patch:
@@ -163,7 +163,7 @@ public static String getSqlRedo(TransactionalBufferMetrics metrics, ResultSet rs
 
             int csf = rs.getInt(CSF);
             if (isDml) {
-                historyRecorder.insertIntoTempTable(scn, tableName, segOwner, operationCode, changeTime, txId, csf, redoSql);
+                historyRecorder.record(scn, tableName, segOwner, operationCode, changeTime, txId, csf, redoSql);
             }
 
             // 0 - indicates SQL_REDO is contained within the same row
@@ -178,7 +178,7 @@ public static String getSqlRedo(TransactionalBufferMetrics metrics, ResultSet rs
                 result.append(rs.getString(SQL_REDO));
                 csf = rs.getInt(CSF);
                 if (isDml) {
-                    historyRecorder.insertIntoTempTable(scn, tableName, segOwner, operationCode, changeTime, txId, csf, rs.getString(SQL_REDO));
+                    historyRecorder.record(scn, tableName, segOwner, operationCode, changeTime, txId, csf, rs.getString(SQL_REDO));
                 }
             }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorTask.java
Patch:
@@ -36,6 +36,7 @@ public class OracleConnectorTask extends BaseSourceTask {
     private volatile OracleTaskContext taskContext;
     private volatile ChangeEventQueue<DataChangeEvent> queue;
     private volatile OracleConnection jdbcConnection;
+    private volatile OracleConnection historyRecorderConnection;
     private volatile ErrorHandler errorHandler;
     private volatile OracleDatabaseSchema schema;
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/jsqlparser/SimpleDmlParser.java
Patch:
@@ -89,7 +89,6 @@ public LogMinerDmlEntry parse(String dmlContent, Tables tables, String txId) {
                 LOGGER.debug("Cannot parse NULL , transaction: {}", txId);
                 return null;
             }
-            // todo investigate: happens on CTAS
             if (dmlContent.endsWith(";null;")) {
                 dmlContent = dmlContent.substring(0, dmlContent.lastIndexOf(";null;"));
             }
@@ -134,7 +133,7 @@ else if (st instanceof Delete) {
 
         }
         catch (Throwable e) {
-            LOGGER.error("Cannot parse statement : {}, transaction: {}, due to the {}", dmlContent, txId, e);
+            LOGGER.error("Cannot parse statement : {}, transaction: {}, due to the {}", dmlContent, txId, e.getMessage());
             return null;
         }
 

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleDdlParserTest.java
Patch:
@@ -89,7 +89,6 @@ public void shouldParseCreateAndAlterTable() throws Exception {
         testColumn(alteredTable, "COL21", true, Types.VARCHAR, "VARCHAR2", 20, null, true, null);
         testColumn(alteredTable, "COL22", true, Types.NUMERIC, "NUMBER", 19, 0, true, null);
 
-        // todo check real LogMiner entry, maybe this entry never happens
         ddl = "alter table " + TABLE_NAME + " add col23 varchar2(20);";
         try {
             parser.parse(ddl, tables);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSnapshotChangeEventSource.java
Patch:
@@ -187,10 +187,10 @@ private Optional<Long> getLatestTableDdlScn(RelationalSnapshotContext ctx) throw
             return Optional.of(rs.getLong(1));
         }
         catch (SQLException e) {
-            if (e.getMessage().startsWith("ORA-08180")) {
+            if (e.getErrorCode() == 8180) {
                 // DBZ-1446 In this use case we actually do not want to propagate the exception but
                 // rather return an empty optional value allowing the current SCN to take prior.
-                LOGGER.debug("No latest table SCN could be resolved, defaulting to current SCN");
+                LOGGER.info("No latest table SCN could be resolved, defaulting to current SCN");
                 return Optional.empty();
             }
             throw e;

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerErrorHandler.java
Patch:
@@ -28,6 +28,8 @@ protected boolean isRetriable(Throwable throwable) {
                         || throwable.getMessage().contains("Connection timed out (Write failed)")
                         || throwable.getMessage().contains("The connection has been closed.")
                         || throwable.getMessage().contains("Connection reset")
-                        || throwable.getMessage().contains("SHUTDOWN is in progress"));
+                        || throwable.getMessage().contains("SHUTDOWN is in progress")
+                        || throwable.getMessage()
+                                .startsWith("An insufficient number of arguments were supplied for the procedure or function cdc.fn_cdc_get_all_changes_"));
     }
 }

File: debezium-testing/debezium-testing-testcontainers/src/main/java/io/debezium/testing/testcontainers/ConnectorConfiguration.java
Patch:
@@ -18,11 +18,11 @@
  */
 public class ConnectorConfiguration {
 
-    private final ObjectMapper mapper = new ObjectMapper();
     private final ObjectNode configNode;
 
     protected ConnectorConfiguration() {
-        this.configNode = this.mapper.createObjectNode();
+        ObjectMapper mapper = new ObjectMapper();
+        this.configNode = mapper.createObjectNode();
         this.configNode.put("tasks.max", 1);
     }
 

File: debezium-testing/debezium-testing-testcontainers/src/test/java/io/debezium/testing/testcontainers/DebeziumContainerTest.java
Patch:
@@ -47,9 +47,9 @@ public class DebeziumContainerTest {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(DebeziumContainerTest.class);
 
-    private static Network network = Network.newNetwork();
+    private static final Network network = Network.newNetwork();
 
-    private static KafkaContainer kafkaContainer = new KafkaContainer()
+    private static final KafkaContainer kafkaContainer = new KafkaContainer()
             .withNetwork(network);
 
     public static PostgreSQLContainer<?> postgresContainer = new PostgreSQLContainer<>("debezium/postgres:11")
@@ -78,7 +78,7 @@ public void canRegisterConnector() throws Exception {
                 .atMost(Duration.ofSeconds(30))
                 .untilAsserted(
                         () -> {
-                            String status = executeHttpRequest(debeziumContainer.getConnectorStatus("my-connector-1"));
+                            String status = executeHttpRequest(debeziumContainer.getConnectorStatusURI("my-connector-1"));
 
                             assertThat(JsonPath.<String> read(status, "$.name")).isEqualTo("my-connector-1");
                             assertThat(JsonPath.<String> read(status, "$.connector.state")).isEqualTo("RUNNING");

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnection.java
Patch:
@@ -156,8 +156,8 @@ public Lsn getMaxLsn() throws SQLException {
         }, "Maximum LSN query must return exactly one value"));
     }
 
-    public MaxLsnResult getMaxLsnResult(boolean skipLowActivityLSNsEnabled) throws SQLException {
-        if (skipLowActivityLSNsEnabled) {
+    public MaxLsnResult getMaxLsnResult(boolean skipLowActivityLsnsEnabled) throws SQLException {
+        if (skipLowActivityLsnsEnabled) {
             return prepareQueryAndMap(GET_MAX_LSN_SKIP_LOW_ACTIVTY, statement -> {
             }, singleResultMapper(rs -> {
                 final MaxLsnResult ret = new MaxLsnResult(Lsn.valueOf(rs.getBytes(1)), Lsn.valueOf(rs.getBytes(2)));

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerStreamingChangeEventSource.java
Patch:
@@ -125,7 +125,7 @@ public void execute(ChangeEventSourceContext context) throws InterruptedExceptio
                 if (connectorConfig.isReadOnlyDatabaseConnection()) {
                     dataConnection.commit();
                 }
-                final MaxLsnResult maxLsnResult = dataConnection.getMaxLsnResult(connectorConfig.isSkipLowActivityLSNsEnabled());
+                final MaxLsnResult maxLsnResult = dataConnection.getMaxLsnResult(connectorConfig.isSkipLowActivityLsnsEnabled());
 
                 // Shouldn't happen if the agent is running, but it is better to guard against such situation
                 if (!maxLsnResult.getMaxLsn().isAvailable() || !maxLsnResult.getMaxTransactionalLsn().isAvailable()) {

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorConfig.java
Patch:
@@ -285,9 +285,9 @@ public static SnapshotIsolationMode parse(String value, String defaultValue) {
             .withDescription("The timezone of the server used to correctly shift the commit transaction timestamp on the client side"
                     + "Options include: Any valid Java ZoneId");
 
-    public static final Field STREAMING_MAX_LSN_SELECT_STATEMENT = Field.create("streaming.max.lsn.select.statement")
+    public static final Field STREAMING_MAX_LSN_SELECT_STATEMENT = Field.createInternal("streaming.max.lsn.select.statement")
             .withDisplayName("A select statement for the maximum lsn to utilize when determining if changes tables should be queried.")
-            .withDefault("")
+            .withDefault("SELECT MAX(start_lsn) FROM cdc.lsn_time_mapping WHERE tran_id <> 0x00")
             .withType(Type.STRING)
             .withWidth(Width.LONG)
             .withImportance(Importance.LOW)

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerStreamingChangeEventSource.java
Patch:
@@ -136,6 +136,7 @@ public void execute(ChangeEventSourceContext context) throws InterruptedExceptio
                 // There is no change in the database
                 if (maxLsnResult.getMaxTransactionalLsn().compareTo(lastProcessedPosition.getCommitLsn()) <= 0 && shouldIncreaseFromLsn) {
                     LOGGER.debug("No change in the database");
+                    metronome.pause();
                     continue;
                 }
 

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSnapshotChangeEventSource.java
Patch:
@@ -17,6 +17,7 @@
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.stream.Collectors;
 
 import org.apache.kafka.connect.errors.ConnectException;
 import org.bson.BsonTimestamp;
@@ -342,7 +343,7 @@ private void createDataEventsForReplicaSet(ChangeEventSourceContext sourceContex
 
         LOGGER.info("Beginning snapshot of '{}' at {}", rsName, rsOffsetContext.getOffset());
 
-        final Set<CollectionId> collections = determineAllowedDataCollectionsForSnapshot(primaryClient.collections());
+        final List<CollectionId> collections = determineDataCollectionsToBeSnapshotted(primaryClient.collections()).collect(Collectors.toList());
         snapshotProgressListener.monitoredDataCollectionsDetermined(collections);
         if (connectionContext.maxNumberOfCopyThreads() > 1) {
             // Since multiple copy threads are to be used, create a thread pool and initiate the copy.

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorIT.java
Patch:
@@ -966,6 +966,7 @@ record = records.recordsForTopic("mongo.dbit.fieldnamedop").get(1);
     }
 
     @Test
+    @FixFor("DBZ-2456")
     public void shouldSelectivelySnapshot() throws InterruptedException {
         config = TestHelper.getConfiguration().edit()
                 .with(MongoDbConnectorConfig.POLL_INTERVAL_MS, 10)

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SnapshotReader.java
Patch:
@@ -255,7 +255,7 @@ protected void execute() {
         final List<TableId> tablesToSnapshotSchemaAfterUnlock = new ArrayList<>();
         Set<TableId> lockedTables = Collections.emptySet();
 
-        final Set<String> snapshotAllowedTables = context.getConnectorConfig().getSnapshotAllowedTables();
+        final Set<String> snapshotAllowedTables = context.getConnectorConfig().getDataCollectionsToBeSnapshotted();
         final Predicate<TableId> isAllowedForSnapshot = tableId -> snapshotAllowedTables.size() == 0
                 || snapshotAllowedTables.stream().anyMatch(s -> tableId.identifier().matches(s));
         try {
@@ -408,7 +408,6 @@ protected void execute() {
                                 else {
                                     logger.info("\t '{}' is not added among known tables", id);
                                 }
-                                //
                                 if (filters.tableFilter().and(isAllowedForSnapshot).test(id)) {
                                     capturedTableIds.add(id);
                                     logger.info("\t including '{}' for further processing", id);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -1159,6 +1159,7 @@ record = s2recs.get(0);
     }
 
     @Test
+    @FixFor("DBZ-2456")
     public void shouldAllowForSelectiveSnapshot() throws InterruptedException {
         TestHelper.execute(SETUP_TABLES_STMT);
         Configuration.Builder configBuilder = TestHelper.defaultConfig()

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SnapshotIT.java
Patch:
@@ -371,6 +371,7 @@ public void testBlacklistColumn() throws Exception {
     }
 
     @Test
+    @FixFor("DBZ-2456")
     public void shouldSelectivelySnapshotTables() throws SQLException, InterruptedException {
         connection.execute(
                 "CREATE TABLE table_a (id int, name varchar(30), amount integer primary key(id))",

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -312,7 +312,7 @@ public static BinaryHandlingMode parse(String value, String defaultValue) {
             .withValidation(Field::isNonNegativeInteger);
 
     public static final Field SNAPSHOT_MODE_TABLES = Field.create("snapshot.include.collection.list")
-            .withDisplayName("Snapshot Mode include Data Collection")
+            .withDisplayName("Snapshot mode include data collection")
             .withType(Type.LIST)
             .withWidth(Width.LONG)
             .withImportance(Importance.MEDIUM)
@@ -553,7 +553,7 @@ public Set<Envelope.Operation> getSkippedOps() {
         }
     }
 
-    public Set<String> getSnapshotAllowedTables() {
+    public Set<String> getDataCollectionsToBeSnapshotted() {
         return Optional.ofNullable(config.getString(SNAPSHOT_MODE_TABLES))
                 .map(tables -> Strings.setOf(tables, Function.identity()))
                 .orElseGet(Collections::emptySet);

File: debezium-core/src/main/java/io/debezium/relational/RelationalSnapshotChangeEventSource.java
Patch:
@@ -186,7 +186,7 @@ private Set<TableId> sort(Set<TableId> capturedTables) throws Exception {
     }
 
     private void determineCapturedTables(RelationalSnapshotContext ctx) throws Exception {
-        Set<TableId> allTableIds = determineAllowedDataCollectionsForSnapshot(getAllTableIds(ctx));
+        Set<TableId> allTableIds = determineDataCollectionsToBeSnapshotted(getAllTableIds(ctx)).collect(Collectors.toSet());
 
         Set<TableId> capturedTables = new HashSet<>();
 

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSnapshotChangeEventSource.java
Patch:
@@ -12,7 +12,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Queue;
-import java.util.Set;
 import java.util.concurrent.ConcurrentLinkedQueue;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutorService;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ConnectionContext.java
Patch:
@@ -6,6 +6,7 @@
 package io.debezium.connector.mongodb;
 
 import java.time.Duration;
+import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
@@ -397,12 +398,12 @@ public Set<String> databaseNames() {
          *
          * @return the collection identifiers; never null
          */
-        public Set<CollectionId> collections() {
+        public List<CollectionId> collections() {
             String replicaSetName = replicaSet.replicaSetName();
 
             // For each database, get the list of collections ...
             return execute("get collections in databases", primary -> {
-                Set<CollectionId> collections = new HashSet<>();
+                List<CollectionId> collections = new ArrayList<>();
                 Set<String> databaseNames = databaseNames();
 
                 for (String dbName : databaseNames) {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -175,11 +175,11 @@ protected DataTypeResolver initializeDataTypeResolver() {
                 new DataTypeEntry(Types.TIMESTAMP, MySqlParser.DATETIME),
                 new DataTypeEntry(Types.BINARY, MySqlParser.BINARY),
                 new DataTypeEntry(Types.VARBINARY, MySqlParser.VARBINARY),
+                new DataTypeEntry(Types.BLOB, MySqlParser.BLOB),
                 new DataTypeEntry(Types.INTEGER, MySqlParser.YEAR)));
         dataTypeResolverBuilder.registerDataTypes(MySqlParser.SimpleDataTypeContext.class.getCanonicalName(), Arrays.asList(
                 new DataTypeEntry(Types.DATE, MySqlParser.DATE),
                 new DataTypeEntry(Types.BLOB, MySqlParser.TINYBLOB),
-                new DataTypeEntry(Types.BLOB, MySqlParser.BLOB),
                 new DataTypeEntry(Types.BLOB, MySqlParser.MEDIUMBLOB),
                 new DataTypeEntry(Types.BLOB, MySqlParser.LONGBLOB),
                 new DataTypeEntry(Types.BOOLEAN, MySqlParser.BOOL),

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/CreateTableParserListener.java
Patch:
@@ -55,7 +55,7 @@ public void exitColumnCreateTable(MySqlParser.ColumnCreateTableContext ctx) {
         parser.runIfNotNull(() -> {
             // Make sure that the table's character set has been set ...
             if (!tableEditor.hasDefaultCharsetName()) {
-                tableEditor.setDefaultCharsetName(parser.currentDatabaseCharset());
+                tableEditor.setDefaultCharsetName(parser.charsetForTable(tableEditor.tableId()));
             }
             listeners.remove(columnDefinitionListener);
             columnDefinitionListener = null;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/CreateViewParserListener.java
Patch:
@@ -56,7 +56,7 @@ public void exitCreateView(MySqlParser.CreateViewContext ctx) {
             tableEditor.addColumns(selectColumnsListener.getSelectedColumns());
             // Make sure that the table's character set has been set ...
             if (!tableEditor.hasDefaultCharsetName()) {
-                tableEditor.setDefaultCharsetName(parser.currentDatabaseCharset());
+                tableEditor.setDefaultCharsetName(parser.charsetForTable(tableEditor.tableId()));
             }
             parser.databaseTables().overwriteTable(tableEditor.create());
             listeners.remove(selectColumnsListener);

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSchema.java
Patch:
@@ -7,6 +7,7 @@
 
 import java.util.HashMap;
 import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
 import java.util.function.Function;
 
 import org.apache.kafka.connect.data.Schema;
@@ -56,7 +57,7 @@ public class MongoDbSchema implements DatabaseSchema<CollectionId> {
     private final Schema sourceSchema;
     private final SchemaNameAdjuster adjuster = SchemaNameAdjuster.create(LOGGER);
     private final Function<Document, String> valueTransformer;
-    private final Map<CollectionId, MongoDbCollectionSchema> collections = new HashMap<>();
+    private final Map<CollectionId, MongoDbCollectionSchema> collections = new ConcurrentHashMap<>();
 
     public MongoDbSchema(Filters filters, TopicSelector<CollectionId> topicSelector, Schema sourceSchema) {
         this.filters = filters;

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -6,7 +6,6 @@
 
 package io.debezium.connector.postgresql;
 
-import static org.fest.assertions.Assertions.assertThat;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.fail;
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -8,6 +8,7 @@
 
 import static org.fest.assertions.Assertions.assertThat;
 import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.fail;
 
 import java.net.URL;
 import java.nio.charset.Charset;
@@ -342,8 +343,8 @@ protected static void assertNoOpenTransactions() throws SQLException {
                         .until(() -> getOpenIdleTransactions(connection).size() == 0);
             }
             catch (ConditionTimeoutException e) {
+                fail("Expected no open transactions but there was at least one.");
             }
-            assertThat(getOpenIdleTransactions(connection)).hasSize(0);
         }
     }
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnection.java
Patch:
@@ -108,7 +108,7 @@ public Set<TableId> readTableNames(String databaseCatalog, String schemaNamePatt
     }
 
     protected Set<TableId> getAllTableIds(String catalogName, String schemaNamePattern, boolean isView) throws SQLException {
-
+        schemaNamePattern = schemaNamePattern == null ? "" : schemaNamePattern;
         String query = "select table_name, owner from all_tables where table_name NOT LIKE 'MDRT_%' AND table_name not LIKE 'MDXT_%' " +
                 " and owner like '%" + schemaNamePattern.toUpperCase() + "%'";
         if (isView) {

File: debezium-embedded/src/test/java/io/debezium/embedded/AbstractConnectorTest.java
Patch:
@@ -29,6 +29,7 @@
 import java.util.function.Predicate;
 import java.util.stream.Collectors;
 
+import javax.management.InstanceNotFoundException;
 import javax.management.MBeanServer;
 import javax.management.MalformedObjectNameException;
 import javax.management.ObjectName;
@@ -875,6 +876,7 @@ public static void waitForSnapshotToBeCompleted(String connector, String server)
                 .alias("Streaming was not started on time")
                 .pollInterval(100, TimeUnit.MILLISECONDS)
                 .atMost(60, TimeUnit.SECONDS)
+                .ignoreException(InstanceNotFoundException.class)
                 .until(() -> {
                     boolean snapshotCompleted = (boolean) mbeanServer
                             .getAttribute(getSnapshotMetricsObjectName(connector, server), "SnapshotCompleted");
@@ -894,6 +896,7 @@ public static void waitForStreamingRunning(String connector, String server, Stri
                 .alias("Streaming was not started on time")
                 .pollInterval(100, TimeUnit.MILLISECONDS)
                 .atMost(60, TimeUnit.SECONDS)
+                .ignoreException(InstanceNotFoundException.class)
                 .until(() -> {
                     boolean connected = (boolean) mbeanServer
                             .getAttribute(getStreamingMetricsObjectName(connector, server, contextName), "Connected");

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/RowMapper.java
Patch:
@@ -169,7 +169,7 @@ private static void logError(TransactionalBufferMetrics metrics, SQLException e,
     }
 
     public static TableId getTableId(String catalogName, ResultSet rs) throws SQLException {
-        return new TableId(catalogName.toUpperCase(), rs.getString(SEG_OWNER).toUpperCase(), rs.getString(TABLE_NAME).toUpperCase());
+        return new TableId(catalogName, rs.getString(SEG_OWNER), rs.getString(TABLE_NAME));
     }
 
 }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -601,6 +601,7 @@ public void shouldExecuteOnConnectStatements() throws Exception {
                 .with(PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE);
         start(PostgresConnector.class, configBuilder.build());
         assertConnectorIsRunning();
+        waitForStreamingRunning();
 
         SourceRecords actualRecords = consumeRecordsByTopic(6);
         assertKey(actualRecords.allRecordsInOrder().get(0), "pk", 1);

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorIT.java
Patch:
@@ -745,6 +745,8 @@ public void verifyOffsets() throws Exception {
         final String tableaCT = connection.getNameOfChangeTable("tablea");
         final String tablebCT = connection.getNameOfChangeTable("tableb");
 
+        TestHelper.waitForCdcRecord(connection, "tableb", rs -> rs.getInt("id") == expectedIds.get(expectedIds.size() - 1));
+
         Awaitility.await().atMost(30, TimeUnit.SECONDS).until(() -> {
             // Wait for max lsn to be available
             if (!connection.getMaxLsn().isAvailable()) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/jsqlparser/SimpleDmlParser.java
Patch:
@@ -226,7 +226,7 @@ private void setNewValues(List<Expression> expressions, List<net.sf.jsqlparser.s
             Object stripedValue = ParserUtils.removeApostrophes(value);
             Column column = table.columnWithName(columnName);
             if (column == null) {
-                LOGGER.trace("blacklisted column: {}", columnName);
+                LOGGER.trace("excluded column: {}", columnName);
                 continue;
             }
             Object valueObject = ParserUtils.convertValueToSchemaType(column, stripedValue, converter);
@@ -252,7 +252,7 @@ public void visit(EqualsTo expr) {
 
                 Column column = table.columnWithName(columnName);
                 if (column == null) {
-                    LOGGER.trace("blacklisted column in where clause: {}", columnName);
+                    LOGGER.trace("excluded column in where clause: {}", columnName);
                     return;
                 }
                 value = ParserUtils.removeApostrophes(value);
@@ -273,7 +273,7 @@ public void visit(IsNullExpression expr) {
                 columnName = ParserUtils.stripeQuotes(columnName);
                 Column column = table.columnWithName(columnName);
                 if (column == null) {
-                    LOGGER.trace("blacklisted column in where clause: {}", columnName);
+                    LOGGER.trace("excluded column in where clause: {}", columnName);
                     return;
                 }
                 LogMinerColumnValueWrapper logMinerColumnValueWrapper = oldColumnValues.get(columnName.toUpperCase());

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerQueryResultProcessor.java
Patch:
@@ -161,12 +161,12 @@ int processResult(ResultSet resultSet) {
                     continue;
                 }
 
-                // this will happen for instance on a blacklisted column change, we will omit this update
+                // this will happen for instance on a excluded column change, we will omit this update
                 if (dmlEntry.getCommandType().equals(Envelope.Operation.UPDATE)
                         && dmlEntry.getOldValues().size() == dmlEntry.getNewValues().size()
                         && dmlEntry.getNewValues().containsAll(dmlEntry.getOldValues())) {
                     LOGGER.trace("Following DML was skipped, " +
-                            "most likely because of ignored blacklisted column change: {}, details: {}", redo_sql, logMessage);
+                            "most likely because of ignored excluded column change: {}, details: {}", redo_sql, logMessage);
                     continue;
                 }
 

File: debezium-quarkus-outbox/integration-tests/src/test/java/io/debezium/outbox/quarkus/it/DatabaseTestResource.java
Patch:
@@ -39,7 +39,7 @@ public Map<String, String> start() {
                     .withStartupTimeout(Duration.ofSeconds(30));
 
             container.start();
-            return Collections.singletonMap("quarkus.datasource.url", container.getJdbcUrl());
+            return Collections.singletonMap("quarkus.datasource.jdbc.url", container.getJdbcUrl());
         }
         catch (Exception e) {
             throw new RuntimeException(e);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorTask.java
Patch:
@@ -55,8 +55,7 @@ public ChangeEventSourceCoordinator start(Configuration config) {
         this.schema = new OracleDatabaseSchema(connectorConfig, schemaNameAdjuster, topicSelector, jdbcConnection);
         this.schema.initializeStorage();
 
-        String adapterString = config.getString("connection.adapter");
-        adapterString = adapterString == null ? config.getString(OracleConnectorConfig.CONNECTOR_ADAPTER) : adapterString;
+        String adapterString = config.getString(OracleConnectorConfig.CONNECTOR_ADAPTER);
         OracleConnectorConfig.ConnectorAdapter adapter = OracleConnectorConfig.ConnectorAdapter.parse(adapterString);
         OffsetContext previousOffset = getPreviousOffset(new OracleOffsetContext.Loader(connectorConfig, adapter));
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/antlr/OracleDmlParser.java
Patch:
@@ -25,10 +25,10 @@
  */
 public class OracleDmlParser extends AntlrDdlParser<PlSqlLexer, PlSqlParser> {
 
+    protected final String catalogName;
+    protected final String schemaName;
+    private final OracleChangeRecordValueConverter converter;
     private LogMinerDmlEntry dmlEntry;
-    protected String catalogName;
-    protected String schemaName;
-    private OracleChangeRecordValueConverter converter;
 
     public OracleDmlParser(boolean throwErrorsFromTreeWalk, final String catalogName, final String schemaName, OracleChangeRecordValueConverter converter) {
         super(throwErrorsFromTreeWalk);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/logminer/LogMinerStreamingChangeEventSource.java
Patch:
@@ -122,8 +122,8 @@ public void execute(ChangeEventSourceContext context) {
 
                 startScn = offsetContext.getScn();
                 createAuditTable(connection);
-                LOGGER.trace("current millis {}, db time {}", System.currentTimeMillis(), getTimeDifference(connection));
-                transactionalBufferMetrics.setTimeDifference(new AtomicLong(getTimeDifference(connection)));
+                LOGGER.trace("current millis {}, db time {}", System.currentTimeMillis(), getTimeDifference(connection).toMillis());
+                transactionalBufferMetrics.setTimeDifference(new AtomicLong(getTimeDifference(connection).toMillis()));
 
                 if (!isContinuousMining && startScn < getFirstOnlineLogScn(connection)) {
                     throw new RuntimeException("Online REDO LOG files don't contain the offset SCN. Clean offset and start over");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorFilterIT.java
Patch:
@@ -33,6 +33,7 @@
 import io.debezium.connector.oracle.util.TestHelper;
 import io.debezium.data.VerifyRecord;
 import io.debezium.embedded.AbstractConnectorTest;
+import io.debezium.relational.RelationalDatabaseConnectorConfig;
 import io.debezium.util.Testing;
 
 /**

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/xstream/LcrEventHandler.java
Patch:
@@ -29,7 +29,7 @@
  */
 class LcrEventHandler implements XStreamLCRCallbackHandler {
 
-    private static final Logger LOGGER = LoggerFactory.getLogger(XstreamStreamingChangeEventSource.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(LcrEventHandler.class);
 
     private final ErrorHandler errorHandler;
     private final EventDispatcher<TableId> dispatcher;

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/util/TestHelper.java
Patch:
@@ -123,7 +123,7 @@ public static OracleConnection defaultConnection() {
     public static OracleConnection logMinerPdbConnection() {
         Configuration jdbcConfig = testJdbcConfig().edit()
                 .with(OracleConnectorConfig.CONNECTOR_ADAPTER, "LogMiner")
-                .with(OracleConnectorConfig.DRIVER_TYPE, "thin")
+                // .with(OracleConnectorConfig.DRIVER_TYPE, "thin")
                 .build();
         return new OracleConnection(jdbcConfig, new OracleConnectionFactory(), TestHelper.class::getClassLoader);
     }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerChangeTablePointer.java
Patch:
@@ -122,7 +122,7 @@ private ResultSetMapper<Object[]> createResultSetMapper(Table table) throws SQLE
         else {
             final IndicesMapping indicesMapping = new IndicesMapping(sourceTableColumns, resultColumns);
             return resultSet -> {
-                final Object[] data = new Object[resultColumnCount];
+                final Object[] data = new Object[sourceColumnCount];
                 for (int i = 0; i < resultColumnCount; i++) {
                     int index = indicesMapping.getSourceTableColumnIndex(i);
                     data[index] = getColumnData(resultSet, columnDataOffset + i);

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSnapshotChangeEventSource.java
Patch:
@@ -500,7 +500,7 @@ public static class MongoDbSnapshottingTask extends SnapshottingTask {
         private final List<ReplicaSet> replicaSetsToSnapshot;
 
         public MongoDbSnapshottingTask(List<ReplicaSet> replicaSetsToSnapshot) {
-            super(false, !replicaSetsToSnapshot.isEmpty(), false);
+            super(false, !replicaSetsToSnapshot.isEmpty());
             this.replicaSetsToSnapshot = replicaSetsToSnapshot;
         }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSnapshotChangeEventSource.java
Patch:
@@ -71,7 +71,7 @@ protected SnapshottingTask getSnapshottingTask(OffsetContext previousOffset) {
             snapshotSchema = false;
         }
 
-        return new SnapshottingTask(snapshotSchema, snapshotData, false);
+        return new SnapshottingTask(snapshotSchema, snapshotData);
     }
 
     @Override
@@ -214,7 +214,7 @@ protected void complete(SnapshotContext snapshotContext) {
     }
 
     @Override
-    protected Optional<String> getSnapshotSelect(SnapshotContext snapshotContext, TableId tableId) {
+    protected Optional<String> getSnapshotSelect(RelationalSnapshotContext snapshotContext, TableId tableId) {
         return snapshotter.buildSnapshotQuery(tableId);
     }
 

File: debezium-core/src/main/java/io/debezium/relational/RelationalSnapshotChangeEventSource.java
Patch:
@@ -391,7 +391,7 @@ protected ChangeRecordEmitter getChangeRecordEmitter(SnapshotContext snapshotCon
      * @param tableId the table to generate a query for
      * @return a valid query string or empty if table will not be snapshotted
      */
-    private Optional<String> determineSnapshotSelect(SnapshotContext snapshotContext, TableId tableId) {
+    private Optional<String> determineSnapshotSelect(RelationalSnapshotContext snapshotContext, TableId tableId) {
         String overriddenSelect = connectorConfig.getSnapshotSelectOverridesByTable().get(tableId);
 
         // try without catalog id, as this might or might not be populated based on the given connector
@@ -408,7 +408,7 @@ private Optional<String> determineSnapshotSelect(SnapshotContext snapshotContext
      * @param overriddenSelect conditional snapshot select
      * @return enhanced select statement. By default it just returns original select statements.
      */
-    protected String enhanceOverriddenSelect(SnapshotContext snapshotContext, String overriddenSelect, TableId tableId) {
+    protected String enhanceOverriddenSelect(RelationalSnapshotContext snapshotContext, String overriddenSelect, TableId tableId) {
         return overriddenSelect;
     }
 
@@ -419,7 +419,7 @@ protected String enhanceOverriddenSelect(SnapshotContext snapshotContext, String
     // TODO Should it be Statement or similar?
     // TODO Handle override option generically; a problem will be how to handle the dynamic part (Oracle's "... as of
     // scn xyz")
-    protected abstract Optional<String> getSnapshotSelect(SnapshotContext snapshotContext, TableId tableId);
+    protected abstract Optional<String> getSnapshotSelect(RelationalSnapshotContext snapshotContext, TableId tableId);
 
     private Column[] getColumnsForResultSet(Table table, ResultSet rs) throws SQLException {
         ResultSetMetaData metaData = rs.getMetaData();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/Filters.java
Patch:
@@ -121,7 +121,6 @@ public Builder(Configuration config) {
                 this.columnFilter = ColumnNameFilterFactory.createIncludeListFilter(includeColumnsFilter);
             }
             else {
-                // Define the filter that excludes blacklisted columns, truncated columns, and masked columns ...
                 this.columnFilter = ColumnNameFilterFactory
                         .createExcludeListFilter(config.getFallbackStringProperty(MySqlConnectorConfig.COLUMN_EXCLUDE_LIST, MySqlConnectorConfig.COLUMN_BLACKLIST));
             }

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/CommitLogReadHandlerImpl.java
Patch:
@@ -425,7 +425,7 @@ private void populateRegularColumns(RowData after, Row row, RowType rowType, Sch
                     Object value;
                     Object deletionTs = null;
                     AbstractType abstractType = cd.type;
-                    if (abstractType.isCollection()) {
+                    if (abstractType.isCollection() && abstractType.isMultiCell()) {
                         ComplexColumnData ccd = row.getComplexColumnData(cd);
                         value = CassandraTypeDeserializer.deserialize((CollectionType) abstractType, ccd);
                     }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerChangeTablePointer.java
Patch:
@@ -130,7 +130,7 @@ private ResultSetMapper<Object[]> createResultSetMapper(Table table) throws SQLE
         else {
             final IndicesMapping indicesMapping = new IndicesMapping(sourceTableColumns, resultColumns);
             return resultSet -> {
-                final Object[] data = new Object[sourceColumnCount];
+                final Object[] data = new Object[resultColumnCount];
                 for (int i = 0; i < resultColumnCount; i++) {
                     int index = indicesMapping.getSourceTableColumnIndex(i);
                     data[index] = getColumnData(resultSet, columnDataOffset + i);

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/ExtractNewDocumentStateTestIT.java
Patch:
@@ -28,6 +28,7 @@
 import org.fest.assertions.Assertions;
 import org.junit.Test;
 
+import io.debezium.connector.mongodb.TestHelper;
 import io.debezium.data.Envelope;
 import io.debezium.data.Envelope.Operation;
 import io.debezium.data.SchemaUtil;
@@ -1434,7 +1435,8 @@ public void testAddPatchFieldAfterUpdate() throws Exception {
         assertThat(value.schema()).isSameAs(transformed.valueSchema());
         assertThat(value.get("id")).isEqualTo(objId.toString());
         assertThat(value.get("a")).isEqualTo(22);
-        assertThat(value.get("__patch")).isEqualTo("{\"$v\": 1,\"$set\": {\"a\": 22}}");
+        String valueJson = TestHelper.getDocumentWithoutLanguageVersion(value.getString("__patch")).toJson();
+        assertThat(valueJson).isEqualTo("{\"$set\": {\"a\": 22}}");
 
         assertThat(value.schema().field("id").schema()).isEqualTo(SchemaBuilder.OPTIONAL_STRING_SCHEMA);
         assertThat(value.schema().field("a").schema()).isEqualTo(SchemaBuilder.OPTIONAL_INT32_SCHEMA);

File: debezium-testing/debezium-testing-openshift/src/main/java/io/debezium/testing/openshift/tools/OpenShiftUtils.java
Patch:
@@ -16,16 +16,16 @@
 import java.util.function.Supplier;
 import java.util.stream.Collectors;
 
-import io.fabric8.kubernetes.api.model.IntOrString;
-import io.fabric8.kubernetes.api.model.Service;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import io.fabric8.kubernetes.api.model.Container;
 import io.fabric8.kubernetes.api.model.EnvVar;
+import io.fabric8.kubernetes.api.model.IntOrString;
 import io.fabric8.kubernetes.api.model.LocalObjectReference;
 import io.fabric8.kubernetes.api.model.Pod;
 import io.fabric8.kubernetes.api.model.PodList;
+import io.fabric8.kubernetes.api.model.Service;
 import io.fabric8.kubernetes.api.model.ServiceAccount;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.networking.NetworkPolicy;

File: debezium-connector-db2/src/main/java/io/debezium/connector/db2/Db2Connection.java
Patch:
@@ -90,7 +90,8 @@ public class Db2Connection extends JdbcConnection {
 
     private static final ConnectionFactory FACTORY = JdbcConnection.patternBasedFactory(URL_PATTERN,
             DB2Driver.class.getName(),
-            Db2Connection.class.getClassLoader());
+            Db2Connection.class.getClassLoader(),
+            JdbcConfiguration.PORT.withDefault(Db2ConnectorConfig.PORT.defaultValueAsString()));
 
     /**
      * actual name of the database, which could differ in casing from the database name given in the connector config.

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/CommitLogProcessor.java
Patch:
@@ -125,8 +125,8 @@ void processCommitLog(File file) throws IOException {
                 if (!latestOnly) {
                     queue.enqueue(new EOFEvent(file, false));
                 }
-                LOGGER.warn("Error occurred while processing commit log " + file.getName(), e);
-                if (commitLogTransfer.getClass().toString() == CassandraConnectorConfig.DEFAULT_COMMIT_LOG_TRANSFER_CLASS) {
+                LOGGER.error("Error occurred while processing commit log " + file.getName(), e);
+                if (commitLogTransfer.getClass().getName().equals(CassandraConnectorConfig.DEFAULT_COMMIT_LOG_TRANSFER_CLASS)) {
                     throw e;
                 }
             }

File: debezium-connector-cassandra/src/test/java/io/debezium/connector/cassandra/CassandraConnectorConfigTest.java
Patch:
@@ -126,9 +126,8 @@ public void testConfigs() {
         config = buildTaskConfig(CassandraConnectorConfig.COMMIT_LOG_POST_PROCESSING_ENABLED.name(), "false");
         assertEquals(false, config.postProcessEnabled());
 
-        boolean shouldReprocessErrorCommitLogs = true;
-        config = buildTaskConfig(CassandraConnectorConfig.COMMIT_LOG_ERROR_REPROCESSING_ENABLED.name(), shouldReprocessErrorCommitLogs);
-        assertEquals(shouldReprocessErrorCommitLogs, config.errorCommitLogReprocessEnabled());
+        config = buildTaskConfig(CassandraConnectorConfig.COMMIT_LOG_ERROR_REPROCESSING_ENABLED.name(), "true");
+        assertTrue(config.errorCommitLogReprocessEnabled());
 
         String transferClazz = "io.debezium.connector.cassandra.BlackHoleCommitLogTransfer";
         config = buildTaskConfig(CassandraConnectorConfig.COMMIT_LOG_TRANSFER_CLASS.name(), transferClazz);

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/CommitLogProcessor.java
Patch:
@@ -126,6 +126,9 @@ void processCommitLog(File file) throws IOException {
                     queue.enqueue(new EOFEvent(file, false));
                 }
                 LOGGER.warn("Error occurred while processing commit log " + file.getName(), e);
+                if (commitLogTransfer.getClass().toString() == CassandraConnectorConfig.DEFAULT_COMMIT_LOG_TRANSFER_CLASS) {
+                    throw e;
+                }
             }
         }
         catch (InterruptedException e) {

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/BlackHoleCommitLogTransfer.java
Patch:
@@ -21,4 +21,7 @@ public void onSuccessTransfer(File file) {
     public void onErrorTransfer(File file) {
         CommitLogUtil.deleteCommitLog(file);
     }
+
+    @Override
+    public void getErrorCommitLogs() {}
 }

File: debezium-connector-db2/src/test/java/io/debezium/connector/db2/Db2ConnectorIT.java
Patch:
@@ -35,6 +35,7 @@
 import io.debezium.doc.FixFor;
 import io.debezium.embedded.AbstractConnectorTest;
 import io.debezium.junit.logging.LogInterceptor;
+import io.debezium.schema.DatabaseSchema;
 import io.debezium.util.Testing;
 
 /**
@@ -707,7 +708,7 @@ public void testEmptySchemaWarningAfterApplyingFilters() throws Exception {
         assertConnectorIsRunning();
         waitForAvailableRecords(100, TimeUnit.MILLISECONDS);
 
-        stopConnector(value -> assertThat(logInterceptor.containsWarnMessage(NO_MONITORED_TABLES_WARNING)).isTrue());
+        stopConnector(value -> assertThat(logInterceptor.containsWarnMessage(DatabaseSchema.NO_CAPTURED_DATA_COLLECTIONS_WARNING)).isTrue());
     }
 
     @Test

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSourceInfoStructMaker.java
Patch:
@@ -45,7 +45,7 @@ public Struct struct(SourceInfo sourceInfo) {
             result.put(SourceInfo.TXID_KEY, sourceInfo.txId());
         }
         if (sourceInfo.lsn() != null) {
-            result.put(SourceInfo.LSN_KEY, sourceInfo.lsn());
+            result.put(SourceInfo.LSN_KEY, sourceInfo.lsn().asLong());
         }
         if (sourceInfo.xmin() != null) {
             result.put(SourceInfo.XMIN_KEY, sourceInfo.xmin());

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/AbstractMessageDecoder.java
Patch:
@@ -47,7 +47,7 @@ protected abstract void processNotEmptyMessage(ByteBuffer buffer, ReplicationMes
             throws SQLException, InterruptedException;
 
     @Override
-    public boolean shouldMessageBeSkipped(ByteBuffer buffer, Long lastReceivedLsn, Long startLsn, boolean skipFirstFlushRecord) {
+    public boolean shouldMessageBeSkipped(ByteBuffer buffer, Lsn lastReceivedLsn, Lsn startLsn, boolean skipFirstFlushRecord) {
         // the lsn we started from is inclusive, so we need to avoid sending back the same message twice
         // but for the first record seen ever it is possible we received the same LSN as the one obtained from replication slot
         if (startLsn.compareTo(lastReceivedLsn) > 0 || (startLsn.equals(lastReceivedLsn) && skipFirstFlushRecord)) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/MessageDecoder.java
Patch:
@@ -69,5 +69,5 @@ default void setContainsMetadata(boolean flag) {
      * @param skipFirstFlushRecord whether first flush record should be skipped
      * @return {@code true} if the incoming message should be skipped, {@code false} otherwise
      */
-    boolean shouldMessageBeSkipped(ByteBuffer buffer, Long lastReceivedLsn, Long startLsn, boolean skipFirstFlushRecord);
+    boolean shouldMessageBeSkipped(ByteBuffer buffer, Lsn lastReceivedLsn, Lsn startLsn, boolean skipFirstFlushRecord);
 }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ReplicationStream.java
Patch:
@@ -63,7 +63,7 @@ public interface ReplicationMessageProcessor {
      *
      * @throws SQLException if anything goes wrong
      */
-    void flushLsn(long lsn) throws SQLException;
+    void flushLsn(Lsn lsn) throws SQLException;
 
     /**
      * Returns the value for the latest server received LSN during a read operation. The value is always updated once messages
@@ -72,14 +72,14 @@ public interface ReplicationMessageProcessor {
      *
      * @return a {@link Long} value, possibly null if this is called before anything has been read
      */
-    Long lastReceivedLsn();
+    Lsn lastReceivedLsn();
 
     /**
      * Returns the value for the LSN form which the streaming is executed.
      *
      * @return a {@link Long} value, possibly null if starting LSN is undefined
      */
-    Long startLsn();
+    Lsn startLsn();
 
     /**
      * Starts a background thread to ensure the slot is kept alive, useful for when temporarily

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgoutput/PgOutputMessageDecoder.java
Patch:
@@ -33,6 +33,7 @@
 import io.debezium.connector.postgresql.UnchangedToastedReplicationMessageColumn;
 import io.debezium.connector.postgresql.connection.AbstractMessageDecoder;
 import io.debezium.connector.postgresql.connection.AbstractReplicationMessageColumn;
+import io.debezium.connector.postgresql.connection.Lsn;
 import io.debezium.connector.postgresql.connection.MessageDecoderConfig;
 import io.debezium.connector.postgresql.connection.PostgresConnection;
 import io.debezium.connector.postgresql.connection.ReplicationMessage.Column;
@@ -107,7 +108,7 @@ public PgOutputMessageDecoder(MessageDecoderConfig config) {
     }
 
     @Override
-    public boolean shouldMessageBeSkipped(ByteBuffer buffer, Long lastReceivedLsn, Long startLsn, boolean skipFirstFlushRecord) {
+    public boolean shouldMessageBeSkipped(ByteBuffer buffer, Lsn lastReceivedLsn, Lsn startLsn, boolean skipFirstFlushRecord) {
         // Cache position as we're going to peak at the first byte to determine message type
         // We need to reprocess all BEGIN/COMMIT messages regardless.
         int position = buffer.position();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlJdbcContext.java
Patch:
@@ -24,6 +24,7 @@
 import io.debezium.config.Configuration.Builder;
 import io.debezium.config.Field;
 import io.debezium.connector.mysql.MySqlConnectorConfig.SecureConnectionMode;
+import io.debezium.jdbc.JdbcConfiguration;
 import io.debezium.jdbc.JdbcConnection;
 import io.debezium.jdbc.JdbcConnection.ConnectionFactory;
 import io.debezium.relational.history.DatabaseHistory;
@@ -43,7 +44,8 @@ public class MySqlJdbcContext implements AutoCloseable {
     private static final String SQL_SHOW_SYSTEM_VARIABLES_CHARACTER_SET = "SHOW VARIABLES WHERE Variable_name IN ('character_set_server','collation_server')";
     private static final String SQL_SHOW_SESSION_VARIABLE_SSL_VERSION = "SHOW SESSION STATUS LIKE 'Ssl_version'";
 
-    protected static ConnectionFactory FACTORY = JdbcConnection.patternBasedFactory(MYSQL_CONNECTION_URL);
+    protected static ConnectionFactory FACTORY = JdbcConnection.patternBasedFactory(MYSQL_CONNECTION_URL,
+            JdbcConfiguration.PORT.withDefault(MySqlConnectorConfig.PORT.defaultValueAsString()));
 
     protected final Logger logger = LoggerFactory.getLogger(getClass());
     protected final Configuration config;

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresConnection.java
Patch:
@@ -26,6 +26,7 @@
 import io.debezium.DebeziumException;
 import io.debezium.annotation.VisibleForTesting;
 import io.debezium.config.Configuration;
+import io.debezium.connector.postgresql.PostgresConnectorConfig;
 import io.debezium.connector.postgresql.PostgresType;
 import io.debezium.connector.postgresql.TypeRegistry;
 import io.debezium.connector.postgresql.spi.SlotState;
@@ -51,7 +52,7 @@ public class PostgresConnection extends JdbcConnection {
             + JdbcConfiguration.PORT + "}/${" + JdbcConfiguration.DATABASE + "}";
     protected static final ConnectionFactory FACTORY = JdbcConnection.patternBasedFactory(URL_PATTERN,
             org.postgresql.Driver.class.getName(),
-            PostgresConnection.class.getClassLoader());
+            PostgresConnection.class.getClassLoader(), JdbcConfiguration.PORT.withDefault(PostgresConnectorConfig.PORT.defaultValueAsString()));
 
     /**
      * Obtaining a replication slot may fail if there's a pending transaction. We're retrying to get a slot for 30 min.

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnection.java
Patch:
@@ -68,7 +68,8 @@ public class SqlServerConnection extends JdbcConnection {
             + JdbcConfiguration.DATABASE + "}";
     private static final ConnectionFactory FACTORY = JdbcConnection.patternBasedFactory(URL_PATTERN,
             SQLServerDriver.class.getName(),
-            SqlServerConnection.class.getClassLoader());
+            SqlServerConnection.class.getClassLoader(),
+            JdbcConfiguration.PORT.withDefault(SqlServerConnectorConfig.PORT.defaultValueAsString()));
 
     /**
      * actual name of the database, which could differ in casing from the database name given in the connector config.

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/type/deserializer/CollectionTypeDeserializer.java
Patch:
@@ -8,6 +8,6 @@
 import org.apache.cassandra.db.marshal.CollectionType;
 import org.apache.cassandra.db.rows.ComplexColumnData;
 
-public abstract class CollectionTypeDeserializer <T extends CollectionType<?>> extends TypeDeserializer {
+public abstract class CollectionTypeDeserializer<T extends CollectionType<?>> extends TypeDeserializer {
     public abstract Object deserialize(T collectionType, ComplexColumnData ccd);
 }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorConfig.java
Patch:
@@ -157,7 +157,7 @@ public static SnapshotMode parse(String value, String defaultValue) {
             .withType(Type.LONG)
             .withWidth(Width.SHORT)
             .withImportance(Importance.MEDIUM)
-            .withDefault(30000)
+            .withDefault(30000L)
             .withValidation(Field::isPositiveInteger)
             .withDescription("Frequency in milliseconds to look for new, removed, or changed replica sets.  Defaults to 30000 milliseconds.");
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDecimalIT.java
Patch:
@@ -22,6 +22,8 @@
 import io.debezium.config.Configuration;
 import io.debezium.doc.FixFor;
 import io.debezium.embedded.AbstractConnectorTest;
+import io.debezium.junit.EqualityCheck;
+import io.debezium.junit.SkipWhenKafkaVersion;
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
 import io.debezium.util.Testing;
 
@@ -61,6 +63,7 @@ public void afterEach() {
 
     @Test
     @FixFor("DBZ-730")
+    @SkipWhenKafkaVersion(value = SkipWhenKafkaVersion.KafkaVersion.KAFKA_1XX, check = EqualityCheck.EQUAL, description = "No compatible with Kafka 1.x")
     public void testPreciseDecimalHandlingMode() throws SQLException, InterruptedException {
         config = DATABASE.defaultConfig()
                 .with(MySqlConnectorConfig.SNAPSHOT_MODE, MySqlConnectorConfig.SnapshotMode.INITIAL)

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/util/TestHelper.java
Patch:
@@ -382,7 +382,7 @@ public static int waitTimeForRecords() {
     public static void waitForCdcRecord(SqlServerConnection connection, String tableName, CdcRecordHandler handler) {
         try {
             Awaitility.await("Checking for expected record in CDC table for " + tableName)
-                    .atMost(30, TimeUnit.SECONDS)
+                    .atMost(60, TimeUnit.SECONDS)
                     .pollDelay(Duration.ofSeconds(0))
                     .pollInterval(Duration.ofMillis(100)).until(() -> {
                         if (!connection.getMaxLsn().isAvailable()) {

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/TablesWithoutPrimaryKeyIT.java
Patch:
@@ -97,6 +97,9 @@ public void shouldProcessFromStreaming() throws Exception {
 
         consumeRecordsByTopic(1);
 
+        TestHelper.waitForStreamingStarted();
+        TestHelper.waitForMaxLsnAvailable(connection);
+
         connection.execute(DDL_STATEMENTS);
 
         Testing.Print.enable();

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/type/deserializer/CollectionTypeDeserializer.java
Patch:
@@ -8,6 +8,6 @@
 import org.apache.cassandra.db.marshal.CollectionType;
 import org.apache.cassandra.db.rows.ComplexColumnData;
 
-public abstract class CollectionTypeDeserializer extends TypeDeserializer {
-    public abstract Object deserialize(CollectionType<?> collectionType, ComplexColumnData ccd);
+public abstract class CollectionTypeDeserializer <T extends CollectionType<?>> extends TypeDeserializer {
+    public abstract Object deserialize(T collectionType, ComplexColumnData ccd);
 }

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/type/deserializer/ListTypeDeserializer.java
Patch:
@@ -30,6 +30,6 @@ public SchemaBuilder getSchemaBuilder(AbstractType<?> abstractType) {
         ListType<?> listType = (ListType<?>) abstractType;
         AbstractType<?> elementsType = listType.getElementsType();
         Schema innerSchema = CassandraTypeDeserializer.getSchemaBuilder(elementsType).build();
-        return SchemaBuilder.array(innerSchema);
+        return SchemaBuilder.array(innerSchema).optional();
     }
 }

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/type/deserializer/MapTypeDeserializer.java
Patch:
@@ -32,6 +32,6 @@ public SchemaBuilder getSchemaBuilder(AbstractType<?> abstractType) {
         AbstractType<?> valuesType = mapType.getValuesType();
         Schema keySchema = CassandraTypeDeserializer.getSchemaBuilder(keysType).build();
         Schema valuesSchema = CassandraTypeDeserializer.getSchemaBuilder(valuesType).build();
-        return SchemaBuilder.map(keySchema, valuesSchema);
+        return SchemaBuilder.map(keySchema, valuesSchema).optional();
     }
 }

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/type/deserializer/SetTypeDeserializer.java
Patch:
@@ -33,6 +33,6 @@ public SchemaBuilder getSchemaBuilder(AbstractType<?> abstractType) {
         SetType<?> listType = (SetType<?>) abstractType;
         AbstractType<?> elementsType = listType.getElementsType();
         Schema innerSchema = CassandraTypeDeserializer.getSchemaBuilder(elementsType).build();
-        return SchemaBuilder.array(innerSchema);
+        return SchemaBuilder.array(innerSchema).optional();
     }
 }

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/type/deserializer/TupleTypeDeserializer.java
Patch:
@@ -53,7 +53,7 @@ public SchemaBuilder getSchemaBuilder(AbstractType<?> abstractType) {
             schemaBuilder.field(createFieldNameForIndex(i), CassandraTypeDeserializer.getSchemaBuilder(innerType).build());
         }
 
-        return schemaBuilder;
+        return schemaBuilder.optional();
     }
 
     private String createTupleName(List<AbstractType<?>> innerTypes) {

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/type/deserializer/UserTypeDeserializer.java
Patch:
@@ -47,6 +47,6 @@ public SchemaBuilder getSchemaBuilder(AbstractType<?> abstractType) {
             Schema fieldSchema = CassandraTypeDeserializer.getSchemaBuilder(fieldTypes.get(i)).build();
             schemaBuilder.field(fieldIdentifiers.get(i).toString(), fieldSchema);
         }
-        return schemaBuilder;
+        return schemaBuilder.optional();
     }
 }

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerChangeTableSetIT.java
Patch:
@@ -753,6 +753,7 @@ public void changeColumn() throws Exception {
     }
 
     @Test
+    @FixFor("DBZ-1491")
     public void addDefaultValue() throws Exception {
         final Configuration config = TestHelper.defaultConfig()
                 .with(SqlServerConnectorConfig.SNAPSHOT_MODE, SnapshotMode.SCHEMA_ONLY)

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectionIT.java
Patch:
@@ -106,7 +106,7 @@ public void shouldEnableCdcWithWrapperFunctionsForTable() throws Exception {
     }
 
     @Test
-    @FixFor("DBZ-1015")
+    @FixFor("DBZ-1491")
     public void shouldProperlyGetDefaultColumnValues() throws Exception {
         try (SqlServerConnection connection = TestHelper.adminConnection()) {
             connection.connect();

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerDatabaseSchema.java
Patch:
@@ -29,7 +29,8 @@ public class SqlServerDatabaseSchema extends HistorizedRelationalDatabaseSchema
 
     private static final Logger LOGGER = LoggerFactory.getLogger(SqlServerDatabaseSchema.class);
 
-    public SqlServerDatabaseSchema(SqlServerConnectorConfig connectorConfig, ValueConverterProvider valueConverter, TopicSelector<TableId> topicSelector, SchemaNameAdjuster schemaNameAdjuster) {
+    public SqlServerDatabaseSchema(SqlServerConnectorConfig connectorConfig, ValueConverterProvider valueConverter, TopicSelector<TableId> topicSelector,
+                                   SchemaNameAdjuster schemaNameAdjuster) {
         super(connectorConfig, topicSelector, connectorConfig.getTableFilters().dataCollectionFilter(), connectorConfig.getColumnFilter(),
                 new TableSchemaBuilder(
                         valueConverter,

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerChangeTableSetIT.java
Patch:
@@ -754,7 +754,7 @@ public void changeColumn() throws Exception {
     @Test
     public void addDefaultValue() throws Exception {
         final Configuration config = TestHelper.defaultConfig()
-                .with(SqlServerConnectorConfig.SNAPSHOT_MODE, SnapshotMode.INITIAL_SCHEMA_ONLY)
+                .with(SqlServerConnectorConfig.SNAPSHOT_MODE, SnapshotMode.SCHEMA_ONLY)
                 .build();
 
         start(SqlServerConnector.class, config);
@@ -780,7 +780,7 @@ public void alterDefaultValue() throws Exception {
         TestHelper.enableTableCdc(connection, "table_dv");
 
         final Configuration config = TestHelper.defaultConfig()
-                .with(SqlServerConnectorConfig.SNAPSHOT_MODE, SnapshotMode.INITIAL_SCHEMA_ONLY)
+                .with(SqlServerConnectorConfig.SNAPSHOT_MODE, SnapshotMode.SCHEMA_ONLY)
                 .build();
 
         start(SqlServerConnector.class, config);

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectionIT.java
Patch:
@@ -19,6 +19,7 @@
 import org.junit.Test;
 
 import io.debezium.connector.sqlserver.util.TestHelper;
+import io.debezium.doc.FixFor;
 import io.debezium.relational.Column;
 import io.debezium.relational.Table;
 import io.debezium.relational.TableId;
@@ -105,6 +106,7 @@ public void shouldEnableCdcWithWrapperFunctionsForTable() throws Exception {
     }
 
     @Test
+    @FixFor("DBZ-1015")
     public void shouldProperlyGetDefaultColumnValues() throws Exception {
         try (SqlServerConnection connection = TestHelper.adminConnection()) {
             connection.connect();
@@ -176,7 +178,7 @@ public void shouldProperlyGetDefaultColumnValues() throws Exception {
             // and issue a test call to a CDC wrapper function
             Thread.sleep(5_000); // Need to wait to make sure the min_lsn is available
 
-            ChangeTable changeTable = new ChangeTable(new TableId("testDB", "dbo", "table_with_defaults"),
+            SqlServerChangeTable changeTable = new SqlServerChangeTable(new TableId("testDB", "dbo", "table_with_defaults"),
                     null, 0, null, null);
             Table table = connection.getTableSchemaFromTable(changeTable);
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerDatabaseSchema.java
Patch:
@@ -12,6 +12,7 @@
 import io.debezium.relational.Table;
 import io.debezium.relational.TableId;
 import io.debezium.relational.TableSchemaBuilder;
+import io.debezium.relational.ValueConverterProvider;
 import io.debezium.relational.ddl.DdlParser;
 import io.debezium.relational.history.TableChanges;
 import io.debezium.schema.SchemaChangeEvent;
@@ -28,11 +29,10 @@ public class SqlServerDatabaseSchema extends HistorizedRelationalDatabaseSchema
 
     private static final Logger LOGGER = LoggerFactory.getLogger(SqlServerDatabaseSchema.class);
 
-    public SqlServerDatabaseSchema(SqlServerConnectorConfig connectorConfig, SchemaNameAdjuster schemaNameAdjuster, TopicSelector<TableId> topicSelector,
-                                   SqlServerConnection connection) {
+    public SqlServerDatabaseSchema(SqlServerConnectorConfig connectorConfig, ValueConverterProvider valueConverter, TopicSelector<TableId> topicSelector, SchemaNameAdjuster schemaNameAdjuster) {
         super(connectorConfig, topicSelector, connectorConfig.getTableFilters().dataCollectionFilter(), connectorConfig.getColumnFilter(),
                 new TableSchemaBuilder(
-                        new SqlServerValueConverters(connectorConfig.getDecimalMode(), connectorConfig.getTemporalPrecisionMode()),
+                        valueConverter,
                         schemaNameAdjuster,
                         connectorConfig.customConverterRegistry(),
                         connectorConfig.getSourceInfoStructMaker().schema(),

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerChangeTableSetIT.java
Patch:
@@ -264,7 +264,7 @@ private void addColumnToTable(boolean pauseAfterCaptureChange) throws Exception
                             .name("server1.dbo.tableb.Value")
                             .field("id", Schema.INT32_SCHEMA)
                             .field("colb", Schema.OPTIONAL_STRING_SCHEMA)
-                            .field("newcol", Schema.INT32_SCHEMA)
+                            .field("newcol", SchemaBuilder.int32().defaultValue(0).build())
                             .build());
         });
 
@@ -286,7 +286,7 @@ private void addColumnToTable(boolean pauseAfterCaptureChange) throws Exception
                             .name("server1.dbo.tableb.Value")
                             .field("id", Schema.INT32_SCHEMA)
                             .field("colb", Schema.OPTIONAL_STRING_SCHEMA)
-                            .field("newcol", Schema.INT32_SCHEMA)
+                            .field("newcol", SchemaBuilder.int32().defaultValue(0).build())
                             .build());
         });
     }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlAntlrDdlParserTest.java
Patch:
@@ -84,7 +84,7 @@ public void shouldParseCharacterDatatype() {
     @Test
     @FixFor("DBZ-2365")
     public void shouldParseOtherDbDatatypes() {
-        String ddl = "CREATE TABLE mytable (id INT PRIMARY KEY, mi MIDDLEINT, f4 FLOAT4, f8 FLOAT8, i1 INT1, i2 INT2, i3 INT, i4 INT4, i8 INT8, l LONG, lvc LONG VARCHAR, lvb LONG VARBINARY);";
+        String ddl = "CREATE TABLE mytable (id INT PRIMARY KEY, mi MIDDLEINT, f4 FLOAT4, f8 FLOAT8, i1 INT1, i2 INT2, i3 INT, i4 INT4, i8 INT8, l LONG CHARSET LATIN2, lvc LONG VARCHAR, lvb LONG VARBINARY);";
         parser.parse(ddl, tables);
         assertThat(((MySqlAntlrDdlParser) parser).getParsingExceptionsFromWalker().size()).isEqualTo(0);
         assertThat(tables.size()).isEqualTo(1);
@@ -108,8 +108,9 @@ public void shouldParseOtherDbDatatypes() {
         assertThat(table.columnWithName("i4").jdbcType()).isEqualTo(Types.INTEGER);
         assertThat(table.columnWithName("i8").jdbcType()).isEqualTo(Types.BIGINT);
         assertThat(table.columnWithName("l").jdbcType()).isEqualTo(Types.VARCHAR);
+        assertThat(table.columnWithName("l").charsetName()).isEqualTo("LATIN2");
         assertThat(table.columnWithName("lvc").jdbcType()).isEqualTo(Types.VARCHAR);
-        assertThat(table.columnWithName("lvb").jdbcType()).isEqualTo(Types.VARBINARY);
+        assertThat(table.columnWithName("lvb").jdbcType()).isEqualTo(Types.BLOB);
     }
 
     @Test

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/AbstractMessageDecoder.java
Patch:
@@ -56,7 +56,7 @@ public boolean shouldMessageBeSkipped(ByteBuffer buffer, Long lastReceivedLsn, L
                 return true;
             }
             else {
-                LOGGER.trace("Streaming requested from LSN {} but received LSN {} that is same or smaller so skipping the message", startLsn, lastReceivedLsn);
+                LOGGER.trace("Streaming requested from LSN {} but received LSN {} that is same or smaller", startLsn, lastReceivedLsn);
             }
         }
         return false;

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -88,7 +88,7 @@ public class PostgresReplicationConnection extends JdbcConnection implements Rep
      * @param dropSlotOnClose           whether the replication slot should be dropped once the connection is closed
      * @param statusUpdateInterval      the interval at which the replication connection should periodically send status
      * @param exportSnapshot            whether the replication should export a snapshot when created
-     * @param exportSnapshot            whether the connector is doing snapshot
+     * @param doSnapshot                whether the connector is doing snapshot
      * @param typeRegistry              registry with PostgreSQL types
      * @param streamParams              additional parameters to pass to the replication stream
      * @param schema                    the schema; must not be null

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ReplicationConnection.java
Patch:
@@ -208,9 +208,8 @@ interface Builder {
 
         /**
          * Whether or not the snapshot is executed
-         * @param doSnapshot true if a snapshot should is going to be executed, false if otherwise
+         * @param doSnapshot true if a snapshot is going to be executed, false if otherwise
          * @return this instance
-         * @see #DEFAULT_EXPORT_SNAPSHOT
          */
         Builder doSnapshot(final boolean doSnapshot);
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/ColumnDefinitionParserListener.java
Patch:
@@ -97,6 +97,7 @@ public void exitColumnDefinition(MySqlParser.ColumnDefinitionContext ctx) {
             tableEditor.addColumn(columnEditor.create());
             tableEditor.setPrimaryKeyNames(columnEditor.name());
         }
+        defaultValueListener.convertDefaultValue(false);
         parser.runIfNotNull(() -> {
             listeners.remove(defaultValueListener);
         }, tableEditor);

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorIT.java
Patch:
@@ -187,8 +187,10 @@ public void readOnlyApplicationIntent() throws Exception {
         assertConnectorIsRunning();
 
         // Wait for snapshot completion
+        TestHelper.waitForSnapshotToBeCompleted();
         consumeRecordsByTopic(1);
 
+        TestHelper.waitForStreamingStarted();
         for (int i = 0; i < RECORDS_PER_TABLE; i++) {
             final int id = ID_START + i;
             connection.execute(
@@ -197,7 +199,7 @@ public void readOnlyApplicationIntent() throws Exception {
                     "INSERT INTO tableb VALUES(" + id + ", 'b')");
         }
 
-        final SourceRecords records = consumeRecordsByTopic(RECORDS_PER_TABLE * TABLES);
+        final SourceRecords records = consumeRecordsByTopic(RECORDS_PER_TABLE * TABLES, 24);
         final List<SourceRecord> tableA = records.recordsForTopic("server1.dbo.tablea");
         final List<SourceRecord> tableB = records.recordsForTopic("server1.dbo.tableb");
         Assertions.assertThat(tableA).hasSize(RECORDS_PER_TABLE);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlSourceTypeInSchemaIT.java
Patch:
@@ -66,7 +66,7 @@ public void shouldPropagateSourceTypeAsSchemaParameter() throws SQLException, In
         // Use the DB configuration to define the connector's configuration ...
         config = DATABASE.defaultConfig()
                 .with(MySqlConnectorConfig.SNAPSHOT_MODE, MySqlConnectorConfig.SnapshotMode.NEVER)
-                .with("column.propagate.source.type", ".*c1,.*c2,.*c3.*,.*f.")
+                .with("column.propagate.source.type", ".*\\.c1,.*\\.c2,.*\\.c3.*,.*\\.f.")
                 .build();
 
         // Start the connector ...

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbErrorHandler.java
Patch:
@@ -26,8 +26,7 @@ protected boolean isRetriable(Throwable throwable) {
             while ((cause != null) && (cause != throwable)) {
                 if (cause instanceof com.mongodb.MongoSocketException) {
                     return true;
-                }
-                else {
+                } else {
                     cause = cause.getCause();
                 }
             }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorTask.java
Patch:
@@ -88,7 +88,7 @@ public ChangeEventSourceCoordinator start(Configuration config) {
                     .loggingContextSupplier(() -> taskContext.configureLoggingContext(CONTEXT_NAME))
                     .build();
 
-            errorHandler = new ErrorHandler(MongoDbConnector.class, connectorConfig.getLogicalName(), queue);
+            errorHandler = new MongoDbErrorHandler(connectorConfig.getLogicalName(), queue);
 
             final MongoDbEventMetadataProvider metadataProvider = new MongoDbEventMetadataProvider();
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlSourceTypeInSchemaIT.java
Patch:
@@ -168,6 +168,7 @@ public void shouldPropagateSourceTypeByDatatype() throws SQLException, Interrupt
 
         // Start the connector ...
         start(MySqlConnector.class, config);
+        waitForStreamingRunning("mysql", DATABASE.getServerName(), "binlog");
 
         // ---------------------------------------------------------------------------------------------------------------
         // Consume all of the events due to startup and initialization of the database

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -1625,6 +1625,7 @@ public void shouldOutputRecordsInCloudEventsFormat() throws Exception {
 
         start(PostgresConnector.class, configBuilder.build());
         assertConnectorIsRunning();
+        waitForSnapshotToBeCompleted();
 
         SourceRecords snapshotRecords = consumeRecordsByTopic(2);
         List<SourceRecord> snapshot = snapshotRecords.allRecordsInOrder();
@@ -1636,6 +1637,7 @@ public void shouldOutputRecordsInCloudEventsFormat() throws Exception {
         }
 
         // insert some more records and test streaming
+        waitForStreamingRunning();
         TestHelper.execute(INSERT_STMT);
 
         Testing.Print.enable();

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerChangeTableSetIT.java
Patch:
@@ -486,7 +486,7 @@ public void readHistoryAfterRestart() throws Exception {
 
         start(SqlServerConnector.class, config);
         assertConnectorIsRunning();
-        TestHelper.waitForSnapshotToBeCompleted();
+        TestHelper.waitForStreamingRunning();
 
         for (int i = 0; i < RECORDS_PER_TABLE; i++) {
             final int id = ID_START_1 + i;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorRegressionIT.java
Patch:
@@ -88,6 +88,7 @@ public void shouldConsumeAllEventsFromDatabaseUsingBinlogAndNoSnapshot() throws
                 .build();
         // Start the connector ...
         start(MySqlConnector.class, config);
+        waitForStreamingRunning("mysql", DATABASE.getServerName(), "binlog");
 
         // ---------------------------------------------------------------------------------------------------------------
         // Consume all of the events due to startup and initialization of the database

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -1489,6 +1489,7 @@ public void shouldNotParseQueryIfServerOptionDisabled() throws Exception {
 
         // Start the connector ...
         start(MySqlConnector.class, config);
+        waitForStreamingRunning(DATABASE.getServerName());
 
         // Flush all existing records not related to the test.
         consumeRecords(PRODUCTS_TABLE_EVENT_COUNT, null);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorRegressionIT.java
Patch:
@@ -933,6 +933,7 @@ public void shouldConsumeAllEventsFromDecimalTableInDatabaseUsingBinlogAndNoSnap
                 .build();
         // Start the connector ...
         start(MySqlConnector.class, config);
+        waitForStreamingRunning("mysql", DATABASE.getServerName(), "binlog");
 
         // ---------------------------------------------------------------------------------------------------------------
         // Consume all of the events due to startup and initialization of the database

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -1560,6 +1560,7 @@ public void testEmptyChangesProducesHeartbeat() throws Exception {
         // the low heartbeat interval should make sure that a heartbeat message is emitted after each change record
         // received from Postgres
         startConnector(config -> config.with(Heartbeat.HEARTBEAT_INTERVAL, "100"));
+        waitForStreamingToStart();
 
         TestHelper.execute(
                 "DROP TABLE IF EXISTS test_table;" +

File: debezium-core/src/main/java/io/debezium/relational/history/DatabaseHistory.java
Patch:
@@ -64,6 +64,8 @@ public interface DatabaseHistory {
                             "INSERT INTO mysql.rds_heartbeat2\\(.*\\) values \\(.*\\) ON DUPLICATE KEY UPDATE value = .*," +
                             "DELETE FROM mysql.rds_sysinfo.*," +
                             "INSERT INTO mysql.rds_sysinfo\\(.*\\) values \\(.*\\)," +
+                            "INSERT INTO mysql.rds_monitor\\(.*\\) values \\(.*\\) ON DUPLICATE KEY UPDATE value = .*," +
+                            "INSERT INTO mysql.rds_monitor\\(.*\\) values \\(.*\\)," +
                             "DELETE FROM mysql.rds_monitor.*," +
                             "FLUSH RELAY LOGS.*," +
                             "flush relay logs.*," +

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/AlterTableParserListener.java
Patch:
@@ -10,6 +10,7 @@
 
 import java.util.ArrayList;
 import java.util.List;
+import java.util.concurrent.atomic.AtomicReference;
 
 import org.antlr.v4.runtime.tree.ParseTreeListener;
 import org.slf4j.Logger;
@@ -265,7 +266,8 @@ public void enterAlterByChangeDefault(MySqlParser.AlterByChangeDefaultContext ct
             if (column != null) {
                 defaultValueColumnEditor = column.edit();
                 if (ctx.SET() != null) {
-                    defaultValueListener = new DefaultValueParserListener(defaultValueColumnEditor, parser.getConverters(), column.isOptional(), true);
+                    defaultValueListener = new DefaultValueParserListener(defaultValueColumnEditor, parser.getConverters(),
+                            new AtomicReference<Boolean>(column.isOptional()), true);
                     listeners.add(defaultValueListener);
                 }
                 else if (ctx.DROP() != null) {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -326,7 +326,7 @@ protected static void assertNoOpenTransactions() throws SQLException {
 
             try {
                 Awaitility.await()
-                        .atMost(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS)
+                        .atMost(TestHelper.waitTimeForRecords() * 5, TimeUnit.SECONDS)
                         .until(() -> getOpenIdleTransactions(connection).size() == 0);
             }
             catch (ConditionTimeoutException e) {

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoUtil.java
Patch:
@@ -228,10 +228,9 @@ public static ServerAddress parseAddress(String addressStr) {
      * @return the session transaction id from the oplog event
      */
     public static String getOplogSessionTransactionId(Document oplogEvent) {
-        if (!(oplogEvent.containsKey("lsid") && oplogEvent.containsKey("txnNumber"))) {
-            throw new DebeziumException("Oplog event does not contain lsid and txnNumber fields");
+        if (!oplogEvent.containsKey("txnNumber")) {
+            return null;
         }
-
         final String lsid = oplogEvent.get("lsid", Document.class).get("id", UUID.class).toString();
         final Long txnNumber = oplogEvent.getLong("txnNumber");
         return lsid + ":" + txnNumber;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSourceInfoStructMaker.java
Patch:
@@ -25,6 +25,7 @@ public MongoDbSourceInfoStructMaker(String connector, String version, CommonConn
                 .field(SourceInfo.ORDER, Schema.INT32_SCHEMA)
                 .field(SourceInfo.OPERATION_ID, Schema.OPTIONAL_INT64_SCHEMA)
                 .field(SourceInfo.TX_ORD, Schema.OPTIONAL_INT64_SCHEMA)
+                .field(SourceInfo.SESSION_TXN_ID, Schema.OPTIONAL_STRING_SCHEMA)
                 .build();
     }
 
@@ -39,7 +40,8 @@ public Struct struct(SourceInfo sourceInfo) {
                 .put(SourceInfo.REPLICA_SET_NAME, sourceInfo.replicaSetName())
                 .put(SourceInfo.COLLECTION, sourceInfo.collectionId().name())
                 .put(SourceInfo.ORDER, sourceInfo.position().getInc())
-                .put(SourceInfo.OPERATION_ID, sourceInfo.position().getOperationId());
+                .put(SourceInfo.OPERATION_ID, sourceInfo.position().getOperationId())
+                .put(SourceInfo.SESSION_TXN_ID, sourceInfo.position().getSessionTxnId());
 
         sourceInfo.transactionPosition().ifPresent(transactionPosition -> struct.put(SourceInfo.TX_ORD, transactionPosition));
 

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/SourceInfoTest.java
Patch:
@@ -264,6 +264,7 @@ public void schemaIsCorrect() {
                 .field("ord", Schema.INT32_SCHEMA)
                 .field("h", Schema.OPTIONAL_INT64_SCHEMA)
                 .field("tord", Schema.OPTIONAL_INT64_SCHEMA)
+                .field("stxnid", Schema.OPTIONAL_STRING_SCHEMA)
                 .build();
 
         assertConnectSchemasAreEqual(null, source.schema(), schema);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -1444,6 +1444,8 @@ public void shouldEmitNoSavepoints() throws Exception {
         SourceRecords records = consumeRecordsByTopic(INITIAL_EVENT_COUNT); // 6 DDL changes
         assertThat(records.recordsForTopic(DATABASE.topicForTable("orders")).size()).isEqualTo(5);
 
+        waitForStreamingRunning(DATABASE.getServerName());
+
         try (MySQLConnection db = MySQLConnection.forTestDatabase(DATABASE.getDatabaseName());) {
             try (JdbcConnection connection = db.connect()) {
                 final Connection jdbc = connection.connection();

File: debezium-connector-db2/src/main/java/io/debezium/connector/db2/Db2ValueConverters.java
Patch:
@@ -42,7 +42,7 @@ public Db2ValueConverters() {
      *            date/time value will be represented either as Connect datatypes or Debezium specific datatypes
      */
     public Db2ValueConverters(DecimalMode decimalMode, TemporalPrecisionMode temporalPrecisionMode) {
-        super(decimalMode, temporalPrecisionMode, ZoneOffset.UTC, null, null);
+        super(decimalMode, temporalPrecisionMode, ZoneOffset.UTC, null, null, null);
     }
 
     @Override

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleValueConverters.java
Patch:
@@ -49,7 +49,7 @@ public class OracleValueConverters extends JdbcValueConverters {
     private final OracleConnection connection;
 
     public OracleValueConverters(OracleConnectorConfig config, OracleConnection connection) {
-        super(config.getDecimalMode(), TemporalPrecisionMode.ADAPTIVE, ZoneOffset.UTC, null, null);
+        super(config.getDecimalMode(), TemporalPrecisionMode.ADAPTIVE, ZoneOffset.UTC, null, null, null);
         this.connection = connection;
     }
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -2033,6 +2033,7 @@ public void testEmptySchemaWarningWithTableWhitelist() throws Exception {
 
         start(MySqlConnector.class, config);
         assertConnectorIsRunning();
+        waitForSnapshotToBeCompleted("mysql", DATABASE.getServerName());
 
         consumeRecordsByTopic(12);
         waitForAvailableRecords(100, TimeUnit.MILLISECONDS);

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSnapshotChangeEventSource.java
Patch:
@@ -202,10 +202,12 @@ protected SnapshottingTask getSnapshottingTask(OffsetContext previousOffset) {
         return new MongoDbSnapshottingTask(replicaSetSnapshots);
     }
 
+    @Override
     protected SnapshotContext prepare(ChangeEventSourceContext sourceContext) throws Exception {
         return new MongoDbSnapshotContext();
     }
 
+    @Override
     protected void complete(SnapshotContext snapshotContext) {
     }
 
@@ -482,7 +484,7 @@ protected ChangeRecordEmitter getChangeRecordEmitter(SnapshotContext snapshotCon
         final ReplicaSetOffsetContext replicaSetOffsetContext = offsetContext.getReplicaSetOffsetContext(replicaSet);
         replicaSetOffsetContext.readEvent(collectionId, getClock().currentTime());
 
-        return new MongoDbChangeRecordEmitter(replicaSetOffsetContext, getClock(), document);
+        return new MongoDbChangeRecordEmitter(replicaSetOffsetContext, getClock(), document, true);
     }
 
     protected Clock getClock() {

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbStreamingChangeEventSource.java
Patch:
@@ -357,7 +357,8 @@ private boolean handleOplogEvent(ServerAddress primaryAddress, Document event, D
                             new MongoDbChangeRecordEmitter(
                                     oplogContext.getOffset(),
                                     clock,
-                                    event));
+                                    event,
+                                    false));
                 }
                 catch (Exception e) {
                     errorHandler.setProducerThrowable(e);

File: debezium-core/src/test/java/io/debezium/transforms/outbox/EventRouterTest.java
Patch:
@@ -799,9 +799,8 @@ public void canPassBinaryMessage() {
         assertThat(eventRouted).isNotNull();
         assertThat(eventRouted.keySchema().type()).isEqualTo(Schema.Type.STRING);
         assertThat(eventRouted.key()).isEqualTo(key);
-        assertThat(eventRouted.valueSchema().type()).isEqualTo(Schema.Type.STRUCT);
-        Struct valuePassed = (Struct) eventRouted.value();
-        assertThat(valuePassed.get("payload")).isEqualTo(value);
+        assertThat(eventRouted.valueSchema().type()).isEqualTo(Schema.Type.BYTES);
+        assertThat(eventRouted.value()).isEqualTo(value);
     }
 
     @Test

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/AbstractReader.java
Patch:
@@ -267,7 +267,7 @@ public List<SourceRecord> poll() throws InterruptedException {
 
         logger.trace("Polling for next batch of records");
         List<SourceRecord> batch = new ArrayList<>(maxBatchSize);
-        final Timer timeout = Threads.timer(Clock.SYSTEM, Temporals.max(pollInterval, ConfigurationDefaults.RETURN_CONTROL_INTERVAL));
+        final Timer timeout = Threads.timer(Clock.SYSTEM, Temporals.min(pollInterval, ConfigurationDefaults.RETURN_CONTROL_INTERVAL));
         while (running.get() && (records.drainTo(batch, maxBatchSize) == 0) && !success.get()) {
             // No records are available even though the snapshot has not yet completed, so sleep for a bit ...
             metronome.pause();

File: debezium-core/src/main/java/io/debezium/connector/base/ChangeEventQueue.java
Patch:
@@ -145,7 +145,7 @@ public List<T> poll() throws InterruptedException {
         try {
             LOGGER.debug("polling records...");
             List<T> records = new ArrayList<>();
-            final Timer timeout = Threads.timer(Clock.SYSTEM, Temporals.max(pollInterval, ConfigurationDefaults.RETURN_CONTROL_INTERVAL));
+            final Timer timeout = Threads.timer(Clock.SYSTEM, Temporals.min(pollInterval, ConfigurationDefaults.RETURN_CONTROL_INTERVAL));
             while (!timeout.expired() && queue.drainTo(records, maxBatchSize) == 0) {
                 throwProducerExceptionIfPresent();
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorTask.java
Patch:
@@ -68,6 +68,8 @@ public ChangeEventSourceCoordinator start(Configuration config) {
             throw new ConnectException("Unable to load snapshotter, if using custom snapshot mode, double check your settings");
         }
 
+        // Global JDBC connection used both for snapshotting and streaming.
+        // Must be able to resolve datatypes.
         jdbcConnection = new PostgresConnection(connectorConfig.jdbcConfig(), true);
         try {
             jdbcConnection.setAutoCommit(false);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresConnection.java
Patch:
@@ -65,6 +65,8 @@ public class PostgresConnection extends JdbcConnection {
 
     /**
      * Creates a Postgres connection using the supplied configuration.
+     * If necessary this connection is able to resolve data type mappings.
+     * Usually only one such connection per connector is needed.
      *
      * @param config {@link Configuration} instance, may not be null.
      * @param provideTypeRegistry {@code true} if type registry should be created
@@ -77,6 +79,7 @@ public PostgresConnection(Configuration config, boolean provideTypeRegistry) {
 
     /**
      * Creates a Postgres connection using the supplied configuration.
+     * The connector is the regular one without datatype resolution capabilities.
      *
      * @param config {@link Configuration} instance, may not be null.
      */

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorTask.java
Patch:
@@ -67,7 +67,7 @@ public ChangeEventSourceCoordinator start(Configuration config) {
             throw new ConnectException("Unable to load snapshotter, if using custom snapshot mode, double check your settings");
         }
 
-        jdbcConnection = new PostgresConnection(connectorConfig.jdbcConfig());
+        jdbcConnection = new PostgresConnection(connectorConfig.jdbcConfig(), true);
         heartbeatConnection = new PostgresConnection(connectorConfig.jdbcConfig());
         final TypeRegistry typeRegistry = jdbcConnection.getTypeRegistry();
         final Charset databaseCharset = jdbcConnection.getDatabaseCharset();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java
Patch:
@@ -96,6 +96,8 @@ public void execute(ChangeEventSourceContext context) throws InterruptedExceptio
         }
 
         try {
+            connection.setAutoCommit(false);
+
             if (hasStartLsnStoredInContext) {
                 // start streaming from the last recorded position in the offset
                 final Long lsn = offsetContext.lastCompletelyProcessedLsn() != null ? offsetContext.lastCompletelyProcessedLsn() : offsetContext.lsn();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/TypeRegistry.java
Patch:
@@ -405,6 +405,9 @@ private PostgresType loadType(Connection connection, PreparedStatement statement
             while (rs.next()) {
                 PostgresType result = createTypeBuilderFromResultSet(connection, rs, typeInfo, sqlTypeMapper).build();
                 addType(result);
+                if (!connection.getAutoCommit()) {
+                    connection.commit();
+                }
                 return result;
             }
         }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -66,6 +66,7 @@
 import io.debezium.data.Bits;
 import io.debezium.data.Enum;
 import io.debezium.data.Envelope;
+import io.debezium.data.SchemaAndValueField;
 import io.debezium.data.SpecialValueDecimal;
 import io.debezium.data.VariableScaleDecimal;
 import io.debezium.data.VerifyRecord;
@@ -2465,7 +2466,7 @@ public void testHeartbeatActionQueryExecuted() throws Exception {
                         "INSERT INTO test_heartbeat_table (text) VALUES ('test_heartbeat');"));
 
         // Expecting 1 data change
-        Awaitility.await().atMost(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS).until(() -> {
+        Awaitility.await().atMost(TestHelper.waitTimeForRecords() * 10, TimeUnit.SECONDS).until(() -> {
             final SourceRecord record = consumeRecord();
             return record != null && Envelope.isEnvelopeSchema(record.valueSchema());
         });

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -1562,7 +1562,7 @@ public void testEmptyChangesProducesHeartbeat() throws Exception {
                         "INSERT INTO test_table (text) VALUES ('mydata');");
 
         // Expecting 1 data change
-        Awaitility.await().atMost(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS).until(() -> {
+        Awaitility.await().atMost(TestHelper.waitTimeForRecords() * 10, TimeUnit.SECONDS).until(() -> {
             final SourceRecord record = consumeRecord();
             return record != null && Envelope.isEnvelopeSchema(record.valueSchema());
         });
@@ -1574,7 +1574,7 @@ public void testEmptyChangesProducesHeartbeat() throws Exception {
 
         // Expecting changes for the empty DDL change
         final Set<Long> lsns = new HashSet<>();
-        Awaitility.await().atMost(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS).until(() -> {
+        Awaitility.await().atMost(TestHelper.waitTimeForRecords() * 10, TimeUnit.SECONDS).until(() -> {
             final SourceRecord record = consumeRecord();
             Assertions.assertThat(record.valueSchema().name()).endsWith(".Heartbeat");
             lsns.add((Long) record.sourceOffset().get("lsn"));

File: debezium-server/debezium-server-pulsar/src/test/java/io/debezium/server/pulsar/PulsarIT.java
Patch:
@@ -31,7 +31,7 @@
 import io.quarkus.test.junit.QuarkusTest;
 
 /**
- * Integration test that verifies basic reading from PostgreSQL database and writing to a Google Cloud PubSub stream.
+ * Integration test that verifies basic reading from PostgreSQL database and writing to an Apache Pulsar topic.
  *
  * @author Jiri Pechanec
  */

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlAntlrDdlParserTest.java
Patch:
@@ -108,7 +108,7 @@ public void shouldUpdateSchemaForRemovedDefaultValue() {
 
     @Test
     @FixFor("DBZ-2061")
-    public void shouldUpdateSchemaForChangeDefaultValue() {
+    public void shouldUpdateSchemaForChangedDefaultValue() {
         String ddl = "CREATE TABLE mytable (id INT PRIMARY KEY, val1 INT);"
                 + "ALTER TABLE mytable ADD COLUMN last_val INT DEFAULT 5;";
         parser.parse(ddl, tables);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/AlterTableParserListener.java
Patch:
@@ -268,6 +268,9 @@ public void enterAlterByChangeDefault(MySqlParser.AlterByChangeDefaultContext ct
                     defaultValueListener = new DefaultValueParserListener(defaultValueColumnEditor, parser.getConverters(), column.isOptional(), true);
                     listeners.add(defaultValueListener);
                 }
+                else if (ctx.DROP() != null) {
+                    defaultValueColumnEditor.unsetDefaultValue();
+                }
             }
         }, tableEditor);
         super.enterAlterByChangeDefault(ctx);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -99,7 +99,6 @@ protected DataTypeResolver initializeDataTypeResolver() {
 
         dataTypeResolverBuilder.registerDataTypes(MySqlParser.StringDataTypeContext.class.getCanonicalName(), Arrays.asList(
                 new DataTypeEntry(Types.CHAR, MySqlParser.CHAR),
-                new DataTypeEntry(Types.CHAR, MySqlParser.CHARACTER),
                 new DataTypeEntry(Types.VARCHAR, MySqlParser.VARCHAR),
                 new DataTypeEntry(Types.VARCHAR, MySqlParser.TINYTEXT),
                 new DataTypeEntry(Types.VARCHAR, MySqlParser.TEXT),
@@ -114,7 +113,8 @@ protected DataTypeResolver initializeDataTypeResolver() {
                 new DataTypeEntry(Types.BINARY, MySqlParser.MEDIUMTEXT, MySqlParser.BINARY),
                 new DataTypeEntry(Types.BINARY, MySqlParser.LONGTEXT, MySqlParser.BINARY),
                 new DataTypeEntry(Types.BINARY, MySqlParser.NCHAR, MySqlParser.BINARY),
-                new DataTypeEntry(Types.BINARY, MySqlParser.NVARCHAR, MySqlParser.BINARY)));
+                new DataTypeEntry(Types.BINARY, MySqlParser.NVARCHAR, MySqlParser.BINARY),
+                new DataTypeEntry(Types.CHAR, MySqlParser.CHARACTER)));
         dataTypeResolverBuilder.registerDataTypes(MySqlParser.NationalStringDataTypeContext.class.getCanonicalName(), Arrays.asList(
                 new DataTypeEntry(Types.NVARCHAR, MySqlParser.NATIONAL, MySqlParser.VARCHAR).setSuffixTokens(MySqlParser.BINARY),
                 new DataTypeEntry(Types.NCHAR, MySqlParser.NATIONAL, MySqlParser.CHARACTER).setSuffixTokens(MySqlParser.BINARY),

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -99,6 +99,7 @@ protected DataTypeResolver initializeDataTypeResolver() {
 
         dataTypeResolverBuilder.registerDataTypes(MySqlParser.StringDataTypeContext.class.getCanonicalName(), Arrays.asList(
                 new DataTypeEntry(Types.CHAR, MySqlParser.CHAR),
+                new DataTypeEntry(Types.CHAR, MySqlParser.CHARACTER),
                 new DataTypeEntry(Types.VARCHAR, MySqlParser.VARCHAR),
                 new DataTypeEntry(Types.VARCHAR, MySqlParser.TINYTEXT),
                 new DataTypeEntry(Types.VARCHAR, MySqlParser.TEXT),

File: debezium-testing/debezium-testing-openshift/src/main/java/io/debezium/testing/openshift/tools/databases/DatabaseController.java
Patch:
@@ -54,7 +54,7 @@ public String getDatabaseUrl() {
         Integer port = svc.getSpec().getPorts().stream().filter(p -> p.getName().equals("db")).findAny().get().getPort();
         return constructDatabaseUrl(hostname, port);
     }
-    
+
     public void reload() throws InterruptedException {
         LOGGER.info("Recreating all pods of '" + name + "' deployment in namespace '" + project + "'");
         ocp.pods().inNamespace(project).withLabel("deployment", name).delete();

File: debezium-core/src/main/java/io/debezium/connector/base/ChangeEventQueue.java
Patch:
@@ -37,7 +37,7 @@
  * the queue.
  * <p>
  * If an exception occurs on the producer side, the producer should make that
- * exception known by calling {@link #producerFailure} before stopping its
+ * exception known by calling {@link #producerException(RuntimeException)} before stopping its
  * operation. Upon the next call to {@link #poll()}, that exception will be
  * raised, causing Kafka Connect to stop the connector and mark it as
  * {@code FAILED}.

File: debezium-server/src/test/java/io/debezium/server/PubSubIT.java
Patch:
@@ -35,7 +35,7 @@
 import io.quarkus.test.junit.QuarkusTest;
 
 /**
- * Integration test that verifies basic reading from PostgreSQL database and writing to Kinesis stream.
+ * Integration test that verifies basic reading from PostgreSQL database and writing to a Google Cloud PubSub stream.
  *
  * @author Jiri Pechanec
  */

File: debezium-server/src/test/java/io/debezium/server/TestConfigSource.java
Patch:
@@ -28,7 +28,6 @@ public class TestConfigSource implements ConfigSource {
 
     public TestConfigSource() {
         pubsubTest.put("debezium.sink.type", "pubsub");
-        pubsubTest.put("debezium.sink.", KINESIS_REGION);
         pubsubTest.put("debezium.source.connector.class", "io.debezium.connector.postgresql.PostgresConnector");
         pubsubTest.put("debezium.source." + StandaloneConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG, OFFSET_STORE_PATH.toAbsolutePath().toString());
         pubsubTest.put("debezium.source.offset.flush.interval.ms", "0");

File: debezium-connector-cassandra/src/test/java/io/debezium/connector/cassandra/EmbeddedCassandraConnectorTestBase.java
Patch:
@@ -10,7 +10,6 @@
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.Paths;
-import java.security.GeneralSecurityException;
 import java.time.Duration;
 import java.util.Map;
 import java.util.Properties;
@@ -76,15 +75,15 @@ protected static void deleteTestKeyspaceTables() {
     /**
      * Generate a task context with default test configs
      */
-    protected static CassandraConnectorContext generateTaskContext() throws GeneralSecurityException, IOException {
+    protected static CassandraConnectorContext generateTaskContext() throws Exception {
         Properties defaults = generateDefaultConfigMap();
         return new CassandraConnectorContext(new CassandraConnectorConfig(Configuration.from(defaults)));
     }
 
     /**
      * General a task context with default and custom test configs
      */
-    protected static CassandraConnectorContext generateTaskContext(Map<String, Object> configs) throws GeneralSecurityException, IOException {
+    protected static CassandraConnectorContext generateTaskContext(Map<String, Object> configs) throws Exception {
         Properties defaults = generateDefaultConfigMap();
         defaults.putAll(configs);
         return new CassandraConnectorContext(new CassandraConnectorConfig(Configuration.from(defaults)));

File: debezium-core/src/main/java/io/debezium/metrics/Metrics.java
Patch:
@@ -64,7 +64,7 @@ public final void unregister(Logger logger) {
             try {
                 final MBeanServer mBeanServer = ManagementFactory.getPlatformMBeanServer();
                 if (mBeanServer == null) {
-                    logger.debug("JMX not supported, beam '{}' not registered");
+                    logger.debug("JMX not supported, bean '{}' not registered");
                     return;
                 }
                 mBeanServer.unregisterMBean(name);

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -363,7 +363,7 @@ private ValueConverter wrapInMappingConverterIfNeeded(ColumnMappers mappers, Tab
      * @param mapper the mapping function for the column; may be null if the columns is not to be mapped to different values
      */
     protected void addField(SchemaBuilder builder, Table table, Column column, ColumnMapper mapper) {
-        SchemaBuilder fieldBuilder = customConverterRegistry.registerConverterFor(table.id(), column)
+        final SchemaBuilder fieldBuilder = customConverterRegistry.registerConverterFor(table.id(), column)
                 .orElse(valueConverterProvider.schemaBuilder(column));
 
         if (fieldBuilder != null) {
@@ -377,7 +377,8 @@ protected void addField(SchemaBuilder builder, Table table, Column column, Colum
 
             // if the default value is provided
             if (column.hasDefaultValue()) {
-                fieldBuilder.defaultValue(column.defaultValue());
+                fieldBuilder
+                        .defaultValue(customConverterRegistry.getValueConverter(table.id(), column).orElse(ValueConverter.passthrough()).convert(column.defaultValue()));
             }
 
             builder.field(fieldNamer.fieldNameFor(column), fieldBuilder.build());

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/CreateTableParserListener.java
Patch:
@@ -97,7 +97,7 @@ public void enterColumnDeclaration(MySqlParser.ColumnDeclarationContext ctx) {
             String columnName = parser.parseName(ctx.uid());
             ColumnEditor columnEditor = Column.editor().name(columnName);
             if (columnDefinitionListener == null) {
-                columnDefinitionListener = new ColumnDefinitionParserListener(tableEditor, columnEditor, parser.dataTypeResolver(), parser.getConverters(), false);
+                columnDefinitionListener = new ColumnDefinitionParserListener(tableEditor, columnEditor, parser, listeners, false);
                 listeners.add(columnDefinitionListener);
             }
             else {

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -737,7 +737,8 @@ public OffsetStorageReader offsetStorageReader() {
                                 return offsetReader;
                             }
 
-                            @Override
+                            // Purposely not marking this method with @Override as it was introduced in Kafka 2.x
+                            // and otherwise would break builds based on Kafka 1.x
                             public Map<String, String> configs() {
                                 // TODO Auto-generated method stub
                                 return null;

File: debezium-core/src/main/java/io/debezium/transforms/outbox/EventRouterConfigDefinition.java
Patch:
@@ -287,9 +287,6 @@ static List<AdditionalField> parseAdditionalFieldsConfig(Configuration config) {
                 }
             }
         }
-        if (!eventTypeMappingProvided) {
-            additionalFields.add(0, new AdditionalField(AdditionalFieldPlacement.ENVELOPE, eventTypeColumn, EventRouter.ENVELOPE_EVENT_TYPE));
-        }
 
         return additionalFields;
     }

File: debezium-core/src/main/java/io/debezium/transforms/SmtManager.java
Patch:
@@ -31,7 +31,7 @@ public boolean isValidEnvelope(final R record) {
         if (record.valueSchema() == null ||
                 record.valueSchema().name() == null ||
                 !Envelope.isEnvelopeSchema(record.valueSchema())) {
-            LOGGER.warn("Expected Envelope for transformation, passing it unchanged");
+            LOGGER.debug("Expected Envelope for transformation, passing it unchanged");
             return false;
         }
         return true;
@@ -41,7 +41,7 @@ public boolean isValidKey(final R record) {
         if (record.keySchema() == null ||
                 record.keySchema().name() == null ||
                 !record.keySchema().name().endsWith(RECORD_ENVELOPE_KEY_SCHEMA_NAME_SUFFIX)) {
-            LOGGER.warn("Expected Key Schema for transformation, passing it unchanged. Message key: \"{}\"", record.key());
+            LOGGER.debug("Expected Key Schema for transformation, passing it unchanged. Message key: \"{}\"", record.key());
             return false;
         }
         return true;

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SchemaHistoryTopicIT.java
Patch:
@@ -26,9 +26,10 @@
 import io.debezium.util.Testing;
 
 /**
- * Integration test for the Debezium SQL Server connector.
+ * Integration test for the user-facing history topic of the Debezium SQL Server connector.
+ * <p>
  * The tests should verify the {@code CREATE} schema events from snapshot and the {@code CREATE} and
- * the {@code ALTER} schem events from streaming
+ * the {@code ALTER} schema events from streaming
  *
  * @author Jiri Pechanec
  */

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -2130,7 +2130,7 @@ public void shouldStreamEnumArrayAsKnownType() throws Exception {
 
         List<SchemaAndValueField> expectedUpdate = Arrays.asList(
                 new SchemaAndValueField(PK_FIELD, Schema.INT32_SCHEMA, 1),
-                new SchemaAndValueField("value", SchemaBuilder.array(Enum.builder("V1"))
+                new SchemaAndValueField("value", SchemaBuilder.array(Enum.builder("V1,V2"))
                         .parameter(TestHelper.TYPE_NAME_PARAMETER_KEY, "_TEST_TYPE")
                         .parameter(TestHelper.TYPE_LENGTH_PARAMETER_KEY, String.valueOf(Integer.MAX_VALUE))
                         .parameter(TestHelper.TYPE_SCALE_PARAMETER_KEY, "0")

File: debezium-core/src/test/java/io/debezium/data/VerifyRecord.java
Patch:
@@ -1090,9 +1090,7 @@ private static boolean areConnectSchemasEqual(Schema schema1, Schema schema2) {
             valueSchemasEqual = Objects.equals(schema1.valueSchema(), schema2.valueSchema());
         }
         else if (schema1.type() == Type.ARRAY && schema2.type() == Type.ARRAY) {
-            String valueSchema1String = SchemaUtil.asString(schema1.valueSchema());
-            String valueSchema2String = SchemaUtil.asString(schema2.valueSchema());
-            valueSchemasEqual = valueSchema1String.equals(valueSchema2String);
+            valueSchemasEqual = areConnectSchemasEqual(schema1.valueSchema(), schema2.valueSchema());
         }
         else if (schema1.type() == Type.STRUCT && schema2.type() == Type.STRUCT) {
             fieldsEqual = areFieldListsEqual(schema1.fields(), schema2.fields());

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresChangeRecordEmitter.java
Patch:
@@ -300,7 +300,7 @@ private boolean schemaChanged(List<ReplicationMessage.Column> columns, Table tab
                                 incomingLength);
                         return true;
                     }
-                    final int localScale = column.scale().get();
+                    final int localScale = column.scale().orElseGet(() -> 0);
                     final int incomingScale = message.getTypeMetadata().getScale();
                     if (localScale != incomingScale) {
                         logger.info("detected new scale for column '{}', old scale was {}, new scale is {}; refreshing table schema", columnName, localScale,

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -299,7 +299,7 @@ private SchemaBuilder numericSchema(Column column) {
         if (decimalMode == DecimalMode.PRECISE && isVariableScaleDecimal(column)) {
             return VariableScaleDecimal.builder();
         }
-        return SpecialValueDecimal.builder(decimalMode, column.length(), column.scale().get());
+        return SpecialValueDecimal.builder(decimalMode, column.length(), column.scale().orElseGet(() -> 0));
     }
 
     private SchemaBuilder hstoreSchema() {
@@ -840,8 +840,8 @@ else if (data instanceof PgArray) {
     }
 
     private boolean isVariableScaleDecimal(final Column column) {
-        return (column.scale().isPresent() && column.scale().get() == 0 && column.length() == VARIABLE_SCALE_DECIMAL_LENGTH)
-                || (!column.scale().isPresent() && column.length() == -1);
+        return column.length() == VARIABLE_SCALE_DECIMAL_LENGTH &&
+                column.scale().orElseGet(() -> 0) == 0;
     }
 
     public static Optional<SpecialValueDecimal> toSpecialValue(String value) {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsSnapshotProducerIT.java
Patch:
@@ -112,6 +112,7 @@ public void converterFor(RelationalColumn column, ConverterRegistration<SchemaBu
         }
     }
 
+    @Override
     protected List<SchemaAndValueField> schemasAndValuesForCustomConverterTypes() {
         return Arrays.asList(new SchemaAndValueField("i",
                 SchemaBuilder.string().name("io.debezium.postgresql.type.Isbn").build(), "0-393-04002-X"));
@@ -408,7 +409,7 @@ public void shouldGenerateSnapshotsForPartitionedTables() throws Exception {
         // then start the producer and validate all records are there
         buildNoStreamProducer(TestHelper.defaultConfig());
 
-        TestConsumer consumer = testConsumer(1 + 2 * 30); // Every record comes once from partitioned table and from partition
+        TestConsumer consumer = testConsumer(1 + 30);
         consumer.await(TestHelper.waitTimeForRecords() * 30, TimeUnit.SECONDS);
 
         Set<Integer> ids = new HashSet<>();
@@ -434,7 +435,7 @@ public void shouldGenerateSnapshotsForPartitionedTables() throws Exception {
 
         // verify each topic contains exactly the number of input records
         assertEquals(1, topicCounts.get("test_server.public.first_table").intValue());
-        assertEquals(30, topicCounts.get("test_server.public.partitioned").intValue());
+        assertEquals(0, topicCounts.get("test_server.public.partitioned").intValue());
         assertEquals(10, topicCounts.get("test_server.public.partitioned_1_100").intValue());
         assertEquals(20, topicCounts.get("test_server.public.partitioned_101_200").intValue());
 

File: debezium-core/src/main/java/io/debezium/relational/ChangeTable.java
Patch:
@@ -6,7 +6,7 @@
 package io.debezium.relational;
 
 /**
- * A logical representation of a change table containtaing changes for a given source table.
+ * A logical representation of a change table containing changes for a given source table.
  * There is usually one change table for each source table.  When the schema of the source table is changed,
  * then two change tables could be present.
  *

File: debezium-core/src/main/java/io/debezium/transforms/ByLogicalTableRouter.java
Patch:
@@ -34,12 +34,12 @@
 /**
  * A logical table consists of one or more physical tables with the same schema. A common use case is sharding -- the
  * two physical tables `db_shard1.my_table` and `db_shard2.my_table` together form one logical table.
- *
+ * <p>
  * This Transformation allows us to change a record's topic name and send change events from multiple physical tables to
  * one topic. For instance, we might choose to send the two tables from the above example to the topic
  * `db_shard.my_table`. The config options {@link #TOPIC_REGEX} and {@link #TOPIC_REPLACEMENT} are used
  * to change the record's topic.
- *
+ * <p>
  * Now that multiple physical tables can share a topic, the event's key may need to be augmented to include fields other
  * than just those for the record's primary/unique key, since these are not guaranteed to be unique across tables. We
  * need some identifier added to the key that distinguishes the different physical tables. The field name specified by

File: debezium-core/src/main/java/io/debezium/relational/RelationalDatabaseConnectorConfig.java
Patch:
@@ -179,6 +179,7 @@ public static DecimalHandlingMode parse(String value, String defaultValue) {
             .withType(Type.STRING)
             .withWidth(Width.LONG)
             .withImportance(Importance.MEDIUM)
+            .withValidation(RelationalDatabaseConnectorConfig::validateColumnBlacklist)
             .withDescription("");
 
     /**
@@ -192,7 +193,6 @@ public static DecimalHandlingMode parse(String value, String defaultValue) {
             .withType(Type.STRING)
             .withWidth(Width.LONG)
             .withImportance(Importance.MEDIUM)
-            .withValidation(RelationalDatabaseConnectorConfig::validateColumnBlacklist)
             .withDescription("");
 
     public static final Field MSG_KEY_COLUMNS = Field.create("message.key.columns")

File: debezium-core/src/main/java/io/debezium/transforms/Filter.java
Patch:
@@ -15,6 +15,7 @@
 import org.slf4j.LoggerFactory;
 
 import io.debezium.DebeziumException;
+import io.debezium.common.annotation.Incubating;
 import io.debezium.config.Configuration;
 import io.debezium.config.EnumeratedValue;
 import io.debezium.config.Field;
@@ -34,6 +35,7 @@
  * @param <R> the subtype of {@link ConnectRecord} on which this transformation will operate
  * @author Jiri Pechanec
  */
+@Incubating
 public class Filter<R extends ConnectRecord<R>> implements Transformation<R> {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(Filter.class);
@@ -154,7 +156,7 @@ public static NullHandling parse(String value, String defaultValue) {
             .withEnum(ExpressionLanguage.class)
             .withWidth(ConfigDef.Width.MEDIUM)
             .withImportance(ConfigDef.Importance.HIGH)
-            .withDescription("An expression language used to evaluate the filtering condition. Only 'groovy' is supported.");
+            .withDescription("An expression language used to evaluate the filtering condition. 'groovy' and 'graal.js' are supported.");
 
     public static final Field EXPRESSION = Field.create("condition")
             .withDisplayName("Filtering condition")

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/ExtractNewDocumentStateTest.java
Patch:
@@ -230,7 +230,9 @@ public void shouldFailWhenTheSchemaLooksValidButDoesNotHaveTheCorrectFields() {
                 valueSchema,
                 value);
 
-        exceptionRule.expect(NullPointerException.class);
+        // Prior to AK 2.4.1, this threw a NullPointerException
+        // As of AK 2.4.1, this now causes an IllegalArgumentException
+        exceptionRule.expect(IllegalArgumentException.class);
 
         // when
         SourceRecord transformed = transformation.apply(eventRecord);

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerErrorHandler.java
Patch:
@@ -24,6 +24,8 @@ public SqlServerErrorHandler(String logicalName, ChangeEventQueue<?> queue) {
     @Override
     protected boolean isRetriable(Throwable throwable) {
         return throwable instanceof SQLServerException
-                && (throwable.getMessage().contains("Connection timed out (Read failed)"));
+                && (throwable.getMessage().contains("Connection timed out (Read failed)")
+                        || throwable.getMessage().contains("The connection has been closed.")
+                        || throwable.getMessage().contains("Connection reset"));
     }
 }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -2017,7 +2017,7 @@ private List<SourceRecord> recordsForTopicForRoProductsTable(SourceRecords recor
 
     @Test
     @FixFor("DBZ-1531")
-    public void shouldEmitOldkeyHeaderOnPrimaryKeyUpdate() throws Exception {
+    public void shouldEmitOldKeyHeaderOnPrimaryKeyUpdate() throws Exception {
         config = DATABASE.defaultConfig()
                 .with(MySqlConnectorConfig.SNAPSHOT_MODE, MySqlConnectorConfig.SnapshotMode.NEVER)
                 .build();

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/RecordMaker.java
Patch:
@@ -5,15 +5,15 @@
  */
 package io.debezium.connector.cassandra;
 
+import java.time.Instant;
+
 import org.apache.kafka.connect.data.Schema;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import io.debezium.connector.cassandra.exceptions.CassandraConnectorTaskException;
 import io.debezium.function.BlockingConsumer;
 
-import java.time.Instant;
-
 /**
  * Responsible for generating ChangeRecord and/or TombstoneRecord for create/update/delete events, as well as EOF events.
  */

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/CommitLogProcessor.java
Patch:
@@ -51,7 +51,7 @@ public CommitLogProcessor(CassandraConnectorContext context) throws IOException
                 context.getOffsetWriter(),
                 new RecordMaker(context.getCassandraConnectorConfig().tombstonesOnDelete(),
                         new Filters(context.getCassandraConnectorConfig().fieldBlacklist()),
-                        new SourceInfo(context.getCassandraConnectorConfig())),
+                        context.getCassandraConnectorConfig()),
                 metrics);
         cdcDir = new File(DatabaseDescriptor.getCDCLogLocation());
         watcher = new AbstractDirectoryWatcher(cdcDir.toPath(), context.getCassandraConnectorConfig().cdcDirPollIntervalMs(), Collections.singleton(ENTRY_CREATE)) {

File: debezium-connector-cassandra/src/test/java/io/debezium/connector/cassandra/FileOffsetWriterTest.java
Patch:
@@ -129,8 +129,8 @@ public void testTwoFileWriterCannotCoexist() throws IOException {
 
     private ChangeRecord generateRecord(boolean markOffset, boolean isSnapshot, OffsetPosition offsetPosition, KeyspaceTable keyspaceTable) {
         CassandraConnectorConfig config = new CassandraConnectorConfig(Configuration.from(new Properties()));
-        SourceInfo sourceInfo = new SourceInfo(config);
-        sourceInfo.update("test-cluster", offsetPosition, keyspaceTable, isSnapshot, Conversions.toInstantFromMicros(System.currentTimeMillis() * 1000));
+        SourceInfo sourceInfo = new SourceInfo(config, "test-cluster", offsetPosition, keyspaceTable,
+                isSnapshot, Conversions.toInstantFromMicros(System.currentTimeMillis() * 1000));
         return new ChangeRecord(sourceInfo, new RowData(), Schema.INT32_SCHEMA, Schema.INT32_SCHEMA, Record.Operation.INSERT, markOffset);
     }
 

File: debezium-testing/debezium-testing-openshift/src/main/java/io/debezium/testing/openshift/tools/kafka/KafkaDeployer.java
Patch:
@@ -7,14 +7,14 @@
 
 import static java.util.concurrent.TimeUnit.MINUTES;
 
-import io.fabric8.kubernetes.api.model.apps.Deployment;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import io.debezium.testing.openshift.tools.OpenShiftUtils;
 import io.debezium.testing.openshift.tools.YAML;
 import io.fabric8.kubernetes.api.model.ConfigMap;
 import io.fabric8.kubernetes.api.model.Secret;
+import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.fabric8.openshift.client.OpenShiftClient;

File: debezium-testing/debezium-testing-openshift/src/test/java/io/debezium/testing/openshift/ConnectorTestBase.java
Patch:
@@ -18,7 +18,6 @@
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;
 
-import io.debezium.testing.openshift.tools.kafka.OperatorController;
 import org.apache.kafka.clients.consumer.Consumer;
 import org.apache.kafka.clients.consumer.ConsumerConfig;
 import org.apache.kafka.clients.consumer.ConsumerRecords;
@@ -32,6 +31,7 @@
 import io.debezium.testing.openshift.tools.kafka.KafkaConnectController;
 import io.debezium.testing.openshift.tools.kafka.KafkaController;
 import io.debezium.testing.openshift.tools.kafka.KafkaDeployer;
+import io.debezium.testing.openshift.tools.kafka.OperatorController;
 import io.fabric8.kubernetes.client.Config;
 import io.fabric8.kubernetes.client.ConfigBuilder;
 import io.fabric8.openshift.client.DefaultOpenShiftClient;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FieldBlacklistIT.java
Patch:
@@ -1267,6 +1267,8 @@ private void assertUpdateRecord(String blackList, ObjectId objectId, Document sn
         SourceRecord record = updateRecords.allRecordsInOrder().get(0);
         Struct value = getValue(record);
 
-        assertThat(value.get(field)).isEqualTo(expected);
+        Document expectedDoc = TestHelper.getDocumentWithoutLanguageVersion(expected);
+        Document actualDoc = TestHelper.getDocumentWithoutLanguageVersion(value.getString(field));
+        assertThat(actualDoc).isEqualTo(expectedDoc);
     }
 }

File: debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java
Patch:
@@ -146,7 +146,6 @@ public synchronized void stop() throws InterruptedException {
             snapshotMetrics.unregister(LOGGER);
             streamingMetrics.unregister(LOGGER);
         }
-        Thread.currentThread().interrupt();
     }
 
     private class ChangeEventSourceContextImpl implements ChangeEventSourceContext {

File: debezium-core/src/main/java/io/debezium/relational/RelationalSnapshotChangeEventSource.java
Patch:
@@ -422,7 +422,6 @@ public static class RelationalSnapshotContext extends SnapshotContext {
         public final Tables tables;
 
         public Set<TableId> capturedTables;
-        public OffsetContext offset;
         public boolean lastTable;
         public boolean lastRecordInTable;
 

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSnapshotChangeEventSource.java
Patch:
@@ -250,8 +250,8 @@ private boolean isSnapshotExpected(MongoPrimary primaryClient, ReplicaSetOffsetC
                 performSnapshot = true;
             }
             else {
-                // todo: Right now we implement when needed snapshot by default.  In the future we should provide the
-                //          same options as other connectors and this is where when_needed functionality would go.
+                // todo: Right now we implement when needed snapshot by default. In the future we should provide the
+                // same options as other connectors and this is where when_needed functionality would go.
                 // There is no ongoing snapshot, so look to see if our last recorded offset still exists in the oplog.
                 BsonTimestamp lastRecordedTs = offsetContext.lastOffsetTimestamp();
                 BsonTimestamp firstAvailableTs = primaryClient.execute("get oplog position", primary -> {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSnapshotChangeEventSource.java
Patch:
@@ -91,7 +91,8 @@ protected Set<TableId> getAllTableIds(RelationalSnapshotContext ctx) throws Exce
     }
 
     @Override
-    protected void lockTablesForSchemaSnapshot(ChangeEventSourceContext sourceContext, RelationalSnapshotContext snapshotContext) throws SQLException, InterruptedException {
+    protected void lockTablesForSchemaSnapshot(ChangeEventSourceContext sourceContext, RelationalSnapshotContext snapshotContext)
+            throws SQLException, InterruptedException {
         final Duration lockTimeout = connectorConfig.snapshotLockTimeout();
         final Optional<String> lockStatement = snapshotter.snapshotTableLockingStatement(lockTimeout, schema.tableIds());
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerSnapshotChangeEventSource.java
Patch:
@@ -101,7 +101,8 @@ protected Set<TableId> getAllTableIds(RelationalSnapshotContext ctx) throws Exce
     }
 
     @Override
-    protected void lockTablesForSchemaSnapshot(ChangeEventSourceContext sourceContext, RelationalSnapshotContext snapshotContext) throws SQLException, InterruptedException {
+    protected void lockTablesForSchemaSnapshot(ChangeEventSourceContext sourceContext, RelationalSnapshotContext snapshotContext)
+            throws SQLException, InterruptedException {
         if (connectorConfig.getSnapshotIsolationMode() == SnapshotIsolationMode.READ_UNCOMMITTED) {
             jdbcConnection.connection().setTransactionIsolation(Connection.TRANSACTION_READ_UNCOMMITTED);
             LOGGER.info("Schema locking was disabled in connector configuration");

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbSchema.java
Patch:
@@ -22,6 +22,7 @@
 import com.mongodb.MongoClient;
 import com.mongodb.util.JSONSerializers;
 import com.mongodb.util.ObjectSerializer;
+
 import io.debezium.connector.mongodb.FieldSelector.FieldFilter;
 import io.debezium.data.Envelope;
 import io.debezium.data.Envelope.FieldName;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbStreamingChangeEventSource.java
Patch:
@@ -30,6 +30,7 @@
 import com.mongodb.client.MongoCollection;
 import com.mongodb.client.MongoCursor;
 import com.mongodb.client.model.Filters;
+
 import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;
 import io.debezium.pipeline.ErrorHandler;
 import io.debezium.pipeline.EventDispatcher;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FieldRenamesIT.java
Patch:
@@ -641,8 +641,8 @@ public void shouldRenameFieldsForUnsetTopLevelFieldUpdateEvent() throws Exceptio
 
         Document updateObj = new Document()
                 .append("$unset", new Document()
-                    .append("name", "")
-                    .append("phone", ""));
+                        .append("name", "")
+                        .append("phone", ""));
 
         // @formatter:off
         String expected = "{"

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorIT.java
Patch:
@@ -46,8 +46,8 @@
 import com.mongodb.client.MongoDatabase;
 import com.mongodb.client.model.InsertOneOptions;
 import com.mongodb.util.JSON;
-
 import com.mongodb.util.JSONSerializers;
+
 import io.debezium.config.CommonConnectorConfig;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;
@@ -329,7 +329,6 @@ public void shouldConsumeAllEventsFromDatabase() throws InterruptedException, IO
         assertThat(insertId).isEqualTo(id.get());
         assertThat(updateId).isEqualTo(id.get());
 
-
         // ---------------------------------------------------------------------------------------------------------------
         // Delete a document
         // ---------------------------------------------------------------------------------------------------------------

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbSchemaIT.java
Patch:
@@ -5,14 +5,14 @@
  */
 package io.debezium.connector.mongodb;
 
+import static org.fest.assertions.Assertions.assertThat;
+
 import org.junit.After;
 import org.junit.Test;
 
 import io.debezium.config.Configuration;
 import io.debezium.schema.DataCollectionSchema;
 
-import static org.fest.assertions.Assertions.assertThat;
-
 /**
  * @author Chris Cranford
  */

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlSourceTypeInSchemaIT.java
Patch:
@@ -163,7 +163,7 @@ public void shouldPropagateSourceTypeByDatatype() throws SQLException, Interrupt
         // Use the DB configuration to define the connector's configuration ...
         config = DATABASE.defaultConfig()
                 .with(MySqlConnectorConfig.SNAPSHOT_MODE, MySqlConnectorConfig.SnapshotMode.NEVER)
-                .with("datatype.propagate.source.type", "FLOAT,VARCHAR")
+                .with("datatype.propagate.source.type", ".+\\.FLOAT,.+\\.VARCHAR")
                 .build();
 
         // Start the connector ...

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresChangeRecordEmitter.java
Patch:
@@ -289,8 +289,8 @@ private boolean schemaChanged(List<ReplicationMessage.Column> columns, Table tab
                         logger.info("detected new type for column '{}', old type was {} ({}), new type is {} ({}); refreshing table schema", columnName, localType,
                                 column.typeName(),
                                 incomingType, message.getType().getName());
+                        return true;
                     }
-                    return true;
                 }
                 if (metadataInMessage) {
                     final int localLength = column.length();

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -845,7 +845,7 @@ public void shouldRegularlyFlushLsn() throws InterruptedException, SQLException
 
                 // Wait max 2 seconds for LSN change
                 try {
-                    Awaitility.await().atMost(2, TimeUnit.MINUTES.SECONDS).ignoreExceptions().until(() -> flushLsn.add(getConfirmedFlushLsn(connection)));
+                    Awaitility.await().atMost(2, TimeUnit.SECONDS).ignoreExceptions().until(() -> flushLsn.add(getConfirmedFlushLsn(connection)));
                 }
                 catch (ConditionTimeoutException e) {
                     // We do not require all flushes to succeed in time

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/converters/TinyIntOneToBooleanConverter.java
Patch:
@@ -19,7 +19,7 @@
 
 /**
  * MySQL reports {@code BOOLEAN} values as {@code TINYINT(1)} in snapshot phase even as a result of
- * {@code DESCRIBE CREATE TABEL}.
+ * {@code DESCRIBE CREATE TABLE}.
  * This custom converter allows user to handle all {@code TINYINT(1)} fields as {@code BOOLEAN} or provide
  * a set of regexes to match only subset of tables/columns.
  *

File: debezium-core/src/main/java/io/debezium/annotation/Immutable.java
Patch:
@@ -12,7 +12,7 @@
 import java.lang.annotation.Target;
 
 @Documented
-@Target({ElementType.TYPE, ElementType.FIELD})
+@Target({ ElementType.TYPE, ElementType.FIELD })
 @Retention(RetentionPolicy.RUNTIME)
 public @interface Immutable {
 }

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -7,7 +7,6 @@
 
 import java.sql.Types;
 import java.util.List;
-import java.util.Optional;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.function.Function;

File: debezium-api/src/main/java/io/debezium/spi/converter/ConvertedField.java
Patch:
@@ -5,7 +5,7 @@
  */
 package io.debezium.spi.converter;
 
-import io.debezium.annotation.Incubating;
+import io.debezium.common.annotation.Incubating;
 
 /**
  * An the base interface for a converted field that provides naming characteristics.

File: debezium-api/src/main/java/io/debezium/spi/converter/CustomConverter.java
Patch:
@@ -8,7 +8,7 @@
 import java.util.Optional;
 import java.util.Properties;
 
-import io.debezium.annotation.Incubating;
+import io.debezium.common.annotation.Incubating;
 
 /**
  * An interface that allows the user to customize how a value will be converted for a given field.

File: debezium-api/src/main/java/io/debezium/spi/converter/RelationalColumn.java
Patch:
@@ -8,7 +8,7 @@
 import java.sql.Types;
 import java.util.Optional;
 
-import io.debezium.annotation.Incubating;
+import io.debezium.common.annotation.Incubating;
 
 /**
  * A definition of a converted relational column.

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -1069,7 +1069,7 @@ private static int validateGtidNewChannelPositionNotSet(Configuration config, Fi
     }
 
     private static int validateEventDeserializationFailureHandlingModeNotSet(Configuration config, Field field, ValidationOutput problems) {
-        final String modeName = config.getString(EVENT_DESERIALIZATION_FAILURE_HANDLING_MODE);
+        final String modeName = config.asMap().get(EVENT_DESERIALIZATION_FAILURE_HANDLING_MODE.name());
         if (modeName != null) {
             LOGGER.warn("Configuration option '{}' is renamed to '{}'", EVENT_DESERIALIZATION_FAILURE_HANDLING_MODE.name(),
                     EVENT_PROCESSING_FAILURE_HANDLING_MODE.name());

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -63,7 +63,7 @@
 import com.github.shyiko.mysql.binlog.network.SSLMode;
 import com.github.shyiko.mysql.binlog.network.SSLSocketFactory;
 
-import io.debezium.connector.mysql.MySqlConnectorConfig.EventProcessingFailureHandlingMode;
+import io.debezium.config.CommonConnectorConfig.EventProcessingFailureHandlingMode;
 import io.debezium.connector.mysql.MySqlConnectorConfig.SecureConnectionMode;
 import io.debezium.connector.mysql.RecordMakers.RecordsForTable;
 import io.debezium.function.BlockingConsumer;
@@ -192,7 +192,7 @@ public BinlogReader(String name, MySqlTaskContext context, HaltingPredicate acce
         recordMakers = context.makeRecord();
         recordSchemaChangesInSourceRecords = context.includeSchemaChangeRecords();
         clock = context.getClock();
-        eventDeserializationFailureHandlingMode = connectionContext.eventDeserializationFailureHandlingMode();
+        eventDeserializationFailureHandlingMode = connectionContext.eventProcessingFailureHandlingMode();
         inconsistentSchemaHandlingMode = connectionContext.inconsistentSchemaHandlingMode();
 
         // Use exponential delay to log the progress frequently at first, but the quickly tapering off to once an hour...

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/BinlogReaderIT.java
Patch:
@@ -30,9 +30,9 @@
 import org.junit.Before;
 import org.junit.Test;
 
+import io.debezium.config.CommonConnectorConfig.EventProcessingFailureHandlingMode;
 import io.debezium.config.Configuration;
 import io.debezium.connector.mysql.AbstractReader.AcceptAllPredicate;
-import io.debezium.connector.mysql.MySqlConnectorConfig.EventProcessingFailureHandlingMode;
 import io.debezium.connector.mysql.MySqlConnectorConfig.SecureConnectionMode;
 import io.debezium.data.Envelope;
 import io.debezium.data.KeyValueStore;
@@ -455,7 +455,7 @@ public void shouldWarnOnSchemaInconsistency() throws Exception {
 
     @Test
     public void shouldIgnoreOnSchemaInconsistency() throws Exception {
-        inconsistentSchema(EventProcessingFailureHandlingMode.IGNORE);
+        inconsistentSchema(EventProcessingFailureHandlingMode.SKIP);
         int consumed = consumeAtLeast(2, 2, TimeUnit.SECONDS);
         assertThat(consumed).isZero();
     }

File: debezium-api/src/main/java/io/debezium/engine/DebeziumEngine.java
Patch:
@@ -224,7 +224,7 @@ public static interface Builder<R> {
      * @return the new builder; never null
      */
     @SuppressWarnings({ "rawtypes", "unchecked" })
-    public static <T> Builder<T> create(Class<T> recordClass) {
+    public static <T> Builder<T> create(Class<? extends ChangeEventFormat<T>> eventFormat) {
         final ServiceLoader<Builder> loader = ServiceLoader.load(Builder.class);
         final Iterator<Builder> iterator = loader.iterator();
         if (!iterator.hasNext()) {

File: debezium-embedded/src/test/java/io/debezium/embedded/EmbeddedEngineTest.java
Patch:
@@ -168,7 +168,7 @@ public void shouldRunDebeziumEngine() throws Exception {
         CountDownLatch allLatch = new CountDownLatch(6);
 
         // create an engine with our custom class
-        final DebeziumEngine<SourceRecord> engine = DebeziumEngine.create(SourceRecord.class)
+        final DebeziumEngine<SourceRecord> engine = DebeziumEngine.create(Connect.class)
                 .using(props)
                 .notifying((records, committer) -> {
                     assertThat(records.size()).isGreaterThanOrEqualTo(NUMBER_OF_LINES);

File: debezium-testing/debezium-testing-openshift/src/main/java/io/debezium/testing/openshift/tools/OpenShiftUtils.java
Patch:
@@ -29,7 +29,7 @@
  * @author Jakub Cechacek
  */
 public class OpenShiftUtils {
-    private static  final Logger LOGGER = LoggerFactory.getLogger(OpenShiftUtils.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(OpenShiftUtils.class);
 
     private OpenShiftClient client;
 

File: debezium-core/src/main/java/io/debezium/converters/CloudEventsMaker.java
Patch:
@@ -70,7 +70,7 @@ public static final class FieldName {
 
     static final Map<SerializerType, String> CONTENT_TYPE_NAME_MAP = Collect.hashMapOf(
             SerializerType.JSON, "application/json",
-            SerializerType.AVRO, "avro/binary");
+            SerializerType.AVRO, "application/avro");
 
     /**
      * Create a concrete CloudEvents maker using the outputs of a record parser. Also need to specify the data content

File: debezium-core/src/test/java/io/debezium/converters/CloudEventsConverterTest.java
Patch:
@@ -175,7 +175,7 @@ public static void shouldConvertToCloudEventsInJsonWithDataAsAvro(SourceRecord r
             assertThat(valueJson.get(CloudEventsMaker.FieldName.ID)).isNotNull();
             assertThat(valueJson.get(CloudEventsMaker.FieldName.SOURCE)).isNotNull();
             assertThat(valueJson.get(CloudEventsMaker.FieldName.SPECVERSION)).isNotNull();
-            assertThat(valueJson.get(CloudEventsMaker.FieldName.DATACONTENTTYPE).asText()).isEqualTo("avro/binary");
+            assertThat(valueJson.get(CloudEventsMaker.FieldName.DATACONTENTTYPE).asText()).isEqualTo("application/avro");
             assertThat(valueJson.get(CloudEventsMaker.FieldName.DATASCHEMA).asText()).startsWith("http://fake-url/schemas/ids/");
             assertThat(valueJson.get(CloudEventsMaker.FieldName.TYPE)).isNotNull();
             assertThat(valueJson.get(CloudEventsMaker.FieldName.TIME)).isNotNull();
@@ -265,7 +265,7 @@ public static void shouldConvertToCloudEventsInAvro(SourceRecord record, String
             assertThat(avroValue.getString(CloudEventsMaker.FieldName.SOURCE)).isEqualTo("/debezium/" + connectorName + "/" + serverName);
             assertThat(avroValue.get(CloudEventsMaker.FieldName.SPECVERSION)).isEqualTo("1.0");
             assertThat(avroValue.get(CloudEventsMaker.FieldName.TYPE)).isEqualTo("io.debezium." + connectorName + ".datachangeevent");
-            assertThat(avroValue.get(CloudEventsMaker.FieldName.DATACONTENTTYPE)).isEqualTo("avro/binary");
+            assertThat(avroValue.get(CloudEventsMaker.FieldName.DATACONTENTTYPE)).isEqualTo("application/avro");
             assertThat(avroValue.getString(CloudEventsMaker.FieldName.DATASCHEMA)).startsWith("http://fake-url/schemas/ids/");
             assertThat(avroValue.get(CloudEventsMaker.FieldName.TIME)).isNotNull();
             assertThat(avroValue.get(CloudEventsMaker.FieldName.DATA)).isNotNull();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -791,7 +791,7 @@ private void informAboutUnknownTableIfRequired(Event event, TableId tableId, Str
                         eventHeader.getPosition(),
                         eventHeader.getNextPosition(),
                         source.binlogFilename());
-                throw new ConnectException("Encountered change event for table " + tableId + "whose schema isn't known to this connector");
+                throw new ConnectException("Encountered change event for table " + tableId + " whose schema isn't known to this connector");
             }
             else if (inconsistentSchemaHandlingMode == EventProcessingFailureHandlingMode.WARN) {
                 logger.warn(

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -28,7 +28,6 @@
 import java.util.Optional;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicInteger;
 import java.util.function.Function;
 import java.util.stream.Collectors;
 import java.util.stream.IntStream;

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -879,6 +879,7 @@ public void shouldFlushLsnOnEmptyMessage() throws InterruptedException, SQLExcep
 
         final Set<String> flushLsn = new HashSet<>();
         TestHelper.execute(INSERT_STMT);
+
         Awaitility.await().atMost(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS).until(() -> {
             final SourceRecords actualRecords = consumeRecordsByTopic(1);
             final List<SourceRecord> topicRecords = actualRecords.recordsForTopic(topicName("s1.a"));
@@ -890,8 +891,8 @@ public void shouldFlushLsnOnEmptyMessage() throws InterruptedException, SQLExcep
             for (int i = 0; i < recordCount; i++) {
                 TestHelper.execute(DDL_STATEMENT);
 
-                // Wait max 2 seconds for LSN change
                 try {
+                    // Wait max 5 seconds for LSN change caused by DDL_STATEMENT
                     Awaitility.await().atMost(Duration.FIVE_SECONDS).ignoreExceptions().until(() -> flushLsn.add(getConfirmedFlushLsn(connection)));
                 }
                 catch (ConditionTimeoutException e) {

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/CassandraConnectorContext.java
Patch:
@@ -35,7 +35,7 @@ public CassandraConnectorContext(CassandraConnectorConfig config) throws General
         this.queue = new BlockingEventQueue<>(this.config.pollIntervalMs(), this.config.maxQueueSize(), this.config.maxBatchSize());
 
         // Setting up schema holder ...
-        this.schemaHolder = new SchemaHolder(this.cassandraClient, this.config.connectorName(), this.config.getSourceInfoStructMaker());
+        this.schemaHolder = new SchemaHolder(this.cassandraClient, this.config.kafkaTopicPrefix(), this.config.getSourceInfoStructMaker());
 
         // Setting up a file-based offset manager ...
         this.offsetWriter = new FileOffsetWriter(this.config.offsetBackingStoreDir());

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SnapshotIT.java
Patch:
@@ -222,7 +222,7 @@ private void testStreaming() throws SQLException, InterruptedException {
             final Struct value1 = (Struct) record1.value();
             assertRecord(key1, expectedKey1);
             assertRecord((Struct) value1.get("after"), expectedRow1);
-            assertThat(record1.sourceOffset()).hasSize(3);
+            assertThat(record1.sourceOffset()).hasSize(4);
 
             Assert.assertTrue(record1.sourceOffset().containsKey("change_lsn"));
             Assert.assertTrue(record1.sourceOffset().containsKey("commit_lsn"));

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlJdbcContext.java
Patch:
@@ -58,6 +58,9 @@ public MySqlJdbcContext(MySqlConnectorConfig config) {
         boolean useSSL = sslModeEnabled();
         Configuration jdbcConfig = this.config
                 .filter(x -> !(x.startsWith(DatabaseHistory.CONFIGURATION_FIELD_PREFIX_STRING) || x.equals(MySqlConnectorConfig.DATABASE_HISTORY.name())))
+                .edit()
+                .withDefault(MySqlConnectorConfig.PORT, MySqlConnectorConfig.PORT.defaultValue())
+                .build()
                 .subset("database.", true);
 
         Builder jdbcConfigBuilder = jdbcConfig

File: debezium-quarkus/extensions/outbox/runtime/src/main/java/io/debezium/outbox/quarkus/ExportedEvent.java
Patch:
@@ -7,11 +7,14 @@
 
 import java.time.Instant;
 
+import io.debezium.annotation.Incubating;
+
 /**
  * Describes an event that should be exported via the "outbox" table.
  *
  * @author Chris Cranford
  */
+@Incubating
 public interface ExportedEvent<I, P> {
 
     /**

File: debezium-quarkus/extensions/outbox/runtime/src/main/java/io/debezium/outbox/quarkus/internal/DebeziumOutboxRuntimeConfig.java
Patch:
@@ -20,5 +20,5 @@ public class DebeziumOutboxRuntimeConfig {
      * Remove outbox entity after being inserted.  Default is {@code true}.
      */
     @ConfigItem(defaultValue = "true")
-    public Boolean removeAfterInsert;
+    public boolean removeAfterInsert;
 }

File: debezium-core/src/test/java/io/debezium/serde/SerdeTest.java
Patch:
@@ -206,7 +206,7 @@ public void valueWithUnknownPropertyThrowRuntimeException() {
     public void valueWithUnknownPropertyIgnored() {
         Map<String, Object> options = new HashMap<>();
         options.put("from.field", "before");
-        options.put("ignore.unknown.properties", true);
+        options.put("unknown.properties.ignored", true);
 
         final Serde<Customer> valueSerde = DebeziumSerdes.payloadJson(Customer.class);
         valueSerde.configure(options, false);

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/AbstractSqlServerDatatypesTest.java
Patch:
@@ -128,7 +128,7 @@ public abstract class AbstractSqlServerDatatypesTest extends AbstractConnectorTe
     private static final List<SchemaAndValueField> EXPECTED_DATE_TIME = Arrays.asList(
             new SchemaAndValueField("val_date", Date.builder().optional().build(), 17_725),
             new SchemaAndValueField("val_time_p2", Time.builder().optional().build(), 37_425_680),
-            new SchemaAndValueField("val_time", MicroTime.builder().optional().build(), 37_425_679_000L), // value truncated by the driver
+            new SchemaAndValueField("val_time", MicroTime.builder().optional().build(), 37_425_678_900L),
             new SchemaAndValueField("val_datetime2", NanoTimestamp.builder().optional().build(), 1_531_481_025_340_000_000L),
             new SchemaAndValueField("val_datetimeoffset", ZonedTimestamp.builder().optional().build(), "2018-07-13T12:23:45.456+11:00"),
             new SchemaAndValueField("val_datetime", Timestamp.builder().optional().build(), 1_531_488_225_780L),
@@ -144,7 +144,7 @@ public abstract class AbstractSqlServerDatatypesTest extends AbstractConnectorTe
                             .atOffset(ZoneOffset.UTC)
                             .toInstant())),
             new SchemaAndValueField("val_time", org.apache.kafka.connect.data.Time.builder().optional().build(),
-                    java.util.Date.from(LocalTime.of(10, 23, 45, 679_000_000).atDate(LocalDate.ofEpochDay(0)) // value truncated by the driver
+                    java.util.Date.from(LocalTime.of(10, 23, 45, 678_900_000).atDate(LocalDate.ofEpochDay(0)) // value truncated by the driver
                             .atOffset(ZoneOffset.UTC)
                             .toInstant())),
             new SchemaAndValueField("val_datetime2", org.apache.kafka.connect.data.Timestamp.builder().optional().build(),

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDefaultValueConverter.java
Patch:
@@ -66,8 +66,8 @@ public Object convert(Column column, String value) {
             return value;
         }
 
-        // boolean is also TINYINT(1)
-        if ("TINYINT".equals(column.typeName())) {
+        // boolean is also INT(1) or TINYINT(1)
+        if ("TINYINT".equals(column.typeName()) || "INT".equals(column.typeName())) {
             if ("true".equalsIgnoreCase(value) || "false".equalsIgnoreCase(value)) {
                 return convertToBoolean(value);
             }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoColumnValue.java
Patch:
@@ -325,9 +325,6 @@ public Object asDefault(TypeRegistry typeRegistry, int columnType, String column
                 type.getOid() == typeRegistry.hstoreArrayOid()) {
             return asArray(columnName, type, fullType, connection);
         }
-        if (type.isEnumType()) {
-            return asString();
-        }
         // unknown data type is sent by decoder as binary value
         if (includeUnknownDatatypes) {
             return asByteArray();

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnection.java
Patch:
@@ -401,7 +401,9 @@ private ZoneId retrieveTransactionTimezone(boolean supportsAtTimeZone) {
         }
         else {
             if (serverTimezoneConfig == null) {
-                LOGGER.warn("The '{}' option should be specified to avoid incorrect timestamp values in case of different timezones between the database server and this connector's JVM.", SERVER_TIMEZONE_PROP_NAME);
+                LOGGER.warn(
+                        "The '{}' option should be specified to avoid incorrect timestamp values in case of different timezones between the database server and this connector's JVM.",
+                        SERVER_TIMEZONE_PROP_NAME);
             }
         }
 

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectorIT.java
Patch:
@@ -232,7 +232,7 @@ public void timestampAndTimezone() throws Exception {
 
         final TimeZone currentTimeZone = TimeZone.getDefault();
         try {
-            TimeZone.setDefault(TimeZone.getTimeZone("Atlantic/Cape_Verde"));
+            TimeZone.setDefault(TimeZone.getTimeZone("Australia/Canberra"));
             final Configuration config = TestHelper.defaultConfig()
                     .with(SqlServerConnectorConfig.SNAPSHOT_MODE, SnapshotMode.INITIAL)
                     .build();

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerStreamingChangeEventSource.java
Patch:
@@ -115,6 +115,7 @@ public void execute(ChangeEventSourceContext context) throws InterruptedExceptio
             // otherwise we might skip an incomplete transaction after restart
             boolean shouldIncreaseFromLsn = offsetContext.isSnapshotCompleted();
             while (context.isRunning()) {
+                dataConnection.connection().commit();
                 final Lsn currentMaxLsn = dataConnection.getMaxLsn();
 
                 // Shouldn't happen if the agent is running, but it is better to guard against such situation

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresTaskContext.java
Patch:
@@ -103,7 +103,9 @@ protected ReplicationConnection createReplicationConnection(boolean exportSnapsh
         final boolean dropSlotOnStop = config.dropSlotOnStop();
         if (dropSlotOnStop) {
             LOGGER.warn(
-                    "Connector has enabled automated replication slot removal upon restart ({} = true). This setting can lead to data loss in production environments!",
+                    "Connector has enabled automated replication slot removal upon restart ({} = true). " +
+                    "This setting is not recommended for production environments, as a new replication slot " +
+                    "will be created after a connector restart, resulting in missed data change events.",
                     PostgresConnectorConfig.DROP_SLOT_ON_STOP.name());
         }
         return ReplicationConnection.builder(config.jdbcConfig())

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresConnection.java
Patch:
@@ -468,7 +468,7 @@ protected Optional<ColumnEditor> readTableColumn(ResultSet columnMetadata, Table
             column.jdbcType(nativeType.getRootType().getJdbcId());
 
             // For domain types, the postgres driver is unable to traverse a nested unbounded
-            // hierarchy of types and report the right length/scale of a given type.  We use
+            // hierarchy of types and report the right length/scale of a given type. We use
             // the TypeRegistry to accomplish this since it is capable of traversing the type
             // hierarchy upward to resolve length/scale regardless of hierarchy depth.
             if (TypeRegistry.DOMAIN_TYPE == nativeType.getJdbcId()) {

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConnection.java
Patch:
@@ -1215,7 +1215,7 @@ public static void columnsFor(ResultSet resultSet, Consumer<Column> consumer) th
         }
     }
 
-    private static boolean isNullable(int jdbcNullable) {
+    protected static boolean isNullable(int jdbcNullable) {
         return jdbcNullable == ResultSetMetaData.columnNullable || jdbcNullable == ResultSetMetaData.columnNullableUnknown;
     }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresChangeRecordEmitter.java
Patch:
@@ -349,10 +349,10 @@ private Table tableFromFromMessage(List<ReplicationMessage.Column> columns, Tabl
                             final PostgresType type = column.getType();
                             final ColumnEditor columnEditor = Column.editor()
                                     .name(column.getName())
-                                    .jdbcType(type.getJdbcId())
+                                    .jdbcType(type.getRootType().getJdbcId())
                                     .type(type.getName())
                                     .optional(column.isOptional())
-                                    .nativeType(type.getOid());
+                                    .nativeType(type.getRootType().getOid());
                             columnEditor.length(column.getTypeMetadata().getLength());
                             columnEditor.scale(column.getTypeMetadata().getScale());
                             return columnEditor.create();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ReplicationMessageColumnValueResolver.java
Patch:
@@ -40,8 +40,8 @@ public static Object resolveValue(String columnName, PostgresType type, String f
             return null;
         }
 
-        if (!type.isBaseType()) {
-            return resolveValue(columnName, type.getBaseType(), fullType, value, connection, includeUnknownDatatypes, typeRegistry);
+        if (!type.isRootType()) {
+            return resolveValue(columnName, type.getParentType(), fullType, value, connection, includeUnknownDatatypes, typeRegistry);
         }
 
         if (value.isArray(type)) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoColumnValue.java
Patch:
@@ -34,6 +34,8 @@
 import io.debezium.time.Conversions;
 
 /**
+ * Replication message column sent by <a href="https://github.com/debezium/postgres-decoderbufs">Postgres Decoderbufs</>
+ *
  * @author Chris Cranford
  */
 public class PgProtoColumnValue extends AbstractColumnValue<PgProto.DatumMessage> {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoColumnValue.java
Patch:
@@ -353,6 +353,9 @@ public Object asDefault(TypeRegistry typeRegistry, int columnType, String column
                 type.getOid() == typeRegistry.hstoreArrayOid()) {
             return asArray(columnName, type, fullType, connection);
         }
+        if (type.isEnumType()) {
+            return asString();
+        }
         // unknown data type is sent by decoder as binary value
         if (includeUnknownDatatypes) {
             return asByteArray();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgoutput/PgOutputMessageDecoder.java
Patch:
@@ -563,7 +563,8 @@ private static List<Column> resolveColumnsFromStreamTupleData(ByteBuffer buffer,
                         new AbstractReplicationMessageColumn(columnName, columnType, typeExpression, optional, true) {
                             @Override
                             public Object getValue(PgConnectionSupplier connection, boolean includeUnknownDatatypes) {
-                                return PgOutputReplicationMessage.getValue(columnName, columnType, typeExpression, valueStr, connection, includeUnknownDatatypes);
+                                return PgOutputReplicationMessage.getValue(columnName, columnType, typeExpression, valueStr, connection, includeUnknownDatatypes,
+                                        typeRegistry);
                             }
 
                             @Override

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgoutput/PgOutputReplicationMessage.java
Patch:
@@ -10,6 +10,7 @@
 
 import io.debezium.connector.postgresql.PostgresStreamingChangeEventSource.PgConnectionSupplier;
 import io.debezium.connector.postgresql.PostgresType;
+import io.debezium.connector.postgresql.TypeRegistry;
 import io.debezium.connector.postgresql.connection.ReplicationMessage;
 import io.debezium.connector.postgresql.connection.ReplicationMessageColumnValueResolver;
 
@@ -90,8 +91,8 @@ public boolean shouldSchemaBeSynchronized() {
      * @return the value; may be null
      */
     public static Object getValue(String columnName, PostgresType type, String fullType, String rawValue, final PgConnectionSupplier connection,
-                                  boolean includeUnknownDataTypes) {
+                                  boolean includeUnknownDataTypes, TypeRegistry typeRegistry) {
         final PgOutputColumnValue columnValue = new PgOutputColumnValue(rawValue);
-        return ReplicationMessageColumnValueResolver.resolveValue(columnName, type, fullType, columnValue, connection, includeUnknownDataTypes);
+        return ReplicationMessageColumnValueResolver.resolveValue(columnName, type, fullType, columnValue, connection, includeUnknownDataTypes, typeRegistry);
     }
 }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/Wal2JsonReplicationMessage.java
Patch:
@@ -168,7 +168,7 @@ private String parseType(String columnName, String typeWithModifiers) {
     public Object getValue(String columnName, PostgresType type, String fullType, Value rawValue, final PgConnectionSupplier connection,
                            boolean includeUnknownDatatypes) {
         final Wal2JsonColumnValue columnValue = new Wal2JsonColumnValue(rawValue);
-        return ReplicationMessageColumnValueResolver.resolveValue(columnName, type, fullType, columnValue, connection, includeUnknownDatatypes);
+        return ReplicationMessageColumnValueResolver.resolveValue(columnName, type, fullType, columnValue, connection, includeUnknownDatatypes, typeRegistry);
     }
 
     @Override

File: debezium-core/src/main/java/io/debezium/transforms/outbox/EventRouter.java
Patch:
@@ -165,7 +165,7 @@ else if (onlyHeadersInOutputMessage) {
         }
 
         R newRecord = r.newRecord(
-                eventStruct.getString(routeByField).toLowerCase(),
+                eventStruct.getString(routeByField),
                 null,
                 Schema.STRING_SCHEMA,
                 defineRecordKey(eventStruct, payloadId),

File: debezium-core/src/test/java/io/debezium/transforms/outbox/EventRouterTest.java
Patch:
@@ -376,7 +376,7 @@ public void canRouteBasedOnField() {
         final SourceRecord userEventRouted = router.apply(userEventRecord);
 
         assertThat(userEventRouted).isNotNull();
-        assertThat(userEventRouted.topic()).isEqualTo("outbox.event.user");
+        assertThat(userEventRouted.topic()).isEqualTo("outbox.event.User");
 
         final SourceRecord userUpdatedEventRecord = createEventRecord(
                 "ab720dd3-176d-40a6-96f3-6cf961d7df6a",
@@ -387,7 +387,7 @@ public void canRouteBasedOnField() {
         final SourceRecord userUpdatedEventRouted = router.apply(userUpdatedEventRecord);
 
         assertThat(userUpdatedEventRouted).isNotNull();
-        assertThat(userUpdatedEventRouted.topic()).isEqualTo("outbox.event.user");
+        assertThat(userUpdatedEventRouted.topic()).isEqualTo("outbox.event.User");
 
         final SourceRecord addressCreatedEventRecord = createEventRecord(
                 "ab720dd3-176d-40a6-96f3-6cf961d7df6a",
@@ -398,7 +398,7 @@ public void canRouteBasedOnField() {
         final SourceRecord addressCreatedEventRouted = router.apply(addressCreatedEventRecord);
 
         assertThat(addressCreatedEventRouted).isNotNull();
-        assertThat(addressCreatedEventRouted.topic()).isEqualTo("outbox.event.address");
+        assertThat(addressCreatedEventRouted.topic()).isEqualTo("outbox.event.Address");
     }
 
     @Test

File: debezium-core/src/main/java/io/debezium/util/IoUtil.java
Patch:
@@ -371,7 +371,9 @@ public static File createDirectory(Path path, boolean removeExistingContent) thr
         File dir = path.toAbsolutePath().toFile();
         if (dir.exists() && dir.canRead() && dir.canWrite()) {
             if (dir.isDirectory()) {
-                delete(path);
+                if (removeExistingContent) {
+                    delete(path);
+                }
                 return dir;
             }
             throw new IllegalStateException("Expecting '" + path + "' to be a directory but found a file");

File: debezium-core/src/main/java/io/debezium/util/VariableLatch.java
Patch:
@@ -38,7 +38,7 @@ public static VariableLatch create() {
      * @return the variable latch; never null
      */
     public static VariableLatch create(int initialValue) {
-        return new VariableLatch(0);
+        return new VariableLatch(initialValue);
     }
 
     /**

File: debezium-core/src/main/java/io/debezium/relational/HistorizedRelationalDatabaseConnectorConfig.java
Patch:
@@ -49,7 +49,8 @@ protected HistorizedRelationalDatabaseConnectorConfig(Configuration config, Stri
         this.useCatalogBeforeSchema = useCatalogBeforeSchema;
     }
 
-    protected HistorizedRelationalDatabaseConnectorConfig(Configuration config, String logicalName, TableFilter systemTablesFilter, TableIdToStringMapper tableIdMapper, boolean useCatalogBeforeSchema) {
+    protected HistorizedRelationalDatabaseConnectorConfig(Configuration config, String logicalName, TableFilter systemTablesFilter, TableIdToStringMapper tableIdMapper,
+                                                          boolean useCatalogBeforeSchema) {
         super(config, logicalName, systemTablesFilter, tableIdMapper, DEFAULT_SNAPSHOT_FETCH_SIZE);
         this.useCatalogBeforeSchema = useCatalogBeforeSchema;
     }

File: debezium-core/src/main/java/io/debezium/relational/history/DatabaseHistory.java
Patch:
@@ -73,7 +73,6 @@ public interface DatabaseHistory {
                     + "from processing and storing into schema history evolution.")
             .withValidation(Field::isListOfRegex);
 
-    
     /**
      * Configure this instance.
      *

File: debezium-core/src/main/java/io/debezium/relational/history/TableChanges.java
Patch:
@@ -37,7 +37,7 @@ public TableChanges() {
     }
 
     /**
-     * useCatalogBeforeSchema is true if the parsed string contains only 2 items and the first should be used as
+     * @param useCatalogBeforeSchema true if the parsed string contains only 2 items and the first should be used as
      * the catalog and the second as the table name, or false if the first should be used as the schema and the
      * second as the table name
      */

File: debezium-core/src/test/java/io/debezium/junit/logging/LogInterceptor.java
Patch:
@@ -8,8 +8,8 @@
 import static org.slf4j.Logger.ROOT_LOGGER_NAME;
 
 import java.lang.reflect.Field;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.concurrent.CopyOnWriteArrayList;
 
 import org.apache.log4j.AppenderSkeleton;
 import org.apache.log4j.Level;
@@ -22,7 +22,7 @@
  * @author Chris Cranford
  */
 public class LogInterceptor extends AppenderSkeleton {
-    private List<LoggingEvent> events = new ArrayList<>();
+    private List<LoggingEvent> events = new CopyOnWriteArrayList<>();
 
     public LogInterceptor() {
         try {

File: debezium-core/src/main/java/io/debezium/connector/base/ChangeEventQueue.java
Patch:
@@ -168,7 +168,7 @@ public void producerFailure(final Throwable producerFailure) {
 
     private void throwProducerFailureIfPresent() {
         if (producerFailure != null) {
-            throw new ConnectException("An exception ocurred in the change event producer. This connector will be stopped.", producerFailure);
+            throw new ConnectException("An exception occurred in the change event producer. This connector will be stopped.", producerFailure);
         }
     }
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -56,9 +56,9 @@
 import org.slf4j.LoggerFactory;
 
 import io.debezium.connector.SnapshotRecord;
+import io.debezium.connector.postgresql.data.Ltree;
 import io.debezium.data.Bits;
 import io.debezium.data.Json;
-import io.debezium.data.Ltree;
 import io.debezium.data.SchemaUtil;
 import io.debezium.data.Uuid;
 import io.debezium.data.VariableScaleDecimal;

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -6,8 +6,8 @@
 
 package io.debezium.connector.postgresql;
 
-import static io.debezium.connector.postgresql.PostgresConnectorConfig.SCHEMA_BLACKLIST;
 import static io.debezium.connector.postgresql.junit.SkipWhenDatabaseVersionLessThan.PostgresVersion.POSTGRES_10;
+import static io.debezium.relational.RelationalDatabaseConnectorConfig.SCHEMA_BLACKLIST;
 import static org.fest.assertions.Assertions.assertThat;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
@@ -27,11 +27,11 @@
 import org.junit.rules.TestRule;
 
 import io.debezium.connector.postgresql.connection.PostgresConnection;
+import io.debezium.connector.postgresql.data.Ltree;
 import io.debezium.connector.postgresql.junit.SkipTestDependingOnDatabaseVersionRule;
 import io.debezium.connector.postgresql.junit.SkipWhenDatabaseVersionLessThan;
 import io.debezium.data.Bits;
 import io.debezium.data.Json;
-import io.debezium.data.Ltree;
 import io.debezium.data.Uuid;
 import io.debezium.data.VariableScaleDecimal;
 import io.debezium.data.VerifyRecord;

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -46,10 +46,10 @@
 
 import io.debezium.connector.postgresql.PostgresConnectorConfig.HStoreHandlingMode;
 import io.debezium.connector.postgresql.PostgresConnectorConfig.IntervalHandlingMode;
+import io.debezium.connector.postgresql.data.Ltree;
 import io.debezium.connector.postgresql.proto.PgProto;
 import io.debezium.data.Bits;
 import io.debezium.data.Json;
-import io.debezium.data.Ltree;
 import io.debezium.data.SpecialValueDecimal;
 import io.debezium.data.Uuid;
 import io.debezium.data.VariableScaleDecimal;

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/data/Ltree.java
Patch:
@@ -3,7 +3,7 @@
  *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
-package io.debezium.data;
+package io.debezium.connector.postgresql.data;
 
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -994,7 +994,7 @@ public void shouldReceiveSchemaForNonWhitelistedTablesAndDatabases() throws SQLE
     }
 
     @Test
-    @FixFor("DBZ-683")
+    @FixFor("DBZ-1546")
     public void shouldHandleWhitelistedTables() throws SQLException, InterruptedException {
         Testing.Files.delete(DB_HISTORY_PATH);
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgoutput/PgOutputMessageDecoder.java
Patch:
@@ -6,6 +6,7 @@
 package io.debezium.connector.postgresql.connection.pgoutput;
 
 import java.nio.ByteBuffer;
+import java.nio.charset.Charset;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.time.Instant;
@@ -494,7 +495,7 @@ private static String readColumnValueAsString(ByteBuffer buffer) {
         int length = buffer.getInt();
         byte[] value = new byte[length];
         buffer.get(value, 0, length);
-        return new String(value);
+        return new String(value, Charset.forName("UTF-8"));
     }
 
     /**

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/LcrEventHandler.java
Patch:
@@ -71,7 +71,7 @@ public void processLCR(LCR lcr) throws StreamsException {
         offsetContext.setTableId(new TableId(lcr.getSourceDatabaseName(), lcr.getObjectOwner(), lcr.getObjectName()));
 
         try {
-            if(lcr instanceof RowLCR) {
+            if (lcr instanceof RowLCR) {
                 dispatchDataChangeEvent((RowLCR) lcr);
             }
             else if (lcr instanceof DDLLCR) {
@@ -92,7 +92,7 @@ else if (lcr instanceof DDLLCR) {
     private void dispatchDataChangeEvent(RowLCR lcr) throws InterruptedException {
         LOGGER.debug("Processing DML event {}", lcr);
 
-        if(RowLCR.COMMIT.equals(lcr.getCommandType())) {
+        if (RowLCR.COMMIT.equals(lcr.getCommandType())) {
             return;
         }
 
@@ -124,7 +124,6 @@ private TableId getTableId(LCR lcr) {
         else {
             return new TableId(lcr.getSourceDatabaseName().toLowerCase(), lcr.getObjectOwner(), lcr.getObjectName().toLowerCase());
         }
-        
     }
 
     @Override

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSnapshotChangeEventSource.java
Patch:
@@ -114,7 +114,7 @@ protected void determineSnapshotOffset(SnapshotContext ctx) throws Exception {
         do {
             currentScn = getCurrentScn(ctx);
         }
-        while(areSameTimestamp(latestTableDdlScn.orElse(null), currentScn));
+        while (areSameTimestamp(latestTableDdlScn.orElse(null), currentScn));
 
         ctx.offset = OracleOffsetContext.create()
                 .logicalName(connectorConfig)
@@ -162,12 +162,12 @@ private Optional<Long> getLatestTableDdlScn(SnapshotContext ctx) throws SQLExcep
                 .append(" FROM all_objects")
                 .append(" WHERE");
 
-        for(TableId table : ctx.capturedTables) {
+        for (TableId table : ctx.capturedTables) {
             lastDdlScnQuery.append(" (owner = '" + table.schema() + "' AND object_name = '" + table.table() + "') OR");
         }
 
         String query = lastDdlScnQuery.substring(0, lastDdlScnQuery.length() - 3).toString();
-        try(Statement statement = jdbcConnection.connection().createStatement();
+        try (Statement statement = jdbcConnection.connection().createStatement();
                 ResultSet rs = statement.executeQuery(query)) {
 
             if (!rs.next()) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleStreamingChangeEventSource.java
Patch:
@@ -59,14 +59,14 @@ public OracleStreamingChangeEventSource(OracleConnectorConfig connectorConfig, O
     public void execute(ChangeEventSourceContext context) throws InterruptedException {
         try {
             // 1. connect
-            final byte[] startPosition = offsetContext.getLcrPosition() != null ? offsetContext.getLcrPosition().getRawPosition() : convertScnToPosition(offsetContext.getScn()); 
+            final byte[] startPosition = offsetContext.getLcrPosition() != null ? offsetContext.getLcrPosition().getRawPosition() : convertScnToPosition(offsetContext.getScn());
             xsOut = XStreamOut.attach((OracleConnection) jdbcConnection.connection(), xStreamServerName,
                     startPosition, 1, 1, XStreamOut.DEFAULT_MODE);
 
             LcrEventHandler handler = new LcrEventHandler(errorHandler, dispatcher, clock, schema, offsetContext, this.tablenameCaseInsensitive);
 
             // 2. receive events while running
-            while(context.isRunning()) {
+            while (context.isRunning()) {
                 LOGGER.trace("Receiving LCR");
                 xsOut.receiveLCRCallback(handler, XStreamOut.DEFAULT_MODE);
             }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/antlr/listener/AlterTableParserListener.java
Patch:
@@ -125,7 +125,7 @@ public void enterDrop_column_clause(PlSqlParser.Drop_column_clauseContext ctx) {
         parser.runIfNotNull(() -> {
             List<PlSqlParser.Column_nameContext> columnNameContexts = ctx.column_name();
             columnEditors = new ArrayList<>(columnNameContexts.size());
-            for (PlSqlParser.Column_nameContext columnNameContext : columnNameContexts){
+            for (PlSqlParser.Column_nameContext columnNameContext : columnNameContexts) {
                 String columnName = getColumnName(columnNameContext);
                 tableEditor.removeColumn(columnName);
             }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/antlr/listener/ColumnDefinitionParserListener.java
Patch:
@@ -55,7 +55,7 @@ public void enterPrimary_key_clause(PlSqlParser.Primary_key_clauseContext ctx) {
     }
 
     // todo use dataTypeResolver instead
-    private void resolveColumnDataType(PlSqlParser.Column_definitionContext ctx){
+    private void resolveColumnDataType(PlSqlParser.Column_definitionContext ctx) {
             PlSqlParser.Precision_partContext precisionPart = ctx.datatype().precision_part();
 
             columnEditor.name(getColumnName(ctx.column_name()));

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/antlr/listener/CreateTableParserListener.java
Patch:
@@ -85,7 +85,7 @@ public void exitColumn_definition(PlSqlParser.Column_definitionContext ctx) {
 
     @Override
     public void exitOut_of_line_constraint(PlSqlParser.Out_of_line_constraintContext ctx) {
-        if(ctx.PRIMARY() != null) {
+        if (ctx.PRIMARY() != null) {
             List<String> pkColumnNames = ctx.column_name().stream()
                     .map(this::getColumnName)
                     .collect(Collectors.toList());

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleDdlParserTest.java
Patch:
@@ -35,7 +35,7 @@ public class OracleDdlParserTest {
     private Tables tables;
 
     @Before
-    public void setUp(){
+    public void setUp() {
         parser = new OracleDdlParser(true, null, null);
         tables = new Tables();
     }
@@ -165,7 +165,7 @@ private void testColumn(@NotNull Table table, @NotNull String name, boolean isOp
         assertThat(column.typeName()).isEqualTo(typeName);
         assertThat(column.length()).isEqualTo(length);
         Optional<Integer> oScale = column.scale();
-        if (oScale.isPresent()){
+        if (oScale.isPresent()) {
             assertThat(oScale.get()).isEqualTo(scale);
         }
         assertThat(column.hasDefaultValue()).isEqualTo(hasDefault);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorTask.java
Patch:
@@ -185,13 +185,13 @@ public ReplicationConnection createReplicationConnection(PostgresTaskContext tas
         final Metronome metronome = Metronome.parker(retryDelay, Clock.SYSTEM);
         short retryCount = 0;
         ReplicationConnection replicationConnection = null;
-        while(retryCount <= maxRetries) {
+        while (retryCount <= maxRetries) {
             try {
                 return taskContext.createReplicationConnection(shouldExport);
             }
             catch (SQLException ex) {
                 retryCount++;
-                if (retryCount > maxRetries){
+                if (retryCount > maxRetries) {
                     LOGGER.error("Too many errors connecting to server. All {} retries failed.", maxRetries);
                     throw new ConnectException(ex);
                 }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -280,7 +280,7 @@ protected static boolean publicationExists() {
     }
 
     protected static boolean publicationExists(String publicationName) {
-        if(decoderPlugin().equals(PostgresConnectorConfig.LogicalDecoder.PGOUTPUT)) {
+        if (decoderPlugin().equals(PostgresConnectorConfig.LogicalDecoder.PGOUTPUT)) {
             try(PostgresConnection connection = create()) {
                 String query = String.format("SELECT pubname FROM pg_catalog.pg_publication WHERE pubname = '%s'", publicationName);
                 try {

File: debezium-core/src/main/java/io/debezium/schema/FieldNameSelector.java
Patch:
@@ -64,7 +64,7 @@ public String fieldNameFor(Column column) {
         private String sanitizeColumnName(String columnName) {
             boolean changed = false;
             StringBuilder sanitizedNameBuilder = new StringBuilder(columnName.length() + 1);
-            for(int i = 0; i < columnName.length(); i++) {
+            for (int i = 0; i < columnName.length(); i++) {
                 char c = columnName.charAt(i);
                 if ( i == 0 && Character.isDigit(c)) {
                     sanitizedNameBuilder.append(NUMBER_PREFIX);

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Replicator.java
Patch:
@@ -400,7 +400,7 @@ private void delaySnapshotIfNeeded() throws InterruptedException {
         Threads.Timer timer = Threads.timer(Clock.SYSTEM, delay);
         Metronome metronome = Metronome.parker(ConfigurationDefaults.RETURN_CONTROL_INTERVAL, Clock.SYSTEM);
 
-        while(!timer.expired()) {
+        while (!timer.expired()) {
             if (!running.get()) {
                 throw new InterruptedException("Interrupted while awaiting initial snapshot delay");
             }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/RecordMakers.java
Patch:
@@ -183,7 +183,7 @@ public void regenerate() {
             return sourceOffset;
         }
         else {
-            for(Entry<String, ?> restartOffsetEntry : restartOffset.entrySet()){
+            for (Entry<String, ?> restartOffsetEntry : restartOffset.entrySet()){
                 sourceOffset.put(SourceInfo.RESTART_PREFIX + restartOffsetEntry.getKey(), restartOffsetEntry.getValue());
             }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SourceInfo.java
Patch:
@@ -274,7 +274,7 @@ private Map<String, Object> offsetUsingPosition(long rowsToSkip) {
         if (isSnapshotInEffect()) {
             map.put(SNAPSHOT_KEY, true);
         }
-        if(hasFilterInfo()) {
+        if (hasFilterInfo()) {
             map.put(DATABASE_WHITELIST_KEY, databaseWhitelist);
             map.put(DATABASE_BLACKLIST_KEY, databaseBlacklist);
             map.put(TABLE_WHITELIST_KEY, tableWhitelist);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/AbstractMySqlConnectorOutputTest.java
Patch:
@@ -147,7 +147,7 @@ protected Map<String, String> readSystemVariables(Configuration config) throws E
                         String masterUuid = uuids.iterator().next();
                         variables.put("master_uuid", masterUuid);
                     }
-                    else if(uuids.isEmpty()) {
+                    else if (uuids.isEmpty()) {
                         // do nothing ...
                     }
                     else {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -182,7 +182,7 @@ public static SnapshotMode parse(String value) {
                 return null;
             }
             value = value.trim();
-            for(SnapshotMode option: SnapshotMode.values()) {
+            for (SnapshotMode option: SnapshotMode.values()) {
                 if (option.getValue().equalsIgnoreCase(value)) {
                     return option;
                 }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSnapshotChangeEventSource.java
Patch:
@@ -227,7 +227,7 @@ protected Object getColumnValue(ResultSet rs, int columnIndex, Column column) th
                     return rs.getString(columnIndex);
                 default:
                     Object x = rs.getObject(columnIndex);
-                    if(x != null) {
+                    if (x != null) {
                         LOGGER.trace("rs getobject returns class: {}; rs getObject value is: {}", x.getClass(), x);
                     }
                     return x;

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -585,12 +585,12 @@ public ReplicationConnectionBuilder dropSlotOnClose(final boolean dropSlotOnClos
 
         @Override
         public ReplicationConnectionBuilder streamParams(final String slotStreamParams) {
-            if(slotStreamParams != null && !slotStreamParams.isEmpty()) {
+            if (slotStreamParams != null && !slotStreamParams.isEmpty()) {
                 this.slotStreamParams = new Properties();
                 String[] paramsWithValues = slotStreamParams.split(";");
-                for(String paramsWithValue : paramsWithValues) {
+                for (String paramsWithValue : paramsWithValues) {
                     String[] paramAndValue = paramsWithValue.split("=");
-                    if(paramAndValue.length == 2) {
+                    if (paramAndValue.length == 2) {
                         this.slotStreamParams.setProperty(paramAndValue[0], paramAndValue[1]);
                     }
                     else {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoReplicationMessage.java
Patch:
@@ -282,7 +282,7 @@ else if (datumMessage.hasDatumString()) {
                 if (type.getOid() == typeRegistry.geometryOid() || type.getOid() == typeRegistry.geographyOid() || type.getOid() == typeRegistry.citextOid() ) {
                     return datumMessage.getDatumBytes().toByteArray();
                 }
-                if(type.getOid() == typeRegistry.hstoreOid()) {
+                if (type.getOid() == typeRegistry.hstoreOid()) {
                     return datumMessage.getDatumBytes().toByteArray();
                 }
                 if (type.getOid() == typeRegistry.geometryArrayOid() ||

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -948,7 +948,7 @@ private void assertValue(Struct content) {
             Object actualValue = content.get(fieldName);
 
             // assert the value type; for List all implementation types (e.g. immutable ones) are acceptable
-            if(actualValue instanceof List) {
+            if (actualValue instanceof List) {
                 assertTrue("Incorrect value type for " + fieldName, value instanceof List);
                 final List<?> actualValueList = (List<?>) actualValue;
                 final List<?> valueList = (List<?>) value;

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SnapshotWithOverridesProducerIT.java
Patch:
@@ -94,7 +94,9 @@ private Map<String, List<SourceRecord>> recordsByTopic(final int expectedRecords
         for (int i = 0; i < expectedRecordsCount; i++) {
             final SourceRecord record = consumer.remove();
             recordsByTopic.putIfAbsent(record.topic(), new ArrayList<SourceRecord>());
-            recordsByTopic.compute(record.topic(), (k, v) -> { v.add(record); return v; });
+            recordsByTopic.compute(record.topic(), (k, v) -> {
+                v.add(record);
+                return v; });
         }
         return recordsByTopic;
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/connection/ReplicationConnectionIT.java
Patch:
@@ -344,7 +344,7 @@ private List<ReplicationMessage> expectedMessagesFromStream(ReplicationStream st
         Metronome metronome = Metronome.sleeper(Duration.ofMillis(50), Clock.SYSTEM);
         Future<?> result = executorService.submit(() -> {
             while (!Thread.interrupted()) {
-                for(;;) {
+                for (;;) {
                     List<ReplicationMessage> message = new ArrayList<>();
                     stream.read(x -> message.add(x));
                     if (message.isEmpty()) {

File: debezium-core/src/main/java/io/debezium/data/SchemaUtil.java
Patch:
@@ -187,7 +187,7 @@ else if (obj instanceof Struct) {
             else if (obj instanceof ByteBuffer) {
                 append((ByteBuffer) obj);
             }
-            else if(obj instanceof byte[]) {
+            else if (obj instanceof byte[]) {
                     append((byte[]) obj);
             }
             else if (obj instanceof Map<?, ?>) {

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcValueConverters.java
Patch:
@@ -210,7 +210,7 @@ public SchemaBuilder schemaBuilder(Column column) {
                 }
                 return org.apache.kafka.connect.data.Date.builder();
             case Types.TIME:
-                if(adaptiveTimeMicrosecondsPrecisionMode) {
+                if (adaptiveTimeMicrosecondsPrecisionMode) {
                     return MicroTime.builder();
                 }
                 if (adaptiveTimePrecisionMode) {
@@ -413,7 +413,7 @@ protected Object convertTimeWithZone(Column column, Field fieldDefn, Object data
     }
 
     protected Object convertTime(Column column, Field fieldDefn, Object data) {
-        if(adaptiveTimeMicrosecondsPrecisionMode) {
+        if (adaptiveTimeMicrosecondsPrecisionMode) {
             return convertTimeToMicrosPastMidnight(column, fieldDefn, data);
         }
         if (adaptiveTimePrecisionMode) {

File: debezium-core/src/main/java/io/debezium/pipeline/EventDispatcher.java
Patch:
@@ -166,7 +166,7 @@ public Optional<DataCollectionSchema> ignoreMissingSchema(T dataCollectionId, Ch
     }
 
     public void dispatchSchemaChangeEvent(T dataCollectionId, SchemaChangeEventEmitter schemaChangeEventEmitter) throws InterruptedException {
-        if(!filter.isIncluded(dataCollectionId)) {
+        if (!filter.isIncluded(dataCollectionId)) {
             LOGGER.trace("Filtering schema change event for {}", dataCollectionId);
             return;
         }
@@ -245,7 +245,7 @@ public void changeRecord(DataCollectionSchema dataCollectionSchema, Operation op
 
             LOGGER.trace( "Received change record for {} operation on key {}", operation, key);
 
-            if(bufferedEvent != null) {
+            if (bufferedEvent != null) {
                 queue.enqueue(bufferedEvent.get());
             }
 
@@ -262,7 +262,7 @@ public void changeRecord(DataCollectionSchema dataCollectionSchema, Operation op
 
         @Override
         public void completeSnapshot() throws InterruptedException {
-            if(bufferedEvent != null) {
+            if (bufferedEvent != null) {
                 // It is possible that the last snapshotted table was empty
                 // this way we ensure that the last event is always marked as last
                 // even if it originates form non-last table

File: debezium-core/src/main/java/io/debezium/relational/RelationalSnapshotChangeEventSource.java
Patch:
@@ -205,7 +205,7 @@ private void delaySnapshotIfNeeded(ChangeEventSourceContext context) throws Inte
         Timer timer = Threads.timer(Clock.SYSTEM, snapshotDelay);
         Metronome metronome = Metronome.parker(ConfigurationDefaults.RETURN_CONTROL_INTERVAL, Clock.SYSTEM);
 
-        while(!timer.expired()) {
+        while (!timer.expired()) {
             if (!context.isRunning()) {
                 throw new InterruptedException("Interrupted while awaiting initial snapshot delay");
             }
@@ -446,7 +446,7 @@ private Column[] getColumnsForResultSet(Table table, ResultSet rs) throws SQLExc
         ResultSetMetaData metaData = rs.getMetaData();
         Column[] columns = new Column[metaData.getColumnCount()];
 
-        for(int i = 0; i < columns.length; i++) {
+        for (int i = 0; i < columns.length; i++) {
             columns[i] = table.columnWithName(metaData.getColumnName(i + 1));
         }
 
@@ -471,7 +471,7 @@ private Statement readTableStatement() throws SQLException {
     protected abstract void complete(SnapshotContext snapshotContext);
 
     private void rollbackTransaction(Connection connection) {
-        if(connection != null) {
+        if (connection != null) {
             try {
                 connection.rollback();
             }

File: debezium-core/src/main/java/io/debezium/relational/TableIdParser.java
Patch:
@@ -29,7 +29,7 @@ public static List<String> parse(String identifier) {
 
         List<String> parts = new ArrayList<>();
 
-        while(stream.hasNext()) {
+        while (stream.hasNext()) {
             parts.add(stream.consume().replaceAll("''", "'").replaceAll("\"\"", "\"").replaceAll("``", "`"));
         }
 
@@ -52,7 +52,7 @@ public void tokenize(CharacterStream input, Tokens tokens) throws ParsingExcepti
 
             currentState.onEntry(parsingContext);
 
-            while(input.hasNext()) {
+            while (input.hasNext()) {
                 previousState = currentState;
                 currentState = currentState.handleCharacter(input.next(), parsingContext);
 
@@ -64,7 +64,7 @@ public void tokenize(CharacterStream input, Tokens tokens) throws ParsingExcepti
 
             currentState.onExit(parsingContext);
 
-            if(currentState != ParsingState.BEFORE_SEPARATOR && currentState != ParsingState.IN_IDENTIFIER) {
+            if (currentState != ParsingState.BEFORE_SEPARATOR && currentState != ParsingState.IN_IDENTIFIER) {
                 throw new IllegalArgumentException("Invalid identifier: " + identifier);
             }
         }

File: debezium-core/src/main/java/io/debezium/relational/Tables.java
Patch:
@@ -401,7 +401,7 @@ boolean isEmpty() {
         }
 
         public void putAll(TablesById tablesByTableId) {
-            if(tableIdCaseInsensitive) {
+            if (tableIdCaseInsensitive) {
                 tablesByTableId.values.entrySet()
                     .forEach(e -> put(e.getKey().toLowercase(), e.getValue()));
             }

File: debezium-core/src/main/java/io/debezium/relational/ddl/AbstractDdlParser.java
Patch:
@@ -390,7 +390,7 @@ else if (Character.isDigit(c)) {
                     if (foundDecimalPoint) {
                         ++scale;
                     }
-                    else{
+                    else {
                         ++precision;
                     }
                 }

File: debezium-core/src/main/java/io/debezium/relational/ddl/LegacyDdlParser.java
Patch:
@@ -47,7 +47,7 @@ protected static interface TokenSet {
 
         default void add(String firstToken, String... additionalTokens){
             add(firstToken);
-            for(String token: additionalTokens) {
+            for (String token: additionalTokens) {
                 add(token);
             }
         }
@@ -188,7 +188,7 @@ protected List<TableId> parseQualifiedTableNames(Marker start) {
         if (id != null) {
             ids.add(id);
         }
-        while(tokens.canConsume(',')){
+        while (tokens.canConsume(',')){
             id = parseQualifiedTableName(start);
             if (id != null) {
                 ids.add(id);

File: debezium-core/src/main/java/io/debezium/relational/history/KafkaDatabaseHistory.java
Patch:
@@ -283,7 +283,7 @@ private Long getEndOffsetOfDbHistoryTopic(Long previousEndOffset, KafkaConsumer<
 
         // The end offset should never change during recovery; doing this check here just as - a rather weak - attempt
         // to spot other connectors that share the same history topic accidentally
-        if(previousEndOffset != null && !previousEndOffset.equals(endOffset)) {
+        if (previousEndOffset != null && !previousEndOffset.equals(endOffset)) {
             throw new IllegalStateException("Detected changed end offset of database history topic (previous: "
                     + previousEndOffset + ", current: " + endOffset
                     + "). Make sure that the same history topic isn't shared by multiple connector instances."

File: debezium-core/src/main/java/io/debezium/schema/TopicSelector.java
Patch:
@@ -111,7 +111,7 @@ public String topicNameFor(I id, String prefix, String delimiter) {
             StringBuilder sanitizedNameBuilder = new StringBuilder(topicName.length());
             boolean changed = false;
 
-            for(int i = 0; i < topicName.length(); i++) {
+            for (int i = 0; i < topicName.length(); i++) {
                 char c = topicName.charAt(i);
                 if (isValidTopicNameCharacter(c)) {
                     sanitizedNameBuilder.append(c);

File: debezium-core/src/main/java/io/debezium/util/Joiner.java
Patch:
@@ -50,7 +50,7 @@ public String join(CharSequence firstValue, CharSequence... additionalValues) {
         if (firstValue != null) {
             joiner.add(firstValue);
         }
-        for(CharSequence value: additionalValues) {
+        for (CharSequence value: additionalValues) {
             if (value != null) {
                 joiner.add(value);
             }
@@ -76,7 +76,7 @@ public String join(Iterable<?> values, CharSequence nextValue, CharSequence... a
         if (nextValue != null) {
             joiner.add(nextValue);
         }
-        for(CharSequence value: additionalValues) {
+        for (CharSequence value: additionalValues) {
             if (value != null) {
                 joiner.add(value);
             }

File: debezium-core/src/main/java/io/debezium/util/Strings.java
Patch:
@@ -1060,7 +1060,7 @@ public static String[] split(String identifier) {
 
             List<String> parts = new ArrayList<>();
 
-            while(stream.hasNext()) {
+            while (stream.hasNext()) {
                 final String part = stream.consume();
                 if (part.length() == 0) {
                     continue;

File: debezium-core/src/test/java/io/debezium/data/SchemaAndValueField.java
Patch:
@@ -48,7 +48,7 @@ private void assertValue(Struct content) {
         Assertions.assertThat(actualValue).as(fieldName + " is not present in the actual content").isNotNull();
 
         // assert the value type; for List all implementation types (e.g. immutable ones) are acceptable
-        if(actualValue instanceof List) {
+        if (actualValue instanceof List) {
             Assertions.assertThat(value).as("Incorrect value type for " + fieldName).isInstanceOf(List.class);
             final List<?> actualValueList = (List<?>) actualValue;
             final List<?> valueList = (List<?>) value;

File: debezium-core/src/test/java/io/debezium/util/Testing.java
Patch:
@@ -62,11 +62,11 @@ public static void print(Object message) {
     }
 
     public static void print(int length, String leader, Object message){
-        if(message!=null&&Print.enabled){
+        if (message!=null&&Print.enabled){
             int len=leader.length();
             System.out.print(leader);
-            if(len<length){
-                for(int i=len; i!=length; ++i){
+            if (len<length){
+                for (int i=len; i!=length; ++i){
                     System.out.print(" ");
                 }
             }

File: debezium-ddl-parser/src/main/java/io/debezium/antlr/AntlrDdlParser.java
Patch:
@@ -344,7 +344,7 @@ public String withoutQuotes(ParserRuleContext ctx) {
     }
 
     private void throwParsingException(Collection<ParsingException> errors) {
-        if(errors.size() == 1) {
+        if (errors.size() == 1) {
             throw errors.iterator().next();
         }
         else {

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/AbstractOracleDatatypesTest.java
Patch:
@@ -150,8 +150,8 @@ public abstract class AbstractOracleDatatypesTest extends AbstractConnectorTest
             new SchemaAndValueField("VAL_TS_PRECISION2", Timestamp.builder().optional().build(), LocalDateTime.of(2018, 3, 27, 12, 34, 56).toEpochSecond(ZoneOffset.UTC) * 1_000 + 130),
             new SchemaAndValueField("VAL_TS_PRECISION4", MicroTimestamp.builder().optional().build(), LocalDateTime.of(2018, 3, 27, 12, 34, 56).toEpochSecond(ZoneOffset.UTC) * 1_000_000 + 125500),
             new SchemaAndValueField("VAL_TSTZ", ZonedTimestamp.builder().optional().build(), "2018-03-27T01:34:56.00789-11:00"),
-            new SchemaAndValueField("VAL_INT_YTM", MicroDuration.builder().optional().build(), -110451600_000_000.0),
-            new SchemaAndValueField("VAL_INT_DTS", MicroDuration.builder().optional().build(), -93784_560_000.0)
+            new SchemaAndValueField("VAL_INT_YTM", MicroDuration.builder().optional().build(), -110451600_000_000L),
+            new SchemaAndValueField("VAL_INT_DTS", MicroDuration.builder().optional().build(), -93784_560_000L)
 //            new SchemaAndValueField("VAL_TSLTZ", ZonedTimestamp.builder().optional().build(), "2018-03-27T01:34:56.00789-11:00")
     );
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresChangeRecordEmitter.java
Patch:
@@ -166,7 +166,7 @@ private Object[] columnValues(List<ReplicationMessage.Column> columns, TableId t
                     cachedOldToastedValues.put(columnName, value);
                 }
                 else {
-                    if (value == ToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE) {
+                    if (value == UnchangedToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE) {
                         final Object candidate = cachedOldToastedValues.get(columnName);
                         if (candidate != null) {
                             value = candidate;
@@ -181,7 +181,7 @@ private Object[] columnValues(List<ReplicationMessage.Column> columns, TableId t
                 int position = getPosition(columnName, table, values);
                 if (position != -1) {
                     final Object candidate = cachedOldToastedValues.get(columnName);
-                    values[position] = candidate != null ? candidate : ToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE;
+                    values[position] = candidate != null ? candidate : UnchangedToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE;
                 }
             }
         }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -793,7 +793,7 @@ protected int getTimePrecision(Column column) {
      */
     @Override
     protected Object convertBinary(Column column, Field fieldDefn, Object data) {
-        if (data == ToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE) {
+        if (data == UnchangedToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE) {
             return toastPlaceholderBinary;
     }
         if (data instanceof PgArray) {
@@ -813,7 +813,7 @@ protected Object convertBinary(Column column, Field fieldDefn, Object data) {
      */
     @Override
     protected Object convertString(Column column, Field fieldDefn, Object data) {
-        if (data == ToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE) {
+        if (data == UnchangedToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE) {
                 return toastPlaceholderString;
         }
         return super.convertString(column, fieldDefn, data);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgoutput/PgOutputMessageDecoder.java
Patch:
@@ -27,7 +27,7 @@
 
 import io.debezium.connector.postgresql.PostgresStreamingChangeEventSource.PgConnectionSupplier;
 import io.debezium.connector.postgresql.PostgresType;
-import io.debezium.connector.postgresql.ToastedReplicationMessageColumn;
+import io.debezium.connector.postgresql.UnchangedToastedReplicationMessageColumn;
 import io.debezium.connector.postgresql.TypeRegistry;
 import io.debezium.connector.postgresql.connection.AbstractMessageDecoder;
 import io.debezium.connector.postgresql.connection.AbstractReplicationMessageColumn;
@@ -541,7 +541,7 @@ public String toString() {
             }
             else if (type == 'u') {
                 columns.add(
-                        new ToastedReplicationMessageColumn(columnName, columnType, typeExpression, optional, true) {
+                        new UnchangedToastedReplicationMessageColumn(columnName, columnType, typeExpression, optional, true) {
                             @Override
                             public String toString() {
                                 return columnName + "(" + typeExpression + ") - Unchanged toasted column";

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoReplicationMessage.java
Patch:
@@ -29,7 +29,7 @@
 import io.debezium.connector.postgresql.PostgresStreamingChangeEventSource.PgConnectionSupplier;
 import io.debezium.connector.postgresql.PostgresType;
 import io.debezium.connector.postgresql.PostgresValueConverter;
-import io.debezium.connector.postgresql.ToastedReplicationMessageColumn;
+import io.debezium.connector.postgresql.UnchangedToastedReplicationMessageColumn;
 import io.debezium.connector.postgresql.TypeRegistry;
 import io.debezium.connector.postgresql.connection.AbstractReplicationMessageColumn;
 import io.debezium.connector.postgresql.connection.ReplicationMessage;
@@ -108,7 +108,7 @@ private List<ReplicationMessage.Column> transform(List<PgProto.DatumMessage> mes
                     final String columnName = Strings.unquoteIdentifierPart(datum.getColumnName());
                     final PostgresType type = typeRegistry.get((int) datum.getColumnType());
                     if (datum.hasDatumMissing()) {
-                        return new ToastedReplicationMessageColumn(columnName, type, typeInfo.map(PgProto.TypeInfo::getModifier).orElse(null), typeInfo.map(PgProto.TypeInfo::getValueOptional).orElse(Boolean.FALSE), hasTypeMetadata());
+                        return new UnchangedToastedReplicationMessageColumn(columnName, type, typeInfo.map(PgProto.TypeInfo::getModifier).orElse(null), typeInfo.map(PgProto.TypeInfo::getValueOptional).orElse(Boolean.FALSE), hasTypeMetadata());
                     }
                     return new AbstractReplicationMessageColumn(columnName, type, typeInfo.map(PgProto.TypeInfo::getModifier).orElse(null), typeInfo.map(PgProto.TypeInfo::getValueOptional).orElse(Boolean.FALSE), hasTypeMetadata()) {
 
@@ -145,7 +145,7 @@ public boolean isLastEventForLsn() {
      */
     public Object getValue(PgProto.DatumMessage datumMessage, PgConnectionSupplier connection, boolean includeUnknownDatatypes) {
         if (datumMessage.hasDatumMissing()) {
-            return ToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE;
+            return UnchangedToastedReplicationMessageColumn.UNCHANGED_TOAST_VALUE;
         }
 
         int columnType = (int) datumMessage.getColumnType();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -776,7 +776,7 @@ public static SchemaRefreshMode parse(String value) {
             .withDisplayName("Toasted value placeholder")
             .withType(Type.STRING)
             .withWidth(Width.MEDIUM)
-            .withDefault("__DEBEZIUM_TOASTED_VALUE__")
+            .withDefault("__debezium_unavailable_value")
             .withImportance(Importance.MEDIUM)
             .withDescription("Specify the constant that will be provided by Debezium to indicate that " +
                     "the original value is a toasted value not provided by the database." + 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/DecoderDifferences.java
Patch:
@@ -15,7 +15,7 @@
  *
  */
 public class DecoderDifferences {
-    static final String TOASTED_VALUE_PLACEHOLDER = "__DEBEZIUM_TOASTED_VALUE__";
+    static final String TOASTED_VALUE_PLACEHOLDER = "__debezium_unavailable_value";
 
     /**
      * wal2json plugin does not send events for updates on tables that does not define primary key.

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoUtil.java
Patch:
@@ -153,7 +153,7 @@ public static void onCollectionDocuments(MongoClient client, String dbName, Stri
                     try {
                         documentOperation.accept(cursor.next());
                     } catch (InterruptedException e) {
-                        Thread.interrupted();
+                        Thread.currentThread().interrupt();
                         break;
                     }
                 }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSetMonitorThread.java
Patch:
@@ -110,7 +110,7 @@ public ReplicaSets getReplicaSets(long timeout, TimeUnit unit) {
                 return replicaSets;
             }
         } catch (InterruptedException e) {
-            Thread.interrupted(); // but do nothing else
+            Thread.currentThread().interrupt(); // but do nothing else
         }
         return null;
     }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Replicator.java
Patch:
@@ -343,7 +343,7 @@ protected boolean performInitialSync() {
         try {
             latch.await();
         } catch (InterruptedException e) {
-            Thread.interrupted();
+            Thread.currentThread().interrupt();
             aborted.set(true);
         }
         this.copyThreads.shutdown();
@@ -574,7 +574,7 @@ protected boolean handleOplogEvent(ServerAddress primaryAddress, Document event)
                 try {
                     factory.recordEvent(event, clock.currentTimeInMillis());
                 } catch (InterruptedException e) {
-                    Thread.interrupted();
+                    Thread.currentThread().interrupt();
                     return false;
                 }
             }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -528,7 +528,7 @@ protected void handleEvent(Event event) {
             logger.info("Error processing binlog event, and propagating to Kafka Connect so it stops this connector. Future binlog events read before connector is shutdown will be ignored.");
         } catch (InterruptedException e) {
             // Most likely because this reader was stopped and our thread was interrupted ...
-            Thread.interrupted();
+            Thread.currentThread().interrupt();
             eventHandlers.clear();
             logger.info("Stopped processing binlog events due to thread interruption");
         }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -266,7 +266,7 @@ public synchronized void start(Configuration config) {
                 logger.error("Failed to start the connector (see other exception), but got this error while cleaning up", s);
             }
             if (e instanceof InterruptedException) {
-                Thread.interrupted();
+                Thread.currentThread().interrupt();
                 throw new ConnectException("Interrupted while starting the connector", e);
             }
             if (e instanceof ConnectException) {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SnapshotReader.java
Patch:
@@ -620,7 +620,7 @@ protected void execute() {
                                             metrics.rowsScanned(tableId, rowNum.get());
                                         }
                                     } catch (InterruptedException e) {
-                                        Thread.interrupted();
+                                        Thread.currentThread().interrupt();
                                         // We were not able to finish all rows in all tables ...
                                         logger.info("Step {}: Stopping the snapshot due to thread interruption", stepNum);
                                         interrupted.set(true);
@@ -654,7 +654,7 @@ protected void execute() {
                                         step, totalRowCount, capturedTableIds.size(), Strings.duration(stop - startScan));
                         }
                     } catch (InterruptedException e) {
-                        Thread.interrupted();
+                        Thread.currentThread().interrupt();
                         // We were not able to finish all rows in all tables ...
                         if (logger.isInfoEnabled()) {
                             logger.info("Step {}: aborting the snapshot after {} rows in {} of {} tables {}",

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/AbstractMySqlConnectorOutputTest.java
Patch:
@@ -93,7 +93,7 @@ protected static void waitForGtidSetsToMatch(Configuration master, Configuration
                     Thread.sleep(100);
                 }
             } catch (InterruptedException e) {
-                Thread.interrupted();
+                Thread.currentThread().interrupt();
             } finally {
                 latch.countDown();
             }
@@ -108,7 +108,7 @@ protected static void waitForGtidSetsToMatch(Configuration master, Configuration
             }
             Testing.print("Waited a total of " + sw.durations().statistics().getTotalAsString() + " for the replica to catch up to the master.");
         } catch (InterruptedException e) {
-            Thread.interrupted();
+            Thread.currentThread().interrupt();
         }
     }
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorTask.java
Patch:
@@ -195,7 +195,7 @@ private void cleanupResources() {
             }
         }
         catch (InterruptedException e) {
-            Thread.interrupted();
+            Thread.currentThread().interrupt();
             LOGGER.error("Interrupted while stopping coordinator", e);
             throw new ConnectException("Interrupted while stopping coordinator, failing the task");
         }
@@ -206,7 +206,7 @@ private void cleanupResources() {
             }
         }
         catch (InterruptedException e) {
-            Thread.interrupted();
+            Thread.currentThread().interrupt();
             LOGGER.error("Interrupted while stopping", e);
         }
 

File: debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java
Patch:
@@ -92,7 +92,7 @@ public synchronized <T extends CdcSourceTaskContext> void start(T taskContext, C
                 }
             }
             catch (InterruptedException e) {
-                Thread.interrupted();
+                Thread.currentThread().interrupt();
                 LOGGER.warn("Change event source executor was interrupted", e);
             }
             catch (Throwable e) {
@@ -117,7 +117,7 @@ public synchronized void stop() throws InterruptedException {
         running = false;
 
         executor.shutdown();
-        Thread.interrupted();
+        Thread.currentThread().interrupt();
         boolean isShutdown = executor.awaitTermination(SHUTDOWN_WAIT_TIMEOUT.toMillis(), TimeUnit.MILLISECONDS);
 
         if (!isShutdown) {

File: debezium-core/src/main/java/io/debezium/relational/history/KafkaDatabaseHistory.java
Patch:
@@ -199,7 +199,7 @@ protected void storeRecord(HistoryRecord record) throws DatabaseHistoryException
             }
         } catch( InterruptedException e) {
             logger.trace("Interrupted before record was written into database history: {}", record);
-            Thread.interrupted();
+            Thread.currentThread().interrupt();
             throw new DatabaseHistoryException(e);
         } catch (ExecutionException e) {
             throw new DatabaseHistoryException(e);

File: debezium-core/src/main/java/io/debezium/util/DelayStrategy.java
Patch:
@@ -57,7 +57,7 @@ public static DelayStrategy constant(long delayInMilliseconds) {
             try {
                 Thread.sleep(delayInMilliseconds);
             } catch (InterruptedException e) {
-                Thread.interrupted();
+                Thread.currentThread().interrupt();
             }
             return true;
         };
@@ -89,7 +89,7 @@ public boolean sleepWhen(boolean criteria) {
                 try {
                     Thread.sleep(misses * delayInMilliseconds);
                 } catch (InterruptedException e) {
-                    Thread.interrupted();
+                    Thread.currentThread().interrupt();
                 }
                 return true;
             }
@@ -148,7 +148,7 @@ public boolean sleepWhen(boolean criteria) {
                 try {
                     Thread.sleep(previousDelay);
                 } catch (InterruptedException e) {
-                    Thread.interrupted();
+                    Thread.currentThread().interrupt();
                 }
                 return true;
             }

File: debezium-core/src/main/java/io/debezium/util/Threads.java
Patch:
@@ -222,7 +222,7 @@ public static Thread timeout(String threadName,
                     Thread.sleep(sleepTimeInMillis);
                 } catch (InterruptedException e) {
                     // awoke from sleep
-                    Thread.interrupted();
+                    Thread.currentThread().interrupt();
                     return;
                 }
             }

File: debezium-core/src/test/java/io/debezium/kafka/ZookeeperServer.java
Patch:
@@ -85,7 +85,7 @@ public synchronized ZookeeperServer startup() throws IOException {
             return this;
         } catch (InterruptedException e) {
             factory = null;
-            Thread.interrupted();
+            Thread.currentThread().interrupt();
             throw new IOException(e);
         }
     }

File: debezium-embedded/src/test/java/io/debezium/embedded/AbstractConnectorTest.java
Patch:
@@ -148,7 +148,7 @@ public void stopConnector(BooleanConsumer callback) {
                     engine.await(60, TimeUnit.SECONDS);
                 } catch (InterruptedException e) {
                     logger.warn("Engine has not stopped on time");
-                    Thread.interrupted();
+                    Thread.currentThread().interrupt();
                 }
             }
             if (executor != null) {
@@ -160,7 +160,7 @@ public void stopConnector(BooleanConsumer callback) {
                     }
                 } catch (InterruptedException e) {
                     logger.warn("Executor has not stopped on time");
-                    Thread.interrupted();
+                    Thread.currentThread().interrupt();
                 }
             }
             if (engine != null && engine.isRunning()) {
@@ -170,7 +170,7 @@ public void stopConnector(BooleanConsumer callback) {
                     }
                 } catch (InterruptedException e) {
                     logger.warn("Connector has not stopped on time");
-                    Thread.interrupted();
+                    Thread.currentThread().interrupt();
                 }
             }
             if (callback != null){

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/CassandraConnectorConfig.java
Patch:
@@ -8,12 +8,9 @@
 import java.time.Duration;
 import java.util.Arrays;
 import java.util.Map;
-import java.util.HashMap;
 import java.util.Optional;
 import java.util.Properties;
 import java.util.stream.Collectors;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
 
 import io.debezium.connector.cassandra.exceptions.CassandraConnectorConfigException;
 import com.datastax.driver.core.ConsistencyLevel;

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/Record.java
Patch:
@@ -98,7 +98,7 @@ public static Schema keySchema(String connectorName, TableMetadata tm) {
         if (tm == null) {
             return null;
         }
-        SchemaBuilder schemaBuilder = SchemaBuilder.struct().name(NAMESPACE+"."+getKeyName(connectorName, tm));
+        SchemaBuilder schemaBuilder = SchemaBuilder.struct().name(NAMESPACE + "." + getKeyName(connectorName, tm));
         for (ColumnMetadata cm : tm.getPrimaryKey()) {
             AbstractType<?> convertedType = CassandraTypeConverter.convert(cm.getType());
             Schema colSchema = CassandraTypeDeserializer.getSchemaBuilder(convertedType).build();
@@ -113,7 +113,7 @@ public static Schema valueSchema(String connectorName, TableMetadata tm) {
         if (tm == null) {
             return null;
         }
-        return SchemaBuilder.struct().name(NAMESPACE+"."+getValueName(connectorName, tm))
+        return SchemaBuilder.struct().name(NAMESPACE + "." + getValueName(connectorName, tm))
                 .field(TIMESTAMP, Schema.INT64_SCHEMA)
                 .field(OPERATION, Schema.STRING_SCHEMA)
                 .field(SOURCE, SourceInfo.SOURCE_SCHEMA)

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/CassandraTypeDeserializer.java
Patch:
@@ -43,7 +43,6 @@
 import org.apache.cassandra.db.marshal.UTF8Type;
 import org.apache.cassandra.db.marshal.UUIDType;
 import org.apache.cassandra.db.marshal.UserType;
-import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
 
 import java.nio.ByteBuffer;

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/type/deserializer/UserTypeDeserializer.java
Patch:
@@ -39,7 +39,7 @@ public Object deserialize(AbstractType<?> abstractType, ByteBuffer bb) {
     @Override
     public SchemaBuilder getSchemaBuilder(AbstractType<?> abstractType) {
         UserType userType = (UserType) abstractType;
-        SchemaBuilder schemaBuilder = SchemaBuilder.struct().name(userType.keyspace+"."+userType.getNameAsString());
+        SchemaBuilder schemaBuilder = SchemaBuilder.struct().name(userType.keyspace + "." + userType.getNameAsString());
         List<org.apache.cassandra.cql3.FieldIdentifier> fieldIdentifiers = userType.fieldNames();
         List<AbstractType<?>> fieldTypes = userType.fieldTypes();
         for (int i = 0; i < fieldIdentifiers.size(); i++) {

File: debezium-connector-cassandra/src/test/java/io/debezium/connector/cassandra/transforms/CassandraTypeDeserializerTest.java
Patch:
@@ -8,7 +8,6 @@
 import com.datastax.driver.core.DataType;
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.data.Schema;
-import org.apache.kafka.connect.data.SchemaBuilder;
 import org.apache.kafka.connect.data.Values;
 import org.apache.cassandra.cql3.Duration;
 import org.apache.cassandra.cql3.FieldIdentifier;

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/type/deserializer/InetAddressDeserializer.java
Patch:
@@ -5,7 +5,7 @@
  */
 package io.debezium.connector.cassandra.transforms.type.deserializer;
 
-import io.debezium.connector.cassandra.transforms.CassandraTypeToAvroSchemaMapper;
+import io.debezium.connector.cassandra.transforms.CassandraTypeKafkaSchemaBuilders;
 import org.apache.cassandra.db.marshal.AbstractType;
 
 import java.net.InetAddress;
@@ -14,7 +14,7 @@
 public class InetAddressDeserializer extends BasicTypeDeserializer {
 
     public InetAddressDeserializer() {
-        super(CassandraTypeToAvroSchemaMapper.STRING_TYPE);
+        super(CassandraTypeKafkaSchemaBuilders.STRING_TYPE);
     }
 
     @Override

File: debezium-connector-cassandra/src/main/java/io/debezium/connector/cassandra/transforms/type/deserializer/TypeDeserializer.java
Patch:
@@ -5,8 +5,8 @@
  */
 package io.debezium.connector.cassandra.transforms.type.deserializer;
 
-import org.apache.avro.Schema;
 import org.apache.cassandra.db.marshal.AbstractType;
+import org.apache.kafka.connect.data.SchemaBuilder;
 
 import java.nio.ByteBuffer;
 
@@ -16,5 +16,5 @@ public Object deserialize(AbstractType<?> abstractType, ByteBuffer bb) {
         return abstractType.getSerializer().deserialize(bb);
     }
 
-    public abstract Schema getSchema(AbstractType<?> abstractType);
+    public abstract SchemaBuilder getSchemaBuilder(AbstractType<?> abstractType);
 }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -484,7 +484,7 @@ public static SchemaRefreshMode parse(String value) {
                                                       .withImportance(Importance.MEDIUM)
                                                       .withDefault(ReplicationConnection.Builder.DEFAULT_PUBLICATION_NAME)
                                                       .withDescription("The name of the Postgres 10+ publication used for streaming changes from a plugin." +
-                                                                       "Defaults to 'dbz_publication'");
+                                                                       "Defaults to '" + ReplicationConnection.Builder.DEFAULT_PUBLICATION_NAME + "'");
 
     public static final Field STREAM_PARAMS = Field.create("slot.stream.params")
                                                         .withDisplayName("Optional parameters to pass to the logical decoder when the stream is started.")

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -103,7 +103,7 @@ private PostgresReplicationConnection(Configuration config,
         this.dropSlotOnClose = dropSlotOnClose;
         this.statusUpdateInterval = statusUpdateInterval;
         this.exportSnapshot = exportSnapshot;
-        this.messageDecoder = plugin.messageDecoder(new MessageDecoderConfig(config, schema));
+        this.messageDecoder = plugin.messageDecoder(new MessageDecoderConfig(config, schema, publicationName));
         this.typeRegistry = typeRegistry;
         this.streamParams = streamParams;
         this.slotCreationInfo = null;
@@ -134,7 +134,7 @@ protected void initPublication() {
                             //      For situations where no publication exists, we likely cannot create it for all tables.
                             //      This is because postgres requires certain super user permissions to use "ALL TABLES".
                             //      We should restrict this to the configured tables here.
-                            stmt.execute("CREATE PUBLICATION dbz_publication FOR ALL TABLES;");
+                            stmt.execute(String.format("CREATE PUBLICATION %s FOR ALL TABLES;", publicationName));
                         }
                         else {
                             LOGGER.trace(

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgoutput/PgOutputMessageDecoder.java
Patch:
@@ -175,7 +175,7 @@ public void processMessage(ByteBuffer buffer, ReplicationMessageProcessor proces
     @Override
     public ChainedLogicalStreamBuilder optionsWithMetadata(ChainedLogicalStreamBuilder builder) {
         return builder.withSlotOption("proto_version", 1)
-                .withSlotOption("publication_names", "dbz_publication");
+                .withSlotOption("publication_names", config.getPublicationName());
     }
 
     @Override

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -1121,6 +1121,7 @@ public void testCustomPublicationNameUsed() throws Exception {
         waitForAvailableRecords(100, TimeUnit.MILLISECONDS);
 
         stopConnector(value -> assertThat(logInterceptor.containsMessage("Creating new publication 'cdc' for plugin 'PGOUTPUT'")).isTrue());
+        assertTrue(TestHelper.publicationExists("cdc"));
     }
 
     private CompletableFuture<Void> batchInsertRecords(long recordsCount, int batchSize) {

File: debezium-core/src/test/java/io/debezium/relational/TableSchemaBuilderTest.java
Patch:
@@ -12,7 +12,6 @@
 import java.nio.ByteBuffer;
 import java.sql.Types;
 import java.util.Collections;
-import java.util.HashMap;
 
 import org.apache.kafka.connect.data.Decimal;
 import org.apache.kafka.connect.data.Schema;

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -310,6 +310,7 @@ public void shouldConsumeMessagesFromSnapshot() throws Exception {
         start(PostgresConnector.class, configBuilder.build());
         assertConnectorIsRunning();
 
+        waitForSnapshotToBeCompleted();
         SourceRecords records = consumeRecordsByTopic(recordCount);
         Assertions.assertThat(records.recordsForTopic("test_server.s1.a")).hasSize(recordCount);
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/OutboxEventRouterIT.java
Patch:
@@ -94,6 +94,9 @@ else if (payloadJson.isEmpty()) {
 
     @Before
     public void beforeEach() throws InterruptedException {
+        TestHelper.dropDefaultReplicationSlot();
+        TestHelper.dropPublication();
+
         outboxEventRouter = new EventRouter<>();
         outboxEventRouter.configure(Collections.emptyMap());
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/OutboxEventRouterIT.java
Patch:
@@ -461,15 +461,12 @@ private void startConnectorWithInitialSnapshotRecord() throws Exception {
         Configuration.Builder configBuilder = getConfigurationBuilder(SnapshotMode.INITIAL);
         start(PostgresConnector.class, configBuilder.build());
         assertConnectorIsRunning();
-        waitForSnapshotToBeCompleted("postgres", TestHelper.TEST_SERVER);
 
         SourceRecords snapshotRecords = consumeRecordsByTopic(1);
         assertThat(snapshotRecords.allRecordsInOrder().size()).isEqualTo(1);
 
         List<SourceRecord> recordsFromOutbox = snapshotRecords.recordsForTopic(topicName("outboxsmtit.outbox"));
         assertThat(recordsFromOutbox.size()).isEqualTo(1);
-
-        waitForStreamingRunning("postgres", TestHelper.TEST_SERVER);
     }
 
     private void startConnectorWithNoSnapshot() throws InterruptedException {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/OutboxEventRouterIT.java
Patch:
@@ -461,12 +461,15 @@ private void startConnectorWithInitialSnapshotRecord() throws Exception {
         Configuration.Builder configBuilder = getConfigurationBuilder(SnapshotMode.INITIAL);
         start(PostgresConnector.class, configBuilder.build());
         assertConnectorIsRunning();
+        waitForSnapshotToBeCompleted("postgres", TestHelper.TEST_SERVER);
 
         SourceRecords snapshotRecords = consumeRecordsByTopic(1);
         assertThat(snapshotRecords.allRecordsInOrder().size()).isEqualTo(1);
 
         List<SourceRecord> recordsFromOutbox = snapshotRecords.recordsForTopic(topicName("outboxsmtit.outbox"));
         assertThat(recordsFromOutbox.size()).isEqualTo(1);
+
+        waitForStreamingRunning("postgres", TestHelper.TEST_SERVER);
     }
 
     private void startConnectorWithNoSnapshot() throws InterruptedException {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -772,7 +772,7 @@ public void shouldRegularlyFlushLsn() throws InterruptedException, SQLException
                                          .build();
         start(PostgresConnector.class, config);
         assertConnectorIsRunning();
-        waitForAvailableRecords(100, TimeUnit.MILLISECONDS);
+        waitForStreamingRunning("postgres", TestHelper.TEST_SERVER);
         // there shouldn't be any snapshot records
         assertNoRecordsToConsume();
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PublicGeometryIT.java
Patch:
@@ -131,6 +131,6 @@ private SourceRecord assertRecordInserted(String expectedTopicName, String pkCol
 
     private void executeAndWait(String statements) throws Exception {
         TestHelper.execute(statements);
-        consumer.await(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS);
+        consumer.await(TestHelper.waitTimeForRecords() * 30, TimeUnit.SECONDS);
     }
 }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsSnapshotProducerIT.java
Patch:
@@ -120,6 +120,7 @@ public void shouldGenerateSnapshotAndContinueStreaming() throws Exception {
         buildWithStreamProducer(TestHelper.defaultConfig());
 
         TestConsumer consumer = testConsumer(2, "s1", "s2");
+        waitForSnapshotToBeCompleted();
 
         // first make sure we get the initial records from both schemas...
         consumer.await(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS);
@@ -151,6 +152,7 @@ public void shouldGenerateSnapshotAndContinueStreaming() throws Exception {
         // start a new producer back up, take a new snapshot (we expect all the records to be read back)
         int expectedRecordsCount = 6;
         buildWithStreamProducer(TestHelper.defaultConfig());
+        waitForSnapshotToBeCompleted();
 
         consumer = testConsumer(expectedRecordsCount, "s1", "s2");
         consumer.await(TestHelper.waitTimeForRecords() * 30, TimeUnit.SECONDS);
@@ -170,7 +172,7 @@ public void shouldGenerateSnapshotAndContinueStreaming() throws Exception {
         TestHelper.execute(insertStmt);
         consumer.expects(2);
 
-        consumer.await(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS);
+        consumer.await(TestHelper.waitTimeForRecords() * 30, TimeUnit.SECONDS);
         first = consumer.remove();
         VerifyRecord.isValidInsert(first, PK_FIELD, 4);
         assertRecordOffsetAndSnapshotSource(first, false, false);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -1503,6 +1503,6 @@ private SourceRecord assertRecordInserted(String expectedTopicName, String pkCol
 
     private void executeAndWait(String statements) throws Exception {
         TestHelper.execute(statements);
-        consumer.await(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS);
+        consumer.await(TestHelper.waitTimeForRecords() * 30, TimeUnit.SECONDS);
     }
 }

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/ExtractNewDocumentStateTest.java
Patch:
@@ -94,6 +94,7 @@ public void closeSmt() {
     }
 
     @Test
+    @FixFor("DBZ-1442")
     public void shouldAddSourceFields() throws InterruptedException {
         CollectionId collectionId = new CollectionId("rs0", "dbA", "c1");
         BsonTimestamp ts = new BsonTimestamp(1000, 1);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java
Patch:
@@ -67,7 +67,7 @@ public PostgresStreamingChangeEventSource(PostgresConnectorConfig connectorConfi
     @Override
     public void execute(ChangeEventSourceContext context) throws InterruptedException {
         if (!snapshotter.shouldStream()) {
-            LOGGER.info("Streaming is not enabled in currect configuration");
+            LOGGER.info("Streaming is not enabled in correct configuration");
             return;
         }
 

File: debezium-connector-cassandra/src/test/java/io/debezium/connector/cassandra/EmbeddedCassandraConnectorTestBase.java
Patch:
@@ -171,7 +171,7 @@ protected static Properties generateDefaultConfigMap() throws IOException {
         props.put(CassandraConnectorConfig.CASSANDRA_CONFIG, TEST_CASSANDRA_YAML_CONFIG);
         props.put(CassandraConnectorConfig.KAFKA_TOPIC_PREFIX, TEST_KAFKA_TOPIC_PREFIX);
         props.put(CassandraConnectorConfig.CASSANDRA_HOSTS, TEST_CASSANDRA_HOSTS);
-        props.put(CassandraConnectorConfig.CASSANDRA_PORT, TEST_CASSANDRA_PORT);
+        props.put(CassandraConnectorConfig.CASSANDRA_PORT, String.valueOf(TEST_CASSANDRA_PORT));
         props.put(CassandraConnectorConfig.OFFSET_BACKING_STORE_DIR, Files.createTempDirectory("offset").toString());
         props.put(CassandraConnectorConfig.KAFKA_PRODUCER_CONFIG_PREFIX + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, TEST_KAFKA_SERVERS);
         props.put(CassandraConnectorConfig.KAFKA_PRODUCER_CONFIG_PREFIX + AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, TEST_SCHEMA_REGISTRY_URL);

File: debezium-connector-cassandra/src/test/java/io/debezium/connector/cassandra/SnapshotProcessorTest.java
Patch:
@@ -111,7 +111,7 @@ public void testSnapshotEmptyTable() throws Exception {
     public void testSnapshotModeAlways() throws Exception {
         Map<String, Object> configs = new HashMap<>();
         configs.put(CassandraConnectorConfig.SNAPSHOT_MODE, "always");
-        configs.put(CassandraConnectorConfig.SNAPSHOT_POLL_INTERVAL_MS, 0);
+        configs.put(CassandraConnectorConfig.SNAPSHOT_POLL_INTERVAL_MS, "0");
         CassandraConnectorContext context = generateTaskContext(configs);
         SnapshotProcessor snapshotProcessorSpy = Mockito.spy(new SnapshotProcessor(context));
         doNothing().when(snapshotProcessorSpy).snapshot();
@@ -128,7 +128,7 @@ public void testSnapshotModeAlways() throws Exception {
     public void testSnapshotModeInitial() throws Exception {
         Map<String, Object> configs = new HashMap<>();
         configs.put(CassandraConnectorConfig.SNAPSHOT_MODE, "initial");
-        configs.put(CassandraConnectorConfig.SNAPSHOT_POLL_INTERVAL_MS, 0);
+        configs.put(CassandraConnectorConfig.SNAPSHOT_POLL_INTERVAL_MS, "0");
         CassandraConnectorContext context = generateTaskContext(configs);
         SnapshotProcessor snapshotProcessorSpy = Mockito.spy(new SnapshotProcessor(context));
         doNothing().when(snapshotProcessorSpy).snapshot();
@@ -145,7 +145,7 @@ public void testSnapshotModeInitial() throws Exception {
     public void testSnapshotModeNever() throws Exception {
         Map<String, Object> configs = new HashMap<>();
         configs.put(CassandraConnectorConfig.SNAPSHOT_MODE, "never");
-        configs.put(CassandraConnectorConfig.SNAPSHOT_POLL_INTERVAL_MS, 0);
+        configs.put(CassandraConnectorConfig.SNAPSHOT_POLL_INTERVAL_MS, "0");
         CassandraConnectorContext context = generateTaskContext(configs);
         SnapshotProcessor snapshotProcessorSpy = Mockito.spy(new SnapshotProcessor(context));
         doNothing().when(snapshotProcessorSpy).snapshot();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ReplicationMessageColumnValueResolver.java
Patch:
@@ -102,11 +102,11 @@ public static Object resolveValue(String columnName, PostgresType type, String f
 
             case "timestamp with time zone":
             case "timestamptz":
-                return value.asTimestampWithTimeZone();
+                return value.asOffsetDateTime();
 
             case "timestamp":
             case "timestamp without time zone":
-                return value.asTimestampWithoutTimeZone();
+                return value.asOffsetDateTimeWithoutTimeZone();
 
             case "time":
                 return value.asString();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/NonStreamingWal2JsonMessageDecoder.java
Patch:
@@ -25,7 +25,6 @@
 import io.debezium.document.Document;
 import io.debezium.document.DocumentReader;
 import io.debezium.document.Value;
-import io.debezium.time.Conversions;
 
 /**
  * A non-streaming version of JSON deserialization of a message sent by
@@ -55,7 +54,7 @@ public void processMessage(ByteBuffer buffer, ReplicationMessageProcessor proces
             final Document message = DocumentReader.floatNumbersAsTextReader().read(content);
             final long txId = message.getLong("xid");
             final String timestamp = message.getString("timestamp");
-            final Instant commitTime = Conversions.toInstant(dateTime.systemTimestamp(timestamp));
+            final Instant commitTime = dateTime.systemTimestampToOffsetDateTime(timestamp).toInstant();
             final Array changes = message.getArray("change");
 
             // WAL2JSON may send empty changes that still have a txid. These events are from things like vacuum,

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/StreamingWal2JsonMessageDecoder.java
Patch:
@@ -21,7 +21,6 @@
 import io.debezium.connector.postgresql.connection.ReplicationStream.ReplicationMessageProcessor;
 import io.debezium.document.Document;
 import io.debezium.document.DocumentReader;
-import io.debezium.time.Conversions;
 
 /**
  * <p>JSON deserialization of a message sent by
@@ -146,7 +145,7 @@ public void processMessage(ByteBuffer buffer, ReplicationMessageProcessor proces
                         // Correct initial chunk
                         txId = message.getLong("xid");
                         final String timestamp = message.getString("timestamp");
-                        commitTime = Conversions.toInstant(dateTime.systemTimestamp(timestamp));
+                        commitTime = dateTime.systemTimestampToOffsetDateTime(timestamp).toInstant();
                         messageInProgress = true;
                         currentChunk = null;
                     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -993,7 +993,7 @@ public void shouldReceiveHeartbeatAlsoWhenChangingNonWhitelistedTable() throws E
                            "INSERT INTO s1.b (bb) VALUES (22);";
 
         // streaming from database is non-blocking so we should receive many heartbeats
-        final int expectedAtMostStartHeartbeats = 3;
+        final int expectedAtMostStartHeartbeats = 10;
         final int expectedHeartbeats = 5;
         // heartbeat for unfiltered table, data change, heartbeats
         consumer = testConsumer(expectedAtMostStartHeartbeats + 1 + expectedHeartbeats);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlSchema.java
Patch:
@@ -137,8 +137,7 @@ protected boolean isPositionAtOrBefore(Document recorded, Document desired) {
     private static MySqlValueConverters getValueConverters(MySqlConnectorConfig configuration) {
         // Use MySQL-specific converters and schemas for values ...
 
-        String timePrecisionModeStr = configuration.getConfig().getString(MySqlConnectorConfig.TIME_PRECISION_MODE);
-        TemporalPrecisionMode timePrecisionMode = TemporalPrecisionMode.parse(timePrecisionModeStr);
+        TemporalPrecisionMode timePrecisionMode = configuration.getTemporalPrecisionMode();
 
         DecimalMode decimalMode = configuration.getDecimalMode();
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerDatabaseSchema.java
Patch:
@@ -31,7 +31,7 @@ public class SqlServerDatabaseSchema extends HistorizedRelationalDatabaseSchema
     public SqlServerDatabaseSchema(SqlServerConnectorConfig connectorConfig, SchemaNameAdjuster schemaNameAdjuster, TopicSelector<TableId> topicSelector, SqlServerConnection connection) {
         super(connectorConfig, topicSelector, connectorConfig.getTableFilters().dataCollectionFilter(), connectorConfig.getColumnFilter(),
                 new TableSchemaBuilder(
-                        new SqlServerValueConverters(connectorConfig.getDecimalMode()),
+                        new SqlServerValueConverters(connectorConfig.getDecimalMode(), connectorConfig.getTemporalPrecisionMode()),
                         schemaNameAdjuster,
                         connectorConfig.getSourceInfoStructMaker().schema()
                 ),

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java
Patch:
@@ -122,8 +122,8 @@ public void execute(ChangeEventSourceContext context) throws InterruptedExceptio
                 })) {
                     if (offsetContext.hasCompletelyProcessedPosition()) {
                         dispatcher.dispatchHeartbeatEvent(offsetContext);
-                        pauseNoMessage.pause();
                     }
+                    pauseNoMessage.pause();
                 }
             }
         }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerOffsetContext.java
Patch:
@@ -15,6 +15,7 @@
 import io.debezium.connector.SnapshotRecord;
 import io.debezium.pipeline.spi.OffsetContext;
 import io.debezium.relational.TableId;
+import io.debezium.schema.DataCollectionId;
 import io.debezium.util.Collect;
 
 public class SqlServerOffsetContext implements OffsetContext {
@@ -180,8 +181,8 @@ public void markLastSnapshotRecord() {
     }
 
     @Override
-    public void event(TableId tableId, Instant timestamp) {
+    public void event(DataCollectionId tableId, Instant timestamp) {
         sourceInfo.setSourceTime(timestamp);
-        sourceInfo.setTableId(tableId);
+        sourceInfo.setTableId((TableId) tableId);
     }
 }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoMessageDecoder.java
Patch:
@@ -38,7 +38,7 @@ public void processMessage(final ByteBuffer buffer, ReplicationMessageProcessor
         try {
             if (!buffer.hasArray()) {
                 throw new IllegalStateException(
-                        "Invalid buffer received from PG server during streaming replication");
+                        "Invalid buffer received from Postgres server during streaming replication");
             }
             final byte[] source = buffer.array();
             final byte[] content = Arrays.copyOfRange(source, buffer.arrayOffset(), source.length);

File: debezium-core/src/main/java/io/debezium/relational/RelationalSnapshotChangeEventSource.java
Patch:
@@ -11,7 +11,6 @@
 import java.sql.SQLException;
 import java.sql.Statement;
 import java.time.Duration;
-import java.time.Instant;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedHashSet;
@@ -412,7 +411,7 @@ private Timer getTableScanLogTimer() {
      * Returns a {@link ChangeRecordEmitter} producing the change records for the given table row.
      */
     protected ChangeRecordEmitter getChangeRecordEmitter(SnapshotContext snapshotContext, TableId tableId, Object[] row) {
-        snapshotContext.offset.event(tableId, Instant.ofEpochMilli(getClock().currentTimeInMillis()));
+        snapshotContext.offset.event(tableId, getClock().currentTime());
         return new SnapshotChangeRecordEmitter(snapshotContext.offset, row, getClock());
     }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java
Patch:
@@ -74,7 +74,7 @@ public void execute(ChangeEventSourceContext context) throws InterruptedExceptio
         try {
             if (offsetContext.hasLastKnownPosition()) {
                 // start streaming from the last recorded position in the offset
-                Long lsn = offsetContext.lsn();
+                final Long lsn = offsetContext.lsn();
                 if (LOGGER.isDebugEnabled()) {
                     LOGGER.debug("retrieved latest position from stored offset '{}'", ReplicationConnection.format(lsn));
                 }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -755,8 +755,9 @@ public void shouldNotSendEmptyOffset() throws InterruptedException, SQLException
         // Generate empty logical decoding message
         TestHelper.execute(statement);
         waitForAvailableRecords(1000, TimeUnit.MILLISECONDS);
-        // there shouldn't be any snapshot records
-        assertNoRecordsToConsume();
+
+        SourceRecord record = consumeRecord();
+        assertThat(record == null || !record.sourceOffset().isEmpty());
     }
 
     @Test

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresStreamingChangeEventSource.java
Patch:
@@ -96,6 +96,7 @@ public void execute(ChangeEventSourceContext context) throws InterruptedExceptio
                     if (message == null) {
                         LOGGER.trace("Received empty message");
                         lastCompletelyProcessedLsn = lsn;
+                        dispatcher.dispatchHeartbeatEvent(offsetContext);
                         return;
                     }
                     if (message.isLastEventForLsn()) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/NonStreamingWal2JsonMessageDecoder.java
Patch:
@@ -51,8 +51,8 @@ public void processMessage(ByteBuffer buffer, ReplicationMessageProcessor proces
             }
             final byte[] source = buffer.array();
             final byte[] content = Arrays.copyOfRange(source, buffer.arrayOffset(), source.length);
+            LOGGER.trace("Message arrived for decoding {}", new String(content));
             final Document message = DocumentReader.floatNumbersAsTextReader().read(content);
-            LOGGER.debug("Message arrived for decoding {}", message);
             final long txId = message.getLong("xid");
             final String timestamp = message.getString("timestamp");
             final Instant commitTime = Conversions.toInstant(dateTime.systemTimestamp(timestamp));

File: debezium-core/src/main/java/io/debezium/relational/RelationalSnapshotChangeEventSource.java
Patch:
@@ -164,7 +164,7 @@ public SnapshotResult execute(ChangeEventSourceContext context) throws Interrupt
                 ctx.offset.postSnapshotCompletion();
             }
 
-            dispatcher.dispatchHeartbeatEvent(ctx.offset);
+            dispatcher.alwaysDispatchHeartbeatEvent(ctx.offset);
             snapshotProgressListener.snapshotCompleted();
             return SnapshotResult.completed(ctx.offset);
         }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -100,7 +100,7 @@ private void startConnector(Function<Configuration.Builder, Configuration.Builde
         start(PostgresConnector.class, new PostgresConnectorConfig(customConfig.apply(TestHelper.defaultConfig()
                 .with(PostgresConnectorConfig.INCLUDE_UNKNOWN_DATATYPES, false)
                 .with(PostgresConnectorConfig.SCHEMA_BLACKLIST, "postgis")
-                .with(PostgresConnectorConfig.SNAPSHOT_MODE, SnapshotMode.INITIAL))
+                .with(PostgresConnectorConfig.SNAPSHOT_MODE, waitForSnapshot ? SnapshotMode.INITIAL : SnapshotMode.NEVER))
                 .build()).getConfig()
         );
         assertConnectorIsRunning();
@@ -1356,7 +1356,8 @@ private void testReceiveChangesForReplicaIdentityFullTableWithToastedValue(Postg
             );
         }
 
-        startConnector(config -> config.with(PostgresConnectorConfig.SCHEMA_REFRESH_MODE, mode));
+        startConnector(config -> config.with(PostgresConnectorConfig.SCHEMA_REFRESH_MODE, mode), false);
+        consumer = testConsumer(1);
 
         final String toastedValue = RandomStringUtils.randomAlphanumeric(10000);
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresTaskContext.java
Patch:
@@ -98,6 +98,7 @@ private SlotState getCurrentSlotState(PostgresConnection connection) throws SQLE
     protected ReplicationConnection createReplicationConnection(boolean exportSnapshot) throws SQLException {
         return ReplicationConnection.builder(config.jdbcConfig())
                                     .withSlot(config.slotName())
+                                    .withPublication(config.publicationName())
                                     .withPlugin(config.plugin())
                                     .dropSlotOnClose(config.dropSlotOnStop())
                                     .streamParams(config.streamParams())

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/snapshot/ExportedSnapshotter.java
Patch:
@@ -10,8 +10,6 @@
 import java.util.Optional;
 import java.util.Set;
 
-import org.postgresql.replication.LogSequenceNumber;
-
 import io.debezium.connector.postgresql.PostgresConnectorConfig;
 import io.debezium.connector.postgresql.spi.OffsetState;
 import io.debezium.connector.postgresql.spi.SlotCreationResult;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -701,13 +701,13 @@ protected void handleQueryEvent(Event event) throws InterruptedException {
             // This is an XA transaction, and we currently ignore these and do nothing ...
             return;
         }
-        if (upperCasedStatementBegin.equals("INSERT ") || upperCasedStatementBegin.equals("UPDATE ") || upperCasedStatementBegin.equals("DELETE ")) {
-            throw new ConnectException("Received DML '" + sql + "' for processing, binlog probably contains events generated with statement or mixed based replication format");
-        }
         if (context.ddlFilter().test(sql)) {
             logger.debug("DDL '{}' was filtered out of processing", sql);
             return;
         }
+        if (upperCasedStatementBegin.equals("INSERT ") || upperCasedStatementBegin.equals("UPDATE ") || upperCasedStatementBegin.equals("DELETE ")) {
+            throw new ConnectException("Received DML '" + sql + "' for processing, binlog probably contains events generated with statement or mixed based replication format");
+        }
         if (sql.equalsIgnoreCase("ROLLBACK")) {
             // We have hit a ROLLBACK which is not supported
             logger.warn("Rollback statements cannot be handled without binlog buffering, the connector will fail. Please check '{}' to see how to enable buffering",

File: debezium-core/src/main/java/io/debezium/transforms/ExtractNewRecordStateConfigDefinition.java
Patch:
@@ -14,6 +14,7 @@ public class ExtractNewRecordStateConfigDefinition {
 
     public static final String DEBEZIUM_OPERATION_HEADER_KEY = "__debezium-operation";
     public static final String DELETED_FIELD = "__deleted";
+    public static final String METADATA_FIELD_PREFIX = "__";
 
     public static enum DeleteHandling implements EnumeratedValue {
         DROP("drop"),

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/CustomTestSnapshot.java
Patch:
@@ -20,7 +20,9 @@
  * to allow for class loading to work
  */
 public class CustomTestSnapshot implements Snapshotter {
+
     private boolean hasState;
+
     @Override
     public void init(PostgresConnectorConfig config, OffsetState sourceInfo, SlotState slotState) {
         hasState = (sourceInfo != null);
@@ -54,9 +56,6 @@ public Optional<String> buildSnapshotQuery(TableId tableId) {
 
     @Override
     public String snapshotTransactionIsolationLevelStatement(SlotCreationResult newSlotInfo) {
-        // this actually is never used in the tests as we don't have any tests
-        // that run against pg10+, leaving it here anyways in hopes that
-        // someday there is a build against pg10
         if (newSlotInfo != null) {
             String snapSet = String.format("SET TRANSACTION SNAPSHOT '%s';", newSlotInfo.snapshotName());
             return "SET TRANSACTION ISOLATION LEVEL REPEATABLE READ; \n" + snapSet;

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/snapshot/SnapshotterWrapper.java
Patch:
@@ -17,11 +17,10 @@
 public class SnapshotterWrapper {
 
     private final Snapshotter snapshotter;
-    private final OffsetState offsetState;
     private final SlotState slotState;
+
     public SnapshotterWrapper(Snapshotter snapshotter, PostgresConnectorConfig config, OffsetState offsetState, SlotState slotState) {
         this.snapshotter = snapshotter;
-        this.offsetState = offsetState;
         this.slotState = slotState;
         this.snapshotter.init(config, offsetState, slotState);
     }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/spi/Snapshotter.java
Patch:
@@ -30,6 +30,7 @@
  */
 @Incubating
 public interface Snapshotter {
+
     void init(PostgresConnectorConfig config, OffsetState sourceInfo,
               SlotState slotState);
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresTaskContext.java
Patch:
@@ -99,14 +99,15 @@ private SlotState getCurrentSlotState() throws SQLException {
         }
     }
 
-    protected ReplicationConnection createReplicationConnection() throws SQLException {
+    protected ReplicationConnection createReplicationConnection(boolean exportSnapshot) throws SQLException {
         return ReplicationConnection.builder(config.jdbcConfig())
                                     .withSlot(config.slotName())
                                     .withPlugin(config.plugin())
                                     .dropSlotOnClose(config.dropSlotOnStop())
                                     .streamParams(config.streamParams())
                                     .statusUpdateInterval(config.statusUpdateInterval())
                                     .withTypeRegistry(schema.getTypeRegistry())
+                                    .exportSnapshotOnCreate(exportSnapshot)
                                     .build();
     }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/spi/SlotState.java
Patch:
@@ -17,7 +17,6 @@ public class SlotState {
     private final Long catalogXmin;
     private final boolean active;
 
-
     public SlotState(Long lastFlushLsn, Long restartLsn, Long catXmin, boolean active) {
         this.active = active;
         this.latestFlushedLsn = lastFlushLsn;

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SnapshotWithOverridesProducerIT.java
Patch:
@@ -14,6 +14,7 @@
 import java.util.concurrent.TimeUnit;
 
 import io.debezium.connector.postgresql.snapshot.InitialOnlySnapshotter;
+import io.debezium.connector.postgresql.snapshot.SnapshotterWrapper;
 import io.debezium.connector.postgresql.spi.Snapshotter;
 import org.apache.kafka.connect.source.SourceRecord;
 import org.fest.assertions.Assertions;
@@ -126,7 +127,7 @@ private Map<String, List<SourceRecord>> recordsByTopic(final int expectedRecords
 
     private RecordsSnapshotProducer buildStreamProducer(PostgresTaskContext ctx, PostgresConnectorConfig config) {
         Snapshotter sn = new InitialOnlySnapshotter();
-        sn.init(config, null, null);
-        return new RecordsSnapshotProducer(ctx, TestHelper.sourceInfo(), sn);
+        SnapshotterWrapper snw = new SnapshotterWrapper(sn, config, null, null);
+        return new RecordsSnapshotProducer(ctx, TestHelper.sourceInfo(), snw);
     }
 }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -235,7 +235,7 @@ protected static boolean shouldSSLConnectionFail() {
     }
 
     protected static int waitTimeForRecords() {
-        return Integer.parseInt(System.getProperty(TEST_PROPERTY_PREFIX + "records.waittime", "2"));
+        return Integer.parseInt(System.getProperty(TEST_PROPERTY_PREFIX + "records.waittime", "20"));
     }
 
     protected static SourceInfo sourceInfo() {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/connection/ReplicationConnectionIT.java
Patch:
@@ -302,7 +302,7 @@ private List<ReplicationMessage> expectedMessagesFromStream(ReplicationStream st
         });
 
         try {
-            if (!latch.tryAcquire(expectedMessages, 10, TimeUnit.SECONDS)) {
+            if (!latch.tryAcquire(expectedMessages, 20, TimeUnit.SECONDS)) {
                 result.cancel(true);
                 fail("expected " + expectedMessages + " messages, but read only " + actualMessages.size());
             }

File: debezium-core/src/main/java/io/debezium/pipeline/metrics/ChangeEventSourceMetricsMXBean.java
Patch:
@@ -16,7 +16,7 @@ public interface ChangeEventSourceMetricsMXBean {
     long getMilliSecondsSinceLastEvent();
     long getTotalNumberOfEventsSeen();
     long getNumberOfEventsFiltered();
-    long getNumberOfEventsInError();
+    long getNumberOfErroneousEvents();
     String[] getMonitoredTables();
     int getQueueTotalCapacity();
     int getQueueRemainingCapacity();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -565,7 +565,7 @@ protected void handleServerHeartbeat(Event event) {
      */
     protected void handleServerIncident(Event event) {
         if (event.getData() instanceof EventDataDeserializationExceptionData) {
-            metrics.onEventInError("source = " + event.toString());
+            metrics.onErroneousEvent("source = " + event.toString());
             EventDataDeserializationExceptionData data = event.getData();
 
             EventHeaderV4 eventHeader = (EventHeaderV4) data.getCause().getEventHeader(); // safe cast, instantiated that ourselves
@@ -757,7 +757,7 @@ protected void handleUpdateTableMetadata(Event event) {
      */
     private void informAboutUnknownTableIfRequired(Event event, TableId tableId, String typeToLog) {
         if (tableId != null && context.dbSchema().isTableMonitored(tableId)) {
-            metrics.onEventInError("source = " + tableId + ", event " + event);
+            metrics.onErroneousEvent("source = " + tableId + ", event " + event);
             EventHeaderV4 eventHeader = event.getHeader();
 
             if (inconsistentSchemaHandlingMode == EventProcessingFailureHandlingMode.FAIL) {

File: debezium-core/src/main/java/io/debezium/pipeline/EventDispatcher.java
Patch:
@@ -85,7 +85,7 @@ public void dispatchSnapshotEvent(T dataCollectionId, ChangeRecordEmitter change
 
         // TODO handle as per inconsistent schema info option
         if (dataCollectionSchema == null) {
-            eventListener.onEventInError("source = " + dataCollectionId);
+            eventListener.onErroneousEvent("source = " + dataCollectionId);
             throw new IllegalArgumentException("No metadata registered for captured table " + dataCollectionId);
         }
 
@@ -122,7 +122,7 @@ public void dispatchDataChangeEvent(T dataCollectionId, ChangeRecordEmitter chan
 
             // TODO handle as per inconsistent schema info option
             if (dataCollectionSchema == null) {
-                eventListener.onEventInError("source = " + dataCollectionId);
+                eventListener.onErroneousEvent("source = " + dataCollectionId);
                 throw new IllegalArgumentException("No metadata registered for captured table " + dataCollectionId);
             }
 

File: debezium-core/src/main/java/io/debezium/pipeline/metrics/PipelineMetrics.java
Patch:
@@ -64,7 +64,7 @@ public void onFilteredEvent(String event) {
     }
 
     @Override
-    public void onEventInError(String event) {
+    public void onErroneousEvent(String event) {
         numberOfEventsInError.incrementAndGet();
         updateCommonEventMetrics();
     }

File: debezium-core/src/main/java/io/debezium/pipeline/source/spi/DataChangeEventListener.java
Patch:
@@ -32,15 +32,15 @@ public interface DataChangeEventListener {
     /**
      * Invoked for events that cannot be processed.
      */
-    void onEventInError(String event);
+    void onErroneousEvent(String event);
 
     static DataChangeEventListener NO_OP = new DataChangeEventListener() {
         @Override
         public void onFilteredEvent(String event) {
         }
 
         @Override
-        public void onEventInError(String event) {
+        public void onErroneousEvent(String event) {
         }
 
         @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -565,6 +565,7 @@ protected void handleServerHeartbeat(Event event) {
      */
     protected void handleServerIncident(Event event) {
         if (event.getData() instanceof EventDataDeserializationExceptionData) {
+            metrics.onEventInError("source = " + event.toString());
             EventDataDeserializationExceptionData data = event.getData();
 
             EventHeaderV4 eventHeader = (EventHeaderV4) data.getCause().getEventHeader(); // safe cast, instantiated that ourselves
@@ -756,6 +757,7 @@ protected void handleUpdateTableMetadata(Event event) {
      */
     private void informAboutUnknownTableIfRequired(Event event, TableId tableId, String typeToLog) {
         if (tableId != null && context.dbSchema().isTableMonitored(tableId)) {
+            metrics.onEventInError("source = " + tableId + ", event " + event);
             EventHeaderV4 eventHeader = event.getHeader();
 
             if (inconsistentSchemaHandlingMode == EventProcessingFailureHandlingMode.FAIL) {

File: debezium-core/src/main/java/io/debezium/pipeline/metrics/ChangeEventSourceMetricsMXBean.java
Patch:
@@ -16,6 +16,7 @@ public interface ChangeEventSourceMetricsMXBean {
     long getMilliSecondsSinceLastEvent();
     long getTotalNumberOfEventsSeen();
     long getNumberOfEventsFiltered();
+    long getNumberOfEventsInError();
     String[] getMonitoredTables();
     int getQueueTotalCapacity();
     int getQueueRemainingCapacity();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/AbstractReplicationMessageColumn.java
Patch:
@@ -137,7 +137,9 @@ public boolean isOptional() {
 
     @Override
     public TypeMetadataImpl getTypeMetadata() {
-        initMetadata();
+        if (typeMetadata == null) {
+            initMetadata();
+        }
         return typeMetadata;
     }
 }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -382,6 +382,7 @@ private PGReplicationStream startPgReplicationStream(final LogSequenceNumber lsn
     @Override
     public synchronized void close() {
         try {
+            LOGGER.debug("Closing replication connection");
             super.close();
         }
         catch (Throwable e) {

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsSnapshotProducerIT.java
Patch:
@@ -75,6 +75,7 @@ public void before() throws Exception {
                 TestHelper.getSchema(config),
                 selector
         );
+        // Testing.Print.enable();
     }
 
     @After
@@ -171,6 +172,7 @@ public void shouldGenerateSnapshotAndContinueStreaming() throws Exception {
         consumer.clear();
 
         // then insert some more data and check that we get it back
+        waitForStreamingToStart(snapshotProducer);
         TestHelper.execute(insertStmt);
         consumer.expects(2);
         consumer.await(TestHelper.waitTimeForRecords(), TimeUnit.SECONDS);
@@ -209,6 +211,7 @@ public void shouldGenerateSnapshotAndContinueStreaming() throws Exception {
         consumer.clear();
 
         // now insert two more records and check that we only get those back from the stream
+        waitForStreamingToStart(snapshotProducer);
         TestHelper.execute(insertStmt);
         consumer.expects(2);
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsSnapshotProducerIT.java
Patch:
@@ -569,6 +569,7 @@ public void shouldGenerateSnapshotForTwentyFourHourTime() throws Exception {
     }
 
     @Test
+    @FixFor("DBZ-1345")
     public void shouldNotSnapshotMaterializedViews() throws Exception {
         TestHelper.dropAllSchemas();
         TestHelper.execute("CREATE TABLE mv_real_table (pk SERIAL, i integer, s VARCHAR(50), PRIMARY KEY(pk));");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -456,6 +456,7 @@ public void shouldReadChangeStreamForExistingTable() throws Exception {
     }
 
     @Test
+    @FixFor("DBZ-835")
     public void deleteWithoutTombstone() throws Exception {
         Configuration config = TestHelper.defaultConfig()
                 .with(RelationalDatabaseConnectorConfig.TABLE_WHITELIST, "ORCLPDB1\\.DEBEZIUM\\.CUSTOMER")

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Replicator.java
Patch:
@@ -366,7 +366,7 @@ protected boolean performInitialSync() {
         }
 
         if (collections.isEmpty()) {
-            logger.warn("After applying blacklist/whitelist filters there is no tables to monitor, please check your configuration");
+            logger.warn("After applying blacklist/whitelist filters there are no tables to monitor, please check your configuration");
         }
 
         if (logger.isInfoEnabled()) {

File: debezium-core/src/main/java/io/debezium/relational/RelationalDatabaseSchema.java
Patch:
@@ -78,7 +78,7 @@ public Set<TableId> tableIds() {
 
     public void assureNonEmptySchema() {
         if (tableIds().isEmpty()) {
-            LOG.warn("After applying blacklist/whitelist filters there is no tables to monitor, please check your configuration");
+            LOG.warn("After applying blacklist/whitelist filters there are no tables to monitor, please check your configuration");
         }
     }
 

File: debezium-embedded/src/test/java/io/debezium/embedded/AbstractConnectorTest.java
Patch:
@@ -78,6 +78,7 @@ public abstract class AbstractConnectorTest implements Testing {
     public TestRule skipTestRule = new SkipTestRule();
 
     protected static final Path OFFSET_STORE_PATH = Testing.Files.createTestingPath("file-connector-offsets.txt").toAbsolutePath();
+    protected static final String NO_MONITORED_TABLES_WARNING = "After applying blacklist/whitelist filters there are no tables to monitor, please check your configuration";
 
     private ExecutorService executor;
     protected EmbeddedEngine engine;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorIT.java
Patch:
@@ -12,7 +12,6 @@
 import java.io.InputStream;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicReference;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -294,6 +294,8 @@ public void doDestroy() {
 
     @Override
     protected void doStart() {
+        context.dbSchema().assureNonEmptySchema();
+
         // Register our event handlers ...
         eventHandlers.put(EventType.STOP, this::handleServerStop);
         eventHandlers.put(EventType.HEARTBEAT, this::handleServerHeartbeat);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsSnapshotProducer.java
Patch:
@@ -282,6 +282,8 @@ private void takeSnapshot(BlockingConsumer<ChangeEvent> consumer) {
                     r -> consumer.accept(new ChangeEvent(r, sourceInfo.lsn())
                 )
             );
+
+            taskContext.schema().assureNonEmptySchema();
         }
         catch (SQLException e) {
             rollbackTransaction(jdbcConnection);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsStreamProducer.java
Patch:
@@ -116,6 +116,7 @@ protected synchronized void start(BlockingConsumer<ChangeEvent> eventConsumer, C
             replicationStream.get().startKeepAlive(Threads.newSingleThreadExecutor(PostgresConnector.class, taskContext.config().getLogicalName(), CONTEXT_NAME + "-keep-alive"));
             // refresh the schema so we have a latest view of the DB tables
             taskContext.refreshSchema(true);
+            taskContext.schema().assureNonEmptySchema();
 
             this.lastCompletelyProcessedLsn = sourceInfo.lsn();
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorTask.java
Patch:
@@ -126,7 +126,8 @@ public void start(Configuration config) {
                 SqlServerConnector.class,
                 connectorConfig.getLogicalName(),
                 new SqlServerChangeEventSourceFactory(connectorConfig, jdbcConnection, errorHandler, dispatcher, clock, schema),
-                dispatcher
+                dispatcher,
+                schema
         );
 
         coordinator.start(taskContext, this.queue, new SqlServerEventMetadataProvider());

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/RecordMakers.java
Patch:
@@ -156,7 +156,7 @@ public CollectionId collectionId() {
          *             the blocking consumer
          */
         public int recordObject(CollectionId id, Document object, long timestamp) throws InterruptedException {
-            final Struct sourceValue = source.lastOffsetStruct(replicaSetName, id);
+            final Struct sourceValue = source.lastSourceInfoStruct(replicaSetName, id);
             final Map<String, ?> offset = source.lastOffset(replicaSetName);
             String objId = idObjToJson(object);
             assert objId != null;
@@ -172,7 +172,7 @@ public int recordObject(CollectionId id, Document object, long timestamp) throws
          *             the blocking consumer
          */
         public int recordEvent(Document oplogEvent, long timestamp) throws InterruptedException {
-            final Struct sourceValue = source.offsetStructForEvent(replicaSetName, oplogEvent);
+            final Struct sourceValue = source.sourceInfoStructForEvent(replicaSetName, oplogEvent);
             final Map<String, ?> offset = source.lastOffset(replicaSetName);
             Document patchObj = oplogEvent.get("o", Document.class);
             // Updates have an 'o2' field, since the updated object in 'o' might not have the ObjectID ...

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Replicator.java
Patch:
@@ -200,7 +200,7 @@ protected void recordCurrentOplogPosition() {
         primaryClient.execute("get oplog position", primary -> {
             MongoCollection<Document> oplog = primary.getDatabase("local").getCollection("oplog.rs");
             Document last = oplog.find().sort(new Document("$natural", -1)).limit(1).first(); // may be null
-            source.offsetStructForEvent(replicaSet.replicaSetName(), last);
+            source.sourceInfoStructForEvent(replicaSet.replicaSetName(), last);
         });
     }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSourceInfoStructMaker.java
Patch:
@@ -41,9 +41,9 @@ public Struct struct(SourceInfo sourceInfo) {
         Struct result = super.commonStruct(sourceInfo);
         result.put(SourceInfo.SCHEMA_NAME_KEY, sourceInfo.schemaName());
         result.put(SourceInfo.TABLE_NAME_KEY, sourceInfo.tableName());
-        // use the offset information without the snapshot part (see below)
+        // use the offset information without the snapshot part and usec part
         sourceInfo.offset().forEach((k, v) -> {
-            if (SourceInfo.TIMESTAMP_USEC_KEY.equals(k) && v != null) {
+            if (SourceInfo.TIMESTAMP_USEC_KEY.equals(k)) {
                 return;
             }
             else if (SourceInfo.LAST_SNAPSHOT_RECORD_KEY.equals(k)) {

File: debezium-core/src/main/java/io/debezium/config/CommonConnectorConfig.java
Patch:
@@ -95,7 +95,7 @@ public abstract class CommonConnectorConfig {
     private final Duration snapshotDelayMs;
     private final int snapshotFetchSize;
 
-    protected CommonConnectorConfig(Configuration config, String logicalName, Integer defaultSnapshotFetchSize) {
+    protected CommonConnectorConfig(Configuration config, String logicalName, int defaultSnapshotFetchSize) {
         this.config = config;
         this.emitTombstoneOnDelete = config.getBoolean(CommonConnectorConfig.TOMBSTONES_ON_DELETE);
         this.maxQueueSize = config.getInteger(MAX_QUEUE_SIZE);

File: debezium-core/src/main/java/io/debezium/relational/RelationalDatabaseConnectorConfig.java
Patch:
@@ -190,7 +190,7 @@ public static DecimalHandlingMode parse(String value, String defaultValue) {
     private final RelationalTableFilters tableFilters;
 
     protected RelationalDatabaseConnectorConfig(Configuration config, String logicalName, TableFilter systemTablesFilter,
-                                                TableIdToStringMapper tableIdMapper, Integer defaultSnapshotFetchSize) {
+                                                TableIdToStringMapper tableIdMapper, int defaultSnapshotFetchSize) {
         super(config, logicalName, defaultSnapshotFetchSize);
 
         if (systemTablesFilter != null && tableIdMapper != null) {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlJdbcContext.java
Patch:
@@ -217,7 +217,8 @@ public GtidSet subtractGtidSet(GtidSet set1, GtidSet set2) {
                         }
                         return new GtidSet("");
             });
-        } catch (SQLException e) {
+        }
+        catch (SQLException e) {
             throw new ConnectException("Unexpected error while connecting to MySQL and looking at GTID mode: ", e);
         }
     }

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -197,15 +197,15 @@ private void validateIncomingRowToInternalMetadata(int[] recordIndexes, Field[]
             Object[] row, int position) {
         if (position >= converters.length) {
             LOGGER.error("Error requesting a converter, converters: {}, requested index: {}", converters.length, position);
-            throw new ConnectException("Column indexing array is larger than number of converters, internal schema represantion is probably out of sync with real database schema");
+            throw new ConnectException("Column indexing array is larger than number of converters, internal schema representation is probably out of sync with real database schema");
         }
         if (position >= fields.length) {
             LOGGER.error("Error requesting a field, fields: {}, requested index: {}", fields.length, position);
-            throw new ConnectException("Too few schema fields, internal schema represantion is probably out of sync with real database schema");
+            throw new ConnectException("Too few schema fields, internal schema representation is probably out of sync with real database schema");
         }
         if (recordIndexes[position] >= row.length) {
             LOGGER.error("Error requesting a row value, row: {}, requested index: {} at position {}", row.length, recordIndexes[position], position);
-            throw new ConnectException("Data row is smaller than a column index, internal schema represantion is probably out of sync with real database schema");
+            throw new ConnectException("Data row is smaller than a column index, internal schema representation is probably out of sync with real database schema");
         }
     }
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/AbstractMysqlDefaultValueTest.java
Patch:
@@ -211,7 +211,7 @@ public void parseStringDefaultValue() {
                 "  F CHAR DEFAULT NULL,\n" +
                 "  G VARCHAR(10) DEFAULT NULL,\n" +
                 "  H NCHAR(10) DEFAULT NULL\n" +
-                ");";
+                ") CHARACTER SET 'latin2';";
         parser.parse(sql, tables);
         Table table = tables.forTable(new TableId(null, null, "UNSIGNED_STRING_TABLE"));
         assertThat(table.columnWithName("A").defaultValue()).isEqualTo("A");

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -764,6 +764,7 @@ public static SchemaRefreshMode parse(String value) {
     public static final Field STATUS_UPDATE_INTERVAL_MS = Field.create("status.update.interval.ms")
                                                           .withDisplayName("Status update interval (ms)")
                                                           .withType(Type.INT) // Postgres doesn't accept long for this value
+                                                          .withDefault(10_000)
                                                           .withWidth(Width.SHORT)
                                                           .withImportance(Importance.MEDIUM)
                                                           .withDescription("Frequency in milliseconds for sending replication connection status updates to the server. Defaults to 10 seconds (10000 ms).")

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -14,6 +14,7 @@
 import java.nio.file.Paths;
 import java.sql.Connection;
 import java.sql.SQLException;
+import java.time.Duration;
 import java.util.Set;
 import java.util.stream.Collectors;
 
@@ -75,6 +76,7 @@ public static ReplicationConnection createForReplication(String slotName, boolea
                                     .withSlot(slotName)
                                     .withTypeRegistry(getTypeRegistry())
                                     .dropSlotOnClose(dropOnClose)
+                                    .statusUpdateInterval(Duration.ofSeconds(10))
                                     .build();
     }
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -82,7 +82,7 @@ public abstract class AbstractRecordsProducerTest {
     protected static final String INSERT_CASH_TYPES_STMT = "INSERT INTO cash_table (csh) VALUES ('$1234.11')";
     protected static final String INSERT_DATE_TIME_TYPES_STMT = "INSERT INTO time_table(ts, tsneg, ts_ms, ts_us, tz, date, ti, tip, ttz, tptz, it) " +
                                                                 "VALUES ('2016-11-04T13:51:30.123456'::TIMESTAMP, '1936-10-25T22:10:12.608'::TIMESTAMP, '2016-11-04T13:51:30.123456'::TIMESTAMP, '2016-11-04T13:51:30.123456'::TIMESTAMP, '2016-11-04T13:51:30.123456+02:00'::TIMESTAMPTZ, " +
-                                                                "'2016-11-04'::DATE, '13:51:30'::TIME, '13:51:30.123'::TIME, '13:51:30.123+02:00'::TIMETZ, '13:51:30.123+02:00'::TIMETZ, " +
+                                                                "'2016-11-04'::DATE, '13:51:30'::TIME, '13:51:30.123'::TIME, '13:51:30.123789+02:00'::TIMETZ, '13:51:30.123+02:00'::TIMETZ, " +
                                                                 "'P1Y2M3DT4H5M0S'::INTERVAL)";
     protected static final String INSERT_BIN_TYPES_STMT = "INSERT INTO bitbin_table (ba, bol, bs, bv) " +
                                                           "VALUES (E'\\\\001\\\\002\\\\003'::bytea, '0'::bit(1), '11'::bit(2), '00'::bit(2))";
@@ -500,7 +500,7 @@ protected List<SchemaAndValueField> schemaAndValuesForDateTimeTypes() {
         int expectedDate = Date.toEpochDay(LocalDate.parse("2016-11-04"), null);
         long expectedTi = LocalTime.parse("13:51:30").toNanoOfDay() / 1_000;
         long expectedTiPrecision = LocalTime.parse("13:51:30.123").toNanoOfDay() / 1_000_000;
-        String expectedTtz = "11:51:30.123Z";  //time is stored with TZ, should be read back at GMT
+        String expectedTtz = "11:51:30.123789Z";  //time is stored with TZ, should be read back at GMT
         String expectedTtzPrecision = "11:51:30.123Z";
         double interval = MicroDuration.durationMicros(1, 2, 3, 4, 5, 0, MicroDuration.DAYS_PER_MONTH_AVG);
 
@@ -524,7 +524,7 @@ protected List<SchemaAndValueField> schemaAndValuesForDateTimeTypesAdaptiveTimeM
         String expectedTz = "2016-11-04T11:51:30.123456Z"; //timestamp is stored with TZ, should be read back with UTC
         int expectedDate = Date.toEpochDay(LocalDate.parse("2016-11-04"), null);
         long expectedTi = LocalTime.parse("13:51:30").toNanoOfDay() / 1_000;
-        String expectedTtz = "11:51:30.123Z";  //time is stored with TZ, should be read back at GMT
+        String expectedTtz = "11:51:30.123789Z";  //time is stored with TZ, should be read back at GMT
         double interval = MicroDuration.durationMicros(1, 2, 3, 4, 5, 0, MicroDuration.DAYS_PER_MONTH_AVG);
 
         return Arrays.asList(new SchemaAndValueField("ts", MicroTimestamp.builder().optional().build(), expectedTs),

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SnapshotReader.java
Patch:
@@ -810,8 +810,9 @@ protected String quote(TableId id) {
      * @throws SQLException if there is a problem creating the statement
      */
     private Statement createStatementWithLargeResultSet(Connection connection) throws SQLException {
+        int fetchSize = context.getConnectorConfig().getSnapshotFetchSize();
         Statement stmt = connection.createStatement(ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);
-        stmt.setFetchSize(Integer.MIN_VALUE);
+        stmt.setFetchSize(fetchSize);
         return stmt;
     }
 

File: debezium-core/src/main/java/io/debezium/relational/HistorizedRelationalSnapshotChangeEventSource.java
Patch:
@@ -386,7 +386,7 @@ private Object getColumnValue(ResultSet rs, int columnIndex, Column column) thro
     }
 
     private Statement readTableStatement() throws SQLException {
-        int fetchSize = connectorConfig.getSnapshotFetchSize(2_000);
+        int fetchSize = connectorConfig.getSnapshotFetchSize();
         Statement statement = jdbcConnection.connection().createStatement(); // the default cursor is FORWARD_ONLY
         statement.setFetchSize(fetchSize);
         return statement;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Replicator.java
Patch:
@@ -418,7 +418,8 @@ protected long copyCollection(MongoClient primary, CollectionId collectionId, lo
         MongoDatabase db = primary.getDatabase(collectionId.dbName());
         MongoCollection<Document> docCollection = db.getCollection(collectionId.name());
         long counter = 0;
-        try (MongoCursor<Document> cursor = docCollection.find().iterator()) {
+        int documentsFetchSize = context.getConnectorConfig().getDocumentsFetchSize();
+        try (MongoCursor<Document> cursor = docCollection.find().batchSize(documentsFetchSize).iterator()) {
             while (running.get() && cursor.hasNext()) {
                 Document doc = cursor.next();
                 logger.trace("Found existing doc in {}: {}", collectionId, doc);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDefaultValuePreConverter.java
Patch:
@@ -235,7 +235,7 @@ private Object convertToBoolean(String value) {
     private DateTimeFormatter timestampFormat(int length) {
         final DateTimeFormatterBuilder dtf = new DateTimeFormatterBuilder()
                 .appendPattern("yyyy-MM-dd HH:mm:ss");
-        if (length !=-1) {
+        if (length > 0) {
             dtf.appendFraction(ChronoField.MICRO_OF_SECOND, 0, length, true);
         }
         return dtf.toFormatter();

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -118,7 +118,8 @@ public void shouldLoadSchemaForBuiltinPostgresTypes() throws Exception {
             assertTableSchema("public.geom_table", "p", Point.builder().optional().build());
             assertTableSchema("public.range_table", "unbounded_exclusive_tsrange, bounded_inclusive_tsrange," +
                             "unbounded_exclusive_tstzrange, bounded_inclusive_tstzrange," +
-                            "unbounded_exclusive_daterange, bounded_exclusive_daterange",
+                            "unbounded_exclusive_daterange, bounded_exclusive_daterange, int4_number_range, numerange, int8_number_range",
+                    Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA,
                     Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA,
                     Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA);
             assertTableSchema("public.array_table", "int_array, bigint_array, text_array",

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDefaultValuePreConverter.java
Patch:
@@ -212,7 +212,7 @@ private Object convertToBits(String value) {
         for (int i = 0; i < nums; i++) {
             int s = value.length() - Byte.SIZE < 0 ? 0 : value.length() - Byte.SIZE;
             int e = value.length();
-            bytes[nums - i - 1] = Byte.parseByte(value.substring(s, e), 2);
+            bytes[nums - i - 1] = (byte) Integer.parseInt(value.substring(s, e), 2);
             value = value.substring(0, s);
         }
         return bytes;

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/Wal2JsonReplicationMessage.java
Patch:
@@ -360,7 +360,9 @@ else if (rawValue.isBigInteger()) {
             case "jsonb":
             case "xml":
             case "uuid":
+            case "tsrange":
             case "tstzrange":
+            case "daterange":
             case "inet":
             case "cidr":
             case "macaddr":

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -138,9 +138,9 @@ public void shouldReceiveChangesForInsertsWithDifferentDataTypes() throws Except
         consumer.expects(1);
         assertInsert(INSERT_GEOM_TYPES_STMT, 1, schemaAndValuesForGeomTypes());
 
-        // timezone range types
+        // range types
         consumer.expects(1);
-        assertInsert(INSERT_TSTZRANGE_TYPES_STMT, 1, schemaAndValuesForTstzRangeTypes());
+        assertInsert(INSERT_RANGE_TYPES_STMT, 1, schemaAndValuesForRangeTypes());
     }
 
     @Test

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/Wal2JsonReplicationMessage.java
Patch:
@@ -363,11 +363,12 @@ else if (rawValue.isBigInteger()) {
             case "tstzrange":
             case "inet":
             case "cidr":
+            case "macaddr":
+            case "macaddr8":
                 return rawValue.asString();
+
             // catch-all for other known/builtin PG types
             // TODO: improve with more specific/useful classes here?
-            case "macaddr":
-            case "macaddr8":
             case "pg_lsn":
             case "tsquery":
             case "tsvector":

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -1096,12 +1096,12 @@ public static final Field MASK_COLUMN(int length) {
     public static final Field ENABLE_TIME_ADJUSTER = Field.create("enable.time.adjuster")
             .withDisplayName("Enable Time Adjuster")
             .withType(Type.BOOLEAN)
-            .withDefault(false)
+            .withDefault(true)
             .withWidth(Width.SHORT)
             .withImportance(Importance.LOW)
             .withDescription("MySQL allows user to insert year value as either 2-digit or 4-digit. In case of two digit the value is automatically mapped into 1970 - 2069." +
-                    "false - (the default) delegates the implicit conversion to the database" +
-                    "true - Debezium makes the conversion");
+                    "false - delegates the implicit conversion to the database" +
+                    "true - (the default) Debezium makes the conversion");
 
     /**
      * The set of {@link Field}s defined as part of this configuration.

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlSchema.java
Patch:
@@ -147,8 +147,8 @@ private static MySqlValueConverters getValueConverters(MySqlConnectorConfig conf
         BigIntUnsignedHandlingMode bigIntUnsignedHandlingMode = BigIntUnsignedHandlingMode.parse(bigIntUnsignedHandlingModeStr);
         BigIntUnsignedMode bigIntUnsignedMode = bigIntUnsignedHandlingMode.asBigIntUnsignedMode();
 
-        final boolean timeAdujsterEnabled = configuration.getConfig().getBoolean(MySqlConnectorConfig.ENABLE_TIME_ADJUSTER);
-        return new MySqlValueConverters(decimalMode, timePrecisionMode, bigIntUnsignedMode, timeAdujsterEnabled ? MySqlValueConverters::adjustTemporal : x -> x);
+        final boolean timeAdjusterEnabled = configuration.getConfig().getBoolean(MySqlConnectorConfig.ENABLE_TIME_ADJUSTER);
+        return new MySqlValueConverters(decimalMode, timePrecisionMode, bigIntUnsignedMode, timeAdjusterEnabled ? MySqlValueConverters::adjustTemporal : x -> x);
     }
 
     protected HistoryRecordComparator historyComparator() {

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlYearIT.java
Patch:
@@ -47,7 +47,8 @@ public void beforeEach() {
     public void afterEach() {
         try {
             stopConnector();
-        } finally {
+        }
+        finally {
             Testing.Files.delete(DB_HISTORY_PATH);
         }
     }
@@ -58,6 +59,7 @@ public void shouldProcessTwoAndForDigitYearsInDatabase() throws SQLException, In
         // Use the DB configuration to define the connector's configuration ...
         config = DATABASE.defaultConfig()
                 .with(MySqlConnectorConfig.SNAPSHOT_MODE, MySqlConnectorConfig.SnapshotMode.INITIAL)
+                .with(MySqlConnectorConfig.ENABLE_TIME_ADJUSTER, false)
                 .build();
 
         // Start the connector ...
@@ -99,7 +101,6 @@ public void shouldProcessTwoAndForDigitYearsInConnector() throws SQLException, I
         // Use the DB configuration to define the connector's configuration ...
         config = DATABASE.defaultConfig()
                 .with(MySqlConnectorConfig.SNAPSHOT_MODE, MySqlConnectorConfig.SnapshotMode.INITIAL)
-                .with(MySqlConnectorConfig.ENABLE_TIME_ADJUSTER, true)
                 .build();
 
         // Start the connector ...

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlSchema.java
Patch:
@@ -147,7 +147,8 @@ private static MySqlValueConverters getValueConverters(MySqlConnectorConfig conf
         BigIntUnsignedHandlingMode bigIntUnsignedHandlingMode = BigIntUnsignedHandlingMode.parse(bigIntUnsignedHandlingModeStr);
         BigIntUnsignedMode bigIntUnsignedMode = bigIntUnsignedHandlingMode.asBigIntUnsignedMode();
 
-        return new MySqlValueConverters(decimalMode, timePrecisionMode, bigIntUnsignedMode);
+        final boolean timeAdujsterEnabled = configuration.getConfig().getBoolean(MySqlConnectorConfig.ENABLE_TIME_ADJUSTER);
+        return new MySqlValueConverters(decimalMode, timePrecisionMode, bigIntUnsignedMode, timeAdujsterEnabled ? MySqlValueConverters::adjustTemporal : x -> x);
     }
 
     protected HistoryRecordComparator historyComparator() {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PgOid.java
Patch:
@@ -23,4 +23,6 @@ public final class PgOid extends Oid {
     public static final int TSTZRANGE_OID = 3910;
     public static final int INET_OID = 869;
     public static final int INET_ARRAY = 1041;
+    public static final int CIDR_OID=650;
+    public static final int CIDR_ARRAY=651;
 }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoReplicationMessage.java
Patch:
@@ -176,6 +176,7 @@ else if (datumMessage.hasDatumString()) {
             case PgOid.BIT:
             case PgOid.VARBIT:
             case PgOid.INET_OID:
+            case PgOid.CIDR_OID:
                 return datumMessage.hasDatumString() ? datumMessage.getDatumString() : null;
             case PgOid.DATE:
                 return datumMessage.hasDatumInt32() ? (long) datumMessage.getDatumInt32() : null;
@@ -242,6 +243,7 @@ else if (datumMessage.hasDatumString()) {
             case PgOid.JSON_ARRAY:
             case PgOid.REF_CURSOR_ARRAY:
             case PgOid.INET_ARRAY:
+            case PgOid.CIDR_ARRAY:
                 return getArray(datumMessage, connection, columnType);
 
             case PgOid.UNSPECIFIED:

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/Wal2JsonReplicationMessage.java
Patch:
@@ -362,10 +362,10 @@ else if (rawValue.isBigInteger()) {
             case "uuid":
             case "tstzrange":
             case "inet":
+            case "cidr":
                 return rawValue.asString();
             // catch-all for other known/builtin PG types
             // TODO: improve with more specific/useful classes here?
-            case "cidr":
             case "macaddr":
             case "macaddr8":
             case "pg_lsn":

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -53,7 +53,7 @@
 public class PostgresSchemaIT {
 
     private static final String[] TEST_TABLES = new String[] { "public.numeric_table", "public.numeric_decimal_table", "public.string_table",
-                                                               "public.cash_table", "public.bitbin_table", "public.network_address_table",
+                                                               "public.cash_table", "public.bitbin_table", "public.network_address_table", "public.cidr_network_address_table",
                                                                "public.time_table", "public.text_table", "public.geom_table", "public.tstzrange_table",
                                                                "public.array_table", "\"Quoted_\"\" . Schema\".\"Quoted_\"\" . Table\"",
                                                                "public.custom_table"
@@ -92,6 +92,7 @@ public void shouldLoadSchemaForBuiltinPostgresTypes() throws Exception {
                               Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA,
                               Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA);
             assertTableSchema("public.network_address_table", "i", Schema.OPTIONAL_STRING_SCHEMA);
+            assertTableSchema("public.cidr_network_address_table", "i", Schema.OPTIONAL_STRING_SCHEMA);
             assertTableSchema("public.cash_table", "csh", Decimal.builder(2).optional().build());
             assertTableSchema("public.bitbin_table", "ba, bol, bs, bv",
                               Schema.OPTIONAL_BYTES_SCHEMA, Schema.OPTIONAL_BOOLEAN_SCHEMA, Bits.builder(2).optional().build(),

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -522,7 +522,9 @@ protected boolean isBinlogAvailable() {
         // And compare with the one we're supposed to use ...
         boolean found = logNames.stream().anyMatch(binlogFilename::equals);
         if (!found) {
-            logger.info("Connector requires binlog file '{}', but MySQL only has {}", binlogFilename, String.join(", ", logNames));
+            if (logger.isInfoEnabled()) {
+                logger.info("Connector requires binlog file '{}', but MySQL only has {}", binlogFilename, String.join(", ", logNames));
+            }
         }
         else {
             logger.info("MySQL has the binlog file '{}' required by the connector", binlogFilename);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlJdbcContext.java
Patch:
@@ -67,7 +67,7 @@ public MySqlJdbcContext(Configuration config) {
             jdbcConfigBuilder.with(JDBC_PROPERTY_LEGACY_DATETIME, "false");
         }
         else if ("true".equals(legacyDateTime)) {
-            logger.warn("'" + JDBC_PROPERTY_LEGACY_DATETIME + "'" + " is set to 'true'. This setting is not recommended and can result in timezone issues.");
+            logger.warn("'{}' is set to 'true'. This setting is not recommended and can result in timezone issues.", JDBC_PROPERTY_LEGACY_DATETIME);
         }
 
         jdbcConfig = jdbcConfigBuilder.build();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorTask.java
Patch:
@@ -90,7 +90,9 @@ public void start(Configuration config) {
             //Print out the server information
             SlotState slotInfo = null;
             try (PostgresConnection connection = taskContext.createConnection()) {
-                logger.info(connection.serverInfo().toString());
+                if (logger.isInfoEnabled()) {
+                    logger.info(connection.serverInfo().toString());
+                }
                 slotInfo = connection.getReplicationSlotInfo(connectorConfig.slotName(), connectorConfig.plugin().getPostgresPluginName());
             }
             catch (SQLException e) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSchema.java
Patch:
@@ -102,7 +102,7 @@ protected PostgresSchema refresh(PostgresConnection connection, boolean printRep
     private void printReplicaIdentityInfo(PostgresConnection connection, TableId tableId) {
         try {
             ServerInfo.ReplicaIdentity replicaIdentity = connection.readReplicaIdentityInfo(tableId);
-            LOGGER.info("REPLICA IDENTITY for '{}' is '{}'; {}", tableId, replicaIdentity.toString(), replicaIdentity.description());
+            LOGGER.info("REPLICA IDENTITY for '{}' is '{}'; {}", tableId, replicaIdentity, replicaIdentity.description());
         } catch (SQLException e) {
             LOGGER.warn("Cannot determine REPLICA IDENTITY info for '{}'", tableId);
         }

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -218,7 +218,7 @@ protected Function<Object[], Struct> createValueGenerator(Schema schema, TableId
                     ValueConverter converter = converters[i];
 
                     if (converter != null) {
-                      LOGGER.trace("converter for value object: *** {} ***", converter.toString());
+                      LOGGER.trace("converter for value object: *** {} ***", converter);
                     }
                     else {
                       LOGGER.trace("converter is null...");

File: debezium-core/src/main/java/io/debezium/relational/ddl/AbstractDdlParser.java
Patch:
@@ -340,7 +340,7 @@ else if (constantValue.equalsIgnoreCase("TRUE") || constantValue.equalsIgnoreCas
             }
         }
         catch (Throwable t) {
-            logger.debug("Unable to create an artificial column for the constant: " + constantValue);
+            logger.debug("Unable to create an artificial column for the constant: {}", constantValue);
         }
         return column.create();
     }

File: debezium-core/src/main/java/io/debezium/transforms/UnwrapFromEnvelope.java
Patch:
@@ -154,7 +154,7 @@ public void configure(final Map<String, ?> configs) {
         dropTombstones = config.getBoolean(DROP_TOMBSTONES);
         handleDeletes = DeleteHandling.parse(config.getString(HANDLE_DELETES));
         if (config.hasKey(DROP_DELETES.name())) {
-            logger.warn(DROP_DELETES.name() + " option is deprecated. Please use " + HANDLE_DELETES.name());
+            logger.warn("{} option is deprecated. Please use {}", DROP_DELETES.name(), HANDLE_DELETES.name());
             dropDeletes = config.getBoolean(DROP_DELETES);
             if (dropDeletes) {
                 handleDeletes = DeleteHandling.DROP;

File: debezium-core/src/main/java/io/debezium/util/IoUtil.java
Patch:
@@ -418,7 +418,7 @@ public static void delete(File... filesOrFolder) throws IOException {
     public static void delete(Path path) throws IOException {
         if (path != null) {
             if (path.toAbsolutePath().toFile().exists()) {
-                LOGGER.debug("Deleting '" + path + "'...");
+                LOGGER.debug("Deleting '{}'...", path);
                 Set<FileVisitOption> options = EnumSet.noneOf(FileVisitOption.class);
                 int maxDepth = 10;
                 FileVisitor<Path> removingVisitor = new SimpleFileVisitor<Path>() {

File: debezium-core/src/main/java/io/debezium/util/Threads.java
Patch:
@@ -246,7 +246,9 @@ private Threads() {
      * @return the thread factory setting the correct name
      */
     public static ThreadFactory threadFactory(Class<? extends SourceConnector> connector, String connectorId, String name, boolean indexed) {
-        LOGGER.info("Requested thread factory for connector {}, id = {} named = {}", connector.getSimpleName(), connectorId, name);
+        if (LOGGER.isInfoEnabled()) {
+            LOGGER.info("Requested thread factory for connector {}, id = {} named = {}", connector.getSimpleName(), connectorId, name);
+        }
 
         return new ThreadFactory() {
             private final AtomicInteger index = new AtomicInteger(0);

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -809,13 +809,13 @@ public Map<String, String> configs() {
                         RecordCommitter committer = buildRecordCommitter(offsetWriter, task, commitTimeout);
                         while (runningThread.get() != null) {
                             try {
-                                logger.debug("Embedded engine is polling task for records on thread " + runningThread.get());
+                                logger.debug("Embedded engine is polling task for records on thread {}", runningThread.get());
                                 changeRecords = task.poll(); // blocks until there are values ...
                                 logger.debug("Embedded engine returned from polling task for records");
                             }
                             catch (InterruptedException e) {
                                 // Interrupted while polling ...
-                                logger.debug("Embedded engine interrupted on thread " + runningThread.get() + " while polling the task for records");
+                                logger.debug("Embedded engine interrupted on thread {} while polling the task for records", runningThread.get());
                                 Thread.interrupted();
                                 break;
                             }
@@ -1004,7 +1004,7 @@ public boolean stop() {
             }
             catch (InterruptedException e) {
             }
-            logger.debug("Interruping the embedded engine's thread " + thread + " (already interrupted: " + thread.isInterrupted() + ")");
+            logger.debug("Interrupting the embedded engine's thread {} (already interrupted: {})", thread, thread.isInterrupted());
             // Interrupt the thread in case it is blocked while polling the task for records ...
             thread.interrupt();
             return true;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/LcrEventHandler.java
Patch:
@@ -39,7 +39,7 @@ class LcrEventHandler implements XStreamLCRCallbackHandler {
     private final OracleOffsetContext offsetContext;
     private final boolean tablenameCaseInsensitive;
 
-    public LcrEventHandler(ErrorHandler errorHandler, EventDispatcher<TableId> dispatcher, Clock clock, RelationalDatabaseSchema schema, OracleOffsetContext offsetContext,boolean tablenameCaseInsensitive) {
+    public LcrEventHandler(ErrorHandler errorHandler, EventDispatcher<TableId> dispatcher, Clock clock, RelationalDatabaseSchema schema, OracleOffsetContext offsetContext, boolean tablenameCaseInsensitive) {
         this.errorHandler = errorHandler;
         this.dispatcher = dispatcher;
         this.clock = clock;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSnapshotChangeEventSource.java
Patch:
@@ -86,7 +86,7 @@ protected Set<TableId> getAllTableIds(SnapshotContext ctx) throws Exception {
 
     @Override
     protected void lockTablesForSchemaSnapshot(ChangeEventSourceContext sourceContext, SnapshotContext snapshotContext) throws SQLException, InterruptedException {
-        ((OracleSnapshotContext)snapshotContext).preSchemaSnapshotSavepoint = jdbcConnection.connection().setSavepoint("dbz_schema_snapshot");
+        ((OracleSnapshotContext) snapshotContext).preSchemaSnapshotSavepoint = jdbcConnection.connection().setSavepoint("dbz_schema_snapshot");
 
         try (Statement statement = jdbcConnection.connection().createStatement()) {
             for (TableId tableId : snapshotContext.capturedTables) {
@@ -103,7 +103,7 @@ protected void lockTablesForSchemaSnapshot(ChangeEventSourceContext sourceContex
 
     @Override
     protected void releaseSchemaSnapshotLocks(SnapshotContext snapshotContext) throws SQLException {
-        jdbcConnection.connection().rollback(((OracleSnapshotContext)snapshotContext).preSchemaSnapshotSavepoint);
+        jdbcConnection.connection().rollback(((OracleSnapshotContext) snapshotContext).preSchemaSnapshotSavepoint);
     }
 
     @Override
@@ -217,7 +217,7 @@ protected SchemaChangeEvent getCreateTableEvent(SnapshotContext snapshotContext,
             }
 
             Object res = rs.getObject(1);
-            String ddl = ((Clob)res).getSubString(1, (int) ((Clob)res).length());
+            String ddl = ((Clob) res).getSubString(1, (int) ((Clob) res).length());
 
             return new SchemaChangeEvent(snapshotContext.offset.getPartition(), snapshotContext.offset.getOffset(), snapshotContext.catalogName,
                     table.id().schema(), ddl, table, SchemaChangeEventType.CREATE, true);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PgOid.java
Patch:
@@ -21,4 +21,6 @@ public final class PgOid extends Oid {
      */
     public static final int JSONB_OID = 3802;
     public static final int TSTZRANGE_OID = 3910;
+    public static final int INET_OID = 869;
+    public static final int INET_ARRAY = 1041;
 }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoReplicationMessage.java
Patch:
@@ -175,6 +175,7 @@ else if (datumMessage.hasDatumString()) {
             case PgOid.UUID:
             case PgOid.BIT:
             case PgOid.VARBIT:
+            case PgOid.INET_OID:
                 return datumMessage.hasDatumString() ? datumMessage.getDatumString() : null;
             case PgOid.DATE:
                 return datumMessage.hasDatumInt32() ? (long) datumMessage.getDatumInt32() : null;
@@ -240,6 +241,7 @@ else if (datumMessage.hasDatumString()) {
             case PgOid.JSONB_ARRAY:
             case PgOid.JSON_ARRAY:
             case PgOid.REF_CURSOR_ARRAY:
+            case PgOid.INET_ARRAY:
                 return getArray(datumMessage, connection, columnType);
 
             case PgOid.UNSPECIFIED:

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/Wal2JsonReplicationMessage.java
Patch:
@@ -361,11 +361,11 @@ else if (rawValue.isBigInteger()) {
             case "xml":
             case "uuid":
             case "tstzrange":
+            case "inet":
                 return rawValue.asString();
             // catch-all for other known/builtin PG types
             // TODO: improve with more specific/useful classes here?
             case "cidr":
-            case "inet":
             case "macaddr":
             case "macaddr8":
             case "pg_lsn":

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -53,7 +53,7 @@
 public class PostgresSchemaIT {
 
     private static final String[] TEST_TABLES = new String[] { "public.numeric_table", "public.numeric_decimal_table", "public.string_table",
-                                                               "public.cash_table", "public.bitbin_table",
+                                                               "public.cash_table", "public.bitbin_table", "public.network_address_table",
                                                                "public.time_table", "public.text_table", "public.geom_table", "public.tstzrange_table",
                                                                "public.array_table", "\"Quoted_\"\" . Schema\".\"Quoted_\"\" . Table\"",
                                                                "public.custom_table"
@@ -91,6 +91,7 @@ public void shouldLoadSchemaForBuiltinPostgresTypes() throws Exception {
             assertTableSchema("public.string_table", "vc, vcv, ch, c, t, ct",
                               Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA,
                               Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA);
+            assertTableSchema("public.network_address_table", "i", Schema.OPTIONAL_STRING_SCHEMA);
             assertTableSchema("public.cash_table", "csh", Decimal.builder(2).optional().build());
             assertTableSchema("public.bitbin_table", "ba, bol, bs, bv",
                               Schema.OPTIONAL_BYTES_SCHEMA, Schema.OPTIONAL_BOOLEAN_SCHEMA, Bits.builder(2).optional().build(),

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsStreamProducer.java
Patch:
@@ -155,11 +155,11 @@ protected synchronized void commit(long lsn)  {
         LoggingContext.PreviousContext previousContext = taskContext.configureLoggingContext(CONTEXT_NAME);
         try {
             ReplicationStream replicationStream = this.replicationStream.get();
+
             if (replicationStream != null) {
                 if (logger.isDebugEnabled()) {
                     logger.debug("Flushing LSN to server: {}", LogSequenceNumber.valueOf(lsn));
                 }
-
                 // tell the server the point up to which we've processed data, so it can be free to recycle WAL segments
                 replicationStream.flushLsn(lsn);
             }
@@ -249,7 +249,7 @@ private void process(ReplicationMessage message, Long lsn, BlockingConsumer<Chan
         // update the source info with the coordinates for this message
         Instant commitTime = message.getCommitTime();
         long txId = message.getTransactionId();
-        sourceInfo.update(lsn, commitTime, txId, tableId);
+        sourceInfo.update(lsn, commitTime, txId, tableId, taskContext.getSlotXmin());
         if (logger.isDebugEnabled()) {
             logger.debug("received new message at position {}\n{}", ReplicationConnection.format(lsn), message);
         }

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -159,7 +159,7 @@ public final class EmbeddedEngine implements Runnable {
     public static final Field OFFSET_COMMIT_POLICY = Field.create("offset.commit.policy")
                                                           .withDescription("The fully-qualified class name of the commit policy type. This class must implement the interface "
                                                                       + OffsetCommitPolicy.class.getName()
-                                                                      + ". The default is a periodic commity policy based upon time intervals.")
+                                                                      + ". The default is a periodic commit policy based upon time intervals.")
                                                           .withDefault(OffsetCommitPolicy.PeriodicCommitOffsetPolicy.class.getName())
                                                           .withValidation(Field::isClassName);
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -173,7 +173,8 @@ protected DataTypeResolver initializeDataTypeResolver() {
                 new DataTypeEntry(Types.BLOB, MySqlParser.MEDIUMBLOB),
                 new DataTypeEntry(Types.BLOB, MySqlParser.LONGBLOB),
                 new DataTypeEntry(Types.BOOLEAN, MySqlParser.BOOL),
-                new DataTypeEntry(Types.BOOLEAN, MySqlParser.BOOLEAN)
+                new DataTypeEntry(Types.BOOLEAN, MySqlParser.BOOLEAN),
+                new DataTypeEntry(Types.BIGINT, MySqlParser.SERIAL)
         ));
         dataTypeResolverBuilder.registerDataTypes(MySqlParser.CollectionDataTypeContext.class.getCanonicalName(), Arrays.asList(
                 new DataTypeEntry(Types.CHAR, MySqlParser.ENUM).setSuffixTokens(MySqlParser.BINARY),

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsStreamProducer.java
Patch:
@@ -233,6 +233,7 @@ private void process(ReplicationMessage message, Long lsn, BlockingConsumer<Chan
         // in some cases we can get null if PG gives us back a message earlier than the latest reported flushed LSN.
         // WAL2JSON can also send empty changes for DDL, materialized views, etc. and the heartbeat still needs to fire.
         if (message == null) {
+            logger.trace("Received empty message");
             lastCompletelyProcessedLsn = lsn;
             heartbeat.heartbeat(sourceInfo.partition(), sourceInfo.offset(),
                     r -> consumer.accept(new ChangeEvent(r, lsn)));

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/NonStreamingWal2JsonMessageDecoder.java
Patch:
@@ -60,7 +60,7 @@ public void processMessage(ByteBuffer buffer, ReplicationMessageProcessor proces
 
             // WAL2JSON may send empty changes that still have a txid. These events are from things like vacuum,
             // materialized view, DDL, etc. They still need to be processed for the heartbeat to fire.
-            if(changes.isEmpty()) {
+            if (changes.isEmpty()) {
                 processor.process(null);
             }
             else {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/StreamingWal2JsonMessageDecoder.java
Patch:
@@ -236,13 +236,12 @@ private boolean isWhitespace(byte c) {
 
     private void doProcessMessage(ReplicationMessageProcessor processor, TypeRegistry typeRegistry, byte[] content, boolean lastMessage)
             throws IOException, SQLException, InterruptedException {
-        if(content != null) {
+        if (content != null) {
             final Document change = DocumentReader.floatNumbersAsTextReader().read(content);
             LOGGER.trace("Change arrived for decoding {}", change);
             processor.process(new Wal2JsonReplicationMessage(txId, commitTime, change, containsMetadata, lastMessage, typeRegistry));
         }
-        else
-        {
+        else {
             // If content is null then this is an empty change event that WAL2JSON can generate for events like DDL,
             // truncate table, materialized views, etc. The transaction still needs to be processed for the heartbeat
             // to fire.

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleStreamingChangeEventSource.java
Patch:
@@ -70,7 +70,7 @@ public void execute(ChangeEventSourceContext context) throws InterruptedExceptio
                 xsOut.receiveLCRCallback(handler, XStreamOut.DEFAULT_MODE);
             }
         }
-        catch (Exception e) {
+        catch (Throwable e) {
             throw new RuntimeException(e);
         }
         finally {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsStreamProducer.java
Patch:
@@ -241,9 +241,9 @@ private void process(ReplicationMessage message, Long lsn, BlockingConsumer<Chan
         assert tableId != null;
 
         // update the source info with the coordinates for this message
-        long commitTimeNs = message.getCommitTime();
+        long commitTimeMicros = message.getCommitTime();
         long txId = message.getTransactionId();
-        sourceInfo.update(lsn, commitTimeNs, txId, tableId);
+        sourceInfo.update(lsn, commitTimeMicros, txId, tableId);
         if (logger.isDebugEnabled()) {
             logger.debug("received new message at position {}\n{}", ReplicationConnection.format(lsn), message);
         }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/Wal2JsonReplicationMessage.java
Patch:
@@ -13,6 +13,7 @@
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 import java.util.regex.Matcher;
 
 import org.apache.kafka.connect.data.Field;
@@ -85,7 +86,7 @@ public Operation getOperation() {
 
     @Override
     public long getCommitTime() {
-        return commitTime;
+        return TimeUnit.NANOSECONDS.toMicros(commitTime);
     }
 
     @Override

File: debezium-core/src/main/java/io/debezium/pipeline/ChangeEventSourceCoordinator.java
Patch:
@@ -90,7 +90,7 @@ public synchronized <T extends CdcSourceTaskContext> void start(T taskContext, C
                 Thread.interrupted();
                 LOGGER.warn("Change event source executor was interrupted", e);
             }
-            catch (Exception e) {
+            catch (Throwable e) {
                 errorHandler.setProducerThrowable(e);
             }
             finally {

File: debezium-core/src/main/java/io/debezium/relational/HistorizedRelationalSnapshotChangeEventSource.java
Patch:
@@ -164,7 +164,7 @@ public SnapshotResult execute(ChangeEventSourceContext context) throws Interrupt
             snapshotProgressListener.snapshotAborted();
             throw e;
         }
-        catch(Exception e) {
+        catch(Throwable e) {
             snapshotProgressListener.snapshotAborted();
             throw new RuntimeException(e);
         }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsStreamProducer.java
Patch:
@@ -289,6 +289,7 @@ protected void generateCreateRecord(TableId tableId, Object[] rowData, BlockingC
         TableSchema tableSchema = schema().schemaFor(tableId);
         assert tableSchema != null;
         Object key = tableSchema.keyFromColumnData(rowData);
+        logger.trace("key value is: {}", String.valueOf(key));
         Struct value = tableSchema.valueFromColumnData(rowData);
         if (value == null) {
             logger.warn("no values found for table '{}' from create message at '{}'; skipping record" , tableId, sourceInfo);

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcValueConverters.java
Patch:
@@ -1180,9 +1180,12 @@ protected Object convertValue(Column column, Field fieldDefn, Object data, Objec
             final Object schemaDefault = fieldDefn.schema().defaultValue();
             return schemaDefault != null ? schemaDefault : fallback;
         }
+        logger.trace("Value from data object: *** {} ***", data.toString());
 
         final ResultReceiver r = ResultReceiver.create();
         callback.convert(r);
+        logger.trace("Callback toString: {}", callback.toString());
+        logger.trace("Value from ResultReceiver: {}", r.toString());
         return r.hasReceived() ? r.get() : handleUnknownData(column, fieldDefn, data);
     }
 }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnection.java
Patch:
@@ -101,8 +101,8 @@ public void readSchema(Tables tables, String databaseCatalog, String schemaNameP
 
         super.readSchema(tables, null, schemaNamePattern, null, columnFilter, removeTablesNotFoundInJdbc);
 
-        Set<TableId> tableIds = new HashSet<>(tables.tableIds());
-
+        Set<TableId> tableIds = tables.tableIds().stream().filter(x -> schemaNamePattern.equals(x.schema())).collect(Collectors.toSet());
+        
         for (TableId tableId : tableIds) {
             // super.readSchema() populates ids without the catalog; hence we apply the filtering only
             // here and if a table is included, overwrite it with a new id including the catalog

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -494,9 +494,9 @@ protected Object convertBits(Column column, Field fieldDefn, Object data, int nu
     }
 
     protected Object convertMoney(Column column, Field fieldDefn, Object data) {
-        return convertValue(column, fieldDefn, data, BigDecimal.ZERO, (r) -> {
+        return convertValue(column, fieldDefn, data, BigDecimal.ZERO.setScale(2), (r) -> {
             if (data instanceof Double) {
-                r.deliver(BigDecimal.valueOf((Double) data));
+                r.deliver(BigDecimal.valueOf((Double) data).setScale(2));
             }
             else if (data instanceof Number) {
                 // the plugin will return a 64bit signed integer where the last 2 are always decimals

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -460,7 +460,7 @@ protected List<SchemaAndValueField> schemaAndValuesForDateTimeTypesAdaptiveTimeM
     }
 
     protected List<SchemaAndValueField> schemaAndValuesForMoneyTypes() {
-        return Collections.singletonList(new SchemaAndValueField("csh", Decimal.builder(0).optional().build(),
+        return Collections.singletonList(new SchemaAndValueField("csh", Decimal.builder(2).optional().build(),
                                                                  BigDecimal.valueOf(1234.11d)));
     }
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -91,7 +91,7 @@ public void shouldLoadSchemaForBuiltinPostgresTypes() throws Exception {
             assertTableSchema("public.string_table", "vc, vcv, ch, c, t, ct",
                               Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA,
                               Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA);
-            assertTableSchema("public.cash_table", "csh", Decimal.builder(0).optional().build());
+            assertTableSchema("public.cash_table", "csh", Decimal.builder(2).optional().build());
             assertTableSchema("public.bitbin_table", "ba, bol, bs, bv",
                               Schema.OPTIONAL_BYTES_SCHEMA, Schema.OPTIONAL_BOOLEAN_SCHEMA, Bits.builder(2).optional().build(),
                               Bits.builder(2).optional().build());

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -154,7 +154,8 @@ public SchemaBuilder schemaBuilder(Column column) {
             case PgOid.POINT:
                 return Point.builder();
             case PgOid.MONEY:
-                return Decimal.builder(column.scale().get());
+                // Money has always scale 2
+                return Decimal.builder(2);
             case PgOid.NUMERIC:
                 return numericSchema(column);
             case PgOid.BYTEA:

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -487,7 +487,7 @@ protected Object convertBits(Column column, Field fieldDefn, Object data, int nu
     }
 
     protected Object convertMoney(Column column, Field fieldDefn, Object data) {
-        return convertValue(column, fieldDefn, data, 0L, (r) -> {
+        return convertValue(column, fieldDefn, data, BigDecimal.ZERO, (r) -> {
             if (data instanceof Double) {
                 r.deliver(BigDecimal.valueOf((Double) data));
             }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDefaultValuePreConverter.java
Patch:
@@ -13,7 +13,6 @@
 import java.time.Instant;
 import java.time.LocalDate;
 import java.time.LocalDateTime;
-import java.time.LocalTime;
 import java.time.ZoneId;
 import java.time.format.DateTimeFormatter;
 import java.time.format.DateTimeFormatterBuilder;
@@ -152,7 +151,7 @@ private Object convertToTimestamp(Column column, String value) {
      * @return the converted value;
      */
     private Object convertToDuration(Column column, String value) {
-        return Duration.between(LocalTime.MIN, LocalTime.from(timeFormat(column.length()).parse(value)));
+        return MySqlValueConverters.stringToDuration(value);
     }
 
     /**

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnectorTask.java
Patch:
@@ -75,6 +75,9 @@ public void start(Configuration config) {
         final TopicSelector<TableId> topicSelector = SqlServerTopicSelector.defaultSelector(connectorConfig);
         final SchemaNameAdjuster schemaNameAdjuster = SchemaNameAdjuster.create(LOGGER);
 
+        // By default do not load whole result sets into memory
+        config = config.edit().withDefault("database.responseBuffering", "adaptive").withDefault("database.fetchSize", 10000).build();
+
         final Configuration jdbcConfig = config.filter(x -> !(x.startsWith(DatabaseHistory.CONFIGURATION_FIELD_PREFIX_STRING) || x.equals(HistorizedRelationalDatabaseConnectorConfig.DATABASE_HISTORY.name())))
                 .subset("database.", true);
         jdbcConnection = new SqlServerConnection(jdbcConfig);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDefaultValuePreConverter.java
Patch:
@@ -6,6 +6,7 @@
 package io.debezium.connector.mysql;
 
 import java.math.BigDecimal;
+import java.math.RoundingMode;
 import java.sql.Timestamp;
 import java.sql.Types;
 import java.time.Duration;
@@ -193,7 +194,7 @@ private Object convertToDouble(String value) {
      */
     private Object convertToDecimal(Column column, String value) {
         return column.scale().isPresent() ?
-                new BigDecimal(value).setScale(column.scale().get()) :
+                new BigDecimal(value).setScale(column.scale().get(), RoundingMode.HALF_UP) :
                 new BigDecimal(value);
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReaderMetrics.java
Patch:
@@ -149,8 +149,8 @@ public String[] getMonitoredTables() {
     }
 
     @Override
-    public long getSecondsBehindSource() {
-        return getSecondsBehindMaster();
+    public long getMilliSecondsBehindSource() {
+        return getSecondsBehindMaster() * 1000;
     }
 
     @Override

File: debezium-core/src/main/java/io/debezium/pipeline/metrics/StreamingChangeEventSourceMetricsMXBean.java
Patch:
@@ -15,7 +15,7 @@
 public interface StreamingChangeEventSourceMetricsMXBean extends ChangeEventSourceMetricsMXBean {
 
     boolean isConnected();
-    long getSecondsBehindSource();
+    long getMilliSecondsBehindSource();
     long getNumberOfCommittedTransactions();
     Map<String, String> getSourceEventPosition();
     String getLastTransactionId();

File: debezium-core/src/main/java/io/debezium/pipeline/source/spi/EventMetadataProvider.java
Patch:
@@ -5,6 +5,7 @@
  */
 package io.debezium.pipeline.source.spi;
 
+import java.time.Instant;
 import java.util.Map;
 
 import org.apache.kafka.connect.data.Struct;
@@ -22,9 +23,9 @@
 public interface EventMetadataProvider {
 
     /**
-     * @return source event timestamp in milliseconds
+     * @return source event timestamp
      */
-    long getEventTimestamp(DataCollectionId source, OffsetContext offset, Object key, Struct value);
+    Instant getEventTimestamp(DataCollectionId source, OffsetContext offset, Object key, Struct value);
 
     /**
      * @return one or more values uniquely position the event in the transaction log - e.g. LSN

File: debezium-core/src/main/java/io/debezium/connector/base/ChangeEventQueueMetrics.java
Patch:
@@ -9,4 +9,4 @@ public interface ChangeEventQueueMetrics {
 
     int totalCapacity();
     int remainingCapacity();
-}
\ No newline at end of file
+}

File: debezium-core/src/main/java/io/debezium/pipeline/source/spi/EventMetadataProvider.java
Patch:
@@ -40,7 +40,7 @@ public interface EventMetadataProvider {
      * @return s String that describes the event
      */
     default String toSummaryString(DataCollectionId source, OffsetContext offset, Object key, Struct value) {
-        return new EventFromatter()
+        return new EventFormatter()
             .sourcePosition(getEventSourcePosition(source, offset, key, value))
             .key(key)
             .value(value)

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConnection.java
Patch:
@@ -564,7 +564,7 @@ public interface StatementFactory {
      * @throws SQLException if there is an error connecting to the database or executing the statements
      * @see #execute(Operations)
      */
-    public JdbcConnection prepareQuery(String preparedQueryString, StatementPreparer preparer, BlockingResultSetConsumer resultConsumer)
+    public JdbcConnection prepareQueryWithBlockingConsumer(String preparedQueryString, StatementPreparer preparer, BlockingResultSetConsumer resultConsumer)
             throws SQLException, InterruptedException {
         final PreparedStatement statement = createPreparedStatement(preparedQueryString);
         preparer.accept(statement);

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SnapshotIT.java
Patch:
@@ -90,8 +90,8 @@ public void takeSnapshotInSnapshotMode() throws Exception {
     }
 
     @Test
-    public void takeSnapshotInNoneMode() throws Exception {
-        takeSnapshot(SnapshotLockingMode.NONE);
+    public void takeSnapshotInRepeatableReadMode() throws Exception {
+        takeSnapshot(SnapshotLockingMode.REPEATABLE_READ);
     }
 
     private void takeSnapshot(SnapshotLockingMode lockingMode) throws Exception {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlJdbcContext.java
Patch:
@@ -130,7 +130,7 @@ public void start() {
             setSystemProperty("javax.net.ssl.keyStore", MySqlConnectorConfig.SSL_KEYSTORE, true);
             setSystemProperty("javax.net.ssl.keyStorePassword", MySqlConnectorConfig.SSL_KEYSTORE_PASSWORD, false);
             setSystemProperty("javax.net.ssl.trustStore", MySqlConnectorConfig.SSL_TRUSTSTORE, true);
-            setSystemProperty("javax.net.ssl.trustStorePassword", MySqlConnectorConfig.SSL_KEYSTORE_PASSWORD, false);
+            setSystemProperty("javax.net.ssl.trustStorePassword", MySqlConnectorConfig.SSL_TRUSTSTORE_PASSWORD, false);
         }
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -146,7 +146,7 @@ public boolean equals(Object obj) {
      * @param context the task context in which this reader is running; may not be null
      * @param acceptAndContinue see {@link AbstractReader#AbstractReader(String, MySqlTaskContext, Predicate)}
      */
-    public BinlogReader(String name, MySqlTaskContext context, Predicate<SourceRecord> acceptAndContinue) {
+    public BinlogReader(String name, MySqlTaskContext context, HaltingPredicate acceptAndContinue) {
         this(name, context, acceptAndContinue, context.serverId());
     }
 
@@ -158,7 +158,7 @@ public BinlogReader(String name, MySqlTaskContext context, Predicate<SourceRecor
      * @param acceptAndContinue see {@link AbstractReader#AbstractReader(String, MySqlTaskContext, Predicate)}
      * @param serverId the server id to use for the {@link BinaryLogClient}
      */
-    public BinlogReader(String name, MySqlTaskContext context, Predicate<SourceRecord> acceptAndContinue, long serverId) {
+    public BinlogReader(String name, MySqlTaskContext context, HaltingPredicate acceptAndContinue, long serverId) {
         super(name, context, acceptAndContinue);
 
         connectionContext = context.getConnectionContext();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SnapshotReader.java
Patch:
@@ -766,7 +766,7 @@ protected void readBinlogPosition(int step, SourceInfo source, JdbcConnection my
      * @return {@link Filters} that represent all the tables that this snapshot reader should CREATE
      */
     private Filters getCreateTableFilters(Filters filters) {
-        MySqlConnectorConfig.SnapshotNewTables snapshotNewTables = context.snapshotNewTables();
+        MySqlConnectorConfig.SnapshotNewTables snapshotNewTables = context.getConnectorConfig().getSnapshotNewTables();
         if (snapshotNewTables == MySqlConnectorConfig.SnapshotNewTables.PARALLEL) {
             // if we are snapshotting new tables in parallel, we need to make sure all the tables in the configuration
             // are created.

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/ChainedReader.java
Patch:
@@ -118,7 +118,7 @@ public synchronized void stop() {
             Reader current = currentReader.get();
             if (current != null) {
                 try {
-                    logger.info("Stopping the {} reader", current.name());
+                    logger.info("ChainedReader: Stopping the {} reader", current.name());
                     current.stop();
                 } catch (Throwable t) {
                     logger.error("Unexpected error stopping the {} reader", current.name(), t);
@@ -196,7 +196,7 @@ private boolean startNextReader() {
         // There is at least one more reader, so start it ...
         Reader lastReader = currentReader.getAndSet(null);
         if (lastReader != null) {
-            logger.debug("Transitioning from the {} reader to the {} reader", lastReader.name(), reader.name());
+            logger.info("Transitioning from the {} reader to the {} reader", lastReader.name(), reader.name());
         } else {
             logger.debug("Starting the {} reader", reader.name());
         }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -128,6 +128,7 @@ public void shouldFailToValidateInvalidConfiguration() {
         assertNoConfigurationErrors(result, MySqlConnectorConfig.INCLUDE_SCHEMA_CHANGES);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_MODE);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_LOCKING_MODE);
+        assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_NEW_TABLES);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SSL_MODE);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SSL_KEYSTORE);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SSL_KEYSTORE_PASSWORD);
@@ -182,6 +183,7 @@ public void shouldValidateValidConfigurationWithSSL() {
         assertNoConfigurationErrors(result, MySqlConnectorConfig.INCLUDE_SCHEMA_CHANGES);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_MODE);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_LOCKING_MODE);
+        assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_NEW_TABLES);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SSL_MODE);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SSL_KEYSTORE);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SSL_KEYSTORE_PASSWORD);
@@ -232,6 +234,7 @@ public void shouldValidateAcceptableConfiguration() {
         assertNoConfigurationErrors(result, MySqlConnectorConfig.INCLUDE_SCHEMA_CHANGES);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_MODE);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_LOCKING_MODE);
+        assertNoConfigurationErrors(result, MySqlConnectorConfig.SNAPSHOT_NEW_TABLES);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SSL_MODE);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SSL_KEYSTORE);
         assertNoConfigurationErrors(result, MySqlConnectorConfig.SSL_KEYSTORE_PASSWORD);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlTaskContextIT.java
Patch:
@@ -21,7 +21,7 @@ public class MySqlTaskContextIT extends MySqlTaskContextTest {
     @Test
     public void shouldCreateTaskFromConfiguration() throws Exception {
         config = simpleConfig().build();
-        context = new MySqlTaskContext(config);
+        context = new MySqlTaskContext(config, new Filters.Builder(config).build());
         context.start();
         assertThat(context.config()).isSameAs(config);
 
@@ -58,7 +58,7 @@ public void shouldCreateTaskFromConfiguration() throws Exception {
     @Test
     public void shouldCloseJdbcConnectionOnShutdown() throws Exception {
         config = simpleConfig().build();
-        context = new MySqlTaskContext(config);
+        context = new MySqlTaskContext(config, new Filters.Builder(config).build());
         context.start();
 
         // JDBC connection is automatically created by MySqlTaskContext when it reads database variables

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SourceInfo.java
Patch:
@@ -37,6 +37,7 @@ public class SourceInfo extends AbstractSourceInfo {
             .build();
 
     private final String serverName;
+
     private Lsn changeLsn;
     private Lsn commitLsn;
     private boolean snapshot;
@@ -81,7 +82,7 @@ public boolean isSnapshot() {
     }
 
     /**
-     * @param snapshot - true if the source of even is snapshot phase, nto the database log
+     * @param snapshot - true if the source of even is snapshot phase, not the database log
      */
     public void setSnapshot(boolean snapshot) {
         this.snapshot = snapshot;

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerChangeRecordEmitter.java
Patch:
@@ -17,6 +17,7 @@
  * @author Jiri Pechanec
  */
 public class SqlServerChangeRecordEmitter extends RelationalChangeRecordEmitter {
+
     public static final int OP_DELETE = 1;
     public static final int OP_INSERT = 2;
     public static final int OP_UPDATE_BEFORE = 3;

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerDatabaseSchema.java
Patch:
@@ -69,7 +69,7 @@ public Set<TableId> getCapturedTables() {
         return capturedTables;
     }
 
-    private Set<TableId> determineCapturedTables(SqlServerConnectorConfig connectorConfig, SqlServerConnection connection) throws SQLException {
+    private static Set<TableId> determineCapturedTables(SqlServerConnectorConfig connectorConfig, SqlServerConnection connection) throws SQLException {
         final Set<TableId> allTableIds = connection.readTableNames(connectorConfig.getDatabaseName(), null, null, new String[] {"TABLE"} );
 
         final Set<TableId> capturedTables = new HashSet<>();

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerStreamingChangeEventSource.java
Patch:
@@ -215,5 +215,4 @@ public String toString() {
             return "ChangeTable [tableId=" + tableId + ", resultSet=" + resultSet + ", completed=" + completed + "]";
         }
     }
-
 }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SourceInfo.java
Patch:
@@ -8,7 +8,7 @@
 import io.debezium.connector.AbstractSourceInfo;
 
 /**
- * Coordinates from the database log to restart streaming from. Maps to {@code source} field in enevlope and
+ * Coordinates from the database log to restart streaming from. Maps to {@code source} field in envelope and
  * to connector offsets.
  *
  * @author Jiri Pechanec

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerStreamingChangeEventSource.java
Patch:
@@ -155,7 +155,6 @@ private static class ChangeTable {
         private boolean completed = false;
 
         public ChangeTable(TableId tableId, ResultSet resultSet) {
-            super();
             this.tableId = tableId;
             this.resultSet = resultSet;
         }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerTaskContext.java
Patch:
@@ -16,6 +16,6 @@
 public class SqlServerTaskContext extends CdcSourceTaskContext {
 
     public SqlServerTaskContext(SqlServerConnectorConfig config) {
-        super("Oracle", config.getLogicalName());
+        super("SQL Server", config.getLogicalName());
     }
 }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnection.java
Patch:
@@ -90,7 +90,7 @@ public void enableDbCdc(String name) throws SQLException {
      *            the name of the table, may not be {@code null}
      * @throws SQLException if anything unexpected fails
      */
-    public void enableTableCcd(String name) throws SQLException {
+    public void enableTableCdc(String name) throws SQLException {
         Objects.requireNonNull(name);
         String enableCdcForTableStmt = ENABLE_TABLE_CDC.replace(STATEMENTS_PLACEHOLDER, name);
         String generateWrapperFunctionsStmts = CDC_WRAPPERS_DML.replaceAll(STATEMENTS_PLACEHOLDER, name);

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectionIT.java
Patch:
@@ -57,7 +57,7 @@ public void shouldEnableCDCWithWrapperFunctionsForTable() throws Exception {
             connection.execute(sql);
 
             // then enable CDC and wrapper functions
-            connection.enableTableCcd("testTable");
+            connection.enableTableCdc("testTable");
             // insert some data
 
             connection.execute("INSERT INTO testTable (NUMBER, TEXT) values (1, 'aaa')\n"

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -507,8 +507,8 @@ public void shouldRegularlyFlushLsn() throws InterruptedException, SQLException
             }
         }
         // Theoretically the LSN should change for each record but in reality there can be
-        // unfrotunate timings so let's suppose the chane will hapeni in 75 % of cases
-        Assertions.assertThat(flushLsn.size()).isGreaterThan((recordCount * 3) / 4);
+        // unfortunate timings so let's suppose the chane will happen in 75 % of cases
+        Assertions.assertThat(flushLsn.size()).isGreaterThanOrEqualTo((recordCount * 3) / 4);
     }
 
     private String getConfirmedFlushLsn(PostgresConnection connection) throws SQLException {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleValueConverters.java
Patch:
@@ -311,7 +311,7 @@ protected Object convertNumericAsBigInteger(Column column, Field fieldDefn, Obje
 
     @Override
     protected Object convertTinyInt(Column column, Field fieldDefn, Object data) {
-        if (data == null) {
+        if (data == null && !fieldDefn.schema().isOptional()) {
             data = fieldDefn.schema().defaultValue();
         }
         if (data == null) {
@@ -398,7 +398,7 @@ protected Object convertTimestampWithZone(Column column, Field fieldDefn, Object
     }
 
     protected Object convertIntervalYearMonth(Column column, Field fieldDefn, Object data) {
-        if (data == null) {
+        if (data == null && !fieldDefn.schema().isOptional()) {
             data = fieldDefn.schema().defaultValue();
         }
         if (data == null) {
@@ -430,7 +430,7 @@ protected Object convertIntervalYearMonth(Column column, Field fieldDefn, Object
     }
 
     protected Object convertIntervalDaySecond(Column column, Field fieldDefn, Object data) {
-        if (data == null) {
+        if (data == null && !fieldDefn.schema().isOptional()) {
             data = fieldDefn.schema().defaultValue();
         }
         if (data == null) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresConnection.java
Patch:
@@ -85,7 +85,7 @@ public PostgresConnection(Configuration config) {
             typeRegistry = initTypeRegistry(connection());
         }
         catch (SQLException e) {
-            throw new ConnectException("Could not intialize type registry", e);
+            throw new ConnectException("Could not initialize type registry", e);
         }
 
         databaseCharset = determineDatabaseCharset();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlValueConverters.java
Patch:
@@ -539,8 +539,8 @@ protected String convertSetValue(Column column, long indexes, List<String> optio
      */
     protected Object convertPoint(Column column, Field fieldDefn, Object data){
         return convertValue(column, fieldDefn, data, (Supplier<?>)() -> {
-            // we can't create an EMPTY Point because it has X & Y integer fields which can't be null.
-            throw new IllegalArgumentException("Nulls not valid on " + column);
+            final MySqlGeometry empty = MySqlGeometry.createEmpty();
+            return io.debezium.data.geometry.Point.createValue(fieldDefn.schema(), empty.getWkb(), empty.getSrid());
         }, (r) -> {
             if (data instanceof byte[]) {
                 // The binlog utility sends a byte array for any Geometry type, we will use our own binaryParse to parse the byte to WKB, hence

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -654,7 +654,7 @@ else if (data instanceof PGobject) {
      * @return a value which will be used by Connect to represent the actual point value
      */
     protected Object convertPoint(Column column, Field fieldDefn, Object data) {
-        return convertValue(column, fieldDefn, (Supplier<?>)() -> handleUnknownData(column, fieldDefn, data), Collections.emptyList(), (r) -> {
+        return convertValue(column, fieldDefn, data, (Supplier<?>)() -> Point.createValue(fieldDefn.schema(), 0, 0), (r) -> {
             final Schema schema = fieldDefn.schema();
             if (data instanceof PGpoint) {
                 PGpoint pgPoint = (PGpoint) data;

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcValueConverters.java
Patch:
@@ -1159,10 +1159,10 @@ protected Object convertValue(Column column, Field fieldDefn, Object data, Objec
                 return null;
             }
             final Object schemaDefault = fieldDefn.schema().defaultValue();
-            if (schemaDefault instanceof Supplier<?>) {
-                return ((Supplier<?>)schemaDefault).get();
+            if (schemaDefault != null) {
+                return schemaDefault;
             }
-            return schemaDefault != null ? schemaDefault : fallback;
+            return (fallback instanceof Supplier<?>) ? ((Supplier<?>)fallback).get() : fallback;
         }
 
         final ResultReceiver r = ResultReceiver.create();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -730,6 +730,7 @@ protected int getTimePrecision(Column column) {
      * @return the converted value, or null if the conversion could not be made and the column allows nulls
      * @throws IllegalArgumentException if the value could not be converted but the column does not allow nulls
      */
+    @Override
     protected Object convertBinary(Column column, Field fieldDefn, Object data) {
         return super.convertBinary(column, fieldDefn,
                 (data instanceof PGobject) ? ((PGobject)data).getValue() : data);

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleDatabaseSchema.java
Patch:
@@ -30,8 +30,8 @@ public class OracleDatabaseSchema extends HistorizedRelationalDatabaseSchema {
 
     public OracleDatabaseSchema(OracleConnectorConfig connectorConfig, SchemaNameAdjuster schemaNameAdjuster, TopicSelector<TableId> topicSelector, OracleConnection connection) {
         super(connectorConfig, topicSelector, connectorConfig.getTableFilters().dataCollectionFilter(), null,
-                new TableSchemaBuilder(new OracleValueConverters(connection), schemaNameAdjuster, SourceInfo.SCHEMA),
-                false);
+            new TableSchemaBuilder(new OracleValueConverters(connection), schemaNameAdjuster, SourceInfo.SCHEMA),
+            connectorConfig.getTablenameCaseInsensitive());  
     }
 
     @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SourceInfo.java
Patch:
@@ -211,6 +211,7 @@ public void setBinlogStartPoint(String binlogFilename, long positionOfFirstEvent
         this.restartBinlogPosition = positionOfFirstEvent;
         this.currentRowNumber = 0;
         this.restartRowsToSkip = 0;
+        this.restartEventsToSkip = 0;
     }
 
     /**
@@ -224,6 +225,8 @@ public void setEventPosition(long positionOfCurrentEvent, long eventSizeInBytes)
         this.currentEventLengthInBytes = eventSizeInBytes;
         if (!inTransaction) {
             this.restartBinlogPosition = positionOfCurrentEvent + eventSizeInBytes;
+            this.restartRowsToSkip = 0;
+            this.restartEventsToSkip = 0;
         }
         // Don't set anything else, since the row numbers are set in the offset(int,int) method called at least once
         // for each processed event

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -728,8 +728,8 @@ public void shouldConsumeAllEventsFromDatabaseUsingSnapshot() throws SQLExceptio
         } else {
             // the replica is not the same server as the master, so it will have a different binlog filename and position ...
         }
-        // Event number is 2 ...
-        assertThat(persistedOffsetSource.eventsToSkipUponRestart()).isEqualTo(2);
+        // Last event is 'SHOW MASTER STATUS' which will reset the event number to 0 ...
+        assertThat(persistedOffsetSource.eventsToSkipUponRestart()).isEqualTo(0);
         // GTID set should match the before-inserts GTID set ...
         // assertThat(persistedOffsetSource.gtidSet()).isEqualTo(positionBeforeInserts.gtidSet());
 

File: debezium-core/src/test/java/io/debezium/config/ConfigurationTest.java
Patch:
@@ -50,7 +50,7 @@ public void shouldConvertFromProperties() {
     }
 
     @Test
-    public void shoulCreateInternalFields() {
+    public void shouldCreateInternalFields() {
         config = Configuration.create().with(Field.createInternal("a"), "a1").build();
         assertThat(config.getString("internal.a")).isEqualTo("a1");
     }
@@ -130,15 +130,15 @@ public void shouldMaskPasswords() {
      */
     @Test
     @FixFor("DBZ-469")
-    public void defaultDddlFilterShouldFilterOutRdsHeartbeatInsert() {
+    public void defaultDdlFilterShouldFilterOutRdsHeartbeatInsert() {
         String defaultDdlFilter = Configuration.create().build().getString(DatabaseHistory.DDL_FILTER);
         Predicate<String> ddlFilter = Predicates.includes(defaultDdlFilter);
         assertThat(ddlFilter.test("INSERT INTO mysql.rds_heartbeat2(id, value) values (1,1510678117058) ON DUPLICATE KEY UPDATE value = 1510678117058")).isTrue();
     }
 
     @Test
     @FixFor("DBZ-661")
-    public void defaultDddlFilterShouldFilterOutFlushRelayLogs() {
+    public void defaultDdlFilterShouldFilterOutFlushRelayLogs() {
         String defaultDdlFilter = Configuration.create().build().getString(DatabaseHistory.DDL_FILTER);
         Predicate<String> ddlFilter = Predicates.includes(defaultDdlFilter);
         assertThat(ddlFilter.test("FLUSH RELAY LOGS")).isTrue();

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/MongoDataConverterTest.java
Patch:
@@ -158,6 +158,7 @@ public void shouldProcessNullValue() {
             SchemaBuilder.struct().name("withnull")
                 .field("_id", Schema.OPTIONAL_STRING_SCHEMA)
                 .field("delivery", SchemaBuilder.struct().name("withnull.delivery").optional()
+                        .field("hour", Schema.OPTIONAL_STRING_SCHEMA)
                         .field("hourId", Schema.OPTIONAL_INT32_SCHEMA)
                         .build()
                 )

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorRegressionIT.java
Patch:
@@ -549,14 +549,13 @@ public void shouldConsumeAllEventsFromDatabaseUsingSnapshot() throws SQLExceptio
         // Consume all of the events due to startup and initialization of the database
         // ---------------------------------------------------------------------------------------------------------------
         // Testing.Debug.enable();
-        int numCreateDatabase = 1;
         int numTables = 11;
         int numDataRecords = 20;
         int numDdlRecords = numTables * 2 + 3; // for each table (1 drop + 1 create) + for each db (1 create + 1 drop + 1 use)
         int numCreateDefiner = 1;
         int numSetVariables = 1;
         SourceRecords records =
-            consumeRecordsByTopic(numDdlRecords + numSetVariables + numDataRecords + numCreateDefiner + numCreateDatabase);
+            consumeRecordsByTopic(numDdlRecords + numSetVariables + numDataRecords);
         stopConnector();
         assertThat(records).isNotNull();
         assertThat(records.recordsForTopic(DATABASE.getServerName()).size())

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -559,7 +559,7 @@ protected List<SchemaAndValueField> schemasAndValuesForNumericTypesUsingStringEn
 
     protected List<SchemaAndValueField> schemasAndValuesForCustomTypes() {
         return Arrays.asList(new SchemaAndValueField("lt", Schema.OPTIONAL_BYTES_SCHEMA, ByteBuffer.wrap("Top.Collections.Pictures.Astronomy.Galaxies".getBytes())),
-                             new SchemaAndValueField("i", Schema.OPTIONAL_BYTES_SCHEMA, ByteBuffer.wrap("0-393-04002-X".getBytes())),
+                             new SchemaAndValueField("i", Schema.BYTES_SCHEMA, ByteBuffer.wrap("0-393-04002-X".getBytes())),
                              new SchemaAndValueField("n", Schema.OPTIONAL_STRING_SCHEMA, null));
 
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -129,7 +129,7 @@ public void shouldLoadSchemaForExtensionPostgresTypes() throws Exception {
             schema.refresh(connection, false);
             assertTablesIncluded(TEST_TABLES);
             assertTableSchema("public.custom_table", "lt, i",
-                    Schema.OPTIONAL_BYTES_SCHEMA, Schema.OPTIONAL_BYTES_SCHEMA);
+                    Schema.OPTIONAL_BYTES_SCHEMA, Schema.BYTES_SCHEMA);
         }
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -281,8 +281,7 @@ protected void doStart() {
             GtidSet availableServerGtidSet = new GtidSet(availableServerGtidStr);
 
             // also take into account purged GTID logs
-            String purgedServerGtidStr = connectionContext.purgedGtidSet();
-            GtidSet purgedServerGtidSet = new GtidSet(purgedServerGtidStr);
+            GtidSet purgedServerGtidSet = connectionContext.purgedGtidSet();
             logger.info("GTID set purged on server: {}", purgedServerGtidSet);
 
             GtidSet filteredGtidSet = context.filterGtidSet(availableServerGtidSet, purgedServerGtidSet);

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -678,6 +678,7 @@ public OffsetStorageReader offsetStorageReader() {
                                 return offsetReader;
                             }
 
+                            @Override
                             public Map<String, String> configs() {
                                 // TODO Auto-generated method stub
                                 return null;
@@ -901,7 +902,7 @@ public boolean await(long timeout, TimeUnit unit) throws InterruptedException {
 
     @Override
     public String toString() {
-        return "EmbeddedConnector{id=" + config.getString(ENGINE_NAME) + '}';
+        return "EmbeddedEngine{id=" + config.getString(ENGINE_NAME) + '}';
     }
 
     protected static class EmbeddedConfig extends WorkerConfig {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -881,13 +881,13 @@ public static DdlParsingMode parse(String value, String defaultValue) {
 
     public static final Field DDL_PARSER_MODE = Field.create("ddl.parser.mode")
             .withDisplayName("DDL parser mode")
-            .withEnum(DdlParsingMode.class, DdlParsingMode.LEGACY)
+            .withEnum(DdlParsingMode.class, DdlParsingMode.ANTLR)
             .withWidth(Width.SHORT)
             .withImportance(Importance.MEDIUM)
             .withDescription("MySQL DDL statements can be parsed in different ways:" +
-                    "'legacy' (the default) parsing is creating a TokenStream and comparing token by token with an expected values." +
+                    "'legacy' parsing is creating a TokenStream and comparing token by token with an expected values." +
                     "The decisions are made by matched token values." +
-                    "'antlr' uses generated parser from MySQL grammar using ANTLR v4 tool which use ALL(*) algorithm for parsing." +
+                    "'antlr' (the default) uses generated parser from MySQL grammar using ANTLR v4 tool which use ALL(*) algorithm for parsing." +
                     "This parser creates a parsing tree for DDL statement, then walks trough it and apply changes by node types in parsed tree.");
 
     /**

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReaderMetrics.java
Patch:
@@ -64,7 +64,7 @@ public long getSecondsSinceLastEvent() {
     }
 
     @Override
-    public long getTimeSinceLastEvent() {
+    public long getMilliSecondsSinceLastEvent() {
         return this.stats.getSecondsSinceLastEvent() * 1000;
     }
 

File: debezium-core/src/main/java/io/debezium/pipeline/EventDispatcher.java
Patch:
@@ -105,12 +105,12 @@ public SnapshotReceiver getSnapshotChangeEventReceiver() {
      * {@link ChangeEventCreator} for converting them into data change events.
      */
     public void dispatchDataChangeEvent(T dataCollectionId, ChangeRecordEmitter changeRecordEmitter) throws InterruptedException {
+        eventListener.onEvent();
 
         if(!filter.isIncluded(dataCollectionId)) {
             LOGGER.trace("Skipping data change event for {}", dataCollectionId);
         }
         else {
-            eventListener.onEvent();
             DataCollectionSchema dataCollectionSchema = schema.schemaFor(dataCollectionId);
 
             // TODO handle as per inconsistent schema info option

File: debezium-core/src/main/java/io/debezium/pipeline/metrics/ChangeEventSourceMetricsMXBean.java
Patch:
@@ -9,12 +9,11 @@
  * Metrics that are common for both snapshot and streaming change event sources
  *
  * @author Jiri Pechanec
- *
  */
 public interface ChangeEventSourceMetricsMXBean {
 
     String getLastEvent();
-    long getTimeSinceLastEvent();
+    long getMilliSecondsSinceLastEvent();
     long getTotalNumberOfEventsSeen();
     String[] getMonitoredTables();
     void reset();

File: debezium-core/src/main/java/io/debezium/pipeline/metrics/StreamingChangeEventSourceMetricsMXBean.java
Patch:
@@ -6,8 +6,9 @@
 package io.debezium.pipeline.metrics;
 
 /**
- * @author Randall Hauch, Jiri Pechanec
+ * Metrics specific to streaming change event sources
  *
+ * @author Randall Hauch, Jiri Pechanec
  */
 public interface StreamingChangeEventSourceMetricsMXBean extends ChangeEventSourceMetricsMXBean {
 

File: debezium-core/src/main/java/io/debezium/pipeline/source/spi/DataChangeEventListener.java
Patch:
@@ -5,6 +5,8 @@
  */
 package io.debezium.pipeline.source.spi;
 
+import io.debezium.pipeline.EventDispatcher;
+
 /**
  * A class invoked by {@link EventDispatcher} whenever an event is available for processing.
  *
@@ -13,6 +15,7 @@
  */
 public interface DataChangeEventListener {
 
+    // TODO DBZ-978 pass representation of incoming event
     void onEvent();
 
     static DataChangeEventListener NO_OP = () -> {};

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/transforms/UnwrapFromMongoDbEnvelope.java
Patch:
@@ -88,9 +88,9 @@ public static ArrayEncoding parse(String value, String defaultValue) {
             .withEnum(ArrayEncoding.class, ArrayEncoding.ARRAY)
             .withWidth(ConfigDef.Width.SHORT)
             .withImportance(ConfigDef.Importance.MEDIUM)
-            .withDescription("The arrays can be encoded using 'array' schema type (the default) ar as a 'struct' (similar to how BSON encodes arrays). "
+            .withDescription("The arrays can be encoded using 'array' schema type (the default) or as a 'document' (similar to how BSON encodes arrays). "
                     + "'array' is easier to consume but requires all elements in the array to be of the same type. "
-                    + "Use 'struct' if the arrays in data source mix different types together.");
+                    + "Use 'document' if the arrays in data source mix different types together.");
 
     private static final Field FLATTEN_STRUCT = Field.create("flatten.struct")
             .withDisplayName("Flatten struct")

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -19,7 +19,6 @@
 import java.util.concurrent.TimeUnit;
 import java.util.function.Consumer;
 
-import io.debezium.relational.Table;
 import org.apache.commons.lang3.RandomStringUtils;
 import org.apache.kafka.connect.data.Decimal;
 import org.apache.kafka.connect.data.SchemaBuilder;
@@ -40,6 +39,7 @@
 import io.debezium.heartbeat.Heartbeat;
 import io.debezium.junit.ConditionalFail;
 import io.debezium.junit.ShouldFailWhen;
+import io.debezium.relational.Table;
 import io.debezium.relational.TableId;
 import io.debezium.schema.TopicSelector;
 
@@ -835,7 +835,7 @@ public void shouldNotRefreshSchemaOnUnchangedToastedData() throws Exception {
         );
         assertRecordSchemaAndValues(expectedAfter, record, Envelope.FieldName.AFTER);
 
-        // now we add another column and update the not_toast column to see that our unchanged toast data
+        // now we remove the toast column and update the not_toast column to see that our unchanged toast data
         // does not trigger a table schema refresh. the after schema should look the same as before.
         statement = "ALTER TABLE test_table DROP COLUMN text; update test_table set not_toast = 5 where not_toast = 10";
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -694,7 +694,7 @@ public void shouldReceiveHStoreTypeWithSpecialValuesInJsonString() throws Except
         setupRecordsProducer(config);
         TestHelper.executeDDL("postgres_create_tables.ddl");
         consumer = testConsumer(1);
-        recordsProducer.start(consumer,blackHole);
+        recordsProducer.start(consumer, blackHole);
 
         assertInsert(INSERT_HSTORE_TYPE_WITH_SPECIAL_CHAR_STMT, schemaAndValueFieldForJsonEncodedHStoreTypeWithSpcialCharacters());
     }
@@ -708,7 +708,7 @@ public void shouldReceiveHStoreTypeWithNullValuesAsJsonString() throws Exception
         setupRecordsProducer(config);
         TestHelper.executeDDL("postgres_create_tables.ddl");
         consumer = testConsumer(1);
-        recordsProducer.start(consumer,blackHole);
+        recordsProducer.start(consumer, blackHole);
 
         assertInsert(INSERT_HSTORE_TYPE_WITH_NULL_VALUES_STMT, schemaAndValueFieldForJsonEncodedHStoreTypeWithNullValues());
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SnapshotWithOverridesProducerIT.java
Patch:
@@ -56,7 +56,7 @@ public void before(Configuration overrides) throws SQLException {
         TopicSelector<TableId> selector = PostgresTopicSelector.create(config);
         context = new PostgresTaskContext(
                 config,
-                new PostgresSchema(config, TestHelper.getTypeRegistry(), selector),
+                TestHelper.getSchema(config),
                 selector
         );
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -139,7 +139,7 @@ public abstract class AbstractRecordsProducerTest {
     protected static final String INSERT_CUSTOM_TYPES_STMT = "INSERT INTO custom_table (lt, i, n, ct) " +
             "VALUES ('Top.Collections.Pictures.Astronomy.Galaxies', '978-0-393-04002-9', NULL, 'Hello World')";
 
-    protected static final String INSERT_HSTORE_TYPE_STMT = "INSERT INTO hstore_table (hs) VALUES ('\"key\" => \"val\"')";
+    protected static final String INSERT_HSTORE_TYPE_STMT = "INSERT INTO hstore_table (hs) VALUES ('\"key\" => \"val\"'::hstore)";
 
     protected static final String INSERT_HSTORE_TYPE_WITH_MULTIPLE_VALUES_STMT = "INSERT INTO hstore_table_mul (hs) VALUES ('\"key1\" => \"val1\",\"key2\" => \"val2\",\"key3\" => \"val3\"')";
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSchema.java
Patch:
@@ -59,7 +59,7 @@ protected PostgresSchema(PostgresConnectorConfig config, TypeRegistry typeRegist
 
     private static TableSchemaBuilder getTableSchemaBuilder(PostgresConnectorConfig config, TypeRegistry typeRegistry) {
         PostgresValueConverter valueConverter = new PostgresValueConverter(config.decimalHandlingMode(), config.temporalPrecisionMode(),
-                ZoneOffset.UTC, null, config.includeUnknownDatatypes(), typeRegistry);
+                ZoneOffset.UTC, null, config.includeUnknownDatatypes(), typeRegistry,config.hStoreHandlingMode());
 
         return new TableSchemaBuilder(valueConverter, SchemaNameAdjuster.create(LOGGER), SourceInfo.SCHEMA);
     }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoReplicationMessage.java
Patch:
@@ -251,7 +251,6 @@ else if (datumMessage.hasDatumString()) {
                 if (type.getOid() == typeRegistry.geometryArrayOid() || type.getOid() == typeRegistry.geographyArrayOid() || type.getOid() == typeRegistry.citextArrayOid() ) {
                     return getArray(datumMessage, connection, columnType);
                 }
-
                 // unknown data type is sent by decoder as binary value
                 if (includeUnknownDatatypes && datumMessage.hasDatumBytes()) {
                     return datumMessage.getDatumBytes().toByteArray();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/Wal2JsonReplicationMessage.java
Patch:
@@ -193,14 +193,16 @@ public Object getValue(String columnName, PostgresType type, String fullType, Va
             }
             return null;
         }
-
         switch (type.getName()) {
             // include all types from https://www.postgresql.org/docs/current/static/datatype.html#DATATYPE-TABLE
             // plus aliases from the shorter names produced by older wal2json
             case "boolean":
             case "bool":
                 return rawValue.asBoolean();
 
+            case "hstore":
+                return rawValue.asString();
+
             case "integer":
             case "int":
             case "int4":

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -677,6 +677,7 @@ public String getPostgresPluginName() {
     public static final Field TCP_KEEPALIVE = Field.create(DATABASE_CONFIG_PREFIX + "tcpKeepAlive")
             .withDisplayName("TCP keep-alive probe")
             .withType(Type.BOOLEAN)
+            .withDefault(true)
             .withWidth(Width.SHORT)
             .withImportance(Importance.MEDIUM)
             .withDescription("Enable or disable TCP keep-alive probe to avoid dropping TCP connection")

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -149,7 +149,7 @@ public void shouldValidateConfiguration() throws Exception {
         validateField(validatedConfig, PostgresConnectorConfig.TIME_PRECISION_MODE, TemporalPrecisionMode.ADAPTIVE);
         validateField(validatedConfig, PostgresConnectorConfig.DECIMAL_HANDLING_MODE, PostgresConnectorConfig.DecimalHandlingMode.PRECISE);
         validateField(validatedConfig, PostgresConnectorConfig.SSL_SOCKET_FACTORY, null);
-        validateField(validatedConfig, PostgresConnectorConfig.TCP_KEEPALIVE, null);
+        validateField(validatedConfig, PostgresConnectorConfig.TCP_KEEPALIVE, true);
    }
 
     @Test

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -69,6 +69,7 @@ public void before() throws Exception {
         TestHelper.execute(statements);
         PostgresConnectorConfig config = new PostgresConnectorConfig(TestHelper.defaultConfig()
                 .with(PostgresConnectorConfig.INCLUDE_UNKNOWN_DATATYPES, true)
+                .with(PostgresConnectorConfig.SCHEMA_BLACKLIST, "postgis")
                 .build());
         setupRecordsProducer(config);
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -758,7 +758,7 @@ protected void clear() {
 
         protected void await(long timeout, TimeUnit unit) throws InterruptedException {
             if (!latch.await(timeout, unit)) {
-                fail("Consumer is stil expecting " + latch.getCount() + " records, as it received only " + records.size());
+                fail("Consumer is still expecting " + latch.getCount() + " records, as it received only " + records.size());
             }
         }
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsSnapshotProducerIT.java
Patch:
@@ -178,6 +178,7 @@ public void shouldGenerateSnapshotAndContinueStreaming() throws Exception {
     }
 
     @Test
+    @FixFor("DBZ-859")
     public void shouldGenerateSnapshotAndSendHeartBeat() throws Exception {
         // PostGIS must not be used
         TestHelper.dropAllSchemas();
@@ -197,7 +198,7 @@ public void shouldGenerateSnapshotAndSendHeartBeat() throws Exception {
                 selector
         );
 
-        snapshotProducer = new RecordsSnapshotProducer(context, new SourceInfo(TestHelper.TEST_SERVER), true);
+        snapshotProducer = new RecordsSnapshotProducer(context, new SourceInfo(TestHelper.TEST_SERVER, TestHelper.TEST_DATABASE), true);
         TestConsumer consumer = testConsumer(2);
         snapshotProducer.start(consumer, e -> {});
 

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsStreamProducerIT.java
Patch:
@@ -728,6 +728,7 @@ private void assertInsert(String statement, int pk, List<SchemaAndValueField> ex
             executeAndWait(statement);
             SourceRecord record = assertRecordInserted(expectedTopicName, PK_FIELD, pk);
             assertRecordOffset(record, false, false);
+            assertSourceInfo(record, "postgres", table.schema(), table.table());
             assertRecordSchemaAndValues(expectedSchemaAndValuesByColumn, record, Envelope.FieldName.AFTER);
         } catch (Exception e) {
             throw new RuntimeException(e);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SourceInfoTest.java
Patch:
@@ -7,6 +7,7 @@
 
 import static org.fest.assertions.Assertions.assertThat;
 
+import io.debezium.relational.TableId;
 import org.junit.Before;
 import org.junit.Test;
 
@@ -23,6 +24,7 @@ public class SourceInfoTest {
     @Before
     public void beforeEach() {
         source = new SourceInfo("serverX", "databaseX");
+        source.update(1L, new TableId("catalogNameX", "schemaNameX", "tableNameX"));
     }
 
     @Test

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -364,7 +364,7 @@ protected boolean isGtidModeEnabled() {
         try {
             connectionContext.jdbc().query("SHOW GLOBAL VARIABLES LIKE 'GTID_MODE'", rs -> {
                 if (rs.next()) {
-                    mode.set(rs.getString(1));
+                    mode.set(rs.getString(2));
                 }
             });
         } catch (SQLException e) {

File: debezium-core/src/main/java/io/debezium/relational/history/KafkaDatabaseHistory.java
Patch:
@@ -251,11 +251,10 @@ protected void recoverRecords(Consumer<HistoryRecord> records) {
                 }
                 if (numRecordsProcessed == 0) {
                     logger.debug("No new records found in the database history; will retry");
+                    recoveryAttempts++;
                 } else {
                     logger.debug("Processed {} records from database history", numRecordsProcessed);
                 }
-
-                recoveryAttempts++;
             }
             while (lastProcessedOffset < endOffset - 1);
         }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorConfig.java
Patch:
@@ -168,7 +168,7 @@ public static enum SnapshotMode implements EnumeratedValue {
         INITIAL("initial", true),
 
         /**
-         * Perform a snapshot of data and schema upon initial startup of a connector.
+         * Perform a snapshot of the schema but no data upon initial startup of a connector.
          */
         INITIAL_SCHEMA_ONLY("initial_schema_only", false);
 

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SourceInfo.java
Patch:
@@ -37,6 +37,7 @@ public class SourceInfo extends AbstractSourceInfo {
             .build();
 
     private final String serverName;
+
     private Lsn changeLsn;
     private Lsn commitLsn;
     private boolean snapshot;
@@ -81,7 +82,7 @@ public boolean isSnapshot() {
     }
 
     /**
-     * @param snapshot - true if the source of even is snapshot phase, nto the database log
+     * @param snapshot - true if the source of even is snapshot phase, not the database log
      */
     public void setSnapshot(boolean snapshot) {
         this.snapshot = snapshot;

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerChangeRecordEmitter.java
Patch:
@@ -17,6 +17,7 @@
  * @author Jiri Pechanec
  */
 public class SqlServerChangeRecordEmitter extends RelationalChangeRecordEmitter {
+
     public static final int OP_DELETE = 1;
     public static final int OP_INSERT = 2;
     public static final int OP_UPDATE_BEFORE = 3;

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerDatabaseSchema.java
Patch:
@@ -69,7 +69,7 @@ public Set<TableId> getCapturedTables() {
         return capturedTables;
     }
 
-    private Set<TableId> determineCapturedTables(SqlServerConnectorConfig connectorConfig, SqlServerConnection connection) throws SQLException {
+    private static Set<TableId> determineCapturedTables(SqlServerConnectorConfig connectorConfig, SqlServerConnection connection) throws SQLException {
         final Set<TableId> allTableIds = connection.readTableNames(connectorConfig.getDatabaseName(), null, null, new String[] {"TABLE"} );
 
         final Set<TableId> capturedTables = new HashSet<>();

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerStreamingChangeEventSource.java
Patch:
@@ -215,5 +215,4 @@ public String toString() {
             return "ChangeTable [tableId=" + tableId + ", resultSet=" + resultSet + ", completed=" + completed + "]";
         }
     }
-
 }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SourceInfo.java
Patch:
@@ -8,7 +8,7 @@
 import io.debezium.connector.AbstractSourceInfo;
 
 /**
- * Coordinates from the database log to restart streaming from. Maps to {@code source} field in enevlope and
+ * Coordinates from the database log to restart streaming from. Maps to {@code source} field in envelope and
  * to connector offsets.
  *
  * @author Jiri Pechanec

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerStreamingChangeEventSource.java
Patch:
@@ -155,7 +155,6 @@ private static class ChangeTable {
         private boolean completed = false;
 
         public ChangeTable(TableId tableId, ResultSet resultSet) {
-            super();
             this.tableId = tableId;
             this.resultSet = resultSet;
         }

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerTaskContext.java
Patch:
@@ -16,6 +16,6 @@
 public class SqlServerTaskContext extends CdcSourceTaskContext {
 
     public SqlServerTaskContext(SqlServerConnectorConfig config) {
-        super("Oracle", config.getLogicalName());
+        super("SQL Server", config.getLogicalName());
     }
 }

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/SourceInfo.java
Patch:
@@ -16,7 +16,7 @@ public class SourceInfo extends AbstractSourceInfo {
 
     public static final String SERVER_NAME_KEY = "name";
     public static final String TXID_KEY = "txId";
-    public static final String TIMESTAMP_KEY = "ts_sec";
+    public static final String TIMESTAMP_KEY = "ts_ms";
     public static final String SCN_KEY = "scn";
     public static final String SNAPSHOT_KEY = "snapshot";
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleChangeEventSourceFactory.java
Patch:
@@ -11,19 +11,20 @@
 import io.debezium.pipeline.source.spi.SnapshotChangeEventSource;
 import io.debezium.pipeline.source.spi.StreamingChangeEventSource;
 import io.debezium.pipeline.spi.OffsetContext;
+import io.debezium.relational.TableId;
 import io.debezium.util.Clock;
 
 public class OracleChangeEventSourceFactory implements ChangeEventSourceFactory {
 
     private final OracleConnectorConfig configuration;
     private final OracleConnection jdbcConnection;
     private final ErrorHandler errorHandler;
-    private final EventDispatcher dispatcher;
+    private final EventDispatcher<TableId> dispatcher;
     private final Clock clock;
     private final OracleDatabaseSchema schema;
 
     public OracleChangeEventSourceFactory(OracleConnectorConfig configuration, OracleConnection jdbcConnection,
-            ErrorHandler errorHandler, EventDispatcher dispatcher, Clock clock, OracleDatabaseSchema schema) {
+            ErrorHandler errorHandler, EventDispatcher<TableId> dispatcher, Clock clock, OracleDatabaseSchema schema) {
         this.configuration = configuration;
         this.jdbcConnection = jdbcConnection;
         this.errorHandler = errorHandler;

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorTask.java
Patch:
@@ -89,7 +89,7 @@ public void start(Configuration config) {
         }
 
         EventDispatcher<TableId> dispatcher = new EventDispatcher<>(topicSelector, schema, queue,
-                connectorConfig.getTableFilters().dataCollectionFilter());
+                connectorConfig.getTableFilters().dataCollectionFilter(), DataChangeEvent::new);
 
         coordinator = new ChangeEventSourceCoordinator(
                 previousOffset,

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleStreamingChangeEventSource.java
Patch:
@@ -14,6 +14,7 @@
 import io.debezium.pipeline.ErrorHandler;
 import io.debezium.pipeline.EventDispatcher;
 import io.debezium.pipeline.source.spi.StreamingChangeEventSource;
+import io.debezium.relational.TableId;
 import io.debezium.util.Clock;
 import oracle.jdbc.OracleConnection;
 import oracle.sql.NUMBER;
@@ -32,15 +33,15 @@ public class OracleStreamingChangeEventSource implements StreamingChangeEventSou
     private static final Logger LOGGER = LoggerFactory.getLogger(OracleStreamingChangeEventSource.class);
 
     private final JdbcConnection jdbcConnection;
-    private final EventDispatcher<?> dispatcher;
+    private final EventDispatcher<TableId> dispatcher;
     private final ErrorHandler errorHandler;
     private final Clock clock;
     private final OracleDatabaseSchema schema;
     private final OracleOffsetContext offsetContext;
     private final String xStreamServerName;
     private volatile XStreamOut xsOut;
 
-    public OracleStreamingChangeEventSource(OracleConnectorConfig connectorConfig, OracleOffsetContext offsetContext, JdbcConnection jdbcConnection, EventDispatcher<?> dispatcher, ErrorHandler errorHandler, Clock clock, OracleDatabaseSchema schema) {
+    public OracleStreamingChangeEventSource(OracleConnectorConfig connectorConfig, OracleOffsetContext offsetContext, JdbcConnection jdbcConnection, EventDispatcher<TableId> dispatcher, ErrorHandler errorHandler, Clock clock, OracleDatabaseSchema schema) {
         this.jdbcConnection = jdbcConnection;
         this.dispatcher = dispatcher;
         this.errorHandler = errorHandler;

File: debezium-connector-sqlserver/src/main/java/io/debezium/connector/sqlserver/SqlServerConnection.java
Patch:
@@ -90,7 +90,7 @@ public void enableDbCdc(String name) throws SQLException {
      *            the name of the table, may not be {@code null}
      * @throws SQLException if anything unexpected fails
      */
-    public void enableTableCcd(String name) throws SQLException {
+    public void enableTableCdc(String name) throws SQLException {
         Objects.requireNonNull(name);
         String enableCdcForTableStmt = ENABLE_TABLE_CDC.replace(STATEMENTS_PLACEHOLDER, name);
         String generateWrapperFunctionsStmts = CDC_WRAPPERS_DML.replaceAll(STATEMENTS_PLACEHOLDER, name);

File: debezium-connector-sqlserver/src/test/java/io/debezium/connector/sqlserver/SqlServerConnectionIT.java
Patch:
@@ -57,7 +57,7 @@ public void shouldEnableCDCWithWrapperFunctionsForTable() throws Exception {
             connection.execute(sql);
 
             // then enable CDC and wrapper functions
-            connection.enableTableCcd("testTable");
+            connection.enableTableCdc("testTable");
             // insert some data
 
             connection.execute("INSERT INTO testTable (NUMBER, TEXT) values (1, 'aaa')\n"

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/AlterTableParserListener.java
Patch:
@@ -169,7 +169,7 @@ public void exitAlterByChangeColumn(MySqlParser.AlterByChangeColumnContext ctx)
             Column column = columnDefinitionListener.getColumn();
             tableEditor.addColumn(column);
             String newColumnName = parser.parseName(ctx.newColumn);
-            if (newColumnName != null && column.name().compareToIgnoreCase(newColumnName) != 0) {
+            if (newColumnName != null && !column.name().equalsIgnoreCase(newColumnName)) {
                 tableEditor.renameColumn(column.name(), newColumnName);
             }
 

File: debezium-core/src/main/java/io/debezium/relational/mapping/AddOriginalDataType.java
Patch:
@@ -17,6 +17,7 @@ public ValueConverter create(Column column) {
 
     @Override
     public void alterFieldSchema(Column column, SchemaBuilder schemaBuilder) {
-       schemaBuilder.parameter("originalType", column.typeName().toUpperCase());
+       schemaBuilder.parameter("originalType", String.valueOf(column.jdbcType()));
+       schemaBuilder.parameter("columnSize", String.valueOf(column.length()));
     }
 }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/Filters.java
Patch:
@@ -99,6 +99,7 @@ public Filters(Configuration config) {
         ColumnMappers.Builder columnMapperBuilder = ColumnMappers.create();
         config.forEachMatchingFieldNameWithInteger("column\\.truncate\\.to\\.(\\d+)\\.chars", columnMapperBuilder::truncateStrings);
         config.forEachMatchingFieldNameWithInteger("column\\.mask\\.with\\.(\\d+)\\.chars", columnMapperBuilder::maskStrings);
+        config.forEachMatchingFieldName("column\\.add\\.original\\.type", columnMapperBuilder::addOriginalType);
         this.columnMappers = columnMapperBuilder.build();
     }
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MysqlDefaultValueIT.java
Patch:
@@ -509,9 +509,8 @@ public void dateAndTimeTest() throws InterruptedException {
         assertThat(schemaI.defaultValue()).isEqualTo(82800123456L);
 
         //current timestamp will be replaced with epoch timestamp
-        String value5 = "1970-01-01 00:00:00";
-        ZonedDateTime t5 = java.sql.Timestamp.valueOf(value5).toInstant().atZone(ZoneId.systemDefault());
-        String isoString5 = ZonedTimestamp.toIsoString(t5, ZoneId.systemDefault(), MySqlValueConverters::adjustTemporal);
+        ZonedDateTime t5 = ZonedDateTime.ofInstant(Instant.EPOCH, ZoneOffset.UTC);
+        String isoString5 = ZonedTimestamp.toIsoString(t5, ZoneOffset.UTC, MySqlValueConverters::adjustTemporal);
         assertThat(schemaJ.defaultValue()).isEqualTo(isoString5);
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -294,7 +294,8 @@ public void runIfNotNull(Runnable function, Object... nullableObjects) {
      */
     public static List<String> parseSetAndEnumOptions(String typeExpression) {
         List<String> options = new ArrayList<>();
-        if (typeExpression.startsWith("ENUM") || typeExpression.startsWith("SET")) {
+        final String ucTypeExpression = typeExpression.toUpperCase();
+        if (ucTypeExpression.startsWith("ENUM") || ucTypeExpression.startsWith("SET")) {
             Pattern pattern = Pattern.compile("['\"][a-zA-Z0-9-!$%^&*()_+|~=`{}\\[\\]:\";'<>?\\/\\\\ ]*['\"]");
             Matcher matcher = pattern.matcher(typeExpression);
             while (matcher.find()) {

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDdlParserTest.java
Patch:
@@ -1105,6 +1105,7 @@ public void shouldParseTicketMonsterLiquibaseStatements() {
     @Test
     public void shouldParseEnumOptions() {
         assertParseEnumAndSetOptions("ENUM('a','b','c')", "a,b,c");
+        assertParseEnumAndSetOptions("enum('a','b','c')", "a,b,c");
         assertParseEnumAndSetOptions("ENUM('a','multi','multi with () paren', 'other')", "a,multi,multi with () paren,other");
         assertParseEnumAndSetOptions("ENUM('a')", "a");
         assertParseEnumAndSetOptions("ENUM()", "");
@@ -1125,6 +1126,7 @@ public void shouldParseEscapedEnumOptions() {
    @Test
     public void shouldParseSetOptions() {
         assertParseEnumAndSetOptions("SET('a','b','c')", "a,b,c");
+        assertParseEnumAndSetOptions("set('a','b','c')", "a,b,c");
         assertParseEnumAndSetOptions("SET('a','multi','multi with () paren', 'other')", "a,multi,multi with () paren,other");
         assertParseEnumAndSetOptions("SET('a')", "a");
         assertParseEnumAndSetOptions("SET()", "");

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/AlterTableParserListener.java
Patch:
@@ -51,7 +51,7 @@ public void enterAlterTable(MySqlParser.AlterTableContext ctx) {
         tableEditor = parser.databaseTables().editTable(tableId);
         if (tableEditor == null) {
             throw new ParsingException(null, "Trying to alter table " + tableId.toString()
-                    + ", which does not exists. Query: " + getText(ctx));
+                    + ", which does not exist. Query: " + getText(ctx));
         }
         super.enterAlterTable(ctx);
     }
@@ -149,7 +149,7 @@ public void enterAlterByChangeColumn(MySqlParser.AlterByChangeColumnContext ctx)
             }
             else {
                 throw new ParsingException(null, "Trying to change column " + oldColumnName + " in "
-                        + tableEditor.tableId().toString() + " table, which does not exists. Query: " + getText(ctx));
+                        + tableEditor.tableId().toString() + " table, which does not exist. Query: " + getText(ctx));
             }
         }, tableEditor);
         super.enterAlterByChangeColumn(ctx);
@@ -186,7 +186,7 @@ public void enterAlterByModifyColumn(MySqlParser.AlterByModifyColumnContext ctx)
             }
             else {
                 throw new ParsingException(null, "Trying to change column " + columnName + " in "
-                        + tableEditor.tableId().toString() + " table, which does not exists. Query: " + getText(ctx));
+                        + tableEditor.tableId().toString() + " table, which does not exist. Query: " + getText(ctx));
             }
         }, tableEditor);
         super.enterAlterByModifyColumn(ctx);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -127,8 +127,8 @@ public void shouldLoadSchemaForExtensionPostgresTypes() throws Exception {
         try (PostgresConnection connection = TestHelper.create()) {
             schema.refresh(connection, false);
             assertTablesIncluded(TEST_TABLES);
-            assertTableSchema("public.custom_table", "lt, i",
-                    Schema.OPTIONAL_BYTES_SCHEMA, Schema.OPTIONAL_BYTES_SCHEMA);
+            assertTableSchema("public.custom_table", "lt, i, ct",
+                    Schema.OPTIONAL_BYTES_SCHEMA, Schema.OPTIONAL_BYTES_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA);
         }
     }
 

File: debezium-core/src/main/java/io/debezium/document/BinaryValue.java
Patch:
@@ -38,8 +38,8 @@ public boolean equals(Object obj) {
         if (obj instanceof Value) {
             Value that = (Value) obj;
             if (that.isNull()) return false;
-            if (that.isBinary()) return this.value.equals(that.asBytes());
-            if (that.isString()) return this.value.equals(that.asString().getBytes());
+            if (that.isBinary()) return Arrays.equals(this.value, that.asBytes());
+            if (that.isString()) return Arrays.equals(this.value, that.asString().getBytes());
             return false;
         }
         return false;

File: debezium-core/src/main/java/io/debezium/document/BinaryValue.java
Patch:
@@ -8,6 +8,8 @@
 import java.math.BigDecimal;
 import java.math.BigInteger;
 
+import java.util.Arrays;
+
 import io.debezium.annotation.Immutable;
 
 /**
@@ -27,7 +29,7 @@ final class BinaryValue implements Value {
 
     @Override
     public int hashCode() {
-        return value.hashCode();
+        return Arrays.hashCode(this.value);
     }
 
     @Override

File: debezium-core/src/main/java/io/debezium/relational/ColumnImpl.java
Patch:
@@ -145,7 +145,7 @@ public boolean equals(Object obj) {
                     Strings.equalsIgnoreCase(this.charsetName(),that.charsetName()) &&
                     this.position() == that.position() &&
                     this.length() == that.length() &&
-                    this.scale() == that.scale() &&
+                    this.scale().equals(that.scale()) &&
                     this.isOptional() == that.isOptional() &&
                     this.isAutoIncremented() == that.isAutoIncremented() &&
                     this.isGenerated() == that.isGenerated() &&

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorFilterIT.java
Patch:
@@ -10,6 +10,7 @@
 import java.math.BigDecimal;
 import java.sql.SQLException;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
@@ -48,6 +49,7 @@ public static void closeConnection() throws SQLException {
 
     @Before
     public void before() throws SQLException {
+        setConsumeTimeout(TestHelper.defaultMessageConsumerPollTimeout(), TimeUnit.SECONDS);
         TestHelper.dropTable(connection, "debezium.table1");
         TestHelper.dropTable(connection, "debezium.table2");
         TestHelper.dropTable(connection, "debezium.table3");

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleConnectorIT.java
Patch:
@@ -65,6 +65,7 @@ public static void closeConnection() throws SQLException {
 
     @Before
     public void before() {
+        setConsumeTimeout(TestHelper.defaultMessageConsumerPollTimeout(), TimeUnit.SECONDS);
         initializeConnectorTestFramework();
         Testing.Files.delete(TestHelper.DB_HISTORY_PATH);
     }

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/SnapshotDatatypesIT.java
Patch:
@@ -6,6 +6,7 @@
 package io.debezium.connector.oracle;
 
 import java.sql.SQLException;
+import java.util.concurrent.TimeUnit;
 
 import org.junit.Before;
 import org.junit.BeforeClass;
@@ -28,6 +29,7 @@ public static void beforeClass() throws SQLException {
 
     @Before
     public void before() throws Exception {
+        setConsumeTimeout(TestHelper.defaultMessageConsumerPollTimeout(), TimeUnit.SECONDS);
         initializeConnectorTestFramework();
         Testing.Debug.enable();
         Testing.Files.delete(TestHelper.DB_HISTORY_PATH);

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/StreamingDatatypesIT.java
Patch:
@@ -5,6 +5,8 @@
  */
 package io.debezium.connector.oracle;
 
+import java.util.concurrent.TimeUnit;
+
 import org.junit.Before;
 
 import io.debezium.config.Configuration;
@@ -20,6 +22,7 @@ public class StreamingDatatypesIT extends AbstractOracleDatatypesTest {
 
     @Before
     public void before() throws Exception {
+        setConsumeTimeout(TestHelper.defaultMessageConsumerPollTimeout(), TimeUnit.SECONDS);
         dropTables();
         initializeConnectorTestFramework();
         Testing.Files.delete(TestHelper.DB_HISTORY_PATH);

File: debezium-embedded/src/test/java/io/debezium/embedded/AbstractConnectorTest.java
Patch:
@@ -82,7 +82,7 @@ public abstract class AbstractConnectorTest implements Testing {
     private ExecutorService executor;
     protected EmbeddedEngine engine;
     private BlockingQueue<SourceRecord> consumedLines;
-    protected long pollTimeoutInMs = TimeUnit.SECONDS.toMillis(120);
+    protected long pollTimeoutInMs = TimeUnit.SECONDS.toMillis(5);
     protected final Logger logger = LoggerFactory.getLogger(getClass());
     private CountDownLatch latch;
     private JsonConverter keyJsonConverter = new JsonConverter();

File: debezium-connector-oracle/src/test/java/io/debezium/connector/oracle/OracleDdlParserTest.java
Patch:
@@ -58,8 +58,8 @@ public void shouldParseCreateTable() {
 
         final Column score = table.columnWithName("SCORE");
         assertThat(score.isOptional()).isTrue();
-        assertThat(score.jdbcType()).isEqualTo(Types.DECIMAL);
-        assertThat(score.typeName()).isEqualTo("DECIMAL");
+        assertThat(score.jdbcType()).isEqualTo(Types.NUMERIC);
+        assertThat(score.typeName()).isEqualTo("NUMBER");
         assertThat(score.length()).isEqualTo(6);
         assertThat(score.scale()).isEqualTo(2);
 

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleConnectorTask.java
Patch:
@@ -80,7 +80,7 @@ public void start(Configuration config) {
         jdbcConnection = new OracleConnection(jdbcConfig, new OracleConnectionFactory());
         SchemaNameAdjuster schemaNameAdjuster = SchemaNameAdjuster.create(LOGGER);
 
-        this.schema = new OracleDatabaseSchema(connectorConfig, schemaNameAdjuster, topicSelector);
+        this.schema = new OracleDatabaseSchema(connectorConfig, schemaNameAdjuster, topicSelector, jdbcConnection);
 
         OracleOffsetContext previousOffset = getPreviousOffset(connectorConfig);
         if (previousOffset != null) {

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleDatabaseSchema.java
Patch:
@@ -40,12 +40,12 @@ public class OracleDatabaseSchema implements RelationalDatabaseSchema {
     private final TableSchemaBuilder tableSchemaBuilder;
     private final DatabaseHistory databaseHistory;
 
-    public OracleDatabaseSchema(OracleConnectorConfig connectorConfig, SchemaNameAdjuster schemaNameAdjuster, TopicSelector topicSelector) {
+    public OracleDatabaseSchema(OracleConnectorConfig connectorConfig, SchemaNameAdjuster schemaNameAdjuster, TopicSelector topicSelector, OracleConnection connection) {
         this.topicSelector = topicSelector;
 
         this.tables = new Tables();
         this.schemas = new HashMap<>();
-        this.tableSchemaBuilder = new TableSchemaBuilder(new OracleValueConverters(), schemaNameAdjuster, SourceInfo.SCHEMA);
+        this.tableSchemaBuilder = new TableSchemaBuilder(new OracleValueConverters(connection), schemaNameAdjuster, SourceInfo.SCHEMA);
 
         this.databaseHistory = connectorConfig.getDatabaseHistory();
         this.databaseHistory.start();

File: debezium-connector-oracle/src/main/java/io/debezium/connector/oracle/OracleSchemaChangeEventEmitter.java
Patch:
@@ -64,7 +64,7 @@ public void emitSchemaChangeEvent(Receiver receiver) throws InterruptedException
     private SchemaChangeEventType getSchemaChangeEventType() {
         switch(ddlLcr.getCommandType()) {
             case "CREATE TABLE": return SchemaChangeEventType.CREATE;
-            case "ALTER TABLE": throw new UnsupportedOperationException("ALTER TABLE not yet implemented");
+//            case "ALTER TABLE": throw new UnsupportedOperationException("ALTER TABLE not yet implemented");
             case "DROP TABLE": throw new UnsupportedOperationException("DROP TABLE not yet implemented");
             default:
                 LOGGER.debug("Ignoring DDL event of type {}", ddlLcr.getCommandType());

File: debezium-embedded/src/test/java/io/debezium/embedded/AbstractConnectorTest.java
Patch:
@@ -82,7 +82,7 @@ public abstract class AbstractConnectorTest implements Testing {
     private ExecutorService executor;
     protected EmbeddedEngine engine;
     private BlockingQueue<SourceRecord> consumedLines;
-    protected long pollTimeoutInMs = TimeUnit.SECONDS.toMillis(60);
+    protected long pollTimeoutInMs = TimeUnit.SECONDS.toMillis(120);
     protected final Logger logger = LoggerFactory.getLogger(getClass());
     private CountDownLatch latch;
     private JsonConverter keyJsonConverter = new JsonConverter();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/MySqlAntlrDdlParser.java
Patch:
@@ -35,7 +35,7 @@
 import io.debezium.relational.TableId;
 
 /**
- * A ANTLR based parser for MySQL DDL statements.
+ * An ANTLR based parser for MySQL DDL statements.
  *
  * @author Roman Kuchár <kucharrom@gmail.com>.
  */

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/antlr/listener/ColumnDefinitionParserListener.java
Patch:
@@ -28,7 +28,7 @@
 import io.debezium.relational.ddl.DataType;
 
 /**
- * Parser listeners that is parsing column definition part of MySQL statements.
+ * Parser listener that is parsing column definition part of MySQL statements.
  *
  * @author Roman Kuchár <kucharrom@gmail.com>.
  */

File: debezium-core/src/main/java/io/debezium/relational/SystemVariables.java
Patch:
@@ -13,7 +13,7 @@
 import java.util.stream.Collectors;
 
 /**
- * Encapsulates a set of the MySQL system variables.
+ * Encapsulates a set of a database's system variables.
  *
  * @author Randall Hauch
  */

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlTaskContext.java
Patch:
@@ -81,7 +81,7 @@ public MySqlTaskContext(Configuration config, Boolean tableIdCaseInsensitive) {
         }
 
         // Set up the MySQL schema ...
-        this.dbSchema = new MySqlSchema(config, serverName(), this.gtidSourceFilter, this.tableIdCaseInsensitive, topicSelector);
+        this.dbSchema = new MySqlSchema(connectorConfig, serverName(), this.gtidSourceFilter, this.tableIdCaseInsensitive, topicSelector);
 
         // Set up the record processor ...
         this.recordProcessor = new RecordMakers(dbSchema, source, topicSelector, config.getBoolean(CommonConnectorConfig.TOMBSTONES_ON_DELETE));

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/Configurator.java
Patch:
@@ -87,7 +87,7 @@ public MySqlSchema createSchemas() {
         Configuration config = configBuilder.build();
         String serverName = config.getString(MySqlConnectorConfig.SERVER_NAME);
 
-        return new MySqlSchema(config, serverName, null, false,
+        return new MySqlSchema(new MySqlConnectorConfig(config), serverName, null, false,
                 TopicSelector.defaultSelector(serverName, "__debezium-heartbeat"));
     }
 }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDdlParserTest.java
Patch:
@@ -152,7 +152,7 @@ public void shouldParseCreateTableStatementWithCollate() {
         Column column = table.columnWithName("v1");
         assertThat(column.typeUsesCharset()).isTrue();
     }
-    
+
     @Test
     @FixFor("DBZ-646")
     public void shouldParseTokuDBTable() {
@@ -705,7 +705,7 @@ public void shouldParseSetOfSessionVariable() {
     }
 
     @Test
-    public void shouldParseButNotSetUserVariableWithHyphenDelimiter() {
+    public void shouldParseButNotSetUserVariableWithUnderscoreDelimiter() {
         String ddl = "SET @a_b_c_d:=1";
         parser.parse(ddl, tables);
         assertLocalVariable("a_b_c_d", null);
@@ -714,7 +714,7 @@ public void shouldParseButNotSetUserVariableWithHyphenDelimiter() {
     }
 
     @Test
-    public void shouldParseVariableWithHyphenDelimiter() {
+    public void shouldParseVariableWithUnderscoreDelimiter() {
         String ddl = "SET a_b_c_d=1";
         parser.parse(ddl, tables);
         assertSessionVariable("a_b_c_d", "1");

File: debezium-core/src/main/java/io/debezium/relational/ddl/LegacyDdlParser.java
Patch:
@@ -256,7 +256,7 @@ protected void parseNextStatement(Marker marker) {
      */
     protected void parseComment(Marker marker) {
         String comment = tokens.consume();
-        commnetParsed(comment);
+        commentParsed(comment);
     }
 
     /**

File: debezium-ddl-parser/src/main/java/io/debezium/antlr/AntlrDdlParser.java
Patch:
@@ -122,7 +122,7 @@ public Collection<ParsingException> getParsingExceptionsFromWalker() {
      * @param ctx the parser rule context; may not be null
      * @return matched part of the getText
      */
-    protected String getText(ParserRuleContext ctx) {
+    public static String getText(ParserRuleContext ctx) {
         Interval interval = new Interval(ctx.start.getStartIndex(), ctx.stop.getStopIndex());
         return ctx.start.getInputStream().getText(interval);
     }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -24,19 +24,19 @@
 
 import io.debezium.annotation.NotThreadSafe;
 import io.debezium.antlr.mysql.MySqlSystemVariables;
+import io.debezium.antlr.mysql.MySqlSystemVariables.MySqlScope;
 import io.debezium.relational.Column;
 import io.debezium.relational.ColumnEditor;
-import io.debezium.antlr.mysql.MySqlSystemVariables.MySqlScope;
 import io.debezium.relational.SystemVariables;
 import io.debezium.relational.Table;
 import io.debezium.relational.TableEditor;
 import io.debezium.relational.TableId;
 import io.debezium.relational.ValueConverter;
 import io.debezium.relational.ddl.DataType;
 import io.debezium.relational.ddl.DataTypeParser;
-import io.debezium.relational.ddl.LegacyDdlParser;
 import io.debezium.relational.ddl.DdlParserListener.SetVariableEvent;
 import io.debezium.relational.ddl.DdlTokenizer;
+import io.debezium.relational.ddl.LegacyDdlParser;
 import io.debezium.text.MultipleParsingExceptions;
 import io.debezium.text.ParsingException;
 import io.debezium.text.TokenStream;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlChanges.java
Patch:
@@ -117,6 +117,7 @@ protected String getDatabase(Event event) {
             case CREATE_TABLE:
             case ALTER_TABLE:
             case DROP_TABLE:
+            case TRUNCATE_TABLE:
                 TableEvent tableEvent = (TableEvent) event;
                 return tableEvent.tableId().catalog();
             case CREATE_INDEX:

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -228,6 +228,8 @@ protected void parseSetVariable(Marker start, AtomicReference<MySqlScope> scope)
             }
             systemVariables.setVariable(scope.get(), "character_set_client", charsetName);
             systemVariables.setVariable(scope.get(), "character_set_results", charsetName);
+            systemVariables.setVariable(MySqlScope.SESSION, MySqlSystemVariables.CHARSET_NAME_CONNECTION,
+                    systemVariables.getVariable(MySqlSystemVariables.CHARSET_NAME_DATABASE));
             // systemVariables.setVariable(scope.get(), "collation_connection", ...);
         } else if (tokens.canConsume("NAMES")) {
             // https://dev.mysql.com/doc/refman/5.7/en/set-statement.html

File: debezium-core/src/main/java/io/debezium/relational/ddl/AbstractDdlParser.java
Patch:
@@ -27,7 +27,7 @@ public abstract class AbstractDdlParser implements DdlParser {
 
     private final String terminator;
     protected final boolean skipViews;
-    private final DdlChanges ddlChanges;
+    protected DdlChanges ddlChanges;
     protected SystemVariables systemVariables;
 
     protected final Logger logger = LoggerFactory.getLogger(getClass());

File: debezium-core/src/test/java/io/debezium/relational/ddl/SimpleDdlParserListener.java
Patch:
@@ -18,7 +18,7 @@
  * @author Randall Hauch
  *
  */
-public class SimpleDdlParserListener implements DdlParserListener {
+public class SimpleDdlParserListener extends DdlChanges implements DdlParserListener {
 
     public static final class EventAssert {
 

File: debezium-ddl-parser/src/main/java/io/debezium/antlr/AntlrDdlParser.java
Patch:
@@ -28,7 +28,7 @@
 public abstract class AntlrDdlParser<L extends Lexer, P extends Parser> extends AbstractDdlParser {
 
     protected Tables databaseTables;
-    protected DataTypeResolver dataTypeResolver;
+    protected DataTypeResolver dataTypeResolver = new DataTypeResolver();
 
     public AntlrDdlParser() {
         super(";");

File: debezium-ddl-parser/src/main/java/io/debezium/antlr/mysql/MySqlSystemVariables.java
Patch:
@@ -47,7 +47,8 @@ public int priority() {
     @Override
     protected ConcurrentMap<String, String> forScope(Scope scope) {
         // local and session scope are the same in MySQL
-        if (scope == MySqlScope.LOCAL) {
+        // use session as default scope
+        if (scope == null || scope == MySqlScope.LOCAL) {
             scope = MySqlScope.SESSION;
         }
         return super.forScope(scope);

File: debezium-core/src/main/java/io/debezium/relational/ddl/AbstractDdlParser.java
Patch:
@@ -52,6 +52,7 @@ public AbstractDdlParser(String terminator, boolean includeViews) {
         this.terminator = terminator != null ? terminator : ";";
         this.skipViews = !includeViews;
         this.ddlChanges = new DdlChanges(terminator);
+        this.systemVariables = createNewSystemVariablesInstance();
     }
 
     @Override
@@ -80,6 +81,8 @@ public SystemVariables systemVariables() {
         return systemVariables;
     }
 
+    protected abstract SystemVariables createNewSystemVariablesInstance();
+
     /**
      * Get the name of the current schema.
      *

File: debezium-ddl-parser/src/main/java/io/debezium/antlr/ProxyParseTreeListener.java
Patch:
@@ -167,4 +167,4 @@ protected List<ParseTreeListener> createParseTreeListenerList() {
     public Collection<ParsingException> getErrors() {
         return errors;
     }
-}
\ No newline at end of file
+}

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlTaskContext.java
Patch:
@@ -12,6 +12,7 @@
 import javax.management.MalformedObjectNameException;
 import javax.management.ObjectName;
 
+import io.debezium.antlr.mysql.MySqlSystemVariables;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlSchemaTest.java
Patch:
@@ -24,6 +24,7 @@
 import io.debezium.util.IoUtil;
 import io.debezium.util.SchemaNameAdjuster;
 import io.debezium.util.Testing;
+import io.debezium.antlr.mysql.MySqlSystemVariables;
 
 /**
  * @author Randall Hauch

File: debezium-core/src/main/java/io/debezium/relational/history/AbstractDatabaseHistory.java
Patch:
@@ -17,8 +17,8 @@
 import io.debezium.config.Configuration;
 import io.debezium.function.Predicates;
 import io.debezium.relational.Tables;
-import io.debezium.relational.ddl.LegacyDdlParser;
 import io.debezium.text.ParsingException;
+import io.debezium.relational.ddl.DdlParser;
 
 /**
  * @author Randall Hauch
@@ -57,7 +57,7 @@ public final void record(Map<String, ?> source, Map<String, ?> position, String
     }
 
     @Override
-    public final void recover(Map<String, ?> source, Map<String, ?> position, Tables schema, LegacyDdlParser ddlParser) {
+    public final void recover(Map<String, ?> source, Map<String, ?> position, Tables schema, DdlParser ddlParser) {
         logger.debug("Recovering DDL history for source partition {} and offset {}", source, position);
         HistoryRecord stopPoint = new HistoryRecord(source, position, null, null);
         recoverRecords(recovered -> {

File: debezium-ddl-parser/src/test/java/io/debezium/antlr/mysql/MySqlAntlrDdlParserTest.java
Patch:
@@ -9,6 +9,7 @@
 import io.debezium.relational.Tables;
 import io.debezium.relational.ddl.DdlParser;
 import io.debezium.relational.ddl.SimpleDdlParserListener;
+import io.debezium.text.MultipleParsingExceptions;
 import org.junit.Before;
 import org.junit.Test;
 
@@ -55,11 +56,10 @@ public void shouldParseAlterStatementsAfterCreate() {
         listener.assertNext().alterTableNamed("foo").ddlStartsWith("ALTER TABLE foo ADD COLUMN c");
     }
 
-    @Test
+    @Test(expected = MultipleParsingExceptions.class)
     public void shouldParseAlterStatementsWithoutCreate() {
         String ddl = "ALTER TABLE foo ADD COLUMN c bigint;" + System.lineSeparator();
         parser.parse(ddl, tables);
-        listener.assertNext().alterTableNamed("foo").ddlStartsWith("ALTER TABLE foo ADD COLUMN c");
     }
 
 }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -878,7 +878,7 @@ protected void parseColumnDefinition(Marker start, String columnName, TokenStrea
             column.charsetName("utf8");
         }
 
-        if (Types.DECIMAL == dataType.jdbcType()) {
+        if (Types.DECIMAL == dataType.jdbcType() || Types.NUMERIC == dataType.jdbcType()) {
             if (dataType.length() == -1) {
                 column.length(10);
             }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/transforms/UnwrapFromMongoDbEnvelope.java
Patch:
@@ -44,8 +44,8 @@ public class UnwrapFromMongoDbEnvelope<R extends ConnectRecord<R>> implements Tr
             .withWidth(ConfigDef.Width.SHORT)
             .withImportance(ConfigDef.Importance.MEDIUM)
             .withDescription("The arrays can be encoded using 'array' schema type (the default) ar as a 'struct' (similar to how BSON encodes arrays). "
-                    + "'array' is easier to consume but requires all elemnts in the array to be of the same type. "
-                    + "Use 'struct' if the arrays in data source mixes different types together.");
+                    + "'array' is easier to consume but requires all elements in the array to be of the same type. "
+                    + "Use 'struct' if the arrays in data source mix different types together.");
 
     public static enum ArrayEncoding implements EnumeratedValue {
         ARRAY("array"),

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/MongoDataConverterTest.java
Patch:
@@ -96,7 +96,7 @@ public void shouldCreateCorrectSchemaFromInsertJson() {
                 SchemaBuilder.struct().name("pub")
                     .field("address", SchemaBuilder.struct().name("pub.address").optional()
                             .field("building", Schema.OPTIONAL_STRING_SCHEMA)
-                            .field("floor", SchemaBuilder.struct().name("pub.address.floor")
+                            .field("floor", SchemaBuilder.struct().name("pub.address.floor").optional()
                                     .field("level", Schema.OPTIONAL_INT32_SCHEMA)
                                     .field("description", Schema.OPTIONAL_STRING_SCHEMA)
                                     .build()

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/transforms/MongoDataConverterTest.java
Patch:
@@ -92,7 +92,7 @@ public void shouldCreateCorrectSchemaFromInsertJson() {
                 SchemaBuilder.struct().name("pub")
                     .field("address", SchemaBuilder.struct().name("pub.address")
                             .field("building", Schema.OPTIONAL_STRING_SCHEMA)
-                            .field("floor", SchemaBuilder.struct().name("pub.address.floor").optional()
+                            .field("floor", SchemaBuilder.struct().name("pub.address.floor")
                                     .field("level", Schema.OPTIONAL_INT32_SCHEMA)
                                     .field("description", Schema.OPTIONAL_STRING_SCHEMA)
                                     .build()

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -622,7 +622,9 @@ protected void parseCreateDefinition(Marker start, TableEditor table, boolean is
                     tokens.rewind(defnStart);
                 }
             }
-            if (tokens.canConsume("CONSTRAINT", TokenStream.ANY_VALUE, "UNIQUE") || tokens.canConsume("UNIQUE")) {
+            if (tokens.canConsume("CONSTRAINT", TokenStream.ANY_VALUE, "UNIQUE")
+                    || tokens.canConsume("CONSTRAINT", "UNIQUE")
+                    || tokens.canConsume("UNIQUE")) {
                 tokens.canConsumeAnyOf("KEY", "INDEX");
                 try {
                     if (!tokens.matches('(')) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -185,10 +185,10 @@ else if (oidValue == typeRegistry.geographyOid()) {
                     return Geography.builder();
                 }
                 else if (oidValue == typeRegistry.geometryArrayOid()) {
-                    return SchemaBuilder.array(Geometry.builder().optional().build()).optional();
+                    return SchemaBuilder.array(Geometry.builder().optional().build());
                 }
                 else if (oidValue == typeRegistry.geographyArrayOid()) {
-                    return SchemaBuilder.array(Geography.builder().optional().build()).optional();
+                    return SchemaBuilder.array(Geography.builder().optional().build());
                 }
                 final SchemaBuilder jdbcSchemaBuilder = super.schemaBuilder(column);
                 if (jdbcSchemaBuilder == null) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -132,7 +132,7 @@ public SchemaBuilder schemaBuilder(Column column) {
             case PgOid.NUMERIC:
                 return numericSchema(column).optional();
             case PgOid.BYTEA:
-                return SchemaBuilder.bytes().optional();
+                return SchemaBuilder.bytes();
             case PgOid.INT2_ARRAY:
                 return SchemaBuilder.array(SchemaBuilder.OPTIONAL_INT16_SCHEMA);
             case PgOid.INT4_ARRAY:

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsSnapshotProducer.java
Patch:
@@ -32,9 +32,9 @@
 import io.debezium.annotation.ThreadSafe;
 import io.debezium.connector.postgresql.connection.PostgresConnection;
 import io.debezium.connector.postgresql.connection.ReplicationConnection;
+import io.debezium.data.DebeziumDecimal;
 import io.debezium.data.Envelope;
 import io.debezium.function.BlockingConsumer;
-import io.debezium.jdbc.JdbcValueConverters.SpecialValue;
 import io.debezium.relational.Table;
 import io.debezium.relational.TableId;
 import io.debezium.relational.TableSchema;
@@ -295,8 +295,8 @@ private Object valueForColumn(ResultSet rs, int colIdx, ResultSetMetaData metaDa
                     return rs.getString(colIdx);
                 case PgOid.NUMERIC:
                     final String s = rs.getString(colIdx);
-                    final SpecialValue v = PostgresValueConverter.toSpecialValue(s);
-                    return v != null ? v : rs.getBigDecimal(colIdx);
+                    final DebeziumDecimal v = PostgresValueConverter.toSpecialValue(s);
+                    return v != null ? v : new DebeziumDecimal(rs.getBigDecimal(colIdx));
                 default:
                     return rs.getObject(colIdx);
             }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/DecoderDifferences.java
Patch:
@@ -50,7 +50,7 @@ private static boolean wal2Json() {
      * @author Jiri Pechanec
      *
      */
-    public static boolean areSpecialFPValuesUnupported() {
+    public static boolean areSpecialFPValuesUnsupported() {
         return wal2Json();
     }
 }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -60,7 +60,7 @@ public static ReplicationConnection createForReplication(String slotName, boolea
      */
     static PostgresConnectorConfig.LogicalDecoder decoderPlugin() {
         final String s = System.getProperty(PostgresConnectorConfig.PLUGIN_NAME.name());
-        return (s == null || s.length() == 0) ? PostgresConnectorConfig.LogicalDecoder.WAL2JSON : PostgresConnectorConfig.LogicalDecoder.parse(s);
+        return (s == null || s.length() == 0) ? PostgresConnectorConfig.LogicalDecoder.DECODERBUFS : PostgresConnectorConfig.LogicalDecoder.parse(s);
     }
 
     /**

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -60,7 +60,7 @@ public static ReplicationConnection createForReplication(String slotName, boolea
      */
     static PostgresConnectorConfig.LogicalDecoder decoderPlugin() {
         final String s = System.getProperty(PostgresConnectorConfig.PLUGIN_NAME.name());
-        return (s == null || s.length() == 0) ? PostgresConnectorConfig.LogicalDecoder.DECODERBUFS : PostgresConnectorConfig.LogicalDecoder.parse(s);
+        return (s == null || s.length() == 0) ? PostgresConnectorConfig.LogicalDecoder.WAL2JSON : PostgresConnectorConfig.LogicalDecoder.parse(s);
     }
 
     /**

File: debezium-core/src/main/java/io/debezium/document/ComparableValue.java
Patch:
@@ -203,6 +203,7 @@ public Float asFloat() {
             double raw = ((Double) value).doubleValue();
             if (isValidFloat(raw)) return Float.valueOf((float) raw);
         }
+        if (value instanceof Number) return ((Number)value).floatValue();
         return null;
     }
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/BinlogReaderIT.java
Patch:
@@ -126,10 +126,11 @@ public void shouldCreateSnapshotOfSingleDatabase() throws Exception {
 
         // Poll for records ...
         // Testing.Print.enable();
-        int expected = 9 + 9 + 4 + 5; // only the inserts for our 4 tables in this database
+        int expected = 9 + 9 + 4 + 5 + 1; // only the inserts for our 4 tables in this database and 1 create table
         int consumed = consumeAtLeast(expected);
         assertThat(consumed).isGreaterThanOrEqualTo(expected);
 
+        store.sourceRecords().forEach(System.out::println);
         // There should be no schema changes ...
         assertThat(schemaChanges.recordCount()).isEqualTo(0);
 
@@ -397,7 +398,7 @@ private void inconsistentSchema(EventProcessingFailureHandlingMode mode) throws
 
         // Poll for records ...
         // Testing.Print.enable();
-        int expected = 9 + 9 + 4 + 5; // only the inserts for our 4 tables in this database
+        int expected = 9 + 9 + 4 + 5 + 1; // only the inserts for our 4 tables in this database and 1 create table
         int consumed = consumeAtLeast(expected);
         assertThat(consumed).isGreaterThanOrEqualTo(expected);
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlTaskContext.java
Patch:
@@ -70,7 +70,7 @@ public MySqlTaskContext(Configuration config, Boolean tableIdCaseInsensitive) {
         }
 
         // Set up the MySQL schema ...
-        this.dbSchema = new MySqlSchema(config, serverName(), this.gtidSourceFilter, this.tableIdCaseInsensitive);
+        this.dbSchema = new MySqlSchema(config, serverName(), this.gtidSourceFilter, this.tableIdCaseInsensitive, topicSelector);
 
         // Set up the record processor ...
         this.recordProcessor = new RecordMakers(dbSchema, source, topicSelector, config.getBoolean(CommonConnectorConfig.TOMBSTONES_ON_DELETE));

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorTask.java
Patch:
@@ -69,8 +69,9 @@ public void start(Map<String, String> props) {
         }
 
         // create the task context and schema...
-        PostgresSchema schema = new PostgresSchema(config, typeRegistry);
-        this.taskContext = new PostgresTaskContext(config, schema);
+        TopicSelector topicSelector = TopicSelector.create(config);
+        PostgresSchema schema = new PostgresSchema(config, typeRegistry, topicSelector);
+        this.taskContext = new PostgresTaskContext(config, schema, topicSelector);
 
         SourceInfo sourceInfo = new SourceInfo(config.serverName());
         Map<String, Object> existingOffset = context.offsetStorageReader().offset(sourceInfo.partition());

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsSnapshotProducer.java
Patch:
@@ -317,7 +317,7 @@ protected void generateReadRecord(TableId tableId, Object[] rowData) {
         Map<String, ?> partition = sourceInfo.partition();
         Map<String, ?> offset = sourceInfo.offset();
         String topicName = topicSelector().topicNameFor(tableId);
-        Envelope envelope = createEnvelope(tableSchema, topicName);
+        Envelope envelope = tableSchema.getEnvelopeSchema();
         currentRecord.set(new SourceRecord(partition, offset, topicName, null, keySchema, key, envelope.schema(),
                                            envelope.read(value, sourceInfo.source(), clock().currentTimeInMillis())));
     }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsStreamProducer.java
Patch:
@@ -273,7 +273,7 @@ protected void generateCreateRecord(TableId tableId, Object[] rowData, boolean i
         Map<String, ?> partition = sourceInfo.partition();
         Map<String, ?> offset = sourceInfo.offset();
         String topicName = topicSelector().topicNameFor(tableId);
-        Envelope envelope = createEnvelope(tableSchema, topicName);
+        Envelope envelope = tableSchema.getEnvelopeSchema();
 
         SourceRecord record = new SourceRecord(partition, offset, topicName, null, keySchema, key, envelope.schema(),
                                                envelope.create(value, sourceInfo.source(), clock().currentTimeInMillis()));
@@ -309,7 +309,7 @@ protected void generateUpdateRecord(TableId tableId, Object[] oldRowData, Object
         Map<String, ?> partition = sourceInfo.partition();
         Map<String, ?> offset = sourceInfo.offset();
         String topicName = topicSelector().topicNameFor(tableId);
-        Envelope envelope = createEnvelope(tableSchema, topicName);
+        Envelope envelope = tableSchema.getEnvelopeSchema();
         Struct source = sourceInfo.source();
 
         if (oldKey != null && !Objects.equals(oldKey, newKey)) {
@@ -371,7 +371,7 @@ protected void generateDeleteRecord(TableId tableId, Object[] oldRowData, boolea
         Map<String, ?> partition = sourceInfo.partition();
         Map<String, ?> offset = sourceInfo.offset();
         String topicName = topicSelector().topicNameFor(tableId);
-        Envelope envelope = createEnvelope(tableSchema, topicName);
+        Envelope envelope = tableSchema.getEnvelopeSchema();
 
         // create the regular delete record
         ChangeEvent changeEvent = new ChangeEvent(

File: debezium-core/src/test/java/io/debezium/relational/TableSchemaBuilderTest.java
Patch:
@@ -95,19 +95,19 @@ public void checkPreconditions() {
 
     @Test(expected = NullPointerException.class)
     public void shouldFailToBuildTableSchemaFromNullTable() {
-        new TableSchemaBuilder(new JdbcValueConverters(),validator::validate).create(prefix,null);
+        new TableSchemaBuilder(new JdbcValueConverters(),validator::validate, SchemaBuilder.struct().build()).create(prefix, "sometopic", null);
     }
 
     @Test
     public void shouldBuildTableSchemaFromTable() {
-        schema = new TableSchemaBuilder(new JdbcValueConverters(),validator::validate).create(prefix,table);
+        schema = new TableSchemaBuilder(new JdbcValueConverters(),validator::validate, SchemaBuilder.struct().build()).create(prefix, "sometopic", table);
         assertThat(schema).isNotNull();
     }
 
     @Test
     public void shouldBuildTableSchemaFromTableWithoutPrimaryKey() {
         table = table.edit().setPrimaryKeyNames().create();
-        schema = new TableSchemaBuilder(new JdbcValueConverters(),validator::validate).create(prefix,table);
+        schema = new TableSchemaBuilder(new JdbcValueConverters(),validator::validate, SchemaBuilder.struct().build()).create(prefix, "sometopic", table);
         assertThat(schema).isNotNull();
         // Check the keys ...
         assertThat(schema.keySchema()).isNull();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ReplicationMessage.java
Patch:
@@ -7,7 +7,6 @@
 package io.debezium.connector.postgresql.connection;
 
 import java.util.List;
-import java.util.OptionalInt;
 
 import io.debezium.connector.postgresql.PostgresType;
 import io.debezium.connector.postgresql.RecordsStreamProducer.PgConnectionSupplier;
@@ -47,8 +46,8 @@ public interface Column {
     }
 
     public interface ColumnTypeMetadata {
-        OptionalInt getLength();
-        OptionalInt getScale();
+        int getLength();
+        int getScale();
     }
 
     /**

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -760,7 +760,7 @@ protected boolean includeUnknownDatatypes() {
         return config.getBoolean(INCLUDE_UNKNOWN_DATATYPES);
     }
 
-    protected Configuration jdbcConfig() {
+    public Configuration jdbcConfig() {
         return config.subset(DATABASE_CONFIG_PREFIX, true);
     }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresTaskContext.java
Patch:
@@ -76,6 +76,7 @@ protected ReplicationConnection createReplicationConnection() throws SQLExceptio
                                     .withPlugin(config.plugin())
                                     .dropSlotOnClose(config.dropSlotOnStop())
                                     .statusUpdateIntervalMillis(config.statusUpdateIntervalMillis())
+                                    .withTypeRegistry(schema.getTypeRegistry())
                                     .build();
     }
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/MessageDecoder.java
Patch:
@@ -11,6 +11,7 @@
 
 import org.postgresql.replication.fluent.logical.ChainedLogicalStreamBuilder;
 
+import io.debezium.connector.postgresql.TypeRegistry;
 import io.debezium.connector.postgresql.connection.ReplicationStream.ReplicationMessageProcessor;
 
 /**
@@ -27,8 +28,9 @@ public interface MessageDecoder {
      *
      * @param buffer - binary representation of replication message
      * @param processor - message processing on arrival
+     * @param typeRegistry - registry with known types
      */
-    void processMessage(final ByteBuffer buffer, ReplicationMessageProcessor processor) throws SQLException, InterruptedException;
+    void processMessage(final ByteBuffer buffer, ReplicationMessageProcessor processor, TypeRegistry typeRegistry) throws SQLException, InterruptedException;
 
     /**
      * Allows MessageDecoder to configure options with which the replication stream is started.

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ReplicationConnection.java
Patch:
@@ -14,6 +14,7 @@
 import io.debezium.annotation.NotThreadSafe;
 import io.debezium.config.Configuration;
 import io.debezium.connector.postgresql.PostgresConnectorConfig;
+import io.debezium.connector.postgresql.TypeRegistry;
 
 /**
  * A Postgres logical streaming replication connection. Replication connections are established for a slot and a given plugin
@@ -126,6 +127,8 @@ interface Builder {
          */
         Builder statusUpdateIntervalMillis(final Integer statusUpdateIntervalMillis);
 
+        Builder withTypeRegistry(TypeRegistry typeRegistry);
+
         /**
          * Creates a new {@link ReplicationConnection} instance
          * @return a connection, never null

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/Wal2JsonMessageDecoder.java
Patch:
@@ -16,6 +16,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import io.debezium.connector.postgresql.TypeRegistry;
 import io.debezium.connector.postgresql.connection.MessageDecoder;
 import io.debezium.connector.postgresql.connection.ReplicationStream.ReplicationMessageProcessor;
 import io.debezium.document.Array;
@@ -40,7 +41,7 @@ public class Wal2JsonMessageDecoder implements MessageDecoder {
     private boolean containsMetadata = false;
 
     @Override
-    public void processMessage(ByteBuffer buffer, ReplicationMessageProcessor processor) throws SQLException, InterruptedException {
+    public void processMessage(ByteBuffer buffer, ReplicationMessageProcessor processor, TypeRegistry typeRegistry) throws SQLException, InterruptedException {
         try {
             if (!buffer.hasArray()) {
                 throw new IllegalStateException("Invalid buffer received from PG server during streaming replication");
@@ -57,7 +58,7 @@ public void processMessage(ByteBuffer buffer, ReplicationMessageProcessor proces
             Iterator<Entry> it = changes.iterator();
             while (it.hasNext()) {
                 Value value = it.next().getValue();
-                processor.process(new Wal2JsonReplicationMessage(txId, commitTime, value.asDocument(), containsMetadata, !it.hasNext()));
+                processor.process(new Wal2JsonReplicationMessage(txId, commitTime, value.asDocument(), containsMetadata, !it.hasNext(), typeRegistry));
             }
         } catch (final IOException e) {
             throw new ConnectException(e);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -291,7 +291,6 @@ public void shouldProduceEventsWhenAlwaysTakingSnapshots() throws InterruptedExc
 
         //check the records from the snapshot
         assertRecordsFromSnapshot(2, 1, 1);
-
         // insert and verify 2 new records
         TestHelper.execute(INSERT_STMT);
         assertRecordsAfterInsert(2, 2, 2);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/SnapshotWithOverridesProducerIT.java
Patch:
@@ -51,7 +51,7 @@ public void before(Configuration overrides) throws SQLException {
         TestHelper.dropAllSchemas();
 
         PostgresConnectorConfig config = new PostgresConnectorConfig(TestHelper.defaultConfig().with(overrides).build());
-        context = new PostgresTaskContext(config, new PostgresSchema(config));
+        context = new PostgresTaskContext(config, new PostgresSchema(config, TestHelper.getTypeRegistry()));
     }
 
     @After

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/connection/ReplicationConnectionIT.java
Patch:
@@ -39,7 +39,7 @@ public class ReplicationConnectionIT {
     @Before
     public void before() throws Exception {
         TestHelper.dropAllSchemas();
-        String statement = "CREATE SCHEMA public;" +
+        String statement = "CREATE SCHEMA IF NOT EXISTS public;" +
                            "CREATE TABLE table_with_pk (a SERIAL, b VARCHAR(30), c TIMESTAMP NOT NULL, PRIMARY KEY(a, c));" +
                            "CREATE TABLE table_without_pk (a SERIAL, b NUMERIC(5,2), c TEXT);";
         TestHelper.execute(statement);

File: debezium-core/src/main/java/io/debezium/data/geometry/Geometry.java
Patch:
@@ -39,6 +39,7 @@ public static SchemaBuilder builder() {
                             .name(LOGICAL_NAME)
                             .version(1)
                             .doc("Geometry")
+                            .optional()
                             .field(WKB_FIELD, Schema.BYTES_SCHEMA)
                             .field(SRID_FIELD, Schema.OPTIONAL_INT32_SCHEMA);
     }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSetMonitorThread.java
Patch:
@@ -23,7 +23,7 @@
  * 
  * @author Randall Hauch
  */
-public final class ReplicaSetMonitorThread extends Thread {
+public final class ReplicaSetMonitorThread implements Runnable {
 
     private final Logger logger = LoggerFactory.getLogger(getClass());
     private final Metronome metronome;
@@ -93,7 +93,7 @@ public void shutdown() {
             logger.debug("Stopping the thread monitoring replica sets");
             // We were running, so interrupt the thread if it is paused ...
             try {
-                this.interrupt();
+                Thread.currentThread().interrupt();
             } catch (Throwable t) {
                 logger.warn("Unable to interrupt the thread monitoring replica sets", t);
             }

File: debezium-core/src/main/java/io/debezium/util/Threads.java
Patch:
@@ -244,7 +244,7 @@ public Thread newThread(Runnable r) {
                 if (indexed) {
                     threadName.append('-').append(index.getAndIncrement());
                 }
-                LOGGER.info("Creating thread {} in group {}", threadName);
+                LOGGER.info("Creating thread {}", threadName);
                 return new Thread(r, threadName.toString());
             }
         };

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -391,7 +391,7 @@ public static EventProcessingFailureHandlingMode parse(String value) {
      * Default length of interval in which BinlogReader generates periodically
      * heartbeat messages. A size of 0 disables heartbeat.
      */
-    private static final int DEFAULT_BINLOG_READER_HEARTBEAT_INTERVAL = 3600;
+    private static final int DEFAULT_BINLOG_READER_HEARTBEAT_INTERVAL = 0;
 
     /**
      * Default prefix for names of heartbeat topics
@@ -702,7 +702,7 @@ public static EventProcessingFailureHandlingMode parse(String value) {
                                                                       .withDescription("The length of interval in which Binlog reader periodically sends heartbeat messages "
                                                                               + "to the Connect. "
                                                                               + "Use 0 to disable heartbeat. "
-                                                                              + "Defaults to " + DEFAULT_BINLOG_READER_HEARTBEAT_INTERVAL + ".")
+                                                                              + "Disabled by default.")
                                                                       .withDefault(DEFAULT_BINLOG_READER_HEARTBEAT_INTERVAL)
                                                                       .withValidation(Field::isNonNegativeInteger);
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/RecordMakers.java
Patch:
@@ -482,7 +482,7 @@ public int delete(Object[] row, long ts, int rowNumber, int numberOfRows) throws
      * @param tableNumber
      * @return the table id or null for unknown tables
      */
-    public TableId getTableIfFromTableNumber(long tableNumber) {
+    public TableId getTableIdFromTableNumber(long tableNumber) {
         return tableIdsByTableNumber.get(tableNumber);
     }
 }

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorTask.java
Patch:
@@ -131,7 +131,7 @@ public void start(Map<String, String> props) {
 
             // Set up a replicator for each replica set ...
             final int numThreads = replicaSets.replicaSetCount();
-            final ExecutorService executor = Threads.newFixedThreadPool(MongoDbConnector.class, replicationContext.serverName(), "replica-set", numThreads);
+            final ExecutorService executor = Threads.newFixedThreadPool(MongoDbConnector.class, replicationContext.serverName(), "replicator", numThreads);
             AtomicInteger stillRunning = new AtomicInteger(numThreads);
             logger.info("Ignoring unnamed replica sets: {}", replicaSets.unnamedReplicaSets());
             logger.info("Starting {} thread(s) to replicate replica sets: {}", numThreads, replicaSets);

File: debezium-core/src/main/java/io/debezium/util/Threads.java
Patch:
@@ -235,7 +235,8 @@ public static ThreadFactory threadFactory(Class<? extends SourceConnector> conne
 
             @Override
             public Thread newThread(Runnable r) {
-                StringBuilder threadName = new StringBuilder(connector.getSimpleName().toLowerCase())
+                StringBuilder threadName = new StringBuilder(DEBEZIUM_THREAD_NAME_PREFIX)
+                                            .append(connector.getSimpleName().toLowerCase())
                                             .append('-')
                                             .append(connectorId)
                                             .append('-')

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSchema.java
Patch:
@@ -49,6 +49,7 @@ public class PostgresSchema {
     private final String schemaPrefix;
     private final Tables tables;
     private final Function<String, String> schemaNameValidator;
+    private final PostgresValueConverter valueConverter;
 
     private Map<String, Integer> typeInfo;
 
@@ -61,7 +62,7 @@ protected PostgresSchema(PostgresConnectorConfig config) {
         this.filters = new Filters(config);
         this.tables = new Tables();
 
-        PostgresValueConverter valueConverter = new PostgresValueConverter(config.decimalHandlingMode(), config.temporalPrecisionMode(),
+        this.valueConverter = new PostgresValueConverter(config.decimalHandlingMode(), config.temporalPrecisionMode(),
                 ZoneOffset.UTC, null, config.includeUnknownDatatypes(), this);
         this.schemaNameValidator = AvroValidator.create(LOGGER)::validate;
         this.schemaBuilder = new TableSchemaBuilder(valueConverter, this.schemaNameValidator);
@@ -131,7 +132,7 @@ protected void refresh(PostgresConnection connection, TableId tableId) throws SQ
 
     /**
      * Refreshes the schema content with a table constructed externally
-     * 
+     *
      * @param table constructed externally - typically from decoder metadata
      */
     protected void refresh(Table table) {

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/transforms/UnwrapFromMongoDbEnvelope.java
Patch:
@@ -48,14 +48,14 @@ public R apply(R r) {
         if (afterRecord.value() == null) {
             final R patchRecord = patchExtractor.apply(r);
             value = BsonDocument.parse(patchRecord.value().toString());
-            value = value.getDocument("$set");            
+            value = value.getDocument("$set");
 
             if (!value.containsKey("id")) {
                 value.append("id", Key.get("id"));
             }
             } else {
-            value = BsonDocument.parse(afterRecord.value().toString());
-        }
+                value = BsonDocument.parse(afterRecord.value().toString());
+            }
 
         Set<Entry<String, BsonValue>> valuePairs = value.entrySet();
         Set<Entry<String, BsonValue>> keyPairs = Key.entrySet();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsSnapshotProducer.java
Patch:
@@ -108,8 +108,8 @@ private void startStreaming(Consumer<SourceRecord> consumer) {
     }
 
     @Override
-    protected void commit(final SourceRecord lastRecordForRecovery)  {
-        streamProducer.ifPresent(x -> x.commit(lastRecordForRecovery));
+    protected void commit(long lsn)  {
+        streamProducer.ifPresent(x -> x.commit(lsn));
     }
 
     @Override

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/AbstractRecordsProducerTest.java
Patch:
@@ -409,7 +409,7 @@ private void assertValue(Struct content) {
 
         private void assertStruct(final Struct expectedStruct, final Struct actualStruct) {
             expectedStruct.schema().fields().stream().forEach(field -> {
-                final Object expectedValue = actualStruct.get(field);
+                final Object expectedValue = expectedStruct.get(field);
                 if (expectedValue == null) {
                     assertNull(fieldName + " is present in the actual content", actualStruct.get(field.name()));
                     return;

File: debezium-core/src/main/java/io/debezium/function/Predicates.java
Patch:
@@ -203,7 +203,7 @@ protected static <T> Predicate<T> includedInPatterns(Collection<Pattern> pattern
     }
 
     /**
-     * Generate a predicate function that for any supplied string returns a {@link Pattern} if of the regular expression
+     * Generate a predicate function that for any supplied string returns a {@link Pattern} representing the first regular expression
      * in the supplied comma-separated list that matches the predicate parameter in a case-insensitive manner.
      *
      * @param regexPatterns the comma-separated regular expression pattern (or literal) strings; may not be null

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/RecordsSnapshotProducerIT.java
Patch:
@@ -18,15 +18,15 @@
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.stream.Collectors;
 
-import io.debezium.doc.FixFor;
-import io.debezium.jdbc.TemporalPrecisionMode;
 import org.apache.kafka.connect.source.SourceRecord;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
 import io.debezium.data.Envelope;
 import io.debezium.data.VerifyRecord;
+import io.debezium.doc.FixFor;
+import io.debezium.jdbc.TemporalPrecisionMode;
 
 /**
  * Integration test for {@link RecordsSnapshotProducerIT}
@@ -157,7 +157,7 @@ private void assertReadRecord(SourceRecord record, Map<String, List<SchemaAndVal
 
     @Test
     @FixFor("DBZ-342")
-    public void shouldGenerateSnapshotsForDefaultDatatypesAdpativeMicroseconds() throws Exception {
+    public void shouldGenerateSnapshotsForDefaultDatatypesAdaptiveMicroseconds() throws Exception {
         PostgresConnectorConfig config = new PostgresConnectorConfig(
                 TestHelper.defaultConfig()
                         .with(PostgresConnectorConfig.TIME_PRECISION_MODE, TemporalPrecisionMode.ADAPTIVE_TIME_MICROSECONDS)

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -1041,7 +1041,7 @@ protected void parseCreateView(Marker start) {
                 List<String> fromTablePkColumnNames = fromTable.columnNames();
                 List<String> viewPkColumnNames = new ArrayList<>();
                 selectedColumnsByAlias.forEach((viewColumnName, fromTableColumn) -> {
-                    if (fromTablePkColumnNames.contains(fromTableColumn)) {
+                    if (fromTablePkColumnNames.contains(fromTableColumn.name())) {
                         viewPkColumnNames.add(viewColumnName);
                     }
                 });

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -495,7 +495,7 @@ private EmbeddedEngine(Configuration config, ClassLoader classLoader, Clock cloc
      * 
      * @return {@code true} if running, or {@code false} otherwise
      */
-    protected boolean isRunning() {
+    public boolean isRunning() {
         return this.runningThread.get() != null;
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReaderMetricsMXBean.java
Patch:
@@ -24,7 +24,7 @@ public interface BinlogReaderMetricsMXBean {
     long getNumberOfDisconnects();
     void reset();
 
-    long getNumberOfCommitedTransactions();
+    long getNumberOfCommittedTransactions();
     long getNumberOfRolledBackTransactions();
     long getNumberOfNotWellFormedTransactions();
     long getNumberOfLargeTransactions();

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/BinlogReaderBufferIT.java
Patch:
@@ -10,7 +10,6 @@
 import java.nio.file.Path;
 import java.sql.Connection;
 import java.sql.SQLException;
-import java.sql.Savepoint;
 import java.sql.Statement;
 
 import org.apache.kafka.connect.data.Struct;
@@ -163,7 +162,7 @@ public void shouldProcessSavepoint() throws SQLException, InterruptedException {
                 connection.setAutoCommit(false);
                 final Statement statement = jdbc.createStatement();
                 statement.executeUpdate("INSERT INTO customers VALUES(default, 'first', 'first', 'first')");
-                final Savepoint savepoint = jdbc.setSavepoint();
+                jdbc.setSavepoint();
                 statement.executeUpdate("INSERT INTO customers VALUES(default, 'second', 'second', 'second')");
                 jdbc.commit();
                 connection.query("SELECT * FROM customers", rs -> {
@@ -239,7 +238,7 @@ public void shouldProcessLargeTransaction() throws SQLException, InterruptedExce
 
             // All records should be present only once
             records = consumeRecordsByTopic(numRecords);
-            int recordIndex = 0; 
+            int recordIndex = 0;
             for (SourceRecord r: records.allRecordsInOrder()) {
                 Struct envelope = (Struct)r.value();
                 assertThat(envelope.getString("op")).isEqualTo(("c"));

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -654,7 +654,7 @@ public static EventDeserializationFailureHandlingMode parse(String value) {
                                                                    .withDescription("The size of a look-ahead buffer used by the  binlog reader to decide whether"
                                                                            + "the transaction in progress is going to be committed or rolled back. "
                                                                            + "Defaults to " + DEFAULT_BINLOG_BUFFER_SIZE + ". Use 0 to disable look-ahead buffering.")
-                                                                   .withDefault(DEFAULT_BINLOG_BUFFER_SIZE)
+                                                                   .withDefault(0)
                                                                    .withValidation(Field::isNonNegativeInteger);
 
     /**

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/UniqueDatabase.java
Patch:
@@ -167,7 +167,8 @@ public Configuration.Builder defaultConfig() {
                 .with(MySqlConnectorConfig.SERVER_NAME, getServerName())
                 .with(MySqlConnectorConfig.POLL_INTERVAL_MS, 10)
                 .with(MySqlConnectorConfig.DATABASE_WHITELIST, getDatabaseName())
-                .with(MySqlConnectorConfig.DATABASE_HISTORY, FileDatabaseHistory.class);
+                .with(MySqlConnectorConfig.DATABASE_HISTORY, FileDatabaseHistory.class)
+                .with(MySqlConnectorConfig.BUFFER_SIZE_FOR_BINLOG_READER, 10000);
         if (dbHistoryPath != null) {
             builder.with(FileDatabaseHistory.FILE_PATH, dbHistoryPath);
         }

File: debezium-core/src/test/java/io/debezium/util/StringsTest.java
Patch:
@@ -270,7 +270,7 @@ public void regexSplit() {
         assertRegexSet("a\\,b", "a,b");
         assertRegexSet("a,b,", "a", "b");
         assertRegexSet("a,b\\,", "a", "b,");
-        assertRegexSet("a\\\\,b", "a\\,b");
+        assertRegexSet("a\\\\\\,b", "a\\\\,b");
                 assertRegexSet(
                 "DROP TEMPORARY TABLE IF EXISTS .+ /\\\\* generated by server \\\\*/,"
                 + "INSERT INTO mysql.rds_heartbeat2\\(.*\\,.*\\) values \\(.*\\,.*\\) ON DUPLICATE KEY UPDATE value = .*",

File: debezium-core/src/main/java/io/debezium/util/Strings.java
Patch:
@@ -87,18 +87,18 @@ public static <T> Set<T> listOf(String input, Function<String, T> factory) {
      * regular expressions.
      *
      * @param input the input string with comma-separated regular expressions. Comma can be escaped with backslash.
-     * @return the list of regular expression {@link Pattern}s included in the list; never null
+     * @return the set of regular expression {@link Pattern}s included within the given string; never null
      * @throws PatternSyntaxException if the input includes an invalid regular expression
      */
-    public static Set<Pattern> listOfRegex(String input) {
+    public static Set<Pattern> setOfRegex(String input) {
         return listOf(input, RegExSplitter::split, Pattern::compile);
     }
 
     /**
      * Generate the set of regular expression {@link Pattern}s that are specified in the string containing comma-separated
      * regular expressions.
      *
-     * @param input the input string with comma-separated regular expressions. . Comma can be escaped with backslash.
+     * @param input the input string with comma-separated regular expressions. Comma can be escaped with backslash.
      * @param regexFlags the flags for {@link Pattern#compile(String, int) compiling regular expressions}
      * @return the list of regular expression {@link Pattern}s included in the list; never null
      * @throws PatternSyntaxException if the input includes an invalid regular expression

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSchema.java
Patch:
@@ -62,7 +62,7 @@ protected PostgresSchema(PostgresConnectorConfig config) {
         this.tables = new Tables();
 
         PostgresValueConverter valueConverter = new PostgresValueConverter(config.decimalHandlingMode(), config.temporalPrecisionMode(),
-                ZoneOffset.UTC, null);
+                ZoneOffset.UTC, null, config.includeUnknownDatatypes());
         this.schemaNameValidator = AvroValidator.create(LOGGER)::validate;
         this.schemaBuilder = new TableSchemaBuilder(valueConverter, this.schemaNameValidator);
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsStreamProducer.java
Patch:
@@ -401,7 +401,7 @@ private Object[] columnValues(List<ReplicationMessage.Column> messageList, Table
             String columnName = Strings.unquoteIdentifierPart(message.getName());
             int position = columnNames.indexOf(columnName);
             assert position >= 0;
-            values[position] = message.getValue(this::typeResolverConnection);
+            values[position] = message.getValue(this::typeResolverConnection, taskContext.config().includeUnknownDatatypes());
         });
         return values;
     }

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ReplicationMessage.java
Patch:
@@ -36,7 +36,7 @@ public enum Operation {
     public interface Column {
         String getName();
         Object getType();
-        Object getValue(final PgConnectionSupplier connection);
+        Object getValue(PgConnectionSupplier connection, boolean includeUnknownDatatypes);
     }
 
     /**

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -718,12 +718,12 @@ public static EventDeserializationFailureHandlingMode parse(String value) {
 
     public static final Field BIGINT_UNSIGNED_HANDLING_MODE = Field.create("bigint.unsigned.handling.mode")
                                                            .withDisplayName("BIGINT UNSIGNED Handling")
-                                                           .withEnum(BigIntUnsignedHandlingMode.class, BigIntUnsignedHandlingMode.PRECISE)
+                                                           .withEnum(BigIntUnsignedHandlingMode.class, BigIntUnsignedHandlingMode.LONG)
                                                            .withWidth(Width.SHORT)
                                                            .withImportance(Importance.MEDIUM)
                                                            .withDescription("Specify how BIGINT UNSIGNED columns should be represented in change events, including:"
-                                                                            + "'precise' (the default) uses java.math.BigDecimal to represent values, which are encoded in the change events using a binary representation and Kafka Connect's 'org.apache.kafka.connect.data.Decimal' type; "
-                                                                            + "'long' represents values using Java's 'long', which may not offer the precision but will be far easier to use in consumers.");
+                                                                            + "'precise' uses java.math.BigDecimal to represent values, which are encoded in the change events using a binary representation and Kafka Connect's 'org.apache.kafka.connect.data.Decimal' type; "
+                                                                            + "'long' (the default) represents values using Java's 'long', which may not offer the precision but will be far easier to use in consumers.");
 
     public static final Field EVENT_DESERIALIZATION_FAILURE_HANDLING_MODE = Field.create("event.deserialization.failure.handling.mode")
             .withDisplayName("Event deserialization failure handling")

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlUnsignedIntegerIT.java
Patch:
@@ -205,7 +205,7 @@ public void shouldConsumeAllEventsFromDatabaseUsingSnapshot() throws SQLExceptio
             } else if (record.topic().endsWith("dbz_228_mediumint_unsigned")) {
                 assertMediumUnsigned(value);
             } else if (record.topic().endsWith("dbz_228_bigint_unsigned")) {
-                assertBigintUnsignedPrecise(value);
+                assertBigintUnsignedLong(value);
             }
         });
     }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlSchema.java
Patch:
@@ -19,11 +19,11 @@
 import io.debezium.config.Configuration;
 import io.debezium.connector.mysql.MySqlConnectorConfig.BigIntUnsignedHandlingMode;
 import io.debezium.connector.mysql.MySqlConnectorConfig.DecimalHandlingMode;
-import io.debezium.connector.mysql.MySqlConnectorConfig.TemporalPrecisionMode;
 import io.debezium.connector.mysql.MySqlSystemVariables.Scope;
 import io.debezium.document.Document;
 import io.debezium.jdbc.JdbcValueConverters.BigIntUnsignedMode;
 import io.debezium.jdbc.JdbcValueConverters.DecimalMode;
+import io.debezium.jdbc.TemporalPrecisionMode;
 import io.debezium.relational.Table;
 import io.debezium.relational.TableId;
 import io.debezium.relational.TableSchema;
@@ -92,14 +92,13 @@ public MySqlSchema(Configuration config, String serverName, Predicate<String> gt
         // Use MySQL-specific converters and schemas for values ...
         String timePrecisionModeStr = config.getString(MySqlConnectorConfig.TIME_PRECISION_MODE);
         TemporalPrecisionMode timePrecisionMode = TemporalPrecisionMode.parse(timePrecisionModeStr);
-        boolean adaptiveTimePrecision = TemporalPrecisionMode.ADAPTIVE.equals(timePrecisionMode);
         String decimalHandlingModeStr = config.getString(MySqlConnectorConfig.DECIMAL_HANDLING_MODE);
         DecimalHandlingMode decimalHandlingMode = DecimalHandlingMode.parse(decimalHandlingModeStr);
         DecimalMode decimalMode = decimalHandlingMode.asDecimalMode();
         String bigIntUnsignedHandlingModeStr = config.getString(MySqlConnectorConfig.BIGINT_UNSIGNED_HANDLING_MODE);
         BigIntUnsignedHandlingMode bigIntUnsignedHandlingMode = BigIntUnsignedHandlingMode.parse(bigIntUnsignedHandlingModeStr);
         BigIntUnsignedMode bigIntUnsignedMode = bigIntUnsignedHandlingMode.asBigIntUnsignedMode();
-        MySqlValueConverters valueConverters = new MySqlValueConverters(decimalMode, adaptiveTimePrecision, bigIntUnsignedMode);
+        MySqlValueConverters valueConverters = new MySqlValueConverters(decimalMode, timePrecisionMode, bigIntUnsignedMode);
         this.schemaBuilder = new TableSchemaBuilder(valueConverters, schemaNameValidator::validate);
 
         // Set up the server name and schema prefix ...

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -264,7 +264,7 @@ public void shouldConsumeAllEventsFromDatabaseUsingSnapshot() throws SQLExceptio
         // ---------------------------------------------------------------------------------------------------------------
         // Consume all of the events due to startup and initialization of the database
         // ---------------------------------------------------------------------------------------------------------------
-        SourceRecords records = consumeRecordsByTopic(5 + 9 + 9 + 4 + 11 + 1); // 11 schema change records + 1 SET statement
+        SourceRecords records = consumeRecordsByTopic(5 + 9 + 9 + 4 + 11 + 1 + 2); // 11 schema change records + 1 SET statement
         assertThat(records.recordsForTopic(DATABASE.getServerName()).size()).isEqualTo(12);
         assertThat(records.recordsForTopic(DATABASE.topicForTable("products")).size()).isEqualTo(9);
         assertThat(records.recordsForTopic(DATABASE.topicForTable("products_on_hand")).size()).isEqualTo(9);
@@ -696,12 +696,12 @@ public void shouldConsumeEventsWithMaskedAndBlacklistedColumns() throws SQLExcep
 
         // Consume the first records due to startup and initialization of the database ...
         // Testing.Print.enable();
-        SourceRecords records = consumeRecordsByTopic(9 + 9 + 4 + 5);
+        SourceRecords records = consumeRecordsByTopic(9 + 9 + 4 + 5 + 1);
         assertThat(records.recordsForTopic(RO_DATABASE.topicForTable("products")).size()).isEqualTo(9);
         assertThat(records.recordsForTopic(RO_DATABASE.topicForTable("products_on_hand")).size()).isEqualTo(9);
         assertThat(records.recordsForTopic(RO_DATABASE.topicForTable("customers")).size()).isEqualTo(4);
         assertThat(records.recordsForTopic(RO_DATABASE.topicForTable("orders")).size()).isEqualTo(5);
-        assertThat(records.topics().size()).isEqualTo(4);
+        assertThat(records.topics().size()).isEqualTo(5);
 
         // Check that all records are valid, can be serialized and deserialized ...
         records.forEach(this::validate);

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresSchema.java
Patch:
@@ -61,7 +61,7 @@ protected PostgresSchema(PostgresConnectorConfig config) {
         this.filters = new Filters(config);
         this.tables = new Tables();
 
-        PostgresValueConverter valueConverter = new PostgresValueConverter(config.decimalHandlingMode(), config.adaptiveTimePrecision(),
+        PostgresValueConverter valueConverter = new PostgresValueConverter(config.decimalHandlingMode(), config.temporalPrecisionMode(),
                 ZoneOffset.UTC, null);
         this.schemaNameValidator = AvroValidator.create(LOGGER)::validate;
         this.schemaBuilder = new TableSchemaBuilder(valueConverter, this.schemaNameValidator);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -46,6 +46,7 @@
 import io.debezium.data.VerifyRecord;
 import io.debezium.embedded.AbstractConnectorTest;
 import io.debezium.embedded.EmbeddedEngine;
+import io.debezium.jdbc.TemporalPrecisionMode;
 import io.debezium.util.Strings;
 
 /**
@@ -145,7 +146,7 @@ public void shouldValidateConfiguration() throws Exception {
         validateField(validatedConfig, PostgresConnectorConfig.COLUMN_BLACKLIST, null);
         validateField(validatedConfig, PostgresConnectorConfig.SNAPSHOT_MODE, INITIAL);
         validateField(validatedConfig, PostgresConnectorConfig.SNAPSHOT_LOCK_TIMEOUT_MS, PostgresConnectorConfig.DEFAULT_SNAPSHOT_LOCK_TIMEOUT_MILLIS);
-        validateField(validatedConfig, PostgresConnectorConfig.TIME_PRECISION_MODE, PostgresConnectorConfig.TemporalPrecisionMode.ADAPTIVE);
+        validateField(validatedConfig, PostgresConnectorConfig.TIME_PRECISION_MODE, TemporalPrecisionMode.ADAPTIVE);
         validateField(validatedConfig, PostgresConnectorConfig.DECIMAL_HANDLING_MODE, PostgresConnectorConfig.DecimalHandlingMode.PRECISE);
         validateField(validatedConfig, PostgresConnectorConfig.SSL_SOCKET_FACTORY, null);
         validateField(validatedConfig, PostgresConnectorConfig.TCP_KEEPALIVE, null);

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConnection.java
Patch:
@@ -341,7 +341,7 @@ public static interface CallPreparer {
      * @see #execute(Operations)
      */
     public JdbcConnection query(String query, ResultSetConsumer resultConsumer) throws SQLException {
-        return query(query,conn->conn.createStatement(),resultConsumer);
+        return query(query, Connection::createStatement, resultConsumer);
     }
 
     /**

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/pgproto/PgProtoReplicationMessage.java
Patch:
@@ -220,9 +220,7 @@ public Object getValue(PgProto.DatumMessage datumMessage, PgConnectionSupplier c
                 }
                 return null;
             default: {
-                LOGGER.warn("processing column '{}' with unknown data type '{}' as byte array", datumMessage.getColumnName(),
-                            datumMessage.getColumnType());
-                return datumMessage.hasDatumBytes()? datumMessage.getDatumBytes().toByteArray() : null;
+                return null;
             }
         }
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -98,8 +98,6 @@ public void shouldLoadSchemaForBuiltinPostgresTypes() throws Exception {
             assertTableSchema("public.geom_table", "p", Point.builder().optional().build());
             assertTableSchema("public.tstzrange_table", "unbounded_exclusive_range, bounded_inclusive_range",
                               Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA);
-            assertTableSchema("public.custom_table", "lt, i",
-                              Schema.OPTIONAL_BYTES_SCHEMA, Schema.OPTIONAL_BYTES_SCHEMA);
             assertTableSchema("public.array_table", "int_array, bigint_array, text_array",
                               SchemaBuilder.array(Schema.OPTIONAL_INT32_SCHEMA).optional().build(), SchemaBuilder.array(Schema.OPTIONAL_INT64_SCHEMA).optional().build(),
                               SchemaBuilder.array(Schema.OPTIONAL_STRING_SCHEMA).optional().build());

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -99,7 +99,7 @@ public void shouldLoadSchemaForBuiltinPostgresTypes() throws Exception {
             assertTableSchema("public.tstzrange_table", "unbounded_exclusive_range, bounded_inclusive_range",
                               Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA);
             assertTableSchema("public.custom_table", "lt, i",
-                              Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA);
+                              Schema.OPTIONAL_BYTES_SCHEMA, Schema.OPTIONAL_BYTES_SCHEMA);
             assertTableSchema("public.array_table", "int_array, bigint_array, text_array",
                               SchemaBuilder.array(Schema.OPTIONAL_INT32_SCHEMA).optional().build(), SchemaBuilder.array(Schema.OPTIONAL_INT64_SCHEMA).optional().build(),
                               SchemaBuilder.array(Schema.OPTIONAL_STRING_SCHEMA).optional().build());

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -98,6 +98,8 @@ public void shouldLoadSchemaForBuiltinPostgresTypes() throws Exception {
             assertTableSchema("public.geom_table", "p", Point.builder().optional().build());
             assertTableSchema("public.tstzrange_table", "unbounded_exclusive_range, bounded_inclusive_range",
                               Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA);
+            assertTableSchema("public.custom_table", "lt, i",
+                              Schema.OPTIONAL_STRING_SCHEMA, Schema.OPTIONAL_STRING_SCHEMA);
             assertTableSchema("public.array_table", "int_array, bigint_array, text_array",
                               SchemaBuilder.array(Schema.OPTIONAL_INT32_SCHEMA).optional().build(), SchemaBuilder.array(Schema.OPTIONAL_INT64_SCHEMA).optional().build(),
                               SchemaBuilder.array(Schema.OPTIONAL_STRING_SCHEMA).optional().build());

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/wal2json/Wal2JsonReplicationMessage.java
Patch:
@@ -228,6 +228,9 @@ public Object getValue(String columnName, String columnType, Value rawValue, fin
             case "_json":
             case "_ref_cursor":
                 try {
+                    if (rawValue.isNull()) {
+                        return null;
+                    }
                     final String dataString = rawValue.asString();
                     PgArray arrayData = new PgArray(connection.get(), Oid.valueOf(columnType.substring(1) + "_array"), dataString);
                     Object deserializedArray = arrayData.getArray();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -1229,7 +1229,7 @@ protected void parseAlterSpecification(Marker start, TableEditor table, Consumer
             }
             tokens.consume(); // column name
             if (!tokens.canConsume("DROP", "DEFAULT")) {
-                tokens.consume("SET", "DEFAULT");
+                tokens.consume("SET");
                 parseDefaultClause(start);
             }
         } else if (tokens.canConsume("CHANGE")) {

File: debezium-core/src/test/java/io/debezium/kafka/KafkaCluster.java
Patch:
@@ -161,7 +161,8 @@ public KafkaCluster usingDirectory(File dataDir) {
     public KafkaCluster withKafkaConfiguration(Properties properties) {
         if (running) throw new IllegalStateException("Unable to add a broker when the cluster is already running");
         if (properties != null && !properties.isEmpty()) {
-            kafkaConfig = new Properties(properties);
+            kafkaConfig = new Properties();
+            kafkaConfig.putAll(properties);
             kafkaServers.values().forEach(kafka -> kafka.setProperties(kafkaConfig));
         }
         return this;

File: debezium-core/src/test/java/io/debezium/kafka/KafkaServer.java
Patch:
@@ -151,7 +151,8 @@ public KafkaServer setPort(int port) {
      * @return the properties for the currently-running server; may be empty if not running
      */
     public Properties config() {
-        Properties runningConfig = new Properties(config);
+        Properties runningConfig = new Properties();
+        runningConfig.putAll(config);
         runningConfig.setProperty(KafkaConfig.ZkConnectProp(), zookeeperConnection());
         runningConfig.setProperty(KafkaConfig.BrokerIdProp(), Integer.toString(brokerId));
         runningConfig.setProperty(KafkaConfig.HostNameProp(), "localhost");

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -121,7 +121,7 @@ protected void initializeDataTypes(DataTypeParser dataTypes) {
         dataTypes.register(Types.BLOB, "MEDIUMTEXT BINARY");
         dataTypes.register(Types.BLOB, "LONGTEXT BINARY");
         dataTypes.register(Types.VARCHAR, "TINYTEXT");
-        dataTypes.register(Types.VARCHAR, "TEXT");
+        dataTypes.register(Types.VARCHAR, "TEXT[(L)]");
         dataTypes.register(Types.VARCHAR, "MEDIUMTEXT");
         dataTypes.register(Types.VARCHAR, "LONGTEXT");
         dataTypes.register(Types.CHAR, "ENUM(...)");

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParser.java
Patch:
@@ -747,7 +747,7 @@ protected Object parseLiteral(Marker start) {
     protected Object parseNumericLiteral(Marker start, boolean signed) {
         StringBuilder sb = new StringBuilder();
         boolean decimal = false;
-        if (signed && tokens.matches("+", "-")) {
+        if (signed && tokens.matchesAnyOf("+", "-")) {
             sb.append(tokens.consumeAnyOf("+", "-"));
         }
         if (!tokens.canConsume('.')) {

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsStreamProducer.java
Patch:
@@ -36,8 +36,9 @@
 import io.debezium.util.Strings;
 
 /**
- * A {@link RecordsProducer} which creates {@link org.apache.kafka.connect.source.SourceRecord records} from a Postgres
- * streaming replication connection and {@link io.debezium.connector.postgresql.connection.ReplicationMessage messages}.
+ * A {@link RecordsProducer} which creates {@link SourceRecord records} from a
+ * Postgres streaming replication connection and {@link ReplicationMessage
+ * messages}.
  *
  * @author Horia Chiorean (hchiorea@redhat.com)
  */

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresReplicationConnection.java
Patch:
@@ -10,7 +10,6 @@
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.SQLWarning;
-
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -49,7 +48,7 @@ public class PostgresReplicationConnection extends JdbcConnection implements Rep
      *
      * @param config the JDBC configuration for the connection; may not be null
      * @param slotName the name of the DB slot for logical replication; may not be null
-     * @param plugin the type of the server side plugin used for streaming changes; may not be null;
+     * @param plugin decoder matching the server side plug-in used for streaming changes; may not be null
      * @param dropSlotOnClose whether the replication slot should be dropped once the connection is closed
      * @param statusUpdateIntervalMillis the number of milli-seconds at which the replication connection should periodically send status
      * updates to the server
@@ -256,7 +255,7 @@ protected static void defaultSettings(Configuration.Builder builder) {
 
     protected static class ReplicationConnectionBuilder implements Builder {
 
-        private Configuration config;
+        private final Configuration config;
         private String slotName = DEFAULT_SLOT_NAME;
         private PostgresConnectorConfig.LogicalDecoder plugin = PostgresConnectorConfig.LogicalDecoder.DECODERBUFS;
         private boolean dropSlotOnClose = DEFAULT_DROP_SLOT_ON_CLOSE;

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -124,7 +124,6 @@ public void shouldValidateConfiguration() throws Exception {
 
         // validate the non required fields
         validateField(validatedConfig, PostgresConnectorConfig.PLUGIN_NAME, LogicalDecoder.DECODERBUFS.getValue());
-        validateField(validatedConfig, PostgresConnectorConfig.PLUGIN_DECODING_CLASS, null);
         validateField(validatedConfig, PostgresConnectorConfig.SLOT_NAME, ReplicationConnection.Builder.DEFAULT_SLOT_NAME);
         validateField(validatedConfig, PostgresConnectorConfig.DROP_SLOT_ON_STOP, Boolean.FALSE);
         validateField(validatedConfig, PostgresConnectorConfig.PORT, PostgresConnectorConfig.DEFAULT_PORT);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlSchema.java
Patch:
@@ -163,7 +163,7 @@ public Filters filters() {
 
     /**
      * Get all of the table definitions for all database tables as defined by
-     * {@link #applyDdl(SourceInfo, String, String, DatabaseStatementStringConsumer) applied DDL statements}, including those
+     * {@link #applyDdl(SourceInfo, String, String, DatabaseStatementStringConsumer) applied DDL statements}, excluding those
      * that have been excluded by the {@link #filters() filters}.
      * 
      * @return the table definitions; never null

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/ReplicatorIT.java
Patch:
@@ -12,6 +12,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicReference;
 
+import com.mongodb.util.JSON;
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
 import org.bson.Document;
@@ -208,7 +209,7 @@ public void shouldReplicateContent() throws InterruptedException {
         records.forEach(record -> {
             VerifyRecord.isValid(record);
             Struct key = (Struct) record.key();
-            ObjectId id = new ObjectId(key.getString("_id"));
+            ObjectId id = (ObjectId)(JSON.parse(key.getString("id")));
             foundIds.add(id);
             if (record.value() != null) {
                 Struct value = (Struct) record.value();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -89,6 +89,8 @@ protected void initializeDataTypes(DataTypeParser dataTypes) {
         dataTypes.register(Types.DOUBLE, "DOUBLE[(M[,D])] [UNSIGNED|SIGNED] [ZEROFILL]");
         dataTypes.register(Types.FLOAT, "FLOAT[(M[,D])] [UNSIGNED|SIGNED] [ZEROFILL]");
         dataTypes.register(Types.DECIMAL, "DECIMAL[(M[,D])] [UNSIGNED|SIGNED] [ZEROFILL]");
+        dataTypes.register(Types.DECIMAL, "FIXED[(M[,D])] [UNSIGNED|SIGNED] [ZEROFILL]");
+        dataTypes.register(Types.DECIMAL, "DEC[(M[,D])] [UNSIGNED|SIGNED] [ZEROFILL]");
         dataTypes.register(Types.NUMERIC, "NUMERIC[(M[,D])] [UNSIGNED|SIGNED] [ZEROFILL]");
         dataTypes.register(Types.BOOLEAN, "BOOLEAN");
         dataTypes.register(Types.BOOLEAN, "BOOL");

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -699,6 +699,7 @@ public void onConnect(BinaryLogClient client) {
 
         @Override
         public void onCommunicationFailure(BinaryLogClient client, Exception ex) {
+            logger.debug("A communication failure event arrived", ex);
             try {
                 // Stop BinaryLogClient background threads
                 client.disconnect();
@@ -711,6 +712,7 @@ public void onCommunicationFailure(BinaryLogClient client, Exception ex) {
 
         @Override
         public void onEventDeserializationFailure(BinaryLogClient client, Exception ex) {
+            logger.debug("A deserialization failure event arrived", ex);
             BinlogReader.this.failed(ex);
         }
     }

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcValueConverters.java
Patch:
@@ -75,8 +75,8 @@ public static enum DecimalMode {
 
     protected final Logger logger = LoggerFactory.getLogger(getClass());
     private final ZoneOffset defaultOffset;
-    private final boolean adaptiveTimePrecision;
-    private final DecimalMode decimalMode;
+    protected final boolean adaptiveTimePrecision;
+    protected final DecimalMode decimalMode;
     private final TemporalAdjuster adjuster;
 
     /**

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnectorConfig.java
Patch:
@@ -368,7 +368,7 @@ public static TopicSelectionStrategy parse(String value) {
                                                     .withType(Type.INT)
                                                     .withWidth(Width.SHORT)
                                                     .withImportance(Importance.MEDIUM)
-                                                    .withDescription("Maximum size of the queue for change events read from the database log but not yet recorded or forwarded. Defaults to 2048, and should always be larger than the maximum batch size.")
+                                                    .withDescription("Maximum size of the queue for change events read from the database log but not yet recorded or forwarded. Defaults to 20480, and should always be larger than the maximum batch size.")
                                                     .withDefault(DEFAULT_MAX_QUEUE_SIZE)
                                                     .withValidation(PostgresConnectorConfig::validateMaxQueueSize);
 
@@ -377,7 +377,7 @@ public static TopicSelectionStrategy parse(String value) {
                                                     .withType(Type.INT)
                                                     .withWidth(Width.SHORT)
                                                     .withImportance(Importance.MEDIUM)
-                                                    .withDescription("Maximum size of each batch of source records. Defaults to 10024.")
+                                                    .withDescription("Maximum size of each batch of source records. Defaults to 10240.")
                                                     .withDefault(DEFAULT_MAX_BATCH_SIZE)
                                                     .withValidation(Field::isPositiveInteger);
 
@@ -395,7 +395,7 @@ public static TopicSelectionStrategy parse(String value) {
                                                       .withType(Type.LONG)
                                                       .withWidth(Width.SHORT)
                                                       .withImportance(Importance.MEDIUM)
-                                                      .withDescription("Frequency in milliseconds to wait for new change events to appear after receiving no events. Defaults to 1 second (1000 ms).")
+                                                      .withDescription("Frequency in milliseconds to wait for new change events to appear after receiving no events. Defaults to 0.5 second (500 ms).")
                                                       .withDefault(DEFAULT_POLL_INTERVAL_MILLIS)
                                                       .withValidation(Field::isPositiveInteger);
 

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresValueConverter.java
Patch:
@@ -78,6 +78,8 @@ public SchemaBuilder schemaBuilder(Column column) {
             case PgOid.JSONB_JDBC_OID:
             case PgOid.JSON:
                 return Json.builder();
+            case PgOid.TSTZRANGE_OID:
+                return SchemaBuilder.string();
             case PgOid.UUID:
                 return Uuid.builder();
             case PgOid.POINT:
@@ -106,6 +108,7 @@ public ValueConverter converter(Column column, Field fieldDefn) {
                 return data -> convertBigInt(column, fieldDefn, data);
             case PgOid.JSONB_JDBC_OID:
             case PgOid.UUID:
+            case PgOid.TSTZRANGE_OID:
             case PgOid.JSON:
                 return data -> super.convertString(column, fieldDefn, data);
             case PgOid.POINT:

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/RecordsStreamProducer.java
Patch:
@@ -8,6 +8,7 @@
 
 import java.io.IOException;
 import java.math.BigDecimal;
+import java.nio.charset.Charset;
 import java.sql.SQLException;
 import java.util.List;
 import java.util.Map;
@@ -472,6 +473,8 @@ protected Object extractValueFromMessage(PgProto.DatumMessage datumMessage) {
                 PgProto.Point datumPoint = datumMessage.getDatumPoint();
                 return new PGpoint(datumPoint.getX(), datumPoint.getY());
             }
+            case PgOid.TSTZRANGE_OID:
+                return datumMessage.hasDatumBytes() ? new String(datumMessage.getDatumBytes().toByteArray(), Charset.forName("UTF-8")) : null;
             default: {
                 logger.warn("processing column '{}' with unknown data type '{}' as byte array", datumMessage.getColumnName(),
                             datumMessage.getColumnType());

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresSchemaIT.java
Patch:
@@ -46,7 +46,7 @@ public class PostgresSchemaIT {
     
     private static final String[] TEST_TABLES = new String[] { "public.numeric_table", "public.string_table", "public.cash_table",
                                                                "public.bitbin_table",
-                                                               "public.time_table", "public.text_table", "public.geom_table" };
+                                                               "public.time_table", "public.text_table", "public.geom_table", "public.tstzrange_table" };
     
     private PostgresSchema schema;
     
@@ -82,6 +82,7 @@ public void shouldLoadSchemaForBuiltinPostgresTypes() throws Exception {
                               Json.builder().optional().build(), Json.builder().optional().build(), Xml.builder().optional().build(),
                               Uuid.builder().optional().build());
             assertTableSchema("public.geom_table", "p", Point.builder().optional().build());
+            assertTableSchema("public.tstzrange_table", "t", Schema.OPTIONAL_STRING_SCHEMA);
         }
     }
     

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -535,7 +535,7 @@ public static SecureConnectionMode parse(String value, String defaultValue) {
                                                            .withValidation(Field::isPositiveInteger);
 
     public static final Field KEEP_ALIVE = Field.create("connect.keep.alive")
-                                                .withDisplayName("Connection Timeout (ms)")
+                                                .withDisplayName("Keep connection alive (true/false)")
                                                 .withType(Type.BOOLEAN)
                                                 .withWidth(Width.SHORT)
                                                 .withImportance(Importance.LOW)

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ReplicationConnection.java
Patch:
@@ -122,7 +122,7 @@ interface Builder {
         /**
          * The number of seconds the replication connection should periodically send updates to the server.
          * 
-         * @param statusUpdateIntervalSeconds a number of seconds; must be positive
+         * @param statusUpdateIntervalSeconds a number of seconds; zero or negative disables
          * @return this instance
          * @see #DEFAULT_STATUS_UPDATE_SECONDS
          */

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -97,9 +97,9 @@ protected void initializeDataTypes(DataTypeParser dataTypes) {
         dataTypes.register(Types.TIMESTAMP_WITH_TIMEZONE, "TIMESTAMP[(L)]"); // includes timezone information
         dataTypes.register(Types.TIMESTAMP, "DATETIME[(L)]");
         dataTypes.register(Types.INTEGER, "YEAR[(2|4)]");
-        dataTypes.register(Types.BLOB, "CHAR[(L)] BINARY");
-        dataTypes.register(Types.BLOB, "VARCHAR(L) BINARY");
-        dataTypes.register(Types.BLOB, "BINARY[(L)]");
+        dataTypes.register(Types.BINARY, "CHAR[(L)] BINARY");
+        dataTypes.register(Types.VARBINARY, "VARCHAR(L) BINARY");
+        dataTypes.register(Types.BINARY, "BINARY[(L)]");
         dataTypes.register(Types.VARCHAR, "VARCHAR(L)");
         dataTypes.register(Types.NVARCHAR, "NVARCHAR(L)");
         dataTypes.register(Types.NVARCHAR, "NATIONAL VARCHAR(L)");

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDdlParserTest.java
Patch:
@@ -143,7 +143,7 @@ public void shouldParseCreateUserTable() {
         Table foo = tables.forTable(new TableId(null, null, "user"));
         assertThat(foo).isNotNull();
         assertThat(foo.columnNames()).contains("Host", "User", "Select_priv");
-        assertColumn(foo, "Host", "CHAR BINARY", Types.BLOB, 60, -1, false, false, false);
+        assertColumn(foo, "Host", "CHAR BINARY", Types.BINARY, 60, -1, false, false, false);
 
         parser.parse("DROP TABLE user", tables);
         assertThat(tables.size()).isEqualTo(0);

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SnapshotReaderIT.java
Patch:
@@ -5,6 +5,7 @@
  */
 package io.debezium.connector.mysql;
 
+import static org.fest.assertions.Assertions.assertThat;
 import static org.junit.Assert.fail;
 
 import java.nio.file.Path;
@@ -17,8 +18,6 @@
 import org.junit.Before;
 import org.junit.Test;
 
-import static org.fest.assertions.Assertions.assertThat;
-
 import io.debezium.config.Configuration;
 import io.debezium.connector.mysql.MySqlConnectorConfig.SecureConnectionMode;
 import io.debezium.data.KeyValueStore;
@@ -78,7 +77,7 @@ protected Configuration.Builder simpleConfig() {
                             .with(MySqlConnectorConfig.PORT, port)
                             .with(MySqlConnectorConfig.USER, "snapper")
                             .with(MySqlConnectorConfig.PASSWORD, "snapperpass")
-                            .with(MySqlConnectorConfig.SSL_MODE, SecureConnectionMode.DISABLED.toString().toLowerCase())
+                            .with(MySqlConnectorConfig.SSL_MODE, SecureConnectionMode.DISABLED)
                             .with(MySqlConnectorConfig.SERVER_ID, 18911)
                             .with(MySqlConnectorConfig.SERVER_NAME, LOGICAL_NAME)
                             .with(MySqlConnectorConfig.POLL_INTERVAL_MS, 10)

File: debezium-core/src/main/java/io/debezium/transforms/ByLogicalTableRouter.java
Patch:
@@ -145,7 +145,7 @@ public R apply(R record) {
             return record;
         }
 
-        logger.info("Applying topic name transformation from " + oldTopic + " to " + newTopic + ".");
+        logger.debug("Applying topic name transformation from " + oldTopic + " to " + newTopic + ".");
         final Struct oldKey = requireStruct(record.key(), "Updating schema");
         final Schema newKeySchema = updateKeySchema(oldKey.schema(), newTopic);
         final Struct newKey = updateKey(newKeySchema, oldKey, oldTopic);

File: debezium-core/src/main/java/io/debezium/transforms/ByLogicalTableRouter.java
Patch:
@@ -145,7 +145,7 @@ public R apply(R record) {
             return record;
         }
 
-        logger.info("Applying topic name transformation from " + oldTopic + " to " + newTopic + ".");
+        logger.debug("Applying topic name transformation from " + oldTopic + " to " + newTopic + ".");
         final Struct oldKey = requireStruct(record.key(), "Updating schema");
         final Schema newKeySchema = updateKeySchema(oldKey.schema(), newTopic);
         final Struct newKey = updateKey(newKeySchema, oldKey, oldTopic);

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -24,6 +24,7 @@
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.function.Predicate;
 import java.util.stream.IntStream;
+
 import org.apache.kafka.common.config.Config;
 import org.apache.kafka.common.config.ConfigDef;
 import org.apache.kafka.connect.data.Struct;
@@ -128,7 +129,7 @@ public void shouldValidateConfiguration() throws Exception {
         validateField(validatedConfig, PostgresConnectorConfig.ROWS_FETCH_SIZE, PostgresConnectorConfig.DEFAULT_ROWS_FETCH_SIZE);
         validateField(validatedConfig, PostgresConnectorConfig.POLL_INTERVAL_MS, PostgresConnectorConfig.DEFAULT_POLL_INTERVAL_MILLIS);
         validateField(validatedConfig, PostgresConnectorConfig.SSL_MODE, 
-                      PostgresConnectorConfig.SecureConnectionMode.DISABLED.name().toLowerCase());
+                      PostgresConnectorConfig.SecureConnectionMode.DISABLED.getValue());
         validateField(validatedConfig, PostgresConnectorConfig.SSL_CLIENT_CERT, null);
         validateField(validatedConfig, PostgresConnectorConfig.SSL_CLIENT_KEY, null);
         validateField(validatedConfig, PostgresConnectorConfig.SSL_CLIENT_KEY_PASSWORD, null);
@@ -158,7 +159,7 @@ public void shouldSupportSSLParameters() throws Exception {
             assertThat(error).isInstanceOf(ConnectException.class);
             Throwable cause = error.getCause();
             assertThat(cause).isInstanceOf(SQLException.class);
-            assertThat(PSQLState.CONNECTION_UNABLE_TO_CONNECT).isEqualTo(new PSQLState(((SQLException)cause).getSQLState()));
+            assertThat(PSQLState.CONNECTION_REJECTED).isEqualTo(new PSQLState(((SQLException)cause).getSQLState()));
         });
         assertConnectorNotRunning();
     }

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -24,6 +24,7 @@
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.function.Predicate;
 import java.util.stream.IntStream;
+
 import org.apache.kafka.common.config.Config;
 import org.apache.kafka.common.config.ConfigDef;
 import org.apache.kafka.connect.data.Struct;
@@ -37,7 +38,6 @@
 import org.postgresql.util.PSQLState;
 
 import io.debezium.config.Configuration;
-import io.debezium.config.EnumeratedValue;
 import io.debezium.config.Field;
 import io.debezium.connector.postgresql.connection.ReplicationConnection;
 import io.debezium.data.Envelope;

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/PostgresConnectorIT.java
Patch:
@@ -37,6 +37,7 @@
 import org.postgresql.util.PSQLState;
 
 import io.debezium.config.Configuration;
+import io.debezium.config.EnumeratedValue;
 import io.debezium.config.Field;
 import io.debezium.connector.postgresql.connection.ReplicationConnection;
 import io.debezium.data.Envelope;
@@ -128,7 +129,7 @@ public void shouldValidateConfiguration() throws Exception {
         validateField(validatedConfig, PostgresConnectorConfig.ROWS_FETCH_SIZE, PostgresConnectorConfig.DEFAULT_ROWS_FETCH_SIZE);
         validateField(validatedConfig, PostgresConnectorConfig.POLL_INTERVAL_MS, PostgresConnectorConfig.DEFAULT_POLL_INTERVAL_MILLIS);
         validateField(validatedConfig, PostgresConnectorConfig.SSL_MODE, 
-                      PostgresConnectorConfig.SecureConnectionMode.DISABLED.name().toLowerCase());
+                      PostgresConnectorConfig.SecureConnectionMode.DISABLED.getValue());
         validateField(validatedConfig, PostgresConnectorConfig.SSL_CLIENT_CERT, null);
         validateField(validatedConfig, PostgresConnectorConfig.SSL_CLIENT_KEY, null);
         validateField(validatedConfig, PostgresConnectorConfig.SSL_CLIENT_KEY_PASSWORD, null);
@@ -158,7 +159,7 @@ public void shouldSupportSSLParameters() throws Exception {
             assertThat(error).isInstanceOf(ConnectException.class);
             Throwable cause = error.getCause();
             assertThat(cause).isInstanceOf(SQLException.class);
-            assertThat(PSQLState.CONNECTION_UNABLE_TO_CONNECT).isEqualTo(new PSQLState(((SQLException)cause).getSQLState()));
+            assertThat(PSQLState.CONNECTION_REJECTED).isEqualTo(new PSQLState(((SQLException)cause).getSQLState()));
         });
         assertConnectorNotRunning();
     }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlGeometry.java
Patch:
@@ -31,9 +31,9 @@ private MySqlGeometry(byte[] wkb) {
     }
 
     /**
-     * Create a MySqlGeometry from the original byte array from MySQL binglog event
+     * Create a MySqlGeometry from the original byte array from MySQL binlog event
      *
-     * @param mysqlBytes he original byte array from MySQL binglog event
+     * @param mysqlBytes he original byte array from MySQL binlog event
      *
      * @return a {@link MySqlGeometry} which represents a MySqlGeometry API
      */
@@ -63,7 +63,7 @@ public Point getPoint() {
      * Since MySQL prepends 4 bytes as type prefix, we remove those bytes in order to have a valid WKB
      * representation
      *
-     * @param source      the original byte array from MySQL binglog event
+     * @param source      the original byte array from MySQL binlog event
      *
      * @return a {@link byte[]} which represents the standard well-known binary
      */

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlValueConverters.java
Patch:
@@ -474,7 +474,7 @@ protected Object convertPoint(Column column, Field fieldDefn, Object data){
         Schema schema = fieldDefn.schema();
 
         if (data instanceof byte[]) {
-            // The binglog utility sends a byte array for any Geometry type, we will use our own binaryParse to parse the byte to WKB, hence
+            // The binlog utility sends a byte array for any Geometry type, we will use our own binaryParse to parse the byte to WKB, hence
             // to the suitable class
             try {
                 MySqlGeometry mySqlGeometry = MySqlGeometry.fromBytes((byte[]) data);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -125,6 +125,7 @@ protected void initializeDataTypes(DataTypeParser dataTypes) {
         dataTypes.register(Types.CHAR, "ENUM(...)");
         dataTypes.register(Types.CHAR, "SET(...)");
         dataTypes.register(Types.OTHER, "JSON");
+        dataTypes.register(Types.OTHER, "POINT");
     }
 
     @Override

File: debezium-core/src/main/java/io/debezium/text/TokenStream.java
Patch:
@@ -938,7 +938,7 @@ public TokenStream consumeThrough(String expected, String skipMatchingTokens) th
      * @throws IllegalStateException if this method was called before the stream was {@link #start() started}
      */
     public TokenStream consumeUntil(char expected) throws ParsingException, IllegalStateException {
-        return consumeUntil(String.valueOf(expected), null);
+        return consumeUntil(String.valueOf(expected), (String[])null);
     }
 
     /**
@@ -972,7 +972,7 @@ public TokenStream consumeUntil(char expected, char skipMatchingTokens) throws P
      * @throws IllegalStateException if this method was called before the stream was {@link #start() started}
      */
     public TokenStream consumeUntil(String expected) throws ParsingException, IllegalStateException {
-        return consumeUntil(expected, null);
+        return consumeUntil(expected, (String[])null);
     }
 
     /**

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -261,6 +261,7 @@ public void shouldValidateAcceptableConfiguration() {
                                             "regression_test.dbz_123_bitvaluetest",
                                             "regression_test.dbz_104_customers",
                                             "regression_test.dbz_147_decimalvalues",
+                                            "regression_test.dbz_195_numvalues",
                                             "json_test.dbz_126_jsontable");
 
         // Now set the whitelist to two databases ...

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -261,6 +261,7 @@ public void shouldValidateAcceptableConfiguration() {
                                             "regression_test.dbz_123_bitvaluetest",
                                             "regression_test.dbz_104_customers",
                                             "regression_test.dbz_147_decimalvalues",
+                                            "regression_test.dbz_195_numvalues",
                                             "json_test.dbz_126_jsontable");
 
         // Now set the whitelist to two databases ...

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -130,7 +130,7 @@ protected void initializeKeywords(TokenSet keywords) {
 
     @Override
     protected void initializeStatementStarts(TokenSet statementStartTokens) {
-        statementStartTokens.add("CREATE", "ALTER", "DROP", "INSERT", "GRANT", "REVOKE", "FLUSH", "TRUNCATE", "COMMIT", "USE");
+        statementStartTokens.add("CREATE", "ALTER", "DROP", "INSERT", "GRANT", "REVOKE", "FLUSH", "TRUNCATE", "COMMIT", "USE", "SAVEPOINT");
     }
 
     @Override

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -606,7 +606,7 @@ protected void parseCreateDefinition(Marker start, TableEditor table) {
             }
             parseIndexColumnNames(start);
             parseIndexOptions(start);
-        } else if (!quoted && tokens.canConsume("FULLTEXT", "SPATIAL")) {
+        } else if (!quoted && tokens.canConsumeAnyOf("FULLTEXT", "SPATIAL")) {
             tokens.canConsumeAnyOf("INDEX", "KEY");
             if (!tokens.matches('(')) {
                 tokens.consume(); // name of unique index ...

File: debezium-embedded/src/test/java/io/debezium/embedded/ConnectorOutputTest.java
Patch:
@@ -1190,7 +1190,7 @@ protected static File replaceVariables(InputStream stream, AvailableVariables va
                 } catch (IOException e) {
                     throw new RuntimeException("Error writing to file '" + tmpFile + "'", e);
                 }
-            });
+            }, StandardCharsets.UTF_8);
         }
         return tmpFile;
     }

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -464,7 +464,7 @@ private EmbeddedEngine(Configuration config, ClassLoader classLoader, Clock cloc
         this.classLoader = classLoader;
         this.clock = clock;
         this.completionCallback = completionCallback != null ? completionCallback : (success, msg, error) -> {
-            if (success) logger.error(msg, error);
+            if (!success) logger.error(msg, error);
         };
         this.connectorCallback = connectorCallback;
         this.completionResult = new CompletionResult();

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -464,7 +464,7 @@ private EmbeddedEngine(Configuration config, ClassLoader classLoader, Clock cloc
         this.classLoader = classLoader;
         this.clock = clock;
         this.completionCallback = completionCallback != null ? completionCallback : (success, msg, error) -> {
-            if (success) logger.error(msg, error);
+            if (!success) logger.error(msg, error);
         };
         this.connectorCallback = connectorCallback;
         this.completionResult = new CompletionResult();

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresTaskContext.java
Patch:
@@ -40,9 +40,9 @@ private TopicSelector initTopicSelector() {
         PostgresConnectorConfig.TopicSelectionStrategy topicSelectionStrategy = config.topicSelectionStrategy();
         switch (topicSelectionStrategy) {
             case TOPIC_PER_SCHEMA: 
-                return TopicSelector.TOPIC_PER_SCHEMA;
+                return TopicSelector.topicPerSchema(config.serverName());
             case TOPIC_PER_TABLE:
-                return TopicSelector.TOPIC_PER_TABLE;
+                return TopicSelector.topicPerTable(config.serverName());
             default: 
                 throw new IllegalArgumentException("Unknown topic selection strategy: " + topicSelectionStrategy);
         }

File: debezium-core/src/main/java/io/debezium/data/Uuid.java
Patch:
@@ -16,7 +16,7 @@
  */
 public class Uuid {
 
-    public static final String LOGICAL_NAME = "io.debezium.data.uuid";
+    public static final String LOGICAL_NAME = "io.debezium.data.Uuid";
 
     /**
      * Returns a {@link SchemaBuilder} for a Uuid field. You can use the resulting SchemaBuilder

File: debezium-core/src/main/java/io/debezium/data/geometry/Point.java
Patch:
@@ -17,7 +17,7 @@
  */
 public class Point {
 
-    public static final String LOGICAL_NAME = "io.debezium.data.geometry.point";
+    public static final String LOGICAL_NAME = "io.debezium.data.geometry.Point";
     public static final String X_FIELD = "x";
     public static final String Y_FIELD = "y";
     

File: debezium-core/src/main/java/io/debezium/time/MicroTimestamp.java
Patch:
@@ -22,7 +22,7 @@
  */
 public class MicroTimestamp {
 
-    public static final String SCHEMA_NAME = "io.debezium.time.NanoTimestamp";
+    public static final String SCHEMA_NAME = "io.debezium.time.MicroTimestamp";
 
     /**
      * Returns a {@link SchemaBuilder} for a {@link MicroTimestamp}. The resulting schema will describe a field

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/PostgresConnector.java
Patch:
@@ -22,7 +22,6 @@
 
 import io.debezium.config.Configuration;
 import io.debezium.connector.postgresql.connection.PostgresConnection;
-import io.debezium.connector.postgresql.connection.ServerInfo;
 
 /**
  * A Kafka Connect source connector that creates tasks which use Postgresql streaming replication off a logical replication slot
@@ -95,8 +94,9 @@ public Config validate(Map<String, String> connectorConfigs) {
             // Try to connect to the database ...
             try (PostgresConnection connection = new PostgresConnection(config.jdbcConfig())) {
                 try {
-                    ServerInfo serverInfo = connection.serverInfo();
-                    logger.info(serverInfo.toString());
+                    connection.execute("SELECT version()");
+                    logger.info("Successfully tested connection for {} with user '{}'", connection.connectionString(),
+                                connection.username());
                 } catch (SQLException e) {
                     logger.info("Failed testing connection for {} with user '{}'", connection.connectionString(),
                                 connection.username());

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/PostgresConnection.java
Patch:
@@ -204,7 +204,7 @@ public ServerInfo serverInfo() throws SQLException {
         if (username != null) {
             query("SELECT oid, rolname, rolsuper, rolinherit, rolcreaterole, rolcreatedb, rolcanlogin, rolreplication FROM pg_roles " +
                   "WHERE pg_has_role('" + username +"', oid, 'member')", rs -> {
-                if (rs.next()) {
+                while (rs.next()) {
                     String roleInfo = "superuser: " + rs.getBoolean(3) + ", replication: " + rs.getBoolean(8) + 
                                       ", inherit: " + rs.getBoolean(4) + ", create role: " + rs.getBoolean(5) +
                                       ", create db: " + rs.getBoolean(6) + ", can log in: " + rs.getBoolean(7);
@@ -226,7 +226,7 @@ private static void validateServerVersion(Statement statement) throws SQLExcepti
         int majorVersion = metaData.getDatabaseMajorVersion();
         int minorVersion = metaData.getDriverMinorVersion();
         if (majorVersion < 9 || (majorVersion == 9 && minorVersion < 4)) {
-            throw new IllegalStateException("Cannot connect to a version of Postgres lower than 9.4");
+            throw new SQLException("Cannot connect to a version of Postgres lower than 9.4");
         }
     }
     

File: debezium-connector-postgres/src/main/java/io/debezium/connector/postgresql/connection/ServerInfo.java
Patch:
@@ -90,7 +90,7 @@ public String toString() {
                                             .map(entry -> "\trole '" + entry.getKey() + "' [" + entry.getValue() + "]")
                                             .collect(Collectors.joining(lineSeparator));
     
-        return "User '" + username + "' connected to database '" + database + "' on " + server + " with:" + lineSeparator + roles;
+        return "user '" + username + "' connected to database '" + database + "' on " + server + " with roles:" + lineSeparator + roles;
     }
     
     /**

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/TestHelper.java
Patch:
@@ -120,7 +120,7 @@ protected static Configuration.Builder defaultConfig() {
     
     protected static void executeDDL(String ddlFile) throws Exception {
         URL ddlTestFile = TestHelper.class.getClassLoader().getResource(ddlFile);
-        assertNotNull("Cannot locate postgres_create_tables.ddl", ddlTestFile);
+        assertNotNull("Cannot locate " + ddlFile, ddlTestFile);
         String statements = Files.readAllLines(Paths.get(ddlTestFile.toURI()))
                                  .stream()
                                  .collect(Collectors.joining(System.lineSeparator()));

File: debezium-connector-postgres/src/test/java/io/debezium/connector/postgresql/connection/PostgresConnectionIT.java
Patch:
@@ -91,8 +91,9 @@ public void shouldDropReplicationSlot() throws Exception {
         }
         // create a new replication slot via a replication connection
         try (ReplicationConnection connection = TestHelper.createForReplication("test", false)) {
-            //nothing
-        };
+            assertTrue(connection.isConnected());
+        }
+        // drop the slot from the previous connection
         try (PostgresConnection connection = TestHelper.create()) {
             // try to drop the previous slot
             assertTrue(connection.dropReplicationSlot("test"));

File: debezium-core/src/test/java/io/debezium/junit/SkipTestRule.java
Patch:
@@ -6,7 +6,6 @@
 package io.debezium.junit;
 
 import java.lang.annotation.Annotation;
-
 import org.junit.rules.TestRule;
 import org.junit.runner.Description;
 import org.junit.runners.model.Statement;
@@ -25,8 +24,8 @@ public Statement apply( Statement base,
                             Description description ) {
         SkipLongRunning skipLongRunningAnnotation = hasAnnotation(description, SkipLongRunning.class);
         if (skipLongRunningAnnotation != null) {
-            boolean skipLongRunning = Boolean.valueOf(System.getProperty(SkipLongRunning.SKIP_LONG_RUNNING_PROPERTY));
-            if (skipLongRunning) {
+            String skipLongRunning = System.getProperty(SkipLongRunning.SKIP_LONG_RUNNING_PROPERTY);
+            if (skipLongRunning == null || Boolean.valueOf(skipLongRunning)) {
                 return emptyStatement(skipLongRunningAnnotation.value(), description);
             }
         }

File: debezium-connector-postgres/src/main/java/org/postgresql/core/Encoding.java
Patch:
@@ -263,7 +263,7 @@ public String toString() {
    * @return If faster ASCII number parsing can be used with this encoding.
    */
   private boolean testAsciiNumbers() {
-    // TODO: test all postgres supported encoding to see if there are
+    // TODO: test all postgresql supported encoding to see if there are
     // any which do _not_ have ascii numbers in same location
     // at least all the encoding listed in the encodings hashmap have
     // working ascii numbers

File: debezium-connector-postgres/src/main/java/org/postgresql/core/v3/ConnectionFactoryImpl.java
Patch:
@@ -295,7 +295,7 @@ public QueryExecutor openConnectionImpl(HostSpec[] hostSpecs, String user, Strin
   }
 
   /**
-   * Convert Java time zone to postgres time zone. All others stay the same except that GMT+nn
+   * Convert Java time zone to postgresql time zone. All others stay the same except that GMT+nn
    * changes to GMT-nn and vise versa.
    *
    * @return The current JVM time zone in postgresql format.

File: debezium-connector-postgres/src/main/java/org/postgresql/gss/MakeGSS.java
Patch:
@@ -39,7 +39,7 @@ public static void authenticate(PGStream pgStream, String host, String user, Str
       jaasApplicationName = "pgjdbc";
     }
     if (kerberosServerName == null) {
-      kerberosServerName = "postgres";
+      kerberosServerName = "postgresql";
     }
 
     Exception result = null;

File: debezium-connector-postgres/src/main/java/org/postgresql/jdbc/PgConnection.java
Patch:
@@ -358,7 +358,7 @@ public TimeZone get() {
 
     TypeInfo types1 = getTypeInfo();
     if (haveMinimumServerVersion(ServerVersion.v8_3)) {
-      types1.addCoreType("uuid", Oid.UUID, Types.OTHER, "java.util.UUID", Oid.UUID_ARRAY);
+      types1.addCoreType("uuid", Oid.UUID, Types.OTHER, "java.util.Uuid", Oid.UUID_ARRAY);
     }
 
     TypeInfo types = getTypeInfo();
@@ -947,7 +947,7 @@ public String getCatalog() throws SQLException {
    * <p>
    * This was done at the request of <a href="mailto:rachel@enlarion.demon.co.uk">Rachel
    * Greenham</a> who hit a problem where multiple clients didn't close the connection, and once a
-   * fortnight enough clients were open to kill the postgres server.
+   * fortnight enough clients were open to kill the postgresql server.
    */
   protected void finalize() throws Throwable {
     try {

File: debezium-connector-postgres/src/main/java/org/postgresql/jdbc/PgStatement.java
Patch:
@@ -611,7 +611,7 @@ public void close() throws SQLException {
 
   /*
    *
-   * The following methods are postgres extensions and are defined in the interface BaseStatement
+   * The following methods are postgresql extensions and are defined in the interface BaseStatement
    *
    */
 

File: debezium-connector-postgres/src/main/java/org/postgresql/util/PGInterval.java
Patch:
@@ -312,7 +312,7 @@ public void setSeconds(double seconds) {
    */
   public void add(Calendar cal) {
     // Avoid precision loss
-    // Be aware postgres doesn't return more than 60 seconds - no overflow can happen
+    // Be aware postgresql doesn't return more than 60 seconds - no overflow can happen
     final int microseconds = (int) (getSeconds() * 1000000.0);
     final int milliseconds = (microseconds + ((microseconds < 0) ? -500 : 500)) / 1000;
 

File: debezium-connector-postgres/src/main/java/org/postgresql/util/PGtokenizer.java
Patch:
@@ -13,7 +13,7 @@
 
 
 /**
- * This class is used to tokenize the text output of org.postgres. It's mainly used by the geometric
+ * This class is used to tokenize the text output of org.postgresql. It's mainly used by the geometric
  * classes, but is useful in parsing any output from custom data types output from org.postgresql.
  *
  * @see org.postgresql.geometric.PGbox

File: debezium-connector-postgres/src/main/java/org/postgresql/util/StreamWrapper.java
Patch:
@@ -26,7 +26,7 @@ public class StreamWrapper {
 
   private static final int MAX_MEMORY_BUFFER_BYTES = 51200;
 
-  private static final String TEMP_FILE_PREFIX = "postgres-pgjdbc-stream";
+  private static final String TEMP_FILE_PREFIX = "postgresql-pgjdbc-stream";
 
   public StreamWrapper(byte[] data, int offset, int length) {
     this.stream = null;

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -325,7 +325,7 @@ protected void addField(SchemaBuilder builder, Column column, ColumnMapper mappe
                              column);
             }
         } else {
-            LOGGER.warn("Unexpected JDBC type {} that will be ignored", column.jdbcType());
+            LOGGER.warn("Unexpected JDBC type '{}' for column '{}' that will be ignored", column.jdbcType(), column.name());
         }
     }
 

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/SourceInfo.java
Patch:
@@ -168,6 +168,7 @@ public Schema schema() {
      * @return the source partition information; never null
      */
     public Map<String, String> partition(String replicaSetName) {
+        if (replicaSetName == null) throw new IllegalArgumentException("Replica set name may not be null");
         return sourcePartitionsByReplicaSetName.computeIfAbsent(replicaSetName, rsName -> {
             return Collect.hashMapOf(SERVER_ID_KEY, serverName, REPLICA_SET_NAME, rsName);
         });

File: debezium-core/src/test/java/io/debezium/relational/history/AbstractDatabaseHistoryTest.java
Patch:
@@ -80,8 +80,8 @@ protected Tables recover(long pos, int entry) {
     @Test
     public void shouldRecordChangesAndRecoverToVariousPoints() {
         record(01, 0, "CREATE TABLE foo ( first VARCHAR(22) NOT NULL );", all, t3, t2, t1, t0);
-        record(23, 1, "CREATE TABLE person ( name VARCHAR(22) NOT NULL );", all, t3, t2, t1);
-        record(30, 2, "CREATE TABLE address ( street VARCHAR(22) NOT NULL );", all, t3, t2);
+        record(23, 1, "CREATE TABLE\\nperson ( name VARCHAR(22) NOT NULL );", all, t3, t2, t1);
+        record(30, 2, "CREATE TABLE address\\n( street VARCHAR(22) NOT NULL );", all, t3, t2);
         record(32, 3, "ALTER TABLE address ADD city VARCHAR(22) NOT NULL;", all, t3);
 
         // Testing.Print.enable();

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParser.java
Patch:
@@ -673,12 +673,12 @@ protected Object parseLiteral(Marker start) {
         if (tokens.canConsume("X")) {
             return parseCharacterLiteral(start);
         }
-        if (tokens.canConsume("B")) {
-            return parseBitFieldLiteral(start);
-        }
         if (tokens.matchesAnyOf(DdlTokenizer.DOUBLE_QUOTED_STRING, DdlTokenizer.SINGLE_QUOTED_STRING)) {
             return tokens.consume();
         }
+        if (tokens.canConsume("B")) {
+            return parseBitFieldLiteral(start);
+        }
         if (tokens.canConsume("DATE")) {
             return parseDateLiteral(start);
         }

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -306,6 +306,7 @@ public void shouldConsumeAllEventsFromDatabaseUsingSnapshot() throws SQLExceptio
                               .with(MySqlConnectorConfig.INCLUDE_SCHEMA_CHANGES, true)
                               .with(FileDatabaseHistory.FILE_PATH, DB_HISTORY_PATH)
                               .build();
+
         // Start the connector ...
         start(MySqlConnector.class, config);
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorRegressionIT.java
Patch:
@@ -697,7 +697,7 @@ public void shouldConsumeAllEventsFromDecimalTableInDatabaseUsingBinlogAndNoSnap
         // ---------------------------------------------------------------------------------------------------------------
         // Consume all of the events due to startup and initialization of the database
         // ---------------------------------------------------------------------------------------------------------------
-        Testing.Debug.enable();
+        //Testing.Debug.enable();
         int numCreateDatabase = 1;
         int numCreateTables = 9; // still read DDL for all tables
         int numDataRecords = 1;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParser.java
Patch:
@@ -673,12 +673,12 @@ protected Object parseLiteral(Marker start) {
         if (tokens.canConsume("X")) {
             return parseCharacterLiteral(start);
         }
-        if (tokens.canConsume("B")) {
-            return parseBitFieldLiteral(start);
-        }
         if (tokens.matchesAnyOf(DdlTokenizer.DOUBLE_QUOTED_STRING, DdlTokenizer.SINGLE_QUOTED_STRING)) {
             return tokens.consume();
         }
+        if (tokens.canConsume("B")) {
+            return parseBitFieldLiteral(start);
+        }
         if (tokens.canConsume("DATE")) {
             return parseDateLiteral(start);
         }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -108,9 +108,9 @@ protected void initializeDataTypes(DataTypeParser dataTypes) {
         dataTypes.register(Types.INTEGER, "YEAR[(2|4)]");
         dataTypes.register(Types.BLOB, "CHAR[(L)] BINARY");
         dataTypes.register(Types.BLOB, "VARCHAR(L) BINARY");
-        dataTypes.register(Types.CHAR, "CHAR[(L)]");
+        dataTypes.register(Types.BLOB, "BINARY[(L)]");
         dataTypes.register(Types.VARCHAR, "VARCHAR(L)");
-        dataTypes.register(Types.CHAR, "BINARY[(L)]");
+        dataTypes.register(Types.CHAR, "CHAR[(L)]");
         dataTypes.register(Types.VARBINARY, "VARBINARY(L)");
         dataTypes.register(Types.BLOB, "TINYBLOB");
         dataTypes.register(Types.BLOB, "BLOB");

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlSchema.java
Patch:
@@ -117,14 +117,14 @@ public MySqlSchema(Configuration config, String serverName) {
     /**
      * Start by acquiring resources needed to persist the database history
      */
-    public void start() {
+    public synchronized void start() {
         this.dbHistory.start();
     }
 
     /**
      * Stop recording history and release any resources acquired since {@link #start()}.
      */
-    public void shutdown() {
+    public synchronized void shutdown() {
         this.dbHistory.stop();
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SourceInfo.java
Patch:
@@ -262,7 +262,7 @@ public void setGtid(String gtid) {
      */
     public void setGtidSet(String gtidSet) {
         if (gtidSet != null && !gtidSet.trim().isEmpty()) {
-            this.gtidSet = gtidSet.replaceAll("\n", ""); // remove all of the newline chars if they exist
+            this.gtidSet = gtidSet.replaceAll("\n", "").replaceAll("\r", ""); // remove all of the newline chars if they exist
         }
     }
 
@@ -385,7 +385,7 @@ private boolean booleanOffsetValue(Map<String, ?> values, String key) {
      * @return the string representation of the binlog GTID ranges; may be null
      */
     public String gtidSet() {
-        return this.gtidSet != null ? this.gtidSet.toString() : null;
+        return this.gtidSet != null ? this.gtidSet : null;
     }
 
     /**

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -249,8 +249,9 @@ protected boolean isBinlogAvailable() {
                 logger.info("Connector used GTIDs previously, but MySQL does not know of any GTIDs or they are not enabled");
                 return false;
             }
-            // GTIDs are enabled, and we used them previously ...
-            GtidSet gtidSet = new GtidSet(gtidStr);
+            // GTIDs are enabled, and we used them previously, but retain only those GTID ranges for the allowed source UUIDs ...
+            GtidSet gtidSet = new GtidSet(gtidStr).retainAll(taskContext.gtidSourceFilter());
+            // Get the GTID set that is available in the server ...
             GtidSet availableGtidSet = new GtidSet(knownGtidSet());
             if (gtidSet.isContainedWithin(availableGtidSet)) {
                 logger.info("MySQL current GTID set {} does contain the GTID set required by the connector {}", availableGtidSet, gtidSet);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/GtidSet.java
Patch:
@@ -31,7 +31,7 @@ public final class GtidSet {
      * @param gtids the string representation of the GTIDs.
      */
     public GtidSet(String gtids) {
-        gtids = gtids.replaceAll("\n", "");
+        gtids = gtids.replaceAll("\n", "").replaceAll("\r", "");
         new com.github.shyiko.mysql.binlog.GtidSet(gtids).getUUIDSets().forEach(uuidSet -> {
             uuidSetsByServerId.put(uuidSet.getUUID(), new UUIDSet(uuidSet));
         });

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -147,7 +147,7 @@ public void start(Map<String, String> props) {
             if (startWithSnapshot) {
                 // We're supposed to start with a snapshot, so set that up ...
                 this.snapshotReader = new SnapshotReader(taskContext);
-                if (!taskContext.isInitialSnapshotOnly()) {
+                if (taskContext.isInitialSnapshotOnly()) {
                     logger.warn("This connector will only perform a snapshot, and will stop after that completes.");
                     this.snapshotReader.onSuccessfulCompletion(this::skipReadBinlog);
                 } else if (rowBinlogEnabled) {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -147,7 +147,7 @@ public void start(Map<String, String> props) {
             if (startWithSnapshot) {
                 // We're supposed to start with a snapshot, so set that up ...
                 this.snapshotReader = new SnapshotReader(taskContext);
-                if (!taskContext.isInitialSnapshotOnly()) {
+                if (taskContext.isInitialSnapshotOnly()) {
                     logger.warn("This connector will only perform a snapshot, and will stop after that completes.");
                     this.snapshotReader.onSuccessfulCompletion(this::skipReadBinlog);
                 } else if (rowBinlogEnabled) {

File: debezium-core/src/main/java/io/debezium/data/Bits.java
Patch:
@@ -52,11 +52,11 @@ public static Schema schema(int length) {
      * @param value the logical value
      * @return the encoded value
      */
-    public static byte[] fromLogical(Schema schema, BitSet value) {
+    public static byte[] fromBitSet(Schema schema, BitSet value) {
         return value.toByteArray();
     }
 
-    public static BitSet toLogical(Schema schema, byte[] value) {
+    public static BitSet toBitSet(Schema schema, byte[] value) {
         return BitSet.valueOf(value);
     }
 }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlTaskContext.java
Patch:
@@ -40,7 +40,6 @@ public MySqlTaskContext(Configuration config) {
 
         // Set up the MySQL schema ...
         this.dbSchema = new MySqlSchema(config, serverName());
-        this.dbSchema.start();
 
         // Set up the record processor ...
         this.recordProcessor = new RecordMakers(dbSchema, source, topicSelector);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlJdbcContext.java
Patch:
@@ -31,7 +31,7 @@
  */
 public class MySqlJdbcContext implements AutoCloseable {
 
-    protected static final String MYSQL_CONNECTION_URL = "jdbc:mysql://${hostname}:${port}/?useInformationSchema=true&nullCatalogMeansCurrent=false&useSSL=${useSSL}&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8";
+    protected static final String MYSQL_CONNECTION_URL = "jdbc:mysql://${hostname}:${port}/?useInformationSchema=true&nullCatalogMeansCurrent=false&useSSL=${useSSL}&useUnicode=true&characterEncoding=UTF-8&characterSetResults=UTF-8&zeroDateTimeBehavior=convertToNull";
     protected static ConnectionFactory FACTORY = JdbcConnection.patternBasedFactory(MYSQL_CONNECTION_URL);
 
     protected final Logger logger = LoggerFactory.getLogger(getClass());

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/GtidSet.java
Patch:
@@ -31,6 +31,7 @@ public final class GtidSet {
      * @param gtids the string representation of the GTIDs.
      */
     public GtidSet(String gtids) {
+        gtids = gtids.replaceAll("\n", "");
         new com.github.shyiko.mysql.binlog.GtidSet(gtids).getUUIDSets().forEach(uuidSet -> {
             uuidSetsByServerId.put(uuidSet.getUUID(), new UUIDSet(uuidSet));
         });

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -216,6 +216,7 @@ protected boolean isBinlogAvailable() {
             GtidSet gtidSet = new GtidSet(gtidStr);
             GtidSet availableGtidSet = new GtidSet(knownGtidSet());
             if (gtidSet.isContainedWithin(availableGtidSet)) {
+                logger.info("MySQL current GTID set {} does contain the GTID set required by the connector {}", availableGtidSet, gtidSet);
                 return true;
             }
             logger.info("Connector last known GTIDs are {}, but MySQL has {}", gtidSet, availableGtidSet);
@@ -244,6 +245,7 @@ protected boolean isBinlogAvailable() {
         if (!found) {
             logger.info("Connector requires binlog file '{}', but MySQL only has {}", binlogFilename, String.join(", ", logNames));
         }
+        logger.info("MySQL has the binlog file '{}' required by the connector", binlogFilename);
         return found;
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -114,11 +114,13 @@ public void start(Map<String, String> props) {
                     // full history of the database.
                     logger.info("Found no existing offset and snapshots disallowed, so starting at beginning of binlog");
                     source.setBinlogStartPoint("", 0L);// start from the beginning of the binlog
+                    taskContext.initializeHistory();
                 } else {
                     // We are allowed to use snapshots, and that is the best way to start ...
                     startWithSnapshot = true;
                     // The snapshot will determine if GTIDs are set
                     logger.info("Found no existing offset, so preparing to perform a snapshot");
+                    // The snapshot will also initialize history ...
                 }
             }
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/BinlogReaderIT.java
Patch:
@@ -116,6 +116,7 @@ public void shouldCreateSnapshotOfSingleDatabase() throws Exception {
         context = new MySqlTaskContext(config);
         context.start();
         context.source().setBinlogStartPoint("",0L); // start from beginning
+        context.initializeHistory();
         reader = new BinlogReader(context);
 
         // Start reading the binlog ...
@@ -175,6 +176,7 @@ public void shouldCreateSnapshotOfSingleDatabaseWithSchemaChanges() throws Excep
         context = new MySqlTaskContext(config);
         context.start();
         context.source().setBinlogStartPoint("",0L); // start from beginning
+        context.initializeHistory();
         reader = new BinlogReader(context);
 
         // Start reading the binlog ...

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcValueConverters.java
Patch:
@@ -61,7 +61,7 @@ public class JdbcValueConverters implements ValueConverterProvider {
     private static final Double DOUBLE_TRUE = new Double(1.0d);
     private static final Double DOUBLE_FALSE = new Double(0.0d);
 
-    private final Logger logger = LoggerFactory.getLogger(getClass());
+    protected final Logger logger = LoggerFactory.getLogger(getClass());
     private final ZoneOffset defaultOffset;
     private final boolean adaptiveTimePrecision;
 

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConnection.java
Patch:
@@ -646,7 +646,8 @@ public void readSchema(Tables tables, String databaseCatalog, String schemaNameP
             // Then define the table ...
             List<Column> columns = columnsByTable.get(id);
             Collections.sort(columns);
-            tables.overwriteTable(id, columns, pkColumnNames);
+            String defaultCharsetName = null; // JDBC does not expose character sets
+            tables.overwriteTable(id, columns, pkColumnNames, defaultCharsetName);
         }
 
         if (removeTablesNotFoundInJdbc) {

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlChanges.java
Patch:
@@ -128,6 +128,8 @@ protected String getDatabase(Event event) {
             case DROP_DATABASE:
                 DatabaseEvent dbEvent = (DatabaseEvent) event;
                 return dbEvent.databaseName();
+            case SET_VARIABLE:
+                return "";
         }
         assert false : "Should never happen";
         return null;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParser.java
Patch:
@@ -577,7 +577,9 @@ protected void consumeStatement() throws ParsingException {
      */
     protected void consumeRemainingStatement(Marker start) {
         while (tokens.hasNext()) {
-            if (tokens.matches(DdlTokenizer.STATEMENT_KEY)) break;
+            if (tokens.matches(DdlTokenizer.STATEMENT_KEY)) {
+                break;
+            }
             if (tokens.canConsume("BEGIN")) {
                 tokens.consumeThrough("END");
             } else if (tokens.matches(DdlTokenizer.STATEMENT_TERMINATOR)) {

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/CollectionId.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ConnectionContext.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Filters.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Module.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoClients.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnector.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorConfig.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorTask.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoUtil.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/RecordMakers.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSet.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSetDiscovery.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSetMonitorThread.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSets.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicationContext.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Replicator.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/SourceInfo.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/TopicSelector.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/AbstractMongoIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/CollectionIdTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/Configurator.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/ConnectionIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FiltersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/ModuleTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoClientsIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoUtilTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/RecordMakersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/ReplicaSetsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/ReplicatorIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/SourceInfoTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/TopicSelectorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/AbstractReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/Filters.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/GtidSet.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/Module.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnector.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlJdbcContext.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlSchema.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlTaskContext.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlValueConverters.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/RecordMakers.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/RowDeserializers.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SnapshotReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SourceInfo.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/StopEventData.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/StopEventDataDeserializer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/TopicSelector.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/BinlogReaderIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/Configurator.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/ConnectionIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/FiltersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/GtidSetTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MetadataIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySQLConnection.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorRegressionIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDdlParserTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlSchemaTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlTaskContextIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/ReadBinLogIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SnapshotReaderIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SourceInfoTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/TableConvertersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-core/src/main/java/io/debezium/config/Configuration.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.config;

File: debezium-core/src/main/java/io/debezium/config/Field.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.config;

File: debezium-core/src/main/java/io/debezium/crdt/CRDT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/Count.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/DeltaCount.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/DeltaCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/GCount.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/GCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/PNCount.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/PNCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/StateBasedGCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/StateBasedPNCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/StateBasedPNDeltaCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/data/Bits.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/data/Enum.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/data/EnumSet.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/data/Envelope.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/data/Json.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/data/SchemaUtil.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/document/Array.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/ArrayReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/ArraySerdes.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/ArrayWriter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/BasicArray.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/BasicDocument.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/BasicEntry.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/BasicField.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/BinaryValue.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/ComparableValue.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/ConvertingValue.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/Document.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/DocumentReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/DocumentSerdes.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/DocumentWriter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/JacksonReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/JacksonWriter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/NullValue.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/Path.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/Paths.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/Value.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/function/BlockingConsumer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/main/java/io/debezium/function/BooleanConsumer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/main/java/io/debezium/function/BufferedBlockingConsumer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/main/java/io/debezium/function/Callable.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/main/java/io/debezium/function/Predicates.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConfiguration.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.jdbc;

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConnection.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.jdbc;

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcValueConverters.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.jdbc;

File: debezium-core/src/main/java/io/debezium/jdbc/TimeZoneAdapter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.jdbc;

File: debezium-core/src/main/java/io/debezium/relational/Column.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ColumnEditor.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ColumnEditorImpl.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ColumnId.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ColumnImpl.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/Selectors.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/Table.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableEditor.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableEditorImpl.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableId.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableImpl.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableSchema.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/Tables.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ValueConverter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ValueConverterProvider.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DataType.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DataTypeGrammarParser.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DataTypeParser.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlChanges.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParser.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParserListener.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParserSql2003.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlTokenizer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/history/AbstractDatabaseHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/DatabaseHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/FileDatabaseHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/HistoryRecord.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/HistoryRecordComparator.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/KafkaDatabaseHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/MemoryDatabaseHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/mapping/ColumnMapper.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/main/java/io/debezium/relational/mapping/ColumnMappers.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/main/java/io/debezium/relational/mapping/MaskStrings.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/main/java/io/debezium/relational/mapping/TruncateStrings.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/main/java/io/debezium/text/MultipleParsingExceptions.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/main/java/io/debezium/text/ParsingException.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/main/java/io/debezium/text/Position.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/main/java/io/debezium/text/TokenStream.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/main/java/io/debezium/text/XmlCharacters.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/main/java/io/debezium/time/Conversions.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/Date.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/MicroTime.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/MicroTimestamp.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/NanoTime.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/NanoTimestamp.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/Time.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/Timestamp.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/Year.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/ZonedTime.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/ZonedTimestamp.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/util/AvroValidator.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Clock.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Collect.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/DelayStrategy.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/FunctionalReadWriteLock.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/HashCode.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/IoUtil.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Iterators.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Joiner.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/LoggingContext.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/MathOps.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Metronome.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Sequences.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Stopwatch.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Strings.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/test/java/io/debezium/config/ConfigurationTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.config;

File: debezium-core/src/test/java/io/debezium/data/EnvelopeTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/test/java/io/debezium/data/KeyValueStore.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/test/java/io/debezium/data/SchemaChangeHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/test/java/io/debezium/data/SourceRecordStats.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/test/java/io/debezium/data/VerifyRecord.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/test/java/io/debezium/doc/FixFor.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.doc;

File: debezium-core/src/test/java/io/debezium/document/ArraySerdesTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/document/DocumentSerdesTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/document/DocumentTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/document/JacksonArrayReadingAndWritingTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/document/JacksonWriterTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/document/PathsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/function/BufferedBlockingConsumerTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/test/java/io/debezium/function/PredicatesTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/test/java/io/debezium/jdbc/TimeZoneAdapterTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.jdbc;

File: debezium-core/src/test/java/io/debezium/junit/SkipLongRunning.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.junit;

File: debezium-core/src/test/java/io/debezium/junit/SkipOnOS.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.junit;

File: debezium-core/src/test/java/io/debezium/junit/SkipTestRule.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.junit;

File: debezium-core/src/test/java/io/debezium/kafka/KafkaCluster.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.kafka;

File: debezium-core/src/test/java/io/debezium/kafka/KafkaClusterTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.kafka;

File: debezium-core/src/test/java/io/debezium/kafka/KafkaServer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.kafka;

File: debezium-core/src/test/java/io/debezium/kafka/ZookeeperServer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.kafka;

File: debezium-core/src/test/java/io/debezium/kafka/ZookeeperServerTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.kafka;

File: debezium-core/src/test/java/io/debezium/relational/ColumnEditorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/test/java/io/debezium/relational/SelectorsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/test/java/io/debezium/relational/TableEditorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/test/java/io/debezium/relational/TableSchemaBuilderTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/test/java/io/debezium/relational/TableTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/test/java/io/debezium/relational/ddl/DataTypeGrammarParserTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/test/java/io/debezium/relational/ddl/DataTypeParserTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/test/java/io/debezium/relational/ddl/DdlChangesTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/test/java/io/debezium/relational/ddl/DdlParserSql2003Test.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/test/java/io/debezium/relational/ddl/SimpleDdlParserListener.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/test/java/io/debezium/relational/history/AbstractDatabaseHistoryTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/test/java/io/debezium/relational/history/FileDatabaseHistoryTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/test/java/io/debezium/relational/history/HistoryRecordTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/test/java/io/debezium/relational/history/KafkaDatabaseHistoryTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/test/java/io/debezium/relational/history/MemoryDatabaseHistoryTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/test/java/io/debezium/relational/mapping/ColumnMappersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/test/java/io/debezium/relational/mapping/MaskStringsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/test/java/io/debezium/relational/mapping/TruncateStringsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/test/java/io/debezium/text/PositionTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/test/java/io/debezium/text/TokenStreamTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/test/java/io/debezium/text/XmlCharactersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/test/java/io/debezium/time/ConversionsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/test/java/io/debezium/util/AvroValidatorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/test/java/io/debezium/util/HashCodeTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/test/java/io/debezium/util/StringsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/test/java/io/debezium/util/Testing.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/test/java/io/debezium/util/TestingTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.embedded;

File: debezium-embedded/src/main/java/io/debezium/embedded/OffsetCommitPolicy.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.embedded;

File: debezium-embedded/src/main/java/io/debezium/embedded/package-info.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 

File: debezium-embedded/src/test/java/io/debezium/embedded/AbstractConnectorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.embedded;

File: debezium-embedded/src/test/java/io/debezium/embedded/EmbeddedEngineTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.embedded;

File: debezium-embedded/src/test/java/io/debezium/embedded/OffsetCommitPolicyTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.embedded;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/CollectionId.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ConnectionContext.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Filters.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Module.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoClients.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnector.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorConfig.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorTask.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoUtil.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/RecordMakers.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSet.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSetDiscovery.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSetMonitorThread.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicaSets.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/ReplicationContext.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/Replicator.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/SourceInfo.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/TopicSelector.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/AbstractMongoIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/CollectionIdTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/Configurator.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/ConnectionIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/FiltersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/ModuleTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoClientsIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoDbConnectorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/MongoUtilTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/RecordMakersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/ReplicaSetsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/ReplicatorIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/SourceInfoTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/TopicSelectorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mongodb;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/AbstractReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/BinlogReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/Filters.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/GtidSet.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/Module.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnector.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlJdbcContext.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlSchema.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlTaskContext.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlValueConverters.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/RecordMakers.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/RowDeserializers.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SnapshotReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SourceInfo.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/StopEventData.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/StopEventDataDeserializer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/TopicSelector.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/BinlogReaderIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/Configurator.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/ConnectionIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/FiltersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/GtidSetTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MetadataIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySQLConnection.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorRegressionIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlDdlParserTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlSchemaTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlTaskContextIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/ReadBinLogIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SnapshotReaderIT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SourceInfoTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/TableConvertersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.connector.mysql;

File: debezium-core/src/main/java/io/debezium/config/Configuration.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.config;

File: debezium-core/src/main/java/io/debezium/config/Field.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.config;

File: debezium-core/src/main/java/io/debezium/crdt/CRDT.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/Count.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/DeltaCount.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/DeltaCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/GCount.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/GCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/PNCount.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/PNCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/StateBasedGCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/StateBasedPNCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/crdt/StateBasedPNDeltaCounter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.crdt;

File: debezium-core/src/main/java/io/debezium/data/Bits.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/data/Enum.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/data/EnumSet.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/data/Envelope.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/data/Json.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/data/SchemaUtil.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/main/java/io/debezium/document/Array.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/ArrayReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/ArraySerdes.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/ArrayWriter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/BasicArray.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/BasicDocument.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/BasicEntry.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/BasicField.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/BinaryValue.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/ComparableValue.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/ConvertingValue.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/Document.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/DocumentReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/DocumentSerdes.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/DocumentWriter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/JacksonReader.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/JacksonWriter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/NullValue.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/Path.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/Paths.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/document/Value.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/main/java/io/debezium/function/BlockingConsumer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/main/java/io/debezium/function/BooleanConsumer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/main/java/io/debezium/function/BufferedBlockingConsumer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/main/java/io/debezium/function/Callable.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/main/java/io/debezium/function/Predicates.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConfiguration.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.jdbc;

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcConnection.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.jdbc;

File: debezium-core/src/main/java/io/debezium/jdbc/JdbcValueConverters.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.jdbc;

File: debezium-core/src/main/java/io/debezium/jdbc/TimeZoneAdapter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.jdbc;

File: debezium-core/src/main/java/io/debezium/relational/Column.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ColumnEditor.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ColumnEditorImpl.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ColumnId.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ColumnImpl.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/Selectors.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/Table.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableEditor.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableEditorImpl.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableId.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableImpl.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableSchema.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/Tables.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ValueConverter.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ValueConverterProvider.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DataType.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DataTypeGrammarParser.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DataTypeParser.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlChanges.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParser.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParserListener.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParserSql2003.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlTokenizer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/main/java/io/debezium/relational/history/AbstractDatabaseHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/DatabaseHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/FileDatabaseHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/HistoryRecord.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/HistoryRecordComparator.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/KafkaDatabaseHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/history/MemoryDatabaseHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/main/java/io/debezium/relational/mapping/ColumnMapper.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/main/java/io/debezium/relational/mapping/ColumnMappers.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/main/java/io/debezium/relational/mapping/MaskStrings.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/main/java/io/debezium/relational/mapping/TruncateStrings.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/main/java/io/debezium/text/MultipleParsingExceptions.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/main/java/io/debezium/text/ParsingException.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/main/java/io/debezium/text/Position.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/main/java/io/debezium/text/TokenStream.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/main/java/io/debezium/text/XmlCharacters.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/main/java/io/debezium/time/Conversions.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/Date.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/MicroTime.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/MicroTimestamp.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/NanoTime.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/NanoTimestamp.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/Time.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/Timestamp.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/Year.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/ZonedTime.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/time/ZonedTimestamp.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/main/java/io/debezium/util/AvroValidator.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Clock.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Collect.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/DelayStrategy.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/FunctionalReadWriteLock.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/HashCode.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/IoUtil.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Iterators.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Joiner.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/LoggingContext.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/MathOps.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Metronome.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Sequences.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Stopwatch.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/main/java/io/debezium/util/Strings.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/test/java/io/debezium/config/ConfigurationTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.config;

File: debezium-core/src/test/java/io/debezium/data/EnvelopeTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/test/java/io/debezium/data/KeyValueStore.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/test/java/io/debezium/data/SchemaChangeHistory.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/test/java/io/debezium/data/SourceRecordStats.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/test/java/io/debezium/data/VerifyRecord.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.data;

File: debezium-core/src/test/java/io/debezium/doc/FixFor.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.doc;

File: debezium-core/src/test/java/io/debezium/document/ArraySerdesTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/document/DocumentSerdesTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/document/DocumentTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/document/JacksonArrayReadingAndWritingTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/document/JacksonWriterTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/document/PathsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.document;

File: debezium-core/src/test/java/io/debezium/function/BufferedBlockingConsumerTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/test/java/io/debezium/function/PredicatesTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.function;

File: debezium-core/src/test/java/io/debezium/jdbc/TimeZoneAdapterTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.jdbc;

File: debezium-core/src/test/java/io/debezium/junit/SkipLongRunning.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.junit;

File: debezium-core/src/test/java/io/debezium/junit/SkipOnOS.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.junit;

File: debezium-core/src/test/java/io/debezium/junit/SkipTestRule.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.junit;

File: debezium-core/src/test/java/io/debezium/kafka/KafkaCluster.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.kafka;

File: debezium-core/src/test/java/io/debezium/kafka/KafkaClusterTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.kafka;

File: debezium-core/src/test/java/io/debezium/kafka/KafkaServer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.kafka;

File: debezium-core/src/test/java/io/debezium/kafka/ZookeeperServer.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.kafka;

File: debezium-core/src/test/java/io/debezium/kafka/ZookeeperServerTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.kafka;

File: debezium-core/src/test/java/io/debezium/relational/ColumnEditorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/test/java/io/debezium/relational/SelectorsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/test/java/io/debezium/relational/TableEditorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/test/java/io/debezium/relational/TableSchemaBuilderTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/test/java/io/debezium/relational/TableTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational;

File: debezium-core/src/test/java/io/debezium/relational/ddl/DataTypeGrammarParserTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/test/java/io/debezium/relational/ddl/DataTypeParserTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/test/java/io/debezium/relational/ddl/DdlChangesTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/test/java/io/debezium/relational/ddl/DdlParserSql2003Test.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/test/java/io/debezium/relational/ddl/SimpleDdlParserListener.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.ddl;

File: debezium-core/src/test/java/io/debezium/relational/history/AbstractDatabaseHistoryTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/test/java/io/debezium/relational/history/FileDatabaseHistoryTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/test/java/io/debezium/relational/history/HistoryRecordTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/test/java/io/debezium/relational/history/KafkaDatabaseHistoryTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/test/java/io/debezium/relational/history/MemoryDatabaseHistoryTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.history;

File: debezium-core/src/test/java/io/debezium/relational/mapping/ColumnMappersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/test/java/io/debezium/relational/mapping/MaskStringsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/test/java/io/debezium/relational/mapping/TruncateStringsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.relational.mapping;

File: debezium-core/src/test/java/io/debezium/text/PositionTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/test/java/io/debezium/text/TokenStreamTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/test/java/io/debezium/text/XmlCharactersTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.text;

File: debezium-core/src/test/java/io/debezium/time/ConversionsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.time;

File: debezium-core/src/test/java/io/debezium/util/AvroValidatorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/test/java/io/debezium/util/HashCodeTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/test/java/io/debezium/util/StringsTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/test/java/io/debezium/util/Testing.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-core/src/test/java/io/debezium/util/TestingTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.util;

File: debezium-embedded/src/main/java/io/debezium/embedded/EmbeddedEngine.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.embedded;

File: debezium-embedded/src/main/java/io/debezium/embedded/OffsetCommitPolicy.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.embedded;

File: debezium-embedded/src/main/java/io/debezium/embedded/package-info.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 

File: debezium-embedded/src/test/java/io/debezium/embedded/AbstractConnectorTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.embedded;

File: debezium-embedded/src/test/java/io/debezium/embedded/EmbeddedEngineTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.embedded;

File: debezium-embedded/src/test/java/io/debezium/embedded/OffsetCommitPolicyTest.java
Patch:
@@ -1,6 +1,6 @@
 /*
  * Copyright Debezium Authors.
- * 
+ *
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */
 package io.debezium.embedded;

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/RecordMakers.java
Patch:
@@ -23,6 +23,7 @@
 import io.debezium.annotation.ThreadSafe;
 import io.debezium.data.Envelope.FieldName;
 import io.debezium.data.Envelope.Operation;
+import io.debezium.data.Json;
 import io.debezium.function.BlockingConsumer;
 import io.debezium.util.AvroValidator;
 
@@ -104,8 +105,8 @@ protected RecordsForCollection(CollectionId collectionId, SourceInfo source, Str
                                           .build();
             this.valueSchema = SchemaBuilder.struct()
                                             .name(validator.validate(topicName + ".Envelope"))
-                                            .field(FieldName.AFTER, Schema.OPTIONAL_STRING_SCHEMA)
-                                            .field("patch", Schema.OPTIONAL_STRING_SCHEMA)
+                                            .field(FieldName.AFTER, Json.builder().optional().build())
+                                            .field("patch", Json.builder().optional().build())
                                             .field(FieldName.SOURCE, source.schema())
                                             .field(FieldName.OPERATION, Schema.OPTIONAL_STRING_SCHEMA)
                                             .field(FieldName.TIMESTAMP, Schema.OPTIONAL_INT64_SCHEMA)

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -75,9 +75,9 @@ protected void initializeDataTypes(DataTypeParser dataTypes) {
         dataTypes.register(Types.BOOLEAN, "BOOL");
         dataTypes.register(Types.DATE, "DATE");
         dataTypes.register(Types.TIME, "TIME[(L)]");
-        dataTypes.register(Types.TIMESTAMP, "TIMESTAMP[(L)]");
+        dataTypes.register(Types.TIMESTAMP_WITH_TIMEZONE, "TIMESTAMP[(L)]"); // includes timezone information
         dataTypes.register(Types.TIMESTAMP, "DATETIME[(L)]");
-        dataTypes.register(Types.DATE, "YEAR[(2|4)]");
+        dataTypes.register(Types.INTEGER, "YEAR[(2|4)]");
         dataTypes.register(Types.BLOB, "CHAR[(L)] BINARY [CHARACTER SET charset_name] [COLLATE collation_name]");
         dataTypes.register(Types.BLOB, "VARCHAR(L) BINARY [CHARACTER SET charset_name] [COLLATE collation_name]");
         dataTypes.register(Types.VARCHAR, "CHAR[(L)] [CHARACTER SET charset_name] [COLLATE collation_name]");

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -232,7 +232,7 @@ protected boolean isBinlogAvailable() {
                 }
             });
         } catch (SQLException e) {
-            throw new ConnectException("Unexpected error while connnecting to MySQL and looking for binary logs: " + e.getMessage());
+            throw new ConnectException("Unexpected error while connecting to MySQL and looking for binary logs: ", e);
         }
 
         // And compare with the one we're supposed to use ...
@@ -257,7 +257,7 @@ protected boolean isGtidModeEnabled() {
                 }
             });
         } catch (SQLException e) {
-            throw new ConnectException("Unexpected error while connnecting to MySQL and looking at GTID mode: " + e.getMessage());
+            throw new ConnectException("Unexpected error while connecting to MySQL and looking at GTID mode: ", e);
         }
 
         return !"OFF".equalsIgnoreCase(mode.get());
@@ -277,7 +277,7 @@ protected String knownGtidSet() {
                 }
             });
         } catch (SQLException e) {
-            throw new ConnectException("Unexpected error while connnecting to MySQL and looking at GTID mode: " + e.getMessage());
+            throw new ConnectException("Unexpected error while connecting to MySQL and looking at GTID mode: ", e);
         }
 
         return gtidSetStr.get();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -232,7 +232,7 @@ protected boolean isBinlogAvailable() {
                 }
             });
         } catch (SQLException e) {
-            throw new ConnectException("Unexpected error while connnecting to MySQL and looking for binary logs: " + e.getMessage());
+            throw new ConnectException("Unexpected error while connecting to MySQL and looking for binary logs: ", e);
         }
 
         // And compare with the one we're supposed to use ...
@@ -257,7 +257,7 @@ protected boolean isGtidModeEnabled() {
                 }
             });
         } catch (SQLException e) {
-            throw new ConnectException("Unexpected error while connnecting to MySQL and looking at GTID mode: " + e.getMessage());
+            throw new ConnectException("Unexpected error while connecting to MySQL and looking at GTID mode: ", e);
         }
 
         return !"OFF".equalsIgnoreCase(mode.get());
@@ -277,7 +277,7 @@ protected String knownGtidSet() {
                 }
             });
         } catch (SQLException e) {
-            throw new ConnectException("Unexpected error while connnecting to MySQL and looking at GTID mode: " + e.getMessage());
+            throw new ConnectException("Unexpected error while connecting to MySQL and looking at GTID mode: ", e);
         }
 
         return gtidSetStr.get();

File: debezium-connector-mongodb/src/main/java/io/debezium/connector/mongodb/MongoDbConnectorTask.java
Patch:
@@ -97,7 +97,7 @@ public void start(Map<String, String> props) {
 
             // The MongoDbConnector.taskConfigs created our configuration, but we still validate the configuration in case of bugs
             // ...
-            if (!config.validate(MongoDbConnectorConfig.ALL_FIELDS, logger::error)) {
+            if (!config.validateAndRecord(MongoDbConnectorConfig.ALL_FIELDS, logger::error)) {
                 throw new ConnectException(
                         "Error configuring an instance of " + getClass().getSimpleName() + "; check the logs for details");
             }

File: debezium-connector-mongodb/src/test/java/io/debezium/connector/mongodb/AbstractMongoIT.java
Patch:
@@ -19,7 +19,7 @@
 import static org.fest.assertions.Assertions.assertThat;
 
 import io.debezium.config.Configuration;
-import io.debezium.connector.mongodb.ReplicationContext.MongoPrimary;
+import io.debezium.connector.mongodb.ConnectionContext.MongoPrimary;
 import io.debezium.util.Testing;
 
 public abstract class AbstractMongoIT implements Testing {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -58,7 +58,7 @@ public void start(Map<String, String> props) {
 
         // Validate the configuration ...
         final Configuration config = Configuration.from(props);
-        if (!config.validate(MySqlConnectorConfig.ALL_FIELDS, logger::error)) {
+        if (!config.validateAndRecord(MySqlConnectorConfig.ALL_FIELDS, logger::error)) {
             throw new ConnectException("Error configuring an instance of " + getClass().getSimpleName() + "; check the logs for details");
         }
 

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MySqlConnectorRegressionIT.java
Patch:
@@ -76,7 +76,7 @@ public void shouldConsumeAllEventsFromDatabaseUsingBinlogAndNoSnapshot() throws
         // ---------------------------------------------------------------------------------------------------------------
         // Consume all of the events due to startup and initialization of the database
         // ---------------------------------------------------------------------------------------------------------------
-        Testing.Debug.enable();
+        //Testing.Debug.enable();
         SourceRecords records = consumeRecordsByTopic(4 + 3); // 4 schema change record, 3 inserts
         stopConnector();
         assertThat(records).isNotNull();

File: debezium-core/src/main/java/io/debezium/relational/history/FileDatabaseHistory.java
Patch:
@@ -51,11 +51,11 @@ public final class FileDatabaseHistory extends AbstractDatabaseHistory {
     @Override
     public void configure(Configuration config, HistoryRecordComparator comparator) {
         lock.write(() -> {
-            if (!config.validate(ALL_FIELDS, logger::error)) {
+            if (!config.validateAndRecord(ALL_FIELDS, logger::error)) {
                 throw new ConnectException(
                         "Error configuring an instance of " + getClass().getSimpleName() + "; check the logs for details");
             }
-            config.validate(ALL_FIELDS, logger::error);
+            config.validateAndRecord(ALL_FIELDS, logger::error);
             super.configure(config,comparator);
             path = Paths.get(config.getString(FILE_PATH));
         });

File: debezium-core/src/main/java/io/debezium/util/LoggingContext.java
Patch:
@@ -42,7 +42,6 @@ public static final class PreviousContext {
         private static final Map<String, String> EMPTY_CONTEXT = Collections.emptyMap();
         private final Map<String, String> context;
 
-        @SuppressWarnings("unchecked")
         protected PreviousContext() {
             Map<String, String> context = MDC.getCopyOfContextMap();
             this.context = context != null ? context : EMPTY_CONTEXT;

File: debezium-core/src/test/java/io/debezium/kafka/KafkaServer.java
Patch:
@@ -17,6 +17,7 @@
 import io.debezium.annotation.ThreadSafe;
 import io.debezium.util.IoUtil;
 import kafka.admin.AdminUtils;
+import kafka.admin.RackAwareMode;
 import kafka.server.KafkaConfig;
 import kafka.utils.ZkUtils;
 
@@ -275,7 +276,8 @@ public void createTopics(int numPartitions, int replicationFactor, String... top
      * @param replicationFactor the replication factor for the topic
      */
     public void createTopic( String topic, int numPartitions, int replicationFactor ) {
-        AdminUtils.createTopic(getZkUtils(), topic, 1, 1, new Properties());
+        RackAwareMode rackAwareMode = null;
+        AdminUtils.createTopic(getZkUtils(), topic, numPartitions, replicationFactor, new Properties(), rackAwareMode);
     }
 
     /**

File: debezium-embedded/src/test/java/io/debezium/embedded/EmbeddedEngineTest.java
Patch:
@@ -43,6 +43,7 @@ public void beforeEach() throws Exception {
         linesAdded = 0;
         Testing.Files.delete(TEST_FILE_PATH);
         inputFile = Testing.Files.createTestingFile(TEST_FILE_PATH);
+        // Basic connector configuration; the remaining engine configuration props are set in base class in startup
         connectorConfig = Configuration.create()
                                        .with(FileStreamSourceConnector.FILE_CONFIG, TEST_FILE_PATH)
                                        .with(FileStreamSourceConnector.TOPIC_CONFIG, "topicX")

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlTaskContext.java
Patch:
@@ -169,9 +169,6 @@ public boolean useMinimalSnapshotLocking() {
     }
 
     public void start() {
-        // First, configure the logging context for the thread that created this context object ...
-        this.configureLoggingContext("task");
-
         // Start the MySQL database history, which simply starts up resources but does not recover the history to a specific point
         dbSchema().start();
     }

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SnapshotReader.java
Patch:
@@ -122,7 +122,7 @@ protected void doCleanup() {
             // Call the completion function to say that we've successfully completed
             if (onSuccessfulCompletion != null) onSuccessfulCompletion.run();
         } catch (Throwable e) {
-            logger.error("Error calling completion function after completing snapshot");
+            logger.error("Error calling completion function after completing snapshot", e);
         }
     }
 
@@ -190,7 +190,7 @@ protected void execute() {
                     String binlogFilename = rs.getString(1);
                     long binlogPosition = rs.getLong(2);
                     source.setBinlogStartPoint(binlogFilename, binlogPosition);
-                    if ( rs.getMetaData().getColumnCount() > 4 ) {
+                    if (rs.getMetaData().getColumnCount() > 4) {
                         // This column exists only in MySQL 5.6.5 or later ...
                         String gtidSet = rs.getString(5);// GTID set, may be null, blank, or contain a GTID set
                         source.setGtidSet(gtidSet);
@@ -321,7 +321,7 @@ protected void execute() {
                                 for (int i = 0, j = 1; i != numColumns; ++i, ++j) {
                                     row[i] = rs.getObject(j);
                                 }
-                                if ( isLastTable && rs.isLast() ) {
+                                if (isLastTable && rs.isLast()) {
                                     // This is the last record, so mark the offset as having completed the snapshot
                                     // but the SourceInfo.struct() will still be marked as being part of the snapshot ...
                                     source.markLastSnapshot();

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -107,7 +107,7 @@ public void start(Map<String, String> props) {
             if (taskContext.isSnapshotNeverAllowed()) {
                 // We're not allowed to take a snapshot, so instead we have to assume that the binlog contains the
                 // full history of the database.
-                source.setBinlogFilename("");// start from the beginning of the binlog
+                source.setBinlogStartPoint("", 0L);// start from the beginning of the binlog
             } else {
                 // We are allowed to use snapshots, and that is the best way to start ...
                 startWithSnapshot = true;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/BinlogReaderIT.java
Patch:
@@ -114,7 +114,7 @@ public void shouldCreateSnapshotOfSingleDatabase() throws Exception {
         config = simpleConfig().build();
         context = new MySqlTaskContext(config);
         context.start();
-        context.source().setBinlogFilename(""); // start from beginning
+        context.source().setBinlogStartPoint("",0L); // start from beginning
         reader = new BinlogReader(context);
 
         // Start reading the binlog ...
@@ -173,7 +173,7 @@ public void shouldCreateSnapshotOfSingleDatabaseWithSchemaChanges() throws Excep
         config = simpleConfig().with(MySqlConnectorConfig.INCLUDE_SCHEMA_CHANGES, true).build();
         context = new MySqlTaskContext(config);
         context.start();
-        context.source().setBinlogFilename(""); // start from beginning
+        context.source().setBinlogStartPoint("",0L); // start from beginning
         reader = new BinlogReader(context);
 
         // Start reading the binlog ...

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/SnapshotReader.java
Patch:
@@ -188,7 +188,7 @@ protected void execute() {
                 if (rs.next()) {
                     source.setBinlogFilename(rs.getString(1));
                     source.setBinlogPosition(rs.getLong(2));
-                    source.setGtids(rs.getString(5));// GTIDs
+                    source.setGtidSet(rs.getString(5));// GTID set, may be null, blank, or contain a GTID set
                     source.startSnapshot();
                 }
             });

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SourceInfoTest.java
Patch:
@@ -86,9 +86,9 @@ protected Document positionWithGtids(String gtids) {
 
     protected Document positionWithGtids(String gtids, boolean snapshot) {
         if (snapshot) {
-            return Document.create(SourceInfo.GTID_KEY, gtids, SourceInfo.SNAPSHOT_KEY, true);
+            return Document.create(SourceInfo.GTID_SET_KEY, gtids, SourceInfo.SNAPSHOT_KEY, true);
         }
-        return Document.create(SourceInfo.GTID_KEY, gtids);
+        return Document.create(SourceInfo.GTID_SET_KEY, gtids);
     }
 
     protected Document positionWithoutGtids(String filename, int position, int row) {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorConfig.java
Patch:
@@ -82,8 +82,8 @@ public class MySqlConnectorConfig {
                                                             .withDescription("Whether the connector should publish changes in the database schema to a Kafka topic with "
                                                                     + "the same name as the database server ID. Each schema change will be recorded using a key that "
                                                                     + "contains the database name and whose value includes the DDL statement(s)."
-                                                                    + "The default is 'false'. This is independent of how the connector internally records database history.")
-                                                            .withDefault(false)
+                                                                    + "The default is 'true'. This is independent of how the connector internally records database history.")
+                                                            .withDefault(true)
                                                             .withValidation(Field::isBoolean);
 
     public static final Field TABLE_BLACKLIST = Field.create("table.blacklist")

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/BinlogReaderIT.java
Patch:
@@ -102,6 +102,7 @@ protected Configuration.Builder simpleConfig() {
                             .with(MySqlConnectorConfig.SERVER_ID, 18911)
                             .with(MySqlConnectorConfig.SERVER_NAME, LOGICAL_NAME)
                             .with(MySqlConnectorConfig.POLL_INTERVAL_MS, 10)
+                            .with(MySqlConnectorConfig.INCLUDE_SCHEMA_CHANGES, false)
                             .with(MySqlConnectorConfig.DATABASE_WHITELIST, DB_NAME)
                             .with(MySqlConnectorConfig.DATABASE_HISTORY, FileDatabaseHistory.class)
                             .with(FileDatabaseHistory.FILE_PATH, DB_HISTORY_PATH)

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/SnapshotReaderIT.java
Patch:
@@ -73,6 +73,7 @@ protected Configuration.Builder simpleConfig() {
                             .with(MySqlConnectorConfig.SERVER_ID, 18911)
                             .with(MySqlConnectorConfig.SERVER_NAME, LOGICAL_NAME)
                             .with(MySqlConnectorConfig.POLL_INTERVAL_MS, 10)
+                            .with(MySqlConnectorConfig.INCLUDE_SCHEMA_CHANGES, false)
                             .with(MySqlConnectorConfig.DATABASE_WHITELIST, DB_NAME)
                             .with(MySqlConnectorConfig.DATABASE_HISTORY, FileDatabaseHistory.class)
                             .with(FileDatabaseHistory.FILE_PATH, DB_HISTORY_PATH)

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlConnectorTask.java
Patch:
@@ -87,6 +87,7 @@ public final class MySqlConnectorTask extends SourceTask {
     private int maxBatchSize;
     private String serverName;
     private Metronome metronome;
+    private final Clock clock = Clock.system();
     private final AtomicBoolean running = new AtomicBoolean(false);
 
     // Used in the methods that process events ...
@@ -176,8 +177,8 @@ public void start(Map<String, String> props) {
 
         // Set up our handlers for specific kinds of events ...
         tables = new Tables();
-        tableConverters = new TableConverters(topicSelector, dbHistory, includeSchemaChanges, tables, tableFilter, columnFilter,
-                columnMappers);
+        tableConverters = new TableConverters(topicSelector, dbHistory, includeSchemaChanges, clock,
+                                              tables, tableFilter, columnFilter, columnMappers);
         eventHandlers.put(EventType.ROTATE, tableConverters::rotateLogs);
         eventHandlers.put(EventType.TABLE_MAP, tableConverters::updateTableMetadata);
         eventHandlers.put(EventType.QUERY, tableConverters::updateTableCommand);

File: debezium-core/src/main/java/io/debezium/relational/TableSchemaBuilder.java
Patch:
@@ -145,7 +145,7 @@ public TableSchema create(Table table, Predicate<ColumnId> filter, ColumnMappers
                 addField(valSchemaBuilder, column, mapper);
             }
         });
-        Schema valSchema = valSchemaBuilder.build();
+        Schema valSchema = valSchemaBuilder.optional().build();
         Schema keySchema = hasPrimaryKey.get() ? keySchemaBuilder.build() : null;
 
         // Create the generators ...

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -105,7 +105,7 @@ protected void initializeKeywords(TokenSet keywords) {
 
     @Override
     protected void initializeStatementStarts(TokenSet statementStartTokens) {
-        statementStartTokens.add("CREATE", "ALTER", "DROP", "INSERT", "SET", "GRANT", "REVOKE", "FLUSH", "TRUNCATE");
+        statementStartTokens.add("CREATE", "ALTER", "DROP", "INSERT", "SET", "GRANT", "REVOKE", "FLUSH", "TRUNCATE", "COMMIT");
     }
 
     @Override

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlTokenizer.java
Patch:
@@ -110,7 +110,7 @@ public boolean includeComments() {
     protected Tokens adapt(CharacterStream input,
                            Tokens output) {
         return (position, startIndex, endIndex, type) -> {
-            output.addToken(position, startIndex, endIndex, retypingFunction.typeOf(type, input.substring(startIndex, endIndex)));
+            output.addToken(position, startIndex, endIndex, retypingFunction.typeOf(type, input.substring(startIndex, endIndex).toUpperCase()));
         };
     }
 

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/MySqlDdlParser.java
Patch:
@@ -969,7 +969,9 @@ protected void parseRenameTable(Marker start) {
         tokens.consume("TO");
         TableId to = parseQualifiedTableName(start);
         databaseTables.renameTable(from, to);
-        signalAlterTable(from, to, start);
+        // Signal a separate statement for this table rename action, even though multiple renames might be
+        // performed by a single DDL statement on the token stream ...
+        signalAlterTable(from,to,"RENAME TABLE " + from + " TO " + to);
     }
 
     protected List<String> parseColumnNameList(Marker start) {

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/TableConverters.java
Patch:
@@ -329,6 +329,7 @@ public void handleDelete(Event event, SourceInfo source, Consumer<SourceRecord>
                     Schema valueSchema = converter.valueSchema();
                     Struct value = converter.deleted(values, includedColumns);
                     if (value != null || key != null) {
+                        if ( value == null ) valueSchema = null;
                         SourceRecord record = new SourceRecord(source.partition(), source.offset(row), topic, partition,
                                 keySchema, key, valueSchema, value);
                         recorder.accept(record);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/TableConverters.java
Patch:
@@ -296,7 +296,7 @@ public void handleDelete(Event event, SourceInfo source, Consumer<SourceRecord>
                 Schema keySchema = converter.keySchema();
                 Object key = converter.createKey(values, includedColumns);
                 Schema valueSchema = converter.valueSchema();
-                Struct value = converter.inserted(values, includedColumns);
+                Struct value = converter.deleted(values, includedColumns);
                 SourceRecord record = new SourceRecord(source.partition(), source.offset(row), topic, partition,
                         keySchema, key, valueSchema, value);
                 recorder.accept(record);

File: debezium-connector-mysql/src/main/java/io/debezium/connector/mysql/Module.java
Patch:
@@ -16,7 +16,7 @@
  */
 public class Module {
     
-    private static final Properties INFO = IoUtil.loadProperties(Module.class, "io/debezium/connector/mysql/build.properties");
+    private static final Properties INFO = IoUtil.loadProperties(Module.class, "io/debezium/connector/mysql/build.version");
 
     public static String version() {
         return INFO.getProperty("version");

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MetadataIT.java
Patch:
@@ -15,8 +15,9 @@
 import io.debezium.relational.Column;
 import io.debezium.relational.Table;
 import io.debezium.relational.Tables;
+import io.debezium.util.Testing;
 
-public class MetadataIT {
+public class MetadataIT implements Testing {
 
     /**
      * Loads the {@link Tables} definition by reading JDBC metadata. Note that some characteristics, such as whether columns

File: debezium-core/src/main/java/io/debezium/relational/ddl/DataTypeParser.java
Patch:
@@ -84,7 +84,7 @@ public DataTypeParser register(int jdbcType, String grammar) {
     public DataType parse(TokenStream stream, Consumer<Collection<ParsingException>> errorHandler) {
         if (stream.hasNext()) {
             // Look for all patterns that begin with the first token ...
-            Collection<DataTypePattern> matchingPatterns = patterns.get(stream.peek());
+            Collection<DataTypePattern> matchingPatterns = patterns.get(stream.peek().toUpperCase());
             if (matchingPatterns != null) {
                 // At least one registered type begins with the first token, so go through them all in order ...
                 ErrorCollector errors = new ErrorCollector();

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParser.java
Patch:
@@ -189,7 +189,7 @@ protected boolean skipComments() {
      * @throws ParsingException if there is a problem parsing the supplied content
      */
     public final void parse(String ddlContent, Tables databaseTables) {
-        TokenStream stream = new TokenStream(ddlContent, new DdlTokenizer(!skipComments(), this::determineTokenType), true);
+        TokenStream stream = new TokenStream(ddlContent, new DdlTokenizer(!skipComments(), this::determineTokenType), false);
         stream.start();
         parse(stream, databaseTables);
     }

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlTokenizer.java
Patch:
@@ -271,7 +271,7 @@ public void tokenize(CharacterStream input,
                     startIndex = input.index();
                     Position startPosition = input.position(startIndex);
                     // Read until another whitespace/symbol/decimal/slash is found
-                    while (input.hasNext() && !(input.isNextWhitespace() || input.isNextAnyOf("/.-(){}*,;+%?[]!<>|=:"))) {
+                    while (input.hasNext() && !(input.isNextWhitespace() || input.isNextAnyOf("/.-(){}*,;+%?[]!<>|=:'\"\u2019"))) {
                         c = input.next();
                     }
                     endIndex = input.index() + 1; // beyond last character that was included

File: debezium-core/src/main/java/io/debezium/relational/history/AbstractDatabaseHistory.java
Patch:
@@ -47,9 +47,9 @@ public final void recover(Map<String, ?> source, Map<String, ?> position, Tables
         HistoryRecord stopPoint = new HistoryRecord(source, position, null, null);
         recoverRecords(schema,ddlParser,recovered->{
             if (recovered.isAtOrBefore(stopPoint)) {
-                ddlParser.setCurrentSchema(recovered.databaseName()); // may be null
                 String ddl = recovered.ddl();
                 if (ddl != null) {
+                    ddlParser.setCurrentSchema(recovered.databaseName()); // may be null
                     ddlParser.parse(ddl, schema);
                 }
             }

File: debezium-core/src/main/java/io/debezium/relational/history/DatabaseHistory.java
Patch:
@@ -20,7 +20,7 @@
  */
 public interface DatabaseHistory {
     
-    public static final String CONFIG_PREFIX = "database.history.";
+    public static final String CONFIGURATION_FIELD_PREFIX_STRING = "database.history.";
     
     /**
      * Configure this instance.

File: debezium-core/src/test/java/io/debezium/kafka/KafkaServer.java
Patch:
@@ -196,10 +196,10 @@ public synchronized KafkaServer startup() {
 
         // Start the server ...
         try {
-            LOGGER.debug("Starting Kafka broker {} @ {} with storage in {}", brokerId, getConnection(), logsDir.getAbsolutePath());
+            LOGGER.debug("Starting Kafka broker {} at {} with storage in {}", brokerId, getConnection(), logsDir.getAbsolutePath());
             server = new kafka.server.KafkaServer(new KafkaConfig(config), new SystemTime(), scala.Option.apply(null));
             server.startup();
-            LOGGER.info("Started Kafka server {} @ {} with storage in {}", brokerId, getConnection(), logsDir.getAbsolutePath());
+            LOGGER.info("Started Kafka server {} at {} with storage in {}", brokerId, getConnection(), logsDir.getAbsolutePath());
             return this;
         } catch (RuntimeException e) {
             server = null;
@@ -214,6 +214,7 @@ public synchronized void shutdown() {
         if (server != null) {
             try {
                 server.shutdown();
+                LOGGER.info("Stopped Kafka server {} at {}", brokerId, getConnection());
             } finally {
                 server = null;
                 port = desiredPort;

File: debezium-connector-mysql/src/test/java/io/debezium/connector/mysql/MetadataIT.java
Patch:
@@ -15,8 +15,9 @@
 import io.debezium.relational.Column;
 import io.debezium.relational.Table;
 import io.debezium.relational.Tables;
+import io.debezium.util.Testing;
 
-public class MetadataIT {
+public class MetadataIT implements Testing {
 
     /**
      * Loads the {@link Tables} definition by reading JDBC metadata. Note that some characteristics, such as whether columns

File: debezium-core/src/main/java/io/debezium/relational/ddl/DataTypeParser.java
Patch:
@@ -84,7 +84,7 @@ public DataTypeParser register(int jdbcType, String grammar) {
     public DataType parse(TokenStream stream, Consumer<Collection<ParsingException>> errorHandler) {
         if (stream.hasNext()) {
             // Look for all patterns that begin with the first token ...
-            Collection<DataTypePattern> matchingPatterns = patterns.get(stream.peek());
+            Collection<DataTypePattern> matchingPatterns = patterns.get(stream.peek().toUpperCase());
             if (matchingPatterns != null) {
                 // At least one registered type begins with the first token, so go through them all in order ...
                 ErrorCollector errors = new ErrorCollector();

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParser.java
Patch:
@@ -189,7 +189,7 @@ protected boolean skipComments() {
      * @throws ParsingException if there is a problem parsing the supplied content
      */
     public final void parse(String ddlContent, Tables databaseTables) {
-        TokenStream stream = new TokenStream(ddlContent, new DdlTokenizer(!skipComments(), this::determineTokenType), true);
+        TokenStream stream = new TokenStream(ddlContent, new DdlTokenizer(!skipComments(), this::determineTokenType), false);
         stream.start();
         parse(stream, databaseTables);
     }

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlTokenizer.java
Patch:
@@ -271,7 +271,7 @@ public void tokenize(CharacterStream input,
                     startIndex = input.index();
                     Position startPosition = input.position(startIndex);
                     // Read until another whitespace/symbol/decimal/slash is found
-                    while (input.hasNext() && !(input.isNextWhitespace() || input.isNextAnyOf("/.-(){}*,;+%?[]!<>|=:"))) {
+                    while (input.hasNext() && !(input.isNextWhitespace() || input.isNextAnyOf("/.-(){}*,;+%?[]!<>|=:'\"\u2019"))) {
                         c = input.next();
                     }
                     endIndex = input.index() + 1; // beyond last character that was included

File: debezium-core/src/main/java/io/debezium/relational/history/AbstractDatabaseHistory.java
Patch:
@@ -47,9 +47,9 @@ public final void recover(Map<String, ?> source, Map<String, ?> position, Tables
         HistoryRecord stopPoint = new HistoryRecord(source, position, null, null);
         recoverRecords(schema,ddlParser,recovered->{
             if (recovered.isAtOrBefore(stopPoint)) {
-                ddlParser.setCurrentSchema(recovered.databaseName()); // may be null
                 String ddl = recovered.ddl();
                 if (ddl != null) {
+                    ddlParser.setCurrentSchema(recovered.databaseName()); // may be null
                     ddlParser.parse(ddl, schema);
                 }
             }

File: debezium-core/src/main/java/io/debezium/relational/history/DatabaseHistory.java
Patch:
@@ -20,7 +20,7 @@
  */
 public interface DatabaseHistory {
     
-    public static final String CONFIG_PREFIX = "database.history.";
+    public static final String CONFIGURATION_FIELD_PREFIX_STRING = "database.history.";
     
     /**
      * Configure this instance.

File: debezium-core/src/test/java/io/debezium/kafka/KafkaServer.java
Patch:
@@ -196,10 +196,10 @@ public synchronized KafkaServer startup() {
 
         // Start the server ...
         try {
-            LOGGER.debug("Starting Kafka broker {} @ {} with storage in {}", brokerId, getConnection(), logsDir.getAbsolutePath());
+            LOGGER.debug("Starting Kafka broker {} at {} with storage in {}", brokerId, getConnection(), logsDir.getAbsolutePath());
             server = new kafka.server.KafkaServer(new KafkaConfig(config), new SystemTime(), scala.Option.apply(null));
             server.startup();
-            LOGGER.info("Started Kafka server {} @ {} with storage in {}", brokerId, getConnection(), logsDir.getAbsolutePath());
+            LOGGER.info("Started Kafka server {} at {} with storage in {}", brokerId, getConnection(), logsDir.getAbsolutePath());
             return this;
         } catch (RuntimeException e) {
             server = null;
@@ -214,6 +214,7 @@ public synchronized void shutdown() {
         if (server != null) {
             try {
                 server.shutdown();
+                LOGGER.info("Stopped Kafka server {} at {}", brokerId, getConnection());
             } finally {
                 server = null;
                 port = desiredPort;

File: debezium-core/src/main/java/io/debezium/relational/ddl/DdlParser.java
Patch:
@@ -108,7 +108,7 @@ protected int determineTokenType(int type, String token) {
      * 
      * @param name the name of the current schema; may be null
      */
-    protected void setCurrentSchema(String name) {
+    public void setCurrentSchema(String name) {
         this.currentSchema = name;
     }
 
@@ -117,7 +117,7 @@ protected void setCurrentSchema(String name) {
      * 
      * @return the current schema name, or null if the current schema name has not been {@link #setCurrentSchema(String) set}
      */
-    protected String currentSchema() {
+    public String currentSchema() {
         return currentSchema;
     }
 

File: debezium-ingest-mysql/src/main/java/io/debezium/mysql/source/SourceInfo.java
Patch:
@@ -83,7 +83,7 @@ public void setServerName(String logicalId) {
      * 
      * @return a copy of the current offset; never null
      */
-    public Map<String, Object> offset() {
+    public Map<String, ?> offset() {
         return Collect.hashMapOf(BINLOG_FILENAME_OFFSET_KEY, binlogFilename,
                                  BINLOG_POSITION_OFFSET_KEY, binlogPosition,
                                  BINLOG_EVENT_ROW_NUMBER_OFFSET_KEY, eventRowNumber);
@@ -96,7 +96,7 @@ public Map<String, Object> offset() {
      * @param eventRowNumber the 0-based row number within the last event that was successfully processed
      * @return a copy of the current offset; never null
      */
-    public Map<String, Object> offset(int eventRowNumber) {
+    public Map<String, ?> offset(int eventRowNumber) {
         setRowInEvent(eventRowNumber);
         return offset();
     }
@@ -134,7 +134,7 @@ public void setRowInEvent(int rowNumber) {
      * 
      * @param sourceOffset the previously-recorded Kafka Connect source offset
      */
-    public void setOffset(Map<String, Object> sourceOffset) {
+    public void setOffset(Map<String, ?> sourceOffset) {
         if (sourceOffset != null) {
             // We have previously recorded an offset ...
             binlogFilename = (String) sourceOffset.get(BINLOG_FILENAME_OFFSET_KEY);

File: debezium-ingest-mysql/src/test/java/io/debezium/mysql/MySqlDdlParserTest.java
Patch:
@@ -23,6 +23,7 @@
 import io.debezium.relational.Tables;
 import io.debezium.relational.ddl.DdlParser;
 import io.debezium.util.IoUtil;
+import io.debezium.util.Testing;
 
 public class MySqlDdlParserTest {
 
@@ -86,13 +87,13 @@ public void shouldParseCreateTableStatementWithSingleGeneratedColumnAsPrimaryKey
     @Test
     public void shouldParseCreateStatements() {
         parser.parse(readFile("ddl/mysql-test-create.ddl"), tables);
-        //System.out.println(tables);
+        Testing.print(tables);
     }
 
     @Test
     public void shouldParseTestStatements() {
         parser.parse(readFile("ddl/mysql-test-statements.ddl"), tables);
-        System.out.println(tables);
+        Testing.print(tables);
     }
 
     @Test

File: debezium-core/src/test/java/io/debezium/util/HashCodeTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015-2016 Red Hat, Inc. and/or its affiliates.
+ * Copyright 2015 Debezium Authors.
  * 
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */

File: debezium-core/src/test/java/io/debezium/util/StringsTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015-2016 Red Hat, Inc. and/or its affiliates.
+ * Copyright 2015 Debezium Authors.
  * 
  * Licensed under the Apache Software License version 2.0, available at http://www.apache.org/licenses/LICENSE-2.0
  */

File: debezium-core/src/main/java/io/debezium/relational/Tables.java
Patch:
@@ -85,7 +85,6 @@ public int size() {
 
     public Set<TableId> drainChanges() {
         return lock.write(() -> {
-            // if (changes.isEmpty()) return Collections.<TableId>emptySet();
             Set<TableId> result = new HashSet<>(changes);
             changes.clear();
             return result;

File: debezium-core/src/main/java/io/debezium/relational/Tables.java
Patch:
@@ -6,7 +6,6 @@
 package io.debezium.relational;
 
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
@@ -86,7 +85,7 @@ public int size() {
 
     public Set<TableId> drainChanges() {
         return lock.write(() -> {
-            if (changes.isEmpty()) return Collections.<TableId>emptySet();
+            // if (changes.isEmpty()) return Collections.<TableId>emptySet();
             Set<TableId> result = new HashSet<>(changes);
             changes.clear();
             return result;
@@ -306,7 +305,7 @@ public String toString() {
         return lock.read(() -> {
             StringBuilder sb = new StringBuilder();
             sb.append("Tables {").append(System.lineSeparator());
-            tablesByTableId.forEach((tableId,table)->{
+            tablesByTableId.forEach((tableId, table) -> {
                 sb.append("  ").append(tableId).append(": {").append(System.lineSeparator());
                 table.toString(sb, "    ");
                 sb.append("  }").append(System.lineSeparator());

File: debezium-core/src/main/java/io/debezium/relational/Tables.java
Patch:
@@ -86,7 +86,7 @@ public int size() {
 
     public Set<TableId> drainChanges() {
         return lock.write(() -> {
-            if (changes.isEmpty()) return Collections.emptySet();
+            if (changes.isEmpty()) return Collections.<TableId>emptySet();
             Set<TableId> result = new HashSet<>(changes);
             changes.clear();
             return result;

