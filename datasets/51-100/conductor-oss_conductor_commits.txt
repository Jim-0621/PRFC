File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -128,7 +128,7 @@ public Switch switchTask() {
 
         @Bean(TASK_TYPE_JOIN)
         public Join join() {
-            return new Join();
+            return new Join(new ConductorProperties());
         }
 
         @Bean
@@ -595,7 +595,8 @@ public void testOptionalWithDynamicFork() {
 
         assertEquals(TaskModel.Status.SCHEDULED, outcome.tasksToBeScheduled.get(0).getStatus());
         System.out.println(outcome.tasksToBeScheduled.get(0));
-        new Join().execute(workflow, outcome.tasksToBeScheduled.get(0), null);
+        new Join(new ConductorProperties())
+                .execute(workflow, outcome.tasksToBeScheduled.get(0), null);
         assertEquals(TaskModel.Status.COMPLETED, outcome.tasksToBeScheduled.get(0).getStatus());
     }
 

File: os-persistence/src/test/java/com/netflix/conductor/os/dao/index/OpenSearchRestDaoBaseTest.java
Patch:
@@ -16,15 +16,14 @@
 import java.io.IOException;
 import java.io.InputStreamReader;
 import java.io.Reader;
-import java.util.regex.Pattern;
 
 import org.apache.http.HttpHost;
+import org.junit.After;
+import org.junit.Before;
 import org.opensearch.client.Request;
 import org.opensearch.client.Response;
 import org.opensearch.client.RestClient;
 import org.opensearch.client.RestClientBuilder;
-import org.junit.After;
-import org.junit.Before;
 import org.springframework.retry.support.RetryTemplate;
 
 public abstract class OpenSearchRestDaoBaseTest extends OpenSearchTest {

File: os-persistence/src/test/java/com/netflix/conductor/os/dao/index/TestBulkRequestBuilderWrapper.java
Patch:
@@ -12,11 +12,11 @@
  */
 package com.netflix.conductor.os.dao.index;
 
+import org.junit.Test;
+import org.mockito.Mockito;
 import org.opensearch.action.bulk.BulkRequestBuilder;
 import org.opensearch.action.index.IndexRequest;
 import org.opensearch.action.update.UpdateRequest;
-import org.junit.Test;
-import org.mockito.Mockito;
 
 public class TestBulkRequestBuilderWrapper {
     BulkRequestBuilder builder = Mockito.mock(BulkRequestBuilder.class);

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/TaskRunnerConfigurer.java
Patch:
@@ -260,6 +260,9 @@ public TaskRunnerConfigurer.Builder withTaskToDomain(Map<String, String> taskToD
         public TaskRunnerConfigurer.Builder withTaskThreadCount(
                 Map<String, Integer> taskToThreadCount) {
             this.taskToThreadCount = taskToThreadCount;
+            if (taskToThreadCount.values().stream().anyMatch(v -> v < 1)) {
+                throw new IllegalArgumentException("No. of threads cannot be less than 1");
+            }
             return this;
         }
 

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/WorkflowClientTests.java
Patch:
@@ -16,17 +16,17 @@
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;
 
-import com.netflix.conductor.common.metadata.tasks.TaskResult;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
-import com.netflix.conductor.common.run.WorkflowTestRequest;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Test;
 
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
+import com.netflix.conductor.common.metadata.tasks.TaskResult;
 import com.netflix.conductor.common.metadata.workflow.StartWorkflowRequest;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
+import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
+import com.netflix.conductor.common.run.WorkflowTestRequest;
 import com.netflix.conductor.sdk.workflow.def.ConductorWorkflow;
 import com.netflix.conductor.sdk.workflow.def.tasks.Http;
 import com.netflix.conductor.sdk.workflow.def.tasks.SimpleTask;

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/TaskRunnerConfigurer.java
Patch:
@@ -260,6 +260,9 @@ public TaskRunnerConfigurer.Builder withTaskToDomain(Map<String, String> taskToD
         public TaskRunnerConfigurer.Builder withTaskThreadCount(
                 Map<String, Integer> taskToThreadCount) {
             this.taskToThreadCount = taskToThreadCount;
+            if (taskToThreadCount.values().stream().anyMatch(v -> v < 1)) {
+                throw new IllegalArgumentException("No. of threads cannot be less than 1");
+            }
             return this;
         }
 

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/WorkflowClientTests.java
Patch:
@@ -16,17 +16,17 @@
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;
 
-import com.netflix.conductor.common.metadata.tasks.TaskResult;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
-import com.netflix.conductor.common.run.WorkflowTestRequest;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Test;
 
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
+import com.netflix.conductor.common.metadata.tasks.TaskResult;
 import com.netflix.conductor.common.metadata.workflow.StartWorkflowRequest;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
+import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
+import com.netflix.conductor.common.run.WorkflowTestRequest;
 import com.netflix.conductor.sdk.workflow.def.ConductorWorkflow;
 import com.netflix.conductor.sdk.workflow.def.tasks.Http;
 import com.netflix.conductor.sdk.workflow.def.tasks.SimpleTask;

File: core/src/test/java/com/netflix/conductor/core/reconciliation/TestWorkflowSweeper.java
Patch:
@@ -204,6 +204,8 @@ public void testPostponeDurationForTaskInProgressWithResponseTimeoutSet() {
         workflowModel.setTasks(List.of(taskModel));
         when(properties.getWorkflowOffsetTimeout())
                 .thenReturn(Duration.ofSeconds(defaultPostPoneOffSetSeconds));
+        when(properties.getMaxPostponeDurationSeconds())
+                .thenReturn(Duration.ofSeconds(defaulMmaxPostponeDurationSeconds));
         workflowSweeper.unack(workflowModel, defaultPostPoneOffSetSeconds);
         verify(queueDAO)
                 .setUnackTimeout(

File: os-persistence/src/main/java/com/netflix/conductor/os/config/OpenSearchProperties.java
Patch:
@@ -58,7 +58,7 @@ public class OpenSearchProperties {
     private int indexShardCount = 5;
 
     /** The number of replicas that the index will be configured to have */
-    private int indexReplicasCount = 1;
+    private int indexReplicasCount = 0;
 
     /** The number of task log results that will be returned in the response */
     private int taskLogResultLimit = 10;

File: core/src/main/java/com/netflix/conductor/dao/QueueDAO.java
Patch:
@@ -15,10 +15,10 @@
 import java.util.List;
 import java.util.Map;
 
-import com.netflix.conductor.core.events.queue.Message;
-import org.springframework.context.annotation.Bean;
 import org.springframework.stereotype.Component;
 
+import com.netflix.conductor.core.events.queue.Message;
+
 /** DAO responsible for managing queuing for the tasks. */
 @SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Component

File: os-persistence/src/main/java/com/netflix/conductor/os/config/OpenSearchProperties.java
Patch:
@@ -12,9 +12,6 @@
  */
 package com.netflix.conductor.os.config;
 
-import org.springframework.boot.context.properties.ConfigurationProperties;
-import org.springframework.boot.convert.DurationUnit;
-
 import java.net.MalformedURLException;
 import java.net.URL;
 import java.time.Duration;
@@ -23,6 +20,9 @@
 import java.util.List;
 import java.util.stream.Collectors;
 
+import org.springframework.boot.context.properties.ConfigurationProperties;
+import org.springframework.boot.convert.DurationUnit;
+
 @ConfigurationProperties("conductor.elasticsearch")
 public class OpenSearchProperties {
 

File: os-persistence/src/main/java/com/netflix/conductor/os/dao/index/BulkRequestBuilderWrapper.java
Patch:
@@ -12,14 +12,14 @@
  */
 package com.netflix.conductor.os.dao.index;
 
+import java.util.Objects;
+
 import org.opensearch.action.bulk.BulkRequestBuilder;
 import org.opensearch.action.bulk.BulkResponse;
 import org.opensearch.action.index.IndexRequest;
 import org.opensearch.action.update.UpdateRequest;
 import org.springframework.lang.NonNull;
 
-import java.util.Objects;
-
 /** Thread-safe wrapper for {@link BulkRequestBuilder}. */
 public class BulkRequestBuilderWrapper {
     private final BulkRequestBuilder bulkRequestBuilder;

File: os-persistence/src/main/java/com/netflix/conductor/os/dao/index/BulkRequestWrapper.java
Patch:
@@ -12,13 +12,13 @@
  */
 package com.netflix.conductor.os.dao.index;
 
+import java.util.Objects;
+
 import org.opensearch.action.bulk.BulkRequest;
 import org.opensearch.action.index.IndexRequest;
 import org.opensearch.action.update.UpdateRequest;
 import org.springframework.lang.NonNull;
 
-import java.util.Objects;
-
 /** Thread-safe wrapper for {@link BulkRequest}. */
 class BulkRequestWrapper {
     private final BulkRequest bulkRequest;

File: os-persistence/src/main/java/com/netflix/conductor/os/dao/query/parser/internal/AbstractNode.java
Patch:
@@ -12,8 +12,6 @@
  */
 package com.netflix.conductor.os.dao.query.parser.internal;
 
-import com.netflix.conductor.os.dao.query.parser.internal.FunctionThrowingException;
-
 import java.io.InputStream;
 import java.math.BigDecimal;
 import java.util.HashSet;

File: os-persistence/src/main/java/com/netflix/conductor/os/dao/query/parser/internal/ConstValue.java
Patch:
@@ -12,8 +12,6 @@
  */
 package com.netflix.conductor.os.dao.query.parser.internal;
 
-import com.netflix.conductor.os.dao.query.parser.internal.AbstractNode;
-
 import java.io.InputStream;
 
 /**

File: common/src/main/java/com/netflix/conductor/common/constraints/TaskTimeoutConstraint.java
Patch:
@@ -67,7 +67,8 @@ public boolean isValid(TaskDef taskDef, ConstraintValidatorContext context) {
             }
 
             // Check if timeoutSeconds is greater than totalTimeoutSeconds
-            if (taskDef.getTimeoutSeconds() > 0 && taskDef.getTotalTimeoutSeconds() > 0
+            if (taskDef.getTimeoutSeconds() > 0
+                    && taskDef.getTotalTimeoutSeconds() > 0
                     && taskDef.getTimeoutSeconds() > taskDef.getTotalTimeoutSeconds()) {
                 valid = false;
                 String message =

File: common/src/test/java/com/netflix/conductor/common/tasks/TaskDefTest.java
Patch:
@@ -80,6 +80,7 @@ public void testTaskDefTotalTimeOutSeconds() {
         taskDef.setName("test-task");
         taskDef.setRetryCount(1);
         taskDef.setTimeoutSeconds(1000);
+        taskDef.setTotalTimeoutSeconds(900);
         taskDef.setResponseTimeoutSeconds(1);
         taskDef.setOwnerEmail("blah@gmail.com");
 
@@ -92,7 +93,7 @@ public void testTaskDefTotalTimeOutSeconds() {
         assertTrue(
                 validationErrors.toString(),
                 validationErrors.contains(
-                        "TaskDef: test-task timeoutSeconds: 1000 must be less than or equal to totalTimeoutSeconds: 0"));
+                        "TaskDef: test-task timeoutSeconds: 1000 must be less than or equal to totalTimeoutSeconds: 900"));
     }
 
     @Test

File: common/src/test/java/com/netflix/conductor/common/tasks/TaskTest.java
Patch:
@@ -98,7 +98,7 @@ public void testDeepCopyTask() {
         final Task task = new Task();
         // In order to avoid forgetting putting inside the copy method the newly added fields check
         // the number of declared fields.
-        final int expectedTaskFieldsNumber = 41;
+        final int expectedTaskFieldsNumber = 42;
         final int declaredFieldsNumber = task.getClass().getDeclaredFields().length;
 
         assertEquals(expectedTaskFieldsNumber, declaredFieldsNumber);

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/service/GRPCHelper.java
Patch:
@@ -21,18 +21,18 @@
 import io.grpc.Metadata;
 import io.grpc.Status;
 import io.grpc.StatusException;
-import io.grpc.protobuf.lite.ProtoLiteUtils;
 import io.grpc.stub.StreamObserver;
 import jakarta.annotation.Nonnull;
 
+import static io.grpc.protobuf.ProtoUtils.metadataMarshaller;
+
 public class GRPCHelper {
 
     private final Logger logger;
 
     private static final Metadata.Key<DebugInfo> STATUS_DETAILS_KEY =
             Metadata.Key.of(
-                    "grpc-status-details-bin",
-                    ProtoLiteUtils.metadataMarshaller(DebugInfo.getDefaultInstance()));
+                    "grpc-status-details-bin", metadataMarshaller(DebugInfo.getDefaultInstance()));
 
     public GRPCHelper(Logger log) {
         this.logger = log;

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/MetadataClient.java
Patch:
@@ -104,7 +104,7 @@ public WorkflowDef getWorkflowDef(String name, Integer version) {
     public List<WorkflowDef> getAllWorkflowsWithLatestVersions() {
         ConductorClientRequest request = ConductorClientRequest.builder()
                 .method(Method.GET)
-                .path("metadata/workflow/latest-versions")
+                .path("/metadata/workflow/latest-versions")
                 .build();
 
         ConductorClientResponse<List<WorkflowDef>> resp = client.execute(request, new TypeReference<>() {

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/ApiClient.java
Patch:
@@ -19,6 +19,7 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
+import org.apache.commons.lang3.StringUtils;
 import org.jetbrains.annotations.NotNull;
 
 import com.netflix.conductor.client.exception.ConductorClientException;
@@ -150,8 +151,8 @@ public static ApiClientBuilder builder() {
     public static class ApiClientBuilder extends Builder<ApiClientBuilder> {
 
         public ApiClientBuilder credentials(String key, String secret) {
-            if (key == null || secret == null) {
-                throw new IllegalArgumentException("Key and secret must not be null");
+            if (StringUtils.isBlank(key) || StringUtils.isBlank(secret)) {
+                throw new IllegalArgumentException("Key and secret must not be blank (null or empty)");
             }
 
             this.addHeaderSupplier(new OrkesAuthentication(key, secret));

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/MetadataClient.java
Patch:
@@ -104,7 +104,7 @@ public WorkflowDef getWorkflowDef(String name, Integer version) {
     public List<WorkflowDef> getAllWorkflowsWithLatestVersions() {
         ConductorClientRequest request = ConductorClientRequest.builder()
                 .method(Method.GET)
-                .path("metadata/workflow/latest-versions")
+                .path("/metadata/workflow/latest-versions")
                 .build();
 
         ConductorClientResponse<List<WorkflowDef>> resp = client.execute(request, new TypeReference<>() {

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesWorkflowClient.java
Patch:
@@ -112,7 +112,7 @@ public CompletableFuture<WorkflowRun> executeWorkflow(StartWorkflowRequest reque
      */
     public WorkflowRun executeWorkflow(StartWorkflowRequest request, String waitUntilTask, Duration waitTimeout) throws ExecutionException, InterruptedException, TimeoutException {
         CompletableFuture<WorkflowRun> future = executeWorkflow(request, waitUntilTask);
-        return future.get(waitTimeout.get(ChronoUnit.MILLIS), TimeUnit.MILLISECONDS);
+        return future.get(waitTimeout.get(ChronoUnit.SECONDS), TimeUnit.SECONDS);
     }
 
     public void terminateWorkflowWithFailure(String workflowId, String reason, boolean triggerFailureWorkflow) {

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesWorkflowClient.java
Patch:
@@ -112,7 +112,7 @@ public CompletableFuture<WorkflowRun> executeWorkflow(StartWorkflowRequest reque
      */
     public WorkflowRun executeWorkflow(StartWorkflowRequest request, String waitUntilTask, Duration waitTimeout) throws ExecutionException, InterruptedException, TimeoutException {
         CompletableFuture<WorkflowRun> future = executeWorkflow(request, waitUntilTask);
-        return future.get(waitTimeout.get(ChronoUnit.MILLIS), TimeUnit.MILLISECONDS);
+        return future.get(waitTimeout.get(ChronoUnit.SECONDS), TimeUnit.SECONDS);
     }
 
     public void terminateWorkflowWithFailure(String workflowId, String reason, boolean triggerFailureWorkflow) {

File: postgres-persistence/src/main/java/com/netflix/conductor/postgres/dao/PostgresIndexDAO.java
Patch:
@@ -85,7 +85,8 @@ public void indexWorkflow(WorkflowSummary workflow) {
                 "INSERT INTO workflow_index (workflow_id, correlation_id, workflow_type, start_time, update_time, status, json_data)"
                         + "VALUES (?, ?, ?, ?, ?, ?, ?::JSONB) ON CONFLICT (workflow_id) \n"
                         + "DO UPDATE SET correlation_id = EXCLUDED.correlation_id, workflow_type = EXCLUDED.workflow_type, "
-                        + "start_time = EXCLUDED.start_time, status = EXCLUDED.status, json_data = EXCLUDED.json_data "
+                        + "start_time = EXCLUDED.start_time, status = EXCLUDED.status, json_data = EXCLUDED.json_data, "
+                        + "update_time = EXCLUDED.update_time "
                         + "WHERE EXCLUDED.update_time >= workflow_index.update_time";
 
         if (onlyIndexOnStatusChange) {

File: postgres-persistence/src/main/java/com/netflix/conductor/postgres/dao/PostgresIndexDAO.java
Patch:
@@ -85,7 +85,8 @@ public void indexWorkflow(WorkflowSummary workflow) {
                 "INSERT INTO workflow_index (workflow_id, correlation_id, workflow_type, start_time, update_time, status, json_data)"
                         + "VALUES (?, ?, ?, ?, ?, ?, ?::JSONB) ON CONFLICT (workflow_id) \n"
                         + "DO UPDATE SET correlation_id = EXCLUDED.correlation_id, workflow_type = EXCLUDED.workflow_type, "
-                        + "start_time = EXCLUDED.start_time, status = EXCLUDED.status, json_data = EXCLUDED.json_data "
+                        + "start_time = EXCLUDED.start_time, status = EXCLUDED.status, json_data = EXCLUDED.json_data, "
+                        + "update_time = EXCLUDED.update_time "
                         + "WHERE EXCLUDED.update_time >= workflow_index.update_time";
 
         if (onlyIndexOnStatusChange) {

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/ApiCallback.java
Patch:
@@ -15,7 +15,8 @@
 import java.util.List;
 import java.util.Map;
 
-@Deprecated
+import com.netflix.conductor.client.exception.ConductorClientException;
+
 /**
  * Callback for asynchronous API call.
  *
@@ -29,7 +30,7 @@ public interface ApiCallback<T> {
      * @param statusCode Status code of the response if available, otherwise it would be 0
      * @param responseHeaders Headers of the response if available, otherwise it would be null
      */
-    void onFailure(ApiException e, int statusCode, Map<String, List<String>> responseHeaders);
+    void onFailure(ConductorClientException e, int statusCode, Map<String, List<String>> responseHeaders);
 
     /**
      * This is called when the API call succeeded.

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/ApiResponse.java
Patch:
@@ -23,7 +23,6 @@
  *
  * @param <T> The type of data that is deserialized from response body
  */
-@Deprecated
 public class ApiResponse<T> {
     private final int statusCode;
     private final Map<String, List<String>> headers;

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/Pair.java
Patch:
@@ -16,7 +16,6 @@
  * This class exists to maintain backward compatibility and facilitate the migration for
  * users of orkes-conductor-client v2.
  */
-@Deprecated
 public class Pair {
     private String name = "";
     private String value = "";

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/event/QueueConfiguration.java
Patch:
@@ -51,7 +51,6 @@ public String getQueueName() {
         return this.queueName;
     }
 
-    //FIXME why? explain me why?
     @Deprecated
     public String getConfiguration() throws Exception {
         if (this.consumer == null) {

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/util/ClientTestUtil.java
Patch:
@@ -16,8 +16,8 @@
 
 import com.netflix.conductor.client.http.ConductorClient;
 
+import io.orkes.conductor.client.ApiClient;
 import io.orkes.conductor.client.OrkesClients;
-import io.orkes.conductor.client.http.OrkesAuthentication;
 
 public class ClientTestUtil {
     private static final String ENV_ROOT_URI = "CONDUCTOR_SERVER_URL";
@@ -41,9 +41,9 @@ public static ConductorClient getClient() {
         String keySecret = getEnv(ENV_SECRET);
         Assertions.assertNotNull(keySecret, ENV_SECRET + " env not set");
 
-        return ConductorClient.builder()
+        return ApiClient.builder()
                 .basePath(basePath)
-                .addHeaderSupplier(new OrkesAuthentication(keyId, keySecret))
+                .credentials(keyId, keySecret)
                 .readTimeout(30_000)
                 .connectTimeout(30_000)
                 .writeTimeout(30_000)

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/events/taskrunner/PollCompleted.java
Patch:
@@ -10,7 +10,7 @@
  * an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
  * specific language governing permissions and limitations under the License.
  */
-package com.netflix.conductor.client.automator.events;
+package com.netflix.conductor.client.events.taskrunner;
 
 import java.time.Duration;
 

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/events/taskrunner/PollFailure.java
Patch:
@@ -10,7 +10,7 @@
  * an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
  * specific language governing permissions and limitations under the License.
  */
-package com.netflix.conductor.client.automator.events;
+package com.netflix.conductor.client.events.taskrunner;
 
 import java.time.Duration;
 

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/events/taskrunner/PollStarted.java
Patch:
@@ -10,7 +10,7 @@
  * an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
  * specific language governing permissions and limitations under the License.
  */
-package com.netflix.conductor.client.automator.events;
+package com.netflix.conductor.client.events.taskrunner;
 
 import lombok.ToString;
 

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/events/taskrunner/TaskExecutionCompleted.java
Patch:
@@ -10,7 +10,7 @@
  * an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
  * specific language governing permissions and limitations under the License.
  */
-package com.netflix.conductor.client.automator.events;
+package com.netflix.conductor.client.events.taskrunner;
 
 import java.time.Duration;
 

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/events/taskrunner/TaskExecutionFailure.java
Patch:
@@ -10,7 +10,7 @@
  * an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
  * specific language governing permissions and limitations under the License.
  */
-package com.netflix.conductor.client.automator.events;
+package com.netflix.conductor.client.events.taskrunner;
 
 import java.time.Duration;
 

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/events/taskrunner/TaskExecutionStarted.java
Patch:
@@ -10,7 +10,7 @@
  * an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
  * specific language governing permissions and limitations under the License.
  */
-package com.netflix.conductor.client.automator.events;
+package com.netflix.conductor.client.events.taskrunner;
 
 import lombok.Getter;
 import lombok.ToString;

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/events/EventListenerExample.java
Patch:
@@ -17,9 +17,9 @@
 import java.util.List;
 
 import com.netflix.conductor.client.automator.TaskRunnerConfigurer;
-import com.netflix.conductor.client.automator.events.PollCompleted;
-import com.netflix.conductor.client.automator.events.PollFailure;
-import com.netflix.conductor.client.automator.events.TaskExecutionFailure;
+import com.netflix.conductor.client.events.taskrunner.PollCompleted;
+import com.netflix.conductor.client.events.taskrunner.PollFailure;
+import com.netflix.conductor.client.events.taskrunner.TaskExecutionFailure;
 import com.netflix.conductor.client.http.TaskClient;
 import com.netflix.conductor.client.worker.Worker;
 import com.netflix.conductor.common.metadata.tasks.Task;

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/events/TaskRunnerEvent.java
Patch:
@@ -21,7 +21,7 @@
 @AllArgsConstructor
 @Getter
 @ToString
-public class TaskRunnerEvent {
+public abstract class TaskRunnerEvent {
     private final Instant time = Instant.now();
     private final String taskType;
 }

File: conductor-clients/java/conductor-java-sdk/conductor-client-spring/src/main/java/com/netflix/conductor/client/spring/ClientProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client-spring/src/main/java/com/netflix/conductor/client/spring/ConductorClientAutoConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client-spring/src/main/java/com/netflix/conductor/client/spring/ConductorWorkerAutoConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client-spring/src/main/java/com/netflix/conductor/client/spring/SpringWorkerConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/TaskRunner.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/TaskRunnerConfigurer.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/events/PollCompleted.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/events/PollFailure.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/events/PollStarted.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/events/TaskExecutionCompleted.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/events/TaskExecutionFailure.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/events/TaskExecutionStarted.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/events/TaskRunnerEvent.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/automator/filters/PollFilter.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/config/ConductorClientConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2018 Orkes, Inc.
+ * Copyright 2018 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/config/PropertyFactory.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/exception/ConductorClientException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/ConductorClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/ConductorClientRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/ConductorClientResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/ConnectionPoolConfig.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/EventClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/HeaderSupplier.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/MetadataClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/Param.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/TaskClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/http/WorkflowClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/client/worker/Worker.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/config/ObjectMapperProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/Auditable.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/SchemaDef.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/events/EventExecution.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/events/EventHandler.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/tasks/PollData.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskDef.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskExecLog.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskResult.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/DynamicForkJoinTask.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/DynamicForkJoinTaskList.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/IdempotencyStrategy.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/RateLimitConfig.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/RerunWorkflowRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/SkipTaskRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/StartWorkflowRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/StateChangeEvent.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/SubWorkflowParams.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/UpgradeWorkflowRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowDef.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowDefSummary.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/model/BulkResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/run/ExternalStorageLocation.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/run/SearchResult.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/run/TaskSummary.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/run/WorkflowSummary.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/run/WorkflowTestRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/utils/ConstraintParamUtil.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/utils/EnvUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/utils/ExternalPayloadStorage.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/utils/SummaryUtil.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/utils/TaskUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/validation/ErrorResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/main/java/com/netflix/conductor/common/validation/ValidationError.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/automator/PollingSemaphoreTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/automator/TaskPollExecutorTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/automator/TaskRunnerConfigurerTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/config/TestPropertyFactory.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/sample/Main.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/sample/SampleWorker.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/testing/AbstractWorkflowTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/testing/LoanWorkflowInput.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/testing/LoanWorkflowTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/testing/RegressionTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/testing/SubWorkflowTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/conductor-client/src/test/java/com/netflix/conductor/client/worker/TestWorkflowTask.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/TaskRegistration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/TaskRunner.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/events/EventListenerExample.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/helloworld/Main.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/helloworld/workers/Workers.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/helloworld/workflowdef/GreetingsWorkflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/sendemail/Main.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/sendemail/workers/Workers.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/sendemail/workflowdef/SendEmailWorkflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/shipment/Main.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/shipment/Order.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/shipment/Shipment.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/shipment/ShipmentState.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/shipment/ShipmentWorkers.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/shipment/ShipmentWorkflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/shipment/User.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/taskdomains/Main.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/com/netflix/conductor/sdk/examples/taskdomains/Workers.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/io/orkes/conductor/sdk/examples/AuthorizationManagement.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/io/orkes/conductor/sdk/examples/MetadataManagement.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/io/orkes/conductor/sdk/examples/SchedulerManagement.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/io/orkes/conductor/sdk/examples/WorkflowManagement.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/io/orkes/conductor/sdk/examples/WorkflowManagement2.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/io/orkes/conductor/sdk/examples/util/ClientUtil.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/io/orkes/conductor/sdk/examples/workflowops/Main.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/examples/src/main/java/io/orkes/conductor/sdk/examples/workflowops/workflowdef/GreetingsWorkflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/ApiClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/AuthorizationClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/IntegrationClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/OrkesClients.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/PromptClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/SchedulerClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/SecretClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/ApiCallback.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/ApiException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/ApiResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/ApplicationResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/AuthorizationResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/EventResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/GroupResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/IntegrationResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/MetadataResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesAuthentication.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesAuthorizationClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesEventClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesIntegrationClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesMetadataClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesPromptClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesSchedulerClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesSecretClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesTaskClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/OrkesWorkflowClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/Pair.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/SchedulerResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/SecretResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/TagsResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/TokenResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/UserResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/WorkflowBulkResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/http/WorkflowResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/AccessKeyResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/AccessKeyStatus.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/AuthorizationRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/ConductorApplication.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/ConductorUser.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/CorrelationIdsSearchRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/CreateAccessKeyResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/CreateOrUpdateApplicationRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/ExternalStorageLocation.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/GenerateTokenRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/GrantedAccess.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/GrantedAccessResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/Group.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/Permission.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/Role.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/SaveScheduleRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/SearchResultWorkflowScheduleExecution.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/SearchResultWorkflowScheduleExecutionModel.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/SearchResultWorkflowSummary.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/Subject.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/SubjectRef.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/TagObject.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/TagString.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/TargetRef.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/TaskDetails.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/TerminateWorkflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/TokenResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/UpsertGroupRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/UpsertUserRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/WorkflowRun.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/WorkflowSchedule.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/WorkflowScheduleExecutionModel.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/WorkflowStateUpdate.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/WorkflowStatus.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/event/QueueConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/event/QueueWorkerConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/Category.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/Integration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/IntegrationApi.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/IntegrationApiUpdate.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/IntegrationDef.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/IntegrationUpdate.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/PromptTemplateTestRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/ChatCompletion.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/ChatMessage.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/EmbeddingRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/IndexDocInput.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/IndexedDoc.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/LLMResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/LLMWorkerInput.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/PromptTemplate.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/PromptTemplateTestRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/StoreEmbeddingsInput.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/TextCompletion.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/model/integration/ai/VectorDBInput.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/worker/WorkerFn.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-client/src/main/java/io/orkes/conductor/client/worker/Workers.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/orkes-spring/src/main/java/io/orkes/conductor/client/spring/OrkesConductorClientAutoConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Orkes, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/healthcheck/HealthCheckClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/testing/LocalServerRunner.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/testing/WorkflowTestRunner.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/ConductorWorkflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/ValidationError.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/WorkflowBuilder.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/DoWhile.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/Dynamic.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/DynamicFork.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/DynamicForkInput.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/Event.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/ForkJoin.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/Http.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/JQ.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/Javascript.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/Join.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/SetVariable.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/SimpleTask.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/SubWorkflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/Switch.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/Task.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/TaskRegistry.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/Terminate.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/Wait.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/WorkflowExecutor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/task/AnnotatedWorker.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/task/AnnotatedWorkerExecutor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/task/DynamicForkWorker.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/task/NonRetryableException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/task/TaskContext.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/task/WorkerConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/task/InputParam.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/task/OutputParam.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/task/WorkerTask.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/utils/InputOutputGetter.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/main/java/com/netflix/conductor/sdk/workflow/utils/MapBuilder.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/test/java/com/netflix/conductor/sdk/workflow/def/TaskConversionsTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/test/java/com/netflix/conductor/sdk/workflow/def/WorkflowCreationTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/test/java/com/netflix/conductor/sdk/workflow/def/WorkflowDefTaskTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/test/java/com/netflix/conductor/sdk/workflow/def/WorkflowState.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/test/java/com/netflix/conductor/sdk/workflow/executor/task/AnnotatedWorkerTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/test/java/com/netflix/conductor/sdk/workflow/executor/task/TestWorkerConfig.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/test/java/com/netflix/conductor/sdk/workflow/testing/Task1Input.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/test/java/com/netflix/conductor/sdk/workflow/testing/TestWorkflowInput.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/sdk/src/test/java/com/netflix/conductor/sdk/workflow/testing/WorkflowTestFrameworkTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Orkes, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/LoadTestWorker.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/LocalWorkerTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/WorkflowRetryTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/AuthorizationClientTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/EventClientTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/MetadataClientTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/PathSuffixTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/SchedulerClientTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/SecretClientTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/TaskClientTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/WorkflowClientTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/http/WorkflowStateUpdateTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2024 Orkes, Inc.
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/util/ClientTestUtil.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/util/Commons.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/util/SimpleWorker.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/util/TestUtil.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/util/WorkflowUtil.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/worker/LocalServerWorkflowExecutionTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/client/worker/WorkflowExecutionTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Orkes, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: conductor-clients/java/conductor-java-sdk/tests/src/test/java/io/orkes/conductor/sdk/WorkflowSDKTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Orkes, Inc.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/MetadataServiceImpl.java
Patch:
@@ -82,6 +82,8 @@ public void updateTaskDef(TaskDef taskDefinition) {
         }
         taskDefinition.setUpdatedBy(WorkflowContext.get().getClientApp());
         taskDefinition.setUpdateTime(System.currentTimeMillis());
+        taskDefinition.setCreateTime(existing.getCreateTime());
+        taskDefinition.setCreatedBy(existing.getCreatedBy());
         metadataDAO.updateTaskDef(taskDefinition);
     }
 

File: core/src/main/java/com/netflix/conductor/core/config/ConductorProperties.java
Patch:
@@ -124,7 +124,7 @@ public class ConductorProperties {
     /**
      * The max number of the threads to be polled within the threadpool for system task workers.
      */
-    private int systemTaskMaxPollCount = systemTaskWorkerThreadCount / 2;
+    private int systemTaskMaxPollCount = systemTaskWorkerThreadCount;
 
     /**
      * The interval (in seconds) after which a system task will be checked by the system task worker

File: metrics/src/main/java/com/netflix/conductor/contribs/metrics/PrometheusMetricsConfiguration.java
Patch:
@@ -21,7 +21,6 @@
 import com.netflix.spectator.micrometer.MicrometerRegistry;
 
 import io.micrometer.core.instrument.MeterRegistry;
-import io.micrometer.prometheus.PrometheusRenameFilter;
 
 /**
  * Metrics prometheus module, sending all metrics to a Prometheus server.
@@ -40,7 +39,6 @@ public class PrometheusMetricsConfiguration {
     public PrometheusMetricsConfiguration(MeterRegistry meterRegistry) {
         LOGGER.info("Prometheus metrics module initialized");
         final MicrometerRegistry metricsRegistry = new MicrometerRegistry(meterRegistry);
-        meterRegistry.config().meterFilter(new PrometheusRenameFilter());
         Spectator.globalRegistry().add(metricsRegistry);
     }
 }

File: metrics/src/test/java/com/netflix/conductor/contribs/metrics/PrometheusMetricsConfigurationTest.java
Patch:
@@ -31,8 +31,7 @@
 import com.netflix.spectator.micrometer.MicrometerRegistry;
 
 import io.micrometer.core.instrument.MeterRegistry;
-import io.micrometer.prometheus.PrometheusConfig;
-import io.micrometer.prometheus.PrometheusMeterRegistry;
+import io.micrometer.core.instrument.simple.SimpleMeterRegistry;
 
 import static org.junit.Assert.assertTrue;
 
@@ -72,7 +71,7 @@ public static class TestConfig {
         @Bean
         @Primary
         public MeterRegistry meterRegistry() {
-            return new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
+            return new SimpleMeterRegistry();
         }
     }
 }

File: postgres-persistence/src/main/java/com/netflix/conductor/postgres/config/PostgresConfiguration.java
Patch:
@@ -65,7 +65,7 @@ public Flyway flywayForPrimaryDb() {
             config.locations("classpath:db/migration_postgres");
         }
 
-        return config.configuration(Map.of("flyway.postgresql.transactional.lock", "false"))
+        return config.configuration(Map.of())
                 .schemas(properties.getSchema())
                 .dataSource(dataSource)
                 .outOfOrder(true)

File: metrics/src/main/java/com/netflix/conductor/contribs/metrics/PrometheusMetricsConfiguration.java
Patch:
@@ -21,7 +21,6 @@
 import com.netflix.spectator.micrometer.MicrometerRegistry;
 
 import io.micrometer.core.instrument.MeterRegistry;
-import io.micrometer.prometheus.PrometheusRenameFilter;
 
 /**
  * Metrics prometheus module, sending all metrics to a Prometheus server.
@@ -40,7 +39,6 @@ public class PrometheusMetricsConfiguration {
     public PrometheusMetricsConfiguration(MeterRegistry meterRegistry) {
         LOGGER.info("Prometheus metrics module initialized");
         final MicrometerRegistry metricsRegistry = new MicrometerRegistry(meterRegistry);
-        meterRegistry.config().meterFilter(new PrometheusRenameFilter());
         Spectator.globalRegistry().add(metricsRegistry);
     }
 }

File: metrics/src/test/java/com/netflix/conductor/contribs/metrics/PrometheusMetricsConfigurationTest.java
Patch:
@@ -31,8 +31,7 @@
 import com.netflix.spectator.micrometer.MicrometerRegistry;
 
 import io.micrometer.core.instrument.MeterRegistry;
-import io.micrometer.prometheus.PrometheusConfig;
-import io.micrometer.prometheus.PrometheusMeterRegistry;
+import io.micrometer.core.instrument.simple.SimpleMeterRegistry;
 
 import static org.junit.Assert.assertTrue;
 
@@ -72,7 +71,7 @@ public static class TestConfig {
         @Bean
         @Primary
         public MeterRegistry meterRegistry() {
-            return new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
+            return new SimpleMeterRegistry();
         }
     }
 }

File: postgres-persistence/src/main/java/com/netflix/conductor/postgres/config/PostgresConfiguration.java
Patch:
@@ -65,7 +65,7 @@ public Flyway flywayForPrimaryDb() {
             config.locations("classpath:db/migration_postgres");
         }
 
-        return config.configuration(Map.of("flyway.postgresql.transactional.lock", "false"))
+        return config.configuration(Map.of())
                 .schemas(properties.getSchema())
                 .dataSource(dataSource)
                 .outOfOrder(true)

File: rest/src/main/java/com/netflix/conductor/rest/controllers/ApplicationExceptionMapper.java
Patch:
@@ -22,6 +22,7 @@
 import org.springframework.http.ResponseEntity;
 import org.springframework.web.bind.annotation.ExceptionHandler;
 import org.springframework.web.bind.annotation.RestControllerAdvice;
+import org.springframework.web.servlet.resource.NoResourceFoundException;
 
 import com.netflix.conductor.common.validation.ErrorResponse;
 import com.netflix.conductor.core.exception.ConflictException;
@@ -49,6 +50,7 @@ public class ApplicationExceptionMapper {
         EXCEPTION_STATUS_MAP.put(ConflictException.class, HttpStatus.CONFLICT);
         EXCEPTION_STATUS_MAP.put(IllegalArgumentException.class, HttpStatus.BAD_REQUEST);
         EXCEPTION_STATUS_MAP.put(InvalidFormatException.class, HttpStatus.INTERNAL_SERVER_ERROR);
+        EXCEPTION_STATUS_MAP.put(NoResourceFoundException.class, HttpStatus.NOT_FOUND);
     }
 
     @ExceptionHandler(Throwable.class)

File: rest/src/main/java/com/netflix/conductor/rest/controllers/ApplicationExceptionMapper.java
Patch:
@@ -22,7 +22,6 @@
 import org.springframework.http.ResponseEntity;
 import org.springframework.web.bind.annotation.ExceptionHandler;
 import org.springframework.web.bind.annotation.RestControllerAdvice;
-import org.springframework.web.servlet.resource.NoResourceFoundException;
 
 import com.netflix.conductor.common.validation.ErrorResponse;
 import com.netflix.conductor.core.exception.ConflictException;
@@ -50,7 +49,6 @@ public class ApplicationExceptionMapper {
         EXCEPTION_STATUS_MAP.put(ConflictException.class, HttpStatus.CONFLICT);
         EXCEPTION_STATUS_MAP.put(IllegalArgumentException.class, HttpStatus.BAD_REQUEST);
         EXCEPTION_STATUS_MAP.put(InvalidFormatException.class, HttpStatus.INTERNAL_SERVER_ERROR);
-        EXCEPTION_STATUS_MAP.put(NoResourceFoundException.class, HttpStatus.NOT_FOUND);
     }
 
     @ExceptionHandler(Throwable.class)

File: task-status-listener/src/main/java/com/netflix/conductor/contribs/listener/RestClientManager.java
Patch:
@@ -196,7 +196,7 @@ public void postNotification(
         executePost(request);
         long duration = System.currentTimeMillis() - start;
         if (duration > 100) {
-            logger.info("Round trip response time = " + (duration) + " millis");
+            logger.info("Round trip response time = {} millis", duration);
         }
     }
 
@@ -213,7 +213,7 @@ private String prepareUrl(
             }
         } else if (notifType == RestClientManager.NotificationType.WORKFLOW) {
             if (statusNotifier != null
-                    && StringUtils.isNotBlank(statusNotifier.getEndpointTask())) {
+                    && StringUtils.isNotBlank(statusNotifier.getEndpointWorkflow())) {
                 urlEndPoint = statusNotifier.getEndpointWorkflow();
             } else {
                 urlEndPoint = config.getEndpointWorkflow();

File: nats/src/main/java/com/netflix/conductor/contribs/queue/nats/LoggingNatsErrorListener.java
Patch:
@@ -1,4 +1,5 @@
 /*
+ * Copyright 2024 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: task-status-listener/src/main/java/com/netflix/conductor/contribs/listener/RestClientManager.java
Patch:
@@ -196,7 +196,7 @@ public void postNotification(
         executePost(request);
         long duration = System.currentTimeMillis() - start;
         if (duration > 100) {
-            logger.info("Round trip response time = " + (duration) + " millis");
+            logger.info("Round trip response time = {} millis", duration);
         }
     }
 
@@ -213,7 +213,7 @@ private String prepareUrl(
             }
         } else if (notifType == RestClientManager.NotificationType.WORKFLOW) {
             if (statusNotifier != null
-                    && StringUtils.isNotBlank(statusNotifier.getEndpointTask())) {
+                    && StringUtils.isNotBlank(statusNotifier.getEndpointWorkflow())) {
                 urlEndPoint = statusNotifier.getEndpointWorkflow();
             } else {
                 urlEndPoint = config.getEndpointWorkflow();

File: task-status-listener/src/main/java/com/netflix/conductor/contribs/listener/RestClientManager.java
Patch:
@@ -188,7 +188,8 @@ public void postNotification(
         String url = prepareUrl(notifType, statusNotifier);
 
         Map<String, String> headers = new HashMap<>();
-        headers.put(config.getHeaderPrefer(), config.getHeaderPreferValue());
+        if (config.getHeaderPrefer() != "" && config.getHeaderPreferValue() != "")
+            headers.put(config.getHeaderPrefer(), config.getHeaderPreferValue());
 
         HttpPost request = createPostRequest(url, data, headers);
         long start = System.currentTimeMillis();

File: redis-persistence/src/main/java/com/netflix/conductor/redis/dao/RedisExecutionDAO.java
Patch:
@@ -289,7 +289,7 @@ public boolean exceedsLimit(TaskModel task) {
         jedisProxy.zaddnx(rateLimitKey, score, taskId);
         recordRedisDaoRequests("checkTaskRateLimiting", task.getTaskType(), task.getWorkflowType());
 
-        Set<String> ids = jedisProxy.zrangeByScore(rateLimitKey, 0, score + 1, limit);
+        Set<String> ids = jedisProxy.zrangeByScore(rateLimitKey, 0, score + 1, Integer.MAX_VALUE);
         boolean rateLimited = !ids.contains(taskId);
         if (rateLimited) {
             LOGGER.info(

File: redis-persistence/src/main/java/com/netflix/conductor/redis/dao/RedisExecutionDAO.java
Patch:
@@ -289,7 +289,7 @@ public boolean exceedsLimit(TaskModel task) {
         jedisProxy.zaddnx(rateLimitKey, score, taskId);
         recordRedisDaoRequests("checkTaskRateLimiting", task.getTaskType(), task.getWorkflowType());
 
-        Set<String> ids = jedisProxy.zrangeByScore(rateLimitKey, 0, score + 1, limit);
+        Set<String> ids = jedisProxy.zrangeByScore(rateLimitKey, 0, score + 1, Integer.MAX_VALUE);
         boolean rateLimited = !ids.contains(taskId);
         if (rateLimited) {
             LOGGER.info(

File: task-status-listener/src/main/java/com/netflix/conductor/contribs/listener/RestClientManager.java
Patch:
@@ -188,7 +188,7 @@ public void postNotification(
         String url = prepareUrl(notifType, statusNotifier);
 
         Map<String, String> headers = new HashMap<>();
-        if(config.getHeaderPrefer() != "" && config.getHeaderPreferValue() != "")
+        if (config.getHeaderPrefer() != "" && config.getHeaderPreferValue() != "")
             headers.put(config.getHeaderPrefer(), config.getHeaderPreferValue());
 
         HttpPost request = createPostRequest(url, data, headers);

File: task-status-listener/src/main/java/com/netflix/conductor/contribs/listener/RestClientManager.java
Patch:
@@ -188,7 +188,8 @@ public void postNotification(
         String url = prepareUrl(notifType, statusNotifier);
 
         Map<String, String> headers = new HashMap<>();
-        headers.put(config.getHeaderPrefer(), config.getHeaderPreferValue());
+        if(config.getHeaderPrefer() != "" && config.getHeaderPreferValue() != "")
+            headers.put(config.getHeaderPrefer(), config.getHeaderPreferValue());
 
         HttpPost request = createPostRequest(url, data, headers);
         long start = System.currentTimeMillis();

File: postgres-persistence/src/test/java/com/netflix/conductor/postgres/dao/PostgresIndexDAOStatusChangeOnlyTest.java
Patch:
@@ -155,7 +155,6 @@ public void testIndexWorkflowOnlyStatusChange() throws SQLException {
         checkWorkflow("workflow-id", "FAILED", "new-correlation-id");
     }
 
-    @Test
     public void testIndexTaskOnlyStatusChange() throws SQLException {
         TaskSummary ts = getMockTaskSummary("task-id");
 

File: postgres-persistence/src/test/java/com/netflix/conductor/postgres/dao/PostgresMetadataDAOTest.java
Patch:
@@ -54,7 +54,7 @@
             FlywayAutoConfiguration.class
         })
 @RunWith(SpringRunner.class)
-@SpringBootTest(properties = "spring.flyway.clean-disabled=false")
+@SpringBootTest(properties = "spring.flyway.clean-disabled=true")
 public class PostgresMetadataDAOTest {
 
     @Autowired private PostgresMetadataDAO metadataDAO;

File: postgres-persistence/src/test/java/com/netflix/conductor/test/integration/grpc/postgres/PostgresGrpcEndToEndTest.java
Patch:
@@ -27,6 +27,7 @@
 @TestPropertySource(
         properties = {
             "conductor.db.type=postgres",
+            "conductor.postgres.experimentalQueueNotify=true",
             "conductor.app.asyncIndexingEnabled=false",
             "conductor.elasticsearch.version=7",
             "conductor.grpc-server.port=8098",
@@ -37,7 +38,8 @@
             "spring.datasource.username=postgres",
             "spring.datasource.password=postgres",
             "spring.datasource.hikari.maximum-pool-size=8",
-            "spring.datasource.hikari.minimum-idle=300000"
+            "spring.datasource.hikari.minimum-idle=300000",
+            "spring.flyway.clean-disabled=true"
         })
 public class PostgresGrpcEndToEndTest extends AbstractGrpcEndToEndTest {
 

File: postgres-persistence/src/test/java/com/netflix/conductor/postgres/dao/PostgresIndexDAOStatusChangeOnlyTest.java
Patch:
@@ -20,7 +20,6 @@
 
 import org.flywaydb.core.Flyway;
 import org.junit.Before;
-import org.junit.Ignore;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.springframework.beans.factory.annotation.Autowired;
@@ -133,7 +132,6 @@ public void checkTask(String taskId, String status, String updateTime) throws SQ
                 result.get(0).get("update_time").toString());
     }
 
-
     @Test
     public void testIndexWorkflowOnlyStatusChange() throws SQLException {
         WorkflowSummary wfs = getMockWorkflowSummary("workflow-id");

File: postgres-persistence/src/test/java/com/netflix/conductor/postgres/dao/PostgresIndexDAOStatusChangeOnlyTest.java
Patch:
@@ -20,6 +20,7 @@
 
 import org.flywaydb.core.Flyway;
 import org.junit.Before;
+import org.junit.Ignore;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.springframework.beans.factory.annotation.Autowired;
@@ -132,6 +133,7 @@ public void checkTask(String taskId, String status, String updateTime) throws SQ
                 result.get(0).get("update_time").toString());
     }
 
+
     @Test
     public void testIndexWorkflowOnlyStatusChange() throws SQLException {
         WorkflowSummary wfs = getMockWorkflowSummary("workflow-id");
@@ -155,7 +157,6 @@ public void testIndexWorkflowOnlyStatusChange() throws SQLException {
         checkWorkflow("workflow-id", "FAILED", "new-correlation-id");
     }
 
-    @Test
     public void testIndexTaskOnlyStatusChange() throws SQLException {
         TaskSummary ts = getMockTaskSummary("task-id");
 

File: postgres-persistence/src/test/java/com/netflix/conductor/postgres/dao/PostgresMetadataDAOTest.java
Patch:
@@ -54,7 +54,7 @@
             FlywayAutoConfiguration.class
         })
 @RunWith(SpringRunner.class)
-@SpringBootTest(properties = "spring.flyway.clean-disabled=false")
+@SpringBootTest(properties = "spring.flyway.clean-disabled=true")
 public class PostgresMetadataDAOTest {
 
     @Autowired private PostgresMetadataDAO metadataDAO;

File: postgres-persistence/src/test/java/com/netflix/conductor/test/integration/grpc/postgres/PostgresGrpcEndToEndTest.java
Patch:
@@ -27,6 +27,7 @@
 @TestPropertySource(
         properties = {
             "conductor.db.type=postgres",
+            "conductor.postgres.experimentalQueueNotify=true",
             "conductor.app.asyncIndexingEnabled=false",
             "conductor.elasticsearch.version=7",
             "conductor.grpc-server.port=8098",
@@ -37,7 +38,8 @@
             "spring.datasource.username=postgres",
             "spring.datasource.password=postgres",
             "spring.datasource.hikari.maximum-pool-size=8",
-            "spring.datasource.hikari.minimum-idle=300000"
+            "spring.datasource.hikari.minimum-idle=300000",
+            "spring.flyway.clean-disabled=true"
         })
 public class PostgresGrpcEndToEndTest extends AbstractGrpcEndToEndTest {
 

File: postgres-persistence/src/main/java/com/netflix/conductor/postgres/util/PostgresIndexQueryBuilder.java
Patch:
@@ -75,6 +75,8 @@ public Condition(String query) {
                 if (this.attribute.endsWith("_time")) {
                     values.set(0, millisToUtc(values.get(0)));
                 }
+            } else {
+                throw new IllegalArgumentException("Incorrectly formatted query string: " + query);
             }
         }
 

File: postgres-persistence/src/main/java/com/netflix/conductor/postgres/dao/PostgresLockDAO.java
Patch:
@@ -23,6 +23,7 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 
 public class PostgresLockDAO extends PostgresBaseDAO implements Lock {
+    private final long DAY_MS = 24 * 60 * 60 * 1000;
 
     public PostgresLockDAO(
             RetryTemplate retryTemplate, ObjectMapper objectMapper, DataSource dataSource) {
@@ -31,12 +32,12 @@ public PostgresLockDAO(
 
     @Override
     public void acquireLock(String lockId) {
-        acquireLock(lockId, Long.MAX_VALUE, Long.MAX_VALUE, TimeUnit.SECONDS);
+        acquireLock(lockId, DAY_MS, DAY_MS, TimeUnit.SECONDS);
     }
 
     @Override
     public boolean acquireLock(String lockId, long timeToTry, TimeUnit unit) {
-        return acquireLock(lockId, timeToTry, Long.MAX_VALUE, unit);
+        return acquireLock(lockId, timeToTry, DAY_MS, unit);
     }
 
     @Override

File: postgres-persistence/src/main/java/com/netflix/conductor/postgres/dao/PostgresLockDAO.java
Patch:
@@ -44,15 +44,15 @@ public boolean acquireLock(String lockId, long timeToTry, long leaseTime, TimeUn
         long endTime = System.currentTimeMillis() + unit.toMillis(timeToTry);
         while (System.currentTimeMillis() < endTime) {
             var sql =
-                    "INSERT INTO locks(lock_id, lease_expiration) VALUES (?, now() + (?::text || ' milliseconds')::interval) ON CONFLICT (lock_id) DO UPDATE SET lease_expiration = now() + (?::text || ' milliseconds')::interval WHERE lock_id = ? AND lease_expiration <= now()";
+                    "INSERT INTO locks(lock_id, lease_expiration) VALUES (?, now() + (?::text || ' milliseconds')::interval) ON CONFLICT (lock_id) DO UPDATE SET lease_expiration = now() + (?::text || ' milliseconds')::interval WHERE locks.lock_id = EXCLUDED.lock_id AND lease_expiration <= now()";
+
             int rowsAffected =
                     queryWithTransaction(
                             sql,
                             q ->
                                     q.addParameter(lockId)
                                             .addParameter(unit.toMillis(leaseTime))
                                             .addParameter(unit.toMillis(leaseTime))
-                                            .addParameter(lockId)
                                             .executeUpdate());
 
             if (rowsAffected > 0) {

File: postgres-persistence/src/main/java/com/netflix/conductor/postgres/config/PostgresConfiguration.java
Patch:
@@ -13,6 +13,7 @@
 package com.netflix.conductor.postgres.config;
 
 import java.sql.SQLException;
+import java.util.Map;
 import java.util.Optional;
 
 import javax.sql.DataSource;
@@ -59,6 +60,7 @@ public PostgresConfiguration(DataSource dataSource, PostgresProperties propertie
     public Flyway flywayForPrimaryDb() {
         return Flyway.configure()
                 .locations("classpath:db/migration_postgres")
+                .configuration(Map.of("flyway.postgresql.transactional.lock", "false"))
                 .schemas(properties.getSchema())
                 .dataSource(dataSource)
                 .outOfOrder(true)

File: postgres-persistence/src/main/java/com/netflix/conductor/postgres/util/PostgresIndexQueryBuilder.java
Patch:
@@ -44,7 +44,7 @@ public class PostgresIndexQueryBuilder {
         "task_def_name",
         "update_time",
         "json_data",
-        "to_tsvector(json_data::text)"
+        "jsonb_to_tsvector('english', json_data, '[\"all\"]')"
     };
 
     private static final String[] VALID_SORT_ORDER = {"ASC", "DESC"};
@@ -186,7 +186,7 @@ private void parseFreeText(String freeText) {
                 conditions.add(cond);
             } else {
                 Condition cond = new Condition();
-                cond.setAttribute("to_tsvector(json_data::text)");
+                cond.setAttribute("jsonb_to_tsvector('english', json_data, '[\"all\"]')");
                 cond.setOperator("@@");
                 String[] values = {freeText};
                 cond.setValues(Arrays.asList(values));

File: postgres-persistence/src/test/java/com/netflix/conductor/postgres/util/PostgresIndexQueryBuilderTest.java
Patch:
@@ -268,7 +268,7 @@ void shouldAllowFullTextSearch() throws SQLException {
                 new PostgresIndexQueryBuilder(
                         "table_name", "", freeText, 0, 15, Arrays.asList(query));
         String expectedQuery =
-                "SELECT json_data::TEXT FROM table_name WHERE to_tsvector(json_data::text) @@ to_tsquery(?) LIMIT ? OFFSET ?";
+                "SELECT json_data::TEXT FROM table_name WHERE jsonb_to_tsvector('english', json_data, '[\"all\"]') @@ to_tsquery(?) LIMIT ? OFFSET ?";
         assertEquals(expectedQuery, builder.getQuery());
     }
 

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -24,6 +24,7 @@
 import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 
+import com.fasterxml.jackson.annotation.JsonIgnore;
 import com.google.protobuf.Any;
 import io.swagger.v3.oas.annotations.Hidden;
 
@@ -629,6 +630,7 @@ public void setOutputMessage(Any outputMessage) {
     /**
      * @return {@link Optional} containing the task definition if available
      */
+    @JsonIgnore
     public Optional<TaskDef> getTaskDefinition() {
         return Optional.ofNullable(this.getWorkflowTask()).map(WorkflowTask::getTaskDefinition);
     }

File: core/src/main/java/com/netflix/conductor/model/TaskModel.java
Patch:
@@ -571,6 +571,7 @@ public void incrementPollCount() {
     /**
      * @return {@link Optional} containing the task definition if available
      */
+    @JsonIgnore
     public Optional<TaskDef> getTaskDefinition() {
         return Optional.ofNullable(this.getWorkflowTask()).map(WorkflowTask::getTaskDefinition);
     }

File: es7-persistence/src/main/java/com/netflix/conductor/es7/config/ElasticSearchV7Configuration.java
Patch:
@@ -59,7 +59,7 @@ public RestClient restClient(ElasticSearchProperties properties) {
     }
 
     @Bean
-    public RestClientBuilder restClientBuilder(ElasticSearchProperties properties) {
+    public RestClientBuilder elasticRestClientBuilder(ElasticSearchProperties properties) {
         RestClientBuilder builder = RestClient.builder(convertToHttpHosts(properties.toURLs()));
 
         if (properties.getUsername() != null && properties.getPassword() != null) {

File: es7-persistence/src/main/java/com/netflix/conductor/es7/dao/index/ElasticSearchRestDAOV7.java
Patch:
@@ -42,7 +42,6 @@
 import org.elasticsearch.client.*;
 import org.elasticsearch.client.core.CountRequest;
 import org.elasticsearch.client.core.CountResponse;
-import org.elasticsearch.common.xcontent.*;
 import org.elasticsearch.index.query.BoolQueryBuilder;
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
@@ -51,6 +50,7 @@
 import org.elasticsearch.search.builder.SearchSourceBuilder;
 import org.elasticsearch.search.sort.FieldSortBuilder;
 import org.elasticsearch.search.sort.SortOrder;
+import org.elasticsearch.xcontent.XContentType;
 import org.joda.time.DateTime;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;

File: es7-persistence/src/test/java/com/netflix/conductor/es7/dao/index/ElasticSearchTest.java
Patch:
@@ -47,8 +47,8 @@ public ElasticSearchProperties elasticSearchProperties() {
 
     protected static final ElasticsearchContainer container =
             new ElasticsearchContainer(
-                    DockerImageName.parse("docker.elastic.co/elasticsearch/elasticsearch-oss")
-                            .withTag("7.10.2")); // this should match the client version
+                    DockerImageName.parse("elasticsearch")
+                            .withTag("7.17.16")); // this should match the client version
 
     @Autowired protected ObjectMapper objectMapper;
 

File: java-sdk/src/main/java/com/netflix/conductor/sdk/testing/LocalServerRunner.java
Patch:
@@ -163,7 +163,7 @@ private synchronized void installAndStartServer(String repositoryURL, int localS
                         + serverFile;
         LOGGER.info("Running command {}", command);
 
-        serverProcess = Runtime.getRuntime().exec(command);
+        serverProcess = Runtime.getRuntime().exec(new String[] {"bash", "-l", "-c", command});
         BufferedReader error =
                 new BufferedReader(new InputStreamReader(serverProcess.getErrorStream()));
         BufferedReader op =

File: rest/src/main/java/com/netflix/conductor/rest/controllers/ApplicationExceptionMapper.java
Patch:
@@ -22,6 +22,7 @@
 import org.springframework.http.ResponseEntity;
 import org.springframework.web.bind.annotation.ExceptionHandler;
 import org.springframework.web.bind.annotation.RestControllerAdvice;
+import org.springframework.web.servlet.resource.NoResourceFoundException;
 
 import com.netflix.conductor.common.validation.ErrorResponse;
 import com.netflix.conductor.core.exception.ConflictException;
@@ -49,6 +50,7 @@ public class ApplicationExceptionMapper {
         EXCEPTION_STATUS_MAP.put(ConflictException.class, HttpStatus.CONFLICT);
         EXCEPTION_STATUS_MAP.put(IllegalArgumentException.class, HttpStatus.BAD_REQUEST);
         EXCEPTION_STATUS_MAP.put(InvalidFormatException.class, HttpStatus.INTERNAL_SERVER_ERROR);
+        EXCEPTION_STATUS_MAP.put(NoResourceFoundException.class, HttpStatus.NOT_FOUND);
     }
 
     @ExceptionHandler(Throwable.class)

File: test-harness/src/test/java/com/netflix/conductor/test/integration/AbstractEndToEndTest.java
Patch:
@@ -65,8 +65,8 @@ public abstract class AbstractEndToEndTest {
 
     private static final ElasticsearchContainer container =
             new ElasticsearchContainer(
-                    DockerImageName.parse("docker.elastic.co/elasticsearch/elasticsearch-oss")
-                            .withTag("7.10.2")); // this should match the client version
+                    DockerImageName.parse("elasticsearch")
+                            .withTag("7.17.16")); // this should match the client version
 
     private static RestClient restClient;
 

File: test-util/src/test/java/com/netflix/conductor/test/integration/AbstractEndToEndTest.java
Patch:
@@ -61,8 +61,8 @@ public abstract class AbstractEndToEndTest {
 
     private static final ElasticsearchContainer container =
             new ElasticsearchContainer(
-                    DockerImageName.parse("docker.elastic.co/elasticsearch/elasticsearch-oss")
-                            .withTag("7.10.2")); // this should match the client version
+                    DockerImageName.parse("elasticsearch")
+                            .withTag("7.17.16")); // this should match the client version
 
     private static RestClient restClient;
 

File: test-harness/src/test/java/com/netflix/conductor/test/integration/grpc/AbstractGrpcEndToEndTest.java
Patch:
@@ -22,6 +22,7 @@
 import org.springframework.test.context.TestPropertySource;
 import org.springframework.test.context.junit4.SpringRunner;
 
+import com.netflix.conductor.ConductorTestApp;
 import com.netflix.conductor.client.grpc.EventClient;
 import com.netflix.conductor.client.grpc.MetadataClient;
 import com.netflix.conductor.client.grpc.TaskClient;
@@ -48,6 +49,7 @@
 
 @RunWith(SpringRunner.class)
 @SpringBootTest(
+        classes = ConductorTestApp.class,
         properties = {"conductor.grpc-server.enabled=true", "conductor.grpc-server.port=8092"})
 @TestPropertySource(locations = "classpath:application-integrationtest.properties")
 public abstract class AbstractGrpcEndToEndTest extends AbstractEndToEndTest {
@@ -156,7 +158,7 @@ public void testAll() throws Exception {
         assertNotNull(polled);
         assertEquals(0, polled.size());
 
-        polled = taskClient.batchPollTasksByTaskType(t0.getName(), "test", 1, 100);
+        polled = taskClient.batchPollTasksByTaskType(t0.getName(), "test", 1, 1000);
         assertNotNull(polled);
         assertEquals(1, polled.size());
         assertEquals(t0.getName(), polled.get(0).getTaskDefName());

File: test-harness/src/test/java/com/netflix/conductor/test/integration/http/AbstractHttpEndToEndTest.java
Patch:
@@ -26,6 +26,7 @@
 import org.springframework.test.context.TestPropertySource;
 import org.springframework.test.context.junit4.SpringRunner;
 
+import com.netflix.conductor.ConductorTestApp;
 import com.netflix.conductor.client.exception.ConductorClientException;
 import com.netflix.conductor.client.http.EventClient;
 import com.netflix.conductor.client.http.MetadataClient;
@@ -55,7 +56,7 @@
 import static org.junit.Assert.fail;
 
 @RunWith(SpringRunner.class)
-@SpringBootTest(webEnvironment = WebEnvironment.RANDOM_PORT)
+@SpringBootTest(webEnvironment = WebEnvironment.RANDOM_PORT, classes = ConductorTestApp.class)
 @TestPropertySource(locations = "classpath:application-integrationtest.properties")
 public abstract class AbstractHttpEndToEndTest extends AbstractEndToEndTest {
 

File: test-util/src/test/java/com/netflix/conductor/test/integration/grpc/AbstractGrpcEndToEndTest.java
Patch:
@@ -20,6 +20,7 @@
 import org.springframework.test.context.TestPropertySource;
 import org.springframework.test.context.junit4.SpringRunner;
 
+import com.netflix.conductor.ConductorTestApp;
 import com.netflix.conductor.client.grpc.EventClient;
 import com.netflix.conductor.client.grpc.MetadataClient;
 import com.netflix.conductor.client.grpc.TaskClient;
@@ -46,6 +47,7 @@
 
 @RunWith(SpringRunner.class)
 @SpringBootTest(
+        classes = ConductorTestApp.class,
         properties = {"conductor.grpc-server.enabled=true", "conductor.grpc-server.port=8092"})
 @TestPropertySource(locations = "classpath:application-integrationtest.properties")
 public abstract class AbstractGrpcEndToEndTest extends AbstractEndToEndTest {

File: workflow-event-listener/src/test/java/com/netflix/conductor/test/listener/WorkflowStatusPublisherIntegrationTest.java
Patch:
@@ -29,6 +29,7 @@
 import org.springframework.test.context.TestPropertySource;
 import org.springframework.test.context.junit4.SpringRunner;
 
+import com.netflix.conductor.ConductorTestApp;
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
 import com.netflix.conductor.common.metadata.tasks.TaskResult;
@@ -51,6 +52,7 @@
 
 @RunWith(SpringRunner.class)
 @SpringBootTest(
+        classes = ConductorTestApp.class,
         properties = {
             "conductor.db.type=memory",
             "conductor.workflow-status-listener.type=queue_publisher",

File: es6-persistence/src/main/java/com/netflix/conductor/es6/config/ElasticSearchConditions.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/config/ElasticSearchProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/config/ElasticSearchV6Configuration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/config/IsHttpProtocol.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/config/IsTcpProtocol.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/index/BulkRequestBuilderWrapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/index/BulkRequestWrapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/index/ElasticSearchBaseDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/index/ElasticSearchDAOV6.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/index/ElasticSearchRestDAOV6.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/Expression.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/FilterProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/GroupedExpression.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/NameValue.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/internal/AbstractNode.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/internal/BooleanOp.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/internal/ComparisonOp.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/internal/ConstValue.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/internal/FunctionThrowingException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/internal/ListConst.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/internal/Name.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/internal/ParserException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/query/parser/internal/Range.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/index/ElasticSearchDaoBaseTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/index/ElasticSearchRestDaoBaseTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/index/ElasticSearchTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/index/TestElasticSearchDAOV6.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/index/TestElasticSearchDAOV6Batch.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/index/TestElasticSearchRestDAOV6.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/index/TestElasticSearchRestDAOV6Batch.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Netflix, Inc.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/query/parser/TestExpression.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/query/parser/internal/TestAbstractParser.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/query/parser/internal/TestBooleanOp.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/query/parser/internal/TestComparisonOp.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/query/parser/internal/TestConstValue.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/query/parser/internal/TestName.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/test/java/com/netflix/conductor/es6/utils/TestUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/AMQPConnection.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/AMQPObservableQueue.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/config/AMQPEventQueueConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/config/AMQPEventQueueProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/config/AMQPEventQueueProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/config/AMQPRetryPattern.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/util/AMQPConfigurations.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/util/AMQPConstants.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/util/AMQPSettings.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/util/ConnectionType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/main/java/com/netflix/conductor/contribs/queue/amqp/util/RetryType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/test/java/com/netflix/conductor/contribs/queue/amqp/AMQPEventQueueProviderTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/test/java/com/netflix/conductor/contribs/queue/amqp/AMQPObservableQueueTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: amqp/src/test/java/com/netflix/conductor/contribs/queue/amqp/AMQPSettingsTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/example/java/com/example/Example.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/AbstractMessage.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/Enum.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/Message.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/ProtoFile.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/ProtoGen.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/ProtoGenTask.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/types/AbstractType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/types/ExternMessageType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/types/GenericType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/types/ListType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/types/MapType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/types/MessageType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/types/ScalarType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/types/TypeMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/types/WrappedType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations-processor/src/test/java/com/netflix/conductor/annotationsprocessor/protogen/ProtoGenTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations/src/main/java/com/netflix/conductor/annotations/protogen/ProtoEnum.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations/src/main/java/com/netflix/conductor/annotations/protogen/ProtoField.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: annotations/src/main/java/com/netflix/conductor/annotations/protogen/ProtoMessage.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: awss3-storage/src/main/java/com/netflix/conductor/s3/config/S3Configuration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: awss3-storage/src/main/java/com/netflix/conductor/s3/config/S3Properties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: awss3-storage/src/main/java/com/netflix/conductor/s3/storage/S3PayloadStorage.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: awssqs-event-queue/src/main/java/com/netflix/conductor/sqs/config/SQSEventQueueConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: awssqs-event-queue/src/main/java/com/netflix/conductor/sqs/config/SQSEventQueueProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: awssqs-event-queue/src/main/java/com/netflix/conductor/sqs/config/SQSEventQueueProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: awssqs-event-queue/src/main/java/com/netflix/conductor/sqs/eventqueue/SQSObservableQueue.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: awssqs-event-queue/src/test/java/com/netflix/conductor/sqs/eventqueue/DefaultEventQueueProcessorTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: awssqs-event-queue/src/test/java/com/netflix/conductor/sqs/eventqueue/SQSObservableQueueTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: azureblob-storage/src/main/java/com/netflix/conductor/azureblob/config/AzureBlobConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: azureblob-storage/src/main/java/com/netflix/conductor/azureblob/config/AzureBlobProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: azureblob-storage/src/main/java/com/netflix/conductor/azureblob/storage/AzureBlobPayloadStorage.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: azureblob-storage/src/test/java/com/netflix/conductor/azureblob/storage/AzureBlobPayloadStorageTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/config/CassandraConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/config/CassandraProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/config/cache/CacheableEventHandlerDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/config/cache/CacheableMetadataDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/config/cache/CachingConfig.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraBaseDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraEventHandlerDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraExecutionDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraMetadataDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraPollDataDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/util/Constants.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/util/Statements.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client-spring/src/main/java/com/netflix/conductor/client/spring/ClientProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client-spring/src/main/java/com/netflix/conductor/client/spring/ConductorClientAutoConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client-spring/src/main/java/com/netflix/conductor/client/spring/ConductorWorkerAutoConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client-spring/src/main/java/com/netflix/conductor/client/spring/SpringWorkerConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client-spring/src/test/java/com/netflix/conductor/client/spring/ExampleClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client-spring/src/test/java/com/netflix/conductor/client/spring/Workers.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/automator/PollingSemaphore.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/automator/TaskPollExecutor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/automator/TaskRunnerConfigurer.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/config/ConductorClientConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2018 Conductor authors.
+ * Copyright 2018 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/config/DefaultConductorClientConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/config/PropertyFactory.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/exception/ConductorClientException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/http/ClientBase.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/http/ClientRequestHandler.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/http/EventClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/http/MetadataClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/http/PayloadStorage.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/http/TaskClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/http/WorkflowClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/telemetry/MetricsContainer.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/worker/Worker.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/automator/PollingSemaphoreTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/automator/TaskPollExecutorTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/automator/TaskRunnerConfigurerTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/config/TestPropertyFactory.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/sample/Main.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/sample/SampleWorker.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/testing/AbstractWorkflowTests.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/testing/LoanWorkflowInput.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/testing/LoanWorkflowTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/testing/RegressionTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/testing/SubWorkflowTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/test/java/com/netflix/conductor/client/worker/TestWorkflowTask.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common-persistence/src/test/java/com/netflix/conductor/dao/ExecutionDAOTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common-persistence/src/test/java/com/netflix/conductor/dao/TestBase.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/config/ObjectMapperBuilderConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/config/ObjectMapperConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/config/ObjectMapperProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/constraints/NoSemiColonConstraint.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/constraints/OwnerEmailMandatoryConstraint.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/constraints/TaskReferenceNameUniqueConstraint.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/constraints/TaskTimeoutConstraint.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/jackson/JsonProtoModule.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/Auditable.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/BaseDef.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/acl/Permission.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/events/EventExecution.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/events/EventHandler.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/PollData.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskDef.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskExecLog.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskResult.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskType.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/DynamicForkJoinTask.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/DynamicForkJoinTaskList.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/RerunWorkflowRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/SkipTaskRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/StartWorkflowRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/SubWorkflowParams.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowDef.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowDefSummary.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/model/BulkResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/run/ExternalStorageLocation.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/run/SearchResult.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/run/TaskSummary.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/run/WorkflowSummary.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/run/WorkflowTestRequest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/utils/ConstraintParamUtil.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/utils/EnvUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/utils/ExternalPayloadStorage.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/utils/SummaryUtil.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/utils/TaskUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/validation/ErrorResponse.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/validation/ValidationError.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/config/TestObjectMapperConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/events/EventHandlerTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/run/TaskSummaryTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/tasks/TaskDefTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/tasks/TaskResultTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/tasks/TaskTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/utils/ConstraintParamUtilTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/utils/SummaryUtilTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/workflow/SubWorkflowParamsTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/workflow/WorkflowDefValidatorTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/test/java/com/netflix/conductor/common/workflow/WorkflowTaskTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/annotations/Audit.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/annotations/Trace.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/annotations/VisibleForTesting.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/LifecycleAwareComponent.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/WorkflowContext.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/config/ConductorCoreConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/config/ConductorProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/config/SchedulerConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/dal/ExecutionDAOFacade.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/event/WorkflowCreationEvent.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/event/WorkflowEvaluationEvent.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/ActionProcessor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/DefaultEventProcessor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/DefaultEventQueueManager.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/EventQueueManager.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/EventQueueProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/EventQueues.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/ScriptEvaluator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/SimpleActionProcessor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/queue/ConductorEventQueueProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/queue/ConductorObservableQueue.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/queue/DefaultEventQueueProcessor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/queue/Message.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/queue/ObservableQueue.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/exception/ConflictException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/exception/NonTransientException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/exception/NotFoundException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/exception/TerminateWorkflowException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/exception/TransientException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/AsyncSystemTaskExecutor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/StartWorkflowInput.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/evaluators/Evaluator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/evaluators/JavascriptEvaluator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/evaluators/ValueParamEvaluator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DoWhileTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DynamicTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/EventTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ExclusiveJoinTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinDynamicTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/HTTPTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/HumanTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/InlineTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/JoinTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Conductor authors.
+ * Copyright 2021 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/JsonJQTransformTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/KafkaPublishTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/LambdaTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/NoopTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SetVariableTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SimpleTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/StartWorkflowTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SubWorkflowTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SwitchTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/TaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/TaskMapperContext.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/TerminateTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/UserDefinedTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Decision.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/DoWhile.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Event.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/ExclusiveJoin.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/ExecutionConfig.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Fork.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Human.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Inline.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/IsolatedTaskQueueProducer.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Join.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Lambda.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Noop.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SetVariable.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/StartWorkflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SubWorkflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Switch.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskRegistry.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorker.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorkerCoordinator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Terminate.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Wait.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/WorkflowSystemTask.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/index/NoopIndexDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/index/NoopIndexDAOConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/listener/TaskStatusListener.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/listener/TaskStatusListenerStub.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/listener/WorkflowStatusListener.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/listener/WorkflowStatusListenerStub.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/metadata/MetadataMapperService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/operation/StartWorkflowOperation.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/operation/WorkflowOperation.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/reconciliation/WorkflowReconciler.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/reconciliation/WorkflowRepairService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/reconciliation/WorkflowSweeper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/storage/DummyPayloadStorage.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/sync/Lock.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/sync/local/LocalOnlyLock.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/sync/local/LocalOnlyLockConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Conductor authors.
+ * Copyright 2020 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/sync/noop/NoopLock.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/DateTimeUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/ExternalPayloadStorageUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/IDGenerator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/JsonUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/ParametersUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/QueueUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/SemaphoreUtil.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/Utils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/ConcurrentExecutionLimitDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/EventHandlerDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/ExecutionDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/IndexDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/MetadataDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/PollDataDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/QueueDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/RateLimitingDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/metrics/Monitors.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/metrics/WorkflowMonitor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/model/TaskModel.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/model/WorkflowModel.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/AdminService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/AdminServiceImpl.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/EventService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/EventServiceImpl.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/ExecutionLockService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/MetadataService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/MetadataServiceImpl.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/TaskService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/TaskServiceImpl.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/WorkflowBulkService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/WorkflowBulkServiceImpl.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/WorkflowService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/WorkflowServiceImpl.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/WorkflowTestService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2023 Conductor authors.
+ * Copyright 2023 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/validations/ValidationContext.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/validations/WorkflowTaskTypeConstraint.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Conductor authors.
+ * Copyright 2022 Conductor Authors.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskType.java
Patch:
@@ -23,7 +23,6 @@ public enum TaskType {
     DYNAMIC,
     FORK_JOIN,
     FORK_JOIN_DYNAMIC,
-    PERMISSIVE,
     DECISION,
     SWITCH,
     JOIN,
@@ -71,7 +70,6 @@ public enum TaskType {
     public static final String TASK_TYPE_JSON_JQ_TRANSFORM = "JSON_JQ_TRANSFORM";
     public static final String TASK_TYPE_SET_VARIABLE = "SET_VARIABLE";
     public static final String TASK_TYPE_FORK = "FORK";
-    public static final String TASK_TYPE_PERMISSIVE = "PERMISSIVE";
     public static final String TASK_TYPE_NOOP = "NOOP";
 
     private static final Set<String> BUILT_IN_TASKS = new HashSet<>();

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1832,7 +1832,7 @@ private static boolean isJoinOnFailedPermissive(List<String> joinOn, WorkflowMod
                 .map(workflow::getTaskByRefName)
                 .anyMatch(
                         t ->
-                                TaskType.PERMISSIVE.name().equals(t.getWorkflowTask().getType())
+                                t.getWorkflowTask().isPermissive()
                                         && !t.getWorkflowTask().isOptional()
                                         && t.getStatus().equals(FAILED));
     }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/ExclusiveJoin.java
Patch:
@@ -24,7 +24,6 @@
 import com.netflix.conductor.model.TaskModel;
 import com.netflix.conductor.model.WorkflowModel;
 
-import static com.netflix.conductor.common.metadata.tasks.TaskType.PERMISSIVE;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.TASK_TYPE_EXCLUSIVE_JOIN;
 
 @Component(TASK_TYPE_EXCLUSIVE_JOIN)
@@ -68,7 +67,7 @@ public boolean execute(
             foundExlusiveJoinOnTask = taskStatus.isTerminal();
             hasFailures =
                     !taskStatus.isSuccessful()
-                            && (!PERMISSIVE.name().equals(exclusiveTask.getWorkflowTask().getType())
+                            && (!exclusiveTask.getWorkflowTask().isPermissive()
                                     || joinOn.stream()
                                             .map(workflow::getTaskByRefName)
                                             .allMatch(t -> t.getStatus().isTerminal()));

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Join.java
Patch:
@@ -23,7 +23,6 @@
 import com.netflix.conductor.model.TaskModel;
 import com.netflix.conductor.model.WorkflowModel;
 
-import static com.netflix.conductor.common.metadata.tasks.TaskType.PERMISSIVE;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.TASK_TYPE_JOIN;
 
 @Component(TASK_TYPE_JOIN)
@@ -61,7 +60,7 @@ public boolean execute(
             hasFailures =
                     !taskStatus.isSuccessful()
                             && !forkedTask.getWorkflowTask().isOptional()
-                            && (!PERMISSIVE.name().equals(forkedTask.getWorkflowTask().getType())
+                            && (!forkedTask.getWorkflowTask().isPermissive()
                                     || joinOn.stream()
                                             .map(workflow::getTaskByRefName)
                                             .allMatch(t -> t.getStatus().isTerminal()));

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -440,22 +440,21 @@ public void testOptional() {
                 outcome.tasksToBeScheduled.get(0).getReferenceTaskName());
     }
 
-    /** Similar to {@link #testOptional} */
     @Test
     public void testPermissive() {
         WorkflowDef def = new WorkflowDef();
         def.setName("test-permissive");
 
         WorkflowTask task1 = new WorkflowTask();
         task1.setName("task0");
-        task1.setType("PERMISSIVE");
+        task1.setPermissive(true);
         task1.setTaskReferenceName("t0");
         task1.getInputParameters().put("taskId", "${CPEWF_TASK_ID}");
         task1.setTaskDefinition(new TaskDef("task0"));
 
         WorkflowTask task2 = new WorkflowTask();
         task2.setName("task1");
-        task2.setType("PERMISSIVE");
+        task2.setPermissive(true);
         task2.setTaskReferenceName("t1");
         task2.setTaskDefinition(new TaskDef("task1"));
 

File: grpc/src/main/java/com/netflix/conductor/grpc/AbstractProtoMapper.java
Patch:
@@ -1351,6 +1351,7 @@ public WorkflowTaskPb.WorkflowTask toProto(WorkflowTask from) {
         if (from.getExpression() != null) {
             to.setExpression( from.getExpression() );
         }
+        to.setPermissive( from.isPermissive() );
         return to.build();
     }
 
@@ -1396,6 +1397,7 @@ public WorkflowTask fromProto(WorkflowTaskPb.WorkflowTask from) {
         to.setRetryCount( from.getRetryCount() );
         to.setEvaluatorType( from.getEvaluatorType() );
         to.setExpression( from.getExpression() );
+        to.setPermissive( from.getPermissive() );
         return to;
     }
 

File: java-sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/WorkflowExecutor.java
Patch:
@@ -72,7 +72,6 @@ public static void initTaskImplementations() {
         TaskRegistry.register(TaskType.DYNAMIC.name(), Dynamic.class);
         TaskRegistry.register(TaskType.FORK_JOIN_DYNAMIC.name(), DynamicFork.class);
         TaskRegistry.register(TaskType.FORK_JOIN.name(), ForkJoin.class);
-        TaskRegistry.register(TaskType.PERMISSIVE.name(), PermissiveTask.class);
         TaskRegistry.register(TaskType.HTTP.name(), Http.class);
         TaskRegistry.register(TaskType.INLINE.name(), Javascript.class);
         TaskRegistry.register(TaskType.JOIN.name(), Join.class);

File: postgres-persistence/src/test/java/com/netflix/conductor/test/integration/grpc/postgres/PostgresGrpcEndToEndTest.java
Patch:
@@ -28,7 +28,7 @@
         properties = {
             "conductor.db.type=postgres",
             "conductor.app.asyncIndexingEnabled=false",
-            "conductor.elasticsearch.version=6",
+            "conductor.elasticsearch.version=7",
             "conductor.grpc-server.port=8098",
             "conductor.indexing.type=elasticsearch",
             "spring.datasource.url=jdbc:tc:postgresql:11.15-alpine:///conductor", // "tc" prefix

File: test-util/src/test/java/com/netflix/conductor/test/integration/AbstractEndToEndTest.java
Patch:
@@ -48,7 +48,7 @@
 import static org.junit.Assert.assertNotNull;
 
 @TestPropertySource(
-        properties = {"conductor.indexing.enabled=true", "conductor.elasticsearch.version=6"})
+        properties = {"conductor.indexing.enabled=true", "conductor.elasticsearch.version=7"})
 public abstract class AbstractEndToEndTest {
 
     private static final Logger log = LoggerFactory.getLogger(AbstractEndToEndTest.class);

File: mysql-persistence/src/test/java/com/netflix/conductor/test/integration/grpc/mysql/MySQLGrpcEndToEndTest.java
Patch:
@@ -34,7 +34,8 @@
             "spring.datasource.username=root",
             "spring.datasource.password=root",
             "spring.datasource.hikari.maximum-pool-size=8",
-            "spring.datasource.hikari.minimum-idle=300000"
+            "spring.datasource.hikari.minimum-idle=300000",
+            "conductor.elasticsearch.version=7"
         })
 public class MySQLGrpcEndToEndTest extends AbstractGrpcEndToEndTest {
 

File: test-util/src/test/java/com/netflix/conductor/test/integration/AbstractEndToEndTest.java
Patch:
@@ -62,7 +62,7 @@ public abstract class AbstractEndToEndTest {
     private static final ElasticsearchContainer container =
             new ElasticsearchContainer(
                     DockerImageName.parse("docker.elastic.co/elasticsearch/elasticsearch-oss")
-                            .withTag("6.8.12")); // this should match the client version
+                            .withTag("7.10.2")); // this should match the client version
 
     private static RestClient restClient;
 

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/index/ElasticSearchTest.java
Patch:
@@ -51,7 +51,7 @@ public ElasticSearchProperties elasticSearchProperties() {
             new ElasticsearchContainer(
                             DockerImageName.parse(
                                             "docker.elastic.co/elasticsearch/elasticsearch-oss")
-                                    .withTag("6.8.17")) // this should match the client version
+                                    .withTag("6.8.23")) // this should match the client version
                     // Resolve issue with es container not starting on m1/m2 macs
                     .withEnv(Map.of("bootstrap.system_call_filter", "false"));
 

File: es6-persistence/src/test/java/com/netflix/conductor/es6/dao/index/ElasticSearchTest.java
Patch:
@@ -51,7 +51,7 @@ public ElasticSearchProperties elasticSearchProperties() {
             new ElasticsearchContainer(
                             DockerImageName.parse(
                                             "docker.elastic.co/elasticsearch/elasticsearch-oss")
-                                    .withTag("6.8.17")) // this should match the client version
+                                    .withTag("6.8.23")) // this should match the client version
                     // Resolve issue with es container not starting on m1/m2 macs
                     .withEnv(Map.of("bootstrap.system_call_filter", "false"));
 

File: workflow-event-listener/src/main/java/com/netflix/conductor/contribs/listener/archive/ArchivingWithTTLWorkflowStatusListener.java
Patch:
@@ -1,4 +1,5 @@
 /*
+ * Copyright 2023 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -14,8 +15,6 @@
 import java.util.concurrent.ScheduledThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 
-
-import jakarta.annotation.*;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -24,6 +23,8 @@
 import com.netflix.conductor.metrics.Monitors;
 import com.netflix.conductor.model.WorkflowModel;
 
+import jakarta.annotation.*;
+
 public class ArchivingWithTTLWorkflowStatusListener implements WorkflowStatusListener {
 
     private static final Logger LOGGER =

File: workflow-event-listener/src/main/java/com/netflix/conductor/contribs/listener/archive/ArchivingWorkflowListenerConfiguration.java
Patch:
@@ -1,4 +1,5 @@
 /*
+ * Copyright 2023 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: workflow-event-listener/src/main/java/com/netflix/conductor/contribs/listener/archive/ArchivingWorkflowListenerProperties.java
Patch:
@@ -1,4 +1,5 @@
 /*
+ * Copyright 2023 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: workflow-event-listener/src/main/java/com/netflix/conductor/contribs/listener/archive/ArchivingWorkflowStatusListener.java
Patch:
@@ -1,4 +1,5 @@
 /*
+ * Copyright 2023 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: workflow-event-listener/src/main/java/com/netflix/conductor/contribs/listener/conductorqueue/ConductorQueueStatusPublisher.java
Patch:
@@ -1,4 +1,5 @@
 /*
+ * Copyright 2023 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: workflow-event-listener/src/main/java/com/netflix/conductor/contribs/listener/conductorqueue/ConductorQueueStatusPublisherConfiguration.java
Patch:
@@ -1,4 +1,5 @@
 /*
+ * Copyright 2023 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: workflow-event-listener/src/main/java/com/netflix/conductor/contribs/listener/conductorqueue/ConductorQueueStatusPublisherProperties.java
Patch:
@@ -1,4 +1,5 @@
 /*
+ * Copyright 2023 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: workflow-event-listener/src/test/java/com/netflix/conductor/contribs/listener/ArchivingWorkflowStatusListenerTest.java
Patch:
@@ -1,4 +1,5 @@
 /*
+ * Copyright 2023 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: workflow-event-listener/src/test/java/com/netflix/conductor/test/listener/WorkflowStatusPublisherIntegrationTest.java
Patch:
@@ -1,4 +1,5 @@
 /*
+ * Copyright 2023 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -51,6 +52,7 @@
 @RunWith(SpringRunner.class)
 @SpringBootTest(
         properties = {
+            "conductor.db.type=memory",
             "conductor.workflow-status-listener.type=queue_publisher",
             "conductor.workflow-status-listener.queue-publisher.successQueue=dummy",
             "conductor.workflow-status-listener.queue-publisher.failureQueue=dummy",

File: redis-persistence/src/main/java/com/netflix/conductor/redis/dynoqueue/ConfigurationHostSupplier.java
Patch:
@@ -40,9 +40,6 @@ public List<Host> getHosts() {
     }
 
     private List<Host> parseHostsFromConfig() {
-        System.out.println("\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n");
-        System.out.println("Properties in ConfigurationHostSupplier: ");
-        System.out.println(properties);
         String hosts = properties.getHosts();
         if (hosts == null) {
             String message =

File: core/src/main/java/com/netflix/conductor/validations/WorkflowTaskTypeConstraint.java
Patch:
@@ -262,7 +262,7 @@ private boolean isDoWhileTaskValid(
                 String message =
                         String.format(
                                 PARAM_REQUIRED_STRING_FORMAT,
-                                "loopExpression",
+                                "loopCondition",
                                 TaskType.DO_WHILE,
                                 workflowTask.getName());
                 context.buildConstraintViolationWithTemplate(message).addConstraintViolation();
@@ -272,7 +272,7 @@ private boolean isDoWhileTaskValid(
                 String message =
                         String.format(
                                 PARAM_REQUIRED_STRING_FORMAT,
-                                "loopover",
+                                "loopOver",
                                 TaskType.DO_WHILE,
                                 workflowTask.getName());
                 context.buildConstraintViolationWithTemplate(message).addConstraintViolation();

File: core/src/test/java/com/netflix/conductor/validations/WorkflowTaskTypeConstraintTest.java
Patch:
@@ -170,10 +170,10 @@ public void testWorkflowTaskTypeDoWhile() {
 
         assertTrue(
                 validationErrors.contains(
-                        "loopExpression field is required for taskType: DO_WHILE taskName: encode"));
+                        "loopCondition field is required for taskType: DO_WHILE taskName: encode"));
         assertTrue(
                 validationErrors.contains(
-                        "loopover field is required for taskType: DO_WHILE taskName: encode"));
+                        "loopOver field is required for taskType: DO_WHILE taskName: encode"));
     }
 
     @Test

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SetVariable.java
Patch:
@@ -66,7 +66,7 @@ private boolean validateVariablesSize(
             if (payloadSize > maxThreshold * 1024) {
                 String errorMsg =
                         String.format(
-                                "The variables payload size: %d of workflow: %s is greater than the permissible limit: %d bytes",
+                                "The variables payload size: %d of workflow: %s is greater than the permissible limit: %d kilobytes",
                                 payloadSize, workflowId, maxThreshold);
                 LOGGER.error(errorMsg);
                 task.setReasonForIncompletion(errorMsg);

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SetVariable.java
Patch:
@@ -66,7 +66,7 @@ private boolean validateVariablesSize(
             if (payloadSize > maxThreshold * 1024) {
                 String errorMsg =
                         String.format(
-                                "The variables payload size: %d of workflow: %s is greater than the permissible limit: %d bytes",
+                                "The variables payload size: %d of workflow: %s is greater than the permissible limit: %d kilobytes",
                                 payloadSize, workflowId, maxThreshold);
                 LOGGER.error(errorMsg);
                 task.setReasonForIncompletion(errorMsg);

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskType.java
Patch:
@@ -23,6 +23,7 @@ public enum TaskType {
     DYNAMIC,
     FORK_JOIN,
     FORK_JOIN_DYNAMIC,
+    PERMISSIVE,
     DECISION,
     SWITCH,
     JOIN,
@@ -70,6 +71,7 @@ public enum TaskType {
     public static final String TASK_TYPE_JSON_JQ_TRANSFORM = "JSON_JQ_TRANSFORM";
     public static final String TASK_TYPE_SET_VARIABLE = "SET_VARIABLE";
     public static final String TASK_TYPE_FORK = "FORK";
+    public static final String TASK_TYPE_PERMISSIVE = "PERMISSIVE";
     public static final String TASK_TYPE_NOOP = "NOOP";
 
     private static final Set<String> BUILT_IN_TASKS = new HashSet<>();

File: java-sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/WorkflowExecutor.java
Patch:
@@ -72,6 +72,7 @@ public static void initTaskImplementations() {
         TaskRegistry.register(TaskType.DYNAMIC.name(), Dynamic.class);
         TaskRegistry.register(TaskType.FORK_JOIN_DYNAMIC.name(), DynamicFork.class);
         TaskRegistry.register(TaskType.FORK_JOIN.name(), ForkJoin.class);
+        TaskRegistry.register(TaskType.PERMISSIVE.name(), PermissiveTask.class);
         TaskRegistry.register(TaskType.HTTP.name(), Http.class);
         TaskRegistry.register(TaskType.INLINE.name(), Javascript.class);
         TaskRegistry.register(TaskType.JOIN.name(), Join.class);

File: core/src/main/java/com/netflix/conductor/validations/WorkflowTaskTypeConstraint.java
Patch:
@@ -262,7 +262,7 @@ private boolean isDoWhileTaskValid(
                 String message =
                         String.format(
                                 PARAM_REQUIRED_STRING_FORMAT,
-                                "loopExpression",
+                                "loopCondition",
                                 TaskType.DO_WHILE,
                                 workflowTask.getName());
                 context.buildConstraintViolationWithTemplate(message).addConstraintViolation();
@@ -272,7 +272,7 @@ private boolean isDoWhileTaskValid(
                 String message =
                         String.format(
                                 PARAM_REQUIRED_STRING_FORMAT,
-                                "loopover",
+                                "loopOver",
                                 TaskType.DO_WHILE,
                                 workflowTask.getName());
                 context.buildConstraintViolationWithTemplate(message).addConstraintViolation();

File: core/src/test/java/com/netflix/conductor/validations/WorkflowTaskTypeConstraintTest.java
Patch:
@@ -170,10 +170,10 @@ public void testWorkflowTaskTypeDoWhile() {
 
         assertTrue(
                 validationErrors.contains(
-                        "loopExpression field is required for taskType: DO_WHILE taskName: encode"));
+                        "loopCondition field is required for taskType: DO_WHILE taskName: encode"));
         assertTrue(
                 validationErrors.contains(
-                        "loopover field is required for taskType: DO_WHILE taskName: encode"));
+                        "loopOver field is required for taskType: DO_WHILE taskName: encode"));
     }
 
     @Test

File: java-sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/WorkflowExecutor.java
Patch:
@@ -238,7 +238,7 @@ public TaskClient getTaskClient() {
         return taskClient;
     }
 
-    public WorkflowClient  getWorkflowClient() {
+    public WorkflowClient getWorkflowClient() {
         return workflowClient;
     }
 }

File: java-sdk/src/test/java/com/netflix/conductor/sdk/workflow/def/WorkflowCreationTests.java
Patch:
@@ -97,7 +97,8 @@ public DynamicForkInput generateDynamicFork() {
         return forks;
     }
 
-    private ConductorWorkflow<TestWorkflowInput> registerTestWorkflow() {
+    private ConductorWorkflow<TestWorkflowInput> registerTestWorkflow()
+            throws InterruptedException {
         InputStream script = getClass().getResourceAsStream("/script.js");
         SimpleTask getUserInfo = new SimpleTask("get_user_info", "get_user_info");
         getUserInfo.input("name", ConductorWorkflow.input.get("name"));
@@ -142,7 +143,7 @@ private ConductorWorkflow<TestWorkflowInput> registerTestWorkflow() {
     }
 
     @Test
-    public void verifyCreatedWorkflow() {
+    public void verifyCreatedWorkflow() throws Exception {
         ConductorWorkflow<TestWorkflowInput> conductorWorkflow = registerTestWorkflow();
         WorkflowDef def = conductorWorkflow.toWorkflowDef();
         assertNotNull(def);

File: test-harness/src/test/java/com/netflix/conductor/test/integration/AbstractEndToEndTest.java
Patch:
@@ -62,7 +62,7 @@ public abstract class AbstractEndToEndTest {
     private static final ElasticsearchContainer container =
             new ElasticsearchContainer(
                     DockerImageName.parse("docker.elastic.co/elasticsearch/elasticsearch-oss")
-                            .withTag("6.8.12")); // this should match the client version
+                            .withTag("6.8.17")); // this should match the client version
 
     private static RestClient restClient;
 

File: redis-persistence/src/main/java/com/netflix/conductor/redis/dao/RedisEventHandlerDAO.java
Patch:
@@ -72,6 +72,9 @@ public void updateEventHandler(EventHandler eventHandler) {
             throw new NotFoundException(
                     "EventHandler with name %s not found!", eventHandler.getName());
         }
+        if (!existing.getEvent().equals(eventHandler.getEvent())) {
+            removeIndex(existing);
+        }
         index(eventHandler);
         jedisProxy.hset(nsKey(EVENT_HANDLERS), eventHandler.getName(), toJson(eventHandler));
         recordRedisDaoRequests("updateEventHandler");

File: core/src/main/java/com/netflix/conductor/core/utils/ParametersUtils.java
Patch:
@@ -48,7 +48,8 @@ public class ParametersUtils {
     private static final Logger LOGGER = LoggerFactory.getLogger(ParametersUtils.class);
     private static final Pattern PATTERN =
             Pattern.compile(
-                    "(?=(?<!\\$)\\$\\{)(?:(?=.*?\\{(?!.*?\\1)(.*\\}(?!.*\\2).*))(?=.*?\\}(?!.*?\\2)(.*)).)+?.*?(?=\\1)[^{]*(?=\\2$)");
+                    "(?=(?<!\\$)\\$\\{)(?:(?=.*?\\{(?!.*?\\1)(.*\\}(?!.*\\2).*))(?=.*?\\}(?!.*?\\2)(.*)).)+?.*?(?=\\1)[^{]*(?=\\2$)",
+                    Pattern.DOTALL);
 
     private final ObjectMapper objectMapper;
     private final TypeReference<Map<String, Object>> map = new TypeReference<>() {};

File: annotations-processor/src/main/java/com/netflix/conductor/annotationsprocessor/protogen/ProtoGen.java
Patch:
@@ -20,7 +20,6 @@
 import java.net.URLClassLoader;
 import java.util.*;
 
-import javax.annotation.Generated;
 import javax.lang.model.element.Modifier;
 
 import com.netflix.conductor.annotations.protogen.ProtoMessage;
@@ -35,6 +34,7 @@
 import com.squareup.javapoet.JavaFile;
 import com.squareup.javapoet.MethodSpec;
 import com.squareup.javapoet.TypeSpec;
+import jakarta.annotation.Generated;
 
 public class ProtoGen {
     private static final String GENERATOR_NAME =

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/config/cache/CacheableEventHandlerDAO.java
Patch:
@@ -20,8 +20,6 @@
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;
 
-import javax.annotation.PostConstruct;
-
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.springframework.cache.Cache;
@@ -36,6 +34,8 @@
 import com.netflix.conductor.dao.EventHandlerDAO;
 import com.netflix.conductor.metrics.Monitors;
 
+import jakarta.annotation.PostConstruct;
+
 import static com.netflix.conductor.cassandra.config.cache.CachingConfig.EVENT_HANDLER_CACHE;
 
 @Trace

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/config/cache/CacheableMetadataDAO.java
Patch:
@@ -20,8 +20,6 @@
 import java.util.concurrent.Executors;
 import java.util.concurrent.TimeUnit;
 
-import javax.annotation.PostConstruct;
-
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.springframework.cache.Cache;
@@ -38,6 +36,8 @@
 import com.netflix.conductor.dao.MetadataDAO;
 import com.netflix.conductor.metrics.Monitors;
 
+import jakarta.annotation.PostConstruct;
+
 import static com.netflix.conductor.cassandra.config.cache.CachingConfig.TASK_DEF_CACHE;
 
 @Trace

File: common/src/main/java/com/netflix/conductor/common/config/ObjectMapperConfiguration.java
Patch:
@@ -12,13 +12,12 @@
  */
 package com.netflix.conductor.common.config;
 
-import javax.annotation.PostConstruct;
-
 import org.springframework.context.annotation.Configuration;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.databind.ObjectMapper;
 import com.fasterxml.jackson.module.afterburner.AfterburnerModule;
+import jakarta.annotation.PostConstruct;
 
 @Configuration
 public class ObjectMapperConfiguration {

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskResult.java
Patch:
@@ -17,8 +17,6 @@
 import java.util.Map;
 import java.util.concurrent.CopyOnWriteArrayList;
 
-import javax.validation.constraints.NotEmpty;
-
 import org.apache.commons.lang3.StringUtils;
 
 import com.netflix.conductor.annotations.protogen.ProtoEnum;
@@ -27,6 +25,7 @@
 
 import com.google.protobuf.Any;
 import io.swagger.v3.oas.annotations.Hidden;
+import jakarta.validation.constraints.NotEmpty;
 
 /** Result of the task execution. */
 @ProtoMessage

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/SubWorkflowParams.java
Patch:
@@ -15,14 +15,13 @@
 import java.util.Map;
 import java.util.Objects;
 
-import javax.validation.constraints.NotEmpty;
-import javax.validation.constraints.NotNull;
-
 import com.netflix.conductor.annotations.protogen.ProtoField;
 import com.netflix.conductor.annotations.protogen.ProtoMessage;
 
 import com.fasterxml.jackson.annotation.JsonGetter;
 import com.fasterxml.jackson.annotation.JsonSetter;
+import jakarta.validation.constraints.NotEmpty;
+import jakarta.validation.constraints.NotNull;
 
 @ProtoMessage
 public class SubWorkflowParams {

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowDefSummary.java
Patch:
@@ -14,12 +14,12 @@
 
 import java.util.Objects;
 
-import javax.validation.constraints.NotEmpty;
-
 import com.netflix.conductor.annotations.protogen.ProtoField;
 import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.netflix.conductor.common.constraints.NoSemiColonConstraint;
 
+import jakarta.validation.constraints.NotEmpty;
+
 @ProtoMessage
 public class WorkflowDefSummary implements Comparable<WorkflowDefSummary> {
 

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -15,9 +15,6 @@
 import java.util.*;
 import java.util.stream.Collectors;
 
-import javax.validation.constraints.Max;
-import javax.validation.constraints.Min;
-
 import org.apache.commons.lang3.StringUtils;
 
 import com.netflix.conductor.annotations.protogen.ProtoEnum;
@@ -27,6 +24,9 @@
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 
+import jakarta.validation.constraints.Max;
+import jakarta.validation.constraints.Min;
+
 @ProtoMessage
 public class Workflow extends Auditable {
 

File: common/src/main/java/com/netflix/conductor/common/utils/SummaryUtil.java
Patch:
@@ -14,8 +14,6 @@
 
 import java.util.Map;
 
-import javax.annotation.PostConstruct;
-
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.springframework.beans.factory.annotation.Value;
@@ -25,6 +23,7 @@
 
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.ObjectMapper;
+import jakarta.annotation.PostConstruct;
 
 @Component
 public class SummaryUtil {

File: core/src/main/java/com/netflix/conductor/core/dal/ExecutionDAOFacade.java
Patch:
@@ -21,8 +21,6 @@
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;
 
-import javax.annotation.PreDestroy;
-
 import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -52,6 +50,7 @@
 
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.ObjectMapper;
+import jakarta.annotation.PreDestroy;
 
 import static com.netflix.conductor.core.utils.Utils.DECIDER_QUEUE;
 

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/StartWorkflow.java
Patch:
@@ -15,8 +15,6 @@
 import java.util.HashMap;
 import java.util.Map;
 
-import javax.validation.Validator;
-
 import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -31,6 +29,7 @@
 import com.netflix.conductor.model.WorkflowModel;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
+import jakarta.validation.Validator;
 
 import static com.netflix.conductor.common.metadata.tasks.TaskType.TASK_TYPE_START_WORKFLOW;
 import static com.netflix.conductor.model.TaskModel.Status.COMPLETED;

File: core/src/main/java/com/netflix/conductor/service/AdminService.java
Patch:
@@ -15,12 +15,12 @@
 import java.util.List;
 import java.util.Map;
 
-import javax.validation.constraints.NotEmpty;
-
 import org.springframework.validation.annotation.Validated;
 
 import com.netflix.conductor.common.metadata.tasks.Task;
 
+import jakarta.validation.constraints.NotEmpty;
+
 @Validated
 public interface AdminService {
 

File: core/src/main/java/com/netflix/conductor/service/WorkflowBulkService.java
Patch:
@@ -14,13 +14,13 @@
 
 import java.util.List;
 
-import javax.validation.constraints.NotEmpty;
-import javax.validation.constraints.Size;
-
 import org.springframework.validation.annotation.Validated;
 
 import com.netflix.conductor.common.model.BulkResponse;
 
+import jakarta.validation.constraints.NotEmpty;
+import jakarta.validation.constraints.Size;
+
 @Validated
 public interface WorkflowBulkService {
 

File: core/src/test/java/com/netflix/conductor/TestUtils.java
Patch:
@@ -16,7 +16,7 @@
 import java.util.Set;
 import java.util.stream.Collectors;
 
-import javax.validation.ConstraintViolation;
+import jakarta.validation.ConstraintViolation;
 
 public class TestUtils {
 

File: core/src/test/java/com/netflix/conductor/core/metadata/MetadataMapperServiceTest.java
Patch:
@@ -16,8 +16,6 @@
 import java.util.Optional;
 import java.util.Set;
 
-import javax.validation.ConstraintViolationException;
-
 import org.junit.After;
 import org.junit.Assert;
 import org.junit.Test;
@@ -37,6 +35,8 @@
 import com.netflix.conductor.core.exception.TerminateWorkflowException;
 import com.netflix.conductor.dao.MetadataDAO;
 
+import jakarta.validation.ConstraintViolationException;
+
 import static com.netflix.conductor.TestUtils.getConstraintViolationMessages;
 
 import static org.junit.Assert.assertEquals;

File: core/src/test/java/com/netflix/conductor/service/EventServiceTest.java
Patch:
@@ -14,8 +14,6 @@
 
 import java.util.Set;
 
-import javax.validation.ConstraintViolationException;
-
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.springframework.beans.factory.annotation.Autowired;
@@ -26,6 +24,8 @@
 
 import com.netflix.conductor.core.events.EventQueues;
 
+import jakarta.validation.ConstraintViolationException;
+
 import static com.netflix.conductor.TestUtils.getConstraintViolationMessages;
 
 import static org.junit.Assert.assertEquals;

File: core/src/test/java/com/netflix/conductor/service/MetadataServiceTest.java
Patch:
@@ -20,8 +20,6 @@
 import java.util.Map;
 import java.util.Set;
 
-import javax.validation.ConstraintViolationException;
-
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.springframework.beans.factory.annotation.Autowired;
@@ -40,6 +38,8 @@
 import com.netflix.conductor.dao.EventHandlerDAO;
 import com.netflix.conductor.dao.MetadataDAO;
 
+import jakarta.validation.ConstraintViolationException;
+
 import static com.netflix.conductor.TestUtils.getConstraintViolationMessages;
 
 import static org.junit.Assert.assertEquals;

File: core/src/test/java/com/netflix/conductor/service/TaskServiceTest.java
Patch:
@@ -15,8 +15,6 @@
 import java.util.List;
 import java.util.Set;
 
-import javax.validation.ConstraintViolationException;
-
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.springframework.beans.factory.annotation.Autowired;
@@ -31,6 +29,8 @@
 import com.netflix.conductor.common.run.TaskSummary;
 import com.netflix.conductor.dao.QueueDAO;
 
+import jakarta.validation.ConstraintViolationException;
+
 import static com.netflix.conductor.TestUtils.getConstraintViolationMessages;
 
 import static org.junit.Assert.*;

File: core/src/test/java/com/netflix/conductor/service/WorkflowBulkServiceTest.java
Patch:
@@ -17,8 +17,6 @@
 import java.util.List;
 import java.util.Set;
 
-import javax.validation.ConstraintViolationException;
-
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.springframework.beans.factory.annotation.Autowired;
@@ -29,6 +27,8 @@
 
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 
+import jakarta.validation.ConstraintViolationException;
+
 import static com.netflix.conductor.TestUtils.getConstraintViolationMessages;
 
 import static org.junit.Assert.assertEquals;

File: core/src/test/java/com/netflix/conductor/service/WorkflowServiceTest.java
Patch:
@@ -18,8 +18,6 @@
 import java.util.Map;
 import java.util.Set;
 
-import javax.validation.ConstraintViolationException;
-
 import org.junit.Test;
 import org.junit.runner.RunWith;
 import org.springframework.beans.factory.annotation.Autowired;
@@ -38,6 +36,8 @@
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import com.netflix.conductor.core.operation.StartWorkflowOperation;
 
+import jakarta.validation.ConstraintViolationException;
+
 import static com.netflix.conductor.TestUtils.getConstraintViolationMessages;
 
 import static org.junit.Assert.*;

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/index/ElasticSearchDAOV6.java
Patch:
@@ -21,9 +21,6 @@
 import java.util.stream.Collectors;
 import java.util.stream.IntStream;
 
-import javax.annotation.PostConstruct;
-import javax.annotation.PreDestroy;
-
 import org.apache.commons.lang3.StringUtils;
 import org.elasticsearch.ResourceAlreadyExistsException;
 import org.elasticsearch.action.DocWriteResponse;
@@ -73,6 +70,8 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import com.fasterxml.jackson.databind.type.MapType;
 import com.fasterxml.jackson.databind.type.TypeFactory;
+import jakarta.annotation.PostConstruct;
+import jakarta.annotation.PreDestroy;
 
 @Trace
 public class ElasticSearchDAOV6 extends ElasticSearchBaseDAO implements IndexDAO {

File: es6-persistence/src/main/java/com/netflix/conductor/es6/dao/index/ElasticSearchRestDAOV6.java
Patch:
@@ -22,9 +22,6 @@
 import java.util.stream.Collectors;
 import java.util.stream.IntStream;
 
-import javax.annotation.PostConstruct;
-import javax.annotation.PreDestroy;
-
 import org.apache.commons.io.IOUtils;
 import org.apache.commons.lang3.StringUtils;
 import org.apache.http.HttpEntity;
@@ -79,6 +76,8 @@
 import com.fasterxml.jackson.databind.node.ObjectNode;
 import com.fasterxml.jackson.databind.type.MapType;
 import com.fasterxml.jackson.databind.type.TypeFactory;
+import jakarta.annotation.PostConstruct;
+import jakarta.annotation.PreDestroy;
 
 @Trace
 public class ElasticSearchRestDAOV6 extends ElasticSearchBaseDAO implements IndexDAO {

File: grpc-client/src/main/java/com/netflix/conductor/client/grpc/ClientBase.java
Patch:
@@ -14,8 +14,6 @@
 
 import java.util.concurrent.TimeUnit;
 
-import javax.annotation.Nullable;
-
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -24,6 +22,7 @@
 
 import io.grpc.ManagedChannel;
 import io.grpc.ManagedChannelBuilder;
+import jakarta.annotation.Nullable;
 
 abstract class ClientBase {
 

File: grpc-client/src/main/java/com/netflix/conductor/client/grpc/MetadataClient.java
Patch:
@@ -14,8 +14,6 @@
 
 import java.util.List;
 
-import javax.annotation.Nullable;
-
 import org.apache.commons.lang3.StringUtils;
 
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
@@ -25,6 +23,7 @@
 
 import com.google.common.base.Preconditions;
 import io.grpc.ManagedChannelBuilder;
+import jakarta.annotation.Nullable;
 
 public class MetadataClient extends ClientBase {
 

File: grpc-client/src/main/java/com/netflix/conductor/client/grpc/TaskClient.java
Patch:
@@ -16,8 +16,6 @@
 import java.util.List;
 import java.util.stream.Collectors;
 
-import javax.annotation.Nullable;
-
 import org.apache.commons.lang3.StringUtils;
 
 import com.netflix.conductor.common.metadata.tasks.Task;
@@ -34,6 +32,7 @@
 import com.google.common.collect.Iterators;
 import com.google.common.collect.Lists;
 import io.grpc.ManagedChannelBuilder;
+import jakarta.annotation.Nullable;
 
 public class TaskClient extends ClientBase {
 

File: grpc-client/src/main/java/com/netflix/conductor/client/grpc/WorkflowClient.java
Patch:
@@ -16,8 +16,6 @@
 import java.util.List;
 import java.util.stream.Collectors;
 
-import javax.annotation.Nullable;
-
 import org.apache.commons.lang3.StringUtils;
 
 import com.netflix.conductor.common.metadata.workflow.RerunWorkflowRequest;
@@ -32,6 +30,7 @@
 
 import com.google.common.base.Preconditions;
 import io.grpc.ManagedChannelBuilder;
+import jakarta.annotation.Nullable;
 
 public class WorkflowClient extends ClientBase {
 

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/GRPCServer.java
Patch:
@@ -15,15 +15,14 @@
 import java.io.IOException;
 import java.util.List;
 
-import javax.annotation.PostConstruct;
-import javax.annotation.PreDestroy;
-
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import io.grpc.BindableService;
 import io.grpc.Server;
 import io.grpc.ServerBuilder;
+import jakarta.annotation.PostConstruct;
+import jakarta.annotation.PreDestroy;
 
 public class GRPCServer {
 

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/service/GRPCHelper.java
Patch:
@@ -14,8 +14,6 @@
 
 import java.util.Arrays;
 
-import javax.annotation.Nonnull;
-
 import org.apache.commons.lang3.exception.ExceptionUtils;
 import org.slf4j.Logger;
 
@@ -25,6 +23,7 @@
 import io.grpc.StatusException;
 import io.grpc.protobuf.lite.ProtoLiteUtils;
 import io.grpc.stub.StreamObserver;
+import jakarta.annotation.Nonnull;
 
 public class GRPCHelper {
 

File: grpc/src/main/java/com/netflix/conductor/grpc/AbstractProtoMapper.java
Patch:
@@ -40,6 +40,7 @@
 import com.netflix.conductor.proto.WorkflowPb;
 import com.netflix.conductor.proto.WorkflowSummaryPb;
 import com.netflix.conductor.proto.WorkflowTaskPb;
+import jakarta.annotation.Generated;
 import java.lang.IllegalArgumentException;
 import java.lang.Object;
 import java.lang.String;
@@ -49,7 +50,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.stream.Collectors;
-import javax.annotation.Generated;
 
 @Generated("com.netflix.conductor.annotationsprocessor.protogen")
 public abstract class AbstractProtoMapper {

File: grpc/src/test/java/com/netflix/conductor/grpc/TestProtoMapper.java
Patch:
@@ -39,7 +39,7 @@ public void workflowTaskFromProto() {
     final WorkflowTaskPb.WorkflowTask taskWithDefaultRetryCount = WorkflowTaskPb.WorkflowTask.newBuilder().build();
     final WorkflowTaskPb.WorkflowTask taskWith1RetryCount = WorkflowTaskPb.WorkflowTask.newBuilder().setRetryCount(1).build();
     final WorkflowTaskPb.WorkflowTask taskWithNoRetryCount = WorkflowTaskPb.WorkflowTask.newBuilder().setRetryCount(-1).build();
-    assertEquals(new Integer(0), mapper.fromProto(taskWithDefaultRetryCount).getRetryCount());
+    assertEquals(Integer.valueOf(0), mapper.fromProto(taskWithDefaultRetryCount).getRetryCount());
     assertEquals(1, mapper.fromProto(taskWith1RetryCount).getRetryCount().intValue());
     assertNull(mapper.fromProto(taskWithNoRetryCount).getRetryCount());
   }

File: http-task/src/test/java/com/netflix/conductor/tasks/http/HttpTaskTest.java
Patch:
@@ -315,7 +315,7 @@ public void testHTTPGETReadTimeOut() {
         task.setScheduledTime(0);
 
         httpTask.start(workflow, task, workflowExecutor);
-        assertEquals(task.getStatus(), TaskModel.Status.FAILED);
+        assertEquals(TaskModel.Status.FAILED, task.getStatus());
     }
 
     @Test

File: http-task/src/test/java/com/netflix/conductor/tasks/http/providers/DefaultRestTemplateProviderTest.java
Patch:
@@ -14,6 +14,7 @@
 
 import java.time.Duration;
 
+import org.junit.Ignore;
 import org.junit.Test;
 import org.springframework.web.client.RestTemplate;
 
@@ -46,6 +47,7 @@ public void differentObjectsForDifferentThreads() throws InterruptedException {
     }
 
     @Test
+    @Ignore("We can no longer do this and have customizable timeouts per HttpTask.")
     public void sameObjectForSameThread() {
         DefaultRestTemplateProvider defaultRestTemplateProvider =
                 new DefaultRestTemplateProvider(Duration.ofMillis(150), Duration.ofMillis(100));

File: redis-persistence/src/main/java/com/netflix/conductor/redis/dynoqueue/ConfigurationHostSupplier.java
Patch:
@@ -40,6 +40,9 @@ public List<Host> getHosts() {
     }
 
     private List<Host> parseHostsFromConfig() {
+        System.out.println("\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n");
+        System.out.println("Properties in ConfigurationHostSupplier: ");
+        System.out.println(properties);
         String hosts = properties.getHosts();
         if (hosts == null) {
             String message =

File: rest/src/main/java/com/netflix/conductor/rest/controllers/ApplicationExceptionMapper.java
Patch:
@@ -15,8 +15,6 @@
 import java.util.HashMap;
 import java.util.Map;
 
-import javax.servlet.http.HttpServletRequest;
-
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.springframework.core.annotation.Order;
@@ -33,6 +31,7 @@
 import com.netflix.conductor.metrics.Monitors;
 
 import com.fasterxml.jackson.databind.exc.InvalidFormatException;
+import jakarta.servlet.http.HttpServletRequest;
 
 @RestControllerAdvice
 @Order(ValidationExceptionMapper.ORDER + 1)

File: test-harness/src/test/java/com/netflix/conductor/test/integration/http/AbstractHttpEndToEndTest.java
Patch:
@@ -22,7 +22,7 @@
 import org.junit.runner.RunWith;
 import org.springframework.boot.test.context.SpringBootTest;
 import org.springframework.boot.test.context.SpringBootTest.WebEnvironment;
-import org.springframework.boot.web.server.LocalServerPort;
+import org.springframework.boot.test.web.server.LocalServerPort;
 import org.springframework.test.context.TestPropertySource;
 import org.springframework.test.context.junit4.SpringRunner;
 

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapper.java
Patch:
@@ -110,7 +110,7 @@ void setCallbackAfter(TaskModel task) {
                 Date expiryDate = parseDate(until);
                 long timeInMS = expiryDate.getTime();
                 long now = System.currentTimeMillis();
-                long seconds = ((timeInMS - now) / 1000) + 1;
+                long seconds = ((timeInMS - now) / 1000);
                 if (seconds < 0) {
                     seconds = 0;
                 }

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapper.java
Patch:
@@ -110,7 +110,7 @@ void setCallbackAfter(TaskModel task) {
                 Date expiryDate = parseDate(until);
                 long timeInMS = expiryDate.getTime();
                 long now = System.currentTimeMillis();
-                long seconds = ((timeInMS - now) / 1000) + 1;
+                long seconds = ((timeInMS - now) / 1000);
                 if (seconds < 0) {
                     seconds = 0;
                 }

File: java-sdk/src/test/java/com/netflix/conductor/sdk/workflow/def/WorkflowCreationTests.java
Patch:
@@ -24,6 +24,7 @@
 
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -41,6 +42,7 @@
 
 import static org.junit.jupiter.api.Assertions.*;
 
+@Disabled
 public class WorkflowCreationTests {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(WorkflowCreationTests.class);

File: java-sdk/src/test/java/com/netflix/conductor/sdk/workflow/def/WorkflowCreationTests.java
Patch:
@@ -24,6 +24,7 @@
 
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -41,6 +42,7 @@
 
 import static org.junit.jupiter.api.Assertions.*;
 
+@Disabled
 public class WorkflowCreationTests {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(WorkflowCreationTests.class);

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -316,8 +316,9 @@ public void testScheduleTask() {
         doAnswer(answer).when(queueDAO).push(any(), any(), anyInt(), anyLong());
 
         boolean stateChanged = workflowExecutor.scheduleTask(workflow, tasks);
-        assertEquals(2, startedTaskCount.get());
-        assertEquals(1, queuedTaskCount.get());
+        // Wait task is no async to it will be queued.
+        assertEquals(1, startedTaskCount.get());
+        assertEquals(2, queuedTaskCount.get());
         assertTrue(stateChanged);
         assertFalse(httpTask.isStarted());
         assertTrue(http2Task.isStarted());

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -316,8 +316,9 @@ public void testScheduleTask() {
         doAnswer(answer).when(queueDAO).push(any(), any(), anyInt(), anyLong());
 
         boolean stateChanged = workflowExecutor.scheduleTask(workflow, tasks);
-        assertEquals(2, startedTaskCount.get());
-        assertEquals(1, queuedTaskCount.get());
+        // Wait task is no async to it will be queued.
+        assertEquals(1, startedTaskCount.get());
+        assertEquals(2, queuedTaskCount.get());
         assertTrue(stateChanged);
         assertFalse(httpTask.isStarted());
         assertTrue(http2Task.isStarted());

File: core/src/main/java/com/netflix/conductor/service/MetadataService.java
Patch:
@@ -154,4 +154,6 @@ void removeEventHandlerStatus(
     List<EventHandler> getEventHandlersForEvent(
             @NotEmpty(message = "EventName cannot be null or empty") String event,
             boolean activeOnly);
+
+    List<WorkflowDef> getWorkflowDefsLatestVersions();
 }

File: core/src/main/java/com/netflix/conductor/core/reconciliation/WorkflowSweeper.java
Patch:
@@ -123,7 +123,7 @@ void unack(WorkflowModel workflowModel, long workflowOffsetTimeout) {
                     } else {
                         long deltaInSeconds =
                                 (taskModel.getWaitTimeout() - System.currentTimeMillis()) / 1000;
-                        postponeDurationSeconds = (deltaInSeconds > 0) ? deltaInSeconds + 1 : 1;
+                        postponeDurationSeconds = (deltaInSeconds > 0) ? deltaInSeconds : 0;
                     }
                 } else if (taskModel.getTaskType().equals(TaskType.TASK_TYPE_HUMAN)) {
                     postponeDurationSeconds = workflowOffsetTimeout;

File: core/src/main/java/com/netflix/conductor/core/reconciliation/WorkflowSweeper.java
Patch:
@@ -119,7 +119,7 @@ void unack(WorkflowModel workflowModel, long workflowOffsetTimeout) {
             if (taskModel.getStatus() == Status.IN_PROGRESS) {
                 if (taskModel.getTaskType().equals(TaskType.TASK_TYPE_WAIT)) {
                     long deltaInSeconds =
-                            (System.currentTimeMillis() - taskModel.getWaitTimeout()) / 1000;
+                            (taskModel.getWaitTimeout() - System.currentTimeMillis()) / 1000;
                     postponeDurationSeconds = (deltaInSeconds > 0) ? deltaInSeconds + 1 : 1;
                 } else if (taskModel.getTaskType().equals(TaskType.TASK_TYPE_HUMAN)) {
                     postponeDurationSeconds = properties.getWorkflowOffsetTimeout().getSeconds();

File: java-sdk/src/main/java/com/netflix/conductor/sdk/testing/LocalServerRunner.java
Patch:
@@ -65,6 +65,7 @@ public LocalServerRunner(int port, String conductorVersion) {
     public String getServerAPIUrl() {
         return this.serverURL + "api/";
     }
+
     /**
      * Starts the local server. Downloads the latest conductor build from the maven repo If you want
      * to start the server from a specific download location, set `repositoryURL` system property

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -49,8 +49,8 @@
 import com.netflix.conductor.core.execution.evaluators.Evaluator;
 import com.netflix.conductor.core.execution.mapper.*;
 import com.netflix.conductor.core.execution.tasks.*;
-import com.netflix.conductor.core.listener.WorkflowStatusListener;
 import com.netflix.conductor.core.listener.TaskStatusListener;
+import com.netflix.conductor.core.listener.WorkflowStatusListener;
 import com.netflix.conductor.core.metadata.MetadataMapperService;
 import com.netflix.conductor.core.operation.StartWorkflowOperation;
 import com.netflix.conductor.core.utils.ExternalPayloadStorageUtils;

File: client/src/main/java/com/netflix/conductor/client/http/EventClient.java
Patch:
@@ -30,6 +30,7 @@
 public class EventClient extends ClientBase {
     private static final GenericType<List<EventHandler>> eventHandlerList =
             new GenericType<List<EventHandler>>() {};
+
     /** Creates a default metadata client */
     public EventClient() {
         this(new DefaultClientConfig(), new DefaultConductorClientConfiguration(), null);

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -50,6 +50,7 @@
 import com.netflix.conductor.core.execution.mapper.*;
 import com.netflix.conductor.core.execution.tasks.*;
 import com.netflix.conductor.core.listener.WorkflowStatusListener;
+import com.netflix.conductor.core.listener.TaskStatusListener;
 import com.netflix.conductor.core.metadata.MetadataMapperService;
 import com.netflix.conductor.core.operation.StartWorkflowOperation;
 import com.netflix.conductor.core.utils.ExternalPayloadStorageUtils;

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -85,6 +85,7 @@ public class TestWorkflowExecutor {
     private MetadataDAO metadataDAO;
     private QueueDAO queueDAO;
     private WorkflowStatusListener workflowStatusListener;
+    private TaskStatusListener taskStatusListener;
     private ExecutionLockService executionLockService;
     private ExternalPayloadStorageUtils externalPayloadStorageUtils;
 
@@ -160,6 +161,7 @@ public void init() {
         metadataDAO = mock(MetadataDAO.class);
         queueDAO = mock(QueueDAO.class);
         workflowStatusListener = mock(WorkflowStatusListener.class);
+        taskStatusListener = mock(TaskStatusListener.class);
         externalPayloadStorageUtils = mock(ExternalPayloadStorageUtils.class);
         executionLockService = mock(ExecutionLockService.class);
         eventPublisher = mock(ApplicationEventPublisher.class);
@@ -210,6 +212,7 @@ public void init() {
                         queueDAO,
                         metadataMapperService,
                         workflowStatusListener,
+                        taskStatusListener,
                         executionDAOFacade,
                         properties,
                         executionLockService,

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskDef.java
Patch:
@@ -63,7 +63,7 @@ public enum RetryLogic {
 
     @ProtoField(id = 3)
     @Min(value = 0, message = "TaskDef retryCount: {value} must be >= 0")
-    @Max(value = 10, message = "TaskDef retryCount: {value} must be <=10")
+    @Max(value = 10, message = "TaskDef retryCount: ${validatedValue} must be <= {value}")
     private int retryCount = 3; // Default
 
     @ProtoField(id = 4)

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskDef.java
Patch:
@@ -63,7 +63,7 @@ public enum RetryLogic {
 
     @ProtoField(id = 3)
     @Min(value = 0, message = "TaskDef retryCount: {value} must be >= 0")
-    @Max(value = 10, message = "TaskDef retryCount: {value} must be <=10")
+    @Max(value = 10, message = "TaskDef retryCount: ${validatedValue} must be <= {value}")
     private int retryCount = 3; // Default
 
     @ProtoField(id = 4)

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -651,6 +651,7 @@ public WorkflowModel terminateWorkflow(
                 if (workflow.getFailedTaskId() != null) {
                     input.put("failureTaskId", workflow.getFailedTaskId());
                 }
+                input.put("failedWorkflow", workflow);
 
                 try {
                     String failureWFId = idGenerator.generate();

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -2101,6 +2101,9 @@ public void testTerminateWorkflowWithFailureWorkflow() {
                 workflow.getWorkflowId(), startWorkflowInput.getWorkflowInput().get("workflowId"));
         assertEquals(
                 failedTask.getTaskId(), startWorkflowInput.getWorkflowInput().get("failureTaskId"));
+        assertNotNull(
+                failedTask.getTaskId(),
+                startWorkflowInput.getWorkflowInput().get("failedWorkflow"));
     }
 
     @Test

File: core/src/test/java/com/netflix/conductor/core/events/TestDefaultEventProcessor.java
Patch:
@@ -222,7 +222,7 @@ public void testEventProcessor() {
         assertTrue(completed.get());
         verify(queue, atMost(1)).ack(any());
         verify(queue, never()).nack(any());
-        verify(queue, atLeastOnce()).publish(any());
+        verify(queue, never()).publish(any());
     }
 
     @Test
@@ -398,7 +398,8 @@ public void testEventProcessorWithRetriableError() {
                         retryTemplate);
         eventProcessor.handle(queue, message);
         verify(queue, never()).ack(any());
-        verify(queue, never()).publish(any());
+        verify(queue, never()).nack(any());
+        verify(queue, atLeastOnce()).publish(any());
     }
 
     @Test

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -2103,7 +2103,7 @@ public void testTerminateWorkflowWithFailureWorkflow() {
                 failedTask.getTaskId(), startWorkflowInput.getWorkflowInput().get("failureTaskId"));
         assertNotNull(
                 failedTask.getTaskId(),
-                argumentCaptor.getAllValues().get(0).getInput().get("failedWorkflow"));
+                startWorkflowInput.getWorkflowInput().get("failedWorkflow"));
     }
 
     @Test

File: core/src/test/java/com/netflix/conductor/core/events/TestDefaultEventProcessor.java
Patch:
@@ -221,7 +221,8 @@ public void testEventProcessor() {
         assertTrue(started.get());
         assertTrue(completed.get());
         verify(queue, atMost(1)).ack(any());
-        verify(queue, never()).publish(any());
+        verify(queue, never()).nack(any());
+        verify(queue, atLeastOnce()).publish(any());
     }
 
     @Test

File: server/src/main/java/com/netflix/conductor/Conductor.java
Patch:
@@ -21,12 +21,14 @@
 import org.springframework.boot.SpringApplication;
 import org.springframework.boot.autoconfigure.SpringBootApplication;
 import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;
+import org.springframework.context.annotation.ComponentScan;
 import org.springframework.core.io.FileSystemResource;
 
 // Prevents from the datasource beans to be loaded, AS they are needed only for specific databases.
 // In case that SQL database is selected this class will be imported back in the appropriate
 // database persistence module.
 @SpringBootApplication(exclude = DataSourceAutoConfiguration.class)
+@ComponentScan(basePackages = {"com.netflix.conductor", "io.orkes.conductor"})
 public class Conductor {
 
     private static final Logger log = LoggerFactory.getLogger(Conductor.class);

File: server/src/test/java/com/netflix/conductor/common/config/ConductorObjectMapperTest.java
Patch:
@@ -21,6 +21,7 @@
 import org.junit.runner.RunWith;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.boot.test.context.SpringBootTest;
+import org.springframework.test.context.TestPropertySource;
 import org.springframework.test.context.junit4.SpringRunner;
 
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
@@ -43,6 +44,7 @@
  */
 @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)
 @RunWith(SpringRunner.class)
+@TestPropertySource(properties = "conductor.queue.type=")
 public class ConductorObjectMapperTest {
 
     @Autowired ObjectMapper objectMapper;

File: java-sdk/src/main/java/com/netflix/conductor/sdk/workflow/executor/WorkflowExecutor.java
Patch:
@@ -113,6 +113,7 @@ public WorkflowExecutor(
                         Workflow workflow = workflowClient.getWorkflow(workflowId, true);
                         if (workflow.getStatus().isTerminal()) {
                             future.complete(workflow);
+                            runningWorkflowFutures.remove(workflowId);
                         }
                     }
                 },
@@ -140,6 +141,7 @@ public WorkflowExecutor(
                         Workflow workflow = workflowClient.getWorkflow(workflowId, true);
                         if (workflow.getStatus().isTerminal()) {
                             future.complete(workflow);
+                            runningWorkflowFutures.remove(workflowId);
                         }
                     }
                 },

File: java-sdk/src/main/java/com/netflix/conductor/sdk/workflow/task/WorkerTask.java
Patch:
@@ -23,5 +23,8 @@
 public @interface WorkerTask {
     String value();
 
+    // No. of threads to use for executing the task
     int threadCount() default 1;
+
+    int pollingInterval() default 100;
 }

File: awssqs-event-queue/src/test/java/com/netflix/conductor/sqs/eventqueue/SQSObservableQueueTest.java
Patch:
@@ -22,7 +22,7 @@
 
 import com.netflix.conductor.core.events.queue.Message;
 
-import com.amazonaws.services.sqs.AmazonSQSClient;
+import com.amazonaws.services.sqs.AmazonSQS;
 import com.amazonaws.services.sqs.model.ListQueuesRequest;
 import com.amazonaws.services.sqs.model.ListQueuesResult;
 import com.amazonaws.services.sqs.model.ReceiveMessageRequest;
@@ -74,7 +74,7 @@ public void testException() {
                         .withReceiptHandle("receiptHandle");
         Answer<?> answer = (Answer<ReceiveMessageResult>) invocation -> new ReceiveMessageResult();
 
-        AmazonSQSClient client = mock(AmazonSQSClient.class);
+        AmazonSQS client = mock(AmazonSQS.class);
         when(client.listQueues(any(ListQueuesRequest.class)))
                 .thenReturn(new ListQueuesResult().withQueueUrls("junit_queue_url"));
         when(client.receiveMessage(any(ReceiveMessageRequest.class)))

File: client/src/main/java/com/netflix/conductor/client/http/WorkflowClient.java
Patch:
@@ -254,7 +254,8 @@ private void populateWorkflowOutput(Workflow workflow) {
      * Removes a workflow from the system
      *
      * @param workflowId the id of the workflow to be deleted
-     * @param archiveWorkflow flag to indicate if the workflow should be archived before deletion
+     * @param archiveWorkflow flag to indicate if the workflow and associated tasks should be
+     *     archived before deletion
      */
     public void deleteWorkflow(String workflowId, boolean archiveWorkflow) {
         Validate.notBlank(workflowId, "Workflow id cannot be blank");

File: core/src/main/java/com/netflix/conductor/core/utils/ExternalPayloadStorageUtils.java
Patch:
@@ -205,7 +205,7 @@ String uploadHelper(
             byte[] payloadBytes, long payloadSize, ExternalPayloadStorage.PayloadType payloadType) {
         ExternalStorageLocation location =
                 externalPayloadStorage.getLocation(
-                        ExternalPayloadStorage.Operation.WRITE, payloadType, "");
+                        ExternalPayloadStorage.Operation.WRITE, payloadType, "", payloadBytes);
         externalPayloadStorage.upload(
                 location.getPath(), new ByteArrayInputStream(payloadBytes), payloadSize);
         return location.getPath();

File: core/src/main/java/com/netflix/conductor/service/WorkflowService.java
Patch:
@@ -134,7 +134,7 @@ Workflow getExecutionStatus(
      * Removes the workflow from the system.
      *
      * @param workflowId WorkflowID of the workflow you want to remove from system.
-     * @param archiveWorkflow Archives the workflow.
+     * @param archiveWorkflow Archives the workflow and associated tasks instead of removing them.
      */
     void deleteWorkflow(
             @NotEmpty(message = "WorkflowId cannot be null or empty.") String workflowId,

File: core/src/main/java/com/netflix/conductor/service/WorkflowServiceImpl.java
Patch:
@@ -190,7 +190,7 @@ public Workflow getExecutionStatus(String workflowId, boolean includeTasks) {
      * Removes the workflow from the system.
      *
      * @param workflowId WorkflowID of the workflow you want to remove from system.
-     * @param archiveWorkflow Archives the workflow.
+     * @param archiveWorkflow Archives the workflow and associated tasks instead of removing them.
      */
     public void deleteWorkflow(String workflowId, boolean archiveWorkflow) {
         executionService.removeWorkflow(workflowId, archiveWorkflow);

File: client/src/main/java/com/netflix/conductor/client/http/WorkflowClient.java
Patch:
@@ -254,7 +254,8 @@ private void populateWorkflowOutput(Workflow workflow) {
      * Removes a workflow from the system
      *
      * @param workflowId the id of the workflow to be deleted
-     * @param archiveWorkflow flag to indicate if the workflow should be archived before deletion
+     * @param archiveWorkflow flag to indicate if the workflow and associated tasks should be
+     *     archived before deletion
      */
     public void deleteWorkflow(String workflowId, boolean archiveWorkflow) {
         Validate.notBlank(workflowId, "Workflow id cannot be blank");

File: core/src/main/java/com/netflix/conductor/service/WorkflowService.java
Patch:
@@ -134,7 +134,7 @@ Workflow getExecutionStatus(
      * Removes the workflow from the system.
      *
      * @param workflowId WorkflowID of the workflow you want to remove from system.
-     * @param archiveWorkflow Archives the workflow.
+     * @param archiveWorkflow Archives the workflow and associated tasks instead of removing them.
      */
     void deleteWorkflow(
             @NotEmpty(message = "WorkflowId cannot be null or empty.") String workflowId,

File: core/src/main/java/com/netflix/conductor/service/WorkflowServiceImpl.java
Patch:
@@ -190,7 +190,7 @@ public Workflow getExecutionStatus(String workflowId, boolean includeTasks) {
      * Removes the workflow from the system.
      *
      * @param workflowId WorkflowID of the workflow you want to remove from system.
-     * @param archiveWorkflow Archives the workflow.
+     * @param archiveWorkflow Archives the workflow and associated tasks instead of removing them.
      */
     public void deleteWorkflow(String workflowId, boolean archiveWorkflow) {
         executionService.removeWorkflow(workflowId, archiveWorkflow);

File: server/src/test/java/com/netflix/conductor/common/config/ConductorObjectMapperTest.java
Patch:
@@ -21,6 +21,7 @@
 import org.junit.runner.RunWith;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.boot.test.context.SpringBootTest;
+import org.springframework.test.context.TestPropertySource;
 import org.springframework.test.context.junit4.SpringRunner;
 
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
@@ -43,6 +44,7 @@
  */
 @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)
 @RunWith(SpringRunner.class)
+@TestPropertySource(properties = "conductor.queue.type=")
 public class ConductorObjectMapperTest {
 
     @Autowired ObjectMapper objectMapper;

File: server/src/main/java/com/netflix/conductor/Conductor.java
Patch:
@@ -21,12 +21,14 @@
 import org.springframework.boot.SpringApplication;
 import org.springframework.boot.autoconfigure.SpringBootApplication;
 import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;
+import org.springframework.context.annotation.ComponentScan;
 import org.springframework.core.io.FileSystemResource;
 
 // Prevents from the datasource beans to be loaded, AS they are needed only for specific databases.
 // In case that SQL database is selected this class will be imported back in the appropriate
 // database persistence module.
 @SpringBootApplication(exclude = DataSourceAutoConfiguration.class)
+@ComponentScan(basePackages = {"com.netflix.conductor", "io.orkes.conductor"})
 public class Conductor {
 
     private static final Logger log = LoggerFactory.getLogger(Conductor.class);

File: java-sdk/example/java/com/netflix/conductor/sdk/example/shipment/ShipmentWorkers.java
Patch:
@@ -24,7 +24,7 @@
 
 public class ShipmentWorkers {
 
-    @WorkerTask("generateDynamicFork")
+    @WorkerTask(value = "generateDynamicFork", threadCount = 3)
     public DynamicForkInput generateDynamicFork(
             @InputParam("orderDetails") List<Order> orderDetails,
             @InputParam("userDetails") User userDetails) {
@@ -46,7 +46,7 @@ public DynamicForkInput generateDynamicFork(
         return input;
     }
 
-    @WorkerTask("get_order_details")
+    @WorkerTask(value = "get_order_details", threadCount = 5)
     public List<Order> getOrderDetails(@InputParam("orderNo") String orderNo) {
         int lineItemCount = new Random().nextInt(10);
         List<Order> orderDetails = new ArrayList<>();

File: java-sdk/src/main/java/com/netflix/conductor/sdk/workflow/task/WorkerTask.java
Patch:
@@ -22,4 +22,6 @@
 @Target({ElementType.METHOD})
 public @interface WorkerTask {
     String value();
+
+    int threadCount() default 1;
 }

File: core/src/main/java/com/netflix/conductor/core/config/ConductorCoreConfiguration.java
Patch:
@@ -30,7 +30,6 @@
 import org.springframework.context.annotation.Configuration;
 import org.springframework.retry.support.RetryTemplate;
 
-import com.netflix.conductor.common.metadata.tasks.TaskType;
 import com.netflix.conductor.common.utils.ExternalPayloadStorage;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.exception.TransientException;
@@ -94,7 +93,7 @@ public ExecutorService executorService(ConductorProperties conductorProperties)
 
     @Bean
     @Qualifier("taskMappersByTaskType")
-    public Map<TaskType, TaskMapper> getTaskMappers(List<TaskMapper> taskMappers) {
+    public Map<String, TaskMapper> getTaskMappers(List<TaskMapper> taskMappers) {
         return taskMappers.stream().collect(Collectors.toMap(TaskMapper::getTaskType, identity()));
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -50,8 +50,8 @@ public class DecisionTaskMapper implements TaskMapper {
     private static final Logger LOGGER = LoggerFactory.getLogger(DecisionTaskMapper.class);
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.DECISION;
+    public String getTaskType() {
+        return TaskType.DECISION.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DoWhileTaskMapper.java
Patch:
@@ -49,8 +49,8 @@ public DoWhileTaskMapper(MetadataDAO metadataDAO, ParametersUtils parametersUtil
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.DO_WHILE;
+    public String getTaskType() {
+        return TaskType.DO_WHILE.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DynamicTaskMapper.java
Patch:
@@ -53,8 +53,8 @@ public DynamicTaskMapper(ParametersUtils parametersUtils, MetadataDAO metadataDA
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.DYNAMIC;
+    public String getTaskType() {
+        return TaskType.DYNAMIC.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/EventTaskMapper.java
Patch:
@@ -41,8 +41,8 @@ public EventTaskMapper(ParametersUtils parametersUtils) {
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.EVENT;
+    public String getTaskType() {
+        return TaskType.EVENT.name();
     }
 
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ExclusiveJoinTaskMapper.java
Patch:
@@ -30,8 +30,8 @@ public class ExclusiveJoinTaskMapper implements TaskMapper {
     public static final Logger LOGGER = LoggerFactory.getLogger(ExclusiveJoinTaskMapper.class);
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.EXCLUSIVE_JOIN;
+    public String getTaskType() {
+        return TaskType.EXCLUSIVE_JOIN.name();
     }
 
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinDynamicTaskMapper.java
Patch:
@@ -74,8 +74,8 @@ public ForkJoinDynamicTaskMapper(
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.FORK_JOIN_DYNAMIC;
+    public String getTaskType() {
+        return TaskType.FORK_JOIN_DYNAMIC.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapper.java
Patch:
@@ -38,8 +38,8 @@ public class ForkJoinTaskMapper implements TaskMapper {
     public static final Logger LOGGER = LoggerFactory.getLogger(ForkJoinTaskMapper.class);
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.FORK_JOIN;
+    public String getTaskType() {
+        return TaskType.FORK_JOIN.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/HTTPTaskMapper.java
Patch:
@@ -49,8 +49,8 @@ public HTTPTaskMapper(ParametersUtils parametersUtils, MetadataDAO metadataDAO)
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.HTTP;
+    public String getTaskType() {
+        return TaskType.HTTP.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/HumanTaskMapper.java
Patch:
@@ -45,8 +45,8 @@ public HumanTaskMapper(ParametersUtils parametersUtils) {
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.HUMAN;
+    public String getTaskType() {
+        return TaskType.HUMAN.name();
     }
 
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/InlineTaskMapper.java
Patch:
@@ -47,8 +47,8 @@ public InlineTaskMapper(ParametersUtils parametersUtils, MetadataDAO metadataDAO
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.INLINE;
+    public String getTaskType() {
+        return TaskType.INLINE.name();
     }
 
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/JoinTaskMapper.java
Patch:
@@ -36,8 +36,8 @@ public class JoinTaskMapper implements TaskMapper {
     public static final Logger LOGGER = LoggerFactory.getLogger(JoinTaskMapper.class);
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.JOIN;
+    public String getTaskType() {
+        return TaskType.JOIN.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/JsonJQTransformTaskMapper.java
Patch:
@@ -41,8 +41,8 @@ public JsonJQTransformTaskMapper(ParametersUtils parametersUtils, MetadataDAO me
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.JSON_JQ_TRANSFORM;
+    public String getTaskType() {
+        return TaskType.JSON_JQ_TRANSFORM.name();
     }
 
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/KafkaPublishTaskMapper.java
Patch:
@@ -48,8 +48,8 @@ public KafkaPublishTaskMapper(ParametersUtils parametersUtils, MetadataDAO metad
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.KAFKA_PUBLISH;
+    public String getTaskType() {
+        return TaskType.KAFKA_PUBLISH.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/LambdaTaskMapper.java
Patch:
@@ -48,8 +48,8 @@ public LambdaTaskMapper(ParametersUtils parametersUtils, MetadataDAO metadataDAO
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.LAMBDA;
+    public String getTaskType() {
+        return TaskType.LAMBDA.name();
     }
 
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SetVariableTaskMapper.java
Patch:
@@ -28,8 +28,8 @@ public class SetVariableTaskMapper implements TaskMapper {
     public static final Logger LOGGER = LoggerFactory.getLogger(SetVariableTaskMapper.class);
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.SET_VARIABLE;
+    public String getTaskType() {
+        return TaskType.SET_VARIABLE.name();
     }
 
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SimpleTaskMapper.java
Patch:
@@ -45,8 +45,8 @@ public SimpleTaskMapper(ParametersUtils parametersUtils) {
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.SIMPLE;
+    public String getTaskType() {
+        return TaskType.SIMPLE.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/StartWorkflowTaskMapper.java
Patch:
@@ -18,7 +18,6 @@
 import org.slf4j.LoggerFactory;
 import org.springframework.stereotype.Component;
 
-import com.netflix.conductor.common.metadata.tasks.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.core.exception.TerminateWorkflowException;
 import com.netflix.conductor.model.TaskModel;
@@ -32,8 +31,8 @@ public class StartWorkflowTaskMapper implements TaskMapper {
     private static final Logger LOGGER = LoggerFactory.getLogger(StartWorkflowTaskMapper.class);
 
     @Override
-    public TaskType getTaskType() {
-        return START_WORKFLOW;
+    public String getTaskType() {
+        return START_WORKFLOW.name();
     }
 
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SubWorkflowTaskMapper.java
Patch:
@@ -45,8 +45,8 @@ public SubWorkflowTaskMapper(ParametersUtils parametersUtils, MetadataDAO metada
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.SUB_WORKFLOW;
+    public String getTaskType() {
+        return TaskType.SUB_WORKFLOW.name();
     }
 
     @SuppressWarnings("rawtypes")

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SwitchTaskMapper.java
Patch:
@@ -48,8 +48,8 @@ public SwitchTaskMapper(Map<String, Evaluator> evaluators) {
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.SWITCH;
+    public String getTaskType() {
+        return TaskType.SWITCH.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/TaskMapper.java
Patch:
@@ -14,13 +14,12 @@
 
 import java.util.List;
 
-import com.netflix.conductor.common.metadata.tasks.TaskType;
 import com.netflix.conductor.core.exception.TerminateWorkflowException;
 import com.netflix.conductor.model.TaskModel;
 
 public interface TaskMapper {
 
-    TaskType getTaskType();
+    String getTaskType();
 
     List<TaskModel> getMappedTasks(TaskMapperContext taskMapperContext)
             throws TerminateWorkflowException;

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/TerminateTaskMapper.java
Patch:
@@ -37,8 +37,8 @@ public TerminateTaskMapper(ParametersUtils parametersUtils) {
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.TERMINATE;
+    public String getTaskType() {
+        return TaskType.TERMINATE.name();
     }
 
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/UserDefinedTaskMapper.java
Patch:
@@ -49,8 +49,8 @@ public UserDefinedTaskMapper(ParametersUtils parametersUtils, MetadataDAO metada
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.USER_DEFINED;
+    public String getTaskType() {
+        return TaskType.USER_DEFINED.name();
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapper.java
Patch:
@@ -45,8 +45,8 @@ public WaitTaskMapper(ParametersUtils parametersUtils) {
     }
 
     @Override
-    public TaskType getTaskType() {
-        return TaskType.WAIT;
+    public String getTaskType() {
+        return TaskType.WAIT.name();
     }
 
     @Override

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -105,7 +105,7 @@ public MetadataDAO mockMetadataDAO() {
         }
 
         @Bean
-        public Map<TaskType, TaskMapper> taskMapperMap(Collection<TaskMapper> taskMappers) {
+        public Map<String, TaskMapper> taskMapperMap(Collection<TaskMapper> taskMappers) {
             return taskMappers.stream()
                     .collect(Collectors.toMap(TaskMapper::getTaskType, Function.identity()));
         }
@@ -132,7 +132,7 @@ public IDGenerator idGenerator() {
 
     @Autowired
     @Qualifier("taskMapperMap")
-    private Map<TaskType, TaskMapper> taskMappers;
+    private Map<String, TaskMapper> taskMappers;
 
     @Autowired private ParametersUtils parametersUtils;
 

File: core/src/main/java/com/netflix/conductor/core/execution/AsyncSystemTaskExecutor.java
Patch:
@@ -135,7 +135,7 @@ public void execute(WorkflowSystemTask systemTask, String taskId) {
 
             if (task.getStatus() == TaskModel.Status.SCHEDULED) {
                 task.setStartTime(System.currentTimeMillis());
-                Monitors.recordQueueWaitTime(task.getTaskDefName(), task.getQueueWaitTime());
+                Monitors.recordQueueWaitTime(task.getTaskType(), task.getQueueWaitTime());
                 systemTask.start(workflow, task, workflowExecutor);
             } else if (task.getStatus() == TaskModel.Status.IN_PROGRESS) {
                 systemTask.execute(workflow, task, workflowExecutor);

File: core/src/main/java/com/netflix/conductor/service/WorkflowServiceImpl.java
Patch:
@@ -89,8 +89,8 @@ public String startWorkflow(
             Map<String, String> taskToDomain,
             WorkflowDef workflowDef) {
         StartWorkflowInput startWorkflowInput = new StartWorkflowInput();
-        startWorkflowInput.setName(workflowDef.getName());
-        startWorkflowInput.setVersion(workflowDef.getVersion());
+        startWorkflowInput.setName(name);
+        startWorkflowInput.setVersion(version);
         startWorkflowInput.setCorrelationId(correlationId);
         startWorkflowInput.setPriority(priority);
         startWorkflowInput.setWorkflowInput(input);

File: core/src/main/java/com/netflix/conductor/model/WorkflowModel.java
Patch:
@@ -570,6 +570,7 @@ public Workflow toWorkflow() {
         BeanUtils.copyProperties(this, workflow);
         workflow.setStatus(Workflow.WorkflowStatus.valueOf(this.status.name()));
         workflow.setTasks(tasks.stream().map(TaskModel::toTask).collect(Collectors.toList()));
+        workflow.setUpdateTime(this.updatedTime);
 
         // ensure that input/output is properly represented
         if (externalInputPayloadStoragePath != null) {

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SubWorkflow.java
Patch:
@@ -205,7 +205,7 @@ private void updateTaskStatus(WorkflowModel subworkflow, TaskModel task) {
                 task.setExternalOutputPayloadStoragePath(
                         subworkflow.getExternalOutputPayloadStoragePath());
             } else {
-                task.getOutputData().putAll(subworkflow.getOutput());
+                task.addOutput(subworkflow.getOutput());
             }
             if (!status.isSuccessful()) {
                 task.setReasonForIncompletion(

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinDynamicTaskMapper.java
Patch:
@@ -245,7 +245,6 @@ TaskModel createDynamicForkTask(
         forkDynamicTask.setTaskDefName(TaskType.TASK_TYPE_FORK);
         forkDynamicTask.setStartTime(System.currentTimeMillis());
         forkDynamicTask.setEndTime(System.currentTimeMillis());
-        forkDynamicTask.setExecuted(true);
         List<String> forkedTaskNames =
                 dynForkTasks.stream()
                         .map(WorkflowTask::getTaskReferenceName)

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapper.java
Patch:
@@ -78,7 +78,6 @@ public List<TaskModel> getMappedTasks(TaskMapperContext taskMapperContext)
         forkTask.setEndTime(epochMillis);
         forkTask.setInputData(taskInput);
         forkTask.setStatus(TaskModel.Status.COMPLETED);
-        forkTask.setExecuted(true);
 
         tasksToBeScheduled.add(forkTask);
         List<List<WorkflowTask>> forkTasks = workflowTask.getForkTasks();

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SwitchTaskMapper.java
Patch:
@@ -96,8 +96,7 @@ public List<TaskModel> getMappedTasks(TaskMapperContext taskMapperContext) {
         switchTask.getInputData().put("case", evalResult);
         switchTask.getOutputData().put("evaluationResult", Collections.singletonList(evalResult));
         switchTask.setStartTime(System.currentTimeMillis());
-        switchTask.setStatus(TaskModel.Status.COMPLETED);
-        switchTask.setExecuted(true);
+        switchTask.setStatus(TaskModel.Status.IN_PROGRESS);
         tasksToBeScheduled.add(switchTask);
 
         // get the list of tasks based on the evaluated expression

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -231,7 +231,7 @@ public void testWorkflowWithNoTasksWithSwitch() throws Exception {
         workflow.getTasks().addAll(outcome.tasksToBeScheduled);
         outcome = deciderService.decide(workflow);
         assertFalse(outcome.isComplete);
-        assertEquals(outcome.tasksToBeUpdated.toString(), 1, outcome.tasksToBeUpdated.size());
+        assertEquals(outcome.tasksToBeUpdated.toString(), 3, outcome.tasksToBeUpdated.size());
         assertEquals(1, outcome.tasksToBeScheduled.size());
         assertEquals("junit_task_3", outcome.tasksToBeScheduled.get(0).getTaskDefName());
     }

File: client/src/main/java/com/netflix/conductor/client/automator/TaskRunnerConfigurer.java
Patch:
@@ -270,7 +270,8 @@ public synchronized void init() {
      * shutdown of your worker, during process termination.
      */
     public void shutdown() {
-        taskPollExecutor.shutdownExecutorService(
+        taskPollExecutor.shutdownAndAwaitTermination(
                 scheduledExecutorService, shutdownGracePeriodSeconds);
+        taskPollExecutor.shutdown(shutdownGracePeriodSeconds);
     }
 }

File: core/src/main/java/com/netflix/conductor/core/dal/ExecutionDAOFacade.java
Patch:
@@ -636,7 +636,7 @@ public List<TaskExecLog> getTaskExecutionLogs(String taskId) {
      * @param workflowModel the workflowModel for which the payload data needs to be populated from
      *     external storage (if applicable)
      */
-    private void populateWorkflowAndTaskPayloadData(WorkflowModel workflowModel) {
+    public void populateWorkflowAndTaskPayloadData(WorkflowModel workflowModel) {
         if (StringUtils.isNotBlank(workflowModel.getExternalInputPayloadStoragePath())) {
             Map<String, Object> workflowInputParams =
                     externalPayloadStorageUtils.downloadPayload(
@@ -662,7 +662,7 @@ private void populateWorkflowAndTaskPayloadData(WorkflowModel workflowModel) {
         workflowModel.getTasks().forEach(this::populateTaskData);
     }
 
-    private void populateTaskData(TaskModel taskModel) {
+    public void populateTaskData(TaskModel taskModel) {
         if (StringUtils.isNotBlank(taskModel.getExternalOutputPayloadStoragePath())) {
             Map<String, Object> outputData =
                     externalPayloadStorageUtils.downloadPayload(

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinDynamicTaskMapper.java
Patch:
@@ -245,6 +245,7 @@ TaskModel createDynamicForkTask(
         forkDynamicTask.setTaskDefName(TaskType.TASK_TYPE_FORK);
         forkDynamicTask.setStartTime(System.currentTimeMillis());
         forkDynamicTask.setEndTime(System.currentTimeMillis());
+        forkDynamicTask.setExecuted(true);
         List<String> forkedTaskNames =
                 dynForkTasks.stream()
                         .map(WorkflowTask::getTaskReferenceName)

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SwitchTaskMapper.java
Patch:
@@ -96,7 +96,8 @@ public List<TaskModel> getMappedTasks(TaskMapperContext taskMapperContext) {
         switchTask.getInputData().put("case", evalResult);
         switchTask.getOutputData().put("evaluationResult", Collections.singletonList(evalResult));
         switchTask.setStartTime(System.currentTimeMillis());
-        switchTask.setStatus(TaskModel.Status.IN_PROGRESS);
+        switchTask.setStatus(TaskModel.Status.COMPLETED);
+        switchTask.setExecuted(true);
         tasksToBeScheduled.add(switchTask);
 
         // get the list of tasks based on the evaluated expression

File: core/src/main/java/com/netflix/conductor/core/reconciliation/WorkflowSweeper.java
Patch:
@@ -27,6 +27,7 @@
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import com.netflix.conductor.dao.QueueDAO;
 import com.netflix.conductor.metrics.Monitors;
+import com.netflix.conductor.model.WorkflowModel;
 
 import static com.netflix.conductor.core.config.SchedulerConfiguration.SWEEPER_EXECUTOR_NAME;
 import static com.netflix.conductor.core.utils.Utils.DECIDER_QUEUE;
@@ -73,8 +74,8 @@ public void sweep(String workflowId) {
                 workflowRepairService.verifyAndRepairWorkflowTasks(workflowId);
             }
 
-            boolean done = workflowExecutor.decide(workflowId);
-            if (done) {
+            WorkflowModel workflow = workflowExecutor.decide(workflowId);
+            if (workflow != null && workflow.getStatus().isTerminal()) {
                 queueDAO.remove(DECIDER_QUEUE, workflowId);
                 return;
             }

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -231,7 +231,7 @@ public void testWorkflowWithNoTasksWithSwitch() throws Exception {
         workflow.getTasks().addAll(outcome.tasksToBeScheduled);
         outcome = deciderService.decide(workflow);
         assertFalse(outcome.isComplete);
-        assertEquals(outcome.tasksToBeUpdated.toString(), 3, outcome.tasksToBeUpdated.size());
+        assertEquals(outcome.tasksToBeUpdated.toString(), 1, outcome.tasksToBeUpdated.size());
         assertEquals(1, outcome.tasksToBeScheduled.size());
         assertEquals("junit_task_3", outcome.tasksToBeScheduled.get(0).getTaskDefName());
     }

File: core/src/main/java/com/netflix/conductor/core/events/DefaultEventProcessor.java
Patch:
@@ -90,6 +90,7 @@ public DefaultEventProcessor(
         this.objectMapper = objectMapper;
         this.jsonUtils = jsonUtils;
         this.evaluators = evaluators;
+        this.retryTemplate = retryTemplate;
 
         if (properties.getEventProcessorThreadCount() <= 0) {
             throw new IllegalStateException(
@@ -105,7 +106,6 @@ public DefaultEventProcessor(
                         properties.getEventProcessorThreadCount(), threadFactory);
 
         this.isEventMessageIndexingEnabled = properties.isEventMessageIndexingEnabled();
-        this.retryTemplate = retryTemplate;
         LOGGER.info("Event Processing is ENABLED");
     }
 

File: common/src/main/java/com/netflix/conductor/common/config/ObjectMapperConfiguration.java
Patch:
@@ -18,6 +18,7 @@
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.module.afterburner.AfterburnerModule;
 
 @Configuration
 public class ObjectMapperConfiguration {
@@ -34,5 +35,6 @@ public void customizeDefaultObjectMapper() {
         objectMapper.setDefaultPropertyInclusion(
                 JsonInclude.Value.construct(
                         JsonInclude.Include.NON_NULL, JsonInclude.Include.ALWAYS));
+        objectMapper.registerModule(new AfterburnerModule());
     }
 }

File: common/src/main/java/com/netflix/conductor/common/config/ObjectMapperProvider.java
Patch:
@@ -17,6 +17,7 @@
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.databind.DeserializationFeature;
 import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.module.afterburner.AfterburnerModule;
 
 /**
  * A Factory class for creating a customized {@link ObjectMapper}. This is only used by the
@@ -46,6 +47,7 @@ public ObjectMapper getObjectMapper() {
                 JsonInclude.Value.construct(
                         JsonInclude.Include.NON_NULL, JsonInclude.Include.ALWAYS));
         objectMapper.registerModule(new JsonProtoModule());
+        objectMapper.registerModule(new AfterburnerModule());
         return objectMapper;
     }
 }

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowDef.java
Patch:
@@ -76,7 +76,7 @@ public enum TimeoutPolicy {
     @Max(value = 2, message = "workflowDef schemaVersion: {value} is only supported")
     private int schemaVersion = 2;
 
-    // By default a workflow is restartable
+    // By default, a workflow is restartable
     @ProtoField(id = 9)
     private boolean restartable = true;
 

File: core/src/main/java/com/netflix/conductor/core/events/DefaultEventProcessor.java
Patch:
@@ -111,7 +111,7 @@ public DefaultEventProcessor(
 
     public void handle(ObservableQueue queue, Message msg) {
         List<EventExecution> transientFailures = null;
-        Boolean executionFailed = false;
+        boolean executionFailed = false;
         try {
             if (isEventMessageIndexingEnabled) {
                 executionService.addMessage(queue.getName(), msg);
@@ -155,7 +155,7 @@ protected List<EventExecution> executeEvent(String event, Message msg) throws Ex
             String evaluatorType = eventHandler.getEvaluatorType();
             // Set default to true so that if condition is not specified, it falls through
             // to process the event.
-            Boolean success = true;
+            boolean success = true;
             if (StringUtils.isNotEmpty(condition) && evaluators.get(evaluatorType) != null) {
                 Object result =
                         evaluators
@@ -267,6 +267,7 @@ protected EventExecution execute(EventExecution eventExecution, Action action, O
                     eventExecution.getMessageId(),
                     payload);
 
+            // TODO: Switch to @Retryable annotation on SimpleActionProcessor.execute()
             Map<String, Object> output =
                     retryTemplate.execute(
                             context ->

File: core/src/main/java/com/netflix/conductor/core/execution/AsyncSystemTaskExecutor.java
Patch:
@@ -102,7 +102,9 @@ public void execute(WorkflowSystemTask systemTask, String taskId) {
         // if we are here the Task object is updated and needs to be persisted regardless of an
         // exception
         try {
-            WorkflowModel workflow = executionDAOFacade.getWorkflowModel(workflowId, true);
+            WorkflowModel workflow =
+                    executionDAOFacade.getWorkflowModel(
+                            workflowId, systemTask.isTaskRetrievalRequired());
 
             if (workflow.getStatus().isTerminal()) {
                 LOGGER.info(

File: core/src/main/java/com/netflix/conductor/core/execution/evaluators/JavascriptEvaluator.java
Patch:
@@ -36,9 +36,8 @@ public Object evaluate(String expression, Object input) {
             LOGGER.debug("Javascript evaluator -- result: {}", result);
             return result;
         } catch (ScriptException e) {
-            String errorMsg = String.format("Error while evaluating script: %s", expression);
-            LOGGER.error(errorMsg, e);
-            throw new TerminateWorkflowException(errorMsg);
+            LOGGER.error("Error while evaluating script: {}", expression, e);
+            throw new TerminateWorkflowException(e.getMessage());
         }
     }
 }

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinDynamicTaskMapper.java
Patch:
@@ -197,7 +197,7 @@ public List<TaskModel> getMappedTasks(TaskMapperContext taskMapperContext)
             for (TaskModel forkedTask : forkedTasks) {
                 Map<String, Object> forkedTaskInput =
                         tasksInput.get(forkedTask.getReferenceTaskName());
-                forkedTask.getInputData().putAll(forkedTaskInput);
+                forkedTask.addInput(forkedTaskInput);
             }
             mappedTasks.addAll(forkedTasks);
             // Get the last of the dynamic tasks so that the join can be performed once this task is

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SetVariable.java
Patch:
@@ -23,7 +23,7 @@
 import org.springframework.stereotype.Component;
 
 import com.netflix.conductor.core.config.ConductorProperties;
-import com.netflix.conductor.core.exception.ApplicationException;
+import com.netflix.conductor.core.exception.NonTransientException;
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import com.netflix.conductor.model.TaskModel;
 import com.netflix.conductor.model.WorkflowModel;
@@ -69,7 +69,8 @@ private boolean validateVariablesSize(
         } catch (IOException e) {
             LOGGER.error(
                     "Unable to validate variables payload size of workflow: {}", workflowId, e);
-            throw new ApplicationException(ApplicationException.Code.INTERNAL_ERROR, e);
+            throw new NonTransientException(
+                    "Unable to validate variables payload size of workflow: " + workflowId, e);
         }
     }
 

File: core/src/main/java/com/netflix/conductor/dao/MetadataDAO.java
Patch:
@@ -24,13 +24,13 @@ public interface MetadataDAO {
     /**
      * @param taskDef task definition to be created
      */
-    void createTaskDef(TaskDef taskDef);
+    TaskDef createTaskDef(TaskDef taskDef);
 
     /**
      * @param taskDef task definition to be updated.
      * @return name of the task definition
      */
-    String updateTaskDef(TaskDef taskDef);
+    TaskDef updateTaskDef(TaskDef taskDef);
 
     /**
      * @param name Name of the task

File: core/src/main/java/com/netflix/conductor/model/WorkflowModel.java
Patch:
@@ -23,6 +23,7 @@
 import com.netflix.conductor.core.utils.Utils;
 
 import com.fasterxml.jackson.annotation.JsonIgnore;
+import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonProperty;
 
 public class WorkflowModel {
@@ -74,6 +75,7 @@ public boolean isSuccessful() {
 
     private Map<String, String> taskToDomain = new HashMap<>();
 
+    @JsonInclude(JsonInclude.Include.NON_EMPTY)
     private Set<String> failedReferenceTaskNames = new HashSet<>();
 
     private WorkflowDef workflowDefinition;

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/InlineTest.java
Patch:
@@ -44,7 +44,7 @@ public void testInlineTaskValidationFailures() {
         TaskModel task = new TaskModel();
         task.getInputData().putAll(inputObj);
         inline.execute(workflow, task, executor);
-        assertEquals(TaskModel.Status.FAILED, task.getStatus());
+        assertEquals(TaskModel.Status.FAILED_WITH_TERMINAL_ERROR, task.getStatus());
         assertEquals(
                 "Empty 'expression' in Inline task's input parameters. A non-empty String value must be provided.",
                 task.getReasonForIncompletion());
@@ -57,9 +57,9 @@ public void testInlineTaskValidationFailures() {
         task = new TaskModel();
         task.getInputData().putAll(inputObj);
         inline.execute(workflow, task, executor);
-        assertEquals(TaskModel.Status.FAILED, task.getStatus());
+        assertEquals(TaskModel.Status.FAILED_WITH_TERMINAL_ERROR, task.getStatus());
         assertEquals(
-                "Empty 'evaluatorType' in Inline task's input parameters. A non-empty String value must be provided.",
+                "Empty 'evaluatorType' in INLINE task's input parameters. A non-empty String value must be provided.",
                 task.getReasonForIncompletion());
     }
 

File: core/src/main/java/com/netflix/conductor/core/events/DefaultEventProcessor.java
Patch:
@@ -90,6 +90,7 @@ public DefaultEventProcessor(
         this.objectMapper = objectMapper;
         this.jsonUtils = jsonUtils;
         this.evaluators = evaluators;
+        this.retryTemplate = retryTemplate;
 
         if (properties.getEventProcessorThreadCount() <= 0) {
             throw new IllegalStateException(
@@ -105,7 +106,6 @@ public DefaultEventProcessor(
                         properties.getEventProcessorThreadCount(), threadFactory);
 
         this.isEventMessageIndexingEnabled = properties.isEventMessageIndexingEnabled();
-        this.retryTemplate = retryTemplate;
         LOGGER.info("Event Processing is ENABLED");
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/AsyncSystemTaskExecutor.java
Patch:
@@ -102,7 +102,9 @@ public void execute(WorkflowSystemTask systemTask, String taskId) {
         // if we are here the Task object is updated and needs to be persisted regardless of an
         // exception
         try {
-            WorkflowModel workflow = executionDAOFacade.getWorkflowModel(workflowId, true);
+            WorkflowModel workflow =
+                    executionDAOFacade.getWorkflowModel(
+                            workflowId, systemTask.isTaskRetrievalRequired());
 
             if (workflow.getStatus().isTerminal()) {
                 LOGGER.info(

File: core/src/main/java/com/netflix/conductor/dao/MetadataDAO.java
Patch:
@@ -24,13 +24,13 @@ public interface MetadataDAO {
     /**
      * @param taskDef task definition to be created
      */
-    void createTaskDef(TaskDef taskDef);
+    TaskDef createTaskDef(TaskDef taskDef);
 
     /**
      * @param taskDef task definition to be updated.
      * @return name of the task definition
      */
-    String updateTaskDef(TaskDef taskDef);
+    TaskDef updateTaskDef(TaskDef taskDef);
 
     /**
      * @param name Name of the task

File: core/src/main/java/com/netflix/conductor/core/execution/evaluators/JavascriptEvaluator.java
Patch:
@@ -36,9 +36,8 @@ public Object evaluate(String expression, Object input) {
             LOGGER.debug("Javascript evaluator -- result: {}", result);
             return result;
         } catch (ScriptException e) {
-            String errorMsg = String.format("Error while evaluating script: %s", expression);
-            LOGGER.error(errorMsg, e);
-            throw new TerminateWorkflowException(errorMsg);
+            LOGGER.error("Error while evaluating script: {}", expression, e);
+            throw new TerminateWorkflowException(e.getMessage());
         }
     }
 }

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/InlineTest.java
Patch:
@@ -44,7 +44,7 @@ public void testInlineTaskValidationFailures() {
         TaskModel task = new TaskModel();
         task.getInputData().putAll(inputObj);
         inline.execute(workflow, task, executor);
-        assertEquals(TaskModel.Status.FAILED, task.getStatus());
+        assertEquals(TaskModel.Status.FAILED_WITH_TERMINAL_ERROR, task.getStatus());
         assertEquals(
                 "Empty 'expression' in Inline task's input parameters. A non-empty String value must be provided.",
                 task.getReasonForIncompletion());
@@ -57,9 +57,9 @@ public void testInlineTaskValidationFailures() {
         task = new TaskModel();
         task.getInputData().putAll(inputObj);
         inline.execute(workflow, task, executor);
-        assertEquals(TaskModel.Status.FAILED, task.getStatus());
+        assertEquals(TaskModel.Status.FAILED_WITH_TERMINAL_ERROR, task.getStatus());
         assertEquals(
-                "Empty 'evaluatorType' in Inline task's input parameters. A non-empty String value must be provided.",
+                "Empty 'evaluatorType' in INLINE task's input parameters. A non-empty String value must be provided.",
                 task.getReasonForIncompletion());
     }
 

File: core/src/test/java/com/netflix/conductor/core/dal/ExecutionDAOFacadeTest.java
Patch:
@@ -61,6 +61,7 @@ public void setUp() {
         executionDAO = mock(ExecutionDAO.class);
         QueueDAO queueDAO = mock(QueueDAO.class);
         indexDAO = mock(IndexDAO.class);
+        externalPayloadStorageUtils = mock(ExternalPayloadStorageUtils.class);
         RateLimitingDAO rateLimitingDao = mock(RateLimitingDAO.class);
         ConcurrentExecutionLimitDAO concurrentExecutionLimitDAO =
                 mock(ConcurrentExecutionLimitDAO.class);

File: awss3-storage/src/main/java/com/netflix/conductor/s3/storage/S3PayloadStorage.java
Patch:
@@ -22,7 +22,7 @@
 
 import com.netflix.conductor.common.run.ExternalStorageLocation;
 import com.netflix.conductor.common.utils.ExternalPayloadStorage;
-import com.netflix.conductor.core.exception.ApplicationException;
+import com.netflix.conductor.core.exception.NonTransientException;
 import com.netflix.conductor.core.exception.TransientException;
 import com.netflix.conductor.core.utils.IDGenerator;
 import com.netflix.conductor.s3.config.S3Properties;
@@ -109,7 +109,7 @@ public ExternalStorageLocation getLocation(
         } catch (URISyntaxException e) {
             String msg = "Invalid URI Syntax";
             LOGGER.error(msg, e);
-            throw new ApplicationException(ApplicationException.Code.INTERNAL_ERROR, msg, e);
+            throw new NonTransientException(msg, e);
         }
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SetVariable.java
Patch:
@@ -23,7 +23,7 @@
 import org.springframework.stereotype.Component;
 
 import com.netflix.conductor.core.config.ConductorProperties;
-import com.netflix.conductor.core.exception.ApplicationException;
+import com.netflix.conductor.core.exception.NonTransientException;
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import com.netflix.conductor.model.TaskModel;
 import com.netflix.conductor.model.WorkflowModel;
@@ -69,7 +69,8 @@ private boolean validateVariablesSize(
         } catch (IOException e) {
             LOGGER.error(
                     "Unable to validate variables payload size of workflow: {}", workflowId, e);
-            throw new ApplicationException(ApplicationException.Code.INTERNAL_ERROR, e);
+            throw new NonTransientException(
+                    "Unable to validate variables payload size of workflow: " + workflowId, e);
         }
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SubWorkflow.java
Patch:
@@ -20,7 +20,7 @@
 import org.springframework.stereotype.Component;
 
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
-import com.netflix.conductor.core.exception.ApplicationException;
+import com.netflix.conductor.core.exception.NonTransientException;
 import com.netflix.conductor.core.exception.TransientException;
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import com.netflix.conductor.model.TaskModel;
@@ -196,8 +196,7 @@ private void updateTaskStatus(WorkflowModel subworkflow, TaskModel task) {
                 task.setStatus(TaskModel.Status.TIMED_OUT);
                 break;
             default:
-                throw new ApplicationException(
-                        ApplicationException.Code.INTERNAL_ERROR,
+                throw new NonTransientException(
                         "Subworkflow status does not conform to relevant task status.");
         }
 

File: core/src/main/java/com/netflix/conductor/core/utils/Utils.java
Patch:
@@ -19,6 +19,7 @@
 import org.apache.commons.lang3.StringUtils;
 
 import com.netflix.conductor.core.exception.ApplicationException;
+import com.netflix.conductor.core.exception.TransientException;
 
 public class Utils {
 
@@ -127,9 +128,7 @@ public static void checkNotNull(Object object, String errorMessage) {
     public static boolean isTransientException(Throwable throwable) {
         if (throwable != null) {
             return !((throwable instanceof UnsupportedOperationException)
-                    || (throwable instanceof ApplicationException
-                            && ((ApplicationException) throwable).getCode()
-                                    != ApplicationException.Code.BACKEND_ERROR));
+                    || (throwable instanceof TransientException));
         }
         return true;
     }

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestSubWorkflow.java
Patch:
@@ -25,6 +25,7 @@
 import com.netflix.conductor.common.config.TestObjectMapperConfiguration;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.core.exception.ApplicationException;
+import com.netflix.conductor.core.exception.TransientException;
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import com.netflix.conductor.model.TaskModel;
 import com.netflix.conductor.model.WorkflowModel;
@@ -129,9 +130,7 @@ public void testStartSubWorkflowQueueFailure() {
                         any(),
                         eq(null),
                         any()))
-                .thenThrow(
-                        new ApplicationException(
-                                ApplicationException.Code.BACKEND_ERROR, "QueueDAO failure"));
+                .thenThrow(new TransientException("QueueDAO failure"));
 
         subWorkflow.start(workflowInstance, task, workflowExecutor);
         assertNull("subWorkflowId should be null", task.getSubWorkflowId());

File: rest/src/main/java/com/netflix/conductor/rest/controllers/ApplicationExceptionMapper.java
Patch:
@@ -29,6 +29,7 @@
 import com.netflix.conductor.core.exception.ApplicationException;
 import com.netflix.conductor.core.exception.ConflictException;
 import com.netflix.conductor.core.exception.NotFoundException;
+import com.netflix.conductor.core.exception.TransientException;
 import com.netflix.conductor.core.utils.Utils;
 import com.netflix.conductor.metrics.Monitors;
 
@@ -74,7 +75,8 @@ public ResponseEntity<ErrorResponse> handleAll(HttpServletRequest request, Throw
         errorResponse.setInstance(host);
         errorResponse.setStatus(status.value());
         errorResponse.setMessage(th.getMessage());
-        errorResponse.setRetryable(false); // set it to true for BACKEND_ERROR
+        errorResponse.setRetryable(
+                th instanceof TransientException); // set it to true for BACKEND_ERROR
 
         Monitors.error("error", String.valueOf(status.value()));
 

File: java-sdk/src/main/java/com/netflix/conductor/sdk/workflow/def/tasks/Task.java
Patch:
@@ -205,6 +205,8 @@ protected final WorkflowTask toWorkflowTask() {
         workflowTask.setWorkflowTaskType(type);
         workflowTask.setDescription(description);
         workflowTask.setInputParameters(input);
+        workflowTask.setStartDelay(startDelay);
+        workflowTask.setOptional(optional);
 
         // Let the sub-classes enrich the workflow task before returning back
         updateWorkflowTask(workflowTask);

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -515,7 +515,9 @@ public void testOptionalWithDynamicFork() {
 
         assertEquals(TaskModel.Status.IN_PROGRESS, outcome.tasksToBeScheduled.get(0).getStatus());
         new Join().execute(workflow, outcome.tasksToBeScheduled.get(0), null);
-        assertEquals(TaskModel.Status.COMPLETED, outcome.tasksToBeScheduled.get(0).getStatus());
+        assertEquals(
+                TaskModel.Status.COMPLETED_WITH_ERRORS,
+                outcome.tasksToBeScheduled.get(0).getStatus());
     }
 
     @Test

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -57,8 +57,6 @@ public class DeciderService {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(DeciderService.class);
 
-    @VisibleForTesting static final String MAX_TASK_LIMIT = "conductor.app.max-task-limit";
-
     private final IDGenerator idGenerator;
     private final ParametersUtils parametersUtils;
     private final ExternalPayloadStorageUtils externalPayloadStorageUtils;

File: core/src/main/java/com/netflix/conductor/core/utils/ParametersUtils.java
Patch:
@@ -124,6 +124,7 @@ public Map<String, Object> getTaskInputV2(
                                     "reasonForIncompletion", task.getReasonForIncompletion());
                             taskParams.put("callbackAfterSeconds", task.getCallbackAfterSeconds());
                             taskParams.put("workerId", task.getWorkerId());
+                            taskParams.put("iteration", task.getIteration());
                             inputMap.put(
                                     task.isLoopOverTask()
                                             ? TaskUtils.removeIterationFromTaskRefName(

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/DoWhileTaskMapperTest.java
Patch:
@@ -95,9 +95,7 @@ public void getMappedTasks() {
                 new DoWhileTaskMapper(metadataDAO).getMappedTasks(taskMapperContext);
 
         assertNotNull(mappedTasks);
-        assertEquals(mappedTasks.size(), 2);
-        assertEquals("task1__1", mappedTasks.get(1).getReferenceTaskName());
-        assertEquals(1, mappedTasks.get(1).getIteration());
+        assertEquals(mappedTasks.size(), 1);
         assertEquals(TASK_TYPE_DO_WHILE, mappedTasks.get(0).getTaskType());
     }
 

File: contribs/src/test/java/com/netflix/conductor/contribs/tasks/http/HttpTaskTest.java
Patch:
@@ -32,6 +32,7 @@
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import com.netflix.conductor.core.execution.tasks.SystemTaskRegistry;
 import com.netflix.conductor.core.utils.ExternalPayloadStorageUtils;
+import com.netflix.conductor.core.utils.IDGenerator;
 import com.netflix.conductor.core.utils.ParametersUtils;
 import com.netflix.conductor.dao.MetadataDAO;
 import com.netflix.conductor.model.TaskModel;
@@ -356,6 +357,7 @@ public void testOptional() {
         SystemTaskRegistry systemTaskRegistry = mock(SystemTaskRegistry.class);
 
         new DeciderService(
+                        new IDGenerator(),
                         parametersUtils,
                         metadataDAO,
                         externalPayloadStorageUtils,

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/DoWhileTaskMapperTest.java
Patch:
@@ -64,7 +64,7 @@ public void setup() {
         workflowTask.setLoopCondition(
                 "if ($.second_task + $.first_task > 10) { false; } else { true; }");
 
-        String taskId = IDGenerator.generate();
+        String taskId = new IDGenerator().generate();
 
         WorkflowDef workflowDef = new WorkflowDef();
         workflow = new WorkflowModel();

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/DynamicTaskMapperTest.java
Patch:
@@ -70,7 +70,7 @@ public void getMappedTasks() {
                         anyMap(), any(WorkflowModel.class), any(TaskDef.class), anyString()))
                 .thenReturn(taskInput);
 
-        String taskId = IDGenerator.generate();
+        String taskId = new IDGenerator().generate();
 
         WorkflowModel workflow = new WorkflowModel();
         WorkflowDef workflowDef = new WorkflowDef();

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/EventTaskMapperTest.java
Patch:
@@ -42,7 +42,7 @@ public void getMappedTasks() {
 
         WorkflowTask taskToBeScheduled = new WorkflowTask();
         taskToBeScheduled.setSink("SQSSINK");
-        String taskId = IDGenerator.generate();
+        String taskId = new IDGenerator().generate();
 
         Map<String, Object> eventTaskInput = new HashMap<>();
         eventTaskInput.put("sink", "SQSSINK");

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/InlineTaskMapperTest.java
Patch:
@@ -55,7 +55,7 @@ public void getMappedTasks() {
                 "function scriptFun() {if ($.input.a==1){return {testValue: true}} else{return "
                         + "{testValue: false} }}; scriptFun();");
 
-        String taskId = IDGenerator.generate();
+        String taskId = new IDGenerator().generate();
 
         WorkflowDef workflowDef = new WorkflowDef();
         WorkflowModel workflow = new WorkflowModel();
@@ -89,7 +89,7 @@ public void getMappedTasks_WithoutTaskDef() {
                 "function scriptFun() {if ($.input.a==1){return {testValue: true}} else{return "
                         + "{testValue: false} }}; scriptFun();");
 
-        String taskId = IDGenerator.generate();
+        String taskId = new IDGenerator().generate();
 
         WorkflowDef workflowDef = new WorkflowDef();
         WorkflowModel workflow = new WorkflowModel();

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/JoinTaskMapperTest.java
Patch:
@@ -39,7 +39,7 @@ public void getMappedTasks() {
         workflowTask.setType(TaskType.JOIN.name());
         workflowTask.setJoinOn(Arrays.asList("task1", "task2"));
 
-        String taskId = IDGenerator.generate();
+        String taskId = new IDGenerator().generate();
 
         WorkflowDef wd = new WorkflowDef();
         WorkflowModel workflow = new WorkflowModel();

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/SetVariableTaskMapperTest.java
Patch:
@@ -33,7 +33,7 @@ public void getMappedTasks() {
         WorkflowTask workflowTask = new WorkflowTask();
         workflowTask.setType(TaskType.TASK_TYPE_SET_VARIABLE);
 
-        String taskId = IDGenerator.generate();
+        String taskId = new IDGenerator().generate();
 
         WorkflowDef workflowDef = new WorkflowDef();
         WorkflowModel workflow = new WorkflowModel();

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/TerminateTaskMapperTest.java
Patch:
@@ -43,7 +43,7 @@ public void getMappedTasks() {
         WorkflowTask workflowTask = new WorkflowTask();
         workflowTask.setType(TaskType.TASK_TYPE_TERMINATE);
 
-        String taskId = IDGenerator.generate();
+        String taskId = new IDGenerator().generate();
 
         WorkflowDef workflowDef = new WorkflowDef();
         WorkflowModel workflow = new WorkflowModel();

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapperTest.java
Patch:
@@ -40,7 +40,7 @@ public void getMappedTasks() {
         WorkflowTask workflowTask = new WorkflowTask();
         workflowTask.setName("Wait_task");
         workflowTask.setType(TaskType.WAIT.name());
-        String taskId = IDGenerator.generate();
+        String taskId = new IDGenerator().generate();
 
         ParametersUtils parametersUtils = mock(ParametersUtils.class);
         WorkflowModel workflow = new WorkflowModel();

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestDoWhile.java
Patch:
@@ -29,6 +29,7 @@
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import com.netflix.conductor.core.listener.WorkflowStatusListener;
 import com.netflix.conductor.core.metadata.MetadataMapperService;
+import com.netflix.conductor.core.utils.IDGenerator;
 import com.netflix.conductor.core.utils.ParametersUtils;
 import com.netflix.conductor.dao.MetadataDAO;
 import com.netflix.conductor.dao.QueueDAO;
@@ -100,7 +101,8 @@ public void setup() {
                                 properties,
                                 executionLockService,
                                 systemTaskRegistry,
-                                parametersUtils));
+                                parametersUtils,
+                                new IDGenerator()));
         WorkflowTask loopWorkflowTask1 = new WorkflowTask();
         loopWorkflowTask1.setTaskReferenceName("task1");
         loopWorkflowTask1.setName("task1");

File: es6-persistence/src/test/java/com/netflix/conductor/es6/utils/TestUtils.java
Patch:
@@ -31,7 +31,7 @@ public static WorkflowSummary loadWorkflowSnapshot(
             ObjectMapper objectMapper, String resourceFileName) {
         try {
             String content = loadJsonResource(resourceFileName);
-            String workflowId = IDGenerator.generate();
+            String workflowId = new IDGenerator().generate();
             content = content.replace(WORKFLOW_INSTANCE_ID_PLACEHOLDER, workflowId);
 
             return objectMapper.readValue(content, WorkflowSummary.class);
@@ -43,7 +43,7 @@ public static WorkflowSummary loadWorkflowSnapshot(
     public static TaskSummary loadTaskSnapshot(ObjectMapper objectMapper, String resourceFileName) {
         try {
             String content = loadJsonResource(resourceFileName);
-            String workflowId = IDGenerator.generate();
+            String workflowId = new IDGenerator().generate();
             content = content.replace(WORKFLOW_INSTANCE_ID_PLACEHOLDER, workflowId);
 
             return objectMapper.readValue(content, TaskSummary.class);

File: es7-persistence/src/test/java/com/netflix/conductor/es7/utils/TestUtils.java
Patch:
@@ -30,7 +30,7 @@ public static WorkflowSummary loadWorkflowSnapshot(
             ObjectMapper objectMapper, String resourceFileName) {
         try {
             String content = loadJsonResource(resourceFileName);
-            String workflowId = IDGenerator.generate();
+            String workflowId = new IDGenerator().generate();
             content = content.replace(WORKFLOW_INSTANCE_ID_PLACEHOLDER, workflowId);
 
             return objectMapper.readValue(content, WorkflowSummary.class);
@@ -42,7 +42,7 @@ public static WorkflowSummary loadWorkflowSnapshot(
     public static TaskSummary loadTaskSnapshot(ObjectMapper objectMapper, String resourceFileName) {
         try {
             String content = loadJsonResource(resourceFileName);
-            String workflowId = IDGenerator.generate();
+            String workflowId = new IDGenerator().generate();
             content = content.replace(WORKFLOW_INSTANCE_ID_PLACEHOLDER, workflowId);
 
             return objectMapper.readValue(content, TaskSummary.class);

File: postgres-external-storage/src/main/java/com/netflix/conductor/postgres/config/PostgresPayloadConfiguration.java
Patch:
@@ -25,6 +25,7 @@
 import org.springframework.context.annotation.Configuration;
 
 import com.netflix.conductor.common.utils.ExternalPayloadStorage;
+import com.netflix.conductor.core.utils.IDGenerator;
 import com.netflix.conductor.postgres.storage.PostgresPayloadStorage;
 
 @Configuration(proxyBeanMethods = false)
@@ -70,14 +71,14 @@ public Flyway flywayForExternalDb() {
 
     @Bean
     public ExternalPayloadStorage postgresExternalPayloadStorage(
-            PostgresPayloadProperties properties) {
+            IDGenerator idGenerator, PostgresPayloadProperties properties) {
         DataSource dataSource =
                 DataSourceBuilder.create()
                         .driverClassName("org.postgresql.Driver")
                         .url(properties.getUrl())
                         .username(properties.getUsername())
                         .password(properties.getPassword())
                         .build();
-        return new PostgresPayloadStorage(properties, dataSource);
+        return new PostgresPayloadStorage(idGenerator, properties, dataSource);
     }
 }

File: core/src/main/java/com/netflix/conductor/core/config/ConductorCoreConfiguration.java
Patch:
@@ -92,7 +92,7 @@ public ExecutorService executorService(ConductorProperties conductorProperties)
     }
 
     @Bean
-    @Qualifier("taskProcessorsMap")
+    @Qualifier("taskMappersByTaskType")
     public Map<TaskType, TaskMapper> getTaskMappers(List<TaskMapper> taskMappers) {
         return taskMappers.stream().collect(Collectors.toMap(TaskMapper::getTaskType, identity()));
     }

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/DynamicTaskMapperTest.java
Patch:
@@ -78,10 +78,9 @@ public void getMappedTasks() {
 
         TaskMapperContext taskMapperContext =
                 TaskMapperContext.newBuilder()
-                        .withWorkflowInstance(workflow)
-                        .withWorkflowDefinition(workflowDef)
+                        .withWorkflowModel(workflow)
                         .withTaskDefinition(workflowTask.getTaskDefinition())
-                        .withTaskToSchedule(workflowTask)
+                        .withWorkflowTask(workflowTask)
                         .withTaskInput(taskInput)
                         .withRetryCount(0)
                         .withTaskId(taskId)

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/EventTaskMapperTest.java
Patch:
@@ -57,10 +57,9 @@ public void getMappedTasks() {
 
         TaskMapperContext taskMapperContext =
                 TaskMapperContext.newBuilder()
-                        .withWorkflowDefinition(workflowDef)
-                        .withWorkflowInstance(workflow)
+                        .withWorkflowModel(workflow)
                         .withTaskDefinition(new TaskDef())
-                        .withTaskToSchedule(taskToBeScheduled)
+                        .withWorkflowTask(taskToBeScheduled)
                         .withRetryCount(0)
                         .withTaskId(taskId)
                         .build();

File: common/src/main/java/com/netflix/conductor/common/run/WorkflowSummary.java
Patch:
@@ -311,9 +311,9 @@ && getPriority() == that.getPriority()
                 && getWorkflowType().equals(that.getWorkflowType())
                 && getWorkflowId().equals(that.getWorkflowId())
                 && Objects.equals(getCorrelationId(), that.getCorrelationId())
-                && getStartTime().equals(that.getStartTime())
-                && getUpdateTime().equals(that.getUpdateTime())
-                && getEndTime().equals(that.getEndTime())
+                && StringUtils.equals(getStartTime(), that.getStartTime())
+                && StringUtils.equals(getUpdateTime(), that.getUpdateTime())
+                && StringUtils.equals(getEndTime(), that.getEndTime())
                 && getStatus() == that.getStatus()
                 && Objects.equals(getReasonForIncompletion(), that.getReasonForIncompletion())
                 && Objects.equals(getEvent(), that.getEvent());

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/IsolatedTaskQueueProducer.java
Patch:
@@ -58,7 +58,7 @@ public IsolatedTaskQueueProducer(
             @Value("${conductor.app.isolatedSystemTaskEnabled:false}")
                     boolean isolatedSystemTaskEnabled,
             @Value("${conductor.app.isolatedSystemTaskQueuePollInterval:10s}")
-                    Duration isolatedSystemTaskQueuePollIntervalSecs) {
+                    Duration isolatedSystemTaskQueuePollInterval) {
 
         this.metadataService = metadataService;
         this.asyncSystemTasks = asyncSystemTasks;
@@ -71,8 +71,8 @@ public IsolatedTaskQueueProducer(
                     .scheduleWithFixedDelay(
                             this::addTaskQueues,
                             1000,
-                            isolatedSystemTaskQueuePollIntervalSecs.getSeconds(),
-                            TimeUnit.SECONDS);
+                            isolatedSystemTaskQueuePollInterval.toMillis(),
+                            TimeUnit.MILLISECONDS);
         } else {
             LOGGER.info("Isolated System Task Worker DISABLED");
         }

File: client/src/main/java/com/netflix/conductor/client/http/TaskClient.java
Patch:
@@ -256,7 +256,7 @@ public void evaluateAndUploadLargePayload(TaskResult taskResult, String taskType
                                         * 1024L) {
                     taskResult.setReasonForIncompletion(
                             String.format(
-                                    "The TaskResult payload size: %d is greater than the permissible %d MB",
+                                    "The TaskResult payload size: %d is greater than the permissible %d bytes",
                                     taskResultSize, payloadSizeThreshold));
                     taskResult.setStatus(TaskResult.Status.FAILED_WITH_TERMINAL_ERROR);
                     taskResult.setOutputData(null);

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/sqs/config/SQSEventQueueConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -22,11 +22,11 @@
 import org.springframework.context.annotation.Bean;
 import org.springframework.context.annotation.Configuration;
 
-import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.contribs.queue.sqs.SQSObservableQueue.Builder;
 import com.netflix.conductor.core.config.ConductorProperties;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
+import com.netflix.conductor.model.TaskModel.Status;
 
 import com.amazonaws.auth.AWSCredentialsProvider;
 import com.amazonaws.services.sqs.AmazonSQSClient;

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -400,8 +400,7 @@ void updateWorkflowOutput(final WorkflowModel workflow, TaskModel task) {
         workflow.setOutput(output);
     }
 
-    @VisibleForTesting
-    boolean checkForWorkflowCompletion(final WorkflowModel workflow)
+    public boolean checkForWorkflowCompletion(final WorkflowModel workflow)
             throws TerminateWorkflowException {
         List<TaskModel> allTasks = workflow.getTasks();
         if (allTasks.isEmpty()) {

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SetVariable.java
Patch:
@@ -59,7 +59,7 @@ private boolean validateVariablesSize(
             if (payloadSize > maxThreshold * 1024) {
                 String errorMsg =
                         String.format(
-                                "The variables payload size: %dB of workflow: %s is greater than the permissible limit: %dKB",
+                                "The variables payload size: %d of workflow: %s is greater than the permissible limit: %d bytes",
                                 payloadSize, workflowId, maxThreshold);
                 LOGGER.error(errorMsg);
                 task.setReasonForIncompletion(errorMsg);

File: core/src/main/java/com/netflix/conductor/core/utils/ExternalPayloadStorageUtils.java
Patch:
@@ -126,7 +126,7 @@ public <T> void verifyAndUpload(T entity, PayloadType payloadType) {
                 if (entity instanceof TaskModel) {
                     String errorMsg =
                             String.format(
-                                    "The payload size: %dB of task: %s in workflow: %s  is greater than the permissible limit: %dKB",
+                                    "The payload size: %d of task: %s in workflow: %s  is greater than the permissible limit: %d bytes",
                                     payloadSize,
                                     ((TaskModel) entity).getTaskId(),
                                     ((TaskModel) entity).getWorkflowInstanceId(),
@@ -135,7 +135,7 @@ public <T> void verifyAndUpload(T entity, PayloadType payloadType) {
                 } else {
                     String errorMsg =
                             String.format(
-                                    "The output payload size: %dB of workflow: %s is greater than the permissible limit: %dKB",
+                                    "The output payload size: %dB of workflow: %s is greater than the permissible limit: %d bytes",
                                     payloadSize,
                                     ((WorkflowModel) entity).getWorkflowId(),
                                     maxThreshold);

File: rest/src/main/java/com/netflix/conductor/rest/controllers/QueueAdminResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -21,8 +21,8 @@
 import org.springframework.web.bind.annotation.RequestMapping;
 import org.springframework.web.bind.annotation.RestController;
 
-import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.core.events.queue.DefaultEventQueueProcessor;
+import com.netflix.conductor.model.TaskModel.Status;
 
 import io.swagger.v3.oas.annotations.Operation;
 

File: client/src/main/java/com/netflix/conductor/client/http/TaskClient.java
Patch:
@@ -256,7 +256,7 @@ public void evaluateAndUploadLargePayload(TaskResult taskResult, String taskType
                                         * 1024L) {
                     taskResult.setReasonForIncompletion(
                             String.format(
-                                    "The TaskResult payload size: %d is greater than the permissible %d MB",
+                                    "The TaskResult payload size: %d is greater than the permissible %d bytes",
                                     taskResultSize, payloadSizeThreshold));
                     taskResult.setStatus(TaskResult.Status.FAILED_WITH_TERMINAL_ERROR);
                     taskResult.setOutputData(null);

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/sqs/config/SQSEventQueueConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -22,11 +22,11 @@
 import org.springframework.context.annotation.Bean;
 import org.springframework.context.annotation.Configuration;
 
-import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.contribs.queue.sqs.SQSObservableQueue.Builder;
 import com.netflix.conductor.core.config.ConductorProperties;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
+import com.netflix.conductor.model.TaskModel.Status;
 
 import com.amazonaws.auth.AWSCredentialsProvider;
 import com.amazonaws.services.sqs.AmazonSQSClient;

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -400,8 +400,7 @@ void updateWorkflowOutput(final WorkflowModel workflow, TaskModel task) {
         workflow.setOutput(output);
     }
 
-    @VisibleForTesting
-    boolean checkForWorkflowCompletion(final WorkflowModel workflow)
+    public boolean checkForWorkflowCompletion(final WorkflowModel workflow)
             throws TerminateWorkflowException {
         List<TaskModel> allTasks = workflow.getTasks();
         if (allTasks.isEmpty()) {

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SetVariable.java
Patch:
@@ -59,7 +59,7 @@ private boolean validateVariablesSize(
             if (payloadSize > maxThreshold * 1024) {
                 String errorMsg =
                         String.format(
-                                "The variables payload size: %dB of workflow: %s is greater than the permissible limit: %dKB",
+                                "The variables payload size: %d of workflow: %s is greater than the permissible limit: %d bytes",
                                 payloadSize, workflowId, maxThreshold);
                 LOGGER.error(errorMsg);
                 task.setReasonForIncompletion(errorMsg);

File: core/src/main/java/com/netflix/conductor/core/utils/ExternalPayloadStorageUtils.java
Patch:
@@ -126,7 +126,7 @@ public <T> void verifyAndUpload(T entity, PayloadType payloadType) {
                 if (entity instanceof TaskModel) {
                     String errorMsg =
                             String.format(
-                                    "The payload size: %dB of task: %s in workflow: %s  is greater than the permissible limit: %dKB",
+                                    "The payload size: %d of task: %s in workflow: %s  is greater than the permissible limit: %d bytes",
                                     payloadSize,
                                     ((TaskModel) entity).getTaskId(),
                                     ((TaskModel) entity).getWorkflowInstanceId(),
@@ -135,7 +135,7 @@ public <T> void verifyAndUpload(T entity, PayloadType payloadType) {
                 } else {
                     String errorMsg =
                             String.format(
-                                    "The output payload size: %dB of workflow: %s is greater than the permissible limit: %dKB",
+                                    "The output payload size: %dB of workflow: %s is greater than the permissible limit: %d bytes",
                                     payloadSize,
                                     ((WorkflowModel) entity).getWorkflowId(),
                                     maxThreshold);

File: rest/src/main/java/com/netflix/conductor/rest/controllers/QueueAdminResource.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -21,8 +21,8 @@
 import org.springframework.web.bind.annotation.RequestMapping;
 import org.springframework.web.bind.annotation.RestController;
 
-import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.core.events.queue.DefaultEventQueueProcessor;
+import com.netflix.conductor.model.TaskModel.Status;
 
 import io.swagger.v3.oas.annotations.Operation;
 

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/config/CassandraConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/config/CassandraProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraBaseDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraEventHandlerDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraMetadataDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/util/Constants.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/util/Statements.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: client/src/main/java/com/netflix/conductor/client/http/TaskClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -248,12 +248,12 @@ public void evaluateAndUploadLargePayload(TaskResult taskResult, String taskType
             MetricsContainer.recordTaskResultPayloadSize(taskType, taskResultSize);
 
             long payloadSizeThreshold =
-                    conductorClientConfiguration.getTaskOutputPayloadThresholdKB() * 1024;
+                    conductorClientConfiguration.getTaskOutputPayloadThresholdKB() * 1024L;
             if (taskResultSize > payloadSizeThreshold) {
                 if (!conductorClientConfiguration.isExternalPayloadStorageEnabled()
                         || taskResultSize
                                 > conductorClientConfiguration.getTaskOutputMaxPayloadThresholdKB()
-                                        * 1024) {
+                                        * 1024L) {
                     taskResult.setReasonForIncompletion(
                             String.format(
                                     "The TaskResult payload size: %d is greater than the permissible %d MB",

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskResult.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: contribs/src/main/java/com/netflix/conductor/contribs/dao/index/NoopIndexDAOConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: contribs/src/main/java/com/netflix/conductor/contribs/listener/archive/ArchivingWorkflowListenerConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -17,8 +17,8 @@
 import org.springframework.context.annotation.Bean;
 import org.springframework.context.annotation.Configuration;
 
+import com.netflix.conductor.core.dal.ExecutionDAOFacade;
 import com.netflix.conductor.core.listener.WorkflowStatusListener;
-import com.netflix.conductor.core.orchestration.ExecutionDAOFacade;
 
 @Configuration
 @EnableConfigurationProperties(ArchivingWorkflowListenerProperties.class)

File: contribs/src/main/java/com/netflix/conductor/contribs/listener/archive/ArchivingWorkflowListenerProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: contribs/src/main/java/com/netflix/conductor/contribs/listener/conductorqueue/ConductorQueueStatusPublisherProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/sqs/SQSObservableQueue.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/sqs/config/SQSEventQueueConfiguration.java
Patch:
@@ -32,7 +32,6 @@
 import com.amazonaws.services.sqs.AmazonSQSClient;
 import rx.Scheduler;
 
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Configuration
 @EnableConfigurationProperties(SQSEventQueueProperties.class)
 @ConditionalOnProperty(name = "conductor.event-queues.sqs.enabled", havingValue = "true")

File: contribs/src/main/java/com/netflix/conductor/contribs/storage/config/S3Configuration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: contribs/src/main/java/com/netflix/conductor/contribs/tasks/http/DefaultRestTemplateProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: contribs/src/main/java/com/netflix/conductor/contribs/tasks/http/RestTemplateProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: contribs/src/main/java/com/netflix/conductor/contribs/tasks/kafka/KafkaProducerManager.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: contribs/src/test/java/com/netflix/conductor/contribs/tasks/http/DefaultRestTemplateProviderTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/annotations/Audit.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/annotations/Trace.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/LifecycleAwareComponent.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/WorkflowContext.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -12,7 +12,7 @@
  */
 package com.netflix.conductor.core;
 
-/** Store the authentication context, app or user name or both */
+/** Store the authentication context, app or username or both */
 public class WorkflowContext {
 
     public static final ThreadLocal<WorkflowContext> THREAD_LOCAL =

File: core/src/main/java/com/netflix/conductor/core/events/ActionProcessor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/DefaultEventProcessor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/DefaultEventQueueManager.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -49,7 +49,6 @@
  *
  * @see DefaultEventQueueProcessor
  */
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Component
 @ConditionalOnProperty(
         name = "conductor.default-event-processor.enabled",

File: core/src/main/java/com/netflix/conductor/core/events/EventQueueManager.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/EventQueueProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/EventQueues.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/ScriptEvaluator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/queue/ConductorEventQueueProvider.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -35,7 +35,6 @@
  *
  * @see ConductorObservableQueue
  */
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Component
 @ConditionalOnProperty(
         name = "conductor.event-queues.default.enabled",

File: core/src/main/java/com/netflix/conductor/core/events/queue/ConductorObservableQueue.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/queue/Message.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/events/queue/ObservableQueue.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/exception/ApplicationException.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -18,7 +18,6 @@
 import java.util.LinkedHashMap;
 import java.util.Map;
 
-@SuppressWarnings("serial")
 public class ApplicationException extends RuntimeException {
 
     public enum Code {
@@ -78,7 +77,7 @@ public String getTrace() {
         PrintStream ps = new PrintStream(baos);
         this.printStackTrace(ps);
         ps.flush();
-        return new String(baos.toByteArray());
+        return baos.toString();
     }
 
     public Map<String, Object> toMap() {

File: core/src/main/java/com/netflix/conductor/core/execution/evaluators/Evaluator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/evaluators/JavascriptEvaluator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -21,7 +21,6 @@
 import com.netflix.conductor.core.events.ScriptEvaluator;
 import com.netflix.conductor.core.exception.TerminateWorkflowException;
 
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Component(JavascriptEvaluator.NAME)
 public class JavascriptEvaluator implements Evaluator {
 

File: core/src/main/java/com/netflix/conductor/core/execution/evaluators/ValueParamEvaluator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -20,13 +20,13 @@
 
 import com.netflix.conductor.core.exception.TerminateWorkflowException;
 
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Component(ValueParamEvaluator.NAME)
 public class ValueParamEvaluator implements Evaluator {
 
     public static final String NAME = "value-param";
     private static final Logger LOGGER = LoggerFactory.getLogger(ValueParamEvaluator.class);
 
+    @SuppressWarnings("unchecked")
     @Override
     public Object evaluate(String expression, Object input) {
         LOGGER.debug("ValueParam evaluator -- evaluating: {}", expression);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/TaskMapper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -14,14 +14,14 @@
 
 import java.util.List;
 
-import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.TaskType;
 import com.netflix.conductor.core.exception.TerminateWorkflowException;
+import com.netflix.conductor.model.TaskModel;
 
 public interface TaskMapper {
 
     TaskType getTaskType();
 
-    List<Task> getMappedTasks(TaskMapperContext taskMapperContext)
+    List<TaskModel> getMappedTasks(TaskMapperContext taskMapperContext)
             throws TerminateWorkflowException;
 }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/ExecutionConfig.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Fork.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/IsolatedTaskQueueProducer.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskRegistry.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorker.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorkerCoordinator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/reconciliation/WorkflowReconciler.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -26,13 +26,12 @@
 import com.netflix.conductor.dao.QueueDAO;
 import com.netflix.conductor.metrics.Monitors;
 
-import static com.netflix.conductor.core.execution.WorkflowExecutor.DECIDER_QUEUE;
+import static com.netflix.conductor.core.utils.Utils.DECIDER_QUEUE;
 
 /**
  * Periodically polls all running workflows in the system and evaluates them for timeouts and/or
  * maintain consistency.
  */
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Component
 @ConditionalOnProperty(
         name = "conductor.workflow-reconciler.enabled",

File: core/src/main/java/com/netflix/conductor/core/reconciliation/WorkflowSweeper.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -29,9 +29,8 @@
 import com.netflix.conductor.metrics.Monitors;
 
 import static com.netflix.conductor.core.config.SchedulerConfiguration.SWEEPER_EXECUTOR_NAME;
-import static com.netflix.conductor.core.execution.WorkflowExecutor.DECIDER_QUEUE;
+import static com.netflix.conductor.core.utils.Utils.DECIDER_QUEUE;
 
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Component
 public class WorkflowSweeper {
 

File: core/src/main/java/com/netflix/conductor/core/storage/DummyPayloadStorage.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/sync/Lock.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -43,7 +43,7 @@ public interface Lock {
      * @param lockId resource to lock on
      * @param timeToTry blocks up to timeToTry duration in attempt to acquire the lock
      * @param unit time unit
-     * @return
+     * @return true, if successfully acquired
      */
     boolean acquireLock(String lockId, long timeToTry, TimeUnit unit);
 
@@ -55,7 +55,7 @@ public interface Lock {
      * @param timeToTry blocks up to timeToTry duration in attempt to acquire the lock
      * @param leaseTime Lock lease expiration duration.
      * @param unit time unit
-     * @return
+     * @return true, if successfully acquired
      */
     boolean acquireLock(String lockId, long timeToTry, long leaseTime, TimeUnit unit);
 

File: core/src/main/java/com/netflix/conductor/core/sync/NoopLock.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/IDGenerator.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/JsonUtils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/SemaphoreUtil.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/core/utils/Utils.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -28,6 +28,8 @@
 
 public class Utils {
 
+    public static final String DECIDER_QUEUE = "_deciderQueue";
+
     /**
      * ID of the server. Can be host name, IP address or any other meaningful identifier
      *

File: core/src/main/java/com/netflix/conductor/dao/EventHandlerDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/MetadataDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/PollDataDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/dao/QueueDAO.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/metrics/WorkflowMonitor.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -26,8 +26,8 @@
 
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
+import com.netflix.conductor.core.dal.ExecutionDAOFacade;
 import com.netflix.conductor.core.execution.tasks.WorkflowSystemTask;
-import com.netflix.conductor.core.orchestration.ExecutionDAOFacade;
 import com.netflix.conductor.dao.QueueDAO;
 import com.netflix.conductor.service.MetadataService;
 

File: core/src/main/java/com/netflix/conductor/service/AdminService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -56,8 +56,8 @@ List<Task> getListOfPendingTask(
     /**
      * Verify that the Workflow is consistent, and run repairs as needed.
      *
-     * @param workflowId
-     * @return
+     * @param workflowId id of the workflow to be returned
+     * @return true, if repair was successful
      */
     boolean verifyAndRepairWorkflowConsistency(
             @NotEmpty(message = "WorkflowId cannot be null or empty.") String workflowId);

File: core/src/main/java/com/netflix/conductor/service/EventService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/EventServiceImpl.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/ExecutionLockService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/MetadataService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/MetadataServiceImpl.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -29,7 +29,6 @@
 import com.netflix.conductor.dao.MetadataDAO;
 import com.netflix.conductor.validations.ValidationContext;
 
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Service
 public class MetadataServiceImpl implements MetadataService {
 

File: core/src/main/java/com/netflix/conductor/service/TaskService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/WorkflowBulkService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/WorkflowBulkServiceImpl.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/service/WorkflowService.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/validations/ValidationContext.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: core/src/main/java/com/netflix/conductor/validations/WorkflowTaskValidConstraint.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -31,7 +31,7 @@
 import static java.lang.annotation.ElementType.TYPE;
 
 /**
- * This constraint class validates following things. 1. Check Task Def exists in DAO or not. If not
+ * This constraint class validates following things. 1. Check Task Def exists in DAO or not. If not,
  * check if it is ephemeral task type.
  */
 @Documented
@@ -67,7 +67,7 @@ public boolean isValid(WorkflowTask workflowTask, ConstraintValidatorContext con
 
             boolean valid = true;
 
-            // avoid task type definition check incase of non simple task
+            // avoid task type definition check in case of non-simple task
             if (!workflowTask.getType().equals(TASK_TYPE_SIMPLE)) {
                 return valid;
             }

File: es6-persistence/src/main/java/com/netflix/conductor/es6/config/ElasticSearchConditions.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/config/ElasticSearchProperties.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: es6-persistence/src/main/java/com/netflix/conductor/es6/config/ElasticSearchV6Configuration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: grpc-client/src/main/java/com/netflix/conductor/client/grpc/TaskClient.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at

File: mysql-persistence/src/main/java/com/netflix/conductor/mysql/config/MySQLConfiguration.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020 Netflix, Inc.
+ * Copyright 2022 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
  * the License. You may obtain a copy of the License at
@@ -28,7 +28,6 @@
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Configuration(proxyBeanMethods = false)
 @EnableConfigurationProperties(MySQLProperties.class)
 @ConditionalOnProperty(name = "conductor.db.type", havingValue = "mysql")

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraBaseDAO.java
Patch:
@@ -20,7 +20,6 @@
 import com.google.common.collect.ImmutableMap;
 import com.netflix.conductor.cassandra.config.CassandraProperties;
 import com.netflix.conductor.metrics.Monitors;
-import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -240,8 +239,7 @@ void recordCassandraDaoEventRequests(String action, String event) {
     }
 
     void recordCassandraDaoPayloadSize(String action, int size, String taskType, String workflowType) {
-        Monitors.recordDaoPayloadSize(DAO_NAME, action, StringUtils.defaultIfBlank(taskType, ""),
-            StringUtils.defaultIfBlank(workflowType, ""), size);
+        Monitors.recordDaoPayloadSize(DAO_NAME, action, taskType, workflowType, size);
     }
 
     static class WorkflowMetadata {

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorker.java
Patch:
@@ -124,7 +124,7 @@ void pollAndExecute(WorkflowSystemTask systemTask, String queueName) {
                 for (String taskId : polledTaskIds) {
                     if (StringUtils.isNotBlank(taskId)) {
                         LOGGER.debug("Task: {} from queue: {} being sent to the workflow executor", taskId, queueName);
-                        Monitors.recordTaskPollCount(queueName, "", 1);
+                        Monitors.recordTaskPollCount(queueName, 1);
 
                         executionService.ackTaskReceived(taskId);
 
@@ -144,7 +144,7 @@ void pollAndExecute(WorkflowSystemTask systemTask, String queueName) {
         } catch (Exception e) {
             // release the permit if exception is thrown during polling, because the thread would not be busy
             semaphoreUtil.completeProcessing(acquiredSlots);
-            Monitors.recordTaskPollError(taskName, "", e.getClass().getSimpleName());
+            Monitors.recordTaskPollError(taskName, e.getClass().getSimpleName());
             LOGGER.error("Error polling system task in queue:{}", queueName, e);
         }
     }

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SubWorkflowTaskMapper.java
Patch:
@@ -92,6 +92,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         subWorkflowTask.setStatus(Task.Status.SCHEDULED);
         subWorkflowTask.setWorkflowTask(taskToSchedule);
         subWorkflowTask.setWorkflowPriority(workflowInstance.getPriority());
+        subWorkflowTask.setCallbackAfterSeconds(taskToSchedule.getStartDelay());
         LOGGER.debug("SubWorkflowTask {} created to be Scheduled", subWorkflowTask);
         return Collections.singletonList(subWorkflowTask);
     }

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/SubWorkflowTaskMapperTest.java
Patch:
@@ -67,6 +67,7 @@ public void getMappedTasks() {
         subWorkflowParams.setName("Foo");
         subWorkflowParams.setVersion(2);
         taskToSchedule.setSubWorkflowParam(subWorkflowParams);
+        taskToSchedule.setStartDelay(30);
         Map<String, Object> taskInput = new HashMap<>();
         Map<String, String> taskToDomain = new HashMap<String, String>() {{
             put("*", "unittest");
@@ -99,6 +100,7 @@ public void getMappedTasks() {
         Task subWorkFlowTask = mappedTasks.get(0);
         assertEquals(Task.Status.SCHEDULED, subWorkFlowTask.getStatus());
         assertEquals(TASK_TYPE_SUB_WORKFLOW, subWorkFlowTask.getTaskType());
+        assertEquals(30, subWorkFlowTask.getCallbackAfterSeconds());
         assertEquals(taskToDomain, subWorkFlowTask.getInputData().get("subWorkflowTaskToDomain"));
     }
 

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/dao/CassandraExecutionDAO.java
Patch:
@@ -270,7 +270,7 @@ public boolean exceedsLimit(Task task) {
                 return true;
             }
         } catch (Exception e) {
-            Monitors.error(CLASS_NAME, "exceedsInProgressLimit");
+            Monitors.error(CLASS_NAME, "exceedsLimit");
             String errorMsg = String.format("Failed to get in progress limit - %s:%s in workflow :%s",
                 task.getTaskDefName(), task.getTaskId(), task.getWorkflowInstanceId());
             LOGGER.error(errorMsg, e);

File: common/src/main/java/com/netflix/conductor/common/metadata/events/EventExecution.java
Patch:
@@ -12,9 +12,9 @@
  */
 package com.netflix.conductor.common.metadata.events;
 
-import com.github.vmg.protogen.annotations.ProtoEnum;
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoEnum;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.netflix.conductor.common.metadata.events.EventHandler.Action;
 
 import java.util.HashMap;

File: common/src/main/java/com/netflix/conductor/common/metadata/events/EventHandler.java
Patch:
@@ -12,9 +12,9 @@
  */
 package com.netflix.conductor.common.metadata.events;
 
-import com.github.vmg.protogen.annotations.ProtoEnum;
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoEnum;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.google.protobuf.Any;
 import io.swagger.v3.oas.annotations.Hidden;
 

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/PollData.java
Patch:
@@ -12,8 +12,8 @@
  */
 package com.netflix.conductor.common.metadata.tasks;
 
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 
 import java.util.Objects;
 

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -12,9 +12,9 @@
  */
 package com.netflix.conductor.common.metadata.tasks;
 
-import com.github.vmg.protogen.annotations.ProtoEnum;
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoEnum;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.google.protobuf.Any;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import io.swagger.v3.oas.annotations.Hidden;

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskDef.java
Patch:
@@ -12,9 +12,9 @@
  */
 package com.netflix.conductor.common.metadata.tasks;
 
-import com.github.vmg.protogen.annotations.ProtoEnum;
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoEnum;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.netflix.conductor.common.constraints.OwnerEmailMandatoryConstraint;
 import com.netflix.conductor.common.constraints.TaskTimeoutConstraint;
 import com.netflix.conductor.common.metadata.Auditable;

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskExecLog.java
Patch:
@@ -12,8 +12,8 @@
  */
 package com.netflix.conductor.common.metadata.tasks;
 
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 
 import java.util.Objects;
 

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskResult.java
Patch:
@@ -12,9 +12,9 @@
  */
 package com.netflix.conductor.common.metadata.tasks;
 
-import com.github.vmg.protogen.annotations.ProtoEnum;
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoEnum;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.google.protobuf.Any;
 import org.apache.commons.lang3.StringUtils;
 

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskType.java
Patch:
@@ -12,7 +12,7 @@
  */
 package com.netflix.conductor.common.metadata.tasks;
 
-import com.github.vmg.protogen.annotations.ProtoEnum;
+import com.netflix.conductor.annotations.protogen.ProtoEnum;
 
 import java.util.HashSet;
 import java.util.Set;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/DynamicForkJoinTask.java
Patch:
@@ -12,8 +12,8 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.netflix.conductor.common.metadata.tasks.TaskType;
 
 import java.util.HashMap;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/DynamicForkJoinTaskList.java
Patch:
@@ -12,8 +12,8 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 
 import java.util.ArrayList;
 import java.util.List;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/RerunWorkflowRequest.java
Patch:
@@ -12,8 +12,8 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 
 import java.util.Map;
 

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/SkipTaskRequest.java
Patch:
@@ -12,8 +12,8 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.google.protobuf.Any;
 
 import java.util.Map;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/StartWorkflowRequest.java
Patch:
@@ -12,8 +12,8 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 
 import javax.validation.Valid;
 import javax.validation.constraints.Max;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/SubWorkflowParams.java
Patch:
@@ -14,8 +14,8 @@
 
 import com.fasterxml.jackson.annotation.JsonGetter;
 import com.fasterxml.jackson.annotation.JsonSetter;
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.google.common.base.Preconditions;
 
 import javax.validation.constraints.NotEmpty;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowDef.java
Patch:
@@ -12,9 +12,9 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.github.vmg.protogen.annotations.ProtoEnum;
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoEnum;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.netflix.conductor.common.constraints.NoSemiColonConstraint;
 import com.netflix.conductor.common.constraints.OwnerEmailMandatoryConstraint;
 import com.netflix.conductor.common.constraints.TaskReferenceNameUniqueConstraint;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -12,8 +12,8 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
 import com.netflix.conductor.common.metadata.tasks.TaskType;
 

File: common/src/main/java/com/netflix/conductor/common/run/TaskSummary.java
Patch:
@@ -12,8 +12,8 @@
  */
 package com.netflix.conductor.common.run;
 
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.common.utils.SummaryUtil;

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -12,9 +12,9 @@
  */
 package com.netflix.conductor.common.run;
 
-import com.github.vmg.protogen.annotations.ProtoEnum;
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoEnum;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.google.common.base.Preconditions;
 import com.netflix.conductor.common.metadata.Auditable;
 import com.netflix.conductor.common.metadata.tasks.Task;

File: common/src/main/java/com/netflix/conductor/common/run/WorkflowSummary.java
Patch:
@@ -12,8 +12,8 @@
  */
 package com.netflix.conductor.common.run;
 
-import com.github.vmg.protogen.annotations.ProtoField;
-import com.github.vmg.protogen.annotations.ProtoMessage;
+import com.netflix.conductor.annotations.protogen.ProtoField;
+import com.netflix.conductor.annotations.protogen.ProtoMessage;
 import com.netflix.conductor.common.run.Workflow.WorkflowStatus;
 import com.netflix.conductor.common.utils.SummaryUtil;
 import org.apache.commons.lang3.StringUtils;

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Inline.java
Patch:
@@ -94,7 +94,7 @@ public boolean execute(Workflow workflow, Task task, WorkflowExecutor workflowEx
     }
 
     private void checkEvaluatorType(String evaluatorType) {
-        if (StringUtils.isNotBlank(evaluatorType)) {
+        if (StringUtils.isBlank(evaluatorType)) {
             LOGGER.error("Empty {} in Inline task. ", QUERY_EVALUATOR_TYPE);
             throw new TerminateWorkflowException("Empty '" + QUERY_EVALUATOR_TYPE
                   + "' in Inline task's input parameters. A non-empty String value must be provided.");
@@ -106,7 +106,7 @@ private void checkEvaluatorType(String evaluatorType) {
     }
 
     private void checkExpression(String expression) {
-        if (StringUtils.isNotBlank(expression)) {
+        if (StringUtils.isBlank(expression)) {
             LOGGER.error("Empty {} in Inline task. ", QUERY_EXPRESSION_PARAMETER);
             throw new TerminateWorkflowException("Empty '" + QUERY_EXPRESSION_PARAMETER
                   + "' in Inline task's input parameters. A non-empty String value must be provided.");

File: core/src/main/java/com/netflix/conductor/core/execution/evaluators/ValueParamEvaluator.java
Patch:
@@ -29,13 +29,13 @@ public class ValueParamEvaluator implements Evaluator {
 
    @Override
    public Object evaluate(String expression, Object input) {
-      LOGGER.debug("ValueParam evaluator -- Evaluating: {}", expression);
+      LOGGER.debug("ValueParam evaluator -- evaluating: {}", expression);
       if (input instanceof Map) {
          Object result = ((Map<String, Object>) input).get(expression);
          LOGGER.debug("ValueParam evaluator -- result: {}", result);
          return result;
       } else {
-         String errorMsg = String.format("Input must of a JSON object: %s", input.getClass());
+         String errorMsg = String.format("Input has to be a JSON object: %s", input.getClass());
          LOGGER.error(errorMsg);
          throw new TerminateWorkflowException(errorMsg);
       }

File: client/src/main/java/com/netflix/conductor/client/exception/ConductorClientException.java
Patch:
@@ -61,6 +61,7 @@ public ConductorClientException(int status, String message) {
     public ConductorClientException(int status, ErrorResponse errorResponse) {
         super(errorResponse.getMessage());
         this.status = status;
+        this.retryable = errorResponse.isRetryable();
         this.message = errorResponse.getMessage();
         this.code = errorResponse.getCode();
         this.instance = errorResponse.getInstance();

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1562,6 +1562,7 @@ private boolean rerunWF(String workflowId, String taskId, Map<String, Object> ta
 
         // Get the workflow
         Workflow workflow = executionDAOFacade.getWorkflowById(workflowId, true);
+        updateAndPushParents(workflow, "reran");
 
         // If the task Id is null it implies that the entire workflow has to be rerun
         if (taskId == null) {

File: client/src/main/java/com/netflix/conductor/client/http/ClientBase.java
Patch:
@@ -123,7 +123,6 @@ private BulkResponse delete(Object[] queryParams, String url, Object[] uriVariab
         URI uri = null;
         try {
             uri = getURIBuilder(root + url, queryParams).build(uriVariables);
-            client.resource(uri).delete();
             if (body != null) {
                 return client.resource(uri).type(MediaType.APPLICATION_JSON_TYPE).delete(BulkResponse.class, body);
             } else {

File: core/src/main/java/com/netflix/conductor/core/config/ConductorCoreConfiguration.java
Patch:
@@ -16,6 +16,7 @@
 import com.netflix.conductor.common.metadata.tasks.TaskType;
 import com.netflix.conductor.common.utils.ExternalPayloadStorage;
 import com.netflix.conductor.core.events.EventQueueProvider;
+import com.netflix.conductor.core.execution.evaluators.Evaluator;
 import com.netflix.conductor.core.execution.mapper.TaskMapper;
 import com.netflix.conductor.core.execution.tasks.WorkflowSystemTask;
 import com.netflix.conductor.core.listener.WorkflowStatusListener;

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -394,8 +394,9 @@ List<Task> getNextTask(Workflow workflow, Task task) {
         final WorkflowDef workflowDef = workflow.getWorkflowDefinition();
 
         // Get the following task after the last completed task
-        if (systemTaskRegistry.isSystemTask(task.getTaskType()) && TaskType.TASK_TYPE_DECISION
-            .equals(task.getTaskType())) {
+        if (systemTaskRegistry.isSystemTask(task.getTaskType()) &&
+              (TaskType.TASK_TYPE_DECISION.equals(task.getTaskType()) ||
+                    TaskType.TASK_TYPE_SWITCH.equals(task.getTaskType()))) {
             if (task.getInputData().get("hasChildren") != null) {
                 return Collections.emptyList();
             }

File: test-harness/src/test/java/com/netflix/conductor/test/integration/AbstractEndToEndTest.java
Patch:
@@ -195,6 +195,8 @@ protected WorkflowTask createWorkflowTask(String name) {
         workflowTask.setDynamicForkTasksParam(DEFAULT_NULL_VALUE);
         workflowTask.setDynamicForkTasksInputParamName(DEFAULT_NULL_VALUE);
         workflowTask.setSink(DEFAULT_NULL_VALUE);
+        workflowTask.setEvaluatorType(DEFAULT_NULL_VALUE);
+        workflowTask.setExpression(DEFAULT_NULL_VALUE);
         return workflowTask;
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorker.java
Patch:
@@ -104,7 +104,7 @@ void pollAndExecute(WorkflowSystemTask systemTask, String queueName) {
             //Since already one slot is acquired, now try if maxSlot-1 is available
             int slotsToAcquire = Math.min(semaphoreUtil.availableSlots(), maxPollCount - 1);
 
-            // Try to acquires remaining permits to achieve maxPollCount
+            // Try to acquire remaining permits to achieve maxPollCount
             if (slotsToAcquire > 0 && semaphoreUtil.acquireSlots(slotsToAcquire)) {
                 acquiredSlots += slotsToAcquire;
             }

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestSystemTaskWorkerCoordinator.java
Patch:
@@ -28,7 +28,6 @@ public class TestSystemTaskWorkerCoordinator {
 
     private static final String TEST_QUEUE = "test";
     private static final String EXECUTION_NAMESPACE_CONSTANT = "@exeNS";
-    private static final String ISOLATION_CONSTANT = "-iso";
 
     private SystemTaskWorker systemTaskWorker;
     private ConductorProperties properties;

File: test-harness/src/test/java/com/netflix/conductor/test/integration/AbstractEndToEndTest.java
Patch:
@@ -18,6 +18,7 @@
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
 import org.apache.http.HttpHost;
+import org.elasticsearch.client.Request;
 import org.elasticsearch.client.Response;
 import org.elasticsearch.client.RestClient;
 import org.elasticsearch.client.RestClientBuilder;
@@ -82,7 +83,7 @@ public static void initializeEs() {
     @AfterClass
     public static void cleanupEs() throws Exception {
         // deletes all indices
-        Response beforeResponse = restClient.performRequest("GET", "/_cat/indices");
+        Response beforeResponse = restClient.performRequest(new Request("GET", "/_cat/indices"));
         Reader streamReader = new InputStreamReader(beforeResponse.getEntity().getContent());
         BufferedReader bufferedReader = new BufferedReader(streamReader);
 
@@ -91,7 +92,7 @@ public static void cleanupEs() throws Exception {
             String[] fields = line.split("\\s");
             String endpoint = String.format("/%s", fields[2]);
 
-            restClient.performRequest("DELETE", endpoint);
+            restClient.performRequest(new Request("DELETE", endpoint));
         }
 
         if (restClient != null) {

File: core/src/main/java/com/netflix/conductor/metrics/Monitors.java
Patch:
@@ -295,7 +295,7 @@ public static void recordDaoRequests(String dao, String action, String taskType,
     }
 
     public static void recordDaoEventRequests(String dao, String action, String event) {
-        counter(classQualifier, "dao_requests", "dao", dao, "action", action, "event", event);
+        counter(classQualifier, "dao_event_requests", "dao", dao, "action", action, "event", event);
     }
 
     public static void recordDaoPayloadSize(String dao, String action, int size) {

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -153,7 +153,7 @@ public List<Task> poll(String taskType, String workerId, String domain, int coun
                 }
                 task.setCallbackAfterSeconds(0);    // reset callbackAfterSeconds when giving the task to the worker
                 task.setWorkerId(workerId);
-                task.setPollCount(task.getPollCount() + 1);
+                task.incrementPollCount();
                 executionDAOFacade.updateTask(task);
                 tasks.add(task);
             } catch (Exception e) {

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -153,7 +153,7 @@ public List<Task> poll(String taskType, String workerId, String domain, int coun
                 }
                 task.setCallbackAfterSeconds(0);    // reset callbackAfterSeconds when giving the task to the worker
                 task.setWorkerId(workerId);
-                task.setPollCount(task.getPollCount() + 1);
+                task.incrementPollCount();
                 executionDAOFacade.updateTask(task);
                 tasks.add(task);
             } catch (Exception e) {

File: mysql-persistence/src/test/java/com/netflix/conductor/mysql/dao/MySQLExecutionDAOTest.java
Patch:
@@ -55,14 +55,12 @@ public class MySQLExecutionDAOTest extends ExecutionDAOTest {
     public void setup() {
         mySQLContainer = new MySQLContainer<>(DockerImageName.parse("mysql")).withDatabaseName(name.getMethodName());
         mySQLContainer.start();
-        testUtil = new MySQLDAOTestUtil(mySQLContainer, objectMapper, name.getMethodName());
+        testUtil = new MySQLDAOTestUtil(mySQLContainer, objectMapper);
         executionDAO = new MySQLExecutionDAO(testUtil.getObjectMapper(), testUtil.getDataSource());
-        testUtil.resetAllData();
     }
 
     @After
     public void teardown() {
-        testUtil.resetAllData();
         testUtil.getDataSource().close();
     }
 

File: mysql-persistence/src/test/java/com/netflix/conductor/mysql/dao/MySQLMetadataDAOTest.java
Patch:
@@ -71,14 +71,13 @@ public class MySQLMetadataDAOTest {
     public void setup() {
         mySQLContainer = new MySQLContainer<>(DockerImageName.parse("mysql")).withDatabaseName(name.getMethodName());
         mySQLContainer.start();
-        testUtil = new MySQLDAOTestUtil(mySQLContainer, objectMapper, name.getMethodName());
+        testUtil = new MySQLDAOTestUtil(mySQLContainer, objectMapper);
         metadataDAO = new MySQLMetadataDAO(testUtil.getObjectMapper(), testUtil.getDataSource(),
             testUtil.getTestProperties());
     }
 
     @After
     public void teardown() {
-        testUtil.resetAllData();
         testUtil.getDataSource().close();
     }
 

File: mysql-persistence/src/test/java/com/netflix/conductor/mysql/dao/MySQLQueueDAOTest.java
Patch:
@@ -70,13 +70,12 @@ public class MySQLQueueDAOTest {
     public void setup() {
         mySQLContainer = new MySQLContainer<>(DockerImageName.parse("mysql")).withDatabaseName(name.getMethodName());
         mySQLContainer.start();
-        testUtil = new MySQLDAOTestUtil(mySQLContainer, objectMapper, name.getMethodName());
+        testUtil = new MySQLDAOTestUtil(mySQLContainer, objectMapper);
         queueDAO = new MySQLQueueDAO(testUtil.getObjectMapper(), testUtil.getDataSource());
     }
 
     @After
     public void teardown() {
-        testUtil.resetAllData();
         testUtil.getDataSource().close();
     }
 

File: postgres-persistence/src/test/java/com/netflix/conductor/postgres/dao/PostgresExecutionDAOTest.java
Patch:
@@ -56,17 +56,15 @@ public void setup() {
         postgreSQLContainer =
             new PostgreSQLContainer<>(DockerImageName.parse("postgres")).withDatabaseName(name.getMethodName().toLowerCase());
         postgreSQLContainer.start();
-        testPostgres = new PostgresDAOTestUtil(postgreSQLContainer, objectMapper, name.getMethodName().toLowerCase());
+        testPostgres = new PostgresDAOTestUtil(postgreSQLContainer, objectMapper);
         executionDAO = new PostgresExecutionDAO(
             testPostgres.getObjectMapper(),
             testPostgres.getDataSource()
         );
-        testPostgres.resetAllData();
     }
 
     @After
     public void teardown() {
-        testPostgres.resetAllData();
         testPostgres.getDataSource().close();
     }
 

File: postgres-persistence/src/test/java/com/netflix/conductor/postgres/dao/PostgresMetadataDAOTest.java
Patch:
@@ -72,14 +72,13 @@ public void setup() {
         postgreSQLContainer =
             new PostgreSQLContainer<>(DockerImageName.parse("postgres")).withDatabaseName(name.getMethodName().toLowerCase());
         postgreSQLContainer.start();
-        testUtil = new PostgresDAOTestUtil(postgreSQLContainer, objectMapper, name.getMethodName().toLowerCase());
+        testUtil = new PostgresDAOTestUtil(postgreSQLContainer, objectMapper);
         metadataDAO = new PostgresMetadataDAO(testUtil.getObjectMapper(), testUtil.getDataSource(),
             testUtil.getTestProperties());
     }
 
     @After
     public void teardown() {
-        testUtil.resetAllData();
         testUtil.getDataSource().close();
     }
 

File: postgres-persistence/src/test/java/com/netflix/conductor/postgres/dao/PostgresQueueDAOTest.java
Patch:
@@ -71,13 +71,12 @@ public void setup() {
         postgreSQLContainer =
             new PostgreSQLContainer<>(DockerImageName.parse("postgres")).withDatabaseName(name.getMethodName().toLowerCase());
         postgreSQLContainer.start();
-        testUtil = new PostgresDAOTestUtil(postgreSQLContainer, objectMapper, name.getMethodName().toLowerCase());
+        testUtil = new PostgresDAOTestUtil(postgreSQLContainer, objectMapper);
         queueDAO = new PostgresQueueDAO(testUtil.getObjectMapper(), testUtil.getDataSource());
     }
 
     @After
     public void teardown() {
-        testUtil.resetAllData();
         testUtil.getDataSource().close();
     }
 

File: common/src/main/java/com/netflix/conductor/common/metadata/events/EventHandler.java
Patch:
@@ -16,6 +16,7 @@
 import com.github.vmg.protogen.annotations.ProtoField;
 import com.github.vmg.protogen.annotations.ProtoMessage;
 import com.google.protobuf.Any;
+import io.swagger.v3.oas.annotations.Hidden;
 
 import javax.validation.Valid;
 import javax.validation.constraints.NotEmpty;
@@ -232,6 +233,7 @@ public static class TaskDetails {
         private Map<String, Object> output = new HashMap<>();
 
         @ProtoField(id = 4)
+        @Hidden
         private Any outputMessage;
 
         @ProtoField(id = 5)
@@ -318,6 +320,7 @@ public static class StartWorkflow {
         private Map<String, Object> input = new HashMap<>();
 
         @ProtoField(id = 5)
+        @Hidden
         private Any inputMessage;
 
         @ProtoField(id = 6)

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -17,6 +17,7 @@
 import com.github.vmg.protogen.annotations.ProtoMessage;
 import com.google.protobuf.Any;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
+import io.swagger.v3.oas.annotations.Hidden;
 import org.apache.commons.lang3.StringUtils;
 
 import java.util.HashMap;
@@ -163,9 +164,11 @@ public boolean isRetriable() {
     private String domain;
 
     @ProtoField(id = 29)
+    @Hidden
     private Any inputMessage;
 
     @ProtoField(id = 30)
+    @Hidden
     private Any outputMessage;
 
     // id 31 is reserved

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1228,7 +1228,7 @@ List<String> cancelNonTerminalTasks(Workflow workflow) {
                     } catch (Exception e) {
                         erroredTasks.add(task.getReferenceTaskName());
                         LOGGER.error("Error canceling system task:{}/{} in workflow: {}",
-                                workflowSystemTask.getName(), task.getTaskId(), workflow.getWorkflowId(), e);
+                                workflowSystemTask.getTaskType(), task.getTaskId(), workflow.getWorkflowId(), e);
                     }
                 }
                 executionDAOFacade.updateTask(task);
@@ -1394,7 +1394,7 @@ public void executeSystemTask(WorkflowSystemTask systemTask, String taskId, long
             }
 
             if (workflow.getStatus().isTerminal()) {
-                LOGGER.info("Workflow {} has been completed for {}/{}", workflow.getWorkflowId(), systemTask.getName(),
+                LOGGER.info("Workflow {} has been completed for {}/{}", workflow.getWorkflowId(), systemTask.getTaskType(),
                         task.getTaskId());
                 if (!task.getStatus().isTerminal()) {
                     task.setStatus(CANCELED);

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskRegistry.java
Patch:
@@ -33,7 +33,7 @@ public class SystemTaskRegistry {
     private final Map<String, WorkflowSystemTask> registry;
 
     public SystemTaskRegistry(Set<WorkflowSystemTask> tasks) {
-        this.registry = tasks.stream().collect(Collectors.toMap(WorkflowSystemTask::getName, Function.identity()));
+        this.registry = tasks.stream().collect(Collectors.toMap(WorkflowSystemTask::getTaskType, Function.identity()));
     }
 
     public WorkflowSystemTask get(String taskType) {

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestSystemTaskWorkerCoordinator.java
Patch:
@@ -76,7 +76,7 @@ public void testIsFromCoordinatorExecutionNameSpace() {
 
     private void createTaskMapping() {
         WorkflowSystemTask mockWorkflowTask = mock(WorkflowSystemTask.class);
-        when(mockWorkflowTask.getName()).thenReturn(TEST_QUEUE);
+        when(mockWorkflowTask.getTaskType()).thenReturn(TEST_QUEUE);
         when(mockWorkflowTask.isAsync()).thenReturn(true);
         SystemTaskWorkerCoordinator.taskNameWorkflowTaskMapping.put(TEST_QUEUE, mockWorkflowTask);
     }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/WorkflowSystemTask.java
Patch:
@@ -19,7 +19,7 @@
 
 import java.util.Optional;
 
-public class WorkflowSystemTask {
+public abstract class WorkflowSystemTask {
 
     private final String name;
 

File: core/src/main/java/com/netflix/conductor/core/utils/ParametersUtils.java
Patch:
@@ -45,8 +45,7 @@ public class ParametersUtils {
     private static final Logger LOGGER = LoggerFactory.getLogger(ParametersUtils.class);
 
     private final ObjectMapper objectMapper;
-    private final TypeReference<Map<String, Object>> map = new TypeReference<Map<String, Object>>() {
-    };
+    private final TypeReference<Map<String, Object>> map = new TypeReference<Map<String, Object>>() {};
 
     public ParametersUtils(ObjectMapper objectMapper) {
         this.objectMapper = objectMapper;

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -71,6 +71,7 @@
 import static com.netflix.conductor.common.metadata.tasks.TaskType.JOIN;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.SIMPLE;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.SUB_WORKFLOW;
+import static com.netflix.conductor.common.metadata.tasks.TaskType.TASK_TYPE_DECISION;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.TASK_TYPE_FORK;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.TASK_TYPE_JOIN;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.USER_DEFINED;
@@ -99,12 +100,12 @@ public class TestDeciderOutcomes {
     @Configuration
     public static class TestConfiguration {
 
-        @Bean(Decision.NAME)
+        @Bean(TASK_TYPE_DECISION)
         public Decision decision() {
             return new Decision();
         }
 
-        @Bean(Join.NAME)
+        @Bean(TASK_TYPE_JOIN)
         public Join join() {
             return new Join();
         }

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -40,7 +40,6 @@
 import com.netflix.conductor.core.execution.mapper.UserDefinedTaskMapper;
 import com.netflix.conductor.core.execution.mapper.WaitTaskMapper;
 import com.netflix.conductor.core.execution.tasks.SystemTaskRegistry;
-import com.netflix.conductor.core.execution.tasks.Terminate;
 import com.netflix.conductor.core.utils.ExternalPayloadStorageUtils;
 import com.netflix.conductor.core.utils.ParametersUtils;
 import com.netflix.conductor.dao.MetadataDAO;
@@ -83,6 +82,7 @@
 import static com.netflix.conductor.common.metadata.tasks.TaskType.JOIN;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.SIMPLE;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.SUB_WORKFLOW;
+import static com.netflix.conductor.common.metadata.tasks.TaskType.TASK_TYPE_TERMINATE;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.USER_DEFINED;
 import static com.netflix.conductor.common.metadata.tasks.TaskType.WAIT;
 import static org.junit.Assert.assertEquals;
@@ -1053,9 +1053,9 @@ public void testUpdateWorkflowOutput_WhenDefinitionHasOutputParameters() {
     public void testUpdateWorkflowOutput_WhenWorkflowHasTerminateTask() {
         Workflow workflow = new Workflow();
         Task task = new Task();
-        task.setTaskType(Terminate.NAME);
+        task.setTaskType(TASK_TYPE_TERMINATE);
         task.setStatus(Status.COMPLETED);
-        task.setOutputData(new HashMap() {{
+        task.setOutputData(new HashMap<String, Object>() {{
             put("taskKey", "taskValue");
         }});
         workflow.getTasks().add(task);

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -116,7 +116,7 @@ public class WorkflowExecutor {
     private final Predicate<PollData> validateLastPolledTime = pollData ->
             pollData.getLastPollTime() > System.currentTimeMillis() - activeWorkerLastPollMs;
 
-    private static final Predicate<Task> SYSTEM_TASK = task -> SystemTaskType.is(task.getTaskType());
+    private static final Predicate<Task> SYSTEM_TASK = task -> WorkflowSystemTask.is(task.getTaskType());
 
     private static final Predicate<Task> NON_TERMINAL_TASK = task -> !task.getStatus().isTerminal();
 

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/amqp/config/AMQPEventQueueProvider.java
Patch:
@@ -16,11 +16,10 @@
 import com.netflix.conductor.contribs.queue.amqp.AMQPObservableQueue.Builder;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 /**
  * @author Ritu Parathody

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/nats/config/NATSStreamEventQueueProvider.java
Patch:
@@ -15,13 +15,12 @@
 import com.netflix.conductor.contribs.queue.nats.NATSStreamObservableQueue;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import rx.Scheduler;
 
-import java.util.Map;
-import java.util.concurrent.ConcurrentHashMap;
-
 /**
  * @author Oleksiy Lysak
  */

File: core/src/main/java/com/netflix/conductor/core/LifecycleAwareComponent.java
Patch:
@@ -19,6 +19,7 @@
 import org.springframework.context.SmartLifecycle;
 
 public abstract class LifecycleAwareComponent implements SmartLifecycle {
+
     private volatile boolean running = false;
 
     private static final Logger LOGGER = LoggerFactory.getLogger(LifecycleAwareComponent.class);

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorkerCoordinator.java
Patch:
@@ -40,7 +40,7 @@
 
 @SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Component
-@ConditionalOnProperty(name="conductor.system-task-workers.enabled", havingValue = "true", matchIfMissing = true)
+@ConditionalOnProperty(name = "conductor.system-task-workers.enabled", havingValue = "true", matchIfMissing = true)
 public class SystemTaskWorkerCoordinator extends LifecycleAwareComponent {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(SystemTaskWorkerCoordinator.class);
@@ -117,7 +117,7 @@ private void listen(String queueName) {
     }
 
     private void pollAndExecute(String queueName) {
-        if (isRunning()) {
+        if (!isRunning()) {
             LOGGER.debug("Component stopped. Not polling for system task in queue : {}", queueName);
             return;
         }

File: test-harness/src/test/java/com/netflix/conductor/test/utils/MockExternalPayloadStorage.java
Patch:
@@ -116,6 +116,7 @@ private Map<String, Object> getPayload(String path) {
                 case INITIAL_WORKFLOW_INPUT_PATH:
                     stringObjectMap.put("param1", "p1 value");
                     stringObjectMap.put("param2", "p2 value");
+                    stringObjectMap.put("case", "two");
                     return stringObjectMap;
                 case TASK_OUTPUT_PATH:
                     InputStream opStream = MockExternalPayloadStorage.class.getResourceAsStream("/output.json");

File: test-harness/src/test/java/com/netflix/conductor/test/utils/MockExternalPayloadStorage.java
Patch:
@@ -116,6 +116,7 @@ private Map<String, Object> getPayload(String path) {
                 case INITIAL_WORKFLOW_INPUT_PATH:
                     stringObjectMap.put("param1", "p1 value");
                     stringObjectMap.put("param2", "p2 value");
+                    stringObjectMap.put("case", "two");
                     return stringObjectMap;
                 case TASK_OUTPUT_PATH:
                     InputStream opStream = MockExternalPayloadStorage.class.getResourceAsStream("/output.json");

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -620,6 +620,7 @@ public WorkflowTask next(String taskReferenceName, WorkflowTask parent) {
                 }
                 break;
             case DYNAMIC:
+            case TERMINATE:
             case SIMPLE:
                 return null;
             default:

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -620,6 +620,7 @@ public WorkflowTask next(String taskReferenceName, WorkflowTask parent) {
                 }
                 break;
             case DYNAMIC:
+            case TERMINATE:
             case SIMPLE:
                 return null;
             default:

File: es6-persistence/src/main/java/com/netflix/conductor/es6/config/ElasticSearchProperties.java
Patch:
@@ -14,6 +14,7 @@
 
 import com.google.common.annotations.VisibleForTesting;
 import org.springframework.beans.factory.annotation.Value;
+import org.springframework.context.annotation.Conditional;
 import org.springframework.stereotype.Component;
 
 import java.net.URI;
@@ -22,6 +23,7 @@
 import java.util.stream.Collectors;
 
 @Component
+@Conditional(ElasticSearchConditions.ElasticSearchV6Enabled.class)
 public class ElasticSearchProperties {
 
     @Value("${workflow.elasticsearch.url:localhost:9300}")

File: es6-persistence/src/main/java/com/netflix/conductor/es6/config/ElasticSearchV6Configuration.java
Patch:
@@ -35,7 +35,6 @@
 import java.util.List;
 import java.util.Optional;
 
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Configuration(proxyBeanMethods = false)
 @Conditional(ElasticSearchConditions.ElasticSearchV6Enabled.class)
 public class ElasticSearchV6Configuration {

File: redis-persistence/src/main/java/com/netflix/conductor/redis/config/DynomiteClusterConfiguration.java
Patch:
@@ -20,7 +20,6 @@
 import org.springframework.context.annotation.Configuration;
 import redis.clients.jedis.commands.JedisCommands;
 
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Configuration(proxyBeanMethods = false)
 @ConditionalOnProperty(name = "db", havingValue = "dynomite")
 public class DynomiteClusterConfiguration extends JedisCommandsConfigurer {

File: redis-persistence/src/main/java/com/netflix/conductor/redis/config/RedisClusterConfiguration.java
Patch:
@@ -22,7 +22,6 @@
 import redis.clients.jedis.HostAndPort;
 import redis.clients.jedis.commands.JedisCommands;
 
-@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
 @Configuration(proxyBeanMethods = false)
 @ConditionalOnProperty(name = "db", havingValue = "redis_cluster")
 public class RedisClusterConfiguration extends JedisCommandsConfigurer {

File: redis-persistence/src/main/java/com/netflix/conductor/redis/dynoqueue/LocalhostHostSupplier.java
Patch:
@@ -38,5 +38,4 @@ public List<Host> getHosts() {
                 .createHost();
         return Lists.newArrayList(dynoHost);
     }
-
 }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/IsolatedTaskQueueProducer.java
Patch:
@@ -79,7 +79,7 @@ void addTaskQueues() {
 		for (TaskDef isolatedTaskDef : isolationTaskDefs) {
 			for (String taskType : taskTypes) {
 				String taskQueue = QueueUtils.getQueueName(taskType, null,
-					isolatedTaskDef.getExecutionNameSpace(), isolatedTaskDef.getIsolationGroupId());
+					isolatedTaskDef.getIsolationGroupId(), isolatedTaskDef.getExecutionNameSpace());
 				logger.debug("Adding taskQueue:'{}' to system task worker coordinator", taskQueue);
 				SystemTaskWorkerCoordinator.queue.add(taskQueue);
 			}

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/IsolatedTaskQueueProducer.java
Patch:
@@ -79,7 +79,7 @@ void addTaskQueues() {
 		for (TaskDef isolatedTaskDef : isolationTaskDefs) {
 			for (String taskType : taskTypes) {
 				String taskQueue = QueueUtils.getQueueName(taskType, null,
-					isolatedTaskDef.getExecutionNameSpace(), isolatedTaskDef.getIsolationGroupId());
+					isolatedTaskDef.getIsolationGroupId(), isolatedTaskDef.getExecutionNameSpace());
 				logger.debug("Adding taskQueue:'{}' to system task worker coordinator", taskQueue);
 				SystemTaskWorkerCoordinator.queue.add(taskQueue);
 			}

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1638,6 +1638,7 @@ private boolean rerunWF(String workflowId, String taskId, Map<String, Object> ta
     public void scheduleNextIteration(Task loopTask, Workflow workflow) {
         //Schedule only first loop over task. Rest will be taken care in Decider Service when this task will get completed.
         List<Task> scheduledLoopOverTasks = deciderService.getTasksToBeScheduled(workflow, loopTask.getWorkflowTask().getLoopOver().get(0), loopTask.getRetryCount(), null);
+        setTaskDomains(scheduledLoopOverTasks, workflow);
         scheduledLoopOverTasks.stream().forEach(t -> {
             t.setReferenceTaskName(TaskUtils.appendIteration(t.getReferenceTaskName(), loopTask.getIteration()));
             t.setIteration(loopTask.getIteration());

File: common/src/main/java/com/netflix/conductor/common/constraints/TaskReferenceNameUniqueConstraint.java
Patch:
@@ -64,7 +64,7 @@ public boolean isValid(WorkflowDef workflowDef, ConstraintValidatorContext conte
 
             //check if taskReferenceNames are unique across tasks or not
             HashMap<String, Integer> taskReferenceMap = new HashMap<>();
-            for (WorkflowTask workflowTask : workflowDef.getTasks()) {
+            for (WorkflowTask workflowTask : workflowDef.collectTasks()) {
                 if (taskReferenceMap.containsKey(workflowTask.getTaskReferenceName())) {
                     String message = String.format("taskReferenceName: %s should be unique across tasks for a given workflowDefinition: %s",
                             workflowTask.getTaskReferenceName(), workflowDef.getName());

File: common/src/main/java/com/netflix/conductor/common/constraints/TaskReferenceNameUniqueConstraint.java
Patch:
@@ -64,7 +64,7 @@ public boolean isValid(WorkflowDef workflowDef, ConstraintValidatorContext conte
 
             //check if taskReferenceNames are unique across tasks or not
             HashMap<String, Integer> taskReferenceMap = new HashMap<>();
-            for (WorkflowTask workflowTask : workflowDef.getTasks()) {
+            for (WorkflowTask workflowTask : workflowDef.collectTasks()) {
                 if (taskReferenceMap.containsKey(workflowTask.getTaskReferenceName())) {
                     String message = String.format("taskReferenceName: %s should be unique across tasks for a given workflowDefinition: %s",
                             workflowTask.getTaskReferenceName(), workflowDef.getName());

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLQueueDAO.java
Patch:
@@ -160,13 +160,13 @@ public void processAllUnacks() {
         logger.trace("processAllUnacks started");
 
 
-        final String PROCESS_ALL_UNACKS = "UPDATE queue_message SET popped = false WHERE popped = true AND TIMESTAMPADD(SECOND,60,CURRENT_TIMESTAMP) > deliver_on";
+        final String PROCESS_ALL_UNACKS = "UPDATE queue_message SET popped = false WHERE popped = true AND TIMESTAMPADD(SECOND,-60,CURRENT_TIMESTAMP) > deliver_on";
         executeWithTransaction(PROCESS_ALL_UNACKS, Query::executeUpdate);
     }
 
     @Override
     public void processUnacks(String queueName) {
-        final String PROCESS_UNACKS = "UPDATE queue_message SET popped = false WHERE queue_name = ? AND popped = true AND TIMESTAMPADD(SECOND,60,CURRENT_TIMESTAMP)  > deliver_on";
+        final String PROCESS_UNACKS = "UPDATE queue_message SET popped = false WHERE queue_name = ? AND popped = true AND TIMESTAMPADD(SECOND,-60,CURRENT_TIMESTAMP)  > deliver_on";
         executeWithTransaction(PROCESS_UNACKS, q -> q.addParameter(queueName).executeUpdate());
     }
 

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLQueueDAOTest.java
Patch:
@@ -329,14 +329,14 @@ public void processUnacksTest() {
 		Map<String, Map<String, Map<String, Long>>> details = dao.queuesDetailVerbose();
 		uacked = details.get(queueName).get("a").get("uacked");
 		assertNotNull(uacked);
-		assertEquals("There should be no unacked messages", uacked.longValue(), 0);
+		assertEquals("The messages that were polled should be unacked still", uacked.longValue(), unackedCount - 1);
 
 		Long otherUacked = details.get(otherQueueName).get("a").get("uacked");
 		assertNotNull(otherUacked);
-		assertEquals("Other queue should have unacked messages", otherUacked.longValue(), count);
+		assertEquals("Other queue should have all unacked messages", otherUacked.longValue(), count);
 
 		Long size = dao.queuesDetail().get(queueName);
 		assertNotNull(size);
-		assertEquals(size.longValue(), count - 1);
+		assertEquals(size.longValue(), count - unackedCount);
 	}
 }

File: postgres-persistence/src/main/java/com/netflix/conductor/dao/postgres/PostgresQueueDAO.java
Patch:
@@ -171,13 +171,13 @@ public void processAllUnacks() {
 
         logger.trace("processAllUnacks started");
 
-        final String PROCESS_ALL_UNACKS = "UPDATE queue_message SET popped = false WHERE popped = true AND (current_timestamp + (60 ||' seconds')::interval) > deliver_on";
+        final String PROCESS_ALL_UNACKS = "UPDATE queue_message SET popped = false WHERE popped = true AND (current_timestamp - (60 ||' seconds')::interval) > deliver_on";
         executeWithTransaction(PROCESS_ALL_UNACKS, Query::executeUpdate);
     }
 
     @Override
     public void processUnacks(String queueName) {
-        final String PROCESS_UNACKS = "UPDATE queue_message SET popped = false WHERE queue_name = ? AND popped = true AND (current_timestamp + (60 ||' seconds')::interval)  > deliver_on";
+        final String PROCESS_UNACKS = "UPDATE queue_message SET popped = false WHERE queue_name = ? AND popped = true AND (current_timestamp - (60 ||' seconds')::interval)  > deliver_on";
         executeWithTransaction(PROCESS_UNACKS, q -> q.addParameter(queueName).executeUpdate());
     }
 

File: postgres-persistence/src/test/java/com/netflix/conductor/dao/postgres/PostgresQueueDAOTest.java
Patch:
@@ -341,14 +341,14 @@ public void processUnacksTest() {
 		Map<String, Map<String, Map<String, Long>>> details = dao.queuesDetailVerbose();
 		uacked = details.get(queueName).get("a").get("uacked");
 		assertNotNull(uacked);
-		assertEquals("There should be no unacked messages", uacked.longValue(), 0);
+		assertEquals("The messages that were polled should be unacked still", uacked.longValue(), unackedCount - 1);
 
 		Long otherUacked = details.get(otherQueueName).get("a").get("uacked");
 		assertNotNull(otherUacked);
-		assertEquals("Other queue should have unacked messages", otherUacked.longValue(), count);
+		assertEquals("Other queue should have all unacked messages", otherUacked.longValue(), count);
 
 		Long size = dao.queuesDetail().get(queueName);
 		assertNotNull(size);
-		assertEquals(size.longValue(), count - 1);
+		assertEquals(size.longValue(), count - unackedCount);
 	}
 }

File: server/src/main/java/com/netflix/conductor/bootstrap/BootstrapModule.java
Patch:
@@ -8,6 +8,5 @@ public class BootstrapModule extends AbstractModule {
     @Override
     protected void configure() {
         bind(Configuration.class).to(SystemPropertiesConfiguration.class);
-        bind(ModulesProvider.class);
     }
 }

File: server/src/main/java/com/netflix/conductor/server/ServerModule.java
Patch:
@@ -20,6 +20,7 @@
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.CoreModule;
 import com.netflix.conductor.core.config.EventModule;
+import com.netflix.conductor.core.config.SystemPropertiesConfiguration;
 import com.netflix.conductor.core.config.ValidationModule;
 import com.netflix.conductor.core.execution.WorkflowSweeper;
 import com.netflix.conductor.dyno.SystemPropertiesDynomiteConfiguration;
@@ -48,7 +49,7 @@ protected void configure() {
         install(new EventModule());
 
         bindInterceptor(Matchers.any(), Matchers.annotatedWith(Service.class), new ServiceInterceptor(getProvider(Validator.class)));
-        bind(Configuration.class).to(SystemPropertiesDynomiteConfiguration.class);
+        bind(Configuration.class).to(SystemPropertiesConfiguration.class).in(Scopes.SINGLETON);
         bind(ExecutorService.class).toProvider(ExecutorServiceProvider.class).in(Scopes.SINGLETON);
         bind(WorkflowSweeper.class).asEagerSingleton();
         bind(WorkflowMonitor.class).asEagerSingleton();

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -375,7 +375,7 @@ public String startWorkflow(
         Workflow workflow = new Workflow();
         workflow.setWorkflowId(workflowId);
         workflow.setCorrelationId(correlationId);
-        workflow.setPriority(priority);
+        workflow.setPriority(priority == null ? 0 : priority);
         workflow.setWorkflowDefinition(workflowDefinition);
         workflow.setStatus(WorkflowStatus.RUNNING);
         workflow.setParentWorkflowId(parentWorkflowId);
@@ -1555,7 +1555,7 @@ private boolean rerunWF(String workflowId, String taskId, Map<String, Object> ta
         }
 
         // If not found look into sub workflows
-        if(rerunFromTask == null) { 
+        if(rerunFromTask == null) {
 	        for (Task task : workflow.getTasks()) {
                 if (task.getTaskType().equalsIgnoreCase(SubWorkflow.NAME)) {
                     String subWorkflowId = task.getSubWorkflowId();

File: client/src/main/java/com/netflix/conductor/client/automator/TaskPollExecutor.java
Patch:
@@ -66,11 +66,9 @@ class TaskPollExecutor {
 
         LOGGER.info("Initialized the TaskPollExecutor with {} threads", threadCount);
 
-        AtomicInteger count = new AtomicInteger(0);
-
         this.executorService = Executors.newFixedThreadPool(threadCount,
             new BasicThreadFactory.Builder()
-                .namingPattern(workerNamePrefix + count.getAndIncrement())
+                .namingPattern(workerNamePrefix)
                 .uncaughtExceptionHandler(uncaughtExceptionHandler)
                 .build());
 

File: client/src/main/java/com/netflix/conductor/client/automator/TaskRunnerConfigurer.java
Patch:
@@ -66,7 +66,7 @@ private TaskRunnerConfigurer(Builder builder) {
      */
     public static class Builder {
 
-        private String workerNamePrefix = "workflow-worker-";
+        private String workerNamePrefix = "workflow-worker-%d";
         private int sleepWhenRetry = 500;
         private int updateRetryCount = 3;
         private int threadCount = -1;

File: client/src/test/java/com/netflix/conductor/client/automator/TaskPollExecutorTest.java
Patch:
@@ -52,13 +52,13 @@ public void testTaskExecutionException() {
             throw new NoSuchMethodError();
         });
         TaskClient taskClient = Mockito.mock(TaskClient.class);
-        TaskPollExecutor taskPollExecutor = new TaskPollExecutor(null, taskClient, 1, 1, new HashMap<>(), "test-worker-");
+        TaskPollExecutor taskPollExecutor = new TaskPollExecutor(null, taskClient, 1, 1, new HashMap<>(), "test-worker-%d");
 
         when(taskClient.pollTask(any(), any(), any())).thenReturn(testTask());
         when(taskClient.ack(any(), any())).thenReturn(true);
         CountDownLatch latch = new CountDownLatch(1);
         doAnswer(invocation -> {
-                assertEquals("test-worker-0", Thread.currentThread().getName());
+                assertEquals("test-worker-1", Thread.currentThread().getName());
                 Object[] args = invocation.getArguments();
                 TaskResult result = (TaskResult) args[0];
                 assertEquals(TaskResult.Status.FAILED, result.getStatus());

File: client/src/main/java/com/netflix/conductor/client/automator/TaskPollExecutor.java
Patch:
@@ -66,11 +66,9 @@ class TaskPollExecutor {
 
         LOGGER.info("Initialized the TaskPollExecutor with {} threads", threadCount);
 
-        AtomicInteger count = new AtomicInteger(0);
-
         this.executorService = Executors.newFixedThreadPool(threadCount,
             new BasicThreadFactory.Builder()
-                .namingPattern(workerNamePrefix + count.getAndIncrement())
+                .namingPattern(workerNamePrefix)
                 .uncaughtExceptionHandler(uncaughtExceptionHandler)
                 .build());
 

File: client/src/main/java/com/netflix/conductor/client/automator/TaskRunnerConfigurer.java
Patch:
@@ -66,7 +66,7 @@ private TaskRunnerConfigurer(Builder builder) {
      */
     public static class Builder {
 
-        private String workerNamePrefix = "workflow-worker-";
+        private String workerNamePrefix = "workflow-worker-%d";
         private int sleepWhenRetry = 500;
         private int updateRetryCount = 3;
         private int threadCount = -1;

File: client/src/test/java/com/netflix/conductor/client/automator/TaskPollExecutorTest.java
Patch:
@@ -52,13 +52,13 @@ public void testTaskExecutionException() {
             throw new NoSuchMethodError();
         });
         TaskClient taskClient = Mockito.mock(TaskClient.class);
-        TaskPollExecutor taskPollExecutor = new TaskPollExecutor(null, taskClient, 1, 1, new HashMap<>(), "test-worker-");
+        TaskPollExecutor taskPollExecutor = new TaskPollExecutor(null, taskClient, 1, 1, new HashMap<>(), "test-worker-%d");
 
         when(taskClient.pollTask(any(), any(), any())).thenReturn(testTask());
         when(taskClient.ack(any(), any())).thenReturn(true);
         CountDownLatch latch = new CountDownLatch(1);
         doAnswer(invocation -> {
-                assertEquals("test-worker-0", Thread.currentThread().getName());
+                assertEquals("test-worker-1", Thread.currentThread().getName());
                 Object[] args = invocation.getArguments();
                 TaskResult result = (TaskResult) args[0];
                 assertEquals(TaskResult.Status.FAILED, result.getStatus());

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/StartWorkflowRequest.java
Patch:
@@ -50,7 +50,7 @@ public class StartWorkflowRequest {
 	@ProtoField(id = 8)
 	@Min(value = 0, message = "priority: ${validatedValue} should be minimum {value}")
 	@Max(value = 99, message = "priority: ${validatedValue} should be maximum {value}")
-	private Integer priority;
+	private Integer priority = 0;
 
     public String getName() {
 		return name;

File: core/src/main/java/com/netflix/conductor/service/WorkflowServiceImpl.java
Patch:
@@ -73,8 +73,9 @@ public WorkflowServiceImpl(WorkflowExecutor workflowExecutor, ExecutionService e
      */
     @Service
     public String startWorkflow(StartWorkflowRequest startWorkflowRequest) {
-        return startWorkflow(startWorkflowRequest.getName(), startWorkflowRequest.getVersion(), startWorkflowRequest.getCorrelationId(), startWorkflowRequest.getInput(),
-                startWorkflowRequest.getExternalInputPayloadStoragePath(), startWorkflowRequest.getTaskToDomain(), startWorkflowRequest.getWorkflowDef());
+        return startWorkflow(startWorkflowRequest.getName(), startWorkflowRequest.getVersion(), startWorkflowRequest.getCorrelationId(),
+            startWorkflowRequest.getPriority(), startWorkflowRequest.getInput(), startWorkflowRequest.getExternalInputPayloadStoragePath(),
+            startWorkflowRequest.getTaskToDomain(), startWorkflowRequest.getWorkflowDef());
     }
 
     /**

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/service/WorkflowServiceImpl.java
Patch:
@@ -62,6 +62,7 @@ public void startWorkflow(StartWorkflowRequestPb.StartWorkflowRequest pbRequest,
         try {
             String id = workflowService.startWorkflow(pbRequest.getName(),
                     GRPC_HELPER.optional(request.getVersion()),request.getCorrelationId(),
+                    request.getPriority(),
                     request.getInput(),
                     request.getExternalInputPayloadStoragePath(),
                     request.getTaskToDomain(), request.getWorkflowDef());

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/StartWorkflowRequest.java
Patch:
@@ -50,7 +50,7 @@ public class StartWorkflowRequest {
 	@ProtoField(id = 8)
 	@Min(value = 0, message = "priority: ${validatedValue} should be minimum {value}")
 	@Max(value = 99, message = "priority: ${validatedValue} should be maximum {value}")
-	private Integer priority;
+	private Integer priority = 0;
 
     public String getName() {
 		return name;

File: core/src/main/java/com/netflix/conductor/service/WorkflowServiceImpl.java
Patch:
@@ -73,8 +73,9 @@ public WorkflowServiceImpl(WorkflowExecutor workflowExecutor, ExecutionService e
      */
     @Service
     public String startWorkflow(StartWorkflowRequest startWorkflowRequest) {
-        return startWorkflow(startWorkflowRequest.getName(), startWorkflowRequest.getVersion(), startWorkflowRequest.getCorrelationId(), startWorkflowRequest.getInput(),
-                startWorkflowRequest.getExternalInputPayloadStoragePath(), startWorkflowRequest.getTaskToDomain(), startWorkflowRequest.getWorkflowDef());
+        return startWorkflow(startWorkflowRequest.getName(), startWorkflowRequest.getVersion(), startWorkflowRequest.getCorrelationId(),
+            startWorkflowRequest.getPriority(), startWorkflowRequest.getInput(), startWorkflowRequest.getExternalInputPayloadStoragePath(),
+            startWorkflowRequest.getTaskToDomain(), startWorkflowRequest.getWorkflowDef());
     }
 
     /**

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/service/WorkflowServiceImpl.java
Patch:
@@ -62,6 +62,7 @@ public void startWorkflow(StartWorkflowRequestPb.StartWorkflowRequest pbRequest,
         try {
             String id = workflowService.startWorkflow(pbRequest.getName(),
                     GRPC_HELPER.optional(request.getVersion()),request.getCorrelationId(),
+                    request.getPriority(),
                     request.getInput(),
                     request.getExternalInputPayloadStoragePath(),
                     request.getTaskToDomain(), request.getWorkflowDef());

File: postgres-persistence/src/main/java/com/netflix/conductor/dao/postgres/PostgresMetadataDAO.java
Patch:
@@ -349,6 +349,7 @@ private Optional<Integer> getLatestVersion(Connection tx, String name) {
      * Update the latest version for the workflow with name {@code WorkflowDef} to the version provided in {@literal version}.
      *
      * @param tx  The {@link Connection} to use for queries.
+     * @param name Workflow def name to update
      * @param version The new latest {@code version} value.
      */
     private void updateLatestVersion(Connection tx, String name, int version) {

File: core/src/main/java/com/netflix/conductor/core/events/queue/dyno/DynoObservableQueue.java
Patch:
@@ -77,7 +77,7 @@ public Observable<Message> observe() {
     @Override
     public List<String> ack(List<Message> messages) {
         for (Message msg : messages) {
-            queueDAO.remove(queueName, msg.getId());
+            queueDAO.ack(queueName, msg.getId());
         }
         return messages.stream().map(Message::getId).collect(Collectors.toList());
     }

File: common/src/test/java/com/netflix/conductor/common/workflow/SubWorkflowParamsTest.java
Patch:
@@ -107,6 +107,7 @@ public void testWorkflowDefJson() throws Exception {
             "    } ],\n" +
             "    \"timeoutPolicy\" : \"ALERT_ONLY\",\n" +
             "    \"timeoutSeconds\" : 0,\n" +
+            "    \"variables\" : { },\n" +
             "    \"version\" : 1,\n" +
             "    \"workflowStatusListenerEnabled\" : false\n" +
             "  }\n" +

File: core/src/main/java/com/netflix/conductor/core/execution/ParametersUtils.java
Patch:
@@ -88,6 +88,7 @@ public Map<String, Object> getTaskInputV2(Map<String, Object> input, Workflow wo
         workflowParams.put("correlationId", workflow.getCorrelationId());
         workflowParams.put("reasonForIncompletion", workflow.getReasonForIncompletion());
         workflowParams.put("schemaVersion", workflow.getSchemaVersion());
+        workflowParams.put("variables", workflow.getVariables());
 
         inputMap.put("workflow", workflowParams);
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -386,6 +386,7 @@ public String startWorkflow(
         workflow.setUpdateTime(null);
         workflow.setEvent(event);
         workflow.setTaskToDomain(taskToDomain);
+        workflow.setVariables(workflowDefinition.getVariables());
 
         workflow.setInput(workflowInput);
         if (workflow.getInput() != null) {

File: core/src/main/java/com/netflix/conductor/core/utils/ExternalPayloadStorageUtils.java
Patch:
@@ -123,10 +123,10 @@ public <T> void verifyAndUpload(T entity, PayloadType payloadType) {
 
             if (payloadSize > maxThreshold * 1024) {
                 if (entity instanceof Task) {
-                    String errorMsg = String.format("The payload size: %dKB of task: %s in workflow: %s  is greater than the permissible limit: %dKB", payloadSize, ((Task) entity).getTaskId(), ((Task) entity).getWorkflowInstanceId(), maxThreshold);
+                    String errorMsg = String.format("The payload size: %dB of task: %s in workflow: %s  is greater than the permissible limit: %dKB", payloadSize, ((Task) entity).getTaskId(), ((Task) entity).getWorkflowInstanceId(), maxThreshold);
                     failTask(((Task) entity), payloadType, errorMsg);
                 } else {
-                    String errorMsg = String.format("The output payload size: %dKB of workflow: %s is greater than the permissible limit: %dKB", payloadSize, ((Workflow) entity).getWorkflowId(), maxThreshold);
+                    String errorMsg = String.format("The output payload size: %dB of workflow: %s is greater than the permissible limit: %dKB", payloadSize, ((Workflow) entity).getWorkflowId(), maxThreshold);
                     failWorkflow(errorMsg);
                 }
             } else if (payloadSize > threshold * 1024) {

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/TaskType.java
Patch:
@@ -20,7 +20,8 @@ public enum TaskType {
     LAMBDA(true),
     EXCLUSIVE_JOIN(true),
     TERMINATE(true),
-    KAFKA_PUBLISH(true);
+    KAFKA_PUBLISH(true),
+    JSON_JQ_TRANSFORM(true);
 
     /**
      * TaskType constants representing each of the possible enumeration values.
@@ -43,6 +44,7 @@ public enum TaskType {
     public static final String TASK_TYPE_EXCLUSIVE_JOIN = "EXCLUSIVE_JOIN";
     public static final String TASK_TYPE_TERMINATE = "TERMINATE";
     public static final String TASK_TYPE_KAFKA_PUBLISH = "KAFKA_PUBLISH";
+    public static final String TASK_TYPE_JSON_JQ_TRANSFORM = "JSON_JQ_TRANSFORM";
     
     private boolean isSystemTask;
 

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -46,7 +46,7 @@ public class DecisionTaskMapper implements TaskMapper {
     private static final Logger logger = LoggerFactory.getLogger(DecisionTaskMapper.class);
 
     /**
-     * This method gets the list of tasks that need to scheduled when the the task to scheduled is of type {@link TaskType#DECISION}.
+     * This method gets the list of tasks that need to scheduled when the task to scheduled is of type {@link TaskType#DECISION}.
      *
      * @param taskMapperContext: A wrapper class containing the {@link WorkflowTask}, {@link WorkflowDef}, {@link Workflow} and a string representation of the TaskId
      * @return List of tasks in the following order:

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinDynamicTaskMapper.java
Patch:
@@ -69,7 +69,7 @@ public ForkJoinDynamicTaskMapper(ParametersUtils parametersUtils, ObjectMapper o
     }
 
     /**
-     * This method gets the list of tasks that need to scheduled when the the task to scheduled is of type {@link TaskType#FORK_JOIN_DYNAMIC}.
+     * This method gets the list of tasks that need to scheduled when the task to scheduled is of type {@link TaskType#FORK_JOIN_DYNAMIC}.
      * Creates a Fork Task, followed by the Dynamic tasks and a final JOIN task.
      * <p>The definitions of the dynamic forks that need to be scheduled are available in the {@link WorkflowTask#getInputParameters()}
      * which are accessed using the {@link TaskMapperContext#getTaskToSchedule()}. The dynamic fork task definitions are referred by a key value either by

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapper.java
Patch:
@@ -39,7 +39,7 @@ public class ForkJoinTaskMapper implements TaskMapper {
     public static final Logger logger = LoggerFactory.getLogger(ForkJoinTaskMapper.class);
 
     /**
-     * This method gets the list of tasks that need to scheduled when the the task to scheduled is of type {@link TaskType#FORK_JOIN}.
+     * This method gets the list of tasks that need to scheduled when the task to scheduled is of type {@link TaskType#FORK_JOIN}.
      *
      * @param taskMapperContext: A wrapper class containing the {@link WorkflowTask}, {@link WorkflowDef}, {@link Workflow} and a string representation of the TaskId
      * @return List of tasks in the following order:

File: core/src/main/java/com/netflix/conductor/dao/ExecutionDAO.java
Patch:
@@ -229,7 +229,7 @@ public interface ExecutionDAO {
 	/**
 	 * 
 	 * @param ee Event Execution to be stored
-	 * @return true if the event was added.  false otherwise when the event by id is already already stored.
+	 * @return true if the event was added.  false otherwise when the event by id is already stored.
 	 */
 	boolean addEventExecution(EventExecution ee);
 

File: core/src/main/java/com/netflix/conductor/dao/IndexDAO.java
Patch:
@@ -67,7 +67,7 @@ public interface IndexDAO {
      *
      * @param query SQL like query for workflow search parameters.
      * @param freeText    Additional query in free text.  Lucene syntax
-     * @param start    start start index for pagination
+     * @param start    start index for pagination
      * @param count    count # of workflow ids to be returned
      * @param sort sort options
      * @return List of workflow ids for the matching query
@@ -78,7 +78,7 @@ public interface IndexDAO {
      *
      * @param query SQL like query for task search parameters.
      * @param freeText    Additional query in free text.  Lucene syntax
-     * @param start    start start index for pagination
+     * @param start    start index for pagination
      * @param count    count # of task ids to be returned
      * @param sort sort options
      * @return List of workflow ids for the matching query

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -810,6 +810,7 @@ public Task deepCopy() {
     deepCopy.setEndTime(endTime);
     deepCopy.setWorkerId(workerId);
     deepCopy.setReasonForIncompletion(reasonForIncompletion);
+    deepCopy.setSeq(seq);
 
     return deepCopy;
   }

File: redis-lock/src/main/java/com/netflix/conductor/locking/redis/config/RedisLockModule.java
Patch:
@@ -53,6 +53,7 @@ public Redisson getRedissonBasedOnConfig(RedisLockConfiguration clusterConfigura
         }
         String redisServerAddress = clusterConfiguration.getRedisServerAddress();
         String redisServerPassword = clusterConfiguration.getRedisServerPassword();
+        String masterName = clusterConfiguration.getRedisServerMasterName();
 
         Config redisConfig = new Config();
 
@@ -74,6 +75,7 @@ public Redisson getRedissonBasedOnConfig(RedisLockConfiguration clusterConfigura
             case SENTINEL:
                 redisConfig.useSentinelServers()
                         .setScanInterval(2000)
+                        .setMasterName(masterName)
                         .addSentinelAddress(redisServerAddress)
                         .setPassword(redisServerPassword)
                         .setTimeout(connectionTimeout);

File: zookeeper-lock/src/main/java/com/netflix/conductor/zookeeper/config/ZookeeperModule.java
Patch:
@@ -18,8 +18,8 @@
 
 import com.google.inject.AbstractModule;
 import com.google.inject.Provides;
+import com.google.inject.Singleton;
 import com.netflix.conductor.core.utils.Lock;
-import com.netflix.conductor.service.ExecutionLockService;
 import com.netflix.conductor.zookeeper.ZookeeperLock;
 
 public class ZookeeperModule extends AbstractModule {
@@ -30,6 +30,7 @@ protected void configure() {
     }
 
     @Provides
+    @Singleton
     protected Lock provideLock(ZookeeperConfiguration config) {
         return new ZookeeperLock(config);
     }

File: core/src/main/java/com/netflix/conductor/core/orchestration/ExecutionDAOFacade.java
Patch:
@@ -152,7 +152,7 @@ public Workflow getWorkflowById(String workflowId, boolean includeTasks) {
      */
     public List<Workflow> getWorkflowsByCorrelationId(String workflowName, String correlationId, boolean includeTasks) {
         if (!executionDAO.canSearchAcrossWorkflows()) {
-        	String query = "correlationId='" + correlationId + "' and workflowType='" + workflowName + "'";
+        	String query = "correlationId='" + correlationId + "' AND workflowType='" + workflowName + "'";
             SearchResult<String> result = indexDAO.searchWorkflows(query, "*", 0, 1000, null);
             return result.getResults().stream()
                 .parallel()

File: core/src/main/java/com/netflix/conductor/core/orchestration/ExecutionDAOFacade.java
Patch:
@@ -152,7 +152,7 @@ public Workflow getWorkflowById(String workflowId, boolean includeTasks) {
      */
     public List<Workflow> getWorkflowsByCorrelationId(String workflowName, String correlationId, boolean includeTasks) {
         if (!executionDAO.canSearchAcrossWorkflows()) {
-        	String query = "correlationId='" + correlationId + "' and workflowType='" + workflowName + "'";
+        	String query = "correlationId='" + correlationId + "' AND workflowType='" + workflowName + "'";
             SearchResult<String> result = indexDAO.searchWorkflows(query, "*", 0, 1000, null);
             return result.getResults().stream()
                 .parallel()

File: contribs/src/main/java/com/netflix/conductor/contribs/NatsModule.java
Patch:
@@ -30,6 +30,7 @@
 import com.netflix.conductor.core.events.nats.NATSEventQueueProvider;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
+import rx.Scheduler;
 
 
 /**
@@ -48,8 +49,8 @@ protected void configure() {
 	@StringMapKey("nats")
 	@Singleton
 	@Named(EVENT_QUEUE_PROVIDERS_QUALIFIER)
-	public EventQueueProvider getNATSEventQueueProvider(Configuration configuration) {
-		return new NATSEventQueueProvider(configuration);
+	public EventQueueProvider getNATSEventQueueProvider(Configuration configuration, Scheduler scheduler) {
+		return new NATSEventQueueProvider(configuration, scheduler);
 	}
 	
 }

File: contribs/src/main/java/com/netflix/conductor/contribs/NatsStreamModule.java
Patch:
@@ -30,6 +30,7 @@
 import com.netflix.conductor.core.events.nats.NATSStreamEventQueueProvider;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
+import rx.Scheduler;
 
 
 /**
@@ -48,8 +49,8 @@ protected void configure() {
 	@StringMapKey("nats_stream")
 	@Singleton
 	@Named(EVENT_QUEUE_PROVIDERS_QUALIFIER)
-	public EventQueueProvider geNATSStreamEventQueueProvider(Configuration configuration) {
-		return new NATSStreamEventQueueProvider(configuration);
+	public EventQueueProvider geNATSStreamEventQueueProvider(Configuration configuration, Scheduler scheduler) {
+		return new NATSStreamEventQueueProvider(configuration, scheduler);
 	}
 	
 }

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/nats/NATSObservableQueue.java
Patch:
@@ -25,6 +25,7 @@
 import io.nats.client.Connection;
 import io.nats.client.ConnectionFactory;
 import io.nats.client.Subscription;
+import rx.Scheduler;
 
 /**
  * @author Oleksiy Lysak
@@ -35,8 +36,8 @@ public class NATSObservableQueue extends NATSAbstractQueue {
     private Subscription subs;
     private Connection conn;
     
-    public NATSObservableQueue(ConnectionFactory factory, String queueURI) {
-        super(queueURI, "nats");
+    public NATSObservableQueue(ConnectionFactory factory, String queueURI, Scheduler scheduler) {
+        super(queueURI, "nats", scheduler);
         this.fact = factory;
         open();
     }

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -20,6 +20,7 @@
 import static com.netflix.conductor.common.metadata.tasks.Task.Status.SCHEDULED;
 import static com.netflix.conductor.common.metadata.tasks.Task.Status.SKIPPED;
 import static com.netflix.conductor.common.metadata.tasks.Task.Status.TIMED_OUT;
+import static com.netflix.conductor.common.metadata.workflow.TaskType.SUB_WORKFLOW;
 
 import com.google.common.annotations.VisibleForTesting;
 import com.netflix.conductor.common.metadata.tasks.Task;
@@ -594,7 +595,7 @@ boolean isResponseTimedOut(TaskDef taskDefinition, Task task) {
             LOGGER.warn("missing task type : {}, workflowId= {}", task.getTaskDefName(), task.getWorkflowInstanceId());
             return false;
         }
-        if (task.getStatus().isTerminal()) {
+        if (task.getStatus().isTerminal() || task.getTaskType().equals(SUB_WORKFLOW.name())) {
             return false;
         }
 

File: cassandra-persistence/src/main/java/com/netflix/conductor/dao/cassandra/CassandraExecutionDAO.java
Patch:
@@ -504,7 +504,7 @@ public List<Workflow> getWorkflowsByType(String workflowName, Long startTime, Lo
      * for Cassandra backed Conductor
      */
     @Override
-    public List<Workflow> getWorkflowsByCorrelationId(String correlationId, boolean includeTasks) {
+    public List<Workflow> getWorkflowsByCorrelationId(String workflowName, String correlationId, boolean includeTasks) {
         throw new UnsupportedOperationException("This method is not implemented in CassandraExecutionDAO. Please use ExecutionDAOFacade instead.");
     }
 

File: core/src/main/java/com/netflix/conductor/dao/ExecutionDAO.java
Patch:
@@ -209,12 +209,13 @@ public interface ExecutionDAO {
 
 	/**
 	 * 
+	 * @param workflowName workflow name
 	 * @param correlationId Correlation Id
 	 * @param includeTasks Option to includeTasks in results
 	 * @return List of workflows by correlation id
 	 *  
 	 */
-	List<Workflow> getWorkflowsByCorrelationId(String correlationId, boolean includeTasks);
+	List<Workflow> getWorkflowsByCorrelationId(String workflowName, String correlationId, boolean includeTasks);
 
 	/**
 	 *

File: core/src/test/java/com/netflix/conductor/core/orchestration/ExecutionDAOFacadeTest.java
Patch:
@@ -91,8 +91,8 @@ public void tesGetWorkflowById() throws Exception {
     @Test
     public void testGetWorkflowsByCorrelationId() {
         when(executionDAO.canSearchAcrossWorkflows()).thenReturn(true);
-        when(executionDAO.getWorkflowsByCorrelationId(any(), anyBoolean())).thenReturn(Collections.singletonList(new Workflow()));
-        List<Workflow> workflows = executionDAOFacade.getWorkflowsByCorrelationId("correlationId", true);
+        when(executionDAO.getWorkflowsByCorrelationId(any(), any(), anyBoolean())).thenReturn(Collections.singletonList(new Workflow()));
+        List<Workflow> workflows = executionDAOFacade.getWorkflowsByCorrelationId("workflowName", "correlationId", true);
         assertNotNull(workflows);
         assertEquals(1, workflows.size());
         verify(indexDAO, never()).searchWorkflows(anyString(), anyString(), anyInt(), anyInt(), any());
@@ -104,7 +104,7 @@ public void testGetWorkflowsByCorrelationId() {
         searchResult.setResults(workflowIds);
         when(indexDAO.searchWorkflows(anyString(), anyString(), anyInt(), anyInt(), any())).thenReturn(searchResult);
         when(executionDAO.getWorkflow("workflowId", true)).thenReturn(new Workflow());
-        workflows = executionDAOFacade.getWorkflowsByCorrelationId("correlationId", true);
+        workflows = executionDAOFacade.getWorkflowsByCorrelationId("workflowName", "correlationId", true);
         assertNotNull(workflows);
         assertEquals(1, workflows.size());
     }

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAOTest.java
Patch:
@@ -63,7 +63,7 @@ public void testPendingByCorrelationId() {
 
         generateWorkflows(workflow, 10);
 
-        List<Workflow> bycorrelationId = getExecutionDAO().getWorkflowsByCorrelationId("corr001", true);
+        List<Workflow> bycorrelationId = getExecutionDAO().getWorkflowsByCorrelationId("pending_count_correlation_jtest", "corr001", true);
         assertNotNull(bycorrelationId);
         assertEquals(10, bycorrelationId.size());
     }

File: postgres-persistence/src/test/java/com/netflix/conductor/dao/postgres/PostgresExecutionDAOTest.java
Patch:
@@ -63,7 +63,7 @@ public void testPendingByCorrelationId() {
 
         generateWorkflows(workflow, 10);
 
-        List<Workflow> bycorrelationId = getExecutionDAO().getWorkflowsByCorrelationId("corr001", true);
+        List<Workflow> bycorrelationId = getExecutionDAO().getWorkflowsByCorrelationId("pending_count_correlation_jtest", "corr001", true);
         assertNotNull(bycorrelationId);
         assertEquals(10, bycorrelationId.size());
     }

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAO.java
Patch:
@@ -461,7 +461,7 @@ public List<Workflow> getWorkflowsByType(String workflowName, Long startTime, Lo
 	}
 
 	@Override
-	public List<Workflow> getWorkflowsByCorrelationId(String correlationId, boolean includeTasks) {
+	public List<Workflow> getWorkflowsByCorrelationId(String workflowName, String correlationId, boolean includeTasks) {
 		throw new UnsupportedOperationException("This method is not implemented in RedisExecutionDAO. Please use ExecutionDAOFacade instead.");
 	}
 

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -20,6 +20,7 @@
 import static com.netflix.conductor.common.metadata.tasks.Task.Status.SCHEDULED;
 import static com.netflix.conductor.common.metadata.tasks.Task.Status.SKIPPED;
 import static com.netflix.conductor.common.metadata.tasks.Task.Status.TIMED_OUT;
+import static com.netflix.conductor.common.metadata.workflow.TaskType.SUB_WORKFLOW;
 
 import com.google.common.annotations.VisibleForTesting;
 import com.netflix.conductor.common.metadata.tasks.Task;
@@ -594,7 +595,7 @@ boolean isResponseTimedOut(TaskDef taskDefinition, Task task) {
             LOGGER.warn("missing task type : {}, workflowId= {}", task.getTaskDefName(), task.getWorkflowInstanceId());
             return false;
         }
-        if (task.getStatus().isTerminal()) {
+        if (task.getStatus().isTerminal() || task.getTaskType().equals(SUB_WORKFLOW.name())) {
             return false;
         }
 

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -741,7 +741,9 @@ public String getSubWorkflowId() {
         if (StringUtils.isNotBlank(subWorkflowId)) {
             return subWorkflowId;
         } else {
-            return this.getOutputData() != null ? (String) this.getOutputData().get("subWorkflowId") : null;
+            return 
+               	this.getOutputData() != null && (String) this.getOutputData().get("subWorkflowId") != null ? (String) this.getOutputData().get("subWorkflowId") : 
+               	this.getInputData() != null ? (String) this.getInputData().get("subWorkflowId") : null;
         }
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1642,4 +1642,4 @@ protected boolean updateParentWorkflow(Task subWorkflowTask, Workflow subWorkflo
         }
         return false;
     }
-}
+}
\ No newline at end of file

File: core/src/main/java/com/netflix/conductor/core/events/queue/dyno/DynoObservableQueue.java
Patch:
@@ -116,7 +116,7 @@ private List<Message> receiveMessages() {
         try {
             List<Message> messages = queueDAO.pollMessages(queueName, pollCount, longPollTimeout);
             Monitors.recordEventQueueMessagesProcessed(QUEUE_TYPE, queueName, messages.size());
-            Monitors.recordQueuePollSize(queueName, messages.size());
+            Monitors.recordEventQueuePollSize(queueName, messages.size());
             return messages;
         } catch (Exception exception) {
             logger.error("Exception while getting messages from  queueDAO", exception);

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -120,7 +120,7 @@ public interface Configuration {
     String ELASTIC_SEARCH_DOCUMENT_TYPE_OVERRIDE_PROPERTY_NAME = "workflow.elasticsearch.document.type.override";
     String ELASTIC_SEARCH_DOCUMENT_TYPE_OVERRIDE_DEFAULT_VALUE = "";
 
-    String EVENT_QUEUE_POLL_SCHEDULER_THREAD_COUNT_PROPERTY_NAME = "worklfow.event.queue.scheduler.poll.thread.count";
+    String EVENT_QUEUE_POLL_SCHEDULER_THREAD_COUNT_PROPERTY_NAME = "workflow.event.queue.scheduler.poll.thread.count";
 
     //TODO add constants for input/output external payload related properties.
 

File: contribs/src/main/java/com/netflix/conductor/contribs/NatsModule.java
Patch:
@@ -30,6 +30,7 @@
 import com.netflix.conductor.core.events.nats.NATSEventQueueProvider;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
+import rx.Scheduler;
 
 
 /**
@@ -48,8 +49,8 @@ protected void configure() {
 	@StringMapKey("nats")
 	@Singleton
 	@Named(EVENT_QUEUE_PROVIDERS_QUALIFIER)
-	public EventQueueProvider getNATSEventQueueProvider(Configuration configuration) {
-		return new NATSEventQueueProvider(configuration);
+	public EventQueueProvider getNATSEventQueueProvider(Configuration configuration, Scheduler scheduler) {
+		return new NATSEventQueueProvider(configuration, scheduler);
 	}
 	
 }

File: contribs/src/main/java/com/netflix/conductor/contribs/NatsStreamModule.java
Patch:
@@ -30,6 +30,7 @@
 import com.netflix.conductor.core.events.nats.NATSStreamEventQueueProvider;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
+import rx.Scheduler;
 
 
 /**
@@ -48,8 +49,8 @@ protected void configure() {
 	@StringMapKey("nats_stream")
 	@Singleton
 	@Named(EVENT_QUEUE_PROVIDERS_QUALIFIER)
-	public EventQueueProvider geNATSStreamEventQueueProvider(Configuration configuration) {
-		return new NATSStreamEventQueueProvider(configuration);
+	public EventQueueProvider geNATSStreamEventQueueProvider(Configuration configuration, Scheduler scheduler) {
+		return new NATSStreamEventQueueProvider(configuration, scheduler);
 	}
 	
 }

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/nats/NATSObservableQueue.java
Patch:
@@ -25,6 +25,7 @@
 import io.nats.client.Connection;
 import io.nats.client.ConnectionFactory;
 import io.nats.client.Subscription;
+import rx.Scheduler;
 
 /**
  * @author Oleksiy Lysak
@@ -35,8 +36,8 @@ public class NATSObservableQueue extends NATSAbstractQueue {
     private Subscription subs;
     private Connection conn;
     
-    public NATSObservableQueue(ConnectionFactory factory, String queueURI) {
-        super(queueURI, "nats");
+    public NATSObservableQueue(ConnectionFactory factory, String queueURI, Scheduler scheduler) {
+        super(queueURI, "nats", scheduler);
         this.fact = factory;
         open();
     }

File: contribs/src/main/java/com/netflix/conductor/contribs/ArchivingWorkflowModule.java
Patch:
@@ -16,7 +16,6 @@
 package com.netflix.conductor.contribs;
 
 import com.google.inject.AbstractModule;
-import com.netflix.conductor.contribs.listener.ArchivingWorkflowStatusListener;
 import com.netflix.conductor.core.execution.WorkflowStatusListener;
 
 /**
@@ -26,6 +25,6 @@ public class ArchivingWorkflowModule extends AbstractModule {
 
     @Override
     protected void configure() {
-        bind(WorkflowStatusListener.class).to(ArchivingWorkflowStatusListener.class);
+        bind(WorkflowStatusListener.class).toProvider(ArchiveWorkflowStatusListenerProvider.class);
     }
 }

File: contribs/src/main/java/com/netflix/conductor/contribs/listener/ArchivingWorkflowStatusListener.java
Patch:
@@ -18,6 +18,7 @@
 import com.netflix.conductor.common.run.Workflow;
 import com.netflix.conductor.core.execution.WorkflowStatusListener;
 import com.netflix.conductor.core.orchestration.ExecutionDAOFacade;
+import com.netflix.conductor.metrics.Monitors;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -43,11 +44,13 @@ public ArchivingWorkflowStatusListener(ExecutionDAOFacade executionDAOFacade) {
     public void onWorkflowCompleted(Workflow workflow) {
         LOGGER.info("Archiving workflow {} on completion ", workflow.getWorkflowId());
         this.executionDAOFacade.removeWorkflow(workflow.getWorkflowId(), true);
+        Monitors.recordWorkflowArchived(workflow.getWorkflowName(), workflow.getStatus());
     }
 
     @Override
     public void onWorkflowTerminated(Workflow workflow) {
         LOGGER.info("Archiving workflow {} on termination", workflow.getWorkflowId());
         this.executionDAOFacade.removeWorkflow(workflow.getWorkflowId(), true);
+        Monitors.recordWorkflowArchived(workflow.getWorkflowName(), workflow.getStatus());
     }
 }

File: core/src/test/java/com/netflix/conductor/core/orchestration/ExecutionDAOFacadeTest.java
Patch:
@@ -116,7 +116,7 @@ public void testRemoveWorkflow() {
         when(executionDAO.getWorkflow(anyString(), anyBoolean())).thenReturn(workflow);
         executionDAOFacade.removeWorkflow("workflowId", false);
         verify(indexDAO, never()).updateWorkflow(any(), any(), any());
-        verify(indexDAO, times(1)).asyncRemoveWorkflow(anyString());
+        verify(indexDAO, times(1)).asyncRemoveWorkflow(workflow.getWorkflowId());
     }
 
     @Test

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskResult.java
Patch:
@@ -294,7 +294,7 @@ public static TaskResult newTaskResult(Status status) {
 
     /**
      * Copy the given task result object
-     * @return a deep copy of the task result object
+     * @return a deep copy of the task result object except the externalOutputPayloadStoragePath field
      */
     public TaskResult copy() {
         TaskResult taskResult = new TaskResult();
@@ -307,7 +307,6 @@ public TaskResult copy() {
         taskResult.setOutputData(outputData);
         taskResult.setOutputMessage(outputMessage);
         taskResult.setLogs(logs);
-        taskResult.setExternalOutputPayloadStoragePath(externalOutputPayloadStoragePath);
         taskResult.setSubWorkflowId(subWorkflowId);
         return taskResult;
     }

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskResult.java
Patch:
@@ -294,7 +294,7 @@ public static TaskResult newTaskResult(Status status) {
 
     /**
      * Copy the given task result object
-     * @return a deep copy of the task result object
+     * @return a deep copy of the task result object except the externalOutputPayloadStoragePath field
      */
     public TaskResult copy() {
         TaskResult taskResult = new TaskResult();
@@ -307,7 +307,6 @@ public TaskResult copy() {
         taskResult.setOutputData(outputData);
         taskResult.setOutputMessage(outputMessage);
         taskResult.setLogs(logs);
-        taskResult.setExternalOutputPayloadStoragePath(externalOutputPayloadStoragePath);
         taskResult.setSubWorkflowId(subWorkflowId);
         return taskResult;
     }

File: client/src/main/java/com/netflix/conductor/client/telemetry/MetricsContainer.java
Patch:
@@ -34,7 +34,7 @@
 public class MetricsContainer {
 
     private static final String TASK_TYPE = "taskType";
-    private static final String WORFLOW_TYPE = "workflowType";
+    private static final String WORKFLOW_TYPE = "workflowType";
     private static final String WORKFLOW_VERSION = "version";
     private static final String EXCEPTION = "exception";
     private static final String ENTITY_NAME = "entityName";
@@ -158,15 +158,15 @@ public static void incrementTaskPollCount(String taskType, int taskCount) {
     }
 
     public static void recordWorkflowInputPayloadSize(String workflowType, String version, long payloadSize) {
-        getGauge(WORKFLOW_INPUT_SIZE, WORFLOW_TYPE, workflowType, WORKFLOW_VERSION, version).getAndSet(payloadSize);
+        getGauge(WORKFLOW_INPUT_SIZE, WORKFLOW_TYPE, workflowType, WORKFLOW_VERSION, version).getAndSet(payloadSize);
     }
 
     public static void incrementExternalPayloadUsedCount(String name, String operation, String payloadType) {
         incrementCount(EXTERNAL_PAYLOAD_USED, ENTITY_NAME, name, OPERATION, operation, PAYLOAD_TYPE, payloadType);
     }
 
     public static void incrementWorkflowStartErrorCount(String workflowType, Throwable t) {
-        incrementCount(WORKFLOW_START_ERROR, WORFLOW_TYPE, workflowType, EXCEPTION, t.getClass().getSimpleName());
+        incrementCount(WORKFLOW_START_ERROR, WORKFLOW_TYPE, workflowType, EXCEPTION, t.getClass().getSimpleName());
     }
 
     /**

File: client/src/main/java/com/netflix/conductor/client/telemetry/MetricsContainer.java
Patch:
@@ -34,7 +34,7 @@
 public class MetricsContainer {
 
     private static final String TASK_TYPE = "taskType";
-    private static final String WORFLOW_TYPE = "workflowType";
+    private static final String WORKFLOW_TYPE = "workflowType";
     private static final String WORKFLOW_VERSION = "version";
     private static final String EXCEPTION = "exception";
     private static final String ENTITY_NAME = "entityName";
@@ -158,15 +158,15 @@ public static void incrementTaskPollCount(String taskType, int taskCount) {
     }
 
     public static void recordWorkflowInputPayloadSize(String workflowType, String version, long payloadSize) {
-        getGauge(WORKFLOW_INPUT_SIZE, WORFLOW_TYPE, workflowType, WORKFLOW_VERSION, version).getAndSet(payloadSize);
+        getGauge(WORKFLOW_INPUT_SIZE, WORKFLOW_TYPE, workflowType, WORKFLOW_VERSION, version).getAndSet(payloadSize);
     }
 
     public static void incrementExternalPayloadUsedCount(String name, String operation, String payloadType) {
         incrementCount(EXTERNAL_PAYLOAD_USED, ENTITY_NAME, name, OPERATION, operation, PAYLOAD_TYPE, payloadType);
     }
 
     public static void incrementWorkflowStartErrorCount(String workflowType, Throwable t) {
-        incrementCount(WORKFLOW_START_ERROR, WORFLOW_TYPE, workflowType, EXCEPTION, t.getClass().getSimpleName());
+        incrementCount(WORKFLOW_START_ERROR, WORKFLOW_TYPE, workflowType, EXCEPTION, t.getClass().getSimpleName());
     }
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/ExecutionConfig.java
Patch:
@@ -22,8 +22,8 @@
 
 class ExecutionConfig {
 
-    private ExecutorService executorService;
-    private SemaphoreUtil semaphoreUtil;
+    private final ExecutorService executorService;
+    private final SemaphoreUtil semaphoreUtil;
 
     ExecutionConfig(int threadCount, String threadNameFormat) {
 

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/DoWhileTest.java
Patch:
@@ -79,7 +79,7 @@ public void setup() {
         executionLockService = Mockito.mock(ExecutionLockService.class);
         config = Mockito.mock(Configuration.class);
         provider = spy(new WorkflowExecutor(deciderService, metadataDAO, queueDAO, metadataMapperService,
-                workflowStatusListener, executionDAOFacade, config, executionLockService));
+                workflowStatusListener, executionDAOFacade, config, executionLockService, parametersUtils));
         loopWorkflowTask1 = new WorkflowTask();
         loopWorkflowTask1.setTaskReferenceName("task1");
         loopWorkflowTask1.setName("task1");

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/ExecutionConfig.java
Patch:
@@ -22,8 +22,8 @@
 
 class ExecutionConfig {
 
-    private ExecutorService executorService;
-    private SemaphoreUtil semaphoreUtil;
+    private final ExecutorService executorService;
+    private final SemaphoreUtil semaphoreUtil;
 
     ExecutionConfig(int threadCount, String threadNameFormat) {
 

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/DoWhileTest.java
Patch:
@@ -79,7 +79,7 @@ public void setup() {
         executionLockService = Mockito.mock(ExecutionLockService.class);
         config = Mockito.mock(Configuration.class);
         provider = spy(new WorkflowExecutor(deciderService, metadataDAO, queueDAO, metadataMapperService,
-                workflowStatusListener, executionDAOFacade, config, executionLockService));
+                workflowStatusListener, executionDAOFacade, config, executionLockService, parametersUtils));
         loopWorkflowTask1 = new WorkflowTask();
         loopWorkflowTask1.setTaskReferenceName("task1");
         loopWorkflowTask1.setName("task1");

File: contribs/src/main/java/com/netflix/conductor/contribs/AMQPModule.java
Patch:
@@ -55,7 +55,7 @@ protected void configure() {
 	}
 
 	@ProvidesIntoMap
-	@StringMapKey("amqp")
+	@StringMapKey("amqp_queue")
 	@Singleton
 	@Named(EVENT_QUEUE_PROVIDERS_QUALIFIER)
 	public EventQueueProvider getAMQQueueEventQueueProvider(Configuration config) {

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -436,6 +436,6 @@ enum DB {
     }
 
     enum LOCKING_SERVER {
-        NOOP_LOCK, REDIS, ZOOKEEPER
+        NOOP_LOCK, REDIS, ZOOKEEPER, LOCAL_ONLY
     }
 }

File: redis-persistence/src/main/java/com/netflix/conductor/dao/RedisWorkflowModule.java
Patch:
@@ -21,7 +21,9 @@
 import com.netflix.conductor.dao.dynomite.queue.DynoQueueDAO;
 import com.netflix.conductor.dyno.DynoProxy;
 import com.netflix.conductor.dyno.RedisQueuesProvider;
+import com.netflix.conductor.dyno.RedisQueuesShardingStrategyProvider;
 import com.netflix.dyno.queues.redis.RedisQueues;
+import com.netflix.dyno.queues.redis.sharding.ShardingStrategy;
 
 /**
  * @author Viren
@@ -37,6 +39,7 @@ protected void configure() {
         bind(PollDataDAO.class).to(RedisPollDataDAO.class);
         bind(QueueDAO.class).to(DynoQueueDAO.class);
 
+        bind(ShardingStrategy.class).toProvider(RedisQueuesShardingStrategyProvider.class).asEagerSingleton();
         bind(RedisQueues.class).toProvider(RedisQueuesProvider.class).asEagerSingleton();
         bind(DynoProxy.class).asEagerSingleton();
     }

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/queue/DynoQueueDAO.java
Patch:
@@ -29,7 +29,6 @@
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
-import java.util.Optional;
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;
 import javax.inject.Inject;
@@ -134,6 +133,7 @@ private void init() {
         if (domain != null) {
             prefix = prefix + "." + domain;
         }
+
         queues = new RedisQueues(dynoClient, dynoClientRead, prefix, ss, 60_000, 60_000);
         logger.info("DynoQueueDAO initialized with prefix " + prefix + "!");
     }

File: core/src/main/java/com/netflix/conductor/service/WorkflowService.java
Patch:
@@ -209,7 +209,7 @@ String rerunWorkflow(@NotEmpty(message = "WorkflowId cannot be null or empty.")
     void retryWorkflow(@NotEmpty(message = "WorkflowId cannot be null or empty.") String workflowId);
 
     /**
-     * Resets callback times of all in_progress tasks to 0.
+     * Resets callback times of all non-terminal SIMPLE tasks to 0.
      *
      * @param workflowId WorkflowId of the workflow.
      */

File: core/src/main/java/com/netflix/conductor/service/WorkflowServiceImpl.java
Patch:
@@ -348,13 +348,13 @@ public void retryWorkflow(String workflowId) {
     }
 
     /**
-     * Resets callback times of all in_progress tasks to 0.
+     * Resets callback times of all non-terminal SIMPLE tasks to 0.
      *
      * @param workflowId WorkflowId of the workflow.
      */
     @Service
     public void resetWorkflow(String workflowId) {
-        workflowExecutor.resetCallbacksForInProgressTasks(workflowId);
+        workflowExecutor.resetCallbacksForWorkflow(workflowId);
     }
 
     /**

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -195,7 +195,7 @@ public void retry(@PathParam("workflowId") String workflowId) {
 
     @POST
     @Path("/{workflowId}/resetcallbacks")
-    @ApiOperation("Resets callback times of all in_progress tasks to 0")
+    @ApiOperation("Resets callback times of all non-terminal SIMPLE tasks to 0")
     @Consumes(MediaType.WILDCARD)
     public void resetWorkflow(@PathParam("workflowId") String workflowId) {
         workflowService.resetWorkflow(workflowId);

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractWorkflowServiceTest.java
Patch:
@@ -3341,7 +3341,7 @@ public void testResetWorkflowInProgressTasks() {
         assertNull(task);
 
         // Reset the callbackAfterSeconds
-        workflowExecutor.resetCallbacksForInProgressTasks(workflowId);
+        workflowExecutor.resetCallbacksForWorkflow(workflowId);
 
         // Now Polling for the first task should return the same task as before
         task = workflowExecutionService.poll("junit_task_1", "task1.junit.worker");

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/ExecutionConfig.java
Patch:
@@ -25,7 +25,7 @@ class ExecutionConfig {
     private ExecutorService executorService;
     private SemaphoreUtil semaphoreUtil;
 
-    public ExecutionConfig(int threadCount, String threadNameFormat) {
+    ExecutionConfig(int threadCount, String threadNameFormat) {
 
         this.executorService = Executors.newFixedThreadPool(threadCount,
             new ThreadFactoryBuilder().setNameFormat(threadNameFormat).build());

File: core/src/main/java/com/netflix/conductor/service/WorkflowService.java
Patch:
@@ -209,7 +209,7 @@ String rerunWorkflow(@NotEmpty(message = "WorkflowId cannot be null or empty.")
     void retryWorkflow(@NotEmpty(message = "WorkflowId cannot be null or empty.") String workflowId);
 
     /**
-     * Resets callback times of all in_progress tasks to 0.
+     * Resets callback times of all non-terminal SIMPLE tasks to 0.
      *
      * @param workflowId WorkflowId of the workflow.
      */

File: core/src/main/java/com/netflix/conductor/service/WorkflowServiceImpl.java
Patch:
@@ -348,13 +348,13 @@ public void retryWorkflow(String workflowId) {
     }
 
     /**
-     * Resets callback times of all in_progress tasks to 0.
+     * Resets callback times of all non-terminal SIMPLE tasks to 0.
      *
      * @param workflowId WorkflowId of the workflow.
      */
     @Service
     public void resetWorkflow(String workflowId) {
-        workflowExecutor.resetCallbacksForInProgressTasks(workflowId);
+        workflowExecutor.resetCallbacksForWorkflow(workflowId);
     }
 
     /**

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -195,7 +195,7 @@ public void retry(@PathParam("workflowId") String workflowId) {
 
     @POST
     @Path("/{workflowId}/resetcallbacks")
-    @ApiOperation("Resets callback times of all in_progress tasks to 0")
+    @ApiOperation("Resets callback times of all non-terminal SIMPLE tasks to 0")
     @Consumes(MediaType.WILDCARD)
     public void resetWorkflow(@PathParam("workflowId") String workflowId) {
         workflowService.resetWorkflow(workflowId);

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractWorkflowServiceTest.java
Patch:
@@ -3341,7 +3341,7 @@ public void testResetWorkflowInProgressTasks() {
         assertNull(task);
 
         // Reset the callbackAfterSeconds
-        workflowExecutor.resetCallbacksForInProgressTasks(workflowId);
+        workflowExecutor.resetCallbacksForWorkflow(workflowId);
 
         // Now Polling for the first task should return the same task as before
         task = workflowExecutionService.poll("junit_task_1", "task1.junit.worker");

File: client/src/main/java/com/netflix/conductor/client/telemetry/MetricsContainer.java
Patch:
@@ -37,7 +37,7 @@ public class MetricsContainer {
     private static final String WORFLOW_TYPE = "workflowType";
     private static final String WORKFLOW_VERSION = "version";
     private static final String EXCEPTION = "exception";
-    private static final String NAME = "name";
+    private static final String ENTITY_NAME = "entityName";
     private static final String OPERATION = "operation";
     private static final String PAYLOAD_TYPE = "payload_type";
 
@@ -162,7 +162,7 @@ public static void recordWorkflowInputPayloadSize(String workflowType, String ve
     }
 
     public static void incrementExternalPayloadUsedCount(String name, String operation, String payloadType) {
-        incrementCount(EXTERNAL_PAYLOAD_USED, NAME, name, OPERATION, operation, PAYLOAD_TYPE, payloadType);
+        incrementCount(EXTERNAL_PAYLOAD_USED, ENTITY_NAME, name, OPERATION, operation, PAYLOAD_TYPE, payloadType);
     }
 
     public static void incrementWorkflowStartErrorCount(String workflowType, Throwable t) {
@@ -177,6 +177,6 @@ public static void incrementWorkflowStartErrorCount(String workflowType, Throwab
      * @param className the name of the class which initialized the client
      */
     public static void incrementInitializationCount(String className) {
-        incrementCount(CLIENT_INITIALIZED, NAME, className);
+        incrementCount(CLIENT_INITIALIZED, ENTITY_NAME, className);
     }
 }

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -140,13 +140,14 @@ public List<Task> poll(String taskType, String workerId, String domain, int coun
 				if (task == null || task.getStatus().isTerminal()) {
 					// Remove taskId(s) without a valid Task/terminal state task from the queue
 					queueDAO.remove(queueName, taskId);
-					logger.debug("Removed taskId from the queue: {}, {}", queueName, taskId);
+					logger.debug("Removed task: {} from the queue: {}", taskId, queueName);
 					continue;
 				}
 
 				if (executionDAOFacade.exceedsInProgressLimit(task)) {
 					// Postpone a message, so that it would be available for poll again.
 					queueDAO.postpone(queueName, taskId, task.getWorkflowPriority(), queueTaskMessagePostponeSeconds);
+					logger.debug("Postponed task: {} in queue: {} by {} seconds", taskId, queueName, queueTaskMessagePostponeSeconds);
 					continue;
 				}
 

File: client/src/main/java/com/netflix/conductor/client/telemetry/MetricsContainer.java
Patch:
@@ -37,7 +37,7 @@ public class MetricsContainer {
     private static final String WORFLOW_TYPE = "workflowType";
     private static final String WORKFLOW_VERSION = "version";
     private static final String EXCEPTION = "exception";
-    private static final String NAME = "name";
+    private static final String ENTITY_NAME = "entityName";
     private static final String OPERATION = "operation";
     private static final String PAYLOAD_TYPE = "payload_type";
 
@@ -162,7 +162,7 @@ public static void recordWorkflowInputPayloadSize(String workflowType, String ve
     }
 
     public static void incrementExternalPayloadUsedCount(String name, String operation, String payloadType) {
-        incrementCount(EXTERNAL_PAYLOAD_USED, NAME, name, OPERATION, operation, PAYLOAD_TYPE, payloadType);
+        incrementCount(EXTERNAL_PAYLOAD_USED, ENTITY_NAME, name, OPERATION, operation, PAYLOAD_TYPE, payloadType);
     }
 
     public static void incrementWorkflowStartErrorCount(String workflowType, Throwable t) {
@@ -177,6 +177,6 @@ public static void incrementWorkflowStartErrorCount(String workflowType, Throwab
      * @param className the name of the class which initialized the client
      */
     public static void incrementInitializationCount(String className) {
-        incrementCount(CLIENT_INITIALIZED, NAME, className);
+        incrementCount(CLIENT_INITIALIZED, ENTITY_NAME, className);
     }
 }

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -140,13 +140,14 @@ public List<Task> poll(String taskType, String workerId, String domain, int coun
 				if (task == null || task.getStatus().isTerminal()) {
 					// Remove taskId(s) without a valid Task/terminal state task from the queue
 					queueDAO.remove(queueName, taskId);
-					logger.debug("Removed taskId from the queue: {}, {}", queueName, taskId);
+					logger.debug("Removed task: {} from the queue: {}", taskId, queueName);
 					continue;
 				}
 
 				if (executionDAOFacade.exceedsInProgressLimit(task)) {
 					// Postpone a message, so that it would be available for poll again.
 					queueDAO.postpone(queueName, taskId, task.getWorkflowPriority(), queueTaskMessagePostponeSeconds);
+					logger.debug("Postponed task: {} in queue: {} by {} seconds", taskId, queueName, queueTaskMessagePostponeSeconds);
 					continue;
 				}
 

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/DoWhile.java
Patch:
@@ -27,6 +27,7 @@
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import java.util.Collection;
 import java.util.HashMap;
+import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.stream.Collectors;
@@ -68,7 +69,7 @@ public boolean execute(Workflow workflow, Task task, WorkflowExecutor workflowEx
 		 * Get the latest set of tasks (the ones that have the highest retry count). We don't want to evaluate any tasks
 		 * that have already failed if there is a more current one (a later retry count).
 		 */
-		Map<String, Task> relevantTasks = new HashMap<String, Task>();
+		Map<String, Task> relevantTasks = new LinkedHashMap<String, Task>();
 		Task relevantTask = null;
 		for(Task t : workflow.getTasks()) {
 			if(task.getWorkflowTask().has(TaskUtils.removeIterationFromTaskRefName(t.getReferenceTaskName()))

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -25,6 +25,7 @@
 import com.netflix.conductor.core.events.ScriptEvaluator;
 import com.netflix.conductor.core.execution.SystemTaskType;
 import com.netflix.conductor.core.execution.TerminateWorkflowException;
+import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -122,7 +123,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
     String getEvaluatedCaseValue(WorkflowTask taskToSchedule, Map<String, Object> taskInput) {
         String expression = taskToSchedule.getCaseExpression();
         String caseValue;
-        if (expression != null) {
+        if (StringUtils.isNotBlank(expression)) {
             logger.debug("Case being evaluated using decision expression: {}", expression);
             try {
                 //Evaluate the expression by using the Nashhorn based script evaluator

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisPollDataDAO.java
Patch:
@@ -62,7 +62,7 @@ public PollData getPollData(String taskDefName, String domain) {
         recordRedisDaoPayloadSize("getPollData", StringUtils.length(pollDataJsonString), "n/a", "n/a");
 
         PollData pollData = null;
-        if (pollDataJsonString != null) {
+        if (StringUtils.isNotBlank(pollDataJsonString)) {
             pollData = readValue(pollDataJsonString, PollData.class);
         }
         return pollData;

File: cassandra-persistence/src/main/java/com/netflix/conductor/dao/cassandra/CassandraEventHandlerDAO.java
Patch:
@@ -48,7 +48,7 @@ public class CassandraEventHandlerDAO extends CassandraBaseDAO implements EventH
     private static final Logger LOGGER = LoggerFactory.getLogger(CassandraEventHandlerDAO.class);
     private static final String CLASS_NAME = CassandraEventHandlerDAO.class.getSimpleName();
 
-    private Map<String, EventHandler> eventHandlerCache = new HashMap<>();
+    private volatile Map<String, EventHandler> eventHandlerCache = new HashMap<>();
 
     private final PreparedStatement insertEventHandlerStatement;
     private final PreparedStatement selectAllEventHandlersStatement;

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -784,7 +784,7 @@ public Task copy() {
         copy.setIteration(iteration);
         copy.setExecutionNameSpace(executionNameSpace);
         copy.setIsolationGroupId(isolationGroupId);
-        copy.setSubWorkflowId(subWorkflowId);
+        copy.setSubWorkflowId(getSubWorkflowId());
 
         return copy;
     }

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractWorkflowServiceTest.java
Patch:
@@ -5139,7 +5139,6 @@ public void testSubWorkflowRetry() {
                 .filter(t -> t.getStatus().equals(SCHEDULED))
                 .findAny().orElse(null);
         assertNotNull(task);
-        assertNull("Retried task in scheduled state shouldn't have a SubworkflowId yet", task.getSubWorkflowId());
         subWorkflowTaskId = task.getTaskId();
 
         workflowExecutor.executeSystemTask(subworkflow, task.getTaskId(), 1);

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -36,8 +36,10 @@
 import java.io.IOException;
 import java.io.InputStream;
 import java.text.SimpleDateFormat;
+import java.time.Clock;
 import java.time.Instant;
 import java.time.LocalDate;
+import java.time.ZoneOffset;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Date;
@@ -723,7 +725,7 @@ private void addSortOptionToSearchRequest(SearchRequestBuilder searchRequestBuil
     @Override
     public List<String> searchArchivableWorkflows(String indexName, long archiveTtlDays) {
         QueryBuilder q = QueryBuilders.boolQuery()
-            .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays).toString()).gte(LocalDate.now().minusDays(archiveTtlDays).minusDays(1).toString()))
+            .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now(ZoneOffset.UTC).minusDays(archiveTtlDays).toString()).gte(LocalDate.now(ZoneOffset.UTC).minusDays(archiveTtlDays).minusDays(1).toString()))
             .should(QueryBuilders.termQuery("status", "COMPLETED"))
             .should(QueryBuilders.termQuery("status", "FAILED"))
             .should(QueryBuilders.termQuery("status", "TIMED_OUT"))

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchRestDAOV5.java
Patch:
@@ -39,6 +39,7 @@
 import java.text.SimpleDateFormat;
 import java.time.Instant;
 import java.time.LocalDate;
+import java.time.ZoneOffset;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Date;
@@ -741,7 +742,7 @@ private SearchResult<String> searchObjectIds(String indexName, QueryBuilder quer
     @Override
     public List<String> searchArchivableWorkflows(String indexName, long archiveTtlDays) {
         QueryBuilder q = QueryBuilders.boolQuery()
-                .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays).toString()).gte(LocalDate.now().minusDays(archiveTtlDays).minusDays(1).toString()))
+                .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now(ZoneOffset.UTC).minusDays(archiveTtlDays).toString()).gte(LocalDate.now(ZoneOffset.UTC).minusDays(archiveTtlDays).minusDays(1).toString()))
                 .should(QueryBuilders.termQuery("status", "COMPLETED"))
                 .should(QueryBuilders.termQuery("status", "FAILED"))
                 .should(QueryBuilders.termQuery("status", "TIMED_OUT"))

File: es5-persistence/src/test/java/com/netflix/conductor/dao/es5/index/TestElasticSearchRestDAOV5.java
Patch:
@@ -67,6 +67,7 @@
 import org.elasticsearch.search.sort.FieldSortBuilder;
 import org.elasticsearch.search.sort.SortOrder;
 import org.joda.time.DateTime;
+import org.joda.time.DateTimeZone;
 import org.junit.After;
 import org.junit.AfterClass;
 import org.junit.Before;
@@ -303,7 +304,7 @@ public void testSearchRecentRunningWorkflows() {
     @Test
     public void testSearchArchivableWorkflows() throws IOException {
         String workflowId = "search-workflow-id";
-        Long time = DateTime.now().minusDays(7).toDate().getTime();
+        Long time = DateTime.now(DateTimeZone.UTC).minusDays(7).toDate().getTime();
 
         workflow.setWorkflowId(workflowId);
         workflow.setStatus(Workflow.WorkflowStatus.COMPLETED);

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -36,8 +36,10 @@
 import java.io.IOException;
 import java.io.InputStream;
 import java.text.SimpleDateFormat;
+import java.time.Clock;
 import java.time.Instant;
 import java.time.LocalDate;
+import java.time.ZoneOffset;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Date;
@@ -723,7 +725,7 @@ private void addSortOptionToSearchRequest(SearchRequestBuilder searchRequestBuil
     @Override
     public List<String> searchArchivableWorkflows(String indexName, long archiveTtlDays) {
         QueryBuilder q = QueryBuilders.boolQuery()
-            .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays).toString()).gte(LocalDate.now().minusDays(archiveTtlDays).minusDays(1).toString()))
+            .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now(ZoneOffset.UTC).minusDays(archiveTtlDays).toString()).gte(LocalDate.now(ZoneOffset.UTC).minusDays(archiveTtlDays).minusDays(1).toString()))
             .should(QueryBuilders.termQuery("status", "COMPLETED"))
             .should(QueryBuilders.termQuery("status", "FAILED"))
             .should(QueryBuilders.termQuery("status", "TIMED_OUT"))

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchRestDAOV5.java
Patch:
@@ -39,6 +39,7 @@
 import java.text.SimpleDateFormat;
 import java.time.Instant;
 import java.time.LocalDate;
+import java.time.ZoneOffset;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Date;
@@ -741,7 +742,7 @@ private SearchResult<String> searchObjectIds(String indexName, QueryBuilder quer
     @Override
     public List<String> searchArchivableWorkflows(String indexName, long archiveTtlDays) {
         QueryBuilder q = QueryBuilders.boolQuery()
-                .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays).toString()).gte(LocalDate.now().minusDays(archiveTtlDays).minusDays(1).toString()))
+                .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now(ZoneOffset.UTC).minusDays(archiveTtlDays).toString()).gte(LocalDate.now(ZoneOffset.UTC).minusDays(archiveTtlDays).minusDays(1).toString()))
                 .should(QueryBuilders.termQuery("status", "COMPLETED"))
                 .should(QueryBuilders.termQuery("status", "FAILED"))
                 .should(QueryBuilders.termQuery("status", "TIMED_OUT"))

File: es5-persistence/src/test/java/com/netflix/conductor/dao/es5/index/TestElasticSearchRestDAOV5.java
Patch:
@@ -67,6 +67,7 @@
 import org.elasticsearch.search.sort.FieldSortBuilder;
 import org.elasticsearch.search.sort.SortOrder;
 import org.joda.time.DateTime;
+import org.joda.time.DateTimeZone;
 import org.junit.After;
 import org.junit.AfterClass;
 import org.junit.Before;
@@ -303,7 +304,7 @@ public void testSearchRecentRunningWorkflows() {
     @Test
     public void testSearchArchivableWorkflows() throws IOException {
         String workflowId = "search-workflow-id";
-        Long time = DateTime.now().minusDays(7).toDate().getTime();
+        Long time = DateTime.now(DateTimeZone.UTC).minusDays(7).toDate().getTime();
 
         workflow.setWorkflowId(workflowId);
         workflow.setStatus(Workflow.WorkflowStatus.COMPLETED);

File: core/src/main/java/com/netflix/conductor/core/events/SimpleActionProcessor.java
Patch:
@@ -154,4 +154,4 @@ private Map<String, Object> startWorkflow(Action action, Object payload, String
         }
         return output;
     }
-}
\ No newline at end of file
+}

File: core/src/main/java/com/netflix/conductor/core/execution/ParametersUtils.java
Patch:
@@ -150,7 +150,7 @@ public Map<String, Object> replace(Map<String, Object> input, Object json) {
         }
         Configuration option = Configuration.defaultConfiguration().addOptions(Option.SUPPRESS_EXCEPTIONS);
         DocumentContext documentContext = JsonPath.parse(doc, option);
-        return replace(input, documentContext, null);
+        return replace(new HashMap<>(input), documentContext, null);
     }
 
     public Object replace(String paramString) {

File: cassandra-persistence/src/main/java/com/netflix/conductor/dao/cassandra/CassandraExecutionDAO.java
Patch:
@@ -54,9 +54,11 @@
 import java.util.UUID;
 import java.util.stream.Collectors;
 import javax.inject.Inject;
+import javax.inject.Singleton;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+@Singleton
 @Trace
 public class CassandraExecutionDAO extends CassandraBaseDAO implements ExecutionDAO, PollDataDAO {
     private static final Logger LOGGER = LoggerFactory.getLogger(CassandraExecutionDAO.class);

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1146,7 +1146,7 @@ public void addTaskToQueue(Task task) {
     }
 
     //Executes the async system task
-    public void executeSystemTask(WorkflowSystemTask systemTask, String taskId, int unackTimeout) {
+    public void executeSystemTask(WorkflowSystemTask systemTask, String taskId, int callbackTime) {
         try {
             Task task = executionDAOFacade.getTaskById(taskId);
             if (task == null) {
@@ -1223,14 +1223,15 @@ public void executeSystemTask(WorkflowSystemTask systemTask, String taskId, int
             }
 
             if (!task.getStatus().isTerminal()) {
-                task.setCallbackAfterSeconds(unackTimeout);
+                task.setCallbackAfterSeconds(callbackTime);
             }
 
             updateTask(new TaskResult(task));
             LOGGER.debug("Done Executing {}/{}-{} output={}", task.getTaskType(), task.getTaskId(), task.getStatus(),
                 task.getOutputData().toString());
 
         } catch (Exception e) {
+            Monitors.error(className, "executeSystemTask");
             LOGGER.error("Error executing system task - {}, with id: {}", systemTask, taskId, e);
         }
     }

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/HTTPTaskMapper.java
Patch:
@@ -1,5 +1,5 @@
  /*
-  * Copyright 2018 Netflix, Inc.
+  * Copyright 2020 Netflix, Inc.
   * <p>
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
@@ -95,7 +95,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
              httpTask.setRateLimitPerFrequency(taskDefinition.getRateLimitPerFrequency());
              httpTask.setRateLimitFrequencyInSeconds(taskDefinition.getRateLimitFrequencyInSeconds());
              httpTask.setIsolationGroupId(taskDefinition.getIsolationGroupId());
-             httpTask.setDomain(taskDefinition.getExecutionNameSpace());
+             httpTask.setExecutionNameSpace(taskDefinition.getExecutionNameSpace());
          }
          return Collections.singletonList(httpTask);
      }

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestIsolatedTaskQueueProducer.java
Patch:
@@ -14,7 +14,7 @@ public class TestIsolatedTaskQueueProducer {
 	@Test
 	public void addTaskQueuesAddsElementToQueue() throws InterruptedException {
 
-		SystemTaskWorkerCoordinator.taskNameWorkFlowTaskMapping.put("HTTP", Mockito.mock(WorkflowSystemTask.class));
+		SystemTaskWorkerCoordinator.taskNameWorkflowTaskMapping.put("HTTP", Mockito.mock(WorkflowSystemTask.class));
 		MetadataService metadataService = Mockito.mock(MetadataService.class);
 		IsolatedTaskQueueProducer isolatedTaskQueueProducer = new IsolatedTaskQueueProducer(metadataService, Mockito.mock(Configuration.class));
 		TaskDef taskDef = new TaskDef();

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -829,7 +829,7 @@ public void updateTask(TaskResult taskResult) {
         task.setOutputData(taskResult.getOutputData());
         task.setSubWorkflowId(taskResult.getSubWorkflowId());
 
-        if (task.getOutputData() != null) {
+        if (task.getOutputData() != null && !task.getOutputData().isEmpty()) {
             deciderService.externalizeTaskData(task);
         } else {
             task.setExternalOutputPayloadStoragePath(taskResult.getExternalOutputPayloadStoragePath());

File: cassandra-persistence/src/main/java/com/netflix/conductor/dao/cassandra/CassandraExecutionDAO.java
Patch:
@@ -93,7 +93,7 @@ public class CassandraExecutionDAO extends CassandraBaseDAO implements Execution
     public CassandraExecutionDAO(Session session, ObjectMapper objectMapper, CassandraConfiguration config, Statements statements) {
         super(session, objectMapper, config);
 
-        eventExecutionsTTL = config.getEventExecutionsTTL();
+        eventExecutionsTTL = config.getEventExecutionPersistenceTTL();
 
         this.insertWorkflowStatement = session.prepare(statements.getInsertWorkflowStatement()).setConsistencyLevel(config.getWriteConsistencyLevel());
         this.insertTaskStatement = session.prepare(statements.getInsertTaskStatement()).setConsistencyLevel(config.getWriteConsistencyLevel());

File: cassandra-persistence/src/test/java/com/netflix/conductor/config/TestConfiguration.java
Patch:
@@ -178,7 +178,7 @@ public ConsistencyLevel getWriteConsistencyLevel() {
     }
 
     @Override
-    public int getEventExecutionsTTL() {
+    public int getEventExecutionPersistenceTTL() {
         return 5;
     }
 }

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -73,7 +73,7 @@ public interface Configuration {
     String IGNORE_LOCKING_EXCEPTIONS_PROPERTY_NAME = "workflow.decider.locking.exceptions.ignore";
     boolean IGNORE_LOCKING_EXCEPTIONS_DEFAULT_VALUE = false;
 
-    String EVENT_MESSAGE_INDEXING_ENABLED_PROPERTY_NAME = "worklfow.event.message.indexing.enabled";
+    String EVENT_MESSAGE_INDEXING_ENABLED_PROPERTY_NAME = "workflow.event.message.indexing.enabled";
     boolean EVENT_MESSAGE_INDEXING_ENABLED_DEFAULT_VALUE = true;
 
     String TASKEXECLOG_INDEXING_ENABLED_PROPERTY_NAME = "workflow.taskExecLog.indexing.enabled";
@@ -88,7 +88,7 @@ public interface Configuration {
     String EVENT_HANDLER_REFRESH_TIME_SECS_PROPERTY_NAME = "conductor.eventhandler.cache.refresh.time.seconds";
     int EVENT_HANDLER_REFRESH_TIME_SECS_DEFAULT_VALUE = 60;
 
-    String EVENT_EXECUTION_PERSISTENCE_TTL_SECS_PROPERTY_NAME = "workflow.event.execution.peristence.ttl.seconds";
+    String EVENT_EXECUTION_PERSISTENCE_TTL_SECS_PROPERTY_NAME = "workflow.event.execution.persistence.ttl.seconds";
     int EVENT_EXECUTION_PERSISTENCE_TTL_SECS_DEFAULT_VALUE = 0;
 
     String OWNER_EMAIL_MANDATORY_NAME = "workflow.owner.email.mandatory";

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/query/parser/NameValue.java
Patch:
@@ -33,7 +33,7 @@
  * @author Viren
  * <pre>
  * Represents an expression of the form as below:
- * key OPR value 
+ * key OPR value
  * OPR is the comparison operator which could be on the following:
  * 	&gt;, &lt;, = , !=, IN, BETWEEN
  * </pre>
@@ -115,6 +115,8 @@ public QueryBuilder getFilterBuilder() {
             }
         } else if (op.getOperator().equals(Operators.LESS_THAN.value())) {
             return QueryBuilders.rangeQuery(name.getName()).to(value.getValue()).includeLower(false).includeUpper(false);
+        } else if (op.getOperator().equals(Operators.STARTS_WITH.value())) {
+            return QueryBuilders.prefixQuery(name.getName(), value.getUnquotedValue());
         }
 
         throw new IllegalStateException("Incorrect/unsupported operators");

File: es5-persistence/src/test/java/com/netflix/conductor/elasticsearch/query/parser/TestComparisonOp.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 /**
- * 
+ *
  */
 package com.netflix.conductor.elasticsearch.query.parser;
 
@@ -32,15 +32,15 @@ public class TestComparisonOp extends AbstractParserTest {
 
 	@Test
 	public void test() throws Exception {
-		String[] tests = new String[]{"<",">","=","!=","IN"};
+		String[] tests = new String[]{"<",">","=","!=","IN","STARTS_WITH"};
 		for(String test : tests){
 			ComparisonOp name = new ComparisonOp(getInputStream(test));
 			String nameVal = name.getOperator();
 			assertNotNull(nameVal);
 			assertEquals(test, nameVal);
 		}
 	}
-	
+
 	@Test(expected=ParserException.class)
 	public void testInvalidOp() throws Exception {
 		String test =  "AND";

File: es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/query/parser/NameValue.java
Patch:
@@ -33,7 +33,7 @@
  * @author Viren
  * <pre>
  * Represents an expression of the form as below:
- * key OPR value 
+ * key OPR value
  * OPR is the comparison operator which could be on the following:
  * 	&gt;, &lt;, = , !=, IN, BETWEEN
  * </pre>
@@ -115,6 +115,8 @@ public QueryBuilder getFilterBuilder() {
             }
         } else if (op.getOperator().equals(Operators.LESS_THAN.value())) {
             return QueryBuilders.rangeQuery(name.getName()).to(value.getValue()).includeLower(false).includeUpper(false);
+        } else if (op.getOperator().equals(Operators.STARTS_WITH.value())) {
+            return QueryBuilders.prefixQuery(name.getName(), value.getUnquotedValue());
         }
 
         throw new IllegalStateException("Incorrect/unsupported operators");

File: es6-persistence/src/test/java/com/netflix/conductor/elasticsearch/query/parser/TestComparisonOp.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 /**
- * 
+ *
  */
 package com.netflix.conductor.elasticsearch.query.parser;
 
@@ -32,15 +32,15 @@ public class TestComparisonOp extends AbstractParserTest {
 
 	@Test
 	public void test() throws Exception {
-		String[] tests = new String[]{"<",">","=","!=","IN"};
+		String[] tests = new String[]{"<",">","=","!=","IN","STARTS_WITH"};
 		for(String test : tests){
 			ComparisonOp name = new ComparisonOp(getInputStream(test));
 			String nameVal = name.getOperator();
 			assertNotNull(nameVal);
 			assertEquals(test, nameVal);
 		}
 	}
-	
+
 	@Test(expected=ParserException.class)
 	public void testInvalidOp() throws Exception {
 		String test =  "AND";

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/query/parser/NameValue.java
Patch:
@@ -33,7 +33,7 @@
  * @author Viren
  * <pre>
  * Represents an expression of the form as below:
- * key OPR value 
+ * key OPR value
  * OPR is the comparison operator which could be on the following:
  * 	&gt;, &lt;, = , !=, IN, BETWEEN
  * </pre>
@@ -115,6 +115,8 @@ public QueryBuilder getFilterBuilder() {
             }
         } else if (op.getOperator().equals(Operators.LESS_THAN.value())) {
             return QueryBuilders.rangeQuery(name.getName()).to(value.getValue()).includeLower(false).includeUpper(false);
+        } else if (op.getOperator().equals(Operators.STARTS_WITH.value())) {
+            return QueryBuilders.prefixQuery(name.getName(), value.getUnquotedValue());
         }
 
         throw new IllegalStateException("Incorrect/unsupported operators");

File: es5-persistence/src/test/java/com/netflix/conductor/elasticsearch/query/parser/TestComparisonOp.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 /**
- * 
+ *
  */
 package com.netflix.conductor.elasticsearch.query.parser;
 
@@ -32,15 +32,15 @@ public class TestComparisonOp extends AbstractParserTest {
 
 	@Test
 	public void test() throws Exception {
-		String[] tests = new String[]{"<",">","=","!=","IN"};
+		String[] tests = new String[]{"<",">","=","!=","IN","STARTS_WITH"};
 		for(String test : tests){
 			ComparisonOp name = new ComparisonOp(getInputStream(test));
 			String nameVal = name.getOperator();
 			assertNotNull(nameVal);
 			assertEquals(test, nameVal);
 		}
 	}
-	
+
 	@Test(expected=ParserException.class)
 	public void testInvalidOp() throws Exception {
 		String test =  "AND";

File: es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/query/parser/NameValue.java
Patch:
@@ -33,7 +33,7 @@
  * @author Viren
  * <pre>
  * Represents an expression of the form as below:
- * key OPR value 
+ * key OPR value
  * OPR is the comparison operator which could be on the following:
  * 	&gt;, &lt;, = , !=, IN, BETWEEN
  * </pre>
@@ -115,6 +115,8 @@ public QueryBuilder getFilterBuilder() {
             }
         } else if (op.getOperator().equals(Operators.LESS_THAN.value())) {
             return QueryBuilders.rangeQuery(name.getName()).to(value.getValue()).includeLower(false).includeUpper(false);
+        } else if (op.getOperator().equals(Operators.STARTS_WITH.value())) {
+            return QueryBuilders.prefixQuery(name.getName(), value.getUnquotedValue());
         }
 
         throw new IllegalStateException("Incorrect/unsupported operators");

File: es6-persistence/src/test/java/com/netflix/conductor/elasticsearch/query/parser/TestComparisonOp.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 /**
- * 
+ *
  */
 package com.netflix.conductor.elasticsearch.query.parser;
 
@@ -32,15 +32,15 @@ public class TestComparisonOp extends AbstractParserTest {
 
 	@Test
 	public void test() throws Exception {
-		String[] tests = new String[]{"<",">","=","!=","IN"};
+		String[] tests = new String[]{"<",">","=","!=","IN","STARTS_WITH"};
 		for(String test : tests){
 			ComparisonOp name = new ComparisonOp(getInputStream(test));
 			String nameVal = name.getOperator();
 			assertNotNull(nameVal);
 			assertEquals(test, nameVal);
 		}
 	}
-	
+
 	@Test(expected=ParserException.class)
 	public void testInvalidOp() throws Exception {
 		String test =  "AND";

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -73,7 +73,7 @@ public interface Configuration {
     String IGNORE_LOCKING_EXCEPTIONS_PROPERTY_NAME = "workflow.decider.locking.exceptions.ignore";
     boolean IGNORE_LOCKING_EXCEPTIONS_DEFAULT_VALUE = false;
 
-    String EVENT_MESSAGE_INDEXING_ENABLED_PROPERTY_NAME = "worklfow.event.message.indexing.enabled";
+    String EVENT_MESSAGE_INDEXING_ENABLED_PROPERTY_NAME = "workflow.event.message.indexing.enabled";
     boolean EVENT_MESSAGE_INDEXING_ENABLED_DEFAULT_VALUE = true;
 
     String TASKEXECLOG_INDEXING_ENABLED_PROPERTY_NAME = "workflow.taskExecLog.indexing.enabled";
@@ -88,7 +88,7 @@ public interface Configuration {
     String EVENT_HANDLER_REFRESH_TIME_SECS_PROPERTY_NAME = "conductor.eventhandler.cache.refresh.time.seconds";
     int EVENT_HANDLER_REFRESH_TIME_SECS_DEFAULT_VALUE = 60;
 
-    String EVENT_EXECUTION_PERSISTENCE_TTL_SECS_PROPERTY_NAME = "workflow.event.execution.peristence.ttl.seconds";
+    String EVENT_EXECUTION_PERSISTENCE_TTL_SECS_PROPERTY_NAME = "workflow.event.execution.persistence.ttl.seconds";
     int EVENT_EXECUTION_PERSISTENCE_TTL_SECS_DEFAULT_VALUE = 0;
 
     String OWNER_EMAIL_MANDATORY_NAME = "workflow.owner.email.mandatory";

File: core/src/main/java/com/netflix/conductor/dao/ExecutionDAO.java
Patch:
@@ -221,7 +221,7 @@ public interface ExecutionDAO {
 	 * @return true if the event was added.  false otherwise when the event by id is already already stored.
 	 */
 	boolean addEventExecution(EventExecution ee);
-	
+
 	/**
 	 * 
 	 * @param ee Event execution to be updated

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -78,10 +78,9 @@ public class ExecutionService {
     private final int taskRequeueTimeout;
 	private int queueTaskMessagePostponeSeconds;
 
-    private static final int MAX_POLL_TIMEOUT_MS = 5000;
+	private static final int MAX_POLL_TIMEOUT_MS = 5000;
     private static final int POLL_COUNT_ONE = 1;
     private static final int POLLING_TIMEOUT_IN_MS = 100;
-
     private static final int MAX_SEARCH_SIZE = 5_000;
 
 	@Inject
@@ -96,6 +95,7 @@ public ExecutionService(WorkflowExecutor workflowExecutor,
 		this.metadataDAO = metadataDAO;
 		this.queueDAO = queueDAO;
 		this.externalPayloadStorage = externalPayloadStorage;
+
 		this.taskRequeueTimeout = config.getIntProperty("task.requeue.timeout", 60_000);
 		this.queueTaskMessagePostponeSeconds = config.getIntProperty("task.queue.message.postponeSeconds", 60);
 	}

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowDef.java
Patch:
@@ -300,6 +300,9 @@ public WorkflowTask getNextTask(String taskReferenceName){
 			 WorkflowTask nextTask = task.next(taskReferenceName, null);
 			 if(nextTask != null){
 				 return nextTask;
+			 } else if (TaskType.DO_WHILE.name().equals(task.getType()) && !task.getTaskReferenceName().equals(taskReferenceName) && task.has(taskReferenceName)) {
+			 	// If the task is child of Loop Task and at last position, return null.
+			 	return null;
 			 }
 
 			 if(task.getTaskReferenceName().equals(taskReferenceName) || task.has(taskReferenceName)){

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -192,7 +192,7 @@ private DeciderOutcome decide(final Workflow workflow, List<Task> preScheduledTa
             if (!pendingTask.isExecuted() && !pendingTask.isRetried() && pendingTask.getStatus().isTerminal()) {
                 pendingTask.setExecuted(true);
                 List<Task> nextTasks = getNextTask(workflow, pendingTask);
-                if (pendingTask.isLoopOverTask() && !nextTasks.isEmpty()) {
+                if (pendingTask.isLoopOverTask() && !TaskType.DO_WHILE.name().equals(pendingTask.getTaskType()) && !nextTasks.isEmpty()) {
                     nextTasks = filterNextLoopOverTasks(nextTasks, pendingTask, workflow);
                 }
                 nextTasks.forEach(nextTask -> tasksToBeScheduled.putIfAbsent(nextTask.getReferenceTaskName(), nextTask));

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -403,7 +403,9 @@ Optional<Task> retry(TaskDef taskDefinition, WorkflowTask workflowTask, Task tas
                 startDelay = taskDefinition.getRetryDelaySeconds();
                 break;
             case EXPONENTIAL_BACKOFF:
-                startDelay = taskDefinition.getRetryDelaySeconds() * (1 + task.getRetryCount());
+                int retryDelaySeconds = taskDefinition.getRetryDelaySeconds() * (int) Math.pow(2, task.getRetryCount());
+                // Reset integer overflow to max value
+                startDelay = retryDelaySeconds < 0 ? Integer.MAX_VALUE : retryDelaySeconds;
                 break;
         }
 

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -80,7 +80,7 @@ public interface Configuration {
     boolean TASKEXECLOG_INDEXING_ENABLED_DEFAULT_VALUE = true;
 
     String INDEXING_ENABLED_PROPERTY_NAME = "workflow.indexing.enabled";
-    boolean INDEXING_ENABLED_DEFAULT_VALUE = false;
+    boolean INDEXING_ENABLED_DEFAULT_VALUE = true;
 
     String TASK_DEF_REFRESH_TIME_SECS_PROPERTY_NAME = "conductor.taskdef.cache.refresh.time.seconds";
     int TASK_DEF_REFRESH_TIME_SECS_DEFAULT_VALUE = 60;

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -403,7 +403,9 @@ Optional<Task> retry(TaskDef taskDefinition, WorkflowTask workflowTask, Task tas
                 startDelay = taskDefinition.getRetryDelaySeconds();
                 break;
             case EXPONENTIAL_BACKOFF:
-                startDelay = taskDefinition.getRetryDelaySeconds() * (1 + task.getRetryCount());
+                int retryDelaySeconds = taskDefinition.getRetryDelaySeconds() * (int) Math.pow(2, task.getRetryCount());
+                // Reset integer overflow to max value
+                startDelay = retryDelaySeconds < 0 ? Integer.MAX_VALUE : retryDelaySeconds;
                 break;
         }
 

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractWorkflowServiceTest.java
Patch:
@@ -1849,7 +1849,7 @@ private void createDoWhileWorkflowWithIteration(int iteration, boolean isInputPa
 
         workflowDef.getTasks().add(loopTask);
 
-        if (iteration ==2) {
+        if (iteration == 2 && isInputParameter == false) {
             TaskDef taskDef2 = new TaskDef();
             taskDef2.setName("loopTask2");
             taskDef2.setTimeoutSeconds(200);

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -485,7 +485,7 @@ public Workflow copy() {
 		copy.setWorkflowDefinition(workflowDefinition);
 		copy.setPriority(priority);
 		copy.setTasks(tasks.stream()
-				.map(Task::copy)
+				.map(Task::deepCopy)
 				.collect(Collectors.toList()));
 		return copy;
 	}
@@ -549,4 +549,5 @@ public int hashCode() {
 				getPriority()
         );
     }
+
 }

File: client/src/main/java/com/netflix/conductor/client/http/WorkflowClient.java
Patch:
@@ -274,7 +274,7 @@ public void skipTaskFromWorkflow(String workflowId, String taskReferenceName) {
         Preconditions.checkArgument(StringUtils.isNotBlank(workflowId), "workflow id cannot be blank");
         Preconditions.checkArgument(StringUtils.isNotBlank(taskReferenceName), "Task reference name cannot be blank");
 
-        put("workflow/{workflowId}/skiptask/{taskReferenceName}", null, workflowId, taskReferenceName);
+        put("workflow/{workflowId}/skiptask/{taskReferenceName}", null, null, workflowId, taskReferenceName);
     }
 
     /**

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractHttpEndToEndTest.java
Patch:
@@ -207,6 +207,8 @@ public void testAll() throws Exception {
         assertNotNull(workflow);
         assertEquals(WorkflowStatus.RUNNING, workflow.getStatus());
         assertEquals(1, workflow.getTasks().size());
+
+        workflowClient.skipTaskFromWorkflow(workflowId, "t1");
     }
 
     @Test(expected = ConductorClientException.class)

File: client/src/main/java/com/netflix/conductor/client/http/WorkflowClient.java
Patch:
@@ -274,7 +274,7 @@ public void skipTaskFromWorkflow(String workflowId, String taskReferenceName) {
         Preconditions.checkArgument(StringUtils.isNotBlank(workflowId), "workflow id cannot be blank");
         Preconditions.checkArgument(StringUtils.isNotBlank(taskReferenceName), "Task reference name cannot be blank");
 
-        put("workflow/{workflowId}/skiptask/{taskReferenceName}", null, workflowId, taskReferenceName);
+        put("workflow/{workflowId}/skiptask/{taskReferenceName}", null, null, workflowId, taskReferenceName);
     }
 
     /**

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractHttpEndToEndTest.java
Patch:
@@ -207,6 +207,8 @@ public void testAll() throws Exception {
         assertNotNull(workflow);
         assertEquals(WorkflowStatus.RUNNING, workflow.getStatus());
         assertEquals(1, workflow.getTasks().size());
+
+        workflowClient.skipTaskFromWorkflow(workflowId, "t1");
     }
 
     @Test(expected = ConductorClientException.class)

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -485,7 +485,7 @@ public Workflow copy() {
 		copy.setWorkflowDefinition(workflowDefinition);
 		copy.setPriority(priority);
 		copy.setTasks(tasks.stream()
-				.map(Task::copy)
+				.map(Task::deepCopy)
 				.collect(Collectors.toList()));
 		return copy;
 	}
@@ -549,4 +549,5 @@ public int hashCode() {
 				getPriority()
         );
     }
+
 }

File: server/src/main/java/com/netflix/conductor/bootstrap/ModulesProvider.java
Patch:
@@ -60,7 +60,8 @@ public class ModulesProvider implements Provider<List<AbstractModule>> {
     private final Configuration configuration;
 
     enum ExternalPayloadStorageType {
-        S3
+        S3,
+        DUMMY
     }
 
     @Inject
@@ -163,7 +164,7 @@ private List<AbstractModule> selectModulesToLoad() {
         }
 
         ExternalPayloadStorageType externalPayloadStorageType = null;
-        String externalPayloadStorageString = configuration.getProperty("workflow.external.payload.storage", "");
+        String externalPayloadStorageString = configuration.getProperty("workflow.external.payload.storage", "DUMMY");
         try {
             externalPayloadStorageType = ExternalPayloadStorageType.valueOf(externalPayloadStorageString);
         } catch (IllegalArgumentException e) {

File: server/src/main/java/com/netflix/conductor/bootstrap/ModulesProvider.java
Patch:
@@ -60,7 +60,8 @@ public class ModulesProvider implements Provider<List<AbstractModule>> {
     private final Configuration configuration;
 
     enum ExternalPayloadStorageType {
-        S3
+        S3,
+        DUMMY
     }
 
     @Inject
@@ -163,7 +164,7 @@ private List<AbstractModule> selectModulesToLoad() {
         }
 
         ExternalPayloadStorageType externalPayloadStorageType = null;
-        String externalPayloadStorageString = configuration.getProperty("workflow.external.payload.storage", "");
+        String externalPayloadStorageString = configuration.getProperty("workflow.external.payload.storage", "DUMMY");
         try {
             externalPayloadStorageType = ExternalPayloadStorageType.valueOf(externalPayloadStorageString);
         } catch (IllegalArgumentException e) {

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -736,7 +736,7 @@ public void testDecideWithLoopTask() {
         assertEquals(1, deciderOutcome.tasksToBeUpdated.size());
         assertEquals("s1", deciderOutcome.tasksToBeUpdated.get(0).getReferenceTaskName());
         assertEquals(1, deciderOutcome.tasksToBeScheduled.size());
-        assertEquals("s2", deciderOutcome.tasksToBeScheduled.get(0).getReferenceTaskName());
+        assertEquals("s2__1", deciderOutcome.tasksToBeScheduled.get(0).getReferenceTaskName());
         assertEquals(0, deciderOutcome.tasksToBeRequeued.size());
         assertFalse(deciderOutcome.isComplete);
     }

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -190,7 +190,7 @@ private DeciderOutcome decide(final Workflow workflow, List<Task> preScheduledTa
             if (!pendingTask.isExecuted() && !pendingTask.isRetried() && pendingTask.getStatus().isTerminal()) {
                 pendingTask.setExecuted(true);
                 List<Task> nextTasks = getNextTask(workflow, pendingTask);
-                if (pendingTask.isLoopOverTask() && nextTasks.stream().allMatch(task -> task.isLoopOverTask() && !task.getTaskType().equals(TaskType.DO_WHILE.name()))) {
+                if (pendingTask.isLoopOverTask() && !TaskType.DO_WHILE.name().equals(pendingTask.getTaskType()) && !nextTasks.isEmpty()) {
                     nextTasks = filterNextLoopOverTasks(nextTasks, pendingTask, workflow);
                 }
                 nextTasks.forEach(nextTask -> tasksToBeScheduled.putIfAbsent(nextTask.getReferenceTaskName(), nextTask));

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -26,6 +26,7 @@
 import java.util.Map;
 import java.util.Objects;
 import java.util.Optional;
+import org.apache.commons.lang3.StringUtils;
 
 @ProtoMessage
 public class Task {
@@ -541,7 +542,7 @@ public String getReasonForIncompletion() {
      * @param reasonForIncompletion the reasonForIncompletion to set
      */
     public void setReasonForIncompletion(String reasonForIncompletion) {
-        this.reasonForIncompletion = reasonForIncompletion;
+        this.reasonForIncompletion = StringUtils.substring(reasonForIncompletion, 0, 500);
     }
 
     /**

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskResult.java
Patch:
@@ -20,12 +20,12 @@
 import com.github.vmg.protogen.annotations.ProtoField;
 import com.github.vmg.protogen.annotations.ProtoMessage;
 import com.google.protobuf.Any;
-
-import javax.validation.constraints.NotEmpty;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.CopyOnWriteArrayList;
+import javax.validation.constraints.NotEmpty;
+import org.apache.commons.lang3.StringUtils;
 
 /**
  * @author Viren
@@ -121,7 +121,7 @@ public String getReasonForIncompletion() {
     }
 
     public void setReasonForIncompletion(String reasonForIncompletion) {
-        this.reasonForIncompletion = reasonForIncompletion;
+        this.reasonForIncompletion = StringUtils.substring(reasonForIncompletion, 0, 500);
     }
 
     public long getCallbackAfterSeconds() {

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -26,6 +26,7 @@
 import java.util.Map;
 import java.util.Objects;
 import java.util.Optional;
+import org.apache.commons.lang3.StringUtils;
 
 @ProtoMessage
 public class Task {
@@ -541,7 +542,7 @@ public String getReasonForIncompletion() {
      * @param reasonForIncompletion the reasonForIncompletion to set
      */
     public void setReasonForIncompletion(String reasonForIncompletion) {
-        this.reasonForIncompletion = reasonForIncompletion;
+        this.reasonForIncompletion = StringUtils.substring(reasonForIncompletion, 0, 500);
     }
 
     /**

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskResult.java
Patch:
@@ -20,12 +20,12 @@
 import com.github.vmg.protogen.annotations.ProtoField;
 import com.github.vmg.protogen.annotations.ProtoMessage;
 import com.google.protobuf.Any;
-
-import javax.validation.constraints.NotEmpty;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.CopyOnWriteArrayList;
+import javax.validation.constraints.NotEmpty;
+import org.apache.commons.lang3.StringUtils;
 
 /**
  * @author Viren
@@ -121,7 +121,7 @@ public String getReasonForIncompletion() {
     }
 
     public void setReasonForIncompletion(String reasonForIncompletion) {
-        this.reasonForIncompletion = reasonForIncompletion;
+        this.reasonForIncompletion = StringUtils.substring(reasonForIncompletion, 0, 500);
     }
 
     public long getCallbackAfterSeconds() {

File: client/src/main/java/com/netflix/conductor/client/http/ClientBase.java
Patch:
@@ -179,7 +179,6 @@ private <T> T getForEntity(String url, Object[] queryParams, Function<ClientResp
                     .get(ClientResponse.class);
             if (clientResponse.getStatus() < 300) {
                 return entityProvider.apply(clientResponse);
-
             } else {
                 throw new UniformInterfaceException(clientResponse);
             }

File: client/src/main/java/com/netflix/conductor/client/http/TaskClient.java
Patch:
@@ -36,6 +36,7 @@
 import java.io.IOException;
 import java.util.List;
 import java.util.Map;
+import java.util.Optional;
 import org.apache.commons.lang.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -121,7 +122,8 @@ public Task pollTask(String taskType, String workerId, String domain) {
         Preconditions.checkArgument(StringUtils.isNotBlank(workerId), "Worker id cannot be blank");
 
         Object[] params = new Object[]{"workerid", workerId, "domain", domain};
-        Task task = getForEntity("tasks/poll/{taskType}", params, Task.class, taskType);
+        Task task = Optional.ofNullable(getForEntity("tasks/poll/{taskType}", params, Task.class, taskType))
+            .orElse(new Task());
         populateTaskInput(task);
         return task;
     }

File: client/src/main/java/com/netflix/conductor/client/http/ClientBase.java
Patch:
@@ -179,7 +179,6 @@ private <T> T getForEntity(String url, Object[] queryParams, Function<ClientResp
                     .get(ClientResponse.class);
             if (clientResponse.getStatus() < 300) {
                 return entityProvider.apply(clientResponse);
-
             } else {
                 throw new UniformInterfaceException(clientResponse);
             }

File: client/src/main/java/com/netflix/conductor/client/http/TaskClient.java
Patch:
@@ -36,6 +36,7 @@
 import java.io.IOException;
 import java.util.List;
 import java.util.Map;
+import java.util.Optional;
 import org.apache.commons.lang.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -121,7 +122,8 @@ public Task pollTask(String taskType, String workerId, String domain) {
         Preconditions.checkArgument(StringUtils.isNotBlank(workerId), "Worker id cannot be blank");
 
         Object[] params = new Object[]{"workerid", workerId, "domain", domain};
-        Task task = getForEntity("tasks/poll/{taskType}", params, Task.class, taskType);
+        Task task = Optional.ofNullable(getForEntity("tasks/poll/{taskType}", params, Task.class, taskType))
+            .orElse(new Task());
         populateTaskInput(task);
         return task;
     }

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -736,7 +736,7 @@ public void testDecideWithLoopTask() {
         assertEquals(1, deciderOutcome.tasksToBeUpdated.size());
         assertEquals("s1", deciderOutcome.tasksToBeUpdated.get(0).getReferenceTaskName());
         assertEquals(1, deciderOutcome.tasksToBeScheduled.size());
-        assertEquals("s2__1", deciderOutcome.tasksToBeScheduled.get(0).getReferenceTaskName());
+        assertEquals("s2", deciderOutcome.tasksToBeScheduled.get(0).getReferenceTaskName());
         assertEquals(0, deciderOutcome.tasksToBeRequeued.size());
         assertFalse(deciderOutcome.isComplete);
     }

File: client/src/test/java/com/netflix/conductor/client/http/MetadataClientTest.java
Patch:
@@ -6,8 +6,8 @@
 import org.junit.rules.ExpectedException;
 import org.mockito.Mockito;
 
-import static org.mockito.Matchers.any;
-import static org.mockito.Matchers.anyString;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Mockito.doThrow;
 import static org.mockito.Mockito.times;
 import static org.mockito.Mockito.verify;
@@ -59,4 +59,4 @@ public void testWorkflowDeleteNameMissing() {
         expectedException.expectMessage("Workflow name cannot be blank");
         metadataClient.unregisterWorkflowDef(null, 1);
     }
-}
\ No newline at end of file
+}

File: contribs/src/test/java/com/netflix/conductor/contribs/queue/sqs/TestSQSObservableQueue.java
Patch:
@@ -36,7 +36,7 @@
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
-import static org.mockito.Matchers.any;
+import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 

File: core/src/test/java/com/netflix/conductor/core/events/TestSimpleEventProcessor.java
Patch:
@@ -52,7 +52,7 @@
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
-import static org.mockito.Matchers.any;
+import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.Mockito.atMost;
 import static org.mockito.Mockito.doAnswer;
 import static org.mockito.Mockito.mock;

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -17,7 +17,7 @@
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNotSame;
 import static org.junit.Assert.assertTrue;
-import static org.mockito.Matchers.anyString;
+import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -19,9 +19,9 @@
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
-import static org.mockito.Matchers.any;
-import static org.mockito.Matchers.anyInt;
-import static org.mockito.Matchers.anyString;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.ArgumentMatchers.anyInt;
+import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 

File: core/src/test/java/com/netflix/conductor/core/execution/TestParametersUtils.java
Patch:
@@ -10,8 +10,8 @@
 import java.util.List;
 import java.util.Map;
 
-import static junit.framework.Assert.assertNotNull;
-import static junit.framework.Assert.assertNull;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertEquals;
 
 public class TestParametersUtils {

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/DynamicTaskMapperTest.java
Patch:
@@ -34,9 +34,9 @@
 import java.util.Map;
 
 import static org.junit.Assert.assertEquals;
-import static org.mockito.Matchers.any;
-import static org.mockito.Matchers.anyMap;
-import static org.mockito.Matchers.anyString;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.ArgumentMatchers.anyMap;
+import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/EventTaskMapperTest.java
Patch:
@@ -15,9 +15,9 @@
 import java.util.Map;
 
 import static org.junit.Assert.*;
-import static org.mockito.Matchers.any;
-import static org.mockito.Matchers.anyMap;
-import static org.mockito.Matchers.anyString;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.ArgumentMatchers.anyMap;
+import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Mockito.when;
 
 public class EventTaskMapperTest {

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/DoWhileTest.java
Patch:
@@ -12,7 +12,7 @@
  */
 package com.netflix.conductor.core.execution.tasks;
 
-import static org.mockito.Matchers.isA;
+import static org.mockito.ArgumentMatchers.isA;
 import static org.mockito.Mockito.spy;
 import static org.mockito.Mockito.times;
 

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestSubWorkflow.java
Patch:
@@ -14,8 +14,8 @@
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
-import static org.mockito.Matchers.any;
-import static org.mockito.Matchers.eq;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.ArgumentMatchers.eq;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestSystemTaskWorkerCoordinator.java
Patch:
@@ -42,8 +42,8 @@ public void testPollAndExecuteForTaskQueues() {
 
 		Configuration configuration = Mockito.mock(Configuration.class);
 		QueueDAO queueDao = Mockito.mock(QueueDAO.class);
-		Mockito.when(configuration.getIntProperty(Mockito.anyString(), Mockito.anyInt())).thenReturn(10);
-		Mockito.when(queueDao.pop(Mockito.anyString(), Mockito.anyInt(), Mockito.anyInt())).thenReturn(Arrays.asList("taskId"));
+		Mockito.when(configuration.getIntProperty(Mockito.any(), Mockito.anyInt())).thenReturn(10);
+		Mockito.when(queueDao.pop(Mockito.any(), Mockito.anyInt(), Mockito.anyInt())).thenReturn(Arrays.asList("taskId"));
 		WorkflowExecutor wfE = Mockito.mock(WorkflowExecutor.class);
 		SystemTaskWorkerCoordinator systemTaskWorkerCoordinator = new SystemTaskWorkerCoordinator(queueDao, wfE, configuration);
 

File: core/src/test/java/com/netflix/conductor/service/MetadataServiceTest.java
Patch:
@@ -25,7 +25,7 @@
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
-import static org.mockito.Matchers.any;
+import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.Mockito.times;
 import static org.mockito.Mockito.verify;
 import static com.netflix.conductor.utility.TestUtils.getConstraintViolationMessages;

File: core/src/test/java/com/netflix/conductor/validations/WorkflowDefConstraintTest.java
Patch:
@@ -19,7 +19,7 @@
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
-import static org.mockito.Matchers.anyString;
+import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Mockito.when;
 
 public class WorkflowDefConstraintTest {

File: core/src/test/java/com/netflix/conductor/validations/WorkflowTaskTypeConstraintTest.java
Patch:
@@ -24,7 +24,7 @@
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
-import static org.mockito.Matchers.anyString;
+import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Mockito.when;
 
 public class WorkflowTaskTypeConstraintTest {

File: jersey/src/test/java/com/netflix/conductor/server/resources/MetadataResourceTest.java
Patch:
@@ -27,8 +27,8 @@
 import java.util.List;
 
 import static org.junit.Assert.assertEquals;
-import static org.mockito.Matchers.any;
-import static org.mockito.Matchers.anyList;
+import static org.mockito.Mockito.any;
+import static org.mockito.Mockito.anyList;
 import static org.mockito.Mockito.anyString;
 import static org.mockito.Mockito.times;
 import static org.mockito.Mockito.verify;

File: redis-persistence/src/test/java/com/netflix/conductor/dao/dynomite/BaseDynoDAOTest.java
Patch:
@@ -8,7 +8,7 @@
 import org.junit.runner.RunWith;
 import org.mockito.Mock;
 import org.mockito.Mockito;
-import org.mockito.runners.MockitoJUnitRunner;
+import org.mockito.junit.MockitoJUnitRunner;
 
 import static org.junit.Assert.assertEquals;
 
@@ -46,4 +46,4 @@ public void testNsKey() {
         Mockito.when(config.getStack()).thenReturn("stack");
         assertEquals("test.stack.key1.key2", baseDynoDAO.nsKey(keys));
     }
-}
\ No newline at end of file
+}

File: redis-persistence/src/test/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAOTest.java
Patch:
@@ -26,7 +26,7 @@
 import org.junit.Before;
 import org.junit.Test;
 import org.junit.runner.RunWith;
-import org.mockito.runners.MockitoJUnitRunner;
+import org.mockito.junit.MockitoJUnitRunner;
 import redis.clients.jedis.commands.JedisCommands;
 
 import java.util.Collections;

File: redis-persistence/src/test/java/com/netflix/conductor/dao/dynomite/RedisRateLimitDaoTest.java
Patch:
@@ -11,7 +11,7 @@
 import org.junit.Before;
 import org.junit.Test;
 import org.junit.runner.RunWith;
-import org.mockito.runners.MockitoJUnitRunner;
+import org.mockito.junit.MockitoJUnitRunner;
 import redis.clients.jedis.commands.JedisCommands;
 
 import java.util.UUID;

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowLegacyMigrationTest.java
Patch:
@@ -27,12 +27,12 @@
 import com.netflix.conductor.core.utils.IDGenerator;
 import com.netflix.conductor.dao.ExecutionDAO;
 import com.netflix.conductor.tests.utils.TestRunner;
-import org.apache.commons.io.Charsets;
 import org.junit.Ignore;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 
 import javax.inject.Inject;
+import java.nio.charset.StandardCharsets;
 import java.util.Map;
 
 import static org.junit.Assert.fail;
@@ -99,7 +99,7 @@ public String startOrLoadWorkflowExecution(String snapshotResourceName, String w
 
     private Workflow loadWorkflowSnapshot(String resourcePath) throws Exception {
 
-        String content = Resources.toString(WorkflowLegacyMigrationTest.class.getResource(resourcePath), Charsets.UTF_8);
+        String content = Resources.toString(WorkflowLegacyMigrationTest.class.getResource(resourcePath), StandardCharsets.UTF_8);
         String workflowId = IDGenerator.generate();
         content = content.replace(WORKFLOW_INSTANCE_ID_PLACEHOLDER, workflowId);
 

File: contribs/src/test/java/com/netflix/conductor/contribs/http/TestHttpTask.java
Patch:
@@ -28,6 +28,7 @@
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
+import com.netflix.conductor.common.utils.JsonMapperProvider;
 import com.netflix.conductor.contribs.http.HttpTask.Input;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.execution.DeciderService;
@@ -83,11 +84,10 @@ public class TestHttpTask {
 
     private static Server server;
 
-    private static ObjectMapper objectMapper = new ObjectMapper();
+    private static ObjectMapper objectMapper = new JsonMapperProvider().get();
 
     @BeforeClass
     public static void init() throws Exception {
-
         Map<String, Object> map = new HashMap<>();
         map.put("key", "value1");
         map.put("num", 42);
@@ -116,7 +116,7 @@ public void setup() {
         config = mock(Configuration.class);
         RestClientManager rcm = new RestClientManager(Mockito.mock(Configuration.class));
         when(config.getServerId()).thenReturn("test_server_id");
-        httpTask = new HttpTask(rcm, config);
+        httpTask = new HttpTask(rcm, config, objectMapper);
     }
 
     @Test

File: server/src/main/java/com/netflix/conductor/bootstrap/ModulesProvider.java
Patch:
@@ -5,6 +5,7 @@
 import com.google.inject.util.Modules;
 import com.netflix.conductor.cassandra.CassandraModule;
 import com.netflix.conductor.common.utils.ExternalPayloadStorage;
+import com.netflix.conductor.common.utils.JsonMapperProvider;
 import com.netflix.conductor.contribs.http.HttpTask;
 import com.netflix.conductor.contribs.http.RestClientManager;
 import com.netflix.conductor.contribs.json.JsonJqTransform;
@@ -169,7 +170,7 @@ protected void configure() {
             });
         }
 
-        new HttpTask(new RestClientManager(configuration), configuration);
+        new HttpTask(new RestClientManager(configuration), configuration, new JsonMapperProvider().get());
         new KafkaPublishTask(configuration, new KafkaProducerManager(configuration));
         new JsonJqTransform();
         modules.add(new ServerModule());

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -527,12 +527,13 @@ public void retry(String workflowId) {
         for (Task task : workflow.getTasks()) {
             switch (task.getStatus()) {
                 case FAILED:
+                case FAILED_WITH_TERMINAL_ERROR:
                     retriableMap.put(task.getReferenceTaskName(), task);
                     break;
                 case CANCELED:
                     if (task.getTaskType().equalsIgnoreCase(TaskType.JOIN.toString())) {
                         task.setStatus(IN_PROGRESS);
-                        // Task doesn't have to updated yet. Will be updated along with other Workflow tasks downstream.
+                        // Task doesn't have to be updated yet. Will be updated along with other Workflow tasks downstream.
                     } else {
                         retriableMap.put(task.getReferenceTaskName(), task);
                     }

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -527,12 +527,13 @@ public void retry(String workflowId) {
         for (Task task : workflow.getTasks()) {
             switch (task.getStatus()) {
                 case FAILED:
+                case FAILED_WITH_TERMINAL_ERROR:
                     retriableMap.put(task.getReferenceTaskName(), task);
                     break;
                 case CANCELED:
                     if (task.getTaskType().equalsIgnoreCase(TaskType.JOIN.toString())) {
                         task.setStatus(IN_PROGRESS);
-                        // Task doesn't have to updated yet. Will be updated along with other Workflow tasks downstream.
+                        // Task doesn't have to be updated yet. Will be updated along with other Workflow tasks downstream.
                     } else {
                         retriableMap.put(task.getReferenceTaskName(), task);
                     }

File: core/src/main/java/com/netflix/conductor/core/execution/ParametersUtils.java
Patch:
@@ -70,7 +70,7 @@ public Map<String, Object> getTaskInputV2(Map<String, Object> input, Workflow wo
             inputParams = new HashMap<>();
         }
         if (taskDefinition != null && taskDefinition.getInputTemplate() != null) {
-            inputParams.putAll(clone(taskDefinition.getInputTemplate()));
+            clone(taskDefinition.getInputTemplate()).forEach(inputParams::putIfAbsent);
         }
 
         Map<String, Map<String, Object>> inputMap = new HashMap<>();

File: core/src/main/java/com/netflix/conductor/core/execution/ParametersUtils.java
Patch:
@@ -70,7 +70,7 @@ public Map<String, Object> getTaskInputV2(Map<String, Object> input, Workflow wo
             inputParams = new HashMap<>();
         }
         if (taskDefinition != null && taskDefinition.getInputTemplate() != null) {
-            inputParams.putAll(clone(taskDefinition.getInputTemplate()));
+            clone(taskDefinition.getInputTemplate()).forEach(inputParams::putIfAbsent);
         }
 
         Map<String, Map<String, Object>> inputMap = new HashMap<>();

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -490,7 +490,7 @@ void checkForTimeout(TaskDef taskDef, Task task) {
             LOGGER.warn("missing task type " + task.getTaskDefName() + ", workflowId=" + task.getWorkflowInstanceId());
             return;
         }
-        if (task.getStatus().isTerminal() || taskDef.getTimeoutSeconds() <= 0 || !task.getStatus().equals(IN_PROGRESS)) {
+        if (task.getStatus().isTerminal() || taskDef.getTimeoutSeconds() <= 0 || task.getStartTime() <= 0) {
             return;
         }
 

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -490,7 +490,7 @@ void checkForTimeout(TaskDef taskDef, Task task) {
             LOGGER.warn("missing task type " + task.getTaskDefName() + ", workflowId=" + task.getWorkflowInstanceId());
             return;
         }
-        if (task.getStatus().isTerminal() || taskDef.getTimeoutSeconds() <= 0 || !task.getStatus().equals(IN_PROGRESS)) {
+        if (task.getStatus().isTerminal() || taskDef.getTimeoutSeconds() <= 0 || task.getStartTime() <= 0) {
             return;
         }
 

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -65,7 +65,7 @@ public interface Configuration {
     String ADDITIONAL_MODULES_PROPERTY_NAME = "conductor.additional.modules";
 
     String EXECUTION_LOCK_ENABLED_PROPERTY_NAME = "decider.locking.enabled";
-    boolean EXECUTION_LOCK_ENABLED_DEFAULT_VALUE = true;
+    boolean EXECUTION_LOCK_ENABLED_DEFAULT_VALUE = false;
 
     //TODO add constants for input/output external payload related properties.
 

File: contribs/src/test/java/com/netflix/conductor/contribs/http/TestHttpTask.java
Patch:
@@ -292,7 +292,7 @@ public void testHTTPGetConnectionTimeOut() throws Exception{
         Instant start  = Instant.now();
         input.setConnectionTimeOut(110);
         input.setMethod("GET");
-        input.setUri("http://10.255.255.255");
+        input.setUri("http://10.255.14.15");
         task.getInputData().put(HttpTask.REQUEST_PARAMETER_NAME, input);
         task.setStatus(Status.SCHEDULED);
         task.setScheduledTime(0);

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -65,7 +65,7 @@ public interface Configuration {
     String ADDITIONAL_MODULES_PROPERTY_NAME = "conductor.additional.modules";
 
     String EXECUTION_LOCK_ENABLED_PROPERTY_NAME = "decider.locking.enabled";
-    boolean EXECUTION_LOCK_ENABLED_DEFAULT_VALUE = false;
+    boolean EXECUTION_LOCK_ENABLED_DEFAULT_VALUE = true;
 
     //TODO add constants for input/output external payload related properties.
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1008,7 +1008,7 @@ public boolean decide(String workflowId) {
             LOGGER.error("Error deciding workflow: {}", workflowId, e);
             throw e;
         } finally {
-            executionLockService.releaseLock(workflowId);
+            executionLockService.releaseLock(workflowId, workflow.getStatus());
         }
         return false;
     }

File: core/src/main/java/com/netflix/conductor/core/utils/Lock.java
Patch:
@@ -34,4 +34,5 @@ public interface Lock {
 
     void releaseLock(String lockId);
 
+    void deleteLock(String lockId);
 }

File: core/src/main/java/com/netflix/conductor/core/utils/NoopLock.java
Patch:
@@ -14,4 +14,6 @@ public boolean acquireLock(String lockId, long timeToTry, TimeUnit unit) {
     @Override
     public void releaseLock(String lockId) {}
 
+    @Override
+    public void deleteLock(String lockId) {}
 }

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/HttpEndToEndTest.java
Patch:
@@ -19,6 +19,7 @@
 import com.netflix.conductor.client.http.MetadataClient;
 import com.netflix.conductor.client.http.TaskClient;
 import com.netflix.conductor.client.http.WorkflowClient;
+import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.elasticsearch.ElasticSearchConfiguration;
 import com.netflix.conductor.elasticsearch.EmbeddedElasticSearchProvider;
 import com.netflix.conductor.jetty.server.JettyServer;
@@ -38,7 +39,7 @@ public static void setup() throws Exception {
         TestEnvironment.setup();
         System.setProperty(ElasticSearchConfiguration.EMBEDDED_PORT_PROPERTY_NAME, "9201");
         System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_URL_PROPERTY_NAME, "localhost:9301");
-        System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_INDEX_BATCH_SIZE_PROPERTY_NAME, "1");
+        System.setProperty(Configuration.EXECUTION_LOCK_ENABLED_PROPERTY_NAME, "false");
 
         Injector bootInjector = Guice.createInjector(new BootstrapModule());
         Injector serverInjector = Guice.createInjector(bootInjector.getInstance(ModulesProvider.class).get());

File: core/src/main/java/com/netflix/conductor/service/ExecutionLockService.java
Patch:
@@ -7,7 +7,6 @@
 import org.slf4j.LoggerFactory;
 
 import javax.inject.Inject;
-import javax.inject.Named;
 import javax.inject.Provider;
 import java.util.concurrent.TimeUnit;
 
@@ -19,7 +18,7 @@ public class ExecutionLockService {
     private final Provider<Lock> lockProvider;
 
     @Inject
-    public ExecutionLockService(Configuration config, @Named("executionLock")Provider<Lock> lockProvider) {
+    public ExecutionLockService(Configuration config, Provider<Lock> lockProvider) {
         this.config = config;
         this.lockProvider = lockProvider;
     }

File: zookeeper-lock/src/main/java/com/netflix/conductor/zookeeper/ZookeeperLock.java
Patch:
@@ -17,17 +17,17 @@
 import javax.inject.Inject;
 import java.util.concurrent.TimeUnit;
 
-public class ZkLock implements Lock {
+public class ZookeeperLock implements Lock {
     public static final int CACHE_MAXSIZE = 20000;
     public static final int CACHE_EXPIRY_TIME = 10;
 
-    private static final Logger LOGGER = LoggerFactory.getLogger(ZkLock.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(ZookeeperLock.class);
     private CuratorFramework client;
     private LoadingCache<String, InterProcessMutex> zkLocks;
     private String zkPath;
 
     @Inject
-    public ZkLock(ZookeeperConfiguration config, String namespace) {
+    public ZookeeperLock(ZookeeperConfiguration config, String namespace) {
         RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);
         client = CuratorFrameworkFactory.newClient(config.getZkConnection(), retryPolicy);
         client.start();

File: zookeeper-lock/src/test/java/com/netflix/conductor/zookeeper/TestZookeeperLock.java
Patch:
@@ -12,7 +12,7 @@
 import java.util.concurrent.Semaphore;
 import java.util.concurrent.TimeUnit;
 
-public class TestZkLock {
+public class TestZookeeperLock {
     TestingServer zkServer;
     ZookeeperConfiguration mockConfig;
 
@@ -31,7 +31,7 @@ public void tearDown() throws Exception {
 
     @Test
     public void testLockReentrance() {
-        Lock zkLock = new ZkLock(mockConfig, "wfexecution");
+        Lock zkLock = new ZookeeperLock(mockConfig, "wfexecution");
         Boolean hasLock = zkLock.acquireLock("reentrantLock1", 50, TimeUnit.MILLISECONDS);
         Assert.assertTrue(hasLock);
 
@@ -43,7 +43,7 @@ public void testLockReentrance() {
 
     @Test
     public void testZkLock() throws InterruptedException {
-        Lock zkLock = new ZkLock(mockConfig, "wfexecution");
+        Lock zkLock = new ZookeeperLock(mockConfig, "wfexecution");
         String lock1 = "lock1";
         String lock2 = "lock2";
 

File: core/src/main/java/com/netflix/conductor/core/utils/Lock.java
Patch:
@@ -20,7 +20,6 @@ public interface Lock {
     /**
      * acquires a re-entrant lock on lockId, blocks indefinitely on lockId until it succeeds
      * @param lockId resource to lock on
-     * @return
      */
     void acquireLock(String lockId);
 

File: redis-persistence/src/main/java/com/netflix/conductor/dyno/RedisQueuesDiscoveryProvider.java
Patch:
@@ -80,7 +80,7 @@ public List<Host> getHosts() {
                 .withApplicationName(configuration.getAppId())
                 .withDynomiteClusterName(cluster)
                 .withHostSupplier(hostSupplier)
-                .isDatastoreClient(true)
+                .withConnectionPoolConsistency("DC_ONE")
                 .build();
 
         String region = configuration.getRegion();

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -124,7 +124,7 @@ public void init() {
 
         DeciderService deciderService = new DeciderService(parametersUtils, queueDAO, metadataDAO, externalPayloadStorageUtils, taskMappers);
         MetadataMapperService metadataMapperService = new MetadataMapperService(metadataDAO);
-        workflowExecutor = new WorkflowExecutor(deciderService, metadataDAO, queueDAO, metadataMapperService, workflowStatusListener, executionDAOFacade, externalPayloadStorageUtils, config);
+        workflowExecutor = new WorkflowExecutor(deciderService, metadataDAO, queueDAO, metadataMapperService, workflowStatusListener, executionDAOFacade, config);
     }
 
     @Test

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -124,7 +124,7 @@ public void init() {
 
         DeciderService deciderService = new DeciderService(parametersUtils, queueDAO, metadataDAO, externalPayloadStorageUtils, taskMappers);
         MetadataMapperService metadataMapperService = new MetadataMapperService(metadataDAO);
-        workflowExecutor = new WorkflowExecutor(deciderService, metadataDAO, queueDAO, metadataMapperService, workflowStatusListener, executionDAOFacade, externalPayloadStorageUtils, config);
+        workflowExecutor = new WorkflowExecutor(deciderService, metadataDAO, queueDAO, metadataMapperService, workflowStatusListener, executionDAOFacade, config);
     }
 
     @Test

File: core/src/main/java/com/netflix/conductor/core/utils/JsonUtils.java
Patch:
@@ -91,7 +91,6 @@ private Object getJson(String jsonAsString) {
         try {
             return objectMapper.readValue(jsonAsString, Object.class);
         } catch (Exception e) {
-            logger.info("Unable to parse (json?) string: {}", jsonAsString, e);
             return jsonAsString;
         }
     }

File: core/src/main/java/com/netflix/conductor/core/utils/JsonUtils.java
Patch:
@@ -91,7 +91,6 @@ private Object getJson(String jsonAsString) {
         try {
             return objectMapper.readValue(jsonAsString, Object.class);
         } catch (Exception e) {
-            logger.info("Unable to parse (json?) string: {}", jsonAsString, e);
             return jsonAsString;
         }
     }

File: es5-persistence/src/test/java/com/netflix/conductor/dao/es5/index/TestElasticSearchRestDAOV5.java
Patch:
@@ -318,7 +318,7 @@ public void testSearchArchivableWorkflows() throws IOException {
                 .atMost(5, TimeUnit.SECONDS)
                 .untilAsserted(
                         () -> {
-                            List<String> searchIds = indexDAO.searchArchivableWorkflows("conductor",1);
+                            List<String> searchIds = indexDAO.searchArchivableWorkflows("conductor",6);
                             assertEquals(1, searchIds.size());
                             assertEquals(workflowId, searchIds.get(0));
                         }

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -1,4 +1,4 @@
-/**
+/*
  * Copyright 2018 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License");
@@ -42,7 +42,7 @@
  */
 public class DecisionTaskMapper implements TaskMapper {
 
-    Logger logger = LoggerFactory.getLogger(DecisionTaskMapper.class);
+    private static final Logger logger = LoggerFactory.getLogger(DecisionTaskMapper.class);
 
     /**
      * This method gets the list of tasks that need to scheduled when the the task to scheduled is of type {@link TaskType#DECISION}.

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorkerCoordinator.java
Patch:
@@ -52,7 +52,7 @@
 @Singleton
 public class SystemTaskWorkerCoordinator {
 
-	private static Logger logger = LoggerFactory.getLogger(SystemTaskWorkerCoordinator.class);
+	private static final Logger logger = LoggerFactory.getLogger(SystemTaskWorkerCoordinator.class);
 
 	private QueueDAO queueDAO;
 

File: core/src/main/java/com/netflix/conductor/core/orchestration/ExecutionDAOFacade.java
Patch:
@@ -51,6 +51,7 @@ public class ExecutionDAOFacade {
     private final IndexDAO indexDAO;
     private final ObjectMapper objectMapper;
     private final Configuration config;
+
     private final ScheduledThreadPoolExecutor scheduledThreadPoolExecutor;
 
     @Inject

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -1,4 +1,4 @@
-/**
+/*
  * Copyright 2018 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License");
@@ -42,7 +42,7 @@
  */
 public class DecisionTaskMapper implements TaskMapper {
 
-    Logger logger = LoggerFactory.getLogger(DecisionTaskMapper.class);
+    private static final Logger logger = LoggerFactory.getLogger(DecisionTaskMapper.class);
 
     /**
      * This method gets the list of tasks that need to scheduled when the the task to scheduled is of type {@link TaskType#DECISION}.

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorkerCoordinator.java
Patch:
@@ -52,7 +52,7 @@
 @Singleton
 public class SystemTaskWorkerCoordinator {
 
-	private static Logger logger = LoggerFactory.getLogger(SystemTaskWorkerCoordinator.class);
+	private static final Logger logger = LoggerFactory.getLogger(SystemTaskWorkerCoordinator.class);
 
 	private QueueDAO queueDAO;
 

File: core/src/main/java/com/netflix/conductor/core/orchestration/ExecutionDAOFacade.java
Patch:
@@ -51,6 +51,7 @@ public class ExecutionDAOFacade {
     private final IndexDAO indexDAO;
     private final ObjectMapper objectMapper;
     private final Configuration config;
+
     private final ScheduledThreadPoolExecutor scheduledThreadPoolExecutor;
 
     @Inject

File: core/src/test/java/com/netflix/conductor/core/orchestration/ExecutionDAOFacadeTest.java
Patch:
@@ -117,7 +117,7 @@ public void testArchiveWorkflow() throws Exception {
 
         when(executionDAO.getWorkflow(anyString(), anyBoolean())).thenReturn(workflow);
         executionDAOFacade.removeWorkflow("workflowId", true);
-        verify(indexDAO, times(1)).asyncUpdateWorkflow(any(), any(), any());
+        verify(indexDAO, times(1)).updateWorkflow(any(), any(), any());
         verify(indexDAO, never()).removeWorkflow(any());
     }
 

File: core/src/test/java/com/netflix/conductor/core/orchestration/ExecutionDAOFacadeTest.java
Patch:
@@ -117,7 +117,7 @@ public void testArchiveWorkflow() throws Exception {
 
         when(executionDAO.getWorkflow(anyString(), anyBoolean())).thenReturn(workflow);
         executionDAOFacade.removeWorkflow("workflowId", true);
-        verify(indexDAO, times(1)).asyncUpdateWorkflow(any(), any(), any());
+        verify(indexDAO, times(1)).updateWorkflow(any(), any(), any());
         verify(indexDAO, never()).removeWorkflow(any());
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -220,7 +220,7 @@ private DeciderOutcome decide(final Workflow workflow, List<Task> preScheduledTa
         return outcome;
     }
 
-    private List<Task> filterNextLoopOverTasks(List<Task> tasks, Task pendingTask, Workflow workflow) {
+    protected List<Task> filterNextLoopOverTasks(List<Task> tasks, Task pendingTask, Workflow workflow) {
 
         //Update the task reference name and iteration
         tasks.forEach(nextTask -> {

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -129,10 +129,10 @@ public List<Task> poll(String taskType, String workerId, String domain, int coun
 			List<String> taskIds = queueDAO.pop(queueName, count, timeoutInMilliSecond);
 			for (String taskId : taskIds) {
 				Task task = getTask(taskId);
-				if (task == null) {
-					// Remove taskId(s) without a valid Task from the queue.
+				if (task == null || task.getStatus().isTerminal()) {
+					// Remove taskId(s) without a valid Task/terminal state task from the queue
 					queueDAO.remove(queueName, taskId);
-					logger.debug("Removed taskId without a valid task from queue: {}, {}", queueName, taskId);
+					logger.debug("Removed taskId from the queue: {}, {}", queueName, taskId);
 					continue;
 				}
 

File: core/src/main/java/com/netflix/conductor/validations/WorkflowTaskTypeConstraint.java
Patch:
@@ -3,6 +3,7 @@
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
 import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
+import com.netflix.conductor.core.execution.tasks.SubWorkflow;
 
 import javax.validation.Constraint;
 import javax.validation.ConstraintValidator;

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/ESRestClientHttpEndToEndTest.java
Patch:
@@ -51,6 +51,7 @@ public static void setup() throws Exception {
         TestEnvironment.setup();
         System.setProperty(ElasticSearchConfiguration.EMBEDDED_PORT_PROPERTY_NAME, "9203");
         System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_URL_PROPERTY_NAME, "http://localhost:9203");
+        System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_INDEX_BATCH_SIZE_PROPERTY_NAME, "1");
 
         Injector bootInjector = Guice.createInjector(new BootstrapModule());
         Injector serverInjector = Guice.createInjector(bootInjector.getInstance(ModulesProvider.class).get());

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/ExclusiveJoinEndToEndTest.java
Patch:
@@ -69,6 +69,7 @@ public static void setUp() throws Exception {
 		TestEnvironment.setup();
         System.setProperty(ElasticSearchConfiguration.EMBEDDED_PORT_PROPERTY_NAME, "9205");
         System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_URL_PROPERTY_NAME, "localhost:9305");
+		System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_INDEX_BATCH_SIZE_PROPERTY_NAME, "1");
 
 		Injector bootInjector = Guice.createInjector(new BootstrapModule());
 		Injector serverInjector = Guice.createInjector(bootInjector.getInstance(ModulesProvider.class).get());

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/GrpcEndToEndTest.java
Patch:
@@ -50,6 +50,7 @@ public static void setup() throws Exception {
         System.setProperty(GRPCServerConfiguration.PORT_PROPERTY_NAME, "8092");
         System.setProperty(ElasticSearchConfiguration.EMBEDDED_PORT_PROPERTY_NAME, "9202");
         System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_URL_PROPERTY_NAME, "localhost:9302");
+        System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_INDEX_BATCH_SIZE_PROPERTY_NAME, "1");
 
         Injector bootInjector = Guice.createInjector(new BootstrapModule());
         Injector serverInjector = Guice.createInjector(bootInjector.getInstance(ModulesProvider.class).get());

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/HttpEndToEndTest.java
Patch:
@@ -38,6 +38,7 @@ public static void setup() throws Exception {
         TestEnvironment.setup();
         System.setProperty(ElasticSearchConfiguration.EMBEDDED_PORT_PROPERTY_NAME, "9201");
         System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_URL_PROPERTY_NAME, "localhost:9301");
+        System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_INDEX_BATCH_SIZE_PROPERTY_NAME, "1");
 
         Injector bootInjector = Guice.createInjector(new BootstrapModule());
         Injector serverInjector = Guice.createInjector(bootInjector.getInstance(ModulesProvider.class).get());

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/MySQLGrpcEndToEndTest.java
Patch:
@@ -54,6 +54,7 @@ public static void setup() throws Exception {
         System.setProperty(GRPCServerConfiguration.PORT_PROPERTY_NAME, "8094");
         System.setProperty(ElasticSearchConfiguration.EMBEDDED_PORT_PROPERTY_NAME, "9204");
         System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_URL_PROPERTY_NAME, "localhost:9304");
+        System.setProperty(ElasticSearchConfiguration.ELASTIC_SEARCH_INDEX_BATCH_SIZE_PROPERTY_NAME, "1");
 
         Injector bootInjector = Guice.createInjector(new BootstrapModule());
         Injector serverInjector = Guice.createInjector(bootInjector.getInstance(ModulesProvider.class).get());

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -400,7 +400,7 @@ Optional<Task> retry(TaskDef taskDefinition, WorkflowTask workflowTask, Task tas
         rescheduled.setRetriedTaskId(task.getTaskId());
         rescheduled.setStatus(SCHEDULED);
         rescheduled.setPollCount(0);
-        rescheduled.setIteration(1);
+        rescheduled.setIteration(task.getIteration());
         rescheduled.setInputData(new HashMap<>());
         rescheduled.getInputData().putAll(task.getInputData());
         rescheduled.setReasonForIncompletion(null);

File: core/src/main/java/com/netflix/conductor/core/config/CoreModule.java
Patch:
@@ -131,8 +131,8 @@ public TaskMapper getDecisionTaskMapper() {
     @StringMapKey(TASK_TYPE_DO_WHILE)
     @Singleton
     @Named(TASK_MAPPERS_QUALIFIER)
-    public TaskMapper getDoWhileTaskMapper(ParametersUtils parametersUtils, MetadataDAO metadataDAO) {
-        return new DoWhileTaskMapper(parametersUtils, metadataDAO);
+    public TaskMapper getDoWhileTaskMapper(MetadataDAO metadataDAO) {
+        return new DoWhileTaskMapper(metadataDAO);
     }
 
     @ProvidesIntoMap

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DoWhileTaskMapper.java
Patch:
@@ -44,10 +44,8 @@ public class DoWhileTaskMapper implements TaskMapper {
     public static final String LOOP_TASK_LEFT_DELIMITER = "__";
 
     private final MetadataDAO metadataDAO;
-    private final ParametersUtils parametersUtils;
 
-    public DoWhileTaskMapper(ParametersUtils parametersUtils, MetadataDAO metadataDAO) {
-        this.parametersUtils = parametersUtils;
+    public DoWhileTaskMapper(MetadataDAO metadataDAO) {
         this.metadataDAO = metadataDAO;
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1429,7 +1429,8 @@ private boolean rerunWF(String workflowId, String taskId, Map<String, Object> ta
                 workflow.setInput(workflowInput);
             }
             executionDAOFacade.updateWorkflow(workflow);
-
+            //update tasks in datastore to update workflow-tasks relationship for archived workflows
+            executionDAOFacade.updateTasks(workflow.getTasks());
             // Remove all tasks after the "rerunFromTask"
             for (Task task : workflow.getTasks()) {
                 if (task.getSeq() > rerunFromTask.getSeq()) {

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/CassandraConfiguration.java
Patch:
@@ -35,7 +35,7 @@ public interface CassandraConfiguration extends Configuration {
     String CASSANDRA_REPLICATION_FACTOR_KEY_PROPERTY_NAME = "workflow.cassandra.replication.factor.key";
     String CASSANDRA_REPLICATION_FACTOR_KEY_DEFAULT_VALUE = "replication_factor";
 
-    String CASSANDRA_REPLICATION_FACTOR_VALUE_PROPERTY_NAME = "workflow.cassandra.replicaton.factor.value";
+    String CASSANDRA_REPLICATION_FACTOR_VALUE_PROPERTY_NAME = "workflow.cassandra.replication.factor.value";
     int CASSANDRA_REPLICATION_FACTOR_VALUE_DEFAULT_VALUE = 3;
 
     String CASSANDRA_SHARD_SIZE_PROPERTY_KEY = "workflow.cassandra.shard.size";

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -584,6 +584,7 @@ private Task taskToBeRescheduled(Task task) {
         taskToBeRetried.setPollCount(0);
         taskToBeRetried.setCallbackAfterSeconds(0);
         task.setRetried(true);
+        task.setExecuted(true); // since this task is being retried and a retry has been computed, task lifecycle is complete
         return taskToBeRetried;
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapper.java
Patch:
@@ -95,7 +95,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
                 .getNextTask(taskToSchedule.getTaskReferenceName());
 
         if (joinWorkflowTask == null || !joinWorkflowTask.getType().equals(TaskType.JOIN.name())) {
-            throw new TerminateWorkflowException("Dynamic join definition is not followed by a join task.  Check the blueprint");
+            throw new TerminateWorkflowException("Fork task definition is not followed by a join task.  Check the blueprint");
         }
         return tasksToBeScheduled;
     }

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapperTest.java
Patch:
@@ -192,7 +192,7 @@ public void getMappedTasksException() throws Exception {
                 .build();
 
         expectedException.expect(TerminateWorkflowException.class);
-        expectedException.expectMessage("Dynamic join definition is not followed by a join task.  Check the blueprint");
+        expectedException.expectMessage("Fork task definition is not followed by a join task.  Check the blueprint");
         forkJoinTaskMapper.getMappedTasks(taskMapperContext);
 
     }

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/CassandraConfiguration.java
Patch:
@@ -35,7 +35,7 @@ public interface CassandraConfiguration extends Configuration {
     String CASSANDRA_REPLICATION_FACTOR_KEY_PROPERTY_NAME = "workflow.cassandra.replication.factor.key";
     String CASSANDRA_REPLICATION_FACTOR_KEY_DEFAULT_VALUE = "replication_factor";
 
-    String CASSANDRA_REPLICATION_FACTOR_VALUE_PROPERTY_NAME = "workflow.cassandra.replicaton.factor.value";
+    String CASSANDRA_REPLICATION_FACTOR_VALUE_PROPERTY_NAME = "workflow.cassandra.replication.factor.value";
     int CASSANDRA_REPLICATION_FACTOR_VALUE_DEFAULT_VALUE = 3;
 
     String CASSANDRA_SHARD_SIZE_PROPERTY_KEY = "workflow.cassandra.shard.size";

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -584,6 +584,7 @@ private Task taskToBeRescheduled(Task task) {
         taskToBeRetried.setPollCount(0);
         taskToBeRetried.setCallbackAfterSeconds(0);
         task.setRetried(true);
+        task.setExecuted(true); // since this task is being retried and a retry has been computed, task lifecycle is complete
         return taskToBeRetried;
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapper.java
Patch:
@@ -95,7 +95,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
                 .getNextTask(taskToSchedule.getTaskReferenceName());
 
         if (joinWorkflowTask == null || !joinWorkflowTask.getType().equals(TaskType.JOIN.name())) {
-            throw new TerminateWorkflowException("Dynamic join definition is not followed by a join task.  Check the blueprint");
+            throw new TerminateWorkflowException("Fork task definition is not followed by a join task.  Check the blueprint");
         }
         return tasksToBeScheduled;
     }

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapperTest.java
Patch:
@@ -192,7 +192,7 @@ public void getMappedTasksException() throws Exception {
                 .build();
 
         expectedException.expect(TerminateWorkflowException.class);
-        expectedException.expectMessage("Dynamic join definition is not followed by a join task.  Check the blueprint");
+        expectedException.expectMessage("Fork task definition is not followed by a join task.  Check the blueprint");
         forkJoinTaskMapper.getMappedTasks(taskMapperContext);
 
     }

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -866,8 +866,7 @@ public void updateTask(TaskResult taskResult) {
             String errorMsg = String.format("Error updating task: %s for workflow: %s, terminating workflow.", task.getTaskId(), workflowId);
             LOGGER.error(errorMsg, e);
             Monitors.recordTaskUpdateError(task.getTaskType(), workflowInstance.getWorkflowName());
-            terminateWorkflow(workflowInstance, errorMsg, null);
-            return;
+            throw new ApplicationException(Code.BACKEND_ERROR, e);
         }
 
         taskResult.getLogs().forEach(taskExecLog -> taskExecLog.setTaskId(task.getTaskId()));

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinDynamicTaskMapper.java
Patch:
@@ -29,6 +29,7 @@
 import com.netflix.conductor.core.execution.TerminateWorkflowException;
 import com.netflix.conductor.core.utils.IDGenerator;
 import com.netflix.conductor.dao.MetadataDAO;
+import org.apache.commons.lang3.StringUtils;
 import org.apache.commons.lang3.tuple.ImmutablePair;
 import org.apache.commons.lang3.tuple.Pair;
 import org.slf4j.Logger;
@@ -241,7 +242,7 @@ Pair<List<WorkflowTask>, Map<String, Map<String, Object>>> getDynamicForkTasksAn
         Object dynamicForkTasksJson = input.get(dynamicForkTaskParam);
         List<WorkflowTask> dynamicForkWorkflowTasks = objectMapper.convertValue(dynamicForkTasksJson, ListOfWorkflowTasks);
         for (WorkflowTask workflowTask : dynamicForkWorkflowTasks) {
-            if (workflowTask.getTaskDefinition() == null) {
+            if ((workflowTask.getTaskDefinition() == null) && StringUtils.isNotBlank(workflowTask.getName())) {
                 workflowTask.setTaskDefinition(metadataDAO.getTaskDef(workflowTask.getName()));
             }
         }
@@ -284,7 +285,7 @@ Pair<List<WorkflowTask>, Map<String, Map<String, Object>>> getDynamicForkJoinTas
                     dynamicForkJoinWorkflowTask.setTaskReferenceName(dynamicForkJoinTask.getReferenceName());
                     dynamicForkJoinWorkflowTask.setName(dynamicForkJoinTask.getTaskName());
                     dynamicForkJoinWorkflowTask.setType(dynamicForkJoinTask.getType());
-                    if (dynamicForkJoinWorkflowTask.getTaskDefinition() == null) {
+                    if (dynamicForkJoinWorkflowTask.getTaskDefinition() == null && StringUtils.isNotBlank(dynamicForkJoinWorkflowTask.getName())) {
                         dynamicForkJoinWorkflowTask.setTaskDefinition(metadataDAO.getTaskDef(dynamicForkJoinTask.getTaskName()));
                     }
                     return dynamicForkJoinWorkflowTask;

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/KafkaPublishTaskMapper.java
Patch:
@@ -69,6 +69,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
 		kafkaPublishTask.setRetryCount(retryCount);
 		kafkaPublishTask.setCallbackAfterSeconds(taskToSchedule.getStartDelay());
 		kafkaPublishTask.setWorkflowTask(taskToSchedule);
+		kafkaPublishTask.setWorkflowPriority(workflowInstance.getPriority());
 		kafkaPublishTask.setRateLimitPerFrequency(taskDefinition.getRateLimitPerFrequency());
 		kafkaPublishTask.setRateLimitFrequencyInSeconds(taskDefinition.getRateLimitFrequencyInSeconds());
 		return Collections.singletonList(kafkaPublishTask);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/TerminateTaskMapper.java
Patch:
@@ -46,6 +46,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         task.setTaskId(taskId);
         task.setStatus(Task.Status.IN_PROGRESS);
         task.setWorkflowTask(taskToSchedule);
+        task.setWorkflowPriority(workflowInstance.getPriority());
         return singletonList(task);
     }
 }

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/DoWhileTest.java
Patch:
@@ -147,7 +147,7 @@ public void testConditionException() {
         Mockito.doNothing().when(provider).scheduleLoopTasks(loopTask, workflow);
         boolean success = doWhile.execute(workflow, loopTask, provider);
         Assert.assertTrue(success);
-        Assert.assertTrue(loopTask.getStatus() == Task.Status.FAILED);
+        Assert.assertTrue(loopTask.getStatus() == Task.Status.FAILED_WITH_TERMINAL_ERROR);
     }
 
 

File: client/src/main/java/com/netflix/conductor/client/http/ClientBase.java
Patch:
@@ -161,11 +161,11 @@ private <T> T postForEntity(String url, Object request, Object[] queryParams, Ob
         return null;
     }
 
-    <T> T getForEntity(String url, Object[] queryParams, Class<T> responseType, Object... uriVariables) {
+    protected <T> T getForEntity(String url, Object[] queryParams, Class<T> responseType, Object... uriVariables) {
         return getForEntity(url, queryParams, response -> response.getEntity(responseType), uriVariables);
     }
 
-    <T> T getForEntity(String url, Object[] queryParams, GenericType<T> responseType, Object... uriVariables) {
+    protected <T> T getForEntity(String url, Object[] queryParams, GenericType<T> responseType, Object... uriVariables) {
         return getForEntity(url, queryParams, response -> response.getEntity(responseType), uriVariables);
     }
 

File: client/src/main/java/com/netflix/conductor/client/http/ClientBase.java
Patch:
@@ -161,11 +161,11 @@ private <T> T postForEntity(String url, Object request, Object[] queryParams, Ob
         return null;
     }
 
-    <T> T getForEntity(String url, Object[] queryParams, Class<T> responseType, Object... uriVariables) {
+    protected <T> T getForEntity(String url, Object[] queryParams, Class<T> responseType, Object... uriVariables) {
         return getForEntity(url, queryParams, response -> response.getEntity(responseType), uriVariables);
     }
 
-    <T> T getForEntity(String url, Object[] queryParams, GenericType<T> responseType, Object... uriVariables) {
+    protected <T> T getForEntity(String url, Object[] queryParams, GenericType<T> responseType, Object... uriVariables) {
         return getForEntity(url, queryParams, response -> response.getEntity(responseType), uriVariables);
     }
 

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/DoWhileTest.java
Patch:
@@ -81,7 +81,7 @@ public void setup() {
         loopTask.setTaskType(TaskType.DO_WHILE.name());
         loopWorkflowTask = new WorkflowTask();
         loopWorkflowTask.setTaskReferenceName("loopWorkflowTask");
-        loopWorkflowTask.setLoopCondition("if ($.task1 + $.task2 > 10) { false; } else { true; }");
+        loopWorkflowTask.setLoopCondition("if ($.task1['task1'] + $.task2['task2'] > 10) { false; } else { true; }");
         loopWorkflowTask.setLoopOver(Arrays.asList(task1.getWorkflowTask(), task2.getWorkflowTask()));
         loopTask.setWorkflowTask(loopWorkflowTask);
         doWhile = new DoWhile();

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -740,7 +740,7 @@ public void testGetTasksToBeScheduled() {
     }
 
     @Test
-    public void testIsResponsedTimeOut() {
+    public void testIsResponseTimedOut() {
         TaskDef taskDef = new TaskDef();
         taskDef.setName("test_rt");
         taskDef.setResponseTimeoutSeconds(10);
@@ -792,7 +792,7 @@ public void testPopulateWorkflowAndTaskData() {
         assertNull(workflowInstance.getTasks().get(0).getExternalInputPayloadStoragePath());
         assertNull(workflowInstance.getTasks().get(0).getExternalOutputPayloadStoragePath());
     }
-    @SuppressWarnings("unchecked")
+
     @Test
     public void testUpdateWorkflowOutput() {
         Workflow workflow = new Workflow();

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -740,7 +740,7 @@ public void testGetTasksToBeScheduled() {
     }
 
     @Test
-    public void testIsResponsedTimeOut() {
+    public void testIsResponseTimedOut() {
         TaskDef taskDef = new TaskDef();
         taskDef.setName("test_rt");
         taskDef.setResponseTimeoutSeconds(10);
@@ -792,7 +792,7 @@ public void testPopulateWorkflowAndTaskData() {
         assertNull(workflowInstance.getTasks().get(0).getExternalInputPayloadStoragePath());
         assertNull(workflowInstance.getTasks().get(0).getExternalOutputPayloadStoragePath());
     }
-    @SuppressWarnings("unchecked")
+
     @Test
     public void testUpdateWorkflowOutput() {
         Workflow workflow = new Workflow();

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/DoWhile.java
Patch:
@@ -103,7 +103,7 @@ Map<String, Object> getConditionInput(Task task, int iteration, Workflow workflo
 				refName += "_" + (iteration);
 			}
 			Task temp = workflow.getTaskByRefName(refName);
-			map.put(taskName, temp.getOutputData());
+			map.putAll(temp.getOutputData());
 			logger.debug("Taskname {} output {}", temp.getReferenceTaskName(), temp.getOutputData());
 		}
 		return map;

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1123,6 +1123,7 @@ private long getTaskDuration(long s, Task task) {
 
     @VisibleForTesting
     public boolean scheduleTask(Workflow workflow, List<Task> tasks) {
+        List<Task> createdTasks = new ArrayList<>();
 
         try {
             if (tasks == null || tasks.isEmpty()) {

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/TaskType.java
Patch:
@@ -11,6 +11,7 @@ public enum TaskType {
     FORK_JOIN_DYNAMIC(true),
     DECISION(true),
     JOIN(true),
+    DO_WHILE(true),
     SUB_WORKFLOW(true),
     EVENT(true),
     WAIT(true),
@@ -27,6 +28,7 @@ public enum TaskType {
     public static final String TASK_TYPE_DECISION = "DECISION";
     public static final String TASK_TYPE_DYNAMIC = "DYNAMIC";
     public static final String TASK_TYPE_JOIN = "JOIN";
+    public static final String TASK_TYPE_DO_WHILE = "DO_WHILE";
     public static final String TASK_TYPE_FORK_JOIN_DYNAMIC = "FORK_JOIN_DYNAMIC";
     public static final String TASK_TYPE_EVENT = "EVENT";
     public static final String TASK_TYPE_WAIT = "WAIT";

File: es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/ElasticSearchRestDAOV6.java
Patch:
@@ -141,7 +141,7 @@ public ElasticSearchRestDAOV6(RestClientBuilder restClientBuilder, ElasticSearch
 
         this.objectMapper = objectMapper;
         this.elasticSearchAdminClient = restClientBuilder.build();
-        this.elasticSearchClient = new RestHighLevelClient(restClientBuilder.build());
+        this.elasticSearchClient = new RestHighLevelClient(restClientBuilder);
         this.clusterHealthColor = config.getClusterHealthColor();
 
         this.indexPrefix = config.getIndexName();

File: es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/ElasticSearchRestDAOV6.java
Patch:
@@ -141,7 +141,7 @@ public ElasticSearchRestDAOV6(RestClientBuilder restClientBuilder, ElasticSearch
 
         this.objectMapper = objectMapper;
         this.elasticSearchAdminClient = restClientBuilder.build();
-        this.elasticSearchClient = new RestHighLevelClient(restClientBuilder.build());
+        this.elasticSearchClient = new RestHighLevelClient(restClientBuilder);
         this.clusterHealthColor = config.getClusterHealthColor();
 
         this.indexPrefix = config.getIndexName();

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -391,8 +391,8 @@ public void rewind(String workflowId, boolean useLatestDefinitions) {
             throw new ApplicationException(CONFLICT, String.format("Workflow: %s is non-restartable", workflow));
         }
 
-        // Remove all the tasks...
-        workflow.getTasks().forEach(task -> executionDAOFacade.removeTask(task.getTaskId()));
+        // Remove the workflow from the primary datastore (archive in indexer) and re-create it
+        executionDAOFacade.removeWorkflow(workflowId, true);
         workflow.getTasks().clear();
         workflow.setReasonForIncompletion(null);
         workflow.setStartTime(System.currentTimeMillis());
@@ -401,7 +401,7 @@ public void rewind(String workflowId, boolean useLatestDefinitions) {
         workflow.setStatus(WorkflowStatus.RUNNING);
         workflow.setOutput(null);
         workflow.setExternalOutputPayloadStoragePath(null);
-        executionDAOFacade.updateWorkflow(workflow);
+        executionDAOFacade.createWorkflow(workflow);
         decide(workflowId);
     }
 

File: core/src/test/java/com/netflix/conductor/dao/ExecutionDAOTest.java
Patch:
@@ -243,15 +243,13 @@ public void testTaskOps() {
         Task matching = pending.stream().filter(task -> task.getTaskId().equals(tasks.get(0).getTaskId())).findAny().get();
         assertTrue(EqualsBuilder.reflectionEquals(matching, tasks.get(0)));
 
-        List<Task> update = new LinkedList<>();
         for (int i = 0; i < 3; i++) {
             Task found = getExecutionDAO().getTask(workflowId + "_t" + i);
             assertNotNull(found);
             found.getOutputData().put("updated", true);
             found.setStatus(Task.Status.COMPLETED);
-            update.add(found);
+            getExecutionDAO().updateTask(found);
         }
-        getExecutionDAO().updateTasks(update);
 
         List<String> taskIds = tasks.stream().map(Task::getTaskId).collect(Collectors.toList());
         List<Task> found = getExecutionDAO().getTasks(taskIds);

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -345,7 +345,7 @@ public void addTaskExecutionLogs(List<TaskExecLog> taskExecLogs) {
             List<String> taskIds = taskExecLogs.stream()
                 .map(TaskExecLog::getTaskId)
                 .collect(Collectors.toList());
-            logger.error("Failed to index task execution logs for tasks: ", taskIds, e);
+            logger.error("Failed to index task execution logs for tasks: {}", taskIds, e);
         }
     }
 

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -136,11 +136,12 @@ public ElasticSearchDAOV5(Client elasticSearchClient, ElasticSearchConfiguration
         int corePoolSize = 6;
         int maximumPoolSize = 12;
         long keepAliveTime = 1L;
+        int workerQueueSize = config.getAsyncWorkerQueueSize();
         this.executorService = new ThreadPoolExecutor(corePoolSize,
             maximumPoolSize,
             keepAliveTime,
             TimeUnit.MINUTES,
-            new LinkedBlockingQueue<>());
+            new LinkedBlockingQueue<>(workerQueueSize));
     }
 
     @Override

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchRestDAOV5.java
Patch:
@@ -124,11 +124,12 @@ public ElasticSearchRestDAOV5(RestClient lowLevelRestClient, ElasticSearchConfig
         int corePoolSize = 6;
         int maximumPoolSize = 12;
         long keepAliveTime = 1L;
+        int workerQueueSize = config.getAsyncWorkerQueueSize();
         this.executorService = new ThreadPoolExecutor(corePoolSize,
                 maximumPoolSize,
                 keepAliveTime,
                 TimeUnit.MINUTES,
-                new LinkedBlockingQueue<>());
+                new LinkedBlockingQueue<>(workerQueueSize));
 
     }
 

File: es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/ElasticSearchDAOV6.java
Patch:
@@ -151,7 +151,9 @@ public ElasticSearchDAOV6(Client elasticSearchClient, ElasticSearchConfiguration
         this.logIndexPrefix = this.indexPrefix + "_" + LOG_DOC_TYPE;
         this.messageIndexPrefix = this.indexPrefix + "_" + MSG_DOC_TYPE;
         this.eventIndexPrefix = this.indexPrefix + "_" + EVENT_DOC_TYPE;
-        this.executorService = new ThreadPoolExecutor(CORE_POOL_SIZE, MAXIMUM_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.MINUTES, new LinkedBlockingQueue<>());
+        int workerQueueSize = config.getAsyncWorkerQueueSize();
+
+        this.executorService = new ThreadPoolExecutor(CORE_POOL_SIZE, MAXIMUM_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.MINUTES, new LinkedBlockingQueue<>(workerQueueSize));
     }
 
     @Override

File: es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/ElasticSearchRestDAOV6.java
Patch:
@@ -150,9 +150,10 @@ public ElasticSearchRestDAOV6(RestClientBuilder restClientBuilder, ElasticSearch
         this.logIndexPrefix = this.indexPrefix + "_" + LOG_DOC_TYPE;
         this.messageIndexPrefix = this.indexPrefix + "_" + MSG_DOC_TYPE;
         this.eventIndexPrefix = this.indexPrefix + "_" + EVENT_DOC_TYPE;
+        int workerQueueSize = config.getAsyncWorkerQueueSize();
 
         // Set up a workerpool for performing async operations.
-        this.executorService = new ThreadPoolExecutor(CORE_POOL_SIZE, MAXIMUM_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.MINUTES, new LinkedBlockingQueue<>());
+        this.executorService = new ThreadPoolExecutor(CORE_POOL_SIZE, MAXIMUM_POOL_SIZE, KEEP_ALIVE_TIME, TimeUnit.MINUTES, new LinkedBlockingQueue<>(workerQueueSize));
     }
 
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -1161,7 +1161,9 @@ boolean scheduleTask(Workflow workflow, List<Task> tasks) {
                 if (workflowSystemTask == null) {
                     throw new ApplicationException(NOT_FOUND, "No system task found by name " + task.getTaskType());
                 }
-                task.setStartTime(System.currentTimeMillis());
+                if (task.getStatus() != null && !task.getStatus().isTerminal() && task.getStartTime() == 0) {
+                    task.setStartTime(System.currentTimeMillis());
+                }
                 if (!workflowSystemTask.isAsync()) {
                     try {
                         workflowSystemTask.start(workflow, task, this);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -87,6 +87,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         decisionTask.getInputData().put("case", caseValue);
         decisionTask.getOutputData().put("caseOutput", Collections.singletonList(caseValue));
         decisionTask.setTaskId(taskId);
+        decisionTask.setStartTime(System.currentTimeMillis());
         decisionTask.setStatus(Task.Status.IN_PROGRESS);
         decisionTask.setWorkflowTask(taskToSchedule);
         tasksToBeScheduled.add(decisionTask);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapper.java
Patch:
@@ -74,7 +74,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         forkTask.setWorkflowType(workflowInstance.getWorkflowName());
         forkTask.setCorrelationId(workflowInstance.getCorrelationId());
         forkTask.setScheduledTime(System.currentTimeMillis());
-        forkTask.setEndTime(System.currentTimeMillis());
+        forkTask.setStartTime(System.currentTimeMillis());
         forkTask.setInputData(taskInput);
         forkTask.setTaskId(taskId);
         forkTask.setStatus(Task.Status.COMPLETED);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/JoinTaskMapper.java
Patch:
@@ -65,6 +65,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         joinTask.setCorrelationId(workflowInstance.getCorrelationId());
         joinTask.setWorkflowType(workflowInstance.getWorkflowName());
         joinTask.setScheduledTime(System.currentTimeMillis());
+        joinTask.setStartTime(System.currentTimeMillis());
         joinTask.setInputData(joinInput);
         joinTask.setTaskId(taskId);
         joinTask.setStatus(Task.Status.IN_PROGRESS);

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAO.java
Patch:
@@ -134,7 +134,9 @@ public List<Task> createTasks(List<Task> tasks) {
 				continue;
 			}
 
-			task.setScheduledTime(System.currentTimeMillis());
+			if(task.getStatus() != null && !task.getStatus().isTerminal() && task.getScheduledTime() == 0){
+				task.setScheduledTime(System.currentTimeMillis());
+			}
 
 			correlateTaskToWorkflowInDS(task.getTaskId(), task.getWorkflowInstanceId());
 			logger.debug("Scheduled task added to WORKFLOW_TO_TASKS workflowId: {}, taskId: {}, taskType: {} during createTasks",

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowLegacyMigrationTest.java
Patch:
@@ -128,4 +128,6 @@ public void testTerminateTaskWithFailedStatus() {}
     @Test
     @Override
     public void testTerminateTaskWithCompletedStatus() {}
+
+
 }

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractHttpEndToEndTest.java
Patch:
@@ -155,7 +155,7 @@ public void testAll() throws Exception {
 
         task.getOutputData().put("key1", "value1");
         task.setStatus(Status.COMPLETED);
-        taskClient.updateTask(new TaskResult(task), task.getTaskType());
+        taskClient.updateTask(new TaskResult(task));
 
         polled = taskClient.batchPollTasksByTaskType(t0.getName(), "test", 1, 100);
         assertNotNull(polled);
@@ -310,7 +310,7 @@ public void testStartWorkflow() {
     public void testUpdateTask() {
         TaskResult taskResult = new TaskResult();
         try {
-            taskClient.updateTask(taskResult, "taskTest");
+            taskClient.updateTask(taskResult);
         } catch (ConductorClientException e) {
             assertEquals(400, e.getStatus());
             assertEquals("Validation failed, check below errors for detail.", e.getMessage());

File: client/src/main/java/com/netflix/conductor/client/http/ClientBase.java
Patch:
@@ -223,7 +223,7 @@ protected Map<String, Object> downloadFromExternalStorage(ExternalPayloadStorage
         try (InputStream inputStream = payloadStorage.download(externalStorageLocation.getUri())) {
             return objectMapper.readValue(inputStream, Map.class);
         } catch (IOException e) {
-            String errorMsg = String.format("Unable to download payload frome external storage location: %s", path);
+            String errorMsg = String.format("Unable to download payload from external storage location: %s", path);
             logger.error(errorMsg, e);
             throw new ConductorClientException(errorMsg, e);
         }

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -235,7 +235,7 @@ private List<Task> startWorkflow(Workflow workflow) throws TerminateWorkflowExce
                 taskToSchedule = workflowDef.getNextTask(taskToSchedule.getTaskReferenceName());
             }
 
-            //In case of a new workflow a the first non-skippable task will be scheduled
+            //In case of a new workflow, the first non-skippable task will be scheduled
             return getTasksToBeScheduled(workflow, taskToSchedule, 0);
         }
 

File: client/src/main/java/com/netflix/conductor/client/http/PayloadStorage.java
Patch:
@@ -63,7 +63,7 @@ public ExternalStorageLocation getLocation(Operation operation, PayloadType payl
             default:
                 throw new ConductorClientException(String.format("Invalid payload type: %s for operation: %s", payloadType.toString(), operation.toString()));
         }
-        return clientBase.getForEntity(String.format("%s/externalstoragelocation", uri), new Object[]{"path", path}, ExternalStorageLocation.class);
+        return clientBase.getForEntity(String.format("%s/externalstoragelocation", uri), new Object[]{"path", path, "operation", operation.toString(), "payloadType", payloadType.toString()}, ExternalStorageLocation.class);
     }
 
     /**

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -219,10 +219,10 @@ public SearchResult<TaskSummary> search(@QueryParam("start") @DefaultValue("0")
 	}
 
 	@GET
-	@ApiOperation("Get the external uri where the task output payload is to be stored")
+	@ApiOperation("Get the external uri where the task payload is to be stored")
 	@Consumes(MediaType.WILDCARD)
 	@Path("/externalstoragelocation")
-	public ExternalStorageLocation getExternalStorageLocation(@QueryParam("path") String path) {
-		return taskService.getExternalStorageLocation(path);
+	public ExternalStorageLocation getExternalStorageLocation(@QueryParam("path") String path, @QueryParam("operation") String operation, @QueryParam("payloadType") String payloadType) {
+		return taskService.getExternalStorageLocation(path, operation, payloadType);
 	}
 }

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -240,10 +240,10 @@ public SearchResult<WorkflowSummary> searchWorkflowsByTasks(@QueryParam("start")
     }
 
     @GET
-    @ApiOperation("Get the uri and path of the external storage where the workflow input payload is to be stored")
+    @ApiOperation("Get the uri and path of the external storage where the workflow payload is to be stored")
     @Consumes(MediaType.WILDCARD)
     @Path("/externalstoragelocation")
-    public ExternalStorageLocation getExternalStorageLocation(@QueryParam("path") String path) {
-        return workflowService.getExternalStorageLocation(path);
+    public ExternalStorageLocation getExternalStorageLocation(@QueryParam("path") String path, @QueryParam("operation") String operation, @QueryParam("payloadType") String payloadType) {
+        return workflowService.getExternalStorageLocation(path, operation, payloadType);
     }
 }
\ No newline at end of file

File: client/src/main/java/com/netflix/conductor/client/http/PayloadStorage.java
Patch:
@@ -63,7 +63,7 @@ public ExternalStorageLocation getLocation(Operation operation, PayloadType payl
             default:
                 throw new ConductorClientException(String.format("Invalid payload type: %s for operation: %s", payloadType.toString(), operation.toString()));
         }
-        return clientBase.getForEntity(String.format("%s/externalstoragelocation", uri), new Object[]{"path", path}, ExternalStorageLocation.class);
+        return clientBase.getForEntity(String.format("%s/externalstoragelocation", uri), new Object[]{"path", path, "operation", operation.toString(), "payloadType", payloadType.toString()}, ExternalStorageLocation.class);
     }
 
     /**

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -219,10 +219,10 @@ public SearchResult<TaskSummary> search(@QueryParam("start") @DefaultValue("0")
 	}
 
 	@GET
-	@ApiOperation("Get the external uri where the task output payload is to be stored")
+	@ApiOperation("Get the external uri where the task payload is to be stored")
 	@Consumes(MediaType.WILDCARD)
 	@Path("/externalstoragelocation")
-	public ExternalStorageLocation getExternalStorageLocation(@QueryParam("path") String path) {
-		return taskService.getExternalStorageLocation(path);
+	public ExternalStorageLocation getExternalStorageLocation(@QueryParam("path") String path, @QueryParam("operation") String operation, @QueryParam("payloadType") String payloadType) {
+		return taskService.getExternalStorageLocation(path, operation, payloadType);
 	}
 }

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -240,10 +240,10 @@ public SearchResult<WorkflowSummary> searchWorkflowsByTasks(@QueryParam("start")
     }
 
     @GET
-    @ApiOperation("Get the uri and path of the external storage where the workflow input payload is to be stored")
+    @ApiOperation("Get the uri and path of the external storage where the workflow payload is to be stored")
     @Consumes(MediaType.WILDCARD)
     @Path("/externalstoragelocation")
-    public ExternalStorageLocation getExternalStorageLocation(@QueryParam("path") String path) {
-        return workflowService.getExternalStorageLocation(path);
+    public ExternalStorageLocation getExternalStorageLocation(@QueryParam("path") String path, @QueryParam("operation") String operation, @QueryParam("payloadType") String payloadType) {
+        return workflowService.getExternalStorageLocation(path, operation, payloadType);
     }
 }
\ No newline at end of file

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -441,9 +441,9 @@ public void retry(String workflowId) {
             }
         });
 
-        scheduleTask(workflow, rescheduledTasks);
         dedupAndAddTasks(workflow, rescheduledTasks);
         executionDAOFacade.updateTasks(workflow.getTasks());
+        scheduleTask(workflow, rescheduledTasks);
 
         decide(workflowId);
     }

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/TerminateTaskMapperTest.java
Patch:
@@ -31,7 +31,6 @@ public void getMappedTasks() throws Exception {
 
         WorkflowTask taskToSchedule = new WorkflowTask();
         taskToSchedule.setType(TaskType.TASK_TYPE_TERMINATE);
-        taskToSchedule.setTerminationStatus("COMPLETED");
 
         String taskId = IDGenerator.generate();
 

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractWorkflowServiceTest.java
Patch:
@@ -4068,7 +4068,7 @@ public void testTerminateTaskWithCompletedStatus() {
 
         Map<String, Object> terminateTaskInputParams = new HashMap<>();
         terminateTaskInputParams.put(Terminate.getTerminationStatusParameter(), "COMPLETED");
-        terminateTaskInputParams.put("input", "${lambda0.output}");
+        terminateTaskInputParams.put(Terminate.getTerminationWorkflowOutputParameter(), "${lambda0.output}");
 
         WorkflowTask terminateWorkflowTask = new WorkflowTask();
         terminateWorkflowTask.setType(TaskType.TASK_TYPE_TERMINATE);
@@ -4126,7 +4126,7 @@ public void testTerminateTaskWithFailedStatus() {
 
         Map<String, Object> terminateTaskInputParams = new HashMap<>();
         terminateTaskInputParams.put(Terminate.getTerminationStatusParameter(), "FAILED");
-        terminateTaskInputParams.put("input", "${lambda0.output}");
+        terminateTaskInputParams.put(Terminate.getTerminationWorkflowOutputParameter(), "${lambda0.output}");
 
         WorkflowTask terminateWorkflowTask = new WorkflowTask();
         terminateWorkflowTask.setType(TaskType.TASK_TYPE_TERMINATE);

File: grpc/src/main/java/com/netflix/conductor/grpc/AbstractProtoMapper.java
Patch:
@@ -808,7 +808,6 @@ public TaskResultPb.TaskResult.Status toProto(TaskResult.Status from) {
             case FAILED: to = TaskResultPb.TaskResult.Status.FAILED; break;
             case FAILED_WITH_TERMINAL_ERROR: to = TaskResultPb.TaskResult.Status.FAILED_WITH_TERMINAL_ERROR; break;
             case COMPLETED: to = TaskResultPb.TaskResult.Status.COMPLETED; break;
-            case SCHEDULED: to = TaskResultPb.TaskResult.Status.SCHEDULED; break;
             default: throw new IllegalArgumentException("Unexpected enum constant: " + from);
         }
         return to;
@@ -821,7 +820,6 @@ public TaskResult.Status fromProto(TaskResultPb.TaskResult.Status from) {
             case FAILED: to = TaskResult.Status.FAILED; break;
             case FAILED_WITH_TERMINAL_ERROR: to = TaskResult.Status.FAILED_WITH_TERMINAL_ERROR; break;
             case COMPLETED: to = TaskResult.Status.COMPLETED; break;
-            case SCHEDULED: to = TaskResult.Status.SCHEDULED; break;
             default: throw new IllegalArgumentException("Unexpected enum constant: " + from);
         }
         return to;

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractWorkflowServiceTest.java
Patch:
@@ -3176,7 +3176,7 @@ public void testNonRestartartableWorkflows() {
         assertEquals("task1.Done", workflow.getOutput().get("o3"));
 
         expectedException.expect(ApplicationException.class);
-        expectedException.expectMessage(String.format("is an instance of WorkflowDef: %s and version: %d and is non restartable", JUNIT_TEST_WF_NON_RESTARTABLE, 1));
+        expectedException.expectMessage(String.format("%s is non-restartable", workflow));
         workflowExecutor.rewind(workflow.getWorkflowId(), false);
     }
 

File: es5-persistence/src/test/java/com/netflix/conductor/dao/es5/index/TestElasticSearchRestDAOV5.java
Patch:
@@ -292,7 +292,7 @@ public void testSearchRecentRunningWorkflows() {
     @Test
     public void testSearchArchivableWorkflows() throws IOException {
         String workflowId = "search-workflow-id";
-        Long time = DateTime.now().minusDays(2).toDate().getTime();
+        Long time = DateTime.now().minusDays(7).toDate().getTime();
 
         workflow.setWorkflowId(workflowId);
         workflow.setStatus(Workflow.WorkflowStatus.COMPLETED);
@@ -305,7 +305,7 @@ public void testSearchArchivableWorkflows() throws IOException {
         assertTrue(indexExists("conductor"));
 
         await()
-                .atMost(3, TimeUnit.SECONDS)
+                .atMost(5, TimeUnit.SECONDS)
                 .untilAsserted(
                         () -> {
                             List<String> searchIds = indexDAO.searchArchivableWorkflows("conductor",1);

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/TaskType.java
Patch:
@@ -16,6 +16,7 @@ public enum TaskType {
     WAIT(true),
     USER_DEFINED(false),
     HTTP(true),
+    LAMBDA(true),
     EXCLUSIVE_JOIN(true);
 
     /**
@@ -34,6 +35,7 @@ public enum TaskType {
     public static final String TASK_TYPE_USER_DEFINED = "USER_DEFINED";
     public static final String TASK_TYPE_SIMPLE = "SIMPLE";
     public static final String TASK_TYPE_HTTP = "HTTP";
+    public static final String TASK_TYPE_LAMBDA= "LAMBDA";
     public static final String TASK_TYPE_EXLCUSIVE_JOIN = "EXCLUSIVE_JOIN";
     
     private boolean isSystemTask;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/TaskType.java
Patch:
@@ -16,7 +16,7 @@ public enum TaskType {
     WAIT(true),
     USER_DEFINED(false),
     HTTP(true),
-    LAMBDA(true);
+    LAMBDA(true),
     EXCLUSIVE_JOIN(true);
 
     /**

File: core/src/main/java/com/netflix/conductor/core/execution/SystemTaskType.java
Patch:
@@ -22,25 +22,26 @@
 import java.util.Set;
 
 import com.netflix.conductor.core.execution.tasks.Decision;
+import com.netflix.conductor.core.execution.tasks.ExclusiveJoin;
 import com.netflix.conductor.core.execution.tasks.Fork;
 import com.netflix.conductor.core.execution.tasks.Join;
 import com.netflix.conductor.core.execution.tasks.WorkflowSystemTask;
-
 /**
  * Defines a system task type
  * 
  *
  */
 public enum SystemTaskType {
 
-	DECISION(new Decision()), FORK(new Fork()), JOIN(new Join());
+	DECISION(new Decision()), FORK(new Fork()), JOIN(new Join()), EXCLUSIVE_JOIN(new ExclusiveJoin());
 	
 	private static Set<String> builtInTasks = new HashSet<>();
 	static {
 
 		builtInTasks.add(SystemTaskType.DECISION.name());
 		builtInTasks.add(SystemTaskType.FORK.name());
 		builtInTasks.add(SystemTaskType.JOIN.name());
+		builtInTasks.add(SystemTaskType.EXCLUSIVE_JOIN.name());
 	}
 
 	private WorkflowSystemTask impl;

File: es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/ElasticSearchDAOV6.java
Patch:
@@ -565,6 +565,8 @@ public List<String> searchArchivableWorkflows(String indexName, long archiveTtlD
                 .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays).toString()))
                 .should(QueryBuilders.termQuery("status", "COMPLETED"))
                 .should(QueryBuilders.termQuery("status", "FAILED"))
+                .should(QueryBuilders.termQuery("status", "TIMED_OUT"))
+                .should(QueryBuilders.termQuery("status", "TERMINATED"))
                 .mustNot(QueryBuilders.existsQuery("archived"))
                 .minimumShouldMatch(1);
         SearchRequestBuilder s = elasticSearchClient.prepareSearch(indexName)

File: es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/ElasticSearchRestDAOV6.java
Patch:
@@ -700,6 +700,8 @@ public List<String> searchArchivableWorkflows(String indexName, long archiveTtlD
                 .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays).toString()))
                 .should(QueryBuilders.termQuery("status", "COMPLETED"))
                 .should(QueryBuilders.termQuery("status", "FAILED"))
+                .should(QueryBuilders.termQuery("status", "TIMED_OUT"))
+                .should(QueryBuilders.termQuery("status", "TERMINATED"))
                 .mustNot(QueryBuilders.existsQuery("archived"))
                 .minimumShouldMatch(1);
 

File: es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/ElasticSearchDAOV6.java
Patch:
@@ -565,6 +565,8 @@ public List<String> searchArchivableWorkflows(String indexName, long archiveTtlD
                 .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays).toString()))
                 .should(QueryBuilders.termQuery("status", "COMPLETED"))
                 .should(QueryBuilders.termQuery("status", "FAILED"))
+                .should(QueryBuilders.termQuery("status", "TIMED_OUT"))
+                .should(QueryBuilders.termQuery("status", "TERMINATED"))
                 .mustNot(QueryBuilders.existsQuery("archived"))
                 .minimumShouldMatch(1);
         SearchRequestBuilder s = elasticSearchClient.prepareSearch(indexName)

File: es6-persistence/src/main/java/com/netflix/conductor/dao/es6/index/ElasticSearchRestDAOV6.java
Patch:
@@ -700,6 +700,8 @@ public List<String> searchArchivableWorkflows(String indexName, long archiveTtlD
                 .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays).toString()))
                 .should(QueryBuilders.termQuery("status", "COMPLETED"))
                 .should(QueryBuilders.termQuery("status", "FAILED"))
+                .should(QueryBuilders.termQuery("status", "TIMED_OUT"))
+                .should(QueryBuilders.termQuery("status", "TERMINATED"))
                 .mustNot(QueryBuilders.existsQuery("archived"))
                 .minimumShouldMatch(1);
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -659,7 +659,8 @@ public void updateTask(TaskResult taskResult) {
             workflowInstance = metadataMapperService.populateWorkflowWithDefinitions(workflowInstance);
         }
 
-        Task task = executionDAOFacade.getTaskById(taskResult.getTaskId());
+        Task task = Optional.ofNullable(executionDAOFacade.getTaskById(taskResult.getTaskId()))
+                .orElseThrow(() -> new ApplicationException(Code.NOT_FOUND, "No such task found by id: " + taskResult.getTaskId()));
 
         LOGGER.debug("Task: {} belonging to Workflow {} being updated", task, workflowInstance);
 

File: server/src/main/java/com/netflix/conductor/server/ServerModule.java
Patch:
@@ -22,6 +22,7 @@
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.CoreModule;
 import com.netflix.conductor.core.config.ValidationModule;
+import com.netflix.conductor.core.execution.WorkflowSweeper;
 import com.netflix.conductor.dyno.SystemPropertiesDynomiteConfiguration;
 import com.netflix.conductor.grpc.server.GRPCModule;
 import com.netflix.conductor.interceptors.ServiceInterceptor;
@@ -49,5 +50,6 @@ protected void configure() {
         bind(ObjectMapper.class).toProvider(JsonMapperProvider.class);
         bind(Configuration.class).to(SystemPropertiesDynomiteConfiguration.class);
         bind(ExecutorService.class).toProvider(ExecutorServiceProvider.class).in(Scopes.SINGLETON);
+        bind(WorkflowSweeper.class).asEagerSingleton();
     }
 }

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -659,7 +659,8 @@ public void updateTask(TaskResult taskResult) {
             workflowInstance = metadataMapperService.populateWorkflowWithDefinitions(workflowInstance);
         }
 
-        Task task = executionDAOFacade.getTaskById(taskResult.getTaskId());
+        Task task = Optional.ofNullable(executionDAOFacade.getTaskById(taskResult.getTaskId()))
+                .orElseThrow(() -> new ApplicationException(Code.NOT_FOUND, "No such task found by id: " + taskResult.getTaskId()));
 
         LOGGER.debug("Task: {} belonging to Workflow {} being updated", task, workflowInstance);
 

File: server/src/main/java/com/netflix/conductor/server/ServerModule.java
Patch:
@@ -22,6 +22,7 @@
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.CoreModule;
 import com.netflix.conductor.core.config.ValidationModule;
+import com.netflix.conductor.core.execution.WorkflowSweeper;
 import com.netflix.conductor.dyno.SystemPropertiesDynomiteConfiguration;
 import com.netflix.conductor.grpc.server.GRPCModule;
 import com.netflix.conductor.interceptors.ServiceInterceptor;
@@ -49,5 +50,6 @@ protected void configure() {
         bind(ObjectMapper.class).toProvider(JsonMapperProvider.class);
         bind(Configuration.class).to(SystemPropertiesDynomiteConfiguration.class);
         bind(ExecutorService.class).toProvider(ExecutorServiceProvider.class).in(Scopes.SINGLETON);
+        bind(WorkflowSweeper.class).asEagerSingleton();
     }
 }

File: contribs/src/main/java/com/netflix/conductor/contribs/lambda/Lambda.java
Patch:
@@ -49,7 +49,7 @@ public void start(Workflow workflow, Task task, WorkflowExecutor executor) {
             taskOutput.put("result", returnValue);
             task.setStatus(Task.Status.COMPLETED);
         } catch (ScriptException e) {
-            logger.error(e.getMessage(), e);
+            logger.error("Failed to execute  Lambda: {}", scriptExpression, e);
             task.setStatus(Task.Status.FAILED);
             task.setReasonForIncompletion(e.getMessage());
             taskOutput.put("error", e.getCause() != null ? e.getCause().getMessage() : e.getMessage());

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -582,6 +582,8 @@ public List<String> searchArchivableWorkflows(String indexName, long archiveTtlD
         QueryBuilder q = QueryBuilders.boolQuery()
             .should(QueryBuilders.termQuery("status", "COMPLETED"))
             .should(QueryBuilders.termQuery("status", "FAILED"))
+            .should(QueryBuilders.termQuery("status", "TIMED_OUT"))
+            .should(QueryBuilders.termQuery("status", "TERMINATED"))
             .mustNot(QueryBuilders.existsQuery("archived"))
             .minimumShouldMatch(1);
         SearchRequestBuilder s = elasticSearchClient.prepareSearch(indexName)

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchRestDAOV5.java
Patch:
@@ -597,6 +597,8 @@ public List<String> searchArchivableWorkflows(String indexName, long archiveTtlD
                 .must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays).toString()))
                 .should(QueryBuilders.termQuery("status", "COMPLETED"))
                 .should(QueryBuilders.termQuery("status", "FAILED"))
+                .should(QueryBuilders.termQuery("status", "TIMED_OUT"))
+                .should(QueryBuilders.termQuery("status", "TERMINATED"))
                 .mustNot(QueryBuilders.existsQuery("archived"))
                 .minimumShouldMatch(1);
 

File: server/src/main/java/com/netflix/conductor/bootstrap/ModulesProvider.java
Patch:
@@ -7,7 +7,7 @@
 import com.netflix.conductor.contribs.http.HttpTask;
 import com.netflix.conductor.contribs.http.RestClientManager;
 import com.netflix.conductor.contribs.json.JsonJqTransform;
-import com.netflix.conductor.contribs.lambda.ScriptTask;
+import com.netflix.conductor.contribs.lambda.Lambda;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.execution.WorkflowExecutorModule;
 import com.netflix.conductor.core.utils.DummyPayloadStorage;
@@ -136,7 +136,7 @@ protected void configure() {
 
         new HttpTask(new RestClientManager(), configuration);
         new JsonJqTransform();
-        new ScriptTask();
+        new Lambda();
         modules.add(new ServerModule());
 
         return modules;

File: jersey/src/main/java/com/netflix/conductor/server/resources/WebAppExceptionMapper.java
Patch:
@@ -67,7 +67,7 @@ public Response toResponse(WebApplicationException exception) {
         this.code = Code.forValue(response.getStatus());
         Map<String, Object> entityMap = new LinkedHashMap<>();
         entityMap.put("instance", host);
-        entityMap.put("code", Optional.of(code.toString()).orElse(null));
+        entityMap.put("code", Optional.ofNullable(code).map(Code::name).orElse(null));
         entityMap.put("message", exception.getCause());
         entityMap.put("retryable", false);
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -538,8 +538,8 @@ void completeWorkflow(Workflow wf) {
         Monitors.recordWorkflowCompletion(workflow.getWorkflowName(), workflow.getEndTime() - workflow.getStartTime(), wf.getOwnerApp());
         queueDAO.remove(DECIDER_QUEUE, workflow.getWorkflowId());    //remove from the sweep queue
 
-        if (wf.getWorkflowDefinition().isWorkflowStatusListenerEnabled()) {
-            workflowStatusListener.onWorkflowCompleted(wf);
+        if (workflow.getWorkflowDefinition().isWorkflowStatusListenerEnabled()) {
+            workflowStatusListener.onWorkflowCompleted(workflow);
         }
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -831,8 +831,6 @@ public boolean decide(String workflowId) {
                 }
             }
 
-            stateChanged = scheduleTask(workflow, tasksToBeScheduled) || stateChanged;
-
             if (!outcome.tasksToBeUpdated.isEmpty()) {
                 for (Task task : tasksToBeUpdated) {
                     if (task.getStatus() != null && (!task.getStatus().equals(Task.Status.IN_PROGRESS)
@@ -848,6 +846,8 @@ public boolean decide(String workflowId) {
                 queueDAO.push(DECIDER_QUEUE, workflow.getWorkflowId(), config.getSweepFrequency());
             }
 
+            stateChanged = scheduleTask(workflow, tasksToBeScheduled) || stateChanged;
+
             if (stateChanged) {
                 decide(workflowId);
             }

File: client/src/main/java/com/netflix/conductor/client/http/ClientBase.java
Patch:
@@ -255,7 +255,7 @@ private void handleUniformInterfaceException(UniformInterfaceException exception
                 return;
             }
             String errorMessage = clientResponse.getEntity(String.class);
-            logger.error("Unable to invoke Conductor API with uri: {}, unexpected response from server: {}", uri, clientResponseToString(exception.getResponse()), exception);
+            logger.error("Unable to invoke Conductor API with uri: {}, unexpected response from server: statusCode={}, responseBody='{}'.", uri, clientResponse.getStatus(), errorMessage);
             ErrorResponse errorResponse;
             try {
                 errorResponse = objectMapper.readValue(errorMessage, ErrorResponse.class);

File: core/src/main/java/com/netflix/conductor/service/AdminService.java
Patch:
@@ -47,5 +47,5 @@ public interface AdminService {
      * @return list of pending {@link Task}
      */
     List<Task> getListOfPendingTask(@NotEmpty(message = "TaskType cannot be null or empty.") String taskType,
-                                    @NotNull Integer start, @NotNull Integer count);
+                                    Integer start, Integer count);
 }

File: core/src/main/java/com/netflix/conductor/service/TaskService.java
Patch:
@@ -87,8 +87,7 @@ Task getPendingTaskForWorkflow(@NotEmpty(message = "WorkflowId cannot be null or
      * @param workerId Id of the worker
      * @return `true|false` if task if received or not
      */
-    String ackTaskReceived(@NotEmpty(message = "TaskId cannot be null or empty.") String taskId,
-                           @NotEmpty(message = "WorkerID cannot be null or empty.") String workerId);
+    String ackTaskReceived(@NotEmpty(message = "TaskId cannot be null or empty.") String taskId, String workerId);
 
     /**
      * Ack Task is received.
@@ -144,7 +143,7 @@ void removeTaskFromQueue(@NotEmpty(message = "TaskType cannot be null or empty."
      * @param taskTypes List of task types.
      * @return map of task type as Key and queue size as value.
      */
-    Map<String, Integer> getTaskQueueSizes(@NotEmpty(message = "List of taskType cannot be null or empty") List<@NotEmpty String> taskTypes);
+    Map<String, Integer> getTaskQueueSizes(List<String> taskTypes);
 
     /**
      * Get the details about each queue.

File: server/src/main/java/com/netflix/conductor/bootstrap/ModulesProvider.java
Patch:
@@ -7,6 +7,7 @@
 import com.netflix.conductor.contribs.http.HttpTask;
 import com.netflix.conductor.contribs.http.RestClientManager;
 import com.netflix.conductor.contribs.json.JsonJqTransform;
+import com.netflix.conductor.contribs.script.ScriptTask;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.execution.WorkflowExecutorModule;
 import com.netflix.conductor.core.utils.DummyPayloadStorage;
@@ -135,6 +136,7 @@ protected void configure() {
 
         new HttpTask(new RestClientManager(), configuration);
         new JsonJqTransform();
+        new ScriptTask();
         modules.add(new ServerModule());
 
         return modules;

File: core/src/test/java/com/netflix/conductor/service/MetadataServiceTest.java
Patch:
@@ -267,7 +267,7 @@ public void testRegisterWorkflowDefInvalidName() {
     public void testRegisterWorkflowDef() {
         WorkflowDef workflowDef = new WorkflowDef();
         workflowDef.setName("somename");
-        workflowDef.setSchemaVersion(5);
+        workflowDef.setSchemaVersion(2);
         List<WorkflowTask> tasks = new ArrayList<>();
         WorkflowTask workflowTask = new WorkflowTask();
         workflowTask.setTaskReferenceName("hello");

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -831,8 +831,6 @@ public boolean decide(String workflowId) {
                 }
             }
 
-            stateChanged = scheduleTask(workflow, tasksToBeScheduled) || stateChanged;
-
             if (!outcome.tasksToBeUpdated.isEmpty()) {
                 for (Task task : tasksToBeUpdated) {
                     if (task.getStatus() != null && (!task.getStatus().equals(Task.Status.IN_PROGRESS)
@@ -848,6 +846,8 @@ public boolean decide(String workflowId) {
                 queueDAO.push(DECIDER_QUEUE, workflow.getWorkflowId(), config.getSweepFrequency());
             }
 
+            stateChanged = scheduleTask(workflow, tasksToBeScheduled) || stateChanged;
+
             if (stateChanged) {
                 decide(workflowId);
             }

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -378,6 +378,8 @@ public void rewind(String workflowId, boolean useLatestDefinitions) {
         workflow.setEndTime(0);
         // Change the status to running
         workflow.setStatus(WorkflowStatus.RUNNING);
+        workflow.setOutput(null);
+        workflow.setExternalOutputPayloadStoragePath(null);
         executionDAOFacade.updateWorkflow(workflow);
         decide(workflowId);
     }

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -427,6 +427,7 @@ public void retry(String workflowId) {
         });
 
         scheduleTask(workflow, rescheduledTasks);
+        dedupAndAddTasks(workflow, rescheduledTasks);
         executionDAOFacade.updateTasks(workflow.getTasks());
 
         decide(workflowId);

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -427,6 +427,7 @@ public void retry(String workflowId) {
         });
 
         scheduleTask(workflow, rescheduledTasks);
+        dedupAndAddTasks(workflow, rescheduledTasks);
         executionDAOFacade.updateTasks(workflow.getTasks());
 
         decide(workflowId);

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -355,7 +355,7 @@ Task retry(TaskDef taskDefinition, WorkflowTask workflowTask, Task task, Workflo
         int retryCount = task.getRetryCount();
 
         if(taskDefinition == null) {
-            taskDefinition = metadataDAO.getTaskDef(task.getTaskType());
+            taskDefinition = metadataDAO.getTaskDef(task.getTaskDefName());
         }
 
         if (!task.getStatus().isRetriable() || SystemTaskType.isBuiltIn(task.getTaskType()) || taskDefinition == null || taskDefinition.getRetryCount() <= retryCount) {

File: contribs/src/test/java/com/netflix/conductor/contribs/http/TestHttpTask.java
Patch:
@@ -31,6 +31,7 @@
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import com.netflix.conductor.core.execution.mapper.TaskMapper;
 import com.netflix.conductor.core.utils.ExternalPayloadStorageUtils;
+import com.netflix.conductor.dao.MetadataDAO;
 import com.netflix.conductor.dao.QueueDAO;
 import org.eclipse.jetty.server.Request;
 import org.eclipse.jetty.server.Server;
@@ -288,11 +289,12 @@ public void testOptional() {
         workflow.getTasks().add(task);
 
         QueueDAO queueDAO = mock(QueueDAO.class);
+        MetadataDAO metadataDAO = mock(MetadataDAO.class);
         ExternalPayloadStorageUtils externalPayloadStorageUtils = mock(ExternalPayloadStorageUtils.class);
         ParametersUtils parametersUtils = mock(ParametersUtils.class);
 
         Map<String, TaskMapper> taskMappers = new HashMap<>();
-        new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers).decide(workflow);
+        new DeciderService(parametersUtils, queueDAO, metadataDAO, externalPayloadStorageUtils, taskMappers).decide(workflow);
 
         System.out.println(workflow.getTasks());
         System.out.println(workflow.getStatus());

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -45,7 +45,6 @@
 import com.netflix.conductor.dao.QueueDAO;
 import org.junit.Before;
 import org.junit.Test;
-import org.mockito.Mockito;
 
 import java.io.InputStream;
 import java.util.Arrays;
@@ -59,7 +58,6 @@
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNotSame;
 import static org.junit.Assert.assertTrue;
-import static org.mockito.Matchers.any;
 import static org.mockito.Matchers.anyString;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
@@ -87,6 +85,8 @@ public class TestDeciderOutcomes {
     public void init() {
         metadataDAO = mock(MetadataDAO.class);
         QueueDAO queueDAO = mock(QueueDAO.class);
+        MetadataDAO metadataDAO = mock(MetadataDAO.class);
+
         ExternalPayloadStorageUtils externalPayloadStorageUtils = mock(ExternalPayloadStorageUtils.class);
         Configuration configuration = mock(Configuration.class);
         when(configuration.getTaskInputPayloadSizeThresholdKB()).thenReturn(10L);
@@ -111,7 +111,7 @@ public void init() {
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
         taskMappers.put("HTTP", new HTTPTaskMapper(parametersUtils, metadataDAO));
 
-        this.deciderService = new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers);
+        this.deciderService = new DeciderService(parametersUtils, queueDAO, metadataDAO,  externalPayloadStorageUtils, taskMappers);
     }
 
     @Test

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -113,6 +113,7 @@ public void setup() {
         metadataDAO = mock(MetadataDAO.class);
         externalPayloadStorageUtils = mock(ExternalPayloadStorageUtils.class);
         QueueDAO queueDAO = mock(QueueDAO.class);
+        MetadataDAO metadataDAO = mock(MetadataDAO.class);
 
         TaskDef taskDef = new TaskDef();
 
@@ -136,7 +137,7 @@ public void setup() {
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
         taskMappers.put("HTTP", new HTTPTaskMapper(parametersUtils, metadataDAO));
 
-        deciderService = new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers);
+        deciderService = new DeciderService(parametersUtils, queueDAO, metadataDAO, externalPayloadStorageUtils, taskMappers);
     }
 
     @Test

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -114,7 +114,7 @@ public void init() {
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
         taskMappers.put("HTTP", new HTTPTaskMapper(parametersUtils, metadataDAO));
 
-        deciderService = new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers);
+        deciderService = new DeciderService(parametersUtils, queueDAO, metadataDAO, externalPayloadStorageUtils, taskMappers);
         MetadataMapperService metadataMapperService = new MetadataMapperService(metadataDAO);
         workflowExecutor = new WorkflowExecutor(deciderService, metadataDAO, queueDAO, metadataMapperService, workflowStatusListener, executionDAOFacade, config);
     }

File: contribs/src/test/java/com/netflix/conductor/contribs/http/TestHttpTask.java
Patch:
@@ -31,6 +31,7 @@
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 import com.netflix.conductor.core.execution.mapper.TaskMapper;
 import com.netflix.conductor.core.utils.ExternalPayloadStorageUtils;
+import com.netflix.conductor.dao.MetadataDAO;
 import com.netflix.conductor.dao.QueueDAO;
 import org.eclipse.jetty.server.Request;
 import org.eclipse.jetty.server.Server;
@@ -288,11 +289,12 @@ public void testOptional() {
         workflow.getTasks().add(task);
 
         QueueDAO queueDAO = mock(QueueDAO.class);
+        MetadataDAO metadataDAO = mock(MetadataDAO.class);
         ExternalPayloadStorageUtils externalPayloadStorageUtils = mock(ExternalPayloadStorageUtils.class);
         ParametersUtils parametersUtils = mock(ParametersUtils.class);
 
         Map<String, TaskMapper> taskMappers = new HashMap<>();
-        new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers).decide(workflow);
+        new DeciderService(parametersUtils, queueDAO, metadataDAO, externalPayloadStorageUtils, taskMappers).decide(workflow);
 
         System.out.println(workflow.getTasks());
         System.out.println(workflow.getStatus());

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -45,7 +45,6 @@
 import com.netflix.conductor.dao.QueueDAO;
 import org.junit.Before;
 import org.junit.Test;
-import org.mockito.Mockito;
 
 import java.io.InputStream;
 import java.util.Arrays;
@@ -59,7 +58,6 @@
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNotSame;
 import static org.junit.Assert.assertTrue;
-import static org.mockito.Matchers.any;
 import static org.mockito.Matchers.anyString;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
@@ -87,6 +85,8 @@ public class TestDeciderOutcomes {
     public void init() {
         metadataDAO = mock(MetadataDAO.class);
         QueueDAO queueDAO = mock(QueueDAO.class);
+        MetadataDAO metadataDAO = mock(MetadataDAO.class);
+
         ExternalPayloadStorageUtils externalPayloadStorageUtils = mock(ExternalPayloadStorageUtils.class);
         Configuration configuration = mock(Configuration.class);
         when(configuration.getTaskInputPayloadSizeThresholdKB()).thenReturn(10L);
@@ -111,7 +111,7 @@ public void init() {
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
         taskMappers.put("HTTP", new HTTPTaskMapper(parametersUtils, metadataDAO));
 
-        this.deciderService = new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers);
+        this.deciderService = new DeciderService(parametersUtils, queueDAO, metadataDAO,  externalPayloadStorageUtils, taskMappers);
     }
 
     @Test

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -113,6 +113,7 @@ public void setup() {
         metadataDAO = mock(MetadataDAO.class);
         externalPayloadStorageUtils = mock(ExternalPayloadStorageUtils.class);
         QueueDAO queueDAO = mock(QueueDAO.class);
+        MetadataDAO metadataDAO = mock(MetadataDAO.class);
 
         TaskDef taskDef = new TaskDef();
 
@@ -136,7 +137,7 @@ public void setup() {
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
         taskMappers.put("HTTP", new HTTPTaskMapper(parametersUtils, metadataDAO));
 
-        deciderService = new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers);
+        deciderService = new DeciderService(parametersUtils, queueDAO, metadataDAO, externalPayloadStorageUtils, taskMappers);
     }
 
     @Test

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -114,7 +114,7 @@ public void init() {
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
         taskMappers.put("HTTP", new HTTPTaskMapper(parametersUtils, metadataDAO));
 
-        deciderService = new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers);
+        deciderService = new DeciderService(parametersUtils, queueDAO, metadataDAO, externalPayloadStorageUtils, taskMappers);
         MetadataMapperService metadataMapperService = new MetadataMapperService(metadataDAO);
         workflowExecutor = new WorkflowExecutor(deciderService, metadataDAO, queueDAO, metadataMapperService, workflowStatusListener, executionDAOFacade, config);
     }

File: common/src/main/java/com/netflix/conductor/common/run/WorkflowSummary.java
Patch:
@@ -86,8 +86,8 @@ public WorkflowSummary() {
 	}
 	public WorkflowSummary(Workflow workflow) {
 
-		SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSS'Z'");
-    	sdf.setTimeZone(gmt);
+        SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSS'Z'");
+        sdf.setTimeZone(gmt);
     	
 		this.workflowType = workflow.getWorkflowName();
 		this.version = workflow.getWorkflowVersion();

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAO.java
Patch:
@@ -127,15 +127,15 @@ public List<Task> createTasks(List<Task> tasks) {
 
 			recordRedisDaoRequests("createTask", task.getTaskType(), task.getWorkflowType());
 
-			task.setScheduledTime(System.currentTimeMillis());
-
 			String taskKey = task.getReferenceTaskName() + "" + task.getRetryCount();
 			Long added = dynoClient.hset(nsKey(SCHEDULED_TASKS, task.getWorkflowInstanceId()), taskKey, task.getTaskId());
 			if (added < 1) {
 				logger.debug("Task already scheduled, skipping the run " + task.getTaskId() + ", ref=" + task.getReferenceTaskName() + ", key=" + taskKey);
 				continue;
 			}
 
+			task.setScheduledTime(System.currentTimeMillis());
+
 			correlateTaskToWorkflowInDS(task.getTaskId(), task.getWorkflowInstanceId());
 			logger.debug("Scheduled task added to WORKFLOW_TO_TASKS workflowId: {}, taskId: {}, taskType: {} during createTasks",
                     task.getWorkflowInstanceId(), task.getTaskId(), task.getTaskType());

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -17,7 +17,6 @@
 
 import com.github.vmg.protogen.annotations.ProtoField;
 import com.github.vmg.protogen.annotations.ProtoMessage;
-import com.netflix.conductor.common.constraints.TaskInputParamConstraint;
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
 
 import javax.validation.Valid;
@@ -82,7 +81,6 @@ public static boolean isSystemTask(String name) {
 	//Key: Name of the input parameter.  MUST be one of the keys defined in TaskDef (e.g. fileName)
 	//Value: mapping of the parameter from another task (e.g. task1.someOutputParameterAsFileName)
 	@ProtoField(id = 4)
-	@TaskInputParamConstraint
 	private Map<String, Object> inputParameters = new HashMap<>();
 
 	@ProtoField(id = 5)

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/TaskMapper.java
Patch:
@@ -1,4 +1,4 @@
-/**
+/*
  * Copyright 2018 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License");

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -32,6 +32,7 @@
 import com.netflix.conductor.core.execution.mapper.EventTaskMapper;
 import com.netflix.conductor.core.execution.mapper.ForkJoinDynamicTaskMapper;
 import com.netflix.conductor.core.execution.mapper.ForkJoinTaskMapper;
+import com.netflix.conductor.core.execution.mapper.HTTPTaskMapper;
 import com.netflix.conductor.core.execution.mapper.JoinTaskMapper;
 import com.netflix.conductor.core.execution.mapper.SimpleTaskMapper;
 import com.netflix.conductor.core.execution.mapper.SubWorkflowTaskMapper;
@@ -108,6 +109,7 @@ public void init() {
         taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
+        taskMappers.put("HTTP", new HTTPTaskMapper(parametersUtils, metadataDAO));
 
         this.deciderService = new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers);
     }

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -33,6 +33,7 @@
 import com.netflix.conductor.core.execution.mapper.EventTaskMapper;
 import com.netflix.conductor.core.execution.mapper.ForkJoinDynamicTaskMapper;
 import com.netflix.conductor.core.execution.mapper.ForkJoinTaskMapper;
+import com.netflix.conductor.core.execution.mapper.HTTPTaskMapper;
 import com.netflix.conductor.core.execution.mapper.JoinTaskMapper;
 import com.netflix.conductor.core.execution.mapper.SimpleTaskMapper;
 import com.netflix.conductor.core.execution.mapper.SubWorkflowTaskMapper;
@@ -133,6 +134,7 @@ public void setup() {
         taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
+        taskMappers.put("HTTP", new HTTPTaskMapper(parametersUtils, metadataDAO));
 
         deciderService = new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers);
     }

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -30,6 +30,7 @@
 import com.netflix.conductor.core.execution.mapper.EventTaskMapper;
 import com.netflix.conductor.core.execution.mapper.ForkJoinDynamicTaskMapper;
 import com.netflix.conductor.core.execution.mapper.ForkJoinTaskMapper;
+import com.netflix.conductor.core.execution.mapper.HTTPTaskMapper;
 import com.netflix.conductor.core.execution.mapper.JoinTaskMapper;
 import com.netflix.conductor.core.execution.mapper.SimpleTaskMapper;
 import com.netflix.conductor.core.execution.mapper.SubWorkflowTaskMapper;
@@ -111,6 +112,7 @@ public void init() {
         taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
+        taskMappers.put("HTTP", new HTTPTaskMapper(parametersUtils, metadataDAO));
 
         deciderService = new DeciderService(parametersUtils, queueDAO, externalPayloadStorageUtils, taskMappers);
         MetadataMapperService metadataMapperService = new MetadataMapperService(metadataDAO);

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -17,7 +17,6 @@
 
 import com.github.vmg.protogen.annotations.ProtoField;
 import com.github.vmg.protogen.annotations.ProtoMessage;
-import com.netflix.conductor.common.constraints.TaskInputParamConstraint;
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
 
 import javax.validation.Valid;
@@ -82,7 +81,6 @@ public static boolean isSystemTask(String name) {
 	//Key: Name of the input parameter.  MUST be one of the keys defined in TaskDef (e.g. fileName)
 	//Value: mapping of the parameter from another task (e.g. task1.someOutputParameterAsFileName)
 	@ProtoField(id = 4)
-	@TaskInputParamConstraint
 	private Map<String, Object> inputParameters = new HashMap<>();
 
 	@ProtoField(id = 5)

File: common/src/test/java/com/netflix/conductor/common/workflow/TestWorkflowDef.java
Patch:
@@ -18,9 +18,9 @@
  */
 package com.netflix.conductor.common.workflow;
 
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
 import org.junit.Test;
 
 import java.util.ArrayList;
@@ -61,7 +61,7 @@ public void test() {
 		wf.setDescription(COND_TASK_WF);
 		
 		WorkflowTask subCaseTask = new WorkflowTask();
-		subCaseTask.setType(Type.DECISION.name());
+		subCaseTask.setType(TaskType.DECISION.name());
 		subCaseTask.setCaseValueParam("case2");
 		subCaseTask.setName("case2");
 		subCaseTask.setTaskReferenceName("case2");
@@ -72,7 +72,7 @@ public void test() {
 		
 		
 		WorkflowTask caseTask = new WorkflowTask();
-		caseTask.setType(Type.DECISION.name());
+		caseTask.setType(TaskType.DECISION.name());
 		caseTask.setCaseValueParam("case");
 		caseTask.setName("case");
 		caseTask.setTaskReferenceName("case");

File: common/src/test/java/com/netflix/conductor/common/workflow/TestWorkflowTask.java
Patch:
@@ -21,10 +21,10 @@
 
 import static org.junit.Assert.*;
 
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import org.junit.Test;
 
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
 
 /**
  * @author Viren
@@ -35,10 +35,10 @@ public class TestWorkflowTask {
 	@Test
 	public void test() {
 		WorkflowTask wt = new WorkflowTask();
-		wt.setWorkflowTaskType(Type.DECISION);
+		wt.setWorkflowTaskType(TaskType.DECISION);
 		
 		assertNotNull(wt.getType());
-		assertEquals(Type.DECISION.name(), wt.getType());
+		assertEquals(TaskType.DECISION.name(), wt.getType());
 	}
 	
 	@Test

File: contribs/src/main/java/com/netflix/conductor/contribs/NatsModule.java
Patch:
@@ -18,6 +18,8 @@
  */
 package com.netflix.conductor.contribs;
 
+import static com.netflix.conductor.core.events.EventQueues.EVENT_QUEUE_PROVIDERS_QUALIFIER;
+
 import com.google.inject.AbstractModule;
 import com.google.inject.Singleton;
 import com.google.inject.multibindings.ProvidesIntoMap;
@@ -45,7 +47,7 @@ protected void configure() {
 	@ProvidesIntoMap
 	@StringMapKey("nats")
 	@Singleton
-	@Named("EventQueueProviders")
+	@Named(EVENT_QUEUE_PROVIDERS_QUALIFIER)
 	public EventQueueProvider getNATSEventQueueProvider(Configuration configuration) {
 		return new NATSEventQueueProvider(configuration);
 	}

File: contribs/src/main/java/com/netflix/conductor/contribs/NatsStreamModule.java
Patch:
@@ -18,6 +18,8 @@
  */
 package com.netflix.conductor.contribs;
 
+import static com.netflix.conductor.core.events.EventQueues.EVENT_QUEUE_PROVIDERS_QUALIFIER;
+
 import com.google.inject.AbstractModule;
 import com.google.inject.Singleton;
 import com.google.inject.multibindings.ProvidesIntoMap;
@@ -26,8 +28,6 @@
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.events.nats.NATSStreamEventQueueProvider;
-import com.netflix.conductor.core.events.queue.dyno.DynoEventQueueProvider;
-import com.netflix.conductor.dao.QueueDAO;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -47,7 +47,7 @@ protected void configure() {
 	@ProvidesIntoMap
 	@StringMapKey("nats_stream")
 	@Singleton
-	@Named("EventQueueProviders")
+	@Named(EVENT_QUEUE_PROVIDERS_QUALIFIER)
 	public EventQueueProvider geNATSStreamEventQueueProvider(Configuration configuration) {
 		return new NATSStreamEventQueueProvider(configuration);
 	}

File: core/src/main/java/com/netflix/conductor/service/TaskService.java
Patch:
@@ -94,7 +94,7 @@ public interface TaskService {
      * @param taskId   Id of the task
      * @return `true|false` if task if received or not
      */
-    String ackTaskReceived(String taskId);
+    boolean ackTaskReceived(String taskId);
 
     /**
      * Log Task Execution Details.

File: cassandra-persistence/src/main/java/com/netflix/conductor/cassandra/CassandraModule.java
Patch:
@@ -26,7 +26,6 @@ protected void configure() {
         bind(CassandraConfiguration.class).to(SystemPropertiesCassandraConfiguration.class);
         bind(Cluster.class).toProvider(CassandraClusterProvider.class).asEagerSingleton();
         bind(Session.class).toProvider(CassandraSessionProvider.class);
-        bind(Statements.class).asEagerSingleton();
 
         bind(ExecutionDAO.class).to(CassandraExecutionDAO.class);
     }

File: client/src/main/java/com/netflix/conductor/client/task/WorkflowTaskCoordinator.java
Patch:
@@ -287,7 +287,7 @@ private void shutdownExecutorService(ExecutorService executorService, long timeo
 				logger.debug("tasks completed, shutting down");
 			} else {
 				logger.warn(String.format("forcing shutdown after waiting for %s second", timeout));
-				this.scheduledExecutorService.shutdownNow();
+				executorService.shutdownNow();
 			}
 		} catch (InterruptedException ie) {
 			logger.warn("shutdown interrupted, invoking shutdownNow");

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -212,6 +212,6 @@ default List<AbstractModule> getAdditionalModules() {
 
 
     enum DB {
-        REDIS, DYNOMITE, MEMORY, REDIS_CLUSTER, MYSQL, CASSANDRA
+        REDIS, DYNOMITE, MEMORY, REDIS_CLUSTER, MYSQL, CASSANDRA, REDIS_SENTINEL
     }
 }

File: core/src/main/java/com/netflix/conductor/service/common/BulkResponse.java
Patch:
@@ -1,4 +1,4 @@
-package com.netflix.conductor.server.common;
+package com.netflix.conductor.service.common;
 
 import java.util.ArrayList;
 import java.util.HashMap;

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -18,7 +18,6 @@
  */
 package com.netflix.conductor.server.resources;
 
-import com.google.common.base.Preconditions;
 import com.netflix.conductor.common.metadata.workflow.RerunWorkflowRequest;
 import com.netflix.conductor.common.metadata.workflow.SkipTaskRequest;
 import com.netflix.conductor.common.metadata.workflow.StartWorkflowRequest;
@@ -29,7 +28,6 @@
 import com.netflix.conductor.service.WorkflowService;
 import io.swagger.annotations.Api;
 import io.swagger.annotations.ApiOperation;
-import org.apache.commons.lang3.StringUtils;
 
 import javax.inject.Inject;
 import javax.inject.Singleton;
@@ -131,7 +129,6 @@ public List<String> getRunningWorkflow(@PathParam("name") String workflowName,
                                            @QueryParam("version") @DefaultValue("1") Integer version,
                                            @QueryParam("startTime") Long startTime,
                                            @QueryParam("endTime") Long endTime) {
-        Preconditions.checkArgument(StringUtils.isNotBlank(workflowName), "Name cannot be null or empty.");
         return workflowService.getRunningWorkflows(workflowName, version, startTime, endTime);
     }
 

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAOTest.java
Patch:
@@ -61,8 +61,7 @@ public void testPendingByCorrelationId() {
         Workflow workflow = createTestWorkflow();
         workflow.setWorkflowDefinition(def);
 
-        String idBase = workflow.getWorkflowId();
-        generateWorkflows(workflow, idBase, 10);
+        generateWorkflows(workflow, 10);
 
         List<Workflow> bycorrelationId = getExecutionDAO().getWorkflowsByCorrelationId("corr001", true);
         assertNotNull(bycorrelationId);

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAO.java
Patch:
@@ -289,7 +289,9 @@ public boolean exceedsInProgressLimit(Task task) {
 			logger.info("Task execution count limited. task - {}:{}, limit: {}, current: {}", task.getTaskId(), task.getTaskDefName(), limit, current);
 			String inProgressKey = nsKey(TASKS_IN_PROGRESS_STATUS, task.getTaskDefName());
 			//Cleanup any items that are still present in the rate limit bucket but not in progress anymore!
-			ids.stream().filter(id -> !dynoClient.sismember(inProgressKey, id)).forEach(id2 -> dynoClient.zrem(rateLimitKey, id2));
+			ids.stream()
+					.filter(id -> !dynoClient.sismember(inProgressKey, id))
+					.forEach(id2 -> dynoClient.zrem(rateLimitKey, id2));
 			Monitors.recordTaskRateLimited(task.getTaskDefName(), limit);
 		}
 		return rateLimited;

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/MySQLTestModule.java
Patch:
@@ -9,6 +9,8 @@
 import com.netflix.conductor.common.utils.JsonMapperProvider;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.CoreModule;
+import com.netflix.conductor.core.execution.WorkflowStatusListener;
+import com.netflix.conductor.core.execution.WorkflowStatusListenerStub;
 import com.netflix.conductor.dao.ExecutionDAO;
 import com.netflix.conductor.dao.IndexDAO;
 import com.netflix.conductor.dao.MetadataDAO;
@@ -50,6 +52,7 @@ protected void configure() {
         bind(ExecutionDAO.class).to(MySQLExecutionDAO.class);
         bind(QueueDAO.class).to(MySQLQueueDAO.class);
         bind(IndexDAO.class).to(MockIndexDAO.class);
+        bind(WorkflowStatusListener.class).to(WorkflowStatusListenerStub.class);
 
         install(new CoreModule());
         bind(UserTask.class).asEagerSingleton();

File: core/src/main/java/com/netflix/conductor/service/WorkflowService.java
Patch:
@@ -55,7 +55,7 @@ public WorkflowService(WorkflowExecutor workflowExecutor, ExecutionService execu
         this.workflowExecutor = workflowExecutor;
         this.executionService = executionService;
         this.metadataService = metadataService;
-        this.maxSearchSize = config.getIntProperty("workflow.max.search.size", 5_000);
+        this.maxSearchSize = config.getIntProperty("workflow.max.search.size", 5000);
     }
 
     /**
@@ -316,7 +316,7 @@ public void terminateWorkflow(String workflowId, String reason) {
      * @return instance of {@link SearchResult}
      */
     public SearchResult<WorkflowSummary> searchWorkflows(int start, int size, String sort, String freeText, String query) {
-        ServiceUtils.checkArgument(size < maxSearchSize, String.format("Cannot return more than %d workflows." +
+        ServiceUtils.checkArgument(size <= maxSearchSize, String.format("Cannot return more than %d workflows." +
                 " Please use pagination.", maxSearchSize));
         return executionService.search(query, freeText, start, size, ServiceUtils.convertStringToList(sort));
     }
@@ -332,7 +332,7 @@ public SearchResult<WorkflowSummary> searchWorkflows(int start, int size, String
      * @return instance of {@link SearchResult}
      */
     public SearchResult<WorkflowSummary> searchWorkflows(int start, int size, List<String> sort, String freeText, String query) {
-        ServiceUtils.checkArgument(size < maxSearchSize, String.format("Cannot return more than %d workflows." +
+        ServiceUtils.checkArgument(size <= maxSearchSize, String.format("Cannot return more than %d workflows." +
                 " Please use pagination.", maxSearchSize));
         return executionService.search(query, freeText, start, size, sort);
     }

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/service/TaskServiceImpl.java
Patch:
@@ -101,7 +101,7 @@ public void getTasksInProgress(TaskServicePb.TasksInProgressRequest req, StreamO
     @Override
     public void getPendingTaskForWorkflow(TaskServicePb.PendingTaskRequest req, StreamObserver<TaskServicePb.PendingTaskResponse> response) {
         try {
-            Task t = taskService.getPendingTaskForWorkflow(req.getTaskRefName(), req.getWorkflowId());
+            Task t = taskService.getPendingTaskForWorkflow(req.getWorkflowId(), req.getTaskRefName());
             response.onNext(
                     TaskServicePb.PendingTaskResponse.newBuilder()
                             .setTask(PROTO_MAPPER.toProto(t))

File: common/src/main/java/com/netflix/conductor/common/constraints/TaskInputParamConstraint.java
Patch:
@@ -53,7 +53,8 @@ public boolean isValid(Map<String, Object> inputParameters, ConstraintValidatorC
                 return true;
             }
 
-            MutableBoolean valid = new MutableBoolean(true);
+            MutableBoolean valid = new MutableBoolean();
+            valid.setValue(true);
             inputParameters.forEach((key, inputParam) -> {
                 String paramPath = Objects.toString(inputParam, "");
                 if (inputParam != null && StringUtils.isNotBlank(paramPath)) {

File: core/src/test/java/com/netflix/conductor/validations/WorkflowDefConstraintTest.java
Patch:
@@ -103,7 +103,7 @@ public void testWorkflowTaskInvalidInputParam() {
         when(mockMetadataDao.getTaskDef("work1")).thenReturn(new TaskDef());
         Set<ConstraintViolation<WorkflowDef>> result = validator.validate(workflowDef);
         assertEquals(1, result.size());
-        assertEquals(result.iterator().next().getMessage(), "taskDef: task_1 input parameter: fileLocation value: ${work.input.fileLocation} is not valid");
+        assertEquals(result.iterator().next().getMessage(), "taskReferenceName: work for given task: task_1 input value: fileLocation of input parameter: ${work.input.fileLocation} is not defined in workflow definition.");
     }
 
     @Test
@@ -147,8 +147,8 @@ public void testWorkflowTaskReferenceNameNotUnique() {
 
         result.forEach(e -> validationErrors.add(e.getMessage()));
 
-        assertTrue(validationErrors.contains("taskDef: task_1 input parameter: fileLocation value: ${task_2.input.fileLocation} is not valid"));
-        assertTrue(validationErrors.contains("taskDef: task_2 input parameter: fileLocation value: ${task_2.input.fileLocation} is not valid"));
+        assertTrue(validationErrors.contains("taskReferenceName: task_2 for given task: task_2 input value: fileLocation of input parameter: ${task_2.input.fileLocation} is not defined in workflow definition."));
+        assertTrue(validationErrors.contains("taskReferenceName: task_2 for given task: task_1 input value: fileLocation of input parameter: ${task_2.input.fileLocation} is not defined in workflow definition."));
         assertTrue(validationErrors.contains("taskReferenceName: task_1 should be unique across tasks for a given workflowDefinition: sampleWorkflow"));
     }
 

File: server/src/main/java/com/netflix/conductor/bootstrap/ModulesProvider.java
Patch:
@@ -11,7 +11,7 @@
 import com.netflix.conductor.core.utils.DummyPayloadStorage;
 import com.netflix.conductor.core.utils.S3PayloadStorage;
 import com.netflix.conductor.dao.RedisWorkflowModule;
-import com.netflix.conductor.elasticsearch.es5.ElasticSearchV5Module;
+import com.netflix.conductor.elasticsearch.ElasticSearchModule;
 import com.netflix.conductor.mysql.MySQLWorkflowModule;
 import com.netflix.conductor.server.DynomiteClusterModule;
 import com.netflix.conductor.server.JerseyModule;
@@ -90,7 +90,7 @@ private List<AbstractModule> selectModulesToLoad() {
                 break;
         }
 
-        modules.add(new ElasticSearchV5Module());
+        modules.add(new ElasticSearchModule());
 
         modules.add(new WorkflowExecutorModule());
 

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -212,6 +212,6 @@ default List<AbstractModule> getAdditionalModules() {
 
 
     enum DB {
-        REDIS, DYNOMITE, MEMORY, REDIS_CLUSTER, MYSQL
+        REDIS, DYNOMITE, MEMORY, REDIS_CLUSTER, MYSQL, REDIS_SENTINEL
     }
 }

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractWorkflowServiceTest.java
Patch:
@@ -1858,6 +1858,8 @@ public void testSimpleWorkflowWithAllTaskInOneDomain() {
         assertEquals(2, workflow.getTasks().size());
 
         task = workflowExecutionService.poll("junit_task_1", "task1.junit.worker");
+        assertNull(task);
+        task = workflowExecutionService.poll("junit_task_1", "task1.junit.worker", "domain12");
         assertNotNull(task);
         assertEquals("junit_task_1", task.getTaskType());
 

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/AbstractWorkflowServiceTest.java
Patch:
@@ -1858,6 +1858,8 @@ public void testSimpleWorkflowWithAllTaskInOneDomain() {
         assertEquals(2, workflow.getTasks().size());
 
         task = workflowExecutionService.poll("junit_task_1", "task1.junit.worker");
+        assertNull(task);
+        task = workflowExecutionService.poll("junit_task_1", "task1.junit.worker", "domain12");
         assertNotNull(task);
         assertEquals("junit_task_1", task.getTaskType());
 

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -677,13 +677,12 @@ public Task copy() {
         copy.setTaskDefName(taskDefName);
         copy.setTaskType(taskType);
         copy.setWorkflowInstanceId(workflowInstanceId);
+        copy.setWorkflowType(workflowType);
         copy.setResponseTimeoutSeconds(responseTimeoutSeconds);
         copy.setStatus(status);
         copy.setRetryCount(retryCount);
         copy.setPollCount(pollCount);
         copy.setTaskId(taskId);
-        copy.setReasonForIncompletion(reasonForIncompletion);
-        copy.setWorkerId(workerId);
         copy.setWorkflowTask(workflowTask);
         copy.setDomain(domain);
         copy.setInputMessage(inputMessage);

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -677,13 +677,12 @@ public Task copy() {
         copy.setTaskDefName(taskDefName);
         copy.setTaskType(taskType);
         copy.setWorkflowInstanceId(workflowInstanceId);
+        copy.setWorkflowType(workflowType);
         copy.setResponseTimeoutSeconds(responseTimeoutSeconds);
         copy.setStatus(status);
         copy.setRetryCount(retryCount);
         copy.setPollCount(pollCount);
         copy.setTaskId(taskId);
-        copy.setReasonForIncompletion(reasonForIncompletion);
-        copy.setWorkerId(workerId);
         copy.setWorkflowTask(workflowTask);
         copy.setDomain(domain);
         copy.setInputMessage(inputMessage);

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -102,6 +102,7 @@ public Task getPendingTaskForWorkflow(@PathParam("workflowId") String workflowId
 
 	@POST
 	@ApiOperation("Update a task")
+	@Produces({MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON})
 	public String updateTask(TaskResult taskResult) {
 		return taskService.updateTask(taskResult);
 	}
@@ -224,4 +225,4 @@ public SearchResult<TaskSummary> search(@QueryParam("start") @DefaultValue("0")
 	public ExternalStorageLocation getExternalStorageLocation(@QueryParam("path") String path) {
 		return taskService.getExternalStorageLocation(path);
 	}
-}
\ No newline at end of file
+}

File: grpc/src/main/java/com/netflix/conductor/grpc/AbstractProtoMapper.java
Patch:
@@ -1013,6 +1013,7 @@ public WorkflowDefPb.WorkflowDef toProto(WorkflowDef from) {
         }
         to.setSchemaVersion( from.getSchemaVersion() );
         to.setRestartable( from.isRestartable() );
+        to.setTerminalWorkflowListenerEnabled( from.isTerminalWorkflowListenerEnabled() );
         return to.build();
     }
 
@@ -1031,6 +1032,7 @@ public WorkflowDef fromProto(WorkflowDefPb.WorkflowDef from) {
         to.setFailureWorkflow( from.getFailureWorkflow() );
         to.setSchemaVersion( from.getSchemaVersion() );
         to.setRestartable( from.getRestartable() );
+        to.setTerminalWorkflowListenerEnabled( from.getTerminalWorkflowListenerEnabled() );
         return to;
     }
 

File: server/src/main/java/com/netflix/conductor/bootstrap/ModulesProvider.java
Patch:
@@ -7,7 +7,7 @@
 import com.netflix.conductor.contribs.http.RestClientManager;
 import com.netflix.conductor.contribs.json.JsonJqTransform;
 import com.netflix.conductor.core.config.Configuration;
-import com.netflix.conductor.core.config.SystemPropertiesConfiguration;
+import com.netflix.conductor.core.execution.WorkflowExecutorModule;
 import com.netflix.conductor.core.utils.DummyPayloadStorage;
 import com.netflix.conductor.core.utils.S3PayloadStorage;
 import com.netflix.conductor.dao.RedisWorkflowModule;
@@ -92,6 +92,8 @@ private List<AbstractModule> selectModulesToLoad() {
 
         modules.add(new ElasticSearchV5Module());
 
+        modules.add(new WorkflowExecutorModule());
+
         if (configuration.getJerseyEnabled()) {
             modules.add(new JerseyModule());
             modules.add(new SwaggerModule());

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -244,7 +244,7 @@ public void setCorrelationId(String correlationId) {
 	 */
 	@Deprecated
 	public String getWorkflowType() {
-		return workflowType;
+		return getWorkflowName();
 	}
 
 	/**
@@ -261,7 +261,7 @@ public void setWorkflowType(String workflowType) {
 	 */
 	@Deprecated
 	public int getVersion() {
-		return version;
+		return getWorkflowVersion();
 	}
 
 	/**

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -244,7 +244,7 @@ public void setCorrelationId(String correlationId) {
 	 */
 	@Deprecated
 	public String getWorkflowType() {
-		return workflowType;
+		return getWorkflowName();
 	}
 
 	/**
@@ -261,7 +261,7 @@ public void setWorkflowType(String workflowType) {
 	 */
 	@Deprecated
 	public int getVersion() {
-		return version;
+		return getWorkflowVersion();
 	}
 
 	/**

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -244,7 +244,7 @@ public void setCorrelationId(String correlationId) {
 	 */
 	@Deprecated
 	public String getWorkflowType() {
-		return getWorkflowName();
+		return workflowType;
 	}
 
 	/**
@@ -261,7 +261,7 @@ public void setWorkflowType(String workflowType) {
 	 */
 	@Deprecated
 	public int getVersion() {
-		return getWorkflowVersion();
+		return version;
 	}
 
 	/**

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -244,7 +244,7 @@ public void setCorrelationId(String correlationId) {
 	 */
 	@Deprecated
 	public String getWorkflowType() {
-		return getWorkflowName();
+		return workflowType;
 	}
 
 	/**
@@ -261,7 +261,7 @@ public void setWorkflowType(String workflowType) {
 	 */
 	@Deprecated
 	public int getVersion() {
-		return getWorkflowVersion();
+		return version;
 	}
 
 	/**

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -244,7 +244,7 @@ public void setCorrelationId(String correlationId) {
 	 */
 	@Deprecated
 	public String getWorkflowType() {
-		return workflowType;
+		return getWorkflowName();
 	}
 
 	/**
@@ -261,7 +261,7 @@ public void setWorkflowType(String workflowType) {
 	 */
 	@Deprecated
 	public int getVersion() {
-		return version;
+		return getWorkflowVersion();
 	}
 
 	/**

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -244,7 +244,7 @@ public void setCorrelationId(String correlationId) {
 	 */
 	@Deprecated
 	public String getWorkflowType() {
-		return workflowType;
+		return getWorkflowName();
 	}
 
 	/**
@@ -261,7 +261,7 @@ public void setWorkflowType(String workflowType) {
 	 */
 	@Deprecated
 	public int getVersion() {
-		return version;
+		return getWorkflowVersion();
 	}
 
 	/**

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLMetadataDAOTest.java
Patch:
@@ -190,9 +190,9 @@ public void testEventHandlers() {
         eh.setName(UUID.randomUUID().toString());
         eh.setActive(false);
         EventHandler.Action action = new EventHandler.Action();
-        action.setAction(EventHandler.Action.Type.START_WORKFLOW);
-        action.setStartWorkflow(new EventHandler.StartWorkflow());
-        action.getStartWorkflow().setName("workflow_x");
+        action.setAction(EventHandler.Action.Type.start_workflow);
+        action.setStart_workflow(new EventHandler.StartWorkflow());
+        action.getStart_workflow().setName("workflow_x");
         eh.getActions().add(action);
         eh.setEvent(event1);
 

File: redis-persistence/src/test/java/com/netflix/conductor/dao/dynomite/RedisMetadataDAOTest.java
Patch:
@@ -237,9 +237,9 @@ public void testEventHandlers() {
 		eh.setName(UUID.randomUUID().toString());
 		eh.setActive(false);
 		Action action = new Action();
-		action.setAction(Type.START_WORKFLOW);
-		action.setStartWorkflow(new StartWorkflow());
-		action.getStartWorkflow().setName("workflow_x");
+		action.setAction(Type.start_workflow);
+		action.setStart_workflow(new StartWorkflow());
+		action.getStart_workflow().setName("workflow_x");
 		eh.getActions().add(action);
 		eh.setEvent(event1);
 		

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/TaskType.java
Patch:
@@ -2,9 +2,6 @@
 
 import com.github.vmg.protogen.annotations.ProtoEnum;
 
-import java.util.HashSet;
-import java.util.Set;
-
 @ProtoEnum
 public enum TaskType {
 

File: common/src/main/java/com/netflix/conductor/common/run/TaskSummary.java
Patch:
@@ -86,6 +86,9 @@ public class TaskSummary {
 	@ProtoField(id = 16)
 	private String taskId;
 
+    public TaskSummary() {
+    }
+
 	public TaskSummary(Task task) {
 		
 		SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss'Z'");

File: contribs/src/main/java/com/netflix/conductor/contribs/ContribsModule.java
Patch:
@@ -58,8 +58,8 @@ protected void configure() {
 	@StringMapKey("sqs")
 	@Singleton
 	@Named(EVENT_QUEUE_PROVIDERS_QUALIFIER)
-	public EventQueueProvider getSQSEventQueueProvider(AmazonSQSClient amazonSQSClient) {
-		return new SQSEventQueueProvider(amazonSQSClient);
+	public EventQueueProvider getSQSEventQueueProvider(AmazonSQSClient amazonSQSClient, Configuration config) {
+		return new SQSEventQueueProvider(amazonSQSClient, config);
 	}
 
 

File: core/src/main/java/com/netflix/conductor/core/execution/TerminateWorkflowException.java
Patch:
@@ -44,5 +44,4 @@ public TerminateWorkflowException(String reason, WorkflowStatus workflowStatus,
         this.workflowStatus = workflowStatus;
         this.task = task;
     }
-
 }
\ No newline at end of file

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -29,6 +29,7 @@
 
 import javax.script.ScriptException;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
@@ -83,9 +84,8 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         decisionTask.setWorkflowType(workflowInstance.getWorkflowName());
         decisionTask.setCorrelationId(workflowInstance.getCorrelationId());
         decisionTask.setScheduledTime(System.currentTimeMillis());
-        decisionTask.setEndTime(System.currentTimeMillis());
         decisionTask.getInputData().put("case", caseValue);
-        decisionTask.getOutputData().put("caseOutput", Arrays.asList(caseValue));
+        decisionTask.getOutputData().put("caseOutput", Collections.singletonList(caseValue));
         decisionTask.setTaskId(taskId);
         decisionTask.setStatus(Task.Status.IN_PROGRESS);
         decisionTask.setWorkflowTask(taskToSchedule);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/EventTaskMapper.java
Patch:
@@ -61,7 +61,6 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         eventTask.setWorkflowType(workflowInstance.getWorkflowName());
         eventTask.setCorrelationId(workflowInstance.getCorrelationId());
         eventTask.setScheduledTime(System.currentTimeMillis());
-        eventTask.setEndTime(System.currentTimeMillis());
         eventTask.setInputData(eventTaskInput);
         eventTask.getInputData().put("sink", sink);
         eventTask.setTaskId(taskId);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/JoinTaskMapper.java
Patch:
@@ -65,7 +65,6 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         joinTask.setCorrelationId(workflowInstance.getCorrelationId());
         joinTask.setWorkflowType(workflowInstance.getWorkflowName());
         joinTask.setScheduledTime(System.currentTimeMillis());
-        joinTask.setEndTime(System.currentTimeMillis());
         joinTask.setInputData(joinInput);
         joinTask.setTaskId(taskId);
         joinTask.setStatus(Task.Status.IN_PROGRESS);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SimpleTaskMapper.java
Patch:
@@ -28,7 +28,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.util.Arrays;
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 import java.util.Optional;
@@ -90,6 +90,6 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         simpleTask.setResponseTimeoutSeconds(taskDefinition.getResponseTimeoutSeconds());
         simpleTask.setWorkflowTask(taskToSchedule);
         simpleTask.setRetriedTaskId(retriedTaskId);
-        return Arrays.asList(simpleTask);
+        return Collections.singletonList(simpleTask);
     }
 }

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapper.java
Patch:
@@ -26,6 +26,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
@@ -64,11 +65,10 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         waitTask.setWorkflowType(workflowInstance.getWorkflowName());
         waitTask.setCorrelationId(workflowInstance.getCorrelationId());
         waitTask.setScheduledTime(System.currentTimeMillis());
-        waitTask.setEndTime(System.currentTimeMillis());
         waitTask.setInputData(waitTaskInput);
         waitTask.setTaskId(taskId);
         waitTask.setStatus(Task.Status.IN_PROGRESS);
         waitTask.setWorkflowTask(taskToSchedule);
-        return Arrays.asList(waitTask);
+        return Collections.singletonList(waitTask);
     }
 }

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapperTest.java
Patch:
@@ -19,7 +19,7 @@
 public class WaitTaskMapperTest {
 
     @Test
-    public void getMappedTasks() throws Exception {
+    public void getMappedTasks() {
 
         //Given
         WorkflowTask taskToSchedule = new WorkflowTask();
@@ -49,7 +49,5 @@ public void getMappedTasks() throws Exception {
         //Then
         assertEquals(1, mappedTasks.size());
         assertEquals(Wait.NAME, mappedTasks.get(0).getTaskType());
-
     }
-
 }

File: es5-persistence/src/main/java/com/netflix/conductor/elasticsearch/EmbeddedElasticSearchProvider.java
Patch:
@@ -1,8 +1,7 @@
 package com.netflix.conductor.elasticsearch;
 
-import java.util.Optional;
-
 import javax.inject.Provider;
+import java.util.Optional;
 
 public interface EmbeddedElasticSearchProvider extends Provider<Optional<EmbeddedElasticSearch>> {
 }

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/service/TaskServiceImpl.java
Patch:
@@ -189,7 +189,7 @@ public void getTask(TaskServicePb.GetTaskRequest req, StreamObserver<TaskService
 
     @Override
     public void removeTaskFromQueue(TaskServicePb.RemoveTaskRequest req, StreamObserver<TaskServicePb.RemoveTaskResponse> response) {
-        taskService.removeTaskfromQueue(req.getTaskType(), req.getTaskId());
+        taskService.removeTaskfromQueue(req.getTaskId());
         response.onNext(TaskServicePb.RemoveTaskResponse.getDefaultInstance());
         response.onCompleted();
     }

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/service/WorkflowServiceImpl.java
Patch:
@@ -59,12 +59,14 @@ public void startWorkflow(StartWorkflowRequestPb.StartWorkflowRequest pbRequest,
                         GRPC_HELPER.optional(request.getVersion()),
                         request.getCorrelationId(),
                         request.getInput(),
+                        request.getExternalInputPayloadStoragePath(),
                         null,
                         request.getTaskToDomain());
             } else {
                 id = executor.startWorkflow(
                         request.getWorkflowDef(),
                         request.getInput(),
+                        request.getExternalInputPayloadStoragePath(),
                         request.getCorrelationId(),
                         null,
                         request.getTaskToDomain());

File: common/src/main/java/com/netflix/conductor/common/metadata/events/EventHandler.java
Patch:
@@ -132,7 +132,9 @@ public void setActive(boolean active) {
 	public static class Action {
 
 		@ProtoEnum
-		public enum Type { START_WORKFLOW, COMPLETE_TASK, FAIL_TASK }
+		public enum Type {
+			start_workflow, complete_task, fail_task
+		}
 
 		@ProtoField(id = 1)
 		private Type action;

File: core/src/main/java/com/netflix/conductor/core/events/ActionProcessor.java
Patch:
@@ -68,11 +68,11 @@ public Map<String, Object> execute(Action action, Object payloadObject, String e
 		}
 
 		switch (action.getAction()) {
-			case START_WORKFLOW:
+			case start_workflow:
 				return startWorkflow(action, jsonObject, event, messageId);
-			case COMPLETE_TASK:
+			case complete_task:
 				return completeTask(action, jsonObject, action.getCompleteTask(), Status.COMPLETED, event, messageId);
-			case FAIL_TASK:
+			case fail_task:
 				return completeTask(action, jsonObject, action.getFailTask(), Status.FAILED, event, messageId);
 			default:
 				break;

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLMetadataDAOTest.java
Patch:
@@ -196,7 +196,7 @@ public void testEventHandlers() {
         eh.setName(UUID.randomUUID().toString());
         eh.setActive(false);
         EventHandler.Action action = new EventHandler.Action();
-        action.setAction(EventHandler.Action.Type.START_WORKFLOW);
+        action.setAction(EventHandler.Action.Type.start_workflow);
         action.setStartWorkflow(new EventHandler.StartWorkflow());
         action.getStartWorkflow().setName("workflow_x");
         eh.getActions().add(action);

File: redis-persistence/src/test/java/com/netflix/conductor/dao/dynomite/RedisMetadataDAOTest.java
Patch:
@@ -242,7 +242,7 @@ public void testEventHandlers() {
 		eh.setName(UUID.randomUUID().toString());
 		eh.setActive(false);
 		Action action = new Action();
-		action.setAction(Type.START_WORKFLOW);
+		action.setAction(Type.start_workflow);
 		action.setStartWorkflow(new StartWorkflow());
 		action.getStartWorkflow().setName("workflow_x");
 		eh.getActions().add(action);

File: core/src/main/java/com/netflix/conductor/core/execution/ParametersUtils.java
Patch:
@@ -159,7 +159,7 @@ public Object replace(String paramString) {
     private Map<String, Object> replace(Map<String, Object> input, DocumentContext documentContext, String taskId) {
         for (Entry<String, Object> e : input.entrySet()) {
             Object value = e.getValue();
-            if (value instanceof String || value instanceof Number) {
+            if (value instanceof String) {
                 Object replaced = replaceVariables(value.toString(), documentContext, taskId);
                 e.setValue(replaced);
             } else if (value instanceof Map) {

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskDef.java
Patch:
@@ -74,7 +74,7 @@ public static enum RetryLogic {FIXED, EXPONENTIAL_BACKOFF}
 	private int retryDelaySeconds = 60;
 
 	@ProtoField(id = 10)
-	private int responseTimeoutSeconds = ONE_HOUR;
+	private long responseTimeoutSeconds = ONE_HOUR;
 
 	@ProtoField(id = 11)
 	private Integer concurrentExecLimit;
@@ -236,15 +236,15 @@ public int getRetryDelaySeconds() {
 	 *
 	 * @return the timeout for task to send response.  After this timeout, the task will be re-queued
 	 */
-	public int getResponseTimeoutSeconds() {
+	public long getResponseTimeoutSeconds() {
 		return responseTimeoutSeconds;
 	}
 
 	/**
 	 *
 	 * @param responseTimeoutSeconds - timeout for task to send response.  After this timeout, the task will be re-queued
 	 */
-	public void setResponseTimeoutSeconds(int responseTimeoutSeconds) {
+	public void setResponseTimeoutSeconds(long responseTimeoutSeconds) {
 		this.responseTimeoutSeconds = responseTimeoutSeconds;
 	}
 

File: core/src/main/java/com/netflix/conductor/core/config/CoreModule.java
Patch:
@@ -144,8 +144,8 @@ public TaskMapper getWaitTaskMapper(ParametersUtils parametersUtils) {
     @StringMapKey(TASK_TYPE_SUB_WORKFLOW)
     @Singleton
     @Named(TASK_MAPPERS_QUALIFIER)
-    public TaskMapper getSubWorkflowTaskMapper(ParametersUtils parametersUtils) {
-        return new SubWorkflowTaskMapper(parametersUtils);
+    public TaskMapper getSubWorkflowTaskMapper(ParametersUtils parametersUtils, MetadataDAO metadataDAO) {
+        return new SubWorkflowTaskMapper(parametersUtils, metadataDAO);
     }
 
     @ProvidesIntoMap

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -448,9 +448,9 @@ void checkForTimeout(TaskDef taskDef, Task task) {
             return;
         }
 
-        long timeout = 1000 * taskDef.getTimeoutSeconds();
+        long timeout = 1000L * taskDef.getTimeoutSeconds();
         long now = System.currentTimeMillis();
-        long elapsedTime = now - (task.getStartTime() + (task.getStartDelayInSeconds() * 1000));
+        long elapsedTime = now - (task.getStartTime() + ((long)task.getStartDelayInSeconds() * 1000L));
 
         if (elapsedTime < timeout) {
             return;
@@ -494,7 +494,7 @@ boolean isResponseTimedOut(TaskDef taskDefinition, Task task) {
 
         logger.debug("Evaluating responseTimeOut for Task: {}, with Task Definition: {} ", task, taskDefinition);
 
-        long responseTimeout = 1000 * taskDefinition.getResponseTimeoutSeconds();
+        long responseTimeout = 1000L * taskDefinition.getResponseTimeoutSeconds();
         long now = System.currentTimeMillis();
         long noResponseTime = now - task.getUpdateTime();
 

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -84,7 +84,6 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         decisionTask.setWorkflowType(workflowInstance.getWorkflowName());
         decisionTask.setCorrelationId(workflowInstance.getCorrelationId());
         decisionTask.setScheduledTime(System.currentTimeMillis());
-        decisionTask.setEndTime(System.currentTimeMillis());
         decisionTask.getInputData().put("case", caseValue);
         decisionTask.getOutputData().put("caseOutput", Collections.singletonList(caseValue));
         decisionTask.setTaskId(taskId);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/EventTaskMapper.java
Patch:
@@ -61,7 +61,6 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         eventTask.setWorkflowType(workflowInstance.getWorkflowName());
         eventTask.setCorrelationId(workflowInstance.getCorrelationId());
         eventTask.setScheduledTime(System.currentTimeMillis());
-        eventTask.setEndTime(System.currentTimeMillis());
         eventTask.setInputData(eventTaskInput);
         eventTask.getInputData().put("sink", sink);
         eventTask.setTaskId(taskId);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/JoinTaskMapper.java
Patch:
@@ -65,7 +65,6 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         joinTask.setCorrelationId(workflowInstance.getCorrelationId());
         joinTask.setWorkflowType(workflowInstance.getWorkflowName());
         joinTask.setScheduledTime(System.currentTimeMillis());
-        joinTask.setEndTime(System.currentTimeMillis());
         joinTask.setInputData(joinInput);
         joinTask.setTaskId(taskId);
         joinTask.setStatus(Task.Status.IN_PROGRESS);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapper.java
Patch:
@@ -65,7 +65,6 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         waitTask.setWorkflowType(workflowInstance.getWorkflowName());
         waitTask.setCorrelationId(workflowInstance.getCorrelationId());
         waitTask.setScheduledTime(System.currentTimeMillis());
-        waitTask.setEndTime(System.currentTimeMillis());
         waitTask.setInputData(waitTaskInput);
         waitTask.setTaskId(taskId);
         waitTask.setStatus(Task.Status.IN_PROGRESS);

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -105,7 +105,7 @@ public void init() {
         taskMappers.put("FORK_JOIN_DYNAMIC", new ForkJoinDynamicTaskMapper(parametersUtils, objectMapper, metadataDAO));
         taskMappers.put("USER_DEFINED", new UserDefinedTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("SIMPLE", new SimpleTaskMapper(parametersUtils));
-        taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils));
+        taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
 

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -130,7 +130,7 @@ public void setup() {
         taskMappers.put("FORK_JOIN_DYNAMIC", new ForkJoinDynamicTaskMapper(parametersUtils, objectMapper, metadataDAO));
         taskMappers.put("USER_DEFINED", new UserDefinedTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("SIMPLE", new SimpleTaskMapper(parametersUtils));
-        taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils));
+        taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
 

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -97,7 +97,7 @@ public void init() {
         taskMappers.put("FORK_JOIN_DYNAMIC", new ForkJoinDynamicTaskMapper(parametersUtils, objectMapper, metadataDAO));
         taskMappers.put("USER_DEFINED", new UserDefinedTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("SIMPLE", new SimpleTaskMapper(parametersUtils));
-        taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils));
+        taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
 
@@ -177,7 +177,6 @@ public void start(Workflow workflow, Task task, WorkflowExecutor executor) {
         task2.setWorkflowInstanceId(workflow.getWorkflowId());
         task2.setCorrelationId(workflow.getCorrelationId());
         task2.setScheduledTime(System.currentTimeMillis());
-        task2.setEndTime(System.currentTimeMillis());
         task2.setInputData(new HashMap<>());
         task2.setTaskId(IDGenerator.generate());
         task2.setStatus(Status.IN_PROGRESS);

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAO.java
Patch:
@@ -175,7 +175,7 @@ public void updateTasks(List<Task> tasks) {
 	public void updateTask(Task task) {
 
 		task.setUpdateTime(System.currentTimeMillis());
-		if (task.getStatus() != null && task.getStatus().isTerminal()) {
+		if (task.getStatus() != null && task.getStatus().isTerminal() && task.getEndTime() == 0) {
 			task.setEndTime(System.currentTimeMillis());
 		}
 

File: es5-persistence/src/main/java/com/netflix/conductor/elasticsearch/EmbeddedElasticSearchProvider.java
Patch:
@@ -1,8 +1,7 @@
 package com.netflix.conductor.elasticsearch;
 
-import java.util.Optional;
-
 import javax.inject.Provider;
+import java.util.Optional;
 
 public interface EmbeddedElasticSearchProvider extends Provider<Optional<EmbeddedElasticSearch>> {
 }

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/Query.java
Patch:
@@ -237,7 +237,7 @@ public boolean exists() {
     public boolean executeDelete() {
         int count = executeUpdate();
         if (count > 1) {
-            logger.debug("Removed {} row(s) for query {}", count, rawQuery);
+            logger.trace("Removed {} row(s) for query {}", count, rawQuery);
         }
 
         return count > 0;

File: mysql-persistence/src/main/java/com/netflix/conductor/mysql/MySQLConfiguration.java
Patch:
@@ -1,7 +1,6 @@
 package com.netflix.conductor.mysql;
 
 import com.netflix.conductor.core.config.Configuration;
-import com.zaxxer.hikari.HikariConfig;
 
 import java.util.Optional;
 import java.util.concurrent.TimeUnit;

File: redis-persistence/src/main/java/com/netflix/conductor/jedis/InMemoryJedisProvider.java
Patch:
@@ -1,10 +1,10 @@
 package com.netflix.conductor.jedis;
 
+import redis.clients.jedis.JedisCommands;
+
 import javax.inject.Provider;
 import javax.inject.Singleton;
 
-import redis.clients.jedis.JedisCommands;
-
 @Singleton
 public class InMemoryJedisProvider implements Provider<JedisCommands> {
     private final JedisCommands mock = new JedisMock();

File: server/src/main/java/com/netflix/conductor/bootstrap/BootstrapModule.java
Patch:
@@ -1,8 +1,6 @@
 package com.netflix.conductor.bootstrap;
 
 import com.google.inject.AbstractModule;
-
-import com.netflix.conductor.common.utils.JsonMapperProvider;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.SystemPropertiesConfiguration;
 

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/End2EndTests.java
Patch:
@@ -57,6 +57,7 @@
 /**
  * @author Viren
  */
+
 public class End2EndTests extends AbstractEndToEndTest {
 
     private static TaskClient taskClient;

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowServiceTest.java
Patch:
@@ -17,7 +17,6 @@
 
 import com.netflix.conductor.tests.utils.TestRunner;
 import org.junit.runner.RunWith;
-
 import java.util.Map;
 
 @RunWith(TestRunner.class)

File: common/src/main/java/com/netflix/conductor/common/run/TaskSummary.java
Patch:
@@ -86,6 +86,9 @@ public class TaskSummary {
 	@ProtoField(id = 16)
 	private String taskId;
 
+    public TaskSummary() {
+    }
+
 	public TaskSummary(Task task) {
 		
 		SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss'Z'");

File: common/src/main/java/com/netflix/conductor/common/run/TaskSummary.java
Patch:
@@ -86,6 +86,9 @@ public class TaskSummary {
 	@ProtoField(id = 16)
 	private String taskId;
 
+    public TaskSummary() {
+    }
+
 	public TaskSummary(Task task) {
 		
 		SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss'Z'");

File: client/src/main/java/com/netflix/conductor/client/http/WorkflowClient.java
Patch:
@@ -247,7 +247,7 @@ public List<Workflow> getWorkflows(String name, String correlationId, boolean in
      */
     private void populateWorkflowOutput(Workflow workflow) {
         if (StringUtils.isNotBlank(workflow.getExternalOutputPayloadStoragePath())) {
-            WorkflowTaskMetrics.incrementExternalPayloadUsedCount(workflow.getWorkflowType(), ExternalPayloadStorage.Operation.READ.name(), ExternalPayloadStorage.PayloadType.WORKFLOW_OUTPUT.name());
+            WorkflowTaskMetrics.incrementExternalPayloadUsedCount(workflow.getWorkflowName(), ExternalPayloadStorage.Operation.READ.name(), ExternalPayloadStorage.PayloadType.WORKFLOW_OUTPUT.name());
             workflow.setOutput(downloadFromExternalStorage(ExternalPayloadStorage.PayloadType.WORKFLOW_OUTPUT, workflow.getExternalOutputPayloadStoragePath()));
         }
     }

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -415,7 +415,7 @@ Workflow populateWorkflowAndTaskData(Workflow workflow) {
         if (StringUtils.isNotBlank(workflow.getExternalInputPayloadStoragePath())) {
             // download the workflow input from external storage here and plug it into the workflow
             Map<String, Object> workflowInputParams = externalPayloadStorageUtils.downloadPayload(workflow.getExternalInputPayloadStoragePath());
-            Monitors.recordExternalPayloadStorageUsage(workflow.getWorkflowType(), ExternalPayloadStorage.Operation.READ.toString(), ExternalPayloadStorage.PayloadType.WORKFLOW_INPUT.toString());
+            Monitors.recordExternalPayloadStorageUsage(workflow.getWorkflowName(), ExternalPayloadStorage.Operation.READ.toString(), ExternalPayloadStorage.PayloadType.WORKFLOW_INPUT.toString());
             workflowInstance.setInput(workflowInputParams);
             workflowInstance.setExternalInputPayloadStoragePath(null);
         }

File: core/src/main/java/com/netflix/conductor/core/execution/ParametersUtils.java
Patch:
@@ -84,8 +84,8 @@ public Map<String, Object> getTaskInputV2(Map<String, Object> input, Workflow wo
         workflowParams.put("workflowId", workflow.getWorkflowId());
         workflowParams.put("parentWorkflowId", workflow.getParentWorkflowId());
         workflowParams.put("parentWorkflowTaskId", workflow.getParentWorkflowTaskId());
-        workflowParams.put("workflowType", workflow.getWorkflowType());
-        workflowParams.put("version", workflow.getVersion());
+        workflowParams.put("workflowType", workflow.getWorkflowName());
+        workflowParams.put("version", workflow.getWorkflowVersion());
         workflowParams.put("correlationId", workflow.getCorrelationId());
         workflowParams.put("reasonForIncompletion", workflow.getReasonForIncompletion());
         workflowParams.put("schemaVersion", workflow.getSchemaVersion());

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowLegacyMigrationTest.java
Patch:
@@ -71,7 +71,7 @@ public String startOrLoadWorkflowExecution(String snapshotResourceName, String w
         workflow.setTaskToDomain(taskToDomain);
         workflow.setVersion(version);
 
-        workflow.getTasks().stream().forEach(task -> {
+        workflow.getTasks().forEach(task -> {
             task.setTaskId(IDGenerator.generate());
             task.setWorkflowInstanceId(workflowId);
             task.setCorrelationId(correlationId);
@@ -85,7 +85,7 @@ public String startOrLoadWorkflowExecution(String snapshotResourceName, String w
          * in order to represent a workflow on the system, we need to populate the
          * respective queues related to tasks in progress or decisions.
          */
-        workflow.getTasks().stream().forEach(task -> {
+        workflow.getTasks().forEach(task -> {
             workflowExecutor.addTaskToQueue(task);
             queueDAO.push(WorkflowExecutor.DECIDER_QUEUE, workflowId, configuration.getSweepFrequency());
         });

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowServiceTest.java
Patch:
@@ -30,5 +30,4 @@ public class WorkflowServiceTest extends AbstractWorkflowServiceTest {
     String startOrLoadWorkflowExecution(String snapshotResourceName, String workflowName, int version, String correlationId, Map<String, Object> input, String event, Map<String, String> taskToDomain) {
         return workflowExecutor.startWorkflow(workflowName, version, correlationId, input, null, event, taskToDomain);
     }
-
 }

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/TestModule.java
Patch:
@@ -22,7 +22,6 @@
 import com.netflix.conductor.common.utils.JsonMapperProvider;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.CoreModule;
-import com.netflix.conductor.core.config.SystemPropertiesConfiguration;
 import com.netflix.conductor.dao.ExecutionDAO;
 import com.netflix.conductor.dao.IndexDAO;
 import com.netflix.conductor.dao.MetadataDAO;
@@ -59,7 +58,7 @@ protected void configure() {
 
         configureExecutorService();
 
-        SystemPropertiesConfiguration config = new SystemPropertiesConfiguration();
+        MockConfiguration config = new MockConfiguration();
         bind(Configuration.class).toInstance(config);
         JedisCommands jedisMock = new JedisMock();
 

File: client/src/main/java/com/netflix/conductor/client/http/WorkflowClient.java
Patch:
@@ -247,7 +247,7 @@ public List<Workflow> getWorkflows(String name, String correlationId, boolean in
      */
     private void populateWorkflowOutput(Workflow workflow) {
         if (StringUtils.isNotBlank(workflow.getExternalOutputPayloadStoragePath())) {
-            WorkflowTaskMetrics.incrementExternalPayloadUsedCount(workflow.getWorkflowType(), ExternalPayloadStorage.Operation.READ.name(), ExternalPayloadStorage.PayloadType.WORKFLOW_OUTPUT.name());
+            WorkflowTaskMetrics.incrementExternalPayloadUsedCount(workflow.getWorkflowName(), ExternalPayloadStorage.Operation.READ.name(), ExternalPayloadStorage.PayloadType.WORKFLOW_OUTPUT.name());
             workflow.setOutput(downloadFromExternalStorage(ExternalPayloadStorage.PayloadType.WORKFLOW_OUTPUT, workflow.getExternalOutputPayloadStoragePath()));
         }
     }

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -415,7 +415,7 @@ Workflow populateWorkflowAndTaskData(Workflow workflow) {
         if (StringUtils.isNotBlank(workflow.getExternalInputPayloadStoragePath())) {
             // download the workflow input from external storage here and plug it into the workflow
             Map<String, Object> workflowInputParams = externalPayloadStorageUtils.downloadPayload(workflow.getExternalInputPayloadStoragePath());
-            Monitors.recordExternalPayloadStorageUsage(workflow.getWorkflowType(), ExternalPayloadStorage.Operation.READ.toString(), ExternalPayloadStorage.PayloadType.WORKFLOW_INPUT.toString());
+            Monitors.recordExternalPayloadStorageUsage(workflow.getWorkflowName(), ExternalPayloadStorage.Operation.READ.toString(), ExternalPayloadStorage.PayloadType.WORKFLOW_INPUT.toString());
             workflowInstance.setInput(workflowInputParams);
             workflowInstance.setExternalInputPayloadStoragePath(null);
         }

File: core/src/main/java/com/netflix/conductor/core/execution/ParametersUtils.java
Patch:
@@ -84,8 +84,8 @@ public Map<String, Object> getTaskInputV2(Map<String, Object> input, Workflow wo
         workflowParams.put("workflowId", workflow.getWorkflowId());
         workflowParams.put("parentWorkflowId", workflow.getParentWorkflowId());
         workflowParams.put("parentWorkflowTaskId", workflow.getParentWorkflowTaskId());
-        workflowParams.put("workflowType", workflow.getWorkflowType());
-        workflowParams.put("version", workflow.getVersion());
+        workflowParams.put("workflowType", workflow.getWorkflowName());
+        workflowParams.put("version", workflow.getWorkflowVersion());
         workflowParams.put("correlationId", workflow.getCorrelationId());
         workflowParams.put("reasonForIncompletion", workflow.getReasonForIncompletion());
         workflowParams.put("schemaVersion", workflow.getSchemaVersion());

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowLegacyMigrationTest.java
Patch:
@@ -71,7 +71,7 @@ public String startOrLoadWorkflowExecution(String snapshotResourceName, String w
         workflow.setTaskToDomain(taskToDomain);
         workflow.setVersion(version);
 
-        workflow.getTasks().stream().forEach(task -> {
+        workflow.getTasks().forEach(task -> {
             task.setTaskId(IDGenerator.generate());
             task.setWorkflowInstanceId(workflowId);
             task.setCorrelationId(correlationId);
@@ -85,7 +85,7 @@ public String startOrLoadWorkflowExecution(String snapshotResourceName, String w
          * in order to represent a workflow on the system, we need to populate the
          * respective queues related to tasks in progress or decisions.
          */
-        workflow.getTasks().stream().forEach(task -> {
+        workflow.getTasks().forEach(task -> {
             workflowExecutor.addTaskToQueue(task);
             queueDAO.push(WorkflowExecutor.DECIDER_QUEUE, workflowId, configuration.getSweepFrequency());
         });

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowServiceTest.java
Patch:
@@ -30,5 +30,4 @@ public class WorkflowServiceTest extends AbstractWorkflowServiceTest {
     String startOrLoadWorkflowExecution(String snapshotResourceName, String workflowName, int version, String correlationId, Map<String, Object> input, String event, Map<String, String> taskToDomain) {
         return workflowExecutor.startWorkflow(workflowName, version, correlationId, input, null, event, taskToDomain);
     }
-
 }

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/TestModule.java
Patch:
@@ -22,7 +22,6 @@
 import com.netflix.conductor.common.utils.JsonMapperProvider;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.CoreModule;
-import com.netflix.conductor.core.config.SystemPropertiesConfiguration;
 import com.netflix.conductor.dao.ExecutionDAO;
 import com.netflix.conductor.dao.IndexDAO;
 import com.netflix.conductor.dao.MetadataDAO;
@@ -59,7 +58,7 @@ protected void configure() {
 
         configureExecutorService();
 
-        SystemPropertiesConfiguration config = new SystemPropertiesConfiguration();
+        MockConfiguration config = new MockConfiguration();
         bind(Configuration.class).toInstance(config);
         JedisCommands jedisMock = new JedisMock();
 

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SubWorkflow.java
Patch:
@@ -88,6 +88,7 @@ public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider)
 		if (subWorkflowStatus.isSuccessful()) {
 			task.setStatus(Status.COMPLETED);
 		} else {
+			task.setReasonForIncompletion(subWorkflow.getReasonForIncompletion());
 			task.setStatus(Status.FAILED);
 		}
 		return true;

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAO.java
Patch:
@@ -10,6 +10,7 @@
 import java.util.stream.Collectors;
 
 import javax.inject.Inject;
+import javax.inject.Singleton;
 import javax.sql.DataSource;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
@@ -29,6 +30,7 @@
 import com.netflix.conductor.dao.MetadataDAO;
 import com.netflix.conductor.metrics.Monitors;
 
+@Singleton
 public class MySQLExecutionDAO extends MySQLBaseDAO implements ExecutionDAO {
 
     private static final String ARCHIVED_FIELD = "archived";

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLWorkflowModule.java
Patch:
@@ -32,7 +32,7 @@ public DataSource getDataSource(Configuration config) {
         
         dataSource.setMaximumPoolSize(config.getIntProperty("jdbc.maxPoolSize", 20));
         dataSource.setMinimumIdle(config.getIntProperty("jdbc.minIdleSize", 5));
-        dataSource.setIdleTimeout(config.getIntProperty("jdbc.idleTimeout", 1000*300));
+        dataSource.setIdleTimeout(config.getIntProperty("jdbc.idleTimeout", 300_000));
         dataSource.setTransactionIsolation(config.getProperty("jdbc.isolationLevel", "TRANSACTION_REPEATABLE_READ"));
         
         flywayMigrate(config, dataSource);

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/Query.java
Patch:
@@ -235,7 +235,7 @@ public boolean exists() {
     public boolean executeDelete() {
         int count = executeUpdate();
         if (count > 1) {
-            logger.debug("Removed {} row(s) for query {}", count, rawQuery);
+            logger.trace("Removed {} row(s) for query {}", count, rawQuery);
         }
 
         return count > 0;

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -652,7 +652,7 @@ public void pauseWorkflow(String workflowId) {
     public void resumeWorkflow(String workflowId) {
         Workflow workflow = executionDAO.getWorkflow(workflowId, false);
         if (!workflow.getStatus().equals(WorkflowStatus.PAUSED)) {
-            throw new IllegalStateException("The workflow " + workflowId + " is PAUSED so cannot resume");
+            throw new IllegalStateException("The workflow " + workflowId + " is not PAUSED so cannot resume");
         }
         workflow.setStatus(WorkflowStatus.RUNNING);
         executionDAO.updateWorkflow(workflow);

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -107,7 +107,7 @@ public Task getPendingTaskForWorkflow(@PathParam("workflowId") String workflowId
 
 	@POST
 	@ApiOperation("Update a task")
-    @Produces({MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON})
+	@Produces({MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON})
 	public String updateTask(TaskResult taskResult) {
 		return taskService.updateTask(taskResult);
 	}

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLMetadataDAO.java
Patch:
@@ -263,6 +263,7 @@ public List<EventHandler> getEventHandlersForEvent(String event, boolean activeO
     private void validate(TaskDef taskDef) {
         Preconditions.checkNotNull(taskDef, "TaskDef object cannot be null");
         Preconditions.checkNotNull(taskDef.getName(), "TaskDef name cannot be null");
+        Preconditions.checkNotNull(taskDef.getResponseTimeoutSeconds(), "ResponseTimeoutSeconds cannot be null");
     }
 
     /**

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisMetadataDAO.java
Patch:
@@ -83,6 +83,7 @@ private String insertOrUpdateTaskDef(TaskDef taskDef) {
 
         Preconditions.checkNotNull(taskDef, "TaskDef object cannot be null");
         Preconditions.checkNotNull(taskDef.getName(), "TaskDef name cannot be null");
+        Preconditions.checkNotNull(taskDef.getResponseTimeoutSeconds(), "ResponseTimeoutSeconds cannot be null");
 
         // Store all task def in under one key
         String payload = toJson(taskDef);

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLPushPopQueueDAOTest.java
Patch:
@@ -28,7 +28,7 @@ public void setup() throws Exception {
         resetAllData();
     }
 
-    @Test
+    @Test(expected =  java.util.concurrent.ExecutionException.class)
     public void testWith2THreads() throws Exception {
         testPollDataWithParallelThreads(2);
     }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SubWorkflow.java
Patch:
@@ -88,6 +88,7 @@ public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider)
 		if (subWorkflowStatus.isSuccessful()) {
 			task.setStatus(Status.COMPLETED);
 		} else {
+			task.setReasonForIncompletion(subWorkflow.getReasonForIncompletion());
 			task.setStatus(Status.FAILED);
 		}
 		return true;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -117,6 +117,7 @@ public void setTasks(List<WorkflowTask> tasks) {
 	@ProtoField(id = 19)
 	private TaskDef taskDefinition;
 
+	@ProtoField(id = 20)
 	private Boolean rateLimited;
 
 	/**

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -117,6 +117,7 @@ public void setTasks(List<WorkflowTask> tasks) {
 	@ProtoField(id = 19)
 	private TaskDef taskDefinition;
 
+	@ProtoField(id = 20)
 	private Boolean rateLimited;
 
 	/**

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -299,15 +299,15 @@ public void retry(String workflowId) {
 
     /**
      * Get all failed and cancelled tasks.
-     * for failed tasks - get one of each task definition(latest failed using seq id)
+     * for failed tasks - get one for each task reference name(latest failed using seq id)
      * @param workflow
-     * @return list of latest failed tasks, one of each type.
+     * @return list of latest failed tasks, one for each task reference reference type.
      */
     @VisibleForTesting
     List<Task> getFailedTasksToRetry(Workflow workflow) {
         return workflow.getTasks().stream()
                 .filter(x -> FAILED.equals(x.getStatus()))
-                .collect(groupingBy(Task::getTaskDefName, maxBy(comparingInt(Task::getSeq))))
+                .collect(groupingBy(Task::getReferenceTaskName, maxBy(comparingInt(Task::getSeq))))
                 .values().stream().filter(Optional::isPresent).map(Optional::get).collect(Collectors.toList());
     }
 

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLDAOTestUtil.java
Patch:
@@ -22,7 +22,7 @@
 @SuppressWarnings("Duplicates")
 public class MySQLDAOTestUtil {
     private static final Logger logger = LoggerFactory.getLogger(MySQLDAOTestUtil.class);
-    private final DataSource dataSource;
+    private final HikariDataSource dataSource;
     private final TestConfiguration testConfiguration = new TestConfiguration();
     private final ObjectMapper objectMapper = new JsonMapperProvider().get();
 
@@ -38,7 +38,7 @@ public class MySQLDAOTestUtil {
         this.dataSource = getDataSource(testConfiguration);
     }
 
-    private DataSource getDataSource(Configuration config) {
+    private HikariDataSource getDataSource(Configuration config) {
 
         HikariDataSource dataSource = new HikariDataSource();
         dataSource.setJdbcUrl(config.getProperty("jdbc.url", "jdbc:mysql://localhost:33307/conductor"));
@@ -70,7 +70,7 @@ private synchronized static void flywayMigrate(DataSource dataSource) {
         }
     }
 
-    public DataSource getDataSource() {
+    public HikariDataSource getDataSource() {
         return dataSource;
     }
 

File: core/src/main/java/com/netflix/conductor/service/TaskService.java
Patch:
@@ -127,7 +127,7 @@ public Task getPendingTaskForWorkflow(String workflowId, String taskReferenceNam
      */
     public String updateTask(TaskResult taskResult) {
         ServiceUtils.checkNotNull(taskResult, "TaskResult cannot be null or empty.");
-        ServiceUtils.checkNotNullOrEmpty(taskResult.getWorkerId(), "Task workerId cannot be null or empty");
+        ServiceUtils.checkNotNullOrEmpty(taskResult.getWorkflowInstanceId(), "Workflow Id cannot be null or empty");
         ServiceUtils.checkNotNullOrEmpty(taskResult.getTaskId(), "Task ID cannot be null or empty");
         logger.debug("Update Task: {} with callback time: {}", taskResult, taskResult.getCallbackAfterSeconds());
         executionService.updateTask(taskResult);

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/End2EndTests.java
Patch:
@@ -314,7 +314,7 @@ public void testUpdateTask() {
         } catch (ConductorClientException e){
             int statuCode = e.getStatus();
             assertEquals(400, statuCode);
-            assertEquals("Task workerId cannot be null or empty", e.getMessage());
+            assertEquals("Workflow Id cannot be null or empty", e.getMessage());
             assertFalse(e.isRetryable());
         }
     }

File: contribs/src/test/java/com/netflix/conductor/contribs/http/TestHttpTask.java
Patch:
@@ -43,6 +43,7 @@
 import com.netflix.conductor.core.execution.mapper.UserDefinedTaskMapper;
 import com.netflix.conductor.core.execution.mapper.WaitTaskMapper;
 import com.netflix.conductor.dao.MetadataDAO;
+import com.netflix.conductor.dao.QueueDAO;
 import org.eclipse.jetty.server.Request;
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.server.handler.AbstractHandler;
@@ -295,6 +296,7 @@ public void testOptional() throws Exception {
  		wft.setTaskReferenceName("t1");
 		def.getTasks().add(wft);
  		MetadataDAO metadataDAO = mock(MetadataDAO.class);
+		QueueDAO queueDAO = mock(QueueDAO.class);
 		ParametersUtils parametersUtils = new ParametersUtils();
 		Map<String, TaskMapper> taskMappers = new HashMap<>();
 		taskMappers.put("DECISION", new DecisionTaskMapper());
@@ -307,7 +309,7 @@ public void testOptional() throws Exception {
 		taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils, metadataDAO));
 		taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
 		taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
- 		new DeciderService(metadataDAO, taskMappers).decide(workflow, def);
+ 		new DeciderService(metadataDAO, queueDAO, taskMappers).decide(workflow, def);
  		
  		System.out.println(workflow.getTasks());
  		System.out.println(workflow.getStatus());

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -44,8 +44,8 @@
 import com.netflix.conductor.core.execution.mapper.TaskMapper;
 import com.netflix.conductor.core.execution.mapper.UserDefinedTaskMapper;
 import com.netflix.conductor.core.execution.mapper.WaitTaskMapper;
-import com.netflix.conductor.dao.ExecutionDAO;
 import com.netflix.conductor.dao.MetadataDAO;
+import com.netflix.conductor.dao.QueueDAO;
 import com.netflix.spectator.api.Counter;
 import com.netflix.spectator.api.DefaultRegistry;
 import com.netflix.spectator.api.Registry;
@@ -113,6 +113,7 @@ public static void init() {
     @Before
     public void setup() {
         MetadataDAO metadataDAO = mock(MetadataDAO.class);
+        QueueDAO queueDAO = mock(QueueDAO.class);
         TaskDef taskDef = new TaskDef();
         WorkflowDef workflowDef = new WorkflowDef();
         when(metadataDAO.getTaskDef(any())).thenReturn(taskDef);
@@ -130,7 +131,7 @@ public void setup() {
         taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
 
-        deciderService = new DeciderService(metadataDAO, taskMappers);
+        deciderService = new DeciderService(metadataDAO, queueDAO, taskMappers);
 
         workflow = new Workflow();
         workflow.getInput().put("requestId", "request id 001");

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -91,7 +91,7 @@ public void init() {
         taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
-        DeciderService deciderService = new DeciderService(metadataDAO, taskMappers);
+        DeciderService deciderService = new DeciderService(metadataDAO, queueDAO, taskMappers);
         workflowExecutor = new WorkflowExecutor(deciderService, metadataDAO, executionDAO, queueDAO, config);
     }
 

File: contribs/src/test/java/com/netflix/conductor/contribs/http/TestHttpTask.java
Patch:
@@ -43,6 +43,7 @@
 import com.netflix.conductor.core.execution.mapper.UserDefinedTaskMapper;
 import com.netflix.conductor.core.execution.mapper.WaitTaskMapper;
 import com.netflix.conductor.dao.MetadataDAO;
+import com.netflix.conductor.dao.QueueDAO;
 import org.eclipse.jetty.server.Request;
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.server.handler.AbstractHandler;
@@ -295,6 +296,7 @@ public void testOptional() throws Exception {
  		wft.setTaskReferenceName("t1");
 		def.getTasks().add(wft);
  		MetadataDAO metadataDAO = mock(MetadataDAO.class);
+		QueueDAO queueDAO = mock(QueueDAO.class);
 		ParametersUtils parametersUtils = new ParametersUtils();
 		Map<String, TaskMapper> taskMappers = new HashMap<>();
 		taskMappers.put("DECISION", new DecisionTaskMapper());
@@ -307,7 +309,7 @@ public void testOptional() throws Exception {
 		taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils, metadataDAO));
 		taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
 		taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
- 		new DeciderService(metadataDAO, taskMappers).decide(workflow, def);
+ 		new DeciderService(metadataDAO, queueDAO, taskMappers).decide(workflow, def);
  		
  		System.out.println(workflow.getTasks());
  		System.out.println(workflow.getStatus());

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderService.java
Patch:
@@ -44,8 +44,8 @@
 import com.netflix.conductor.core.execution.mapper.TaskMapper;
 import com.netflix.conductor.core.execution.mapper.UserDefinedTaskMapper;
 import com.netflix.conductor.core.execution.mapper.WaitTaskMapper;
-import com.netflix.conductor.dao.ExecutionDAO;
 import com.netflix.conductor.dao.MetadataDAO;
+import com.netflix.conductor.dao.QueueDAO;
 import com.netflix.spectator.api.Counter;
 import com.netflix.spectator.api.DefaultRegistry;
 import com.netflix.spectator.api.Registry;
@@ -113,6 +113,7 @@ public static void init() {
     @Before
     public void setup() {
         MetadataDAO metadataDAO = mock(MetadataDAO.class);
+        QueueDAO queueDAO = mock(QueueDAO.class);
         TaskDef taskDef = new TaskDef();
         WorkflowDef workflowDef = new WorkflowDef();
         when(metadataDAO.getTaskDef(any())).thenReturn(taskDef);
@@ -130,7 +131,7 @@ public void setup() {
         taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
 
-        deciderService = new DeciderService(metadataDAO, taskMappers);
+        deciderService = new DeciderService(metadataDAO, queueDAO, taskMappers);
 
         workflow = new Workflow();
         workflow.getInput().put("requestId", "request id 001");

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -91,7 +91,7 @@ public void init() {
         taskMappers.put("SUB_WORKFLOW", new SubWorkflowTaskMapper(parametersUtils, metadataDAO));
         taskMappers.put("EVENT", new EventTaskMapper(parametersUtils));
         taskMappers.put("WAIT", new WaitTaskMapper(parametersUtils));
-        DeciderService deciderService = new DeciderService(metadataDAO, taskMappers);
+        DeciderService deciderService = new DeciderService(metadataDAO, queueDAO, taskMappers);
         workflowExecutor = new WorkflowExecutor(deciderService, metadataDAO, executionDAO, queueDAO, config);
     }
 

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -97,7 +97,7 @@ public List<Workflow> getWorkflows(@PathParam("name") String name,
     @POST
     @Path("/{name}/correlated")
     @ApiOperation("Lists workflows for the given correlation id list")
-    @Consumes(MediaType.WILDCARD)
+    @Consumes(MediaType.APPLICATION_JSON)
     public Map<String, List<Workflow>> getWorkflows(@PathParam("name") String name,
                                                     @QueryParam("includeClosed") @DefaultValue("false") boolean includeClosed,
                                                     @QueryParam("includeTasks") @DefaultValue("false") boolean includeTasks,

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -97,7 +97,7 @@ public List<Workflow> getWorkflows(@PathParam("name") String name,
     @POST
     @Path("/{name}/correlated")
     @ApiOperation("Lists workflows for the given correlation id list")
-    @Consumes(MediaType.WILDCARD)
+    @Consumes(MediaType.APPLICATION_JSON)
     public Map<String, List<Workflow>> getWorkflows(@PathParam("name") String name,
                                                     @QueryParam("includeClosed") @DefaultValue("false") boolean includeClosed,
                                                     @QueryParam("includeTasks") @DefaultValue("false") boolean includeTasks,

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -613,8 +613,7 @@ public void setOutputMessage(Any outputMessage) {
      */
     public Optional<TaskDef> getTaskDefinition() {
         return Optional.ofNullable(this.getWorkflowTask())
-                .map(workflowTask -> Optional.ofNullable(workflowTask.getTaskDefinition()))
-                .orElse(Optional.empty());
+                .map(workflowTask -> workflowTask.getTaskDefinition());
     }
 
     public Task copy() {

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/UserDefinedTaskMapper.java
Patch:
@@ -88,7 +88,8 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         userDefinedTask.setRetryCount(retryCount);
         userDefinedTask.setCallbackAfterSeconds(taskToSchedule.getStartDelay());
         userDefinedTask.setWorkflowTask(taskToSchedule);
-        userDefinedTask.setRateLimitPerSecond(taskDefinition.getRateLimitPerSecond());
+        userDefinedTask.setRateLimitPerFrequency(taskDefinition.getRateLimitPerFrequency());
+        userDefinedTask.setRateLimitFrequencyInSeconds(taskDefinition.getRateLimitFrequencyInSeconds());
         return Collections.singletonList(userDefinedTask);
     }
 

File: client/src/test/java/com/netflix/conductor/client/http/MetadataClientTest.java
Patch:
@@ -25,16 +25,14 @@
  *
  */
 public class MetadataClientTest {
-
-    //private Client jerseyClient;
+    
     private MetadataClient metadataClient;
 
     @Rule
     public ExpectedException expectedException = ExpectedException.none();
 
     @Before
     public void before() {
-        //this.jerseyClient = Mockito.mock(Client.class);
         this.metadataClient = new MetadataClient();
     }
 

File: jersey/src/main/java/com/netflix/conductor/server/resources/ApplicationExceptionMapper.java
Patch:
@@ -100,8 +100,8 @@ Request getRequest() {
 	}
 
 	private void logException(ApplicationException exception) {
-		logger.error(String.format("%s message= '%s' url= '%s'", exception.getClass().getSimpleName(),
-				exception.getMessage(), getUriInfo().getPath()));
+		logger.error(String.format("Error %s url: '%s'", exception.getClass().getSimpleName(),
+				getUriInfo().getPath()), exception);
 	}
 	
 }

File: jersey/src/main/java/com/netflix/conductor/server/resources/GenericExceptionMapper.java
Patch:
@@ -65,8 +65,7 @@ public GenericExceptionMapper(Configuration config) {
 	
 	@Override
 	public Response toResponse(Throwable exception) {
-		logger.error(String.format("%s message= '%s' url= '%s'", exception.getClass().getSimpleName(),
-				exception.getMessage(), uriInfo.getPath()));
+		logger.error(String.format("Error %s url: '%s'", exception.getClass().getSimpleName(), uriInfo.getPath()), exception);
 		Monitors.error("error", "error");
 
 		ApplicationException applicationException = null;

File: jersey/src/main/java/com/netflix/conductor/server/resources/WebAppExceptionMapper.java
Patch:
@@ -57,7 +57,7 @@ public Response toResponse(WebApplicationException exception) {
         entityMap.put("instance", host);
         entityMap.put("code", code.toString());
         entityMap.put("message", exception.getCause());
-        entityMap.put("isRetryable", false);
+        entityMap.put("retryable", false);
 
         return Response.status(response.getStatus()).entity(entityMap).build();
 	}

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -206,7 +206,6 @@ public Task getPendingTaskForWorkflow(String taskReferenceName, String workflowI
 	 * This method removes the task from the un-acked Queue
 	 *
 	 * @param taskId: the taskId that needs to be updated and removed from the unacked queue
-	 * @throws Exception In case of an error while getting the Task from the executionDao
 	 * @return True in case of successful removal of the taskId from the un-acked queue
 	 */
 	public boolean ackTaskReceived(String taskId) {

File: core/src/main/java/com/netflix/conductor/service/TaskService.java
Patch:
@@ -85,7 +85,6 @@ public Task poll(String taskType, String workerId, String domain) {
      * @param count Number of tasks
      * @param timeout Timeout for polling in milliseconds
      * @return list of {@link Task}
-     * @throws Exception
      */
     public List<Task> batchPoll(String taskType, String workerId, String domain, Integer count, Integer timeout) {
         ServiceUtils.checkNotNullOrEmpty(taskType, "TaskType cannot be null or empty.");
@@ -140,7 +139,7 @@ public String updateTask(TaskResult taskResult) {
      * @param workerId Id of the worker
      * @return `true|false` if task if received or not
      */
-    public String ackTaskReceived(String taskId, String workerId) throws Exception {
+    public String ackTaskReceived(String taskId, String workerId) {
         ServiceUtils.checkNotNullOrEmpty(taskId, "TaskId cannot be null or empty.");
         logger.debug("Ack received for task: {} from worker: {}", taskId, workerId);
         return String.valueOf(executionService.ackTaskReceived(taskId));
@@ -244,7 +243,6 @@ public String requeue() {
      * Requeue pending tasks.
      * @param taskType Task name.
      * @return number of tasks requeued.
-     * @throws Exception
      */
     public String requeuePendingTask(String taskType) {
         ServiceUtils.checkNotNullOrEmpty(taskType,"TaskType cannot be null or empty.");

File: client/src/main/java/com/netflix/conductor/client/exceptions/ErrorResponse.java
Patch:
@@ -2,16 +2,16 @@
 
 public class ErrorResponse {
 
-    private String statusCode;
+    private String code;
     private String message;
     private String instance;
 
     public String getCode() {
-        return statusCode;
+        return code;
     }
 
     public void setCode(String code) {
-        this.statusCode = code;
+        this.code = code;
     }
 
     public String getMessage() {

File: jersey/src/main/java/com/netflix/conductor/server/resources/GenericExceptionMapper.java
Patch:
@@ -66,9 +66,7 @@ public Response toResponse(Throwable exception) {
 
 		ApplicationException applicationException = null;
 
-        if (exception instanceof IllegalArgumentException) {
-            applicationException = new ApplicationException(Code.INVALID_INPUT, exception.getMessage(), exception);
-        } else if (exception instanceof InvalidFormatException) {
+        if (exception instanceof IllegalArgumentException || exception instanceof InvalidFormatException) {
             applicationException = new ApplicationException(Code.INVALID_INPUT, exception.getMessage(), exception);
         } else {
             applicationException = new ApplicationException(Code.INTERNAL_ERROR, exception.getMessage(), exception);

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/End2EndTests.java
Patch:
@@ -189,9 +189,9 @@ public void testAll() throws Exception {
 		getTasks = tc.getPendingTasksByType(t1.getName(), null, 1);
 		assertNotNull(getTasks);
 		assertEquals(1, getTasks.size());
-		
-		
+
 		Task pending = tc.getPendingTaskForWorkflow(workflowId, t1.getTaskReferenceName());
+        Thread.sleep(5000);
 		assertNotNull(pending);
 		assertEquals(t1.getTaskReferenceName(), pending.getReferenceTaskName());
 		assertEquals(workflowId, pending.getWorkflowInstanceId());
@@ -258,7 +258,7 @@ public void testInvalidResource() {
         } catch (ConductorClientException e) {
             int statusCode = e.getStatus();
             //TODO: this should be 404
-            assertEquals(500, statusCode);
+            assertEquals(404, statusCode);
         }
 	}
 	

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -131,7 +131,6 @@ private DeciderOutcome decide(final WorkflowDef workflowDef, final Workflow work
         Map<String, Task> tasksToBeScheduled = new LinkedHashMap<>();
 
         preScheduledTasks.forEach(pst -> {
-            executedTaskRefNames.remove(pst.getReferenceTaskName());
             tasksToBeScheduled.put(pst.getReferenceTaskName(), pst);
         });
 

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAOTest.java
Patch:
@@ -142,8 +142,8 @@ public void testPollData() throws Exception {
 	}
 	
 	@Test
-    public void testWith5THreads() throws InterruptedException, ExecutionException {
-        testPollDataWithParallelThreads(5);
+    public void testWith2THreads() throws InterruptedException, ExecutionException {
+        testPollDataWithParallelThreads(2);
     }
     
     

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAO.java
Patch:
@@ -81,6 +81,7 @@ public class RedisExecutionDAO extends BaseDynoDAO implements ExecutionDAO {
 	private final static String POLL_DATA = "POLL_DATA";
 
 	private final static String EVENT_EXECUTION = "EVENT_EXECUTION";
+
 	private static final String WORKFLOW_DYNOMITE_TASK_PAYLOAD_THRESHOLD = "workflow.dynomite.task.payload.threshold";
 	private static final String WORKFLOW_DYNOMITE_WORKFLOW_INPUT_THRESHOLD = "workflow.dynomite.workflow.input.threshold";
 

File: core/src/main/java/com/netflix/conductor/core/events/ActionProcessor.java
Patch:
@@ -61,13 +61,13 @@ public ActionProcessor(WorkflowExecutor executor, MetadataService metadataServic
         this.metadataService = metadataService;
     }
 
-    public Map<String, Object> execute(Action action, String payload, String event, String messageId) {
+    public Map<String, Object> execute(Action action, Object payloadObject, String event, String messageId) {
 
         logger.debug("Executing action: {} for event: {} with messageId:{}", action.getAction(), event, messageId);
 
-        Object jsonObject = payload;
+        Object jsonObject = payloadObject;
         if (action.isExpandInlineJSON()) {
-            jsonObject = expand(payload);
+            jsonObject = expand(payloadObject);
         }
 
         switch (action.getAction()) {

File: core/src/main/java/com/netflix/conductor/core/events/ActionProcessor.java
Patch:
@@ -61,13 +61,13 @@ public ActionProcessor(WorkflowExecutor executor, MetadataService metadataServic
         this.metadataService = metadataService;
     }
 
-    public Map<String, Object> execute(Action action, String payload, String event, String messageId) {
+    public Map<String, Object> execute(Action action, Object payloadObject, String event, String messageId) {
 
         logger.debug("Executing action: {} for event: {} with messageId:{}", action.getAction(), event, messageId);
 
-        Object jsonObject = payload;
+        Object jsonObject = payloadObject;
         if (action.isExpandInlineJSON()) {
-            jsonObject = expand(payload);
+            jsonObject = expand(payloadObject);
         }
 
         switch (action.getAction()) {

File: client/src/main/java/com/netflix/conductor/client/http/MetadataClient.java
Patch:
@@ -117,14 +117,15 @@ public List<WorkflowDef> getAllWorkflowDefs() {
 
     /**
      * Removes the workflow definition of a workflow from the conductor server.
-     * User with caution.
+     * It does not remove associated workflows. Use with caution.
      *
      * @param name Name of the workflow to be unregistered.
+     * @param version Version of the workflow definition to be unregistered.
      */
     public void unregisterWorkflowDef(String name, Integer version) {
         Preconditions.checkArgument(StringUtils.isNotBlank(name), "Workflow name cannot be blank");
         Preconditions.checkNotNull(version, "Version cannot be null");
-        delete("metadata/workflow/{name}/version/{version}",  name, version);
+        delete("metadata/workflow/{name}/{version}",  name, version);
     }
 
     // Task Metadata Operations

File: common/src/main/java/com/netflix/conductor/common/utils/RetryUtil.java
Patch:
@@ -84,6 +84,7 @@ public class RetryUtil<T> {
      *                          <li>And a reference to the original exception generated during the last {@link Attempt} of the retry</li>
      *                          </ul>
      */
+    @SuppressWarnings("Guava")
     public T retryOnException(Supplier<T> supplierCommand,
                               Predicate<Throwable> throwablePredicate,
                               Predicate<T> resultRetryPredicate,
@@ -115,7 +116,7 @@ public <V> void onRetry(Attempt<V> attempt) {
             String errorMessage = String.format("Operation '%s:%s' failed for the %d time in RetryUtil", operationName,
                     shortDescription, internalNumberOfRetries.get());
             logger.debug(errorMessage);
-            throw new RuntimeException(errorMessage, executionException);
+            throw new RuntimeException(errorMessage, executionException.getCause());
         } catch (RetryException retryException) {
             String errorMessage = String.format("Operation '%s:%s' failed after retrying %d times, retry limit %d", operationName,
                     shortDescription, internalNumberOfRetries.get(), 3);

File: core/src/main/java/com/netflix/conductor/core/config/CoreModule.java
Patch:
@@ -49,6 +49,8 @@
 import com.netflix.conductor.core.execution.tasks.Wait;
 import com.netflix.conductor.dao.MetadataDAO;
 import com.netflix.conductor.dao.QueueDAO;
+import com.netflix.conductor.service.DummyRateLimitingService;
+import com.netflix.conductor.service.RateLimitingService;
 
 
 /**
@@ -66,6 +68,7 @@ protected void configure() {
         bind(SubWorkflow.class).asEagerSingleton();
         bind(Wait.class).asEagerSingleton();
         bind(Event.class).asEagerSingleton();
+        bind(RateLimitingService.class).to(DummyRateLimitingService.class);
     }
 
     @Provides

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/EventTaskMapper.java
Patch:
@@ -25,6 +25,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
@@ -67,6 +68,6 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         eventTask.setStatus(Task.Status.SCHEDULED);
         eventTask.setWorkflowTask(taskToSchedule);
 
-        return Arrays.asList(eventTask);
+        return Collections.singletonList(eventTask);
     }
 }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Decision.java
Patch:
@@ -34,9 +34,8 @@ public Decision() {
 	}
 	
 	@Override
-	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) throws Exception {
+	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) {
 		task.setStatus(Status.COMPLETED);
 		return true;
 	}
-
 }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Join.java
Patch:
@@ -18,13 +18,13 @@
  */
 package com.netflix.conductor.core.execution.tasks;
 
-import java.util.List;
-
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.common.run.Workflow;
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 
+import java.util.List;
+
 /**
  * @author Viren
  *
@@ -37,7 +37,7 @@ public Join() {
 	
 	@Override
 	@SuppressWarnings("unchecked")
-	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) throws Exception {
+	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) {
 		
 		boolean allDone = true;
 		boolean hasFailures = false;

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Wait.java
Patch:
@@ -36,17 +36,17 @@ public Wait() {
 	}
 	
 	@Override
-	public void start(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+	public void start(Workflow workflow, Task task, WorkflowExecutor executor) {
 		task.setStatus(Status.IN_PROGRESS);
 	}
 
 	@Override
-	public boolean execute(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+	public boolean execute(Workflow workflow, Task task, WorkflowExecutor executor) {
 		return false;
 	}
 	
 	@Override
-	public void cancel(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+	public void cancel(Workflow workflow, Task task, WorkflowExecutor executor) {
 		task.setStatus(Status.CANCELED);
 	}
 }

File: core/src/main/java/com/netflix/conductor/metrics/Monitors.java
Patch:
@@ -205,7 +205,7 @@ public static void recordUpdateConflict(String taskType, String workflowType, Wo
 	}
 
 	public static void recordUpdateConflict(String taskType, String workflowType, Status status) {
-		counter(classQualifier, "task_update_conflict", "workflowName", workflowType, "taskType", taskType, "workflowStatus", status.name());
+		counter(classQualifier, "task_update_conflict", "workflowName", workflowType, "taskType", taskType, "taskStatus", status.name());
 	}
 
 	public static void recordWorkflowCompletion(String workflowType, long duration, String ownerApp) {

File: core/src/test/java/com/netflix/conductor/core/events/MockQueueProvider.java
Patch:
@@ -26,16 +26,14 @@
  */
 public class MockQueueProvider implements EventQueueProvider {
 
-	private String type;
+	private final String type;
 	
 	public MockQueueProvider(String type) {
 		this.type = type;
 	}
 	
-	
 	@Override
 	public ObservableQueue getQueue(String queueURI) {
 		return new MockObservableQueue(queueURI, queueURI, type);
 	}
-
 }

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestEvent.java
Patch:
@@ -218,15 +218,15 @@ public void testFailures() throws Exception {
 		
 		event.start(workflow, task, null);
 		assertEquals(Task.Status.FAILED, task.getStatus());
-		assertTrue(task.getReasonForIncompletion() != null);
+		assertNotNull(task.getReasonForIncompletion());
 		System.out.println(task.getReasonForIncompletion());
 		
 		task.getInputData().put("sink", "bad_sink");
 		task.setStatus(Status.SCHEDULED);
 		
 		event.start(workflow, task, null);
 		assertEquals(Task.Status.FAILED, task.getStatus());
-		assertTrue(task.getReasonForIncompletion() != null);
+		assertNotNull(task.getReasonForIncompletion());
 		System.out.println(task.getReasonForIncompletion());
 
 		task.setStatus(Status.SCHEDULED);

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/ElasticSearchDAO.java
Patch:
@@ -317,7 +317,7 @@ public List<TaskExecLog> getTaskExecutionLogs(String taskId) {
 			QueryStringQueryBuilder stringQuery = QueryBuilders.queryStringQuery("*");
 			BoolQueryBuilder fq = QueryBuilders.boolQuery().must(stringQuery).must(filterQuery);
 
-			final SearchRequestBuilder srb = elasticSearchClient.prepareSearch(logIndexPrefix + "*").setQuery(fq).setTypes(TASK_DOC_TYPE).addSort(SortBuilders.fieldSort("createdTime").order(SortOrder.ASC).unmappedType("long"));
+			final SearchRequestBuilder srb = elasticSearchClient.prepareSearch(logIndexPrefix + "*").setQuery(fq).setTypes(LOG_DOC_TYPE).addSort(SortBuilders.fieldSort("createdTime").order(SortOrder.ASC).unmappedType("long"));
 			SearchResponse response = srb.execute().actionGet();
 			SearchHit[] hits = response.getHits().getHits();
 			List<TaskExecLog> logs = new ArrayList<>(hits.length);

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/utils/RetryUtil.java
Patch:
@@ -84,6 +84,7 @@ public class RetryUtil<T> {
      *                          <li>And a reference to the original exception generated during the last {@link Attempt} of the retry</li>
      *                          </ul>
      */
+    @SuppressWarnings("Guava")
     public T retryOnException(Supplier<T> supplierCommand,
                               Predicate<Throwable> throwablePredicate,
                               Predicate<T> resultRetryPredicate,
@@ -115,7 +116,7 @@ public <V> void onRetry(Attempt<V> attempt) {
             String errorMessage = String.format("Operation '%s:%s' failed for the %d time in RetryUtil", operationName,
                     shortDescription, internalNumberOfRetries.get());
             logger.debug(errorMessage);
-            throw new RuntimeException(errorMessage, executionException);
+            throw new RuntimeException(errorMessage, executionException.getCause());
         } catch (RetryException retryException) {
             String errorMessage = String.format("Operation '%s:%s' failed after retrying %d times, retry limit %d", operationName,
                     shortDescription, internalNumberOfRetries.get(), 3);

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -65,6 +65,7 @@
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHits;
 import org.elasticsearch.search.fetch.subphase.FetchSourceContext;
+import org.elasticsearch.search.sort.SortBuilders;
 import org.elasticsearch.search.sort.SortOrder;
 import org.joda.time.DateTime;
 import org.slf4j.Logger;
@@ -318,7 +319,7 @@ public List<TaskExecLog> getTaskExecutionLogs(String taskId) {
 			QueryStringQueryBuilder stringQuery = QueryBuilders.queryStringQuery("*");
 			BoolQueryBuilder fq = QueryBuilders.boolQuery().must(stringQuery).must(filterQuery);
 
-			final SearchRequestBuilder srb = elasticSearchClient.prepareSearch(indexName).setQuery(fq).setTypes(TASK_DOC_TYPE);
+			final SearchRequestBuilder srb = elasticSearchClient.prepareSearch(logIndexPrefix + "*").setQuery(fq).setTypes(LOG_DOC_TYPE).addSort(SortBuilders.fieldSort("createdTime").order(SortOrder.ASC));
 			SearchResponse response = srb.execute().actionGet();
 			SearchHit[] hits = response.getHits().getHits();
 			List<TaskExecLog> logs = new ArrayList<>(hits.length);
@@ -426,7 +427,7 @@ public CompletableFuture<Void> asyncRemoveWorkflow(String workflowId) {
 	@Override
 	public void updateWorkflow(String workflowInstanceId, String[] keys, Object[] values) {
 		if (keys.length != values.length) {
-			throw new IllegalArgumentException("Number of keys and values should be same.");
+			throw new ApplicationException(Code.INVALID_INPUT, "Number of keys and values do not match");
 		}
 
 		UpdateRequest request = new UpdateRequest(indexName, WORKFLOW_DOC_TYPE, workflowInstanceId);

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLMetadataDAO.java
Patch:
@@ -128,7 +128,7 @@ public WorkflowDef get(String name, int version) {
     }
 
     @Override
-    public void removeWorkflowDef(String name, int version) {
+    public void removeWorkflowDef(String name, Integer version) {
         final String DELETE_WORKFLOW_QUERY = "DELETE from meta_workflow_def WHERE name = ? AND version = ?";
 
         executeWithTransaction(DELETE_WORKFLOW_QUERY, q -> {
@@ -152,7 +152,6 @@ public List<WorkflowDef> getAll() {
         return queryWithTransaction(GET_ALL_WORKFLOW_DEF_QUERY, q -> q.executeAndFetch(WorkflowDef.class));
     }
 
-    @Override
     public List<WorkflowDef> getAllLatest() {
         final String GET_ALL_LATEST_WORKFLOW_DEF_QUERY = "SELECT json_data FROM meta_workflow_def WHERE version = " +
                                                          "latest_version";

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/ElasticSearchDAO.java
Patch:
@@ -317,7 +317,7 @@ public List<TaskExecLog> getTaskExecutionLogs(String taskId) {
 			QueryStringQueryBuilder stringQuery = QueryBuilders.queryStringQuery("*");
 			BoolQueryBuilder fq = QueryBuilders.boolQuery().must(stringQuery).must(filterQuery);
 
-			final SearchRequestBuilder srb = elasticSearchClient.prepareSearch(logIndexPrefix + "*").setQuery(fq).setTypes(TASK_DOC_TYPE).addSort(SortBuilders.fieldSort("createdTime").order(SortOrder.ASC).unmappedType("long"));
+			final SearchRequestBuilder srb = elasticSearchClient.prepareSearch(logIndexPrefix + "*").setQuery(fq).setTypes(LOG_DOC_TYPE).addSort(SortBuilders.fieldSort("createdTime").order(SortOrder.ASC).unmappedType("long"));
 			SearchResponse response = srb.execute().actionGet();
 			SearchHit[] hits = response.getHits().getHits();
 			List<TaskExecLog> logs = new ArrayList<>(hits.length);

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -65,6 +65,7 @@
 import org.elasticsearch.search.SearchHit;
 import org.elasticsearch.search.SearchHits;
 import org.elasticsearch.search.fetch.subphase.FetchSourceContext;
+import org.elasticsearch.search.sort.SortBuilders;
 import org.elasticsearch.search.sort.SortOrder;
 import org.joda.time.DateTime;
 import org.slf4j.Logger;
@@ -318,7 +319,7 @@ public List<TaskExecLog> getTaskExecutionLogs(String taskId) {
 			QueryStringQueryBuilder stringQuery = QueryBuilders.queryStringQuery("*");
 			BoolQueryBuilder fq = QueryBuilders.boolQuery().must(stringQuery).must(filterQuery);
 
-			final SearchRequestBuilder srb = elasticSearchClient.prepareSearch(indexName).setQuery(fq).setTypes(TASK_DOC_TYPE);
+			final SearchRequestBuilder srb = elasticSearchClient.prepareSearch(logIndexPrefix + "*").setQuery(fq).setTypes(LOG_DOC_TYPE).addSort(SortBuilders.fieldSort("createdTime").order(SortOrder.ASC));
 			SearchResponse response = srb.execute().actionGet();
 			SearchHit[] hits = response.getHits().getHits();
 			List<TaskExecLog> logs = new ArrayList<>(hits.length);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinDynamicTaskMapper.java
Patch:
@@ -27,6 +27,7 @@
 import com.netflix.conductor.core.execution.ParametersUtils;
 import com.netflix.conductor.core.execution.SystemTaskType;
 import com.netflix.conductor.core.execution.TerminateWorkflowException;
+import com.netflix.conductor.core.metadata.MetadataMapperService;
 import com.netflix.conductor.core.utils.IDGenerator;
 import com.netflix.conductor.dao.MetadataDAO;
 import org.apache.commons.lang3.tuple.ImmutablePair;
@@ -240,7 +241,7 @@ Pair<List<WorkflowTask>, Map<String, Map<String, Object>>> getDynamicForkTasksAn
         Object dynamicForkTasksJson = input.get(dynamicForkTaskParam);
         List<WorkflowTask> dynamicForkWorkflowTasks = objectMapper.convertValue(dynamicForkTasksJson, ListOfWorkflowTasks);
         for (WorkflowTask workflowTask : dynamicForkWorkflowTasks) {
-            if (workflowTask.shouldPopulateDefinition()) {
+            if (MetadataMapperService.shouldPopulateDefinition(workflowTask)) {
                 workflowTask.setTaskDefinition(metadataDAO.getTaskDef(workflowTask.getName()));
             }
         }
@@ -283,7 +284,7 @@ Pair<List<WorkflowTask>, Map<String, Map<String, Object>>> getDynamicForkJoinTas
                     dynamicForkJoinWorkflowTask.setTaskReferenceName(dynamicForkJoinTask.getReferenceName());
                     dynamicForkJoinWorkflowTask.setName(dynamicForkJoinTask.getTaskName());
                     dynamicForkJoinWorkflowTask.setType(dynamicForkJoinTask.getType());
-                    if (dynamicForkJoinWorkflowTask.shouldPopulateDefinition()) {
+                    if (MetadataMapperService.shouldPopulateDefinition(dynamicForkJoinWorkflowTask)) {
                         dynamicForkJoinWorkflowTask.setTaskDefinition(
                                 metadataDAO.getTaskDef(dynamicForkJoinTask.getTaskName()));
                     }

File: client/src/test/java/com/netflix/conductor/client/metadata/workflow/TestWorkflowTask.java
Patch:
@@ -17,11 +17,11 @@
 
 import static org.junit.Assert.*;
 
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import org.junit.Test;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
 
 /**
  * 
@@ -45,7 +45,7 @@ public void test() throws Exception {
 		assertEquals(task.getType(), read.getType());
 		
 		task = new WorkflowTask();
-		task.setWorkflowTaskType(Type.SUB_WORKFLOW);
+		task.setWorkflowTaskType(TaskType.SUB_WORKFLOW);
 		task.setName("name");
 		
 		json = om.writeValueAsString(task);
@@ -54,6 +54,6 @@ public void test() throws Exception {
 		assertNotNull(read);
 		assertEquals(task.getName(), read.getName());
 		assertEquals(task.getType(), read.getType());
-		assertEquals(Type.SUB_WORKFLOW.name(), read.getType());
+		assertEquals(TaskType.SUB_WORKFLOW.name(), read.getType());
 	}
 }

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -17,6 +17,7 @@
 
 import com.google.protobuf.Any;
 import com.github.vmg.protogen.annotations.*;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 
 import java.util.HashMap;
@@ -173,7 +174,7 @@ public Task() {
 
     /**
      * @return Type of the task
-     * @see WorkflowTask.Type
+     * @see TaskType
      */
     public String getTaskType() {
         return taskType;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/DynamicForkJoinTask.java
Patch:
@@ -19,7 +19,6 @@
 import java.util.Map;
 
 import com.github.vmg.protogen.annotations.*;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
 
 @ProtoMessage
 public class DynamicForkJoinTask {
@@ -37,7 +36,7 @@ public class DynamicForkJoinTask {
     private Map<String, Object> input = new HashMap<>();
 
     @ProtoField(id = 5)
-    private String type = Type.SIMPLE.name();
+    private String type = TaskType.SIMPLE.name();
 
     public DynamicForkJoinTask() {
     }

File: common/src/test/java/com/netflix/conductor/common/workflow/TestWorkflowDef.java
Patch:
@@ -27,11 +27,11 @@
 import java.util.List;
 import java.util.Map;
 
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import org.junit.Test;
 
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
 
 /**
  * @author Viren
@@ -61,7 +61,7 @@ public void test() throws Exception {
 		wf.setDescription(COND_TASK_WF);
 		
 		WorkflowTask subCaseTask = new WorkflowTask();
-		subCaseTask.setType(Type.DECISION.name());
+		subCaseTask.setType(TaskType.DECISION.name());
 		subCaseTask.setCaseValueParam("case2");
 		subCaseTask.setName("case2");
 		subCaseTask.setTaskReferenceName("case2");
@@ -72,7 +72,7 @@ public void test() throws Exception {
 		
 		
 		WorkflowTask caseTask = new WorkflowTask();
-		caseTask.setType(Type.DECISION.name());
+		caseTask.setType(TaskType.DECISION.name());
 		caseTask.setCaseValueParam("case");
 		caseTask.setName("case");
 		caseTask.setTaskReferenceName("case");

File: common/src/test/java/com/netflix/conductor/common/workflow/TestWorkflowTask.java
Patch:
@@ -21,10 +21,10 @@
 
 import static org.junit.Assert.*;
 
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import org.junit.Test;
 
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
 
 /**
  * @author Viren
@@ -35,10 +35,10 @@ public class TestWorkflowTask {
 	@Test
 	public void test() {
 		WorkflowTask wt = new WorkflowTask();
-		wt.setWorkflowTaskType(Type.DECISION);
+		wt.setWorkflowTaskType(TaskType.DECISION);
 		
 		assertNotNull(wt.getType());
-		assertEquals(Type.DECISION.name(), wt.getType());
+		assertEquals(TaskType.DECISION.name(), wt.getType());
 	}
 	
 	@Test

File: contribs/src/test/java/com/netflix/conductor/contribs/http/TestHttpTask.java
Patch:
@@ -19,9 +19,9 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
 import com.netflix.conductor.common.run.Workflow;
 import com.netflix.conductor.contribs.http.HttpTask.Input;
 import com.netflix.conductor.core.config.Configuration;
@@ -272,7 +272,7 @@ public void testOptional() throws Exception {
         WorkflowTask workflowTask = new WorkflowTask();
         workflowTask.setOptional(true);
         workflowTask.setName("HTTP");
-        workflowTask.setWorkflowTaskType(Type.USER_DEFINED);
+        workflowTask.setWorkflowTaskType(TaskType.USER_DEFINED);
         workflowTask.setTaskReferenceName("t1");
 
         WorkflowDef def = new WorkflowDef();

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -18,6 +18,7 @@
 
 import com.google.common.annotations.VisibleForTesting;
 import com.netflix.conductor.common.metadata.tasks.Task;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
@@ -34,7 +35,7 @@
 
 
 /**
- * An implementation of {@link TaskMapper} to map a {@link WorkflowTask} of type {@link WorkflowTask.Type#DECISION}
+ * An implementation of {@link TaskMapper} to map a {@link WorkflowTask} of type {@link TaskType#DECISION}
  * to a List {@link Task} starting with Task of type {@link SystemTaskType#DECISION} which is marked as IN_PROGRESS,
  * followed by the list of {@link Task} based on the case expression evaluation in the Decision task.
  */
@@ -43,7 +44,7 @@ public class DecisionTaskMapper implements TaskMapper {
     Logger logger = LoggerFactory.getLogger(DecisionTaskMapper.class);
 
     /**
-     * This method gets the list of tasks that need to scheduled when the the task to scheduled is of type {@link WorkflowTask.Type#DECISION}.
+     * This method gets the list of tasks that need to scheduled when the the task to scheduled is of type {@link TaskType#DECISION}.
      *
      * @param taskMapperContext: A wrapper class containing the {@link WorkflowTask}, {@link WorkflowDef}, {@link Workflow} and a string representation of the TaskId
      * @return List of tasks in the following order:

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DynamicTaskMapper.java
Patch:
@@ -19,6 +19,7 @@
 import com.google.common.annotations.VisibleForTesting;
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
@@ -34,7 +35,7 @@
 
 
 /**
- * An implementation of {@link TaskMapper} to map a {@link WorkflowTask} of type {@link WorkflowTask.Type#DYNAMIC}
+ * An implementation of {@link TaskMapper} to map a {@link WorkflowTask} of type {@link TaskType#DYNAMIC}
  * to a {@link Task} based on definition derived from the dynamic task name defined in {@link WorkflowTask#getInputParameters()}
  */
 public class DynamicTaskMapper implements TaskMapper {

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/JoinTaskMapper.java
Patch:
@@ -17,6 +17,7 @@
 package com.netflix.conductor.core.execution.mapper;
 
 import com.netflix.conductor.common.metadata.tasks.Task;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
@@ -30,15 +31,15 @@
 import java.util.Map;
 
 /**
- * An implementation of {@link TaskMapper} to map a {@link WorkflowTask} of type {@link WorkflowTask.Type#JOIN}
+ * An implementation of {@link TaskMapper} to map a {@link WorkflowTask} of type {@link TaskType#JOIN}
  * to a {@link Task} of type {@link SystemTaskType#JOIN}
  */
 public class JoinTaskMapper implements TaskMapper {
 
     public static final Logger logger = LoggerFactory.getLogger(JoinTaskMapper.class);
 
     /**
-     * This method maps {@link TaskMapper} to map a {@link WorkflowTask} of type {@link WorkflowTask.Type#JOIN} to a {@link Task} of type {@link SystemTaskType#JOIN}
+     * This method maps {@link TaskMapper} to map a {@link WorkflowTask} of type {@link TaskType#JOIN} to a {@link Task} of type {@link SystemTaskType#JOIN}
      * with a status of {@link Task.Status#IN_PROGRESS}
      *
      * @param taskMapperContext: A wrapper class containing the {@link WorkflowTask}, {@link WorkflowDef}, {@link Workflow} and a string representation of the TaskId

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SimpleTaskMapper.java
Patch:
@@ -19,6 +19,7 @@
 
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
@@ -34,7 +35,7 @@
 
 
 /**
- * An implementation of {@link TaskMapper} to map a {@link WorkflowTask} of type {@link WorkflowTask.Type#SIMPLE}
+ * An implementation of {@link TaskMapper} to map a {@link WorkflowTask} of type {@link TaskType#SIMPLE}
  * to a {@link Task} with status {@link Task.Status#SCHEDULED}. <b>NOTE:</b> There is not type defined for simples task.
  */
 public class SimpleTaskMapper implements TaskMapper {
@@ -48,7 +49,7 @@ public SimpleTaskMapper(ParametersUtils parametersUtils) {
     }
 
     /**
-     * This method maps a {@link WorkflowTask} of type {@link WorkflowTask.Type#SIMPLE}
+     * This method maps a {@link WorkflowTask} of type {@link TaskType#SIMPLE}
      * to a {@link Task}
      *
      * @param taskMapperContext: A wrapper class containing the {@link WorkflowTask}, {@link WorkflowDef}, {@link Workflow} and a string representation of the TaskId

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapper.java
Patch:
@@ -17,6 +17,7 @@
 package com.netflix.conductor.core.execution.mapper;
 
 import com.netflix.conductor.common.metadata.tasks.Task;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
 import com.netflix.conductor.core.execution.ParametersUtils;
@@ -30,7 +31,7 @@
 
 
 /**
- * An implementation of {@link TaskMapper} to map a {@link WorkflowTask} of type {@link WorkflowTask.Type#WAIT}
+ * An implementation of {@link TaskMapper} to map a {@link WorkflowTask} of type {@link TaskType#WAIT}
  * to a {@link Task} of type {@link Wait} with {@link Task.Status#IN_PROGRESS}
  */
 public class WaitTaskMapper implements TaskMapper {

File: core/src/main/java/com/netflix/conductor/core/metadata/MetadataMapperService.java
Patch:
@@ -2,6 +2,7 @@
 
 import com.google.inject.Singleton;
 import com.netflix.conductor.common.metadata.workflow.SubWorkflowParams;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.core.execution.TerminateWorkflowException;
@@ -10,7 +11,6 @@
 import org.slf4j.LoggerFactory;
 
 import javax.inject.Inject;
-import java.util.List;
 
 @Singleton
 public class MetadataMapperService {
@@ -29,7 +29,7 @@ public WorkflowDef populateTaskDefinitions(WorkflowDef workflowDefinition) {
                 workflowTask -> {
                     if (workflowTask.shouldPopulateDefinition()) {
                         workflowTask.setTaskDefinition(metadataDAO.getTaskDef(workflowTask.getName()));
-                    } else if (workflowTask.getType().equals(WorkflowTask.Type.SUB_WORKFLOW.name())) {
+                    } else if (workflowTask.getType().equals(TaskType.SUB_WORKFLOW.name())) {
                         populateVersionForSubWorkflow(workflowTask);
                     }
                 }

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowDef.java
Patch:
@@ -31,7 +31,7 @@
 
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 
 /**
  * @author Viren
@@ -50,7 +50,7 @@ public void test(){
 		
 		WorkflowTask task3 = create("decision_task_1");
 		def.getTasks().add(task3);
-		task3.setType(Type.DECISION.name());
+		task3.setType(TaskType.DECISION.name());
 		task3.getDecisionCases().put("Case1", Arrays.asList(create("case_1_task_1"), create("case_1_task_2")));
 		task3.getDecisionCases().put("Case2", Arrays.asList(create("case_2_task_1"), create("case_2_task_2")));
 		task3.getDecisionCases().put("Case3", Arrays.asList(deciderTask("decision_task_2", toMap("Case31", "case31_task_1", "case_31_task_2"), Arrays.asList("case3_def_task"))));
@@ -98,7 +98,7 @@ private WorkflowTask create(String name){
 	
 	private WorkflowTask deciderTask(String name, Map<String, List<String>> decisions, List<String> defaultTasks){
 		WorkflowTask task = create(name);
-		task.setType(Type.DECISION.name());
+		task.setType(TaskType.DECISION.name());
 		decisions.entrySet().forEach(e -> {
 			List<WorkflowTask> tasks = new LinkedList<>();			
 			e.getValue().forEach(taskName -> tasks.add(create(taskName)));

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/JoinTaskMapperTest.java
Patch:
@@ -1,6 +1,7 @@
 package com.netflix.conductor.core.execution.mapper;
 
 import com.netflix.conductor.common.metadata.tasks.Task;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
@@ -20,7 +21,7 @@ public class JoinTaskMapperTest {
     public void getMappedTasks() throws Exception {
 
         WorkflowTask taskToSchedule = new WorkflowTask();
-        taskToSchedule.setType(WorkflowTask.Type.JOIN.name());
+        taskToSchedule.setType(TaskType.JOIN.name());
         taskToSchedule.setJoinOn(Arrays.asList("task1, task2"));
 
         String taskId = IDGenerator.generate();

File: core/src/test/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapperTest.java
Patch:
@@ -1,6 +1,7 @@
 package com.netflix.conductor.core.execution.mapper;
 
 import com.netflix.conductor.common.metadata.tasks.Task;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
@@ -22,7 +23,7 @@ public void getMappedTasks() throws Exception {
         //Given
         WorkflowTask taskToSchedule = new WorkflowTask();
         taskToSchedule.setName("Wait_task");
-        taskToSchedule.setType(WorkflowTask.Type.WAIT.name());
+        taskToSchedule.setType(TaskType.WAIT.name());
         String taskId = IDGenerator.generate();
 
         ParametersUtils parametersUtils = new ParametersUtils();

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestEvent.java
Patch:
@@ -17,8 +17,8 @@
 
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
 import com.netflix.conductor.core.events.EventQueues;
 import com.netflix.conductor.core.events.MockQueueProvider;
@@ -104,7 +104,7 @@ public void testSinkParam() {
         Task task = new Task();
         task.setReferenceTaskName("event");
         task.getInputData().put("sink", sink);
-        task.setTaskType(WorkflowTask.Type.EVENT.name());
+        task.setTaskType(TaskType.EVENT.name());
         workflow.getTasks().add(task);
 
         Event event = new Event();

File: core/src/test/java/com/netflix/conductor/metadata/MetadataMapperServiceTest.java
Patch:
@@ -2,6 +2,7 @@
 
 import com.google.common.collect.ImmutableList;
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.core.metadata.MetadataMapperService;
@@ -119,7 +120,7 @@ private WorkflowDef createWorkflowDefinition(String name) {
     private WorkflowTask createWorkflowTask(String name) {
         WorkflowTask workflowTask = new WorkflowTask();
         workflowTask.setName(name);
-        workflowTask.setType(WorkflowTask.Type.SIMPLE.name());
+        workflowTask.setType(TaskType.SIMPLE.name());
         return workflowTask;
     }
 

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/End2EndGrpcTests.java
Patch:
@@ -31,7 +31,7 @@
 import com.netflix.conductor.common.metadata.workflow.StartWorkflowRequest;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
-import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
+import com.netflix.conductor.common.metadata.workflow.TaskType;
 import com.netflix.conductor.common.run.SearchResult;
 import com.netflix.conductor.common.run.Workflow;
 import com.netflix.conductor.common.run.Workflow.WorkflowStatus;
@@ -116,12 +116,12 @@ public void testAll() throws Exception {
         def.setName("test");
         WorkflowTask t0 = new WorkflowTask();
         t0.setName("t0");
-        t0.setWorkflowTaskType(Type.SIMPLE);
+        t0.setWorkflowTaskType(TaskType.SIMPLE);
         t0.setTaskReferenceName("t0");
 
         WorkflowTask t1 = new WorkflowTask();
         t1.setName("t1");
-        t1.setWorkflowTaskType(Type.SIMPLE);
+        t1.setWorkflowTaskType(TaskType.SIMPLE);
         t1.setTaskReferenceName("t1");
 
 

File: common/src/main/java/com/netflix/conductor/common/utils/RetryUtil.java
Patch:
@@ -84,6 +84,7 @@ public class RetryUtil<T> {
      *                          <li>And a reference to the original exception generated during the last {@link Attempt} of the retry</li>
      *                          </ul>
      */
+    @SuppressWarnings("Guava")
     public T retryOnException(Supplier<T> supplierCommand,
                               Predicate<Throwable> throwablePredicate,
                               Predicate<T> resultRetryPredicate,
@@ -115,7 +116,7 @@ public <V> void onRetry(Attempt<V> attempt) {
             String errorMessage = String.format("Operation '%s:%s' failed for the %d time in RetryUtil", operationName,
                     shortDescription, internalNumberOfRetries.get());
             logger.debug(errorMessage);
-            throw new RuntimeException(errorMessage, executionException);
+            throw new RuntimeException(errorMessage, executionException.getCause());
         } catch (RetryException retryException) {
             String errorMessage = String.format("Operation '%s:%s' failed after retrying %d times, retry limit %d", operationName,
                     shortDescription, internalNumberOfRetries.get(), 3);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/EventTaskMapper.java
Patch:
@@ -25,6 +25,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
@@ -67,6 +68,6 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         eventTask.setStatus(Task.Status.SCHEDULED);
         eventTask.setWorkflowTask(taskToSchedule);
 
-        return Arrays.asList(eventTask);
+        return Collections.singletonList(eventTask);
     }
 }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Decision.java
Patch:
@@ -34,9 +34,8 @@ public Decision() {
 	}
 	
 	@Override
-	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) throws Exception {
+	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) {
 		task.setStatus(Status.COMPLETED);
 		return true;
 	}
-
 }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Join.java
Patch:
@@ -18,13 +18,13 @@
  */
 package com.netflix.conductor.core.execution.tasks;
 
-import java.util.List;
-
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.common.run.Workflow;
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 
+import java.util.List;
+
 /**
  * @author Viren
  *
@@ -37,7 +37,7 @@ public Join() {
 	
 	@Override
 	@SuppressWarnings("unchecked")
-	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) throws Exception {
+	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) {
 		
 		boolean allDone = true;
 		boolean hasFailures = false;

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Wait.java
Patch:
@@ -36,17 +36,17 @@ public Wait() {
 	}
 	
 	@Override
-	public void start(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+	public void start(Workflow workflow, Task task, WorkflowExecutor executor) {
 		task.setStatus(Status.IN_PROGRESS);
 	}
 
 	@Override
-	public boolean execute(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+	public boolean execute(Workflow workflow, Task task, WorkflowExecutor executor) {
 		return false;
 	}
 	
 	@Override
-	public void cancel(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+	public void cancel(Workflow workflow, Task task, WorkflowExecutor executor) {
 		task.setStatus(Status.CANCELED);
 	}
 }

File: core/src/main/java/com/netflix/conductor/metrics/Monitors.java
Patch:
@@ -205,7 +205,7 @@ public static void recordUpdateConflict(String taskType, String workflowType, Wo
 	}
 
 	public static void recordUpdateConflict(String taskType, String workflowType, Status status) {
-		counter(classQualifier, "task_update_conflict", "workflowName", workflowType, "taskType", taskType, "workflowStatus", status.name());
+		counter(classQualifier, "task_update_conflict", "workflowName", workflowType, "taskType", taskType, "taskStatus", status.name());
 	}
 
 	public static void recordWorkflowCompletion(String workflowType, long duration, String ownerApp) {

File: core/src/test/java/com/netflix/conductor/core/events/MockQueueProvider.java
Patch:
@@ -26,16 +26,14 @@
  */
 public class MockQueueProvider implements EventQueueProvider {
 
-	private String type;
+	private final String type;
 	
 	public MockQueueProvider(String type) {
 		this.type = type;
 	}
 	
-	
 	@Override
 	public ObservableQueue getQueue(String queueURI) {
 		return new MockObservableQueue(queueURI, queueURI, type);
 	}
-
 }

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -112,7 +112,7 @@ public boolean isAsync() {
             }
 
             @Override
-            public void start(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+            public void start(Workflow workflow, Task task, WorkflowExecutor executor) {
                 httpTaskExecuted.set(true);
                 task.setStatus(Status.COMPLETED);
                 super.start(workflow, task, executor);
@@ -123,7 +123,7 @@ public void start(Workflow workflow, Task task, WorkflowExecutor executor) throw
         new WorkflowSystemTask("HTTP2") {
 
             @Override
-            public void start(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+            public void start(Workflow workflow, Task task, WorkflowExecutor executor) {
                 http2TaskExecuted.set(true);
                 task.setStatus(Status.COMPLETED);
                 super.start(workflow, task, executor);

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestEvent.java
Patch:
@@ -218,15 +218,15 @@ public void testFailures() throws Exception {
 		
 		event.start(workflow, task, null);
 		assertEquals(Task.Status.FAILED, task.getStatus());
-		assertTrue(task.getReasonForIncompletion() != null);
+		assertNotNull(task.getReasonForIncompletion());
 		System.out.println(task.getReasonForIncompletion());
 		
 		task.getInputData().put("sink", "bad_sink");
 		task.setStatus(Status.SCHEDULED);
 		
 		event.start(workflow, task, null);
 		assertEquals(Task.Status.FAILED, task.getStatus());
-		assertTrue(task.getReasonForIncompletion() != null);
+		assertNotNull(task.getReasonForIncompletion());
 		System.out.println(task.getReasonForIncompletion());
 
 		task.setStatus(Status.SCHEDULED);

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/utils/RetryUtil.java
Patch:
@@ -84,6 +84,7 @@ public class RetryUtil<T> {
      *                          <li>And a reference to the original exception generated during the last {@link Attempt} of the retry</li>
      *                          </ul>
      */
+    @SuppressWarnings("Guava")
     public T retryOnException(Supplier<T> supplierCommand,
                               Predicate<Throwable> throwablePredicate,
                               Predicate<T> resultRetryPredicate,
@@ -115,7 +116,7 @@ public <V> void onRetry(Attempt<V> attempt) {
             String errorMessage = String.format("Operation '%s:%s' failed for the %d time in RetryUtil", operationName,
                     shortDescription, internalNumberOfRetries.get());
             logger.debug(errorMessage);
-            throw new RuntimeException(errorMessage, executionException);
+            throw new RuntimeException(errorMessage, executionException.getCause());
         } catch (RetryException retryException) {
             String errorMessage = String.format("Operation '%s:%s' failed after retrying %d times, retry limit %d", operationName,
                     shortDescription, internalNumberOfRetries.get(), 3);

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -426,7 +426,7 @@ public CompletableFuture<Void> asyncRemoveWorkflow(String workflowId) {
 	@Override
 	public void updateWorkflow(String workflowInstanceId, String[] keys, Object[] values) {
 		if (keys.length != values.length) {
-			throw new IllegalArgumentException("Number of keys and values should be same.");
+			throw new ApplicationException(Code.INVALID_INPUT, "Number of keys and values do not match");
 		}
 
 		UpdateRequest request = new UpdateRequest(indexName, WORKFLOW_DOC_TYPE, workflowInstanceId);

File: common/src/main/java/com/netflix/conductor/common/utils/RetryUtil.java
Patch:
@@ -84,6 +84,7 @@ public class RetryUtil<T> {
      *                          <li>And a reference to the original exception generated during the last {@link Attempt} of the retry</li>
      *                          </ul>
      */
+    @SuppressWarnings("Guava")
     public T retryOnException(Supplier<T> supplierCommand,
                               Predicate<Throwable> throwablePredicate,
                               Predicate<T> resultRetryPredicate,
@@ -115,7 +116,7 @@ public <V> void onRetry(Attempt<V> attempt) {
             String errorMessage = String.format("Operation '%s:%s' failed for the %d time in RetryUtil", operationName,
                     shortDescription, internalNumberOfRetries.get());
             logger.debug(errorMessage);
-            throw new RuntimeException(errorMessage, executionException);
+            throw new RuntimeException(errorMessage, executionException.getCause());
         } catch (RetryException retryException) {
             String errorMessage = String.format("Operation '%s:%s' failed after retrying %d times, retry limit %d", operationName,
                     shortDescription, internalNumberOfRetries.get(), 3);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/EventTaskMapper.java
Patch:
@@ -25,6 +25,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 
@@ -67,6 +68,6 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         eventTask.setStatus(Task.Status.SCHEDULED);
         eventTask.setWorkflowTask(taskToSchedule);
 
-        return Arrays.asList(eventTask);
+        return Collections.singletonList(eventTask);
     }
 }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Decision.java
Patch:
@@ -34,9 +34,8 @@ public Decision() {
 	}
 	
 	@Override
-	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) throws Exception {
+	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) {
 		task.setStatus(Status.COMPLETED);
 		return true;
 	}
-
 }

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Join.java
Patch:
@@ -18,13 +18,13 @@
  */
 package com.netflix.conductor.core.execution.tasks;
 
-import java.util.List;
-
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.common.run.Workflow;
 import com.netflix.conductor.core.execution.WorkflowExecutor;
 
+import java.util.List;
+
 /**
  * @author Viren
  *
@@ -37,7 +37,7 @@ public Join() {
 	
 	@Override
 	@SuppressWarnings("unchecked")
-	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) throws Exception {
+	public boolean execute(Workflow workflow, Task task, WorkflowExecutor provider) {
 		
 		boolean allDone = true;
 		boolean hasFailures = false;

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Wait.java
Patch:
@@ -36,17 +36,17 @@ public Wait() {
 	}
 	
 	@Override
-	public void start(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+	public void start(Workflow workflow, Task task, WorkflowExecutor executor) {
 		task.setStatus(Status.IN_PROGRESS);
 	}
 
 	@Override
-	public boolean execute(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+	public boolean execute(Workflow workflow, Task task, WorkflowExecutor executor) {
 		return false;
 	}
 	
 	@Override
-	public void cancel(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+	public void cancel(Workflow workflow, Task task, WorkflowExecutor executor) {
 		task.setStatus(Status.CANCELED);
 	}
 }

File: core/src/main/java/com/netflix/conductor/metrics/Monitors.java
Patch:
@@ -205,7 +205,7 @@ public static void recordUpdateConflict(String taskType, String workflowType, Wo
 	}
 
 	public static void recordUpdateConflict(String taskType, String workflowType, Status status) {
-		counter(classQualifier, "task_update_conflict", "workflowName", workflowType, "taskType", taskType, "workflowStatus", status.name());
+		counter(classQualifier, "task_update_conflict", "workflowName", workflowType, "taskType", taskType, "taskStatus", status.name());
 	}
 
 	public static void recordWorkflowCompletion(String workflowType, long duration, String ownerApp) {

File: core/src/test/java/com/netflix/conductor/core/events/MockQueueProvider.java
Patch:
@@ -26,16 +26,14 @@
  */
 public class MockQueueProvider implements EventQueueProvider {
 
-	private String type;
+	private final String type;
 	
 	public MockQueueProvider(String type) {
 		this.type = type;
 	}
 	
-	
 	@Override
 	public ObservableQueue getQueue(String queueURI) {
 		return new MockObservableQueue(queueURI, queueURI, type);
 	}
-
 }

File: core/src/test/java/com/netflix/conductor/core/execution/TestWorkflowExecutor.java
Patch:
@@ -112,7 +112,7 @@ public boolean isAsync() {
             }
 
             @Override
-            public void start(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+            public void start(Workflow workflow, Task task, WorkflowExecutor executor) {
                 httpTaskExecuted.set(true);
                 task.setStatus(Status.COMPLETED);
                 super.start(workflow, task, executor);
@@ -123,7 +123,7 @@ public void start(Workflow workflow, Task task, WorkflowExecutor executor) throw
         new WorkflowSystemTask("HTTP2") {
 
             @Override
-            public void start(Workflow workflow, Task task, WorkflowExecutor executor) throws Exception {
+            public void start(Workflow workflow, Task task, WorkflowExecutor executor) {
                 http2TaskExecuted.set(true);
                 task.setStatus(Status.COMPLETED);
                 super.start(workflow, task, executor);

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestEvent.java
Patch:
@@ -218,15 +218,15 @@ public void testFailures() throws Exception {
 		
 		event.start(workflow, task, null);
 		assertEquals(Task.Status.FAILED, task.getStatus());
-		assertTrue(task.getReasonForIncompletion() != null);
+		assertNotNull(task.getReasonForIncompletion());
 		System.out.println(task.getReasonForIncompletion());
 		
 		task.getInputData().put("sink", "bad_sink");
 		task.setStatus(Status.SCHEDULED);
 		
 		event.start(workflow, task, null);
 		assertEquals(Task.Status.FAILED, task.getStatus());
-		assertTrue(task.getReasonForIncompletion() != null);
+		assertNotNull(task.getReasonForIncompletion());
 		System.out.println(task.getReasonForIncompletion());
 
 		task.setStatus(Status.SCHEDULED);

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/utils/RetryUtil.java
Patch:
@@ -84,6 +84,7 @@ public class RetryUtil<T> {
      *                          <li>And a reference to the original exception generated during the last {@link Attempt} of the retry</li>
      *                          </ul>
      */
+    @SuppressWarnings("Guava")
     public T retryOnException(Supplier<T> supplierCommand,
                               Predicate<Throwable> throwablePredicate,
                               Predicate<T> resultRetryPredicate,
@@ -115,7 +116,7 @@ public <V> void onRetry(Attempt<V> attempt) {
             String errorMessage = String.format("Operation '%s:%s' failed for the %d time in RetryUtil", operationName,
                     shortDescription, internalNumberOfRetries.get());
             logger.debug(errorMessage);
-            throw new RuntimeException(errorMessage, executionException);
+            throw new RuntimeException(errorMessage, executionException.getCause());
         } catch (RetryException retryException) {
             String errorMessage = String.format("Operation '%s:%s' failed after retrying %d times, retry limit %d", operationName,
                     shortDescription, internalNumberOfRetries.get(), 3);

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -426,7 +426,7 @@ public CompletableFuture<Void> asyncRemoveWorkflow(String workflowId) {
 	@Override
 	public void updateWorkflow(String workflowInstanceId, String[] keys, Object[] values) {
 		if (keys.length != values.length) {
-			throw new IllegalArgumentException("Number of keys and values should be same.");
+			throw new ApplicationException(Code.INVALID_INPUT, "Number of keys and values do not match");
 		}
 
 		UpdateRequest request = new UpdateRequest(indexName, WORKFLOW_DOC_TYPE, workflowInstanceId);

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -166,5 +166,4 @@ default List<AbstractModule> getAdditionalModules() {
     enum DB {
         REDIS, DYNOMITE, MEMORY, REDIS_CLUSTER, MYSQL
     }
-
 }

File: core/src/main/java/com/netflix/conductor/core/config/Configuration.java
Patch:
@@ -166,5 +166,4 @@ default List<AbstractModule> getAdditionalModules() {
     enum DB {
         REDIS, DYNOMITE, MEMORY, REDIS_CLUSTER, MYSQL
     }
-
 }

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisMetadataDAO.java
Patch:
@@ -39,6 +39,7 @@
 import com.netflix.conductor.core.execution.ApplicationException.Code;
 import com.netflix.conductor.dao.MetadataDAO;
 import com.netflix.conductor.metrics.Monitors;
+import org.apache.commons.lang.StringUtils;
 
 @Singleton
 @Trace
@@ -219,8 +220,8 @@ public WorkflowDef get(String name, int version) {
 
     @Override
     public void removeWorkflowDef(String name, int version) {
-        Preconditions.checkNotNull(name, "WorkflowDef name cannot be null");
-        Preconditions.checkNotNull(version, "Version cannot be null");
+        Preconditions.checkArgument(StringUtils.isNotBlank(name), "WorkflowDef name cannot be null");
+        Preconditions.checkArgument(version > 0, "Input version is not valid");
         Long result = dynoClient.hdel(nsKey(WORKFLOW_DEF, name), String.valueOf(version));
         if (!result.equals(1L)) {
             throw new ApplicationException(Code.NOT_FOUND, String.format("Cannot remove the workflow - no such workflow" +

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLMetadataDAO.java
Patch:
@@ -133,7 +133,8 @@ public void removeWorkflowDef(String name, int version) {
 
         executeWithTransaction(DELETE_WORKFLOW_QUERY, q -> {
             if (!q.addParameter(name).addParameter(version).executeDelete()) {
-                throw new ApplicationException(ApplicationException.Code.NOT_FOUND, "No such workflow definition");
+                throw new ApplicationException(ApplicationException.Code.NOT_FOUND,
+                        String.format("No such workflow definition: %s version: %d", name, version));
             }
         });
     }

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -493,7 +493,7 @@ private SearchResult<String> search(String structuredQuery, int start, int size,
 	@Override
 	public List<String> searchArchivableWorkflows(String indexName, long archiveTtlDays) {
 		QueryBuilder q = QueryBuilders.boolQuery()
-				.must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays)))
+				.must(QueryBuilders.rangeQuery("endTime").lt(LocalDate.now().minusDays(archiveTtlDays).toString()))
 				.should(QueryBuilders.termQuery("status", "COMPLETED"))
 				.should(QueryBuilders.termQuery("status", "FAILED"))
 				.mustNot(QueryBuilders.existsQuery("archived"))

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/ElasticSearchDAO.java
Patch:
@@ -104,7 +104,7 @@ public class ElasticSearchDAO implements IndexDAO {
 
 	private static final String TASK_DOC_TYPE = "task";
 
-	private static final String LOG_DOC_TYPE = "task";
+	private static final String LOG_DOC_TYPE = "task_log";
 
 	private static final String EVENT_DOC_TYPE = "event";
 

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAOV5.java
Patch:
@@ -102,7 +102,7 @@ public class ElasticSearchDAOV5 implements IndexDAO {
 	
 	private static final String TASK_DOC_TYPE = "task";
 	
-	private static final String LOG_DOC_TYPE = "task";
+	private static final String LOG_DOC_TYPE = "task_log";
 	
 	private static final String EVENT_DOC_TYPE = "event";
 	

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowServiceTest.java
Patch:
@@ -2756,7 +2756,7 @@ public void testNonRestartartableWorkflows() throws Exception {
         taskDef.setRetryCount(0);
         metadataService.updateTaskDef(taskDef);
 
-        WorkflowDef found = metadataService.getWorkflowDef(LINEAR_WORKFLOW_T1_T2, 1);
+        WorkflowDef found = metadataService.getWorkflowDef(LINEAR_WORKFLOW_T1_T2, 1).get();
         found.setName(JUNIT_TEST_WF_NON_RESTARTABLE);
         found.setRestartable(false);
         metadataService.updateWorkflowDef(found);
@@ -3581,7 +3581,7 @@ public void testEventWorkflow() throws Exception {
 
     @Test
     public void testTaskWithCallbackAfterSecondsInWorkflow() throws Exception {
-        WorkflowDef workflowDef = metadataService.getWorkflowDef(LINEAR_WORKFLOW_T1_T2, 1);
+        WorkflowDef workflowDef = metadataService.getWorkflowDef(LINEAR_WORKFLOW_T1_T2, 1).get();
         assertNotNull(workflowDef);
 
         String workflowId = workflowExecutor.startWorkflow(workflowDef.getName(), workflowDef.getVersion(), "", new HashMap<>());

File: client/src/main/java/com/netflix/conductor/client/http/TaskClient.java
Patch:
@@ -225,6 +225,7 @@ public void updateTask(TaskResult taskResult, String taskType) {
                 taskResult.setReasonForIncompletion(String.format("The TaskResult payload: %d is greater than the permissible 3MB", taskResultSize));
                 taskResult.setStatus(TaskResult.Status.FAILED_WITH_TERMINAL_ERROR);
                 taskResult.setOutputData(null);
+                taskResult.setOutputMessage(null);
             }
         } catch (Exception e) {
             logger.error("Unable to parse the TaskResult: {}", taskResult);

File: common/src/main/java/com/netflix/conductor/common/metadata/events/EventExecution.java
Patch:
@@ -21,7 +21,7 @@
 import java.util.HashMap;
 import java.util.Map;
 
-import com.netflix.conductor.common.annotations.*;
+import com.github.vmg.protogen.annotations.*;
 import com.netflix.conductor.common.metadata.events.EventHandler.Action;
 
 /**

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/PollData.java
Patch:
@@ -1,7 +1,6 @@
 package com.netflix.conductor.common.metadata.tasks;
 
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 
 /**
  * Copyright 2016 Netflix, Inc.

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskDef.java
Patch:
@@ -23,9 +23,7 @@
 import java.util.List;
 import java.util.Map;
 
-import com.netflix.conductor.common.annotations.ProtoEnum;
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 import com.netflix.conductor.common.metadata.Auditable;
 
 /**

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskExecLog.java
Patch:
@@ -18,8 +18,7 @@
  */
 package com.netflix.conductor.common.metadata.tasks;
 
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 
 /**
  * @author Viren

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/DynamicForkJoinTask.java
Patch:
@@ -18,8 +18,7 @@
 import java.util.HashMap;
 import java.util.Map;
 
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
 
 @ProtoMessage

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/DynamicForkJoinTaskList.java
Patch:
@@ -15,8 +15,7 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 
 import java.util.ArrayList;
 import java.util.List;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/RerunWorkflowRequest.java
Patch:
@@ -15,8 +15,7 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 
 import java.util.Map;
 

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/StartWorkflowRequest.java
Patch:
@@ -1,7 +1,6 @@
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 
 import java.util.HashMap;
 import java.util.Map;

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/SubWorkflowParams.java
Patch:
@@ -18,8 +18,7 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 
 /**
  * @author Viren

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowDef.java
Patch:
@@ -25,8 +25,7 @@
 import java.util.Map;
 import java.util.Optional;
 
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 import com.netflix.conductor.common.metadata.Auditable;
 
 /**

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -18,9 +18,7 @@
  */
 package com.netflix.conductor.common.metadata.workflow;
 
-import com.netflix.conductor.common.annotations.ProtoEnum;
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 
 import java.util.Collection;
 import java.util.HashMap;

File: common/src/main/java/com/netflix/conductor/common/run/TaskSummary.java
Patch:
@@ -22,8 +22,7 @@
 import java.util.Date;
 import java.util.TimeZone;
 
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
 

File: common/src/main/java/com/netflix/conductor/common/run/Workflow.java
Patch:
@@ -22,9 +22,7 @@
 import java.util.Map;
 import java.util.Set;
 
-import com.netflix.conductor.common.annotations.ProtoEnum;
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 import com.netflix.conductor.common.metadata.Auditable;
 import com.netflix.conductor.common.metadata.tasks.Task;
 

File: common/src/main/java/com/netflix/conductor/common/run/WorkflowSummary.java
Patch:
@@ -23,8 +23,7 @@
 import java.util.TimeZone;
 import java.util.stream.Collectors;
 
-import com.netflix.conductor.common.annotations.ProtoField;
-import com.netflix.conductor.common.annotations.ProtoMessage;
+import com.github.vmg.protogen.annotations.*;
 import com.netflix.conductor.common.run.Workflow.WorkflowStatus;
 
 /**

File: core/src/main/java/com/netflix/conductor/core/events/ActionProcessor.java
Patch:
@@ -109,9 +109,10 @@ private Map<String, Object> completeTask(Action action, Object payload, TaskDeta
 			replaced.put("error", "No task found with reference name: " + taskRefName + ", workflowId: " + workflowId);
 			return replaced;
 		}
-		
+
 		task.setStatus(status);
 		task.setOutputData(replaced);
+		task.setOutputMessage(taskDetails.getOutputMessage());
 		task.getOutputData().put("conductor.event.messageId", messageId);
 		task.getOutputData().put("conductor.event.name", event);
 		

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAO.java
Patch:
@@ -223,6 +223,7 @@ public void updateTask(Task task) {
 			task.setReasonForIncompletion(String.format("Payload of the task: %s larger than the permissible %s bytes",
 					FileUtils.byteCountToDisplaySize(payload.length()), FileUtils.byteCountToDisplaySize(taskPayloadThreshold)));
 			task.setOutputData(null);
+			task.setOutputMessage(null);
 			task.setStatus(Status.FAILED_WITH_TERMINAL_ERROR);
 			payload = toJson(task);
 		}

File: server/src/main/java/com/netflix/conductor/bootstrap/BootstrapModule.java
Patch:
@@ -2,6 +2,7 @@
 
 import com.google.inject.AbstractModule;
 
+import com.netflix.conductor.common.utils.JsonMapperProvider;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.SystemPropertiesConfiguration;
 

File: server/src/main/java/com/netflix/conductor/server/ServerModule.java
Patch:
@@ -15,9 +15,11 @@
  */
 package com.netflix.conductor.server;
 
+import com.fasterxml.jackson.databind.ObjectMapper;
 import com.google.inject.AbstractModule;
 import com.google.inject.Scopes;
 
+import com.netflix.conductor.common.utils.JsonMapperProvider;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.CoreModule;
 import com.netflix.conductor.dyno.SystemPropertiesDynomiteConfiguration;
@@ -38,6 +40,7 @@ protected void configure() {
         install(new JettyModule());
         install(new GRPCModule());
 
+        bind(ObjectMapper.class).toProvider(JsonMapperProvider.class);
         bind(Configuration.class).to(SystemPropertiesDynomiteConfiguration.class);
         bind(ExecutorService.class).toProvider(ExecutorServiceProvider.class).in(Scopes.SINGLETON);
     }

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/TestModule.java
Patch:
@@ -15,11 +15,13 @@
  */
 package com.netflix.conductor.tests.utils;
 
+import com.fasterxml.jackson.databind.ObjectMapper;
 import com.google.inject.AbstractModule;
 import com.google.inject.Provides;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.CoreModule;
 import com.netflix.conductor.core.config.SystemPropertiesConfiguration;
+import com.netflix.conductor.common.utils.JsonMapperProvider;
 import com.netflix.conductor.dao.ExecutionDAO;
 import com.netflix.conductor.dao.IndexDAO;
 import com.netflix.conductor.dao.MetadataDAO;
@@ -81,6 +83,7 @@ public String getCurrentShard() {
         bind(JedisCommands.class).toProvider(InMemoryJedisProvider.class);
         install(new CoreModule());
         bind(UserTask.class).asEagerSingleton();
+        bind(ObjectMapper.class).toProvider(JsonMapperProvider.class);
     }
 
     @Provides

File: grpc/src/main/java/com/netflix/conductor/grpc/ProtoMapper.java
Patch:
@@ -35,7 +35,7 @@ private ProtoMapper() {}
      * value representable as a native JSON type. Consequently, this method expects
      * the given {@link Object} instance to be a Java object instance of JSON-native
      * value, namely: null, {@link Boolean}, {@link Double}, {@link String},
-     * {@link Map<String, Object>}, {@link List<Object>}.
+     * {@link Map}, {@link List}.
      *
      * Any other values will cause an exception to be thrown.
      * See {@link ProtoMapper#fromProto(Value)} for the reverse mapping.

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/MockIndexDAO.java
Patch:
@@ -126,7 +126,7 @@ public List<String> searchArchivableWorkflows(String indexName, long archiveTtlD
 	}
 
 	@Override
-	public List<String> searchRecentIncompletedWorkflows(String indexName, long lastModifiedHours) {
+	public List<String> searchRecentRunningWorkflows(int lastModifiedHours) {
 		return null;
 	}
 }

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/queue/DynoQueueDAO.java
Patch:
@@ -148,7 +148,7 @@ public boolean pushIfNotExists(String queueName, String id, long offsetTimeInSec
 	@Override
 	public List<String> pop(String queueName, int count, int timeout) {
 		List<Message> msg = queues.get(queueName).pop(count, timeout, TimeUnit.MILLISECONDS);
-		return msg.stream().map(m -> m.getId()).collect(Collectors.toList());
+		return msg.stream().map(Message::getId).collect(Collectors.toList());
 	}
 
 	@Override

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/TestModule.java
Patch:
@@ -19,6 +19,8 @@
 package com.netflix.conductor.tests.utils;
 
 import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashSet;
 import java.util.Set;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.atomic.AtomicInteger;
@@ -69,7 +71,7 @@ protected void configure() {
 			
 			@Override
 			public Set<String> getQueueShards() {
-				return Arrays.asList("a").stream().collect(Collectors.toSet());
+				return new HashSet<>(Collections.singletonList("a"));
 			}
 			
 			@Override

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/MockIndexDAO.java
Patch:
@@ -126,7 +126,7 @@ public List<String> searchArchivableWorkflows(String indexName, long archiveTtlD
 	}
 
 	@Override
-	public List<String> searchRecentIncompletedWorkflows(String indexName, long lastModifiedHours) {
+	public List<String> searchRecentRunningWorkflows(long lastModifiedHours) {
 		return null;
 	}
 }

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/MockIndexDAO.java
Patch:
@@ -126,7 +126,7 @@ public List<String> searchArchivableWorkflows(String indexName, long archiveTtlD
 	}
 
 	@Override
-	public List<String> searchRecentIncompletedWorkflows(String indexName, long lastModifiedHours) {
+	public List<String> searchRecentRunningWorkflows(long lastModifiedHours) {
 		return null;
 	}
 }

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/queue/DynoQueueDAO.java
Patch:
@@ -148,7 +148,7 @@ public boolean pushIfNotExists(String queueName, String id, long offsetTimeInSec
 	@Override
 	public List<String> pop(String queueName, int count, int timeout) {
 		List<Message> msg = queues.get(queueName).pop(count, timeout, TimeUnit.MILLISECONDS);
-		return msg.stream().map(m -> m.getId()).collect(Collectors.toList());
+		return msg.stream().map(Message::getId).collect(Collectors.toList());
 	}
 
 	@Override

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/TestModule.java
Patch:
@@ -19,6 +19,8 @@
 package com.netflix.conductor.tests.utils;
 
 import java.util.Arrays;
+import java.util.Collections;
+import java.util.HashSet;
 import java.util.Set;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.atomic.AtomicInteger;
@@ -69,7 +71,7 @@ protected void configure() {
 			
 			@Override
 			public Set<String> getQueueShards() {
-				return Arrays.asList("a").stream().collect(Collectors.toSet());
+				return new HashSet<>(Collections.singletonList("a"));
 			}
 			
 			@Override

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAO.java
Patch:
@@ -761,7 +761,7 @@ private void updateEventExecution(Connection connection, EventExecution eventExe
                 + "json_data = ?, "
                 + "modified_on = CURRENT_TIMESTAMP "
                 + "WHERE event_handler_name = ? "
-                + "AND execution_event = ? "
+                + "AND event_name = ? "
                 + "AND message_id = ? "
                 + "AND execution_id = ?";
         //@formatter:on

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/service/MetadataServiceImpl.java
Patch:
@@ -55,8 +55,7 @@ public void updateWorkflows(MetadataServicePb.UpdateWorkflowsRequest req, Stream
 
     @Override
     public void getWorkflow(MetadataServicePb.GetWorkflowRequest req, StreamObserver<WorkflowDefPb.WorkflowDef> response) {
-        // TODO: req.getVersion optional
-        WorkflowDef def = service.getWorkflowDef(req.getName(), req.getVersion());
+        WorkflowDef def = service.getWorkflowDef(req.getName(), grpcHelper.optional(req.getVersion()));
         if (def != null) {
             response.onNext(protoMapper.toProto(def));
             response.onCompleted();

File: server/src/main/java/com/netflix/conductor/bootstrap/ModulesProvider.java
Patch:
@@ -70,7 +70,6 @@ private List<AbstractModule> selectModulesToLoad() {
                 break;
 
             case MYSQL:
-                modules.add(new MySQLWorkflowModule());
                 modules.add(new MySQLWorkflowModule());
                 logger.info("Starting conductor server using MySQL data store", database);
                 break;

File: server/src/main/java/com/netflix/conductor/jetty/server/JettyServerConfiguration.java
Patch:
@@ -4,7 +4,7 @@
 
 public interface JettyServerConfiguration extends Configuration {
     String ENABLED_PROPERTY_NAME = "conductor.jetty.server.enabled";
-    boolean ENABLED_DEFAULT_VALUE = false;
+    boolean ENABLED_DEFAULT_VALUE = true;
 
     String PORT_PROPERTY_NAME = "conductor.jetty.server.port";
     int PORT_DEFAULT_VALUE = 8080;

File: mysql-persistence/src/main/java/com/netflix/conductor/sql/ExecuteFunction.java
Patch:
@@ -1,4 +1,6 @@
-package com.netflix.conductor.dao.mysql;
+package com.netflix.conductor.sql;
+
+import com.netflix.conductor.dao.mysql.Query;
 
 import java.sql.SQLException;
 

File: mysql-persistence/src/main/java/com/netflix/conductor/sql/QueryFunction.java
Patch:
@@ -1,4 +1,6 @@
-package com.netflix.conductor.dao.mysql;
+package com.netflix.conductor.sql;
+
+import com.netflix.conductor.dao.mysql.Query;
 
 import java.sql.SQLException;
 

File: mysql-persistence/src/main/java/com/netflix/conductor/sql/ResultSetHandler.java
Patch:
@@ -1,4 +1,6 @@
-package com.netflix.conductor.dao.mysql;
+package com.netflix.conductor.sql;
+
+import com.netflix.conductor.dao.mysql.Query;
 
 import java.sql.ResultSet;
 import java.sql.SQLException;

File: mysql-persistence/src/main/java/com/netflix/conductor/sql/TransactionalFunction.java
Patch:
@@ -1,4 +1,4 @@
-package com.netflix.conductor.dao.mysql;
+package com.netflix.conductor.sql;
 
 import java.sql.Connection;
 import java.sql.SQLException;

File: server/src/main/java/com/netflix/conductor/server/ServerModule.java
Patch:
@@ -30,7 +30,7 @@
 import com.netflix.conductor.dao.RedisWorkflowModule;
 import com.netflix.conductor.dao.es.index.ElasticSearchModule;
 import com.netflix.conductor.dao.es5.index.ElasticSearchModuleV5;
-import com.netflix.conductor.dao.mysql.MySQLWorkflowModule;
+import com.netflix.conductor.mysql.MySQLWorkflowModule;
 import com.netflix.dyno.connectionpool.HostSupplier;
 
 import java.util.List;

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/AbstractProtoMapper.java
Patch:
@@ -482,6 +482,7 @@ public TaskResultPb.TaskResult.Status toProto(TaskResult.Status from) {
         switch (from) {
             case IN_PROGRESS: to = TaskResultPb.TaskResult.Status.IN_PROGRESS; break;
             case FAILED: to = TaskResultPb.TaskResult.Status.FAILED; break;
+            case FAILED_WITH_TERMINAL_ERROR: to = TaskResultPb.TaskResult.Status.FAILED_WITH_TERMINAL_ERROR; break;
             case COMPLETED: to = TaskResultPb.TaskResult.Status.COMPLETED; break;
             case SCHEDULED: to = TaskResultPb.TaskResult.Status.SCHEDULED; break;
             default: throw new IllegalArgumentException("Unexpected enum constant: " + from);
@@ -494,6 +495,7 @@ public TaskResult.Status fromProto(TaskResultPb.TaskResult.Status from) {
         switch (from) {
             case IN_PROGRESS: to = TaskResult.Status.IN_PROGRESS; break;
             case FAILED: to = TaskResult.Status.FAILED; break;
+            case FAILED_WITH_TERMINAL_ERROR: to = TaskResult.Status.FAILED_WITH_TERMINAL_ERROR; break;
             case COMPLETED: to = TaskResult.Status.COMPLETED; break;
             case SCHEDULED: to = TaskResult.Status.SCHEDULED; break;
             default: throw new IllegalArgumentException("Unexpected enum constant: " + from);

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -838,9 +838,6 @@ boolean scheduleTask(Workflow workflow, List<Task> tasks) throws Exception {
             task.setStartTime(System.currentTimeMillis());
             if (!workflowSystemTask.isAsync()) {
                 workflowSystemTask.start(workflow, task, this);
-                if (task.getStatus().isTerminal()) {
-                    task.setExecuted(true);
-                }
                 startedSystemTasks = true;
                 executionDAO.updateTask(task);
             } else {

File: common/src/main/java/com/netflix/conductor/common/metadata/events/EventExecution.java
Patch:
@@ -54,7 +54,7 @@ public enum Status {
 	@ProtoField(id = 6)
 	private Status status;
 
-	// TODO: Proto
+	@ProtoField(id = 7)
 	private Action.Type action;
 
 	@ProtoField(id = 8)

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLMetadataDAOTest.java
Patch:
@@ -177,9 +177,9 @@ public void testEventHandlers() {
         eh.setName(UUID.randomUUID().toString());
         eh.setActive(false);
         EventHandler.Action action = new EventHandler.Action();
-        action.setAction(EventHandler.Action.Type.start_workflow);
-        action.setStart_workflow(new EventHandler.StartWorkflow());
-        action.getStart_workflow().setName("workflow_x");
+        action.setAction(EventHandler.Action.Type.START_WORKFLOW);
+        action.setStartWorkflow(new EventHandler.StartWorkflow());
+        action.getStartWorkflow().setName("workflow_x");
         eh.getActions().add(action);
         eh.setEvent(event1);
 

File: redis-persistence/src/test/java/com/netflix/conductor/dao/dynomite/RedisMetadataDAOTest.java
Patch:
@@ -225,9 +225,9 @@ public void testEventHandlers() {
 		eh.setName(UUID.randomUUID().toString());
 		eh.setActive(false);
 		Action action = new Action();
-		action.setAction(Type.start_workflow);
-		action.setStart_workflow(new StartWorkflow());
-		action.getStart_workflow().setName("workflow_x");
+		action.setAction(Type.START_WORKFLOW);
+		action.setStartWorkflow(new StartWorkflow());
+		action.getStartWorkflow().setName("workflow_x");
 		eh.getActions().add(action);
 		eh.setEvent(event1);
 		

File: grpc-server/src/main/java/com/netflix/conductor/grpc/server/MetadataServiceImpl.java
Patch:
@@ -30,7 +30,7 @@ public void createWorkflow(WorkflowDefPb.WorkflowDef req, StreamObserver<Empty>
             service.registerWorkflowDef(ProtoMapper.fromProto(req));
             response.onCompleted();
         } catch (Exception e) {
-            response.onError(e);
+            GRPCUtil.onError(response, e);
         }
     }
 
@@ -45,7 +45,7 @@ public void updateWorkflows(MetadataServicePb.UpdateWorkflowsRequest req, Stream
             service.updateWorkflowDef(workflows);
             response.onCompleted();
         } catch (Exception e) {
-            response.onError(e);
+            GRPCUtil.onError(response, e);
         }
     }
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -836,9 +836,6 @@ boolean scheduleTask(Workflow workflow, List<Task> tasks) throws Exception {
             task.setStartTime(System.currentTimeMillis());
             if (!workflowSystemTask.isAsync()) {
                 workflowSystemTask.start(workflow, task, this);
-                if (task.getStatus().isTerminal()) {
-                    task.setExecuted(true);
-                }
                 startedSystemTasks = true;
                 executionDAO.updateTask(task);
             } else {

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -836,6 +836,9 @@ boolean scheduleTask(Workflow workflow, List<Task> tasks) throws Exception {
             task.setStartTime(System.currentTimeMillis());
             if (!workflowSystemTask.isAsync()) {
                 workflowSystemTask.start(workflow, task, this);
+                if (task.getStatus().isTerminal()) {
+                    task.setExecuted(true);
+                }
                 startedSystemTasks = true;
                 executionDAO.updateTask(task);
             } else {

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -836,6 +836,9 @@ boolean scheduleTask(Workflow workflow, List<Task> tasks) throws Exception {
             task.setStartTime(System.currentTimeMillis());
             if (!workflowSystemTask.isAsync()) {
                 workflowSystemTask.start(workflow, task, this);
+                if (task.getStatus().isTerminal()) {
+                    task.setExecuted(true);
+                }
                 startedSystemTasks = true;
                 executionDAO.updateTask(task);
             } else {

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/AbstractNode.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 import java.io.InputStream;
 import java.math.BigDecimal;

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/BooleanOp.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 import java.io.InputStream;
 

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/ComparisonOp.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 import java.io.InputStream;
 

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/ConstValue.java
Patch:
@@ -16,13 +16,11 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 import java.io.InputStream;
 
 
-
-
 /**
  * @author Viren
  * Constant value can be:

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/FilterProvider.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 import org.elasticsearch.index.query.QueryBuilder;
 

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/FunctionThrowingException.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 /**
  * @author Viren

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/GroupedExpression.java
Patch:
@@ -16,12 +16,12 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
-
-import java.io.InputStream;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 import org.elasticsearch.index.query.QueryBuilder;
 
+import java.io.InputStream;
+
 /**
  * @author Viren
  * 

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/ListConst.java
Patch:
@@ -16,15 +16,13 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 import java.io.InputStream;
 import java.util.LinkedList;
 import java.util.List;
 
 
-
-
 /**
  * @author Viren
  * List of constants

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/Name.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 import java.io.InputStream;
 

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/NameValue.java
Patch:
@@ -16,13 +16,13 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
-
-import java.io.InputStream;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 import org.elasticsearch.index.query.QueryBuilder;
 import org.elasticsearch.index.query.QueryBuilders;
 
+import java.io.InputStream;
+
 /**
  * @author Viren
  * <pre>

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/ParserException.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 /**
  * @author Viren

File: es2-persistence/src/main/java/com/netflix/conductor/dao/es/index/query/parser/Range.java
Patch:
@@ -16,13 +16,11 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
+package com.netflix.conductor.dao.es.index.query.parser;
 
 import java.io.InputStream;
 
 
-
-
 /**
  * @author Viren
  * 

File: es2-persistence/src/test/java/com/netflix/conductor/dao/es/index/query/parser/AbstractParserTest.java
Patch:
@@ -1,4 +1,4 @@
-/**
+package com.netflix.conductor.dao.es.index.query.parser; /**
  * Copyright 2016 Netflix, Inc.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
@@ -16,7 +16,6 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
 
 import java.io.BufferedInputStream;
 import java.io.ByteArrayInputStream;

File: es2-persistence/src/test/java/com/netflix/conductor/dao/es/index/query/parser/TestBooleanOp.java
Patch:
@@ -1,4 +1,4 @@
-/**
+package com.netflix.conductor.dao.es.index.query.parser; /**
  * Copyright 2016 Netflix, Inc.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
@@ -16,7 +16,6 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
 
 import org.junit.Test;
 

File: es2-persistence/src/test/java/com/netflix/conductor/dao/es/index/query/parser/TestComparisonOp.java
Patch:
@@ -1,4 +1,4 @@
-/**
+package com.netflix.conductor.dao.es.index.query.parser; /**
  * Copyright 2016 Netflix, Inc.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
@@ -16,7 +16,6 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
 
 import org.junit.Test;
 

File: es2-persistence/src/test/java/com/netflix/conductor/dao/es/index/query/parser/TestConstValue.java
Patch:
@@ -1,4 +1,4 @@
-/**
+package com.netflix.conductor.dao.es.index.query.parser; /**
  * Copyright 2016 Netflix, Inc.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
@@ -16,7 +16,6 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
 
 import org.junit.Test;
 

File: es2-persistence/src/test/java/com/netflix/conductor/dao/es/index/query/parser/TestExpression.java
Patch:
@@ -1,4 +1,4 @@
-/**
+package com.netflix.conductor.dao.es.index.query.parser; /**
  * Copyright 2016 Netflix, Inc.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
@@ -16,7 +16,6 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
 
 import org.junit.Test;
 

File: es2-persistence/src/test/java/com/netflix/conductor/dao/es/index/query/parser/TestGroupedExpression.java
Patch:
@@ -1,4 +1,4 @@
-/**
+package com.netflix.conductor.dao.es.index.query.parser; /**
  * Copyright 2016 Netflix, Inc.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
@@ -16,7 +16,6 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
 
 import org.junit.Test;
 

File: es2-persistence/src/test/java/com/netflix/conductor/dao/es/index/query/parser/TestName.java
Patch:
@@ -1,4 +1,4 @@
-/**
+package com.netflix.conductor.dao.es.index.query.parser; /**
  * Copyright 2016 Netflix, Inc.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
@@ -16,7 +16,6 @@
 /**
  * 
  */
-package com.netflix.conductor.dao.index.query.parser;
 
 import org.junit.Test;
 

File: es5-persistence/src/test/java/com/netflix/conductor/dao/es5/index/query/parser/TestBooleanOp.java
Patch:
@@ -20,9 +20,6 @@
 
 import org.junit.Test;
 
-import com.netflix.conductor.dao.es5.index.query.parser.BooleanOp;
-import com.netflix.conductor.dao.es5.index.query.parser.ParserException;
-
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 

File: es5-persistence/src/test/java/com/netflix/conductor/dao/es5/index/query/parser/TestComparisonOp.java
Patch:
@@ -20,9 +20,6 @@
 
 import org.junit.Test;
 
-import com.netflix.conductor.dao.es5.index.query.parser.ComparisonOp;
-import com.netflix.conductor.dao.es5.index.query.parser.ParserException;
-
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 

File: es5-persistence/src/test/java/com/netflix/conductor/dao/es5/index/query/parser/TestName.java
Patch:
@@ -20,8 +20,6 @@
 
 import org.junit.Test;
 
-import com.netflix.conductor.dao.es5.index.query.parser.Name;
-
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/End2EndTests.java
Patch:
@@ -59,6 +59,7 @@ public class End2EndTests {
 		System.setProperty("workflow.elasticsearch.index.name", "conductor");
 		System.setProperty("workflow.namespace.prefix", "integration-test");
 		System.setProperty("db", "memory");
+		System.setProperty("workflow.elasticsearch.version", "5");
 	}
 	
 	private static TaskClient tc;
@@ -68,7 +69,7 @@ public class End2EndTests {
 	
 	@BeforeClass
 	public static void setup() throws Exception {
-		
+
 		ConductorServer server = new ConductorServer(new ConductorConfig());
 		server.start(8080, false);
 		

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAO.java
Patch:
@@ -528,6 +528,8 @@ private void updateTask(Connection connection, Task task) {
             removeTaskInProgress(connection, task);
         }
 
+        addWorkflowToTaskMapping(connection, task);
+
         indexer.indexTask(task);
     }
 

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisMetadataDAO.java
Patch:
@@ -103,7 +103,7 @@ public TaskDef getTaskDef(String name) {
 		return taskDef;
 	}
 	
-	public TaskDef getTaskDefFromDB(String name) {
+	private TaskDef getTaskDefFromDB(String name) {
 		Preconditions.checkNotNull(name, "TaskDef name cannot be null");
 		
 		TaskDef taskDef = null;

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAO.java
Patch:
@@ -528,8 +528,6 @@ private void updateTask(Connection connection, Task task) {
             removeTaskInProgress(connection, task);
         }
 
-        addWorkflowToTaskMapping(connection, task);
-
         indexer.indexTask(task);
     }
 

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisMetadataDAO.java
Patch:
@@ -103,7 +103,7 @@ public TaskDef getTaskDef(String name) {
 		return taskDef;
 	}
 	
-	private TaskDef getTaskDefFromDB(String name) {
+	public TaskDef getTaskDefFromDB(String name) {
 		Preconditions.checkNotNull(name, "TaskDef name cannot be null");
 		
 		TaskDef taskDef = null;

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAO.java
Patch:
@@ -528,6 +528,8 @@ private void updateTask(Connection connection, Task task) {
             removeTaskInProgress(connection, task);
         }
 
+        addWorkflowToTaskMapping(connection, task);
+
         indexer.indexTask(task);
     }
 

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisMetadataDAO.java
Patch:
@@ -103,7 +103,7 @@ public TaskDef getTaskDef(String name) {
 		return taskDef;
 	}
 	
-	public TaskDef getTaskDefFromDB(String name) {
+	private TaskDef getTaskDefFromDB(String name) {
 		Preconditions.checkNotNull(name, "TaskDef name cannot be null");
 		
 		TaskDef taskDef = null;

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAO.java
Patch:
@@ -528,6 +528,8 @@ private void updateTask(Connection connection, Task task) {
             removeTaskInProgress(connection, task);
         }
 
+        addWorkflowToTaskMapping(connection, task);
+
         indexer.indexTask(task);
     }
 

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisMetadataDAO.java
Patch:
@@ -103,7 +103,7 @@ public TaskDef getTaskDef(String name) {
 		return taskDef;
 	}
 	
-	public TaskDef getTaskDefFromDB(String name) {
+	private TaskDef getTaskDefFromDB(String name) {
 		Preconditions.checkNotNull(name, "TaskDef name cannot be null");
 		
 		TaskDef taskDef = null;

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAO.java
Patch:
@@ -759,7 +759,7 @@ private void updateEventExecution(Connection connection, EventExecution eventExe
                 + "json_data = ?, "
                 + "modified_on = CURRENT_TIMESTAMP "
                 + "WHERE event_handler_name = ? "
-                + "AND execution_event = ? "
+                + "AND event_name = ? "
                 + "AND message_id = ? "
                 + "AND execution_id = ?";
         //@formatter:on

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -28,7 +28,6 @@
 import javax.inject.Inject;
 import javax.inject.Singleton;
 
-import org.apache.commons.lang.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/nats/NATSObservableQueue.java
Patch:
@@ -18,7 +18,7 @@
  */
 package com.netflix.conductor.contribs.queue.nats;
 
-import org.apache.commons.lang.StringUtils;
+import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/nats/NATSStreamObservableQueue.java
Patch:
@@ -20,7 +20,7 @@
 
 import java.util.UUID;
 
-import org.apache.commons.lang.StringUtils;
+import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: core/src/main/java/com/netflix/conductor/core/events/EventProcessor.java
Patch:
@@ -34,7 +34,7 @@
 import javax.inject.Inject;
 import javax.inject.Singleton;
 
-import org.apache.commons.lang.StringUtils;
+import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -42,7 +42,8 @@
 import com.netflix.conductor.dao.MetadataDAO;
 import com.netflix.conductor.dao.QueueDAO;
 import com.netflix.conductor.metrics.Monitors;
-import org.apache.commons.lang.StringUtils;
+
+import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SubWorkflow.java
Patch:
@@ -20,7 +20,7 @@
 
 import java.util.Map;
 
-import org.apache.commons.lang.StringUtils;
+import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: es5-persistence/src/main/java/com/netflix/conductor/dao/es5/index/ElasticSearchDAO.java
Patch:
@@ -37,7 +37,7 @@
 import com.netflix.conductor.dao.es5.index.query.parser.ParserException;
 import com.netflix.conductor.metrics.Monitors;
 import org.apache.commons.io.IOUtils;
-import org.apache.commons.lang.StringUtils;
+import org.apache.commons.lang3.StringUtils;
 import org.elasticsearch.ResourceAlreadyExistsException;
 import org.elasticsearch.action.DocWriteResponse;
 import org.elasticsearch.action.admin.indices.mapping.get.GetMappingsResponse;

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLQueueDAO.java
Patch:
@@ -8,6 +8,9 @@
 import com.netflix.conductor.core.events.queue.Message;
 import com.netflix.conductor.core.execution.ApplicationException;
 import com.netflix.conductor.dao.QueueDAO;
+
+import org.apache.commons.lang3.time.DateUtils;
+
 import java.sql.Connection;
 import java.util.ArrayList;
 import java.util.Calendar;
@@ -18,7 +21,6 @@
 import java.util.concurrent.TimeUnit;
 import javax.inject.Inject;
 import javax.sql.DataSource;
-import org.apache.commons.lang.time.DateUtils;
 
 public class MySQLQueueDAO extends MySQLBaseDAO implements QueueDAO {
 

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/Query.java
Patch:
@@ -17,7 +17,8 @@
 import java.sql.Date;
 import java.util.List;
 import java.util.concurrent.atomic.AtomicInteger;
-import org.apache.commons.lang.math.NumberUtils;
+
+import org.apache.commons.lang3.math.NumberUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAOTest.java
Patch:
@@ -23,7 +23,8 @@
 import java.util.Set;
 import java.util.UUID;
 import java.util.stream.Collectors;
-import org.apache.commons.lang.builder.EqualsBuilder;
+
+import org.apache.commons.lang3.builder.EqualsBuilder;
 import org.junit.Before;
 import org.junit.Rule;
 import org.junit.Test;

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLMetadataDAOTest.java
Patch:
@@ -13,7 +13,8 @@
 import java.util.Set;
 import java.util.UUID;
 import java.util.stream.Collectors;
-import org.apache.commons.lang.builder.EqualsBuilder;
+
+import org.apache.commons.lang3.builder.EqualsBuilder;
 import org.junit.Before;
 import org.junit.Test;
 import org.junit.runner.RunWith;

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAOTest.java
Patch:
@@ -388,7 +388,7 @@ public void test() throws Exception {
 			dao.createWorkflow(workflow);
 		}
 
-		List<Workflow> bycorrelationId = dao.getWorkflowsByCorrelationId("corr001");
+		List<Workflow> bycorrelationId = dao.getWorkflowsByCorrelationId("corr001", true);
 		assertNotNull(bycorrelationId);
 		assertEquals(10, bycorrelationId.size());
 

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAOTest.java
Patch:
@@ -388,7 +388,7 @@ public void test() throws Exception {
 			dao.createWorkflow(workflow);
 		}
 
-		List<Workflow> bycorrelationId = dao.getWorkflowsByCorrelationId("corr001");
+		List<Workflow> bycorrelationId = dao.getWorkflowsByCorrelationId("corr001", true);
 		assertNotNull(bycorrelationId);
 		assertEquals(10, bycorrelationId.size());
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -297,10 +297,10 @@ public void retry(String workflowId) throws Exception {
 
     }
 
-    public List<Workflow> getStatusByCorrelationId(String workflowName, String correlationId, boolean includeClosed) throws Exception {
+    public List<Workflow> getStatusByCorrelationId(String workflowName, String correlationId, boolean includeClosed, boolean includeTasks) throws Exception {
         Preconditions.checkNotNull(correlationId, "correlation id is missing");
         Preconditions.checkNotNull(workflowName, "workflow name is missing");
-        List<Workflow> workflows = executionDAO.getWorkflowsByCorrelationId(correlationId);
+        List<Workflow> workflows = executionDAO.getWorkflowsByCorrelationId(correlationId, includeTasks);
         List<Workflow> result = new LinkedList<>();
         for (Workflow wf : workflows) {
             if (wf.getWorkflowType().equals(workflowName) && (includeClosed || wf.getStatus().equals(WorkflowStatus.RUNNING))) {

File: mysql-persistence/src/test/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAOTest.java
Patch:
@@ -388,7 +388,7 @@ public void test() throws Exception {
 			dao.createWorkflow(workflow);
 		}
 
-		List<Workflow> bycorrelationId = dao.getWorkflowsByCorrelationId("corr001");
+		List<Workflow> bycorrelationId = dao.getWorkflowsByCorrelationId("corr001", true);
 		assertNotNull(bycorrelationId);
 		assertEquals(10, bycorrelationId.size());
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -297,10 +297,10 @@ public void retry(String workflowId) throws Exception {
 
     }
 
-    public List<Workflow> getStatusByCorrelationId(String workflowName, String correlationId, boolean includeClosed) throws Exception {
+    public List<Workflow> getStatusByCorrelationId(String workflowName, String correlationId, boolean includeClosed, boolean includeTasks) throws Exception {
         Preconditions.checkNotNull(correlationId, "correlation id is missing");
         Preconditions.checkNotNull(workflowName, "workflow name is missing");
-        List<Workflow> workflows = executionDAO.getWorkflowsByCorrelationId(correlationId);
+        List<Workflow> workflows = executionDAO.getWorkflowsByCorrelationId(correlationId, includeTasks);
         List<Workflow> result = new LinkedList<>();
         for (Workflow wf : workflows) {
             if (wf.getWorkflowType().equals(workflowName) && (includeClosed || wf.getStatus().equals(WorkflowStatus.RUNNING))) {

File: redis-persistence/src/main/java/com/netflix/conductor/dao/index/ElasticSearchDAO.java
Patch:
@@ -284,7 +284,7 @@ public CompletableFuture<Void> asyncAddTaskExecutionLogs(List<TaskExecLog> logs)
 		return CompletableFuture.runAsync(() -> addTaskExecutionLogs(logs), executorService);
 	}
 
-
+	@Override
 	public List<TaskExecLog> getTaskExecutionLogs(String taskId) {
 		
 		try {
@@ -359,7 +359,7 @@ private void updateWithRetry(UpdateRequest request, String operationDescription)
 					null, RETRY_COUNT, operationDescription, "updateWithRetry");
 		} catch (Exception e) {
 			Monitors.error(className, "index");
-			logger.error("Indexing failed for {}, {}", request.index(), request.type(), e.getMessage());
+			logger.error("Indexing failed for {}, {}", request.index(), request.type(), e);
 		}
 	}
 	

File: common/src/main/java/com/netflix/conductor/common/utils/RetryUtil.java
Patch:
@@ -102,7 +102,7 @@ public T retryOnException(Supplier<T> supplierCommand,
                 .withRetryListener(new RetryListener() {
                     @Override
                     public <V> void onRetry(Attempt<V> attempt) {
-                        logger.debug("Attempt # {}, millis since first attempt {}. Operation {}:{}",
+                        logger.debug("Attempt # {}, {} millis since first attempt. Operation: {}, description:{}",
                                 attempt.getAttemptNumber(), attempt.getDelaySinceFirstAttempt(), operationName, shortDescription);
                         internalNumberOfRetries.incrementAndGet();
                     }

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -80,6 +80,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         decisionTask.setTaskDefName(SystemTaskType.DECISION.name());
         decisionTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         decisionTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        decisionTask.setWorkflowType(workflowInstance.getWorkflowType());
         decisionTask.setCorrelationId(workflowInstance.getCorrelationId());
         decisionTask.setScheduledTime(System.currentTimeMillis());
         decisionTask.setEndTime(System.currentTimeMillis());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DynamicTaskMapper.java
Patch:
@@ -80,6 +80,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         dynamicTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         dynamicTask.setInputData(input);
         dynamicTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        dynamicTask.setWorkflowType(workflowInstance.getWorkflowType());
         dynamicTask.setStatus(Task.Status.SCHEDULED);
         dynamicTask.setTaskType(taskToSchedule.getType());
         dynamicTask.setTaskDefName(taskToSchedule.getName());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/EventTaskMapper.java
Patch:
@@ -57,6 +57,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         eventTask.setTaskDefName(taskToSchedule.getName());
         eventTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         eventTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        eventTask.setWorkflowType(workflowInstance.getWorkflowType());
         eventTask.setCorrelationId(workflowInstance.getCorrelationId());
         eventTask.setScheduledTime(System.currentTimeMillis());
         eventTask.setEndTime(System.currentTimeMillis());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinDynamicTaskMapper.java
Patch:
@@ -205,6 +205,7 @@ Task createJoinTask(Workflow workflowInstance, WorkflowTask joinWorkflowTask, Ha
         joinTask.setTaskDefName(SystemTaskType.JOIN.name());
         joinTask.setReferenceTaskName(joinWorkflowTask.getTaskReferenceName());
         joinTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        joinTask.setWorkflowType(workflowInstance.getWorkflowType());
         joinTask.setCorrelationId(workflowInstance.getCorrelationId());
         joinTask.setScheduledTime(System.currentTimeMillis());
         joinTask.setEndTime(System.currentTimeMillis());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapper.java
Patch:
@@ -71,6 +71,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         forkTask.setTaskDefName(SystemTaskType.FORK.name());
         forkTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         forkTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        forkTask.setWorkflowType(workflowInstance.getWorkflowType());
         forkTask.setCorrelationId(workflowInstance.getCorrelationId());
         forkTask.setScheduledTime(System.currentTimeMillis());
         forkTask.setEndTime(System.currentTimeMillis());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/JoinTaskMapper.java
Patch:
@@ -62,6 +62,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         joinTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         joinTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
         joinTask.setCorrelationId(workflowInstance.getCorrelationId());
+        joinTask.setWorkflowType(workflowInstance.getWorkflowType());
         joinTask.setScheduledTime(System.currentTimeMillis());
         joinTask.setEndTime(System.currentTimeMillis());
         joinTask.setInputData(joinInput);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SimpleTaskMapper.java
Patch:
@@ -82,6 +82,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         simpleTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         simpleTask.setInputData(input);
         simpleTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        simpleTask.setWorkflowType(workflowInstance.getWorkflowType());
         simpleTask.setStatus(Task.Status.SCHEDULED);
         simpleTask.setTaskType(taskToSchedule.getName());
         simpleTask.setTaskDefName(taskToSchedule.getName());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SubWorkflowTaskMapper.java
Patch:
@@ -71,6 +71,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         subWorkflowTask.setTaskDefName(taskToSchedule.getName());
         subWorkflowTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         subWorkflowTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        subWorkflowTask.setWorkflowType(workflowInstance.getWorkflowType());
         subWorkflowTask.setCorrelationId(workflowInstance.getCorrelationId());
         subWorkflowTask.setScheduledTime(System.currentTimeMillis());
         subWorkflowTask.setEndTime(System.currentTimeMillis());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/UserDefinedTaskMapper.java
Patch:
@@ -79,6 +79,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         userDefinedTask.setTaskDefName(taskToSchedule.getName());
         userDefinedTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         userDefinedTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        userDefinedTask.setWorkflowType(workflowInstance.getWorkflowType());
         userDefinedTask.setCorrelationId(workflowInstance.getCorrelationId());
         userDefinedTask.setScheduledTime(System.currentTimeMillis());
         userDefinedTask.setTaskId(taskId);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapper.java
Patch:
@@ -60,6 +60,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         waitTask.setTaskDefName(taskMapperContext.getTaskToSchedule().getName());
         waitTask.setReferenceTaskName(taskMapperContext.getTaskToSchedule().getTaskReferenceName());
         waitTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        waitTask.setWorkflowType(workflowInstance.getWorkflowType());
         waitTask.setCorrelationId(workflowInstance.getCorrelationId());
         waitTask.setScheduledTime(System.currentTimeMillis());
         waitTask.setEndTime(System.currentTimeMillis());

File: common/src/main/java/com/netflix/conductor/common/utils/RetryUtil.java
Patch:
@@ -102,7 +102,7 @@ public T retryOnException(Supplier<T> supplierCommand,
                 .withRetryListener(new RetryListener() {
                     @Override
                     public <V> void onRetry(Attempt<V> attempt) {
-                        logger.debug("Attempt # {}, millis since first attempt {}. Operation {}:{}",
+                        logger.debug("Attempt # {}, {} millis since first attempt. Operation: {}, description:{}",
                                 attempt.getAttemptNumber(), attempt.getDelaySinceFirstAttempt(), operationName, shortDescription);
                         internalNumberOfRetries.incrementAndGet();
                     }

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DecisionTaskMapper.java
Patch:
@@ -80,6 +80,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         decisionTask.setTaskDefName(SystemTaskType.DECISION.name());
         decisionTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         decisionTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        decisionTask.setWorkflowType(workflowInstance.getWorkflowType());
         decisionTask.setCorrelationId(workflowInstance.getCorrelationId());
         decisionTask.setScheduledTime(System.currentTimeMillis());
         decisionTask.setEndTime(System.currentTimeMillis());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/DynamicTaskMapper.java
Patch:
@@ -80,6 +80,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         dynamicTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         dynamicTask.setInputData(input);
         dynamicTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        dynamicTask.setWorkflowType(workflowInstance.getWorkflowType());
         dynamicTask.setStatus(Task.Status.SCHEDULED);
         dynamicTask.setTaskType(taskToSchedule.getType());
         dynamicTask.setTaskDefName(taskToSchedule.getName());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/EventTaskMapper.java
Patch:
@@ -57,6 +57,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         eventTask.setTaskDefName(taskToSchedule.getName());
         eventTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         eventTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        eventTask.setWorkflowType(workflowInstance.getWorkflowType());
         eventTask.setCorrelationId(workflowInstance.getCorrelationId());
         eventTask.setScheduledTime(System.currentTimeMillis());
         eventTask.setEndTime(System.currentTimeMillis());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinDynamicTaskMapper.java
Patch:
@@ -205,6 +205,7 @@ Task createJoinTask(Workflow workflowInstance, WorkflowTask joinWorkflowTask, Ha
         joinTask.setTaskDefName(SystemTaskType.JOIN.name());
         joinTask.setReferenceTaskName(joinWorkflowTask.getTaskReferenceName());
         joinTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        joinTask.setWorkflowType(workflowInstance.getWorkflowType());
         joinTask.setCorrelationId(workflowInstance.getCorrelationId());
         joinTask.setScheduledTime(System.currentTimeMillis());
         joinTask.setEndTime(System.currentTimeMillis());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapper.java
Patch:
@@ -71,6 +71,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         forkTask.setTaskDefName(SystemTaskType.FORK.name());
         forkTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         forkTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        forkTask.setWorkflowType(workflowInstance.getWorkflowType());
         forkTask.setCorrelationId(workflowInstance.getCorrelationId());
         forkTask.setScheduledTime(System.currentTimeMillis());
         forkTask.setEndTime(System.currentTimeMillis());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/JoinTaskMapper.java
Patch:
@@ -62,6 +62,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         joinTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         joinTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
         joinTask.setCorrelationId(workflowInstance.getCorrelationId());
+        joinTask.setWorkflowType(workflowInstance.getWorkflowType());
         joinTask.setScheduledTime(System.currentTimeMillis());
         joinTask.setEndTime(System.currentTimeMillis());
         joinTask.setInputData(joinInput);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SimpleTaskMapper.java
Patch:
@@ -82,6 +82,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         simpleTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         simpleTask.setInputData(input);
         simpleTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        simpleTask.setWorkflowType(workflowInstance.getWorkflowType());
         simpleTask.setStatus(Task.Status.SCHEDULED);
         simpleTask.setTaskType(taskToSchedule.getName());
         simpleTask.setTaskDefName(taskToSchedule.getName());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SubWorkflowTaskMapper.java
Patch:
@@ -71,6 +71,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         subWorkflowTask.setTaskDefName(taskToSchedule.getName());
         subWorkflowTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         subWorkflowTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        subWorkflowTask.setWorkflowType(workflowInstance.getWorkflowType());
         subWorkflowTask.setCorrelationId(workflowInstance.getCorrelationId());
         subWorkflowTask.setScheduledTime(System.currentTimeMillis());
         subWorkflowTask.setEndTime(System.currentTimeMillis());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/UserDefinedTaskMapper.java
Patch:
@@ -79,6 +79,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws Ter
         userDefinedTask.setTaskDefName(taskToSchedule.getName());
         userDefinedTask.setReferenceTaskName(taskToSchedule.getTaskReferenceName());
         userDefinedTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        userDefinedTask.setWorkflowType(workflowInstance.getWorkflowType());
         userDefinedTask.setCorrelationId(workflowInstance.getCorrelationId());
         userDefinedTask.setScheduledTime(System.currentTimeMillis());
         userDefinedTask.setTaskId(taskId);

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/WaitTaskMapper.java
Patch:
@@ -60,6 +60,7 @@ public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) {
         waitTask.setTaskDefName(taskMapperContext.getTaskToSchedule().getName());
         waitTask.setReferenceTaskName(taskMapperContext.getTaskToSchedule().getTaskReferenceName());
         waitTask.setWorkflowInstanceId(workflowInstance.getWorkflowId());
+        waitTask.setWorkflowType(workflowInstance.getWorkflowType());
         waitTask.setCorrelationId(workflowInstance.getCorrelationId());
         waitTask.setScheduledTime(System.currentTimeMillis());
         waitTask.setEndTime(System.currentTimeMillis());

File: client/src/main/java/com/netflix/conductor/client/worker/Worker.java
Patch:
@@ -1,4 +1,4 @@
-/**
+/*
  * Copyright 2016 Netflix, Inc.
  * <p>
  * Licensed under the Apache License, Version 2.0 (the "License");

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -429,7 +429,7 @@ public void updateTask(TaskResult result) throws Exception {
         if (workflowInstance.getStatus().isTerminal()) {
             // Workflow is in terminal state
             queueDAO.remove(taskQueueName, result.getTaskId());
-            logger.debug("Workflow: {} is in terminal state Task: {} removed from Queue: {} during update task", task, workflowInstance, taskQueueName);
+            logger.debug("Workflow: {} is in terminal state Task: {} removed from Queue: {} during update task", workflowInstance, task, taskQueueName);
             if (!task.getStatus().isTerminal()) {
                 task.setStatus(Status.COMPLETED);
             }

File: core/src/main/java/com/netflix/conductor/core/events/ActionProcessor.java
Patch:
@@ -43,7 +43,7 @@
 /**
  * @author Viren
  * Action Processor subscribes to the Event Actions queue and processes the actions (e.g. start workflow etc)
- * <p><font color=red>Warning</font> This is a work in progress and may be changed in future.  Not ready for production yet.
+ * <p><b>Warning:</b> This is a work in progress and may be changed in future.  Not ready for production yet.
  */
 @Singleton
 public class ActionProcessor {

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -685,6 +685,7 @@ public void executeSystemTask(WorkflowSystemTask systemTask, String taskId, int
         try {
 
             Task task = executionDAO.getTask(taskId);
+            logger.info("Task: {} fetched from execution DAO for TaskId: {}", task, taskId);
             if (task.getStatus().isTerminal()) {
                 //Tune the SystemTaskWorkerCoordinator's queues - if the queue size is very big this can happen!
                 logger.info("Task {}/{} was already completed.", task.getTaskType(), task.getTaskId());

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/SystemTaskWorkerCoordinator.java
Patch:
@@ -147,6 +147,7 @@ private void pollAndExecute(WorkflowSystemTask systemTask) {
 			Monitors.recordTaskPoll(className);
 			logger.debug("Polling for {}, got {}", name, polled.size());
 			for(String task : polled) {
+				logger.debug("Task: {} being sent to the workflow executor", task);
 				try {
 					es.submit(()->executor.executeSystemTask(systemTask, task, unackTimeout));
 				}catch(RejectedExecutionException ree) {

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -392,7 +392,7 @@ public void log(String taskId, String log) {
 	 * @return Execution Logs (logged by the worker)
 	 */
 	public List<TaskExecLog> getTaskLogs(String taskId) {
-		return indexer.getTaskLogs(taskId);		
+		return indexer.getTaskExecutionLogs(taskId);
 	}
 	
 }

File: core/src/main/java/com/netflix/conductor/core/events/ActionProcessor.java
Patch:
@@ -43,7 +43,7 @@
 /**
  * @author Viren
  * Action Processor subscribes to the Event Actions queue and processes the actions (e.g. start workflow etc)
- * <p><font color=red>Warning</font> This is a work in progress and may be changed in future.  Not ready for production yet.
+ * <p><b>Warning:</b> This is a work in progress and may be changed in future.  Not ready for production yet.
  */
 @Singleton
 public class ActionProcessor {

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -392,7 +392,7 @@ public void log(String taskId, String log) {
 	 * @return Execution Logs (logged by the worker)
 	 */
 	public List<TaskExecLog> getTaskLogs(String taskId) {
-		return indexer.getTaskLogs(taskId);		
+		return indexer.getTaskExecutionLogs(taskId);
 	}
 	
 }

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -324,7 +324,7 @@ public void completeWorkflow(Workflow wf) throws Exception {
 
         if (workflow.getStatus().equals(WorkflowStatus.COMPLETED)) {
             executionDAO.removeFromPendingWorkflow(workflow.getWorkflowType(), workflow.getWorkflowId());
-            logger.info("Workflow has already been completed.  Current status=" + workflow.getStatus() + ", workflowId=" + wf.getWorkflowId());
+            logger.info("Workflow has already been completed.  Current status={}, workflowId= {}", workflow.getStatus(), wf.getWorkflowId());
             return;
         }
 
@@ -429,7 +429,7 @@ public void updateTask(TaskResult result) throws Exception {
         if (workflowInstance.getStatus().isTerminal()) {
             // Workflow is in terminal state
             queueDAO.remove(taskQueueName, result.getTaskId());
-            logger.debug("Workflow: {} is in terminal state Task: {} removed from Queue: {} during update task", task, workflowInstance);
+            logger.debug("Workflow: {} is in terminal state Task: {} removed from Queue: {} during update task", task, workflowInstance, taskQueueName);
             if (!task.getStatus().isTerminal()) {
                 task.setStatus(Status.COMPLETED);
             }
@@ -472,7 +472,7 @@ public void updateTask(TaskResult result) throws Exception {
         if (Status.FAILED.equals(task.getStatus())) {
             workflowInstance.getFailedReferenceTaskNames().add(task.getReferenceTaskName());
             executionDAO.updateWorkflow(workflowInstance);
-            logger.debug("Task: {} has a FAILED status and the Workflow has been updated with failed task reference");
+            logger.debug("Task: {} has a FAILED status and the Workflow has been updated with failed task reference", task);
         }
 
         result.getLogs().forEach(tl -> tl.setTaskId(task.getTaskId()));

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -149,7 +149,7 @@ public String updateTask(TaskResult task) throws Exception {
 	@ApiOperation("Ack Task is recieved")
 	@Consumes({ MediaType.WILDCARD })
 	public String ack(@PathParam("taskId") String taskId, @QueryParam("workerid") String workerId) throws Exception {
-		return "" + taskService.ackTaskRecieved(taskId, workerId);
+		return "" + taskService.ackTaskReceived(taskId);
 	}
 	
 	@POST

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -149,7 +149,7 @@ public String updateTask(TaskResult task) throws Exception {
 	@ApiOperation("Ack Task is recieved")
 	@Consumes({ MediaType.WILDCARD })
 	public String ack(@PathParam("taskId") String taskId, @QueryParam("workerid") String workerId) throws Exception {
-		return "" + taskService.ackTaskRecieved(taskId, workerId);
+		return "" + taskService.ackTaskReceived(taskId);
 	}
 	
 	@POST

File: contribs/src/main/java/com/netflix/conductor/core/events/nats/NATSEventQueueProvider.java
Patch:
@@ -63,8 +63,6 @@ public NATSEventQueueProvider(Configuration config) {
         
         // Init NATS API
         factory = new ConnectionFactory(props);
-        
-        EventQueues.registerProvider("nats", this);
         logger.info("NATS Event Queue Provider initialized...");
     }
     

File: contribs/src/main/java/com/netflix/conductor/core/events/nats/NATSStreamEventQueueProvider.java
Patch:
@@ -57,8 +57,6 @@ public NATSStreamEventQueueProvider(Configuration config) {
         
         logger.info("NATS Streaming clusterId=" + clusterId +
                 ", natsUrl=" + natsUrl + ", durableName=" + durableName);
-        
-        EventQueues.registerProvider("nats_stream", this);
         logger.info("NATS Stream Event Queue Provider initialized...");
     }
     

File: contribs/src/main/java/com/netflix/conductor/core/events/sqs/SQSEventQueueProvider.java
Patch:
@@ -45,7 +45,6 @@ public class SQSEventQueueProvider implements EventQueueProvider {
 	@Inject
 	public SQSEventQueueProvider(AmazonSQSClient client) {
 		this.client = client;
-		EventQueues.registerProvider("sqs", this);
 	}
 	
 	@Override

File: core/src/main/java/com/netflix/conductor/core/events/queue/dyno/DynoEventQueueProvider.java
Patch:
@@ -47,7 +47,6 @@ public class DynoEventQueueProvider implements EventQueueProvider {
 	public DynoEventQueueProvider(QueueDAO dao, Configuration config) {
 		this.dao = dao;
 		this.config = config;
-		EventQueues.registerProvider("conductor", this);
 	}
 	
 	@Override

File: core/src/test/java/com/netflix/conductor/core/events/MockQueueProvider.java
Patch:
@@ -30,7 +30,6 @@ public class MockQueueProvider implements EventQueueProvider {
 	
 	public MockQueueProvider(String type) {
 		this.type = type;
-		EventQueues.registerProvider(type, this);
 	}
 	
 	

File: core/src/test/java/com/netflix/conductor/core/events/TestEventProcessor.java
Patch:
@@ -27,6 +27,7 @@
 import static org.mockito.Mockito.when;
 
 import java.util.Arrays;
+import java.util.HashMap;
 import java.util.UUID;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
@@ -73,9 +74,9 @@ public void testEventProcessor() throws Exception {
 		when(queue.getName()).thenReturn(queueURI);
 		when(queue.getType()).thenReturn("sqs");
 		when(provider.getQueue(queueURI)).thenReturn(queue);
+		EventQueues.providers = new HashMap<>();
 		
-		
-		EventQueues.registerProvider("sqs", provider);
+		EventQueues.providers.put("sqs", provider);
 		
 		EventHandler eh = new EventHandler();
 		eh.setName(UUID.randomUUID().toString());

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/ForkJoinTaskMapper.java
Patch:
@@ -50,7 +50,7 @@ public class ForkJoinTaskMapper implements TaskMapper {
      * Might be any kind of task, but in most cases is a UserDefinedTask with {@link Task.Status#SCHEDULED}
      * </li>
      * </ul>
-     * @throws TerminateWorkflow: When the task after {@link WorkflowTask.Type#FORK_JOIN} is not a {@link WorkflowTask.Type#JOIN}
+     * @throws TerminateWorkflow When the task after {@link WorkflowTask.Type#FORK_JOIN} is not a {@link WorkflowTask.Type#JOIN}
      */
     @Override
     public List<Task> getMappedTasks(TaskMapperContext taskMapperContext) throws TerminateWorkflow {

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/SimpleTaskMapper.java
Patch:
@@ -56,7 +56,7 @@ public SimpleTaskMapper(ParametersUtils parametersUtils, MetadataDAO metadataDAO
      * to a {@link Task}
      *
      * @param taskMapperContext: A wrapper class containing the {@link WorkflowTask}, {@link WorkflowDef}, {@link Workflow} and a string representation of the TaskId
-     * @throws TerminateWorkflow: In case if the task definition does not exist in the {@link MetadataDAO}
+     * @throws TerminateWorkflow In case if the task definition does not exist in the {@link MetadataDAO}
      * @return: a List with just one simple task
      */
     @Override

File: core/src/main/java/com/netflix/conductor/core/execution/mapper/UserDefinedTaskMapper.java
Patch:
@@ -53,7 +53,7 @@ public UserDefinedTaskMapper(ParametersUtils parametersUtils, MetadataDAO metada
      * to a {@link Task} in a {@link Task.Status#SCHEDULED} state
      *
      * @param taskMapperContext: A wrapper class containing the {@link WorkflowTask}, {@link WorkflowDef}, {@link Workflow} and a string representation of the TaskId
-     * @throws TerminateWorkflow: In case if the task definition does not exist in the {@link MetadataDAO}
+     * @throws TerminateWorkflow In case if the task definition does not exist in the {@link MetadataDAO}
      * @return: a List with just one User defined task
      */
     @Override

File: redis-persistence/src/main/java/com/netflix/conductor/dao/index/ElasticSearchDAO.java
Patch:
@@ -303,7 +303,7 @@ public List<TaskExecLog> getTaskLogs(String taskId) {
 			QueryStringQueryBuilder stringQuery = QueryBuilders.queryStringQuery("*");
 			BoolQueryBuilder fq = QueryBuilders.boolQuery().must(stringQuery).must(filterQuery);
 			
-			final SearchRequestBuilder srb = client.prepareSearch(logIndexPrefix + "*").setQuery(fq).setTypes(TASK_DOC_TYPE).addSort(SortBuilders.fieldSort("createdTime").order(SortOrder.ASC));
+			final SearchRequestBuilder srb = client.prepareSearch(logIndexPrefix + "*").setQuery(fq).setTypes(TASK_DOC_TYPE).addSort(SortBuilders.fieldSort("createdTime").order(SortOrder.ASC).unmappedType("long"));
 			SearchResponse response = srb.execute().actionGet();
 			SearchHit[] hits = response.getHits().getHits();
 			List<TaskExecLog> logs = new ArrayList<>(hits.length);

File: contribs/src/main/java/com/netflix/conductor/core/events/nats/NATSEventQueueProvider.java
Patch:
@@ -22,7 +22,6 @@
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.events.EventQueues;
-import com.netflix.conductor.core.events.EventQueues.QueueType;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
 import io.nats.client.ConnectionFactory;
 import org.slf4j.Logger;
@@ -65,7 +64,7 @@ public NATSEventQueueProvider(Configuration config) {
         // Init NATS API
         factory = new ConnectionFactory(props);
         
-        EventQueues.registerProvider(QueueType.nats, this);
+        EventQueues.registerProvider("nats", this);
         logger.info("NATS Event Queue Provider initialized...");
     }
     

File: contribs/src/main/java/com/netflix/conductor/core/events/sqs/SQSEventQueueProvider.java
Patch:
@@ -29,7 +29,6 @@
 import com.netflix.conductor.contribs.queue.sqs.SQSObservableQueue.Builder;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.events.EventQueues;
-import com.netflix.conductor.core.events.EventQueues.QueueType;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
 
 /**
@@ -46,7 +45,7 @@ public class SQSEventQueueProvider implements EventQueueProvider {
 	@Inject
 	public SQSEventQueueProvider(AmazonSQSClient client) {
 		this.client = client;
-		EventQueues.registerProvider(QueueType.sqs, this);
+		EventQueues.registerProvider("sqs", this);
 	}
 	
 	@Override

File: core/src/main/java/com/netflix/conductor/core/events/queue/dyno/DynoEventQueueProvider.java
Patch:
@@ -27,7 +27,6 @@
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.events.EventQueues;
-import com.netflix.conductor.core.events.EventQueues.QueueType;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
 import com.netflix.conductor.dao.QueueDAO;
 
@@ -48,7 +47,7 @@ public class DynoEventQueueProvider implements EventQueueProvider {
 	public DynoEventQueueProvider(QueueDAO dao, Configuration config) {
 		this.dao = dao;
 		this.config = config;
-		EventQueues.registerProvider(QueueType.conductor, this);
+		EventQueues.registerProvider("conductor", this);
 	}
 	
 	@Override

File: core/src/test/java/com/netflix/conductor/core/events/TestEventProcessor.java
Patch:
@@ -42,7 +42,6 @@
 import com.netflix.conductor.common.metadata.events.EventHandler.Action.Type;
 import com.netflix.conductor.common.metadata.events.EventHandler.StartWorkflow;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
-import com.netflix.conductor.core.events.EventQueues.QueueType;
 import com.netflix.conductor.core.events.queue.Message;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
 import com.netflix.conductor.core.execution.TestConfiguration;
@@ -76,7 +75,7 @@ public void testEventProcessor() throws Exception {
 		when(provider.getQueue(queueURI)).thenReturn(queue);
 		
 		
-		EventQueues.registerProvider(QueueType.sqs, provider);
+		EventQueues.registerProvider("sqs", provider);
 		
 		EventHandler eh = new EventHandler();
 		eh.setName(UUID.randomUUID().toString());

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestEvent.java
Patch:
@@ -39,7 +39,6 @@
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
-import com.netflix.conductor.core.events.EventQueues.QueueType;
 import com.netflix.conductor.core.events.MockQueueProvider;
 import com.netflix.conductor.core.events.queue.Message;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
@@ -56,8 +55,8 @@ public class TestEvent {
 
 	@Before
 	public void setup() {
-		new MockQueueProvider(QueueType.sqs);
-		new MockQueueProvider(QueueType.conductor);
+		new MockQueueProvider("sqs");
+		new MockQueueProvider("conductor");
 	}
 	
 	@Test

File: client/src/main/java/com/netflix/conductor/client/http/WorkflowClient.java
Patch:
@@ -125,11 +125,11 @@ public List<String> getRunningWorkflow(String workflowName, Integer version) {
 	}
 
 	public void pauseWorkflow(String workflowId) {
-		put("workflow/{workflowId}/pause", null, workflowId);		
+		put("workflow/{workflowId}/pause", null, null, workflowId);		
 	}
 
 	public void resumeWorkflow(String workflowId) {
-		put("workflow/{workflowId}/resume", null, workflowId);		
+		put("workflow/{workflowId}/resume", null, null, workflowId);		
 	}
 	
 	public void restart(String workflowId) {

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowServiceTest.java
Patch:
@@ -2022,6 +2022,7 @@ private void validate(String wfid, String[] sequence, String[] executedTasks, in
 		}
 	}
 
+	
 	private Task getTask(String tt) throws Exception {
 		Task task = null;
 		int count = 2;

File: contribs/src/main/java/com/netflix/conductor/core/events/sqs/SQSEventQueueProvider.java
Patch:
@@ -29,7 +29,6 @@
 import com.netflix.conductor.contribs.queue.sqs.SQSObservableQueue.Builder;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.events.EventQueues;
-import com.netflix.conductor.core.events.EventQueues.QueueType;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
 
 /**
@@ -46,7 +45,7 @@ public class SQSEventQueueProvider implements EventQueueProvider {
 	@Inject
 	public SQSEventQueueProvider(AmazonSQSClient client) {
 		this.client = client;
-		EventQueues.registerProvider(QueueType.sqs, this);
+		EventQueues.registerProvider("sqs", this);
 	}
 	
 	@Override

File: core/src/main/java/com/netflix/conductor/core/events/queue/dyno/DynoEventQueueProvider.java
Patch:
@@ -27,7 +27,6 @@
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.events.EventQueueProvider;
 import com.netflix.conductor.core.events.EventQueues;
-import com.netflix.conductor.core.events.EventQueues.QueueType;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
 import com.netflix.conductor.dao.QueueDAO;
 
@@ -48,7 +47,7 @@ public class DynoEventQueueProvider implements EventQueueProvider {
 	public DynoEventQueueProvider(QueueDAO dao, Configuration config) {
 		this.dao = dao;
 		this.config = config;
-		EventQueues.registerProvider(QueueType.conductor, this);
+		EventQueues.registerProvider("conductor", this);
 	}
 	
 	@Override

File: core/src/test/java/com/netflix/conductor/core/events/TestEventProcessor.java
Patch:
@@ -42,7 +42,6 @@
 import com.netflix.conductor.common.metadata.events.EventHandler.Action.Type;
 import com.netflix.conductor.common.metadata.events.EventHandler.StartWorkflow;
 import com.netflix.conductor.common.metadata.workflow.WorkflowDef;
-import com.netflix.conductor.core.events.EventQueues.QueueType;
 import com.netflix.conductor.core.events.queue.Message;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
 import com.netflix.conductor.core.execution.TestConfiguration;
@@ -76,7 +75,7 @@ public void testEventProcessor() throws Exception {
 		when(provider.getQueue(queueURI)).thenReturn(queue);
 		
 		
-		EventQueues.registerProvider(QueueType.sqs, provider);
+		EventQueues.registerProvider("sqs", provider);
 		
 		EventHandler eh = new EventHandler();
 		eh.setName(UUID.randomUUID().toString());

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestEvent.java
Patch:
@@ -39,7 +39,6 @@
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.run.Workflow;
-import com.netflix.conductor.core.events.EventQueues.QueueType;
 import com.netflix.conductor.core.events.MockQueueProvider;
 import com.netflix.conductor.core.events.queue.Message;
 import com.netflix.conductor.core.events.queue.ObservableQueue;
@@ -56,8 +55,8 @@ public class TestEvent {
 
 	@Before
 	public void setup() {
-		new MockQueueProvider(QueueType.sqs);
-		new MockQueueProvider(QueueType.conductor);
+		new MockQueueProvider("sqs");
+		new MockQueueProvider("conductor");
 	}
 	
 	@Test

File: jersey/src/main/java/com/netflix/conductor/server/resources/MetadataResource.java
Patch:
@@ -65,7 +65,7 @@ public void create(WorkflowDef def) throws Exception{
 	}
 	
 	@PUT
-	@Path("/workflow")
+	@Path("/workflows")
 	@ApiOperation("Create or update multi  workflow definition")
 	public void update(List<WorkflowDef> defs) throws Exception{
 		service.updateWorkflowDef(defs);

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLExecutionDAO.java
Patch:
@@ -174,7 +174,7 @@ public void removeTask(String taskId) {
 			return;
 		}
 
-		String taskKey = task.getReferenceTaskName() + "" + task.getRetryCount();
+		String taskKey = task.getReferenceTaskName() + "_" + task.getRetryCount();
 
 		withTransaction(connection -> {
 			removeScheduledTask(connection, task, taskKey);

File: mysql-persistence/src/main/java/com/netflix/conductor/dao/mysql/MySQLQueueDAO.java
Patch:
@@ -184,7 +184,6 @@ public boolean setOffsetTime(String queueName, String messageId, long offsetTime
 						.getResult()
 		) == 1;
 	}
-
 	private boolean existsMessage(Connection connection, String queueName, String messageId) {
 		String EXISTS_MESSAGE = "SELECT EXISTS(SELECT 1 FROM queue_message WHERE queue_name = :queueName AND message_id = :messageId)";
 		return connection.createQuery(EXISTS_MESSAGE).addParameter("queueName", queueName).addParameter("messageId", messageId).executeScalar(Boolean.class);

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAO.java
Patch:
@@ -38,6 +38,7 @@
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
 import com.netflix.conductor.common.metadata.tasks.TaskExecLog;
+import com.netflix.conductor.common.run.SearchResult;
 import com.netflix.conductor.common.run.Workflow;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.events.queue.Message;
@@ -423,8 +424,8 @@ public List<Workflow> getWorkflowsByCorrelationId(String correlationId) {
 		
 		Preconditions.checkNotNull(correlationId, "correlationId cannot be null");
 		List<Workflow> workflows = new LinkedList<Workflow>();
-
-		Set<String> workflowIds = dynoClient.smembers(nsKey(CORR_ID_TO_WORKFLOWS, correlationId));
+		SearchResult<String> result = indexer.searchWorkflows("correlationId='" + correlationId + "'", "*", 0, 10000, null);
+		List<String> workflowIds = result.getResults();
 		for(String wfId : workflowIds) {
 			workflows.add(getWorkflow(wfId));
 		}

File: redis-persistence/src/test/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAOTest.java
Patch:
@@ -518,10 +518,11 @@ public void test() throws Exception {
 			dao.createWorkflow(workflow);
 		}
 
+		/*
 		List<Workflow> bycorrelationId = dao.getWorkflowsByCorrelationId("corr001");
 		assertNotNull(bycorrelationId);
 		assertEquals(10, bycorrelationId.size());
-
+		 */
 		long count = dao.getPendingWorkflowCount(workflowName);
 		assertEquals(10, count);
 

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -393,8 +393,9 @@ public void setTaskDefName(String taskDefName) {
 	 * 
 	 * @return the timeout for task to send response.  After this timeout, the task will be re-queued
 	 */
+	@Deprecated
 	public int getResponseTimeoutSeconds() {
-		return responseTimeoutSeconds;
+		return 0;
 	}
 	
 	/**

File: core/src/test/java/com/netflix/conductor/core/execution/TestDeciderOutcomes.java
Patch:
@@ -47,10 +47,8 @@
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask;
 import com.netflix.conductor.common.metadata.workflow.WorkflowTask.Type;
 import com.netflix.conductor.common.run.Workflow;
-import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.execution.DeciderService.DeciderOutcome;
 import com.netflix.conductor.core.execution.tasks.Join;
-import com.netflix.conductor.dao.ExecutionDAO;
 import com.netflix.conductor.dao.MetadataDAO;
 
 /**

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -293,7 +293,8 @@ private String getNextTasksToBeScheduled(WorkflowDef def, Workflow workflow, Tas
 		
 	}
 
-	private Task retry(TaskDef taskDef, WorkflowTask workflowTask, Task task, Workflow workflow) throws TerminateWorkflow {
+	@VisibleForTesting
+	Task retry(TaskDef taskDef, WorkflowTask workflowTask, Task task, Workflow workflow) throws TerminateWorkflow {
 
 		int retryCount = task.getRetryCount();
 		if (!task.getStatus().isRetriable() || SystemTaskType.isBuiltIn(task.getTaskType()) || taskDef == null || taskDef.getRetryCount() <= retryCount) {

File: client/src/test/java/com/netflix/conductor/client/worker/TestPropertyFactory.java
Patch:
@@ -61,8 +61,6 @@ public void test() {
 		assertEquals("domainA", PropertyFactory.getString("workerA", "domain", null));	
 		assertEquals("domainB", PropertyFactory.getString("workerB", "domain", null));	
 		assertEquals(null, PropertyFactory.getString("workerC", "domain", null));	// Non Existent
-
-		assertEquals("test-group-", PropertyFactory.getString("", "workerNamePrefix", "workflow-worker-"));
 	}
 	
 	@Test

File: client/src/test/java/com/netflix/conductor/client/worker/TestPropertyFactory.java
Patch:
@@ -61,8 +61,6 @@ public void test() {
 		assertEquals("domainA", PropertyFactory.getString("workerA", "domain", null));	
 		assertEquals("domainB", PropertyFactory.getString("workerB", "domain", null));	
 		assertEquals(null, PropertyFactory.getString("workerC", "domain", null));	// Non Existent
-
-		assertEquals("test-group-", PropertyFactory.getString("", "workerNamePrefix", "workflow-worker-"));
 	}
 	
 	@Test

File: client/src/main/java/com/netflix/conductor/client/task/WorkflowTaskCoordinator.java
Patch:
@@ -243,7 +243,7 @@ public synchronized void init() {
 			@Override
 			public Thread newThread(Runnable r) {
 				Thread t = new Thread(r);
-				t.setName("workflow-worker-" + count.getAndIncrement());
+				t.setName(PropertyFactory.getString("", "workerNamePrefix", "workflow-worker-") + count.getAndIncrement());
 				return t;
 			}
 		});

File: client/src/test/java/com/netflix/conductor/client/worker/TestPropertyFactory.java
Patch:
@@ -62,7 +62,7 @@ public void test() {
 		assertEquals("domainB", PropertyFactory.getString("workerB", "domain", null));	
 		assertEquals(null, PropertyFactory.getString("workerC", "domain", null));	// Non Existent
 
-
+		assertEquals("test-group-", PropertyFactory.getString("", "workerNamePrefix", "workflow-worker-"));
 	}
 	
 	@Test

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -549,6 +549,9 @@ private Task getDynamicTasks(WorkflowDef def, Workflow workflow, WorkflowTask ta
 			Map<String, Object> input = getTaskInput(taskToSchedule.getInputParameters(), workflow, null, null);
 			Object paramValue = input.get(paramName);
 			DynamicForkJoinTaskList dynForkTasks0 = om.convertValue(paramValue, DynamicForkJoinTaskList.class);
+			if(dynForkTasks0 == null) {
+				throw new TerminateWorkflow("Dynamic tasks could not be created.  The value of " + paramName + " from task's input " + input + " has no dynamic tasks to be scheduled");
+			}
 			for( DynamicForkJoinTask dt : dynForkTasks0.getDynamicTasks()) {
 				WorkflowTask wft = new WorkflowTask();
 				wft.setTaskReferenceName(dt.getReferenceName());

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -176,9 +176,9 @@ public Task getPendingTaskForWorkflow(String taskReferenceName, String workflowI
 
 	public boolean ackTaskRecieved(String taskId, String consumerId) throws Exception {
 		Task task = getTask(taskId);
-		String queueName = QueueUtils.getQueueName(task);
 
 		if (task != null) {
+			String queueName = QueueUtils.getQueueName(task);
 			if(task.getResponseTimeoutSeconds() > 0) {
 				logger.debug("Adding task " + queueName + "/" + taskId + " to be requeued if no response received " + task.getResponseTimeoutSeconds());
 				return queue.setUnackTimeout(queueName, task.getTaskId(), 1000 * task.getResponseTimeoutSeconds());		//Value is in millisecond

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -549,6 +549,9 @@ private Task getDynamicTasks(WorkflowDef def, Workflow workflow, WorkflowTask ta
 			Map<String, Object> input = getTaskInput(taskToSchedule.getInputParameters(), workflow, null, null);
 			Object paramValue = input.get(paramName);
 			DynamicForkJoinTaskList dynForkTasks0 = om.convertValue(paramValue, DynamicForkJoinTaskList.class);
+			if(dynForkTasks0 == null) {
+				throw new TerminateWorkflow("Dynamic tasks could not be created.  The value of " + paramName + " from task's input " + input + " has no dynamic tasks to be scheduled");
+			}
 			for( DynamicForkJoinTask dt : dynForkTasks0.getDynamicTasks()) {
 				WorkflowTask wft = new WorkflowTask();
 				wft.setTaskReferenceName(dt.getReferenceName());

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -176,9 +176,9 @@ public Task getPendingTaskForWorkflow(String taskReferenceName, String workflowI
 
 	public boolean ackTaskRecieved(String taskId, String consumerId) throws Exception {
 		Task task = getTask(taskId);
-		String queueName = QueueUtils.getQueueName(task);
 
 		if (task != null) {
+			String queueName = QueueUtils.getQueueName(task);
 			if(task.getResponseTimeoutSeconds() > 0) {
 				logger.debug("Adding task " + queueName + "/" + taskId + " to be requeued if no response received " + task.getResponseTimeoutSeconds());
 				return queue.setUnackTimeout(queueName, task.getTaskId(), 1000 * task.getResponseTimeoutSeconds());		//Value is in millisecond

File: client/src/main/java/com/netflix/conductor/client/task/WorkflowTaskCoordinator.java
Patch:
@@ -243,7 +243,7 @@ public synchronized void init() {
 			@Override
 			public Thread newThread(Runnable r) {
 				Thread t = new Thread(r);
-				t.setName("workflow-worker-" + count.getAndIncrement());
+				t.setName(PropertyFactory.getString("", "workerNamePrefix", "workflow-worker-") + count.getAndIncrement());
 				return t;
 			}
 		});

File: client/src/test/java/com/netflix/conductor/client/worker/TestPropertyFactory.java
Patch:
@@ -62,7 +62,7 @@ public void test() {
 		assertEquals("domainB", PropertyFactory.getString("workerB", "domain", null));	
 		assertEquals(null, PropertyFactory.getString("workerC", "domain", null));	// Non Existent
 
-
+		assertEquals("test-group-", PropertyFactory.getString("", "workerNamePrefix", "workflow-worker-"));
 	}
 	
 	@Test

File: client/src/main/java/com/netflix/conductor/client/task/WorkflowTaskCoordinator.java
Patch:
@@ -243,7 +243,7 @@ public synchronized void init() {
 			@Override
 			public Thread newThread(Runnable r) {
 				Thread t = new Thread(r);
-				t.setName("workflow-worker-" + count.getAndIncrement());
+				t.setName(PropertyFactory.getString("", "workerNamePrefix", "workflow-worker-") + count.getAndIncrement());
 				return t;
 			}
 		});

File: client/src/test/java/com/netflix/conductor/client/worker/TestPropertyFactory.java
Patch:
@@ -62,7 +62,7 @@ public void test() {
 		assertEquals("domainB", PropertyFactory.getString("workerB", "domain", null));	
 		assertEquals(null, PropertyFactory.getString("workerC", "domain", null));	// Non Existent
 
-
+		assertEquals("test-group-", PropertyFactory.getString("", "workerNamePrefix", "workflow-worker-"));
 	}
 	
 	@Test

File: server/src/main/java/com/netflix/conductor/server/ConductorServer.java
Patch:
@@ -41,7 +41,7 @@
 import com.google.inject.servlet.GuiceFilter;
 import com.netflix.conductor.common.metadata.tasks.TaskDef;
 import com.netflix.conductor.redis.utils.JedisMock;
-import com.netflix.conductor.server.es.EmbeddedElasticSearch;
+import com.netflix.conductor.dao.es.EmbeddedElasticSearch;
 import com.netflix.dyno.connectionpool.Host;
 import com.netflix.dyno.connectionpool.Host.Status;
 import com.netflix.dyno.connectionpool.HostSupplier;

File: server/src/main/java/com/netflix/conductor/server/ServerModule.java
Patch:
@@ -27,6 +27,7 @@
 import com.google.inject.Provides;
 import com.netflix.conductor.contribs.http.HttpTask;
 import com.netflix.conductor.contribs.http.RestClientManager;
+import com.netflix.conductor.contribs.json.JsonTransform;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.CoreModule;
 import com.netflix.conductor.dao.ExecutionDAO;
@@ -97,6 +98,7 @@ protected void configure() {
 		install(new CoreModule());
 		install(new JerseyModule());
 		new HttpTask(new RestClientManager(), config);
+		new JsonTransform();
 		List<AbstractModule> additionalModules = config.getAdditionalModules();
 		if(additionalModules != null) {
 			for(AbstractModule additionalModule : additionalModules) {

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -360,7 +360,7 @@ public void addMessage(String queue, Message msg) {
 	public void log(String taskId, String log) {
 		TaskExecLog executionLog = new TaskExecLog();
 		executionLog.setTaskId(taskId);
-		executionLog.getLogs().add(log);
+		executionLog.setLog(log);
 		executionLog.setCreatedTime(System.currentTimeMillis());
 		edao.addTaskExecLog(Arrays.asList(executionLog));
 	}

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -16,6 +16,7 @@
 package com.netflix.conductor.service;
 
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.HashMap;
 import java.util.LinkedList;
 import java.util.List;
@@ -361,7 +362,7 @@ public void log(String taskId, String log) {
 		executionLog.setTaskId(taskId);
 		executionLog.getLogs().add(log);
 		executionLog.setCreatedTime(System.currentTimeMillis());
-		edao.addTaskExecLog(executionLog);
+		edao.addTaskExecLog(Arrays.asList(executionLog));
 	}
 	
 	/**

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/MockIndexDAO.java
Patch:
@@ -58,7 +58,8 @@ public void index(Task task) {
 	}
 	
 	@Override
-	public void add(TaskExecLog log) {
+	public void add(List<TaskExecLog> logs) {
+		
 	}
 	
 	@Override

File: server/src/main/java/com/netflix/conductor/server/ServerModule.java
Patch:
@@ -27,6 +27,7 @@
 import com.google.inject.Provides;
 import com.netflix.conductor.contribs.http.HttpTask;
 import com.netflix.conductor.contribs.http.RestClientManager;
+import com.netflix.conductor.contribs.json.JsonTransform;
 import com.netflix.conductor.core.config.Configuration;
 import com.netflix.conductor.core.config.CoreModule;
 import com.netflix.conductor.dao.ExecutionDAO;
@@ -97,6 +98,7 @@ protected void configure() {
 		install(new CoreModule());
 		install(new JerseyModule());
 		new HttpTask(new RestClientManager(), config);
+		new JsonTransform();
 		List<AbstractModule> additionalModules = config.getAdditionalModules();
 		if(additionalModules != null) {
 			for(AbstractModule additionalModule : additionalModules) {

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/TaskExecLog.java
Patch:
@@ -18,6 +18,7 @@
  */
 package com.netflix.conductor.common.metadata.tasks;
 
+import java.util.LinkedList;
 import java.util.List;
 
 /**
@@ -26,7 +27,7 @@
  */
 public class TaskExecLog {
 	
-	private List<String> logs;
+	private List<String> logs = new LinkedList<>();
 	
 	private String taskId;
 	

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -506,7 +506,7 @@ public WorkflowTask getWorkflowTask() {
 	
 	/**
 	 * 
-	 * @param workflowTask
+	 * @param workflowTask Task definition
 	 */
 	public void setWorkflowTask(WorkflowTask workflowTask) {
 		this.workflowTask = workflowTask;

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -514,7 +514,7 @@ private List<Task> getTasksToBeScheduled(WorkflowDef def, Workflow workflow, Wor
 				break;
 			case WAIT:				
 				Map<String, Object> waitTaskInput = pu.getTaskInputV2(taskToSchedule.getInputParameters(), workflow, taskId, null);
-				Task waitTask = SystemTask.waitTask(workflow, workflow.getCorrelationId(), taskToSchedule, waitTaskInput);
+				Task waitTask = SystemTask.waitTask(workflow, taskId, taskToSchedule, waitTaskInput);
 				tasks.add(waitTask);
 				break;
 			default:

File: core/src/main/java/com/netflix/conductor/core/events/EventProcessor.java
Patch:
@@ -148,7 +148,7 @@ private void handle(ObservableQueue queue, Message msg) {
 			for(EventHandler handler : handlers) {
 				
 				String condition = handler.getCondition();
-				logger.info("condition: {}", condition);
+				logger.debug("condition: {}", condition);
 				if(!StringUtils.isEmpty(condition)) {
 					Boolean success = ScriptEvaluator.evalBool(condition, payloadObj);
 					if(!success) {

File: redis-persistence/src/main/java/com/netflix/conductor/dao/index/ElasticSearchDAO.java
Patch:
@@ -73,8 +73,8 @@
 import com.netflix.conductor.core.execution.ApplicationException;
 import com.netflix.conductor.core.execution.ApplicationException.Code;
 import com.netflix.conductor.dao.IndexDAO;
-import com.netflix.conductor.dao.index.query.parser.Expression;
-import com.netflix.conductor.dao.index.query.parser.ParserException;
+import com.netflix.conductor.dao.es5.index.query.parser.Expression;
+import com.netflix.conductor.dao.es5.index.query.parser.ParserException;
 import com.netflix.conductor.metrics.Monitors;
 
 /**

File: client/src/test/java/com/netflix/conductor/client/task/WorkflowTaskCoordinatorTests.java
Patch:
@@ -118,7 +118,7 @@ public void testTaskException() {
 				.withUpdateRetryCount(1)
 				.withTaskClient(client)
 				.build();
-		when(client.poll(anyString(), anyString(), anyInt(), anyInt())).thenReturn(ImmutableList.of(new Task()));
+		when(client.poll(anyString(), anyString(), anyString(), anyInt(), anyInt())).thenReturn(ImmutableList.of(new Task()));
 		when(client.ack(anyString(), anyString())).thenReturn(true);
 		CountDownLatch latch = new CountDownLatch(1);
 		doAnswer(new Answer<Void>() {

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -137,7 +137,6 @@ private DeciderOutcome decide(final WorkflowDef def, final Workflow workflow, Li
 				}
 				if (workflowTask != null && workflowTask.isOptional()) {					
 					task.setStatus(Status.COMPLETED_WITH_ERRORS);
-					//outcome.tasksToBeUpdated.add(task);
 				} else {
 					Task rt = retry(taskDef, workflowTask, task, workflow);
 					tasksToBeScheduled.put(rt.getReferenceTaskName(), rt);
@@ -321,10 +320,11 @@ private Task retry(TaskDef taskDef, WorkflowTask workflowTask, Task task, Workfl
 		rescheduled.setRetriedTaskId(task.getTaskId());
 		rescheduled.setStatus(Status.SCHEDULED);
 		rescheduled.setPollCount(0);
-		
+		rescheduled.setInputData(new HashMap<>());
+		rescheduled.getInputData().putAll(task.getInputData());
 		if(workflowTask != null && workflow.getSchemaVersion() > 1) {
 			Map<String, Object> taskInput = pu.getTaskInputV2(workflowTask.getInputParameters(), workflow, rescheduled.getTaskId(), taskDef);
-			rescheduled.setInputData(taskInput);
+			rescheduled.getInputData().putAll(taskInput);
 		}	
 		//for the schema version 1, we do not have to recompute the inputs
 		return rescheduled;

File: core/src/main/java/com/netflix/conductor/core/execution/DeciderService.java
Patch:
@@ -137,7 +137,6 @@ private DeciderOutcome decide(final WorkflowDef def, final Workflow workflow, Li
 				}
 				if (workflowTask != null && workflowTask.isOptional()) {					
 					task.setStatus(Status.COMPLETED_WITH_ERRORS);
-					//outcome.tasksToBeUpdated.add(task);
 				} else {
 					Task rt = retry(taskDef, workflowTask, task, workflow);
 					tasksToBeScheduled.put(rt.getReferenceTaskName(), rt);
@@ -321,10 +320,11 @@ private Task retry(TaskDef taskDef, WorkflowTask workflowTask, Task task, Workfl
 		rescheduled.setRetriedTaskId(task.getTaskId());
 		rescheduled.setStatus(Status.SCHEDULED);
 		rescheduled.setPollCount(0);
-		
+		rescheduled.setInputData(new HashMap<>());
+		rescheduled.getInputData().putAll(task.getInputData());
 		if(workflowTask != null && workflow.getSchemaVersion() > 1) {
 			Map<String, Object> taskInput = pu.getTaskInputV2(workflowTask.getInputParameters(), workflow, rescheduled.getTaskId(), taskDef);
-			rescheduled.setInputData(taskInput);
+			rescheduled.getInputData().putAll(taskInput);
 		}	
 		//for the schema version 1, we do not have to recompute the inputs
 		return rescheduled;

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowServiceTest.java
Patch:
@@ -2595,7 +2595,7 @@ public void testSubWorkflowFailure() throws Exception {
 		es = ess.getExecutionStatus(subWorkflowId, true);
 		assertNotNull(es);
 		assertEquals(WorkflowStatus.FAILED, es.getStatus());
-		provider.executeSystemTask(subworkflow, es.getParentWorkflowTaskId(), "test", 1);
+		provider.executeSystemTask(subworkflow, es.getParentWorkflowTaskId(), 1);
 		es = ess.getExecutionStatus(wfId, true);
 		assertEquals(WorkflowStatus.FAILED, es.getStatus());
 		

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -28,6 +28,7 @@ public enum Status {
 		CANCELED(true, false, false), 
 		FAILED(true, false, true), 
 		COMPLETED(true, true, true), 
+		COMPLETED_WITH_ERRORS(true, true, true), 
 		SCHEDULED(false, true, true), 
 		TIMED_OUT(true, false, true),
 		READY_FOR_RERUN(false, true, true),
@@ -62,7 +63,7 @@ public boolean isRetriable(){
 
 	private Status status;
 	
-	private Map<String, Object> inputData = new HashMap<>();;
+	private Map<String, Object> inputData = new HashMap<>();
 
 	private String referenceTaskName;
 

File: contribs/src/test/java/com/netflix/conductor/contribs/queue/sqs/TestQueueManager.java
Patch:
@@ -84,6 +84,7 @@ public List<Message> answer(InvocationOnMock invocation) throws Throwable {
 		
 		doAnswer(new Answer<Void>() {
 
+			@SuppressWarnings("unchecked")
 			@Override
 			public Void answer(InvocationOnMock invocation) throws Throwable {
 				List<Message> msgs = invocation.getArgumentAt(0, List.class);

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Event.java
Patch:
@@ -113,7 +113,7 @@ ObservableQueue getQueue(Workflow workflow, Task task) {
 			
 			sink = Sink.conductor;			
 			if("conductor".equals(sinkValue)) {
-				queueName = "conductor:" + workflow.getWorkflowType() + ":" + task.getReferenceTaskName();	
+				queueName = workflow.getWorkflowType() + ":" + task.getReferenceTaskName();	
 			} else {
 				queueName = sinkValue;
 			}

File: core/src/test/java/com/netflix/conductor/core/execution/tasks/TestEvent.java
Patch:
@@ -261,7 +261,7 @@ public void testDynamicSinks() {
 		queue = event.getQueue(workflow, task);
 		assertEquals(Task.Status.IN_PROGRESS, task.getStatus());
 		assertNotNull(queue);
-		assertEquals("conductor:testWorkflow:task0", queue.getName());
+		assertEquals("testWorkflow:task0", queue.getName());
 		
 	}
 	

File: common/src/main/java/com/netflix/conductor/common/metadata/tasks/Task.java
Patch:
@@ -28,6 +28,7 @@ public enum Status {
 		CANCELED(true, false, false), 
 		FAILED(true, false, true), 
 		COMPLETED(true, true, true), 
+		COMPLETED_WITH_ERRORS(true, true, true), 
 		SCHEDULED(false, true, true), 
 		TIMED_OUT(true, false, true),
 		READY_FOR_RERUN(false, true, true),

File: contribs/src/test/java/com/netflix/conductor/contribs/queue/sqs/TestQueueManager.java
Patch:
@@ -84,6 +84,7 @@ public List<Message> answer(InvocationOnMock invocation) throws Throwable {
 		
 		doAnswer(new Answer<Void>() {
 
+			@SuppressWarnings("unchecked")
 			@Override
 			public Void answer(InvocationOnMock invocation) throws Throwable {
 				List<Message> msgs = invocation.getArgumentAt(0, List.class);

File: client/src/main/java/com/netflix/conductor/client/task/WorkflowTaskCoordinator.java
Patch:
@@ -217,7 +217,7 @@ private void pollForTask(Worker worker) {
 			logger.error("Execution queue is full", qfe);
 		} catch (Exception e) {
 			WorkflowTaskMetrics.pollingException(worker.getTaskDefName(), e);
-			logger.error("Error when pollig for task", e);
+			logger.error("Error when polling for task " + e.getMessage(), e);
 		}
 	}
 	

File: core/src/main/java/com/netflix/conductor/core/execution/ParametersUtils.java
Patch:
@@ -46,7 +46,7 @@ public enum SystemParameters {
 	}
 	
 	public ParametersUtils() {
-		
+
 	}
 	
 	public Map<String, Object> getTaskInputV2(Map<String, Object> input, Workflow workflow, String taskId, TaskDef taskDef) {
@@ -76,7 +76,7 @@ public Map<String, Object> getTaskInputV2(Map<String, Object> input, Workflow wo
 		return replaced;
 	}
 	
-	public Map<String, Object> replace(Map<String, Object> input, String json) {
+	public Map<String, Object> replace(Map<String, Object> input, Object json) {
 		DocumentContext io = JsonPath.parse(json, option);
 		return replace(input, io, null);
 	}

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -40,7 +40,6 @@
 import com.netflix.conductor.common.metadata.tasks.TaskResult;
 import com.netflix.conductor.dao.QueueDAO;
 import com.netflix.conductor.service.ExecutionService;
-import com.netflix.conductor.service.MetadataService;
 
 import io.swagger.annotations.Api;
 import io.swagger.annotations.ApiOperation;
@@ -60,8 +59,6 @@ public class TaskResource {
 	private ExecutionService taskService;
 
 	private QueueDAO queues;
-	
-	private MetadataService metadata;
 
 	@Inject
 	public TaskResource(ExecutionService taskService, QueueDAO queues) {

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -410,7 +410,7 @@ public void updateTask(TaskResult result) throws Exception {
 		String workflowId = result.getWorkflowInstanceId();
 		Workflow wf = edao.getWorkflow(workflowId);
 		Task task = edao.getTask(result.getTaskId());
-		long cpuTime = System.currentTimeMillis() - task.getPolledTime();
+		long cpuTime = System.currentTimeMillis() - task.getUpdateTime();
 		
 		if (wf.getStatus().isTerminal()) {
 			// Workflow is in terminal state

File: core/src/main/java/com/netflix/conductor/service/ExecutionService.java
Patch:
@@ -117,7 +117,6 @@ public List<Task> poll(String taskType, String workerId, int count, int timeoutI
 			}
 			task.setWorkerId(workerId);
 			task.setPollCount(task.getPollCount() + 1);
-			task.setPolledTime(System.currentTimeMillis());
 			
 			edao.updateTask(task);
 			tasks.add(task);

File: client/src/main/java/com/netflix/conductor/client/http/ClientBase.java
Patch:
@@ -190,7 +190,7 @@ private void handleException(Exception e) {
 	}	
 	
 	
-	protected ObjectMapper objectMapper() {
+	protected static ObjectMapper objectMapper() {
 	    final ObjectMapper om = new ObjectMapper();
         om.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
         om.configure(DeserializationFeature.FAIL_ON_IGNORED_PROPERTIES, false);

File: client/src/test/java/com/netflix/conductor/client/metadata/workflow/TestWorkflowTask.java
Patch:
@@ -45,7 +45,7 @@ public void test() throws Exception {
 		assertEquals(task.getType(), read.getType());
 		
 		task = new WorkflowTask();
-		task.setType(Type.SUB_WORKFLOW);
+		task.setWorkflowTaskType(Type.SUB_WORKFLOW);
 		task.setName("name");
 		
 		json = om.writeValueAsString(task);

File: common/src/test/java/com/netflix/conductor/common/workflow/TestWorkflowTask.java
Patch:
@@ -35,7 +35,7 @@ public class TestWorkflowTask {
 	@Test
 	public void test() {
 		WorkflowTask wt = new WorkflowTask();
-		wt.setType(Type.DECISION);
+		wt.setWorkflowTaskType(Type.DECISION);
 		
 		assertNotNull(wt.getType());
 		assertEquals(Type.DECISION.name(), wt.getType());

File: contribs/src/main/java/com/netflix/conductor/contribs/queue/QueueManager.java
Patch:
@@ -38,9 +38,11 @@
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.common.run.Workflow;
-import com.netflix.conductor.contribs.tasks.Wait;
+import com.netflix.conductor.core.events.queue.Message;
+import com.netflix.conductor.core.events.queue.ObservableQueue;
 import com.netflix.conductor.core.execution.ApplicationException;
 import com.netflix.conductor.core.execution.ApplicationException.Code;
+import com.netflix.conductor.core.execution.tasks.Wait;
 import com.netflix.conductor.service.ExecutionService;
 
 /**

File: contribs/src/test/java/com/netflix/conductor/contribs/queue/sqs/TestSQSObservableQueue.java
Patch:
@@ -33,8 +33,8 @@
 import org.mockito.stubbing.Answer;
 
 import com.google.common.util.concurrent.Uninterruptibles;
-import com.netflix.conductor.contribs.queue.Message;
 import com.netflix.conductor.contribs.queue.sqs.SQSObservableQueue;
+import com.netflix.conductor.core.events.queue.Message;
 
 import rx.Observable;
 

File: core/src/main/java/com/netflix/conductor/core/events/queue/Message.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * 
  */
-package com.netflix.conductor.contribs.queue;
+package com.netflix.conductor.core.events.queue;
 
 /**
  * @author Viren

File: core/src/main/java/com/netflix/conductor/core/events/queue/ObservableQueue.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * 
  */
-package com.netflix.conductor.contribs.queue;
+package com.netflix.conductor.core.events.queue;
 
 import java.util.List;
 

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Decision.java
Patch:
@@ -1,5 +1,5 @@
 /**
- * Copyright 2016 Netflix, Inc.
+ * Copyright 2017 Netflix, Inc.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
  * you may not use this file except in compliance with the License.
@@ -28,7 +28,7 @@
  *
  */
 public class Decision extends WorkflowSystemTask {
-
+	
 	public Decision() {
 		super("DECISION");
 	}

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Fork.java
Patch:
@@ -1,5 +1,5 @@
 /**
- * Copyright 2016 Netflix, Inc.
+ * Copyright 2017 Netflix, Inc.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
  * you may not use this file except in compliance with the License.
@@ -19,11 +19,11 @@
 package com.netflix.conductor.core.execution.tasks;
 
 /**
- * @author vbaraiya
+ * @author Viren
  *
  */
 public class Fork extends WorkflowSystemTask {
-
+	
 	public Fork() {
 		super("FORK");
 	}

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Wait.java
Patch:
@@ -16,13 +16,12 @@
 /**
  * 
  */
-package com.netflix.conductor.contribs.tasks;
+package com.netflix.conductor.core.execution.tasks;
 
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.Task.Status;
 import com.netflix.conductor.common.run.Workflow;
 import com.netflix.conductor.core.execution.WorkflowExecutor;
-import com.netflix.conductor.core.execution.tasks.WorkflowSystemTask;
 
 /**
  * @author Viren

File: jersey/src/main/java/com/netflix/conductor/server/resources/MetadataResource.java
Patch:
@@ -52,7 +52,6 @@ public class MetadataResource {
 
 	private MetadataService service;
 	
-	
 	@Inject
 	public MetadataResource(MetadataService service) {
 		this.service = service;

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -78,7 +78,7 @@ public WorkflowResource(WorkflowExecutor executor, ExecutionService service, Met
 		this.executor = executor;
 		this.service = service;
 		this.metadata = metadata;
-		this.maxSearchSize = config.getIntProperty("workflow.max.search.size", 100);
+		this.maxSearchSize = config.getIntProperty("workflow.max.search.size", 5_000);
 	}
 
 	@POST

File: redis-persistence/src/main/java/com/netflix/conductor/dao/index/query/parser/NameValue.java
Patch:
@@ -90,7 +90,6 @@ public ConstValue getValue() {
 		return value;
 	}
 	
-	@SuppressWarnings("deprecation")
 	@Override
 	public QueryBuilder getFilterBuilder(){
 		if(op.getOperator().equals(Operators.EQUALS.value())){

File: server/src/main/java/com/netflix/conductor/server/ConductorConfig.java
Patch:
@@ -74,7 +74,7 @@ public String getStack() {
 
 	@Override
 	public String getAppId() {
-		return getProperty("APP_ID", "");
+		return getProperty("APP_ID", "conductor");
 	}
 
 	@Override

File: server/src/main/java/com/netflix/conductor/server/Main.java
Patch:
@@ -32,7 +32,7 @@ public class Main {
 	
 	public static void main(String[] args) throws Exception {
 		
-		if(args.length > 1) {
+		if(args.length > 0) {
 			String propertyFile = args[0];	
 			System.out.println("Using " + propertyFile);
 			FileInputStream propFile = new FileInputStream(propertyFile);

File: server/src/main/java/com/netflix/conductor/server/ServerModule.java
Patch:
@@ -29,6 +29,7 @@
 import com.netflix.conductor.contribs.http.HttpTask;
 import com.netflix.conductor.contribs.http.RestClientManager;
 import com.netflix.conductor.core.config.Configuration;
+import com.netflix.conductor.core.config.CoreModule;
 import com.netflix.conductor.dao.ExecutionDAO;
 import com.netflix.conductor.dao.IndexDAO;
 import com.netflix.conductor.dao.MetadataDAO;
@@ -94,6 +95,7 @@ protected void configure() {
 		DynoProxy proxy = new DynoProxy(dynoConn);
 		bind(DynoProxy.class).toInstance(proxy);
 		
+		install(new CoreModule());
 		install(new JerseyModule());
 		new HttpTask(new RestClientManager(), config);
 		List<AbstractModule> additionalModules = config.getAdditionalModules();

File: test-harness/src/test/java/com/netflix/conductor/tests/utils/TestModule.java
Patch:
@@ -28,6 +28,7 @@
 import com.google.inject.AbstractModule;
 import com.google.inject.Provides;
 import com.netflix.conductor.core.config.Configuration;
+import com.netflix.conductor.core.config.CoreModule;
 import com.netflix.conductor.dao.ExecutionDAO;
 import com.netflix.conductor.dao.IndexDAO;
 import com.netflix.conductor.dao.MetadataDAO;
@@ -82,6 +83,7 @@ public String getCurrentShard() {
 		
 		DynoProxy proxy = new DynoProxy(jedisMock);
 		bind(DynoProxy.class).toInstance(proxy);
+		install(new CoreModule());
 	}
 	
 	@Provides

File: core/src/test/java/com/netflix/conductor/core/events/TestScriptEval.java
Patch:
@@ -38,7 +38,5 @@ public void testScript() throws Exception {
 		assertTrue(ScriptEvaluator.evalBool(script3, payload));
 		assertFalse(ScriptEvaluator.evalBool(script4, payload));
 		
-		payload.clear();
-		assertTrue(ScriptEvaluator.evalBool(script3, payload));
 	}
 }

File: client/src/test/java/com/netflix/conductor/client/metadata/workflow/TestWorkflowTask.java
Patch:
@@ -45,7 +45,7 @@ public void test() throws Exception {
 		assertEquals(task.getType(), read.getType());
 		
 		task = new WorkflowTask();
-		task.setType(Type.SUB_WORKFLOW);
+		task.setWorkflowTaskType(Type.SUB_WORKFLOW);
 		task.setName("name");
 		
 		json = om.writeValueAsString(task);

File: common/src/main/java/com/netflix/conductor/common/metadata/workflow/WorkflowTask.java
Patch:
@@ -139,7 +139,7 @@ public String getType() {
 		return type;
 	}
 
-	public void setType(Type type) {
+	public void setWorkflowTaskType(Type type) {
 		this.type = type.name();
 	}
 	

File: common/src/test/java/com/netflix/conductor/common/workflow/TestWorkflowTask.java
Patch:
@@ -35,7 +35,7 @@ public class TestWorkflowTask {
 	@Test
 	public void test() {
 		WorkflowTask wt = new WorkflowTask();
-		wt.setType(Type.DECISION);
+		wt.setWorkflowTaskType(Type.DECISION);
 		
 		assertNotNull(wt.getType());
 		assertEquals(Type.DECISION.name(), wt.getType());

File: core/src/main/java/com/netflix/conductor/core/events/EventProcessor.java
Patch:
@@ -134,7 +134,7 @@ private void handle(ObservableQueue queue, Message msg) {
 				for(Action action : actions) {
 					String id = msg.getId() + "_" + i++;
 					
-					EventExecution ee = new EventExecution(id);
+					EventExecution ee = new EventExecution(id, msg.getId());
 					ee.setCreated(System.currentTimeMillis());
 					ee.setEvent(handler.getEvent());
 					ee.setName(handler.getName());

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/End2EndTests.java
Patch:
@@ -95,12 +95,12 @@ public void testAll() throws Exception {
 		def.setName("test");
 		WorkflowTask t0 = new WorkflowTask();
 		t0.setName("t0");
-		t0.setType(Type.SIMPLE);
+		t0.setWorkflowTaskType(Type.SIMPLE);
 		t0.setTaskReferenceName("t0");
 		
 		WorkflowTask t1 = new WorkflowTask();
 		t1.setName("t1");
-		t1.setType(Type.SIMPLE);
+		t1.setWorkflowTaskType(Type.SIMPLE);
 		t1.setTaskReferenceName("t1");
 		
 		

File: test-harness/src/test/java/com/netflix/conductor/tests/integration/WorkflowServiceTest.java
Patch:
@@ -257,7 +257,7 @@ public void testTaskDefTemplate() throws Exception {
 		templateWf.setName("template_workflow");
 		WorkflowTask wft = new WorkflowTask();
 		wft.setName(templatedTask.getName());
-		wft.setType(Type.SIMPLE);
+		wft.setWorkflowTaskType(Type.SIMPLE);
 		wft.setTaskReferenceName("t0");
 		templateWf.getTasks().add(wft);
 		templateWf.setSchemaVersion(2);

File: client/src/main/java/com/netflix/conductor/client/worker/Worker.java
Patch:
@@ -43,7 +43,7 @@ public interface Worker {
 	/**
 	 * Callback used by the WorkflowTaskCoordinator before a task is acke'ed.  
 	 * Workers can implement the callback to get notified before the task is ack'ed.
-	 * @param task
+	 * @param task Task to be ack'ed before execution
 	 * @return True, if the task should be accepted and acknowledged.  execute() method is called ONLY when this method returns true.  Return false if the task cannot be accepted for whatever reason.  
 	 */
 	public default boolean preAck(Task task) {

File: core/src/main/java/com/netflix/conductor/dao/QueueDAO.java
Patch:
@@ -37,7 +37,7 @@ public interface QueueDAO {
 	public void push(String queueName, String id, long offsetTimeInSecond);
 	
 	/**
-	 * 
+	 * @param queueName Name of the queue
 	 * @param messages messages to be pushed.
 	 */
 	public void push(String queueName, List<Message> messages);

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -122,7 +122,7 @@ public String updateTask(TaskResult task) throws Exception {
 	@ApiOperation("Ack Task is recieved")
 	@Consumes({ MediaType.WILDCARD })
 	public String ack(@PathParam("taskId") String taskId, @QueryParam("workerid") String workerId) throws Exception {
-		return "\"" + taskService.ackTaskRecieved(taskId, workerId) + "\"";
+		return "" + taskService.ackTaskRecieved(taskId, workerId);
 	}
 
 	@GET

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -114,16 +114,15 @@ public Task getPendingTaskForWorkflow(@PathParam("workflowId") String workflowId
 	@ApiOperation("Update a task")
 	public String updateTask(TaskResult task) throws Exception {
 		taskService.updateTask(task);
-		return task.getTaskId();
+		return "\"" + task.getTaskId() + "\"";
 	}
 
 	@POST
 	@Path("/{taskId}/ack")
 	@ApiOperation("Ack Task is recieved")
 	@Consumes({ MediaType.WILDCARD })
-	@Produces({ MediaType.TEXT_PLAIN })
 	public String ack(@PathParam("taskId") String taskId, @QueryParam("workerid") String workerId) throws Exception {
-		return "" + taskService.ackTaskRecieved(taskId, workerId);
+		return "\"" + taskService.ackTaskRecieved(taskId, workerId) + "\"";
 	}
 
 	@GET

File: client/src/main/java/com/netflix/conductor/client/task/WorkflowTaskCoordinator.java
Patch:
@@ -287,7 +287,7 @@ private Map<String, Object> getEnvData(Worker worker) {
 		String[] properties = props.split(",");
 		String workerName = worker.getTaskDefName();
 		for(String property : properties) {
-			String value = PropertyFactory.getString(workerName, property, null);
+			String value = PropertyFactory.getString(workerName, property, System.getenv(property));
 			data.put(property, value);
 		}
 		

File: core/src/main/java/com/netflix/conductor/core/execution/tasks/Event.java
Patch:
@@ -32,15 +32,15 @@ public class Event extends WorkflowSystemTask {
 
 	private QueueDAO queues;
 	
+	private static final String EVENT_QUEUE_NAME = "_events";
+	
 	public Event() {
 		super("EVENT");
 	}
 	
 	@Override
 	public void start(Workflow workflow, Task task, WorkflowExecutor provider) throws Exception {
-
-		String eventName = workflow.getWorkflowType() + "." + task.getReferenceTaskName();
-		queues.push(eventName, task.getTaskId(), 0);
+		queues.push(EVENT_QUEUE_NAME, task.getTaskId(), 0);
 		task.setStatus(Status.COMPLETED);
 	}
 	

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/queue/DynoQueueDAO.java
Patch:
@@ -79,7 +79,7 @@ public List<Host> getHosts() {
 				List<Host> hosts = super.getHosts();
 				List<Host> updatedHosts = new ArrayList<>(hosts.size());
 				hosts.forEach(host -> {
-					updatedHosts.add(new Host(host.getHostName(), host.getIpAddress(), readConnPort, host.getRack(), host.getDatacenter(), Status.Up));
+					updatedHosts.add(new Host(host.getHostName(), host.getIpAddress(), readConnPort, host.getRack(), host.getDatacenter(), host.isUp() ? Status.Up : Status.Down));
 				});
 				return updatedHosts;
 			}

File: client/src/main/java/com/netflix/conductor/client/http/ClientBase.java
Patch:
@@ -190,7 +190,7 @@ private void handleException(Exception e) {
 	}	
 	
 	
-	protected ObjectMapper objectMapper() {
+	protected static ObjectMapper objectMapper() {
 	    final ObjectMapper om = new ObjectMapper();
         om.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
         om.configure(DeserializationFeature.FAIL_ON_IGNORED_PROPERTIES, false);

File: client/src/main/java/com/netflix/conductor/client/worker/Worker.java
Patch:
@@ -20,7 +20,6 @@
 import java.util.function.Function;
 import java.util.function.Supplier;
 
-import com.netflix.conductor.client.http.TaskClient;
 import com.netflix.conductor.common.metadata.tasks.Task;
 import com.netflix.conductor.common.metadata.tasks.TaskResult;
 

File: core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java
Patch:
@@ -428,7 +428,7 @@ public void updateTask(TaskResult result) throws Exception {
 			return;
 		}
 
-		task.setStatus(Status.valueOf(result.getTaskStatus().name()));
+		task.setStatus(Status.valueOf(result.getStatus().name()));
 		task.setOutputData(result.getOutputData());
 		task.setReasonForIncompletion(result.getReasonForIncompletion());
 		task.setWorkerId(result.getWorkerId());

File: core/src/main/java/com/netflix/conductor/service/MetadataService.java
Patch:
@@ -99,6 +99,9 @@ public List<WorkflowDef> getWorkflowDefs() throws Exception {
 	}
 
 	public void registerWorkflowDef(WorkflowDef def) throws Exception {
+		if(def.getName().contains(":")) {
+			throw new ApplicationException(Code.INVALID_INPUT, "Workflow name cannot contain the following set of characters: ':'");
+		}
 		metadata.create(def);
 	}
 

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -78,7 +78,7 @@ public WorkflowResource(WorkflowExecutor executor, ExecutionService service, Met
 		this.executor = executor;
 		this.service = service;
 		this.metadata = metadata;
-		this.maxSearchSize = config.getIntProperty("workflow.max.search.size", 100);
+		this.maxSearchSize = config.getIntProperty("workflow.max.search.size", 5_000);
 	}
 
 	@POST

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/queue/DynoQueueDAO.java
Patch:
@@ -79,7 +79,7 @@ public List<Host> getHosts() {
 				List<Host> hosts = super.getHosts();
 				List<Host> updatedHosts = new ArrayList<>(hosts.size());
 				hosts.forEach(host -> {
-					updatedHosts.add(new Host(host.getHostName(), host.getIpAddress(), readConnPort, host.getRack(), host.getDatacenter(), Status.Up));
+					updatedHosts.add(new Host(host.getHostName(), host.getIpAddress(), readConnPort, host.getRack(), host.getDatacenter(), host.isUp() ? Status.Up : Status.Down));
 				});
 				return updatedHosts;
 			}

File: client/src/main/java/com/netflix/conductor/client/worker/Worker.java
Patch:
@@ -45,7 +45,6 @@ public interface Worker {
 	/**
 	 * Called when the task coordinator fails to update the task to the server.
 	 * Client should store the task id (in a database) and retry the update later
-	 * @see TaskClient#updateTask(Task)
 	 * @param task Task which cannot be updated back to the server.
 	 * 
 	 */

File: server/src/main/java/com/netflix/conductor/server/ConductorConfig.java
Patch:
@@ -74,7 +74,7 @@ public String getStack() {
 
 	@Override
 	public String getAppId() {
-		return getProperty("APP_ID", "");
+		return getProperty("APP_ID", "conductor");
 	}
 
 	@Override

File: server/src/main/java/com/netflix/conductor/server/Main.java
Patch:
@@ -32,7 +32,7 @@ public class Main {
 	
 	public static void main(String[] args) throws Exception {
 		
-		if(args.length > 1) {
+		if(args.length > 0) {
 			String propertyFile = args[0];	
 			System.out.println("Using " + propertyFile);
 			FileInputStream propFile = new FileInputStream(propertyFile);

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -119,7 +119,7 @@ public void updateTask(Task task) throws Exception {
 	@Path("/{taskId}/ack")
 	@ApiOperation("Ack Task is recieved")
 	@Consumes({ MediaType.WILDCARD })
-	@Produces({ MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON })
+	@Produces({ MediaType.TEXT_PLAIN })
 	public String ack(@PathParam("taskId") String taskId, @QueryParam("workerid") String workerId) throws Exception {
 		return "" + taskService.ackTaskRecieved(taskId, workerId);
 	}

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -83,7 +83,7 @@ public WorkflowResource(WorkflowExecutor executor, ExecutionService service, Met
 
 	@POST
 	@Path("/{name}")
-	@Produces({MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON})
+	@Produces({ MediaType.TEXT_PLAIN })
 	@ApiOperation("Start a new workflow.  Returns the ID of the workflow instance that can be later used for tracking")
 	public String startWorkflow (
 			@PathParam("name") String name, @QueryParam("version") Integer version, 

File: jersey/src/main/java/com/netflix/conductor/server/resources/TaskResource.java
Patch:
@@ -114,7 +114,7 @@ public void updateTask(Task task) throws Exception {
 	@Path("/{taskId}/ack")
 	@ApiOperation("Ack Task is recieved")
 	@Consumes({ MediaType.WILDCARD })
-	@Produces({ MediaType.TEXT_PLAIN })
+	@Produces({ MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON })
 	public String ack(@PathParam("taskId") String taskId, @QueryParam("workerid") String workerId) throws Exception {
 		return "" + taskService.ackTaskRecieved(taskId, workerId);
 	}
@@ -162,7 +162,7 @@ public Map<String, Long> all() throws Exception {
 	@Path("/queue/requeue")
 	@ApiOperation("Requeue pending tasks for all the running workflows")
 	@Consumes({ MediaType.WILDCARD })
-	@Produces({ MediaType.TEXT_PLAIN })
+	@Produces({ MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON })
 	public String requeue() throws Exception {
 		return "" + taskService.requeuePendingTasks();
 	}
@@ -171,7 +171,7 @@ public String requeue() throws Exception {
 	@Path("/queue/requeue/{taskType}")
 	@ApiOperation("Requeue pending tasks")
 	@Consumes({ MediaType.WILDCARD })
-	@Produces({ MediaType.TEXT_PLAIN })
+	@Produces({ MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON })
 	public String requeue(@PathParam("taskType") String taskType) throws Exception {
 		return "" + taskService.requeuePendingTasks(taskType);
 	}

File: jersey/src/main/java/com/netflix/conductor/server/resources/WorkflowResource.java
Patch:
@@ -83,7 +83,7 @@ public WorkflowResource(WorkflowExecutor executor, ExecutionService service, Met
 
 	@POST
 	@Path("/{name}")
-	@Produces({MediaType.TEXT_PLAIN})
+	@Produces({MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON})
 	@ApiOperation("Start a new workflow.  Returns the ID of the workflow instance that can be later used for tracking")
 	public String startWorkflow (
 			@PathParam("name") String name, @QueryParam("version") Integer version, 
@@ -174,7 +174,7 @@ public void skipTaskFromWorkflow(@PathParam("workflowId") String workflowId, @Pa
 	@Path("/{workflowId}/rerun")
 	@ApiOperation("Reruns the workflow from a specific task")
 	@Consumes(MediaType.APPLICATION_JSON)
-	@Produces(MediaType.TEXT_PLAIN)
+	@Produces({MediaType.TEXT_PLAIN, MediaType.APPLICATION_JSON})
 	public String rerun(@PathParam("workflowId") String workflowId, RerunWorkflowRequest request) throws Exception {		
 		request.setReRunFromWorkflowId(workflowId);
 		return executor.rerun(request);
@@ -206,7 +206,7 @@ public void terminate(@PathParam("workflowId") String workflowId, @QueryParam("r
 	
 	@ApiOperation(value="Search for workflows based in payload and other parameters", notes="use sort options as sort=<field>:ASC|DESC e.g. sort=name&sort=workflowId:DESC.  If order is not specified, defaults to ASC")
 	@GET
-	@Consumes(MediaType.TEXT_PLAIN)
+	@Consumes(MediaType.WILDCARD)
 	@Produces(MediaType.APPLICATION_JSON)
 	@Path("/search")
     public SearchResult<WorkflowSummary> search(

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/queue/DynoQueueDAO.java
Patch:
@@ -104,6 +104,7 @@ public List<Host> getHosts() {
 
 	public DynoQueueDAO(JedisCommands dynoClient, JedisCommands dynoClientRead, ShardSupplier ss, Configuration config, int dynoThreadCount) {
 		this.dynoClient = dynoClient;
+		this.dynoClientRead = dynoClient;
 		this.ss = ss;
 		this.config = config;
 		this.dynoThreadCount = dynoThreadCount;

File: client/src/main/java/com/netflix/conductor/client/http/WorkflowClient.java
Patch:
@@ -141,8 +141,8 @@ public void skipTaskFromWorkflow(String workflowId, String taskReferenceName) {
 		put("workflow/{workflowId}/skiptask/{taskReferenceName}", null, workflowId, taskReferenceName);		
 	}
 
-	public void runDecider(String workflowName) {
-		put("workflow/decide/{workflowName}", null, workflowName);
+	public void runDecider(String workflowId) {
+		put("workflow/decide/{workflowId}", null, null, workflowId);
 	}
 
 	public SearchResult<WorkflowSummary> search(String query) {

File: core/src/main/java/com/netflix/conductor/core/WorkflowContext.java
Patch:
@@ -25,7 +25,7 @@
  */
 public class WorkflowContext {
 
-	public static final ThreadLocal<WorkflowContext> threadLocal = new InheritableThreadLocal<WorkflowContext>();
+	public static final ThreadLocal<WorkflowContext> threadLocal = InheritableThreadLocal.withInitial(() -> new WorkflowContext(""));
 	
 	private String clientApp;
     

File: redis-persistence/src/main/java/com/netflix/conductor/dao/index/ElasticSearchDAO.java
Patch:
@@ -98,6 +98,7 @@ public void index(Workflow workflow) {
 			UpdateRequest req = new UpdateRequest(indexName, WORKFLOW_DOC_TYPE, id);
 			req.doc(doc);
 			req.upsert(doc);
+			req.retryOnConflict(5);
 			
 			BulkResponse response = client.prepareBulk().add(req).execute().actionGet();
 			BulkItemResponse[] indexedItems = response.getItems();

File: redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/queue/DynoJedisClient.java
Patch:
@@ -3176,7 +3176,7 @@ public long pfcount(final byte[] key)  {
      * NOT SUPPORTED ! Use {@link #dyno_scan(CursorBasedResult, String...)}
      * instead.
      *
-     * @param cursor
+     * @param cursor cursor
      * @return nothing -- throws UnsupportedOperationException when invoked
      * @see #dyno_scan(CursorBasedResult, String...)
      */
@@ -3189,7 +3189,7 @@ public ScanResult<String> scan(int cursor) {
      * NOT SUPPORTED ! Use {@link #dyno_scan(CursorBasedResult, String...)}
      * instead.
      *
-     * @param cursor
+     * @param cursor cursor
      * @return nothing -- throws UnsupportedOperationException when invoked
      * @see #dyno_scan(CursorBasedResult, String...)
      */

