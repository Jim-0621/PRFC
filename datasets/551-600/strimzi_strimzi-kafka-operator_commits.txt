File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Cluster.java
Patch:
@@ -200,11 +200,8 @@ protected List<VolumeMount> getVolumeMounts() {
             String oauthTlsVolumeMountPath =  buildClusterVolumeMountPath(MIRRORMAKER_2_OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT, alias);
             String oauthVolumeMountPath =  buildClusterVolumeMountPath(MIRRORMAKER_2_OAUTH_SECRETS_BASE_VOLUME_MOUNT, alias);
             AuthenticationUtils.configureClientAuthenticationVolumeMounts(mirrorMaker2Cluster.getAuthentication(), volumeMountList, tlsVolumeMountPath, passwordVolumeMountPath, oauthTlsVolumeMountPath, mirrorMaker2Cluster.getAlias() + "-oauth-certs", mirrorMaker2Cluster.getAlias() + '-', true, oauthVolumeMountPath);
-
         }
 
-        TemplateUtils.addAdditionalVolumeMounts(volumeMountList, templateContainer);
-
         return volumeMountList;
     }
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/BatchingTopicController.java
Patch:
@@ -535,8 +535,8 @@ private Results filterOutNonAlterableConfigChanges(
         reconcilableTopics.forEach(reconcilableTopic -> {
             var configChanges = results.getConfigChanges().stream()
                 .filter(pair -> pair.getKey().equals(reconcilableTopic)).findFirst();
-            if (configChanges != null && configChanges.isEmpty()) {
-                LOGGER.debugCr(reconcilableTopic.reconciliation(), "Config changes {}", configChanges);
+            if (configChanges.isPresent()) {
+                LOGGER.debugCr(reconcilableTopic.reconciliation(), "Config changes: {}", configChanges.get());
             } else {
                 LOGGER.debugCr(reconcilableTopic.reconciliation(), "No config change");
             }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1693,8 +1693,8 @@ public NetworkPolicy generateNetworkPolicy(String operatorNamespace, Labels oper
         List<NetworkPolicyIngressRule> rules = new ArrayList<>();
 
         // Control Plane rule covers the control plane listener.
-        // Control plane listener is used by Kafka for internal coordination only
-        rules.add(NetworkPolicyUtils.createIngressRule(CONTROLPLANE_PORT, List.of(kafkaClusterPeer)));
+        // Control plane listener is used by Kafka for internal coordination only, but also by CO during rolling updates
+        rules.add(NetworkPolicyUtils.createIngressRule(CONTROLPLANE_PORT, List.of(kafkaClusterPeer, clusterOperatorPeer)));
 
         // Replication rule covers the replication listener.
         // Replication listener is used by Kafka but also by our own tools => Operators, Cruise Control, and Kafka Exporter

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -269,7 +269,9 @@ private static Future<HttpServer> startHealthServer(Vertx vertx, MetricsProvider
                         request.response().setStatusCode(204).end();
                     } else if (request.path().equals("/metrics")) {
                         PrometheusMeterRegistry metrics = (PrometheusMeterRegistry) metricsProvider.meterRegistry();
-                        request.response().setStatusCode(200)
+                        request.response()
+                                .putHeader("Content-Type", "text/plain; version=0.0.4; charset=utf-8")
+                                .setStatusCode(200)
                                 .end(metrics.scrape());
                     }
                 })

File: operator-common/src/test/java/io/strimzi/operator/common/http/HealthCheckAndMetricsServerTest.java
Patch:
@@ -54,6 +54,8 @@ public void testAllGood() throws IOException, InterruptedException, URISyntaxExc
             request = HttpRequest.newBuilder().uri(new URI("http://localhost:" + port + "/metrics")).GET().build();
             HttpResponse<String> response = client.send(request, HttpResponse.BodyHandlers.ofString());
             assertThat(response.statusCode(), is(200));
+            assertThat(response.headers().map().get("Content-Type").size(), is(1));
+            assertThat(response.headers().map().get("Content-Type").get(0), is("text/plain; version=0.0.4;charset=utf-8"));
             assertThat(response.body(), containsString("my_metric_total 1.0"));
         } finally {
             server.stop();

File: api/src/main/java/io/strimzi/api/kafka/Crds.java
Patch:
@@ -98,6 +98,7 @@ private static CustomResourceDefinition crd(Class<? extends CustomResource> cls)
             kind = KafkaTopic.RESOURCE_KIND;
             listKind = KafkaTopic.RESOURCE_LIST_KIND;
             versions = KafkaTopic.VERSIONS;
+            status = new CustomResourceSubresourceStatus();
         } else if (cls.equals(KafkaUser.class)) {
             scope = KafkaUser.SCOPE;
             plural = KafkaUser.RESOURCE_PLURAL;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -135,7 +135,7 @@ public class CruiseControl extends AbstractModel implements SupportsMetrics, Sup
 
     protected static final String ENV_VAR_API_SSL_ENABLED = "STRIMZI_CC_API_SSL_ENABLED";
     protected static final String ENV_VAR_API_AUTH_ENABLED = "STRIMZI_CC_API_AUTH_ENABLED";
-    protected static final String ENV_VAR_API_HEALTHCHECK_USERNAME = "API_HEALTHCHECK";
+    protected static final String ENV_VAR_API_HEALTHCHECK_USERNAME = "API_HEALTHCHECK_USERNAME";
     protected static final String ENV_VAR_API_PORT = "API_PORT";
     protected static final String ENV_VAR_API_HEALTHCHECK_PATH = "API_HEALTHCHECK_PATH";
 

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/kraft/KRaftStrimziUpgradeST.java
Patch:
@@ -127,12 +127,12 @@ void testUpgradeAcrossVersionsWithUnsupportedKafkaVersion() throws IOException {
 
         waitForKafkaClusterRollingUpdate(testStorage.getNamespaceName());
 
-        logPodImages(CO_NAMESPACE);
+        logPodImages(CO_NAMESPACE, coSelector);
 
         // Upgrade kafka
         changeKafkaVersion(testStorage.getNamespaceName(), acrossUpgradeData, true);
 
-        logPodImages(CO_NAMESPACE);
+        logPodImages(CO_NAMESPACE, coSelector);
 
         checkAllComponentsImages(testStorage.getNamespaceName(), acrossUpgradeData);
 
@@ -162,7 +162,7 @@ void testUpgradeAcrossVersionsWithNoKafkaVersion() throws IOException {
         eoPods = DeploymentUtils.waitTillDepHasRolled(testStorage.getNamespaceName(), KafkaResources.entityOperatorDeploymentName(clusterName), 1, eoPods);
 
         LOGGER.info("Rolling to new images has finished!");
-        logPodImages(CO_NAMESPACE);
+        logPodImages(CO_NAMESPACE, coSelector);
 
         // Upgrade kafka
         changeKafkaVersion(testStorage.getNamespaceName(), acrossUpgradeData);

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceDeletionRecoveryST.java
Patch:
@@ -278,10 +278,11 @@ void createStorageClass() {
         // Delete specific StorageClass if present from previous
         kubeClient().getClient().storage().v1().storageClasses().withName(storageClassName).delete();
 
+        final String storageClassKubernetesIo = "storageclass.kubernetes.io/is-default-class";
         // Get default StorageClass and change reclaim policy
         StorageClass defaultStorageClass =  kubeClient().getClient().storage().v1().storageClasses().list().getItems().stream().filter(sg -> {
             Map<String, String> annotations = sg.getMetadata().getAnnotations();
-            return annotations.get("storageclass.kubernetes.io/is-default-class").equals("true");
+            return annotations != null && annotations.containsKey(storageClassKubernetesIo) && annotations.get(storageClassKubernetesIo).equals("true");
         }).findFirst().get();
 
         StorageClass retainStorageClass = new StorageClassBuilder(defaultStorageClass)

File: api/src/main/java/io/strimzi/api/kafka/model/kafka/cruisecontrol/KafkaAutoRebalanceConfiguration.java
Patch:
@@ -36,8 +36,8 @@ public class KafkaAutoRebalanceConfiguration implements UnknownPropertyPreservin
     private LocalObjectReference template;
     private Map<String, Object> additionalProperties;
 
-    @Description("Mode for which running the auto-rebalancing on scaling, when brokers are added or removed. " +
-            "The supported modes are `add-brokers` and `remove-brokers`.\n")
+    @Description("Specifies the mode for automatically rebalancing when brokers are added or removed. " +
+            "Supported modes are `add-brokers` and `remove-brokers`. \n")
     @JsonProperty(required = true)
     public KafkaRebalanceMode getMode() {
         return mode;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceUtilsTest.java
Patch:
@@ -92,7 +92,7 @@ public void testNullStatus() {
     public void testAutoRebalanceNoStatusNoAddedNodes() {
         KafkaStatus kafkaStatus = new KafkaStatusBuilder().build();
         KafkaRebalanceUtils.updateKafkaAutoRebalanceStatus(kafkaStatus, null, Set.of());
-        assertThat(kafkaStatus.getAutoRebalance(), is(nullValue()));
+        assertThat(kafkaStatus.getAutoRebalance(), is(notNullValue()));
     }
 
     @Test

File: topic-operator/src/main/java/io/strimzi/operator/topic/BatchingTopicController.java
Patch:
@@ -796,7 +796,7 @@ private PartitionedByError<ReconcilableTopic, TopicState> findDifferentRf(
         var apparentlyDifferentRf = currentStates.filter(pair -> {
             var reconcilableTopic = pair.getKey();
             var currentState = pair.getValue();
-            return reconcilableTopic.kt().getSpec().getReplicas() != null
+            return currentState.uniqueReplicationFactor() > 0 && reconcilableTopic.kt().getSpec().getReplicas() != null
                 && currentState.uniqueReplicationFactor() != reconcilableTopic.kt().getSpec().getReplicas();
         }).toList();
         return TopicOperatorUtil.partitionedByError(kafkaHandler.filterByReassignmentTargetReplicas(apparentlyDifferentRf).stream());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/AbstractResourceStateMatchers.java
Patch:
@@ -55,7 +55,7 @@ public void describeTo(final Description description) {
      * Checks all conditions in the supplied resource to see if the type of one of them matches the supplied rebalance state.
      *
      * @param state he expected rebalance state to be searched for.
-     * @return
+     * @return Matcher for the List of Conditions
      */
     public static Matcher<List<Condition>> hasStateInConditions(KafkaRebalanceState state) {
         return new TypeSafeDiagnosingMatcher<>() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -920,7 +920,8 @@ public void testConnectorConnectConnectConnector() {
                 eq(connectorName));
     }
 
-    /** Change the cluster label from one cluster to another
+    /**
+     * Change the cluster label from one cluster to another
      * check the connector is deleted from the old cluster
      * check the connector is added to the new cluster
      * */

File: operator-common/src/test/java/io/strimzi/operator/common/operator/MockCertManager.java
Patch:
@@ -299,7 +299,7 @@ private static byte[] loadResource(InputStream is) {
      * @param certFile path to the file which will contain the self signed certificate
      * @param sbj      subject information
      * @param days     certificate duration
-     * @throws IOException
+     * @throws IOException  Thrown when writing to file fails
      */
     @Override
     public void generateSelfSignedCert(File keyFile, File certFile, Subject sbj, int days) throws IOException {
@@ -315,7 +315,7 @@ public void generateSelfSignedCert(File keyFile, File certFile, Subject sbj, int
      * @param certFile path to the file which will contain the new self signed certificate
      * @param sbj      subject information
      * @param days     certificate duration
-     * @throws IOException
+     * @throws IOException  Thrown when writing to file fails
      */
     @Override
     public void renewSelfSignedCert(File keyFile, File certFile, Subject sbj, int days) throws IOException {

File: systemtest/src/main/java/io/strimzi/systemtest/TestConstants.java
Patch:
@@ -80,7 +80,7 @@ public interface TestConstants {
 
     /**
      * Constants for KafkaConnect EchoSink plugin
-      */
+     */
     String ECHO_SINK_CONNECTOR_NAME = "echo-sink-connector";
     String ECHO_SINK_CLASS_NAME = "cz.scholz.kafka.connect.echosink.EchoSinkConnector";
     String ECHO_SINK_TGZ_URL = "https://github.com/scholzj/echo-sink/archive/1.6.0.tar.gz";

File: systemtest/src/main/java/io/strimzi/systemtest/logs/LogCollector.java
Patch:
@@ -54,7 +54,7 @@
  *                      describe-pod-kafka-cluster-entity-operator-56t123sd-31221-container...log
  *                      logs-pod-kafka-cluster-entity-operator-56t123sd-31221.log
  *                      ...
-*                 ...
+ *                 ...
  *              cluster-operator.log    // shared cluster operator logs for all tests inside one test suite
  *          /another-test-suite_time/
  *      ...

File: systemtest/src/main/java/io/strimzi/systemtest/resources/NamespaceManager.java
Patch:
@@ -198,8 +198,8 @@ public void deleteNamespaceWithWait(String namespaceName) {
      * Deletes Namespace with {@param namespaceName}, waits for its deletion, and in case that {@param collectorElement}
      * is not {@code null}, removes the Namespace from the {@link #MAP_WITH_SUITE_NAMESPACES}.
      *
-     * @param namespaceName
-     * @param collectorElement
+     * @param namespaceName     Name of the Namespace that should be deleted
+     * @param collectorElement  Collector element for removing the Namespace from the set
      */
     public void deleteNamespaceWithWaitAndRemoveFromSet(String namespaceName, CollectorElement collectorElement) {
         deleteNamespaceWithWait(namespaceName);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/NodePoolsConverter.java
Patch:
@@ -51,7 +51,7 @@ public static KafkaNodePool[] convertNodePoolsIfNeeded(KafkaNodePool... nodePool
      * it does following:
      *  - removes all controller NodePools (so we have just one NodePool instead of two - easier handling in STs)
      *  - for each NodePool that left (broker NodePools) adds {@link ProcessRoles#CONTROLLER} role to its `spec`
-     * @param nodePools
+     * @param nodePools     List of NodePools that should be converted to mixed roles
      */
     private static void changeNodePoolsToHaveMixedRoles(List<KafkaNodePool> nodePools) {
         if (!Environment.isSeparateRolesMode() && Environment.isKRaftModeEnabled()) {

File: systemtest/src/main/java/io/strimzi/systemtest/storage/TestStorage.java
Patch:
@@ -30,7 +30,7 @@
 import static io.strimzi.systemtest.TestConstants.MESSAGE_COUNT;
 
 /**
- * TestStorage generate and stores values in the specific @see{ExtensionContext}. This ensures that if one want to
+ * TestStorage generate and stores values in the specific {@link ExtensionContext}. This ensures that if one want to
  * retrieve data from TestStorage it can be done via ExtensionContext (with help of @ConcurrentHashMap)
  */
 final public class TestStorage {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java
Patch:
@@ -143,7 +143,7 @@ public static void waitForConnectStatusContainsPlugins(String namespaceName, Str
      * @param testStorage      The {@link TestStorage} contains test details.
      * @param connectPods      A map of Kafka Connect Pods.
      * @param scraperPodName   The name of the pod used to perform network requests within the cluster.
-     * @param connectLogMatch  A {@link Predicate <String>} that tests log entries to confirm the presence of the new log level.
+     * @param connectLogMatch  A {@link Predicate} that tests log entries to confirm the presence of the new log level.
      * @param logLevel         The desired log level (e.g., "INFO", "DEBUG") that the method waits to be propagated to the Kafka Connect
      *                         configuration and reflected in the logs.
      */

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/BuildUtils.java
Patch:
@@ -19,9 +19,9 @@ private BuildUtils() { }
 
     /**
      * Gets OpenShift build name based on name and version
-     * @param name
-     * @param version
-     * @return
+     * @param name      Name of the build
+     * @param version   Version of the build
+     * @return  Returns `name-version` build name
      */
     public static String getBuildName(String name, Long version) {
         return name + "-" + version;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/MinioUtils.java
Patch:
@@ -24,8 +24,8 @@ private MinioUtils() {
 
     /**
      * Collect data from Minio about usage of a specific bucket
-     * @param namespace
-     * @param bucketName
+     * @param namespace     Name of the Namespace where the Minio Pod is running
+     * @param bucketName    Name of the bucket for which we want to get info about its size
      * @return Overall statistics about the bucket in String format
      */
     public static String getBucketSizeInfo(String namespace, String bucketName) {

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfSharedST.java
Patch:
@@ -196,7 +196,7 @@ private static Map<String, Object> generateTestCases(String kafkaVersion) {
     }
 
     /**
-     * Method, which randomly choose 3 dynamic properties for verification from @see{testCases}. In this case we are ok
+     * Method, which randomly choose 3 dynamic properties for verification from {@param testCases}. In this case we are ok
      * with stochastic selection, because we don't care, which configuration is used. Furthermore, it's the same path
      * of code (i.e., same CFG (control flow graph), which does not triggers RollingUpdate).
      * @param testCases test cases, where each consist of one dynamic property

File: systemtest/src/test/java/io/strimzi/systemtest/security/PodSecurityProfilesST.java
Patch:
@@ -54,7 +54,6 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 
 /**
- *
  * PodSecurityProfilesST provides tests for Pod Security profiles. In short, Pod security profiles are a mechanism used
  * in Pods or containers, which may prohibit some set of operations (e.g., running only as a non-root user, allowing
  * only some Volume types etc.).

File: test/src/main/java/io/strimzi/test/executor/Exec.java
Patch:
@@ -240,9 +240,9 @@ public static ExecResult exec(String input, List<String> command, int timeout, L
      * @param commands arguments for command
      * @param timeoutMs  timeout in ms for kill
      * @return returns ecode of execution
-     * @throws IOException
-     * @throws InterruptedException
-     * @throws ExecutionException
+     * @throws IOException When writing/closing the OutputStreams or starting the process
+     * @throws InterruptedException In the waitFor method, if the wait is interrupted
+     * @throws ExecutionException When getting the output from std
      */
     public int execute(String input, List<String> commands, long timeoutMs) throws IOException, InterruptedException, ExecutionException {
         LOGGER.trace("Running command - " + join(" ", commands.toArray(new String[0])));

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -867,8 +867,8 @@ void testMetricsChange() throws JsonProcessingException {
         RollingUpdateUtils.waitTillComponentHasRolledAndPodsReady(testStorage.getNamespaceName(), testStorage.getBrokerSelector(), 3, brokerPods);
 
         LOGGER.info("Check if metrics do not exist in Pods");
-        kafkaCollector.collectMetricsFromPodsWithoutWait().values().forEach(value -> assertThat(value, is("")));
-        zkCollector.collectMetricsFromPodsWithoutWait().values().forEach(value -> assertThat(value, is("")));
+        kafkaCollector.collectMetricsFromPodsWithoutWait().values().forEach(value -> assertThat(value.isEmpty(), is(true)));
+        zkCollector.collectMetricsFromPodsWithoutWait().values().forEach(value -> assertThat(value.isEmpty(), is(true)));
     }
 
     /**

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
Patch:
@@ -53,6 +53,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.JobUtils;
+import io.strimzi.systemtest.utils.specific.MetricsUtils;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.WaitException;
 import io.strimzi.test.k8s.KubeClusterResource;
@@ -82,8 +83,6 @@
 import static io.strimzi.systemtest.TestConstants.REGRESSION;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
-import static org.hamcrest.CoreMatchers.containsString;
-import static org.hamcrest.MatcherAssert.assertThat;
 import static org.junit.jupiter.api.Assertions.assertDoesNotThrow;
 
 @Tag(OAUTH)
@@ -792,7 +791,7 @@ private void assertOauthMetricsForComponent(MetricsCollector collector) {
         for (final String podName : collector.getCollectedData().keySet()) {
             for (final String expectedMetric : expectedOauthMetrics) {
                 LOGGER.info("Searching value from Pod with IP {} for metric {}", podName, expectedMetric);
-                assertThat(collector.getCollectedData().get(podName), containsString(expectedMetric));
+                MetricsUtils.assertContainsMetric(collector.getCollectedData().get(podName), expectedMetric);
             }
         }
     }

File: api/src/main/java/io/strimzi/api/kafka/model/connector/AbstractConnectorSpec.java
Patch:
@@ -33,7 +33,7 @@
 @ToString(callSuper = true)
 public abstract class AbstractConnectorSpec extends Spec {
     /**
-     * Forbidden options in the connector configuration
+     * Forbidden options in the connector configuration => these are full options and not prefixes
      */
     public static final String FORBIDDEN_PARAMETERS = "name, connector.class, tasks.max";
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeAdminClientConfiguration.java
Patch:
@@ -22,8 +22,8 @@ public class KafkaBridgeAdminClientConfiguration extends AbstractConfiguration {
     private static final Map<String, String> DEFAULTS;
 
     static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(KafkaBridgeAdminClientSpec.FORBIDDEN_PREFIXES);
-        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(KafkaBridgeAdminClientSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
+        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaBridgeAdminClientSpec.FORBIDDEN_PREFIXES);
+        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaBridgeAdminClientSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
         DEFAULTS = new HashMap<>(0);
     }
 
@@ -35,6 +35,6 @@ public class KafkaBridgeAdminClientConfiguration extends AbstractConfiguration {
      * @param jsonOptions     Json object with configuration options as key ad value pairs.
      */
     public KafkaBridgeAdminClientConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, DEFAULTS);
+        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), DEFAULTS);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeConsumerConfiguration.java
Patch:
@@ -22,8 +22,8 @@ public class KafkaBridgeConsumerConfiguration extends AbstractConfiguration {
     private static final Map<String, String> DEFAULTS;
 
     static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(KafkaBridgeConsumerSpec.FORBIDDEN_PREFIXES);
-        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(KafkaBridgeConsumerSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
+        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaBridgeConsumerSpec.FORBIDDEN_PREFIXES);
+        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaBridgeConsumerSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
         DEFAULTS = new HashMap<>(0);
     }
 
@@ -35,6 +35,6 @@ public class KafkaBridgeConsumerConfiguration extends AbstractConfiguration {
      * @param jsonOptions     Json object with configuration options as key ad value pairs.
      */
     public KafkaBridgeConsumerConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, DEFAULTS);
+        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), DEFAULTS);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeProducerConfiguration.java
Patch:
@@ -22,8 +22,8 @@ public class KafkaBridgeProducerConfiguration extends AbstractConfiguration {
     private static final Map<String, String> DEFAULTS;
 
     static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(KafkaBridgeProducerSpec.FORBIDDEN_PREFIXES);
-        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(KafkaBridgeProducerSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
+        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaBridgeProducerSpec.FORBIDDEN_PREFIXES);
+        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaBridgeProducerSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
         DEFAULTS = new HashMap<>(0);
     }
 
@@ -35,6 +35,6 @@ public class KafkaBridgeProducerConfiguration extends AbstractConfiguration {
      * @param jsonOptions     Json object with configuration options as key ad value pairs.
      */
     public KafkaBridgeProducerConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, DEFAULTS);
+        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), DEFAULTS);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectConfiguration.java
Patch:
@@ -21,8 +21,8 @@ public class KafkaConnectConfiguration extends AbstractConfiguration {
     private static final Map<String, String> DEFAULTS;
 
     static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(KafkaConnectSpec.FORBIDDEN_PREFIXES);
-        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(KafkaConnectSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
+        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaConnectSpec.FORBIDDEN_PREFIXES);
+        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaConnectSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
 
         DEFAULTS = new HashMap<>(6);
         DEFAULTS.put("group.id", "connect-cluster");
@@ -41,6 +41,6 @@ public class KafkaConnectConfiguration extends AbstractConfiguration {
      * @param jsonOptions     Json object with configuration options as key ad value pairs.
      */
     public KafkaConnectConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, DEFAULTS);
+        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), DEFAULTS);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaListenerCustomAuthConfiguration.java
Patch:
@@ -17,7 +17,7 @@
 public class KafkaListenerCustomAuthConfiguration extends AbstractConfiguration {
     private static final List<String> FORBIDDEN_PREFIXES;
     static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(KafkaListenerAuthenticationCustom.FORBIDDEN_PREFIXES);
+        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaListenerAuthenticationCustom.FORBIDDEN_PREFIXES);
     }
 
     /**
@@ -27,6 +27,6 @@ public class KafkaListenerCustomAuthConfiguration extends AbstractConfiguration
      * @param jsonOptions       Configuration options
      */
     public KafkaListenerCustomAuthConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES);
+        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, List.of(), List.of(), Map.of());
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Configuration.java
Patch:
@@ -21,8 +21,8 @@ public class KafkaMirrorMaker2Configuration extends AbstractConfiguration {
     private static final Map<String, String> DEFAULTS;
 
     static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(KafkaMirrorMaker2ClusterSpec.FORBIDDEN_PREFIXES);
-        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(KafkaMirrorMaker2ClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
+        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaMirrorMaker2ClusterSpec.FORBIDDEN_PREFIXES);
+        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaMirrorMaker2ClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
 
         DEFAULTS = new HashMap<>(9);
         DEFAULTS.put("group.id", "mirrormaker2-cluster");
@@ -45,6 +45,6 @@ public class KafkaMirrorMaker2Configuration extends AbstractConfiguration {
      *                    pairs.
      */
     public KafkaMirrorMaker2Configuration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, DEFAULTS);
+        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), DEFAULTS);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerConsumerConfiguration.java
Patch:
@@ -21,8 +21,8 @@ public class KafkaMirrorMakerConsumerConfiguration extends AbstractConfiguration
     private static final Map<String, String> DEFAULTS;
 
     static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(KafkaMirrorMakerConsumerSpec.FORBIDDEN_PREFIXES);
-        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(KafkaMirrorMakerConsumerSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
+        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaMirrorMakerConsumerSpec.FORBIDDEN_PREFIXES);
+        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaMirrorMakerConsumerSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
         DEFAULTS = new HashMap<>(0);
     }
 
@@ -34,6 +34,6 @@ public class KafkaMirrorMakerConsumerConfiguration extends AbstractConfiguration
      * @param jsonOptions     Json object with configuration options as key ad value pairs.
      */
     public KafkaMirrorMakerConsumerConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, DEFAULTS);
+        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), DEFAULTS);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerProducerConfiguration.java
Patch:
@@ -21,8 +21,8 @@ public class KafkaMirrorMakerProducerConfiguration extends AbstractConfiguration
     private static final Map<String, String> DEFAULTS;
 
     static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(KafkaMirrorMakerProducerSpec.FORBIDDEN_PREFIXES);
-        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(KafkaMirrorMakerProducerSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
+        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaMirrorMakerProducerSpec.FORBIDDEN_PREFIXES);
+        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(KafkaMirrorMakerProducerSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
         DEFAULTS = new HashMap<>(0);
     }
 
@@ -34,6 +34,6 @@ public class KafkaMirrorMakerProducerConfiguration extends AbstractConfiguration
      * @param jsonOptions     Json object with configuration options as key ad value pairs.
      */
     public KafkaMirrorMakerProducerConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, DEFAULTS);
+        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), DEFAULTS);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperConfiguration.java
Patch:
@@ -23,8 +23,8 @@ public class ZookeeperConfiguration extends AbstractConfiguration {
     protected static final Map<String, String> DEFAULTS;
 
     static {
-        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(ZookeeperClusterSpec.FORBIDDEN_PREFIXES);
-        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(ZookeeperClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
+        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(ZookeeperClusterSpec.FORBIDDEN_PREFIXES);
+        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(ZookeeperClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
 
         Map<String, String> config = new HashMap<>(5);
         config.put("tickTime", "2000");
@@ -43,6 +43,6 @@ public class ZookeeperConfiguration extends AbstractConfiguration {
      * @param jsonOptions     Json object with configuration options as key ad value pairs.
      */
     public ZookeeperConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, DEFAULTS);
+        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), DEFAULTS);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/cruisecontrol/CruiseControlConfiguration.java
Patch:
@@ -102,8 +102,8 @@ public class CruiseControlConfiguration extends AbstractConfiguration {
             Map.entry(CruiseControlConfigurationParameters.METRIC_REPORTER_TOPIC_NAME.getValue(), CruiseControlConfigurationParameters.DEFAULT_METRIC_REPORTER_TOPIC_NAME)
     )));
 
-    private static final List<String> FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(CruiseControlSpec.FORBIDDEN_PREFIXES);
-    private static final List<String> FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(CruiseControlSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
+    private static final List<String> FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesOrOptionsToList(CruiseControlSpec.FORBIDDEN_PREFIXES);
+    private static final List<String> FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesOrOptionsToList(CruiseControlSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
 
     /**
      * Constructor used to instantiate this class from JsonObject. Should be used to create configuration from
@@ -114,7 +114,7 @@ public class CruiseControlConfiguration extends AbstractConfiguration {
      * @param defaults        Default configuration values
      */
     public CruiseControlConfiguration(Reconciliation reconciliation, Iterable<Map.Entry<String, Object>> jsonOptions, Map<String, String> defaults) {
-        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, defaults);
+        super(reconciliation, jsonOptions, FORBIDDEN_PREFIXES, FORBIDDEN_PREFIX_EXCEPTIONS, List.of(), defaults);
     }
 
     /**

File: certificate-manager/src/main/java/io/strimzi/certs/OpenSslCertManager.java
Patch:
@@ -124,8 +124,10 @@ private Path createDefaultConfig() throws IOException {
      * Add basic constraints and subject alt names section to the provided openssl configuration file
      *
      * @param sbj subject information
+     *
      * @return openssl configuration file with subject alt names added
-     * @throws IOException
+     *
+     * @throws IOException  Throws IOException when IO operations fail
      */
     private Path buildConfigFile(Subject sbj, boolean isCa) throws IOException {
         Path sna = createDefaultConfig();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java
Patch:
@@ -185,7 +185,7 @@ public void stop(Promise<Void> stop) {
     }
 
     /**
-      Periodical reconciliation (in case we lost some event)
+     * Periodical reconciliation (in case we lost some event)
      */
     private void reconcileAll(String trigger) {
         if (!config.isPodSetReconciliationOnly()) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CertUtils.java
Patch:
@@ -281,7 +281,7 @@ private static void maybeAddTrustedCertificateVolumeMount(List<VolumeMount> volu
      *
      * @param certSecretSource      Represents a certificate inside a Secret
      * @param prefix                Prefix used to generate the volume name
-
+     *
      * @return  The generated volume name
      */
     private static String trustedCertificateVolumeName(CertSecretSource certSecretSource, String prefix)    {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -880,7 +880,7 @@ public LoggingModel logging()   {
         return logging;
     }
 
-     /**
+    /**
      * @return  Returns the preferred Deployment Strategy. This is used for the migration form Deployment to
      * StrimziPodSet or the other way around
      */

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java
Patch:
@@ -336,7 +336,7 @@ public void validateKafkaMirrorMakerImages(Set<String> versions) throws NoImageE
             validateImages(versions, kafkaMirrorMakerImages);
         }
 
-       /**
+        /**
          * The Kafka MirrorMaker 2 image to use for a Kafka MirrorMaker 2 cluster.
          * @param image The image given in the CR.
          * @param version The version given in the CR.

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ListenersUtils.java
Patch:
@@ -723,7 +723,7 @@ public static List<String> bootstrapExternalIPs(GenericKafkaListener listener) {
                 : null;
     }
 
-     /**
+    /**
      * Returns broker service external IPs
      * 
      * @param listener  Listener for which the external IPs should be found

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/MetricsAndLogging.java
Patch:
@@ -8,5 +8,8 @@
 
 /**
  * Holder record for ConfigMaps with Metrics and Logging configuration
+ *
+ * @param metricsCm     Config Map with metrics configuration
+ * @param loggingCm     Config Map with logging configuration
  */
 public record MetricsAndLogging(ConfigMap metricsCm, ConfigMap loggingCm) { }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractConnectOperator.java
Patch:
@@ -473,7 +473,7 @@ private Future<List<Condition>> updateState(Reconciliation reconciliation, Strin
      * @param connectorName                 Name of the connector
      * @param status                        The new/future status of the connector
      * @param previousAutoRestartStatus     Previous auto-restart status used to generate the new status (increment the restart counter etc.)
-
+     *
      * @return  Future with connector status and conditions which completes when the connector is restarted
      */
     private Future<ConnectorStatusAndConditions> autoRestartConnector(Reconciliation reconciliation, String host, KafkaConnectApi apiClient, String connectorName, ConnectorStatusAndConditions status, AutoRestartStatus previousAutoRestartStatus) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractOperator.java
Patch:
@@ -56,9 +56,11 @@
  *
  * <li>add support for operator-side {@linkplain StatusUtils#validate(Reconciliation, CustomResource)} validation}.
  *     This can be used to automatically log warnings about source resources which used deprecated part of the CR API.
- *Ä…
  * </ul>
+ *
  * @param <T> The Java representation of the Kubernetes resource, e.g. {@code Kafka} or {@code KafkaConnect}
+ * @param <P> The Java representation of the Kubernetes resource .spec section
+ * @param <S> The Java representation of the Kubernetes resource .status section
  * @param <O> The "Resource Operator" for the source resource type. Typically, this will be some instantiation of
  *           {@link io.strimzi.operator.cluster.operator.resource.kubernetes.CrdOperator}.
  */

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/ConnectBuildOperator.java
Patch:
@@ -212,10 +212,10 @@ private Future<Void> kubernetesBuildStart(Reconciliation reconciliation, String
     /**
      * Checks if the builder Pod finished the build
      *
-     @param namespace               Namespace of the Connect cluster
-     * @param podName               The name of the Pod which should be checked whether it finished
+     * @param namespace     Namespace of the Connect cluster
+     * @param podName       The name of the Pod which should be checked whether it finished
      *
-     * @return                      True if the build already finished, false if it is still building
+     * @return      True if the build already finished, false if it is still building
      */
     private boolean kubernetesBuildPodFinished(String namespace, String podName, String containerName)   {
         Pod buildPod = podOperator.get(namespace, podName);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/CruiseControlReconciler.java
Patch:
@@ -124,7 +124,7 @@ public CruiseControlReconciler(
      * @param imagePullPolicy   Image pull policy
      * @param imagePullSecrets  List of Image pull secrets
      * @param clock             The clock for supplying the reconciler with the time instant of each reconciliation cycle.
- *                              That time is used for checking maintenance windows
+     *                          That time is used for checking maintenance windows
      *
      * @return                  Future which completes when the reconciliation completes
      */

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/ZooKeeperEraser.java
Patch:
@@ -170,7 +170,7 @@ protected Future<Void> deletePodSet() {
      * If deleteClaim is set to true (PVCs have Kafka CR as owner), this method deletes the PVCs.
      * If deleteClaim is set to false (PVCs don't have Kafka CR as owner), this method doesn't delete the PVCs (user has to do it manually).
      *
-      @return  Future which completes when the PVCs which should be deleted
+     * @return  Future which completes when the PVCs which should be deleted
      */
     protected Future<Void> deletePersistentClaims() {
         Labels zkSelectorLabels = Labels.EMPTY

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/DefaultZookeeperScalerProvider.java
Patch:
@@ -25,6 +25,7 @@ public class DefaultZookeeperScalerProvider implements ZookeeperScalerProvider {
      * @param zkNodeAddress                 Function for generating the Zookeeper node addresses
      * @param tlsPemIdentity                Trust set and identity for TLS client authentication for connecting to ZooKeeper
      * @param operationTimeoutMs            Operation timeout
+     * @param zkAdminSessionTimeoutMs       Session timeout for the ZooKeeper connection
      *
      * @return  ZookeeperScaler instance
      */

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiff.java
Patch:
@@ -29,7 +29,7 @@
 import java.util.stream.Collectors;
 
 /**
- The algorithm:
+ * The algorithm:
  *  1. Create a map from the supplied desired String
  *  2. Fill placeholders (e.g. ${BROKER_ID}) in desired map as the broker's {@code kafka_config_generator.sh} would
  *  3a. Loop over all entries. If the entry is in IGNORABLE_PROPERTIES or entry.value from desired is equal to entry.value from current, do nothing

File: crd-annotations/src/main/java/io/strimzi/api/annotations/VersionRange.java
Patch:
@@ -81,7 +81,8 @@ private VersionRange(Version from, Version to) {
 
     /**
      * Abstracts the parsing of a version.
-     * @param <Version>
+     *
+     * @param <Version> Custom Resource API Version
      */
     interface VersionParser<Version extends Comparable<Version>> {
         Version parse(String version) throws IllegalArgumentException;

File: operator-common/src/main/java/io/strimzi/operator/common/config/ConfigParameterParser.java
Patch:
@@ -25,6 +25,8 @@
 
 /**
  * Abstraction for things which convert a single configuration parameter value from a String to some specific type.
+ *
+ * @param <T> Configuration type that will be parsed
  */
 public interface ConfigParameterParser<T> {
 

File: operator-common/src/main/java/io/strimzi/operator/common/model/Labels.java
Patch:
@@ -474,7 +474,6 @@ public String toString() {
     }
 
     /**
-     *
      * When adding new labels, ensure the names of any resources are truncated for sanitization purposes to be compatible with Kubernetes
      * Note: Valid label values must be a maximum length of 63 characters
      * https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set

File: operator-common/src/main/java/io/strimzi/operator/common/model/OrderedProperties.java
Patch:
@@ -466,9 +466,11 @@ public void write(BufferedWriter bufferedWriter, String comment) throws IOExcept
 
         /**
          * Write comment to a Writer, handling newlines embedded in the comment
+         *
          * @param bufferedWriter BufferedWriter to write.
          * @param comment A comment to be written
-         * @throws IOException
+         *
+         * @throws IOException  Throws IOException when IO operations fail
          */
         private static void writeComment(BufferedWriter bufferedWriter, String comment) throws IOException {
             for (String line : LINE_SPLITTER.split(comment)) {

File: topic-operator/src/main/java/io/strimzi/operator/topic/BatchingTopicController.java
Patch:
@@ -146,7 +146,7 @@ public class BatchingTopicController {
      *
      * @param admin The {@link Admin} client used to interact with the Kafka cluster.
      * @param name The name of the configuration to retrieve.
-     * @return An {@link Optional<String>} containing the value of the requested configuration if found, or an empty Optional if not.
+     * @return An {@link Optional} {@link String} containing the value of the requested configuration if found, or an empty Optional if not.
      * @throws RuntimeException if there is an error during the operation. This exception wraps the underlying exception's message.
      */
     private static Optional<String> getClusterConfig(Admin admin, String name) {

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicOperatorConfig.java
Patch:
@@ -50,14 +50,15 @@
  * @param saslEnabled                           Whether the Admin client should be configured to use SASL.
  * @param saslMechanism                         The SASL mechanism for the Admin client.
  * @param saslCustomConfigJson                  The SASL custom values for the Admin client when using alternate auth mechanisms.
- * @param saslUsername,                         The SASL username for the Admin client.
- * @param saslPassword,                         The SASL password for the Admin client.
+ * @param saslUsername                          The SASL username for the Admin client.
+ * @param saslPassword                          The SASL password for the Admin client.
  * @param securityProtocol                      The security protocol for the Admin client.
  * @param useFinalizer                          Whether to use finalizers.
  * @param maxQueueSize                          The capacity of the queue.
  * @param maxBatchSize                          The maximum size of a reconciliation batch.
  * @param maxBatchLingerMs                      The maximum time to wait for a reconciliation batch to contain {@code maxBatchSize} items.
  * @param enableAdditionalMetrics               Whether to enable additional metrics.
+ * @param featureGates                          Configured feature gates.
  * @param cruiseControlEnabled                  Whether Cruise Control integration is enabled.
  * @param cruiseControlRackEnabled              Whether the target Kafka cluster has rack awareness.
  * @param cruiseControlHostname                 Cruise Control hostname.

File: user-operator/src/main/java/io/strimzi/operator/user/operator/AdminApiOperator.java
Patch:
@@ -13,6 +13,9 @@
 
 /**
  * Interface for operators using the Kafka Admin API
+ *
+ * @param <T>   The type that is being reconciled by the operator instance
+ * @param <S>   Collection type that is used by given operator instance
  */
 public interface AdminApiOperator<T, S extends Collection<String>> {
     /**

File: user-operator/src/main/java/io/strimzi/operator/user/operator/batching/AbstractBatchReconciler.java
Patch:
@@ -18,6 +18,8 @@
 /**
  * Abstract class for collecting Kafka Admin API requests and sending them to Kafka in batches. The batches are sent
  * when we collect some (configurable) amount of requests or after some (configurable) time interval
+ *
+ * @param <T>   The type that is reconciled by given batch reconciler instance
  */
 public abstract class AbstractBatchReconciler<T> {
     private final static Logger LOGGER = LogManager.getLogger(AbstractBatchReconciler.class);

File: user-operator/src/main/java/io/strimzi/operator/user/operator/cache/AbstractCache.java
Patch:
@@ -16,6 +16,8 @@
 /**
  * Abstract cache provides a periodically refreshed cache. The cache is based around ConcurrentHashMap and a scheduled
  * periodical timer which regularly updates the cache. It also provides method to access the cache and its data.
+ *
+ * @param <T> Type of the resource that will be cached
  */
 public abstract class AbstractCache<T> {
     private final static Logger LOGGER = LogManager.getLogger(AbstractCache.class);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1234,6 +1234,8 @@ public Secret generateCertificatesSecret(ClusterCa clusterCa, ClientsCa clientsC
     /* test */ List<ContainerPort> getContainerPortList(KafkaPool pool) {
         List<ContainerPort> ports = new ArrayList<>(listeners.size() + 3);
 
+        ports.add(ContainerUtils.createContainerPort(KAFKA_AGENT_PORT_NAME, KAFKA_AGENT_PORT));
+
         if (kafkaMetadataConfigState.isZooKeeperToMigration() || pool.isController()) {
             // The control plane listener is on all nodes in ZooKeeper based clusters and on nodes with controller role in KRaft
             // this excludes all the KRaft broker-only nodes even during the migration

File: kafka-agent/src/main/java/io/strimzi/kafka/agent/KafkaAgent.java
Patch:
@@ -240,12 +240,15 @@ private void startHttpServer() throws Exception {
         ServerConnector httpsConn = new ServerConnector(server,
                 new SslConnectionFactory(getSSLContextFactory(), "http/1.1"),
                 new HttpConnectionFactory(https));
+        httpsConn.setHost("0.0.0.0");
         httpsConn.setPort(HTTPS_PORT);
 
         ContextHandler brokerStateContext = new ContextHandler(BROKER_STATE_PATH);
         brokerStateContext.setHandler(getBrokerStateHandler());
 
         ServerConnector httpConn  = new ServerConnector(server);
+        // The HTTP port should not be exposed outside the Pod, so it listens only on localhost
+        httpConn.setHost("localhost");
         httpConn.setPort(HTTP_PORT);
 
         ContextHandler readinessContext = new ContextHandler(READINESS_ENDPOINT_PATH);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/NamespaceManager.java
Patch:
@@ -290,15 +290,15 @@ public static Map<CollectorElement, Set<String>> getMapWithSuiteNamespaces() {
 
     public static void labelNamespace(String namespaceName, Map<String, String> labels) {
         TestUtils.waitFor(
-            String.join("%s will be updated with %s and the labels will be present", namespaceName, labels.toString()),
+            String.format("%s will be updated with %s and the labels will be present", namespaceName, labels.toString()),
             TestConstants.GLOBAL_POLL_INTERVAL,
             TestConstants.GLOBAL_STATUS_TIMEOUT,
             () -> {
                 try {
                     kubeClient().getClient().namespaces().withName(namespaceName).edit(namespace ->
                         new NamespaceBuilder(namespace)
                             .editOrNewMetadata()
-                            .addToLabels("pod-security.kubernetes.io/enforce", "restricted")
+                                .addToLabels(labels)
                             .endMetadata()
                             .build()
                     );

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/OpenTelemetryST.java
Patch:
@@ -498,4 +498,4 @@ void setup() {
         ResourceManager.STORED_RESOURCES.computeIfAbsent(ResourceManager.getTestContext().getDisplayName(), k -> new Stack<>());
         SetupJaeger.deployJaegerOperatorAndCertManager();
     }
-}
\ No newline at end of file
+}

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -211,7 +211,7 @@ public class Environment {
     private static final String ST_CLIENTS_KAFKA_VERSION_DEFAULT = "3.8.0";
     public static final String TEST_CLIENTS_VERSION_DEFAULT = "0.9.1";
     public static final String ST_FILE_PLUGIN_URL_DEFAULT = "https://repo1.maven.org/maven2/org/apache/kafka/connect-file/" + ST_KAFKA_VERSION_DEFAULT + "/connect-file-" + ST_KAFKA_VERSION_DEFAULT + ".jar";
-    public static final String OLM_OPERATOR_VERSION_DEFAULT = "0.42.0";
+    public static final String OLM_OPERATOR_VERSION_DEFAULT = "0.43.0";
 
     public static final String IP_FAMILY_DEFAULT = "ipv4";
     public static final String IP_FAMILY_VERSION_6 = "ipv6";

File: systemtest/src/main/java/io/strimzi/systemtest/logs/LogCollector.java
Patch:
@@ -218,10 +218,10 @@ private void collectLogsForTestSuite(final Pod pod) {
             }
         // Tracing Pods (they can't be labeled because CR of the Jaeger does not propagate labels to the Pods )
         } else if (pod.getMetadata().getName().contains("jaeger") || pod.getMetadata().getName().contains("cert-manager")) {
-            LOGGER.debug("Collecting logs for TestSuite: {}, and Jaeger Pods: {}/{}", this.collectorElement.getTestClassName(), pod.getMetadata().getNamespace(), pod.getMetadata().getName());
+            LOGGER.debug("Collecting logs for TestSuite: {}, and Jaeger or Cert Manager Pods: {}/{}", this.collectorElement.getTestClassName(), pod.getMetadata().getNamespace(), pod.getMetadata().getName());
             pod.getStatus().getContainerStatuses().forEach(
                 containerStatus -> scrapeAndCreateLogs(namespacePath, pod.getMetadata().getName(), containerStatus, pod.getMetadata().getNamespace()));
-        } else if (pod.getMetadata().getName().contains("keycloak") || pod.getMetadata().getName().contains("keycloak")) {
+        } else if (pod.getMetadata().getName().contains("keycloak")) {
             LOGGER.debug("Collecting logs for TestSuite: {}, and Keycloak Pods: {}/{}", this.collectorElement.getTestClassName(), pod.getMetadata().getNamespace(), pod.getMetadata().getName());
             pod.getStatus().getContainerStatuses().forEach(
                 containerStatus -> scrapeAndCreateLogs(namespacePath, pod.getMetadata().getName(), containerStatus, pod.getMetadata().getNamespace()));

File: api/src/main/java/io/strimzi/api/kafka/model/common/template/ContainerTemplate.java
Patch:
@@ -5,7 +5,6 @@
 package io.strimzi.api.kafka.model.common.template;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.fabric8.kubernetes.api.model.SecurityContext;
 import io.fabric8.kubernetes.api.model.VolumeMount;
@@ -42,7 +41,7 @@ public class ContainerTemplate implements UnknownPropertyPreserving {
     private List<VolumeMount> volumeMounts;
     
     @Description("Additional volume mounts which should be applied to the container")
-    @JsonProperty("volumeMounts")
+    @KubeLink(group = "core", version = "v1", kind = "volumemount")
     public List<VolumeMount> getVolumeMounts() {
         return volumeMounts;
     }

File: systemtest/src/test/java/io/strimzi/systemtest/security/custom/CustomCaST.java
Patch:
@@ -139,9 +139,8 @@ void testReplacingCustomClusterKeyPairToInvokeRenewalProcess() {
 
         // Start a manual rolling update of your cluster to pick up the changes made to the secret configuration.
         StrimziPodSetUtils.annotateStrimziPodSet(testStorage.getNamespaceName(), testStorage.getControllerComponentName(), Collections.singletonMap(Annotations.ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE, "true"));
-        RollingUpdateUtils.waitTillComponentHasRolled(testStorage.getNamespaceName(), testStorage.getControllerSelector(), 3, controllerPods);
-
         StrimziPodSetUtils.annotateStrimziPodSet(testStorage.getNamespaceName(), testStorage.getBrokerComponentName(), Collections.singletonMap(Annotations.ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE, "true"));
+        RollingUpdateUtils.waitTillComponentHasRolled(testStorage.getNamespaceName(), testStorage.getControllerSelector(), 3, controllerPods);
         RollingUpdateUtils.waitTillComponentHasRolled(testStorage.getNamespaceName(), testStorage.getBrokerSelector(), 3, brokerPods);
 
     }

File: crd-generator/src/main/java/io/strimzi/crdgenerator/DocGenerator.java
Patch:
@@ -399,7 +399,7 @@ private void appendDescription(Class<?> cls) throws IOException {
             File includeFile = new File(filename);
 
             if (!includeFile.isFile())   {
-                throw new RuntimeException("Class " + cls.getCanonicalName() + " has @DescribeFile annotation, but file " + filename + " does not exist!");
+                throw new RuntimeException("Class " + cls.getCanonicalName() + " has @DescriptionFile annotation, but file " + filename + " does not exist!");
             }
 
             out.append("xref:type-").append(cls.getSimpleName()).append("-schema-{context}[Full list of `").append(cls.getSimpleName()).append("` schema properties]").append(NL);

File: crd-generator/src/main/java/io/strimzi/crdgenerator/annotations/DescriptionFile.java
Patch:
@@ -10,7 +10,7 @@
 import java.lang.annotation.Target;
 
 /**
- * The DescribeFile annotation indicates that given class has an additional file with Asciidoc description.
+ * The DescriptionFile annotation indicates that given class has an additional file with Asciidoc description.
  * The file has to be placed in the documentation/book/api folder and the filename has to be a fully classified class
  * name (e.g. io.strimzi.api.kafka.MyApiClass). The asciidoc file will be included into the API reference for given
  * class.

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/ZooKeeperReconciler.java
Patch:
@@ -898,7 +898,7 @@ protected Future<Void> maybeDeleteControllerZnode() {
      */
     protected Future<Void> deleteControllerZnode() {
         // migration rollback process ongoing
-        String zkConnectionString = KafkaResources.zookeeperServiceName(reconciliation.name()) + ":" + ZookeeperCluster.CLIENT_TLS_PORT;
+        String zkConnectionString = DnsNameGenerator.serviceDnsNameWithoutClusterDomain(reconciliation.namespace(), KafkaResources.zookeeperServiceName(reconciliation.name()))  + ":" + ZookeeperCluster.CLIENT_TLS_PORT;
         return KRaftMigrationUtils.deleteZooKeeperControllerZnode(
                 reconciliation,
                 vertx,

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicReplicasChangeST.java
Patch:
@@ -443,7 +443,7 @@ void setup() {
         );
         
         // we need to deploy Kafka with CC enabled (to have RF feature)
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaWithCruiseControl(sharedTestStorage.getClusterName(), 3, 3)
+        resourceManager.createResourceWithWait(KafkaTemplates.kafkaWithCruiseControlTunedForFastModelGeneration(sharedTestStorage.getClusterName(), 3, 3)
                     .editMetadata()
                         .withNamespace(sharedTestStorage.getNamespaceName())
                     .endMetadata()
@@ -454,7 +454,7 @@ void setup() {
                             .endTopicOperator()
                         .endEntityOperator()
                         .editCruiseControl()
-                            // faster cluster model generation tuning: reserve some resources at startup
+                            // reserve some resources at startup for faster cluster model generation
                             .withResources(new ResourceRequirementsBuilder()
                                 .addToLimits("memory", new Quantity("1Gi"))
                                 .addToRequests("memory", new Quantity("1Gi"))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/cruisecontrol/CruiseControlConfiguration.java
Patch:
@@ -28,6 +28,7 @@ public class CruiseControlConfiguration extends AbstractConfiguration {
      */
     protected static final List<String> CRUISE_CONTROL_GOALS_LIST = List.of(
             CruiseControlGoals.RACK_AWARENESS_GOAL.toString(),
+            CruiseControlGoals.RACK_AWARENESS_DISTRIBUTION_GOAL.toString(),
             CruiseControlGoals.MIN_TOPIC_LEADERS_PER_BROKER_GOAL.toString(),
             CruiseControlGoals.REPLICA_CAPACITY_GOAL.toString(),
             CruiseControlGoals.DISK_CAPACITY_GOAL.toString(),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CruiseControlReconcilerTest.java
Patch:
@@ -181,7 +181,7 @@ public void reconcileEnabledCruiseControl(boolean topicOperatorEnabled, VertxTes
                     assertThat(deployCaptor.getValue(), is(notNullValue()));
                     assertThat(deployCaptor.getValue().getSpec().getTemplate().getMetadata().getAnnotations().get(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION), is("0"));
                     assertThat(deployCaptor.getValue().getSpec().getTemplate().getMetadata().getAnnotations().get(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_KEY_GENERATION), is("0"));
-                    assertThat(deployCaptor.getAllValues().get(0).getSpec().getTemplate().getMetadata().getAnnotations().get(CruiseControl.ANNO_STRIMZI_SERVER_CONFIGURATION_HASH), is("096591fb"));
+                    assertThat(deployCaptor.getAllValues().get(0).getSpec().getTemplate().getMetadata().getAnnotations().get(CruiseControl.ANNO_STRIMZI_SERVER_CONFIGURATION_HASH), is("4b8f68dd"));
                     assertThat(deployCaptor.getAllValues().get(0).getSpec().getTemplate().getMetadata().getAnnotations().get(CruiseControl.ANNO_STRIMZI_CAPACITY_CONFIGURATION_HASH), is("1eb49220"));
                     assertThat(deployCaptor.getValue().getSpec().getTemplate().getMetadata().getAnnotations().get(Annotations.ANNO_STRIMZI_SERVER_CERT_HASH), is("4d715cdd"));
                     if (topicOperatorEnabled) {

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/TieredStorageST.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Environment;
+import io.strimzi.systemtest.annotations.MicroShiftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
 import io.strimzi.systemtest.resources.NamespaceManager;
@@ -43,6 +44,7 @@
  * @usecase
  *  - tiered-storage-integration
  */
+@MicroShiftNotSupported("We are using Kaniko and OpenShift builds to build Kafka image with TS. To make it working on Microshift we will invest much time with not much additional value.")
 @Tag(REGRESSION)
 @Tag(TIERED_STORAGE)
 public class TieredStorageST extends AbstractST {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaRoller.java
Patch:
@@ -379,8 +379,8 @@ private Future<Void> schedule(NodeRef nodeRef, long delay, TimeUnit unit) {
                 // Let the executor deal with interruption.
                 Thread.currentThread().interrupt();
             } catch (FatalProblem e) {
-                LOGGER.infoCr(reconciliation, "Could not verify pod {} is up-to-date, giving up after {} attempts. Total delay between attempts {}ms",
-                        nodeRef, ctx.backOff.maxAttempts(), ctx.backOff.totalDelayMs(), e);
+                LOGGER.infoCr(reconciliation, "Could not reconcile {}, giving up without retrying because we encountered a fatal error",
+                        nodeRef, e);
                 ctx.promise.fail(e);
                 singleExecutor.shutdownNow();
                 podToContext.forEachValue(Integer.MAX_VALUE, f -> f.promise.tryFail(e));

File: topic-operator/src/test/java/io/strimzi/operator/topic/MockCruiseControl.java
Patch:
@@ -205,6 +205,7 @@ public void expectTopicConfigRequestUnauthorized(File apiUserFile, File apiPassF
             .respond(
                 HttpResponse.response()
                     .withStatusCode(HttpStatusCode.UNAUTHORIZED_401.code())
+                    .withBody("<html>Unauthorized</html>")
                     .withDelay(TimeUnit.SECONDS, 0));
     }
 
@@ -321,6 +322,7 @@ public void expectUserTasksRequestUnauthorized(File apiUserFile, File apiPassFil
             .respond(
                 HttpResponse.response()
                     .withStatusCode(HttpStatusCode.UNAUTHORIZED_401.code())
+                    .withBody("<html>Unauthorized</html>")
                     .withDelay(TimeUnit.SECONDS, 0));
     }
 }

File: topic-operator/src/test/java/io/strimzi/operator/topic/ReplicasChangeHandlerTest.java
Patch:
@@ -242,12 +242,12 @@ public void shouldFailWhenTheRequestIsUnauthorized() {
         server.expectTopicConfigRequestUnauthorized(apiUserFile, apiPassFile);
         var pending = buildPendingReconcilableTopics();
         var pendingAndOngoing = handler.requestPendingChanges(pending);
-        assertFailedWithMessage(pendingAndOngoing, "Replicas change failed, Request failed (401)");
+        assertFailedWithMessage(pendingAndOngoing, "Replicas change failed, Request failed (401), Authorization error");
 
         server.expectUserTasksRequestUnauthorized(apiUserFile, apiPassFile);
         var ongoing = buildOngoingReconcilableTopics();
         var completedAndFailed = handler.requestOngoingChanges(ongoing);
-        assertFailedWithMessage(completedAndFailed, "Replicas change failed, Request failed (401)");
+        assertFailedWithMessage(completedAndFailed, "Replicas change failed, Request failed (401), Authorization error");
     }
 
     private static void assertOngoing(List<ReconcilableTopic> input, List<ReconcilableTopic> output) {

File: api/src/main/java/io/strimzi/api/kafka/Crds.java
Patch:
@@ -320,7 +320,7 @@ public static <T extends CustomResource> List<String> apiVersions(Class<T> cls)
 
             List<String> versions;
             try {
-                versions = singletonList(group + "/" + (String) cls.getField("VERSION").get(null));
+                versions = singletonList(group + "/" + cls.getField("VERSION").get(null));
             } catch (NoSuchFieldException e) {
                 versions = ((List<String>) cls.getField("VERSIONS").get(null)).stream().map(v ->
                         group + "/" + v).collect(Collectors.toList());

File: api/src/main/java/io/strimzi/api/kafka/model/bridge/KafkaBridgeAdminClientSpec.java
Patch:
@@ -29,6 +29,6 @@ public class KafkaBridgeAdminClientSpec extends KafkaBridgeClientSpec {
     @Override
     @Description("The Kafka AdminClient configuration used for AdminClient instances created by the bridge.")
     public Map<String, Object> getConfig() {
-        return config;
+        return this.config != null ? this.config : Map.of();
     }
 }

File: api/src/main/java/io/strimzi/api/kafka/model/bridge/KafkaBridgeConsumerSpec.java
Patch:
@@ -36,7 +36,7 @@ public class KafkaBridgeConsumerSpec extends KafkaBridgeClientSpec {
     @Override
     @Description("The Kafka consumer configuration used for consumer instances created by the bridge. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     public Map<String, Object> getConfig() {
-        return config;
+        return this.config != null ? this.config : Map.of();
     }
 
     @JsonInclude(JsonInclude.Include.NON_DEFAULT)

File: api/src/main/java/io/strimzi/api/kafka/model/bridge/KafkaBridgeProducerSpec.java
Patch:
@@ -33,7 +33,7 @@ public class KafkaBridgeProducerSpec extends KafkaBridgeClientSpec {
     @Override
     @Description("The Kafka producer configuration used for producer instances created by the bridge. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     public Map<String, Object> getConfig() {
-        return config;
+        return this.config != null ? this.config : Map.of();
     }
 
     @JsonInclude(JsonInclude.Include.NON_DEFAULT)

File: api/src/main/java/io/strimzi/api/kafka/model/common/CertAndKeySecretSource.java
Patch:
@@ -30,7 +30,6 @@ public class CertAndKeySecretSource implements UnknownPropertyPreserving {
     private String secretName;
     private String certificate;
     private String key;
-
     private Map<String, Object> additionalProperties;
 
     @Description("The name of the Secret containing the certificate.")
@@ -65,13 +64,13 @@ public void setKey(String key) {
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/common/CertSecretSource.java
Patch:
@@ -32,7 +32,6 @@ public class CertSecretSource implements UnknownPropertyPreserving {
     private String secretName;
     private String certificate;
     private String pattern;
-
     private Map<String, Object> additionalProperties;
 
     @Description("The name of the Secret containing the certificate.")
@@ -67,13 +66,13 @@ public void setPattern(String pattern) {
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/common/CustomResourceConditions.java
Patch:
@@ -30,7 +30,6 @@
  * </pre>
  */
 public class CustomResourceConditions {
-
     private CustomResourceConditions() {
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/common/GenericSecretSource.java
Patch:
@@ -29,7 +29,6 @@
 public class GenericSecretSource implements UnknownPropertyPreserving {
     protected String secretName;
     protected String key;
-
     protected Map<String, Object> additionalProperties;
 
     @Description("The name of the Kubernetes Secret containing the secret value.")
@@ -54,13 +53,13 @@ public void setKey(String key) {
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/common/PasswordSecretSource.java
Patch:
@@ -29,7 +29,6 @@
 public class PasswordSecretSource implements UnknownPropertyPreserving {
     protected String secretName;
     protected String password;
-
     protected Map<String, Object> additionalProperties;
 
     @Description("The name of the Secret containing the password.")
@@ -54,13 +53,13 @@ public void setPassword(String password) {
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/common/TlsClientAuthentication.java
Patch:
@@ -24,13 +24,13 @@ public class TlsClientAuthentication implements UnknownPropertyPreserving {
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/common/UnknownPropertyPreserving.java
Patch:
@@ -10,7 +10,6 @@
 import java.util.Map;
 
 public interface UnknownPropertyPreserving {
-
     @JsonAnyGetter
     Map<String, Object> getAdditionalProperties();
 

File: api/src/main/java/io/strimzi/api/kafka/model/common/authentication/KafkaClientAuthentication.java
Patch:
@@ -51,7 +51,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/common/tracing/Tracing.java
Patch:
@@ -39,13 +39,13 @@ public abstract class Tracing implements UnknownPropertyPreserving {
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/connect/KafkaConnectSpec.java
Patch:
@@ -17,7 +17,6 @@
 import lombok.EqualsAndHashCode;
 import lombok.ToString;
 
-import java.util.HashMap;
 import java.util.Map;
 
 @DescriptionFile
@@ -37,15 +36,15 @@ public class KafkaConnectSpec extends AbstractKafkaConnectSpec {
     public static final String FORBIDDEN_PREFIXES = "ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers, consumer.interceptor.classes, producer.interceptor.classes";
     public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
 
-    private Map<String, Object> config = new HashMap<>(0);
+    private Map<String, Object> config;
     private String bootstrapServers;
     private ClientTls tls;
     private KafkaClientAuthentication authentication;
     private Build build;
 
     @Description("The Kafka Connect configuration. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     public Map<String, Object> getConfig() {
-        return config;
+        return this.config != null ? this.config : Map.of();
     }
 
     public void setConfig(Map<String, Object> config) {

File: api/src/main/java/io/strimzi/api/kafka/model/kafka/KafkaAuthorization.java
Patch:
@@ -50,13 +50,13 @@ public abstract class KafkaAuthorization implements UnknownPropertyPreserving {
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/kafka/KafkaResources.java
Patch:
@@ -289,7 +289,7 @@ public static String entityOperatorDeploymentName(String clusterName) {
      * Returns the name of the Entity Operator {@code Secret} for a {@code Kafka} cluster of the given name.
      * This {@code Secret} will only exist if {@code Kafka.spec.entityOperator} is configured in the
      * {@code Kafka} resource with the given name.
-     *
+     * 
      * This secret is not used anymore and is deprecated. This method will be removed in the future.
      *
      * @param clusterName  The {@code metadata.name} of the {@code Kafka} resource.

File: api/src/main/java/io/strimzi/api/kafka/model/kafka/listener/GenericKafkaListener.java
Patch:
@@ -140,13 +140,13 @@ public void setNetworkPolicyPeers(List<NetworkPolicyPeer> networkPolicyPeers) {
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/kafka/listener/KafkaListenerAuthentication.java
Patch:
@@ -49,13 +49,13 @@ public abstract class KafkaListenerAuthentication implements UnknownPropertyPres
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/mirrormaker/KafkaMirrorMakerProducerSpec.java
Patch:
@@ -43,7 +43,6 @@ public void setAbortOnSendFailure(Boolean abortOnSendFailure) {
     @Override
     @Description("The MirrorMaker producer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     public Map<String, Object> getConfig() {
-        return config;
+        return this.config != null ? this.config : Map.of();
     }
-
 }

File: api/src/main/java/io/strimzi/api/kafka/model/rebalance/KafkaRebalanceMode.java
Patch:
@@ -12,7 +12,7 @@ public enum KafkaRebalanceMode {
     ADD_BROKERS("add-brokers"),
     REMOVE_BROKERS("remove-brokers");
 
-    private String name;
+    private final String name;
 
     KafkaRebalanceMode(String name) {
         this.name = name;

File: api/src/main/java/io/strimzi/api/kafka/model/rebalance/KafkaRebalanceStatus.java
Patch:
@@ -13,7 +13,6 @@
 import lombok.EqualsAndHashCode;
 import lombok.ToString;
 
-import java.util.HashMap;
 import java.util.Map;
 
 /**
@@ -30,12 +29,12 @@
 @ToString(callSuper = true)
 public class KafkaRebalanceStatus extends Status {
     private String sessionId;
-    private Map<String, Object> optimizationResult = new HashMap<>(0);
+    private Map<String, Object> optimizationResult;
 
     @Description("A JSON object describing the optimization result")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public Map<String, Object> getOptimizationResult() {
-        return optimizationResult;
+        return optimizationResult != null ? optimizationResult : Map.of();
     }
 
     public void setOptimizationResult(Map<String, Object> optimizationResult) {

File: api/src/main/java/io/strimzi/api/kafka/model/user/KafkaUserAuthentication.java
Patch:
@@ -34,13 +34,13 @@ public abstract class KafkaUserAuthentication implements UnknownPropertyPreservi
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/user/KafkaUserAuthorization.java
Patch:
@@ -34,13 +34,13 @@ public abstract class KafkaUserAuthorization implements UnknownPropertyPreservin
 
     @Override
     public Map<String, Object> getAdditionalProperties() {
-        return this.additionalProperties;
+        return this.additionalProperties != null ? this.additionalProperties : Map.of();
     }
 
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>(1);
+            this.additionalProperties = new HashMap<>(2);
         }
         this.additionalProperties.put(name, value);
     }

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -275,7 +275,6 @@ public class Environment {
 
     public static final String KAFKA_TIERED_STORAGE_BASE_IMAGE = getOrDefault(KAFKA_TIERED_STORAGE_BASE_IMAGE_ENV, KAFKA_TIERED_STORAGE_BASE_IMAGE_DEFAULT);
 
-
     private Environment() { }
 
     static {

File: systemtest/src/main/java/io/strimzi/systemtest/TestConstants.java
Patch:
@@ -30,6 +30,7 @@ public interface TestConstants {
     long GLOBAL_CMD_CLIENT_TIMEOUT = Duration.ofMinutes(5).toMillis();
     long GLOBAL_STATUS_TIMEOUT = Duration.ofMinutes(3).toMillis();
     long GLOBAL_POLL_INTERVAL = Duration.ofSeconds(1).toMillis();
+    long GLOBAL_POLL_INTERVAL_5_SECS = Duration.ofSeconds(5).toMillis();
     long GLOBAL_POLL_INTERVAL_MEDIUM = Duration.ofSeconds(10).toMillis();
     long PRODUCER_TIMEOUT = Duration.ofSeconds(25).toMillis();
     long METRICS_COLLECT_TIMEOUT = Duration.ofMinutes(1).toMillis();

File: api/src/main/java/io/strimzi/api/kafka/model/kafka/cruisecontrol/CruiseControlSpec.java
Patch:
@@ -60,7 +60,7 @@ public class CruiseControlSpec implements HasConfigurableMetrics, HasConfigurabl
     private BrokerCapacity brokerCapacity;
     private Map<String, Object> config = new HashMap<>(0);
     private MetricsConfig metricsConfig;
-    private Map<String, Object> additionalProperties = new HashMap<>(0);
+    private final Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Description("The container image used for Cruise Control pods. "
         + "If no image name is explicitly specified, the image name corresponds to the name specified in the Cluster Operator configuration. "

File: api/src/main/java/io/strimzi/api/kafka/model/kafka/cruisecontrol/CruiseControlTemplate.java
Patch:
@@ -44,7 +44,7 @@ public class CruiseControlTemplate implements UnknownPropertyPreserving {
     private ContainerTemplate cruiseControlContainer;
     private ContainerTemplate tlsSidecarContainer;
     private ResourceTemplate serviceAccount;
-    private Map<String, Object> additionalProperties = new HashMap<>(0);
+    private final Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Description("Template for Cruise Control `Deployment`.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/CruiseControlUtils.java
Patch:
@@ -55,8 +55,8 @@ public enum Scheme {
     }
 
     public static class ApiResult {
-        private String responseText;
-        private int responseCode;
+        private final String responseText;
+        private final int responseCode;
 
         public ApiResult(ExecResult execResult) {
             this.responseText = execResult.out();

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/TieredStorageST.java
Patch:
@@ -85,7 +85,7 @@ void testTieredStorageWithAivenPlugin() {
             )
         );
 
-        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getClusterName(), 1)
+        resourceManager.createResourceWithWait(KafkaTemplates.kafkaPersistent(testStorage.getClusterName(), 3)
             .editMetadata()
                 .withNamespace(testStorage.getNamespaceName())
             .endMetadata()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -86,7 +86,7 @@ public class EntityTopicOperator extends AbstractModel implements SupportsLoggin
     private String featureGatesEnvVarValue;
 
     private String watchedNamespace;
-    /* test */ int reconciliationIntervalMs;
+    /* test */ long reconciliationIntervalMs;
     /* test */ final String resourceLabels;
     private ResourceTemplate templateRoleBinding;
 
@@ -134,7 +134,7 @@ public static EntityTopicOperator fromCrd(Reconciliation reconciliation,
             }
             result.image = image;
             result.watchedNamespace = topicOperatorSpec.getWatchedNamespace() != null ? topicOperatorSpec.getWatchedNamespace() : kafkaAssembly.getMetadata().getNamespace();
-            result.reconciliationIntervalMs = topicOperatorSpec.getReconciliationIntervalSeconds() * 1_000;
+            result.reconciliationIntervalMs = topicOperatorSpec.getReconciliationIntervalSeconds() * 1_000L;
             result.logging = new LoggingModel(topicOperatorSpec, result.getClass().getSimpleName(), true, false);
             result.gcLoggingEnabled = topicOperatorSpec.getJvmOptions() == null ? JvmOptions.DEFAULT_GC_LOGGING_ENABLED : topicOperatorSpec.getJvmOptions().isGcLoggingEnabled();
             result.jvmOptions = topicOperatorSpec.getJvmOptions();
@@ -181,7 +181,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_RESOURCE_LABELS, resourceLabels));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_BOOTSTRAP_SERVERS, kafkaBootstrapServers));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_WATCHED_NAMESPACE, watchedNamespace));
-        varList.add(ContainerUtils.createEnvVar(ENV_VAR_FULL_RECONCILIATION_INTERVAL_MS, Integer.toString(reconciliationIntervalMs)));
+        varList.add(ContainerUtils.createEnvVar(ENV_VAR_FULL_RECONCILIATION_INTERVAL_MS, Long.toString(reconciliationIntervalMs)));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_SECURITY_PROTOCOL, EntityTopicOperatorSpec.DEFAULT_SECURITY_PROTOCOL));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_TLS_ENABLED, Boolean.toString(true)));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, Boolean.toString(gcLoggingEnabled)));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -80,14 +80,14 @@ public class EntityTopicOperator extends AbstractModel implements SupportsLoggin
     /* test */ static final String ENV_VAR_CRUISE_CONTROL_AUTH_ENABLED = "STRIMZI_CRUISE_CONTROL_AUTH_ENABLED";
 
     // Kafka bootstrap servers can't be specified in the JSON
-    /* test */ String kafkaBootstrapServers;
+    /* test */ final String kafkaBootstrapServers;
     private boolean cruiseControlEnabled;
     private boolean rackAwarenessEnabled;
     private String featureGatesEnvVarValue;
 
     private String watchedNamespace;
     /* test */ int reconciliationIntervalMs;
-    /* test */ String resourceLabels;
+    /* test */ final String resourceLabels;
     private ResourceTemplate templateRoleBinding;
 
     private LoggingModel logging;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -69,9 +69,9 @@ public class EntityUserOperator extends AbstractModel implements SupportsLogging
     // Because the container shares the pod with other containers, it needs to have unique name
     /*test*/ static final String USER_OPERATOR_TMP_DIRECTORY_DEFAULT_VOLUME_NAME = "strimzi-uo-tmp";
 
-    /* test */ String kafkaBootstrapServers;
+    /* test */ final String kafkaBootstrapServers;
     private String watchedNamespace;
-    /* test */ String resourceLabels;
+    private String resourceLabels;
     /* test */ String secretPrefix;
     /* test */ long reconciliationIntervalMs;
     /* test */ int clientsCaValidityDays;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -694,7 +694,7 @@ Future<KafkaReconciler> kafkaReconciler()   {
                                 .prepareKafkaCluster(kafkaAssembly, nodePools, oldStorage, currentPods, versionChange, kafkaStatus, true)
                                 .compose(kafkaCluster -> {
                                     // We store this for use with Cruise Control later. As these configurations might
-                                    // not be exactly hte same as in the original custom resource (for example because
+                                    // not be exactly the same as in the original custom resource (for example because
                                     // of un-allowed storage changes being reverted) they are passed this way from the
                                     // KafkaCluster object and not from the custom resource.
                                     kafkaBrokerNodes = kafkaCluster.brokerNodes();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaClusterCreator.java
Patch:
@@ -227,9 +227,9 @@ private Future<KafkaAndNodePools> revertScaleDown(KafkaCluster kafka, Kafka kafk
 
                 Kafka newKafkaCr = new KafkaBuilder(kafkaCr)
                         .editSpec()
-                        .editKafka()
-                        .withReplicas(newReplicasCount)
-                        .endKafka()
+                            .editKafka()
+                                .withReplicas(newReplicasCount)
+                            .endKafka()
                         .endSpec()
                         .build();
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/BatchingTopicController.java
Patch:
@@ -465,6 +465,7 @@ private void updateInternal(List<ReconcilableTopic> topics) {
         var partitionedByManaged = remainingAfterDeletions.stream().collect(Collectors.partitioningBy(reconcilableTopic -> TopicOperatorUtil.isManaged(reconcilableTopic.kt())));
         var unmanaged = partitionedByManaged.get(false);
         addOrRemoveFinalizer(useFinalizer, unmanaged).forEach(rt -> putResult(results, rt, Either.ofRight(null)));
+        metrics.reconciliationsCounter(namespace).increment(unmanaged.size());
 
         // skip reconciliation of paused KafkaTopics
         var partitionedByPaused = validateManagedTopics(partitionedByManaged).stream().filter(hasTopicSpec)

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -205,7 +205,7 @@ public class Environment {
     private static final String ST_CLIENTS_KAFKA_VERSION_DEFAULT = "3.7.0";
     public static final String TEST_CLIENTS_VERSION_DEFAULT = "0.8.0";
     public static final String ST_FILE_PLUGIN_URL_DEFAULT = "https://repo1.maven.org/maven2/org/apache/kafka/connect-file/" + ST_KAFKA_VERSION_DEFAULT + "/connect-file-" + ST_KAFKA_VERSION_DEFAULT + ".jar";
-    public static final String OLM_OPERATOR_VERSION_DEFAULT = "0.40.0";
+    public static final String OLM_OPERATOR_VERSION_DEFAULT = "0.41.0";
 
     public static final String IP_FAMILY_DEFAULT = "ipv4";
     public static final String IP_FAMILY_VERSION_6 = "ipv6";

File: api/src/main/java/io/strimzi/api/kafka/model/user/acl/AclRule.java
Patch:
@@ -75,7 +75,8 @@ public void setResource(AclRuleResource resource) {
         this.resource = resource;
     }
 
-    @Description("The host from which the action described in the ACL rule is allowed or denied.")
+    @Description("The host from which the action described in the ACL rule is allowed or denied. " +
+            "If not set, it defaults to `*`, allowing or denying the action from any host.")
     @JsonProperty(defaultValue = "*")
     @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public String getHost() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -34,6 +34,7 @@
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
 import io.strimzi.operator.cluster.operator.resource.DefaultKafkaAgentClientProvider;
+import io.strimzi.operator.cluster.operator.resource.DefaultZooKeeperAdminProvider;
 import io.strimzi.operator.cluster.operator.resource.DefaultZookeeperScalerProvider;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.cluster.operator.resource.ZookeeperLeaderFinder;
@@ -178,6 +179,7 @@ public void beforeEach(TestInfo testInfo, VertxTestContext testContext) {
                 new DefaultZookeeperScalerProvider(),
                 new DefaultKafkaAgentClientProvider(),
                 metricsProvider,
+                new DefaultZooKeeperAdminProvider(),
                 pfa, 10_000);
 
         podSetController = new StrimziPodSetController(namespace, Labels.EMPTY, ros.kafkaOperator, ros.connectOperator, ros.mirrorMaker2Operator, ros.strimziPodSetOperator, ros.podOperations, ros.metricsProvider, Integer.parseInt(ClusterOperatorConfig.POD_SET_CONTROLLER_WORK_QUEUE_SIZE.defaultValue()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageMockTest.java
Patch:
@@ -150,7 +150,7 @@ public void beforeEach(TestInfo testInfo) {
                 new ResourceOperatorSupplier(JbodStorageMockTest.vertx, client,
                         ResourceUtils.zookeeperLeaderFinder(JbodStorageMockTest.vertx, client),
                         ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(),
-                        ResourceUtils.metricsProvider(), pfa, 60_000L);
+                        ResourceUtils.metricsProvider(), ResourceUtils.zooKeeperAdminProvider(), pfa, 60_000L);
 
         podSetController = new StrimziPodSetController(namespace, Labels.EMPTY, ros.kafkaOperator, ros.connectOperator, ros.mirrorMaker2Operator, ros.strimziPodSetOperator, ros.podOperations, ros.metricsProvider, Integer.parseInt(ClusterOperatorConfig.POD_SET_CONTROLLER_WORK_QUEUE_SIZE.defaultValue()));
         podSetController.start();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KRaftMigrationMockTest.java
Patch:
@@ -174,7 +174,7 @@ public void afterEach() {
 
     private Future<Void> initialize() {
         supplier =  new ResourceOperatorSupplier(vertx, client, ResourceUtils.zookeeperLeaderFinder(vertx, client), ResourceUtils.adminClientProvider(),
-                ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(), ResourceUtils.metricsProvider(), PFA, 2_000);
+                ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(), ResourceUtils.metricsProvider(), ResourceUtils.zooKeeperAdminProvider(), PFA, 2_000);
 
         podSetController = new StrimziPodSetController(namespace, Labels.EMPTY, supplier.kafkaOperator, supplier.connectOperator, supplier.mirrorMaker2Operator, supplier.strimziPodSetOperator, supplier.podOperations, supplier.metricsProvider, Integer.parseInt(ClusterOperatorConfig.POD_SET_CONTROLLER_WORK_QUEUE_SIZE.defaultValue()));
         podSetController.start();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorCustomCertMockTest.java
Patch:
@@ -118,6 +118,7 @@ private ResourceOperatorSupplier supplier(KubernetesClient bootstrapClient, Plat
                 ResourceUtils.zookeeperLeaderFinder(vertx, bootstrapClient),
                 ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(),
                 ResourceUtils.metricsProvider(),
+                ResourceUtils.zooKeeperAdminProvider(),
                 pfa,
                 60_000L);
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -191,7 +191,7 @@ public void afterEach() {
     private ResourceOperatorSupplier supplierWithMocks() {
         return new ResourceOperatorSupplier(vertx, client, ResourceUtils.zookeeperLeaderFinder(vertx, client),
                 ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(),
-                ResourceUtils.metricsProvider(), new PlatformFeaturesAvailability(false, KubernetesVersion.MINIMAL_SUPPORTED_VERSION), 2_000);
+                ResourceUtils.metricsProvider(), ResourceUtils.zooKeeperAdminProvider(), new PlatformFeaturesAvailability(false, KubernetesVersion.MINIMAL_SUPPORTED_VERSION), 2_000);
     }
 
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorWithPoolsKRaftMockTest.java
Patch:
@@ -185,7 +185,7 @@ public void beforeEach(TestInfo testInfo) {
     private ResourceOperatorSupplier supplierWithMocks() {
         return new ResourceOperatorSupplier(vertx, client, ResourceUtils.zookeeperLeaderFinder(vertx, client),
                 ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(),
-                ResourceUtils.metricsProvider(), new PlatformFeaturesAvailability(false, KubernetesVersion.MINIMAL_SUPPORTED_VERSION), 2_000);
+                ResourceUtils.metricsProvider(), ResourceUtils.zooKeeperAdminProvider(), new PlatformFeaturesAvailability(false, KubernetesVersion.MINIMAL_SUPPORTED_VERSION), 2_000);
     }
 
     @AfterEach

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorWithPoolsMockTest.java
Patch:
@@ -207,7 +207,7 @@ public void afterEach() {
     private ResourceOperatorSupplier supplierWithMocks() {
         return new ResourceOperatorSupplier(vertx, client, ResourceUtils.zookeeperLeaderFinder(vertx, client),
                 ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(),
-                ResourceUtils.metricsProvider(), new PlatformFeaturesAvailability(false, KubernetesVersion.MINIMAL_SUPPORTED_VERSION), 2_000);
+                ResourceUtils.metricsProvider(), ResourceUtils.zooKeeperAdminProvider(), new PlatformFeaturesAvailability(false, KubernetesVersion.MINIMAL_SUPPORTED_VERSION), 2_000);
     }
 
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -103,7 +103,7 @@ public void beforeEach(TestInfo testInfo) {
         namespace = testInfo.getTestMethod().orElseThrow().getName().toLowerCase(Locale.ROOT);
         mockKube.prepareNamespace(namespace);
 
-        supplier = new ResourceOperatorSupplier(vertx, client, ResourceUtils.zookeeperLeaderFinder(vertx, client), ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(), ResourceUtils.metricsProvider(), PFA, 2_000);
+        supplier = new ResourceOperatorSupplier(vertx, client, ResourceUtils.zookeeperLeaderFinder(vertx, client), ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(), ResourceUtils.metricsProvider(), ResourceUtils.zooKeeperAdminProvider(), PFA, 2_000);
         podSetController = new StrimziPodSetController(namespace, Labels.EMPTY, supplier.kafkaOperator, supplier.connectOperator, supplier.mirrorMaker2Operator, supplier.strimziPodSetOperator, supplier.podOperations, supplier.metricsProvider, Integer.parseInt(ClusterOperatorConfig.POD_SET_CONTROLLER_WORK_QUEUE_SIZE.defaultValue()));
         podSetController.start();
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -18,6 +18,7 @@
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.DefaultKafkaAgentClientProvider;
+import io.strimzi.operator.cluster.operator.resource.DefaultZooKeeperAdminProvider;
 import io.strimzi.operator.cluster.operator.resource.DefaultZookeeperScalerProvider;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.cluster.operator.resource.ZookeeperLeaderFinder;
@@ -119,6 +120,7 @@ public void beforeEach(TestInfo testInfo) {
                 new DefaultZookeeperScalerProvider(),
                 new DefaultKafkaAgentClientProvider(),
                 ResourceUtils.metricsProvider(),
+                new DefaultZooKeeperAdminProvider(),
                 PFA, 60_000L);
         podSetController = new StrimziPodSetController(namespace, Labels.EMPTY, supplier.kafkaOperator, supplier.connectOperator, supplier.mirrorMaker2Operator, supplier.strimziPodSetOperator, supplier.podOperations, supplier.metricsProvider, Integer.parseInt(ClusterOperatorConfig.POD_SET_CONTROLLER_WORK_QUEUE_SIZE.defaultValue()));
         podSetController.start();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -138,7 +138,7 @@ public void beforeEach(TestInfo testInfo) {
         ccServer.reset();
 
         supplier =  new ResourceOperatorSupplier(vertx, client, ResourceUtils.zookeeperLeaderFinder(vertx, client), ResourceUtils.adminClientProvider(),
-                ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(), ResourceUtils.metricsProvider(), PFA, 2_000);
+                ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(), ResourceUtils.metricsProvider(), ResourceUtils.zooKeeperAdminProvider(), PFA, 2_000);
 
         // Override to inject mocked cruise control address so real cruise control not required
         krao = new KafkaRebalanceAssemblyOperator(vertx, supplier, ResourceUtils.dummyClusterOperatorConfig()) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpgradeDowngradeMockTest.java
Patch:
@@ -144,7 +144,7 @@ public void afterEach() {
 
     private Future<Void> initialize()   {
         supplier =  new ResourceOperatorSupplier(vertx, client, ResourceUtils.zookeeperLeaderFinder(vertx, client), ResourceUtils.adminClientProvider(),
-                ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(), ResourceUtils.metricsProvider(), PFA, 2_000);
+                ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(), ResourceUtils.metricsProvider(), ResourceUtils.zooKeeperAdminProvider(), PFA, 2_000);
 
         podSetController = new StrimziPodSetController(namespace, Labels.EMPTY, supplier.kafkaOperator, supplier.connectOperator, supplier.mirrorMaker2Operator, supplier.strimziPodSetOperator, supplier.podOperations, supplier.metricsProvider, Integer.parseInt(ClusterOperatorConfig.POD_SET_CONTROLLER_WORK_QUEUE_SIZE.defaultValue()));
         podSetController.start();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpgradeDowngradeWithKRaftMockTest.java
Patch:
@@ -181,7 +181,7 @@ private Future<Void> initialize(String initialMetadataVersion)   {
         metadataLevel = new AtomicInteger(metadataVersionToLevel(initialMetadataVersion));
         mockAdminClient(mockAdmin);
         supplier =  new ResourceOperatorSupplier(vertx, client, ResourceUtils.zookeeperLeaderFinder(vertx, client), ResourceUtils.adminClientProvider(mockAdmin),
-                ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(), ResourceUtils.metricsProvider(), PFA, 2_000);
+                ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(), ResourceUtils.metricsProvider(), ResourceUtils.zooKeeperAdminProvider(), PFA, 2_000);
 
         podSetController = new StrimziPodSetController(namespace, Labels.EMPTY, supplier.kafkaOperator, supplier.connectOperator, supplier.mirrorMaker2Operator, supplier.strimziPodSetOperator, supplier.podOperations, supplier.metricsProvider, Integer.parseInt(ClusterOperatorConfig.POD_SET_CONTROLLER_WORK_QUEUE_SIZE.defaultValue()));
         podSetController.start();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateMockTest.java
Patch:
@@ -177,6 +177,7 @@ ResourceOperatorSupplier supplier(KubernetesClient bootstrapClient, PlatformFeat
                 ResourceUtils.zookeeperLeaderFinder(vertx, bootstrapClient),
                 ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(), ResourceUtils.kafkaAgentClientProvider(),
                 ResourceUtils.metricsProvider(),
+                ResourceUtils.zooKeeperAdminProvider(),
                 pfa,
                 60_000L);
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/events/KubernetesRestartEventsMockTest.java
Patch:
@@ -188,6 +188,7 @@ void beforeEach(TestInfo testInfo, Vertx vertx) throws ExecutionException, Inter
                 ResourceUtils.zookeeperScalerProvider(),
                 ResourceUtils.kafkaAgentClientProvider(),
                 ResourceUtils.metricsProvider(),
+                ResourceUtils.zooKeeperAdminProvider(),
                 PFA,
                 60_000);
 
@@ -613,6 +614,7 @@ public Admin createAdminClient(String bootstrapHostnames, PemTrustSet kafkaCaTru
                 ResourceUtils.zookeeperScalerProvider(),
                 ResourceUtils.kafkaAgentClientProvider(),
                 ResourceUtils.metricsProvider(),
+                ResourceUtils.zooKeeperAdminProvider(),
                 PFA,
                 60_000);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/specific/RackAwarenessST.java
Patch:
@@ -121,7 +121,7 @@ void testKafkaRackAwareness() {
 
         String rackIdOut = cmdKubeClient(testStorage.getNamespaceName()).execInPod(podName, "/bin/bash", "-c", "cat /opt/kafka/init/rack.id").out().trim();
         String brokerRackOut = cmdKubeClient(testStorage.getNamespaceName()).execInPod(podName, "/bin/bash", "-c", "cat /tmp/strimzi.properties | grep broker.rack").out().trim();
-        assertThat(rackIdOut.trim(), is(hostname));
+        assertThat(rackIdOut.trim().contains(hostname), is(true));
         assertThat(brokerRackOut.contains("broker.rack=" + hostname), is(true));
 
         LOGGER.info("Producing and Consuming data in the Kafka cluster: {}/{}", testStorage.getNamespaceName(), testStorage.getClusterName());
@@ -208,7 +208,7 @@ void testConnectRackAwareness() {
         String hostname = podNodeName.contains(".") ? podNodeName.substring(0, podNodeName.indexOf(".")) : podNodeName;
         String commandOut = cmdKubeClient(testStorage.getNamespaceName()).execInPod(podName,
                 "/bin/bash", "-c", "cat /tmp/strimzi-connect.properties | grep consumer.client.rack").out().trim();
-        assertThat(commandOut.equals("consumer.client.rack=" + hostname), is(true));
+        assertThat(commandOut.contains("consumer.client.rack=" + hostname), is(true));
 
         // produce data which are to be available in the topic
         final KafkaClients kafkaClients = ClientUtils.getInstantPlainClients(testStorage);
@@ -287,7 +287,7 @@ void testMirrorMaker2RackAwareness() {
         String podNodeName = pod.getSpec().getNodeName();
         String hostname = podNodeName.contains(".") ? podNodeName.substring(0, podNodeName.indexOf(".")) : podNodeName;
         String commandOut = cmdKubeClient(testStorage.getNamespaceName()).execInPod(podName, "/bin/bash", "-c", "cat /tmp/strimzi-connect.properties | grep consumer.client.rack").out().trim();
-        assertThat(commandOut.equals("consumer.client.rack=" + hostname), is(true));
+        assertThat(commandOut.contains("consumer.client.rack=" + hostname), is(true));
 
         // Mirroring messages by: Producing to the Source Kafka Cluster and consuming them from mirrored KafkaTopic in target Kafka Cluster.
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/BatchingTopicController.java
Patch:
@@ -557,8 +557,8 @@ private void updateInternal(List<ReconcilableTopic> topics) {
         } else {
             okStream = differentRfResults.ok().map(pair -> {
                 var reconcilableTopic = pair.getKey();
-                var specPartitions = partitions(reconcilableTopic.kt());
-                var partitions = pair.getValue().partitionsWithDifferentRfThan(specPartitions);
+                var specReplicas = replicas(reconcilableTopic.kt());
+                var partitions = pair.getValue().partitionsWithDifferentRfThan(specReplicas);
                 return pair(reconcilableTopic, Either.ofLeft(new TopicOperatorException.NotSupported(
                     "Replication factor change not supported, but required for partitions " + partitions)));
             });

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceOperation.java
Patch:
@@ -97,7 +97,7 @@ public static long getTimeoutForResourceDeletion(String kind) {
                 timeout = Duration.ofMinutes(5).toMillis();
                 break;
             default:
-                timeout = Duration.ofMinutes(3).toMillis();
+                timeout = Duration.ofMinutes(2).toMillis();
         }
 
         return timeout;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java
Patch:
@@ -581,7 +581,7 @@ public static void removeAnnotation(String clusterName, String namespaceName, St
     }
 
     public static void waitUntilKafkaStatusContainsKafkaMetadataState(String namespaceName, String clusterName, KafkaMetadataState desiredKafkaMetadataState) {
-        TestUtils.waitFor(String.join("Kafka status to be contain kafkaMetadataState: %s", desiredKafkaMetadataState.name()), TestConstants.GLOBAL_POLL_INTERVAL, TestConstants.GLOBAL_STATUS_TIMEOUT, () -> {
+        TestUtils.waitFor(String.join("Kafka status to be contain kafkaMetadataState: %s", desiredKafkaMetadataState.name()), TestConstants.GLOBAL_POLL_INTERVAL, TestConstants.GLOBAL_TIMEOUT, () -> {
             Kafka k = KafkaResource.kafkaClient().inNamespace(namespaceName).withName(clusterName).get();
             return k.getStatus().getKafkaMetadataState().equals(desiredKafkaMetadataState);
         });

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Connectors.java
Patch:
@@ -150,6 +150,7 @@ public List<KafkaConnector> generateConnectorDefinitions()    {
                                 .withConfig(prepareMirrorMaker2ConnectorConfig(mirror, mm2ConnectorSpec, clusters.get(mirror.getSourceCluster()), clusters.get(mirror.getTargetCluster())))
                                 .withPause(mm2ConnectorSpec.getPause())
                                 .withState(mm2ConnectorSpec.getState())
+                                .withAutoRestart(mm2ConnectorSpec.getAutoRestart())
                                 .withTasksMax(mm2ConnectorSpec.getTasksMax())
                             .endSpec()
                             .build();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KRaftUtils.java
Patch:
@@ -152,7 +152,7 @@ public static void validateVersionsForKRaftMigration(String kafkaVersionFromCr,
 
         MetadataVersion kafkaVersion = MetadataVersion.fromVersionString(kafkaVersionFromCr);
         // this should check that spec.kafka.version is >= 3.7.0
-        boolean isMigrationSupported = kafkaVersion.isMigrationSupported();
+        boolean isMigrationSupported = kafkaVersion.isAtLeast(MetadataVersion.IBP_3_7_IV0);
 
         MetadataVersion metadataVersion = MetadataVersion.fromVersionString(metadataVersionFromCr);
         MetadataVersion interBrokerProtocolVersion = MetadataVersion.fromVersionString(interBrokerProtocolVersionFromCr);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KRaftUtilsTest.java
Patch:
@@ -281,7 +281,7 @@ public void testZooKeeperWarnings() {
     @ParallelTest
     public void testsVersionsForKRaftMigrationValidation() {
         // Valid values
-        assertDoesNotThrow(() -> KRaftUtils.validateVersionsForKRaftMigration("3.6.1", "3.6-IV2", "3.6", "3.6"));
+        assertDoesNotThrow(() -> KRaftUtils.validateVersionsForKRaftMigration("3.7.0", "3.7-IV4", "3.7", "3.7"));
 
         // Invalid Values
         InvalidResourceException e = assertThrows(InvalidResourceException.class, () -> KRaftUtils.validateVersionsForKRaftMigration("3.6.1", "3.6-IV2", "3.5", "3.5"));

File: systemtest/src/test/java/io/strimzi/systemtest/migration/MigrationST.java
Patch:
@@ -691,6 +691,7 @@ private void assertThatClusterMetadataTopicPresentInBrokerPod(String namespaceNa
     @BeforeAll
     void setup() {
         // skip if Kafka version is lower than 3.7.0
+        // TODO: remove once support for Kafka 3.6.x is removed - https://github.com/strimzi/strimzi-kafka-operator/issues/9921
         assumeTrue(TestKafkaVersion.compareDottedVersions(Environment.ST_KAFKA_VERSION, "3.7.0") >= 0);
         assumeTrue(Environment.isKafkaNodePoolsEnabled() && Environment.isKRaftForCOEnabled());
         this.clusterOperator = this.clusterOperator

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java
Patch:
@@ -62,10 +62,11 @@ public static void waitUntilKafkaConnectRestApiIsAvailable(String namespaceName,
         LOGGER.info("KafkaConnect API is available");
     }
 
-    public static void waitForMessagesInKafkaConnectFileSink(String namespaceName, String kafkaConnectPodName, String sinkFileName, String message) {
+    public static void waitForMessagesInKafkaConnectFileSink(String namespaceName, String kafkaConnectPodName, String sinkFileName, int sinkReceivedMsgCount) {
+        final String lastReceivedMessageIndex = Integer.toString(sinkReceivedMsgCount - 1);
         LOGGER.info("Waiting for messages to be present in file sink on {}/{}", namespaceName, kafkaConnectPodName);
         TestUtils.waitFor("messages to be present in file sink", TestConstants.GLOBAL_POLL_INTERVAL, TestConstants.TIMEOUT_FOR_SEND_RECEIVE_MSG,
-            () -> cmdKubeClient(namespaceName).execInPod(Level.TRACE, kafkaConnectPodName, "/bin/bash", "-c", "cat " + sinkFileName).out().contains(message),
+            () -> cmdKubeClient(namespaceName).execInPod(Level.TRACE, kafkaConnectPodName, "/bin/bash", "-c", "cat " + sinkFileName).out().contains(lastReceivedMessageIndex),
             () -> LOGGER.warn(cmdKubeClient(namespaceName).execInPod(Level.TRACE, kafkaConnectPodName, "/bin/bash", "-c", "cat " + sinkFileName).out()));
         LOGGER.info("Expected messages are in file sink on {}/{}", namespaceName, kafkaConnectPodName);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicReplicasChangeST.java
Patch:
@@ -422,7 +422,7 @@ private void sendAndRecvMessages(final TestStorage testStorage) {
                 kafkaClients.producerStrimzi(),
                 kafkaClients.consumerStrimzi()
         );
-        ClientUtils.waitForClientsSuccess(testStorage);
+        ClientUtils.waitForInstantClientSuccess(testStorage);
     }
 
     @BeforeAll

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPasswordGrantsST.java
Patch:
@@ -426,7 +426,7 @@ void testPasswordGrantsKafkaConnect() {
 
         KafkaConnectorUtils.createFileSinkConnector(Environment.TEST_SUITE_NAMESPACE, kafkaConnectPodName, testStorage.getTopicName(), TestConstants.DEFAULT_SINK_FILE_PATH, "http://localhost:8083");
 
-        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(Environment.TEST_SUITE_NAMESPACE, kafkaConnectPodName, TestConstants.DEFAULT_SINK_FILE_PATH, "\"Hello-world - 99\"");
+        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(Environment.TEST_SUITE_NAMESPACE, kafkaConnectPodName, TestConstants.DEFAULT_SINK_FILE_PATH, testStorage.getMessageCount());
 
         final String kafkaConnectLogs = KubeClusterResource.cmdKubeClient(Environment.TEST_SUITE_NAMESPACE).execInCurrentNamespace(Level.DEBUG, "logs", kafkaConnectPodName).out();
         verifyOauthConfiguration(kafkaConnectLogs);

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
Patch:
@@ -367,7 +367,7 @@ void testProducerConsumerConnectWithOauthMetrics() {
 
         KafkaConnectorUtils.createFileSinkConnector(Environment.TEST_SUITE_NAMESPACE, kafkaConnectPodName, testStorage.getTopicName(), TestConstants.DEFAULT_SINK_FILE_PATH, "http://localhost:8083");
 
-        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(Environment.TEST_SUITE_NAMESPACE, kafkaConnectPodName, TestConstants.DEFAULT_SINK_FILE_PATH, "\"Hello-world - 99\"");
+        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(Environment.TEST_SUITE_NAMESPACE, kafkaConnectPodName, TestConstants.DEFAULT_SINK_FILE_PATH, testStorage.getMessageCount());
 
         final String kafkaConnectLogs = KubeClusterResource.cmdKubeClient(Environment.TEST_SUITE_NAMESPACE).execInCurrentNamespace(Level.DEBUG, "logs", kafkaConnectPodName).out();
         verifyOauthConfiguration(kafkaConnectLogs);

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -188,7 +188,7 @@ void testProducerConsumerConnect() {
 
         KafkaConnectorUtils.createFileSinkConnector(Environment.TEST_SUITE_NAMESPACE, scraperPodName, testStorage.getTopicName(), TestConstants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(testStorage.getClusterName(), Environment.TEST_SUITE_NAMESPACE, 8083));
 
-        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(Environment.TEST_SUITE_NAMESPACE, kafkaConnectPodName, TestConstants.DEFAULT_SINK_FILE_PATH, "\"Hello-world - 99\"");
+        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(Environment.TEST_SUITE_NAMESPACE, kafkaConnectPodName, TestConstants.DEFAULT_SINK_FILE_PATH, testStorage.getMessageCount());
     }
 
     @Description("As a OAuth bridge, i am able to send messages to bridge endpoint using encrypted communication")

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/kraft/KRaftStrimziDowngradeST.java
Patch:
@@ -92,7 +92,7 @@ private void performDowngrade(BundleVersionModificationData downgradeData) throw
         checkAllImages(downgradeData, TestConstants.CO_NAMESPACE);
 
         // Verify upgrade
-        verifyProcedure(downgradeData, testStorage.getProducerName(), testStorage.getConsumerName(), TestConstants.CO_NAMESPACE, wasUTOUsedBefore);
+        verifyProcedure(downgradeData, testStorage.getContinuousProducerName(), testStorage.getContinuousConsumerName(), TestConstants.CO_NAMESPACE, wasUTOUsedBefore);
     }
 
     @BeforeEach

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/regular/StrimziDowngradeST.java
Patch:
@@ -91,7 +91,7 @@ private void performDowngrade(BundleVersionModificationData downgradeData) throw
         PodUtils.verifyThatRunningPodsAreStable(TestConstants.CO_NAMESPACE, clusterName);
         checkAllImages(downgradeData, TestConstants.CO_NAMESPACE);
         // Verify upgrade
-        verifyProcedure(downgradeData, testStorage.getProducerName(), testStorage.getConsumerName(), TestConstants.CO_NAMESPACE, wasUTOUsedBefore);
+        verifyProcedure(downgradeData, testStorage.getContinuousProducerName(), testStorage.getContinuousConsumerName(), TestConstants.CO_NAMESPACE, wasUTOUsedBefore);
     }
 
     @BeforeEach

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -224,7 +224,7 @@ public class Environment {
     public static final String STRIMZI_RBAC_SCOPE = getOrDefault(STRIMZI_RBAC_SCOPE_ENV, STRIMZI_RBAC_SCOPE_DEFAULT);
     public static final String STRIMZI_FEATURE_GATES = getOrDefault(STRIMZI_FEATURE_GATES_ENV, STRIMZI_FEATURE_GATES_DEFAULT);
     public static final boolean STRIMZI_USE_KRAFT_IN_TESTS = getOrDefault(STRIMZI_USE_KRAFT_IN_TESTS_ENV, Boolean::parseBoolean, false);
-    public static final boolean STRIMZI_USE_NODE_POOLS_IN_TESTS = getOrDefault(STRIMZI_USE_NODE_POOLS_IN_TESTS_ENV, Boolean::parseBoolean, false);
+    public static final boolean STRIMZI_USE_NODE_POOLS_IN_TESTS = getOrDefault(STRIMZI_USE_NODE_POOLS_IN_TESTS_ENV, Boolean::parseBoolean, true);
     public static final NodePoolsRoleMode STRIMZI_NODE_POOLS_ROLE_MODE = getOrDefault(STRIMZI_NODE_POOLS_ROLE_MODE_ENV, value -> NodePoolsRoleMode.valueOf(value.toUpperCase(Locale.ENGLISH)), NodePoolsRoleMode.SEPARATE);
 
     // variables for kafka client app images

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaTemplates.java
Patch:
@@ -486,6 +486,8 @@ private static KafkaBuilder removeFieldsNotRelatedToParticularMode(KafkaBuilder
         // fields here
         if (!withZookeeper) {
             kafka.getSpec().setZookeeper(null);
+            kafka.getSpec().getKafka().getConfig().remove("log.message.format.version");
+            kafka.getSpec().getKafka().getConfig().remove("inter.broker.protocol.version");
 
             if (!Environment.isUnidirectionalTopicOperatorEnabled()) {
                 kafka.getSpec().getEntityOperator().setTopicOperator(null);

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlST.java
Patch:
@@ -285,9 +285,9 @@ void testCruiseControlWithSingleNodeKafka() {
         if (Environment.isKafkaNodePoolsEnabled()) {
             KafkaNodePoolResource.replaceKafkaNodePoolResourceInSpecificNamespace(testStorage.getBrokerPoolName(), knp ->
                 knp.getSpec().setReplicas(scaleTo), testStorage.getNamespaceName());
+        } else {
+            KafkaResource.replaceKafkaResourceInSpecificNamespace(testStorage.getClusterName(), kafka -> kafka.getSpec().getKafka().setReplicas(3), testStorage.getNamespaceName());
         }
-        // should be moved to else block once the issue - https://github.com/strimzi/strimzi-kafka-operator/issues/8770 - will be fixed
-        KafkaResource.replaceKafkaResourceInSpecificNamespace(testStorage.getClusterName(), kafka -> kafka.getSpec().getKafka().setReplicas(3), testStorage.getNamespaceName());
         KafkaUtils.waitForKafkaReady(testStorage.getNamespaceName(), testStorage.getClusterName());
 
         kafkaStatus = KafkaResource.kafkaClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).get().getStatus();

File: systemtest/src/main/java/io/strimzi/systemtest/TestConstants.java
Patch:
@@ -533,7 +533,7 @@ public interface TestConstants {
     /**
      * NodePool's name prefix based on role
      */
-    String MIXED_ROLE_PREFIX = "mixed-";
-    String BROKER_ROLE_PREFIX = "broker-";
-    String CONTROLLER_ROLE_PREFIX = "control-";
+    String MIXED_ROLE_PREFIX = "m-";
+    String BROKER_ROLE_PREFIX = "b-";
+    String CONTROLLER_ROLE_PREFIX = "c-";
 }

File: systemtest/src/main/java/io/strimzi/systemtest/storage/TestStorage.java
Patch:
@@ -38,9 +38,7 @@ final public class TestStorage {
     private static final String CONSUMER = "hello-world-consumer";
     private static final String ADMIN = "admin-client";
     private static final String USER = "user";
-    private static final String CLUSTER_NAME_PREFIX = "my-cluster-";
-    private static final String BROKER_ROLE_PREFIX = "broker-";
-    private static final String CONTROLLER_ROLE_PREFIX = "controller-";
+    private static final String CLUSTER_NAME_PREFIX = "cluster-";
     private static final Random RANDOM = new Random();
 
     private ExtensionContext extensionContext;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/MetricsUtils.java
Patch:
@@ -59,7 +59,6 @@ public static String getExporterRunScript(String podName, String namespace) thro
     }
 
     public static MetricsCollector setupCOMetricsCollectorInNamespace(String coName, String coNamespace, String coScraperName) {
-
         LabelSelector scraperDeploymentPodLabel = new LabelSelector(null, Map.of(TestConstants.APP_POD_LABEL, coScraperName));
         String coScraperPodName = ResourceManager.kubeClient().listPods(coNamespace, scraperDeploymentPodLabel).get(0).getMetadata().getName();
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeCorsST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.systemtest.resources.NodePoolsConverter;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;
+import io.strimzi.systemtest.resources.kubernetes.NetworkPolicyResource;
 import io.strimzi.systemtest.storage.TestStorage;
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
@@ -149,6 +150,8 @@ void beforeAll() {
             .endMetadata()
             .build());
 
+        NetworkPolicyResource.allowNetworkPolicySettingsForBridgeScraper(suiteTestStorage.getNamespaceName(), suiteTestStorage.getScraperPodName(), KafkaBridgeResources.componentName(suiteTestStorage.getClusterName()));
+
         KafkaBridgeHttpCors kafkaBridgeHttpCors = KafkaBridgeResource.kafkaBridgeClient().inNamespace(suiteTestStorage.getNamespaceName()).withName(suiteTestStorage.getClusterName()).get().getSpec().getHttp().getCors();
         LOGGER.info("Bridge with the following CORS settings {}", kafkaBridgeHttpCors.toString());
 

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java
Patch:
@@ -45,6 +45,7 @@
 import static io.strimzi.systemtest.TestConstants.LOADBALANCER_SUPPORTED;
 import static io.strimzi.systemtest.TestConstants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.TestConstants.REGRESSION;
+import static io.strimzi.systemtest.TestConstants.ROUTE;
 import static org.junit.jupiter.api.Assumptions.assumeFalse;
 
 @Tag(REGRESSION)
@@ -103,6 +104,7 @@ void testMultipleLoadBalancers() {
 
     @OpenShiftOnly
     @Tag(EXTERNAL_CLIENTS_USED)
+    @Tag(ROUTE)
     @IsolatedTest("Using more tha one Kafka cluster in one namespace")
     void testMultipleRoutes() {
         final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java
Patch:
@@ -18,6 +18,7 @@
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.TestConstants;
 import io.strimzi.systemtest.annotations.IsolatedTest;
+import io.strimzi.systemtest.annotations.SkipDefaultNetworkPolicyCreation;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
 import io.strimzi.systemtest.metrics.MetricsCollector;
 import io.strimzi.systemtest.resources.ComponentType;
@@ -298,6 +299,8 @@ void testNPWhenOperatorIsInDifferentNamespaceThanOperand() {
 
     @IsolatedTest("Specific Cluster Operator for test case")
     @Tag(CRUISE_CONTROL)
+    @SkipDefaultNetworkPolicyCreation("NetworkPolicy generation from CO is disabled in this test, resulting in problems with connection" +
+        " in case of that DENY ALL global NetworkPolicy is used")
     void testNPGenerationEnvironmentVariable() {
         assumeTrue(!Environment.isHelmInstall() && !Environment.isOlmInstall());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Connectors.java
Patch:
@@ -282,8 +282,8 @@ private static String oauthJaasConfig(KafkaMirrorMaker2ClusterSpec cluster, Kafk
         }
 
         if (oauth.getTlsTrustedCertificates() != null && !oauth.getTlsTrustedCertificates().isEmpty()) {
-            jaasOptions.put("oauth.ssl.truststore.location", "/tmp/kafka/clusters/\"" + cluster.getAlias() + "\"-oauth.truststore.p12");
-            jaasOptions.put("oauth.ssl.truststore.password", "\"${file:" + CONNECTORS_CONFIG_FILE + ":oauth.ssl.truststore.password}\"");
+            jaasOptions.put("oauth.ssl.truststore.location", "/tmp/kafka/clusters/" + cluster.getAlias() + "-oauth.truststore.p12");
+            jaasOptions.put("oauth.ssl.truststore.password", "${file:" + CONNECTORS_CONFIG_FILE + ":oauth.ssl.truststore.password}");
             jaasOptions.put("oauth.ssl.truststore.type", "PKCS12");
         }
 

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -170,7 +170,9 @@ void tearDownTestCase(ExtensionContext extensionContext) throws Exception {
         // does not proceed with the next method (i.e., afterEachMustExecute()). This ensures that if such problem happen
         // it will always execute the second method.
         try {
-            assertNoCoErrorsLogged(clusterOperator.getDeploymentNamespace(), storageMap.get(extensionContext).getTestExecutionTimeInSeconds());
+            // This method needs to be disabled for the moment, as it brings flakiness and is unstable due to regexes and current matcher checks.
+            // Needs to be reworked on what errors to ignore. Better error logging should be added.
+            //assertNoCoErrorsLogged(clusterOperator.getDeploymentNamespace(), storageMap.get(extensionContext).getTestExecutionTimeInSeconds());
         } finally {
             afterEachMayOverride();
             afterEachMustExecute();

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -170,7 +170,7 @@ void tearDownTestCase(ExtensionContext extensionContext) throws Exception {
         // does not proceed with the next method (i.e., afterEachMustExecute()). This ensures that if such problem happen
         // it will always execute the second method.
         try {
-            //assertNoCoErrorsLogged(clusterOperator.getDeploymentNamespace(), storageMap.get(extensionContext).getTestExecutionTimeInSeconds());
+            assertNoCoErrorsLogged(clusterOperator.getDeploymentNamespace(), storageMap.get(extensionContext).getTestExecutionTimeInSeconds());
         } finally {
             afterEachMayOverride();
             afterEachMustExecute();

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/QuotasST.java
Patch:
@@ -16,6 +16,7 @@
 import io.strimzi.systemtest.templates.crd.KafkaNodePoolTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
+import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.JobUtils;
 import io.strimzi.test.WaitException;
 import org.hamcrest.CoreMatchers;
@@ -87,8 +88,8 @@ void testKafkaQuotasPluginIntegration() {
 
     @AfterEach
     void afterEach() {
-        final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-        kubeClient(testStorage.getNamespaceName()).getClient().persistentVolumeClaims().inNamespace(testStorage.getNamespaceName()).delete();
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(Environment.TEST_SUITE_NAMESPACE, ResourceManager.getTestContext());
+        kubeClient().getClient().persistentVolumeClaims().inNamespace(namespaceName).delete();
     }
 
     @BeforeAll

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/ListenersST.java
Patch:
@@ -2519,8 +2519,8 @@ void testAdvertisedHostNamesAppearsInBrokerCerts() throws CertificateException {
 
     @AfterEach
     void afterEach() {
-        final TestStorage testStorage = new TestStorage(ResourceManager.getTestContext());
-        kubeClient(testStorage.getNamespaceName()).getClient().persistentVolumeClaims().inNamespace(testStorage.getNamespaceName()).delete();
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(Environment.TEST_SUITE_NAMESPACE, ResourceManager.getTestContext());
+        kubeClient(namespaceName).getClient().persistentVolumeClaims().inNamespace(namespaceName).delete();
     }
 
     private ASN1Encodable[] retrieveKafkaBrokerSANs(final TestStorage testStorage) {

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -151,6 +151,7 @@ private void testWeirdUsername(String weirdUserName, KafkaListenerAuthentication
             .withProducerName(testStorage.getClusterName() + "-" + producerName)
             .withConsumerName(testStorage.getClusterName() + "-" + consumerName)
             .withBootstrapAddress(KafkaBridgeResources.serviceName(testStorage.getClusterName()))
+            .withComponentName(KafkaBridgeResources.componentName(testStorage.getClusterName()))
             .withTopicName(testStorage.getTopicName())
             .withMessageCount(testStorage.getMessageCount())
             .withPort(TestConstants.HTTP_BRIDGE_DEFAULT_PORT)

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -76,6 +76,7 @@ void testSendSimpleMessage() {
         final BridgeClients kafkaBridgeClientJob = new BridgeClientsBuilder()
             .withProducerName(testStorage.getProducerName())
             .withBootstrapAddress(KafkaBridgeResources.serviceName(suiteTestStorage.getClusterName()))
+            .withComponentName(KafkaBridgeResources.componentName(suiteTestStorage.getClusterName()))
             .withTopicName(testStorage.getTopicName())
             .withMessageCount(testStorage.getMessageCount())
             .withPort(TestConstants.HTTP_BRIDGE_DEFAULT_PORT)
@@ -117,6 +118,7 @@ void testReceiveSimpleMessage() {
         final BridgeClients kafkaBridgeClientJob = new BridgeClientsBuilder()
             .withConsumerName(testStorage.getConsumerName())
             .withBootstrapAddress(KafkaBridgeResources.serviceName(suiteTestStorage.getClusterName()))
+            .withComponentName(KafkaBridgeResources.componentName(suiteTestStorage.getClusterName()))
             .withTopicName(testStorage.getTopicName())
             .withMessageCount(testStorage.getMessageCount())
             .withPort(TestConstants.HTTP_BRIDGE_DEFAULT_PORT)

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -183,6 +183,7 @@ void setUp() {
 
         kafkaBridgeClientJob = new BridgeClientsBuilder()
             .withBootstrapAddress(KafkaBridgeResources.serviceName(suiteTestStorage.getClusterName()))
+            .withComponentName(KafkaBridgeResources.componentName(suiteTestStorage.getClusterName()))
             .withTopicName(suiteTestStorage.getTopicName())
             .withMessageCount(suiteTestStorage.getMessageCount())
             .withPort(TestConstants.HTTP_BRIDGE_DEFAULT_PORT)

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -176,6 +176,7 @@ void setUp() {
 
         kafkaBridgeClientJob = new BridgeClientsBuilder()
             .withBootstrapAddress(KafkaBridgeResources.serviceName(suiteTestStorage.getClusterName()))
+            .withComponentName(KafkaBridgeResources.componentName(suiteTestStorage.getClusterName()))
             .withTopicName(suiteTestStorage.getTopicName())
             .withMessageCount(suiteTestStorage.getMessageCount())
             .withPort(TestConstants.HTTP_BRIDGE_DEFAULT_PORT)

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPasswordGrantsST.java
Patch:
@@ -483,6 +483,7 @@ void testPasswordGrantsKafkaBridge() {
         BridgeClients kafkaBridgeClientJob = new BridgeClientsBuilder()
             .withProducerName(producerName)
             .withBootstrapAddress(KafkaBridgeResources.serviceName(oauthClusterName))
+            .withComponentName(KafkaBridgeResources.componentName(oauthClusterName))
             .withTopicName(testStorage.getTopicName())
             .withMessageCount(testStorage.getMessageCount())
             .withPort(HTTP_BRIDGE_DEFAULT_PORT)

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
Patch:
@@ -748,6 +748,7 @@ void testProducerConsumerBridgeWithOauthMetrics() {
             .withNamespaceName(Environment.TEST_SUITE_NAMESPACE)
             .withProducerName(bridgeProducerName)
             .withBootstrapAddress(KafkaBridgeResources.serviceName(oauthClusterName))
+            .withComponentName(KafkaBridgeResources.componentName(oauthClusterName))
             .withTopicName(testStorage.getTopicName())
             .withMessageCount(testStorage.getMessageCount())
             .withPort(HTTP_BRIDGE_DEFAULT_PORT)

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -239,6 +239,7 @@ void testProducerConsumerBridge() {
         BridgeClients kafkaBridgeClientJob = new BridgeClientsBuilder()
             .withProducerName(producerName)
             .withBootstrapAddress(KafkaBridgeResources.serviceName(oauthClusterName))
+            .withComponentName(KafkaBridgeResources.componentName(oauthClusterName))
             .withTopicName(testStorage.getTopicName())
             .withMessageCount(10)
             .withPort(HTTP_BRIDGE_DEFAULT_PORT)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectApiImpl.java
Patch:
@@ -390,7 +390,7 @@ public Future<List<ConnectorPlugin>> listConnectorPlugins(Reconciliation reconci
     }
 
     private Future<Void> updateConnectorLogger(Reconciliation reconciliation, String host, int port, String logger, String level) {
-        String path = "/admin/loggers/" + logger;
+        String path = "/admin/loggers/" + logger + "?scope=cluster";
         JsonObject levelJO = new JsonObject();
         levelJO.put("level", level);
         LOGGER.debugCr(reconciliation, "Making PUT request to {} with body {}", path, levelJO);
@@ -405,7 +405,7 @@ private Future<Void> updateConnectorLogger(Reconciliation reconciliation, String
                                     .write(buffer.toString());
                             request.result().send(response -> {
                                 if (response.succeeded()) {
-                                    if (response.result().statusCode() == 200) {
+                                    if (List.of(200, 204).contains(response.result().statusCode())) {
                                         response.result().bodyHandler(body -> {
                                             LOGGER.debugCr(reconciliation, "Logger {} updated to level {}", logger, level);
                                             result.complete();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectApiIT.java
Patch:
@@ -54,12 +54,12 @@ public class KafkaConnectApiIT {
 
     @BeforeEach
     public void beforeEach() throws InterruptedException {
-        // Start a 3 node connect cluster
+        // Start a 1 node connect cluster
         connectCluster = new ConnectCluster()
                 .usingBrokers(cluster.getBootstrapServers())
-                .addConnectNodes(3);
+                .addConnectNodes(1);
         connectCluster.startup();
-        port = connectCluster.getPort(2);
+        port = connectCluster.getPort(0);
     }
 
     @AfterEach

File: user-operator/src/main/java/io/strimzi/operator/user/Main.java
Patch:
@@ -71,7 +71,7 @@ public static void main(String[] args) {
 
         // Create and log UserOperatorConfig
         UserOperatorConfig config = UserOperatorConfig.buildFromMap(System.getenv());
-        LOGGER.info("Cluster Operator configuration is {}", config);
+        LOGGER.info("UserOperator configuration is {}", config);
 
         // Create KubernetesClient, AdminClient and KafkaUserOperator classes
         ExecutorService kafkaUserOperatorExecutor = Executors.newFixedThreadPool(config.getUserOperationsThreadPoolSize(), new OperatorWorkThreadFactory());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaRoller.java
Patch:
@@ -225,7 +225,7 @@ private boolean maybeInitControllerAdminClient() {
         if (this.controllerAdminClient == null) {
             try {
                 // TODO: Currently, when running in KRaft mode Kafka does not support using Kafka Admin API with controller
-                //       nodes. This is tracked in https://github.com/strimzi/strimzi-kafka-operator/issues/8593.
+                //       nodes. This is tracked in https://github.com/strimzi/strimzi-kafka-operator/issues/9692.
                 //       Therefore use broker nodes of the cluster to initialise adminClient for quorum health check.
                 //       Once Kafka Admin API is supported for controllers, nodes.stream().filter(NodeRef:controller)
                 //       can be used here. Until then pass an empty set of nodes so the client is initialized with
@@ -629,7 +629,7 @@ private void checkIfRestartOrReconfigureRequired(NodeRef nodeRef, boolean isCont
 
                 restartContext.quorumCheck = quorumCheck(controllerAdminClient, Long.parseLong(controllerQuorumFetchTimeout));
             } else {
-                //TODO When https://github.com/strimzi/strimzi-kafka-operator/issues/8593 is complete
+                //TODO When https://github.com/strimzi/strimzi-kafka-operator/issues/9692 is complete
                 // we should change this logic to immediately restart this pod because we cannot connect to it.
                 if (isBroker) {
                     // If it is a combined node (controller and broker) and the admin client cannot be initialised,
@@ -917,7 +917,7 @@ protected Future<Void> restart(Pod pod, RestartContext restartContext) {
      */
     /* test */ Admin adminClient(Set<NodeRef> nodes, boolean ceShouldBeFatal) throws ForceableProblem, FatalProblem {
         // If no nodes are passed initialize the admin client using the brokers service
-        // TODO when https://github.com/strimzi/strimzi-kafka-operator/issues/8593 is completed review whether
+        // TODO when https://github.com/strimzi/strimzi-kafka-operator/issues/9692 is completed review whether
         //      this function can be reverted to expect nodes to be non empty
         String bootstrapHostnames;
         if (nodes.isEmpty()) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -989,7 +989,7 @@ public void testKraftOauthBrokerControllerAndMixedNodes()  {
         // Mixed node
         configuration = new KafkaBrokerConfigurationBuilder(Reconciliation.DUMMY_RECONCILIATION, "14", true)
             .withKRaft("my-cluster", "my-namespace", Set.of(ProcessRoles.BROKER, ProcessRoles.CONTROLLER), nodes)
-            .withListeners("my-cluster", "my-namespace", new NodeRef("my-cluster-kafka-14", 14, "kafka", false, true), singletonList(listener), listenerId -> "my-cluster-kafka-14.my-cluster-kafka-brokers.my-namespace.svc", listenerId -> "9092")
+            .withListeners("my-cluster", "my-namespace", new NodeRef("my-cluster-kafka-14", 14, "kafka", true, true), singletonList(listener), listenerId -> "my-cluster-kafka-14.my-cluster-kafka-brokers.my-namespace.svc", listenerId -> "9092")
             .build();
 
         assertThat(configuration, isEquivalent("node.id=14",
@@ -1010,7 +1010,7 @@ public void testKraftOauthBrokerControllerAndMixedNodes()  {
             "listener.name.replication-9091.ssl.truststore.password=${CERTS_STORE_PASSWORD}",
             "listener.name.replication-9091.ssl.truststore.type=PKCS12",
             "listener.name.replication-9091.ssl.client.auth=required",
-            "listeners=REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092",
+            "listeners=CONTROLPLANE-9090://0.0.0.0:9090,REPLICATION-9091://0.0.0.0:9091,PLAIN-9092://0.0.0.0:9092",
             "advertised.listeners=REPLICATION-9091://my-cluster-kafka-14.my-cluster-kafka-brokers.my-namespace.svc:9091,PLAIN-9092://my-cluster-kafka-14.my-cluster-kafka-brokers.my-namespace.svc:9092",
             "listener.security.protocol.map=CONTROLPLANE-9090:SSL,REPLICATION-9091:SSL,PLAIN-9092:SASL_PLAINTEXT",
             "inter.broker.listener.name=REPLICATION-9091",

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/SetupClusterOperator.java
Patch:
@@ -100,7 +100,8 @@ public class SetupClusterOperator {
     private int replicas = 1;
 
     private String testClassName;
-    private String testMethodName;
+    // by default, we expect at least empty method name in order to collect logs correctly
+    private String testMethodName = "";
     private List<RoleBinding> roleBindings;
     private List<Role> roles;
     private List<ClusterRole> clusterRoles;

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerST.java
Patch:
@@ -6,7 +6,6 @@
 
 import io.fabric8.kubernetes.api.model.Affinity;
 import io.fabric8.kubernetes.api.model.AffinityBuilder;
-import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.Event;
 import io.fabric8.kubernetes.api.model.LabelSelector;
 import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
@@ -323,8 +322,6 @@ void testKafkaPodPendingDueToRack(ExtensionContext extensionContext) {
 
         // kafka should get back ready in some reasonable time frame
         KafkaUtils.waitForKafkaReady(testStorage.getNamespaceName(), testStorage.getClusterName());
-        KafkaResource.kafkaClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
-        KafkaUtils.waitForKafkaDeletion(testStorage.getNamespaceName(), testStorage.getClusterName());
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperator.java
Patch:
@@ -1235,7 +1235,7 @@ private Future<MapAndStatus<ConfigMap, KafkaRebalanceStatus>> onReady(Reconcilia
                                     return Future.failedFuture(Util.missingSecretException(clusterNamespace, ccApiSecretName));
                                 }
 
-                                CruiseControlConfiguration ccConfig = new CruiseControlConfiguration(reconciliation, kafka.getSpec().getCruiseControl().getConfig().entrySet());
+                                CruiseControlConfiguration ccConfig = new CruiseControlConfiguration(reconciliation, kafka.getSpec().getCruiseControl().getConfig().entrySet(), Map.of());
                                 boolean apiAuthEnabled = ccConfig.isApiAuthEnabled();
                                 boolean apiSslEnabled = ccConfig.isApiSslEnabled();
                                 CruiseControlApi apiClient = cruiseControlClientProvider(ccSecret, ccApiSecret, apiAuthEnabled, apiSslEnabled);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CruiseControlReconcilerTest.java
Patch:
@@ -154,7 +154,7 @@ public void reconcileEnabledCruiseControl(VertxTestContext context) {
                     // Verify deployment
                     assertThat(deployCaptor.getAllValues().size(), is(1));
                     assertThat(deployCaptor.getValue(), is(notNullValue()));
-                    assertThat(deployCaptor.getAllValues().get(0).getSpec().getTemplate().getMetadata().getAnnotations().get(CruiseControl.ANNO_STRIMZI_SERVER_CONFIGURATION_HASH), is("fc0ad847"));
+                    assertThat(deployCaptor.getAllValues().get(0).getSpec().getTemplate().getMetadata().getAnnotations().get(CruiseControl.ANNO_STRIMZI_SERVER_CONFIGURATION_HASH), is("096591fb"));
                     assertThat(deployCaptor.getAllValues().get(0).getSpec().getTemplate().getMetadata().getAnnotations().get(CruiseControl.ANNO_STRIMZI_CAPACITY_CONFIGURATION_HASH), is("1eb49220"));
                     assertThat(deployCaptor.getAllValues().get(0).getSpec().getTemplate().getMetadata().getAnnotations().get(Annotations.ANNO_STRIMZI_AUTH_HASH), is("27ada64b"));
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/ThrottlingQuotaST.java
Patch:
@@ -27,6 +27,7 @@
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
+import static io.strimzi.systemtest.TestConstants.ARM64_UNSUPPORTED;
 import static io.strimzi.systemtest.TestConstants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.TestConstants.REGRESSION;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
@@ -40,6 +41,7 @@
  */
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
+@Tag(ARM64_UNSUPPORTED) // Due to https://github.com/strimzi/test-clients/issues/75
 public class ThrottlingQuotaST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(ThrottlingQuotaST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -47,6 +47,7 @@
 
 import java.util.List;
 
+import static io.strimzi.systemtest.TestConstants.ARM64_UNSUPPORTED;
 import static io.strimzi.systemtest.TestConstants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.TestConstants.REGRESSION;
 import static io.strimzi.systemtest.enums.ConditionStatus.False;
@@ -140,6 +141,7 @@ void testCreateTopicViaKafka(ExtensionContext extensionContext) {
         verifyTopicViaKafka(Environment.TEST_SUITE_NAMESPACE, testStorage.getTopicName(), topicPartitions, KAFKA_CLUSTER_NAME);
     }
 
+    @Tag(ARM64_UNSUPPORTED) // Due to https://github.com/strimzi/test-clients/issues/75
     @ParallelTest
     void testCreateDeleteCreate(ExtensionContext extensionContext) throws InterruptedException {
         final TestStorage testStorage = new TestStorage(extensionContext);

File: systemtest/src/main/java/io/strimzi/systemtest/TestConstants.java
Patch:
@@ -500,7 +500,7 @@ public interface TestConstants {
     /**
      * KafkaNodePools constants
      */
-    String KAFKA_NODE_POOL_PREFIX = "kafka-pool-";
+    String KAFKA_NODE_POOL_PREFIX = "kafka-";
 
     /**
      * Persistent Volume related

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -594,7 +594,9 @@ void tearDownTestCase(ExtensionContext extensionContext) throws Exception {
         // does not proceed with the next method (i.e., afterEachMustExecute()). This ensures that if such problem happen
         // it will always execute the second method.
         try {
-            assertNoCoErrorsLogged(clusterOperator.getDeploymentNamespace(), storageMap.get(extensionContext).getTestExecutionTimeInSeconds());
+            // TODO: currently this asserts makes a lot of tests failing, we should investigate all the failures and fix/whitelist them before enabling
+            // this check again - https://github.com/strimzi/strimzi-kafka-operator/issues/9648
+            // assertNoCoErrorsLogged(clusterOperator.getDeploymentNamespace(), storageMap.get(extensionContext).getTestExecutionTimeInSeconds());
             afterEachMayOverride(extensionContext);
         } finally {
             afterEachMustExecute(extensionContext);

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectBuilderST.java
Patch:
@@ -402,6 +402,8 @@ void testUpdateConnectWithAnotherPlugin(ExtensionContext extensionContext) {
             .endSpec()
             .build());
 
+        KafkaConnectUtils.waitForConnectStatusContainsPlugins(testStorage.getNamespaceName(), testStorage.getClusterName());
+
         KafkaConnect kafkaConnect = KafkaConnectResource.kafkaConnectClient().inNamespace(testStorage.getNamespaceName()).withName(testStorage.getClusterName()).get();
 
         LOGGER.info("Checking if both Connectors were created and Connect contains both plugins");

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerST.java
Patch:
@@ -174,7 +174,9 @@ void testKafkaDoesNotRollsWhenTopicIsUnderReplicated(ExtensionContext extensionC
         //Test that CO doesn't have any exceptions in log
         Instant endTime = Instant.now();
         long duration = Duration.between(startTime, endTime).toSeconds();
-        assertNoCoErrorsLogged(testStorage.getNamespaceName(), duration);
+        // TODO: currently this asserts makes a lot of tests failing, we should investigate all the failures and fix/whitelist them before enabling
+        // this check again - https://github.com/strimzi/strimzi-kafka-operator/issues/9648
+        //assertNoCoErrorsLogged(testStorage.getNamespaceName(), duration);
     }
 
     @ParallelNamespaceTest

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -699,6 +699,7 @@ CruiseControlReconciler cruiseControlReconciler()   {
                     reconciliation,
                     config,
                     supplier,
+                    passwordGenerator,
                     kafkaAssembly,
                     versions,
                     kafkaBrokerNodes,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/MockCruiseControl.java
Patch:
@@ -12,6 +12,7 @@
 import io.strimzi.operator.cluster.model.CruiseControl;
 import io.strimzi.operator.cluster.model.ModelUtils;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.operator.common.model.PasswordGenerator;
 import io.strimzi.operator.common.model.cruisecontrol.CruiseControlEndpoints;
 import io.strimzi.operator.common.model.cruisecontrol.CruiseControlParameters;
 import io.strimzi.operator.common.operator.MockCertManager;
@@ -79,7 +80,7 @@ public class MockCruiseControl {
             .addToData("cruise-control.crt", MockCertManager.clusterCaCert())
             .build();
     public static final Secret CC_API_SECRET = ModelUtils.createSecret(CruiseControlResources.apiSecretName(CLUSTER), NAMESPACE, Labels.EMPTY, null,
-            CruiseControl.generateCruiseControlApiCredentials(), Collections.emptyMap(), Collections.emptyMap());
+            CruiseControl.generateCruiseControlApiCredentials(new PasswordGenerator(16)), Collections.emptyMap(), Collections.emptyMap());
 
     private static final Header AUTH_HEADER = convertToHeader(CruiseControlApiImpl.getAuthHttpHeader(true, CC_API_SECRET));
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/v2/BatchingLoop.java
Patch:
@@ -191,7 +191,7 @@ private boolean runOnce(int batchId, Batch batch) {
             try {
                 synchronized (BatchingLoop.this) {
                     // remove the old batch from the inflight set and reset the batch
-                    LOGGER.debugOp("[Batch #{}] Removing batch from inflight", batchId - 1);
+                    LOGGER.traceOp("[Batch #{}] Removing batch from inflight", batchId - 1);
                     batch.toUpdate.stream().map(TopicEvent::toRef).forEach(inFlight::remove);
                     batch.toDelete.stream().map(TopicEvent::toRef).forEach(inFlight::remove);
                     batch.clear();
@@ -210,7 +210,7 @@ private boolean runOnce(int batchId, Batch batch) {
                     }
                     LOGGER.debugOp("[Batch #{}] Reconciled batch", batchId);
                 } else {
-                    LOGGER.debugOp("[Batch #{}] Empty batch", batchId);
+                    LOGGER.traceOp("[Batch #{}] Empty batch", batchId);
                 }
             } catch (InterruptedException e) {
                 LOGGER.infoOp("[Batch #{}] Interrupted", batchId);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.client.KubernetesClient;
-import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.model.common.CertSecretSource;
 import io.strimzi.api.kafka.model.common.Condition;
 import io.strimzi.api.kafka.model.common.authentication.KafkaClientAuthenticationOAuth;
@@ -81,7 +80,7 @@
  *     <li>A set of MirrorMaker 2 connectors</li>
  * </ul>
  */
-public class KafkaMirrorMaker2AssemblyOperator extends AbstractConnectOperator<KubernetesClient, KafkaMirrorMaker2, KafkaMirrorMaker2List, Resource<KafkaMirrorMaker2>, KafkaMirrorMaker2Spec, KafkaMirrorMaker2Status> {
+public class KafkaMirrorMaker2AssemblyOperator extends AbstractConnectOperator<KubernetesClient, KafkaMirrorMaker2, KafkaMirrorMaker2List, KafkaMirrorMaker2Spec, KafkaMirrorMaker2Status> {
     private static final ReconciliationLogger LOGGER = ReconciliationLogger.create(KafkaMirrorMaker2AssemblyOperator.class.getName());
 
     private static final String MIRRORMAKER2_CONNECTOR_PACKAGE = "org.apache.kafka.connect.mirror";
@@ -169,7 +168,7 @@ protected Future<KafkaMirrorMaker2Status> createOrUpdate(Reconciliation reconcil
                 .compose(i -> manualRollingUpdate(reconciliation, mirrorMaker2Cluster))
                 .compose(i -> serviceOperations.reconcile(reconciliation, namespace, mirrorMaker2Cluster.getServiceName(), mirrorMaker2Cluster.generateService()))
                 .compose(i -> serviceOperations.reconcile(reconciliation, namespace, mirrorMaker2Cluster.getComponentName(), mirrorMaker2Cluster.generateHeadlessService()))
-                .compose(i -> generateMetricsAndLoggingConfigMap(reconciliation, namespace, mirrorMaker2Cluster))
+                .compose(i -> generateMetricsAndLoggingConfigMap(reconciliation, mirrorMaker2Cluster))
                 .compose(logAndMetricsConfigMap -> {
                     String logging = logAndMetricsConfigMap.getData().get(mirrorMaker2Cluster.logging().configMapKey());
                     podAnnotations.put(Annotations.ANNO_STRIMZI_LOGGING_APPENDERS_HASH, Util.hashStub(Util.getLoggingDynamicallyUnmodifiableEntries(logging)));

File: test/src/main/java/io/strimzi/test/k8s/cluster/Kind.java
Patch:
@@ -45,9 +45,9 @@ public boolean isAvailable() {
      */
     @Override
     public boolean isClusterUp() {
-        List<String> cmd = Arrays.asList(CMD, "status");
+        List<String> cmd = Arrays.asList("kubectl", "get", "nodes", "-o", "jsonpath='{.items[*].spec.providerID}'");
         try {
-            return Exec.exec(cmd).exitStatus();
+            return Exec.exec(cmd).out().startsWith("kind");
         } catch (KubeClusterException e) {
             LOGGER.debug("'" + String.join(" ", cmd) + "' failed. Please double check connectivity to your cluster!");
             LOGGER.debug(e);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -350,6 +350,7 @@ private Future<Void> reconcileMirrorMaker2Connectors(Reconciliation reconciliati
                                 .withClassName(className)
                                 .withConfig(mm2ConnectorSpec.getConfig())
                                 .withPause(mm2ConnectorSpec.getPause())
+                                .withState(mm2ConnectorSpec.getState())
                                 .withTasksMax(mm2ConnectorSpec.getTasksMax())
                                 .build();
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserST.java
Patch:
@@ -432,7 +432,7 @@ void testTlsExternalUser(ExtensionContext extensionContext) throws IOException,
     void setup(ExtensionContext extensionContext) {
         this.clusterOperator = this.clusterOperator
             .defaultInstallation(extensionContext)
-            .withBindingsNamespaces(List.of(Environment.TEST_SUITE_NAMESPACE, Constants.CO_NAMESPACE))
+            .withBindingsNamespaces(List.of(Environment.TEST_SUITE_NAMESPACE, TestConstants.CO_NAMESPACE))
             .createInstallation()
             .runInstallation();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaListenersReconciler.java
Patch:
@@ -275,7 +275,7 @@ protected Future<Void> internalServicesReady()   {
             result.listenerStatuses.add(ls);
 
             // Set advertised hostnames and ports
-            for (NodeRef node : kafka.nodes()) {
+            for (NodeRef node : kafka.brokerNodes()) {
                 String brokerAddress;
 
                 if (useServiceDnsDomain) {

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserST.java
Patch:
@@ -442,6 +442,8 @@ void setup(ExtensionContext extensionContext) {
             .createInstallation()
             .runInstallation();
 
+        cluster.createNamespace(Environment.TEST_SUITE_NAMESPACE);
+
         resourceManager.createResourceWithWait(extensionContext, KafkaTemplates.kafkaEphemeral(userClusterName, 1, 1)
             .editMetadata()
                 .withNamespace(Environment.TEST_SUITE_NAMESPACE)

File: systemtest/src/main/java/io/strimzi/systemtest/security/OpenSsl.java
Patch:
@@ -184,7 +184,7 @@ public static void waitForCertIsInValidDateRange(File certificate) {
         String endDate = dates.split("\n")[1].replace("notAfter=", "");
 
         ZoneId gmtZone = ZoneId.of("GMT");
-        DateTimeFormatter formatter = DateTimeFormatter.ofPattern("MMM dd HH:mm:ss yyyy z");
+        DateTimeFormatter formatter = DateTimeFormatter.ofPattern("MMM d[d] HH:mm:ss yyyy z");
         ZonedDateTime notBefore = ZonedDateTime.of(LocalDateTime.parse(startDate, formatter), gmtZone);
         ZonedDateTime notAfter = ZonedDateTime.of(LocalDateTime.parse(endDate, formatter), gmtZone);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/PlatformFeaturesAvailability.java
Patch:
@@ -46,8 +46,8 @@ public static Future<PlatformFeaturesAvailability> create(Vertx vertx, Kubernete
         Future<VersionInfo> futureVersion = getVersionInfo(vertx, client);
 
         futureVersion.compose(versionInfo -> {
-            String major = versionInfo.getMajor().equals("") ? Integer.toString(KubernetesVersion.MINIMAL_SUPPORTED_MAJOR) : versionInfo.getMajor();
-            String minor = versionInfo.getMinor().equals("") ? Integer.toString(KubernetesVersion.MINIMAL_SUPPORTED_MINOR) : versionInfo.getMinor();
+            String major = versionInfo.getMajor().isEmpty() ? Integer.toString(KubernetesVersion.MINIMAL_SUPPORTED_MAJOR) : versionInfo.getMajor();
+            String minor = versionInfo.getMinor().isEmpty() ? Integer.toString(KubernetesVersion.MINIMAL_SUPPORTED_MINOR) : versionInfo.getMinor();
             pfa.setKubernetesVersion(new KubernetesVersion(Integer.parseInt(major.split("\\D")[0]), Integer.parseInt(minor.split("\\D")[0])));
 
             return checkApiAvailability(vertx, client, "route.openshift.io", "v1");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/CaReconciler.java
Patch:
@@ -594,5 +594,5 @@ Future<Void> maybeRemoveOldClusterCaCertificates() {
     /**
      * Helper class to pass both Cluster and Clients CA as a result of the reconciliation
      */
-    protected record CaReconciliationResult(ClusterCa clusterCa, ClientsCa clientsCa) { }
+    public record CaReconciliationResult(ClusterCa clusterCa, ClientsCa clientsCa) { }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractNonNamespacedResourceOperator.java
Patch:
@@ -164,7 +164,7 @@ protected Future<ReconcileResult<T>> internalUpdate(Reconciliation reconciliatio
     }
 
     /**
-     * Method for patching or replacing a resource. By default is using JSON-type patch. Overriding this method can be
+     * Method for patching or replacing a resource. By default, is using JSON-type patch. Overriding this method can be
      * used to use replace instead of patch or different patch strategies.
      *
      * @param name          Name of the resource

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractScalableNamespacedResourceOperator.java
Patch:
@@ -86,7 +86,7 @@ public Future<Integer> scaleUp(Reconciliation reconciliation, String namespace,
 
     /**
      * Asynchronously scale down the resource given by {@code namespace} and {@code name} to have the scale given by
-     * {@code scaleTo}, returning a future for the outcome. If the resource does not exists, is has a current
+     * {@code scaleTo}, returning a future for the outcome. If the resource does not exist, it has a current
      * scale &lt;= the given {@code scaleTo} then complete successfully.
      *
      * @param reconciliation    The reconciliation

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/BuildConfigOperator.java
Patch:
@@ -37,7 +37,7 @@ protected MixedOperation<BuildConfig, BuildConfigList, BuildConfigResource<Build
     @Override
     protected Future<ReconcileResult<BuildConfig>> internalUpdate(Reconciliation reconciliation, String namespace, String name, BuildConfig current, BuildConfig desired) {
         desired.getSpec().setTriggers(current.getSpec().getTriggers());
-        // Cascading needs to be set to false to make sure the Builds are not deleted during reconciliation
+        // Cascading needs to be set to false in order to make sure the Builds are not deleted during reconciliation
         return super.internalUpdate(reconciliation, namespace, name, current, desired);
     }
 
@@ -50,7 +50,7 @@ protected Future<ReconcileResult<BuildConfig>> internalUpdate(Reconciliation rec
      * @param reconciliation The reconciliation
      * @param namespace Namespace of the resource which should be deleted
      * @param name Name of the resource which should be deleted
-     * @param cascading Defines whether the delete should be cascading or not (e.g. whether a STS deletion should delete pods etc.)
+     * @param cascading Defines whether the deletion should be cascading or not (e.g. whether an STS deletion should delete pods etc.)
      *
      * @return A future which will be completed on the context thread once the resource has been deleted.
      */

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -55,12 +55,12 @@ protected MixedOperation<T, L, Resource<T>> operation() {
     }
 
     /**
-     * The selfClosingWatch does not work for Custom Resources. Therefore we override the method and delete custom
+     * The selfClosingWatch does not work for Custom Resources. Therefore, we override the method and delete custom
      * resources without it.
      *
      * @param namespace Namespace of the resource which should be deleted
      * @param name Name of the resource which should be deleted
-     * @param cascading Defines whether the delete should be cascading or not (e.g. whether a STS deletion should delete pods etc.)
+     * @param cascading Defines whether the deletion should be cascading or not (e.g. whether an STS deletion should delete pods etc.)
      *
      * @return A future which will be completed on the context thread
      *         once the resource has been deleted.

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -319,7 +319,7 @@ public KafkaBrokerConfigurationBuilder withListeners(
             writer.println("inter.broker.listener.name=" + REPLICATION_LISTENER_NAME);
         }
 
-        // Control plane listener is on all ZooKeeper based brokers or on KRaft nodes with only the broker role (i.e. not mixed nodes)
+        // Control plane listener is on all ZooKeeper based brokers, it's not supported in KRaft mode
         if (!useKRaft) {
             writer.println("control.plane.listener.name=" + CONTROL_PLANE_LISTENER_NAME);
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaReconciler.java
Patch:
@@ -473,7 +473,7 @@ protected Future<Void> maybeRollKafka(
                                 compositeFuture.resultAt(0),
                                 compositeFuture.resultAt(1),
                                 adminClientProvider,
-                                brokerId -> kafka.generatePerBrokerBrokerConfiguration(brokerId, kafkaAdvertisedHostnames, kafkaAdvertisedPorts),
+                                brokerId -> kafka.generatePerBrokerConfiguration(brokerId, kafkaAdvertisedHostnames, kafkaAdvertisedPorts),
                                 logging,
                                 kafka.getKafkaVersion(),
                                 allowReconfiguration,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterPodSetTest.java
Patch:
@@ -184,7 +184,7 @@ public void testPerBrokerConfiguration() {
                 2, Map.of("PLAIN_9092", "10002")
         );
 
-        String config = KC.generatePerBrokerBrokerConfiguration(2, advertisedHostnames, advertisedPorts);
+        String config = KC.generatePerBrokerConfiguration(2, advertisedHostnames, advertisedPorts);
 
         assertThat(config, containsString("broker.id=2"));
         assertThat(config, containsString("node.id=2"));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterWithKRaftTest.java
Patch:
@@ -324,11 +324,11 @@ public void testBrokerConfiguration()  {
                 SHARED_ENV_PROVIDER
         );
 
-        String configuration = kc.generatePerBrokerBrokerConfiguration(2, Map.of(), Map.of());
+        String configuration = kc.generatePerBrokerConfiguration(2, Map.of(), Map.of());
         assertThat(configuration, containsString("node.id=2\n"));
         assertThat(configuration, containsString("process.roles=controller\n"));
 
-        configuration = kc.generatePerBrokerBrokerConfiguration(1001, advertisedHostnames, advertisedPorts);
+        configuration = kc.generatePerBrokerConfiguration(1001, advertisedHostnames, advertisedPorts);
         assertThat(configuration, containsString("node.id=1001\n"));
         assertThat(configuration, containsString("process.roles=broker\n"));
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterWithPoolsTest.java
Patch:
@@ -363,11 +363,11 @@ public void testBrokerConfiguration()  {
                 null, SHARED_ENV_PROVIDER
         );
 
-        String configuration = kc.generatePerBrokerBrokerConfiguration(2, advertisedHostnames, advertisedPorts);
+        String configuration = kc.generatePerBrokerConfiguration(2, advertisedHostnames, advertisedPorts);
         assertThat(configuration, containsString("node.id=2\n"));
         assertThat(configuration, containsString("process.roles=broker\n"));
 
-        configuration = kc.generatePerBrokerBrokerConfiguration(10, advertisedHostnames, advertisedPorts);
+        configuration = kc.generatePerBrokerConfiguration(10, advertisedHostnames, advertisedPorts);
         assertThat(configuration, containsString("node.id=10\n"));
         assertThat(configuration, containsString("process.roles=broker\n"));
 

File: crd-annotations/src/main/java/io/strimzi/api/annotations/VersionRange.java
Patch:
@@ -188,7 +188,7 @@ public int hashCode() {
     /**
      * Checks when the version is part of the version range
      *
-     * @param apiVersion    API Version which should be checked whether it is in the raneg or not
+     * @param apiVersion    API Version which should be checked whether it is in the range or not
      *
      * @return      True when the range contains the version. False otherwise
      */

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/nodepools/NodePoolUtils.java
Patch:
@@ -148,7 +148,7 @@ public static void validateNodePools(Reconciliation reconciliation, Kafka kafka,
 
             // Throw an exception if there are any errors
             if (!errors.isEmpty()) {
-                throw new InvalidResourceException("Tha Kafka cluster " + kafka.getMetadata().getName() + " is invalid: " + errors);
+                throw new InvalidResourceException("The Kafka cluster " + kafka.getMetadata().getName() + " is invalid: " + errors);
             }
         }
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/ReconcilerUtils.java
Patch:
@@ -365,7 +365,7 @@ public static boolean trackedServerCertChanged(Pod pod, Map<Integer, String> cer
     /**
      * Checks whether Node pools are enabled for given Kafka custom resource using the strimzi.io/node-pools anotation
      *
-     * @param kafka     Tha Kafka custom resource which might have the node-pools anotation
+     * @param kafka     The Kafka custom resource which might have the node-pools anotation
      *
      * @return      True when the node pools are enabled. False otherwise.
      */

File: api/src/main/java/io/strimzi/api/kafka/model/status/ListenerStatus.java
Patch:
@@ -42,8 +42,8 @@ public class ListenerStatus implements UnknownPropertyPreserving, Serializable {
     private Map<String, Object> additionalProperties;
 
     @Deprecated
-    @DeprecatedProperty(description = "The `type` property is deprecated and not used anymore.")
-    @Description("*The `type` property is deprecated and not used anymore. Use the `name` property.* The name of the listener.")
+    @DeprecatedProperty(description = "The `type` property is not used anymore. Use the `name` property with the same value.")
+    @Description("The name of the listener.")
     public String getType() {
         return type;
     }

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaTest.java
Patch:
@@ -200,8 +200,6 @@ public void testListenersTypeAndName()    {
 
         List<ListenerStatus> listeners = model.getStatus().getListeners();
 
-        assertThat(listeners.get(0).getType(), is("plain"));
-        assertThat(listeners.get(1).getType(), is("external"));
         assertThat(listeners.get(0).getName(), is("plain"));
         assertThat(listeners.get(1).getName(), is("external"));
     }

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -188,7 +188,7 @@ private void testWeirdUsername(ExtensionContext extensionContext, String weirdUs
         final String kafkaProducerExternalName = "kafka-producer-external" + new Random().nextInt(Integer.MAX_VALUE);
 
         final List<ListenerStatus> listenerStatusList = KafkaResource.kafkaClient().inNamespace(ts.getNamespaceName()).withName(ts.getClusterName()).get().getStatus().getListeners();
-        final String externalBootstrapServers = listenerStatusList.stream().filter(listener -> listener.getType().equals(Constants.EXTERNAL_LISTENER_DEFAULT_NAME))
+        final String externalBootstrapServers = listenerStatusList.stream().filter(listener -> listener.getName().equals(Constants.EXTERNAL_LISTENER_DEFAULT_NAME))
             .findFirst()
             .orElseThrow(RuntimeException::new)
             .getBootstrapServers();

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/ListenersST.java
Patch:
@@ -442,7 +442,7 @@ void testNodePort(ExtensionContext extensionContext) {
 
         // Check that Kafka status has correct addresses in NodePort external listener part
         for (ListenerStatus listenerStatus : KafkaResource.getKafkaStatus(clusterName, namespaceName).getListeners()) {
-            if (listenerStatus.getType().equals(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)) {
+            if (listenerStatus.getName().equals(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)) {
                 List<String> listStatusAddresses = listenerStatus.getAddresses().stream().map(ListenerAddress::getHost).collect(Collectors.toList());
                 listStatusAddresses.sort(Comparator.comparing(String::toString));
                 List<Integer> listStatusPorts = listenerStatus.getAddresses().stream().map(ListenerAddress::getPort).collect(Collectors.toList());

File: systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusST.java
Patch:
@@ -476,7 +476,7 @@ void assertKafkaStatus(long expectedObservedGeneration, String internalAddress)
         assertThat("Kafka cluster status has incorrect Observed Generation", observedGeneration, is(expectedObservedGeneration));
 
         for (ListenerStatus listener : kafkaStatus.getListeners()) {
-            switch (listener.getType()) {
+            switch (listener.getName()) {
                 case Constants.TLS_LISTENER_DEFAULT_NAME:
                     assertThat("TLS bootstrap has incorrect port", listener.getAddresses().get(0).getPort(), is(9093));
                     assertThat("TLS bootstrap has incorrect host", listener.getAddresses().get(0).getHost(), is(internalAddress));

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -182,7 +182,7 @@ void testCreateTopicViaAdminClient(ExtensionContext extensionContext) throws Exe
 
         properties.setProperty(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, KafkaResource.kafkaClient().inNamespace(Constants.TEST_SUITE_NAMESPACE)
             .withName(clusterName).get().getStatus().getListeners().stream()
-            .filter(listener -> listener.getType().equals(Constants.EXTERNAL_LISTENER_DEFAULT_NAME))
+            .filter(listener -> listener.getName().equals(Constants.EXTERNAL_LISTENER_DEFAULT_NAME))
             .findFirst()
             .orElseThrow(RuntimeException::new)
             .getBootstrapServers());

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -45,7 +45,7 @@ public class KafkaClusterSpec implements HasConfigurableMetrics, HasConfigurable
             + "inter.broker.listener.name, sasl., ssl., security., password., log.dir, "
             + "zookeeper.connect, zookeeper.set.acl, zookeeper.ssl, zookeeper.clientCnxnSocket, authorizer., super.user, "
             + "cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers,"
-            + "node.id, process.roles, controller."; // KRaft options
+            + "node.id, process.roles, controller., metadata.log.dir"; // KRaft options
 
     public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, sasl.server.max.receive.size,"
             + "ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols, ssl.secure.random.implementation,"

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -1093,11 +1093,11 @@ void testKMM2RollAfterSecretsCertsUpdateScramSha(ExtensionContext extensionConte
 
         LOGGER.info("Changing KafkaUser sha-password on MirrorMaker2 Source and make sure it rolled");
 
-        KafkaUserUtils.modifyKafkaUserPasswordWithNewSecret(testStorage.getNamespaceName(), kafkaUserSourceName, customSecretSource, "c291cmNlLXBhc3N3b3Jk", extensionContext);
+        KafkaUserUtils.modifyKafkaUserPasswordWithNewSecret(testStorage.getNamespaceName(), kafkaUserSourceName, customSecretSource, "UjhlTjJhSHhQN1lzVDZmQ2pNMWRRb1d6VnBYNWJHa1U=", extensionContext);
         RollingUpdateUtils.waitTillComponentHasRolledAndPodsReady(testStorage.getNamespaceName(), mmSelector, 1, mmSnapshot);
         mmSnapshot = PodUtils.podSnapshot(testStorage.getNamespaceName(), mmSelector);
 
-        KafkaUserUtils.modifyKafkaUserPasswordWithNewSecret(testStorage.getNamespaceName(), kafkaUserTargetName, customSecretTarget, "dGFyZ2V0LXBhc3N3b3Jk", extensionContext);
+        KafkaUserUtils.modifyKafkaUserPasswordWithNewSecret(testStorage.getNamespaceName(), kafkaUserTargetName, customSecretTarget, "VDZmQ2pNMWRRb1d6VnBYNWJHa1VSOGVOMmFIeFA3WXM=", extensionContext);
         RollingUpdateUtils.waitTillComponentHasRolledAndPodsReady(testStorage.getNamespaceName(), mmSelector, 1, mmSnapshot);
 
         RollingUpdateUtils.waitTillComponentHasRolledAndPodsReady(testStorage.getNamespaceName(), mmSelector, 1, mmSnapshot);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/FeatureGates.java
Patch:
@@ -19,14 +19,12 @@ public class FeatureGates {
     private static final String USE_KRAFT = "UseKRaft";
     private static final String STABLE_CONNECT_IDENTITIES = "StableConnectIdentities";
     private static final String KAFKA_NODE_POOLS = "KafkaNodePools";
-
     private static final String UNIDIRECTIONAL_TOPIC_OPERATOR = "UnidirectionalTopicOperator";
 
     // When adding new feature gates, do not forget to add them to allFeatureGates() and toString() methods
     private final FeatureGate useKRaft = new FeatureGate(USE_KRAFT, false);
-    private final FeatureGate stableConnectIdentities = new FeatureGate(STABLE_CONNECT_IDENTITIES, false);
+    private final FeatureGate stableConnectIdentities = new FeatureGate(STABLE_CONNECT_IDENTITIES, true);
     private final FeatureGate kafkaNodePools = new FeatureGate(KAFKA_NODE_POOLS, false);
-
     private final FeatureGate unidirectionalTopicOperator = new FeatureGate(UNIDIRECTIONAL_TOPIC_OPERATOR, false);
 
     /**

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
Patch:
@@ -43,7 +43,7 @@ public class ClusterOperatorConfigTest {
         ENV_VARS.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
         ENV_VARS.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
         ENV_VARS.put(ClusterOperatorConfig.OPERATOR_NAMESPACE.key(), "operator-namespace");
-        ENV_VARS.put(ClusterOperatorConfig.FEATURE_GATES.key(), "+StableConnectIdentities");
+        ENV_VARS.put(ClusterOperatorConfig.FEATURE_GATES.key(), "-StableConnectIdentities");
         ENV_VARS.put(ClusterOperatorConfig.DNS_CACHE_TTL.key(), "10");
         ENV_VARS.put(ClusterOperatorConfig.POD_SECURITY_PROVIDER_CLASS.key(), "my.package.CustomPodSecurityProvider");
     }
@@ -65,7 +65,7 @@ public void testDefaultConfig() {
         assertThat(config.getConnectBuildTimeoutMs(), is(Long.parseLong(ClusterOperatorConfig.CONNECT_BUILD_TIMEOUT_MS.defaultValue())));
         assertThat(config.getOperatorNamespace(), is("operator-namespace"));
         assertThat(config.getOperatorNamespaceLabels(), is(nullValue()));
-        assertThat(config.featureGates().stableConnectIdentitiesEnabled(), is(false));
+        assertThat(config.featureGates().stableConnectIdentitiesEnabled(), is(true));
         assertThat(config.featureGates().useKRaftEnabled(), is(false));
         assertThat(config.isCreateClusterRoles(), is(false));
         assertThat(config.isNetworkPolicyGeneration(), is(true));
@@ -101,7 +101,7 @@ public void testEnvVars() {
         assertThat(config.getOperationTimeoutMs(), is(30_000L));
         assertThat(config.getConnectBuildTimeoutMs(), is(40_000L));
         assertThat(config.getOperatorNamespace(), is("operator-namespace"));
-        assertThat(config.featureGates().stableConnectIdentitiesEnabled(), is(true));
+        assertThat(config.featureGates().stableConnectIdentitiesEnabled(), is(false));
         assertThat(config.getDnsCacheTtlSec(), is(10));
         assertThat(config.getPodSecurityProviderClass(), is("my.package.CustomPodSecurityProvider"));
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
Patch:
@@ -64,7 +64,7 @@ private static Map<String, String> buildEnv(String namespaces, boolean podSetsOn
         env.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
         env.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
         env.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
-        env.put(ClusterOperatorConfig.FEATURE_GATES.key(), "+KafkaNodePools,+StableConnectIdentities");
+        env.put(ClusterOperatorConfig.FEATURE_GATES.key(), "+KafkaNodePools,-StableConnectIdentities");
 
         if (podSetsOnly) {
             env.put(ClusterOperatorConfig.POD_SET_RECONCILIATION_ONLY.key(), "true");

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/FeatureGatesTest.java
Patch:
@@ -61,7 +61,7 @@ public void testAllFeatureGates() {
     @ParallelTest
     public void testFeatureGatesParsing() {
         assertThat(new FeatureGates("+UseKRaft,+KafkaNodePools").useKRaftEnabled(), is(true));
-        assertThat(new FeatureGates("+StableConnectIdentities").stableConnectIdentitiesEnabled(), is(true));
+        assertThat(new FeatureGates("-StableConnectIdentities").stableConnectIdentitiesEnabled(), is(false));
         assertThat(new FeatureGates("+KafkaNodePools").kafkaNodePoolsEnabled(), is(true));
         assertThat(new FeatureGates("-UseKRaft,-StableConnectIdentities").useKRaftEnabled(), is(false));
         assertThat(new FeatureGates("-UseKRaft,-StableConnectIdentities").stableConnectIdentitiesEnabled(), is(false));

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -191,7 +191,7 @@ public interface Constants {
      * Feature gate related constants
      */
     String USE_KRAFT_MODE = "+UseKRaft";
-    String USE_STABLE_CONNECT_IDENTITIES = "+StableConnectIdentities";
+    String DONT_USE_STABLE_CONNECT_IDENTITIES = "-StableConnectIdentities";
     String USE_KAFKA_NODE_POOLS = "+KafkaNodePools";
     String UNIDIRECTIONAL_TOPIC_OPERATOR = "+UnidirectionalTopicOperator";
 

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -253,7 +253,7 @@ public static boolean isNamespaceRbacScope() {
     }
 
     public static boolean isStableConnectIdentitiesEnabled() {
-        return STRIMZI_FEATURE_GATES.contains(Constants.USE_STABLE_CONNECT_IDENTITIES);
+        return !STRIMZI_FEATURE_GATES.contains(Constants.DONT_USE_STABLE_CONNECT_IDENTITIES);
     }
 
     /**

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/SetupClusterOperator.java
Patch:
@@ -183,9 +183,7 @@ private boolean isClusterOperatorNamespaceNotCreated() {
     /**
      * Auxiliary method, which provides default Cluster Operator instance. By default we mean using in all cases
      * @code{BeforeAllOnce.getSharedExtensionContext())} and other attributes are dependent base on the installation type
-     * (i.e., Olm, Helm, Bundle) and RBAC setup (i.e., Cluster, Namespace). This method used across whole systemtest
-     * module, with combination of {@link #rollbackToDefaultConfiguration()} or in @IsolatedSuites where we are forced
-     * to build more comprehensive deployment of CLuster Operator.
+     * (i.e., Olm, Helm, Bundle) and RBAC setup (i.e., Cluster, Namespace).
      *
      * @param extensionContext test context, which primary responsibility is to create unique resource and delete after
      *                         such resource is no longer neeeded (e.g., after test class)

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -61,8 +61,8 @@
 @Tag(REGRESSION)
 @Tag(BRIDGE)
 @Tag(INTERNAL_CLIENTS_USED)
-class HttpBridgeIsolatedST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(HttpBridgeIsolatedST.class);
+class HttpBridgeST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(HttpBridgeST.class);
 
     private final String httpBridgeClusterName = "http-bridge-cluster-name";
 

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectBuilderST.java
Patch:
@@ -75,9 +75,9 @@
 @Tag(REGRESSION)
 @Tag(CONNECT_COMPONENTS)
 @Tag(CONNECT)
-class ConnectBuilderIsolatedST extends AbstractST {
+class ConnectBuilderST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(ConnectBuilderIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(ConnectBuilderST.class);
 
     private static final String CAMEL_CONNECTOR_HTTP_SINK_CLASS_NAME = "org.apache.camel.kafkaconnector.http.CamelHttpSinkConnector";
     private static final String CAMEL_CONNECTOR_TIMER_CLASS_NAME = "org.apache.camel.kafkaconnector.timer.CamelTimerSourceConnector";

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -107,9 +107,9 @@
 @Tag(CONNECT)
 @Tag(CONNECT_COMPONENTS)
 @SuppressWarnings({"checkstyle:ClassDataAbstractionCoupling"})
-class ConnectIsolatedST extends AbstractST {
+class ConnectST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(ConnectIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(ConnectST.class);
 
     @ParallelNamespaceTest
     void testDeployUndeploy(ExtensionContext extensionContext) {

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/JmxST.java
Patch:
@@ -39,9 +39,9 @@
 import static org.junit.jupiter.api.Assertions.assertTrue;
 
 @Tag(REGRESSION)
-public class JmxIsolatedST extends AbstractST {
+public class JmxST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(JmxIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(JmxST.class);
 
     @ParallelNamespaceTest
     @Tag(CONNECT)

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -143,9 +143,9 @@
 @Tag(REGRESSION)
 @Tag(METRICS)
 @Tag(CRUISE_CONTROL)
-public class MetricsIsolatedST extends AbstractST {
+public class MetricsST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(MetricsIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(MetricsST.class);
 
     private final String namespaceFirst = "metrics-test-0";
     private final String namespaceSecond = "metrics-test-1";

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -83,9 +83,9 @@
 @Tag(MIRROR_MAKER2)
 @Tag(CONNECT_COMPONENTS)
 @Tag(INTERNAL_CLIENTS_USED)
-class MirrorMaker2IsolatedST extends AbstractST {
+class MirrorMaker2ST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(MirrorMaker2IsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(MirrorMaker2ST.class);
 
     @ParallelNamespaceTest
     void testMirrorMaker2(ExtensionContext extensionContext) {

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerST.java
Patch:
@@ -67,9 +67,9 @@
 @Tag(REGRESSION)
 @Tag(MIRROR_MAKER)
 @Tag(INTERNAL_CLIENTS_USED)
-public class MirrorMakerIsolatedST extends AbstractST {
+public class MirrorMakerST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(MirrorMakerIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(MirrorMakerST.class);
 
     @ParallelNamespaceTest
     void testMirrorMaker(ExtensionContext extensionContext) {

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAllNamespaceST.java
Patch:
@@ -22,7 +22,7 @@
 
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @Tag(OLM)
-public class OlmAllNamespaceIsolatedST extends OlmAbstractST {
+public class OlmAllNamespaceST extends OlmAbstractST {
 
     public static final String NAMESPACE = "olm-namespace";
 

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmSingleNamespaceST.java
Patch:
@@ -23,7 +23,7 @@
 
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @Tag(OLM)
-public class OlmSingleNamespaceIsolatedST extends OlmAbstractST {
+public class OlmSingleNamespaceST extends OlmAbstractST {
 
     public static final String NAMESPACE = "olm-namespace";
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ClusterOperatorRbacST.java
Patch:
@@ -36,8 +36,8 @@
 import static org.junit.jupiter.api.Assumptions.assumeFalse;
 
 @Tag(REGRESSION)
-public class ClusterOperatorRbacIsolatedST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(ClusterOperatorRbacIsolatedST.class);
+public class ClusterOperatorRbacST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(ClusterOperatorRbacST.class);
 
     @IsolatedTest("We need for each test case its own Cluster Operator")
     @Tag(CONNECT)

File: systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusST.java
Patch:
@@ -98,8 +98,8 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 
 @Tag(REGRESSION)
-class CustomResourceStatusIsolatedST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(CustomResourceStatusIsolatedST.class);
+class CustomResourceStatusST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(CustomResourceStatusST.class);
 
     private static final String CUSTOM_RESOURCE_STATUS_CLUSTER_NAME = "custom-resource-status-cluster-name";
     private static final String EXAMPLE_TOPIC_NAME = "example-topic-name";

File: systemtest/src/test/java/io/strimzi/systemtest/operators/FeatureGatesST.java
Patch:
@@ -69,8 +69,8 @@
  * https://github.com/strimzi/proposals/blob/main/022-feature-gates.md
  */
 @Tag(REGRESSION)
-public class FeatureGatesIsolatedST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(FeatureGatesIsolatedST.class);
+public class FeatureGatesST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(FeatureGatesST.class);
 
     /**
      * UseKRaft feature gate

File: systemtest/src/test/java/io/strimzi/systemtest/operators/LeaderElectionST.java
Patch:
@@ -51,9 +51,9 @@
  */
 
 @Tag(REGRESSION)
-public class LeaderElectionIsolatedST extends AbstractST {
+public class LeaderElectionST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(LeaderElectionIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(LeaderElectionST.class);
 
     private static final EnvVar LEADER_DISABLED_ENV = new EnvVarBuilder()
         .withName("STRIMZI_LEADER_ELECTION_ENABLED")

File: systemtest/src/test/java/io/strimzi/systemtest/operators/MultipleClusterOperatorsST.java
Patch:
@@ -67,9 +67,9 @@
 import static org.junit.jupiter.api.Assumptions.assumeTrue;
 
 @Tag(REGRESSION)
-public class MultipleClusterOperatorsIsolatedST extends AbstractST {
+public class MultipleClusterOperatorsST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(MultipleClusterOperatorsIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(MultipleClusterOperatorsST.class);
 
     public static final String DEFAULT_NAMESPACE = "multiple-co-cluster-test";
     public static final String FIRST_NAMESPACE = "first-co-namespace";

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceDeletionRecoveryST.java
Patch:
@@ -55,8 +55,8 @@
  */
 @Tag(RECOVERY)
 @KRaftNotSupported("Topic Operator is not supported by KRaft mode and is used in this test class")
-class NamespaceDeletionRecoveryIsolatedST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(NamespaceDeletionRecoveryIsolatedST.class);
+class NamespaceDeletionRecoveryST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(NamespaceDeletionRecoveryST.class);
     private String storageClassName = "retain";
 
     /**

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceRbacScopeOperatorST.java
Patch:
@@ -27,7 +27,7 @@
 import static org.junit.jupiter.api.Assumptions.assumeFalse;
 
 @Tag(REGRESSION)
-class NamespaceRbacScopeOperatorIsolatedST extends AbstractST {
+class NamespaceRbacScopeOperatorST extends AbstractST {
 
     @IsolatedTest("This test case needs own Cluster Operator")
     void testNamespacedRbacScopeDeploysRoles(ExtensionContext extensionContext) {

File: systemtest/src/test/java/io/strimzi/systemtest/operators/PodSetST.java
Patch:
@@ -37,9 +37,9 @@
  * they should be replacement for StatefulSets in the future.
  */
 @Tag(REGRESSION)
-public class PodSetIsolatedST extends AbstractST {
+public class PodSetST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(PodSetIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(PodSetST.class);
 
     @IsolatedTest("We are changing CO env variables in this test")
     void testPodSetOnlyReconciliation(ExtensionContext extensionContext) {

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicScalabilityST.java
Patch:
@@ -28,9 +28,9 @@
 
 @Tag(SCALABILITY)
 @Disabled("TO is not so stable with large number of topics. After new version of TO, these should be enabled again")
-public class TopicScalabilityIsolatedST extends AbstractST {
+public class TopicScalabilityST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(TopicScalabilityIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(TopicScalabilityST.class);
     private static final int NUMBER_OF_TOPICS = 200;
     private final String sharedClusterName = "topic-scalability-shared-cluster-name";
     final String topicPrefix = "example-topic";

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserScalabilityST.java
Patch:
@@ -32,8 +32,8 @@
 import static io.strimzi.systemtest.Constants.SCALABILITY;
 
 @Tag(SCALABILITY)
-public class UserScalabilityIsolatedST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(UserScalabilityIsolatedST.class);
+public class UserScalabilityST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(UserScalabilityST.class);
     private static String clusterName;
     private static String topicName;
 

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerST.java
Patch:
@@ -71,8 +71,8 @@
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
 @Tag(ROLLING_UPDATE)
-public class KafkaRollerIsolatedST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(KafkaRollerIsolatedST.class);
+public class KafkaRollerST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(KafkaRollerST.class);
 
     @ParallelNamespaceTest
     @KRaftNotSupported("Topic Operator is not supported by KRaft mode and is used in this test class")

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java
Patch:
@@ -59,8 +59,8 @@
 
 @Tag(NETWORKPOLICIES_SUPPORTED)
 @Tag(REGRESSION)
-public class NetworkPoliciesIsolatedST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesIsolatedST.class);
+public class NetworkPoliciesST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesST.class);
 
     @IsolatedTest("Specific Cluster Operator for test case")
     @Tag(INTERNAL_CLIENTS_USED)

File: systemtest/src/test/java/io/strimzi/systemtest/security/PodSecurityProfilesST.java
Patch:
@@ -59,9 +59,9 @@
  */
 @Tag(REGRESSION)
 @Tag(POD_SECURITY_PROFILES_RESTRICTED)
-public class PodSecurityProfilesIsolatedST extends AbstractST {
+public class PodSecurityProfilesST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(PodSecurityProfilesIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(PodSecurityProfilesST.class);
 
     @Tag(ACCEPTANCE)
     @ParallelNamespaceTest

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationST.java
Patch:
@@ -63,8 +63,8 @@
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @KRaftNotSupported("OAuth is not supported by KRaft mode and is used in this test case")
 @FIPSNotSupported("Keycloak is not customized to run on FIPS env - https://github.com/strimzi/strimzi-kafka-operator/issues/8331")
-public class OauthAuthorizationIsolatedST extends OauthAbstractST {
-    protected static final Logger LOGGER = LogManager.getLogger(OauthAuthorizationIsolatedST.class);
+public class OauthAuthorizationST extends OauthAbstractST {
+    protected static final Logger LOGGER = LogManager.getLogger(OauthAuthorizationST.class);
 
     private final String oauthClusterName = "oauth-cluster-authz-name";
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPasswordGrantsST.java
Patch:
@@ -62,8 +62,8 @@
 @Tag(REGRESSION)
 @Tag(ARM64_UNSUPPORTED)
 @FIPSNotSupported("Keycloak is not customized to run on FIPS env - https://github.com/strimzi/strimzi-kafka-operator/issues/8331")
-public class OauthPasswordGrantsIsolatedST extends OauthAbstractST {
-    protected static final Logger LOGGER = LogManager.getLogger(OauthAuthorizationIsolatedST.class);
+public class OauthPasswordGrantsST extends OauthAbstractST {
+    protected static final Logger LOGGER = LogManager.getLogger(OauthAuthorizationST.class);
     private final String oauthClusterName = "oauth-pass-grants-cluster-name";
     private static final String TEST_REALM = "internal";
     private static final String ALICE_SECRET = "alice-secret";

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
Patch:
@@ -81,8 +81,8 @@
 @Tag(REGRESSION)
 @Tag(ARM64_UNSUPPORTED)
 @FIPSNotSupported("Keycloak is not customized to run on FIPS env - https://github.com/strimzi/strimzi-kafka-operator/issues/8331")
-public class OauthPlainIsolatedST extends OauthAbstractST {
-    protected static final Logger LOGGER = LogManager.getLogger(OauthPlainIsolatedST.class);
+public class OauthPlainST extends OauthAbstractST {
+    protected static final Logger LOGGER = LogManager.getLogger(OauthPlainST.class);
 
     private static final String OAUTH_METRICS_CM_PATH = TestUtils.USER_PATH + "/../packaging/examples/metrics/oauth-metrics.yaml";
     private static final String OAUTH_METRICS_CM_KEY = "metrics-config.yml";

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthScopeST.java
Patch:
@@ -47,7 +47,7 @@
 @Tag(REGRESSION)
 @Tag(ARM64_UNSUPPORTED)
 @FIPSNotSupported("Keycloak is not customized to run on FIPS env - https://github.com/strimzi/strimzi-kafka-operator/issues/8331")
-public class OauthScopeIsolatedST extends OauthAbstractST {
+public class OauthScopeST extends OauthAbstractST {
     
     private final String oauthClusterName = "oauth-cluster-scope-name";
     private final String scopeListener = "scopelist";

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -69,8 +69,8 @@
 @Tag(ARM64_UNSUPPORTED)
 @KRaftNotSupported("OAuth is not supported by KRaft mode and is used in this test case")
 @FIPSNotSupported("Keycloak is not customized to run on FIPS env - https://github.com/strimzi/strimzi-kafka-operator/issues/8331")
-public class OauthTlsIsolatedST extends OauthAbstractST {
-    protected static final Logger LOGGER = LogManager.getLogger(OauthTlsIsolatedST.class);
+public class OauthTlsST extends OauthAbstractST {
+    protected static final Logger LOGGER = LogManager.getLogger(OauthTlsST.class);
 
     private final String oauthClusterName = "oauth-cluster-tls-name";
 

File: systemtest/src/test/java/io/strimzi/systemtest/specific/DrainCleanerST.java
Patch:
@@ -37,9 +37,9 @@
 import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;
 
 @Tag(REGRESSION)
-public class DrainCleanerIsolatedST extends AbstractST {
+public class DrainCleanerST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(DrainCleanerIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(DrainCleanerST.class);
     private static SetupDrainCleaner drainCleaner = new SetupDrainCleaner();
 
     @Tag(ACCEPTANCE)

File: systemtest/src/test/java/io/strimzi/systemtest/specific/HelmChartST.java
Patch:
@@ -25,7 +25,7 @@
 
 @Tag(HELM)
 @Tag(REGRESSION)
-class HelmChartIsolatedST extends AbstractST {
+class HelmChartST extends AbstractST {
 
     @IsolatedTest
     void testStrimziComponentsViaHelmChart(ExtensionContext extensionContext) {

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -38,8 +38,8 @@
 
 @Tag(SPECIFIC)
 @Tag(REGRESSION)
-public class SpecificIsolatedST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(SpecificIsolatedST.class);
+public class SpecificST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(SpecificST.class);
 
     @IsolatedTest
     void testClusterWideOperatorWithLimitedAccessToSpecificNamespaceViaRbacRole(final ExtensionContext extensionContext) {

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/KafkaUpgradeDowngradeST.java
Patch:
@@ -41,9 +41,9 @@
  */
 @Tag(UPGRADE)
 @KRaftNotSupported("Strimzi and Kafka downgrade is not supported with KRaft mode")
-public class KafkaUpgradeDowngradeIsolatedST extends AbstractUpgradeST {
+public class KafkaUpgradeDowngradeST extends AbstractUpgradeST {
 
-    private static final Logger LOGGER = LogManager.getLogger(KafkaUpgradeDowngradeIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(KafkaUpgradeDowngradeST.class);
 
     private final String continuousTopicName = "continuous-topic";
     private final int continuousClientsMessageCount = 1000;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java
Patch:
@@ -43,14 +43,14 @@
 
 /**
  * This test class contains tests for Strimzi downgrade from version X to version X - 1.
- * The difference between this class and {@link StrimziUpgradeIsolatedST} is in cluster operator install type.
+ * The difference between this class and {@link StrimziUpgradeST} is in cluster operator install type.
  * Tests in this class use OLM for install cluster operator.
  */
 @Tag(OLM_UPGRADE)
 @KRaftNotSupported("Strimzi and Kafka downgrade is not supported with KRaft mode")
-public class OlmUpgradeIsolatedST extends AbstractUpgradeST {
+public class OlmUpgradeST extends AbstractUpgradeST {
 
-    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);
     private final OlmVersionModificationData olmUpgradeData = new VersionModificationDataLoader(ModificationType.OLM_UPGRADE).getOlmUpgradeData();
     @Test
     void testStrimziUpgrade(ExtensionContext extensionContext) throws IOException {

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziDowngradeST.java
Patch:
@@ -28,13 +28,13 @@
 /**
  * This test class contains tests for Strimzi downgrade from version X to version X - 1.
  * Metadata for downgrade procedure are available in resource file StrimziDowngrade.json
- * Kafka upgrade is done as part of those tests as well, but the tests for Kafka upgrade/downgrade are in {@link KafkaUpgradeDowngradeIsolatedST}.
+ * Kafka upgrade is done as part of those tests as well, but the tests for Kafka upgrade/downgrade are in {@link KafkaUpgradeDowngradeST}.
  */
 @Tag(UPGRADE)
 @KRaftNotSupported("Strimzi and Kafka downgrade is not supported with KRaft mode")
-public class StrimziDowngradeIsolatedST extends AbstractUpgradeST {
+public class StrimziDowngradeST extends AbstractUpgradeST {
 
-    private static final Logger LOGGER = LogManager.getLogger(StrimziDowngradeIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(StrimziDowngradeST.class);
     private final List<BundleVersionModificationData> bundleDowngradeMetadata = new VersionModificationDataLoader(VersionModificationDataLoader.ModificationType.BUNDLE_DOWNGRADE).getBundleUpgradeOrDowngradeDataList();
 
     @ParameterizedTest(name = "testDowngradeStrimziVersion-{0}-{1}")

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -39,13 +39,13 @@
 /**
  * This test class contains tests for Strimzi upgrade from version X to version X + 1.
  * Metadata for upgrade procedure are available in resource file StrimziUpgrade.json
- * Kafka upgrade is done as part of those tests as well, but the tests for Kafka upgrade/downgrade are in {@link KafkaUpgradeDowngradeIsolatedST}.
+ * Kafka upgrade is done as part of those tests as well, but the tests for Kafka upgrade/downgrade are in {@link KafkaUpgradeDowngradeST}.
  */
 @Tag(UPGRADE)
 @KRaftNotSupported("Strimzi and Kafka upgrade is not supported with KRaft mode")
-public class StrimziUpgradeIsolatedST extends AbstractUpgradeST {
+public class StrimziUpgradeST extends AbstractUpgradeST {
 
-    private static final Logger LOGGER = LogManager.getLogger(StrimziUpgradeIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(StrimziUpgradeST.class);
     private final BundleVersionModificationData acrossUpgradeData = new VersionModificationDataLoader(ModificationType.BUNDLE_UPGRADE).buildDataForUpgradeAcrossVersions();
 
     @ParameterizedTest(name = "from: {0} (using FG <{2}>) to: {1} (using FG <{3}>) ")

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceST.java
Patch:
@@ -19,9 +19,9 @@
 import static org.junit.jupiter.api.Assumptions.assumeFalse;
 
 @Tag(REGRESSION)
-class AllNamespaceIsolatedST extends AbstractNamespaceST {
+class AllNamespaceST extends AbstractNamespaceST {
 
-    private static final Logger LOGGER = LogManager.getLogger(AllNamespaceIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(AllNamespaceST.class);
 
     private void deployTestSpecificClusterOperator(final ExtensionContext extensionContext) {
         LOGGER.info("Creating Cluster Operator which will watch over all Namespaces");

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/MultipleNamespaceST.java
Patch:
@@ -18,9 +18,9 @@
 import static io.strimzi.systemtest.Constants.INFRA_NAMESPACE;
 
 @Tag(REGRESSION)
-class MultipleNamespaceIsolatedST extends AbstractNamespaceST {
+class MultipleNamespaceST extends AbstractNamespaceST {
 
-    private static final Logger LOGGER = LogManager.getLogger(MultipleNamespaceIsolatedST.class);
+    private static final Logger LOGGER = LogManager.getLogger(MultipleNamespaceST.class);
 
     private void deployTestSpecificClusterOperator(final ExtensionContext extensionContext) {
         LOGGER.info("Creating Cluster Operator which will watch over multiple Namespaces");

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -352,7 +352,7 @@ public final <T extends HasMetadata> void deleteResource(T... resources) {
     }
 
     @SafeVarargs
-    public final <T extends HasMetadata> void updateResource(ExtensionContext testContext, T... resources) {
+    public final <T extends HasMetadata> void updateResource(T... resources) {
         for (T resource : resources) {
             ResourceType<T> type = findResourceType(resource);
             type.update(resource);

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserScalabilityIsolatedST.java
Patch:
@@ -121,7 +121,7 @@ private void alterAllUsersInList(ExtensionContext extensionContext, List<KafkaUs
         // get one user spec as the template for wait
         KafkaUserSpec kafkaUserSpec = listOfUsers.stream().findFirst().get().getSpec();
 
-        resourceManager.updateResource(extensionContext, listOfUsers.toArray(new KafkaUser[listOfUsers.size()]));
+        resourceManager.updateResource(listOfUsers.toArray(new KafkaUser[listOfUsers.size()]));
         KafkaUserUtils.waitForConfigToBeChangedInAllUsersWithPrefix(clusterOperator.getDeploymentNamespace(), usersPrefix, kafkaUserSpec);
         KafkaUserUtils.waitForAllUsersWithPrefixReady(clusterOperator.getDeploymentNamespace(), usersPrefix);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/AbstractUpgradeST.java
Patch:
@@ -623,7 +623,5 @@ protected void doKafkaConnectAndKafkaConnectorUpgradeOrDowngradeProcedure(final
 
         // Verify that pods are stable
         PodUtils.verifyThatRunningPodsAreStable(testStorage.getNamespaceName(), clusterName);
-        // Check errors in CO log
-        assertNoCoErrorsLogged(testStorage.getNamespaceName(), 0);
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeIsolatedST.java
Patch:
@@ -145,9 +145,6 @@ void testStrimziUpgrade(ExtensionContext extensionContext) throws IOException {
 
         // Wait for messages of previously created clients
         ClientUtils.waitForClientsSuccess(testStorage.getProducerName(), testStorage.getConsumerName(), clusterOperator.getDeploymentNamespace(), testStorage.getMessageCount());
-
-        // Check for errors in Cluster Operator log
-        assertNoCoErrorsLogged(clusterOperator.getDeploymentNamespace(), 0);
     }
 
     @BeforeAll

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziDowngradeIsolatedST.java
Patch:
@@ -79,8 +79,6 @@ private void performDowngrade(BundleVersionModificationData downgradeData, Exten
         checkAllImages(downgradeData, clusterOperator.getDeploymentNamespace());
         // Verify upgrade
         verifyProcedure(downgradeData, testStorage.getProducerName(), testStorage.getConsumerName(), clusterOperator.getDeploymentNamespace());
-        // Check errors in CO log
-        assertNoCoErrorsLogged(clusterOperator.getDeploymentNamespace(), 0);
     }
 
     @BeforeEach

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -531,6 +531,7 @@ private void afterAllMustExecute(ExtensionContext extensionContext)  {
     protected synchronized void afterAllMayOverride(ExtensionContext extensionContext) throws Exception {
         if (!Environment.SKIP_TEARDOWN) {
             ResourceManager.getInstance().deleteResources(extensionContext);
+            KubeClusterResource.getInstance().deleteAllSetNamespaces();
         }
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAllNamespaceIsolatedST.java
Patch:
@@ -82,7 +82,6 @@ void testDeployExampleKafkaRebalance(ExtensionContext extensionContext) {
     @BeforeAll
     void setup(ExtensionContext extensionContext) {
         clusterOperator = clusterOperator.defaultInstallation(extensionContext)
-            .withNamespace(cluster.getDefaultOlmNamespace())
             .withWatchingNamespaces(WATCH_ALL_NAMESPACES)
             .createInstallation()
             // run always OLM installation

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/KubeCmdClient.java
Patch:
@@ -24,9 +24,6 @@
 public interface KubeCmdClient<K extends KubeCmdClient<K>> {
 
     String defaultNamespace();
-    String defaultOlmNamespace();
-    String defaultOlmSourceNamespace();
-
 
     /** Deletes the resources by resource name. */
     K deleteByName(String resourceType, String resourceName);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaTopicUtils.java
Patch:
@@ -201,7 +201,7 @@ public static void waitForTopicsByPrefixDeletionUsingPodCli(String namespace, St
 
     public static void waitForTopicWillBePresentInKafka(String namespaceName, String topicName, String bootstrapName, String scraperPodName) {
         LOGGER.info("Waiting for KafkaTopic: {}/{} to be present in Kafka", namespaceName, topicName);
-        TestUtils.waitFor("KafkaTopic: " + namespaceName + "/" + topicName + " to be present in Kafka", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,
+        TestUtils.waitFor("KafkaTopic: " + namespaceName + "/" + topicName + " to be present in Kafka", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_RESOURCE_RECOVERY,
             () -> KafkaCmdClient.listTopicsUsingPodCli(namespaceName, scraperPodName, bootstrapName).contains(topicName));
     }
 

File: user-operator/src/main/java/io/strimzi/operator/user/Main.java
Patch:
@@ -136,7 +136,7 @@ public static void main(String[] args) {
      * Creates the Kafka Admin API client
      *
      * @param config                User Operator configuration
-     * @param client                Kubernetes client
+     * @param secretOperator        Secret operator for managing secrets
      * @param adminClientProvider   Admin client provider
      *
      * @return  An instance of the Admin API client

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/specific/HelmResource.java
Patch:
@@ -97,7 +97,7 @@ private void clusterOperator(long operationTimeout, long reconciliationInterval,
         }
 
         Path pathToChart = new File(HELM_CHART).toPath();
-        ResourceManager.helmClient().install(pathToChart, HELM_RELEASE_NAME, values);
+        ResourceManager.helmClient().namespace(namespaceInstallTo).install(pathToChart, HELM_RELEASE_NAME, values);
         DeploymentUtils.waitForDeploymentReady(namespaceInstallTo, ResourceManager.getCoDeploymentName());
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -451,10 +451,11 @@ private static void configureCruiseControlMetrics(Kafka kafkaAssembly, KafkaClus
             addAll(metricReporterList, configuration.getConfigOption(KAFKA_METRIC_REPORTERS_CONFIG_FIELD).split(","));
         }
 
-        if (kafkaAssembly.getSpec().getCruiseControl() != null && kafkaAssembly.getSpec().getKafka().getReplicas() < 2) {
+        if (kafkaAssembly.getSpec().getCruiseControl() != null
+                && kafkaCluster.nodes().stream().filter(n -> n.broker()).count() < 2) {
             throw new InvalidResourceException("Kafka " +
                     kafkaAssembly.getMetadata().getNamespace() + "/" + kafkaAssembly.getMetadata().getName() +
-                    " has invalid configuration. Cruise Control cannot be deployed with a single-node Kafka cluster. It requires at least two Kafka nodes.");
+                    " has invalid configuration. Cruise Control cannot be deployed with a Kafka cluster which has only one broker. It requires at least two Kafka brokers.");
         }
         kafkaCluster.cruiseControlSpec = kafkaAssembly.getSpec().getCruiseControl();
         if (kafkaCluster.cruiseControlSpec != null) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -3706,11 +3706,12 @@ public void testCruiseControlWithSingleNodeKafka() {
 
         InvalidResourceException ex = assertThrows(InvalidResourceException.class, () -> {
             List<KafkaPool> pools = NodePoolUtils.createKafkaPools(Reconciliation.DUMMY_RECONCILIATION, kafkaAssembly, null, Map.of(), Map.of(), false, SHARED_ENV_PROVIDER);
-            KafkaCluster kc = KafkaCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kafkaAssembly, pools, VERSIONS, false, null, SHARED_ENV_PROVIDER);
+            KafkaCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kafkaAssembly, pools, VERSIONS, false, null, SHARED_ENV_PROVIDER);
         });
 
         assertThat(ex.getMessage(), is("Kafka " + NAMESPACE + "/" + CLUSTER + " has invalid configuration. " +
-                "Cruise Control cannot be deployed with a single-node Kafka cluster. It requires at least two Kafka nodes."));
+                "Cruise Control cannot be deployed with a Kafka cluster which has only one broker. " +
+                "It requires at least two Kafka brokers."));
     }
 
     @ParallelTest

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlST.java
Patch:
@@ -203,9 +203,9 @@ void testCruiseControlWithSingleNodeKafka(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(clusterOperator.getDeploymentNamespace(), extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
 
-        final String errMessage =  "Kafka " + namespaceName + "/" + clusterName + " has invalid configuration." +
-            " Cruise Control cannot be deployed with a single-node Kafka cluster. It requires " +
-            "at least two Kafka nodes.";
+        final String errMessage =  "Kafka " + namespaceName + "/" + clusterName + " has invalid configuration. " +
+            "Cruise Control cannot be deployed with a Kafka cluster which has only one broker. " +
+                "It requires at least two Kafka brokers.";
 
         LOGGER.info("Deploying single node Kafka with CruiseControl");
         resourceManager.createResource(extensionContext, false, KafkaTemplates.kafkaWithCruiseControl(clusterName, 1, 1).build());

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -100,7 +100,7 @@ public Future<T> patchAsync(Reconciliation reconciliation, T resource) {
                 T result = operation().inNamespace(namespace).withName(name).patch(PatchContext.of(PatchType.JSON), resource);
                 LOGGER.debugCr(reconciliation, "{} {} in namespace {} has been patched", resourceKind, name, namespace);
                 future.complete(result);
-            } catch (Exception e) {
+            } catch (Throwable e) {
                 LOGGER.debugCr(reconciliation, "Caught exception while patching {} {} in namespace {}", resourceKind, name, namespace, e);
                 future.fail(e);
             }
@@ -113,7 +113,7 @@ public Future<T> patchAsync(Reconciliation reconciliation, T resource) {
      * Updates custom resource status asynchronously
      *
      * @param reconciliation    Reconciliation marker
-     * @param resource          Desired resource with the updated statis
+     * @param resource          Desired resource with the updated status
      *
      * @return  Future which completes when the status is patched
      */
@@ -128,7 +128,7 @@ public Future<T> updateStatusAsync(Reconciliation reconciliation, T resource) {
                 T result = operation().inNamespace(namespace).resource(resource).updateStatus();
                 LOGGER.infoCr(reconciliation, "Status of {} {} in namespace {} has been updated", resourceKind, name, namespace);
                 future.complete(result);
-            } catch (Exception e) {
+            } catch (Throwable e) {
                 LOGGER.debugCr(reconciliation, "Caught exception while updating status of {} {} in namespace {}", resourceKind, name, namespace, e);
                 future.fail(e);
             }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java
Patch:
@@ -60,7 +60,8 @@ public static void waitUntilKafkaConnectRestApiIsAvailable(String namespaceName,
     public static void waitForMessagesInKafkaConnectFileSink(String namespaceName, String kafkaConnectPodName, String sinkFileName, String message) {
         LOGGER.info("Waiting for messages in file sink on {}", kafkaConnectPodName);
         TestUtils.waitFor("messages in file sink", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_SEND_RECEIVE_MSG,
-            () -> cmdKubeClient(namespaceName).execInPod(Level.TRACE, kafkaConnectPodName, "/bin/bash", "-c", "cat " + sinkFileName).out().contains(message));
+            () -> cmdKubeClient(namespaceName).execInPod(Level.TRACE, kafkaConnectPodName, "/bin/bash", "-c", "cat " + sinkFileName).out().contains(message),
+            () -> LOGGER.warn(cmdKubeClient(namespaceName).execInPod(Level.TRACE, kafkaConnectPodName, "/bin/bash", "-c", "cat " + sinkFileName).out()));
         LOGGER.info("Expected messages are in file sink on {}", kafkaConnectPodName);
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/EntityOperatorReconciler.java
Patch:
@@ -114,7 +114,7 @@ public Future<Void> reconcile(boolean isOpenShift, ImagePullPolicy imagePullPoli
                 .compose(i -> networkPolicy())
                 .compose(i -> topicOperatorRoleBindings())
                 .compose(i -> userOperatorRoleBindings())
-                .compose(i -> topicOperagorConfigMap())
+                .compose(i -> topicOperatorConfigMap())
                 .compose(i -> userOperatorConfigMap())
                 .compose(i -> deleteOldEntityOperatorSecret())
                 .compose(i -> topicOperatorSecret(clock))
@@ -275,7 +275,7 @@ protected Future<Void> userOperatorRoleBindings() {
      *
      * @return  Future which completes when the reconciliation is done
      */
-    protected Future<Void> topicOperagorConfigMap() {
+    protected Future<Void> topicOperatorConfigMap() {
         if (entityOperator != null && entityOperator.topicOperator() != null) {
             return MetricsAndLoggingUtils.metricsAndLogging(reconciliation, configMapOperator, entityOperator.topicOperator().logging(), null)
                     .compose(logging ->

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -392,9 +392,9 @@ protected List<EnvVar> getEnvVars() {
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_API_PORT,  String.valueOf(REST_API_PORT)));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_API_HEALTHCHECK_PATH, API_HEALTHCHECK_PATH));
 
-        ModelUtils.heapOptions(varList, 75, 0L, jvmOptions, resources);
-        ModelUtils.jvmPerformanceOptions(varList, jvmOptions);
-        ModelUtils.jvmSystemProperties(varList, jvmOptions);
+        JvmOptionUtils.heapOptions(varList, 75, 0L, jvmOptions, resources);
+        JvmOptionUtils.jvmPerformanceOptions(varList, jvmOptions);
+        JvmOptionUtils.jvmSystemProperties(varList, jvmOptions);
 
         if (configuration != null && !configuration.getConfiguration().isEmpty()) {
             varList.add(ContainerUtils.createEnvVar(ENV_VAR_CRUISE_CONTROL_CONFIGURATION, configuration.getConfiguration()));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -169,7 +169,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_SECURITY_PROTOCOL, EntityTopicOperatorSpec.DEFAULT_SECURITY_PROTOCOL));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_TLS_ENABLED, Boolean.toString(true)));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
-        ModelUtils.javaOptions(varList, jvmOptions);
+        JvmOptionUtils.javaOptions(varList, jvmOptions);
 
         // Add shared environment variables used for all containers
         varList.addAll(ContainerUtils.requiredEnvVars());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -199,7 +199,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_SECRET_PREFIX, secretPrefix));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_ACLS_ADMIN_API_SUPPORTED, String.valueOf(aclsAdminApiSupported)));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_KRAFT_ENABLED, String.valueOf(kraftEnabled)));
-        ModelUtils.javaOptions(varList, jvmOptions);
+        JvmOptionUtils.javaOptions(varList, jvmOptions);
 
         // Add shared environment variables used for all containers
         varList.addAll(ContainerUtils.requiredEnvVars());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -394,7 +394,7 @@ protected List<EnvVar> getEnvVars() {
         List<EnvVar> varList = new ArrayList<>();
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_BRIDGE_METRICS_ENABLED, String.valueOf(isMetricsEnabled)));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
-        ModelUtils.javaOptions(varList, jvmOptions);
+        JvmOptionUtils.javaOptions(varList, jvmOptions);
 
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_BRIDGE_BOOTSTRAP_SERVERS, bootstrapServers));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_BRIDGE_ADMIN_CLIENT_CONFIG, kafkaBridgeAdminClient == null ? "" : new KafkaBridgeAdminClientConfiguration(reconciliation, kafkaBridgeAdminClient.getConfig().entrySet()).getConfiguration()));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1457,9 +1457,9 @@ protected List<EnvVar> getEnvVars(KafkaPool pool) {
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_METRICS_ENABLED, String.valueOf(metrics.isEnabled())));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED, String.valueOf(pool.gcLoggingEnabled)));
 
-        ModelUtils.heapOptions(varList, 50, 5L * 1024L * 1024L * 1024L, pool.jvmOptions, pool.resources);
-        ModelUtils.jvmPerformanceOptions(varList, pool.jvmOptions);
-        ModelUtils.jvmSystemProperties(varList, pool.jvmOptions);
+        JvmOptionUtils.heapOptions(varList, 50, 5L * 1024L * 1024L * 1024L, pool.jvmOptions, pool.resources);
+        JvmOptionUtils.jvmPerformanceOptions(varList, pool.jvmOptions);
+        JvmOptionUtils.jvmSystemProperties(varList, pool.jvmOptions);
 
         for (GenericKafkaListener listener : listeners) {
             if (isListenerWithOAuth(listener))   {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -647,9 +647,9 @@ protected List<EnvVar> getEnvVars(boolean stableIdentities) {
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_CONNECT_BOOTSTRAP_SERVERS, bootstrapServers));
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
 
-        ModelUtils.heapOptions(varList, 75, 0L, jvmOptions, resources);
-        ModelUtils.jvmPerformanceOptions(varList, jvmOptions);
-        ModelUtils.jvmSystemProperties(varList, jvmOptions);
+        JvmOptionUtils.heapOptions(varList, 75, 0L, jvmOptions, resources);
+        JvmOptionUtils.jvmPerformanceOptions(varList, jvmOptions);
+        JvmOptionUtils.jvmSystemProperties(varList, jvmOptions);
 
         if (tls != null) {
             populateTLSEnvVars(varList);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Cluster.java
Patch:
@@ -291,7 +291,7 @@ protected List<EnvVar> getEnvVars(boolean stableIdentities) {
             varList.add(ContainerUtils.createEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_2_OAUTH_PASSWORDS_CLUSTERS, clustersOauthPasswords.toString()));
         }
 
-        ModelUtils.jvmSystemProperties(varList, jvmOptions);
+        JvmOptionUtils.jvmSystemProperties(varList, jvmOptions);
 
         return varList;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -370,9 +370,9 @@ protected List<EnvVar> getEnvVars() {
             varList.add(ContainerUtils.createEnvVar(ENV_VAR_STRIMZI_TRACING, tracing.getType()));
         }
 
-        ModelUtils.heapOptions(varList, 75, 0L, jvmOptions, resources);
-        ModelUtils.jvmPerformanceOptions(varList, jvmOptions);
-        ModelUtils.jvmSystemProperties(varList, jvmOptions);
+        JvmOptionUtils.heapOptions(varList, 75, 0L, jvmOptions, resources);
+        JvmOptionUtils.jvmPerformanceOptions(varList, jvmOptions);
+        JvmOptionUtils.jvmSystemProperties(varList, jvmOptions);
 
         /* consumer */
         addConsumerEnvVars(varList);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -493,9 +493,9 @@ protected List<EnvVar> getEnvVars() {
 
         varList.addAll(jmx.envVars());
 
-        ModelUtils.heapOptions(varList, 75, 2L * 1024L * 1024L * 1024L, jvmOptions, resources);
-        ModelUtils.jvmPerformanceOptions(varList, jvmOptions);
-        ModelUtils.jvmSystemProperties(varList, jvmOptions);
+        JvmOptionUtils.heapOptions(varList, 75, 2L * 1024L * 1024L * 1024L, jvmOptions, resources);
+        JvmOptionUtils.jvmPerformanceOptions(varList, jvmOptions);
+        JvmOptionUtils.jvmSystemProperties(varList, jvmOptions);
         varList.add(ContainerUtils.createEnvVar(ENV_VAR_ZOOKEEPER_CONFIGURATION, configuration.getConfiguration()));
 
         // Add shared environment variables used for all containers

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractModelTest.java
Patch:
@@ -58,7 +58,7 @@ private String getPerformanceOptions(JvmOptions opts) {
         AbstractModel am = new Model(kafka);
         am.jvmOptions = opts;
         List<EnvVar> envVars = new ArrayList<>(1);
-        ModelUtils.jvmPerformanceOptions(envVars, am.jvmOptions);
+        JvmOptionUtils.jvmPerformanceOptions(envVars, am.jvmOptions);
 
         if (!envVars.isEmpty()) {
             return envVars.get(0).getValue();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -218,7 +218,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_API_USER).withValue(API_USER_NAME).build());
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_API_PORT).withValue(Integer.toString(CruiseControl.REST_API_PORT)).build());
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_API_HEALTHCHECK_PATH).withValue(API_HEALTHCHECK_PATH).build());
-        expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_KAFKA_HEAP_OPTS).withValue("-Xms" + ModelUtils.DEFAULT_JVM_XMS).build());
+        expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_KAFKA_HEAP_OPTS).withValue("-Xms" + JvmOptionUtils.DEFAULT_JVM_XMS).build());
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_CRUISE_CONTROL_CONFIGURATION).withValue(ccConfiguration.getConfiguration()).build());
         io.strimzi.operator.cluster.TestUtils.maybeAddHttpProxyEnvVars(expected);
         return expected;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -121,7 +121,7 @@ public class KafkaConnectClusterTest {
     private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics("metrics-config.yml", metricsCMName);
     private final String configurationJson = "foo: bar";
     private final String bootstrapServers = "foo-kafka:9092";
-    private final String kafkaHeapOpts = "-Xms" + ModelUtils.DEFAULT_JVM_XMS;
+    private final String kafkaHeapOpts = "-Xms" + JvmOptionUtils.DEFAULT_JVM_XMS;
 
     private final OrderedProperties defaultConfiguration = new OrderedProperties()
             .addPair("offset.storage.topic", "connect-cluster-offsets")

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -109,7 +109,7 @@ public class KafkaMirrorMaker2ClusterTest {
     private final String configurationJson = "foo: bar";
     private final String bootstrapServers = "foo-kafka:9092";
     private final String targetClusterAlias = "target";
-    private final String kafkaHeapOpts = "-Xms" + ModelUtils.DEFAULT_JVM_XMS;
+    private final String kafkaHeapOpts = "-Xms" + JvmOptionUtils.DEFAULT_JVM_XMS;
 
     private final OrderedProperties defaultConfiguration = new OrderedProperties()
             .addPair("config.storage.topic", "mirrormaker2-cluster-configs")

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -97,7 +97,7 @@ public class KafkaMirrorMakerClusterTest {
     private final String include = ".*";
     private final int offsetCommitInterval = 42000;
     private final boolean abortOnSendFailure = false;
-    private final String kafkaHeapOpts = "-Xms" + ModelUtils.DEFAULT_JVM_XMS;
+    private final String kafkaHeapOpts = "-Xms" + JvmOptionUtils.DEFAULT_JVM_XMS;
 
     private final KafkaMirrorMakerProducerSpec producer = new KafkaMirrorMakerProducerSpecBuilder()
             .withBootstrapServers(producerBootstrapServers)

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -10,7 +10,6 @@
 import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
 import com.fasterxml.jackson.dataformat.yaml.YAMLGenerator;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.client.CustomResource;
@@ -81,7 +80,6 @@
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
 @Group(Constants.RESOURCE_GROUP_NAME)
-@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class Kafka extends CustomResource<KafkaSpec, KafkaStatus> implements Namespaced, UnknownPropertyPreserving {
 
     public static final String V1BETA2 = Constants.V1BETA2;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnect.java
Patch:
@@ -10,7 +10,6 @@
 import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
 import com.fasterxml.jackson.dataformat.yaml.YAMLGenerator;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.model.annotation.Group;
@@ -75,7 +74,6 @@
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
 @Group(Constants.RESOURCE_GROUP_NAME)
-@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaConnect extends CustomResource<KafkaConnectSpec, KafkaConnectStatus> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnector.java
Patch:
@@ -6,7 +6,6 @@
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.model.annotation.Group;
@@ -82,7 +81,6 @@
 @ToString
 @Version(Constants.V1BETA2)
 @Group(Constants.RESOURCE_GROUP_NAME)
-@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaConnector extends CustomResource<KafkaConnectorSpec, KafkaConnectorStatus> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
     public static final String V1BETA2 = Constants.V1BETA2;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2.java
Patch:
@@ -9,7 +9,6 @@
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.model.annotation.Group;
@@ -74,7 +73,6 @@
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
 @Group(Constants.RESOURCE_GROUP_NAME)
-@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaMirrorMaker2 extends CustomResource<KafkaMirrorMaker2Spec, KafkaMirrorMaker2Status> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaRebalance.java
Patch:
@@ -9,7 +9,6 @@
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.model.annotation.Group;
@@ -90,7 +89,6 @@
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
 @Group(Constants.RESOURCE_GROUP_NAME)
-@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaRebalance extends CustomResource<KafkaRebalanceSpec, KafkaRebalanceStatus> implements Namespaced, UnknownPropertyPreserving {
 
     private static final long serialVersionUID = 1L;

File: api/src/main/java/io/strimzi/api/kafka/model/StrimziPodSet.java
Patch:
@@ -9,7 +9,6 @@
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.model.annotation.Group;
@@ -82,7 +81,6 @@
 @EqualsAndHashCode(callSuper = true)
 @Version(Constants.V1BETA2)
 @Group(Constants.RESOURCE_CORE_GROUP_NAME)
-@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class StrimziPodSet extends CustomResource<StrimziPodSetSpec, StrimziPodSetStatus> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConfiguration.java
Patch:
@@ -6,7 +6,6 @@
 package io.strimzi.operator.cluster.model;
 
 import com.fasterxml.jackson.databind.ObjectMapper;
-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.strimzi.api.kafka.model.KafkaClusterSpec;
 import io.strimzi.kafka.config.model.ConfigModel;
 import io.strimzi.kafka.config.model.ConfigModels;
@@ -107,7 +106,6 @@ public List<String> validate(KafkaVersion kafkaVersion) {
      * @param kafkaVersion The broker version.
      * @return The config model for that broker version.
      */
-    @SuppressFBWarnings({"RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE"})
     public static Map<String, ConfigModel> readConfigModel(KafkaVersion kafkaVersion) {
         String name = "/kafka-" + kafkaVersion.version() + "-config-model.json";
         try {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaRoller.java
Patch:
@@ -352,7 +352,6 @@ private Future<Void> schedule(NodeRef nodeRef, long delay, TimeUnit unit) {
      * @throws ForceableProblem         Some error. Not thrown when finalAttempt==true.
      * @throws UnforceableProblem       Some error, still thrown when finalAttempt==true.
      */
-    @SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
     @SuppressWarnings({"checkstyle:CyclomaticComplexity"})
     private void restartIfNecessary(NodeRef nodeRef, RestartContext restartContext)
             throws Exception {

File: operator-common/src/main/java/io/strimzi/operator/common/ShutdownHook.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common;
 
-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.vertx.core.Vertx;
 import static java.util.Objects.requireNonNull;
 import org.apache.logging.log4j.LogManager;
@@ -19,7 +18,6 @@
  * <p>
  * We add a fixed timeout because Vertx has none for stopping running Verticles.
  */
-@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class ShutdownHook implements Runnable {
     private static final Logger LOGGER = LogManager.getLogger(ShutdownHook.class);
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.DefaultKubernetesResourceList;
 import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.client.CustomResource;
@@ -28,8 +27,6 @@
  * @param <T> The custom resource type.
  * @param <L> The list variant of the custom resource type.
  */
-@SuppressFBWarnings(value = "RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE",
-        justification = "Erroneous on Java 11: https://github.com/spotbugs/spotbugs/issues/756")
 public class CrdOperator<C extends KubernetesClient,
             T extends CustomResource,
             L extends DefaultKubernetesResourceList<T>>

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/CruiseControlReconciler.java
Patch:
@@ -276,6 +276,9 @@ protected Future<Void> deployment(boolean isOpenShift, ImagePullPolicy imagePull
             int caCertGeneration = ModelUtils.caCertGeneration(clusterCa);
             Annotations.annotations(deployment.getSpec().getTemplate()).put(
                     Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION, String.valueOf(caCertGeneration));
+            int caKeyGeneration = ModelUtils.caKeyGeneration(clusterCa);
+            Annotations.annotations(deployment.getSpec().getTemplate()).put(
+                    Ca.ANNO_STRIMZI_IO_CLUSTER_CA_KEY_GENERATION, String.valueOf(caKeyGeneration));
 
             return deploymentOperator
                     .reconcile(reconciliation, reconciliation.namespace(), CruiseControlResources.deploymentName(reconciliation.name()), deployment)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/EntityOperatorReconciler.java
Patch:
@@ -424,6 +424,8 @@ protected Future<Void> deployment(boolean isOpenShift, ImagePullPolicy imagePull
             Deployment deployment = entityOperator.generateDeployment(isOpenShift, imagePullPolicy, imagePullSecrets);
             int caCertGeneration = ModelUtils.caCertGeneration(clusterCa);
             Annotations.annotations(deployment.getSpec().getTemplate()).put(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION, String.valueOf(caCertGeneration));
+            int caKeyGeneration = ModelUtils.caKeyGeneration(clusterCa);
+            Annotations.annotations(deployment.getSpec().getTemplate()).put(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_KEY_GENERATION, String.valueOf(caKeyGeneration));
 
             return deploymentOperator
                     .reconcile(reconciliation, reconciliation.namespace(), KafkaResources.entityOperatorDeploymentName(reconciliation.name()), deployment)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaExporterReconciler.java
Patch:
@@ -183,6 +183,9 @@ private Future<Void> deployment(boolean isOpenShift, ImagePullPolicy imagePullPo
             int caCertGeneration = ModelUtils.caCertGeneration(this.clusterCa);
             Annotations.annotations(deployment.getSpec().getTemplate()).put(
                     Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION, String.valueOf(caCertGeneration));
+            int caKeyGeneration = ModelUtils.caKeyGeneration(clusterCa);
+            Annotations.annotations(deployment.getSpec().getTemplate()).put(
+                    Ca.ANNO_STRIMZI_IO_CLUSTER_CA_KEY_GENERATION, String.valueOf(caKeyGeneration));
 
             return deploymentOperator
                     .reconcile(reconciliation, reconciliation.namespace(), KafkaExporterResources.deploymentName(reconciliation.name()), deployment)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaReconciler.java
Patch:
@@ -732,6 +732,7 @@ protected Future<Void> podDisruptionBudget() {
     private Map<String, String> podSetPodAnnotations(int nodeId) {
         Map<String, String> podAnnotations = new LinkedHashMap<>(9);
         podAnnotations.put(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION, String.valueOf(ModelUtils.caCertGeneration(this.clusterCa)));
+        podAnnotations.put(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_KEY_GENERATION, String.valueOf(ModelUtils.caKeyGeneration(this.clusterCa)));
         podAnnotations.put(Ca.ANNO_STRIMZI_IO_CLIENTS_CA_CERT_GENERATION, String.valueOf(ModelUtils.caCertGeneration(this.clientsCa)));
         podAnnotations.put(Annotations.ANNO_STRIMZI_LOGGING_APPENDERS_HASH, loggingHash);
         podAnnotations.put(KafkaCluster.ANNO_STRIMZI_BROKER_CONFIGURATION_HASH, brokerConfigurationHash.get(nodeId));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/ZooKeeperReconciler.java
Patch:
@@ -513,6 +513,7 @@ private Future<Void> podSet(int replicas) {
     public Map<String, String> zkPodSetPodAnnotations(int podNum) {
         Map<String, String> podAnnotations = new LinkedHashMap<>((int) Math.ceil(podNum / 0.75));
         podAnnotations.put(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION, String.valueOf(ModelUtils.caCertGeneration(this.clusterCa)));
+        podAnnotations.put(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_KEY_GENERATION, String.valueOf(ModelUtils.caKeyGeneration(this.clusterCa)));
         podAnnotations.put(Annotations.ANNO_STRIMZI_LOGGING_HASH, loggingHash);
         podAnnotations.put(ANNO_STRIMZI_SERVER_CERT_HASH, zkCertificateHash.get(podNum));
         return podAnnotations;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -195,6 +195,7 @@ private Future<Void> initialReconcile(VertxTestContext context) {
                 sps.getSpec().getPods().stream().map(PodSetUtils::mapToPod).forEach(pod -> {
                     assertThat(pod.getMetadata().getAnnotations(), hasEntry(Ca.ANNO_STRIMZI_IO_CLIENTS_CA_CERT_GENERATION, "0"));
                     assertThat(pod.getMetadata().getAnnotations(), hasEntry(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION, "0"));
+                    assertThat(pod.getMetadata().getAnnotations(), hasEntry(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_KEY_GENERATION, "0"));
                     var brokersSecret = client.secrets().inNamespace(NAMESPACE).withName(KafkaResources.kafkaSecretName(CLUSTER_NAME)).get();
                     assertThat(pod.getMetadata().getAnnotations(), hasEntry(Annotations.ANNO_STRIMZI_SERVER_CERT_HASH,
                             CertUtils.getCertificateThumbprint(brokersSecret, ClusterCa.secretEntryNameForPod(pod.getMetadata().getName(), Ca.SecretEntry.CRT))
@@ -204,6 +205,7 @@ private Future<Void> initialReconcile(VertxTestContext context) {
                 StrimziPodSet zkSps = supplier.strimziPodSetOperator.client().inNamespace(NAMESPACE).withName(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME)).get();
                 zkSps.getSpec().getPods().stream().map(PodSetUtils::mapToPod).forEach(pod -> {
                     assertThat(pod.getMetadata().getAnnotations(), hasEntry(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION, "0"));
+                    assertThat(pod.getMetadata().getAnnotations(), hasEntry(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_KEY_GENERATION, "0"));
                     var zooKeeperSecret = client.secrets().inNamespace(NAMESPACE).withName(KafkaResources.zookeeperSecretName(CLUSTER_NAME)).get();
                     assertThat(pod.getMetadata().getAnnotations(), hasEntry(Annotations.ANNO_STRIMZI_SERVER_CERT_HASH,
                             CertUtils.getCertificateThumbprint(zooKeeperSecret, ClusterCa.secretEntryNameForPod(pod.getMetadata().getName(), Ca.SecretEntry.CRT))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperator.java
Patch:
@@ -881,9 +881,9 @@ private Future<MapAndStatus<ConfigMap, KafkaRebalanceStatus>> onPendingProposal(
                                             }
                                         })
                                         .onFailure(e -> {
-                                            LOGGER.errorCr(reconciliation, "Cruise Control getting rebalance proposal failed", e.getCause());
+                                            LOGGER.errorCr(reconciliation, "Cruise Control getting rebalance proposal failed");
                                             vertx.cancelTimer(t);
-                                            p.fail(e.getCause());
+                                            p.fail(e);
                                         });
                                 }
                             } else {

File: systemtest/src/test/java/io/strimzi/systemtest/specific/RackAwarenessST.java
Patch:
@@ -37,7 +37,6 @@
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
-import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StrimziPodSetUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
@@ -197,7 +196,6 @@ void testConnectRackAwareness(ExtensionContext extensionContext) {
 
         LOGGER.info("KafkaConnect cluster deployed successfully");
         String deployName = KafkaConnectResources.deploymentName(testStorage.getClusterName());
-        DeploymentUtils.waitForDeploymentReady(testStorage.getNamespaceName(), deployName);
         String podName = PodUtils.getPodNameByPrefix(testStorage.getNamespaceName(), deployName);
         Pod pod = kubeClient().getPod(testStorage.getNamespaceName(), podName);
 

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectIsolatedST.java
Patch:
@@ -1059,6 +1059,7 @@ void testScaleConnectWithConnectorToZero(ExtensionContext extensionContext) {
 
         KafkaConnectUtils.waitForConnectReady(namespaceName, clusterName);
         PodUtils.waitForPodsReady(namespaceName, labelSelector, 0, true);
+        KafkaConnectorUtils.waitForConnectorNotReady(namespaceName, clusterName);
 
         connectPods = kubeClient(namespaceName).listPods(Labels.STRIMZI_NAME_LABEL, KafkaConnectResources.deploymentName(clusterName));
         KafkaConnectStatus connectStatus = KafkaConnectResource.kafkaConnectClient().inNamespace(namespaceName).withName(clusterName).get().getStatus();

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthScopeIsolatedST.java
Patch:
@@ -26,8 +26,6 @@
 import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.JobUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
-import io.strimzi.test.k8s.KubeClusterResource;
-import org.apache.logging.log4j.Level;
 import org.hamcrest.CoreMatchers;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Tag;
@@ -134,7 +132,7 @@ void testScopeKafkaConnectSetCorrectly(ExtensionContext extensionContext) {
         // explicitly verifying also logs
         String kafkaPodName = kubeClient().listPodsByPrefixInName(clusterOperator.getDeploymentNamespace(), KafkaResources.kafkaPodName(oauthClusterName, 0)).get(0).getMetadata().getName();
 
-        String kafkaLog = KubeClusterResource.cmdKubeClient(clusterOperator.getDeploymentNamespace()).execInCurrentNamespace(Level.DEBUG, "logs", kafkaPodName, "--tail", "50").out();
+        String kafkaLog = kubeClient().logsInSpecificNamespace(clusterOperator.getDeploymentNamespace(), kafkaPodName);
         assertThat(kafkaLog, CoreMatchers.containsString("Access token expires at"));
         assertThat(kafkaLog, CoreMatchers.containsString("Evaluating path: $[*][?]"));
         assertThat(kafkaLog, CoreMatchers.containsString("Evaluating path: @['scope']"));

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAllNamespaceIsolatedST.java
Patch:
@@ -23,7 +23,7 @@
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @Tag(OLM)
 @IsolatedSuite
-public class AllNamespacesIsolatedST extends OlmAbstractST {
+public class OlmAllNamespaceIsolatedST extends OlmAbstractST {
 
     public static final String NAMESPACE = "olm-namespace";
 

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmSingleNamespaceIsolatedST.java
Patch:
@@ -24,7 +24,7 @@
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @Tag(OLM)
 @IsolatedSuite
-public class SingleNamespaceIsolatedST extends OlmAbstractST {
+public class OlmSingleNamespaceIsolatedST extends OlmAbstractST {
 
     public static final String NAMESPACE = "olm-namespace";
 

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/MultipleNamespaceIsolatedST.java
Patch:
@@ -36,6 +36,7 @@ private void deployTestSpecificClusterOperator() {
             .withExtensionContext(BeforeAllOnce.getSharedExtensionContext())
             .withNamespace(INFRA_NAMESPACE)
             .withWatchingNamespaces(String.join(",", INFRA_NAMESPACE, PRIMARY_KAFKA_WATCHED_NAMESPACE, MAIN_TEST_NAMESPACE))
+            .withBindingsNamespaces(Arrays.asList(INFRA_NAMESPACE, PRIMARY_KAFKA_WATCHED_NAMESPACE, MAIN_TEST_NAMESPACE))
             .createInstallation()
             .runInstallation();
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -191,7 +191,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_API_HEALTHCHECK_PATH).withValue(API_HEALTHCHECK_PATH).build());
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_KAFKA_HEAP_OPTS).withValue("-Xms" + ModelUtils.DEFAULT_JVM_XMS).build());
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_CRUISE_CONTROL_CONFIGURATION).withValue(ccConfiguration.getConfiguration()).build());
-
+        io.strimzi.operator.cluster.TestUtils.maybeAddHttpProxyEnvVars(expected);
         return expected;
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -128,6 +128,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_JAVA_OPTS).withValue("-Xms128m").build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_JAVA_SYSTEM_PROPERTIES).withValue("-Djavax.net.debug=verbose -Dsomething.else=42").build());
+        io.strimzi.operator.cluster.TestUtils.maybeAddHttpProxyEnvVars(expected);
         return expected;
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -143,7 +143,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_SECRET_PREFIX).withValue(secretPrefix).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_ACLS_ADMIN_API_SUPPORTED).withValue(String.valueOf(false)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_KRAFT_ENABLED).withValue(String.valueOf(true)).build());
-
+        io.strimzi.operator.cluster.TestUtils.maybeAddHttpProxyEnvVars(expected);
         return expected;
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -76,6 +76,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.contains;
 import static org.hamcrest.Matchers.containsInAnyOrder;
+import static org.hamcrest.Matchers.greaterThanOrEqualTo;
 import static org.hamcrest.Matchers.hasSize;
 import static org.junit.jupiter.api.Assertions.assertThrows;
 
@@ -128,7 +129,6 @@ private Map<String, String> expectedSelectorLabels()    {
     }
 
     protected List<EnvVar> getExpectedEnvVars() {
-
         List<EnvVar> expected = new ArrayList<>();
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_METRICS_ENABLED).withValue(String.valueOf(true)).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(String.valueOf(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
@@ -140,6 +140,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_HTTP_HOST).withValue(KafkaBridgeHttpConfig.HTTP_DEFAULT_HOST).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_HTTP_PORT).withValue(String.valueOf(KafkaBridgeHttpConfig.HTTP_DEFAULT_PORT)).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_CORS_ENABLED).withValue(String.valueOf(false)).build());
+        io.strimzi.operator.cluster.TestUtils.maybeAddHttpProxyEnvVars(expected);
         return expected;
     }
 
@@ -833,7 +834,7 @@ private static void assertRackAwareDeploymentConfigured(final KafkaBridge resour
         assertThat(first.isPresent(), is(true));
         final Container container = first.get();
         assertThat(container.getImage(), is(expectedInitImage));
-        assertThat(container.getEnv(), hasSize(3));
+        assertThat(container.getEnv().size(), greaterThanOrEqualTo(3));
         final List<EnvVar> initEnv = container.getEnv();
         assertThat(initEnv.stream().filter(var -> AbstractModel.ENV_VAR_KAFKA_INIT_RACK_TOPOLOGY_KEY.equals(var.getName())).findFirst().orElseThrow().getValue(), is(
                 "topology-key"));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaExporterTest.java
Patch:
@@ -125,6 +125,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaExporter.ENV_VAR_KAFKA_EXPORTER_TOPIC_REGEX).withValue(topicRegex).build());
         expected.add(new EnvVarBuilder().withName(KafkaExporter.ENV_VAR_KAFKA_EXPORTER_KAFKA_SERVER).withValue("foo-kafka-bootstrap:" + KafkaCluster.REPLICATION_PORT).build());
         expected.add(new EnvVarBuilder().withName(KafkaExporter.ENV_VAR_KAFKA_EXPORTER_ENABLE_SARAMA).withValue("true").build());
+        io.strimzi.operator.cluster.TestUtils.maybeAddHttpProxyEnvVars(expected);
         return expected;
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -193,6 +193,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMaker2Cluster.ENV_VAR_KAFKA_CONNECT_BOOTSTRAP_SERVERS).withValue(bootstrapServers).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMaker2Cluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(AbstractModel.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
+        io.strimzi.operator.cluster.TestUtils.maybeAddHttpProxyEnvVars(expected);
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMaker2Cluster.ENV_VAR_KAFKA_MIRRORMAKER_2_CLUSTERS).withValue(targetClusterAlias).build());
         return expected;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -162,9 +162,7 @@ private Map<String, String> expectedLabels()    {
     }
 
     protected List<EnvVar> getExpectedEnvVars() {
-
         List<EnvVar> expected = new ArrayList<>();
-
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_CONFIGURATION_CONSUMER).withValue(expectedConsumerConfiguration).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_CONFIGURATION_PRODUCER).withValue(expectedProducerConfiguration).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_METRICS_ENABLED).withValue("true").build());
@@ -179,7 +177,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_LIVENESS_PERIOD).withValue("10").build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_READINESS_PERIOD).withValue("10").build());
-
+        io.strimzi.operator.cluster.TestUtils.maybeAddHttpProxyEnvVars(expected);
         return expected;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaRoller.java
Patch:
@@ -495,7 +495,7 @@ private void checkReconfigurability(NodeRef nodeRef, Pod pod, RestartContext res
             // If the pod is unschedulable then deleting it, or trying to open an Admin client to it will make no difference
             // Treat this as fatal because if it's not possible to schedule one pod then it's likely that proceeding
             // and deleting a different pod in the meantime will likely result in another unschedulable pod.
-            throw new FatalProblem("Pod is unschedulable");
+            throw new FatalProblem("Pod is unschedulable or is not starting");
         }
         // Unless the annotation is present, check the pod is at least ready.
         boolean needsRestart = reasonToRestartPod.shouldRestart();

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/SecretUtils.java
Patch:
@@ -178,7 +178,7 @@ public static void deleteSecretWithWait(String secretName, String namespace) {
 
         LOGGER.info("Waiting for Secret {}/{} to be deleted", namespace, secretName);
         TestUtils.waitFor(String.format("Deletion of Secret %s#%s", namespace, secretName), Constants.GLOBAL_POLL_INTERVAL, DELETION_TIMEOUT,
-            () -> kubeClient().getSecret(secretName) == null);
+            () -> kubeClient().getSecret(namespace, secretName) == null);
 
         LOGGER.info("Secret {}/{} successfully deleted", namespace, secretName);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlST.java
Patch:
@@ -61,7 +61,6 @@
 import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
-import static org.hamcrest.Matchers.anEmptyMap;
 import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.is;
 import static org.hamcrest.Matchers.not;
@@ -278,7 +277,8 @@ void testCruiseControlReplicaMovementStrategy(ExtensionContext extensionContext)
         LOGGER.info("Check for default CruiseControl replicaMovementStrategy in pod configuration file.");
         Map<String, Object> actualStrategies = KafkaResource.kafkaClient().inNamespace(namespaceName)
             .withName(clusterName).get().getSpec().getCruiseControl().getConfig();
-        assertThat(actualStrategies, anEmptyMap());
+        // Check that config contains only configurations for max.active.user.tasks
+        assertThat(actualStrategies.size(), is(1));
 
         String ccConfFileContent = cmdKubeClient(namespaceName).execInPodContainer(ccPodName, Constants.CRUISE_CONTROL_CONTAINER_NAME, "cat", Constants.CRUISE_CONTROL_CONFIGURATION_FILE_PATH).out();
         assertThat(ccConfFileContent, not(containsString(replicaMovementStrategies)));

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/ListenersST.java
Patch:
@@ -1962,8 +1962,8 @@ void testCustomCertRouteAndTlsRollingUpdate(ExtensionContext extensionContext) {
         ClientUtils.waitForConsumerClientSuccess(testStorage);
 
         // Delete already existing secrets
-        kubeClient().deleteSecret(testStorage.getNamespaceName(), clusterCustomCertServer1);
-        kubeClient().deleteSecret(testStorage.getNamespaceName(), clusterCustomCertServer2);
+        SecretUtils.deleteSecretWithWait(clusterCustomCertServer1, testStorage.getNamespaceName());
+        SecretUtils.deleteSecretWithWait(clusterCustomCertServer2, testStorage.getNamespaceName());
         // Create secrets with new values (update)
         SecretUtils.createCustomSecret(clusterCustomCertServer1, testStorage.getClusterName(), testStorage.getNamespaceName(), strimziCertAndKey2);
         SecretUtils.createCustomSecret(clusterCustomCertServer2, testStorage.getClusterName(), testStorage.getNamespaceName(), strimziCertAndKey1);

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsIsolatedST.java
Patch:
@@ -269,7 +269,7 @@ void testKafkaConnectAndConnectorMetrics(ExtensionContext extensionContext) {
         if (Environment.isStableConnectIdentitiesEnabled()) {
             // check StrimziPodSet metrics in CO
             assertMetricValueHigherThan(clusterOperatorCollector, getResourceMetricPattern(StrimziPodSet.RESOURCE_KIND, namespaceFirst), 1);
-            assertCoMetricResources(clusterOperatorCollector, StrimziPodSet.RESOURCE_KIND, namespaceSecond, 1);
+            assertMetricValueHigherThan(clusterOperatorCollector, getResourceMetricPattern(StrimziPodSet.RESOURCE_KIND, namespaceSecond), 0);
         }
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/AbstractUpgradeST.java
Patch:
@@ -51,6 +51,7 @@
 import java.io.File;
 import java.io.IOException;
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.List;
 import java.util.Locale;
 import java.util.Map;
@@ -596,7 +597,7 @@ protected void doKafkaConnectAndKafkaConnectorUpgradeOrDowngradeProcedure(final
         logPodImages(clusterName);
 
         // Verify FileSink KafkaConnector before upgrade
-        String connectorPodName = kubeClient().listPodsByPrefixInName(testStorage.getNamespaceName(), clusterName + "-connect").get(0).getMetadata().getName();
+        String connectorPodName = kubeClient().listPods(testStorage.getNamespaceName(), Collections.singletonMap(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND)).get(0).getMetadata().getName();
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(testStorage.getNamespaceName(), connectorPodName, DEFAULT_SINK_FILE_PATH, "\"Hello-world - 499\"");
 
         // Upgrade CO to HEAD and wait for readiness of ClusterOperator
@@ -613,7 +614,7 @@ protected void doKafkaConnectAndKafkaConnectorUpgradeOrDowngradeProcedure(final
         // Verify that Producer finish successfully
         ClientUtils.waitForProducerClientSuccess(testStorage);
         // Verify FileSink KafkaConnector
-        connectorPodName = kubeClient().listPodsByPrefixInName(testStorage.getNamespaceName(), clusterName + "-connect").get(0).getMetadata().getName();
+        connectorPodName = kubeClient().listPods(testStorage.getNamespaceName(), Collections.singletonMap(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND)).get(0).getMetadata().getName();
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(testStorage.getNamespaceName(), connectorPodName, DEFAULT_SINK_FILE_PATH, "\"Hello-world - 499\"");
 
         // Verify that pods are stable

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -188,7 +188,7 @@ public void setup(VertxTestContext testContext) {
         Checkpoint async = testContext.checkpoint();
         // Fail test if watcher closes for any reason
         kafkaConnectOperator.createWatch(NAMESPACE, e -> testContext.failNow(e))
-            .onComplete(testContext.succeedingThenComplete())
+            .onComplete(testContext.succeeding(i -> { }))
             .compose(watch -> {
                 connectWatch = watch;
                 return AbstractConnectOperator.createConnectorWatch(kafkaConnectOperator, NAMESPACE, null);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -229,7 +229,7 @@ public void afterEach() {
     public void testReconcile(VertxTestContext context) {
         Checkpoint async = context.checkpoint();
         initialReconcile(context)
-            .onComplete(context.succeedingThenComplete())
+            .onComplete(context.succeeding(i -> { }))
             .compose(v -> operator.reconcile(new Reconciliation("test-trigger", Kafka.RESOURCE_KIND, NAMESPACE, CLUSTER_NAME)))
             .onComplete(context.succeeding(v -> async.flag()));
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -159,7 +159,7 @@ public void testReconcileCreateAndUpdate(VertxTestContext context) {
 
         Checkpoint async = context.checkpoint();
         createConnectCluster(context, mock, false)
-            .onComplete(context.succeedingThenComplete())
+            .onComplete(context.succeeding(i -> { }))
             .compose(v -> {
                 LOGGER.info("Reconciling again -> update");
                 return kco.reconcile(new Reconciliation("test-trigger", KafkaConnect.RESOURCE_KIND, NAMESPACE, CLUSTER_NAME));
@@ -187,7 +187,7 @@ public void testPauseReconcileUnpause(VertxTestContext context) {
 
         Checkpoint async = context.checkpoint();
         createConnectCluster(context, mock, true)
-                .onComplete(context.succeedingThenComplete())
+                .onComplete(context.succeeding(i -> { }))
                 .compose(v -> {
                     LOGGER.info("Reconciling again -> update");
                     return kco.reconcile(new Reconciliation("test-trigger", KafkaConnect.RESOURCE_KIND, NAMESPACE, CLUSTER_NAME));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -164,7 +164,7 @@ public void testReconcileUpdate(VertxTestContext context) {
 
         Checkpoint async = context.checkpoint();
         createMirrorMaker2Cluster(context, mock, false)
-            .onComplete(context.succeedingThenComplete())
+            .onComplete(context.succeeding(i -> { }))
             .compose(i -> {
                 LOGGER.info("Reconciling again -> update");
                 return kco.reconcile(new Reconciliation("test-trigger", KafkaMirrorMaker2.RESOURCE_KIND, NAMESPACE, CLUSTER_NAME));

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicStoreTestBase.java
Patch:
@@ -36,7 +36,7 @@ public void testCrud(VertxTestContext context) {
 
         // Create the topic
         store.create(topic)
-            .onComplete(context.succeedingThenComplete())
+            .onComplete(context.succeeding(i -> { }))
 
             // Read the topic
             .compose(v -> store.read(new TopicName(topicName)))
@@ -63,7 +63,7 @@ public void testCrud(VertxTestContext context) {
         failedCreateCompleted.future()
                 // update my_topic
                 .compose(v -> store.update(updatedTopic))
-            .onComplete(context.succeedingThenComplete())
+            .onComplete(context.succeeding(i -> { }))
 
             // re-read it and assert equal
             .compose(v -> store.read(new TopicName(topicName)))
@@ -77,7 +77,7 @@ public void testCrud(VertxTestContext context) {
 
                 // delete it
                 .compose(v -> store.delete(updatedTopic.getTopicName()))
-                .onComplete(context.succeedingThenComplete())
+                .onComplete(context.succeeding(i -> { }))
 
                 // assert we can't read it again
                 .compose(v -> store.read(new TopicName(topicName)))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/ConnectBuildOperator.java
Patch:
@@ -379,7 +379,7 @@ private Future<String> openShiftBuildWaitForFinish(Reconciliation reconciliation
                                 && build.getStatus().getOutput().getTo().getImageDigest() != null) {
                             String digest = "@" + build.getStatus().getOutput().getTo().getImageDigest();
                             String image = build.getStatus().getOutputDockerImageReference();
-                            String tag = image.substring(image.lastIndexOf(":"));
+                            String tag = image.lastIndexOf(":") != -1 ? image.substring(image.lastIndexOf(":")) : "latest";
 
                             String imageWithDigest = image.replace(tag, digest);
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/keycloak/SetupKeycloak.java
Patch:
@@ -148,12 +148,14 @@ private static void importRealms(String namespaceName, KeycloakInstance keycloak
     private static void deleteKeycloak(String namespaceName) {
         LOGGER.info("Deleting Keycloak in namespace {}", namespaceName);
         cmdKubeClient(namespaceName).delete(KEYCLOAK_INSTANCE_FILE_PATH);
+        kubeClient().deleteSecret(namespaceName, KEYCLOAK_SECRET_NAME);
         DeploymentUtils.waitForDeploymentDeletion(namespaceName, KEYCLOAK_DEPLOYMENT_NAME);
     }
 
     private static void deletePostgres(String namespaceName) {
         LOGGER.info("Deleting Postgres in namespace {}", namespaceName);
         cmdKubeClient(namespaceName).delete(POSTGRES_FILE_PATH);
+        kubeClient().deleteSecret(namespaceName, POSTGRES_SECRET_NAME);
         DeploymentUtils.waitForDeploymentDeletion(namespaceName, "postgres");
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/KeycloakUtils.java
Patch:
@@ -25,7 +25,7 @@ private KeycloakUtils() {}
      * @return user token
      */
     public static String getToken(String namespaceName, String baseURI, String userName, String password) {
-        String coPodName = kubeClient(namespaceName).getClusterOperatorPodName();
+        String coPodName = kubeClient().getClusterOperatorPodName(namespaceName);
         return new JsonObject(
             cmdKubeClient(namespaceName).execInPod(
                 coPodName,

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesIsolatedST.java
Patch:
@@ -245,6 +245,7 @@ void testNPWhenOperatorIsInSameNamespaceAsOperand(ExtensionContext extensionCont
 
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
 
+        clusterOperator.unInstall();
         clusterOperator = new SetupClusterOperator.SetupClusterOperatorBuilder()
             .withExtensionContext(BeforeAllOnce.getSharedExtensionContext())
             .withNamespace(clusterOperator.getDeploymentNamespace())

File: test/src/main/java/io/strimzi/test/k8s/KubeClient.java
Patch:
@@ -8,6 +8,7 @@
 import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.Event;
 import io.fabric8.kubernetes.api.model.LabelSelector;
+import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
 import io.fabric8.kubernetes.api.model.Namespace;
 import io.fabric8.kubernetes.api.model.NamespaceBuilder;
 import io.fabric8.kubernetes.api.model.Node;
@@ -917,7 +918,7 @@ public String clusterKubernetesVersion() {
      * @return cluster operator pod name
      */
     public String getClusterOperatorPodName(final String namespaceName) {
-        LabelSelector selector = kubeClient(namespaceName).getDeploymentSelectors(namespaceName, "strimzi-cluster-operator");
+        LabelSelector selector = new LabelSelectorBuilder().withMatchLabels(Map.of("strimzi.io/kind", "cluster-operator")).build();
         return kubeClient(namespaceName).listPods(namespaceName, selector).get(0).getMetadata().getName();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/configuration/OlmConfiguration.java
Patch:
@@ -59,7 +59,7 @@ public OlmInstallationStrategy getOlmInstallationStrategy() {
     }
 
     public void setOperatorVersion(String operatorVersion) {
-        this.operatorVersion = operatorVersion == null ? Environment.OLM_OPERATOR_LATEST_RELEASE_VERSION : operatorVersion;
+        this.operatorVersion = operatorVersion != null && operatorVersion.isEmpty() ? Environment.OLM_OPERATOR_LATEST_RELEASE_VERSION : operatorVersion;
     }
 
     public String getOperatorVersion() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZooKeeperRoller.java
Patch:
@@ -82,15 +82,15 @@ public Future<Void> maybeRollingUpdate(Reconciliation reconciliation, int replic
                             final boolean ready = podOperator.isReady(namespace, pod.getMetadata().getName());
                             ZookeeperPodContext podContext = new ZookeeperPodContext(podName, restartReasons, true, ready);
                             if (restartReasons != null && !restartReasons.isEmpty())    {
-                                LOGGER.infoCr(reconciliation, "Pod {} should be rolled due to {}", podContext.getPodName(), restartReasons);
+                                LOGGER.debugCr(reconciliation, "Pod {} should be rolled due to {}", podContext.getPodName(), restartReasons);
                             } else {
-                                LOGGER.infoCr(reconciliation, "Pod {} does not need to be rolled", podContext.getPodName());
+                                LOGGER.debugCr(reconciliation, "Pod {} does not need to be rolled", podContext.getPodName());
                             }
                             clusterRollContext.add(podContext);
                         } else {
                             // Pod does not exist, but we still add it to the roll context because we should not roll
                             // any other pods before it is ready
-                            LOGGER.infoCr(reconciliation, "Pod {} does not exist and cannot be rolled", podName);
+                            LOGGER.debugCr(reconciliation, "Pod {} does not exist and cannot be rolled", podName);
                             ZookeeperPodContext podContext = new ZookeeperPodContext(podName, null, false, false);
                             clusterRollContext.add(podContext);
                         }

File: user-operator/src/main/java/io/strimzi/operator/user/UserOperatorConfig.java
Patch:
@@ -172,7 +172,7 @@ public static Set<String> keyNames() {
      * @return         Configuration value w.r.t to the key
      */
     @SuppressWarnings("unchecked")
-    public  <T> T get(ConfigParameter<T> value) {
+    public <T> T get(ConfigParameter<T> value) {
         return (T) this.map.get(value.key());
     }
 
@@ -201,7 +201,7 @@ protected UserOperatorConfig build() {
      * @return  namespace in which the operator runs and creates resources
      */
     public String getNamespace() {
-        return (String) this.map.get(NAMESPACE.key());
+        return get(NAMESPACE);
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -314,6 +314,7 @@ protected boolean hasCaCertGenerationChanged() {
                     && secret != null && secret.getData() != null // Secret exists and has some data
                     && secretEntryExists(secret, podName, SecretEntry.CRT) // The secret has the public key for this pod
                     && secretEntryExists(secret, podName, SecretEntry.KEY) // The secret has the private key for this pod
+                    && !hasCaCertGenerationChanged(secret) // The generation on the Secret is the same as the CA has
             )   {
                 // A certificate for this node already exists, so we will try to reuse it
                 LOGGER.debugCr(reconciliation, "Certificate for node {} already exists", node);

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeSpec.java
Patch:
@@ -54,7 +54,8 @@ public class KafkaBridgeSpec extends Spec implements HasConfigurableLogging, Has
     private String clientRackInitImage;
     private Rack rack;
 
-    @Description("The number of pods in the `Deployment`.")
+    @Description("The number of pods in the `Deployment`.  " +
+            "Defaults to `1`.")
     @Minimum(0)
     @JsonProperty(defaultValue = "1")
     public int getReplicas() {

File: api/src/main/java/io/strimzi/api/kafka/model/ZookeeperClusterSpec.java
Patch:
@@ -44,8 +44,6 @@ public class ZookeeperClusterSpec implements HasConfigurableMetrics, HasConfigur
     public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.protocol, ssl.quorum.protocol, ssl.enabledProtocols, " +
             "ssl.quorum.enabledProtocols, ssl.ciphersuites, ssl.quorum.ciphersuites, ssl.hostnameVerification, ssl.quorum.hostnameVerification";
 
-    public static final int DEFAULT_REPLICAS = 3;
-
     protected SingleVolumeStorage storage;
     private Map<String, Object> config = new HashMap<>(0);
     private Logging logging;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -104,7 +104,6 @@ public class KafkaConnectCluster extends AbstractModel implements SupportsMetric
     protected static final String LOG_AND_METRICS_CONFIG_VOLUME_MOUNT = "/opt/kafka/custom-config/";
 
     // Configuration defaults
-    /* test */ static final int DEFAULT_REPLICAS = 3;
     private static final Probe DEFAULT_HEALTHCHECK_OPTIONS = new ProbeBuilder().withInitialDelaySeconds(5).withInitialDelaySeconds(60).build();
 
     // Kafka Connect configuration keys (EnvVariables)
@@ -188,7 +187,6 @@ protected KafkaConnectCluster(Reconciliation reconciliation, HasMetadata resourc
 
         this.serviceName = KafkaConnectResources.serviceName(cluster);
         this.loggingAndMetricsConfigMapName = KafkaConnectResources.metricsAndLogConfigMapName(cluster);
-        this.replicas = DEFAULT_REPLICAS;
     }
 
     /**
@@ -221,7 +219,7 @@ protected static <C extends KafkaConnectCluster> C fromSpec(Reconciliation recon
                                                                 KafkaConnectSpec spec,
                                                                 KafkaVersion.Lookup versions,
                                                                 C result) {
-        result.replicas = spec.getReplicas() != null && spec.getReplicas() >= 0 ? spec.getReplicas() : DEFAULT_REPLICAS;
+        result.replicas = spec.getReplicas();
         result.tracing = spec.getTracing();
 
         // Might already contain configuration from Mirror Maker 2 which extends Connect

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -148,7 +148,7 @@ public void testDefaultValues() {
         KafkaBridgeCluster kbc = KafkaBridgeCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, ResourceUtils.createEmptyKafkaBridge(namespace, cluster));
 
         assertThat(kbc.image, is("quay.io/strimzi/kafka-bridge:latest"));
-        assertThat(kbc.getReplicas(), is(KafkaBridgeCluster.DEFAULT_REPLICAS));
+        assertThat(kbc.getReplicas(), is(1));
         assertThat(kbc.readinessProbeOptions.getInitialDelaySeconds(), is(15));
         assertThat(kbc.readinessProbeOptions.getTimeoutSeconds(), is(5));
         assertThat(kbc.livenessProbeOptions.getInitialDelaySeconds(), is(15));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -205,7 +205,7 @@ public void testDefaultValues() {
         KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, ResourceUtils.createEmptyKafkaConnect(namespace, clusterName), VERSIONS);
 
         assertThat(kc.image, is(KafkaVersionTestUtils.DEFAULT_KAFKA_CONNECT_IMAGE));
-        assertThat(kc.getReplicas(), is(KafkaConnectCluster.DEFAULT_REPLICAS));
+        assertThat(kc.getReplicas(), is(3));
         assertThat(kc.readinessProbeOptions.getInitialDelaySeconds(), is(60));
         assertThat(kc.readinessProbeOptions.getTimeoutSeconds(), is(5));
         assertThat(kc.livenessProbeOptions.getInitialDelaySeconds(), is(60));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -206,7 +206,7 @@ public void testDefaultValues() {
         KafkaMirrorMaker2Cluster kmm2 = KafkaMirrorMaker2Cluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, ResourceUtils.createEmptyKafkaMirrorMaker2(namespace, clusterName), VERSIONS);
 
         assertThat(kmm2.image, is(KafkaVersionTestUtils.DEFAULT_KAFKA_CONNECT_IMAGE));
-        assertThat(kmm2.getReplicas(), is(KafkaMirrorMaker2Cluster.DEFAULT_REPLICAS));
+        assertThat(kmm2.getReplicas(), is(3));
         assertThat(kmm2.readinessProbeOptions.getInitialDelaySeconds(), is(60));
         assertThat(kmm2.readinessProbeOptions.getTimeoutSeconds(), is(5));
         assertThat(kmm2.livenessProbeOptions.getInitialDelaySeconds(), is(60));

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/SetupClusterOperator.java
Patch:
@@ -363,7 +363,7 @@ public void upgradeClusterOperator(OlmConfiguration olmConfiguration) {
         }
 
         updateSubscription(olmConfiguration);
-        OlmUtils.waitUntilInstallPlanContainingCertainCsvIsPresent(namespaceInstallTo, olmConfiguration.getCsvName());
+        OlmUtils.waitUntilNonUsedInstallPlanWithSpecificCsvIsPresentAndApprove(namespaceInstallTo, olmConfiguration.getCsvName());
         DeploymentUtils.waitForDeploymentAndPodsReady(namespaceInstallTo, olmConfiguration.getOlmOperatorDeploymentName(), 1);
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/configuration/OlmConfiguration.java
Patch:
@@ -20,6 +20,7 @@ public class OlmConfiguration {
     private String featureGates = Environment.STRIMZI_FEATURE_GATES;
     private String olmAppBundlePrefix = Environment.OLM_APP_BUNDLE_PREFIX;
     private String olmOperatorName = Environment.OLM_OPERATOR_NAME;
+    private String olmOperatorDeploymentNamePrefix = Environment.OLM_OPERATOR_DEPLOYMENT_NAME;
     private String olmSourceName = Environment.OLM_SOURCE_NAME;
     private String olmSourceNamespace = Environment.OLM_SOURCE_NAMESPACE;
     private String operatorVersion;
@@ -109,7 +110,7 @@ public String getOlmAppBundlePrefix() {
     }
 
     public String getOlmOperatorDeploymentName() {
-        return olmAppBundlePrefix + "-v" + operatorVersion;
+        return olmOperatorDeploymentNamePrefix + "-v" + operatorVersion;
     }
 
     public String getOlmOperatorName() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -40,7 +40,7 @@ public class ClusterCa extends Ca {
     /**
      * Constructor
      *
-     * @param reconciliation        Reocnciliation marker
+     * @param reconciliation        Reconciliation marker
      * @param certManager           Certificate manager instance
      * @param passwordGenerator     Password generator instance
      * @param clusterName           Name of the Kafka cluster
@@ -54,7 +54,7 @@ public ClusterCa(Reconciliation reconciliation, CertManager certManager, Passwor
     /**
      * Constructor
      *
-     * @param reconciliation        Reocnciliation marker
+     * @param reconciliation        Reconciliation marker
      * @param certManager           Certificate manager instance
      * @param passwordGenerator     Password generator instance
      * @param clusterName           Name of the Kafka cluster

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ConfigMapUtils.java
Patch:
@@ -22,7 +22,7 @@ public class ConfigMapUtils {
      * @param namespace         Namespace of the Config Map
      * @param labels            Labels of the Config Map
      * @param ownerReference    OwnerReference of the Config Map
-     * @param data              Data which will be stored int he Config Map
+     * @param data              Data which will be stored in the Config Map
      *
      * @return  New Config Map
      */

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -666,7 +666,7 @@ public Service generateService() {
      * @return The list with generated Services
      */
     public List<Service> generateExternalBootstrapServices() {
-        List<GenericKafkaListener> externalListeners = ListenersUtils.externalListeners(listeners);
+        List<GenericKafkaListener> externalListeners = ListenersUtils.listenersWithOwnServices(listeners);
         List<Service> services = new ArrayList<>(externalListeners.size());
 
         for (GenericKafkaListener listener : externalListeners)   {
@@ -745,7 +745,7 @@ public List<Service> generateExternalBootstrapServices() {
      * @return The list with generated Services
      */
     public List<Service> generateExternalServices(int pod) {
-        List<GenericKafkaListener> externalListeners = ListenersUtils.externalListeners(listeners);
+        List<GenericKafkaListener> externalListeners = ListenersUtils.listenersWithOwnServices(listeners);
         List<Service> services = new ArrayList<>(externalListeners.size());
 
         for (GenericKafkaListener listener : externalListeners)   {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ListenersValidator.java
Patch:
@@ -57,7 +57,7 @@ public static void validate(Reconciliation reconciliation, int replicas, List<Ge
             errors.add("every listener needs to have a unique name");
         }
 
-        List<String> invalidNames = names.stream().filter(name -> !LISTENER_NAME_PATTERN.matcher(name).matches()).collect(Collectors.toList());
+        List<String> invalidNames = names.stream().filter(name -> !LISTENER_NAME_PATTERN.matcher(name).matches()).toList();
         if (!invalidNames.isEmpty())    {
             errors.add("listener names " + invalidNames + " are invalid and do not match the pattern " + GenericKafkaListener.LISTENER_NAME_REGEX);
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -694,7 +694,7 @@ private void createCluster(VertxTestContext context, Kafka kafka, List<Secret> s
                         KafkaResources.brokersServiceName(kafkaName));
 
                 if (kafkaListeners != null) {
-                    List<GenericKafkaListener> externalListeners = ListenersUtils.externalListeners(kafkaListeners);
+                    List<GenericKafkaListener> externalListeners = ListenersUtils.listenersWithOwnServices(kafkaListeners);
 
                     for (GenericKafkaListener listener : externalListeners) {
                         expectedServices.add(ListenersUtils.backwardsCompatibleBootstrapServiceName(kafkaName, listener));

File: user-operator/src/main/java/io/strimzi/operator/user/operator/KafkaUserOperator.java
Patch:
@@ -300,7 +300,7 @@ private void maybeGenerateScramCredentials(Reconciliation reconciliation, KafkaU
             // User is a SCRAM-SHA-512 user and requested some specific password instead of generating a random password
             desiredPasswordSecret = client.secrets().inNamespace(reconciliation.namespace()).withName(user.desiredPasswordSecretName()).get();
             if (desiredPasswordSecret == null) {
-                throw new InvalidResourceException("Secret " + config.getCaCertSecretName() + " in namespace " + config.getCaNamespace() + " with requested password not found");
+                throw new InvalidResourceException("Secret " + user.desiredPasswordSecretName() + " in namespace " + reconciliation.namespace() + " with requested password not found");
             }
         }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -41,7 +41,6 @@ public abstract class AbstractModel {
     protected static final ReconciliationLogger LOGGER = ReconciliationLogger.create(AbstractModel.class.getName());
 
     protected static final String DEFAULT_JVM_XMS = "128M";
-    protected static final boolean DEFAULT_JVM_GC_LOGGING_ENABLED = false;
 
     /**
      * Init container related configuration

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -19,6 +19,7 @@
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeer;
 import io.strimzi.api.kafka.model.CruiseControlResources;
 import io.strimzi.api.kafka.model.CruiseControlSpec;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaClusterSpec;
 import io.strimzi.api.kafka.model.KafkaResources;
@@ -223,7 +224,7 @@ public static CruiseControl fromCrd(Reconciliation reconciliation, Kafka kafkaCr
 
             cruiseControl.logging = ccSpec.getLogging();
 
-            cruiseControl.gcLoggingEnabled = ccSpec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : ccSpec.getJvmOptions().isGcLoggingEnabled();
+            cruiseControl.gcLoggingEnabled = ccSpec.getJvmOptions() == null ? JvmOptions.DEFAULT_GC_LOGGING_ENABLED : ccSpec.getJvmOptions().isGcLoggingEnabled();
             cruiseControl.jvmOptions = ccSpec.getJvmOptions();
             cruiseControl.resources = ccSpec.getResources();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -16,6 +16,7 @@
 import io.fabric8.kubernetes.api.model.rbac.Subject;
 import io.fabric8.kubernetes.api.model.rbac.SubjectBuilder;
 import io.strimzi.api.kafka.model.EntityTopicOperatorSpec;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.Probe;
@@ -132,7 +133,7 @@ public static EntityTopicOperator fromCrd(Reconciliation reconciliation, Kafka k
             result.zookeeperSessionTimeoutMs = topicOperatorSpec.getZookeeperSessionTimeoutSeconds() * 1_000;
             result.topicMetadataMaxAttempts = topicOperatorSpec.getTopicMetadataMaxAttempts();
             result.logging = topicOperatorSpec.getLogging();
-            result.gcLoggingEnabled = topicOperatorSpec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : topicOperatorSpec.getJvmOptions().isGcLoggingEnabled();
+            result.gcLoggingEnabled = topicOperatorSpec.getJvmOptions() == null ? JvmOptions.DEFAULT_GC_LOGGING_ENABLED : topicOperatorSpec.getJvmOptions().isGcLoggingEnabled();
             result.jvmOptions = topicOperatorSpec.getJvmOptions();
             result.resources = topicOperatorSpec.getResources();
             if (topicOperatorSpec.getStartupProbe() != null) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -17,6 +17,7 @@
 import io.fabric8.kubernetes.api.model.rbac.SubjectBuilder;
 import io.strimzi.api.kafka.model.CertificateAuthority;
 import io.strimzi.api.kafka.model.EntityUserOperatorSpec;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.Probe;
@@ -132,7 +133,7 @@ public static EntityUserOperator fromCrd(Reconciliation reconciliation, Kafka ka
             result.reconciliationIntervalMs = userOperatorSpec.getReconciliationIntervalSeconds() * 1_000;
             result.secretPrefix = userOperatorSpec.getSecretPrefix() == null ? EntityUserOperatorSpec.DEFAULT_SECRET_PREFIX : userOperatorSpec.getSecretPrefix();
             result.logging = userOperatorSpec.getLogging();
-            result.gcLoggingEnabled = userOperatorSpec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : userOperatorSpec.getJvmOptions().isGcLoggingEnabled();
+            result.gcLoggingEnabled = userOperatorSpec.getJvmOptions() == null ? JvmOptions.DEFAULT_GC_LOGGING_ENABLED : userOperatorSpec.getJvmOptions().isGcLoggingEnabled();
             result.jvmOptions = userOperatorSpec.getJvmOptions();
             result.resources = userOperatorSpec.getResources();
             if (userOperatorSpec.getReadinessProbe() != null) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -23,6 +23,7 @@
 import io.fabric8.kubernetes.api.model.rbac.SubjectBuilder;
 import io.strimzi.api.kafka.model.CertSecretSource;
 import io.strimzi.api.kafka.model.ClientTls;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.KafkaBridge;
 import io.strimzi.api.kafka.model.KafkaBridgeAdminClientSpec;
 import io.strimzi.api.kafka.model.KafkaBridgeConsumerSpec;
@@ -188,7 +189,7 @@ public static KafkaBridgeCluster fromCrd(Reconciliation reconciliation, KafkaBri
         kafkaBridgeCluster.tracing = spec.getTracing();
         kafkaBridgeCluster.resources = spec.getResources();
         kafkaBridgeCluster.logging = spec.getLogging();
-        kafkaBridgeCluster.gcLoggingEnabled = spec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : spec.getJvmOptions().isGcLoggingEnabled();
+        kafkaBridgeCluster.gcLoggingEnabled = spec.getJvmOptions() == null ? JvmOptions.DEFAULT_GC_LOGGING_ENABLED : spec.getJvmOptions().isGcLoggingEnabled();
         kafkaBridgeCluster.jvmOptions = spec.getJvmOptions();
         String image = spec.getImage();
         if (image == null) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -41,6 +41,7 @@
 import io.strimzi.api.kafka.model.CertAndKeySecretSource;
 import io.strimzi.api.kafka.model.CruiseControlResources;
 import io.strimzi.api.kafka.model.CruiseControlSpec;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaAuthorization;
 import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloak;
@@ -339,7 +340,7 @@ public static KafkaCluster fromCrd(Reconciliation reconciliation, Kafka kafkaAss
         result.initImage = initImage;
 
         result.logging = kafkaClusterSpec.getLogging();
-        result.gcLoggingEnabled = kafkaClusterSpec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : kafkaClusterSpec.getJvmOptions().isGcLoggingEnabled();
+        result.gcLoggingEnabled = kafkaClusterSpec.getJvmOptions() == null ? JvmOptions.DEFAULT_GC_LOGGING_ENABLED : kafkaClusterSpec.getJvmOptions().isGcLoggingEnabled();
         result.jvmOptions = kafkaClusterSpec.getJvmOptions();
 
         result.jmx = new JmxModel(

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -35,6 +35,7 @@
 import io.fabric8.kubernetes.api.model.rbac.SubjectBuilder;
 import io.strimzi.api.kafka.model.CertSecretSource;
 import io.strimzi.api.kafka.model.ClientTls;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectResources;
 import io.strimzi.api.kafka.model.KafkaConnectSpec;
@@ -243,7 +244,7 @@ protected static <C extends KafkaConnectCluster> C fromSpec(Reconciliation recon
 
         kafkaConnect.resources = spec.getResources();
         kafkaConnect.logging = spec.getLogging();
-        kafkaConnect.gcLoggingEnabled = spec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : spec.getJvmOptions().isGcLoggingEnabled();
+        kafkaConnect.gcLoggingEnabled = spec.getJvmOptions() == null ? JvmOptions.DEFAULT_GC_LOGGING_ENABLED : spec.getJvmOptions().isGcLoggingEnabled();
 
         kafkaConnect.jvmOptions = spec.getJvmOptions();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -15,6 +15,7 @@
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.CertSecretSource;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerConsumerSpec;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerProducerSpec;
@@ -202,7 +203,7 @@ public static KafkaMirrorMakerCluster fromCrd(Reconciliation reconciliation, Kaf
             kafkaMirrorMakerCluster.image = versions.kafkaMirrorMakerImage(spec.getImage(), spec.getVersion());
 
             kafkaMirrorMakerCluster.logging = spec.getLogging();
-            kafkaMirrorMakerCluster.gcLoggingEnabled = spec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : spec.getJvmOptions().isGcLoggingEnabled();
+            kafkaMirrorMakerCluster.gcLoggingEnabled = spec.getJvmOptions() == null ? JvmOptions.DEFAULT_GC_LOGGING_ENABLED : spec.getJvmOptions().isGcLoggingEnabled();
             kafkaMirrorMakerCluster.jvmOptions = spec.getJvmOptions();
 
             // Parse different types of metrics configurations

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -21,6 +21,7 @@
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyIngressRule;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeer;
 import io.fabric8.kubernetes.api.model.policy.v1.PodDisruptionBudget;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaClusterSpec;
 import io.strimzi.api.kafka.model.KafkaResources;
@@ -211,7 +212,7 @@ public static ZookeeperCluster fromCrd(Reconciliation reconciliation, Kafka kafk
         }
 
         zk.logging = zookeeperClusterSpec.getLogging();
-        zk.gcLoggingEnabled = zookeeperClusterSpec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : zookeeperClusterSpec.getJvmOptions().isGcLoggingEnabled();
+        zk.gcLoggingEnabled = zookeeperClusterSpec.getJvmOptions() == null ? JvmOptions.DEFAULT_GC_LOGGING_ENABLED : zookeeperClusterSpec.getJvmOptions().isGcLoggingEnabled();
 
         // Parse different types of metrics configurations
         ModelUtils.parseMetrics(zk, zookeeperClusterSpec);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -36,6 +36,7 @@
 import io.strimzi.api.kafka.model.CruiseControlSpecBuilder;
 import io.strimzi.api.kafka.model.InlineLogging;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetricsBuilder;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
@@ -180,7 +181,7 @@ private List<EnvVar> getExpectedEnvVars() {
         List<EnvVar> expected = new ArrayList<>();
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_CRUISE_CONTROL_METRICS_ENABLED).withValue(Boolean.toString(CruiseControl.DEFAULT_CRUISE_CONTROL_METRICS_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_STRIMZI_KAFKA_BOOTSTRAP_SERVERS).withValue(KafkaResources.bootstrapServiceName(cluster) + ":" + KafkaCluster.REPLICATION_PORT).build());
-        expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
+        expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_MIN_INSYNC_REPLICAS).withValue(minInsyncReplicas).build());
         expected.add(new EnvVarBuilder().withName(ENV_VAR_CRUISE_CONTROL_CAPACITY_CONFIGURATION).withValue(cc.capacity.toString()).build());
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_API_SSL_ENABLED).withValue(Boolean.toString(CruiseControlConfigurationParameters.DEFAULT_WEBSERVER_SSL_ENABLED)).build());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.api.kafka.model.EntityTopicOperatorSpec;
 import io.strimzi.api.kafka.model.EntityTopicOperatorSpecBuilder;
 import io.strimzi.api.kafka.model.InlineLogging;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
@@ -124,7 +125,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_TOPIC_METADATA_MAX_ATTEMPTS).withValue(String.valueOf(toTopicMetadataMaxAttempts)).build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_SECURITY_PROTOCOL).withValue(EntityTopicOperatorSpec.DEFAULT_SECURITY_PROTOCOL).build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_TLS_ENABLED).withValue(Boolean.toString(true)).build());
-        expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
+        expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_JAVA_OPTS).withValue("-Xms128m").build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_JAVA_SYSTEM_PROPERTIES).withValue("-Djavax.net.debug=verbose -Dsomething.else=42").build());
         return expected;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -15,6 +15,7 @@
 import io.strimzi.api.kafka.model.EntityUserOperatorSpecBuilder;
 import io.strimzi.api.kafka.model.InlineLogging;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetrics;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaAuthorization;
 import io.strimzi.api.kafka.model.KafkaAuthorizationCustomBuilder;
@@ -133,7 +134,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_NAMESPACE).withValue(namespace).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLUSTER_CA_CERT_SECRET_NAME).withValue(KafkaCluster.clusterCaCertSecretName(cluster)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_EO_KEY_SECRET_NAME).withValue(KafkaResources.entityUserOperatorSecretName(cluster)).build());
-        expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
+        expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_VALIDITY).withValue(Integer.toString(CertificateAuthority.DEFAULT_CERTS_VALIDITY_DAYS)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_RENEWAL).withValue(Integer.toString(CertificateAuthority.DEFAULT_CERTS_RENEWAL_DAYS)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_STRIMZI_JAVA_OPTS).withValue("-Xmx256m").build());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -31,6 +31,7 @@
 import io.strimzi.api.kafka.model.CertSecretSource;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
 import io.strimzi.api.kafka.model.ContainerEnvVar;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.JvmOptionsBuilder;
 import io.strimzi.api.kafka.model.KafkaBridge;
 import io.strimzi.api.kafka.model.KafkaBridgeBuilder;
@@ -130,7 +131,7 @@ protected List<EnvVar> getExpectedEnvVars() {
 
         List<EnvVar> expected = new ArrayList<>();
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_METRICS_ENABLED).withValue(String.valueOf(true)).build());
-        expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(String.valueOf(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
+        expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(String.valueOf(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_BOOTSTRAP_SERVERS).withValue(bootstrapServers).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_ADMIN_CLIENT_CONFIG).withValue(defaultAdminclientConfiguration).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_CONSUMER_CONFIG).withValue(defaultConsumerConfiguration).build());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterPodSetTest.java
Patch:
@@ -24,6 +24,7 @@
 import io.fabric8.kubernetes.api.model.TopologySpreadConstraint;
 import io.fabric8.kubernetes.api.model.TopologySpreadConstraintBuilder;
 import io.strimzi.api.kafka.model.ContainerEnvVar;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
@@ -135,7 +136,7 @@ public void testPodSet()   {
             assertThat(pod.getSpec().getContainers().get(0).getLivenessProbe().getInitialDelaySeconds(), is(15));
             assertThat(pod.getSpec().getContainers().get(0).getReadinessProbe().getTimeoutSeconds(), is(5));
             assertThat(pod.getSpec().getContainers().get(0).getReadinessProbe().getInitialDelaySeconds(), is(15));
-            assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(pod.getSpec().getContainers().get(0)).get(AbstractModel.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)));
+            assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(pod.getSpec().getContainers().get(0)).get(AbstractModel.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)));
             assertThat(pod.getSpec().getContainers().get(0).getVolumeMounts().get(0).getName(), is("data-0"));
             assertThat(pod.getSpec().getContainers().get(0).getVolumeMounts().get(0).getMountPath(), is("/var/lib/kafka/data-0"));
             assertThat(pod.getSpec().getContainers().get(0).getVolumeMounts().get(1).getName(), is(VolumeUtils.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterStatefulSetTest.java
Patch:
@@ -20,6 +20,7 @@
 import io.fabric8.kubernetes.api.model.TopologySpreadConstraintBuilder;
 import io.fabric8.kubernetes.api.model.WeightedPodAffinityTerm;
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
@@ -132,7 +133,7 @@ private void checkStatefulSet(StatefulSet sts, Kafka kafka) {
         assertThat(containers.get(0).getLivenessProbe().getInitialDelaySeconds(), is(15));
         assertThat(containers.get(0).getReadinessProbe().getTimeoutSeconds(), is(5));
         assertThat(containers.get(0).getReadinessProbe().getInitialDelaySeconds(), is(15));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)));
+        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(KafkaCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)));
         assertThat(containers.get(0).getVolumeMounts().get(1).getName(), is(VolumeUtils.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME));
         assertThat(containers.get(0).getVolumeMounts().get(1).getMountPath(), is(VolumeUtils.STRIMZI_TMP_DIRECTORY_DEFAULT_MOUNT_PATH));
         assertThat(containers.get(0).getVolumeMounts().get(3).getName(), is(KafkaCluster.BROKER_CERTS_VOLUME));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -41,6 +41,7 @@
 import io.strimzi.api.kafka.model.ContainerEnvVar;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetrics;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetricsBuilder;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectBuilder;
 import io.strimzi.api.kafka.model.KafkaConnectResources;
@@ -188,7 +189,7 @@ protected List<EnvVar> getExpectedEnvVars(boolean stablePodIdentities) {
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_CONFIGURATION).withValue(expectedConfiguration.asPairs()).build());
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_METRICS_ENABLED).withValue(String.valueOf(true)).build());
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_BOOTSTRAP_SERVERS).withValue(bootstrapServers).build());
-        expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
+        expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(AbstractModel.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
 
         if (stablePodIdentities)    {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -34,6 +34,7 @@
 import io.strimzi.api.kafka.model.ContainerEnvVar;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetrics;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetricsBuilder;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.KafkaJmxAuthenticationPasswordBuilder;
 import io.strimzi.api.kafka.model.KafkaJmxOptionsBuilder;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2;
@@ -189,7 +190,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMaker2Cluster.ENV_VAR_KAFKA_CONNECT_CONFIGURATION).withValue(expectedConfiguration.asPairs()).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMaker2Cluster.ENV_VAR_KAFKA_CONNECT_METRICS_ENABLED).withValue(String.valueOf(true)).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMaker2Cluster.ENV_VAR_KAFKA_CONNECT_BOOTSTRAP_SERVERS).withValue(bootstrapServers).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMaker2Cluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
+        expected.add(new EnvVarBuilder().withName(KafkaMirrorMaker2Cluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(AbstractModel.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMaker2Cluster.ENV_VAR_KAFKA_MIRRORMAKER_2_CLUSTERS).withValue(targetClusterAlias).build());
         return expected;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -25,6 +25,7 @@
 import io.strimzi.api.kafka.model.ContainerEnvVar;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetrics;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetricsBuilder;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerBuilder;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerConsumerSpec;
@@ -173,7 +174,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_NUMSTREAMS).withValue(Integer.toString(numStreams)).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OFFSET_COMMIT_INTERVAL).withValue(Integer.toString(offsetCommitInterval)).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_ABORT_ON_SEND_FAILURE).withValue(Boolean.toString(abortOnSendFailure)).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
+        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_LIVENESS_PERIOD).withValue("10").build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_READINESS_PERIOD).withValue("10").build());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterPodSetTest.java
Patch:
@@ -23,6 +23,7 @@
 import io.fabric8.kubernetes.api.model.TopologySpreadConstraint;
 import io.fabric8.kubernetes.api.model.TopologySpreadConstraintBuilder;
 import io.strimzi.api.kafka.model.ContainerEnvVar;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
@@ -118,7 +119,7 @@ public void testPodSet()   {
             assertThat(pod.getSpec().getContainers().get(0).getLivenessProbe().getInitialDelaySeconds(), is(15));
             assertThat(pod.getSpec().getContainers().get(0).getReadinessProbe().getTimeoutSeconds(), is(5));
             assertThat(pod.getSpec().getContainers().get(0).getReadinessProbe().getInitialDelaySeconds(), is(15));
-            assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(pod.getSpec().getContainers().get(0)).get(ZookeeperCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)));
+            assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(pod.getSpec().getContainers().get(0)).get(ZookeeperCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)));
             assertThat(pod.getSpec().getContainers().get(0).getVolumeMounts().get(0).getName(), is(VolumeUtils.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME));
             assertThat(pod.getSpec().getContainers().get(0).getVolumeMounts().get(0).getMountPath(), is(VolumeUtils.STRIMZI_TMP_DIRECTORY_DEFAULT_MOUNT_PATH));
             assertThat(pod.getSpec().getContainers().get(0).getVolumeMounts().get(1).getName(), is(AbstractModel.VOLUME_NAME));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterStatefulSetTest.java
Patch:
@@ -14,6 +14,7 @@
 import io.fabric8.kubernetes.api.model.TopologySpreadConstraint;
 import io.fabric8.kubernetes.api.model.TopologySpreadConstraintBuilder;
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
+import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
@@ -131,7 +132,7 @@ private void checkStatefulSet(StatefulSet sts) {
         OrderedProperties actual = new OrderedProperties()
                 .addStringPairs(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(ZookeeperCluster.ENV_VAR_ZOOKEEPER_CONFIGURATION));
         assertThat(actual, is(expectedConfig));
-        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(ZookeeperCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)));
+        assertThat(io.strimzi.operator.cluster.TestUtils.containerEnvVars(containers.get(0)).get(ZookeeperCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(JvmOptions.DEFAULT_GC_LOGGING_ENABLED)));
         assertThat(containers.get(0).getVolumeMounts().get(0).getName(), is(VolumeUtils.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME));
         assertThat(containers.get(0).getVolumeMounts().get(0).getMountPath(), is(VolumeUtils.STRIMZI_TMP_DIRECTORY_DEFAULT_MOUNT_PATH));
         assertThat(containers.get(0).getVolumeMounts().get(0).getName(), is(VolumeUtils.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageMockTest.java
Patch:
@@ -149,7 +149,7 @@ public void init() {
 
         this.operator = new KafkaAssemblyOperator(JbodStorageMockTest.vertx, pfa, new MockCertManager(),
                 new PasswordGenerator(10, "a", "a"), ros,
-                ResourceUtils.dummyClusterOperatorConfig(VERSIONS, 2_000));
+                ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
     }
 
     @AfterEach

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorCustomCertMockTest.java
Patch:
@@ -91,7 +91,7 @@ public void setup() throws InterruptedException {
         podSetController.start();
 
         operator = new KafkaAssemblyOperator(vertx, pfa, new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier, ResourceUtils.dummyClusterOperatorConfig(VERSIONS, 2_000));
+                supplier, ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
     }
 
     @AfterEach

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorManualRollingUpdatesTest.java
Patch:
@@ -167,7 +167,7 @@ public void noManualRollingUpdate(VertxTestContext context, boolean useStrimziPo
 
         ClusterOperatorConfig config;
         if (useStrimziPodSets) {
-            config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS, ClusterOperatorConfig.DEFAULT_OPERATION_TIMEOUT_MS);
+            config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS);
         } else {
             config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS, ClusterOperatorConfig.DEFAULT_OPERATION_TIMEOUT_MS, "-UseStrimziPodSets");
         }
@@ -300,7 +300,7 @@ public void manualRollingUpdate(VertxTestContext context, boolean useStrimziPodS
 
         ClusterOperatorConfig config;
         if (useStrimziPodSets) {
-            config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS, ClusterOperatorConfig.DEFAULT_OPERATION_TIMEOUT_MS);
+            config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS);
         } else {
             config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS, ClusterOperatorConfig.DEFAULT_OPERATION_TIMEOUT_MS, "-UseStrimziPodSets");
         }
@@ -440,7 +440,7 @@ public void manualPodRollingUpdate(VertxTestContext context, boolean useStrimziP
 
         ClusterOperatorConfig config;
         if (useStrimziPodSets) {
-            config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS, ClusterOperatorConfig.DEFAULT_OPERATION_TIMEOUT_MS);
+            config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS);
         } else {
             config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS, ClusterOperatorConfig.DEFAULT_OPERATION_TIMEOUT_MS, "-UseStrimziPodSets");
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -173,7 +173,7 @@ public void init() {
         podSetController = new StrimziPodSetController(NAMESPACE, Labels.EMPTY, supplier.kafkaOperator, supplier.connectOperator, supplier.mirrorMaker2Operator, supplier.strimziPodSetOperator, supplier.podOperations, supplier.metricsProvider, ClusterOperatorConfig.DEFAULT_POD_SET_CONTROLLER_WORK_QUEUE_SIZE);
         podSetController.start();
 
-        ClusterOperatorConfig config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS, ClusterOperatorConfig.DEFAULT_OPERATION_TIMEOUT_MS);
+        ClusterOperatorConfig config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS);
         operator = new KafkaAssemblyOperator(vertx, pfa, new MockCertManager(),
                 new PasswordGenerator(10, "a", "a"), supplier, config);
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpgradeDowngradeMockTest.java
Patch:
@@ -137,7 +137,7 @@ private Future<Void> initialize(Kafka initialKafka)   {
         podSetController = new StrimziPodSetController(NAMESPACE, Labels.EMPTY, supplier.kafkaOperator, supplier.connectOperator, supplier.mirrorMaker2Operator, supplier.strimziPodSetOperator, supplier.podOperations, supplier.metricsProvider, ClusterOperatorConfig.DEFAULT_POD_SET_CONTROLLER_WORK_QUEUE_SIZE);
         podSetController.start();
 
-        ClusterOperatorConfig config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS, ClusterOperatorConfig.DEFAULT_OPERATION_TIMEOUT_MS);
+        ClusterOperatorConfig config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS);
 
         operator = new KafkaAssemblyOperator(vertx, PFA, new MockCertManager(),
                 new PasswordGenerator(10, "a", "a"), supplier, config);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ManualPodCleanerTest.java
Patch:
@@ -200,7 +200,7 @@ private void manualPodCleanup(VertxTestContext context, boolean useStrimziPodSet
 
         ClusterOperatorConfig config;
         if (useStrimziPodSets) {
-            config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS, ClusterOperatorConfig.DEFAULT_OPERATION_TIMEOUT_MS);
+            config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS);
         } else {
             config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS, ClusterOperatorConfig.DEFAULT_OPERATION_TIMEOUT_MS, "-UseStrimziPodSets");
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateMockTest.java
Patch:
@@ -141,7 +141,7 @@ public void beforeEach(VertxTestContext context) throws InterruptedException {
         podSetController.start();
 
         kco = new KafkaAssemblyOperator(vertx, pfa, new MockCertManager(), new PasswordGenerator(10, "a", "a"),
-                supplier, ResourceUtils.dummyClusterOperatorConfig(VERSIONS, 2_000));
+                supplier, ResourceUtils.dummyClusterOperatorConfig(VERSIONS));
 
         LOGGER.info("Initial reconciliation");
         CountDownLatch createAsync = new CountDownLatch(1);

File: systemtest/src/main/java/io/strimzi/systemtest/annotations/RequiredMinKubeOrOpenshiftVersionCondition.java
Patch:
@@ -28,7 +28,7 @@ public ConditionEvaluationResult evaluateExecutionCondition(ExtensionContext ext
         final boolean isOcp = cluster.isOpenShift();
 
         if ((isOcp && Double.parseDouble(cluster.client().clusterKubernetesVersion()) >= ocpBasedKubeVersion) ||
-            Double.parseDouble(cluster.client().clusterKubernetesVersion()) >= kubeVersion) {
+            !isOcp && Double.parseDouble(cluster.client().clusterKubernetesVersion()) >= kubeVersion) {
             return ConditionEvaluationResult.enabled("Test is enabled");
         } else {
             LOGGER.info("@RequiredMinKubeOrOpenshiftVersion with type of cluster: {} and version {}, but the running on cluster with {}: Ignoring {}",

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -73,7 +73,7 @@ class AlternativeReconcileTriggersST extends AbstractST {
     void testManualTriggeringRollingUpdate(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, namespace);
 
-        final String continuousTopicName = "continuous-topic";
+        final String continuousTopicName = "continuous-" + testStorage.getTopicName();
         final String continuousProducerName = "continuous-" + testStorage.getProducerName();
         final String continuousConsumerName = "continuous-" + testStorage.getConsumerName();
 
@@ -334,7 +334,7 @@ void testManualRollingUpdateForSinglePod(ExtensionContext extensionContext) {
     void testAddingAndRemovingJbodVolumes(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, namespace);
 
-        final String continuousTopicName = "continuous-topic";
+        final String continuousTopicName = "continuous-" + testStorage.getTopicName();
         final String continuousProducerName = "continuous-" + testStorage.getProducerName();
         final String continuousConsumerName = "continuous-" + testStorage.getConsumerName();
 

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeIsolatedST.java
Patch:
@@ -110,7 +110,7 @@ private void performUpgradeVerification(UpgradeDowngradeData upgradeData, Extens
         this.kafkaUpgradeTopic = new YAMLMapper().readValue(new File(dir, upgradeData.getFromExamples() + "/examples/topic/kafka-topic.yaml"), KafkaTopic.class);
         this.kafkaUpgradeTopic.getMetadata().setName(topicUpgradeName);
         this.kafkaUpgradeTopic.getSpec().setReplicas(3);
-        this.kafkaUpgradeTopic.getSpec().setAdditionalProperty("min.insync.replicas", 2);
+        this.kafkaUpgradeTopic.getSpec().getConfig().put("min.insync.replicas", 2);
 
         LOGGER.info("Deploy KafkaTopic: {}", this.kafkaUpgradeTopic.toString());
 

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -91,7 +91,6 @@ class LoggingChangeST extends AbstractST {
     private final String namespace = testSuiteNamespaceManager.getMapOfAdditionalNamespaces().get(LoggingChangeST.class.getSimpleName()).stream().findFirst().get();
 
     @ParallelNamespaceTest
-    @KRaftNotSupported("Debug needed - https://github.com/strimzi/strimzi-kafka-operator/issues/6863")
     @SuppressWarnings({"checkstyle:MethodLength"})
     void testJSONFormatLogging(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(namespace, extensionContext);
@@ -248,8 +247,8 @@ void testJSONFormatLogging(ExtensionContext extensionContext) {
 
         StUtils.checkLogForJSONFormat(clusterOperator.getDeploymentNamespace(), operatorSnapshot, ResourceManager.getCoDeploymentName());
         StUtils.checkLogForJSONFormat(namespaceName, kafkaPods, "kafka");
-        StUtils.checkLogForJSONFormat(namespaceName, zkPods, "zookeeper");
         if (!Environment.isKRaftModeEnabled()) {
+            StUtils.checkLogForJSONFormat(namespaceName, zkPods, "zookeeper");
             StUtils.checkLogForJSONFormat(namespaceName, eoPods, "topic-operator");
         }
         StUtils.checkLogForJSONFormat(namespaceName, eoPods, "user-operator");

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/JmxIsolatedST.java
Patch:
@@ -15,7 +15,6 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.annotations.IsolatedSuite;
-import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
@@ -51,7 +50,6 @@ public class JmxIsolatedST extends AbstractST {
     @ParallelNamespaceTest
     @Tag(CONNECT)
     @Tag(CONNECT_COMPONENTS)
-    @KRaftNotSupported("Debug needed - https://github.com/strimzi/strimzi-kafka-operator/issues/6863")
     void testKafkaZookeeperAndKafkaConnectWithJMX(ExtensionContext extensionContext) {
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         final String scraperName = mapWithScraperNames.get(extensionContext.getDisplayName());

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -1120,9 +1120,7 @@ void testCaRenewalBreakInMiddle(ExtensionContext extensionContext) {
         Map<String, String> kafkaPods = PodUtils.podSnapshot(testStorage.getNamespaceName(), testStorage.getKafkaSelector());
         Map<String, String> eoPods = DeploymentUtils.depSnapshot(testStorage.getNamespaceName(), testStorage.getEoDeploymentName());
 
-        InputStream secretInputStream = getClass().getClassLoader().getResourceAsStream("security-st-certs/expired-cluster-ca.crt");
-        String clusterCaCert = TestUtils.readResource(secretInputStream);
-        SecretUtils.createSecret(testStorage.getNamespaceName(), clusterCaCertificateSecretName(testStorage.getClusterName()), "ca.crt", clusterCaCert);
+        final String clusterCaCert = kubeClient().getSecret(testStorage.getNamespaceName(), KafkaResources.clusterCaCertificateSecretName(testStorage.getClusterName())).getData().get("ca.crt");
 
         KafkaResource.replaceKafkaResourceInSpecificNamespace(testStorage.getClusterName(), k -> {
             k.getSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -1334,12 +1334,12 @@ void testUOListeningOnlyUsersInSameCluster(ExtensionContext extensionContext) {
         LOGGER.info("Verifying that KafkaUser {} in cluster {} is created", userName, firstClusterName);
         String entityOperatorPodName = kubeClient(namespaceName).listPodNamesInSpecificNamespace(namespaceName, Labels.STRIMZI_NAME_LABEL, KafkaResources.entityOperatorDeploymentName(firstClusterName)).get(0);
         String uOLogs = kubeClient(namespaceName).logsInSpecificNamespace(namespaceName, entityOperatorPodName, "user-operator");
-        assertThat(uOLogs, containsString("KafkaUser " + namespaceName + "/" + userName + " was ADDED"));
+        assertThat(uOLogs, containsString("KafkaUser " + userName + " in namespace " + namespaceName + " was ADDED"));
 
         LOGGER.info("Verifying that KafkaUser {} in cluster {} is not created", userName, secondClusterName);
         entityOperatorPodName = kubeClient(namespaceName).listPodNamesInSpecificNamespace(namespaceName, Labels.STRIMZI_NAME_LABEL, KafkaResources.entityOperatorDeploymentName(secondClusterName)).get(0);
         uOLogs = kubeClient(namespaceName).logsInSpecificNamespace(namespaceName, entityOperatorPodName, "user-operator");
-        assertThat(uOLogs, not(containsString("KafkaUser " + namespaceName + "/" + userName + " was ADDED")));
+        assertThat(uOLogs, not(containsString("KafkaUser " + userName + " in namespace " + namespaceName + " was ADDED")));
 
         LOGGER.info("Verifying that KafkaUser belongs to {} cluster", firstClusterName);
         String kafkaUserResource = cmdKubeClient(namespaceName).getResourceAsYaml("kafkauser", userName);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperator.java
Patch:
@@ -400,7 +400,7 @@ private Future<Void> reconcile(Reconciliation reconciliation, String host,
         if (kafkaRebalance != null && kafkaRebalance.getStatus() != null
                 && "Ready".equals(rebalanceStateConditionType(kafkaRebalance.getStatus()))
                 && rawRebalanceAnnotation(kafkaRebalance) == null) {
-            LOGGER.infoCr(reconciliation, "Rebalancing is completed. You can use the  `refresh` annotation to ask for a new rebalance request");
+            LOGGER.infoCr(reconciliation, "Rebalancing is completed. You can use the `refresh` annotation to ask for a new rebalance request");
         } else {
             LOGGER.infoCr(reconciliation, "Rebalance action is performed and KafkaRebalance resource is currently in [{}] state", currentState);
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -1422,7 +1422,7 @@ public void testCruiseControlDisabled(VertxTestContext context) {
                     // the resource moved from New to NotReady due to the error
                     assertState(context, client, CLUSTER_NAMESPACE, RESOURCE_NAME,
                             KafkaRebalanceState.NotReady, InvalidResourceException.class,
-                            "Kafka resource lacks 'cruiseControl' declaration : No deployed Cruise Control for doing a rebalance.");
+                            "Kafka resource lacks 'cruiseControl' declaration");
                     checkpoint.flag();
                 })));
     }
@@ -1462,7 +1462,7 @@ public void testCruiseControlDisabledToEnabledBehaviour(VertxTestContext context
                 // the resource moved from New to NotReady due to the error
                 assertState(context, client, CLUSTER_NAMESPACE, RESOURCE_NAME,
                         KafkaRebalanceState.NotReady, InvalidResourceException.class,
-                        "Kafka resource lacks 'cruiseControl' declaration : No deployed Cruise Control for doing a rebalance.");
+                        "Kafka resource lacks 'cruiseControl' declaration");
             })))
                 .compose(v -> {
                     try {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/ConnectBuildOperator.java
Patch:
@@ -20,6 +20,7 @@
 import io.strimzi.operator.cluster.model.KafkaConnectDockerfile;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Annotations;
+import io.strimzi.operator.common.InvalidConfigurationException;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.ReconciliationLogger;
 import io.strimzi.operator.common.Util;
@@ -336,8 +337,7 @@ public Future<Void> validateImageStream(String namespace, Output buidlOutput)
             return imageStreamOperations.getAsync(namespace, imageName)
                 .compose(is -> {
                     if (is == null) {
-                        return Future.failedFuture(
-                            String.format("The build can't start because there is no image stream with name %s", imageName));
+                        return Future.failedFuture(new InvalidConfigurationException(String.format("The build can't start because there is no image stream with name %s", imageName)));
                     } else {
                         return Future.succeededFuture();
                     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaRoller.java
Patch:
@@ -800,7 +800,7 @@ private void maybeTcpProbe(PodRef podRef, Exception executionException, RestartC
             try {
                 LOGGER.debugCr(reconciliation, "Probing TCP port due to previous problems connecting to pod {}", podRef);
                 // do a tcp connect and close (with a short connect timeout)
-                tcpProbe(podRef.getPodName(), KafkaCluster.REPLICATION_PORT);
+                tcpProbe(DnsNameGenerator.podDnsName(namespace, KafkaResources.brokersServiceName(cluster), podRef.getPodName()), KafkaCluster.REPLICATION_PORT);
             } catch (IOException connectionException) {
                 throw new ForceableProblem("Unable to connect to " + podRef.getPodName() + ":" + KafkaCluster.REPLICATION_PORT, executionException.getCause(), true);
             }
@@ -817,7 +817,7 @@ private void maybeTcpProbe(PodRef podRef, Exception executionException, RestartC
      * @param port The port
      * @throws IOException if anything went wrong.
      */
-    void tcpProbe(String hostname, int port) throws IOException {
+    /*test*/ void tcpProbe(String hostname, int port) throws IOException {
         Socket socket = new Socket();
         try {
             socket.connect(new InetSocketAddress(hostname, port), 5_000);

File: systemtest/src/main/java/io/strimzi/systemtest/tracing/TracingConstants.java
Patch:
@@ -28,6 +28,8 @@ public interface TracingConstants {
     String JAEGER_COLLECTOR_OTLP_URL = "http://" + JAEGER_COLLECTOR_NAME + ":4317";
 
     String CERT_MANAGER_WEBHOOK_DEPLOYMENT = "cert-manager-webhook";
+    String CERT_MANAGER_CA_INJECTOR_DEPLOYMENT = "cert-manager-cainjector";
+    String CERT_MANAGER_DEPLOYMENT = "cert-manager";
     String CERT_MANAGER_NAMESPACE = "cert-manager";
 
     String JAEGER_SERVICE_ENV = "JAEGER_SERVICE_NAME";

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java
Patch:
@@ -107,7 +107,7 @@ public static void waitForPodsReady(String namespaceName, LabelSelector selector
      * The method to wait when all pods of specific prefix will be deleted
      * To wait for the cluster to be updated, the following methods must be used:
      * {@link io.strimzi.systemtest.utils.RollingUpdateUtils#componentHasRolled(String, LabelSelector, Map)},
-     * {@link io.strimzi.systemtest.utils.RollingUpdateUtils#waitTillComponentHasRolled(LabelSelector, int, Map)} )}
+     * {@link io.strimzi.systemtest.utils.RollingUpdateUtils#waitTillComponentHasRolled(String, LabelSelector, int, Map)} )}
      * @param podsNamePrefix Cluster name where pods should be deleted
      */
     public static void waitForPodsWithPrefixDeletion(String podsNamePrefix) {

File: test/src/main/java/io/strimzi/test/k8s/KubeClusterResource.java
Patch:
@@ -147,7 +147,7 @@ public void createNamespaces(CollectorElement collectorElement, String useNamesp
         bindingsNamespaces = namespaces;
         for (String namespace: namespaces) {
 
-            if (kubeClient().getNamespace(namespace) != null && System.getenv("SKIP_TEARDOWN") == null) {
+            if (kubeClient().getNamespace(namespace) != null && (System.getenv("SKIP_TEARDOWN") == null || !System.getenv("SKIP_TEARDOWN").equals("true"))) {
                 LOGGER.warn("Namespace {} is already created, going to delete it", namespace);
                 kubeClient().deleteNamespace(namespace);
                 cmdKubeClient().waitForResourceDeletion("Namespace", namespace);

File: topic-operator/src/main/java/io/strimzi/operator/topic/K8s.java
Patch:
@@ -12,6 +12,7 @@
 
 import java.util.List;
 
+/** K8s Interface */
 public interface K8s {
 
     /**

File: topic-operator/src/main/java/io/strimzi/operator/topic/StoreAndServiceFactory.java
Patch:
@@ -30,11 +30,11 @@ public StoreContext(ReadOnlyKeyValueStore<String, Topic> store, BiFunction<Strin
             this.service = Objects.requireNonNull(service);
         }
 
-        public ReadOnlyKeyValueStore<String, Topic> getStore() {
+        protected ReadOnlyKeyValueStore<String, Topic> getStore() {
             return store;
         }
 
-        public BiFunction<String, String, CompletionStage<Integer>> getService() {
+        protected BiFunction<String, String, CompletionStage<Integer>> getService() {
             return service;
         }
     }

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicMetadata.java
Patch:
@@ -18,16 +18,16 @@ public class TopicMetadata {
     private final Config config;
     private final TopicDescription description;
 
-    public TopicMetadata(TopicDescription description, Config config) {
+    protected TopicMetadata(TopicDescription description, Config config) {
         this.config = config;
         this.description = description;
     }
 
-    public Config getConfig() {
+    protected Config getConfig() {
         return config;
     }
 
-    public TopicDescription getDescription() {
+    protected TopicDescription getDescription() {
         return description;
     }
 }

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicMetadataHandler.java
Patch:
@@ -16,6 +16,7 @@
 import java.util.concurrent.TimeUnit;
 
 /**
+ * Done
  * Represents a handler for getting Kafka topic metadata, providing a helper {@link #retry} method
  * for subclasses which want to retry when they need to do that
  */

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicStore.java
Patch:
@@ -12,11 +12,11 @@
  */
 interface TopicStore {
 
-    public static class EntityExistsException extends Exception {
+    class EntityExistsException extends Exception {
 
     }
 
-    public static class NoSuchEntityExistsException extends Exception {
+    class NoSuchEntityExistsException extends Exception {
 
     }
 
@@ -25,7 +25,7 @@ public static class NoSuchEntityExistsException extends Exception {
      * e.g. in the case of KafkaStreamsTopicStore we throw this when
      * waiting on a async result takes too long -- see Config#STALE_RESULT_TIMEOUT_MS
      */
-    public static class InvalidStateException extends Exception {
+    class InvalidStateException extends Exception {
 
     }
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/Zk2KafkaStreams.java
Patch:
@@ -23,7 +23,7 @@
 public class Zk2KafkaStreams {
     private static final Logger LOGGER = LoggerFactory.getLogger(Zk2KafkaStreams.class);
 
-    public static CompletionStage<KafkaStreamsTopicStoreService> upgrade(
+    protected static CompletionStage<KafkaStreamsTopicStoreService> upgrade(
             Zk zk,
             Config config,
             Properties kafkaProperties,

File: topic-operator/src/main/java/io/strimzi/operator/topic/ZkTopicsWatcher.java
Patch:
@@ -92,10 +92,11 @@ private class ChildrenWatchHandler implements Handler<AsyncResult<List<String>>>
         private final Zk zk;
         private int watchCount = 0;
 
-        public ChildrenWatchHandler(Zk zk) {
+        protected ChildrenWatchHandler(Zk zk) {
             this.zk = zk;
         }
 
+        /** Handles the event that has happened */
         @Override
         public void handle(AsyncResult<List<String>> childResult) {
             if (state == 2) {

File: topic-operator/src/main/java/io/strimzi/operator/topic/ZkWatcher.java
Patch:
@@ -13,7 +13,7 @@
 import java.util.concurrent.ConcurrentHashMap;
 
 /**
- * Base abstract class for a ZooKeeper watcher for child znodes
+ * Base abstract class for a ZooKeeper watcher for child znodes.
  */
 public abstract class ZkWatcher {
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/zk/ZkImpl.java
Patch:
@@ -43,7 +43,7 @@ private static final <T> Handler<AsyncResult<T>> log(String msg) {
     private final ConcurrentHashMap<String, IZkDataListener> dataWatches = new ConcurrentHashMap<>();
     private final ConcurrentHashMap<String, IZkChildListener> childWatches = new ConcurrentHashMap<>();
 
-    public ZkImpl(Vertx vertx, ZkClient zkClient) {
+    protected ZkImpl(Vertx vertx, ZkClient zkClient) {
         this.vertx = vertx;
         this.workerExecutor = vertx.createSharedWorkerExecutor(getClass().getName(), 4);
         this.zookeeper = zkClient;

File: topic-operator/src/test/java/io/strimzi/operator/topic/MockTopicOperator.java
Patch:
@@ -77,8 +77,6 @@ public String toString() {
     public Future<Void> topicDeletedResult = Future.failedFuture("Unexpected mock interaction. Configure " + getClass().getSimpleName() + ".topicDeletedResult");
     public Future<Void> topicModifiedResult = Future.failedFuture("Unexpected mock interaction. Configure " + getClass().getSimpleName() + ".topicModifiedResult");
     public Future<Void> resourceAddedResult = Future.failedFuture("Unexpected mock interaction. Configure " + getClass().getSimpleName() + ".resourceAddedResult");
-    public Future<Void> resourceDeletedResult = Future.failedFuture("Unexpected mock interaction. Configure " + getClass().getSimpleName() + ".resourceDeletedResult");
-    public Future<Void> resourceModifiedResult = Future.failedFuture("Unexpected mock interaction. Configure " + getClass().getSimpleName() + ".resourceModifiedResult");
     private List<MockOperatorEvent> mockOperatorEvents = new ArrayList<>();
 
     public List<MockOperatorEvent> getMockOperatorEvents() {
@@ -90,7 +88,7 @@ public void clearEvents() {
     }
 
     @Override
-    public void initMetrics() {
+    protected void initMetrics() {
         return;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractConnectOperator.java
Patch:
@@ -1050,6 +1050,6 @@ Future<ReconcileResult<Secret>> kafkaConnectJmxSecret(Reconciliation reconciliat
      * @return Future for tracking the asynchronous result of the ClusterRoleBinding reconciliation
      */
     protected Future<ReconcileResult<ClusterRoleBinding>> connectInitClusterRoleBinding(Reconciliation reconciliation, String crbName, ClusterRoleBinding crb) {
-        return withIgnoreRbacError(reconciliation, clusterRoleBindingOperations.reconcile(reconciliation, crbName, crb), crb);
+        return ReconcilerUtils.withIgnoreRbacError(reconciliation, clusterRoleBindingOperations.reconcile(reconciliation, crbName, crb), crb);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -664,7 +664,7 @@ protected KafkaStatus createStatus() {
      */
     @Override
     protected Future<Boolean> delete(Reconciliation reconciliation) {
-        return withIgnoreRbacError(reconciliation, clusterRoleBindingOperations.reconcile(reconciliation, KafkaResources.initContainerClusterRoleBindingName(reconciliation.name(), reconciliation.namespace()), null), null)
+        return ReconcilerUtils.withIgnoreRbacError(reconciliation, clusterRoleBindingOperations.reconcile(reconciliation, KafkaResources.initContainerClusterRoleBindingName(reconciliation.name(), reconciliation.namespace()), null), null)
                 .map(Boolean.FALSE); // Return FALSE since other resources are still deleted by garbage collection
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -134,7 +134,7 @@ protected Future<KafkaBridgeStatus> createOrUpdate(Reconciliation reconciliation
     @Override
     protected Future<Boolean> delete(Reconciliation reconciliation) {
         return super.delete(reconciliation)
-                    .compose(i -> withIgnoreRbacError(reconciliation, clusterRoleBindingOperations.reconcile(reconciliation, KafkaBridgeResources.initContainerClusterRoleBindingName(reconciliation.name(), reconciliation.namespace()), null), null))
+                    .compose(i -> ReconcilerUtils.withIgnoreRbacError(reconciliation, clusterRoleBindingOperations.reconcile(reconciliation, KafkaBridgeResources.initContainerClusterRoleBindingName(reconciliation.name(), reconciliation.namespace()), null), null))
                     .map(Boolean.FALSE); // Return FALSE since other resources are still deleted by garbage collection
     }
 
@@ -151,6 +151,6 @@ Future<ReconcileResult<ServiceAccount>> kafkaBridgeServiceAccount(Reconciliation
     }
 
     protected Future<ReconcileResult<ClusterRoleBinding>> bridgeInitClusterRoleBinding(Reconciliation reconciliation, String crbName, ClusterRoleBinding crb) {
-        return withIgnoreRbacError(reconciliation, clusterRoleBindingOperations.reconcile(reconciliation, crbName, crb), crb);
+        return ReconcilerUtils.withIgnoreRbacError(reconciliation, clusterRoleBindingOperations.reconcile(reconciliation, crbName, crb), crb);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -236,7 +236,7 @@ public void reconcileThese(String trigger, Set<NamespaceAndName> desiredNames, S
     @Override
     protected Future<Boolean> delete(Reconciliation reconciliation) {
         return super.delete(reconciliation)
-                .compose(i -> withIgnoreRbacError(reconciliation, clusterRoleBindingOperations.reconcile(reconciliation, KafkaConnectResources.initContainerClusterRoleBindingName(reconciliation.name(), reconciliation.namespace()), null), null))
+                .compose(i -> ReconcilerUtils.withIgnoreRbacError(reconciliation, clusterRoleBindingOperations.reconcile(reconciliation, KafkaConnectResources.initContainerClusterRoleBindingName(reconciliation.name(), reconciliation.namespace()), null), null))
                 .map(Boolean.FALSE); // Return FALSE since other resources are still deleted by garbage collection
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ClusterOperatorRbacIsolatedST.java
Patch:
@@ -65,14 +65,14 @@ void testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled(ExtensionContext
 
         LOGGER.info("CO log should contain some information about ignoring forbidden access to CRB for Kafka");
         String log = cmdKubeClient().execInCurrentNamespace(Level.DEBUG, "logs", coPodName).out();
-        assertTrue(log.contains("Ignoring forbidden access to ClusterRoleBindings resource which does not seem to be required."));
+        assertTrue(log.contains("Kafka(" + cmdKubeClient().namespace() + "/" + clusterName + "): Ignoring forbidden access to ClusterRoleBindings resource which does not seem to be required."));
 
         LOGGER.info("Deploying KafkaConnect: {} without rack awareness, the CR should be deployed without error", clusterName);
         resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnect(clusterName, 1).build());
 
         LOGGER.info("CO log should contain some information about ignoring forbidden access to CRB for KafkaConnect");
-        log = cmdKubeClient().execInCurrentNamespace(Level.DEBUG, "logs", coPodName, "--tail", "50").out();
-        assertTrue(log.contains("Ignoring forbidden access to ClusterRoleBindings resource which does not seem to be required."));
+        log = cmdKubeClient().execInCurrentNamespace(Level.DEBUG, "logs", coPodName).out();
+        assertTrue(log.contains("KafkaConnect(" + cmdKubeClient().namespace() + "/" + clusterName + "): Ignoring forbidden access to ClusterRoleBindings resource which does not seem to be required."));
     }
 
     @IsolatedTest("We need for each test case its own Cluster Operator")

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -358,8 +358,8 @@ Future<ReconciliationState> reconcileCas(Clock clock)    {
             return caReconciler()
                     .reconcile(clock)
                     .compose(cas -> {
-                        this.clusterCa = cas.clusterCa;
-                        this.clientsCa = cas.clientsCa;
+                        this.clusterCa = cas.clusterCa();
+                        this.clientsCa = cas.clientsCa();
                         return Future.succeededFuture(this);
                     });
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaListenersReconciler.java
Patch:
@@ -329,8 +329,7 @@ protected Future<Void> clusterIPServicesReady()   {
             String bootstrapAddress = getInternalServiceHostname(reconciliation.namespace(), ListenersUtils.backwardsCompatibleBootstrapServiceName(reconciliation.name(), listener), useServiceDnsDomain);
 
             if (listener.isTls()) {
-                ModelUtils.generateAllServiceDnsNames(reconciliation.namespace(), ListenersUtils.backwardsCompatibleBootstrapServiceName(reconciliation.name(), listener))
-                                .forEach(dnsName -> result.bootstrapDnsNames.add(dnsName));
+                result.bootstrapDnsNames.addAll(ModelUtils.generateAllServiceDnsNames(reconciliation.namespace(), ListenersUtils.backwardsCompatibleBootstrapServiceName(reconciliation.name(), listener)));
             }
 
             ListenerStatus ls = new ListenerStatusBuilder()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -18,6 +18,7 @@
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.PlatformFeaturesAvailability;
+import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaMirrorMakerCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
@@ -103,7 +104,7 @@ protected Future<KafkaMirrorMakerStatus> createOrUpdate(Reconciliation reconcili
                 .compose(i -> Util.metricsAndLogging(reconciliation, configMapOperations, namespace, mirror.getLogging(), mirror.getMetricsConfigInCm()))
                 .compose(metricsAndLoggingCm -> {
                     ConfigMap logAndMetricsConfigMap = mirror.generateMetricsAndLogConfigMap(metricsAndLoggingCm);
-                    annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(mirror.ANCILLARY_CM_KEY_LOG_CONFIG));
+                    annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG));
                     return configMapOperations.reconcile(reconciliation, namespace, mirror.getAncillaryConfigMapName(), logAndMetricsConfigMap);
                 })
                 .compose(i -> pfa.hasPodDisruptionBudgetV1() ? podDisruptionBudgetOperator.reconcile(reconciliation, namespace, mirror.getName(), mirror.generatePodDisruptionBudget()) : Future.succeededFuture())

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaReconciler.java
Patch:
@@ -641,7 +641,7 @@ protected Future<Void> perBrokerKafkaConfiguration(MetricsAndLogging metricsAndL
                     // Delete all existing ConfigMaps which are not desired and are not the shared config map
                     List<String> desiredNames = new ArrayList<>(desiredConfigMaps.size() + 1);
                     desiredNames.add(kafka.getAncillaryConfigMapName()); // We do not want to delete the shared ConfigMap, so we add it here
-                    desiredNames.addAll(desiredConfigMaps.stream().map(cm -> cm.getMetadata().getName()).collect(Collectors.toList()));
+                    desiredNames.addAll(desiredConfigMaps.stream().map(cm -> cm.getMetadata().getName()).toList());
 
                     for (ConfigMap cm : existingConfigMaps) {
                         // We delete the cms not on the desired names list
@@ -950,9 +950,8 @@ protected Future<Void> rollToAddOrRemoveVolumes() {
         //   * JBOD storage is actually used as storage
         //   * and StatefulSets are used
         // StrimziPodSets do not need special rolling update, they can add / remove volumes during regular rolling updates
-        if (storage instanceof JbodStorage
+        if (storage instanceof JbodStorage jbodStorage
                 && !featureGates.useStrimziPodSetsEnabled()) {
-            JbodStorage jbodStorage = (JbodStorage) storage;
             return kafkaRollToAddOrRemoveVolumesInStatefulSet(jbodStorage);
         } else {
             return Future.succeededFuture();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractConfiguration.java
Patch:
@@ -161,6 +161,7 @@ public String getConfigOption(String configOption) {
      * Returns a value for a specific config option or a default value
      *
      * @param configOption  Config option which should be looked-up
+     * @param defaultValue  Default value
      *
      * @return  The configured value for this option or the default value if given option is not configured
      */

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectDockerfile.java
Patch:
@@ -48,12 +48,11 @@ public class KafkaConnectDockerfile {
     private static final String DEFAULT_MAVEN_IMAGE = "quay.io/strimzi/maven-builder:latest";
     private final String mavenBuilder;
 
-    public static Cmd run(String cmd, String... args) {
+    private static Cmd run(String cmd, String... args) {
         return new Cmd(new StringBuilder(), cmd, args);
     }
 
-    public static class Cmd {
-
+    private static class Cmd {
         private final StringBuilder stringBuilder;
         boolean doneFirst = false;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Cluster.java
Patch:
@@ -35,6 +35,9 @@
 
 import static io.strimzi.operator.cluster.ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_INIT_IMAGE;
 
+/**
+ * Kafka Mirror Maker 2 model
+ */
 public class KafkaMirrorMaker2Cluster extends KafkaConnectCluster {
     protected static final String APPLICATION_NAME = "kafka-mirror-maker-2";
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ListenersValidator.java
Patch:
@@ -29,8 +29,8 @@
 public class ListenersValidator {
     protected static final ReconciliationLogger LOGGER = ReconciliationLogger.create(ListenersValidator.class.getName());
     private final static Pattern LISTENER_NAME_PATTERN = Pattern.compile(GenericKafkaListener.LISTENER_NAME_REGEX);
-    public final static List<Integer> FORBIDDEN_PORTS = List.of(9404, 9999);
-    public final static int LOWEST_ALLOWED_PORT_NUMBER = 9092;
+    private final static List<Integer> FORBIDDEN_PORTS = List.of(9404, 9999);
+    private final static int LOWEST_ALLOWED_PORT_NUMBER = 9092;
 
     /**
      * Validated the listener configuration. If the configuration is not valid, InvalidResourceException will be thrown.

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/PodRevision.java
Patch:
@@ -20,6 +20,9 @@
  * a bit simple.
  */
 public class PodRevision {
+    /**
+     * Annotation for tracking pod revisions
+     */
     public static final String STRIMZI_REVISION_ANNOTATION = Labels.STRIMZI_DOMAIN + "revision";
     private static final ReconciliationLogger LOGGER = ReconciliationLogger.create(PodRevision.class.getName());
 

File: systemtest/src/main/java/io/strimzi/systemtest/tracing/TracingConstants.java
Patch:
@@ -25,7 +25,7 @@ public interface TracingConstants {
     String JAEGER_AGENT_HOST = JAEGER_INSTANCE_NAME + "-agent";
     String JAEGER_QUERY_SERVICE = JAEGER_INSTANCE_NAME + "-query";
     String JAEGER_COLLECTOR_NAME = JAEGER_INSTANCE_NAME + "-collector";
-    String JAEGER_COLLECTOR_URL = "http://" + JAEGER_COLLECTOR_NAME + ":14250";
+    String JAEGER_COLLECTOR_OTLP_URL = "http://" + JAEGER_COLLECTOR_NAME + ":4317";
 
     String CERT_MANAGER_WEBHOOK_DEPLOYMENT = "cert-manager-webhook";
     String CERT_MANAGER_NAMESPACE = "cert-manager";

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/OpenTelemetryST.java
Patch:
@@ -8,7 +8,6 @@
 import io.strimzi.api.kafka.model.tracing.Tracing;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelSuite;
-import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
@@ -26,7 +25,6 @@
 @Tag(TRACING)
 @Tag(INTERNAL_CLIENTS_USED)
 @ParallelSuite
-@Disabled
 public class OpenTelemetryST extends TracingAbstractST {
 
     @Override

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaRoller.java
Patch:
@@ -179,6 +179,7 @@ private boolean initAdminClient() {
             try {
                 this.allClient = adminClient(IntStream.range(0, podList.size()).boxed().collect(Collectors.toList()), false);
             } catch (ForceableProblem | FatalProblem e) {
+                LOGGER.warnCr(reconciliation, "Failed to create adminClient.", e);
                 return false;
             }
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ListenersValidator.java
Patch:
@@ -315,7 +315,7 @@ private static void validateFinalizers(Set<String> errors, GenericKafkaListener
     private static void validateBootstrapHost(Set<String> errors, GenericKafkaListener listener) {
         if ((!KafkaListenerType.ROUTE.equals(listener.getType()) && !KafkaListenerType.INGRESS.equals(listener.getType()))
                 && listener.getConfiguration().getBootstrap().getHost() != null)    {
-            errors.add("listener " + listener.getName() + " cannot configure bootstrap.host because it is not Route ot Ingress based listener");
+            errors.add("listener " + listener.getName() + " cannot configure bootstrap.host because it is not Route or Ingress based listener");
         }
     }
 
@@ -381,7 +381,7 @@ private static void validateBootstrapLabelsAndAnnotations(Set<String> errors, Ge
     private static void validateBrokerHost(Set<String> errors, GenericKafkaListener listener, GenericKafkaListenerConfigurationBroker broker) {
         if ((!KafkaListenerType.ROUTE.equals(listener.getType()) && !KafkaListenerType.INGRESS.equals(listener.getType()))
                 && broker.getHost() != null)    {
-            errors.add("listener " + listener.getName() + " cannot configure brokers[].host because it is not Route ot Ingress based listener");
+            errors.add("listener " + listener.getName() + " cannot configure brokers[].host because it is not Route or Ingress based listener");
         }
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -135,7 +135,7 @@ protected Future<KafkaConnectStatus> createOrUpdate(Reconciliation reconciliatio
                 .compose(i -> generateMetricsAndLoggingConfigMap(reconciliation, namespace, connect))
                 .compose(logAndMetricsConfigMap -> {
                     String logging = logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG);
-                    annotations.put(Annotations.ANNO_STRIMZI_LOGGING_DYNAMICALLY_UNCHANGEABLE_HASH,
+                    annotations.put(Annotations.ANNO_STRIMZI_LOGGING_APPENDERS_HASH,
                             Util.hashStub(Util.getLoggingDynamicallyUnmodifiableEntries(logging)));
                     desiredLogging.set(logging);
                     return configMapOperations.reconcile(reconciliation, namespace, connect.getAncillaryConfigMapName(), logAndMetricsConfigMap);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -161,7 +161,7 @@ protected Future<KafkaMirrorMaker2Status> createOrUpdate(Reconciliation reconcil
                 .compose(i -> generateMetricsAndLoggingConfigMap(reconciliation, namespace, mirrorMaker2Cluster))
                 .compose(logAndMetricsConfigMap -> {
                     String logging = logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG);
-                    annotations.put(Annotations.ANNO_STRIMZI_LOGGING_DYNAMICALLY_UNCHANGEABLE_HASH,
+                    annotations.put(Annotations.ANNO_STRIMZI_LOGGING_APPENDERS_HASH,
                         Util.hashStub(Util.getLoggingDynamicallyUnmodifiableEntries(logging)));
                     desiredLogging.set(logging);
                     return configMapOperations.reconcile(reconciliation, namespace, mirrorMaker2Cluster.getAncillaryConfigMapName(), logAndMetricsConfigMap);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -193,7 +193,7 @@ public void createKafkaConnectCluster(VertxTestContext context, KafkaConnect kc,
                 Deployment dc = capturedDc.get(0);
                 assertThat(dc.getMetadata().getName(), is(connect.getName()));
                 Map<String, String> annotations = new HashMap<>();
-                annotations.put(Annotations.ANNO_STRIMZI_LOGGING_DYNAMICALLY_UNCHANGEABLE_HASH,
+                annotations.put(Annotations.ANNO_STRIMZI_LOGGING_APPENDERS_HASH,
                                                          Util.hashStub(Util.getLoggingDynamicallyUnmodifiableEntries(LOGGING_CONFIG)));
                 annotations.put(Annotations.ANNO_STRIMZI_AUTH_HASH, "0");
                 assertThat(dc, is(connect.generateDeployment(annotations, true, null, null)));
@@ -463,7 +463,7 @@ public void testCreateOrUpdateUpdatesCluster(VertxTestContext context) {
                 String dynamicallyUnmodifiableEntries = Util.getLoggingDynamicallyUnmodifiableEntries(loggingConfiguration);
                 String hashedLoggingConf = Util.hashStub(dynamicallyUnmodifiableEntries);
                 Map<String, String> annotations = new HashMap<>();
-                annotations.put(Annotations.ANNO_STRIMZI_LOGGING_DYNAMICALLY_UNCHANGEABLE_HASH,
+                annotations.put(Annotations.ANNO_STRIMZI_LOGGING_APPENDERS_HASH,
                                                          hashedLoggingConf);
                 annotations.put(Annotations.ANNO_STRIMZI_AUTH_HASH, "0");
 

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/NodeUtils.java
Patch:
@@ -12,6 +12,9 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
+/**
+ * Utils for working with nodes
+ */
 public class NodeUtils {
     private static final ReconciliationLogger LOGGER = ReconciliationLogger.create(NodeUtils.class);
 

File: operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java
Patch:
@@ -12,6 +12,9 @@
 import java.nio.charset.StandardCharsets;
 import java.util.Properties;
 
+/**
+ * Provides the default KAfka Admin client
+ */
 public class DefaultAdminClientProvider implements AdminClientProvider {
     @Override
     public Admin createAdminClient(String bootstrapHostnames, Secret clusterCaCertSecret, Secret keyCertSecret, String keyCertName) {

File: operator-common/src/main/java/io/strimzi/operator/common/ReconciliationException.java
Patch:
@@ -12,6 +12,9 @@
  * the custom resource.
  */
 public class ReconciliationException extends Exception {
+    /**
+     * Status of the custom resource
+     */
     private final Status status;
 
     /**

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractJsonDiff.java
Patch:
@@ -10,6 +10,9 @@
 import com.fasterxml.jackson.databind.node.MissingNode;
 import io.fabric8.kubernetes.client.utils.Serialization;
 
+/**
+ * Abstract class for diffing Json and YAML resources
+ */
 public abstract class AbstractJsonDiff {
     // use SerializationFeature.ORDER_MAP_ENTRIES_BY_KEYS just for better human readability in the logs
     @SuppressWarnings("deprecation") // Suppress deprecated warning of SerializationFeature.WRITE_EMPTY_JSON_ARRAYS which currently does not have proper alternative

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ClusterRoleBindingOperator.java
Patch:
@@ -11,6 +11,9 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.vertx.core.Vertx;
 
+/**
+ * Operator for managing Cluster Role Bindings
+ */
 public class ClusterRoleBindingOperator extends AbstractNonNamespacedResourceOperator<KubernetesClient,
         ClusterRoleBinding, ClusterRoleBindingList, Resource<ClusterRoleBinding>> {
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/NodeOperator.java
Patch:
@@ -11,9 +11,11 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.vertx.core.Vertx;
 
+/**
+ * Operator for managing nodes
+ */
 public class NodeOperator extends AbstractNonNamespacedResourceOperator<KubernetesClient,
         Node, NodeList, Resource<Node>> {
-
     /**
      * Constructor.
      *

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/RoleBindingOperator.java
Patch:
@@ -11,7 +11,9 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.vertx.core.Vertx;
 
-
+/**
+ * Operator for managing Role Bindings
+ */
 public class RoleBindingOperator extends AbstractResourceOperator<KubernetesClient, RoleBinding,
         RoleBindingList,
         Resource<RoleBinding>> {

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/RoleOperator.java
Patch:
@@ -11,12 +11,14 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.vertx.core.Vertx;
 
+/**
+ * Operator for managing Roles
+ */
 public class RoleOperator extends AbstractResourceOperator<
         KubernetesClient,
         Role,
         RoleList,
         Resource<Role>> {
-
     /**
      * Constructor
      * @param vertx The Vertx instance

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ServiceAccountOperator.java
Patch:
@@ -13,6 +13,9 @@
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
 
+/**
+ * Operator for managing Service Accounts
+ */
 public class ServiceAccountOperator extends AbstractResourceOperator<KubernetesClient, ServiceAccount, ServiceAccountList, Resource<ServiceAccount>> {
     /**
      * Constructor

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/StorageClassOperator.java
Patch:
@@ -11,9 +11,11 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.vertx.core.Vertx;
 
+/**
+ * Operator for managing storage classes
+ */
 public class StorageClassOperator extends AbstractNonNamespacedResourceOperator<KubernetesClient,
         StorageClass, StorageClassList, Resource<StorageClass>> {
-
     /**
      * Constructor.
      *
@@ -25,7 +27,6 @@ public StorageClassOperator(Vertx vertx, KubernetesClient client) {
         super(vertx, client, "StorageClass");
     }
 
-
     @Override
     protected NonNamespaceOperation<StorageClass, StorageClassList,
                 Resource<StorageClass>> operation() {

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/ListenersST.java
Patch:
@@ -282,7 +282,7 @@ void testSendMessagesPlainScramSha(ExtensionContext extensionContext) {
     @KRaftNotSupported("Scram-sha is not supported by KRaft mode and is used in this test case")
     void testSendMessagesTlsScramSha(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext);
-        final int passwordLength = 25;
+        final int passwordLength = 50;
 
         // Use a Kafka with plain listener disabled
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(testStorage.getClusterName(), 3)

File: user-operator/src/main/java/io/strimzi/operator/user/UserOperatorConfig.java
Patch:
@@ -52,7 +52,7 @@ public class UserOperatorConfig {
      * Configures the default prefix of user secrets created by the operator
      */
     public static final String DEFAULT_SECRET_PREFIX = "";
-    static final int DEFAULT_SCRAM_SHA_PASSWORD_LENGTH = 12;
+    static final int DEFAULT_SCRAM_SHA_PASSWORD_LENGTH = 32;
     /**
      * Indicates whether the Admin APi can be used to manage ACLs. Defaults to true for backwards compatibility reasons.
      */

File: user-operator/src/test/java/io/strimzi/operator/user/ResourceUtils.java
Patch:
@@ -46,7 +46,7 @@ public static UserOperatorConfig createUserOperatorConfig(Map<String, String> la
         envVars.put(UserOperatorConfig.STRIMZI_ACLS_ADMIN_API_SUPPORTED, Boolean.toString(aclsAdminApiSupported));
         envVars.put(UserOperatorConfig.STRIMZI_KRAFT_ENABLED, Boolean.toString(useKRaft));
 
-        if (!scramShaPasswordLength.equals("12")) {
+        if (!scramShaPasswordLength.equals("32")) {
             envVars.put(UserOperatorConfig.STRIMZI_SCRAM_SHA_PASSWORD_LENGTH, scramShaPasswordLength);
         }
 
@@ -73,7 +73,7 @@ public static UserOperatorConfig createUserOperatorConfigForUserControllerTestin
     }
 
     public static UserOperatorConfig createUserOperatorConfig() {
-        return createUserOperatorConfig(Map.of(), true, false, "12", null);
+        return createUserOperatorConfig(Map.of(), true, false, "32", null);
     }
 
     public static UserOperatorConfig createUserOperatorConfig(String scramShaPasswordLength) {

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -47,7 +47,8 @@ public class KafkaClusterSpec implements HasConfigurableMetrics, UnknownProperty
             + "cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers,"
             + "node.id, process.roles, controller."; // KRaft options
 
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols, sasl.server.max.receive.size,"
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, sasl.server.max.receive.size,"
+            + "ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols, ssl.secure.random.implementation,"
             + "cruise.control.metrics.topic.num.partitions, cruise.control.metrics.topic.replication.factor, cruise.control.metrics.topic.retention.ms,"
             + "cruise.control.metrics.topic.auto.create.retries, cruise.control.metrics.topic.auto.create.timeout.ms,"
             + "cruise.control.metrics.topic.min.insync.replicas,"

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -341,7 +341,6 @@ public KafkaBrokerConfigurationBuilder withListeners(
 
         writer.println("inter.broker.listener.name=" + REPLICATION_LISTENER_NAME);
         writer.println("sasl.enabled.mechanisms=");
-        writer.println("ssl.secure.random.implementation=SHA1PRNG");
         writer.println("ssl.endpoint.identification.algorithm=HTTPS");
         writer.println();
 
@@ -686,7 +685,6 @@ private void configureAuthorization(String clusterName, List<String> superUsers,
                 writer.println("strimzi.authorization.ssl.truststore.location=/tmp/kafka/authz-keycloak.truststore.p12");
                 writer.println("strimzi.authorization.ssl.truststore.password=" + PLACEHOLDER_CERT_STORE_PASSWORD);
                 writer.println("strimzi.authorization.ssl.truststore.type=PKCS12");
-                writer.println("strimzi.authorization.ssl.secure.random.implementation=SHA1PRNG");
                 String endpointIdentificationAlgorithm = keycloakAuthz.isDisableTlsHostnameVerification() ? "" : "HTTPS";
                 writer.println("strimzi.authorization.ssl.endpoint.identification.algorithm=" + endpointIdentificationAlgorithm);
             }

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlApiST.java
Patch:
@@ -201,7 +201,7 @@ void testKafkaRebalanceAutoApprovalMechanism(ExtensionContext extensionContext)
             .endMetadata()
             .build());
 
-        KafkaRebalanceUtils.doRebalancingProcess(new Reconciliation("test", KafkaRebalance.RESOURCE_KIND,
+        KafkaRebalanceUtils.doRebalancingProcessWithAutoApproval(new Reconciliation("test", KafkaRebalance.RESOURCE_KIND,
             testStorage.getNamespaceName(), testStorage.getClusterName()), testStorage.getNamespaceName(), testStorage.getClusterName());
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/MockCruiseControl.java
Patch:
@@ -91,8 +91,8 @@ public class MockCruiseControl {
     public static ClientAndServer server(int port) throws IOException {
         ConfigurationProperties.logLevel("WARN");
 
-        File key = File.createTempFile("key-", ".key");
-        File cert = File.createTempFile("crt-", ".crt");
+        File key = Files.createTempFile("key-", ".key").toFile();
+        File cert = Files.createTempFile("crt-", ".crt").toFile();
 
         MockCertManager certManager = new MockCertManager();
         certManager.generateSelfSignedCert(key, cert, new Subject.Builder().withCommonName("Test CA").build(), 365);

File: operator-common/src/main/java/io/strimzi/operator/common/Util.java
Patch:
@@ -230,7 +230,7 @@ public static RuntimeException missingSecretException(String namespace, String s
     public static File createFileStore(String prefix, String suffix, byte[] bytes) {
         File f = null;
         try {
-            f = File.createTempFile(prefix, suffix);
+            f = Files.createTempFile(prefix, suffix).toFile();
             f.deleteOnExit();
             try (OutputStream os = new BufferedOutputStream(new FileOutputStream(f))) {
                 os.write(bytes);
@@ -286,7 +286,7 @@ public static File createFileTrustStore(String prefix, String suffix, Set<X509Ce
     private static File store(String prefix, String suffix, KeyStore trustStore, char[] password) throws Exception {
         File f = null;
         try {
-            f = File.createTempFile(prefix, suffix);
+            f = Files.createTempFile(prefix, suffix).toFile();
             f.deleteOnExit();
             try (OutputStream os = new BufferedOutputStream(new FileOutputStream(f))) {
                 trustStore.store(os, password);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/specific/OlmResource.java
Patch:
@@ -211,7 +211,7 @@ private static void approveNonUsedInstallPlan() {
                     " patch installplan " + nonUsedInstallPlan + " --type json  --patch '[{\"op\": \"add\", \"path\": \"/spec/approved\", \"value\": true}]' -n " + KubeClusterResource.getInstance().getNamespace();
 
             InputStream inputStream = new ByteArrayInputStream(dynamicScriptContent.getBytes(Charset.defaultCharset()));
-            File patchScript = File.createTempFile("installplan_patch",  ".sh");
+            File patchScript = Files.createTempFile("installplan_patch", ".sh").toFile();
             Files.copy(inputStream, patchScript.toPath(), StandardCopyOption.REPLACE_EXISTING);
 
             Exec.exec("bash", patchScript.getAbsolutePath());
@@ -246,7 +246,7 @@ public void updateSubscription(final String newChannelName, final String olmOper
      */
     private static void createOperatorGroup(String namespace) {
         try {
-            File operatorGroupFile = File.createTempFile("operatorgroup", ".yaml");
+            File operatorGroupFile = Files.createTempFile("operatorgroup", ".yaml").toFile();
             InputStream groupInputStream = OlmResource.class.getClassLoader().getResourceAsStream("olm/operator-group.yaml");
             String operatorGroup = TestUtils.readResource(groupInputStream);
             TestUtils.writeFile(operatorGroupFile.getAbsolutePath(), operatorGroup.replace("${OPERATOR_NAMESPACE}", namespace));

File: systemtest/src/main/java/io/strimzi/systemtest/security/SystemTestCertManager.java
Patch:
@@ -14,6 +14,7 @@
 import java.io.File;
 import java.io.FileWriter;
 import java.io.IOException;
+import java.nio.file.Files;
 import java.security.KeyFactory;
 import java.security.NoSuchAlgorithmException;
 import java.security.PrivateKey;
@@ -149,7 +150,7 @@ public static File convertPrivateKeyToPKCS8File(PrivateKey privatekey) throws No
     }
 
     private static File exportPrivateKeyToPemFile(PrivateKey privateKey) throws IOException {
-        File keyFile = File.createTempFile("key-", ".key");
+        File keyFile = Files.createTempFile("key-", ".key").toFile();
         try (JcaPEMWriter pemWriter = new JcaPEMWriter(new FileWriter(keyFile, UTF_8))) {
             pemWriter.writeObject(privateKey);
             pemWriter.flush();
@@ -158,7 +159,7 @@ private static File exportPrivateKeyToPemFile(PrivateKey privateKey) throws IOEx
     }
 
     private static File exportCertsToPemFile(SystemTestCertAndKey... certs) throws IOException {
-        File certFile = File.createTempFile("crt-", ".crt");
+        File certFile = Files.createTempFile("crt-", ".crt").toFile();
         try (JcaPEMWriter pemWriter = new JcaPEMWriter(new FileWriter(certFile, UTF_8))) {
             for (SystemTestCertAndKey certAndKey : certs) {
                 pemWriter.writeObject(certAndKey.getCertificate());

File: systemtest/src/main/java/io/strimzi/systemtest/utils/FileUtils.java
Patch:
@@ -75,7 +75,7 @@ public static File downloadAndUnzip(String url) throws IOException {
 
     @SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE")
     public static File downloadYaml(String url) throws IOException {
-        File yamlFile = File.createTempFile("temp-file", ".yaml");
+        File yamlFile = Files.createTempFile("temp-file", ".yaml").toFile();
 
         try (InputStream bais = (InputStream) URI.create(url).toURL().openConnection().getContent();
              BufferedReader br = new BufferedReader(new InputStreamReader(bais, StandardCharsets.UTF_8));
@@ -101,7 +101,7 @@ public static File downloadYaml(String url) throws IOException {
 
     public static File updateNamespaceOfYamlFile(String pathToOrigin, String namespace) throws IOException {
         byte[] encoded;
-        File yamlFile = File.createTempFile("temp-file", ".yaml");
+        File yamlFile = Files.createTempFile("temp-file", ".yaml").toFile();
 
         try (OutputStreamWriter osw = new OutputStreamWriter(new FileOutputStream(yamlFile), StandardCharsets.UTF_8)) {
             encoded = Files.readAllBytes(Paths.get(pathToOrigin));

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorReplicationIT.java
Patch:
@@ -21,6 +21,7 @@
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.PrintStream;
+import java.nio.file.Files;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.ExecutionException;
@@ -99,7 +100,7 @@ public void testKafkaTopicModifiedChangedReplication() throws Exception {
         operation().inNamespace(NAMESPACE).withName(resourceName).patch(changedTopic);
         assertStatusReady(topicName);
 
-        File file = File.createTempFile(getClass().getSimpleName(), ".json");
+        File file = Files.createTempFile(getClass().getSimpleName(), ".json").toFile();
         ObjectMapper mapper = new ObjectMapper();
         ObjectNode root = new ObjectNode(mapper.getNodeFactory());
         root.put("version", 1)

File: api/src/main/java/io/strimzi/api/kafka/model/listener/arraylistener/GenericKafkaListenerConfiguration.java
Patch:
@@ -148,7 +148,7 @@ public void setFinalizers(List<String> finalizers) {
             "If set to `true`, the generated addresses will contain the service DNS domain suffix " +
             "(by default `.cluster.local`, can be configured using environment variable `KUBERNETES_SERVICE_DNS_DOMAIN`). " +
             "Defaults to `false`." +
-            "This field can be used only with `internal` type listener.")
+            "This field can be used only with `internal` and `cluster-ip` type listeners.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     public Boolean getUseServiceDnsDomain() {
         return useServiceDnsDomain;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ListenersValidator.java
Patch:
@@ -193,9 +193,9 @@ private static void validateIngress(Set<String> errors, int replicas, GenericKaf
      * @param listener  Listener which needs to be validated
      */
     private static void validateServiceDnsDomain(Set<String> errors, GenericKafkaListener listener) {
-        if (KafkaListenerType.INTERNAL != listener.getType()
+        if (!(KafkaListenerType.INTERNAL.equals(listener.getType()) || KafkaListenerType.CLUSTER_IP.equals(listener.getType()))
                 && listener.getConfiguration().getUseServiceDnsDomain() != null)    {
-            errors.add("listener " + listener.getName() + " cannot configure useServiceDnsDomain because it is not internal listener");
+            errors.add("listener " + listener.getName() + " cannot configure useServiceDnsDomain because it is not internal or cluster-ip listener");
         }
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/OpenTelemetryST.java
Patch:
@@ -8,7 +8,6 @@
 import io.strimzi.api.kafka.model.tracing.Tracing;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelSuite;
-import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
@@ -26,7 +25,6 @@
 @Tag(TRACING)
 @Tag(INTERNAL_CLIENTS_USED)
 @ParallelSuite
-@Disabled("because of https://github.com/strimzi/strimzi-kafka-operator/issues/7622")
 public class OpenTelemetryST extends TracingAbstractST {
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/OpenTracingST.java
Patch:
@@ -8,7 +8,6 @@
 import io.strimzi.api.kafka.model.tracing.Tracing;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelSuite;
-import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
@@ -32,7 +31,6 @@
 @Tag(TRACING)
 @Tag(INTERNAL_CLIENTS_USED)
 @ParallelSuite
-@Disabled("because of https://github.com/strimzi/strimzi-kafka-operator/issues/7622")
 public class OpenTracingST extends TracingAbstractST {
     @Override
     protected Tracing tracing() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceStateMachineTest.java
Patch:
@@ -339,7 +339,7 @@ public void testNewBadGoalsErrorWithSkipHGCheck(Vertx vertx, VertxTestContext co
                 .withSkipHardGoalCheck(true)
                 .build();
         kcRebalance = createKafkaRebalance(KafkaRebalanceState.New, null, null, rebalanceSpec, null, false);
-        this.krNewBadGoalsError(vertx, context, CruiseControlEndpoints.ADD_BROKER, kcRebalance);
+        this.krNewBadGoalsErrorWithSkipHGCheck(vertx, context, CruiseControlEndpoints.ADD_BROKER, kcRebalance);
 
         rebalanceSpec = new KafkaRebalanceSpecBuilder()
                 .withMode(KafkaRebalanceMode.REMOVE_BROKERS)
@@ -348,7 +348,7 @@ public void testNewBadGoalsErrorWithSkipHGCheck(Vertx vertx, VertxTestContext co
                 .withSkipHardGoalCheck(true)
                 .build();
         kcRebalance = createKafkaRebalance(KafkaRebalanceState.New, null, null, rebalanceSpec, null, false);
-        this.krNewBadGoalsError(vertx, context, CruiseControlEndpoints.REMOVE_BROKER, kcRebalance);
+        this.krNewBadGoalsErrorWithSkipHGCheck(vertx, context, CruiseControlEndpoints.REMOVE_BROKER, kcRebalance);
     }
 
     private void krNewBadGoalsErrorWithSkipHGCheck(Vertx vertx, VertxTestContext context, CruiseControlEndpoints endpoint, KafkaRebalance kcRebalance) throws IOException, URISyntaxException {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ListenersValidator.java
Patch:
@@ -222,7 +222,7 @@ private static void validateCreateBootstrapService(Set<String> errors, GenericKa
     private static void validateIpFamilyPolicy(Set<String> errors, GenericKafkaListener listener) {
         if (KafkaListenerType.INTERNAL == listener.getType()
                 && listener.getConfiguration().getIpFamilyPolicy() != null)    {
-            errors.add("listener " + listener.getName() + " cannot configure ipFamilyPolicy because it is not internal listener");
+            errors.add("listener " + listener.getName() + " cannot configure ipFamilyPolicy because it is internal listener");
         }
     }
 
@@ -235,7 +235,7 @@ private static void validateIpFamilyPolicy(Set<String> errors, GenericKafkaListe
     private static void validateIpFamilies(Set<String> errors, GenericKafkaListener listener) {
         if (KafkaListenerType.INTERNAL == listener.getType()
                 && listener.getConfiguration().getIpFamilies() != null)    {
-            errors.add("listener " + listener.getName() + " cannot configure ipFamilies because it is not internal listener");
+            errors.add("listener " + listener.getName() + " cannot configure ipFamilies because it is internal listener");
         }
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ListenersValidatorTest.java
Patch:
@@ -271,8 +271,8 @@ public void testInternalListener() {
                 "listener " + name + " cannot configure brokers[].nodePort because it is not NodePort based listener",
                 "listener " + name + " cannot configure brokers[].annotations because it is not LoadBalancer, NodePort, Route, or Ingress based listener",
                 "listener " + name + " cannot configure brokers[].labels because it is not LoadBalancer, NodePort, Route, or Ingress based listener",
-                "listener " + name + " cannot configure ipFamilyPolicy because it is not internal listener",
-                "listener " + name + " cannot configure ipFamilies because it is not internal listener"
+                "listener " + name + " cannot configure ipFamilyPolicy because it is internal listener",
+                "listener " + name + " cannot configure ipFamilies because it is internal listener"
         );
 
         assertThat(ListenersValidator.validateAndGetErrorMessages(3, listeners), containsInAnyOrder(expectedErrors.toArray()));

File: crd-generator/src/main/java/io/strimzi/crdgenerator/DocGenerator.java
Patch:
@@ -293,15 +293,15 @@ private void addTypesFromAlternatives(List<Property> alternatives, LinkedHashSet
     }
 
     private String getDeprecation(Property property, DeprecatedProperty deprecated) {
-        String msg = String.format("*The `%s` property has been deprecated",
+        String msg = String.format("**The `%s` property has been deprecated",
                 property.getName());
         if (!deprecated.movedToPath().isEmpty()) {
             msg += ", and should now be configured using `" + deprecated.movedToPath() + "`";
         }
         if (!deprecated.removalVersion().isEmpty()) {
             msg += ". The property " + property.getName() + " is removed in API version `" + deprecated.removalVersion() + "`";
         }
-        msg += ".* ";
+        msg += ".** ";
         if (!deprecated.description().isEmpty()) {
             msg += deprecated.description() + " ";
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterStatefulSetTest.java
Patch:
@@ -198,8 +198,6 @@ public void testGenerateStatefulSet() {
         checkStatefulSet(sts, KAFKA);
         checkOwnerReference(KC.createOwnerReference(), sts);
 
-        System.out.println(sts.getSpec().getTemplate().getSpec().getVolumes());
-
         // Check Volumes
         assertThat(sts.getSpec().getTemplate().getSpec().getVolumes().size(), is(6));
         assertThat(sts.getSpec().getTemplate().getSpec().getVolumes().get(0).getName(), is(AbstractModel.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME));
@@ -552,7 +550,8 @@ public void testSecurityContext() {
 
     @ParallelTest
     public void testDefaultSecurityContext() {
-        StatefulSet sts = KC.generateStatefulSet(true, null, null, null);
+        StatefulSet sts = KC.generateStatefulSet(false, null, null, null);
+        assertThat(sts.getSpec().getTemplate().getSpec().getSecurityContext(), is(notNullValue()));
         assertThat(sts.getSpec().getTemplate().getSpec().getSecurityContext().getFsGroup(), is(0L));
         assertThat(sts.getSpec().getTemplate().getSpec().getContainers().get(0).getSecurityContext(), is(nullValue()));
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/events/V1Beta1RestartEventPublisherTest.java
Patch:
@@ -21,7 +21,6 @@
 
 import java.time.Clock;
 import java.time.Instant;
-import java.time.ZoneId;
 
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.is;
@@ -62,7 +61,7 @@ void testPopulatesExpectedFields() {
                 .endMetadata()
                 .build();
 
-        Clock clock = Clock.fixed(Instant.parse("2020-10-11T00:00:00Z"), ZoneId.of("UTC"));
+        Clock clock = Clock.fixed(Instant.parse("2020-10-11T00:00:00Z"), Clock.systemUTC().getZone());
 
         V1Beta1RestartEventPublisher eventPublisher = new V1Beta1RestartEventPublisher(clock, client, "cluster-operator-id");
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/events/V1RestartEventPublisherTest.java
Patch:
@@ -21,7 +21,6 @@
 
 import java.time.Clock;
 import java.time.Instant;
-import java.time.ZoneId;
 
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.is;
@@ -62,7 +61,7 @@ void testPopulatesExpectedFields() {
                 .endMetadata()
                 .build();
 
-        Clock clock = Clock.fixed(Instant.parse("2020-10-11T00:00:00Z"), ZoneId.of("UTC"));
+        Clock clock = Clock.fixed(Instant.parse("2020-10-11T00:00:00Z"), Clock.systemUTC().getZone());
 
         V1RestartEventPublisher eventPublisher = new V1RestartEventPublisher(clock, client, "cluster-operator-id");
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsIsolatedST.java
Patch:
@@ -582,8 +582,8 @@ void testStrimziPodSetMetrics() {
             .collectMetricsFromPods();
 
         // check StrimziPodSet metrics in CO
-        assertCoMetricResources(StrimziPodSet.RESOURCE_KIND, clusterOperator.getDeploymentNamespace(), 2);
-        assertCoMetricResources(StrimziPodSet.RESOURCE_KIND, SECOND_NAMESPACE, 2);
+        assertCoMetricResources(StrimziPodSet.RESOURCE_KIND, clusterOperator.getDeploymentNamespace(), Environment.isKRaftModeEnabled() ? 1 : 2);
+        assertCoMetricResources(StrimziPodSet.RESOURCE_KIND, SECOND_NAMESPACE, Environment.isKRaftModeEnabled() ? 1 : 2);
 
         assertCoMetricNotNull("strimzi_reconciliations_duration_seconds_bucket", StrimziPodSet.RESOURCE_KIND, clusterOperatorMetricsData);
         assertCoMetricNotNull("strimzi_reconciliations_duration_seconds_count", StrimziPodSet.RESOURCE_KIND, clusterOperatorMetricsData);

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/KubeCmdClient.java
Patch:
@@ -31,6 +31,8 @@ public interface KubeCmdClient<K extends KubeCmdClient<K>> {
     /** Deletes the resources by resource name. */
     K deleteByName(String resourceType, String resourceName);
 
+    K deleteAllByResource(String resourceType);
+
     KubeCmdClient<K> namespace(String namespace);
 
     /** Returns namespace for cluster */

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/leaderelection/LeaderElectionManagerMockTest.java
Patch:
@@ -12,7 +12,9 @@
 import java.time.Duration;
 import java.util.concurrent.CountDownLatch;
 
+import static org.hamcrest.CoreMatchers.anyOf;
 import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.CoreMatchers.nullValue;
 import static org.hamcrest.MatcherAssert.assertThat;
 
 @EnableKubernetesMockClient(crud = true)
@@ -52,7 +54,7 @@ public void testLeaderElectionManager() throws InterruptedException {
         // Stop the second member => the leadership in the lease resource will stay as it was
         le2.stop();
         le2NotLeader.await();
-        assertThat(getLease().getSpec().getHolderIdentity(), is("le-2"));
+        assertThat(getLease().getSpec().getHolderIdentity(), anyOf(is("le-2"), nullValue()));
     }
 
     private LeaderElectionManager createLeaderElectionManager(String identity, Runnable startLeadershipCallback, Runnable stopLeadershipCallback)   {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/CustomMatchers.java
Patch:
@@ -26,7 +26,7 @@ private CustomMatchers() { }
      * @return a custom Matcher which iterates through entries and delegates matching to hasEntry
      */
     public static Matcher<Map<String, String>> hasEntries(Map<String, String> entries) {
-        return new TypeSafeDiagnosingMatcher<Map<String, String>>() {
+        return new TypeSafeDiagnosingMatcher<>() {
 
             @Override
             public void describeTo(final Description description) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/MainIT.java
Patch:
@@ -43,18 +43,18 @@ public static void after() {
     }
 
     @BeforeEach
-    private void createClient() {
+    public void createClient() {
         client = new KubernetesClientBuilder().build();
     }
 
     @AfterEach
-    private void closeClient() {
+    public void closeClient() {
         client.close();
     }
 
     @Test
     public void testCreateClusterRolesCreatesClusterRoles(VertxTestContext context) {
-        assertDoesNotThrow(() -> KubeCluster.bootstrap());
+        assertDoesNotThrow(KubeCluster::bootstrap);
         Map<String, String> envVars = new HashMap<>(6);
         envVars.put(ClusterOperatorConfig.STRIMZI_CREATE_CLUSTER_ROLES, "TRUE");
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_IMAGES, KafkaVersionTestUtils.getKafkaImagesEnvVarString());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractModelTest.java
Patch:
@@ -37,7 +37,7 @@
 public class AbstractModelTest {
 
     // Implement AbstractModel to test the abstract class
-    private class Model extends AbstractModel   {
+    private static class Model extends AbstractModel   {
         public Model(HasMetadata resource) {
             super(new Reconciliation("test", resource.getKind(), resource.getMetadata().getNamespace(), resource.getMetadata().getName()), resource, "model-app");
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CaRenewalTest.java
Patch:
@@ -215,9 +215,9 @@ public void renewalOfStatefulSetCertificatesDelayedRenewalOutsideWindow() throws
     }
 
     public static class MockedCa extends Ca {
+        private final AtomicInteger invocationCount = new AtomicInteger(0);
         private boolean isCertRenewed;
         private boolean isCertExpiring;
-        private final AtomicInteger invocationCount = new AtomicInteger(0);
 
         public MockedCa(Reconciliation reconciliation, CertManager certManager, PasswordGenerator passwordGenerator, String commonName, String caCertSecretName, Secret caCertSecret, String caKeySecretName, Secret caKeySecret, int validityDays, int renewalDays, boolean generateCa, CertificateExpirationPolicy policy) {
             super(reconciliation, certManager, passwordGenerator, commonName, caCertSecretName, caCertSecret, caKeySecretName, caKeySecret, validityDays, renewalDays, generateCa, policy);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.cluster.model;
 
-import com.fasterxml.jackson.core.JsonProcessingException;
 import io.fabric8.kubernetes.api.model.Affinity;
 import io.fabric8.kubernetes.api.model.AffinityBuilder;
 import io.fabric8.kubernetes.api.model.ConfigMapKeySelectorBuilder;
@@ -212,7 +211,7 @@ private static boolean isJBOD(Map<String, Object> brokerCapacity) {
     }
 
     @ParallelTest
-    public void testBrokerCapacities() throws JsonProcessingException {
+    public void testBrokerCapacities() {
         // Test user defined capacities
         String userDefinedCpuCapacity = "2575m";
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConfigurationTests.java
Patch:
@@ -99,9 +99,9 @@ public void validVersion() {
 
     @ParallelTest
     public void unsupportedVersion() {
-        RuntimeException exc = Assertions.assertThrows(RuntimeException.class, () -> {
-            KafkaConfiguration.readConfigModel(KafkaVersionTestUtils.getKafkaVersionLookup().version("2.6.0"));
-        });
+        RuntimeException exc = Assertions.assertThrows(RuntimeException.class, () ->
+            KafkaConfiguration.readConfigModel(KafkaVersionTestUtils.getKafkaVersionLookup().version("2.6.0"))
+        );
 
         assertThat(exc.getMessage(), containsString("Configuration model /kafka-2.6.0-config-model.json was not found"));
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaVersionTest.java
Patch:
@@ -37,9 +37,7 @@ public void parsingInvalidVersionTest() {
         assertThat(KafkaVersion.compareDottedIVVersions("2.7-IV1", kv.protocolVersion()), lessThan(0));
         assertThat(KafkaVersion.compareDottedIVVersions("2.9-IV1", kv.protocolVersion()), greaterThan(0));
 
-        assertThrows(NumberFormatException.class, () -> {
-            KafkaVersion.compareDottedIVVersions("wrong", kv.protocolVersion());
-        });
+        assertThrows(NumberFormatException.class, () -> KafkaVersion.compareDottedIVVersions("wrong", kv.protocolVersion()));
     }
 
     @ParallelTest

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/AbstractResourceStateMatchers.java
Patch:
@@ -94,7 +94,7 @@ public void describeTo(final Description description) {
         };
     }
 
-    public static Matcher<Condition> hasStateInCondition(KafkaRebalanceState state, Class reason, String message) {
+    public static Matcher<Condition> hasStateInCondition(KafkaRebalanceState state, Class<?> reason, String message) {
         return new TypeSafeDiagnosingMatcher<>() {
 
             @Override

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorNonParametrizedTest.java
Patch:
@@ -143,7 +143,7 @@ public void testCustomLabelsAndAnnotations(VertxTestContext context) {
 
         Checkpoint async = context.checkpoint();
 
-        op.new ReconciliationState(reconciliation, kafka).reconcileCas(() -> new Date())
+        op.new ReconciliationState(reconciliation, kafka).reconcileCas(Date::new)
                 .onComplete(context.succeeding(c -> context.verify(() -> {
                     assertThat(clusterCaCert.getAllValues(), hasSize(1));
                     assertThat(clusterCaKey.getAllValues(), hasSize(1));
@@ -228,7 +228,7 @@ public void testClusterCASecretsWithoutOwnerReference(VertxTestContext context)
 
         Checkpoint async = context.checkpoint();
 
-        op.new ReconciliationState(reconciliation, kafka).reconcileCas(() -> new Date())
+        op.new ReconciliationState(reconciliation, kafka).reconcileCas(Date::new)
                 .onComplete(context.succeeding(c -> context.verify(() -> {
                     assertThat(clusterCaCert.getAllValues(), hasSize(1));
                     assertThat(clusterCaKey.getAllValues(), hasSize(1));
@@ -307,7 +307,7 @@ public void testClientsCASecretsWithoutOwnerReference(VertxTestContext context)
 
         Checkpoint async = context.checkpoint();
 
-        op.new ReconciliationState(reconciliation, kafka).reconcileCas(() -> new Date())
+        op.new ReconciliationState(reconciliation, kafka).reconcileCas(Date::new)
                 .onComplete(context.succeeding(c -> context.verify(() -> {
                     assertThat(clusterCaCert.getAllValues(), hasSize(1));
                     assertThat(clusterCaKey.getAllValues(), hasSize(1));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectApiMockTest.java
Patch:
@@ -24,7 +24,7 @@
 @ExtendWith(VertxExtension.class)
 public class KafkaConnectApiMockTest {
     private static Vertx vertx;
-    private BackOff backOff = new BackOff(1L, 2, 3);
+    private final BackOff backOff = new BackOff(1L, 2, 3);
 
     @BeforeAll
     public static void before() {
@@ -89,7 +89,7 @@ public void testStatusWithBackOffOtherExceptionStillFails(VertxTestContext conte
             .onComplete(context.failing(res -> async.flag()));
     }
 
-    class MockKafkaConnectApi extends KafkaConnectApiImpl   {
+    static class MockKafkaConnectApi extends KafkaConnectApiImpl   {
         private final Queue<Future<Map<String, Object>>> statusResults;
 
         public MockKafkaConnectApi(Vertx vertx, Queue<Future<Map<String, Object>>> statusResults) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -1610,7 +1610,7 @@ private void assertValidationCondition(VertxTestContext context, KubernetesClien
         });
     }
 
-    private void assertState(VertxTestContext context, KubernetesClient kubernetesClient, String namespace, String resource, KafkaRebalanceState state, Class reason, String message) {
+    private void assertState(VertxTestContext context, KubernetesClient kubernetesClient, String namespace, String resource, KafkaRebalanceState state, Class<?> reason, String message) {
         context.verify(() -> {
             KafkaRebalance kafkaRebalance = Crds.kafkaRebalanceOperation(kubernetesClient).inNamespace(namespace).withName(resource).get();
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/StrimziPodSetControllerIT.java
Patch:
@@ -82,7 +82,7 @@ public static void beforeAll() {
         cluster = KubeClusterResource.getInstance();
         cluster.setNamespace(NAMESPACE);
 
-        assertDoesNotThrow(() -> KubeCluster.bootstrap(), "Could not bootstrap server");
+        assertDoesNotThrow(KubeCluster::bootstrap, "Could not bootstrap server");
 
         if (cluster.getNamespace() != null && System.getenv("SKIP_TEARDOWN") == null) {
             LOGGER.warn("Namespace {} is already created, going to delete it", NAMESPACE);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/TolerationsIT.java
Patch:
@@ -35,7 +35,7 @@
 public class TolerationsIT {
 
     protected KubeClusterResource cluster = KubeClusterResource.getInstance();
-    private String namespace = "kafka-it-2";
+    private final String namespace = "kafka-it-2";
 
     @BeforeEach
     public void beforeEach() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/StatefulSetRollingUpdateTest.java
Patch:
@@ -86,7 +86,7 @@ public void testNotNeedsRollingUpdateWhenReplicasDecrease() {
 
     @Test
     public void testNeedsRollingUpdateWhenLabelsRemoved() {
-        Map<String, String> labels = new HashMap(desiredSts.getMetadata().getLabels());
+        Map<String, String> labels = new HashMap<>(desiredSts.getMetadata().getLabels());
         labels.put("foo", "bar");
         currectSts.getMetadata().setLabels(labels);
         assertThat(StatefulSetOperator.needsRollingUpdate(Reconciliation.DUMMY_RECONCILIATION, createDiff()), is(true));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/MockCruiseControl.java
Patch:
@@ -128,7 +128,7 @@ private static JsonBody getJsonFromResource(String resource) throws URISyntaxExc
         Optional<String> json = Files.lines(Paths.get(jsonURI), UTF_8)
                 .reduce((x, y) -> x + y);
 
-        if (!json.isPresent()) {
+        if (json.isEmpty()) {
             throw new IOException("File " + resource + " from resources was empty");
         }
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/Main.java
Patch:
@@ -7,6 +7,7 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.operator.common.OperatorKubernetesClientBuilder;
+import io.strimzi.operator.common.ShutdownHook;
 import io.vertx.core.Vertx;
 
 import java.util.HashMap;
@@ -49,6 +50,7 @@ private void deploy(Config config) {
                         .setJvmMetricsEnabled(true)
                         .setEnabled(true));
         Vertx vertx = Vertx.vertx(options);
+        Runtime.getRuntime().addShutdownHook(new Thread(new ShutdownHook(vertx)));
 
         Session session = new Session(kubeClient, config);
         vertx.deployVerticle(session, ar -> {

File: user-operator/src/main/java/io/strimzi/operator/user/Main.java
Patch:
@@ -15,6 +15,7 @@
 import io.strimzi.operator.common.DefaultAdminClientProvider;
 import io.strimzi.operator.common.OperatorKubernetesClientBuilder;
 import io.strimzi.operator.common.Util;
+import io.strimzi.operator.common.ShutdownHook;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
 import io.strimzi.operator.common.operator.resource.SecretOperator;
 import io.strimzi.operator.user.operator.KafkaUserOperator;
@@ -58,6 +59,7 @@ public static void main(String[] args) {
                         .setJvmMetricsEnabled(true)
                         .setEnabled(true));
         Vertx vertx = Vertx.vertx(options);
+        Runtime.getRuntime().addShutdownHook(new Thread(new ShutdownHook(vertx)));
 
         KubernetesClient client = new OperatorKubernetesClientBuilder("strimzi-user-operator", strimziVersion).build();
         AdminClientProvider adminClientProvider = new DefaultAdminClientProvider();

File: topic-operator/src/main/java/io/strimzi/operator/topic/Main.java
Patch:
@@ -5,8 +5,8 @@
 package io.strimzi.operator.topic;
 
 import io.fabric8.kubernetes.client.KubernetesClient;
-import io.fabric8.kubernetes.client.KubernetesClientBuilder;
 import io.strimzi.api.kafka.Crds;
+import io.strimzi.operator.common.OperatorKubernetesClientBuilder;
 import io.vertx.core.Vertx;
 
 import java.util.HashMap;
@@ -40,7 +40,8 @@ public void run() {
     }
 
     private void deploy(Config config) {
-        KubernetesClient kubeClient = new KubernetesClientBuilder().build();
+        final String strimziVersion = Main.class.getPackage().getImplementationVersion();
+        KubernetesClient kubeClient = new OperatorKubernetesClientBuilder("strimzi-topic-operator", strimziVersion).build();
         Crds.registerCustomKinds();
         VertxOptions options = new VertxOptions().setMetricsOptions(
                 new MicrometerMetricsOptions()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialStatefulSetRollingUpdateMockTest.java
Patch:
@@ -16,7 +16,6 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
-import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
@@ -27,6 +26,7 @@
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.operator.MockCertManager;
+import io.strimzi.platform.KubernetesVersion;
 import io.strimzi.test.mockkube2.MockKube2;
 import io.vertx.core.Vertx;
 import io.vertx.junit5.Checkpoint;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectCluster.java
Patch:
@@ -58,8 +58,8 @@ public void startup() throws InterruptedException {
                 try {
                     ConnectDistributed connectDistributed = new ConnectDistributed();
                     Connect connect = connectDistributed.startConnect(workerProps);
-                    l.countDown();
                     connectInstances.add(connect);
+                    l.countDown();
                     connect.awaitStop();
                 } catch (ConnectException e)    {
                     startupException.set(e);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -353,7 +353,7 @@ public static String changeDeploymentConfiguration(File deploymentFile, String n
             imagePulPolicyEnvVar.put("name", "STRIMZI_IMAGE_PULL_POLICY");
             imagePulPolicyEnvVar.put("value", Environment.COMPONENTS_IMAGE_PULL_POLICY);
 
-            if (!strimziFeatureGatesValue.isEmpty()) {
+            if (strimziFeatureGatesValue != null && !strimziFeatureGatesValue.isEmpty()) {
                 ObjectNode strimziFeatureGates =  new ObjectMapper().createObjectNode();
                 strimziFeatureGates.put("name", "STRIMZI_FEATURE_GATES");
                 strimziFeatureGates.put("value", strimziFeatureGatesValue);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -112,6 +112,7 @@ public ConnectorState(boolean paused, JsonObject config) {
 
     private Vertx vertx;
     // Injected by Fabric8 Mock Kubernetes Server
+    @SuppressWarnings("unused")
     private KubernetesClient client;
     private MockKube2 mockKube;
     private Watch connectWatch;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageMockTest.java
Patch:
@@ -65,6 +65,7 @@ public class JbodStorageMockTest {
     private static Vertx vertx;
     private Kafka kafka;
     // Injected by Fabric8 Mock Kubernetes Server
+    @SuppressWarnings("unused")
     private KubernetesClient client;
     private MockKube2 mockKube;
     private KafkaAssemblyOperator operator;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorCustomCertMockTest.java
Patch:
@@ -86,6 +86,7 @@ public class KafkaAssemblyOperatorCustomCertMockTest {
     private KafkaAssemblyOperator operator;
 
     // Injected by Fabric8 Mock Kubernetes Server
+    @SuppressWarnings("unused")
     private KubernetesClient client;
     private MockKube2 mockKube;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -109,6 +109,7 @@ public class KafkaAssemblyOperatorMockTest {
     private ResourceRequirements resources;
 
     // Injected by Fabric8 Mock Kubernetes Server
+    @SuppressWarnings("unused")
     private KubernetesClient client;
     private MockKube2 mockKube;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -72,6 +72,7 @@ public class KafkaConnectAssemblyOperatorMockTest {
     private final int replicas = 3;
 
     // Injected by Fabric8 Mock Kubernetes Server
+    @SuppressWarnings("unused")
     private KubernetesClient client;
     private MockKube2 mockKube;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -72,6 +72,7 @@ public class KafkaMirrorMaker2AssemblyOperatorMockTest {
     private final int replicas = 3;
 
     // Injected by Fabric8 Mock Kubernetes Server
+    @SuppressWarnings("unused")
     private KubernetesClient client;
     private MockKube2 mockKube;
 

File: mockkube/src/test/java/io/strimzi/test/mockkube2/MockKube2ControllersTest.java
Patch:
@@ -40,6 +40,7 @@ public class MockKube2ControllersTest {
     private final static String NAMESPACE = "my-namespace";
 
     // Injected by Fabric8 Mock Kubernetes Server
+    @SuppressWarnings("unused")
     private KubernetesClient client;
     private MockKube2 mockKube;
 

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorMockIT.java
Patch:
@@ -55,6 +55,7 @@ public class TopicOperatorMockIT {
     private static final String NAMESPACE = "my-namespace";
 
     // Injected by Fabric8 Mock Kubernetes Server
+    @SuppressWarnings("unused")
     private KubernetesClient client;
     private MockKube2 mockKube;
     private Session session;
@@ -175,12 +176,12 @@ public void tearDown(VertxTestContext context) {
     }
 
     private void createInKube(KafkaTopic topic) {
-        Crds.topicOperation(client).create(topic);
+        Crds.topicOperation(client).resource(topic).create();
     }
 
     private void updateInKube(KafkaTopic topic) {
         LOGGER.info("Updating topic {} in kube", topic.getMetadata().getName());
-        Crds.topicOperation(client).withName(topic.getMetadata().getName()).patch(topic);
+        Crds.topicOperation(client).resource(topic).replace();
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -101,7 +101,6 @@
 import java.io.IOException;
 import java.security.cert.CertificateParsingException;
 import java.security.cert.X509Certificate;
-import java.time.ZoneId;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
@@ -175,8 +174,6 @@ public class KafkaClusterTest {
 
     private final KafkaCluster kc = KafkaCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kafkaAssembly, VERSIONS);
 
-    private static final ZoneId UTC = ZoneId.of("UTC");
-
     private void checkOwnerReference(OwnerReference ownerRef, HasMetadata resource)  {
         assertThat(resource.getMetadata().getOwnerReferences().size(), is(1));
         assertThat(resource.getMetadata().getOwnerReferences().get(0), is(ownerRef));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -183,7 +183,7 @@ public void setup(VertxTestContext testContext) {
         Checkpoint async = testContext.checkpoint();
         // Fail test if watcher closes for any reason
         kafkaConnectOperator.createWatch(NAMESPACE, e -> testContext.failNow(e))
-            .onComplete(testContext.succeeding())
+            .onComplete(testContext.succeedingThenComplete())
             .compose(watch -> {
                 connectWatch = watch;
                 return AbstractConnectOperator.createConnectorWatch(kafkaConnectOperator, NAMESPACE, null);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -117,7 +117,7 @@ private Future<Void> createConnectCluster(VertxTestContext context, KafkaConnect
         ClusterOperatorConfig config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS);
         this.kco = new KafkaConnectAssemblyOperator(vertx, pfa, supplier, config, foo -> kafkaConnectApi);
 
-        Promise created = Promise.promise();
+        Promise<Void> created = Promise.promise();
 
         LOGGER.info("Reconciling initially -> create");
         kco.reconcile(new Reconciliation("test-trigger", KafkaConnect.RESOURCE_KIND, NAMESPACE, CLUSTER_NAME))
@@ -153,7 +153,7 @@ public void testReconcileCreateAndUpdate(VertxTestContext context) {
 
         Checkpoint async = context.checkpoint();
         createConnectCluster(context, mock, false)
-            .onComplete(context.succeeding())
+            .onComplete(context.succeedingThenComplete())
             .compose(v -> {
                 LOGGER.info("Reconciling again -> update");
                 return kco.reconcile(new Reconciliation("test-trigger", KafkaConnect.RESOURCE_KIND, NAMESPACE, CLUSTER_NAME));
@@ -181,7 +181,7 @@ public void testPauseReconcileUnpause(VertxTestContext context) {
 
         Checkpoint async = context.checkpoint();
         createConnectCluster(context, mock, true)
-                .onComplete(context.succeeding())
+                .onComplete(context.succeedingThenComplete())
                 .compose(v -> {
                     LOGGER.info("Reconciling again -> update");
                     return kco.reconcile(new Reconciliation("test-trigger", KafkaConnect.RESOURCE_KIND, NAMESPACE, CLUSTER_NAME));

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicStoreTestBase.java
Patch:
@@ -41,7 +41,7 @@ public void testCrud(VertxTestContext context) {
 
         // Create the topic
         store.create(topic)
-            .onComplete(context.succeeding())
+            .onComplete(context.succeedingThenComplete())
 
             // Read the topic
             .compose(v -> store.read(new TopicName(topicName)))
@@ -68,7 +68,7 @@ public void testCrud(VertxTestContext context) {
         failedCreateCompleted.future()
                 // update my_topic
                 .compose(v -> store.update(updatedTopic))
-            .onComplete(context.succeeding())
+            .onComplete(context.succeedingThenComplete())
 
             // re-read it and assert equal
             .compose(v -> store.read(new TopicName(topicName)))
@@ -82,7 +82,7 @@ public void testCrud(VertxTestContext context) {
 
                 // delete it
                 .compose(v -> store.delete(updatedTopic.getTopicName()))
-                .onComplete(context.succeeding())
+                .onComplete(context.succeedingThenComplete())
 
                 // assert we can't read it again
                 .compose(v -> store.read(new TopicName(topicName)))

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractWatchableStatusedResourceOperator.java
Patch:
@@ -27,9 +27,6 @@ public abstract class AbstractWatchableStatusedResourceOperator<
         L extends KubernetesResourceList<T>,
         R extends Resource<T>>
         extends AbstractWatchableResourceOperator<C, T, L, R> {
-
-    public final static String ANY_NAMESPACE = "*";
-
     /**
      * Constructor.
      *

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ResourceSupport.java
Patch:
@@ -29,7 +29,7 @@
 
 public class ResourceSupport {
     public static final long DEFAULT_TIMEOUT_MS = 300_000;
-    protected static final ReconciliationLogger LOGGER = ReconciliationLogger.create(ResourceSupport.class);
+    private static final ReconciliationLogger LOGGER = ReconciliationLogger.create(ResourceSupport.class);
 
     private final Vertx vertx;
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/StrimziPodSetOperator.java
Patch:
@@ -8,16 +8,13 @@
 import io.strimzi.api.kafka.StrimziPodSetList;
 import io.strimzi.api.kafka.model.StrimziPodSet;
 import io.strimzi.operator.common.Reconciliation;
-import io.strimzi.operator.common.ReconciliationLogger;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
 
 /**
  * Operator for {@code StrimziPodSet}s
  */
 public class StrimziPodSetOperator extends CrdOperator<KubernetesClient, StrimziPodSet, StrimziPodSetList> {
-    protected static final ReconciliationLogger LOGGER = ReconciliationLogger.create(StrimziPodSetOperator.class.getName());
-
     protected final long operationTimeoutMs;
 
     /**

File: topic-operator/src/test/java/io/strimzi/operator/topic/KafkaStreamsTopicStoreIT.java
Patch:
@@ -19,7 +19,7 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.BeforeEach;
 
-public class KafkaStreamsTopicStoreTest extends TopicStoreTestBase {
+public class KafkaStreamsTopicStoreIT extends TopicStoreTestBase {
     private static final Map<String, String> MANDATORY_CONFIG;
     private static StrimziKafkaContainer kafkaContainer;
 

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorMockIT.java
Patch:
@@ -50,8 +50,8 @@
 
 @EnableKubernetesMockClient(crud = true)
 @ExtendWith(VertxExtension.class)
-public class TopicOperatorMockTest {
-    private static final Logger LOGGER = LogManager.getLogger(TopicOperatorMockTest.class);
+public class TopicOperatorMockIT {
+    private static final Logger LOGGER = LogManager.getLogger(TopicOperatorMockIT.class);
     private static final String NAMESPACE = "my-namespace";
 
     // Injected by Fabric8 Mock Kubernetes Server

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicStoreUpgradeIT.java
Patch:
@@ -33,7 +33,7 @@
 import static org.junit.jupiter.api.Assertions.assertNotNull;
 
 @ExtendWith(VertxExtension.class)
-public class TopicStoreUpgradeTest {
+public class TopicStoreUpgradeIT {
 
     private Map<String, String> mandatoryConfig;
     private StrimziKafkaCluster cluster;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/ZooKeeperReconciler.java
Patch:
@@ -743,9 +743,9 @@ private Future<Void> scaleDownStatefulSetOrPodSet(int desiredScale)   {
      */
     protected Future<Void> rollingUpdate() {
         if (featureGates.useStrimziPodSetsEnabled())   {
-            return maybeRollZooKeeper(pod -> ReconcilerUtils.reasonsToRestartPod(reconciliation, podSetDiff.resource(), pod, fsResizingRestartRequest, existingCertsChanged, clusterCa));
+            return maybeRollZooKeeper(pod -> ReconcilerUtils.reasonsToRestartPod(reconciliation, podSetDiff.resource(), pod, fsResizingRestartRequest, existingCertsChanged, clusterCa).getAllReasonNotes());
         } else {
-            return maybeRollZooKeeper(pod -> ReconcilerUtils.reasonsToRestartPod(reconciliation, statefulSetDiff.resource(), pod, fsResizingRestartRequest, existingCertsChanged, clusterCa));
+            return maybeRollZooKeeper(pod -> ReconcilerUtils.reasonsToRestartPod(reconciliation, statefulSetDiff.resource(), pod, fsResizingRestartRequest, existingCertsChanged, clusterCa).getAllReasonNotes());
         }
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
Patch:
@@ -89,7 +89,8 @@ public void testReconciliationInterval() {
                 20_000,
                 10,
                 false,
-                1024);
+                1024,
+                "operator_name");
 
         assertThat(config.getNamespaces(), is(singleton("namespace")));
         assertThat(config.getReconciliationIntervalMs(), is(60_000L));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CaRenewalTest.java
Patch:
@@ -215,10 +215,10 @@ public void renewalOfStatefulSetCertificatesDelayedRenewalOutsideWindow() throws
         assertThat(newCerts.get("pod2").storePassword(), is("old-password"));
     }
 
-    public class MockedCa extends Ca {
+    public static class MockedCa extends Ca {
         private boolean isCertRenewed;
         private boolean isCertExpiring;
-        private AtomicInteger invocationCount = new AtomicInteger(0);
+        private final AtomicInteger invocationCount = new AtomicInteger(0);
 
         public MockedCa(Reconciliation reconciliation, CertManager certManager, PasswordGenerator passwordGenerator, String commonName, String caCertSecretName, Secret caCertSecret, String caKeySecretName, Secret caKeySecret, int validityDays, int renewalDays, boolean generateCa, CertificateExpirationPolicy policy) {
             super(reconciliation, certManager, passwordGenerator, commonName, caCertSecretName, caCertSecret, caKeySecretName, caKeySecret, validityDays, renewalDays, generateCa, policy);
@@ -246,7 +246,7 @@ public X509Certificate getAsX509Certificate(Secret secret, String key)    {
 
         @Override
         protected CertAndKey generateSignedCert(Subject subject,
-                                                File csrFile, File keyFile, File certFile, File keyStoreFile) throws IOException {
+                                                File csrFile, File keyFile, File certFile, File keyStoreFile) {
             int index = invocationCount.getAndIncrement();
 
             return new CertAndKey(

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -154,7 +154,6 @@ public void setup(VertxTestContext testContext) {
         mockKube.start();
 
         PlatformFeaturesAvailability pfa = new PlatformFeaturesAvailability(false, KubernetesVersion.V1_18);
-
         setupMockConnectAPI();
 
         metricsProvider = ResourceUtils.metricsProvider();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorNonParametrizedTest.java
Patch:
@@ -400,7 +400,8 @@ public void testSelectorLabels(VertxTestContext context) {
                 10_000,
                 30,
                 false,
-                1024);
+                1024,
+                "cluster-operator-name");
 
         KafkaAssemblyOperator op = new KafkaAssemblyOperator(vertx, new PlatformFeaturesAvailability(false, KubernetesVersion.V1_19), certManager, passwordGenerator,
                 supplier, config);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -138,7 +138,8 @@ public void test(VertxTestContext context) {
                 new DefaultAdminClientProvider(),
                 new DefaultZookeeperScalerProvider(),
                 metrics,
-                pfa, 10_000);
+                pfa, 10_000
+        );
 
         KafkaConnectAssemblyOperator operator = new KafkaConnectAssemblyOperator(vertx, pfa, ros,
                 ClusterOperatorConfig.fromMap(Collections.emptyMap(), KafkaVersionTestUtils.getKafkaVersionLookup()),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -1282,7 +1282,8 @@ public void testKafkaClusterNotMatchingLabelSelector(VertxTestContext context) {
                 10_000,
                 30,
                 false,
-                1024);
+                1024,
+                "cluster-operator-name");
 
         kcrao = new KafkaRebalanceAssemblyOperator(Vertx.vertx(), supplier, config);
 

File: test/src/main/java/io/strimzi/test/k8s/KubeClusterResource.java
Patch:
@@ -335,7 +335,7 @@ public String defaultNamespace() {
         return cmdClient().defaultNamespace();
     }
 
-    public KubeCmdClient cmdClient() {
+    public KubeCmdClient<?> cmdClient() {
         if (cmdClient == null) {
             cmdClient = cluster().defaultCmdClient();
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperConfiguration.java
Patch:
@@ -26,11 +26,12 @@ public class ZookeeperConfiguration extends AbstractConfiguration {
         FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(ZookeeperClusterSpec.FORBIDDEN_PREFIXES);
         FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(ZookeeperClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
 
-        Map<String, String> config = new HashMap<>(4);
+        Map<String, String> config = new HashMap<>(5);
         config.put("tickTime", "2000");
         config.put("initLimit", "5");
         config.put("syncLimit", "2");
         config.put("autopurge.purgeInterval", "1");
+        config.put("admin.enableServer", "false");
         DEFAULTS = Collections.unmodifiableMap(config);
     }
 

File: api/src/test/java/io/strimzi/api/kafka/model/AbstractCrdTest.java
Patch:
@@ -17,11 +17,10 @@
 public abstract class AbstractCrdTest<R extends CustomResource> {
 
     private final Class<R> crdClass;
-    private String kind;
 
     protected AbstractCrdTest(Class<R> crdClass) {
         this.crdClass = crdClass;
-        assertDoesNotThrow(() -> kind = crdClass.newInstance().getKind());
+        assertDoesNotThrow(() -> crdClass.getDeclaredConstructor().newInstance().getKind());
     }
 
     protected void assertDesiredResource(R actual, String expectedResource) {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorTest.java
Patch:
@@ -75,7 +75,7 @@ protected Kafka resource() {
     @Override
     protected Kafka modifiedResource() {
         return new KafkaBuilder(resource())
-                .editSpec()
+                .editOrNewSpec()
                     .withNewEntityOperator()
                         .withNewTopicOperator()
                         .endTopicOperator()
@@ -100,7 +100,7 @@ protected CrdOperator createResourceOperations(Vertx vertx, KubernetesClient moc
     public void testUpdateStatusAsync(VertxTestContext context) throws IOException {
         Kafka resource = resource();
         Resource mockResource = mock(resourceType());
-        when(mockResource.updateStatus(any())).thenReturn(resource);
+        when(mockResource.replaceStatus(any())).thenReturn(resource);
 
         NonNamespaceOperation mockNameable = mock(NonNamespaceOperation.class);
         when(mockNameable.withName(matches(resource.getMetadata().getName()))).thenReturn(mockResource);

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -206,7 +206,7 @@ public class Environment {
     public static final String TEST_HTTP_PRODUCER_IMAGE = getOrDefault(TEST_HTTP_PRODUCER_IMAGE_ENV, TEST_HTTP_PRODUCER_IMAGE_DEFAULT);
     public static final String TEST_HTTP_CONSUMER_IMAGE = getOrDefault(TEST_HTTP_CONSUMER_IMAGE_ENV, TEST_HTTP_CONSUMER_IMAGE_DEFAULT);
 
-    private static final String SCRAPER_IMAGE_DEFAULT = STRIMZI_REGISTRY_DEFAULT + "/" + STRIMZI_ORG_DEFAULT + "/kafka:" + STRIMZI_TAG + "-kafka-" + ST_KAFKA_VERSION;
+    private static final String SCRAPER_IMAGE_DEFAULT = STRIMZI_REGISTRY + "/" + STRIMZI_ORG + "/kafka:" + STRIMZI_TAG + "-kafka-" + ST_KAFKA_VERSION;
     public static final String SCRAPER_IMAGE = getOrDefault(SCRAPER_IMAGE_ENV, SCRAPER_IMAGE_DEFAULT);
 
     // variables for kafka bridge image

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/Quantities.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.operator.cluster.operator.resource;
 
-class Quantities {
+public class Quantities {
     private Quantities() {
 
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ListenersValidator.java
Patch:
@@ -340,6 +340,7 @@ private static void validateBootstrapLoadBalancerIp(Set<String> errors, GenericK
      */
     private static void validateBootstrapNodePort(Set<String> errors, GenericKafkaListener listener) {
         if (!KafkaListenerType.NODEPORT.equals(listener.getType())
+                && !KafkaListenerType.LOADBALANCER.equals(listener.getType())
                 && listener.getConfiguration().getBootstrap().getNodePort() != null)    {
             errors.add("listener " + listener.getName() + " cannot configure bootstrap.nodePort because it is not NodePort based listener");
         }
@@ -406,6 +407,7 @@ private static void validateBrokerLoadBalancerIp(Set<String> errors, GenericKafk
      */
     private static void validateBrokerNodePort(Set<String> errors, GenericKafkaListener listener, GenericKafkaListenerConfigurationBroker broker) {
         if (!KafkaListenerType.NODEPORT.equals(listener.getType())
+                && !KafkaListenerType.LOADBALANCER.equals(listener.getType())
                 && broker.getNodePort() != null)    {
             errors.add("listener " + listener.getName() + " cannot configure brokers[].nodePort because it is not NodePort based listener");
         }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -160,7 +160,7 @@ public final <T extends HasMetadata> void createResource(ExtensionContext testCo
             if (Environment.isKRaftModeEnabled()) {
                 if (Objects.equals(resource.getKind(), Kafka.RESOURCE_KIND)) {
                     // Remove TO when KRaft mode is enabled, because it is not supported
-                    ((Kafka) resource).getSpec().setEntityOperator(null);
+                    ((Kafka) resource).getSpec().getEntityOperator().setTopicOperator(null);
                 }
                 if (Objects.equals(resource.getKind(), KafkaTopic.RESOURCE_KIND)) {
                     // Do not create KafkaTopic when KRaft is enabled

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -53,7 +53,7 @@
 @Tag(BRIDGE)
 @Tag(NODEPORT_SUPPORTED)
 @Tag(EXTERNAL_CLIENTS_USED)
-@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
+@KRaftNotSupported("Scram-sha is not supported by KRaft mode and is used in this test class")
 @ParallelSuite
 public class HttpBridgeKafkaExternalListenersST extends AbstractST {
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -12,7 +12,6 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.BridgeClients;
@@ -44,7 +43,6 @@
 @Tag(BRIDGE)
 @Tag(ACCEPTANCE)
 @Tag(INTERNAL_CLIENTS_USED)
-@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
 @ParallelSuite
 class HttpBridgeTlsST extends AbstractST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeTlsST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfST.java
Patch:
@@ -13,7 +13,6 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.annotations.IsolatedTest;
-import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
@@ -249,7 +248,6 @@ void testUpdateToExternalListenerCausesRollingRestart(ExtensionContext extension
     @Tag(NODEPORT_SUPPORTED)
     @Tag(EXTERNAL_CLIENTS_USED)
     @Tag(ROLLING_UPDATE)
-    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
     void testUpdateToExternalListenerCausesRollingRestartUsingExternalClients(ExtensionContext extensionContext) {
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java
Patch:
@@ -12,7 +12,6 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.annotations.IsolatedTest;
@@ -48,7 +47,6 @@
 
 @Tag(REGRESSION)
 @ParallelSuite
-@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
 public class MultipleListenersST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerIsolatedST.java
Patch:
@@ -153,7 +153,6 @@ void testMirrorMaker(ExtensionContext extensionContext) {
      */
     @ParallelNamespaceTest
     @Tag(ACCEPTANCE)
-    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
     @SuppressWarnings({"checkstyle:MethodLength"})
     void testMirrorMakerTlsAuthenticated(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, clusterOperator.getDeploymentNamespace());
@@ -266,7 +265,7 @@ void testMirrorMakerTlsAuthenticated(ExtensionContext extensionContext) {
      * Test mirroring messages by Mirror Maker over tls transport using scram-sha auth
      */
     @ParallelNamespaceTest
-    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
+    @KRaftNotSupported("Scram-sha is not supported by KRaft mode and is used in this test case")
     @SuppressWarnings("checkstyle:methodlength")
     void testMirrorMakerTlsScramSha(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, clusterOperator.getDeploymentNamespace());

File: systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java
Patch:
@@ -156,7 +156,6 @@ void testKafkaStatus(ExtensionContext extensionContext) {
     }
 
     @ParallelTest
-    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
     void testKafkaUserStatus(ExtensionContext extensionContext) {
         String userName = mapWithTestUsers.get(extensionContext.getDisplayName());
 
@@ -171,7 +170,6 @@ void testKafkaUserStatus(ExtensionContext extensionContext) {
     }
 
     @ParallelTest
-    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
     void testKafkaUserStatusNotReady(ExtensionContext extensionContext) {
         // Simulate NotReady state with userName longer than 64 characters
         String userName = "sasl-use-rabcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef";

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/ThrottlingQuotaST.java
Patch:
@@ -41,7 +41,7 @@
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
 @ParallelSuite
-@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
+@KRaftNotSupported("Scram-sha is not supported by KRaft mode and is used in this test case")
 public class ThrottlingQuotaST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(ThrottlingQuotaST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesIsolatedST.java
Patch:
@@ -66,7 +66,7 @@ public class NetworkPoliciesIsolatedST extends AbstractST {
 
     @IsolatedTest("Specific cluster operator for test case")
     @Tag(INTERNAL_CLIENTS_USED)
-    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
+    @KRaftNotSupported("Scram-sha is not supported by KRaft mode and is used in this test case")
     void testNetworkPoliciesWithPlainListener(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, clusterOperator.getDeploymentNamespace());
 
@@ -165,7 +165,7 @@ void testNetworkPoliciesWithPlainListener(ExtensionContext extensionContext) {
 
     @IsolatedTest("Specific cluster operator for test case")
     @Tag(INTERNAL_CLIENTS_USED)
-    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
+    @KRaftNotSupported("Scram-sha is not supported by KRaft mode and is used in this test case")
     void testNetworkPoliciesWithTlsListener(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, clusterOperator.getDeploymentNamespace());
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/OpaIntegrationST.java
Patch:
@@ -11,7 +11,6 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
@@ -39,7 +38,6 @@
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
 @ParallelSuite
-@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
 public class OpaIntegrationST extends AbstractST {
     private static final Logger LOGGER = LogManager.getLogger(OpaIntegrationST.class);
     private static final String OPA_SUPERUSER = "arnost";

File: systemtest/src/test/java/io/strimzi/systemtest/security/custom/CustomAuthorizerST.java
Patch:
@@ -36,7 +36,7 @@
 
 @Tag(REGRESSION)
 @ParallelSuite
-@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
+@KRaftNotSupported("Custom Authorizer is not supported by KRaft mode and is used in this test case")
 public class CustomAuthorizerST extends AbstractST {
     static final String CLUSTER_NAME = "custom-authorizer";
     static final String ADMIN = "sre-admin";

File: systemtest/src/test/java/io/strimzi/systemtest/security/custom/CustomCaST.java
Patch:
@@ -12,7 +12,6 @@
 import io.strimzi.operator.cluster.model.Ca;
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.systemtest.AbstractST;
-import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
@@ -59,7 +58,6 @@
  * @see <a href="https://strimzi.io/docs/operators/in-development/configuring.html#proc-replacing-your-own-private-keys-str">Replacing your own private keys</a>
  */
 @ParallelSuite
-@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
 public class CustomCaST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(CustomCaST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationIsolatedST.java
Patch:
@@ -62,7 +62,7 @@
 @Tag(INTERNAL_CLIENTS_USED)
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @IsolatedSuite
-@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
+@KRaftNotSupported("OAuth is not supported by KRaft mode and is used in this test case")
 public class OauthAuthorizationIsolatedST extends OauthAbstractST {
     protected static final Logger LOGGER = LogManager.getLogger(OauthAuthorizationIsolatedST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsIsolatedST.java
Patch:
@@ -67,7 +67,7 @@
 @Tag(REGRESSION)
 @Tag(ACCEPTANCE)
 @IsolatedSuite
-@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
+@KRaftNotSupported("OAuth is not supported by KRaft mode and is used in this test case")
 public class OauthTlsIsolatedST extends OauthAbstractST {
     protected static final Logger LOGGER = LogManager.getLogger(OauthTlsIsolatedST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceIsolatedST.java
Patch:
@@ -116,7 +116,6 @@ void testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO(ExtensionCont
     }
 
     @IsolatedTest
-    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
     void testUOWatchingOtherNamespace(ExtensionContext extensionContext) {
         String previousNamespace = cluster.setNamespace(SECOND_NAMESPACE);
         LOGGER.info("Creating user in other namespace than CO and Kafka cluster with UO");
@@ -126,7 +125,6 @@ void testUOWatchingOtherNamespace(ExtensionContext extensionContext) {
     }
 
     @IsolatedTest
-    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
     void testUserInDifferentNamespace(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, SECOND_NAMESPACE);
         String startingNamespace = cluster.setNamespace(SECOND_NAMESPACE);

File: systemtest/src/main/java/io/strimzi/systemtest/templates/specific/ScraperTemplates.java
Patch:
@@ -46,7 +46,7 @@ public static DeploymentBuilder scraperPod(String namespaceName, String podName)
                         .withContainers(
                             new ContainerBuilder()
                                 .withName(podName)
-                                .withImage("registry.access.redhat.com/ubi8/openjdk-11:latest")
+                                .withImage(Environment.SCRAPER_IMAGE)
                                 .withCommand("sleep")
                                 .withArgs("infinity")
                                 .withImagePullPolicy(Environment.COMPONENTS_IMAGE_PULL_POLICY)

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -165,6 +165,7 @@ public interface Constants {
      * Feature gate related constants
      */
     String USE_STRIMZI_POD_SET = "+UseStrimziPodSets";
+    String USE_KRAFT_MODE = "+UseKRaft";
 
     /**
      * Default value which allows execution of tests with any tags

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaTemplates.java
Patch:
@@ -263,6 +263,7 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl
                 .endEntityOperator()
                 .endSpec();
         }
+
         return kb;
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -170,7 +170,6 @@ protected void assertExpectedJavaOpts(String namespaceName, String podName, Stri
 
     public Map<String, String> getImagesFromConfig(String namespaceName) {
         Map<String, String> images = new HashMap<>();
-        LOGGER.info(ResourceManager.getCoDeploymentName());
         for (Container c : kubeClient(namespaceName).getDeployment(namespaceName, ResourceManager.getCoDeploymentName()).getSpec().getTemplate().getSpec().getContainers()) {
             for (EnvVar envVar : c.getEnv()) {
                 images.put(envVar.getName(), envVar.getValue());

File: systemtest/src/test/java/io/strimzi/systemtest/backup/ColdBackupScriptIsolatedST.java
Patch:
@@ -11,6 +11,7 @@
 import static org.hamcrest.CoreMatchers.is;
 
 import io.strimzi.api.kafka.model.KafkaResources;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClientsBuilder;
 
@@ -47,6 +48,7 @@ void setUp() {
     }
 
     @IsolatedTest
+    @KRaftNotSupported("Debug needed - https://github.com/strimzi/strimzi-kafka-operator/issues/6863")
     void backupAndRestore(ExtensionContext context) {
         String clusterName = mapWithClusterNames.get(context.getDisplayName());
         String groupId = "my-group", newGroupId = "new-group";

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -19,6 +19,7 @@
 import io.strimzi.api.kafka.model.status.ListenerStatus;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.BridgeClients;
@@ -52,6 +53,7 @@
 @Tag(BRIDGE)
 @Tag(NODEPORT_SUPPORTED)
 @Tag(EXTERNAL_CLIENTS_USED)
+@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
 @ParallelSuite
 public class HttpBridgeKafkaExternalListenersST extends AbstractST {
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.BridgeClients;
@@ -41,6 +42,7 @@
 @Tag(INTERNAL_CLIENTS_USED)
 @Tag(BRIDGE)
 @Tag(REGRESSION)
+@KRaftNotSupported("UserOperator and scram-sha are not supported by KRaft mode and is used in this test class")
 @ParallelSuite
 class HttpBridgeScramShaST extends AbstractST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -12,6 +12,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.BridgeClients;
@@ -43,6 +44,7 @@
 @Tag(BRIDGE)
 @Tag(ACCEPTANCE)
 @Tag(INTERNAL_CLIENTS_USED)
+@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
 @ParallelSuite
 class HttpBridgeTlsST extends AbstractST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeTlsST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlApiST.java
Patch:
@@ -7,6 +7,7 @@
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlEndpoints;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlUserTaskStatus;
 import io.strimzi.systemtest.AbstractST;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.storage.TestStorage;
@@ -40,6 +41,7 @@ public class CruiseControlApiST extends AbstractST {
     private final String cruiseControlApiClusterName = "cruise-control-api-cluster-name";
 
     @ParallelNamespaceTest
+    @KRaftNotSupported("TopicOperator is not supported by KRaft mode and is used in this test class")
     void testCruiseControlBasicAPIRequests(ExtensionContext extensionContext)  {
         final TestStorage testStorage = new TestStorage(extensionContext);
 

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.annotations.IsolatedTest;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
@@ -248,6 +249,7 @@ void testUpdateToExternalListenerCausesRollingRestart(ExtensionContext extension
     @Tag(NODEPORT_SUPPORTED)
     @Tag(EXTERNAL_CLIENTS_USED)
     @Tag(ROLLING_UPDATE)
+    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
     void testUpdateToExternalListenerCausesRollingRestartUsingExternalClients(ExtensionContext extensionContext) {
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java
Patch:
@@ -12,6 +12,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.annotations.IsolatedTest;
@@ -47,6 +48,7 @@
 
 @Tag(REGRESSION)
 @ParallelSuite
+@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
 public class MultipleListenersST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
Patch:
@@ -20,6 +20,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.IsolatedTest;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
@@ -190,6 +191,7 @@ class LogSettingST extends AbstractST {
     };
 
     @IsolatedTest("Using shared Kafka")
+    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
     void testKafkaLogSetting(ExtensionContext extensionContext) {
         String kafkaMap = KafkaResources.kafkaMetricsAndLogConfigMapName(LOG_SETTING_CLUSTER_NAME);
         String zookeeperMap = KafkaResources.zookeeperMetricsAndLogConfigMapName(LOG_SETTING_CLUSTER_NAME);

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerIsolatedST.java
Patch:
@@ -22,6 +22,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.BeforeAllOnce;
 import io.strimzi.systemtest.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClientsBuilder;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
@@ -152,6 +153,7 @@ void testMirrorMaker(ExtensionContext extensionContext) {
      */
     @ParallelNamespaceTest
     @Tag(ACCEPTANCE)
+    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
     @SuppressWarnings({"checkstyle:MethodLength"})
     void testMirrorMakerTlsAuthenticated(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, clusterOperator.getDeploymentNamespace());
@@ -264,6 +266,7 @@ void testMirrorMakerTlsAuthenticated(ExtensionContext extensionContext) {
      * Test mirroring messages by Mirror Maker over tls transport using scram-sha auth
      */
     @ParallelNamespaceTest
+    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
     @SuppressWarnings("checkstyle:methodlength")
     void testMirrorMakerTlsScramSha(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, clusterOperator.getDeploymentNamespace());

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ReconciliationST.java
Patch:
@@ -15,6 +15,7 @@
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.enums.CustomResourceStatus;
@@ -65,6 +66,7 @@ public class ReconciliationST extends AbstractST {
     @ParallelNamespaceTest
     @Tag(CONNECT)
     @Tag(CONNECT_COMPONENTS)
+    @KRaftNotSupported("Probably bug - https://github.com/strimzi/strimzi-kafka-operator/issues/6862")
     void testPauseReconciliationInKafkaAndKafkaConnectWithConnector(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(clusterOperator.getDeploymentNamespace(), extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
@@ -132,6 +134,7 @@ void testPauseReconciliationInKafkaAndKafkaConnectWithConnector(ExtensionContext
 
     @ParallelNamespaceTest
     @Tag(CRUISE_CONTROL)
+    @KRaftNotSupported("TopicOperator is not supported by KRaft mode and is used in this test class")
     void testPauseReconciliationInKafkaRebalanceAndTopic(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(clusterOperator.getDeploymentNamespace(), extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/ThrottlingQuotaST.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.AdminClientOperation;
@@ -40,6 +41,7 @@
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
 @ParallelSuite
+@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
 public class ThrottlingQuotaST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(ThrottlingQuotaST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.IsolatedTest;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
@@ -64,6 +65,7 @@
 
 @Tag(REGRESSION)
 @ParallelSuite
+@KRaftNotSupported("TopicOperator is not supported by KRaft mode and is used in this test class")
 public class TopicST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(TopicST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserST.java
Patch:
@@ -20,6 +20,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.IsolatedTest;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
@@ -61,6 +62,7 @@
 
 @Tag(REGRESSION)
 @ParallelSuite
+@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test class")
 class UserST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(UserST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerIsolatedST.java
Patch:
@@ -28,6 +28,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
@@ -75,6 +76,7 @@ public class KafkaRollerIsolatedST extends AbstractST {
     private static final Logger LOGGER = LogManager.getLogger(KafkaRollerIsolatedST.class);
 
     @ParallelNamespaceTest
+    @KRaftNotSupported("TopicOperator is not supported by KRaft mode and is used in this test class")
     void testKafkaRollsWhenTopicIsUnderReplicated(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(clusterOperator.getDeploymentNamespace(), extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
@@ -135,6 +137,7 @@ void testKafkaRollsWhenTopicIsUnderReplicated(ExtensionContext extensionContext)
     }
 
     @ParallelNamespaceTest
+    @KRaftNotSupported("TopicOperator is not supported by KRaft mode and is used in this test class")
     void testKafkaTopicRFLowerThanMinInSyncReplicas(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(clusterOperator.getDeploymentNamespace(), extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesIsolatedST.java
Patch:
@@ -18,6 +18,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClientsBuilder;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
@@ -65,6 +66,7 @@ public class NetworkPoliciesIsolatedST extends AbstractST {
 
     @IsolatedTest("Specific cluster operator for test case")
     @Tag(INTERNAL_CLIENTS_USED)
+    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
     void testNetworkPoliciesWithPlainListener(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, clusterOperator.getDeploymentNamespace());
 
@@ -163,6 +165,7 @@ void testNetworkPoliciesWithPlainListener(ExtensionContext extensionContext) {
 
     @IsolatedTest("Specific cluster operator for test case")
     @Tag(INTERNAL_CLIENTS_USED)
+    @KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
     void testNetworkPoliciesWithTlsListener(ExtensionContext extensionContext) {
         final TestStorage testStorage = new TestStorage(extensionContext, clusterOperator.getDeploymentNamespace());
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/OpaIntegrationST.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
@@ -38,6 +39,7 @@
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
 @ParallelSuite
+@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
 public class OpaIntegrationST extends AbstractST {
     private static final Logger LOGGER = LogManager.getLogger(OpaIntegrationST.class);
     private static final String OPA_SUPERUSER = "arnost";

File: systemtest/src/test/java/io/strimzi/systemtest/security/custom/CustomAuthorizerST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
@@ -35,6 +36,7 @@
 
 @Tag(REGRESSION)
 @ParallelSuite
+@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
 public class CustomAuthorizerST extends AbstractST {
     static final String CLUSTER_NAME = "custom-authorizer";
     static final String ADMIN = "sre-admin";

File: systemtest/src/test/java/io/strimzi/systemtest/security/custom/CustomCaST.java
Patch:
@@ -12,6 +12,7 @@
 import io.strimzi.operator.cluster.model.Ca;
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.systemtest.AbstractST;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
@@ -58,6 +59,7 @@
  * @see <a href="https://strimzi.io/docs/operators/in-development/configuring.html#proc-replacing-your-own-private-keys-str">Replacing your own private keys</a>
  */
 @ParallelSuite
+@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
 public class CustomCaST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(CustomCaST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationIsolatedST.java
Patch:
@@ -12,6 +12,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.annotations.IsolatedTest;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaOauthClients;
@@ -61,6 +62,7 @@
 @Tag(INTERNAL_CLIENTS_USED)
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @IsolatedSuite
+@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
 public class OauthAuthorizationIsolatedST extends OauthAbstractST {
     protected static final Logger LOGGER = LogManager.getLogger(OauthAuthorizationIsolatedST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsIsolatedST.java
Patch:
@@ -18,6 +18,7 @@
 import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.annotations.IsolatedTest;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.BridgeClients;
 import io.strimzi.systemtest.kafkaclients.internalClients.BridgeClientsBuilder;
@@ -64,6 +65,7 @@
 @Tag(REGRESSION)
 @Tag(ACCEPTANCE)
 @IsolatedSuite
+@KRaftNotSupported("UserOperator is not supported by KRaft mode and is used in this test case")
 public class OauthTlsIsolatedST extends OauthAbstractST {
     protected static final Logger LOGGER = LogManager.getLogger(OauthTlsIsolatedST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/KafkaUpgradeDowngradeIsolatedST.java
Patch:
@@ -8,6 +8,7 @@
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.annotations.IsolatedTest;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClientsBuilder;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
@@ -41,6 +42,7 @@
  */
 @Tag(UPGRADE)
 @IsolatedSuite
+@KRaftNotSupported("Strimzi and Kafka downgrade is not supported with KRaft mode")
 public class KafkaUpgradeDowngradeIsolatedST extends AbstractUpgradeST {
 
     private static final Logger LOGGER = LogManager.getLogger(KafkaUpgradeDowngradeIsolatedST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeIsolatedST.java
Patch:
@@ -9,6 +9,7 @@
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.enums.OlmInstallationStrategy;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClientsBuilder;
@@ -50,6 +51,7 @@
  */
 @Tag(OLM_UPGRADE)
 @IsolatedSuite
+@KRaftNotSupported("Strimzi and Kafka downgrade is not supported with KRaft mode")
 public class OlmUpgradeIsolatedST extends AbstractUpgradeST {
 
     private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeIsolatedST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziDowngradeIsolatedST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.upgrade;
 
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.systemtest.annotations.IsolatedSuite;
@@ -31,6 +32,7 @@
  */
 @Tag(UPGRADE)
 @IsolatedSuite
+@KRaftNotSupported("Strimzi and Kafka downgrade is not supported with KRaft mode")
 public class StrimziDowngradeIsolatedST extends AbstractUpgradeST {
 
     private static final Logger LOGGER = LogManager.getLogger(StrimziDowngradeIsolatedST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeIsolatedST.java
Patch:
@@ -8,6 +8,7 @@
 import com.fasterxml.jackson.databind.node.ObjectNode;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
 import io.strimzi.api.kafka.model.KafkaResources;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.utils.FileUtils;
@@ -55,6 +56,7 @@
  */
 @Tag(UPGRADE)
 @IsolatedSuite
+@KRaftNotSupported("Strimzi and Kafka downgrade is not supported with KRaft mode")
 public class StrimziUpgradeIsolatedST extends AbstractUpgradeST {
 
     private static final Logger LOGGER = LogManager.getLogger(StrimziUpgradeIsolatedST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/MultipleNamespaceIsolatedST.java
Patch:
@@ -7,6 +7,7 @@
 import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.strimzi.systemtest.BeforeAllOnce;
 import io.strimzi.systemtest.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.KRaftNotSupported;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
@@ -39,6 +40,7 @@ class MultipleNamespaceIsolatedST extends AbstractNamespaceST {
      * Test the case where the TO is configured to watch a different namespace that it is deployed in
      */
     @IsolatedTest
+    @KRaftNotSupported("TopicOperator is not supported by KRaft mode and is used in this test case")
     void testTopicOperatorWatchingOtherNamespace(ExtensionContext extensionContext) {
         String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -327,7 +327,7 @@ public static KafkaCluster fromCrd(Reconciliation reconciliation, Kafka kafkaAss
                 LOGGER.warnCr(reconciliation, "Only the following changes to Kafka storage are allowed: " +
                         "changing the deleteClaim flag, " +
                         "adding volumes to Jbod storage or removing volumes from Jbod storage, " +
-                        "changing overrides to nodes which do not exist yet" +
+                        "changing overrides to nodes which do not exist yet " +
                         "and increasing size of persistent claim volumes (depending on the volume type and used storage class).");
                 LOGGER.warnCr(reconciliation, "The desired Kafka storage configuration in the custom resource {}/{} contains changes which are not allowed. As a " +
                         "result, all storage changes will be ignored. Use DEBUG level logging for more information " +

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -399,7 +399,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
         varList.add(buildEnvVar(ENV_VAR_MIN_INSYNC_REPLICAS, String.valueOf(minInsyncReplicas)));
 
-        varList.add(buildEnvVar(ENV_VAR_CRUISE_CONTROL_CAPACITY_CONFIGURATION, capacity.generateCapacityConfig()));
+        varList.add(buildEnvVar(ENV_VAR_CRUISE_CONTROL_CAPACITY_CONFIGURATION, capacity.toString()));
 
         varList.add(buildEnvVar(ENV_VAR_API_SSL_ENABLED,  String.valueOf(this.sslEnabled)));
         varList.add(buildEnvVar(ENV_VAR_API_AUTH_ENABLED,  String.valueOf(this.authEnabled)));

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/JmxIsolatedST.java
Patch:
@@ -51,7 +51,7 @@ public class JmxIsolatedST extends AbstractST {
     void testKafkaZookeeperAndKafkaConnectWithJMX(ExtensionContext extensionContext) {
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         final String scraperName = mapWithScraperNames.get(extensionContext.getDisplayName());
-        final String namespaceName = StUtils.getNamespaceBasedOnRbac(INFRA_NAMESPACE, extensionContext);
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(clusterOperator.getDeploymentNamespace(), extensionContext);
         final String zkSecretName = clusterName + "-zookeeper-jmx";
         final String connectJmxSecretName = clusterName + "-kafka-connect-jmx";
         final String kafkaJmxSecretName = clusterName + "-kafka-jmx";

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ReconciliationST.java
Patch:
@@ -49,7 +49,6 @@
 import static io.strimzi.systemtest.Constants.CONNECT;
 import static io.strimzi.systemtest.Constants.CONNECT_COMPONENTS;
 import static io.strimzi.systemtest.Constants.CRUISE_CONTROL;
-import static io.strimzi.systemtest.Constants.INFRA_NAMESPACE;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
@@ -67,7 +66,7 @@ public class ReconciliationST extends AbstractST {
     @Tag(CONNECT)
     @Tag(CONNECT_COMPONENTS)
     void testPauseReconciliationInKafkaAndKafkaConnectWithConnector(ExtensionContext extensionContext) {
-        final String namespaceName = StUtils.getNamespaceBasedOnRbac(INFRA_NAMESPACE, extensionContext);
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(clusterOperator.getDeploymentNamespace(), extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         String kafkaSsName = KafkaResources.kafkaStatefulSetName(clusterName);
 
@@ -134,7 +133,7 @@ void testPauseReconciliationInKafkaAndKafkaConnectWithConnector(ExtensionContext
     @ParallelNamespaceTest
     @Tag(CRUISE_CONTROL)
     void testPauseReconciliationInKafkaRebalanceAndTopic(ExtensionContext extensionContext) {
-        final String namespaceName = StUtils.getNamespaceBasedOnRbac(INFRA_NAMESPACE, extensionContext);
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(clusterOperator.getDeploymentNamespace(), extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         final String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesIsolatedST.java
Patch:
@@ -47,9 +47,9 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
-import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
-import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;
+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.CoreMatchers.not;

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsIsolatedST.java
Patch:
@@ -161,7 +161,7 @@ void testProducerConsumerConnect(ExtensionContext extensionContext) {
             .endSpec()
             .build());
 
-        String kafkaConnectPodName = kubeClient(clusterOperator.getDeploymentNamespace()).listPods(clusterOperator.getDeploymentNamespace(), clusterName, Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND).get(0).getMetadata().getName();
+        String kafkaConnectPodName = kubeClient().listPods(clusterOperator.getDeploymentNamespace(), clusterName, Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND).get(0).getMetadata().getName();
         String scraperPodName = kubeClient().listPodsByPrefixInName(clusterName + "-" + Constants.SCRAPER_NAME).get(0).getMetadata().getName();
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(clusterOperator.getDeploymentNamespace(), kafkaConnectPodName);
 
@@ -486,7 +486,7 @@ void setUp(ExtensionContext extensionContext) {
     @AfterAll
     void tearDown(ExtensionContext extensionContext) throws Exception {
         // delete keycloak before namespace
-        KeycloakUtils.deleteKeycloak(Constants.INFRA_NAMESPACE, clusterOperator.getDeploymentNamespace());
+        KeycloakUtils.deleteKeycloak(clusterOperator.getDeploymentNamespace(), clusterOperator.getDeploymentNamespace());
         // delete namespace etc.
         super.afterAllMayOverride(extensionContext);
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlApiImpl.java
Patch:
@@ -191,9 +191,7 @@ private void internalRebalance(String host, int port, String path, String userTa
                                 // ... or one or more brokers doesn't exist on a add/remove brokers rebalance request
                                 } else if (json.getString(CC_REST_API_ERROR_KEY).contains("IllegalArgumentException") &&
                                             json.getString(CC_REST_API_ERROR_KEY).contains("does not exist.")) {
-                                    CruiseControlRebalanceResponse ccResponse = new CruiseControlRebalanceResponse(userTaskID, json);
-                                    ccResponse.setBrokersNotExist(true);
-                                    result.complete(ccResponse);
+                                    result.fail(new IllegalArgumentException("Some/all brokers specified don't exist"));
                                 } else {
                                     // If there was any other kind of error propagate this to the operator
                                     result.fail(new CruiseControlRestException(

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/AbstractRebalanceOptions.java
Patch:
@@ -111,6 +111,8 @@ public abstract static class AbstractRebalanceOptionsBuilder<B extends AbstractR
 
         protected abstract B self();
 
+        public abstract T build();
+
         public B withFullRun() {
             this.isDryRun = false;
             return self();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/PathBuilder.java
Patch:
@@ -8,6 +8,7 @@
 import java.net.URLEncoder;
 import java.nio.charset.StandardCharsets;
 import java.util.List;
+import java.util.stream.Collectors;
 
 public class PathBuilder {
 
@@ -107,7 +108,7 @@ private PathBuilder withAbstractRebalanceParameters(AbstractRebalanceOptions opt
     public PathBuilder withAddBrokerParameters(AddBrokerOptions options) {
         if (options != null) {
             PathBuilder builder = withAbstractRebalanceParameters(options)
-                    .withParameter(CruiseControlParameters.BROKER_ID, String.join(",", options.getBrokers()));
+                    .withParameter(CruiseControlParameters.BROKER_ID, options.getBrokers().stream().map(String::valueOf).collect(Collectors.joining(",")));
             return builder;
         } else {
             return this;
@@ -117,7 +118,7 @@ public PathBuilder withAddBrokerParameters(AddBrokerOptions options) {
     public PathBuilder withRemoveBrokerParameters(RemoveBrokerOptions options) {
         if (options != null) {
             PathBuilder builder = withAbstractRebalanceParameters(options)
-                    .withParameter(CruiseControlParameters.BROKER_ID, String.join(",", options.getBrokers()));
+                    .withParameter(CruiseControlParameters.BROKER_ID, options.getBrokers().stream().map(String::valueOf).collect(Collectors.joining(",")));
             return builder;
         } else {
             return this;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/RebalanceOptions.java
Patch:
@@ -53,6 +53,7 @@ public RebalanceOptionsBuilder withConcurrentIntraPartitionMovements(int movemen
             return self();
         }
 
+        @Override
         public RebalanceOptions build() {
             return new RebalanceOptions(this);
         }

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -150,7 +150,7 @@ public interface Constants {
     String PATH_TO_KAFKA_CONNECT_CONFIG = Constants.PATH_TO_PACKAGING_EXAMPLES + "/connect/kafka-connect.yaml";
     String PATH_TO_KAFKA_CONNECT_METRICS_CONFIG = Constants.PATH_TO_PACKAGING_EXAMPLES + "/metrics/kafka-connect-metrics.yaml";
     String PATH_TO_KAFKA_BRIDGE_CONFIG = Constants.PATH_TO_PACKAGING_EXAMPLES + "/bridge/kafka-bridge.yaml";
-    String PATH_TO_KAFKA_REBALANCE_CONFIG = Constants.PATH_TO_PACKAGING_EXAMPLES + "/cruise-control/kafka-rebalance.yaml";
+    String PATH_TO_KAFKA_REBALANCE_CONFIG = Constants.PATH_TO_PACKAGING_EXAMPLES + "/cruise-control/kafka-rebalance-full.yaml";
     String PATH_TO_KAFKA_CRUISE_CONTROL_CONFIG = Constants.PATH_TO_PACKAGING_EXAMPLES + "/cruise-control/kafka-cruise-control.yaml";
     String PATH_TO_KAFKA_EPHEMERAL_CONFIG = Constants.PATH_TO_PACKAGING_EXAMPLES + "/kafka/kafka-ephemeral.yaml";
     String PATH_TO_KAFKA_PERSISTENT_CONFIG = Constants.PATH_TO_PACKAGING_EXAMPLES + "/kafka/kafka-persistent.yaml";

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -83,7 +83,6 @@ public interface Constants {
     String KAFKA_ADMIN_CLIENT_LABEL_VALUE = "kafka-clients";
     String KAFKA_BRIDGE_CLIENTS_LABEL_VALUE = "kafka-clients";
 
-    String KAFKA_CLIENTS = "kafka-clients";
     String STRIMZI_DEPLOYMENT_NAME = "strimzi-cluster-operator";
     String ALWAYS_IMAGE_PULL_POLICY = "Always";
     String IF_NOT_PRESENT_IMAGE_PULL_POLICY = "IfNotPresent";
@@ -382,7 +381,6 @@ public interface Constants {
     String CLUSTER_KEY = "CLUSTER_NAME";
     String TOPIC_KEY = "TOPIC_NAME";
     String STREAM_TOPIC_KEY = "STREAM_TOPIC_NAME";
-    String KAFKA_CLIENTS_KEY = "KAFKA_CLIENTS_NAME";
     String SCRAPER_KEY = "SCRAPER_NAME";
     String PRODUCER_KEY = "PRODUCER_NAME";
     String CONSUMER_KEY = "CONSUMER_NAME";

File: systemtest/src/main/java/io/strimzi/systemtest/templates/specific/ScraperTemplates.java
Patch:
@@ -46,7 +46,7 @@ public static DeploymentBuilder scraperPod(String namespaceName, String podName)
                         .withContainers(
                             new ContainerBuilder()
                                 .withName(podName)
-                                .withImage("registry.access.redhat.com/ubi8/ubi:latest")
+                                .withImage("registry.access.redhat.com/ubi8/openjdk-11:latest")
                                 .withCommand("sleep")
                                 .withArgs("infinity")
                                 .withImagePullPolicy(Environment.COMPONENTS_IMAGE_PULL_POLICY)

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -93,7 +93,7 @@ public abstract class AbstractST implements TestSeparator {
     protected static Map<String, String> mapWithClusterNames = new HashMap<>();
     protected static Map<String, String> mapWithTestTopics = new HashMap<>();
     protected static Map<String, String> mapWithTestUsers = new HashMap<>();
-    protected static Map<String, String> mapWithKafkaClientNames = new HashMap<>();
+    protected static Map<String, String> mapWithScraperNames = new HashMap<>();
     protected static ConcurrentHashMap<ExtensionContext, TestStorage> storageMap = new ConcurrentHashMap<>();
 
     // we need to shared this number across all test suites
@@ -610,12 +610,12 @@ protected void beforeEachMayOverride(ExtensionContext extensionContext) {
             mapWithClusterNames.put(testName, clusterName);
             mapWithTestTopics.put(testName, KafkaTopicUtils.generateRandomNameOfTopic());
             mapWithTestUsers.put(testName, KafkaUserUtils.generateRandomNameOfKafkaUser());
-            mapWithKafkaClientNames.put(testName, clusterName + "-" + Constants.KAFKA_CLIENTS);
+            mapWithScraperNames.put(testName, clusterName + "-" + Constants.SCRAPER_NAME);
 
             LOGGER.trace("CLUSTER_NAMES_MAP: {}", mapWithClusterNames);
             LOGGER.trace("USERS_NAME_MAP: {}", mapWithTestUsers);
             LOGGER.trace("TOPIC_NAMES_MAP: {}", mapWithTestTopics);
-            LOGGER.trace("THIS IS CLIENTS MAP: {}", mapWithKafkaClientNames);
+            LOGGER.trace("THIS IS CLIENTS MAP: {}", mapWithScraperNames);
             testSuiteNamespaceManager.createParallelNamespace(extensionContext);
         }
     }

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlST.java
Patch:
@@ -30,7 +30,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.storage.TestStorage;
-import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaRebalanceTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
@@ -258,15 +257,13 @@ void testCruiseControlTopicExclusion(ExtensionContext extensionContext) {
     void testCruiseControlReplicaMovementStrategy(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(namespace, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
-        final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
 
         final String replicaMovementStrategies = "default.replica.movement.strategies";
         final String newReplicaMovementStrategies = "com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizeSmallReplicaMovementStrategy," +
             "com.linkedin.kafka.cruisecontrol.executor.strategy.PrioritizeLargeReplicaMovementStrategy," +
             "com.linkedin.kafka.cruisecontrol.executor.strategy.PostponeUrpReplicaMovementStrategy";
 
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaWithCruiseControl(clusterName, 3, 3).build());
-        resourceManager.createResource(extensionContext, KafkaClientsTemplates.kafkaClients(kafkaClientsName).build());
 
         String ccPodName = kubeClient().listPodsByPrefixInName(namespaceName, CruiseControlResources.deploymentName(clusterName)).get(0).getMetadata().getName();
 

File: systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
Patch:
@@ -262,7 +262,6 @@ void testKafkaLogSetting(ExtensionContext extensionContext) {
     @ParallelTest
     void testConnectLogSetting(ExtensionContext extensionContext) {
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
-        String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
         String connectClusterName = clusterName + "-connect";
 
         resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnect(extensionContext, connectClusterName, namespace, LOG_SETTING_CLUSTER_NAME, 1, true)

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -1082,7 +1082,6 @@ void testDynamicallySetKafkaExternalLogging(ExtensionContext extensionContext) {
     void testDynamicallySetMM2LoggingLevels(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(namespace, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
-        final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
 
         InlineLogging ilOff = new InlineLogging();
         Map<String, String> loggers = new HashMap<>();
@@ -1190,7 +1189,6 @@ void testDynamicallySetMM2LoggingLevels(ExtensionContext extensionContext) {
     void testMM2LoggingLevelsHierarchy(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(namespace, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
-        final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
 
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(clusterName + "-source", 1).build());
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(clusterName + "-target", 1).build());

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ClusterOperatorRbacIsolatedST.java
Patch:
@@ -82,7 +82,6 @@ void testCRBDeletionErrorsWhenRackAwarenessIsEnabled(ExtensionContext extensionC
         assumeFalse(Environment.isNamespaceRbacScope());
 
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
-        String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
 
         // 060-Deployment
         clusterOperator.unInstall();

File: systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java
Patch:
@@ -538,8 +538,6 @@ void setup(ExtensionContext extensionContext) {
                 .endKafka()
             .endSpec();
 
-        String kafkaClientsName = Constants.INFRA_NAMESPACE + "-shared-" + Constants.KAFKA_CLIENTS;
-
         resourceManager.createResource(extensionContext, kafkaBuilder.build());
         resourceManager.createResource(extensionContext, KafkaTopicTemplates.topic(CUSTOM_RESOURCE_STATUS_CLUSTER_NAME, TOPIC_NAME).build());
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ReconciliationST.java
Patch:
@@ -69,7 +69,6 @@ public class ReconciliationST extends AbstractST {
     void testPauseReconciliationInKafkaAndKafkaConnectWithConnector(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(INFRA_NAMESPACE, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
-        final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
         String kafkaSsName = KafkaResources.kafkaStatefulSetName(clusterName);
 
         final LabelSelector kafkaSelector = KafkaResource.getLabelSelector(clusterName, kafkaSsName);

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesIsolatedST.java
Patch:
@@ -304,7 +304,6 @@ void testNPGenerationEnvironmentVariable(ExtensionContext extensionContext) {
         assumeTrue(!Environment.isHelmInstall() && !Environment.isOlmInstall());
 
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
-        final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
 
         EnvVar networkPolicyGenerationEnv = new EnvVarBuilder()
             .withName("STRIMZI_NETWORK_POLICY_GENERATION")

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -788,7 +788,6 @@ void testCertRegeneratedAfterInternalCAisDeleted(ExtensionContext extensionConte
     void testTlsHostnameVerificationWithKafkaConnect(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(namespace, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
-        final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
 
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(clusterName, 3, 1).build());
         LOGGER.info("Getting IP of the bootstrap service");
@@ -1211,7 +1210,6 @@ void testCaRenewalBreakInMiddle(ExtensionContext extensionContext) {
     void testKafkaAndKafkaConnectTlsVersion(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(namespace, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
-        final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
         final Map<String, Object> configWithNewestVersionOfTls = new HashMap<>();
 
         final String tlsVersion12 = "TLSv1.2";
@@ -1286,7 +1284,6 @@ void testKafkaAndKafkaConnectTlsVersion(ExtensionContext extensionContext) {
     void testKafkaAndKafkaConnectCipherSuites(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(namespace, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
-        final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
         final Map<String, Object> configWithCipherSuitesSha384 = new HashMap<>();
 
         final String cipherSuitesSha384 = "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384";

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainIsolatedST.java
Patch:
@@ -623,7 +623,6 @@ void testProducerConsumerMirrorMaker2(ExtensionContext extensionContext) {
     @ParallelTest
     @Tag(BRIDGE)
     void testProducerConsumerBridge(ExtensionContext extensionContext) {
-        String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         String producerName = OAUTH_PRODUCER_NAME + "-" + clusterName;
         String consumerName = OAUTH_CONSUMER_NAME + "-" + clusterName;

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthScopeIsolatedST.java
Patch:
@@ -63,7 +63,6 @@ public class OauthScopeIsolatedST extends OauthAbstractST {
     @ParallelTest
     @Tag(CONNECT)
     void testScopeKafkaConnectSetIncorrectly(ExtensionContext extensionContext) {
-        final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
 
         // SCOPE TESTING
@@ -102,7 +101,6 @@ void testScopeKafkaConnectSetIncorrectly(ExtensionContext extensionContext) {
     @ParallelTest
     @Tag(CONNECT)
     void testScopeKafkaConnectSetCorrectly(ExtensionContext extensionContext) {
-        final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
 
         // SCOPE TESTING

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsIsolatedST.java
Patch:
@@ -174,7 +174,6 @@ void testProducerConsumerConnect(ExtensionContext extensionContext) {
     @ParallelTest
     @Tag(BRIDGE)
     void testProducerConsumerBridge(ExtensionContext extensionContext) {
-        String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         String producerName = OAUTH_PRODUCER_NAME + "-" + clusterName;
         String consumerName = OAUTH_CONSUMER_NAME + "-" + clusterName;

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -388,7 +388,7 @@ public interface Constants {
     String CONSUMER_KEY = "CONSUMER_NAME";
     String ADMIN_KEY = "ADMIN_NAME";
     String USER_NAME_KEY = "USER_NAME";
-    String KAFKA_CLIENTS_POD_KEY = "KAFKA_CLIENTS_POD_NAME";
+    String SCRAPER_POD_KEY = "SCRAPER_POD_NAME";
     String KAFKA_TRACING_CLIENT_KEY = "KAFKA_TRACING_CLIENT";
     String KAFKA_SELECTOR = "KAFKA_SELECTOR";
     String ZOOKEEPER_SELECTOR = "ZOOKEEPER_SELECTOR";

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthScopeIsolatedST.java
Patch:
@@ -18,7 +18,6 @@
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClients;
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClientsBuilder;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
-import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
@@ -68,7 +67,6 @@ void testScopeKafkaConnectSetIncorrectly(ExtensionContext extensionContext) {
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
 
         // SCOPE TESTING
-        resourceManager.createResource(extensionContext, KafkaClientsTemplates.kafkaClients(INFRA_NAMESPACE, false, kafkaClientsName).build());
         resourceManager.createResource(extensionContext, false, KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, clusterName, 1)
             .editMetadata()
                 .withNamespace(INFRA_NAMESPACE)
@@ -108,7 +106,6 @@ void testScopeKafkaConnectSetCorrectly(ExtensionContext extensionContext) {
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
 
         // SCOPE TESTING
-        resourceManager.createResource(extensionContext, KafkaClientsTemplates.kafkaClients(INFRA_NAMESPACE, false, kafkaClientsName).build());
         resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, clusterName, 1)
             .editMetadata()
                 .withNamespace(INFRA_NAMESPACE)

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/NodeUtils.java
Patch:
@@ -43,7 +43,7 @@ public static Map<String, List<String>> getPodsForEachNodeInNamespace(String nam
     public static void drainNode(String nodeName) {
         List<String> cmd = new ArrayList<>();
 
-        if (KubeClusterResource.getInstance().isNotKubernetes()) {
+        if (KubeClusterResource.getInstance().isOpenShift()) {
             cmd.add("adm");
         }
 
@@ -59,7 +59,7 @@ public static void cordonNode(String node, boolean schedule) {
         LOGGER.info("Set {} schedule {}", node, schedule);
         List<String> cmd = new ArrayList<>();
 
-        if (KubeClusterResource.getInstance().isNotKubernetes()) {
+        if (KubeClusterResource.getInstance().isOpenShift()) {
             cmd.add("adm");
         }
 

File: test/src/main/java/io/strimzi/test/k8s/KubeClusterResource.java
Patch:
@@ -367,7 +367,7 @@ public String getDefaultOlmNamespace() {
         return cluster().defaultOlmNamespace();
     }
 
-    public boolean isNotKubernetes() {
+    public boolean isOpenShift() {
         return kubeClusterResource.cluster() instanceof OpenShift;
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java
Patch:
@@ -125,7 +125,7 @@ protected void setupCoAndKeycloak(ExtensionContext extensionContext, String name
         LOGGER.info("Deploying keycloak...");
 
         // this is need for cluster-wide OLM (creating `infra-namespace` for Keycloak)
-        // Keycloak do not support cluster-wide namespace and thus we need it to deploy in non-OLM cluster wide namespace
+        // Keycloak do not support cluster-wide namespace, thus we need it to deploy in non-OLM cluster wide namespace
         // (f.e., our `infra-namespace`)
         if (kubeClient().getNamespace(Constants.INFRA_NAMESPACE) == null) {
             cluster.createNamespace(CollectorElement.createCollectorElement(extensionContext.getRequiredTestClass().getName()), Constants.INFRA_NAMESPACE);

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -24,6 +24,7 @@ public interface Constants {
 
     long TIMEOUT_TEARDOWN = Duration.ofSeconds(10).toMillis();
     long GLOBAL_TIMEOUT = Duration.ofMinutes(5).toMillis();
+    long GLOBAL_TIMEOUT_SHORT = Duration.ofMinutes(2).toMillis();
     long GLOBAL_CMD_CLIENT_TIMEOUT = Duration.ofMinutes(5).toMillis();
     long GLOBAL_STATUS_TIMEOUT = Duration.ofMinutes(3).toMillis();
     long GLOBAL_POLL_INTERVAL = Duration.ofSeconds(1).toMillis();

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -884,7 +884,7 @@ void testKafkaJBODDeleteClaimsTrueFalse(ExtensionContext extensionContext) {
         cmdKubeClient(namespaceName).deleteByName("kafka", clusterName);
 
         LOGGER.info("Waiting for PVC deletion");
-        PersistentVolumeClaimUtils.waitForPVCDeletion(namespaceName, volumesCount, jbodStorage, clusterName);
+        PersistentVolumeClaimUtils.waitForJbodStorageDeletion(namespaceName, volumesCount, jbodStorage, clusterName);
     }
 
     @ParallelNamespaceTest
@@ -908,7 +908,7 @@ void testKafkaJBODDeleteClaimsTrue(ExtensionContext extensionContext) {
         cmdKubeClient(namespaceName).deleteByName("kafka", clusterName);
 
         LOGGER.info("Waiting for PVC deletion");
-        PersistentVolumeClaimUtils.waitForPVCDeletion(namespaceName, volumesCount, jbodStorage, clusterName);
+        PersistentVolumeClaimUtils.waitForJbodStorageDeletion(namespaceName, volumesCount, jbodStorage, clusterName);
     }
 
     @ParallelNamespaceTest
@@ -932,7 +932,7 @@ void testKafkaJBODDeleteClaimsFalse(ExtensionContext extensionContext) {
         cmdKubeClient(namespaceName).deleteByName("kafka", clusterName);
 
         LOGGER.info("Waiting for PVC deletion");
-        PersistentVolumeClaimUtils.waitForPVCDeletion(namespaceName, volumesCount, jbodStorage, clusterName);
+        PersistentVolumeClaimUtils.waitForJbodStorageDeletion(namespaceName, volumesCount, jbodStorage, clusterName);
     }
 
     @ParallelNamespaceTest

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperator.java
Patch:
@@ -1189,7 +1189,7 @@ private Future<MapAndStatus<ConfigMap, KafkaRebalanceStatus>> requestRebalance(R
                             // If there is not enough data for a rebalance, it's an error at the Cruise Control level
                             // Need to re-request the proposal at a later time so move to the PendingProposal State.
                             return buildRebalanceStatus(null, KafkaRebalanceState.PendingProposal, validate(reconciliation, kafkaRebalance));
-                        } else if (response.isProposalStillCalaculating()) {
+                        } else if (response.isProposalStillCalculating()) {
                             // If rebalance proposal is still being processed, we need to re-request the proposal at a later time
                             // with the corresponding session-id so we move to the PendingProposal State.
                             return buildRebalanceStatus(response.getUserTaskId(), KafkaRebalanceState.PendingProposal, validate(reconciliation, kafkaRebalance));
@@ -1199,7 +1199,7 @@ private Future<MapAndStatus<ConfigMap, KafkaRebalanceStatus>> requestRebalance(R
                             // We do not include a session id with this status as we do not want to retrieve the state of
                             // this failed tasks (COMPLETED_WITH_ERROR)
                             return buildRebalanceStatus(null, KafkaRebalanceState.PendingProposal, validate(reconciliation, kafkaRebalance));
-                        } else if (response.isProposalStillCalaculating()) {
+                        } else if (response.isProposalStillCalculating()) {
                             // If dryrun=false and the proposal is not ready we are going to be in a rebalancing state as
                             // soon as it is ready, so set the state to rebalancing.
                             // In the onRebalancing method the optimization proposal will be added when it is ready.

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlApiImpl.java
Patch:
@@ -169,7 +169,7 @@ private void internalRebalance(String host, int port, String path, String userTa
                             CruiseControlRebalanceResponse ccResponse = new CruiseControlRebalanceResponse(userTaskID, json);
                             if (json.containsKey(CC_REST_API_PROGRESS_KEY)) {
                                 // If the response contains a "progress" key then the rebalance proposal has not yet completed processing
-                                ccResponse.setProposalStillCalaculating(true);
+                                ccResponse.setProposalStillCalculating(true);
                             } else {
                                 result.fail(new CruiseControlRestException(
                                         "Error for request: " + host + ":" + port + path +

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlClientTest.java
Patch:
@@ -106,7 +106,7 @@ public void testCCRebalanceProposalNotReady(Vertx vertx, VertxTestContext contex
         RebalanceOptions options = new RebalanceOptions.RebalanceOptionsBuilder().build();
         this.ccRebalanceProposalNotReady(vertx, context, 1, options, CruiseControlEndpoints.REBALANCE,
                 result -> {
-                    assertThat(result.isProposalStillCalaculating(), is(true));
+                    assertThat(result.isProposalStillCalculating(), is(true));
                 });
     }
 
@@ -169,7 +169,7 @@ public void testCCAddBrokerProposalNotReady(Vertx vertx, VertxTestContext contex
                 .build();
         this.ccRebalanceProposalNotReady(vertx, context, 1, options, CruiseControlEndpoints.ADD_BROKER,
                 result -> {
-                    assertThat(result.isProposalStillCalaculating(), is(true));
+                    assertThat(result.isProposalStillCalculating(), is(true));
                 });
     }
 
@@ -227,7 +227,7 @@ public void testCCRemoveBrokerProposalNotReady(Vertx vertx, VertxTestContext con
                 .build();
         this.ccRebalanceProposalNotReady(vertx, context, 1, options, CruiseControlEndpoints.REMOVE_BROKER,
                 result -> {
-                    assertThat(result.isProposalStillCalaculating(), is(true));
+                    assertThat(result.isProposalStillCalculating(), is(true));
                 });
     }
 

File: operator-common/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlEndpoints.java
Patch:
@@ -9,7 +9,9 @@ public enum CruiseControlEndpoints {
     STATE("/kafkacruisecontrol/state"),
     REBALANCE("/kafkacruisecontrol/rebalance"),
     STOP("/kafkacruisecontrol/stop_proposal_execution"),
-    USER_TASKS("/kafkacruisecontrol/user_tasks");
+    USER_TASKS("/kafkacruisecontrol/user_tasks"),
+    ADD_BROKER("/kafkacruisecontrol/add_broker"),
+    REMOVE_BROKER("/kafkacruisecontrol/remove_broker");
 
     String path;
 

File: operator-common/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlParameters.java
Patch:
@@ -23,7 +23,8 @@ public enum CruiseControlParameters {
     CONCURRENT_INTRA_PARTITION_MOVEMENTS("concurrent_intra_broker_partition_movements"),
     CONCURRENT_LEADER_MOVEMENTS("concurrent_leader_movements"),
     REPLICATION_THROTTLE("replication_throttle"),
-    REPLICA_MOVEMENT_STRATEGIES("replica_movement_strategies");
+    REPLICA_MOVEMENT_STRATEGIES("replica_movement_strategies"),
+    BROKER_ID("brokerid");
 
     String key;
 

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/ConfigProviderST.java
Patch:
@@ -74,7 +74,7 @@ void testConnectWithConnectorUsingConfigAndEnvProvider(ExtensionContext extensio
 
         kubeClient().getClient().configMaps().inNamespace(namespaceName).create(connectorConfig);
 
-        resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, 1, false)
+        resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnectWithFilePlugin(extensionContext, namespaceName, clusterName, 1, false)
             .editOrNewMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata()

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -1369,7 +1369,7 @@ void testLoggingHierarchy(ExtensionContext extensionContext) {
                 KafkaTemplates.kafkaEphemeral(testStorage.getClusterName(), 3).build());
 
         resourceManager.createResource(extensionContext,
-                KafkaConnectTemplates.kafkaConnect(extensionContext, testStorage.getClusterName(), 1)
+                KafkaConnectTemplates.kafkaConnectWithFilePlugin(extensionContext, testStorage.getNamespaceName(), testStorage.getClusterName(), 1)
                     .editMetadata()
                         .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
                     .endMetadata()

File: systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java
Patch:
@@ -269,7 +269,7 @@ void testKafkaConnectAndConnectorStatus(ExtensionContext extensionContext) {
         final TestStorage ts = new TestStorage(extensionContext);
         String connectUrl = KafkaConnectResources.url(CUSTOM_RESOURCE_STATUS_CLUSTER_NAME, ts.getNamespaceName(), 8083);
 
-        resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnect(extensionContext, CUSTOM_RESOURCE_STATUS_CLUSTER_NAME, 1)
+        resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnectWithFilePlugin(extensionContext, ts.getNamespaceName(), CUSTOM_RESOURCE_STATUS_CLUSTER_NAME, 1)
             .editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
                 .withNamespace(ts.getNamespaceName())

File: systemtest/src/test/java/io/strimzi/systemtest/operators/MultipleClusterOperatorsIsolatedST.java
Patch:
@@ -117,7 +117,7 @@ void testMultipleCOsInDifferentNamespaces(ExtensionContext extensionContext) {
                     .withNamespace(DEFAULT_NAMESPACE)
                 .endMetadata()
                 .build(),
-            KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, 1, false)
+            KafkaConnectTemplates.kafkaConnectWithFilePlugin(extensionContext, DEFAULT_NAMESPACE, clusterName, 1, false)
                 .editOrNewMetadata()
                     .addToLabels(FIRST_CO_SELECTOR)
                     .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ReconciliationST.java
Patch:
@@ -91,7 +91,7 @@ void testPauseReconciliationInKafkaAndKafkaConnectWithConnector(ExtensionContext
         RollingUpdateUtils.waitForComponentAndPodsReady(namespaceName, kafkaSelector, SCALE_TO);
 
         LOGGER.info("Deploying KafkaConnect with pause annotation from the start, no pods should appear");
-        resourceManager.createResource(extensionContext, false, KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, 1)
+        resourceManager.createResource(extensionContext, false, KafkaConnectTemplates.kafkaConnectWithFilePlugin(extensionContext, namespaceName, clusterName, 1)
             .editOrNewMetadata()
                 .addToAnnotations(PAUSE_ANNO)
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainIsolatedST.java
Patch:
@@ -282,7 +282,7 @@ void testProducerConsumerConnect(ExtensionContext extensionContext) {
         resourceManager.createResource(extensionContext, oauthExampleClients.consumerStrimziOauthPlain());
         ClientUtils.waitForClientSuccess(consumerName, INFRA_NAMESPACE, MESSAGE_COUNT);
 
-        resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, oauthClusterName, 1)
+        resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnectWithFilePlugin(extensionContext, clusterName, INFRA_NAMESPACE, oauthClusterName, 1)
             .editMetadata()
                 .withNamespace(INFRA_NAMESPACE)
             .endMetadata()

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsIsolatedST.java
Patch:
@@ -137,7 +137,7 @@ void testProducerConsumerConnect(ExtensionContext extensionContext) {
         String defaultKafkaClientsPodName =
                 ResourceManager.kubeClient().listPodsByPrefixInName(clusterOperator.getDeploymentNamespace(), oauthClusterName + "-" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();
 
-        resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, clusterOperator.getDeploymentNamespace(), oauthClusterName, 1)
+        resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnectWithFilePlugin(extensionContext, clusterName, clusterOperator.getDeploymentNamespace(), oauthClusterName, 1)
             .editSpec()
                 .withConfig(connectorConfig)
                 .addToConfig("key.converter.schemas.enable", false)

File: systemtest/src/test/java/io/strimzi/systemtest/specific/HelmChartIsolatedST.java
Patch:
@@ -50,7 +50,7 @@ void testStrimziComponentsViaHelmChart(ExtensionContext extensionContext) {
         resourceManager.createResource(extensionContext,
             KafkaTopicTemplates.topic(clusterName, topicName).build(),
             // Deploy KafkaConnect and wait for readiness
-            KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, 1).editMetadata()
+            KafkaConnectTemplates.kafkaConnectWithFilePlugin(extensionContext, INFRA_NAMESPACE, clusterName, 1).editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
                 .endMetadata().build(),
             // Deploy KafkaBridge (different image than Kafka) and wait for readiness

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceIsolatedST.java
Patch:
@@ -104,7 +104,7 @@ void testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO(ExtensionCont
         String previousNamespace = cluster.setNamespace(SECOND_NAMESPACE);
         resourceManager.createResource(extensionContext, KafkaClientsTemplates.kafkaClients(false, kafkaClientsName).build());
         // Deploy Kafka Connect in other namespace than CO
-        resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnect(extensionContext, kafkaConnectName, SECOND_CLUSTER_NAME, 1)
+        resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnectWithFilePlugin(extensionContext, kafkaConnectName, SECOND_NAMESPACE, SECOND_CLUSTER_NAME, 1)
             .editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata()

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ClusterOperatorRbacIsolatedST.java
Patch:
@@ -14,7 +14,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
-import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
@@ -112,7 +111,6 @@ void testCRBDeletionErrorsWhenRackAwarenessIsEnabled(ExtensionContext extensionC
         assertTrue(kafkaStatusCondition.getMessage().contains("Configured service account doesn't have access."));
         assertThat(kafkaStatusCondition.getType(), is(NotReady.toString()));
 
-        resourceManager.createResource(extensionContext, KafkaClientsTemplates.kafkaClients(kafkaClientsName).build());
         resourceManager.createResource(extensionContext, false, KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, clusterName, 1)
             .editSpec()
                 .withNewRack(rackKey)

File: systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java
Patch:
@@ -49,7 +49,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
 import io.strimzi.systemtest.storage.TestStorage;
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;
-import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectorTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaMirrorMaker2Templates;
@@ -543,7 +542,6 @@ void setup(ExtensionContext extensionContext) {
 
         resourceManager.createResource(extensionContext, kafkaBuilder.build());
         resourceManager.createResource(extensionContext, KafkaTopicTemplates.topic(CUSTOM_RESOURCE_STATUS_CLUSTER_NAME, TOPIC_NAME).build());
-        resourceManager.createResource(extensionContext, KafkaClientsTemplates.kafkaClients(false, kafkaClientsName).build());
 
         topicOperatorReconciliationInterval = KafkaResource.kafkaClient().inNamespace(Constants.INFRA_NAMESPACE).withName(CUSTOM_RESOURCE_STATUS_CLUSTER_NAME).get()
             .getSpec().getEntityOperator().getTopicOperator().getReconciliationIntervalSeconds() * 1_000 * 2 + 5_000;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ReconciliationST.java
Patch:
@@ -23,7 +23,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaRebalanceResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
-import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectorTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaRebalanceTemplates;
@@ -92,7 +91,6 @@ void testPauseReconciliationInKafkaAndKafkaConnectWithConnector(ExtensionContext
         RollingUpdateUtils.waitForComponentAndPodsReady(namespaceName, kafkaSelector, SCALE_TO);
 
         LOGGER.info("Deploying KafkaConnect with pause annotation from the start, no pods should appear");
-        resourceManager.createResource(extensionContext, KafkaClientsTemplates.kafkaClients(false, kafkaClientsName).build());
         resourceManager.createResource(extensionContext, false, KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, 1)
             .editOrNewMetadata()
                 .addToAnnotations(PAUSE_ANNO)

File: systemtest/src/test/java/io/strimzi/systemtest/operators/RecoveryIsolatedST.java
Patch:
@@ -21,7 +21,6 @@
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.rollingupdate.KafkaRollerIsolatedST;
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;
-import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.utils.RollingUpdateUtils;
 import io.strimzi.systemtest.utils.StUtils;
@@ -308,10 +307,8 @@ void setup(ExtensionContext extensionContext) {
             .runInstallation();
 
         sharedClusterName = generateRandomNameOfKafka("recovery-cluster");
-        String kafkaClientsName = Constants.KAFKA_CLIENTS + "-" + sharedClusterName;
 
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaPersistent(sharedClusterName, KAFKA_REPLICAS).build());
-        resourceManager.createResource(extensionContext, KafkaClientsTemplates.kafkaClients(false, kafkaClientsName).build());
         resourceManager.createResource(extensionContext, KafkaBridgeTemplates.kafkaBridge(sharedClusterName, KafkaResources.plainBootstrapAddress(sharedClusterName), 1).build());
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -130,7 +130,7 @@ public KafkaBrokerConfigurationBuilder withCruiseControl(String clusterName, Cru
         if (cruiseControl != null) {
             printSectionHeader("Cruise Control configuration");
             String metricsTopicName = Optional.ofNullable(cruiseControl.getConfig())
-                    .map(config -> config.get(CruiseControlConfigurationParameters.CRUISE_CONTROL_METRIC_REPORTER_TOPIC_NAME.getValue()))
+                    .map(config -> config.get(CruiseControlConfigurationParameters.METRIC_REPORTER_TOPIC_NAME.getValue()))
                     .map(Object::toString)
                     .orElse(CruiseControlConfigurationParameters.DEFAULT_METRIC_REPORTER_TOPIC_NAME);
             writer.println(CruiseControlConfigurationParameters.METRICS_TOPIC_NAME + "=" + metricsTopicName);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -114,7 +114,7 @@ public void testCruiseControl()  {
     public void testCruiseControlCustomMetricReporterTopic()  {
         String metricReporterTopicName = "metric-reporter-topic";
         Map<String, Object> config = new HashMap<>();
-        config.put(CruiseControlConfigurationParameters.CRUISE_CONTROL_METRIC_REPORTER_TOPIC_NAME.getValue(), metricReporterTopicName);
+        config.put(CruiseControlConfigurationParameters.METRIC_REPORTER_TOPIC_NAME.getValue(), metricReporterTopicName);
         CruiseControlSpec cruiseControlSpec = new CruiseControlSpecBuilder().withConfig(config).build();
 
         String configuration = new KafkaBrokerConfigurationBuilder(Reconciliation.DUMMY_RECONCILIATION)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/CaReconciler.java
Patch:
@@ -30,6 +30,7 @@
 import io.strimzi.operator.cluster.operator.resource.ZooKeeperRoller;
 import io.strimzi.operator.cluster.operator.resource.ZookeeperLeaderFinder;
 import io.strimzi.operator.common.AdminClientProvider;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.BackOff;
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.Reconciliation;
@@ -477,7 +478,7 @@ Future<Void> maybeRemoveOldClusterCaCertificates() {
                     // only if all Kafka related components pods are updated to the new cluster CA cert generation,
                     // there is the possibility that we should remove the older cluster CA from the Secret and stores
                     for (Pod pod : pods) {
-                        int podClusterCaCertGeneration = Integer.parseInt(pod.getMetadata().getAnnotations().get(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION));
+                        int podClusterCaCertGeneration = Annotations.intAnnotation(pod, Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION, clusterCaCertGeneration);
                         LOGGER.debugCr(reconciliation, "Pod {} cluster CA cert generation {}", pod.getMetadata().getName(), podClusterCaCertGeneration);
 
                         if (clusterCaCertGeneration != podClusterCaCertGeneration) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -694,11 +694,13 @@ public void testReconcile(VertxTestContext context) {
 
         ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
         var mockConnectOps = supplier.connectOperator;
+        var mockConnectorOps = supplier.kafkaConnectorOperator;
         DeploymentOperator mockDcOps = supplier.deploymentOperations;
         SecretOperator mockSecretOps = supplier.secretOperations;
         PodDisruptionBudgetOperator mockPdbOps = supplier.podDisruptionBudgetOperator;
         NetworkPolicyOperator mockNetPolOps = supplier.networkPolicyOperator;
 
+        when(mockConnectorOps.listAsync(any(), any(Optional.class))).thenReturn(Future.succeededFuture(List.of()));
         String kcNamespace = "test";
 
         KafkaConnect foo = ResourceUtils.createEmptyKafkaConnect(kcNamespace, "foo");

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -624,7 +624,7 @@ void testClusterOperatorFinishAllRollingUpdates(ExtensionContext extensionContex
 
         TestUtils.waitFor("rolling update starts", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,
             () -> kubeClient(namespace).listPods(namespace).stream().filter(pod -> pod.getStatus().getPhase().equals("Running"))
-                    .map(pod -> pod.getStatus().getPhase()).collect(Collectors.toList()).size() < kubeClient().listPods().size());
+                    .map(pod -> pod.getStatus().getPhase()).collect(Collectors.toList()).size() < kubeClient().listPods(namespace).size());
 
         LabelSelector coLabelSelector = kubeClient(INFRA_NAMESPACE).getDeployment(INFRA_NAMESPACE, ResourceManager.getCoDeploymentName()).getSpec().getSelector();
         LOGGER.info("Deleting Cluster Operator pod with labels {}", coLabelSelector);
@@ -634,7 +634,7 @@ void testClusterOperatorFinishAllRollingUpdates(ExtensionContext extensionContex
         RollingUpdateUtils.waitTillComponentHasRolled(namespace, zkSelector, 3, zkPods);
 
         TestUtils.waitFor("rolling update starts", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,
-            () -> kubeClient(namespace).listPods().stream().map(pod -> pod.getStatus().getPhase()).collect(Collectors.toList()).contains("Pending"));
+            () -> kubeClient(namespace).listPods(namespace).stream().map(pod -> pod.getStatus().getPhase()).collect(Collectors.toList()).contains("Pending"));
 
         LOGGER.info("Deleting Cluster Operator pod with labels {}", coLabelSelector);
         kubeClient(INFRA_NAMESPACE).deletePodsByLabelSelector(coLabelSelector);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorNonParametrizedTest.java
Patch:
@@ -53,7 +53,7 @@
 import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.eq;
 import static org.mockito.Mockito.times;
-import static org.mockito.Mockito.verifyZeroInteractions;
+import static org.mockito.Mockito.verifyNoInteractions;
 import static org.mockito.Mockito.when;
 
 @ExtendWith(VertxExtension.class)
@@ -394,7 +394,7 @@ public void testSelectorLabels(VertxTestContext context) {
                     // The resource labels don't match the selector labels => the reconciliation should exit right on
                     // beginning with success. It should not reconcile any resources other than getting the Kafka
                     // resource it self.
-                    verifyZeroInteractions(
+                    verifyNoInteractions(
                             supplier.stsOperations,
                             supplier.serviceOperations,
                             supplier.secretOperations,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -73,7 +73,7 @@
 import static org.junit.jupiter.api.Assertions.assertTrue;
 import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.eq;
-import static org.mockito.Mockito.verifyZeroInteractions;
+import static org.mockito.Mockito.verifyNoInteractions;
 import static org.mockito.Mockito.when;
 
 @ExtendWith(VertxExtension.class)
@@ -1012,7 +1012,7 @@ public void testKafkaClusterNotMatchingLabelSelector(VertxTestContext context) {
                 kr).onComplete(context.succeeding(v -> context.verify(() -> {
                     // The labels of the Kafka resource do not match the => the KafkaRebalance should not be reconciled and the
                     // rebalance ops should have no interactions.
-                    verifyZeroInteractions(mockRebalanceOps);
+                    verifyNoInteractions(mockRebalanceOps);
                     checkpoint.flag();
                 })));
     }

File: topic-operator/src/main/java/io/strimzi/operator/topic/Main.java
Patch:
@@ -47,6 +47,7 @@ private void deploy(Config config) {
                         .setJvmMetricsEnabled(true)
                         .setEnabled(true));
         Vertx vertx = Vertx.vertx(options);
+
         Session session = new Session(kubeClient, config);
         vertx.deployVerticle(session, ar -> {
             if (ar.succeeded()) {

File: api/src/main/java/io/strimzi/api/kafka/model/CruiseControlSpec.java
Patch:
@@ -34,8 +34,7 @@ public class CruiseControlSpec implements HasConfigurableMetrics, UnknownPropert
     // For the full configuration list refer to https://github.com/linkedin/cruise-control/wiki/Configurations
     public static final String FORBIDDEN_PREFIXES = "bootstrap.servers, client.id, zookeeper., network., security., failed.brokers.zk.path,"
         + "webserver.http., webserver.api.urlprefix, webserver.session.path, webserver.accesslog., two.step., request.reason.required,"
-        + "metric.reporter.sampler.bootstrap.servers, metric.reporter.topic, partition.metric.sample.store.topic, broker.metric.sample.store.topic,"
-        + "capacity.config.file, self.healing., ssl., kafka.broker.failure.detection.enable, topic.config.provider.class";
+        + "metric.reporter.sampler.bootstrap.servers, capacity.config.file, self.healing., ssl., kafka.broker.failure.detection.enable, topic.config.provider.class";
     public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols, webserver.http.cors.enabled, "
         + "webserver.http.cors.origin, webserver.http.cors.exposeheaders, webserver.security.enable, webserver.ssl.enable";
 

File: api/src/main/java/io/strimzi/api/kafka/model/template/CruiseControlTemplate.java
Patch:
@@ -6,6 +6,7 @@
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import io.strimzi.api.annotations.DeprecatedProperty;
 import io.strimzi.api.kafka.model.Constants;
 import io.strimzi.api.kafka.model.UnknownPropertyPreserving;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -90,6 +91,8 @@ public void setCruiseControlContainer(ContainerTemplate cruiseControlContainer)
         this.cruiseControlContainer = cruiseControlContainer;
     }
 
+    @DeprecatedProperty
+    @Deprecated
     @Description("Template for the Cruise Control TLS sidecar container")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public ContainerTemplate getTlsSidecarContainer() {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/CruiseControlUtils.java
Patch:
@@ -60,7 +60,7 @@ public static String callApi(String namespaceName, SupportedHttpMethods method,
         String args = " -k ";
 
         if (withCredentials) {
-            args = " --cacert /etc/tls-sidecar/cc-certs/cruise-control.crt"
+            args = " --cacert /etc/cruise-control/cc-certs/cruise-control.crt"
                 + " --user admin:$(cat /opt/cruise-control/api-auth-config/cruise-control.apiAdminPassword) ";
         }
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/BridgeClients.java
Patch:
@@ -63,7 +63,7 @@ public Job producerStrimziBridge() {
                         .withLabels(producerLabels)
                     .endMetadata()
                     .withNewSpecLike(podSpecBuilder.build())
-                        .withRestartPolicy("OnFailure")
+                        .withRestartPolicy("Never")
                         .addNewContainer()
                             .withName(this.getProducerName())
                             .withImagePullPolicy(Constants.IF_NOT_PRESENT_IMAGE_PULL_POLICY)
@@ -120,7 +120,7 @@ public Job consumerStrimziBridge() {
                         .withLabels(consumerLabels)
                     .endMetadata()
                     .withNewSpecLike(podSpecBuilder.build())
-                        .withRestartPolicy("OnFailure")
+                        .withRestartPolicy("Never")
                         .addNewContainer()
                             .withName(this.getConsumerName())
                             .withImagePullPolicy(Constants.IF_NOT_PRESENT_IMAGE_PULL_POLICY)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/CruiseControlReconciler.java
Patch:
@@ -281,8 +281,8 @@ Future<Void> cruiseControlDeployment(boolean isOpenShift, ImagePullPolicy imageP
                     .reconcile(reconciliation, reconciliation.namespace(), CruiseControlResources.deploymentName(reconciliation.name()), deployment)
                     .compose(patchResult -> {
                         if (patchResult instanceof ReconcileResult.Noop)   {
-                            // Deployment needs ot be rolled because the certificate secret changed
-                            if (existingCertsChanged) {
+                            // Deployment needs ot be rolled because the certificate secret changed or older/expired cluster CA removed
+                            if (existingCertsChanged || clusterCa.certsRemoved()) {
                                 return cruiseControlRollingUpdate();
                             }
                         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/EntityOperatorReconciler.java
Patch:
@@ -404,8 +404,8 @@ Future<Void> reconcileDeployment(boolean isOpenShift, ImagePullPolicy imagePullP
                     .reconcile(reconciliation, reconciliation.namespace(), KafkaResources.entityOperatorDeploymentName(reconciliation.name()), deployment)
                     .compose(patchResult -> {
                         if (patchResult instanceof ReconcileResult.Noop)   {
-                            // Deployment needs ot be rolled because the certificate secret changed
-                            if (existingEntityTopicOperatorCertsChanged || existingEntityUserOperatorCertsChanged) {
+                            // Deployment needs ot be rolled because the certificate secret changed or older/expired cluster CA removed
+                            if (existingEntityTopicOperatorCertsChanged || existingEntityUserOperatorCertsChanged || clusterCa.certsRemoved()) {
                                 return rollDeployment();
                             }
                         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaExporterReconciler.java
Patch:
@@ -162,8 +162,8 @@ private Future<Void> kafkaExporterDeployment(boolean isOpenShift, ImagePullPolic
                     .reconcile(reconciliation, reconciliation.namespace(), KafkaExporterResources.deploymentName(reconciliation.name()), deployment)
                     .compose(patchResult -> {
                         if (patchResult instanceof ReconcileResult.Noop)   {
-                            // Deployment needs ot be rolled because the certificate secret changed
-                            if (existingKafkaExporterCertsChanged) {
+                            // Deployment needs ot be rolled because the certificate secret changed or older/expired cluster CA removed
+                            if (existingKafkaExporterCertsChanged || clusterCa.certsRemoved()) {
                                 return kafkaExporterRollingUpdate();
                             }
                         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -138,10 +138,10 @@ public abstract class AbstractModel {
 
     public static final String NETWORK_POLICY_KEY_SUFFIX = "-network-policy";
 
-    public static final String ENV_VAR_DYNAMIC_HEAP_FRACTION = "DYNAMIC_HEAP_FRACTION";
+    public static final String ENV_VAR_DYNAMIC_HEAP_PERCENTAGE = "STRIMZI_DYNAMIC_HEAP_PERCENTAGE";
     public static final String ENV_VAR_KAFKA_HEAP_OPTS = "KAFKA_HEAP_OPTS";
     public static final String ENV_VAR_KAFKA_JVM_PERFORMANCE_OPTS = "KAFKA_JVM_PERFORMANCE_OPTS";
-    public static final String ENV_VAR_DYNAMIC_HEAP_MAX = "DYNAMIC_HEAP_MAX";
+    public static final String ENV_VAR_DYNAMIC_HEAP_MAX = "STRIMZI_DYNAMIC_HEAP_MAX";
     public static final String ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED = "STRIMZI_KAFKA_GC_LOG_ENABLED";
     public static final String ENV_VAR_STRIMZI_JAVA_SYSTEM_PROPERTIES = "STRIMZI_JAVA_SYSTEM_PROPERTIES";
     public static final String ENV_VAR_STRIMZI_JAVA_OPTS = "STRIMZI_JAVA_OPTS";

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -464,7 +464,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_API_PORT,  String.valueOf(REST_API_PORT)));
         varList.add(buildEnvVar(ENV_VAR_API_HEALTHCHECK_PATH, API_HEALTHCHECK_PATH));
 
-        ModelUtils.heapOptions(varList, 1.0, 0L, getJvmOptions(), getResources());
+        ModelUtils.heapOptions(varList, 75, 0L, getJvmOptions(), getResources());
         ModelUtils.jvmPerformanceOptions(varList, getJvmOptions());
         ModelUtils.jvmSystemProperties(varList, getJvmOptions());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1645,7 +1645,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_KAFKA_METRICS_ENABLED, String.valueOf(isMetricsEnabled)));
         varList.add(buildEnvVar(ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
 
-        ModelUtils.heapOptions(varList, 0.5, 5L * 1024L * 1024L * 1024L, getJvmOptions(), getResources());
+        ModelUtils.heapOptions(varList, 50, 5L * 1024L * 1024L * 1024L, getJvmOptions(), getResources());
         ModelUtils.jvmPerformanceOptions(varList, getJvmOptions());
         ModelUtils.jvmSystemProperties(varList, getJvmOptions());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -539,7 +539,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_KAFKA_CONNECT_BOOTSTRAP_SERVERS, bootstrapServers));
         varList.add(buildEnvVar(ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
 
-        ModelUtils.heapOptions(varList, 1.0, 0L, getJvmOptions(), getResources());
+        ModelUtils.heapOptions(varList, 75, 0L, getJvmOptions(), getResources());
         ModelUtils.jvmPerformanceOptions(varList, getJvmOptions());
         ModelUtils.jvmSystemProperties(varList, getJvmOptions());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -351,7 +351,7 @@ protected List<EnvVar> getEnvVars() {
             varList.add(buildEnvVar(ENV_VAR_STRIMZI_TRACING, tracing.getType()));
         }
 
-        ModelUtils.heapOptions(varList, 1.0, 0L, getJvmOptions(), getResources());
+        ModelUtils.heapOptions(varList, 75, 0L, getJvmOptions(), getResources());
         ModelUtils.jvmPerformanceOptions(varList, getJvmOptions());
         ModelUtils.jvmSystemProperties(varList, getJvmOptions());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -551,7 +551,7 @@ protected List<EnvVar> getEnvVars() {
             }
         }
 
-        ModelUtils.heapOptions(varList, 0.75, 2L * 1024L * 1024L * 1024L, getJvmOptions(), getResources());
+        ModelUtils.heapOptions(varList, 75, 2L * 1024L * 1024L * 1024L, getJvmOptions(), getResources());
         ModelUtils.jvmPerformanceOptions(varList, getJvmOptions());
         ModelUtils.jvmSystemProperties(varList, getJvmOptions());
         varList.add(buildEnvVar(ENV_VAR_ZOOKEEPER_CONFIGURATION, configuration.getConfiguration()));

File: systemtest/src/test/java/io/strimzi/systemtest/specific/DrainCleanerIsolatedST.java
Patch:
@@ -36,6 +36,7 @@
 import java.util.stream.Collectors;
 import java.util.stream.IntStream;
 
+import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;
 
@@ -46,6 +47,7 @@ public class DrainCleanerIsolatedST extends AbstractST {
     private static final Logger LOGGER = LogManager.getLogger(DrainCleanerIsolatedST.class);
     private static SetupDrainCleaner drainCleaner = new SetupDrainCleaner();
 
+    @Tag(ACCEPTANCE)
     @IsolatedTest
     @RequiredMinKubeApiVersion(version = 1.17)
     void testDrainCleanerWithComponents(ExtensionContext extensionContext) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java
Patch:
@@ -97,7 +97,7 @@ public void start(Promise<Void> start) {
         getVertx().createSharedWorkerExecutor("kubernetes-ops-pool", config.getOperationsThreadPoolSize(), TimeUnit.SECONDS.toNanos(120));
 
         if (config.featureGates().useStrimziPodSetsEnabled()) {
-            strimziPodSetController = new StrimziPodSetController(namespace, config.getCustomResourceSelector(), resourceOperatorSupplier.kafkaOperator, resourceOperatorSupplier.strimziPodSetOperator, resourceOperatorSupplier.podOperations);
+            strimziPodSetController = new StrimziPodSetController(namespace, config.getCustomResourceSelector(), resourceOperatorSupplier.kafkaOperator, resourceOperatorSupplier.strimziPodSetOperator, resourceOperatorSupplier.podOperations, config.getPodSetControllerWorkQueueSize());
             strimziPodSetController.start();
         }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/StrimziPodSetController.java
Patch:
@@ -58,7 +58,7 @@ public class StrimziPodSetController implements Runnable {
     private final Optional<LabelSelector> crSelector;
     private final String watchedNamespace;
 
-    private final BlockingQueue<SimplifiedReconciliation> workQueue = new ArrayBlockingQueue<>(1024);
+    private final BlockingQueue<SimplifiedReconciliation> workQueue;
     private final SharedIndexInformer<Pod> podInformer;
     private final SharedIndexInformer<StrimziPodSet> strimziPodSetInformer;
     private final SharedIndexInformer<Kafka> kafkaInformer;
@@ -78,11 +78,12 @@ public class StrimziPodSetController implements Runnable {
      *                              their status etc.
      * @param podOperator           Pod operator for managing pods
      */
-    public StrimziPodSetController(String watchedNamespace, Labels crSelectorLabels, CrdOperator<KubernetesClient, Kafka, KafkaList> kafkaOperator, CrdOperator<KubernetesClient, StrimziPodSet, StrimziPodSetList> strimziPodSetOperator, PodOperator podOperator) {
+    public StrimziPodSetController(String watchedNamespace, Labels crSelectorLabels, CrdOperator<KubernetesClient, Kafka, KafkaList> kafkaOperator, CrdOperator<KubernetesClient, StrimziPodSet, StrimziPodSetList> strimziPodSetOperator, PodOperator podOperator, int podSetControllerWorkQueueSize) {
         this.podOperator = podOperator;
         this.strimziPodSetOperator = strimziPodSetOperator;
         this.crSelector = (crSelectorLabels == null || crSelectorLabels.toMap().isEmpty()) ? Optional.empty() : Optional.of(new LabelSelector(null, crSelectorLabels.toMap()));
         this.watchedNamespace = watchedNamespace;
+        this.workQueue = new ArrayBlockingQueue<>(podSetControllerWorkQueueSize);
 
         // Kafka informer and lister is used to get Kafka CRs quickly. This is needed for verification of the CR selector labels
         this.kafkaInformer = kafkaOperator.informer(watchedNamespace, (crSelectorLabels == null) ? Map.of() : crSelectorLabels.toMap());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
Patch:
@@ -89,7 +89,8 @@ public void testReconciliationInterval() {
                 10,
                 20_000,
                 10,
-                false);
+                false,
+                1024);
 
         assertThat(config.getNamespaces(), is(singleton("namespace")));
         assertThat(config.getReconciliationIntervalMs(), is(60_000L));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorNonParametrizedTest.java
Patch:
@@ -382,7 +382,8 @@ public void testSelectorLabels(VertxTestContext context) {
                 10,
                 10_000,
                 30,
-                false);
+                false,
+                1024);
 
         KafkaAssemblyOperator op = new KafkaAssemblyOperator(vertx, new PlatformFeaturesAvailability(false, KubernetesVersion.V1_19), certManager, passwordGenerator,
                 supplier, config);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -942,7 +942,8 @@ public void testKafkaClusterNotMatchingLabelSelector(VertxTestContext context) {
                 10,
                 10_000,
                 30,
-                false);
+                false,
+                1024);
 
         kcrao = new KafkaRebalanceAssemblyOperator(Vertx.vertx(), pfa, supplier, config);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/StrimziPodSetControllerIT.java
Patch:
@@ -62,6 +62,7 @@ public class StrimziPodSetControllerIT {
     private static final Map<String, String> MATCHING_LABELS = Map.of("selector", "matching");
     private static final String OTHER_KAFKA_NAME = "bar";
     private static final Map<String, String> OTHER_LABELS = Map.of("selector", "not-matching");
+    private static final int POD_SET_CONTROLLER_WORK_QUEUE_SIZE = 1024;
 
     private static KubernetesClient client;
     private static KubeClusterResource cluster;
@@ -223,7 +224,7 @@ private static void checkOwnerReference(HasMetadata resource, String podSetName)
     }
 
     private static void startController()  {
-        controller = new StrimziPodSetController(NAMESPACE, Labels.fromMap(MATCHING_LABELS), kafkaOperator, podSetOperator, podOperator);
+        controller = new StrimziPodSetController(NAMESPACE, Labels.fromMap(MATCHING_LABELS), kafkaOperator, podSetOperator, podOperator, POD_SET_CONTROLLER_WORK_QUEUE_SIZE);
         controller.start();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -385,6 +385,7 @@ public interface Constants {
     String KAFKA_TRACING_CLIENT_KEY = "KAFKA_TRACING_CLIENT";
     String KAFKA_SELECTOR = "KAFKA_SELECTOR";
     String ZOOKEEPER_SELECTOR = "ZOOKEEPER_SELECTOR";
+    String ENTITY_OPERATOR_NAME = "ENTITY_OPERATOR_NAME";
 
     /**
      * Resource constants for Cluster Operator. In case we execute more than 5 test cases in parallel we at least these configuration

File: systemtest/src/main/java/io/strimzi/systemtest/security/SystemTestCertManager.java
Patch:
@@ -122,7 +122,7 @@ public static CertAndKeyFiles exportToPemFiles(SystemTestCertAndKey... certs) {
         }
     }
 
-    static File convertPrivateKeyToPKCS8File(PrivateKey privatekey) throws NoSuchAlgorithmException, InvalidKeySpecException, IOException {
+    public static File convertPrivateKeyToPKCS8File(PrivateKey privatekey) throws NoSuchAlgorithmException, InvalidKeySpecException, IOException {
         byte[] encoded = privatekey.getEncoded();
         final PrivateKeyInfo privateKeyInfo = PrivateKeyInfo.getInstance(encoded);
 
@@ -155,7 +155,7 @@ private static File exportCertsToPemFile(SystemTestCertAndKey... certs) throws I
         return certFile;
     }
 
-    static boolean containsAllDN(String principal1, String principal2) {
+    public static boolean containsAllDN(String principal1, String principal2) {
         try {
             return new LdapName(principal1).getRdns().containsAll(new LdapName(principal2).getRdns());
         } catch (InvalidNameException e) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java
Patch:
@@ -211,7 +211,7 @@ public static void waitUntilPodStabilityReplicasCount(String namespaceName, Stri
         TestUtils.waitFor(" Pod" + podNamePrefix + " will have " + expectedPods + " replicas",
             Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,
             () -> {
-                if (kubeClient(namespaceName).listPodsByPrefixInName(podNamePrefix).size() == expectedPods) {
+                if (kubeClient(namespaceName).listPodsByPrefixInName(namespaceName, podNamePrefix).size() == expectedPods) {
                     stableCounter[0]++;
                     if (stableCounter[0] == Constants.GLOBAL_STABILITY_OFFSET_COUNT) {
                         LOGGER.info("Pod replicas are stable for {} polls intervals", stableCounter[0]);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Cluster.java
Patch:
@@ -291,9 +291,7 @@ protected List<EnvVar> getEnvVars() {
             varList.add(buildEnvVar(ENV_VAR_KAFKA_MIRRORMAKER_2_OAUTH_REFRESH_TOKENS_CLUSTERS, clustersOauthRefreshTokens.toString()));
         }
 
-        if (javaSystemProperties != null) {
-            varList.add(buildEnvVar(ENV_VAR_STRIMZI_JAVA_SYSTEM_PROPERTIES, ModelUtils.getJavaSystemPropertiesToString(javaSystemProperties)));
-        }
+        ModelUtils.jvmSystemProperties(varList, getJvmOptions());
 
         return varList;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractModelTest.java
Patch:
@@ -86,7 +86,7 @@ private Map<String, String> getStringStringMap(String xmx, String xms, double dy
         am.setJvmOptions(jvmOptions(xmx, xms));
         am.setResources(resources);
         List<EnvVar> envVars = new ArrayList<>(1);
-        am.heapOptions(envVars, dynamicFraction, dynamicMax);
+        ModelUtils.heapOptions(envVars, dynamicFraction, dynamicMax, am.getJvmOptions(), am.getResources());
         return envVars.stream().collect(Collectors.toMap(e -> e.getName(), e -> e.getValue()));
     }
 
@@ -169,7 +169,7 @@ private String getPerformanceOptions(JvmOptions opts) {
         am.setLabels(Labels.forStrimziCluster("foo"));
         am.setJvmOptions(opts);
         List<EnvVar> envVars = new ArrayList<>(1);
-        am.jvmPerformanceOptions(envVars);
+        ModelUtils.jvmPerformanceOptions(envVars, am.getJvmOptions());
 
         if (!envVars.isEmpty()) {
             return envVars.get(0).getValue();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -183,8 +183,8 @@ public void testMetricsConfigMap() {
 
     @ParallelTest
     public void  testJavaSystemProperties() {
-        assertThat(kc.getEnvVars().get(2).getName(), is("STRIMZI_JAVA_SYSTEM_PROPERTIES"));
-        assertThat(kc.getEnvVars().get(2).getValue(), is("-D" + javaSystemProperties.get(0).getName() + "=" + javaSystemProperties.get(0).getValue() + " " +
+        assertThat(kc.getEnvVars().get(3).getName(), is("STRIMZI_JAVA_SYSTEM_PROPERTIES"));
+        assertThat(kc.getEnvVars().get(3).getValue(), is("-D" + javaSystemProperties.get(0).getName() + "=" + javaSystemProperties.get(0).getValue() + " " +
                 "-D" + javaSystemProperties.get(1).getName() + "=" + javaSystemProperties.get(1).getValue()));
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -367,7 +367,6 @@ public interface Constants {
      */
     String NAMESPACE_KEY = "NAMESPACE_NAME";
     String PREPARE_OPERATOR_ENV_KEY = "PREPARE_OPERATOR_ENV";
-    String PARALLEL_CLASS_COUNT = "PARALLEL_CLASS_COUNT";
 
     /**
      * Auxiliary variable for cluster operator deployment

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -151,7 +151,6 @@ public class Environment {
     public static final String OLM_OPERATOR_DEPLOYMENT_NAME_DEFAULT = Constants.STRIMZI_DEPLOYMENT_NAME;
     public static final String OLM_SOURCE_NAME_DEFAULT = "community-operators";
     public static final String OLM_APP_BUNDLE_PREFIX_DEFAULT = "strimzi-cluster-operator";
-    public static final String OLM_OPERATOR_VERSION_DEFAULT = "0.26.1";
     private static final boolean DEFAULT_TO_DENY_NETWORK_POLICIES_DEFAULT = true;
     private static final ClusterOperatorInstallType CLUSTER_OPERATOR_INSTALL_TYPE_DEFAULT = ClusterOperatorInstallType.BUNDLE;
     private static final boolean LB_FINALIZERS_DEFAULT = false;
@@ -206,7 +205,7 @@ public class Environment {
     public static final String OLM_SOURCE_NAME = getOrDefault(OLM_SOURCE_NAME_ENV, OLM_SOURCE_NAME_DEFAULT);
     public static final String OLM_SOURCE_NAMESPACE = getOrDefault(OLM_SOURCE_NAMESPACE_ENV, OpenShift.OLM_SOURCE_NAMESPACE);
     public static final String OLM_APP_BUNDLE_PREFIX = getOrDefault(OLM_APP_BUNDLE_PREFIX_ENV, OLM_APP_BUNDLE_PREFIX_DEFAULT);
-    public static final String OLM_OPERATOR_LATEST_RELEASE_VERSION = getOrDefault(OLM_OPERATOR_VERSION_ENV, OLM_OPERATOR_VERSION_DEFAULT);
+    public static final String OLM_OPERATOR_LATEST_RELEASE_VERSION = getOrDefault(OLM_OPERATOR_VERSION_ENV, "");
     // NetworkPolicy variable
     public static final boolean DEFAULT_TO_DENY_NETWORK_POLICIES = getOrDefault(DEFAULT_TO_DENY_NETWORK_POLICIES_ENV, Boolean::parseBoolean, DEFAULT_TO_DENY_NETWORK_POLICIES_DEFAULT);
     // ClusterOperator installation type variable

File: systemtest/src/main/java/io/strimzi/systemtest/logs/TestExecutionWatcher.java
Patch:
@@ -72,6 +72,7 @@ public void handleAfterAllMethodExecutionException(ExtensionContext extensionCon
 
         SuiteThreadController suiteThreadController = SuiteThreadController.getInstance();
         if (StUtils.isParallelSuite(extensionContext)) {
+            suiteThreadController.notifyParallelSuiteToAllowExecution(extensionContext);
             suiteThreadController.removeParallelSuite(extensionContext);
         }
 

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/LogHasNoUnexpectedErrors.java
Patch:
@@ -73,7 +73,7 @@ enum LogIgnoreList {
                 + "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: PATCH"),
         // This happen from time to time during CO startup, it doesn't influence CO behavior
         EXIT_ON_OUT_OF_MEMORY("ExitOnOutOfMemoryError"),
-        OPERATION_TIMEOUT("Util:[0-9]+ - Exceeded timeout of.*while waiting for.*"),
+        OPERATION_TIMEOUT("Util:[0-9]+ - Reconciliation #[0-9]+.*Exceeded timeout of.*while waiting for.*"),
         // This is ignored cause it's no real problem when this error appears, components are being created even after timeout
         RECONCILIATION_TIMEOUT("ERROR Abstract.*Operator:[0-9]+ - Reconciliation.*"),
         ASSEMBLY_OPERATOR_RECONCILIATION_TIMEOUT("ERROR .*AssemblyOperator:[0-9]+ - Reconciliation.*[fF]ailed.*"),

File: systemtest/src/main/java/io/strimzi/systemtest/parallel/TestSuiteNamespaceManager.java
Patch:
@@ -134,6 +134,9 @@ public void createAdditionalNamespaces(ExtensionContext extensionContext) {
                 }
                 KubeClusterResource.getInstance().createNamespace(CollectorElement.createCollectorElement(testSuite), namespaceName);
                 NetworkPolicyResource.applyDefaultNetworkPolicySettings(extensionContext, Collections.singletonList(namespaceName));
+                if (Environment.SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET != null && !Environment.SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET.isEmpty()) {
+                    StUtils.copyImagePullSecret(namespaceName);
+                }
             }
         }
     }

File: systemtest/src/test/java/io/strimzi/systemtest/backup/ColdBackupScriptIsolatedST.java
Patch:
@@ -16,9 +16,9 @@
 import io.strimzi.systemtest.kafkaclients.internalClients.KafkaClientsBuilder;
 
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.JobUtils;
-import io.strimzi.test.annotations.IsolatedSuite;
 import io.strimzi.test.annotations.IsolatedTest;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;

File: systemtest/src/test/java/io/strimzi/systemtest/dump/LogDumpScriptIsolatedST.java
Patch:
@@ -17,7 +17,7 @@
 import io.strimzi.systemtest.storage.TestStorage;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.utils.ClientUtils;
-import io.strimzi.test.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.test.annotations.IsolatedTest;
 import io.strimzi.test.executor.Exec;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationIsolatedST.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
+import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
@@ -685,7 +686,7 @@ void setUp(ExtensionContext extensionContext)  {
     @AfterAll
     void tearDown(ExtensionContext extensionContext) throws Exception {
         // delete keycloak before namespace
-        KeycloakUtils.deleteKeycloak(INFRA_NAMESPACE);
+        KeycloakUtils.deleteKeycloak(Constants.INFRA_NAMESPACE, clusterOperator.getDeploymentNamespace());
         // delete namespace etc.
         super.afterAllMayOverride(extensionContext);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainIsolatedST.java
Patch:
@@ -798,7 +798,7 @@ void setUp(ExtensionContext extensionContext) {
     @AfterAll
     void tearDown(ExtensionContext extensionContext) throws Exception {
         // delete keycloak before namespace
-        KeycloakUtils.deleteKeycloak(INFRA_NAMESPACE);
+        KeycloakUtils.deleteKeycloak(Constants.INFRA_NAMESPACE, clusterOperator.getDeploymentNamespace());
         // delete namespace etc.
         super.afterAllMayOverride(extensionContext);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthScopeIsolatedST.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
+import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.ParallelTest;
@@ -278,7 +279,7 @@ void setUp(ExtensionContext extensionContext) {
     @AfterAll
     void tearDown(ExtensionContext extensionContext) throws Exception {
         // delete keycloak before namespace
-        KeycloakUtils.deleteKeycloak(INFRA_NAMESPACE);
+        KeycloakUtils.deleteKeycloak(Constants.INFRA_NAMESPACE, clusterOperator.getDeploymentNamespace());
         // delete namespace etc.
         super.afterAllMayOverride(extensionContext);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/specific/ClusterOperationIsolatedST.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.NodeUtils;
-import io.strimzi.test.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.AfterEach;

File: systemtest/src/test/java/io/strimzi/systemtest/specific/HelmChartIsolatedST.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.systemtest.templates.crd.KafkaConnectorTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
-import io.strimzi.test.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.test.logs.CollectorElement;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificIsolatedST.java
Patch:
@@ -44,7 +44,7 @@
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.systemtest.utils.specific.BridgeUtils;
-import io.strimzi.test.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.test.executor.Exec;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/AbstractUpgradeST.java
Patch:
@@ -31,7 +31,7 @@
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
-import io.strimzi.test.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.test.executor.Exec;
 import io.strimzi.test.executor.ExecResult;
 import io.vertx.core.json.JsonArray;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/KafkaUpgradeDowngradeIsolatedST.java
Patch:
@@ -18,7 +18,7 @@
 import io.strimzi.systemtest.utils.TestKafkaVersion;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
-import io.strimzi.test.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziDowngradeIsolatedST.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
-import io.strimzi.test.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.vertx.core.json.JsonObject;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeIsolatedST.java
Patch:
@@ -18,7 +18,7 @@
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
-import io.strimzi.test.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.vertx.core.json.JsonObject;
 import io.vertx.core.json.JsonArray;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java
Patch:
@@ -18,7 +18,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils;
 import io.strimzi.test.TestUtils;
-import io.strimzi.test.annotations.IsolatedSuite;
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.extension.ExtensionContext;

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceIsolatedST.java
Patch:
@@ -192,7 +192,7 @@ private void deployTestSpecificResources(ExtensionContext extensionContext) {
         clusterOperator.unInstall();
         clusterOperator = clusterOperator.defaultInstallation()
             .withWatchingNamespaces(Constants.WATCH_ALL_NAMESPACES)
-            .withBindingsNamespaces(Arrays.asList(Constants.INFRA_NAMESPACE, SECOND_NAMESPACE, THIRD_NAMESPACE))
+            .withBindingsNamespaces(Arrays.asList(clusterOperator.getDeploymentNamespace(), SECOND_NAMESPACE, THIRD_NAMESPACE))
             .createInstallation()
             .runInstallation();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -4464,7 +4464,7 @@ Future<ReconciliationState> kafkaExporterReady() {
         Future<ReconciliationState> getJmxTransDescription() {
             try {
                 int numOfBrokers = kafkaCluster.getReplicas();
-                this.jmxTrans = JmxTrans.fromCrd(reconciliation, kafkaAssembly, versions);
+                this.jmxTrans = JmxTrans.fromCrd(reconciliation, kafkaAssembly);
                 if (this.jmxTrans != null) {
                     this.jmxTransConfigMap = jmxTrans.generateJmxTransConfigMap(kafkaAssembly.getSpec().getJmxTrans(), numOfBrokers);
                     this.jmxTransDeployment = jmxTrans.generateDeployment(imagePullPolicy, imagePullSecrets);

File: systemtest/src/main/java/io/strimzi/systemtest/enums/DeploymentTypes.java
Patch:
@@ -11,4 +11,5 @@ public enum DeploymentTypes {
     OlmClusterOperator,
     KafkaClients,
     DrainCleaner,
+    Scraper,
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/NetworkPolicyResource.java
Patch:
@@ -168,7 +168,7 @@ public static void allowNetworkPolicySettingsForKafkaExporter(ExtensionContext e
      */
     public static void allowNetworkPolicySettingsForResource(ExtensionContext extensionContext, HasMetadata resource, String deploymentName) {
         LabelSelector labelSelector = new LabelSelectorBuilder()
-            .addToMatchLabels(Constants.KAFKA_CLIENTS_LABEL_KEY, Constants.KAFKA_CLIENTS_LABEL_VALUE)
+            .addToMatchLabels(Constants.SCRAPER_LABEL_KEY, Constants.SCRAPER_LABEL_VALUE)
             .build();
 
         final String namespaceName = StUtils.isParallelNamespaceTest(extensionContext) && !Environment.isNamespaceRbacScope() ?

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlST.java
Patch:
@@ -201,7 +201,7 @@ void testCruiseControlTopicExclusion(ExtensionContext extensionContext) {
 
         resourceManager.createResource(extensionContext,  KafkaRebalanceTemplates.kafkaRebalance(clusterName)
             .editOrNewSpec()
-            .withExcludedTopics("excluded-.*")
+                .withExcludedTopics("excluded-.*")
             .endSpec()
             .build());
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/FeatureGatesIsolatedST.java
Patch:
@@ -328,6 +328,6 @@ void testSwitchingStrimziPodSetFeatureGateOnAndOff(ExtensionContext extensionCon
         RollingUpdateUtils.waitTillComponentHasRolled(zkSelector, zkReplicas, zkPods);
         RollingUpdateUtils.waitTillComponentHasRolled(kafkaSelector, kafkaReplicas, kafkaPods);
 
-        ClientUtils.waitTillContinuousClientsFinish(producerName, consumerName, INFRA_NAMESPACE, messageCount);
+        ClientUtils.waitForClientsSuccess(producerName, consumerName, INFRA_NAMESPACE, messageCount);
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -205,7 +205,7 @@ void testManualTriggeringRollingUpdate(ExtensionContext extensionContext) {
         // ##############################
         // Validate that continuous clients finished successfully
         // ##############################
-        ClientUtils.waitTillContinuousClientsFinish(producerName, consumerName, namespaceName, continuousClientsMessageCount);
+        ClientUtils.waitForClientsSuccess(producerName, consumerName, namespaceName, continuousClientsMessageCount);
         // ##############################
     }
 
@@ -429,7 +429,7 @@ void testAddingAndRemovingJbodVolumes(ExtensionContext extensionContext) {
         // ##############################
         // Validate that continuous clients finished successfully
         // ##############################
-        ClientUtils.waitTillContinuousClientsFinish(producerName, consumerName, namespaceName, continuousClientsMessageCount);
+        ClientUtils.waitForClientsSuccess(producerName, consumerName, namespaceName, continuousClientsMessageCount);
         // ##############################
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthScopeIsolatedST.java
Patch:
@@ -178,7 +178,6 @@ void testClientScopeKafkaSetCorrectly(ExtensionContext extensionContext) throws
         resourceManager.createResource(extensionContext, oauthInternalClientChecksJob.producerStrimzi());
         // client should succeeded because we set to `clientScope=test` and also Kafka has `scope=test`
         ClientUtils.waitForClientSuccess(producerName, INFRA_NAMESPACE, MESSAGE_COUNT);
-        JobUtils.deleteJobWithWait(INFRA_NAMESPACE, producerName);
     }
 
     @IsolatedTest("Modification of shared Kafka cluster")

File: systemtest/src/test/java/io/strimzi/systemtest/specific/ClusterOperationIsolatedST.java
Patch:
@@ -90,9 +90,7 @@ void testAvailabilityDuringNodeDrain(ExtensionContext extensionContext) {
             NodeUtils.cordonNode(node.getMetadata().getName(), true);
         });
 
-        producerNames.forEach(producerName -> ClientUtils.waitTillContinuousClientsFinish(producerName, consumerNames.get(producerName.indexOf(producerName)), NAMESPACE, continuousClientsMessageCount));
-        producerNames.forEach(producerName -> kubeClient().deleteJob(producerName));
-        consumerNames.forEach(consumerName -> kubeClient().deleteJob(consumerName));
+        producerNames.forEach(producerName -> ClientUtils.waitForClientsSuccess(producerName, consumerNames.get(producerName.indexOf(producerName)), NAMESPACE, continuousClientsMessageCount));
     }
 
     @BeforeAll

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -399,7 +399,7 @@ void testProducerConsumerStreamsConnectService(ExtensionContext extensionContext
         resourceManager.createResource(extensionContext, ((KafkaTracingClients) extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get(KAFKA_TRACING_CLIENT_KEY)).producerWithTracing());
         resourceManager.createResource(extensionContext, ((KafkaTracingClients) extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get(KAFKA_TRACING_CLIENT_KEY)).consumerWithTracing());
 
-        ClientUtils.waitTillContinuousClientsFinish(
+        ClientUtils.waitForClientsSuccess(
             storageMap.get(extensionContext).getProducerName(),
             storageMap.get(extensionContext).getConsumerName(),
             storageMap.get(extensionContext).getNamespaceName(), MESSAGE_COUNT);

File: crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java
Patch:
@@ -166,6 +166,9 @@
 @SuppressWarnings("ClassFanOutComplexity")
 public class CrdGenerator {
     public static final YAMLMapper YAML_MAPPER = new YAMLMapper()
+            .configure(YAMLGenerator.Feature.MINIMIZE_QUOTES, true)
+            .configure(YAMLGenerator.Feature.SPLIT_LINES, false)
+            .configure(YAMLGenerator.Feature.LITERAL_BLOCK_STYLE, true)
             .configure(YAMLGenerator.Feature.WRITE_DOC_START_MARKER, false);
     public static final ObjectMapper JSON_MATTER = new ObjectMapper();
     private final ApiVersion crdApiVersion;

File: systemtest/src/main/java/io/strimzi/systemtest/storage/TestStorage.java
Patch:
@@ -14,6 +14,7 @@
 
 import java.util.Random;
 
+import static io.strimzi.operator.common.Util.sha1Prefix;
 import static io.strimzi.systemtest.Constants.INFRA_NAMESPACE;
 
 /**
@@ -45,7 +46,7 @@ public TestStorage(ExtensionContext extensionContext) {
     public TestStorage(ExtensionContext extensionContext, String namespaceName) {
         this.extensionContext = extensionContext;
         this.namespaceName = StUtils.isParallelNamespaceTest(extensionContext) ? StUtils.getNamespaceBasedOnRbac(namespaceName, extensionContext) : namespaceName;
-        this.clusterName = CLUSTER_NAME_PREFIX + RANDOM.nextInt(Integer.MAX_VALUE);
+        this.clusterName = CLUSTER_NAME_PREFIX + sha1Prefix(String.valueOf(RANDOM.nextInt(Integer.MAX_VALUE)));
         this.topicName = KafkaTopicUtils.generateRandomNameOfTopic();
         this.streamsTopicTargetName = KafkaTopicUtils.generateRandomNameOfTopic();
         this.kafkaClientsName = clusterName + "-" + Constants.KAFKA_CLIENTS;

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -51,6 +51,7 @@
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.stream.Collectors;
 
+import static io.strimzi.operator.common.Util.sha1Prefix;
 import static io.strimzi.systemtest.matchers.Matchers.logHasNoUnexpectedErrors;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
@@ -594,7 +595,8 @@ protected void beforeEachMayOverride(ExtensionContext extensionContext) {
             }
 
             LOGGER.info("Not first test we are gonna generate cluster name");
-            String clusterName = CLUSTER_NAME_PREFIX + new Random().nextInt(Integer.MAX_VALUE);
+
+            String clusterName = CLUSTER_NAME_PREFIX + sha1Prefix(String.valueOf(new Random().nextInt(Integer.MAX_VALUE)));
 
             mapWithClusterNames.put(testName, clusterName);
             mapWithTestTopics.put(testName, KafkaTopicUtils.generateRandomNameOfTopic());

File: systemtest/src/main/java/io/strimzi/systemtest/annotations/ParallelSuite.java
Patch:
@@ -4,8 +4,6 @@
  */
 package io.strimzi.systemtest.annotations;
 
-import org.junit.jupiter.api.parallel.Execution;
-import org.junit.jupiter.api.parallel.ExecutionMode;
 
 import java.lang.annotation.Retention;
 
@@ -17,6 +15,5 @@
  * be sure that you do not use shared resources, and if you use shared resources please work with synchronization
  */
 @Retention(RUNTIME)
-@Execution(ExecutionMode.CONCURRENT)
 public @interface ParallelSuite {
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/SetupClusterOperator.java
Patch:
@@ -190,6 +190,7 @@ public SetupClusterOperatorBuilder defaultInstallation() {
      * It can install operator by classic way (apply bundle yamls) or use OLM. For OLM you need to set all other OLM env variables.
      * Don't use this method in tests, where specific configuration of CO is needed.
      */
+    @SuppressFBWarnings("ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD")
     public SetupClusterOperator runInstallation() {
         LOGGER.info("Cluster operator installation configuration:\n{}", this::prettyPrint);
         LOGGER.debug("Cluster operator installation configuration:\n{}", this::toString);
@@ -660,9 +661,6 @@ public String diff(final SetupClusterOperator otherClusterOperator) {
         if (this.reconciliationInterval != otherClusterOperator.reconciliationInterval) {
             diffString.append("reconciliationInterval=").append(this.reconciliationInterval).append(", ");
         }
-        if (this.cluster != otherClusterOperator.cluster) {
-            diffString.append("cluster=").append(this.cluster).append(", ");
-        }
         if (!this.clusterOperatorName.equals(otherClusterOperator.clusterOperatorName)) {
             diffString.append("clusterOperatorName=").append(this.clusterOperatorName).append(", ");
         }

File: systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
Patch:
@@ -40,7 +40,7 @@
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
-import io.strimzi.test.annotations.ParallelSuite;
+import io.strimzi.systemtest.annotations.ParallelSuite;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.apache.logging.log4j.Level;

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -46,7 +46,7 @@
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
-import io.strimzi.test.annotations.ParallelSuite;
+import io.strimzi.systemtest.annotations.ParallelSuite;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.apache.logging.log4j.Level;

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -37,7 +37,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
-import io.strimzi.test.annotations.ParallelSuite;
+import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.vertx.core.cli.annotations.Description;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -40,7 +40,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
-import io.strimzi.test.annotations.ParallelSuite;
+import io.strimzi.systemtest.annotations.ParallelSuite;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.Tag;

File: systemtest/src/test/java/io/strimzi/systemtest/specific/DrainCleanerIsolatedST.java
Patch:
@@ -7,6 +7,7 @@
 import io.fabric8.kubernetes.api.model.AffinityBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.AbstractST;
+import io.strimzi.systemtest.BeforeAllOnce;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.annotations.IsolatedTest;
@@ -262,7 +263,7 @@ void teardown() {
     void setup(ExtensionContext extensionContext) {
         clusterOperator.unInstall();
         clusterOperator = new SetupClusterOperator.SetupClusterOperatorBuilder()
-            .withExtensionContext(extensionContext)
+            .withExtensionContext(BeforeAllOnce.getSharedExtensionContext())
             .withNamespace(Constants.DRAIN_CLEANER_NAMESPACE)
             .withOperationTimeout(Constants.CO_OPERATION_TIMEOUT_DEFAULT)
             .createInstallation()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/cruisecontrol/Capacity.java
Patch:
@@ -46,8 +46,8 @@ public Capacity(KafkaSpec spec, Storage storage) {
         this.replicas = spec.getKafka().getReplicas();
         this.storage = storage;
 
-        this.diskMiB = bc != null && bc.getDisk() != null ? getSizeInMiB(bc.getDisk()) : generateDiskCapacity(storage);
-        this.cpuUtilization = bc != null && bc.getCpuUtilization() != null ? bc.getCpuUtilization() : DEFAULT_BROKER_CPU_UTILIZATION_CAPACITY;
+        this.diskMiB = generateDiskCapacity(storage);
+        this.cpuUtilization = DEFAULT_BROKER_CPU_UTILIZATION_CAPACITY;
         this.inboundNetworkKiBPerSecond = bc != null && bc.getInboundNetwork() != null ? getThroughputInKiB(bc.getInboundNetwork()) : DEFAULT_BROKER_INBOUND_NETWORK_CAPACITY_IN_KIB_PER_SECOND;
         this.outboundNetworkKiBPerSecond = bc != null && bc.getOutboundNetwork() != null ? getThroughputInKiB(bc.getOutboundNetwork()) : DEFAULT_BROKER_OUTBOUND_NETWORK_CAPACITY_IN_KIB_PER_SECOND;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -213,8 +213,6 @@ public String getCapacityConfigurationFromEnvVar(Kafka resource, String envVar)
     public void testBrokerCapacities() {
         // Test user defined capacities
         BrokerCapacity userDefinedBrokerCapacity = new BrokerCapacity();
-        userDefinedBrokerCapacity.setDisk("20000M");
-        userDefinedBrokerCapacity.setCpuUtilization(95);
         userDefinedBrokerCapacity.setInboundNetwork("50000KB/s");
         userDefinedBrokerCapacity.setOutboundNetwork("50000KB/s");
 

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlConfigurationST.java
Patch:
@@ -158,7 +158,7 @@ void testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods(ExtensionC
 
             CruiseControlSpec cruiseControl = new CruiseControlSpecBuilder()
                 .withNewBrokerCapacity()
-                    .withDisk("200M")
+                    .withOutboundNetwork("20KB/s")
                 .endBrokerCapacity()
                 .build();
 
@@ -174,7 +174,7 @@ void testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods(ExtensionC
         LOGGER.info("Verifying new configuration in the Kafka CR");
 
         assertThat(KafkaResource.kafkaClient().inNamespace(namespaceName).withName(clusterName).get().getSpec()
-            .getCruiseControl().getBrokerCapacity().getDisk(), is("200M"));
+            .getCruiseControl().getBrokerCapacity().getOutboundNetwork(), is("20KB/s"));
 
         CruiseControlUtils.verifyThatCruiseControlTopicsArePresent(namespaceName);
     }

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/KafkaClientOperations.java
Patch:
@@ -8,7 +8,7 @@
  * Interface KafkaClientOperations used for basic operations with the clients
  *
  * @see io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient
- * @see io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient
+ * @see io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient
  */
 public interface KafkaClientOperations {
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clients/ClientArgument.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalClients;
+package io.strimzi.systemtest.kafkaclients.clients;
 
 /**
  * Enum with argument for external clients

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clients/ClientArgumentMap.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalClients;
+package io.strimzi.systemtest.kafkaclients.clients;
 
 import java.util.ArrayList;
 import java.util.HashMap;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clients/ClientType.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalClients;
+package io.strimzi.systemtest.kafkaclients.clients;
 
 public enum ClientType {
     CLI_KAFKA_VERIFIABLE_PRODUCER,

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clients/InternalKafkaClient.java
Patch:
@@ -2,10 +2,10 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalClients;
+package io.strimzi.systemtest.kafkaclients.clients;
 
-import static io.strimzi.systemtest.kafkaclients.internalClients.ClientType.CLI_KAFKA_VERIFIABLE_CONSUMER;
-import static io.strimzi.systemtest.kafkaclients.internalClients.ClientType.CLI_KAFKA_VERIFIABLE_PRODUCER;
+import static io.strimzi.systemtest.kafkaclients.clients.ClientType.CLI_KAFKA_VERIFIABLE_CONSUMER;
+import static io.strimzi.systemtest.kafkaclients.clients.ClientType.CLI_KAFKA_VERIFIABLE_PRODUCER;
 import static org.hamcrest.MatcherAssert.assertThat;
 
 import java.time.Duration;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/clients/VerifiableClient.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalClients;
+package io.strimzi.systemtest.kafkaclients.clients;
 
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/AdminClientOperations.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.resources.crd.kafkaclients;
+package io.strimzi.systemtest.kafkaclients.internalClients;
 
 public enum AdminClientOperations {
     CREATE_TOPICS("create"),
@@ -21,4 +21,4 @@ public enum AdminClientOperations {
     public String toString() {
         return operation;
     }
-}
+}
\ No newline at end of file

File: systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.KafkaClientOperations;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
@@ -25,7 +25,7 @@
 /**
  * ClientUtils class, which provides static methods for the all type clients
  * @see io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient
- * @see io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient
+ * @see io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient
  */
 public class ClientUtils {
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java
Patch:
@@ -8,7 +8,7 @@
 import io.strimzi.api.kafka.model.KafkaConnectResources;
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;

File: systemtest/src/test/java/io/strimzi/systemtest/backup/ColdBackupScriptIsolatedST.java
Patch:
@@ -26,7 +26,7 @@
 
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.strimzi.test.executor.Exec;

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectIsolatedST.java
Patch:
@@ -37,7 +37,7 @@
 import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectorResource;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/dump/LogDumpScriptIsolatedST.java
Patch:
@@ -12,7 +12,7 @@
 
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -37,7 +37,7 @@
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/ListenersST.java
Patch:
@@ -26,7 +26,7 @@
 import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.security.CertAndKeyFiles;
 import io.strimzi.systemtest.security.SystemTestCertAndKey;

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerIsolatedST.java
Patch:
@@ -25,7 +25,7 @@
 import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaMirrorMakerTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceDeletionRecoveryIsolatedST.java
Patch:
@@ -17,7 +17,7 @@
 import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserST.java
Patch:
@@ -23,7 +23,7 @@
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -24,7 +24,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.metrics.MetricsCollector;
 import io.strimzi.systemtest.resources.ComponentType;
 import io.strimzi.systemtest.resources.ResourceManager;

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesIsolatedST.java
Patch:
@@ -20,7 +20,7 @@
 import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.metrics.MetricsCollector;
 import io.strimzi.systemtest.resources.ComponentType;
 import io.strimzi.systemtest.resources.crd.KafkaResource;

File: systemtest/src/test/java/io/strimzi/systemtest/security/OpaIntegrationST.java
Patch:
@@ -12,7 +12,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -33,7 +33,7 @@
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;

File: systemtest/src/test/java/io/strimzi/systemtest/security/custom/CustomAuthorizerST.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.ParallelSuite;
 import io.strimzi.systemtest.annotations.ParallelTest;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java
Patch:
@@ -8,7 +8,7 @@
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectorTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceIsolatedST.java
Patch:
@@ -16,7 +16,7 @@
 import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
-import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.clients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceOperation.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.model.KafkaConnector;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2;
+import io.strimzi.api.kafka.model.StrimziPodSet;
 import io.strimzi.api.kafka.model.balancing.KafkaRebalanceState;
 import io.strimzi.systemtest.Constants;
 
@@ -37,6 +38,7 @@ public static long getTimeoutForResourceReadiness(String kind) {
             case KafkaMirrorMaker.RESOURCE_KIND:
             case KafkaBridge.RESOURCE_KIND:
             case Constants.STATEFUL_SET:
+            case StrimziPodSet.RESOURCE_KIND:
             case Constants.KAFKA_CRUISE_CONTROL_DEPLOYMENT:
             case Constants.KAFKA_EXPORTER_DEPLOYMENT:
             case Constants.DEPLOYMENT:

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/StrimziPodSetControllerIT.java
Patch:
@@ -75,11 +75,11 @@ public class StrimziPodSetControllerIT {
     @BeforeAll
     public static void beforeAll() {
         cluster = KubeClusterResource.getInstance();
-        cluster.setTestNamespace(NAMESPACE);
+        cluster.setNamespace(NAMESPACE);
 
         assertDoesNotThrow(() -> KubeCluster.bootstrap(), "Could not bootstrap server");
 
-        if (cluster.getTestNamespace() != null && System.getenv("SKIP_TEARDOWN") == null) {
+        if (cluster.getNamespace() != null && System.getenv("SKIP_TEARDOWN") == null) {
             LOGGER.warn("Namespace {} is already created, going to delete it", NAMESPACE);
             kubeClient().deleteNamespace(NAMESPACE);
             cmdKubeClient().waitForResourceDeletion("Namespace", NAMESPACE);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractCustomResourceOperatorIT.java
Patch:
@@ -78,13 +78,13 @@ public abstract class AbstractCustomResourceOperatorIT<C extends KubernetesClien
     public void before() {
         String namespace = getNamespace();
         cluster = KubeClusterResource.getInstance();
-        cluster.setTestNamespace(namespace);
+        cluster.setNamespace(namespace);
 
         assertDoesNotThrow(() -> KubeCluster.bootstrap(), "Could not bootstrap server");
         vertx = Vertx.vertx();
         client = new DefaultKubernetesClient();
 
-        if (cluster.getTestNamespace() != null && System.getenv("SKIP_TEARDOWN") == null) {
+        if (cluster.getNamespace() != null && System.getenv("SKIP_TEARDOWN") == null) {
             LOGGER.warn("Namespace {} is already created, going to delete it", namespace);
             kubeClient().deleteNamespace(namespace);
             cmdKubeClient().waitForResourceDeletion("Namespace", namespace);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractResourceOperatorIT.java
Patch:
@@ -63,13 +63,13 @@ public void renameResource() {
     @BeforeAll
     public static void before() {
         cluster = KubeClusterResource.getInstance();
-        cluster.setTestNamespace(namespace);
+        cluster.setNamespace(namespace);
 
         assertDoesNotThrow(() -> KubeCluster.bootstrap(), "Could not bootstrap server");
         vertx = Vertx.vertx();
         client = new DefaultKubernetesClient();
 
-        if (cluster.getTestNamespace() != null && System.getenv("SKIP_TEARDOWN") == null) {
+        if (cluster.getNamespace() != null && System.getenv("SKIP_TEARDOWN") == null) {
             LOGGER.warn("Namespace {} is already created, going to delete it", namespace);
             kubeClient().deleteNamespace(namespace);
             cmdKubeClient().waitForResourceDeletion("Namespace", namespace);

File: systemtest/src/main/java/io/strimzi/systemtest/logs/LogCollector.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.test.k8s.KubeClusterResource;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import org.apache.logging.log4j.Level;
 
 import java.io.File;
 import java.io.IOException;
@@ -212,13 +213,13 @@ private void collectReplicaSets(String namespace) {
 
     private void collectStrimzi(String namespace) {
         LOGGER.info("Collecting Strimzi in Namespace {}", namespace);
-        String crData = cmdKubeClient(namespace).exec(false, false, "get", "strimzi", "-o", "yaml", "-n", namespaceFile.getName()).out();
+        String crData = cmdKubeClient(namespace).exec(false, Level.DEBUG, "get", "strimzi", "-o", "yaml", "-n", namespaceFile.getName()).out();
         writeFile(namespaceFile + "/strimzi-custom-resources.log", crData);
     }
 
     private void collectClusterInfo(String namespace) {
         LOGGER.info("Collecting cluster status");
-        String nodes = cmdKubeClient(namespace).exec(false, false, "describe", "nodes").out();
+        String nodes = cmdKubeClient(namespace).exec(false, Level.DEBUG, "describe", "nodes").out();
         writeFile(this.testSuite + "/cluster-status.log", nodes);
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/kafkaclients/KafkaBasicExampleClients.java
Patch:
@@ -273,7 +273,7 @@ public JobBuilder consumerStrimzi() {
     public JobBuilder defaultProducerStrimzi() {
         if (producerName == null || producerName.isEmpty()) throw new InvalidParameterException("Producer name is not set.");
         if (namespaceName == null || namespaceName.isEmpty()) {
-            LOGGER.info("Deploying {} to namespace: {}", producerName, ResourceManager.kubeClient().getNamespace());
+            LOGGER.info("Deploy {} to namespace: {}", producerName, ResourceManager.kubeClient().getNamespace());
             namespaceName = ResourceManager.kubeClient().getNamespace();
         }
 
@@ -354,7 +354,7 @@ public JobBuilder defaultProducerStrimzi() {
     public JobBuilder defaultConsumerStrimzi() {
         if (consumerName == null || consumerName.isEmpty()) throw new InvalidParameterException("Consumer name is not set.");
         if (namespaceName == null || namespaceName.isEmpty()) {
-            LOGGER.info("Deploying {} to namespace: {}", consumerName, ResourceManager.kubeClient().getNamespace());
+            LOGGER.info("Deploy {} to namespace: {}", consumerName, ResourceManager.kubeClient().getNamespace());
             namespaceName = ResourceManager.kubeClient().getNamespace();
         }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/specific/OlmResource.java
Patch:
@@ -17,6 +17,7 @@
 import io.vertx.core.json.JsonObject;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import org.apache.logging.log4j.Level;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
 import java.io.ByteArrayInputStream;
@@ -287,7 +288,7 @@ private static void waitFor(String deploymentName, String namespace, int replica
     }
 
     private static Map<String, JsonObject> parseExamplesFromCsv(String csvName, String namespace) {
-        String csvString = ResourceManager.cmdKubeClient().exec(true, false, "get", "csv", csvName, "-o", "json", "-n", namespace).out();
+        String csvString = ResourceManager.cmdKubeClient().exec(true, Level.DEBUG, "get", "csv", csvName, "-o", "json", "-n", namespace).out();
         JsonObject csv = new JsonObject(csvString);
         String almExamples = csv.getJsonObject("metadata").getJsonObject("annotations").getString("alm-examples");
         JsonArray examples = new JsonArray(almExamples);

File: systemtest/src/main/java/io/strimzi/systemtest/templates/kubernetes/NetworkPolicyTemplates.java
Patch:
@@ -59,7 +59,7 @@ public static NetworkPolicy applyDefaultNetworkPolicy(ExtensionContext extension
                 .build();
         }
 
-        LOGGER.debug("Going to apply the following NetworkPolicy: {}", networkPolicy.toString());
+        LOGGER.debug("Creating NetworkPolicy: {}", networkPolicy.toString());
 
         return networkPolicy;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/TestKafkaVersion.java
Patch:
@@ -41,8 +41,6 @@ public class TestKafkaVersion implements Comparable<TestKafkaVersion> {
                 throw new Exception("There is no one Kafka version supported inside " + TestUtils.USER_PATH + "/../kafka-versions.yaml file");
             }
 
-            LOGGER.debug("These are following Kafka versions:\n{}", kafkaVersions.toString());
-            LOGGER.debug("These are following supported Kafka versions:\n{}", supportedKafkaVersions.toString());
         } catch (Exception e) {
             e.printStackTrace();
         }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java
Patch:
@@ -15,6 +15,7 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import org.apache.logging.log4j.Level;
 
 import java.util.List;
 
@@ -72,7 +73,7 @@ public static void waitUntilKafkaConnectRestApiIsAvailable(String podNamePrefix)
     public static void waitForMessagesInKafkaConnectFileSink(String namespaceName, String kafkaConnectPodName, String sinkFileName, String message) {
         LOGGER.info("Waiting for messages in file sink on {}", kafkaConnectPodName);
         TestUtils.waitFor("messages in file sink", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_SEND_RECEIVE_MSG,
-            () -> cmdKubeClient(namespaceName).execInPod(false, kafkaConnectPodName, "/bin/bash", "-c", "cat " + sinkFileName).out().contains(message));
+            () -> cmdKubeClient(namespaceName).execInPod(Level.TRACE, kafkaConnectPodName, "/bin/bash", "-c", "cat " + sinkFileName).out().contains(message));
         LOGGER.info("Expected messages are in file sink on {}", kafkaConnectPodName);
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/CruiseControlUtils.java
Patch:
@@ -15,6 +15,7 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import org.apache.logging.log4j.Level;
 
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
@@ -62,7 +63,7 @@ public static String callApi(String namespaceName, SupportedHttpMethods method,
                 + " --user admin:$(cat /opt/cruise-control/api-auth-config/cruise-control.apiAdminPassword) ";
         }
 
-        return cmdKubeClient(namespaceName).execInPodContainer(false, ccPodName, CONTAINER_NAME, "/bin/bash", "-c",
+        return cmdKubeClient(namespaceName).execInPodContainer(Level.DEBUG, ccPodName, CONTAINER_NAME, "/bin/bash", "-c",
             "curl -X" + method.name() + args + " " + scheme + "://localhost:" + CRUISE_CONTROL_DEFAULT_PORT + endpoint.toString()).out();
     }
 
@@ -71,7 +72,7 @@ public static String callApi(String namespaceName, SupportedHttpMethods method,
     public static String callApi(String namespaceName, SupportedHttpMethods method, String endpoint) {
         String ccPodName = PodUtils.getFirstPodNameContaining(namespaceName, CONTAINER_NAME);
 
-        return cmdKubeClient(namespaceName).execInPodContainer(false, ccPodName, CONTAINER_NAME, "/bin/bash", "-c",
+        return cmdKubeClient(namespaceName).execInPodContainer(Level.DEBUG, ccPodName, CONTAINER_NAME, "/bin/bash", "-c",
             "curl -X" + method.name() + " localhost:" + CRUISE_CONTROL_METRICS_PORT + endpoint).out();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/KeycloakUtils.java
Patch:
@@ -13,6 +13,7 @@
 import io.vertx.core.json.JsonObject;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import org.apache.logging.log4j.Level;
 
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
@@ -35,7 +36,7 @@ public static void deployKeycloak(String namespace) {
 
         // This is needed because from time to time the first try fails on Azure
         TestUtils.waitFor("Keycloak instance readiness", Constants.KEYCLOAK_DEPLOYMENT_POLL, Constants.KEYCLOAK_DEPLOYMENT_TIMEOUT, () -> {
-            ExecResult result = Exec.exec(true, "/bin/bash", PATH_TO_KEYCLOAK_PREPARE_SCRIPT, namespace, getValidKeycloakVersion());
+            ExecResult result = Exec.exec(Level.INFO, "/bin/bash", PATH_TO_KEYCLOAK_PREPARE_SCRIPT, namespace, getValidKeycloakVersion());
 
             if (!result.out().contains("All realms were successfully imported")) {
                 LOGGER.info("Errors occurred during Keycloak install: {}", result.err());
@@ -49,7 +50,7 @@ public static void deployKeycloak(String namespace) {
 
     public static void deleteKeycloak(String namespace) {
         LOGGER.info("Teardown Keycloak in namespace: {}", namespace);
-        Exec.exec(true, "/bin/bash", PATH_TO_KEYCLOAK_TEARDOWN_SCRIPT, namespace, getValidKeycloakVersion());
+        Exec.exec(Level.INFO, "/bin/bash", PATH_TO_KEYCLOAK_TEARDOWN_SCRIPT, namespace, getValidKeycloakVersion());
     }
 
     /**

File: systemtest/src/test/java/io/strimzi/systemtest/backup/ColdBackupScriptIsolatedST.java
Patch:
@@ -20,6 +20,7 @@
 import io.strimzi.test.annotations.IsolatedTest;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import org.apache.logging.log4j.Level;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Tag;
 
@@ -70,7 +71,7 @@ void backupAndRestore(ExtensionContext context) {
         String[] backupCommand = new String[] {
             USER_PATH + "/../tools/cold-backup/run.sh", "backup", "-n", INFRA_NAMESPACE, "-c", clusterName, "-t", backupFilePath, "-y"
         };
-        Exec.exec(true, backupCommand);
+        Exec.exec(Level.INFO, backupCommand);
 
         clusterOperator.unInstall();
         clusterOperator = clusterOperator.defaultInstallation().createInstallation().runInstallation();
@@ -80,7 +81,7 @@ void backupAndRestore(ExtensionContext context) {
         String[] restoreCommand = new String[] {
             USER_PATH + "/../tools/cold-backup/run.sh", "restore", "-n", INFRA_NAMESPACE, "-c", clusterName, "-s", backupFilePath, "-y"
         };
-        Exec.exec(true, restoreCommand);
+        Exec.exec(Level.INFO, restoreCommand);
 
         // check consumer group offsets
         KafkaUtils.waitForKafkaReady(clusterName);

File: systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
Patch:
@@ -43,6 +43,7 @@
 import io.strimzi.test.annotations.ParallelSuite;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import org.apache.logging.log4j.Level;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.MethodOrderer.OrderAnnotation;
 import org.junit.jupiter.api.Tag;
@@ -447,7 +448,7 @@ private synchronized void checkContainersHaveProcessOneAsTini(String namespaceNa
 
                     PodUtils.waitForPodContainerReady(namespaceName, podName, containerName);
                     LOGGER.info("Checking tini process for pod {} with container {}", podName, containerName);
-                    String processOne = cmdKubeClient().namespace(namespaceName).execInPodContainer(false, podName, containerName, "/bin/bash", "-c", command).out().trim();
+                    String processOne = cmdKubeClient().namespace(namespaceName).execInPodContainer(Level.DEBUG, podName, containerName, "/bin/bash", "-c", command).out().trim();
                     assertThat(processOne, startsWith("/usr/bin/tini"));
                 }
             }

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ClusterOperatorRbacIsolatedST.java
Patch:
@@ -21,6 +21,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import org.apache.logging.log4j.Level;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
@@ -64,14 +65,14 @@ void testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled(ExtensionContext
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(clusterName, 3).build());
 
         LOGGER.info("CO log should contain some information about ignoring forbidden access to CRB for Kafka");
-        String log = cmdKubeClient().execInCurrentNamespace(false, "logs", coPodName).out();
+        String log = cmdKubeClient().execInCurrentNamespace(Level.DEBUG, "logs", coPodName).out();
         assertTrue(log.contains("Ignoring forbidden access to ClusterRoleBindings resource which does not seem to be required."));
 
         LOGGER.info("Deploying KafkaConnect: {} without rack awareness, the CR should be deployed without error", clusterName);
         resourceManager.createResource(extensionContext, KafkaConnectTemplates.kafkaConnect(extensionContext, clusterName, 1, false).build());
 
         LOGGER.info("CO log should contain some information about ignoring forbidden access to CRB for KafkaConnect");
-        log = cmdKubeClient().execInCurrentNamespace(false, "logs", coPodName, "--tail", "50").out();
+        log = cmdKubeClient().execInCurrentNamespace(Level.DEBUG, "logs", coPodName, "--tail", "50").out();
         assertTrue(log.contains("Ignoring forbidden access to ClusterRoleBindings resource which does not seem to be required."));
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/ThrottlingQuotaST.java
Patch:
@@ -290,7 +290,7 @@ void testKafkaAdminTopicOperations(ExtensionContext extensionContext) {
 
     void setupKafkaInNamespace(ExtensionContext extensionContext) {
         // Deploy kafka with ScramSHA512
-        LOGGER.info("Deploying shared kafka across all test cases in {} namespace", namespace);
+        LOGGER.info("Deploying shared Kafka across all test cases in {} namespace", namespace);
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(CLUSTER_NAME, 1)
             .editMetadata()
                 .withNamespace(namespace)

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicScalabilityIsolatedST.java
Patch:
@@ -55,7 +55,7 @@ void testBigAmountOfTopicsCreatingViaK8s(ExtensionContext extensionContext) {
     void setup(ExtensionContext extensionContext) {
         clusterOperator.unInstall();
         clusterOperator.defaultInstallation().createInstallation().runInstallation();
-        LOGGER.info("Deploying shared kafka across all test cases in {} namespace", INFRA_NAMESPACE);
+        LOGGER.info("Deploying shared Kafka across all test cases in {} namespace", INFRA_NAMESPACE);
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(sharedClusterName, 3, 1)
             .editMetadata()
                 .withNamespace(INFRA_NAMESPACE)

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthScopeIsolatedST.java
Patch:
@@ -27,6 +27,7 @@
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.systemtest.utils.specific.KeycloakUtils;
 import io.strimzi.test.k8s.KubeClusterResource;
+import org.apache.logging.log4j.Level;
 import org.hamcrest.CoreMatchers;
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.BeforeAll;
@@ -141,7 +142,7 @@ void testScopeKafkaConnectSetCorrectly(ExtensionContext extensionContext) throws
         // explicitly verifying also logs
         String kafkaPodName = kubeClient().listPodsByPrefixInName(INFRA_NAMESPACE, KafkaResources.kafkaPodName(oauthClusterName, 0)).get(0).getMetadata().getName();
 
-        String kafkaLog = KubeClusterResource.cmdKubeClient(INFRA_NAMESPACE).execInCurrentNamespace(false, "logs", kafkaPodName, "--tail", "50").out();
+        String kafkaLog = KubeClusterResource.cmdKubeClient(INFRA_NAMESPACE).execInCurrentNamespace(Level.DEBUG, "logs", kafkaPodName, "--tail", "50").out();
         assertThat(kafkaLog, CoreMatchers.containsString("Access token expires at"));
         assertThat(kafkaLog, CoreMatchers.containsString("Evaluating path: $[*][?]"));
         assertThat(kafkaLog, CoreMatchers.containsString("Evaluating path: @['scope']"));

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsIsolatedST.java
Patch:
@@ -424,8 +424,6 @@ void testIntrospectionEndpoint(ExtensionContext extensionContext) {
 
         resourceManager.createResource(extensionContext, KafkaTopicTemplates.topic(oauthClusterName, topicName, INFRA_NAMESPACE).build());
 
-        LOGGER.info("Deploying kafka...");
-
         keycloakInstance.setIntrospectionEndpointUri("https://" + keycloakInstance.getHttpsUri() + "/auth/realms/internal/protocol/openid-connect/token/introspect");
         String introspectionKafka = oauthClusterName + "-intro";
 

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -516,9 +516,9 @@ private void deployJaegerOperator(ExtensionContext extensionContext) throws IOEx
             .endSpec()
             .build();
 
-        LOGGER.debug("Going to apply the following NetworkPolicy: {}", networkPolicy.toString());
+        LOGGER.debug("Creating NetworkPolicy: {}", networkPolicy.toString());
         resourceManager.createResource(extensionContext, networkPolicy);
-        LOGGER.info("Network policy for jaeger successfully applied");
+        LOGGER.info("Network policy for jaeger successfully created");
     }
 
     /**

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeIsolatedST.java
Patch:
@@ -105,7 +105,7 @@ private void performUpgradeVerification(JsonObject testParameters, ExtensionCont
 
         // In chainUpgrade we want to setup Kafka only at the begging and then upgrade it via CO
         kafkaYaml = new File(dir, testParameters.getString("fromExamples") + "/examples/kafka/kafka-persistent.yaml");
-        LOGGER.info("Going to deploy Kafka from: {}", kafkaYaml.getPath());
+        LOGGER.info("Deploy Kafka from: {}", kafkaYaml.getPath());
         KubeClusterResource.cmdKubeClient().create(kafkaYaml);
         // Wait for readiness
         waitForReadinessOfKafkaCluster();

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeIsolatedST.java
Patch:
@@ -93,7 +93,7 @@ void testUpgradeKafkaWithoutVersion(ExtensionContext extensionContext) throws IO
         // Modify + apply installation files
         copyModifyApply(coDir, INFRA_NAMESPACE, extensionContext, "");
         // Apply Kafka Persistent without version
-        LOGGER.info("Going to deploy Kafka from: {}", startKafkaPersistent.getPath());
+        LOGGER.info("Deploy Kafka from: {}", startKafkaPersistent.getPath());
         // Change kafka version of it's empty (null is for remove the version)
         cmdKubeClient().applyContent(KafkaUtils.changeOrRemoveKafkaConfiguration(startKafkaPersistent, null, startLogMessageFormat, startInterBrokerProtocol));
         // Wait for readiness

File: test/src/main/java/io/strimzi/test/k8s/HelmClient.java
Patch:
@@ -8,6 +8,7 @@
 import io.strimzi.test.k8s.cmdClient.KubeCmdClient;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import org.apache.logging.log4j.Level;
 
 import java.nio.file.Path;
 import java.util.ArrayList;
@@ -49,7 +50,7 @@ public HelmClient install(Path chart, String releaseName, Map<String, Object> va
                 "--set", values,
                 "--timeout", INSTALL_TIMEOUT_SECONDS,
                 "--debug",
-                chart.toString()))), 0, true, true);
+                chart.toString()))), 0, Level.INFO, true);
         return this;
     }
 
@@ -68,7 +69,7 @@ public HelmClient delete(String releaseName) {
      */
     public HelmClient delete(String namespace, String releaseName) {
         LOGGER.info("Deleting helm-chart:{} in namespace:{}", releaseName, namespace);
-        Exec.exec(null, command("delete", releaseName, "--namespace", namespace), 0, false, false);
+        Exec.exec(null, command("delete", releaseName, "--namespace", namespace), 0, Level.DEBUG, false);
         return this;
     }
 

File: test/src/main/java/io/strimzi/test/k8s/cluster/KubeCluster.java
Patch:
@@ -74,10 +74,10 @@ static KubeCluster bootstrap() throws NoClusterException {
                     cluster = kc;
                     break;
                 } else {
-                    logger.warn("Cluster {} is not running!", kc);
+                    logger.debug("Cluster {} is not running!", kc);
                 }
             } else {
-                logger.warn("Cluster {} is not installed!", kc);
+                logger.debug("Cluster {} is not installed!", kc);
             }
         }
         if (cluster == null) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -442,6 +442,8 @@ private String getSecurityProtocol(boolean tls, boolean sasl)   {
         addOption(options, ServerConfig.OAUTH_USERNAME_CLAIM, oauth.getUserNameClaim());
         addOption(options, ServerConfig.OAUTH_FALLBACK_USERNAME_CLAIM, oauth.getFallbackUserNameClaim());
         addOption(options, ServerConfig.OAUTH_FALLBACK_USERNAME_PREFIX, oauth.getFallbackUserNamePrefix());
+        addOption(options, ServerConfig.OAUTH_GROUPS_CLAIM, oauth.getGroupsClaim());
+        addOption(options, ServerConfig.OAUTH_GROUPS_CLAIM_DELIMITER, oauth.getGroupsClaimDelimiter());
         addBooleanOptionIfFalse(options, ServerConfig.OAUTH_ACCESS_TOKEN_IS_JWT, oauth.isAccessTokenIsJwt());
         addBooleanOptionIfFalse(options, ServerConfig.OAUTH_CHECK_ACCESS_TOKEN_TYPE, oauth.isCheckAccessTokenType());
         addOption(options, ServerConfig.OAUTH_VALID_TOKEN_TYPE, oauth.getValidTokenType());

File: systemtest/src/main/java/io/strimzi/systemtest/annotations/ParallelTest.java
Patch:
@@ -24,7 +24,7 @@
 @Target(ElementType.METHOD)
 @Retention(RUNTIME)
 @Execution(ExecutionMode.CONCURRENT)
-@ResourceLock(mode = ResourceAccessMode.READ, value = "parallel-test")
+@ResourceLock(mode = ResourceAccessMode.READ, value = "global")
 @Test
 public @interface ParallelTest {
 }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaTopicUtils.java
Patch:
@@ -67,7 +67,7 @@ public static String topicSnapshot(String topicName) {
     public static String waitTopicHasRolled(final String namespaceName, String topicName, String topicUid) {
         TestUtils.waitFor("Topic " + topicName + " has rolled", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,
             () -> !topicUid.equals(topicSnapshot(namespaceName, topicName)));
-        return topicSnapshot(topicName);
+        return topicSnapshot(namespaceName, topicName);
     }
 
     public static String waitTopicHasRolled(String topicName, String topicUid) {

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -536,6 +536,8 @@ protected void afterEachMayOverride(ExtensionContext extensionContext) throws Ex
     }
 
     private final void afterAllMustExecute(ExtensionContext extensionContext)  {
+        clusterOperator = SetupClusterOperator.getInstanceHolder();
+
         if (StUtils.isParallelSuite(extensionContext)) {
             parallelSuiteController.removeParallelSuite(extensionContext);
         }
@@ -559,7 +561,7 @@ private final void afterAllMustExecute(ExtensionContext extensionContext)  {
             LOGGER.debug("Default Cluster Operator configuration:\n" + clusterOperator.defaultInstallation().createInstallation().toString());
             LOGGER.info("Current Cluster Operator configuration differs from default Cluster Operator in these attributes:{}", clusterOperator.diff(clusterOperator.defaultInstallation().createInstallation()));
             LOGGER.debug(String.join("", Collections.nCopies(76, "=")));
-            clusterOperator = clusterOperator.rollbackToDefaultConfiguration();
+            clusterOperator.rollbackToDefaultConfiguration();
         }
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -264,7 +264,7 @@ private static JsonNode loadConfigurationFile() {
             File jsonFile = new File(config).getAbsoluteFile();
             return mapper.readTree(jsonFile);
         } catch (IOException ex) {
-            LOGGER.info("Json configuration is not provided or cannot be processed");
+            LOGGER.debug("Json configuration is not provided or cannot be processed!");
             return mapper.createObjectNode();
         }
     }

File: systemtest/src/main/java/io/strimzi/systemtest/parallel/SuiteThreadController.java
Patch:
@@ -71,7 +71,7 @@ public boolean waitUntilZeroParallelSuites(ExtensionContext extensionContext) {
         int isZeroParallelSuitesCounter = 0;
 
         while (preCondition) {
-            LOGGER.debug("{} - Parallel suites count: {}", extensionContext.getRequiredTestClass().getSimpleName(), runningTestSuitesInParallelCount.get());
+            LOGGER.trace("{} - Parallel suites count: {}", extensionContext.getRequiredTestClass().getSimpleName(), runningTestSuitesInParallelCount.get());
             try {
                 Thread.sleep(STARTING_DELAY);
             } catch (InterruptedException e) {
@@ -80,7 +80,7 @@ public boolean waitUntilZeroParallelSuites(ExtensionContext extensionContext) {
 
             isZeroParallelSuitesCounter = runningTestSuitesInParallelCount.get() <= 0 ? ++isZeroParallelSuitesCounter : 0;
 
-            LOGGER.debug("{} - isZeroParallelSuitesCounter counter is:{}", extensionContext.getRequiredTestClass().getSimpleName(), isZeroParallelSuitesCounter);
+            LOGGER.trace("{} - isZeroParallelSuitesCounter counter is:{}", extensionContext.getRequiredTestClass().getSimpleName(), isZeroParallelSuitesCounter);
 
             preCondition = runningTestSuitesInParallelCount.get() > 0 || isZeroParallelSuitesCounter < 5;
         }

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -727,7 +727,7 @@ void testDynamicallySetConnectLoggingLevels(ExtensionContext extensionContext) {
         String log4jConfig =
                 "log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\n" +
                         "log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\n" +
-                        "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %m (%c) [%t]%n\n" +
+                        "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %X{connector.context}%m (%c) [%t]%n\n" +
                         "log4j.rootLogger=OFF, CONSOLE\n" +
                         "log4j.logger.org.apache.zookeeper=ERROR\n" +
                         "log4j.logger.org.I0Itec.zkclient=ERROR\n" +
@@ -1143,7 +1143,7 @@ void testDynamicallySetMM2LoggingLevels(ExtensionContext extensionContext) {
         String log4jConfig =
                 "log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\n" +
                         "log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\n" +
-                        "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %m (%c) [%t]%n\n" +
+                        "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %X{connector.context}%m (%c) [%t]%n\n" +
                         "log4j.rootLogger=OFF, CONSOLE\n" +
                         "log4j.logger.org.apache.zookeeper=ERROR\n" +
                         "log4j.logger.org.I0Itec.zkclient=ERROR\n" +

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/SetupClusterOperator.java
Patch:
@@ -66,9 +66,9 @@ public class SetupClusterOperator {
 
     private static SetupClusterOperator instanceHolder;
 
-    private KubeClusterResource cluster = KubeClusterResource.getInstance();
-    private HelmResource helmResource;
-    private OlmResource olmResource;
+    private static KubeClusterResource cluster = KubeClusterResource.getInstance();
+    private static HelmResource helmResource;
+    private static OlmResource olmResource;
 
     private ExtensionContext extensionContext;
     private String clusterOperatorName;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -225,6 +225,8 @@ public abstract class AbstractModel {
      */
     protected Storage storage;
     public static final String VOLUME_NAME = "data";
+    public static final String KAFKA_MOUNT_PATH = "/var/lib/kafka";
+    public static final String KAFKA_LOG_DIR = "kafka-log";
     protected String mountPath;
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -3842,7 +3842,7 @@ private boolean isPodUpToDate(StatefulSet sts, Pod pod) {
         }
 
         /*test*/ final Future<ReconciliationState> getCruiseControlDescription() {
-            CruiseControl cruiseControl = CruiseControl.fromCrd(reconciliation, kafkaAssembly, versions);
+            CruiseControl cruiseControl = CruiseControl.fromCrd(reconciliation, kafkaAssembly, versions, kafkaCluster.getStorage());
 
             if (cruiseControl != null) {
                 return Util.metricsAndLogging(reconciliation, configMapOperations, kafkaAssembly.getMetadata().getNamespace(),

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/PathBuilder.java
Patch:
@@ -71,7 +71,8 @@ public PathBuilder addRebalanceParameters(RebalanceOptions options) {
         if (options != null) {
             PathBuilder builder = addParameter(CruiseControlParameters.DRY_RUN, String.valueOf(options.isDryRun()))
                     .addParameter(CruiseControlParameters.VERBOSE, String.valueOf(options.isVerbose()))
-                    .addParameter(CruiseControlParameters.SKIP_HARD_GOAL_CHECK, String.valueOf(options.isSkipHardGoalCheck()));
+                    .addParameter(CruiseControlParameters.SKIP_HARD_GOAL_CHECK, String.valueOf(options.isSkipHardGoalCheck()))
+                    .addParameter(CruiseControlParameters.REBALANCE_DISK, String.valueOf(options.isRebalanceDisk()));
 
             if (options.getExcludedTopics() != null) {
                 builder.addParameter(CruiseControlParameters.EXCLUDED_TOPICS, options.getExcludedTopics());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -886,7 +886,7 @@ private void updateCluster(VertxTestContext context, Kafka originalAssembly, Kaf
         ZookeeperCluster updatedZookeeperCluster = ZookeeperCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, updatedAssembly, VERSIONS);
         EntityOperator originalEntityOperator = EntityOperator.fromCrd(new Reconciliation("test", originalAssembly.getKind(), originalAssembly.getMetadata().getNamespace(), originalAssembly.getMetadata().getName()), originalAssembly, VERSIONS);
         KafkaExporter originalKafkaExporter = KafkaExporter.fromCrd(new Reconciliation("test", originalAssembly.getKind(), originalAssembly.getMetadata().getNamespace(), originalAssembly.getMetadata().getName()), originalAssembly, VERSIONS);
-        CruiseControl originalCruiseControl = CruiseControl.fromCrd(Reconciliation.DUMMY_RECONCILIATION, originalAssembly, VERSIONS);
+        CruiseControl originalCruiseControl = CruiseControl.fromCrd(Reconciliation.DUMMY_RECONCILIATION, originalAssembly, VERSIONS, updatedKafkaCluster.getStorage());
 
         // create CM, Service, headless service, statefulset and so on
         ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(openShift);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/PathBuilderTest.java
Patch:
@@ -33,6 +33,7 @@ private String getExpectedRebalanceString() throws UnsupportedEncodingException
                         CruiseControlParameters.DRY_RUN.key + "=false&" +
                         CruiseControlParameters.VERBOSE.key + "=true&" +
                         CruiseControlParameters.SKIP_HARD_GOAL_CHECK.key + "=false&" +
+                        CruiseControlParameters.REBALANCE_DISK.key + "=false&" +
                         CruiseControlParameters.EXCLUDED_TOPICS.key + "=test-.*&" +
                         CruiseControlParameters.GOALS.key + "=");
 
@@ -55,6 +56,7 @@ public void testQueryStringPair() {
                 .addParameter(CruiseControlParameters.JSON, "true")
                 .addParameter(CruiseControlParameters.DRY_RUN, "true")
                 .addParameter(CruiseControlParameters.VERBOSE, "false")
+                .addParameter(CruiseControlParameters.REBALANCE_DISK, "false")
                 .build();
 
         assertThat(path, containsString(DEFAULT_QUERY));
@@ -69,6 +71,7 @@ public void testQueryStringList() throws UnsupportedEncodingException {
                 .addParameter(CruiseControlParameters.DRY_RUN, "false")
                 .addParameter(CruiseControlParameters.VERBOSE, "true")
                 .addParameter(CruiseControlParameters.SKIP_HARD_GOAL_CHECK, "false")
+                .addParameter(CruiseControlParameters.REBALANCE_DISK, "false")
                 .addParameter(CruiseControlParameters.EXCLUDED_TOPICS, "test-.*")
                 .addParameter(CruiseControlParameters.GOALS, GOALS)
                 .build();

File: operator-common/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlParameters.java
Patch:
@@ -15,6 +15,7 @@ public enum CruiseControlParameters {
     GOALS("goals"),
     VERBOSE("verbose"),
     SKIP_HARD_GOAL_CHECK("skip_hard_goal_check"),
+    REBALANCE_DISK("rebalance_disk"),
     FETCH_COMPLETE("fetch_completed_task"),
     USER_TASK_IDS("user_task_ids"),
     EXCLUDED_TOPICS("excluded_topics"),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaStatusTest.java
Patch:
@@ -391,7 +391,7 @@ vertx, new PlatformFeaturesAvailability(false, kubernetesVersion),
             assertThat(status.getListeners().get(0).getAddresses().get(0).getPort(), is(Integer.valueOf(9092)));
             assertThat(status.getListeners().get(0).getBootstrapServers(), is("my-service.my-namespace.svc:9092"));
 
-            assertThat(status.getConditions().size(), is(2));
+            assertThat(status.getConditions().size(), is(1));
             assertThat(status.getConditions().get(0).getType(), is("NotReady"));
             assertThat(status.getConditions().get(0).getStatus(), is("True"));
             assertThat(status.getConditions().get(0).getReason(), is("RuntimeException"));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -692,7 +692,8 @@ public Secret generateSecret(Kafka kafka, ClusterCa clusterCa, boolean isMainten
         data.put(keyCertName + ".p12", cert.keyStoreAsBase64String());
         data.put(keyCertName + ".password", cert.storePasswordAsBase64String());
 
-        return createSecret(CruiseControl.secretName(cluster), data);
+        return createSecret(CruiseControl.secretName(cluster), data,
+                Collections.singletonMap(clusterCa.caCertGenerationAnnotation(), String.valueOf(clusterCa.certGeneration())));
     }
 
     /**

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -461,7 +461,7 @@ private Secret generateNodeSecret() {
         clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), emptyMap(), emptyMap(), null, true);
 
         zc.generateCertificates(ka, clusterCa, true);
-        return zc.generateNodesSecret();
+        return zc.generateNodesSecret(clusterCa);
     }
 
     @ParallelTest

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -1336,7 +1336,7 @@ public void testReconcile(Params params, VertxTestContext context) {
             invocation -> new ArrayList<>(asList(
                     barClientsCa.caKeySecret(),
                     barClientsCa.caCertSecret(),
-                    barCluster.generateBrokersSecret(),
+                    barCluster.generateBrokersSecret(barClusterCa, barClientsCa),
                     barClusterCa.caCertSecret()))
         );
         when(mockSecretOps.get(eq(kafkaNamespace), eq(AbstractModel.clusterCaCertSecretName(bar.getMetadata().getName())))).thenReturn(barSecrets.get(0));
@@ -1421,7 +1421,7 @@ public void testReconcileAllNamespaces(Params params, VertxTestContext context)
             invocation -> new ArrayList<>(asList(
                     barClientsCa.caKeySecret(),
                     barClientsCa.caCertSecret(),
-                    barCluster.generateBrokersSecret(),
+                    barCluster.generateBrokersSecret(barClusterCa, barClientsCa),
                     barClusterCa.caCertSecret()))
         );
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaRoller.java
Patch:
@@ -455,7 +455,9 @@ private RestartPlan restartPlan(int podId, Pod pod, RestartContext restartContex
                 "PodScheduled".equals(ps.getType())
                         && "Unschedulable".equals(ps.getReason())
                         && "False".equals(ps.getStatus()));
-        if (podStuck && !reasonToRestartPod.contains("Pod has old generation")) {
+        if (podStuck
+                && !reasonToRestartPod.contains("Pod has old generation")   // "Pod has old generation" is used with StatefulSets
+                && !reasonToRestartPod.contains("Pod has old revision")) {  // "Pod has old revision" is used with PodSets
             // If the pod is unschedulable then deleting it, or trying to open an Admin client to it will make no difference
             // Treat this as fatal because if it's not possible to schedule one pod then it's likely that proceeding
             // and deleting a different pod in the meantime will likely result in another unschedulable pod.

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -42,7 +42,7 @@ public class KafkaClusterSpec implements HasConfigurableMetrics, UnknownProperty
     private static final long serialVersionUID = 1L;
 
     public static final String FORBIDDEN_PREFIXES = "listeners, advertised., broker., listener., host.name, port, "
-            + "inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, "
+            + "inter.broker.listener.name, sasl., ssl., security., password., log.dir, "
             + "zookeeper.connect, zookeeper.set.acl, zookeeper.ssl, zookeeper.clientCnxnSocket, authorizer., super.user, "
             + "cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers";
 

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthentication.java
Patch:
@@ -27,6 +27,7 @@
     @JsonSubTypes.Type(name = KafkaListenerAuthenticationTls.TYPE_TLS, value = KafkaListenerAuthenticationTls.class),
     @JsonSubTypes.Type(name = KafkaListenerAuthenticationScramSha512.SCRAM_SHA_512, value = KafkaListenerAuthenticationScramSha512.class),
     @JsonSubTypes.Type(name = KafkaListenerAuthenticationOAuth.TYPE_OAUTH, value = KafkaListenerAuthenticationOAuth.class),
+    @JsonSubTypes.Type(name = KafkaListenerAuthenticationCustom.TYPE_CUSTOM, value = KafkaListenerAuthenticationCustom.class),
 })
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @Buildable(
@@ -43,7 +44,8 @@ public abstract class KafkaListenerAuthentication implements UnknownPropertyPres
             "`oauth` type uses SASL OAUTHBEARER Authentication. " +
             "`scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. " +
             "`tls` type uses TLS Client Authentication. " +
-            "`tls` type is supported only on TLS listeners.")
+            "`tls` type is supported only on TLS listeners." +
+            "`custom` type allows for any authentication type to be used.")
     public abstract String getType();
 
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/SecretUtils.java
Patch:
@@ -76,7 +76,7 @@ public static void createSecret(String namespaceName, String secretName, String
                 .withNamespace(namespaceName)
             .endMetadata()
             .withType("Opaque")
-                .withData(Collections.singletonMap(dataKey, dataValue))
+                .withStringData(Collections.singletonMap(dataKey, dataValue))
             .build());
     }
 

File: api/src/main/java/io/strimzi/api/kafka/Crds.java
Patch:
@@ -288,7 +288,7 @@ public static MixedOperation<StrimziPodSet, StrimziPodSetList, Resource<StrimziP
 
     public static <T extends CustomResource> String kind(Class<T> cls) {
         try {
-            return cls.newInstance().getKind();
+            return cls.getDeclaredConstructor().newInstance().getKind();
         } catch (ReflectiveOperationException e) {
             throw new RuntimeException(e);
         }

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractNonNamespacedResourceOperatorTest.java
Patch:
@@ -100,7 +100,7 @@ public void testCreateWhenExistsWithChangeIsAPatch(VertxTestContext context) {
         HasMetadata hasMetadata = mock(HasMetadata.class);
         when(mockResource.get()).thenReturn(resource);
 
-        when(mockResource.withPropagationPolicy(true ? DeletionPropagation.FOREGROUND : DeletionPropagation.ORPHAN)).thenReturn(mockR);
+        when(mockResource.withPropagationPolicy(DeletionPropagation.FOREGROUND)).thenReturn(mockR);
         when(mockR.patch((T) any())).thenReturn(hasMetadata);
 
         NonNamespaceOperation mockNameable = mock(NonNamespaceOperation.class);
@@ -132,7 +132,7 @@ public void testCreateWhenExistsWithoutChangeIsNotAPatch(VertxTestContext contex
         T resource = resource();
         Resource mockResource = mock(resourceType());
         when(mockResource.get()).thenReturn(resource);
-        when(mockResource.withPropagationPolicy(true ? DeletionPropagation.FOREGROUND : DeletionPropagation.ORPHAN)).thenReturn(mockResource);
+        when(mockResource.withPropagationPolicy(DeletionPropagation.FOREGROUND)).thenReturn(mockResource);
         when(mockResource.patch(any())).thenReturn(resource);
 
         NonNamespaceOperation mockNameable = mock(NonNamespaceOperation.class);

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/ExternalKafkaClient.java
Patch:
@@ -35,6 +35,7 @@
 public class ExternalKafkaClient extends AbstractKafkaClient<ExternalKafkaClient.Builder> {
 
     private static final Logger LOGGER = LogManager.getLogger(ExternalKafkaClient.class);
+    private static final Random RANDOM = new Random();
 
     protected ExternalKafkaClient(AbstractKafkaClient.Builder<ExternalKafkaClient.Builder> builder) {
         super(builder);
@@ -64,7 +65,7 @@ private ProducerProperties.ProducerPropertiesBuilder getProducerProperties() {
             .withBootstrapServerConfig(getBootstrapServerFromStatus())
             .withKeySerializerConfig(StringSerializer.class)
             .withValueSerializerConfig(StringSerializer.class)
-            .withClientIdConfig("producer-" + new Random().nextInt(Integer.MAX_VALUE));
+            .withClientIdConfig("producer-" + RANDOM.nextInt(Integer.MAX_VALUE));
     }
 
     private ConsumerProperties.ConsumerPropertiesBuilder getConsumerProperties() {
@@ -74,7 +75,7 @@ private ConsumerProperties.ConsumerPropertiesBuilder getConsumerProperties() {
             .withBootstrapServerConfig(getBootstrapServerFromStatus())
             .withKeyDeserializerConfig(StringDeserializer.class)
             .withValueDeserializerConfig(StringDeserializer.class)
-            .withClientIdConfig("consumer-" + new Random().nextInt(Integer.MAX_VALUE))
+            .withClientIdConfig("consumer-" + RANDOM.nextInt(Integer.MAX_VALUE))
             .withAutoOffsetResetConfig(OffsetResetStrategy.EARLIEST)
             .withGroupIdConfig(consumerGroup);
     }

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/VerifiableClient.java
Patch:
@@ -123,8 +123,9 @@ public VerifiableClient(VerifiableClientBuilder verifiableClientBuilder) {
 
         if (clientType == ClientType.CLI_KAFKA_VERIFIABLE_CONSUMER) {
             this.consumerGroupName = verifiableClientBuilder.consumerGroupName;
-            this.clientArgumentMap.put(ClientArgument.GROUP_ID, consumerGroupName);
             this.consumerInstanceId = verifiableClientBuilder.consumerInstanceId;
+            this.clientArgumentMap.put(ClientArgument.GROUP_ID, consumerGroupName);
+            this.clientArgumentMap.put(ClientArgument.GROUP_INSTANCE_ID, consumerInstanceId);
         }
 
         if (clientType == ClientType.CLI_KAFKA_CONSUMER_GROUPS) {

File: systemtest/src/main/java/io/strimzi/systemtest/storage/TestStorage.java
Patch:
@@ -25,6 +25,7 @@ final public class TestStorage {
     private static final String PRODUCER = "hello-world-producer";
     private static final String CONSUMER = "hello-world-consumer";
     private static final String CLUSTER_NAME_PREFIX = "my-cluster-";
+    private static final Random RANDOM = new Random();
 
     private ExtensionContext extensionContext;
     private String namespaceName;
@@ -44,7 +45,7 @@ public TestStorage(ExtensionContext extensionContext) {
     public TestStorage(ExtensionContext extensionContext, String namespaceName) {
         this.extensionContext = extensionContext;
         this.namespaceName = StUtils.isParallelNamespaceTest(extensionContext) ? StUtils.getNamespaceBasedOnRbac(namespaceName, extensionContext) : namespaceName;
-        this.clusterName = CLUSTER_NAME_PREFIX + new Random().nextInt(Integer.MAX_VALUE);
+        this.clusterName = CLUSTER_NAME_PREFIX + RANDOM.nextInt(Integer.MAX_VALUE);
         this.topicName = KafkaTopicUtils.generateRandomNameOfTopic();
         this.streamsTopicTargetName = KafkaTopicUtils.generateRandomNameOfTopic();
         this.kafkaClientsName = clusterName + "-" + Constants.KAFKA_CLIENTS;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaTopicUtils.java
Patch:
@@ -29,6 +29,7 @@ public class KafkaTopicUtils {
     private static final String TOPIC_NAME_PREFIX = "my-topic-";
     private static final long READINESS_TIMEOUT = ResourceOperation.getTimeoutForResourceReadiness(KafkaTopic.RESOURCE_KIND);
     private static final long DELETION_TIMEOUT = ResourceOperation.getTimeoutForResourceDeletion();
+    private static final Random RANDOM = new Random();
 
     private KafkaTopicUtils() {}
 
@@ -37,7 +38,7 @@ private KafkaTopicUtils() {}
      * @return random name with additional salt
      */
     public static String generateRandomNameOfTopic() {
-        String salt = new Random().nextInt(Integer.MAX_VALUE) + "-" + new Random().nextInt(Integer.MAX_VALUE);
+        String salt = RANDOM.nextInt(Integer.MAX_VALUE) + "-" + RANDOM.nextInt(Integer.MAX_VALUE);
 
         return  TOPIC_NAME_PREFIX + salt;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUserUtils.java
Patch:
@@ -31,6 +31,7 @@ public class KafkaUserUtils {
     private static final Logger LOGGER = LogManager.getLogger(KafkaUserUtils.class);
     private static final String KAFKA_USER_NAME_PREFIX = "my-user-";
     private static final long DELETION_TIMEOUT = ResourceOperation.getTimeoutForResourceDeletion();
+    private static final Random RANDOM = new Random();
 
     private KafkaUserUtils() {}
 
@@ -39,7 +40,7 @@ private KafkaUserUtils() {}
      * @return random name with additional salt
      */
     public static String generateRandomNameOfKafkaUser() {
-        String salt = new Random().nextInt(Integer.MAX_VALUE) + "-" + new Random().nextInt(Integer.MAX_VALUE);
+        String salt = RANDOM.nextInt(Integer.MAX_VALUE) + "-" + RANDOM.nextInt(Integer.MAX_VALUE);
 
         return  KAFKA_USER_NAME_PREFIX + salt;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java
Patch:
@@ -59,6 +59,7 @@ public class KafkaUtils {
 
     private static final Logger LOGGER = LogManager.getLogger(KafkaUtils.class);
     private static final long DELETION_TIMEOUT = ResourceOperation.getTimeoutForResourceDeletion();
+    private static final Random RANDOM = new Random();
 
     private KafkaUtils() {}
 
@@ -378,7 +379,7 @@ public static Map<String, ConfigModel> getDynamicConfigurationProperties(String
      * @return name with prefix and random salt
      */
     public static String generateRandomNameOfKafka(String clusterName) {
-        return clusterName + "-" + new Random().nextInt(Integer.MAX_VALUE);
+        return clusterName + "-" + RANDOM.nextInt(Integer.MAX_VALUE);
     }
 
     public static String getVersionFromKafkaPodLibs(String kafkaPodName) {

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfSharedST.java
Patch:
@@ -152,7 +152,7 @@ private static Map<String, Object> generateTestCases(String kafkaVersion) {
                             stochasticChosenValue = false;
                             break;
                         default:
-                            stochasticChosenValue = ThreadLocalRandom.current().nextInt(2) == 0 ? true : false;
+                            stochasticChosenValue = ThreadLocalRandom.current().nextInt(2) == 0;
                     }
                     testCases.put(key, stochasticChosenValue);
                     break;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -168,7 +168,7 @@ public static EntityOperator fromCrd(Reconciliation reconciliation, Kafka kafkaA
 
             result.setOwnerReference(kafkaAssembly);
 
-            EntityTopicOperator topicOperator = EntityTopicOperator.fromCrd(reconciliation, kafkaAssembly);
+            EntityTopicOperator topicOperator = EntityTopicOperator.fromCrd(reconciliation, kafkaAssembly, versions);
             EntityUserOperator userOperator = EntityUserOperator.fromCrd(reconciliation, kafkaAssembly);
             TlsSidecar tlsSidecar = entityOperatorSpec.getTlsSidecar();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java
Patch:
@@ -232,7 +232,7 @@ public String kafkaImage(String image, String version) {
          * @throws NoImageException If one of the versions lacks an image.
          * @throws UnsupportedVersionException If any version with configured image is not supported
          */
-        public void validateImages(Set<String> versions, Map<String, String> images) throws NoImageException, UnsupportedVersionException   {
+        public void validateImages(Set<String> versions, Map<String, String> images) throws NoImageException, UnsupportedVersionException {
             for (String version : versions) {
                 image(null, version, images);
             }

File: systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusIsolatedST.java
Patch:
@@ -645,6 +645,7 @@ void assertKafkaTopicWrongMinInSyncReplicasStatus(String topicName, String inval
         assertThat(kafkaTopicStatus.getConditions().stream()
             .anyMatch(condition -> condition.getReason().equals("InvalidRequestException")), is(true));
         assertThat(kafkaTopicStatus.getConditions().stream()
-            .anyMatch(condition -> condition.getMessage().contains(String.format("Invalid value %s for configuration min.insync.replicas", invalidValue))), is(true));
+            .anyMatch(condition -> condition.getMessage().contains(String.format("KafkaTopic %s/%s has invalid spec.config: " +
+                    "min.insync.replicas has value '%s' which is not an int", Constants.INFRA_NAMESPACE, topicName, invalidValue))), is(true));
     }
 }

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorBaseIT.java
Patch:
@@ -231,6 +231,7 @@ protected Map<String, String> topicOperatorConfig(EmbeddedKafkaCluster kafkaClus
         m.put(Config.CLIENT_ID.key, CLIENTID);
         m.put(Config.TC_RESOURCE_LABELS, io.strimzi.operator.common.model.Labels.STRIMZI_KIND_LABEL + "=topic");
         m.put(Config.FULL_RECONCILIATION_INTERVAL_MS.key, "20000");
+        m.put(Config.KAFKA_VERSION.key, KafkaVersionTopicTestUtils.kafkaVersion());
         return m;
     }
 
@@ -404,7 +405,7 @@ protected void awaitTopicConfigInKube(String resourceName, String key, String ex
         waitFor(() -> {
             KafkaTopic topic = operation().inNamespace(NAMESPACE).withName(resourceName).get();
             LOGGER.info("Polled topic {}, waiting for config change", resourceName);
-            String gotValue = TopicSerialization.fromTopicResource(topic).getConfig().get(key);
+            String gotValue = TopicSerialization.fromTopicResource(topic, KafkaVersionTopicTestUtils.kafkaVersion()).getConfig().get(key);
             LOGGER.info("Expecting value {}, got value {}", expectedValue, gotValue);
             return expectedValue.equals(gotValue);
         }, "Expected the config of topic " + resourceName + " to have " + key + "=" + expectedValue + " in Kube by now");
@@ -448,7 +449,7 @@ protected void alterTopicNumPartitions(String topicName, String resourceName) th
         waitFor(() -> {
             KafkaTopic topic = operation().inNamespace(NAMESPACE).withName(resourceName).get();
             LOGGER.info("Polled topic {}, waiting for partitions change", resourceName);
-            int gotValue = TopicSerialization.fromTopicResource(topic).getNumPartitions();
+            int gotValue = TopicSerialization.fromTopicResource(topic, KafkaVersionTopicTestUtils.kafkaVersion()).getNumPartitions();
             LOGGER.info("Expected value {}, got value {}", changedValue, gotValue);
             return changedValue == gotValue;
         }, "Expected the topic " + topicName + "to have " + changedValue + " partitions by now");

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorMockTest.java
Patch:
@@ -99,7 +99,8 @@ public void setup(VertxTestContext context) throws Exception {
             Config.ZOOKEEPER_CONNECTION_TIMEOUT_MS.key, "30000",
             Config.NAMESPACE.key, "myproject",
             Config.CLIENT_ID.key, "myproject-client-id",
-            Config.FULL_RECONCILIATION_INTERVAL_MS.key, "10000"
+            Config.FULL_RECONCILIATION_INTERVAL_MS.key, "10000",
+            Config.KAFKA_VERSION.key, KafkaVersionTopicTestUtils.kafkaVersion()
         ));
 
         session = new Session(kubeClient, topicConfig);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -44,6 +44,7 @@ public class EntityTopicOperator extends AbstractModel {
     protected static final String TOPIC_OPERATOR_CONTAINER_NAME = "topic-operator";
     private static final String NAME_SUFFIX = "-entity-topic-operator";
     protected static final String METRICS_AND_LOG_CONFIG_SUFFIX = NAME_SUFFIX + "-config";
+    private static final String CERT_SECRET_KEY_NAME = "entity-operator";
 
     // Port configuration
     protected static final int HEALTHCHECK_PORT = 8080;
@@ -379,6 +380,6 @@ public String createLog4jProperties(OrderedProperties properties) {
     public Secret generateSecret(ClusterCa clusterCa, boolean isMaintenanceTimeWindowsSatisfied) {
         Secret secret = clusterCa.entityTopicOperatorSecret();
         return ModelUtils.buildSecret(reconciliation, clusterCa, secret, namespace, EntityTopicOperator.secretName(cluster), name,
-                APPLICATION_NAME, labels, createOwnerReference(), isMaintenanceTimeWindowsSatisfied);
+            CERT_SECRET_KEY_NAME, labels, createOwnerReference(), isMaintenanceTimeWindowsSatisfied);
     }
 }

File: user-operator/src/main/java/io/strimzi/operator/user/Main.java
Patch:
@@ -125,7 +125,7 @@ private static Future<Admin> createAdminClient(AdminClientProvider adminClientPr
                 .onComplete(ar -> {
                     if (ar.succeeded()) {
                         Admin adminClient = adminClientProvider.createAdminClient(config.getKafkaBootstrapServers(),
-                                clusterCaCertSecretFuture.result(), euoKeySecretFuture.result(), euoKeySecretFuture.result() != null ? "entity-user-operator" : null);
+                                clusterCaCertSecretFuture.result(), euoKeySecretFuture.result(), euoKeySecretFuture.result() != null ? "entity-operator" : null);
                         promise.complete(adminClient);
                     } else {
                         promise.fail(ar.cause());

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -151,7 +151,7 @@ public class Environment {
     public static final String OLM_OPERATOR_DEPLOYMENT_NAME_DEFAULT = Constants.STRIMZI_DEPLOYMENT_NAME;
     public static final String OLM_SOURCE_NAME_DEFAULT = "community-operators";
     public static final String OLM_APP_BUNDLE_PREFIX_DEFAULT = "strimzi-cluster-operator";
-    public static final String OLM_OPERATOR_VERSION_DEFAULT = "0.25.0";
+    public static final String OLM_OPERATOR_VERSION_DEFAULT = "0.26.1";
     private static final boolean DEFAULT_TO_DENY_NETWORK_POLICIES_DEFAULT = true;
     private static final ClusterOperatorInstallType CLUSTER_OPERATOR_INSTALL_TYPE_DEFAULT = ClusterOperatorInstallType.BUNDLE;
     private static final boolean LB_FINALIZERS_DEFAULT = false;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/InternalKafkaClient.java
Patch:
@@ -305,6 +305,7 @@ public Map<String, String> getCurrentOffsets(long timeoutMs) {
             .withClientType(ClientType.CLI_KAFKA_CONSUMER_GROUPS)
             .withUsingPodName(podName)
             .withPodNamespace(namespaceName)
+            .withTopicName(topicName)
             .withBootstrapServer(getBootstrapServerFromStatus())
             .withConsumerGroupName(consumerGroup)
             .build();

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/VerifiableClient.java
Patch:
@@ -111,6 +111,7 @@ public VerifiableClient(VerifiableClientBuilder verifiableClientBuilder) {
         this.topicName = verifiableClientBuilder.topicName;
         this.maxMessages = verifiableClientBuilder.maxMessages;
         this.kafkaUsername = verifiableClientBuilder.kafkaUsername;
+        this.consumerInstanceId = verifiableClientBuilder.consumerInstanceId;
 
         this.setAllowedArguments(this.clientType);
         this.clientArgumentMap = new ClientArgumentMap();

File: systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java
Patch:
@@ -63,7 +63,7 @@ public static void waitForClientSuccess(String jobName, String namespace, int me
         TestUtils.waitFor("job finished", Constants.GLOBAL_POLL_INTERVAL, timeoutForClientFinishJob(messageCount),
             () -> {
                 LOGGER.debug("Job {} in namespace {}, has status {}", jobName, namespace, kubeClient().namespace(namespace).getJobStatus(jobName));
-                return kubeClient().namespace(namespace).checkSucceededJobStatus(jobName);
+                return kubeClient().namespace(namespace).checkSucceededJobStatus(namespace, jobName, 1);
             });
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/dump/LogDumpScriptIsolatedST.java
Patch:
@@ -31,8 +31,8 @@
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
 @IsolatedSuite
-public class LogDumpScriptST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(LogDumpScriptST.class);
+public class LogDumpScriptIsolatedST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(LogDumpScriptIsolatedST.class);
 
     @IsolatedTest
     void dumpPartitions(ExtensionContext context) {

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/QuotasIsolatedST.java
Patch:
@@ -32,7 +32,7 @@
 import static org.junit.jupiter.api.Assertions.assertThrows;
 
 @IsolatedSuite
-public class QuotasST extends AbstractST {
+public class QuotasIsolatedST extends AbstractST {
 
     /**
      * Test to check Kafka Quotas Plugin for disk space
@@ -86,8 +86,8 @@ void testKafkaQuotasPluginIntegration(ExtensionContext extensionContext) {
 
     @BeforeAll
     void setup(ExtensionContext extensionContext) {
-        install.unInstall();
-        install = new SetupClusterOperator.SetupClusterOperatorBuilder()
+        clusterOperator.unInstall();
+        clusterOperator = new SetupClusterOperator.SetupClusterOperatorBuilder()
             .withExtensionContext(BeforeAllOnce.getSharedExtensionContext())
             .withNamespace(INFRA_NAMESPACE)
             .withWatchingNamespaces(Constants.WATCH_ALL_NAMESPACES)

File: systemtest/src/test/java/io/strimzi/systemtest/olm/AllNamespacesIsolatedST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.olm;
 
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.resources.operator.specific.OlmResource;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.MethodOrderer;
@@ -21,7 +22,8 @@
 
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @Tag(OLM)
-public class AllNamespacesST extends OlmAbstractST {
+@IsolatedSuite
+public class AllNamespacesIsolatedST extends OlmAbstractST {
 
     public static final String NAMESPACE = "olm-namespace";
     public static OlmResource olmResource;

File: systemtest/src/test/java/io/strimzi/systemtest/olm/SingleNamespaceIsolatedST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.olm;
 
+import io.strimzi.systemtest.annotations.IsolatedSuite;
 import io.strimzi.systemtest.resources.operator.specific.OlmResource;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.MethodOrderer;
@@ -21,7 +22,8 @@
 
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @Tag(OLM)
-public class SingleNamespaceST extends OlmAbstractST {
+@IsolatedSuite
+public class SingleNamespaceIsolatedST extends OlmAbstractST {
 
     public static final String NAMESPACE = "olm-namespace";
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceRbacScopeOperatorIsolatedST.java
Patch:
@@ -31,16 +31,16 @@
 
 @Tag(REGRESSION)
 @IsolatedSuite
-class NamespaceRbacScopeOperatorST extends AbstractST {
+class NamespaceRbacScopeOperatorIsolatedST extends AbstractST {
 
     @IsolatedTest("This test case needs own Cluster Operator")
     void testNamespacedRbacScopeDeploysRoles(ExtensionContext extensionContext) {
         assumeFalse(Environment.isOlmInstall() || Environment.isHelmInstall());
 
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
 
-        install.unInstall();
-        install = new SetupClusterOperator.SetupClusterOperatorBuilder()
+        clusterOperator.unInstall();
+        clusterOperator = new SetupClusterOperator.SetupClusterOperatorBuilder()
             .withExtensionContext(BeforeAllOnce.getSharedExtensionContext())
             .withNamespace(INFRA_NAMESPACE)
             .withExtraEnvVars(Collections.singletonList(new EnvVar(Environment.STRIMZI_RBAC_SCOPE_ENV, Environment.STRIMZI_RBAC_SCOPE_NAMESPACE, null)))

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationIsolatedST.java
Patch:
@@ -61,8 +61,8 @@
 @Tag(INTERNAL_CLIENTS_USED)
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 @IsolatedSuite
-public class OauthAuthorizationST extends OauthAbstractST {
-    protected static final Logger LOGGER = LogManager.getLogger(OauthAuthorizationST.class);
+public class OauthAuthorizationIsolatedST extends OauthAbstractST {
+    protected static final Logger LOGGER = LogManager.getLogger(OauthAuthorizationIsolatedST.class);
 
     private final String oauthClusterName = "oauth-cluster-authz-name";
 
@@ -652,7 +652,6 @@ void testKeycloakAuthorizerToDelegateToSimpleAuthorizer(ExtensionContext extensi
 
     @BeforeAll
     void setUp(ExtensionContext extensionContext)  {
-        super.beforeAllMayOverride(extensionContext);
         // for namespace
         super.setupCoAndKeycloak(extensionContext, INFRA_NAMESPACE);
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainIsolatedST.java
Patch:
@@ -61,8 +61,8 @@
 @Tag(OAUTH)
 @Tag(REGRESSION)
 @IsolatedSuite
-public class OauthPlainST extends OauthAbstractST {
-    protected static final Logger LOGGER = LogManager.getLogger(OauthPlainST.class);
+public class OauthPlainIsolatedST extends OauthAbstractST {
+    protected static final Logger LOGGER = LogManager.getLogger(OauthPlainIsolatedST.class);
 
     private final String oauthClusterName = "oauth-cluster-plain-name";
     private final String customClaimListenerPort = "9099";
@@ -694,7 +694,6 @@ void testSaslPlainAuthenticationKafkaConnectIsAbleToConnectToKafkaOAuth(Extensio
 
     @BeforeAll
     void setUp(ExtensionContext extensionContext) {
-        super.beforeAllMayOverride(extensionContext);
         // for namespace
         super.setupCoAndKeycloak(extensionContext, INFRA_NAMESPACE);
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthScopeIsolatedST.java
Patch:
@@ -47,7 +47,7 @@
 @Tag(OAUTH)
 @Tag(REGRESSION)
 @IsolatedSuite
-public class OauthScopeST extends OauthAbstractST {
+public class OauthScopeIsolatedST extends OauthAbstractST {
     
     private final String oauthClusterName = "oauth-cluster-scope-name";
     private final String scopeListener = "scopelist";
@@ -239,7 +239,6 @@ void testClientScopeKafkaSetIncorrectly(ExtensionContext extensionContext) throw
 
     @BeforeAll
     void setUp(ExtensionContext extensionContext) {
-        super.beforeAllMayOverride(extensionContext);
         // for namespace
         super.setupCoAndKeycloak(extensionContext, INFRA_NAMESPACE);
 

File: systemtest/src/test/java/io/strimzi/systemtest/specific/ClusterOperationIsolatedST.java
Patch:
@@ -30,9 +30,9 @@
 
 @Tag(SPECIFIC)
 @IsolatedSuite
-public class ClusterOperationST extends AbstractST {
+public class ClusterOperationIsolatedST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(ClusterOperationST.class);
+    private static final Logger LOGGER = LogManager.getLogger(ClusterOperationIsolatedST.class);
 
     public static final String NAMESPACE = "cluster-operations-test";
 

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/KafkaUpgradeDowngradeIsolatedST.java
Patch:
@@ -40,9 +40,9 @@
  */
 @Tag(UPGRADE)
 @IsolatedSuite
-public class KafkaUpgradeDowngradeST extends AbstractUpgradeST {
+public class KafkaUpgradeDowngradeIsolatedST extends AbstractUpgradeST {
 
-    private static final Logger LOGGER = LogManager.getLogger(KafkaUpgradeDowngradeST.class);
+    private static final Logger LOGGER = LogManager.getLogger(KafkaUpgradeDowngradeIsolatedST.class);
 
     private final String continuousTopicName = "continuous-topic";
     private final int continuousClientsMessageCount = 1000;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeIsolatedST.java
Patch:
@@ -39,14 +39,14 @@
 
 /**
  * This test class contains tests for Strimzi downgrade from version X to version X - 1.
- * The difference between this class and {@link StrimziUpgradeST} is in cluster operator install type.
+ * The difference between this class and {@link StrimziUpgradeIsolatedST} is in cluster operator install type.
  * Tests in this class use OLM for install cluster operator.
  */
 @Tag(OLM_UPGRADE)
 @IsolatedSuite
-public class OlmUpgradeST extends AbstractUpgradeST {
+public class OlmUpgradeIsolatedST extends AbstractUpgradeST {
 
-    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);
+    private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeIsolatedST.class);
 
     private final String namespace = "olm-upgrade-namespace";
     private final String producerName = "producer";

File: test/src/main/java/io/strimzi/test/k8s/HelmClient.java
Patch:
@@ -48,6 +48,7 @@ public HelmClient install(Path chart, String releaseName, Map<String, Object> va
                 releaseName,
                 "--set", values,
                 "--timeout", INSTALL_TIMEOUT_SECONDS,
+                "--debug",
                 chart.toString()))), 0, true, true);
         return this;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaExporter.java
Patch:
@@ -156,7 +156,7 @@ public static KafkaExporter fromCrd(Reconciliation reconciliation, Kafka kafkaAs
                 ModelUtils.parsePodTemplate(kafkaExporter, template.getPod());
             }
 
-            kafkaExporter.setVersion(versions.version(kafkaAssembly.getSpec().getKafka().getVersion()).version());
+            kafkaExporter.setVersion(versions.supportedVersion(kafkaAssembly.getSpec().getKafka().getVersion()).version());
             kafkaExporter.setOwnerReference(kafkaAssembly);
         } else {
             kafkaExporter.isDeployed = false;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -256,7 +256,7 @@ public static ZookeeperCluster fromCrd(Reconciliation reconciliation, Kafka kafk
 
         // Get the ZK version information from either the CRD or from the default setting
         KafkaClusterSpec kafkaClusterSpec = kafkaAssembly.getSpec().getKafka();
-        String version = versions.version(kafkaClusterSpec != null ? kafkaClusterSpec.getVersion() : null).zookeeperVersion();
+        String version = versions.supportedVersion(kafkaClusterSpec != null ? kafkaClusterSpec.getVersion() : null).zookeeperVersion();
         zk.setVersion(version);
 
         String image = zookeeperClusterSpec.getImage();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiffTest.java
Patch:
@@ -34,7 +34,7 @@ public class KafkaBrokerConfigurationDiffTest {
 
     private static final KafkaVersion.Lookup VERSIONS = KafkaVersionTestUtils.getKafkaVersionLookup();
     private static final String KAFKA_VERSION = "3.0.0";
-    KafkaVersion kafkaVersion = VERSIONS.version(KAFKA_VERSION);
+    KafkaVersion kafkaVersion = VERSIONS.supportedVersion(KAFKA_VERSION);
     private int brokerId = 0;
 
     private ConfigEntry instantiateConfigEntry(String name, String val) {

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -392,7 +392,7 @@ void testLoadBalancerIpOverride(ExtensionContext extensionContext) {
     @Tag(REGRESSION)
     void testDeployUnsupportedKafka(ExtensionContext extensionContext) {
         String nonExistingVersion = "6.6.6";
-        String nonExistingVersionMessage = "Version " + nonExistingVersion + " is not supported. Supported versions are.*";
+        String nonExistingVersionMessage = "Unsupported Kafka.spec.kafka.version: " + nonExistingVersion + ". Supported versions are:.*";
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
 
         resourceManager.createResource(extensionContext, false, KafkaTemplates.kafkaEphemeral(clusterName, 1, 1)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -469,7 +469,8 @@ public KafkaBrokerConfigurationBuilder withAuthorization(String clusterName, Kaf
 
             // Broker super users
             superUsers.add(String.format("User:CN=%s,O=io.strimzi", KafkaResources.kafkaStatefulSetName(clusterName)));
-            superUsers.add(String.format("User:CN=%s-%s,O=io.strimzi", clusterName, "entity-operator"));
+            superUsers.add(String.format("User:CN=%s-%s,O=io.strimzi", clusterName, "entity-topic-operator"));
+            superUsers.add(String.format("User:CN=%s-%s,O=io.strimzi", clusterName, "entity-user-operator"));
             superUsers.add(String.format("User:CN=%s-%s,O=io.strimzi", clusterName, "kafka-exporter"));
             superUsers.add(String.format("User:CN=%s-%s,O=io.strimzi", clusterName, "cruise-control"));
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -140,7 +140,7 @@ public void testGenerateDeployment() {
         assertThat(EntityOperatorTest.volumeMounts(tlsSidecarContainer.getVolumeMounts()), is(map(
                         EntityOperator.TLS_SIDECAR_TMP_DIRECTORY_DEFAULT_VOLUME_NAME, AbstractModel.STRIMZI_TMP_DIRECTORY_DEFAULT_MOUNT_PATH,
                         EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT,
-                        EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT)));
+                        EntityOperator.ETO_CERTS_VOLUME_NAME, EntityOperator.ETO_CERTS_VOLUME_MOUNT)));
         assertThat(tlsSidecarContainer.getReadinessProbe().getInitialDelaySeconds(), is(Integer.valueOf(tlsHealthDelay)));
         assertThat(tlsSidecarContainer.getReadinessProbe().getTimeoutSeconds(), is(Integer.valueOf(tlsHealthTimeout)));
         assertThat(tlsSidecarContainer.getLivenessProbe().getInitialDelaySeconds(), is(Integer.valueOf(tlsHealthDelay)));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -224,7 +224,7 @@ public void testGetContainers() {
                 EntityTopicOperator.TOPIC_OPERATOR_TMP_DIRECTORY_DEFAULT_VOLUME_NAME, AbstractModel.STRIMZI_TMP_DIRECTORY_DEFAULT_MOUNT_PATH,
                 "entity-topic-operator-metrics-and-logging", "/opt/topic-operator/custom-config/",
                 EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT,
-                EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT)));
+                EntityOperator.ETO_CERTS_VOLUME_NAME, EntityOperator.ETO_CERTS_VOLUME_MOUNT)));
     }
 
     @ParallelTest

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -124,7 +124,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_CERT_SECRET_NAME).withValue(KafkaCluster.clientsCaCertSecretName(cluster)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_NAMESPACE).withValue(namespace).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLUSTER_CA_CERT_SECRET_NAME).withValue(KafkaCluster.clusterCaCertSecretName(cluster)).build());
-        expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_EO_KEY_SECRET_NAME).withValue(EntityOperator.secretName(cluster)).build());
+        expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_EO_KEY_SECRET_NAME).withValue(EntityUserOperator.secretName(cluster)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_VALIDITY).withValue(Integer.toString(CertificateAuthority.DEFAULT_CERTS_VALIDITY_DAYS)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_RENEWAL).withValue(Integer.toString(CertificateAuthority.DEFAULT_CERTS_RENEWAL_DAYS)).build());
@@ -241,7 +241,7 @@ public void testGetContainers() {
                 EntityUserOperator.USER_OPERATOR_TMP_DIRECTORY_DEFAULT_VOLUME_NAME, AbstractModel.STRIMZI_TMP_DIRECTORY_DEFAULT_MOUNT_PATH,
                 "entity-user-operator-metrics-and-logging", "/opt/user-operator/custom-config/",
                 EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT,
-                EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT)));
+                EntityOperator.EUO_CERTS_VOLUME_NAME, EntityOperator.EUO_CERTS_VOLUME_MOUNT)));
     }
 
     @ParallelTest

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -626,7 +626,7 @@ void testRemoveTopicOperatorFromEntityOperator(ExtensionContext extensionContext
         //Waiting when EO pod will be recreated without TO
         PodUtils.deletePodWithWait(namespaceName, eoPodName);
         DeploymentUtils.waitForDeploymentAndPodsReady(namespaceName, KafkaResources.entityOperatorDeploymentName(clusterName), 1);
-        PodUtils.waitUntilPodContainersCount(namespaceName, KafkaResources.entityOperatorDeploymentName(clusterName), 2);
+        PodUtils.waitUntilPodContainersCount(namespaceName, KafkaResources.entityOperatorDeploymentName(clusterName), 1);
 
         //Checking that TO was removed
         kubeClient(namespaceName).listPodsByPrefixInName(namespaceName, KafkaResources.entityOperatorDeploymentName(clusterName)).forEach(pod -> {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectBuildUtils.java
Patch:
@@ -15,8 +15,10 @@ public class KafkaConnectBuildUtils {
      *
      * @return      True if the Pod is already complete, false otherwise
      */
+    @SuppressWarnings("BooleanExpressionComplexity")
     public static boolean buildPodComplete(Pod pod)   {
-        return pod.getStatus() != null
+        return pod != null
+                && pod.getStatus() != null
                 && pod.getStatus().getContainerStatuses() != null
                 && pod.getStatus().getContainerStatuses().size() > 0
                 && pod.getStatus().getContainerStatuses().get(0) != null

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/InternalKafkaClient.java
Patch:
@@ -312,6 +312,9 @@ public Map<String, String> getCurrentOffsets(long timeoutMs) {
 
         boolean hasPassed = consumerGroups.run(timeoutMs);
         LOGGER.info("ConsumerGroups finished correctly: {}", hasPassed);
+        if (!hasPassed) {
+            throw new RuntimeException("VerifiableClient has failed. Check stderr for more details.");
+        }
 
         // output parsing
         Map<String, String> currentOffsets = new HashMap<>();

File: systemtest/src/test/java/io/strimzi/systemtest/backup/ColdBackupScriptST.java
Patch:
@@ -58,6 +58,7 @@ void backupAndRestore(ExtensionContext context) {
 
         // save consumer group offsets
         Map<String, String> offsetsBeforeBackup = clients.getCurrentOffsets();
+        assertThat("No offsets map before backup", offsetsBeforeBackup != null && offsetsBeforeBackup.size() > 0);
 
         // send additional messages
         clients.setMessageCount(secondBatchSize);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java
Patch:
@@ -213,6 +213,7 @@ public static void waitForClusterStability(String namespaceName, String clusterN
             }
             zkPods[0] = zkSnapshot;
             kafkaPods[0] = kafkaSnaptop;
+            eoPods[0] = eoSnapshot;
             count[0] = 0;
             return false;
         });

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -283,7 +283,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_SECURITY_PROTOCOL, EntityTopicOperatorSpec.DEFAULT_SECURITY_PROTOCOL));
         varList.add(buildEnvVar(ENV_VAR_TLS_ENABLED, Boolean.toString(true)));
         varList.add(buildEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
-        EntityOperator.javaOptions(varList, getJvmOptions(), javaSystemProperties);
+        ModelUtils.javaOptions(varList, getJvmOptions(), javaSystemProperties);
 
         // Add shared environment variables used for all containers
         varList.addAll(getRequiredEnvVars());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -281,7 +281,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
         varList.add(buildEnvVar(ENV_VAR_SECRET_PREFIX, secretPrefix));
         varList.add(buildEnvVar(ENV_VAR_ACLS_ADMIN_API_SUPPORTED, String.valueOf(aclsAdminApiSupported)));
-        EntityOperator.javaOptions(varList, getJvmOptions(), javaSystemProperties);
+        ModelUtils.javaOptions(varList, getJvmOptions(), javaSystemProperties);
 
         // Add shared environment variables used for all containers
         varList.addAll(getRequiredEnvVars());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -167,6 +167,7 @@ public static KafkaBridgeCluster fromCrd(Reconciliation reconciliation, KafkaBri
         if (spec.getJvmOptions() != null) {
             kafkaBridgeCluster.setJavaSystemProperties(spec.getJvmOptions().getJavaSystemProperties());
         }
+        kafkaBridgeCluster.setJvmOptions(spec.getJvmOptions());
         String image = spec.getImage();
         if (image == null) {
             image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE, "quay.io/strimzi/kafka-bridge:latest");
@@ -346,9 +347,7 @@ protected List<EnvVar> getEnvVars() {
         List<EnvVar> varList = new ArrayList<>();
         varList.add(buildEnvVar(ENV_VAR_KAFKA_BRIDGE_METRICS_ENABLED, String.valueOf(isMetricsEnabled)));
         varList.add(buildEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
-        if (javaSystemProperties != null) {
-            varList.add(buildEnvVar(ENV_VAR_STRIMZI_JAVA_SYSTEM_PROPERTIES, ModelUtils.getJavaSystemPropertiesToString(javaSystemProperties)));
-        }
+        ModelUtils.javaOptions(varList, getJvmOptions(), javaSystemProperties);
 
         varList.add(buildEnvVar(ENV_VAR_KAFKA_BRIDGE_BOOTSTRAP_SERVERS, bootstrapServers));
         varList.add(buildEnvVar(ENV_VAR_KAFKA_BRIDGE_ADMIN_CLIENT_CONFIG, kafkaBridgeAdminClient == null ? "" : new KafkaBridgeAdminClientConfiguration(reconciliation, kafkaBridgeAdminClient.getConfig().entrySet()).getConfiguration()));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -261,13 +261,13 @@ Future<Void> connectBuild(Reconciliation reconciliation, String namespace, Kafka
         if (connectBuild.getBuild() != null) {
             // Build exists => let's build
             KafkaConnectDockerfile dockerfile = connectBuild.generateDockerfile();
-            String newBuildRevision = dockerfile.hashStub();
+            String newBuildRevision = dockerfile.hashStub() + Util.sha1Prefix(connectBuild.getBuild().getOutput().getImage());
             ConfigMap dockerFileConfigMap = connectBuild.generateDockerfileConfigMap(dockerfile);
 
             if (newBuildRevision.equals(buildState.currentBuildRevision)
                     && !buildState.forceRebuild) {
                 // The revision is the same and rebuild was not forced => nothing to do
-                LOGGER.infoCr(reconciliation, "Build configuration did not changed. Nothing new to build. Container image {} will be used.", buildState.currentImage);
+                LOGGER.infoCr(reconciliation, "Build configuration did not change. Nothing new to build. Container image {} will be used.", buildState.currentImage);
                 buildState.desiredImage = buildState.currentImage;
                 buildState.desiredBuildRevision = newBuildRevision;
                 return Future.succeededFuture();

File: api/src/main/java/io/strimzi/api/kafka/model/authentication/KafkaClientAuthentication.java
Patch:
@@ -23,6 +23,7 @@
         property = "type")
 @JsonSubTypes({
     @JsonSubTypes.Type(name = KafkaClientAuthenticationTls.TYPE_TLS, value = KafkaClientAuthenticationTls.class),
+    @JsonSubTypes.Type(name = KafkaClientAuthenticationScramSha256.TYPE_SCRAM_SHA_256, value = KafkaClientAuthenticationScramSha256.class),
     @JsonSubTypes.Type(name = KafkaClientAuthenticationScramSha512.TYPE_SCRAM_SHA_512, value = KafkaClientAuthenticationScramSha512.class),
     @JsonSubTypes.Type(name = KafkaClientAuthenticationPlain.TYPE_PLAIN, value = KafkaClientAuthenticationPlain.class),
     @JsonSubTypes.Type(name = KafkaClientAuthenticationOAuth.TYPE_OAUTH, value = KafkaClientAuthenticationOAuth.class),
@@ -35,8 +36,8 @@ public abstract class KafkaClientAuthentication implements UnknownPropertyPreser
     private Map<String, Object> additionalProperties;
 
     @Description("Authentication type. " +
-            "Currently the only supported types are `tls`, `scram-sha-512`, and `plain`. " +
-            "`scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. " +
+            "Currently the only supported types are `tls`, `scram-sha-256`, `scram-sha-512`, and `plain`. " +
+            "`scram-sha-256` and `scram-sha-512` types use SASL SCRAM-SHA-256 and SASL SCRAM-SHA-512 Authentication, respectively. " +
             "`plain` type uses SASL PLAIN Authentication. " +
             "`oauth` type uses SASL OAUTHBEARER Authentication. " +
             "The `tls` type uses TLS Client Authentication. " +

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Cluster.java
Patch:
@@ -22,7 +22,7 @@
 import io.strimzi.api.kafka.model.authentication.KafkaClientAuthentication;
 import io.strimzi.api.kafka.model.authentication.KafkaClientAuthenticationOAuth;
 import io.strimzi.api.kafka.model.authentication.KafkaClientAuthenticationPlain;
-import io.strimzi.api.kafka.model.authentication.KafkaClientAuthenticationScramSha512;
+import io.strimzi.api.kafka.model.authentication.KafkaClientAuthenticationScram;
 import io.strimzi.api.kafka.model.authentication.KafkaClientAuthenticationTls;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.Util;
@@ -239,8 +239,8 @@ protected List<EnvVar> getEnvVars() {
                 } else if (authentication instanceof KafkaClientAuthenticationPlain) {
                     KafkaClientAuthenticationPlain passwordAuth = (KafkaClientAuthenticationPlain) authentication;
                     appendClusterPasswordSecretSource(clustersSaslPasswordFiles, clusterAlias, passwordAuth.getPasswordSecret());
-                } else if (authentication instanceof KafkaClientAuthenticationScramSha512) {
-                    KafkaClientAuthenticationScramSha512 passwordAuth = (KafkaClientAuthenticationScramSha512) authentication;
+                } else if (authentication instanceof KafkaClientAuthenticationScram) {
+                    KafkaClientAuthenticationScram passwordAuth = (KafkaClientAuthenticationScram) authentication;
                     appendClusterPasswordSecretSource(clustersSaslPasswordFiles, clusterAlias, passwordAuth.getPasswordSecret());
                 } else if (authentication instanceof KafkaClientAuthenticationOAuth) {
                     KafkaClientAuthenticationOAuth oauth = (KafkaClientAuthenticationOAuth) authentication;

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaConnectCrdIT.java
Patch:
@@ -48,7 +48,7 @@ void testKafkaConnectWithExtraProperty() {
     @Test
     void testKafkaConnectWithMissingRequired() {
         Throwable exception = assertThrows(
-            KubeClusterException.InvalidResource.class,
+            KubeClusterException.class,
             () -> createDeleteCustomResource("KafkaConnect-with-missing-required-property.yaml"));
 
         assertMissingRequiredPropertiesMessage(exception.getMessage(), "spec.bootstrapServers");

File: api/src/test/java/io/strimzi/api/kafka/model/AbstractCrdIT.java
Patch:
@@ -55,7 +55,7 @@ private void createDelete(File resourceFile) {
         RuntimeException deletionException = null;
         try {
             try {
-                cmdKubeClient().create(resourceFile, false);
+                cmdKubeClient().create(resourceFile, true);
             } catch (RuntimeException t) {
                 creationException = t;
             }
@@ -116,7 +116,8 @@ protected void assertMissingRequiredPropertiesMessage(String message, String...
             assertThat("Could not find" + requiredProperty + " in message: " + message, message, anyOf(
                     containsStringIgnoringCase(requiredProperty + " in body is required"),
                     containsStringIgnoringCase(requiredProperty + ": Required value"),
-                    containsStringIgnoringCase("missing required field \"" + requiredProperty + "\"")
+                    containsStringIgnoringCase("missing required field \"" + requiredProperty + "\""),
+                    containsStringIgnoringCase("missing required field \"" + requiredProperty.substring(requiredProperty.lastIndexOf(".") + 1) + "\"")
             ));
         }
     }

File: api/src/test/java/io/strimzi/api/kafka/model/StrimziPodSetCrdIT.java
Patch:
@@ -37,9 +37,9 @@ void testStrimziPodSettWithMissingRequired() {
 
     @BeforeAll
     void setupEnvironment() throws InterruptedException {
-        cluster.createNamespace(NAMESPACE);
         cluster.createCustomResources(TestUtils.CRD_STRIMZI_POD_SET);
         cluster.waitForCustomResourceDefinition("strimzipodsets.core.strimzi.io");
+        cluster.createNamespace(NAMESPACE);
     }
 
     @AfterAll

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -93,7 +93,6 @@ public KafkaBrokerConfigurationBuilder withCruiseControl(String clusterName, Cru
             writer.println(CruiseControlConfigurationParameters.METRICS_REPORTER_SSL_TRUSTSTORE_LOCATION + "=/tmp/kafka/cluster.truststore.p12");
             writer.println(CruiseControlConfigurationParameters.METRICS_REPORTER_SSL_TRUSTSTORE_PASSWORD + "=${CERTS_STORE_PASSWORD}");
             writer.println(CruiseControlConfigurationParameters.METRICS_TOPIC_AUTO_CREATE + "=true");
-            writer.println(CruiseControlConfigurationParameters.METRICS_REPORTER_KUBERNETES_MODE + "=true");
             if (numPartitions != null) {
                 writer.println(CruiseControlConfigurationParameters.METRICS_TOPIC_NUM_PARTITIONS + "=" + numPartitions);
             }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -93,7 +93,6 @@ public void testCruiseControl()  {
                 CruiseControlConfigurationParameters.METRICS_REPORTER_SSL_TRUSTSTORE_LOCATION + "=/tmp/kafka/cluster.truststore.p12\n" +
                 CruiseControlConfigurationParameters.METRICS_REPORTER_SSL_TRUSTSTORE_PASSWORD + "=${CERTS_STORE_PASSWORD}\n" +
                 CruiseControlConfigurationParameters.METRICS_TOPIC_AUTO_CREATE + "=true\n" +
-                CruiseControlConfigurationParameters.METRICS_REPORTER_KUBERNETES_MODE + "=true\n" +
                 CruiseControlConfigurationParameters.METRICS_TOPIC_NUM_PARTITIONS + "=1\n" +
                 CruiseControlConfigurationParameters.METRICS_TOPIC_REPLICATION_FACTOR + "=1\n" +
                 CruiseControlConfigurationParameters.METRICS_TOPIC_MIN_ISR + "=1"));

File: api/src/main/java/io/strimzi/api/kafka/model/Constants.java
Patch:
@@ -7,14 +7,14 @@
 
 public class Constants {
     public static final String RESOURCE_GROUP_NAME = "kafka.strimzi.io";
+    public static final String RESOURCE_CORE_GROUP_NAME = "core.strimzi.io";
 
     public static final String V1 = "v1";
     public static final String V1BETA2 = "v1beta2";
     public static final String V1BETA1 = "v1beta1";
     public static final String V1ALPHA1 = "v1alpha1";
 
     public static final String STRIMZI_CATEGORY = "strimzi";
-    public static final String STRIMZI_GROUP = "kafka.strimzi.io";
 
     public static final String FABRIC8_KUBERNETES_API = "io.fabric8.kubernetes.api.builder";
 

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -84,7 +84,7 @@
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
-@Group(Constants.STRIMZI_GROUP)
+@Group(Constants.RESOURCE_GROUP_NAME)
 @SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class Kafka extends CustomResource<KafkaSpec, KafkaStatus> implements Namespaced, UnknownPropertyPreserving {
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridge.java
Patch:
@@ -82,7 +82,7 @@
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
-@Group(Constants.STRIMZI_GROUP)
+@Group(Constants.RESOURCE_GROUP_NAME)
 public class KafkaBridge extends CustomResource<KafkaBridgeSpec, KafkaBridgeStatus> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnect.java
Patch:
@@ -79,7 +79,7 @@
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
-@Group(Constants.STRIMZI_GROUP)
+@Group(Constants.RESOURCE_GROUP_NAME)
 @SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaConnect extends CustomResource<KafkaConnectSpec, KafkaConnectStatus> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnector.java
Patch:
@@ -84,7 +84,7 @@
 @EqualsAndHashCode
 @ToString
 @Version(Constants.V1BETA2)
-@Group(Constants.STRIMZI_GROUP)
+@Group(Constants.RESOURCE_GROUP_NAME)
 @SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaConnector extends CustomResource<KafkaConnectorSpec, KafkaConnectorStatus> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker.java
Patch:
@@ -90,7 +90,7 @@
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
-@Group(Constants.STRIMZI_GROUP)
+@Group(Constants.RESOURCE_GROUP_NAME)
 @Deprecated
 @DeprecatedType(replacedWithType = io.strimzi.api.kafka.model.KafkaMirrorMaker2.class)
 public class KafkaMirrorMaker extends CustomResource<KafkaMirrorMakerSpec, KafkaMirrorMakerStatus> implements Namespaced, UnknownPropertyPreserving {

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2.java
Patch:
@@ -78,7 +78,7 @@
 @JsonPropertyOrder({ "apiVersion", "kind", "metadata", "spec", "status" })
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
-@Group(Constants.STRIMZI_GROUP)
+@Group(Constants.RESOURCE_GROUP_NAME)
 @SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaMirrorMaker2 extends CustomResource<KafkaMirrorMaker2Spec, KafkaMirrorMaker2Status> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaRebalance.java
Patch:
@@ -68,7 +68,7 @@
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
-@Group(Constants.STRIMZI_GROUP)
+@Group(Constants.RESOURCE_GROUP_NAME)
 @SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaRebalance extends CustomResource<KafkaRebalanceSpec, KafkaRebalanceStatus> implements Namespaced, UnknownPropertyPreserving {
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaTopic.java
Patch:
@@ -82,7 +82,7 @@
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
-@Group(Constants.STRIMZI_GROUP)
+@Group(Constants.RESOURCE_GROUP_NAME)
 public class KafkaTopic extends CustomResource<KafkaTopicSpec, KafkaTopicStatus> implements Namespaced, UnknownPropertyPreserving {
 
     private static final long serialVersionUID = 1L;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUser.java
Patch:
@@ -82,7 +82,7 @@
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
-@Group(Constants.STRIMZI_GROUP)
+@Group(Constants.RESOURCE_GROUP_NAME)
 public class KafkaUser extends CustomResource<KafkaUserSpec, KafkaUserStatus> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -110,6 +110,7 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
                 "abcdefghijklmnopqrstuvwxyz" +
                         "ABCDEFGHIJKLMNOPQRSTUVWXYZ" +
                         "0123456789");
+
         KafkaAssemblyOperator kafkaClusterOperations = new KafkaAssemblyOperator(vertx, pfa,
                 certManager, passwordGenerator, resourceOperatorSupplier, config);
         KafkaConnectAssemblyOperator kafkaConnectClusterOperations = new KafkaConnectAssemblyOperator(vertx, pfa,
@@ -140,7 +141,7 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
                     kafkaMirrorMaker2AssemblyOperator,
                     kafkaBridgeAssemblyOperator,
                     kafkaRebalanceAssemblyOperator,
-                    resourceOperatorSupplier.metricsProvider);
+                    resourceOperatorSupplier);
             vertx.deployVerticle(operator,
                 res -> {
                     if (res.succeeded()) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -151,7 +151,7 @@ public void test(VertxTestContext context) {
                 new ResourceOperatorSupplier(
                         null, null, null, null, null, null, null, null, null, null, null,
                         null, null, null, null, null, null, null, null, null,
-                        null, null, connectCrdOperator, null, null, null, null, null, metrics, null, null),
+                        null, null, connectCrdOperator, null, null, null, null, null, null, metrics, null, null),
                 ClusterOperatorConfig.fromMap(Collections.emptyMap(), KafkaVersionTestUtils.getKafkaVersionLookup()),
             connect -> new KafkaConnectApiImpl(vertx),
             connectCluster.getPort() + 2

File: operator-common/src/main/java/io/strimzi/operator/common/Util.java
Patch:
@@ -511,7 +511,7 @@ public static String sha1Prefix(String toBeHashed)   {
 
             return String.format("%040x", new BigInteger(1, digest)).substring(0, 8);
         } catch (NoSuchAlgorithmException e) {
-            throw new RuntimeException("Failed to get artifact URL SHA-1 hash", e);
+            throw new RuntimeException("Failed to get SHA-1 hash", e);
         }
     }
 
@@ -622,7 +622,8 @@ public static Future<MetricsAndLogging> metricsAndLogging(Reconciliation reconci
     /**
      * Checks if the Kubernetes resource matches LabelSelector. This is useful when you use get/getAsync to retrieve an
      * resource and want to check if it matches the labels from the selector (since get/getAsync is using name and not
-     * labels to identify the resource).
+     * labels to identify the resource). This method currently supports only the matchLabels object. matchExpressions
+     * array is not supported.
      *
      * @param labelSelector The LabelSelector with the labels which should be present in the resource
      * @param cr            The Custom Resource which labels should be checked

File: systemtest/src/main/java/io/strimzi/systemtest/metrics/MetricsCollector.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.resources.ComponentType;
 import io.strimzi.systemtest.resources.ResourceManager;
+import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.executor.Exec;
 import org.apache.logging.log4j.LogManager;
@@ -155,9 +156,9 @@ protected MetricsCollector(Builder builder) {
     private LabelSelector getLabelSelectorForResource() {
         switch (this.componentType) {
             case Kafka:
-                return kubeClient(namespaceName).getStatefulSetSelectors(KafkaResources.kafkaStatefulSetName(componentName));
+                return KafkaResource.getLabelSelector(componentName, KafkaResources.kafkaStatefulSetName(componentName));
             case Zookeeper:
-                return kubeClient(namespaceName).getStatefulSetSelectors(KafkaResources.zookeeperStatefulSetName(componentName));
+                return KafkaResource.getLabelSelector(componentName, KafkaResources.zookeeperStatefulSetName(componentName));
             case KafkaConnect:
                 return kubeClient(namespaceName).getDeploymentSelectors(KafkaConnectResources.deploymentName(componentName));
             case KafkaExporter:

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -286,8 +286,7 @@ void testKafkaAndZookeeperScaleUpScaleDown(ExtensionContext extensionContext) {
 
         LOGGER.info("Running kafkaScaleUpScaleDown {}", clusterName);
 
-        final int initialReplicas = kubeClient(namespaceName).getStatefulSet(KafkaResources.kafkaStatefulSetName(clusterName)).getStatus().getReplicas();
-
+        final int initialReplicas = kubeClient(namespaceName).getClient().pods().inNamespace(namespaceName).withLabelSelector(kafkaSelector).list().getItems().size();
         assertEquals(3, initialReplicas);
 
         resourceManager.createResource(extensionContext, KafkaTopicTemplates.topic(clusterName, topicName, 3, initialReplicas, initialReplicas).build());
@@ -400,7 +399,7 @@ void testZookeeperScaleUpScaleDown(ExtensionContext extensionContext) {
 
         // kafka cluster already deployed
         LOGGER.info("Running zookeeperScaleUpScaleDown with cluster {}", clusterName);
-        final int initialZkReplicas = kubeClient(namespaceName).getStatefulSet(KafkaResources.zookeeperStatefulSetName(clusterName)).getStatus().getReplicas();
+        final int initialZkReplicas = kubeClient(namespaceName).getClient().pods().inNamespace(namespaceName).withLabelSelector(zkSelector).list().getItems().size();
         assertThat(initialZkReplicas, is(3));
 
         resourceManager.createResource(extensionContext, false, KafkaClientsTemplates.kafkaClients(true, kafkaClientsName, user).build());

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/AbstractUpgradeST.java
Patch:
@@ -560,9 +560,9 @@ protected String getResourceApiVersion(String resourcePlural) {
 
     protected String getResourceApiVersion(String resourcePlural, String coVersion) {
         if (coVersion.equals("HEAD") || TestKafkaVersion.compareDottedVersions(coVersion, "0.22.0") >= 0) {
-            return resourcePlural + "." + Constants.V1BETA2 + "." + Constants.STRIMZI_GROUP;
+            return resourcePlural + "." + Constants.V1BETA2 + "." + Constants.RESOURCE_GROUP_NAME;
         } else {
-            return resourcePlural + "." + Constants.V1BETA1 + "." + Constants.STRIMZI_GROUP;
+            return resourcePlural + "." + Constants.V1BETA1 + "." + Constants.RESOURCE_GROUP_NAME;
         }
     }
 

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -91,6 +91,8 @@ public final class TestUtils {
 
     public static final String CRD_KAFKA_REBALANCE = USER_PATH + "/../packaging/install/cluster-operator/049-Crd-kafkarebalance.yaml";
 
+    public static final String CRD_STRIMZI_POD_SET = USER_PATH + "/../packaging/install/cluster-operator/042-Crd-strimzipodset.yaml";
+
     private TestUtils() {
         // All static methods
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -85,6 +85,7 @@
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.ReconciliationLogger;
 import io.strimzi.operator.common.Util;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.model.OrderedProperties;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControlConfiguration.java
Patch:
@@ -9,6 +9,7 @@
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlGoals;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlConfigurationParameters;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.util.Arrays;
 import java.util.Collections;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -167,7 +167,7 @@ public static EntityOperator fromCrd(Reconciliation reconciliation, Kafka kafkaA
 
             result.setOwnerReference(kafkaAssembly);
 
-            EntityTopicOperator topicOperator = EntityTopicOperator.fromCrd(reconciliation, kafkaAssembly);
+            EntityTopicOperator topicOperator = EntityTopicOperator.fromCrd(reconciliation, kafkaAssembly, versions);
             EntityUserOperator userOperator = EntityUserOperator.fromCrd(reconciliation, kafkaAssembly);
             TlsSidecar tlsSidecar = entityOperatorSpec.getTlsSidecar();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeAdminClientConfiguration.java
Patch:
@@ -7,6 +7,7 @@
 
 import io.strimzi.api.kafka.model.KafkaBridgeAdminClientSpec;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.util.HashMap;
 import java.util.List;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeConsumerConfiguration.java
Patch:
@@ -7,6 +7,7 @@
 
 import io.strimzi.api.kafka.model.KafkaBridgeConsumerSpec;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.util.HashMap;
 import java.util.List;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeProducerConfiguration.java
Patch:
@@ -7,6 +7,7 @@
 
 import io.strimzi.api.kafka.model.KafkaBridgeProducerSpec;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.util.HashMap;
 import java.util.List;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -23,6 +23,7 @@
 import io.strimzi.kafka.oauth.server.ServerConfig;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlConfigurationParameters;
 import io.strimzi.kafka.oauth.server.plain.ServerPlainConfig;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.io.PrintWriter;
 import java.io.StringWriter;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConfiguration.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.kafka.config.model.ConfigModels;
 import io.strimzi.kafka.config.model.Scope;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.io.IOException;
 import java.io.InputStream;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -58,6 +58,7 @@
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.Util;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 import io.strimzi.operator.common.model.Labels;
 
 import java.nio.charset.StandardCharsets;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectConfiguration.java
Patch:
@@ -7,6 +7,7 @@
 
 import io.strimzi.api.kafka.model.KafkaConnectSpec;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.util.HashMap;
 import java.util.List;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Configuration.java
Patch:
@@ -7,6 +7,7 @@
 
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2ClusterSpec;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.util.HashMap;
 import java.util.List;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerConsumerConfiguration.java
Patch:
@@ -7,6 +7,7 @@
 
 import io.strimzi.api.kafka.model.KafkaMirrorMakerConsumerSpec;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.util.HashMap;
 import java.util.List;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerProducerConfiguration.java
Patch:
@@ -7,6 +7,7 @@
 
 import io.strimzi.api.kafka.model.KafkaMirrorMakerProducerSpec;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.util.HashMap;
 import java.util.List;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperConfiguration.java
Patch:
@@ -7,6 +7,7 @@
 
 import io.strimzi.api.kafka.model.ZookeeperClusterSpec;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 
 import java.util.Collections;
 import java.util.HashMap;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
Patch:
@@ -8,6 +8,7 @@
 import io.fabric8.kubernetes.api.model.LocalObjectReferenceBuilder;
 import io.strimzi.operator.cluster.model.ImagePullPolicy;
 import io.strimzi.operator.cluster.model.KafkaVersion;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.model.UnsupportedVersionException;
 import io.strimzi.operator.common.InvalidConfigurationException;
 import io.strimzi.operator.common.model.Labels;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
Patch:
@@ -12,6 +12,7 @@
 import io.fabric8.openshift.client.OpenShiftClient;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.vertx.core.Vertx;
 import io.vertx.core.VertxOptions;
 import io.vertx.junit5.VertxExtension;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/MainIT.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.fabric8.kubernetes.client.DefaultKubernetesClient;
 import io.fabric8.kubernetes.client.KubernetesClient;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.common.operator.resource.ClusterRoleOperator;
 import io.strimzi.test.k8s.cluster.KubeCluster;
 import io.vertx.core.Vertx;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractConfigurationTest.java
Patch:
@@ -10,6 +10,7 @@
 
 import io.strimzi.operator.common.InvalidConfigParameterException;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.AbstractConfiguration;
 import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.test.annotations.ParallelSuite;
 import io.strimzi.test.annotations.ParallelTest;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -49,7 +49,6 @@
 import io.strimzi.api.kafka.model.storage.Storage;
 import io.strimzi.api.kafka.model.template.IpFamily;
 import io.strimzi.api.kafka.model.template.IpFamilyPolicy;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.cruisecontrol.Capacity;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlConfigurationParameters;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -38,7 +38,6 @@
 import io.strimzi.api.kafka.model.TlsSidecarBuilder;
 import io.strimzi.api.kafka.model.TlsSidecarLogLevel;
 import io.strimzi.api.kafka.model.template.ContainerTemplate;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/JmxTransTest.java
Patch:
@@ -28,7 +28,6 @@
 import io.strimzi.api.kafka.model.template.ContainerTemplate;
 import io.strimzi.api.kafka.model.template.JmxTransOutputDefinitionTemplateBuilder;
 import io.strimzi.api.kafka.model.template.JmxTransQueryTemplateBuilder;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.components.JmxTransOutputWriter;
 import io.strimzi.operator.cluster.model.components.JmxTransQueries;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -43,7 +43,6 @@
 import io.strimzi.api.kafka.model.tracing.JaegerTracing;
 import io.strimzi.kafka.oauth.client.ClientConfig;
 import io.strimzi.kafka.oauth.server.ServerConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterOAuthValidationTest.java
Patch:
@@ -14,7 +14,6 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.api.kafka.model.storage.EphemeralStorage;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.test.annotations.ParallelSuite;
 import io.strimzi.test.annotations.ParallelTest;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -78,7 +78,6 @@
 import io.strimzi.api.kafka.model.template.IpFamilyPolicy;
 import io.strimzi.api.kafka.model.template.PodManagementPolicy;
 import io.strimzi.certs.OpenSslCertManager;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlConfigurationParameters;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConfigurationTests.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.cluster.model;
 
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.test.annotations.ParallelSuite;
 import io.strimzi.test.annotations.ParallelTest;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectBuildTest.java
Patch:
@@ -17,7 +17,6 @@
 import io.strimzi.api.kafka.model.connect.build.Artifact;
 import io.strimzi.api.kafka.model.connect.build.JarArtifactBuilder;
 import io.strimzi.api.kafka.model.connect.build.PluginBuilder;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.test.TestUtils;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -62,7 +62,6 @@
 import io.strimzi.api.kafka.model.template.IpFamilyPolicy;
 import io.strimzi.kafka.oauth.client.ClientConfig;
 import io.strimzi.kafka.oauth.server.ServerConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.common.Reconciliation;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaExporterTest.java
Patch:
@@ -34,7 +34,6 @@
 import io.strimzi.api.kafka.model.storage.EphemeralStorage;
 import io.strimzi.api.kafka.model.storage.SingleVolumeStorage;
 import io.strimzi.api.kafka.model.storage.Storage;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -55,7 +55,6 @@
 import io.strimzi.api.kafka.model.template.IpFamilyPolicy;
 import io.strimzi.kafka.oauth.client.ClientConfig;
 import io.strimzi.kafka.oauth.server.ServerConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.common.Reconciliation;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -41,7 +41,6 @@
 import io.strimzi.api.kafka.model.template.DeploymentStrategy;
 import io.strimzi.kafka.oauth.client.ClientConfig;
 import io.strimzi.kafka.oauth.server.ServerConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.common.Reconciliation;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaVersionTest.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.cluster.model;
 
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.test.annotations.ParallelSuite;
 import io.strimzi.test.annotations.ParallelTest;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ModelUtilsTest.java
Patch:
@@ -38,7 +38,6 @@
 import io.strimzi.api.kafka.model.template.PodDisruptionBudgetTemplateBuilder;
 import io.strimzi.api.kafka.model.template.PodTemplate;
 import io.strimzi.api.kafka.model.template.PodTemplateBuilder;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.test.annotations.ParallelSuite;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -51,7 +51,6 @@
 import io.strimzi.api.kafka.model.template.IpFamilyPolicy;
 import io.strimzi.api.kafka.model.template.PodManagementPolicy;
 import io.strimzi.certs.OpenSslCertManager;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.common.PasswordGenerator;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -24,7 +24,7 @@
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.cluster.FeatureGates;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
 import io.strimzi.operator.cluster.operator.resource.DefaultZookeeperScalerProvider;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -21,7 +21,7 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.FeatureGates;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaCluster;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorCustomCertTest.java
Patch:
@@ -27,7 +27,7 @@
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.cluster.FeatureGates;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorManualRollingUpdatesTest.java
Patch:
@@ -15,10 +15,10 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.model.ZookeeperCluster;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.cluster.operator.resource.StatefulSetOperator;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -35,7 +35,7 @@
 import io.strimzi.operator.cluster.ClusterOperator;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.cluster.FeatureGates;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.Ca;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorNonParametrizedTest.java
Patch:
@@ -22,10 +22,10 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaCluster;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.cluster.operator.resource.StatefulSetOperator;
 import io.strimzi.operator.common.PasswordGenerator;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorRbacScopeTest.java
Patch:
@@ -14,7 +14,7 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.EntityOperator;
 import io.strimzi.operator.cluster.model.KafkaVersion;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -49,7 +49,7 @@
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperator;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.ClientsCa;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -18,11 +18,11 @@
 import io.strimzi.api.kafka.model.status.KafkaBridgeStatus;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaBridgeCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.PasswordGenerator;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -19,7 +19,7 @@
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.cluster.FeatureGates;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.DefaultZookeeperScalerProvider;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -24,7 +24,7 @@
 import io.strimzi.api.kafka.model.status.KafkaConnectStatus;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectBuildAssemblyOperatorKubeTest.java
Patch:
@@ -24,7 +24,7 @@
 import io.strimzi.api.kafka.model.status.KafkaConnectStatus;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaConnectBuild;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectBuildAssemblyOperatorOpenShiftTest.java
Patch:
@@ -25,7 +25,7 @@
 import io.strimzi.api.kafka.model.status.KafkaConnectStatus;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaConnectBuild;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -13,7 +13,7 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.AbstractOperator;
 import io.strimzi.operator.common.MetricsProvider;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -17,7 +17,7 @@
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.cluster.FeatureGates;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.DefaultZookeeperScalerProvider;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorTest.java
Patch:
@@ -21,7 +21,7 @@
 import io.strimzi.api.kafka.model.status.KafkaMirrorMaker2Status;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaMirrorMaker2Cluster;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -17,7 +17,7 @@
 import io.strimzi.api.kafka.model.status.KafkaMirrorMakerStatus;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaMirrorMakerCluster;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -24,7 +24,7 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.CruiseControl;
 import io.strimzi.operator.cluster.model.InvalidResourceException;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaStatusTest.java
Patch:
@@ -28,7 +28,7 @@
 import io.strimzi.operator.cluster.ClusterOperator;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpgradeDowngradeMockTest.java
Patch:
@@ -20,7 +20,7 @@
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.cluster.FeatureGates;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaConfiguration;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -20,7 +20,7 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.FeatureGates;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.Ca;
 import io.strimzi.operator.cluster.model.KafkaCluster;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/VolumeResizingTest.java
Patch:
@@ -17,7 +17,7 @@
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiffTest.java
Patch:
@@ -5,7 +5,7 @@
 
 package io.strimzi.operator.cluster.operator.resource;
 
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.test.TestUtils;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaRollerTest.java
Patch:
@@ -22,7 +22,7 @@
 import io.fabric8.kubernetes.api.model.Secret;
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
 import io.fabric8.kubernetes.api.model.apps.StatefulSetBuilder;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.common.BackOff;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSpecCheckerTest.java
Patch:
@@ -12,7 +12,7 @@
 import io.strimzi.api.kafka.model.storage.EphemeralStorage;
 import io.strimzi.api.kafka.model.storage.EphemeralStorageBuilder;
 import io.strimzi.api.kafka.model.storage.JbodStorageBuilder;
-import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaConfiguration;

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java
Patch:
@@ -195,7 +195,7 @@ public String kafkaImage(String image, String version) {
          * @throws NoImageException If one of the versions lacks an image.
          * @throws UnsupportedVersionException If any version with configured image is not supported
          */
-        public void validateImages(Set<String> versions, Map<String, String> images) throws NoImageException, UnsupportedVersionException   {
+        public void validateImages(Set<String> versions, Map<String, String> images) throws NoImageException, UnsupportedVersionException {
             for (String version : versions) {
                 image(null, version, images);
             }

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/KafkaVersionTestUtils.java
Patch:
@@ -2,9 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster;
-
-import io.strimzi.operator.cluster.model.KafkaVersion;
+package io.strimzi.operator.cluster.model;
 
 import java.util.Collections;
 import java.util.HashMap;

File: operator-common/src/main/java/io/strimzi/operator/common/model/AbstractConfiguration.java
Patch:
@@ -3,11 +3,10 @@
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
 
-package io.strimzi.operator.cluster.model;
+package io.strimzi.operator.common.model;
 
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.ReconciliationLogger;
-import io.strimzi.operator.common.model.OrderedProperties;
 
 import java.util.Collections;
 import java.util.List;
@@ -186,7 +185,7 @@ public OrderedProperties asOrderedProperties() {
      * @param prefixes  String with comma-separated items
      * @return          List with the values as separate items
      */
-    protected static List<String> splitPrefixesToList(String prefixes) {
+    public static List<String> splitPrefixesToList(String prefixes) {
         return asList(prefixes.split("\\s*,+\\s*"));
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusST.java
Patch:
@@ -605,8 +605,9 @@ void assertKafkaTopicWrongMinInSyncReplicasStatus(String topicName, String inval
         assertThat(kafkaTopicStatus.getConditions().stream()
             .anyMatch(condition -> condition.getType().equals(NotReady.toString())), is(true));
         assertThat(kafkaTopicStatus.getConditions().stream()
-            .anyMatch(condition -> condition.getReason().equals("InvalidRequestException")), is(true));
+            .anyMatch(condition -> condition.getReason().equals("InvalidTopicException")), is(true));
         assertThat(kafkaTopicStatus.getConditions().stream()
-            .anyMatch(condition -> condition.getMessage().contains(String.format("Invalid value %s for configuration min.insync.replicas", invalidValue))), is(true));
+            .anyMatch(condition -> condition.getMessage().contains(String.format("KafkaTopic %s/%s has invalid spec.config: " +
+                    "min.insync.replicas has value '%s' which is not an int", INFRA_NAMESPACE, topicName, invalidValue))), is(true));
     }
 }

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorMockTest.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.KafkaTopicList;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopicBuilder;
+import io.strimzi.operator.cluster.model.KafkaVersionTestUtils;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.test.mockkube.MockKube;
@@ -99,7 +100,8 @@ public void setup(VertxTestContext context) throws Exception {
             Config.ZOOKEEPER_CONNECTION_TIMEOUT_MS.key, "30000",
             Config.NAMESPACE.key, "myproject",
             Config.CLIENT_ID.key, "myproject-client-id",
-            Config.FULL_RECONCILIATION_INTERVAL_MS.key, "10000"
+            Config.FULL_RECONCILIATION_INTERVAL_MS.key, "10000",
+            Config.KAFKA_VERSION.key, KafkaVersionTestUtils.LATEST_KAFKA_VERSION
         ));
 
         session = new Session(kubeClient, topicConfig);

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaMirrorMaker2Templates.java
Patch:
@@ -66,9 +66,9 @@ private static KafkaMirrorMaker2Builder defaultKafkaMirrorMaker2(KafkaMirrorMake
         KafkaMirrorMaker2ClusterSpec targetClusterSpec = new KafkaMirrorMaker2ClusterSpecBuilder()
             .withAlias(kafkaTargetClusterName)
             .withBootstrapServers(targetNs == null ? KafkaResources.plainBootstrapAddress(kafkaTargetClusterName) : KafkaUtils.namespacedPlainBootstrapAddress(kafkaTargetClusterName, targetNs))
-            .addToConfig("config.storage.replication.factor", 1)
-            .addToConfig("offset.storage.replication.factor", 1)
-            .addToConfig("status.storage.replication.factor", 1)
+            .addToConfig("config.storage.replication.factor", -1)
+            .addToConfig("offset.storage.replication.factor", -1)
+            .addToConfig("status.storage.replication.factor", -1)
             .build();
 
         KafkaMirrorMaker2ClusterSpec sourceClusterSpec = new KafkaMirrorMaker2ClusterSpecBuilder()

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaTemplates.java
Patch:
@@ -187,6 +187,8 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl
                     .addToConfig("offsets.topic.replication.factor", Math.min(kafkaReplicas, 3))
                     .addToConfig("transaction.state.log.min.isr", Math.min(kafkaReplicas, 2))
                     .addToConfig("transaction.state.log.replication.factor", Math.min(kafkaReplicas, 3))
+                    .addToConfig("default.replication.factor", Math.min(kafkaReplicas, 3))
+                    .addToConfig("min.insync.replicas", Math.min(Math.max(kafkaReplicas - 1, 1), 2))
                     .withListeners(new GenericKafkaListenerBuilder()
                                 .withName(Constants.PLAIN_LISTENER_DEFAULT_NAME)
                                 .withPort(9092)

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/CruiseControlUtils.java
Patch:
@@ -119,7 +119,7 @@ public static void verifyThatCruiseControlSamplesTopicsArePresent(String namespa
 
     public static void verifyThatKafkaCruiseControlMetricReporterTopicIsPresent(String namespaceName, long timeout) {
         final int numberOfPartitionsMetricTopic = 1;
-        final int numberOfReplicasMetricTopic = 1;
+        final int numberOfReplicasMetricTopic = 3;
 
         TestUtils.waitFor("Verify that kafka contains cruise control topics with related configuration.",
             Constants.GLOBAL_POLL_INTERVAL, timeout, () -> {

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -628,9 +628,9 @@ void testCustomAndUpdatedValues(ExtensionContext extensionContext) {
         envVarUpdated.put("TEST_ENV_3", "test.env.three");
 
         Map<String, Object> connectConfig = new HashMap<>();
-        connectConfig.put("config.storage.replication.factor", "1");
-        connectConfig.put("offset.storage.replication.factor", "1");
-        connectConfig.put("status.storage.replication.factor", "1");
+        connectConfig.put("config.storage.replication.factor", "-1");
+        connectConfig.put("offset.storage.replication.factor", "-1");
+        connectConfig.put("status.storage.replication.factor", "-1");
 
         final int initialDelaySeconds = 30;
         final int timeoutSeconds = 10;

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlST.java
Patch:
@@ -89,7 +89,7 @@ void testAutoCreationOfCruiseControlTopics(ExtensionContext extensionContext) {
 
         LOGGER.info("Checking partitions and replicas for {}", CRUISE_CONTROL_METRICS_TOPIC);
         assertThat(metricsTopic.getPartitions(), is(1));
-        assertThat(metricsTopic.getReplicas(), is(1));
+        assertThat(metricsTopic.getReplicas(), is(3));
 
         LOGGER.info("Checking partitions and replicas for {}", CRUISE_CONTROL_MODEL_TRAINING_SAMPLES_TOPIC);
         assertThat(modelTrainingTopic.getPartitions(), is(32));

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -133,7 +133,7 @@ void testKafkaBrokersCount() {
     void testKafkaTopicPartitions() {
         Pattern topicPartitions = Pattern.compile("kafka_server_replicamanager_partitioncount ([\\d.][^\\n]+)", Pattern.CASE_INSENSITIVE);
         ArrayList<Double> values = MetricsCollector.collectSpecificMetric(topicPartitions, kafkaMetricsData);
-        assertThat("Topic partitions count doesn't match expected value", values.stream().mapToDouble(i -> i).sum(), is(438.0));
+        assertThat("Topic partitions count doesn't match expected value", values.stream().mapToDouble(i -> i).sum(), is(504.0));
     }
 
     @ParallelTest

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java
Patch:
@@ -69,10 +69,10 @@ public class OauthAbstractST extends AbstractST {
     public static Map<String, Object> connectorConfig;
     static {
         connectorConfig = new HashMap<>();
-        connectorConfig.put("config.storage.replication.factor", 1);
+        connectorConfig.put("config.storage.replication.factor", -1);
         connectorConfig.put("config.topic.cleanup.policy", "compact");
-        connectorConfig.put("offset.storage.replication.factor", 1);
-        connectorConfig.put("status.storage.replication.factor", 1);
+        connectorConfig.put("offset.storage.replication.factor", -1);
+        connectorConfig.put("status.storage.replication.factor", -1);
     }
 
     protected static final Function<KeycloakInstance, GenericKafkaListener> BUILD_OAUTH_TLS_LISTENER = (keycloakInstance) -> {

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -341,9 +341,9 @@ void testProducerConsumerStreamsConnectService(ExtensionContext extensionContext
             .build());
 
         Map<String, Object> configOfKafkaConnect = new HashMap<>();
-        configOfKafkaConnect.put("config.storage.replication.factor", "1");
-        configOfKafkaConnect.put("offset.storage.replication.factor", "1");
-        configOfKafkaConnect.put("status.storage.replication.factor", "1");
+        configOfKafkaConnect.put("config.storage.replication.factor", "-1");
+        configOfKafkaConnect.put("offset.storage.replication.factor", "-1");
+        configOfKafkaConnect.put("status.storage.replication.factor", "-1");
         configOfKafkaConnect.put("key.converter", "org.apache.kafka.connect.storage.StringConverter");
         configOfKafkaConnect.put("value.converter", "org.apache.kafka.connect.storage.StringConverter");
         configOfKafkaConnect.put("key.converter.schemas.enable", "false");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConfiguration.java
Patch:
@@ -31,6 +31,8 @@ public class KafkaConfiguration extends AbstractConfiguration {
 
     public static final String INTERBROKER_PROTOCOL_VERSION = "inter.broker.protocol.version";
     public static final String LOG_MESSAGE_FORMAT_VERSION = "log.message.format.version";
+    public static final String DEFAULT_REPLICATION_FACTOR = "default.replication.factor";
+    public static final String MIN_INSYNC_REPLICAS = "min.insync.replicas";
 
     private static final List<String> FORBIDDEN_PREFIXES;
     private static final List<String> FORBIDDEN_PREFIX_EXCEPTIONS;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -538,8 +538,8 @@ public void testTemplate() {
                         .withLabels(podLabels)
                         .withAnnotations(podAnots)
                     .endMetadata()
-                    .withNewPriorityClassName("top-priority")
-                    .withNewSchedulerName("my-scheduler")
+                    .withPriorityClassName("top-priority")
+                    .withSchedulerName("my-scheduler")
                     .withHostAliases(hostAlias1, hostAlias2)
                     .withAffinity(affinity)
                     .withTolerations(tolerations)

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -357,6 +357,8 @@ public interface Constants {
     String CONSUMER_KEY = "CONSUMER_NAME";
     String KAFKA_CLIENTS_POD_KEY = "KAFKA_CLIENTS_POD_NAME";
     String KAFKA_TRACING_CLIENT_KEY = "KAFKA_TRACING_CLIENT";
+    String KAFKA_SELECTOR = "KAFKA_SELECTOR";
+    String ZOOKEEPER_SELECTOR = "ZOOKEEPER_SELECTOR";
 
     /**
      * Resource constants for Cluster Operator. In case we execute more than 5 test cases in parallel we at least these configuration

File: api/src/main/java/io/strimzi/api/kafka/model/template/BuildConfigTemplate.java
Patch:
@@ -33,7 +33,7 @@ public class BuildConfigTemplate implements Serializable, UnknownPropertyPreserv
     private String pullSecret;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
-    @Description("Metadata to apply to the `PodDistruptionBugetTemplate` resource.")
+    @Description("Metadata to apply to the `PodDisruptionBudgetTemplate` resource.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public MetadataTemplate getMetadata() {
         return metadata;

File: api/src/main/java/io/strimzi/api/kafka/model/template/PodDisruptionBudgetTemplate.java
Patch:
@@ -37,7 +37,7 @@ public class PodDisruptionBudgetTemplate implements Serializable, UnknownPropert
     private int maxUnavailable = 1;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
-    @Description("Metadata to apply to the `PodDistruptionBugetTemplate` resource.")
+    @Description("Metadata to apply to the `PodDisruptionBudgetTemplate` resource.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public MetadataTemplate getMetadata() {
         return metadata;

File: systemtest/src/main/java/io/strimzi/systemtest/parallel/ParallelNamespacesSuitesNames.java
Patch:
@@ -23,7 +23,9 @@ public class ParallelNamespacesSuitesNames {
         Constants.BRIDGE_KAFKA_CORS_NAMESPACE,
         Constants.BRIDGE_KAFKA_EXTERNAL_LISTENER_NAMESPACE,
         Constants.BRIDGE_SCRAM_SHA_NAMESPACE,
-        Constants.BRIDGE_HTTP_TLS_NAMESPACE
+        Constants.BRIDGE_HTTP_TLS_NAMESPACE,
+        // metrics namespace
+        Constants.METRICS_SECOND_NAMESPACE
     );
 
     public static String getRbacNamespacesToWatch() {

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java
Patch:
@@ -70,6 +70,7 @@ public class OauthAbstractST extends AbstractST {
     static {
         connectorConfig = new HashMap<>();
         connectorConfig.put("config.storage.replication.factor", 1);
+        connectorConfig.put("config.topic.cleanup.policy", "compact");
         connectorConfig.put("offset.storage.replication.factor", 1);
         connectorConfig.put("status.storage.replication.factor", 1);
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java
Patch:
@@ -436,7 +436,8 @@ public static int compareDottedVersions(String version1, String version2) {
                 return 1;
             }
         }
-        return components.length - otherComponents.length;
+        // mismatch was not found, but the versions are of different length, e.g. 2.8 and 2.8.0
+        return 0;
     }
 
     @Override

File: operator-common/src/main/java/io/strimzi/operator/common/InvalidConfigParameterException.java
Patch:
@@ -11,7 +11,7 @@ public class InvalidConfigParameterException extends InvalidResourceException {
 
     private String key;
     public InvalidConfigParameterException(String key, String message) {
-        super(key + message);
+        super(key + ": " + message);
         this.key = key;
     }
 

File: operator-common/src/main/java/io/strimzi/operator/common/model/OrderedProperties.java
Patch:
@@ -77,7 +77,7 @@ public OrderedProperties addIterablePairs(Iterable<? extends Map.Entry<String, ?
                 throw new InvalidConfigParameterException(key, "A null value is not allowed for this key");
             } else {
                 throw new InvalidConfigParameterException(key,
-                    " - Unsupported type " + value.getClass() + " in configuration for this key");
+                    "Unsupported type " + value.getClass() + " in configuration for this key");
             }
         }
         return this;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -91,7 +91,7 @@ void testUpgradeKafkaWithoutVersion(ExtensionContext extensionContext) throws IO
         String startInterBrokerProtocol = getValueForLastKafkaVersionInFile(startKafkaVersionsYaml, "protocol");
 
         // Modify + apply installation files
-        copyModifyApply(coDir, INFRA_NAMESPACE, extensionContext);
+        copyModifyApply(coDir, INFRA_NAMESPACE, extensionContext, "");
         // Apply Kafka Persistent without version
         LOGGER.info("Going to deploy Kafka from: {}", startKafkaPersistent.getPath());
         // Change kafka version of it's empty (null is for remove the version)

File: systemtest/src/main/java/io/strimzi/systemtest/BeforeAllOnce.java
Patch:
@@ -77,7 +77,7 @@ public void beforeAll(ExtensionContext extensionContext) throws Exception {
     }
 
     /**
-     * CloseableResource implementation, adding value into GLOBAL context is required to  registers a callback hook
+     * CloseableResource implementation, adding value into GLOBAL context is required to registers a callback hook
      * With such steps close() method will be executed only once in the end of test execution
      */
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/parallel/ParallelNamespacesSuitesNames.java
Patch:
@@ -23,8 +23,7 @@ public class ParallelNamespacesSuitesNames {
         Constants.BRIDGE_KAFKA_CORS_NAMESPACE,
         Constants.BRIDGE_KAFKA_EXTERNAL_LISTENER_NAMESPACE,
         Constants.BRIDGE_SCRAM_SHA_NAMESPACE,
-        Constants.BRIDGE_HTTP_TLS_NAMESPACE,
-        Constants.METRICS_SECOND_NAMESPACE
+        Constants.BRIDGE_HTTP_TLS_NAMESPACE
     );
 
     public static String getRbacNamespacesToWatch() {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java
Patch:
@@ -140,8 +140,8 @@ public static List<Pod> getPodsByPrefixInNameWithDynamicWait(String namespaceNam
         return result.get();
     }
 
-    public static String getFirstPodNameContaining(String searchTerm) {
-        return kubeClient().listPods().stream().filter(pod -> pod.getMetadata().getName().contains(searchTerm))
+    public static String getFirstPodNameContaining(final String namespaceName, String searchTerm) {
+        return kubeClient(namespaceName).listPods(namespaceName).stream().filter(pod -> pod.getMetadata().getName().contains(searchTerm))
                 .findFirst().orElseThrow().getMetadata().getName();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/CruiseControlUtils.java
Patch:
@@ -54,7 +54,7 @@ public enum SupportedSchemes {
     @SuppressWarnings("Regexp")
     @SuppressFBWarnings("DM_CONVERT_CASE")
     public static String callApi(String namespaceName, SupportedHttpMethods method, CruiseControlEndpoints endpoint, SupportedSchemes scheme, Boolean withCredentials) {
-        String ccPodName = PodUtils.getFirstPodNameContaining(CONTAINER_NAME);
+        String ccPodName = PodUtils.getFirstPodNameContaining(namespaceName, CONTAINER_NAME);
         String args = " -k ";
 
         if (withCredentials) {
@@ -69,7 +69,7 @@ public static String callApi(String namespaceName, SupportedHttpMethods method,
     @SuppressWarnings("Regexp")
     @SuppressFBWarnings("DM_CONVERT_CASE")
     public static String callApi(String namespaceName, SupportedHttpMethods method, String endpoint) {
-        String ccPodName = PodUtils.getFirstPodNameContaining(CONTAINER_NAME);
+        String ccPodName = PodUtils.getFirstPodNameContaining(namespaceName, CONTAINER_NAME);
 
         return cmdKubeClient(namespaceName).execInPodContainer(false, ccPodName, CONTAINER_NAME, "/bin/bash", "-c",
             "curl -X" + method.name() + " localhost:" + CRUISE_CONTROL_METRICS_PORT + endpoint).out();

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -214,7 +214,7 @@ void testKafkaConnectAndPausedConnectorWithFileSinkPlugin(ExtensionContext exten
         KafkaConnectorResource.replaceKafkaConnectorResourceInSpecificNamespace(clusterName,
             kafkaConnector -> kafkaConnector.getSpec().setPause(true), namespaceName);
 
-        KafkaConnectorUtils.waitForConnectorReady(clusterName);
+        KafkaConnectorUtils.waitForConnectorReady(namespaceName, clusterName);
 
         LOGGER.info("Clearing FileSink file to check if KafkaConnector will be really paused");
         KafkaConnectUtils.clearFileSinkFile(namespaceName, kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_PATH);
@@ -231,7 +231,7 @@ void testKafkaConnectAndPausedConnectorWithFileSinkPlugin(ExtensionContext exten
         KafkaConnectorResource.replaceKafkaConnectorResourceInSpecificNamespace(clusterName,
             kafkaConnector -> kafkaConnector.getSpec().setPause(false), namespaceName);
 
-        KafkaConnectorUtils.waitForConnectorReady(clusterName);
+        KafkaConnectorUtils.waitForConnectorReady(namespaceName, clusterName);
 
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(namespaceName, kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_PATH, "99");
     }
@@ -950,7 +950,7 @@ void testScaleConnectWithoutConnectorToZero(ExtensionContext extensionContext) {
         KafkaConnectUtils.waitForConnectReady(namespaceName, clusterName);
         PodUtils.waitForPodsReady(kubeClient(namespaceName).getDeploymentSelectors(connectDeploymentName), 0, true);
 
-        connectPods = kubeClient(namespaceName).listPodsByPrefixInName(KafkaConnectResources.deploymentName(clusterName));
+        connectPods = kubeClient(namespaceName).listPodsByPrefixInName(namespaceName, KafkaConnectResources.deploymentName(clusterName));
         KafkaConnectStatus connectStatus = KafkaConnectResource.kafkaConnectClient().inNamespace(namespaceName).withName(clusterName).get().getStatus();
 
         assertThat(connectPods.size(), is(0));

File: systemtest/src/main/java/io/strimzi/systemtest/enums/DeploymentTypes.java
Patch:
@@ -9,5 +9,6 @@ public enum DeploymentTypes {
     BundleClusterOperator,
     HelmClusterOperator,
     OlmClusterOperator,
-    KafkaClients
+    KafkaClients,
+    DrainCleaner,
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/FeatureGates.java
Patch:
@@ -20,8 +20,8 @@ public class FeatureGates {
     private static final String SERVICE_ACCOUNT_PATCHING = "ServiceAccountPatching";
 
     // When adding new feature gates, do not forget to add them to allFeatureGates() and toString() methods
-    private final FeatureGate controlPlaneListener = new FeatureGate(CONTROL_PLANE_LISTENER, false);
-    private final FeatureGate serviceAccountPatching = new FeatureGate(SERVICE_ACCOUNT_PATCHING, false);
+    private final FeatureGate controlPlaneListener = new FeatureGate(CONTROL_PLANE_LISTENER, true);
+    private final FeatureGate serviceAccountPatching = new FeatureGate(SERVICE_ACCOUNT_PATCHING, true);
 
     /**
      * Constructs the feature gates configuration.

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
Patch:
@@ -43,7 +43,7 @@ public class ClusterOperatorConfigTest {
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_OPERATOR_NAMESPACE, "operator-namespace");
-        envVars.put(ClusterOperatorConfig.STRIMZI_FEATURE_GATES, "+ControlPlaneListener");
+        envVars.put(ClusterOperatorConfig.STRIMZI_FEATURE_GATES, "-ControlPlaneListener");
     }
 
     @Test
@@ -62,7 +62,7 @@ public void testDefaultConfig() {
         assertThat(config.getConnectBuildTimeoutMs(), is(ClusterOperatorConfig.DEFAULT_CONNECT_BUILD_TIMEOUT_MS));
         assertThat(config.getOperatorNamespace(), is("operator-namespace"));
         assertThat(config.getOperatorNamespaceLabels(), is(nullValue()));
-        assertThat(config.featureGates().controlPlaneListenerEnabled(), is(false));
+        assertThat(config.featureGates().controlPlaneListenerEnabled(), is(true));
     }
 
     @Test
@@ -101,7 +101,7 @@ public void testEnvVars() {
         assertThat(config.getOperationTimeoutMs(), is(30_000L));
         assertThat(config.getConnectBuildTimeoutMs(), is(40_000L));
         assertThat(config.getOperatorNamespace(), is("operator-namespace"));
-        assertThat(config.featureGates().controlPlaneListenerEnabled(), is(true));
+        assertThat(config.featureGates().controlPlaneListenerEnabled(), is(false));
     }
 
     @Test

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -11,6 +11,7 @@
 import io.fabric8.kubernetes.api.model.Pod;
 import io.fabric8.kubernetes.api.model.PodCondition;
 import io.fabric8.kubernetes.api.model.apiextensions.v1.CustomResourceDefinition;
+import io.fabric8.kubernetes.api.model.rbac.ClusterRole;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.client.CustomResourceList;
@@ -199,7 +200,7 @@ public final <T extends HasMetadata> boolean waitResourceCondition(T resource, R
         assertNotNull(resource.getMetadata().getName());
 
         // cluster role binding and custom resource definition does not need namespace...
-        if (!(resource instanceof ClusterRoleBinding || resource instanceof CustomResourceDefinition)) {
+        if (!(resource instanceof ClusterRoleBinding || resource instanceof CustomResourceDefinition || resource instanceof ClusterRole)) {
             assertNotNull(resource.getMetadata().getNamespace());
         }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/kafkaclients/KafkaBasicExampleClients.java
Patch:
@@ -118,6 +118,7 @@ protected KafkaBasicExampleClients(Builder builder) {
             builder.consumerGroup = ClientUtils.generateRandomConsumerGroup();
         }
         if (builder.message == null || builder.message.isEmpty()) builder.message = "Hello-world";
+        if (builder.additionalConfig == null || builder.additionalConfig.isEmpty()) builder.additionalConfig = "";
 
         producerName = builder.producerName;
         consumerName = builder.consumerName;
@@ -209,7 +210,7 @@ public JobBuilder producerScramShaStrimzi(final String clusterName, final String
                 "security.protocol=" + SecurityProtocol.SASL_SSL + "\n" +
                 "sasl.jaas.config=" + saslJaasConfigDecrypted;
 
-        return defaultConsumerStrimzi()
+        return defaultProducerStrimzi()
             .editSpec()
                 .editTemplate()
                     .editSpec()
@@ -248,7 +249,7 @@ public JobBuilder producerTlsStrimzi(final String clusterName, final String kafk
             .endValueFrom()
             .build();
 
-        return defaultConsumerStrimzi()
+        return defaultProducerStrimzi()
             .editSpec()
                 .editTemplate()
                     .editSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -241,5 +241,4 @@ private void testWeirdUsername(ExtensionContext extensionContext, String weirdUs
 
         ClientUtils.waitForClientSuccess(clusterName + "-" + consumerName, NAMESPACE, MESSAGE_COUNT);
     }
-
 }

File: systemtest/src/main/java/io/strimzi/systemtest/annotations/ParallelTest.java
Patch:
@@ -24,8 +24,7 @@
 @Target(ElementType.METHOD)
 @Retention(RUNTIME)
 @Execution(ExecutionMode.CONCURRENT)
-@ResourceLock(mode = ResourceAccessMode.READ, value = "global")
+@ResourceLock(mode = ResourceAccessMode.READ, value = "parallel-test")
 @Test
 public @interface ParallelTest {
 }
-

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/RoleResource.java
Patch:
@@ -36,7 +36,7 @@ public void delete(Role resource) {
     }
     @Override
     public boolean waitForReadiness(Role resource) {
-        return resource != null;
+        return resource != null && get(resource.getMetadata().getNamespace(), resource.getMetadata().getName()) != null;
     }
 
     public static void role(ExtensionContext extensionContext, String yamlPath, String namespace) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/specific/HelmResource.java
Patch:
@@ -94,7 +94,7 @@ private void clusterOperator(long operationTimeout, long reconciliationInterval)
         // We need to remove CO namespace to avoid creation of roles and rolebindings multiple times in one namespace
         // Roles will be created in installTo namespace even if it's not specified in watchNamespaces
         if (!this.namespaceToWatch.equals("*") && !this.namespaceToWatch.equals(this.namespaceInstallTo)) {
-            values.put("watchNamespaces", "{" + this.namespaceToWatch.replaceAll(",*" + namespaceInstallTo + ",*", "") + "}");
+            values.put("watchNamespaces", namespaceToWatch);
         }
 
         Path pathToChart = new File(HELM_CHART).toPath();

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/specific/OlmResource.java
Patch:
@@ -7,7 +7,6 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.enums.OlmInstallationStrategy;
-import io.strimzi.systemtest.resources.ResourceItem;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.specific.OlmUtils;
@@ -57,7 +56,6 @@ public void create(ExtensionContext extensionContext) {
 
     public void create(ExtensionContext extensionContext, long operationTimeout, long reconciliationInterval) {
         ResourceManager.STORED_RESOURCES.computeIfAbsent(extensionContext.getDisplayName(), k -> new Stack<>());
-        ResourceManager.STORED_RESOURCES.get(extensionContext.getDisplayName()).push(new ResourceItem(this::delete));
         this.clusterOperator(this.namespace, operationTimeout, reconciliationInterval);
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaTemplates.java
Patch:
@@ -175,6 +175,7 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl
         return new KafkaBuilder(kafka)
             .withNewMetadata()
                 .withName(name)
+                .withClusterName(name)
                 .withNamespace(kubeClient().getNamespace())
             .endMetadata()
             .editSpec()

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/TracingUtils.java
Patch:
@@ -6,12 +6,12 @@
 
 import io.strimzi.systemtest.Constants;
 import io.strimzi.test.TestUtils;
+import io.strimzi.test.k8s.KubeClusterResource;
 import io.vertx.core.json.JsonArray;
 import io.vertx.core.json.JsonObject;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
-import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 
 
@@ -105,7 +105,7 @@ private static void verifyThatServiceTracesArePresent(String namespaceName, Stri
     }
 
     public static String getValidTracingVersion() {
-        if (Double.parseDouble(kubeClient().clusterKubernetesVersion()) >= 1.22) {
+        if (Double.parseDouble(KubeClusterResource.getInstance().client().clusterKubernetesVersion()) >= 1.22) {
             return LATEST_TRACING_VERSION;
         } else {
             return OLD_TRACING_VERSION;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/AbstractUpgradeST.java
Patch:
@@ -25,6 +25,7 @@
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import io.strimzi.test.TestUtils;
+import io.strimzi.test.annotations.IsolatedSuite;
 import io.strimzi.test.executor.Exec;
 import io.strimzi.test.executor.ExecResult;
 import io.vertx.core.json.JsonArray;
@@ -58,6 +59,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.junit.jupiter.api.Assertions.fail;
 
+@IsolatedSuite
 public class AbstractUpgradeST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(AbstractUpgradeST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java
Patch:
@@ -16,6 +16,7 @@
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import io.strimzi.systemtest.utils.specific.OlmUtils;
+import io.strimzi.test.annotations.IsolatedSuite;
 import io.strimzi.test.k8s.KubeClusterResource;
 import io.vertx.core.json.JsonArray;
 import io.vertx.core.json.JsonObject;
@@ -42,6 +43,7 @@
  * Tests in this class use OLM for install cluster operator.
  */
 @Tag(OLM_UPGRADE)
+@IsolatedSuite
 public class OlmUpgradeST extends AbstractUpgradeST {
 
     private static final Logger LOGGER = LogManager.getLogger(OlmUpgradeST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java
Patch:
@@ -18,6 +18,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils;
 import io.strimzi.test.TestUtils;
+import io.strimzi.test.annotations.IsolatedSuite;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.extension.ExtensionContext;
@@ -30,6 +31,7 @@
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 
+@IsolatedSuite
 public abstract class AbstractNamespaceST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(AbstractNamespaceST.class);

File: test/src/main/java/io/strimzi/test/k8s/KubeClusterResource.java
Patch:
@@ -311,7 +311,9 @@ public void deleteCustomResources(String... resources) {
     }
 
     public void deleteCustomResources(ExtensionContext extensionContext, String... resources) {
-        final String namespaceName = !extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get("NAMESPACE_NAME").toString().isEmpty() ?
+        final String namespaceName =
+            extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get("NAMESPACE_NAME") != null &&
+            !extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get("NAMESPACE_NAME").toString().isEmpty() ?
             extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get("NAMESPACE_NAME").toString() :
             getNamespace();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperScaler.java
Patch:
@@ -284,6 +284,7 @@ private Future<ZKClientConfig> getClientConfig()  {
 
                 clientConfig.setProperty("zookeeper.clientCnxnSocket", "org.apache.zookeeper.ClientCnxnSocketNetty");
                 clientConfig.setProperty("zookeeper.client.secure", "true");
+                clientConfig.setProperty("zookeeper.sasl.client", "false");
                 clientConfig.setProperty("zookeeper.ssl.trustStore.location", trustStoreFile.getAbsolutePath());
                 clientConfig.setProperty("zookeeper.ssl.trustStore.password", trustStorePassword);
                 clientConfig.setProperty("zookeeper.ssl.trustStore.type", "PKCS12");

File: systemtest/src/test/java/io/strimzi/systemtest/security/OpaIntegrationST.java
Patch:
@@ -24,7 +24,6 @@
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
@@ -39,7 +38,6 @@
 
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
-@Disabled("Issue with OPA -> users in allowedList or superusers are not able to producer/consume messages")
 public class OpaIntegrationST extends AbstractST {
     public static final String NAMESPACE = "opa-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(OpaIntegrationST.class);

File: user-operator/src/main/java/io/strimzi/operator/user/operator/QuotasOperator.java
Patch:
@@ -9,6 +9,7 @@
 import io.strimzi.operator.common.ReconciliationLogger;
 import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.operator.resource.ReconcileResult;
+import io.strimzi.operator.user.model.KafkaUserModel;
 import io.strimzi.operator.user.model.QuotaUtils;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
@@ -153,7 +154,8 @@ public Future<Set<String>> getAllUsers() {
 
                     for (ClientQuotaEntity entity : quotas.keySet()) {
                         if (entity.entries().containsKey(ClientQuotaEntity.USER)) {
-                            users.add(entity.entries().get(ClientQuotaEntity.USER));
+                            String username = KafkaUserModel.decodeUsername(entity.entries().get(ClientQuotaEntity.USER));
+                            users.add(username);
                         }
                     }
 

File: user-operator/src/test/java/io/strimzi/operator/user/operator/QuotasOperatorIT.java
Patch:
@@ -52,8 +52,8 @@ KafkaUserQuotas getModified() {
     }
 
     @Override
-    KafkaUserQuotas get() {
-        ClientQuotaFilterComponent c = ClientQuotaFilterComponent.ofEntity(ClientQuotaEntity.USER, USERNAME);
+    KafkaUserQuotas get(String username) {
+        ClientQuotaFilterComponent c = ClientQuotaFilterComponent.ofEntity(ClientQuotaEntity.USER, username);
         ClientQuotaFilter f =  ClientQuotaFilter.contains(List.of(c));
 
         Map<ClientQuotaEntity, Map<String, Double>> quotas;
@@ -63,7 +63,7 @@ KafkaUserQuotas get() {
             throw new RuntimeException("Failed to get quotas", e);
         }
 
-        ClientQuotaEntity cqe = new ClientQuotaEntity(Map.of(ClientQuotaEntity.USER, USERNAME));
+        ClientQuotaEntity cqe = new ClientQuotaEntity(Map.of(ClientQuotaEntity.USER, username));
 
         if (quotas.containsKey(cqe)) {
             return QuotaUtils.fromClientQuota(quotas.get(cqe));

File: user-operator/src/test/java/io/strimzi/operator/user/operator/SimpleAclOperatorIT.java
Patch:
@@ -92,8 +92,8 @@ Set<SimpleAclRule> getModified() {
     }
 
     @Override
-    Set<SimpleAclRule> get() {
-        KafkaPrincipal principal = new KafkaPrincipal("User", USERNAME);
+    Set<SimpleAclRule> get(String username) {
+        KafkaPrincipal principal = new KafkaPrincipal("User", username);
         AclBindingFilter aclBindingFilter = new AclBindingFilter(ResourcePatternFilter.ANY,
                 new AccessControlEntryFilter(principal.toString(), null, org.apache.kafka.common.acl.AclOperation.ANY, AclPermissionType.ANY));
 

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -47,7 +47,6 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
@@ -786,7 +785,6 @@ void testScaleMirrorMaker2ToZero(ExtensionContext extensionContext) {
     }
 
     @ParallelNamespaceTest
-    @Disabled("Disabled because of issue with IdentityReplicationPolicy -> messages are not mirrored from source to target cluster")
     void testIdentityReplicationPolicy(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationST.java
Patch:
@@ -55,7 +55,6 @@
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
-@Disabled("Due to fatal exception when deploying Kafka. Should be enabled after new version of Strimzi OAuth will be released")
 public class OauthAuthorizationST extends OauthAbstractST {
     protected static final Logger LOGGER = LogManager.getLogger(OauthAuthorizationST.class);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -24,6 +24,7 @@
 import io.strimzi.operator.cluster.model.KafkaBridgeCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
@@ -156,7 +157,7 @@ public void testCreateOrUpdateCreatesCluster(VertxTestContext context) {
                 assertThat(capturedDc, hasSize(1));
                 Deployment dc = capturedDc.get(0);
                 assertThat(dc.getMetadata().getName(), is(bridge.getName()));
-                assertThat(dc, is(bridge.generateDeployment(Collections.emptyMap(), true, null, null)));
+                assertThat(dc, is(bridge.generateDeployment(Collections.singletonMap(Annotations.ANNO_STRIMZI_AUTH_HASH, "0"), true, null, null)));
 
                 // Verify PodDisruptionBudget
                 List<PodDisruptionBudget> capturedPdb = pdbCaptor.getAllValues();
@@ -344,7 +345,7 @@ public void testCreateOrUpdateUpdatesCluster(VertxTestContext context) {
                 assertThat(capturedDc, hasSize(1));
                 Deployment dc = capturedDc.get(0);
                 assertThat(dc.getMetadata().getName(), is(compareTo.getName()));
-                assertThat(dc, is(compareTo.generateDeployment(Collections.emptyMap(), true, null, null)));
+                assertThat(dc, is(compareTo.generateDeployment(Collections.singletonMap(Annotations.ANNO_STRIMZI_AUTH_HASH, "0"), true, null, null)));
 
                 // Verify PodDisruptionBudget
                 List<PodDisruptionBudget> capturedPdb = pdbCaptor.getAllValues();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -161,6 +161,7 @@ public void testCreateCluster(VertxTestContext context) {
                 assertThat(dc.getMetadata().getName(), is(mirror.getName()));
                 Map annotations = new HashMap();
                 annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, LOGGING_CONFIG);
+                annotations.put(Annotations.ANNO_STRIMZI_AUTH_HASH, "0");
                 assertThat("Deployments are not equal", dc, is(mirror.generateDeployment(annotations, true, null, null)));
 
                 // Verify PodDisruptionBudget
@@ -354,6 +355,7 @@ public void testUpdateCluster(VertxTestContext context) {
                 assertThat(dc.getMetadata().getName(), is(compareTo.getName()));
                 Map<String, String> annotations = new HashMap();
                 annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, loggingCm.getData().get(compareTo.ANCILLARY_CM_KEY_LOG_CONFIG));
+                annotations.put(Annotations.ANNO_STRIMZI_AUTH_HASH, "0");
                 assertThat("Deployments are not equal", dc, is(compareTo.generateDeployment(annotations, true, null, null)));
 
                 // Verify PodDisruptionBudget

File: operator-common/src/main/java/io/strimzi/operator/common/Annotations.java
Patch:
@@ -29,6 +29,8 @@ public class Annotations {
     public static final String ANNO_STRIMZI_LOGGING_HASH = STRIMZI_DOMAIN + "logging-hash";
     public static final String ANNO_STRIMZI_LOGGING_APPENDERS_HASH = STRIMZI_DOMAIN + "logging-appenders-hash";
     public static final String ANNO_STRIMZI_LOGGING_DYNAMICALLY_UNCHANGEABLE_HASH = STRIMZI_DOMAIN + "logging-appenders-hash";
+    public static final String ANNO_STRIMZI_AUTH_HASH = STRIMZI_DOMAIN + "auth-hash";
+
 
     public static final String STRIMZI_IO_USE_CONNECTOR_RESOURCES = STRIMZI_DOMAIN + "use-connector-resources";
     // Used to store the revision of the Kafka Connect build (hash of the Dockerfile)

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -190,8 +190,6 @@ private void testWeirdUsername(ExtensionContext extensionContext, String weirdUs
 
     @BeforeAll
     void createClassResources(ExtensionContext extensionContext) {
-        LOGGER.debug("===============================================================");
-        LOGGER.debug("{} - [BEFORE ALL] has been called", this.getClass().getName());
         install = new SetupClusterOperator.SetupClusterOperatorBuilder()
             .withExtensionContext(extensionContext)
             .withNamespace(NAMESPACE)

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ReconciliationST.java
Patch:
@@ -146,10 +146,10 @@ void testPauseReconciliationInKafkaRebalanceAndTopic(ExtensionContext extensionC
         resourceManager.createResource(extensionContext, KafkaTopicTemplates.topic(clusterName, topicName).build());
 
         LOGGER.info("Adding pause annotation into KafkaTopic resource and changing replication factor");
-        KafkaTopicResource.replaceTopicResource(topicName, topic -> {
+        KafkaTopicResource.replaceTopicResourceInSpecificNamespace(topicName, topic -> {
             topic.getMetadata().setAnnotations(PAUSE_ANNO);
             topic.getSpec().setPartitions(SCALE_TO);
-        });
+        }, namespaceName);
 
         KafkaTopicUtils.waitForKafkaTopicStatus(namespaceName, topicName, CustomResourceStatus.ReconciliationPaused);
         KafkaTopicUtils.waitForKafkaTopicSpecStability(topicName, KafkaResources.kafkaPodName(clusterName, 0), KafkaResources.plainBootstrapAddress(clusterName));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlApiImpl.java
Patch:
@@ -23,6 +23,7 @@
 import java.io.File;
 import java.net.ConnectException;
 import java.nio.charset.StandardCharsets;
+import java.util.Set;
 import java.util.concurrent.TimeoutException;
 
 import static io.strimzi.operator.cluster.model.CruiseControl.encodeToBase64;
@@ -46,7 +47,7 @@ public CruiseControlApiImpl(Vertx vertx, int idleTimeout, Secret ccSecret, Secre
         this.apiSslEnabled = apiSslEnabled;
         this.authHttpHeader = getAuthHttpHeader(apiAuthEnabled, ccApiSecret);
         this.trustStorePassword = new PasswordGenerator(12).generate();
-        this.truststoreFile = Util.createFileTrustStore(getClass().getName(), "ts", Ca.cert(ccSecret, "cruise-control.crt"), trustStorePassword.toCharArray());
+        this.truststoreFile = Util.createFileTrustStore(getClass().getName(), "ts", Set.of(Ca.cert(ccSecret, "cruise-control.crt")), trustStorePassword.toCharArray());
     }
 
     @Override

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperScaler.java
Patch:
@@ -279,7 +279,7 @@ private Future<ZKClientConfig> getClientConfig()  {
             try {
                 ZKClientConfig clientConfig = new ZKClientConfig();
 
-                trustStoreFile = Util.createFileTrustStore(getClass().getName(), "p12", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());
+                trustStoreFile = Util.createFileTrustStore(getClass().getName(), "p12", Ca.certs(clusterCaCertSecret), trustStorePassword.toCharArray());
                 keyStoreFile = Util.createFileStore(getClass().getName(), "p12", Util.decodeFromSecret(coKeySecret, "cluster-operator.p12"));
 
                 clientConfig.setProperty("zookeeper.clientCnxnSocket", "org.apache.zookeeper.ClientCnxnSocketNetty");

File: operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java
Patch:
@@ -50,7 +50,7 @@ public Admin createAdminClient(String bootstrapHostnames, Secret clusterCaCertSe
         if (clusterCaCertSecret != null) {
             PasswordGenerator pg = new PasswordGenerator(12);
             trustStorePassword = pg.generate();
-            truststoreFile = Util.createFileTrustStore(getClass().getName(), "ts", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());
+            truststoreFile = Util.createFileTrustStore(getClass().getName(), "ts", Ca.certs(clusterCaCertSecret), trustStorePassword.toCharArray());
         }
 
         try {

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -7,6 +7,7 @@
 import com.fasterxml.jackson.databind.JsonNode;
 import com.fasterxml.jackson.databind.ObjectMapper;
 import io.strimzi.systemtest.enums.ClusterOperatorInstallType;
+import io.strimzi.systemtest.utils.TestKafkaVersion;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.k8s.cluster.OpenShift;
 import org.apache.logging.log4j.LogManager;
@@ -133,7 +134,7 @@ public class Environment {
     /**
      * Defaults
      */
-    private static final String ST_KAFKA_VERSION_DEFAULT = "2.8.0";
+    private static final String ST_KAFKA_VERSION_DEFAULT = TestKafkaVersion.getDefaultSupportedKafkaVersion();
     public static final String STRIMZI_ORG_DEFAULT = "strimzi";
     public static final String STRIMZI_TAG_DEFAULT = "latest";
     public static final String STRIMZI_REGISTRY_DEFAULT = "quay.io";

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -47,6 +47,7 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
@@ -785,6 +786,7 @@ void testScaleMirrorMaker2ToZero(ExtensionContext extensionContext) {
     }
 
     @ParallelNamespaceTest
+    @Disabled("Disabled because of issue with IdentityReplicationPolicy -> messages are not mirrored from source to target cluster")
     void testIdentityReplicationPolicy(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());

File: systemtest/src/test/java/io/strimzi/systemtest/security/OpaIntegrationST.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
@@ -38,6 +39,7 @@
 
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
+@Disabled("Issue with OPA -> users in allowedList or superusers are not able to producer/consume messages")
 public class OpaIntegrationST extends AbstractST {
     public static final String NAMESPACE = "opa-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(OpaIntegrationST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationST.java
Patch:
@@ -55,6 +55,7 @@
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
+@Disabled("Due to fatal exception when deploying Kafka. Should be enabled after new version of Strimzi OAuth will be released")
 public class OauthAuthorizationST extends OauthAbstractST {
     protected static final Logger LOGGER = LogManager.getLogger(OauthAuthorizationST.class);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -79,7 +79,6 @@ public String toString() {
         return "cluster-ca";
     }
 
-    @SuppressWarnings("deprecation")
     public void initCaSecrets(List<Secret> secrets) {
         for (Secret secret: secrets) {
             String name = secret.getMetadata().getName();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -715,7 +715,7 @@ public void checkCustomCaSecret(CertificateAuthority ca, Secret certSecret, Secr
          * It is not necessary when the CA certificate is replace while retaining the existing key.
          */
         Future<ReconciliationState> rollingUpdateForNewCaKey() {
-            List<String> reason = new ArrayList<>(4);
+            List<String> reason = new ArrayList<>(2);
             if (this.clusterCa.keyReplaced()) {
                 reason.add("trust new cluster CA certificate signed by new key");
             }

File: api/src/main/java/io/strimzi/api/kafka/model/CruiseControlSpec.java
Patch:
@@ -35,8 +35,8 @@ public class CruiseControlSpec implements HasConfigurableMetrics, UnknownPropert
         + "webserver.http., webserver.api.urlprefix, webserver.session.path, webserver.accesslog., two.step., request.reason.required,"
         + "metric.reporter.sampler.bootstrap.servers, metric.reporter.topic, partition.metric.sample.store.topic, broker.metric.sample.store.topic,"
         + "capacity.config.file, self.healing., ssl.";
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols, webserver.http.cors.enabled," +
-            "webserver.http.cors.origin, webserver.http.cors.exposeheaders";
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols, webserver.http.cors.enabled, "
+        + "webserver.http.cors.origin, webserver.http.cors.exposeheaders, webserver.security.enable, webserver.ssl.enable";
 
     private String image;
     private TlsSidecar tlsSidecar;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -705,6 +705,7 @@ public static ResourceOperatorSupplier supplierWithMocks(boolean openShift) {
                 metricsProvider(),
                 adminClientProvider());
 
+        when(supplier.secretOperations.getAsync(any(), any())).thenReturn(Future.succeededFuture());
         when(supplier.serviceAccountOperations.reconcile(any(), anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.roleBindingOperations.reconcile(any(), anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.roleOperations.reconcile(any(), anyString(), anyString(), any())).thenReturn(Future.succeededFuture());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceStateMachineTest.java
Patch:
@@ -47,6 +47,7 @@
 import java.util.Collections;
 import java.util.List;
 
+import static io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlApiImpl.HTTP_DEFAULT_IDLE_TIMEOUT_SECONDS;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.junit.jupiter.api.Assertions.assertEquals;
 import static org.mockito.Mockito.when;
@@ -58,7 +59,6 @@ public class KafkaRebalanceStateMachineTest {
     private static final String RESOURCE_NAME = "my-rebalance";
     private static final String CLUSTER_NAMESPACE = "cruise-control-namespace";
     private static final String CLUSTER_NAME = "kafka-cruise-control-test-cluster";
-
     private final KubernetesVersion kubernetesVersion = KubernetesVersion.V1_18;
 
     private static ClientAndServer ccServer;
@@ -134,7 +134,7 @@ private Future<KafkaRebalanceStatus> checkTransition(Vertx vertx, VertxTestConte
                                                          KafkaRebalanceAnnotation initialAnnotation,
                                                          KafkaRebalance kcRebalance) {
 
-        CruiseControlApi client = new CruiseControlApiImpl(vertx);
+        CruiseControlApi client = new CruiseControlApiImpl(vertx, HTTP_DEFAULT_IDLE_TIMEOUT_SECONDS, MockCruiseControl.CC_SECRET, MockCruiseControl.CC_API_SECRET, true, true);
         ResourceOperatorSupplier supplier = ResourceUtils.supplierWithMocks(true);
         ConfigMapOperator mockCmOps = supplier.configMapOperations;
         PlatformFeaturesAvailability pfa = new PlatformFeaturesAvailability(true, kubernetesVersion);

File: operator-common/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlConfigurationParameters.java
Patch:
@@ -19,6 +19,9 @@ public enum CruiseControlConfigurationParameters {
     CRUISE_CONTROL_BROKER_METRICS_WINDOW_MS_CONFIG_KEY("broker.metrics.window.ms"),
     CRUISE_CONTROL_BROKER_METRICS_WINDOW_NUM_CONFIG_KEY("num.broker.metrics.windows"),
     CRUISE_CONTROL_COMPLETED_USER_TASK_RETENTION_MS_CONFIG_KEY("completed.user.task.retention.time.ms"),
+    CRUISE_CONTROL_WEBSERVER_SECURITY_ENABLE("webserver.security.enable"),
+    CRUISE_CONTROL_WEBSERVER_AUTH_CREDENTIALS_FILE("webserver.auth.credentials.file"),
+    CRUISE_CONTROL_WEBSERVER_SSL_ENABLE("webserver.ssl.enable"),
 
     // Metrics reporter configurations
     METRICS_REPORTER_BOOTSTRAP_SERVERS("cruise.control.metrics.reporter.bootstrap.servers"),

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker.java
Patch:
@@ -14,6 +14,7 @@
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.model.annotation.Group;
 import io.fabric8.kubernetes.model.annotation.Version;
+import io.strimzi.api.annotations.DeprecatedType;
 import io.strimzi.api.kafka.model.status.KafkaMirrorMakerStatus;
 import io.strimzi.crdgenerator.annotations.Crd;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -94,8 +95,9 @@
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
 @Group(Constants.STRIMZI_GROUP)
+@Deprecated
+@DeprecatedType(replacedWithType = io.strimzi.api.kafka.model.KafkaMirrorMaker2.class)
 public class KafkaMirrorMaker extends CustomResource<KafkaMirrorMakerSpec, KafkaMirrorMakerStatus> implements Namespaced, UnknownPropertyPreserving {
-
     private static final long serialVersionUID = 1L;
 
     public static final String SCOPE = "Namespaced";

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -41,6 +41,8 @@
  *     <li>A Kafka Mirror Maker Deployment and related Services</li>
  * </ul>
  */
+// Deprecation is suppressed because of KafkaMirrorMaker
+@SuppressWarnings("deprecation")
 public class KafkaMirrorMakerAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList, Resource<KafkaMirrorMaker>, KafkaMirrorMakerSpec, KafkaMirrorMakerStatus> {
 
     private static final ReconciliationLogger LOGGER = ReconciliationLogger.create(KafkaMirrorMakerAssemblyOperator.class.getName());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ResourceOperatorSupplier.java
Patch:
@@ -50,7 +50,8 @@
 import io.strimzi.operator.common.operator.resource.StorageClassOperator;
 import io.vertx.core.Vertx;
 
-@SuppressWarnings({"checkstyle:ClassDataAbstractionCoupling"})
+// Deprecation is suppressed because of KafkaMirrorMaker
+@SuppressWarnings({"checkstyle:ClassDataAbstractionCoupling", "deprecation"})
 public class ResourceOperatorSupplier {
     public final SecretOperator secretOperations;
     public final ServiceOperator serviceOperations;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -16,6 +16,8 @@
 
 import java.util.function.Consumer;
 
+// Deprecation is suppressed because of KafkaMirrorMaker
+@SuppressWarnings("deprecation")
 public class KafkaMirrorMakerResource implements ResourceType<KafkaMirrorMaker> {
 
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaMirrorMakerTemplates.java
Patch:
@@ -19,6 +19,8 @@
 import org.apache.kafka.clients.consumer.ConsumerConfig;
 import org.apache.kafka.clients.producer.ProducerConfig;
 
+// Deprecation is suppressed because of KafkaMirrorMaker
+@SuppressWarnings("deprecation")
 public class KafkaMirrorMakerTemplates {
 
     private KafkaMirrorMakerTemplates() {}

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaMirrorMakerUtils.java
Patch:
@@ -22,6 +22,8 @@ private KafkaMirrorMakerUtils() {}
      * @param clusterName name of KafkaMirrorMaker cluster
      * @param state desired state - like Ready
      */
+    // Deprecation is suppressed because of KafkaMirrorMaker
+    @SuppressWarnings("deprecation")
     public static boolean waitForKafkaMirrorMakerStatus(String namespaceName, String clusterName, Enum<?>  state) {
         KafkaMirrorMaker kafkaMirrorMaker = KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(namespaceName).withName(clusterName).get();
         return ResourceManager.waitForResourceStatus(KafkaMirrorMakerResource.kafkaMirrorMakerClient(), kafkaMirrorMaker, state);

File: api/src/main/java/io/strimzi/api/kafka/model/listener/arraylistener/GenericKafkaListenerConfiguration.java
Patch:
@@ -188,8 +188,7 @@ public void setMaxConnections(Integer maxConnections) {
     }
 
     @Description("The maximum connection creation rate we allow in this listener at any time. " +
-            "New connections will be throttled if the limit is reached." +
-            "Supported only on Kafka 2.7.0 and newer.")
+            "New connections will be throttled if the limit is reached.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     public Integer getMaxConnectionCreationRate() {
         return maxConnectionCreationRate;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiff.java
Patch:
@@ -87,7 +87,7 @@ public boolean canBeUpdatedDynamically() {
         for (AlterConfigOp entry : diff) {
             if (isEntryReadOnly(entry.configEntry())) {
                 result = false;
-                LOGGER.debugCr(reconciliation, "Configuration can't be updated dynamically due to: {}", entry);
+                LOGGER.infoCr(reconciliation, "Configuration can't be updated dynamically due to: {}", entry);
                 break;
             }
         }
@@ -221,7 +221,7 @@ private void removeProperty(Map<String, ConfigModel> configModel, Collection<Alt
             // if the entry was custom, it should be deleted
             if (!isIgnorableProperty(pathValueWithoutSlash)) {
                 updatedCE.add(new AlterConfigOp(new ConfigEntry(pathValueWithoutSlash, null), AlterConfigOp.OpType.DELETE));
-                LOGGER.traceCr(reconciliation, "{} not set in desired, unsetting back to default {}", entry.name(), "deleted entry");
+                LOGGER.infoCr(reconciliation, "{} not set in desired, unsetting back to default {}", entry.name(), "deleted entry");
             } else {
                 LOGGER.traceCr(reconciliation, "{} is ignorable, not considering as removed");
             }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConfigurationTests.java
Patch:
@@ -87,7 +87,7 @@ public void passwordType() {
     @ParallelTest
     public void invalidVersion() {
         assertConfigError("inter.broker.protocol.version", "dclncswn",
-                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E|\\Q2.5\\E(\\.[0-9]+)*|\\Q2.5-IV0\\E|\\Q2.6\\E(\\.[0-9]+)*|\\Q2.6-IV0\\E|\\Q2.7\\E(\\.[0-9]+)*|\\Q2.7-IV0\\E|\\Q2.7-IV1\\E|\\Q2.7-IV2\\E|\\Q2.8\\E(\\.[0-9]+)*|\\Q2.8-IV0\\E|\\Q2.8-IV1\\E");
+                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E|\\Q2.5\\E(\\.[0-9]+)*|\\Q2.5-IV0\\E|\\Q2.6\\E(\\.[0-9]+)*|\\Q2.6-IV0\\E|\\Q2.7\\E(\\.[0-9]+)*|\\Q2.7-IV0\\E|\\Q2.7-IV1\\E|\\Q2.7-IV2\\E|\\Q2.8\\E(\\.[0-9]+)*|\\Q2.8-IV0\\E|\\Q2.8-IV1\\E|\\Q3.0\\E(\\.[0-9]+)*|\\Q3.0-IV0\\E|\\Q3.0-IV1\\E");
     }
 
     @ParallelTest

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectApiTest.java
Patch:
@@ -104,6 +104,7 @@ public static void before() throws IOException {
 
     @AfterAll
     public static void after() {
+        cluster.stop();
         vertx.close();
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -73,6 +73,7 @@ public static void before() throws IOException {
 
     @AfterAll
     public static void after() {
+        cluster.stop();
         vertx.close();
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerLoggingConfigurationDiffTest.java
Patch:
@@ -43,7 +43,7 @@ private Config getCurrentConfiguration(List<ConfigEntry> additional) {
         configList.forEach(entry -> {
             String[] split = entry.split("=");
             String val = split.length == 1 ? "" : split[1];
-            ConfigEntry ce = new ConfigEntry(split[0].replace("\n", ""), val, true, true, false);
+            ConfigEntry ce = new ConfigEntry(split[0].replace("\n", ""), val);
             entryList.add(ce);
         });
         entryList.addAll(additional);

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -77,13 +77,13 @@ void testMoreReplicasThanAvailableBrokers(ExtensionContext extensionContext) {
         assertThat("Topic exists in Kafka CR (Kubernetes)", hasTopicInCRK8s(kafkaTopic, topicName));
         assertThat("Topic doesn't exists in Kafka itself", !hasTopicInKafka(topicName, TOPIC_CLUSTER_NAME));
 
-        String errorMessage = "Replication factor: 5 larger than available brokers: 3";
+        String errorMessage = "org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 5 larger than available brokers: 3";
 
         KafkaTopicUtils.waitForKafkaTopicNotReady(topicName);
         KafkaTopicStatus kafkaTopicStatus = KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(topicName).get().getStatus();
 
         assertThat(kafkaTopicStatus.getConditions().get(0).getMessage(), containsString(errorMessage));
-        assertThat(kafkaTopicStatus.getConditions().get(0).getReason(), containsString("InvalidReplicationFactorException"));
+        assertThat(kafkaTopicStatus.getConditions().get(0).getReason(), containsString("CompletionException"));
 
         LOGGER.info("Delete topic {}", topicName);
         cmdKubeClient().deleteByName("kafkatopic", topicName);

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/KafkaUpgradeDowngradeST.java
Patch:
@@ -319,7 +319,6 @@ void runVersionChange(TestKafkaVersion initialVersion, TestKafkaVersion newVersi
             } else {
                 LOGGER.info("ClusterOperator already changed the configuration, there should be no RollingUpdate");
                 PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(clusterName));
-                LOGGER.info("test");
                 assertFalse(StatefulSetUtils.ssHasRolled(KafkaResources.kafkaStatefulSetName(clusterName), kafkaPods));
             }
         }

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -267,7 +267,7 @@ private void performUpgrade(JsonObject testParameters, ExtensionContext extensio
         logPodImages(clusterName);
         changeClusterOperator(testParameters, NAMESPACE, extensionContext);
 
-        if (TestKafkaVersion.containsVersion(getDefaultKafkaVersionPerStrimzi(testParameters.getString("fromVersion")).version())) {
+        if (TestKafkaVersion.supportedVersionsContainsVersion(getDefaultKafkaVersionPerStrimzi(testParameters.getString("fromVersion")).version())) {
             waitForKafkaClusterRollingUpdate();
         }
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/KafkaImpl.java
Patch:
@@ -56,7 +56,7 @@ public Future<Void> deleteTopic(Reconciliation reconciliation, TopicName topicNa
         Promise<Void> handler = Promise.promise();
         LOGGER.debugCr(reconciliation, "Deleting topic {}", topicName);
         KafkaFuture<Void> future = adminClient.deleteTopics(
-                singleton(topicName.toString())).values().get(topicName.toString());
+                singleton(topicName.toString())).topicNameValues().get(topicName.toString());
         mapFuture(future).onComplete(ar -> {
             // Complete the result future on the context thread.
             vertx.runOnContext(ignored -> {

File: topic-operator/src/test/java/io/strimzi/operator/topic/KafkaImplTest.java
Patch:
@@ -151,7 +151,7 @@ private void mockDescribeTopics(Admin admin, Map<String, Either<TopicDescription
 
     private void mockDeleteTopics(Admin admin, Map<String, Either<Void, Exception>> result) {
         DeleteTopicsResult deleteTopicsResult = mock(DeleteTopicsResult.class);
-        when(deleteTopicsResult.values()).thenReturn(result.entrySet().stream().collect(toMap(
+        when(deleteTopicsResult.topicNameValues()).thenReturn(result.entrySet().stream().collect(toMap(
             Map.Entry::getKey,
             entry -> {
                 KafkaFutureImpl<Void> kafkaFuture = new KafkaFutureImpl<>();

File: topic-operator/src/test/java/io/strimzi/operator/topic/KafkaStreamsTopicStoreTest.java
Patch:
@@ -74,6 +74,8 @@ public static void after() {
         if (service != null) {
             service.stop();
         }
+
+        cluster.stop();
     }
 
     @BeforeEach

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorReplicationIT.java
Patch:
@@ -47,6 +47,7 @@ public static void beforeAll() throws IOException {
     @AfterAll
     public static void afterAll() {
         teardownKubeCluster();
+        kafkaCluster.stop();
     }
 
     @BeforeEach

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorTopicDeletionDisabledIT.java
Patch:
@@ -33,6 +33,7 @@ public static void beforeAll() throws IOException {
     @AfterAll
     public static void afterAll() {
         teardownKubeCluster();
+        kafkaCluster.stop();
     }
 
     @BeforeEach

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicSerializationTest.java
Patch:
@@ -219,7 +219,7 @@ public void testErrorInDefaultTopicName() {
             fail("Should throw");
         } catch (InvalidTopicException e) {
             assertThat(e.getMessage(), is("KafkaTopics's spec.topicName property is absent and KafkaTopics's metadata.name is invalid as a topic name: " +
-                    "Topic name is illegal, it can't be longer than 249 characters, topic name: " +
+                    "Topic name is illegal, it can't be longer than 249 characters, Topic name: " +
                     illegalAsATopicName));
         }
     }

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicStoreUpgradeTest.java
Patch:
@@ -137,6 +137,7 @@ public static void before() throws Exception {
 
     @AfterAll
     public static void after() {
+        cluster.stop();
         vertx.close();
     }
 }

File: user-operator/src/test/java/io/strimzi/operator/user/operator/AbstractAdminApiOperatorIT.java
Patch:
@@ -66,6 +66,8 @@ public static void afterAll() {
         if (adminClient != null) {
             adminClient.close();
         }
+
+        kafkaCluster.stop();
     }
 
     abstract AbstractAdminApiOperator<T, S> operator();

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -63,7 +63,9 @@ public interface Constants {
      * Constants for Kafka clients labels
      */
     String KAFKA_CLIENTS_LABEL_KEY = "user-test-app";
+    String KAFKA_ADMIN_CLIENT_LABEL_KEY = "user-test-admin-app";
     String KAFKA_CLIENTS_LABEL_VALUE = "kafka-clients";
+    String KAFKA_ADMIN_CLIENT_LABEL_VALUE = "kafka-clients";
     String KAFKA_BRIDGE_CLIENTS_LABEL_VALUE = "kafka-clients";
 
     String KAFKA_CLIENTS = "kafka-clients";

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -60,6 +60,7 @@ public class Environment {
     private static final String TEST_PRODUCER_IMAGE_ENV = "TEST_PRODUCER_IMAGE";
     private static final String TEST_CONSUMER_IMAGE_ENV = "TEST_CONSUMER_IMAGE";
     private static final String TEST_STREAMS_IMAGE_ENV = "TEST_STREAMS_IMAGE";
+    private static final String TEST_ADMIN_IMAGE_ENV = "TEST_ADMIN_IMAGE";
     /**
      * Specify kafka bridge image used in system tests.
      */
@@ -170,9 +171,11 @@ public class Environment {
     private static final String TEST_PRODUCER_IMAGE_DEFAULT = STRIMZI_REGISTRY_DEFAULT + "/strimzi-examples/java-kafka-producer:latest";
     private static final String TEST_CONSUMER_IMAGE_DEFAULT = STRIMZI_REGISTRY_DEFAULT + "/strimzi-examples/java-kafka-consumer:latest";
     private static final String TEST_STREAMS_IMAGE_DEFAULT = STRIMZI_REGISTRY_DEFAULT + "/strimzi-examples/java-kafka-streams:latest";
+    private static final String TEST_ADMIN_IMAGE_DEFAULT = STRIMZI_REGISTRY_DEFAULT + "/strimzi-test-clients/test-client-kafka-admin:latest";
     public static final String TEST_PRODUCER_IMAGE = getOrDefault(TEST_PRODUCER_IMAGE_ENV, TEST_PRODUCER_IMAGE_DEFAULT);
     public static final String TEST_CONSUMER_IMAGE = getOrDefault(TEST_CONSUMER_IMAGE_ENV, TEST_CONSUMER_IMAGE_DEFAULT);
     public static final String TEST_STREAMS_IMAGE = getOrDefault(TEST_STREAMS_IMAGE_ENV, TEST_STREAMS_IMAGE_DEFAULT);
+    public static final String TEST_ADMIN_IMAGE = getOrDefault(TEST_ADMIN_IMAGE_ENV, TEST_ADMIN_IMAGE_DEFAULT);
     // variables for kafka bridge image
     private static final String BRIDGE_IMAGE_DEFAULT = "latest-released";
     public static final String BRIDGE_IMAGE = getOrDefault(BRIDGE_IMAGE_ENV, BRIDGE_IMAGE_DEFAULT);

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/KafkaClientOperations.java
Patch:
@@ -7,9 +7,7 @@
 /**
  * Interface KafkaClientOperations used for basic operations with the clients
  *
- * @see io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient
- * @see io.strimzi.systemtest.kafkaclients.externalClients.OauthExternalKafkaClient
- * @see io.strimzi.systemtest.kafkaclients.externalClients.TracingExternalKafkaClient
+ * @see io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient
  * @see io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient
  */
 public interface KafkaClientOperations {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java
Patch:
@@ -24,9 +24,7 @@
 
 /**
  * ClientUtils class, which provides static methods for the all type clients
- * @see io.strimzi.systemtest.kafkaclients.externalClients.OauthExternalKafkaClient
- * @see io.strimzi.systemtest.kafkaclients.externalClients.TracingExternalKafkaClient
- * @see io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient
+ * @see io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient
  * @see io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient
  */
 public class ClientUtils {

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -17,9 +17,9 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.resources.kubernetes.ServiceResource;
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
@@ -174,7 +174,7 @@ private void testWeirdUsername(ExtensionContext extensionContext, String weirdUs
 
         resourceManager.createResource(extensionContext, kafkaBridgeClientJob.consumerStrimziBridge().build());
 
-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()
+        ExternalKafkaClient externalKafkaClient = new ExternalKafkaClient.Builder()
             .withClusterName(clusterName)
             .withNamespaceName(NAMESPACE)
             .withTopicName(topicName)
@@ -184,7 +184,7 @@ private void testWeirdUsername(ExtensionContext extensionContext, String weirdUs
             .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)
             .build();
 
-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));
+        assertThat(externalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));
         ClientUtils.waitForClientSuccess(clusterName + "-" + consumerName, NAMESPACE, MESSAGE_COUNT);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -34,9 +34,9 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
+import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectorResource;
@@ -871,7 +871,7 @@ void testConnectAuthorizationWithWeirdUserName(ExtensionContext extensionContext
             .endSpec()
             .build());
 
-        BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()
+        ExternalKafkaClient externalKafkaClient = new ExternalKafkaClient.Builder()
             .withNamespaceName(namespaceName)
             .withClusterName(clusterName)
             .withKafkaUsername(userName)
@@ -881,7 +881,7 @@ void testConnectAuthorizationWithWeirdUserName(ExtensionContext extensionContext
             .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)
             .build();
 
-        assertThat(basicExternalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));
+        assertThat(externalKafkaClient.sendMessagesTls(), is(MESSAGE_COUNT));
 
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(namespaceName, connectorPodName, Constants.DEFAULT_SINK_FILE_PATH, "\"Hello-world - 99\"");
     }

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java
Patch:
@@ -11,10 +11,10 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
+import io.strimzi.systemtest.kafkaclients.externalClients.ExternalKafkaClient;
 import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
-import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
@@ -187,7 +187,7 @@ private void runListenersTest(ExtensionContext extensionContext, List<GenericKaf
 
                 if (listener.getType() != KafkaListenerType.INTERNAL) {
                     if (isTlsEnabled) {
-                        BasicExternalKafkaClient externalTlsKafkaClient = new BasicExternalKafkaClient.Builder()
+                        ExternalKafkaClient externalTlsKafkaClient = new ExternalKafkaClient.Builder()
                             .withTopicName(topicName)
                             .withNamespaceName(NAMESPACE)
                             .withClusterName(clusterName)
@@ -206,7 +206,7 @@ private void runListenersTest(ExtensionContext extensionContext, List<GenericKaf
                             externalTlsKafkaClient.receiveMessagesTls()
                         );
                     } else {
-                        BasicExternalKafkaClient externalPlainKafkaClient = new BasicExternalKafkaClient.Builder()
+                        ExternalKafkaClient externalPlainKafkaClient = new ExternalKafkaClient.Builder()
                             .withTopicName(topicName)
                             .withNamespaceName(NAMESPACE)
                             .withClusterName(clusterName)

File: api/src/main/java/io/strimzi/api/kafka/model/ClientTls.java
Patch:
@@ -18,7 +18,7 @@
 import static java.util.Collections.emptyMap;
 
 /**
- * Represent the TLS configuration for Kafka Connect
+ * Represent the TLS configuration for all the Clients(KafkaConnect, KafkaBridge, KafkaMirrorMaker, KafkaMirrorMaker2).
  */
 @DescriptionFile
 @Buildable(
@@ -27,7 +27,7 @@
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @EqualsAndHashCode
-public class KafkaConnectTls implements UnknownPropertyPreserving, Serializable {
+public class ClientTls implements UnknownPropertyPreserving, Serializable {
     private static final long serialVersionUID = 1L;
 
     private List<CertSecretSource> trustedCertificates;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeSpec.java
Patch:
@@ -39,7 +39,7 @@ public class KafkaBridgeSpec extends Spec {
     private String image;
     private KafkaBridgeHttpConfig http;
     private String bootstrapServers;
-    private KafkaBridgeTls tls;
+    private ClientTls tls;
     private KafkaClientAuthentication authentication;
     private KafkaBridgeConsumerSpec consumer;
     private KafkaBridgeProducerSpec producer;
@@ -118,11 +118,11 @@ public void setAuthentication(KafkaClientAuthentication authentication) {
 
     @Description("TLS configuration for connecting Kafka Bridge to the cluster.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    public KafkaBridgeTls getTls() {
+    public ClientTls getTls() {
         return tls;
     }
 
-    public void setTls(KafkaBridgeTls tls) {
+    public void setTls(ClientTls tls) {
         this.tls = tls;
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java
Patch:
@@ -40,7 +40,7 @@ public class KafkaConnectSpec extends AbstractKafkaConnectSpec {
     private String clientRackInitImage;
     private Rack rack;
     private String bootstrapServers;
-    private KafkaConnectTls tls;
+    private ClientTls tls;
     private KafkaClientAuthentication authentication;
     private Build build;
 
@@ -85,11 +85,11 @@ public void setBootstrapServers(String bootstrapServers) {
 
     @Description("TLS configuration")
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    public KafkaConnectTls getTls() {
+    public ClientTls getTls() {
         return tls;
     }
 
-    public void setTls(KafkaConnectTls tls) {
+    public void setTls(ClientTls tls) {
         this.tls = tls;
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2ClusterSpec.java
Patch:
@@ -39,7 +39,7 @@ public class KafkaMirrorMaker2ClusterSpec implements UnknownPropertyPreserving,
     private String alias;
     private String bootstrapServers;
     protected Map<String, Object> config = new HashMap<>(0);
-    private KafkaMirrorMaker2Tls tls;
+    private ClientTls tls;
     private KafkaClientAuthentication authentication;
     private Map<String, Object> additionalProperties;
 
@@ -76,11 +76,11 @@ public void setConfig(Map<String, Object> config) {
 
     @Description("TLS configuration for connecting MirrorMaker 2.0 connectors to a cluster.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    public KafkaMirrorMaker2Tls getTls() {
+    public ClientTls getTls() {
         return tls;
     }
 
-    public void setTls(KafkaMirrorMaker2Tls tls) {
+    public void setTls(ClientTls tls) {
         this.tls = tls;
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerClientSpec.java
Patch:
@@ -29,7 +29,7 @@ public class KafkaMirrorMakerClientSpec implements UnknownPropertyPreserving, Se
 
     private String bootstrapServers;
     protected Map<String, Object> config = new HashMap<>(0);
-    private KafkaMirrorMakerTls tls;
+    private ClientTls tls;
     private KafkaClientAuthentication authentication;
     private Map<String, Object> additionalProperties;
 
@@ -54,11 +54,11 @@ public void setConfig(Map<String, Object> config) {
 
     @Description("TLS configuration for connecting MirrorMaker to the cluster.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    public KafkaMirrorMakerTls getTls() {
+    public ClientTls getTls() {
         return tls;
     }
 
-    public void setTls(KafkaMirrorMakerTls tls) {
+    public void setTls(ClientTls tls) {
         this.tls = tls;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AuthenticationUtils.java
Patch:
@@ -383,5 +383,4 @@ public static void configureZookeeperJmxOptions(KafkaJmxAuthentication authentic
             zookeeperCluster.setJmxAuthenticated(false);
         }
     }
-
 }

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserST.java
Patch:
@@ -233,7 +233,7 @@ synchronized void testUserWithQuotas(ExtensionContext extensionContext, KafkaUse
             .endMetadata()
             .build());
 
-        String command = "bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --entity-type users";
+        String command = "bin/kafka-configs.sh --bootstrap-server localhost:9092 --describe --user " + userName;
         LOGGER.debug("Command for kafka-configs.sh {}", command);
 
         ExecResult result = cmdKubeClient(NAMESPACE).execInPod(KafkaResources.kafkaPodName(userClusterName, 0), "/bin/bash", "-c", command);

File: crd-generator/src/main/java/io/strimzi/crdgenerator/annotations/Pattern.java
Patch:
@@ -12,11 +12,11 @@
 
 /**
  * This annotation is used to restrict a string to a particular regular expression.
- * <br/><br/>
+ * <br><br>
  * When defining the regular expression, it's important to note that the string is considered valid if the expression
  * matches anywhere within the string. Unless there is a good reason to do so, it's usually less confusing to wrap the
  * regular expression in {@code ^...$}.
- * <br/><br/>
+ * <br><br>
  * For example, the expression {@code p} will match any string containing a p, like "apple", instead the expression
  * {@code ^p$} will only match the string "p".
  */

File: api/src/main/java/io/strimzi/api/kafka/model/JvmOptions.java
Patch:
@@ -37,7 +37,7 @@ public class JvmOptions implements UnknownPropertyPreserving, Serializable {
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @JsonProperty("-Xmx")
-    @Pattern("[0-9]+[mMgG]?")
+    @Pattern("^[0-9]+[mMgG]?$")
     @Description("-Xmx option to to the JVM")
     public String getXmx() {
         return xmx;
@@ -48,7 +48,7 @@ public void setXmx(String xmx) {
     }
 
     @JsonProperty("-Xms")
-    @Pattern("[0-9]+[mMgG]?")
+    @Pattern("^[0-9]+[mMgG]?$")
     @Description("-Xms option to to the JVM")
     public String getXms() {
         return xms;

File: api/src/main/java/io/strimzi/api/kafka/model/balancing/BrokerCapacity.java
Patch:
@@ -66,7 +66,7 @@ public void setCpuUtilization(Integer cpuUtilization) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    @Pattern("[0-9]+([KMG]i?)?B/s")
+    @Pattern("^[0-9]+([KMG]i?)?B/s$")
     @Description("Broker capacity for inbound network throughput in bytes per second, for example, 10000KB/s")
     public String getInboundNetwork() {
         return inboundNetwork;
@@ -77,7 +77,7 @@ public void setInboundNetwork(String inboundNetwork) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    @Pattern("[0-9]+([KMG]i?)?B/s")
+    @Pattern("^[0-9]+([KMG]i?)?B/s$")
     @Description("Broker capacity for outbound network throughput in bytes per second, for example 10000KB/s")
     public String getOutboundNetwork() {
         return outboundNetwork;

File: api/src/main/java/io/strimzi/api/kafka/model/connect/build/DownloadableArtifact.java
Patch:
@@ -32,7 +32,7 @@ public abstract class DownloadableArtifact extends Artifact {
             "For security reasons, you should first verify the artifacts manually and configure the checksum verification to make sure the same artifact is used in the automated build. " +
             "Required for `jar`, `zip`, `tgz` and `other` artifacts. " +
             "Not applicable to the `maven` artifact type.")
-    @Pattern("^(https?|ftp)://[-a-zA-Z0-9+&@#/%?=~_|!:,.;]*[-a-zA-Z0-9+&@#/%=~_|]")
+    @Pattern("^(https?|ftp)://[-a-zA-Z0-9+&@#/%?=~_|!:,.;]*[-a-zA-Z0-9+&@#/%=~_|]$")
     public String getUrl() {
         return url;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java
Patch:
@@ -64,7 +64,7 @@ public static void waitForClientSuccess(String jobName, String namespace, int me
         LOGGER.info("Waiting for producer/consumer:{} to finished", jobName);
         TestUtils.waitFor("job finished", Constants.GLOBAL_POLL_INTERVAL, timeoutForClientFinishJob(messageCount),
             () -> {
-                LOGGER.info("Job {} in namespace {}, has status {}", jobName, namespace, kubeClient().namespace(namespace).getJobStatus(jobName));
+                LOGGER.debug("Job {} in namespace {}, has status {}", jobName, namespace, kubeClient().namespace(namespace).getJobStatus(jobName));
                 return kubeClient().namespace(namespace).checkSucceededJobStatus(jobName);
             });
     }

File: api/src/main/java/io/strimzi/api/kafka/model/connect/build/Artifact.java
Patch:
@@ -46,7 +46,7 @@ public abstract class Artifact implements UnknownPropertyPreserving, Serializabl
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Description("Artifact type. " +
-            "Currently, the supported artifact types are `tgz`, `jar`, `zip` and `maven`.")
+            "Currently, the supported artifact types are `tgz`, `jar`, `zip`, `other` and `maven`.")
     public abstract String getType();
 
     @Override

File: api/src/main/java/io/strimzi/api/kafka/model/connect/build/Artifact.java
Patch:
@@ -28,6 +28,7 @@
             @JsonSubTypes.Type(value = JarArtifact.class, name = Artifact.TYPE_JAR),
             @JsonSubTypes.Type(value = TgzArtifact.class, name = Artifact.TYPE_TGZ),
             @JsonSubTypes.Type(value = ZipArtifact.class, name = Artifact.TYPE_ZIP),
+            @JsonSubTypes.Type(value = MavenArtifact.class, name = Artifact.TYPE_MVN),
             @JsonSubTypes.Type(value = OtherArtifact.class, name = Artifact.TYPE_OTHER)
         }
 )
@@ -39,12 +40,13 @@ public abstract class Artifact implements UnknownPropertyPreserving, Serializabl
     public static final String TYPE_JAR = "jar";
     public static final String TYPE_TGZ = "tgz";
     public static final String TYPE_ZIP = "zip";
+    public static final String TYPE_MVN = "maven";
     public static final String TYPE_OTHER = "other";
 
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Description("Artifact type. " +
-            "Currently, the supported artifact types are `tgz`, `jar`, and `zip`.")
+            "Currently, the supported artifact types are `tgz`, `jar`, `zip` and `maven`.")
     public abstract String getType();
 
     @Override

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -71,6 +71,7 @@ public class ClusterOperatorConfig {
     public static final String STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE = "STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE";
     public static final String STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE = "STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE";
     public static final String STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE = "STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE";
+    public static final String STRIMZI_DEFAULT_MAVEN_BUILDER = "STRIMZI_DEFAULT_MAVEN_BUILDER";
 
     public static final long DEFAULT_FULL_RECONCILIATION_INTERVAL_MS = 120_000;
     public static final long DEFAULT_OPERATION_TIMEOUT_MS = 300_000;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -86,7 +86,7 @@ public class EntityTopicOperatorTest {
             .withReadinessProbe(readinessProbe)
             .withLogging(topicOperatorLogging)
             .withNewJvmOptions()
-                    .withNewXms("128m")
+                    .withXms("128m")
                     .addAllToJavaSystemProperties(javaSystemProperties)
             .endJvmOptions()
             .build();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -97,7 +97,7 @@ public class EntityUserOperatorTest {
             .withLogging(userOperatorLogging)
             .withNewJvmOptions()
                 .addAllToJavaSystemProperties(javaSystemProperties)
-                .withNewXmx("256m")
+                .withXmx("256m")
             .endJvmOptions()
             .build();
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/JmxTransTest.java
Patch:
@@ -81,7 +81,7 @@ public class JmxTransTest {
             .withKafkaQueries(new JmxTransQueryTemplateBuilder()
                     .withOutputs("name")
                     .withAttributes("attributes")
-                    .withNewTargetMBean("mbean")
+                    .withTargetMBean("mbean")
                     .build())
             .build();
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -3203,7 +3203,7 @@ image, healthDelay, healthTimeout, jmxMetricsConfig, configuration, emptyMap()))
                     .editKafka()
                         // Set a rack to force init-container to be templated
                         .withNewRack()
-                            .withNewTopologyKey("a-topology")
+                            .withTopologyKey("a-topology")
                         .endRack()
                         .withNewTemplate()
                             .withNewInitContainer()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -1143,8 +1143,8 @@ public void testJvmOptions() {
         KafkaConnect resource = new KafkaConnectBuilder(this.resource)
                 .editSpec()
                     .withNewJvmOptions()
-                        .withNewXms("512m")
-                        .withNewXmx("1024m")
+                        .withXms("512m")
+                        .withXmx("1024m")
                         .withXx(xx)
                     .endJvmOptions()
                 .endSpec()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaExporterTest.java
Patch:
@@ -394,7 +394,7 @@ public void testTemplate() {
                                     .withAnnotations(podAnots)
                                 .endMetadata()
                                 .withPriorityClassName("top-priority")
-                                .withNewSchedulerName("my-scheduler")
+                                .withSchedulerName("my-scheduler")
                                 .withAffinity(affinity)
                                 .withTolerations(tolerations)
                                 .withTopologySpreadConstraints(tsc1, tsc2)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -1227,8 +1227,8 @@ public void testJvmOptions() {
         KafkaMirrorMaker2 resource = new KafkaMirrorMaker2Builder(this.resource)
                 .editSpec()
                     .withNewJvmOptions()
-                        .withNewXms("512m")
-                        .withNewXmx("1024m")
+                        .withXms("512m")
+                        .withXmx("1024m")
                         .withXx(xx)
                     .endJvmOptions()
                 .endSpec()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -794,8 +794,8 @@ public void testJvmOptions() {
         KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(this.resource)
                 .editSpec()
                     .withNewJvmOptions()
-                        .withNewXms("512m")
-                        .withNewXmx("1024m")
+                        .withXms("512m")
+                        .withXmx("1024m")
                         .withXx(xx)
                     .endJvmOptions()
                 .endSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaBridgeCrdOperatorIT.java
Patch:
@@ -58,7 +58,7 @@ protected KafkaBridge getResource(String resourceName) {
                     .withNamespace(getNamespace())
                 .endMetadata()
                 .withNewSpec()
-                    .withNewBootstrapServers("localhost:9092")
+                    .withBootstrapServers("localhost:9092")
                 .endSpec()
                 .withNewStatus()
                 .endStatus()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectCrdOperatorIT.java
Patch:
@@ -56,7 +56,7 @@ protected KafkaConnect getResource(String resourceName) {
                     .withNamespace(getNamespace())
                 .endMetadata()
                 .withNewSpec()
-                    .withNewBootstrapServers("localhost:9092")
+                    .withBootstrapServers("localhost:9092")
                 .endSpec()
                 .withNewStatus()
                 .endStatus()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorTest.java
Patch:
@@ -67,7 +67,7 @@ protected Kafka resource() {
                     .endZookeeper()
                 .endSpec()
                 .withNewStatus()
-                    .addToConditions(new ConditionBuilder().withNewStatus("Ready").withNewMessage("Kafka is ready").build())
+                    .addToConditions(new ConditionBuilder().withStatus("Ready").withMessage("Kafka is ready").build())
                 .endStatus()
                 .build();
     }

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -71,7 +71,7 @@ void testScramShaAuthWithWeirdUsername(ExtensionContext extensionContext) {
 
         KafkaBridgeSpec bridgeSpec = new KafkaBridgeSpecBuilder()
             .withNewKafkaClientAuthenticationScramSha512()
-                .withNewUsername(weirdUserName)
+                .withUsername(weirdUserName)
                 .withPasswordSecret(passwordSecret)
             .endKafkaClientAuthenticationScramSha512()
             .withNewTls()

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -228,7 +228,7 @@ void testKafkaConnectWithPlainAndScramShaAuthentication(ExtensionContext extensi
             .withNewSpec()
                 .withBootstrapServers(KafkaResources.plainBootstrapAddress(clusterName))
                 .withNewKafkaClientAuthenticationScramSha512()
-                    .withNewUsername(userName)
+                    .withUsername(userName)
                     .withPasswordSecret(new PasswordSecretSourceBuilder()
                         .withSecretName(userName)
                         .withPassword("password")
@@ -837,7 +837,7 @@ void testConnectScramShaAuthWithWeirdUserName(ExtensionContext extensionContext)
                 .editOrNewSpec()
                     .withBootstrapServers(KafkaResources.tlsBootstrapAddress(clusterName))
                     .withNewKafkaClientAuthenticationScramSha512()
-                        .withNewUsername(weirdUserName)
+                        .withUsername(weirdUserName)
                         .withPasswordSecret(new PasswordSecretSourceBuilder()
                             .withSecretName(weirdUserName)
                             .withPassword("password")

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlConfigurationST.java
Patch:
@@ -157,7 +157,7 @@ void testConfigurationDiskChangeDoNotTriggersRollingUpdateOfKafkaPods(ExtensionC
 
             CruiseControlSpec cruiseControl = new CruiseControlSpecBuilder()
                 .withNewBrokerCapacity()
-                    .withNewDisk("200M")
+                    .withDisk("200M")
                 .endBrokerCapacity()
                 .build();
 

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/QuotasST.java
Patch:
@@ -52,7 +52,7 @@ void testKafkaQuotasPluginIntegration(ExtensionContext extensionContext) {
                     .addToConfig("client.quota.callback.static.storage.soft", "50000000")
                     .addToConfig("client.quota.callback.static.storage.check-interval", "5")
                     .withNewPersistentClaimStorage()
-                        .withNewSize("1Gi")
+                        .withSize("1Gi")
                     .endPersistentClaimStorage()
                 .endKafka()
             .endSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -376,7 +376,7 @@ void testMirrorMaker2TlsAndTlsClientAuth(ExtensionContext extensionContext) thro
             .editSpec()
                 .withClusters(sourceClusterWithTlsAuth, targetClusterWithTlsAuth)
                 .editFirstMirror()
-                    .withNewTopicsPattern(MIRRORMAKER2_TOPIC_NAME + ".*")
+                    .withTopicsPattern(MIRRORMAKER2_TOPIC_NAME + ".*")
                 .endMirror()
             .endSpec()
             .build());

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerST.java
Patch:
@@ -507,7 +507,7 @@ void testIncludeList(ExtensionContext extensionContext) {
                 .withNamespace(namespaceName)
             .endMetadata()
             .editSpec()
-                .withNewInclude(topicName)
+                .withInclude(topicName)
             .endSpec().build());
 
         internalKafkaClient = internalKafkaClient.toBuilder()

File: systemtest/src/test/java/io/strimzi/systemtest/security/OpaIntegrationST.java
Patch:
@@ -147,7 +147,7 @@ void setup(ExtensionContext extensionContext) throws Exception {
                 .editKafka()
                     .withNewKafkaAuthorizationOpa()
                         .withUrl("http://opa:8181/v1/data/kafka/simple/authz/allow")
-                        .addNewSuperUser("CN=" + OPA_SUPERUSER)
+                        .addToSuperUsers("CN=" + OPA_SUPERUSER)
                     .endKafkaAuthorizationOpa()
                     .withListeners(new GenericKafkaListenerBuilder()
                             .withName(Constants.TLS_LISTENER_DEFAULT_NAME)

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -664,7 +664,7 @@ void testCertRenewalInMaintenanceWindow(ExtensionContext extensionContext) {
 
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaPersistent(clusterName, 3, 1)
             .editSpec()
-                .addNewMaintenanceTimeWindow(maintenanceWindowCron)
+                .addToMaintenanceTimeWindows(maintenanceWindowCron)
             .endSpec()
             .build());
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -346,7 +346,7 @@ void testMirrorMaker(ExtensionContext extensionContext) {
                         .withGroupId(ClientUtils.generateRandomConsumerGroup())
                         .addToConfig(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest")
                         .withNewKafkaClientAuthenticationOAuth()
-                            .withNewTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
+                            .withTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
                             .withClientId("kafka-mirror-maker")
                             .withNewClientSecret()
                                 .withSecretName(MIRROR_MAKER_OAUTH_SECRET)
@@ -370,7 +370,7 @@ void testMirrorMaker(ExtensionContext extensionContext) {
                                 .build())
                         .endTls()
                         .withNewKafkaClientAuthenticationOAuth()
-                            .withNewTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
+                            .withTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
                             .withClientId("kafka-mirror-maker")
                             .withNewClientSecret()
                                 .withSecretName(MIRROR_MAKER_OAUTH_SECRET)

File: test/src/main/java/io/strimzi/test/k8s/HelmClient.java
Patch:
@@ -39,14 +39,14 @@ public HelmClient namespace(String namespace) {
     }
 
     /** Install a chart given its local path, release name, and values to override */
-    public HelmClient install(Path chart, String releaseName, Map<String, String> valuesMap) {
+    public HelmClient install(Path chart, String releaseName, Map<String, Object> valuesMap) {
         LOGGER.info("Installing helm-chart {}", releaseName);
         String values = Stream.of(valuesMap).flatMap(m -> m.entrySet().stream())
                 .map(entry -> String.format("%s=%s", entry.getKey(), entry.getValue()))
                 .collect(Collectors.joining(","));
         Exec.exec(null, wait(namespace(command("install",
                 releaseName,
-                "--set-string", values,
+                "--set", values,
                 "--timeout", INSTALL_TIMEOUT_SECONDS,
                 chart.toString()))), 0, true, true);
         return this;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -1234,7 +1234,8 @@ Future<ReconciliationState> zkJmxSecret() {
                 Future<Secret> secretFuture = secretOperations.getAsync(namespace, ZookeeperCluster.jmxSecretName(name));
                 return secretFuture.compose(secret -> {
                     if (secret == null) {
-                        return withVoid(secretOperations.reconcile(reconciliation, namespace, ZookeeperCluster.jmxSecretName(name), zkCluster.generateJmxSecret()));
+                        return withVoid(secretOperations.reconcile(reconciliation, namespace, ZookeeperCluster.jmxSecretName(name),
+                                zkCluster.generateJmxSecret()));
                     }
                     return withVoid(Future.succeededFuture(ReconcileResult.noop(secret)));
                 });

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -3211,7 +3211,7 @@ image, healthDelay, healthTimeout, jmxMetricsConfig, configuration, emptyMap()))
         KafkaCluster kc = KafkaCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, kafkaAssembly, VERSIONS);
         StatefulSet sts = kc.generateStatefulSet(true, null, null);
         Container cont = sts.getSpec().getTemplate().getSpec().getContainers().get(0);
-        
+
         assertThat(cont.getEnv().stream().filter(var -> "STRIMZI_PLAIN_9092_OAUTH_CLIENT_SECRET".equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
         assertThat(cont.getEnv().stream().filter(var -> "STRIMZI_PLAIN_9092_OAUTH_CLIENT_SECRET".equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
     }
@@ -3370,10 +3370,10 @@ image, healthDelay, healthTimeout, jmxMetricsConfig, configuration, emptyMap()))
 
         assertThat(cont.getEnv().stream().filter(var -> "STRIMZI_PLAIN_9092_OAUTH_CLIENT_SECRET".equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
         assertThat(cont.getEnv().stream().filter(var -> "STRIMZI_PLAIN_9092_OAUTH_CLIENT_SECRET".equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        
+
         assertThat(cont.getEnv().stream().filter(var -> "STRIMZI_TLS_9093_OAUTH_CLIENT_SECRET".equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
         assertThat(cont.getEnv().stream().filter(var -> "STRIMZI_TLS_9093_OAUTH_CLIENT_SECRET".equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
-        
+
         assertThat(cont.getEnv().stream().filter(var -> "STRIMZI_EXTERNAL_9094_OAUTH_CLIENT_SECRET".equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
         assertThat(cont.getEnv().stream().filter(var -> "STRIMZI_EXTERNAL_9094_OAUTH_CLIENT_SECRET".equals(var.getName())).findFirst().orElseThrow().getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/ClientHandlerBase.java
Patch:
@@ -5,15 +5,12 @@
 package io.strimzi.systemtest.kafkaclients.externalClients;
 
 import io.vertx.core.AbstractVerticle;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
 
 import java.util.concurrent.CompletableFuture;
 import java.util.function.IntPredicate;
 
 public abstract class ClientHandlerBase<T> extends AbstractVerticle {
 
-    private static final Logger LOGGER = LogManager.getLogger(ClientHandlerBase.class);
     final CompletableFuture<T> resultPromise;
     final IntPredicate msgCntPredicate;
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/TracingExternalKafkaClient.java
Patch:
@@ -6,16 +6,13 @@
 
 import io.strimzi.systemtest.kafkaclients.AbstractKafkaClient;
 import io.strimzi.systemtest.kafkaclients.KafkaClientOperations;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
 
 /**
  * The TracingKafkaClient for sending and receiving messages using tracing properties.
  * The client is using an external listeners.
  */
 public class TracingExternalKafkaClient extends AbstractKafkaClient<TracingExternalKafkaClient.Builder> implements KafkaClientOperations {
 
-    private static final Logger LOGGER = LogManager.getLogger(TracingExternalKafkaClient.class);
     private String serviceName;
 
     public static class Builder extends AbstractKafkaClient.Builder<Builder> {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/JobUtils.java
Patch:
@@ -43,13 +43,12 @@ public static void deleteJobWithWait(String namespace, String name) {
     /**
      * Wait for specific Job failure
      * @param jobName job name
-     * @param namespace namespace
      * @param timeout timeout in ms after which we assume that job failed
      */
     public static void waitForJobFailure(String jobName, String namespace, long timeout) {
         LOGGER.info("Waiting for job: {} will be in error state", jobName);
         TestUtils.waitFor("job finished", Constants.GLOBAL_POLL_INTERVAL, timeout,
-            () -> !kubeClient().checkSucceededJobStatus(jobName));
+            () -> kubeClient().checkFailedJobStatus(namespace, jobName, 1));
     }
 
     /**

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/TracingUtils.java
Patch:
@@ -18,7 +18,6 @@ public class TracingUtils {
 
     private static final Logger LOGGER = LogManager.getLogger(TracingUtils.class);
 
-    private static final String JAEGER_QUERY_SERVICE = "my-jaeger-query";
     private static final String JAEGER_QUERY_SERVICE_ENDPOINT = "/jaeger/api/services";
     private static final String JAEGER_QUERY_SERVICE_TRACES_ENDPOINT = "/jaeger/api/traces";
     private static final String JAEGER_QUERY_SERVICE_PARAM_SERVICE = "?service=";

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/QuotasST.java
Patch:
@@ -15,8 +15,6 @@
 import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.JobUtils;
 import io.strimzi.test.WaitException;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
 import org.hamcrest.CoreMatchers;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeAll;
@@ -31,7 +29,6 @@
 import static org.junit.jupiter.api.Assertions.assertThrows;
 
 public class QuotasST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(QuotasST.class);
 
     public static final String NAMESPACE = "quotas";
     /**

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/ListenersST.java
Patch:
@@ -123,7 +123,6 @@ void testSendMessagesPlainAnonymous(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         final String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());
-        final String clientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
 
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(clusterName, 3).build());
         resourceManager.createResource(extensionContext, KafkaTopicTemplates.topic(clusterName, topicName).build());

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/JmxST.java
Patch:
@@ -17,8 +17,6 @@
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.specific.JmxUtils;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.extension.ExtensionContext;
@@ -33,7 +31,6 @@
 @Tag(REGRESSION)
 public class JmxST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(JmxST.class);
     public static final String NAMESPACE = "jmx-cluster-test";
 
     @ParallelNamespaceTest

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -87,7 +87,6 @@ class MirrorMaker2ST extends AbstractST {
     public static final String NAMESPACE = "mirrormaker2-cluster-test";
 
     private static final String MIRRORMAKER2_TOPIC_NAME = "mirrormaker2-topic-example";
-    private static int consumerCounter = 0;
     private final int messagesCount = 200;
 
     @SuppressWarnings({"checkstyle:MethodLength"})
@@ -178,7 +177,7 @@ void testMirrorMaker2(ExtensionContext extensionContext) {
         assertThat(StUtils.getPropertiesFromJson(0, kafkaPodJson, "KAFKA_CONNECT_CONFIGURATION"), is(expectedConfig));
         testDockerImagesForKafkaMirrorMaker2(clusterName, NAMESPACE, namespaceName);
 
-        verifyLabelsOnPods(namespaceName, clusterName, "mirrormaker2", null, "KafkaMirrorMaker2");
+        verifyLabelsOnPods(namespaceName, clusterName, "mirrormaker2", "KafkaMirrorMaker2");
         verifyLabelsForService(namespaceName, clusterName, "mirrormaker2-api", "KafkaMirrorMaker2");
         verifyLabelsForConfigMaps(namespaceName, kafkaClusterSourceName, null, kafkaClusterTargetName);
         verifyLabelsForServiceAccounts(namespaceName, kafkaClusterSourceName, null);

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAbstractST.java
Patch:
@@ -26,16 +26,13 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.vertx.core.json.JsonObject;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.extension.ExtensionContext;
 
 
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 
 public class OlmAbstractST extends AbstractST {
-    private static final Logger LOGGER = LogManager.getLogger(OlmAbstractST.class);
 
     void doTestDeployExampleKafka() {
         JsonObject kafkaResource = OlmResource.getExampleResources().get(Kafka.RESOURCE_KIND);

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceDeletionRecoveryST.java
Patch:
@@ -64,7 +64,7 @@ void testTopicAvailable(ExtensionContext extensionContext) {
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());
 
-        prepareEnvironmentForRecovery(extensionContext, topicName, MESSAGE_COUNT);
+        prepareEnvironmentForRecovery(extensionContext, topicName);
 
         // Wait till consumer offset topic is created
         KafkaTopicUtils.waitForKafkaTopicCreationByNamePrefix("consumer-offsets");
@@ -134,7 +134,7 @@ void testTopicNotAvailable(ExtensionContext extensionContext) throws Interrupted
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());
 
-        prepareEnvironmentForRecovery(extensionContext, topicName, MESSAGE_COUNT);
+        prepareEnvironmentForRecovery(extensionContext, topicName);
 
         // Wait till consumer offset topic is created
         KafkaTopicUtils.waitForKafkaTopicCreationByNamePrefix("consumer-offsets");
@@ -205,7 +205,7 @@ void testTopicNotAvailable(ExtensionContext extensionContext) throws Interrupted
         );
     }
 
-    private void prepareEnvironmentForRecovery(ExtensionContext extensionContext, String topicName, int messageCount) {
+    private void prepareEnvironmentForRecovery(ExtensionContext extensionContext, String topicName) {
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
 
         install = new SetupClusterOperator.SetupClusterOperatorBuilder()

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -401,7 +401,7 @@ void testAddingAndRemovingJbodVolumes(ExtensionContext extensionContext) {
         // Add Jbod volume to Kafka => triggers RU
         LOGGER.info("Add JBOD volume to the Kafka cluster {}", kafkaName);
 
-        String operationId = timeMeasuringSystem.startTimeMeasuring(Operation.ROLLING_UPDATE, extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName());
+        timeMeasuringSystem.startTimeMeasuring(Operation.ROLLING_UPDATE, extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName());
         KafkaResource.replaceKafkaResourceInSpecificNamespace(clusterName, kafka -> {
             JbodStorage storage = (JbodStorage) kafka.getSpec().getKafka().getStorage();
             storage.getVolumes().add(vol1);
@@ -414,7 +414,7 @@ void testAddingAndRemovingJbodVolumes(ExtensionContext extensionContext) {
         // Remove Jbod volume to Kafka => triggers RU
         LOGGER.info("Remove JBOD volume to the Kafka cluster {}", kafkaName);
 
-        operationId = timeMeasuringSystem.startTimeMeasuring(Operation.ROLLING_UPDATE, extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName());
+        timeMeasuringSystem.startTimeMeasuring(Operation.ROLLING_UPDATE, extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName());
         KafkaResource.replaceKafkaResourceInSpecificNamespace(clusterName, kafka -> {
             JbodStorage storage = (JbodStorage) kafka.getSpec().getKafka().getStorage();
             storage.getVolumes().remove(vol1);

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerST.java
Patch:
@@ -109,7 +109,7 @@ void testKafkaRollsWhenTopicIsUnderReplicated(ExtensionContext extensionContext)
 
         //Test that CO doesn't have any exceptions in log
         timeMeasuringSystem.stopOperation(operationId, extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName());
-        assertNoCoErrorsLogged(NAMESPACE, timeMeasuringSystem.getDurationInSeconds(extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName(), operationId));
+        assertNoCoErrorsLogged(timeMeasuringSystem.getDurationInSeconds(extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName(), operationId));
 
         // scale down
         final int scaledDownReplicas = 3;
@@ -149,7 +149,6 @@ void testKafkaTopicRFLowerThanMinInSyncReplicas(ExtensionContext extensionContex
 
         // rolling update for kafka
         LOGGER.info("Annotate Kafka StatefulSet {} with manual rolling update annotation", kafkaName);
-        String operationId = timeMeasuringSystem.startTimeMeasuring(Operation.CLUSTER_RECOVERY, extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName());
 
         // set annotation to trigger Kafka rolling update
         kubeClient(namespaceName).statefulSet(kafkaName).withPropagationPolicy(DeletionPropagation.ORPHAN).edit(sts -> new StatefulSetBuilder(sts)

File: systemtest/src/test/java/io/strimzi/systemtest/security/OpaIntegrationST.java
Patch:
@@ -44,7 +44,6 @@ public class OpaIntegrationST extends AbstractST {
     private static final String OPA_SUPERUSER = "arnost";
     private static final String OPA_GOOD_USER = "good-user";
     private static final String OPA_BAD_USER = "bad-user";
-    private static String clientsPodName = "";
     private static final String CLUSTER_NAME = "opa-cluster";
 
     @ParallelTest

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -649,8 +649,8 @@ void testCertRenewalInMaintenanceWindow(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         final String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());
-        final String userName = mapWithTestUsers.get(extensionContext.getDisplayName());
         final String secretName = KafkaResources.clusterCaCertificateSecretName(clusterName);
+        final String userName = mapWithTestUsers.get(extensionContext.getDisplayName());
 
         LocalDateTime maintenanceWindowStart = LocalDateTime.now().withSecond(0);
         long maintenanceWindowDuration = 14;
@@ -669,7 +669,7 @@ void testCertRenewalInMaintenanceWindow(ExtensionContext extensionContext) {
             .build());
 
 
-        KafkaUser user = KafkaUserTemplates.tlsUser(clusterName, KafkaUserUtils.generateRandomNameOfKafkaUser()).build();
+        KafkaUser user = KafkaUserTemplates.tlsUser(clusterName, userName).build();
 
         resourceManager.createResource(extensionContext, user);
         resourceManager.createResource(extensionContext, KafkaTopicTemplates.topic(clusterName, topicName).build());

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -64,7 +64,6 @@
 public class OauthTlsST extends OauthAbstractST {
     protected static final Logger LOGGER = LogManager.getLogger(OauthTlsST.class);
 
-    private KafkaOauthExampleClients oauthInternalClientJob;
     private final String oauthClusterName = "oauth-cluster-tls-name";
     private static final String NAMESPACE = "oauth2-tls-cluster-test";
 
@@ -255,7 +254,6 @@ void testProducerConsumerBridge(ExtensionContext extensionContext) {
     @Tag(NODEPORT_SUPPORTED)
     @SuppressWarnings({"checkstyle:MethodLength"})
     void testMirrorMaker(ExtensionContext extensionContext) {
-        String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         String producerName = OAUTH_PRODUCER_NAME + "-" + clusterName;
         String consumerName = OAUTH_CONSUMER_NAME + "-" + clusterName;
@@ -417,7 +415,6 @@ void testMirrorMaker(ExtensionContext extensionContext) {
 
     @ParallelTest
     void testIntrospectionEndpoint(ExtensionContext extensionContext) {
-        String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
         String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         String producerName = OAUTH_PRODUCER_NAME + "-" + clusterName;
         String consumerName = OAUTH_CONSUMER_NAME + "-" + clusterName;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -227,8 +227,6 @@ private JsonObject buildDataForUpgradeAcrossVersions() throws IOException {
 
     private JsonObject getDataForStartUpgrade(JsonArray upgradeJson) throws IOException {
         List<TestKafkaVersion> sortedVersions = TestKafkaVersion.getSupportedKafkaVersions();
-        List<String> versions = sortedVersions.stream().map(item -> item.version()).collect(Collectors.toList());
-
         Collections.reverse(upgradeJson.getList());
 
         JsonObject startingVersion = null;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/kafkaclients/KafkaBasicExampleClients.java
Patch:
@@ -221,7 +221,7 @@ public JobBuilder defaultProducerStrimzi() {
                             .addNewContainer()
                                 .withName(producerName)
                                 .withImagePullPolicy(Constants.IF_NOT_PRESENT_IMAGE_PULL_POLICY)
-                                .withImage(Environment.STRIMZI_REGISTRY_DEFAULT + "/" + Environment.STRIMZI_CLIENTS_ORG_DEFAULT + "/" + Constants.STRIMZI_EXAMPLE_PRODUCER_NAME + ":latest")
+                                .withImage(Environment.TEST_PRODUCER_IMAGE)
                                 .addNewEnv()
                                     .withName("BOOTSTRAP_SERVERS")
                                     .withValue(bootstrapAddress)
@@ -295,7 +295,7 @@ public JobBuilder defaultConsumerStrimzi() {
                                 .addNewContainer()
                                     .withName(consumerName)
                                     .withImagePullPolicy(Constants.IF_NOT_PRESENT_IMAGE_PULL_POLICY)
-                                    .withImage(Environment.STRIMZI_REGISTRY_DEFAULT + "/" + Environment.STRIMZI_CLIENTS_ORG_DEFAULT + "/" + Constants.STRIMZI_EXAMPLE_CONSUMER_NAME + ":latest")
+                                    .withImage(Environment.TEST_CONSUMER_IMAGE)
                                     .addNewEnv()
                                         .withName("BOOTSTRAP_SERVERS")
                                         .withValue(bootstrapAddress)

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/kafkaclients/KafkaTracingExampleClients.java
Patch:
@@ -5,7 +5,6 @@
 package io.strimzi.systemtest.resources.crd.kafkaclients;
 
 import io.fabric8.kubernetes.api.model.batch.v1.JobBuilder;
-import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.resources.ResourceManager;
 
@@ -227,7 +226,7 @@ public JobBuilder kafkaStreamsWithTracing() {
                         .withContainers()
                         .addNewContainer()
                             .withName(kafkaStreamsName)
-                            .withImage(Environment.STRIMZI_REGISTRY_DEFAULT + "/" + Environment.STRIMZI_CLIENTS_ORG_DEFAULT + "/" + Constants.STRIMZI_EXAMPLE_STREAMS_NAME + ":latest")
+                            .withImage(Environment.TEST_STREAMS_IMAGE)
                             .addNewEnv()
                                 .withName("BOOTSTRAP_SERVERS")
                                 .withValue(bootstrapAddress)

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -79,6 +79,7 @@
 
 import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;
 import static io.strimzi.api.kafka.model.KafkaResources.zookeeperStatefulSetName;
+import static io.strimzi.systemtest.Constants.CRUISE_CONTROL;
 import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
@@ -1596,6 +1597,7 @@ void testKafkaOffsetsReplicationFactorHigherThanReplicas(ExtensionContext extens
 
     @ParallelNamespaceTest
     @Tag(INTERNAL_CLIENTS_USED)
+    @Tag(CRUISE_CONTROL)
     void testReadOnlyRootFileSystem(ExtensionContext extensionContext) {
         final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ClusterOperatorRbacST.java
Patch:
@@ -23,6 +23,7 @@
 import org.junit.jupiter.api.extension.ExtensionContext;
 
 import static io.strimzi.systemtest.Constants.CONNECT;
+import static io.strimzi.systemtest.Constants.CONNECT_COMPONENTS;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.enums.CustomResourceStatus.NotReady;
 import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;
@@ -39,6 +40,7 @@ public class ClusterOperatorRbacST extends AbstractST {
 
     @IsolatedTest("We need for each test case its own Cluster Operator")
     @Tag(CONNECT)
+    @Tag(CONNECT_COMPONENTS)
     void testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled(ExtensionContext extensionContext) {
         assumeFalse(Environment.isNamespaceRbacScope());
 
@@ -71,6 +73,7 @@ void testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled(ExtensionContext
 
     @IsolatedTest("We need for each test case its own Cluster Operator")
     @Tag(CONNECT)
+    @Tag(CONNECT_COMPONENTS)
     void testCRBDeletionErrorsWhenRackAwarenessIsEnabled(ExtensionContext extensionContext) {
         assumeFalse(Environment.isNamespaceRbacScope());
 

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -57,6 +57,7 @@
 
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.CONNECT;
+import static io.strimzi.systemtest.Constants.CONNECT_COMPONENTS;
 import static io.strimzi.systemtest.Constants.CO_OPERATION_TIMEOUT_SHORT;
 import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
@@ -142,6 +143,7 @@ void testRackAware(ExtensionContext extensionContext) {
 
     @IsolatedTest("Modification of shared Cluster Operator configuration")
     @Tag(CONNECT)
+    @Tag(CONNECT_COMPONENTS)
     @Tag(REGRESSION)
     @Tag(INTERNAL_CLIENTS_USED)
     void testRackAwareConnectWrongDeployment(ExtensionContext extensionContext) {
@@ -248,6 +250,7 @@ void testRackAwareConnectWrongDeployment(ExtensionContext extensionContext) {
 
     @IsolatedTest("Modification of shared Cluster Operator configuration")
     @Tag(CONNECT)
+    @Tag(CONNECT_COMPONENTS)
     @Tag(ACCEPTANCE)
     @Tag(INTERNAL_CLIENTS_USED)
     public void testRackAwareConnectCorrectDeployment(ExtensionContext extensionContext) {

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -85,7 +85,7 @@ public void setImage(String image) {
     }
 
     @Description("List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. " +
-            "Mirroring two topics named A and B is achieved by using the expression `'A|B'`. Or, as a special case, you can mirror all topics using the regular expression '*'. " +
+            "Mirroring two topics named A and B is achieved by using the expression `A|B`. Or, as a special case, you can mirror all topics using the regular expression `*`. " +
             "You can also specify multiple regular expressions separated by commas.")
     @DeprecatedProperty(movedToPath = "spec.include")
     @PresentInVersions("v1alpha1-v1beta2")
@@ -99,7 +99,7 @@ public void setWhitelist(String whitelist) {
     }
 
     @Description("List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. " +
-            "Mirroring two topics named A and B is achieved by using the expression `'A|B'`. Or, as a special case, you can mirror all topics using the regular expression '*'. " +
+            "Mirroring two topics named A and B is achieved by using the expression `A|B`. Or, as a special case, you can mirror all topics using the regular expression `*`. " +
             "You can also specify multiple regular expressions separated by commas.")
     public String getInclude() {
         return include;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/arraylistener/GenericKafkaListenerConfiguration.java
Patch:
@@ -84,7 +84,7 @@ public void setIngressClass(String ingressClass) {
 
     @Description("Defines which address type should be used as the node address. " +
             "Available types are: `ExternalDNS`, `ExternalIP`, `InternalDNS`, `InternalIP` and `Hostname`. " +
-            "By default, the addresses will be used in the following order (the first one found will be used):\n" +
+            "By default, the addresses will be used in the following order (the first one found will be used):\n\n" +
             "* `ExternalDNS`\n" +
             "* `ExternalIP`\n" +
             "* `InternalDNS`\n" +

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -22,7 +22,6 @@
 import io.fabric8.kubernetes.api.model.Service;
 import io.fabric8.kubernetes.api.model.ServicePort;
 import io.fabric8.kubernetes.api.model.Volume;
-import io.fabric8.kubernetes.api.model.VolumeBuilder;
 import io.fabric8.kubernetes.api.model.VolumeMount;
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
 import io.fabric8.kubernetes.api.model.networking.v1.HTTPIngressPath;
@@ -1410,15 +1409,15 @@ private List<Volume> getVolumes(boolean isOpenShift) {
         List<Volume> volumeList = new ArrayList<>(dataVolumes);
 
         if (rack != null || isExposedWithNodePort()) {
-            volumeList.add(VolumeUtils.createEmptyDirVolume(INIT_VOLUME_NAME, null));
+            volumeList.add(VolumeUtils.createEmptyDirVolume(INIT_VOLUME_NAME, "100Ki", "Memory"));
         }
 
         volumeList.add(createTempDirVolume());
         volumeList.add(VolumeUtils.createSecretVolume(CLUSTER_CA_CERTS_VOLUME, AbstractModel.clusterCaCertSecretName(cluster), isOpenShift));
         volumeList.add(VolumeUtils.createSecretVolume(BROKER_CERTS_VOLUME, KafkaCluster.brokersSecretName(cluster), isOpenShift));
         volumeList.add(VolumeUtils.createSecretVolume(CLIENT_CA_CERTS_VOLUME, KafkaCluster.clientsCaCertSecretName(cluster), isOpenShift));
         volumeList.add(VolumeUtils.createConfigMapVolume(logAndMetricsConfigVolumeName, ancillaryConfigMapName));
-        volumeList.add(new VolumeBuilder().withName("ready-files").withNewEmptyDir().withMedium("Memory").endEmptyDir().build());
+        volumeList.add(VolumeUtils.createEmptyDirVolume("ready-files", "1Ki", "Memory"));
 
         for (GenericKafkaListener listener : listeners) {
             if (listener.isTls()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -344,7 +344,7 @@ protected List<Volume> getVolumes(boolean isOpenShift) {
         volumeList.add(VolumeUtils.createConfigMapVolume(logAndMetricsConfigVolumeName, ancillaryConfigMapName));
 
         if (rack != null) {
-            volumeList.add(VolumeUtils.createEmptyDirVolume(INIT_VOLUME_NAME, null));
+            volumeList.add(VolumeUtils.createEmptyDirVolume(INIT_VOLUME_NAME, "10Ki", "Memory"));
         }
 
         if (tls != null) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -584,7 +584,7 @@ private List<Volume> getVolumes(boolean isOpenShift) {
 
         if (storage instanceof EphemeralStorage) {
             String sizeLimit = ((EphemeralStorage) storage).getSizeLimit();
-            volumeList.add(VolumeUtils.createEmptyDirVolume(VOLUME_NAME, sizeLimit));
+            volumeList.add(VolumeUtils.createEmptyDirVolume(VOLUME_NAME, sizeLimit, null));
         }
 
         volumeList.add(createTempDirVolume());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -305,10 +305,12 @@ public void testGenerateDeployment() {
         volume = volumes.stream().filter(vol -> AbstractModel.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME.equals(vol.getName())).findFirst().orElseThrow();
         assertThat(volume, is(notNullValue()));
         assertThat(volume.getEmptyDir().getMedium(), is("Memory"));
+        assertThat(volume.getEmptyDir().getSizeLimit(), is(new Quantity("1Mi")));
 
         volume = volumes.stream().filter(vol -> CruiseControl.TLS_SIDECAR_TMP_DIRECTORY_DEFAULT_VOLUME_NAME.equals(vol.getName())).findFirst().orElseThrow();
         assertThat(volume, is(notNullValue()));
         assertThat(volume.getEmptyDir().getMedium(), is("Memory"));
+        assertThat(volume.getEmptyDir().getSizeLimit(), is(new Quantity("1Mi")));
 
         // Test volume mounts
         // TLS sidecar container

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaExporterTest.java
Patch:
@@ -13,6 +13,7 @@
 import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
 import io.fabric8.kubernetes.api.model.NodeSelectorTermBuilder;
 import io.fabric8.kubernetes.api.model.OwnerReference;
+import io.fabric8.kubernetes.api.model.Quantity;
 import io.fabric8.kubernetes.api.model.ServiceAccount;
 import io.fabric8.kubernetes.api.model.Toleration;
 import io.fabric8.kubernetes.api.model.TolerationBuilder;
@@ -191,6 +192,7 @@ public void testGenerateDeployment() {
         Volume volume = volumes.stream().filter(vol -> AbstractModel.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME.equals(vol.getName())).findFirst().orElseThrow();
         assertThat(volume, is(notNullValue()));
         assertThat(volume.getEmptyDir().getMedium(), is("Memory"));
+        assertThat(volume.getEmptyDir().getSizeLimit(), is(new Quantity("1Mi")));
 
         volume = volumes.stream().filter(vol -> KafkaExporter.CLUSTER_CA_CERTS_VOLUME_NAME.equals(vol.getName())).findFirst().orElseThrow();
         assertThat(volume, is(notNullValue()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -290,6 +290,8 @@ private void checkStatefulSet(StatefulSet sts) {
         assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(ZookeeperCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)));
         assertThat(containers.get(0).getVolumeMounts().get(0).getName(), is(AbstractModel.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME));
         assertThat(containers.get(0).getVolumeMounts().get(0).getMountPath(), is(AbstractModel.STRIMZI_TMP_DIRECTORY_DEFAULT_MOUNT_PATH));
+        assertThat(containers.get(0).getVolumeMounts().get(0).getName(), is(AbstractModel.STRIMZI_TMP_DIRECTORY_DEFAULT_VOLUME_NAME));
+        assertThat(containers.get(0).getVolumeMounts().get(0).getMountPath(), is(AbstractModel.STRIMZI_TMP_DIRECTORY_DEFAULT_MOUNT_PATH));
         assertThat(containers.get(0).getVolumeMounts().get(3).getName(), is(ZookeeperCluster.ZOOKEEPER_NODE_CERTIFICATES_VOLUME_NAME));
         assertThat(containers.get(0).getVolumeMounts().get(3).getMountPath(), is(ZookeeperCluster.ZOOKEEPER_NODE_CERTIFICATES_VOLUME_MOUNT));
         assertThat(containers.get(0).getVolumeMounts().get(4).getName(), is(ZookeeperCluster.ZOOKEEPER_CLUSTER_CA_VOLUME_NAME));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -527,6 +527,7 @@ public void testConnectorNotReadyWhenConnectNotConfiguredForConnectors() {
         KafkaConnector connector = new KafkaConnectorBuilder()
                 .withNewMetadata()
                     .withName(connectorName)
+                    .withNamespace(NAMESPACE)
                     .addToLabels(Labels.STRIMZI_CLUSTER_LABEL, connectName)
                 .endMetadata()
                 .withNewSpec().endSpec()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -179,7 +179,6 @@ public void test(VertxTestContext context) {
 
                 assertThat(registry.get(AbstractOperator.METRICS_PREFIX + "reconciliations").tag("kind", KafkaConnector.RESOURCE_KIND).counter().count(), CoreMatchers.is(2.0));
                 assertThat(registry.get(AbstractOperator.METRICS_PREFIX + "reconciliations.successful").tag("kind", KafkaConnector.RESOURCE_KIND).counter().count(), CoreMatchers.is(2.0));
-                assertThat(registry.get(AbstractOperator.METRICS_PREFIX + "reconciliations.failed").tag("kind", KafkaConnector.RESOURCE_KIND).counter().count(), CoreMatchers.is(0.0));
 
                 assertThat(registry.get(AbstractOperator.METRICS_PREFIX + "reconciliations.duration").tag("kind", KafkaConnector.RESOURCE_KIND).timer().count(), CoreMatchers.is(2L));
                 assertThat(registry.get(AbstractOperator.METRICS_PREFIX + "reconciliations.duration").tag("kind", KafkaConnector.RESOURCE_KIND).timer().totalTime(TimeUnit.MILLISECONDS), greaterThan(0.0));

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -322,6 +322,7 @@ public interface Constants {
      * Auxiliary variables for storing data across our tests
      */
     String NAMESPACE_KEY = "NAMESPACE_NAME";
+    String PREPARE_OPERATOR_ENV_KEY = "PREPARE_OPERATOR_ENV";
 
     /**
      * Auxiliary variable for cluster operator deployment

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -42,6 +42,7 @@
 import io.strimzi.systemtest.resources.kubernetes.JobResource;
 import io.strimzi.systemtest.resources.kubernetes.NetworkPolicyResource;
 import io.strimzi.systemtest.resources.kubernetes.RoleBindingResource;
+import io.strimzi.systemtest.resources.kubernetes.RoleResource;
 import io.strimzi.systemtest.resources.kubernetes.ServiceResource;
 import io.strimzi.systemtest.resources.operator.BundleResource;
 import io.strimzi.systemtest.utils.StUtils;
@@ -119,7 +120,8 @@ public static HelmClient helmClient() {
         new JobResource(),
         new NetworkPolicyResource(),
         new RoleBindingResource(),
-        new ServiceResource()
+        new ServiceResource(),
+        new RoleResource()
     };
 
     @SafeVarargs

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/specific/HelmResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.resources.specific;
+package io.strimzi.systemtest.resources.operator.specific;
 
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/specific/OlmResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.resources.specific;
+package io.strimzi.systemtest.resources.operator.specific;
 
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/specific/SpecificResourceType.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.resources.specific;
+package io.strimzi.systemtest.resources.operator.specific;
 
 import org.junit.jupiter.api.extension.ExtensionContext;
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/OlmUtils.java
Patch:
@@ -5,7 +5,7 @@
 package io.strimzi.systemtest.utils.specific;
 
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.resources.specific.OlmResource;
+import io.strimzi.systemtest.resources.operator.specific.OlmResource;
 import io.strimzi.test.TestUtils;
 
 public class OlmUtils {

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -15,8 +15,9 @@
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.interfaces.IndicativeSentences;
 import io.strimzi.systemtest.logs.TestExecutionWatcher;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.resources.kubernetes.NetworkPolicyResource;
-import io.strimzi.systemtest.resources.specific.OlmResource;
+import io.strimzi.systemtest.resources.operator.specific.OlmResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;

File: systemtest/src/test/java/io/strimzi/systemtest/backup/ColdBackupScriptST.java
Patch:
@@ -12,7 +12,7 @@
 
 import java.util.Map;
 
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import org.apache.logging.log4j.LogManager;
@@ -76,6 +76,8 @@ void backupAndRestore(ExtensionContext context) {
         // recreate the namespace and deploy the operator
         ResourceManager.kubeClient().deleteNamespace(NAMESPACE);
         NamespaceUtils.waitForNamespaceDeletion(NAMESPACE);
+        // This is needed to allow installation of new operator and creation of the namespace
+        context.getStore(ExtensionContext.Namespace.GLOBAL).put(Constants.PREPARE_OPERATOR_ENV_KEY + NAMESPACE, null);
 
         install = new SetupClusterOperator.SetupClusterOperatorBuilder()
             .withExtensionContext(context)

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeCorsST.java
Patch:
@@ -8,7 +8,7 @@
 import io.strimzi.api.kafka.model.KafkaBridgeResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -17,7 +17,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.resources.kubernetes.ServiceResource;

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -13,7 +13,7 @@
 import io.strimzi.api.kafka.model.template.DeploymentStrategy;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -12,7 +12,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -11,7 +11,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectBuilderST.java
Patch:
@@ -23,7 +23,7 @@
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -34,7 +34,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlApiST.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlEndpoints;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlUserTaskStatus;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlConfigurationST.java
Patch:
@@ -14,7 +14,7 @@
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlConfigurationParameters;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -37,7 +37,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.cli.KafkaCmdClient;

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/QuotasST.java
Patch:
@@ -7,7 +7,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java
Patch:
@@ -11,7 +11,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaResource;

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationSharedST.java
Patch:
@@ -9,7 +9,7 @@
 import io.strimzi.kafka.config.model.Type;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.utils.TestKafkaVersion;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/ListenersST.java
Patch:
@@ -17,7 +17,7 @@
 import io.strimzi.api.kafka.model.status.ListenerStatus;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java
Patch:
@@ -10,7 +10,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
Patch:
@@ -18,7 +18,7 @@
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -22,7 +22,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.enums.CustomResourceStatus;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/JmxST.java
Patch:
@@ -10,7 +10,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -25,7 +25,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -22,7 +22,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerST.java
Patch:
@@ -21,7 +21,7 @@
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;

File: systemtest/src/test/java/io/strimzi/systemtest/olm/AllNamespacesST.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.olm;
 
-import io.strimzi.systemtest.resources.specific.OlmResource;
+import io.strimzi.systemtest.resources.operator.specific.OlmResource;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.MethodOrderer;
 import org.junit.jupiter.api.Order;

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAbstractST.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.api.kafka.model.balancing.KafkaRebalanceState;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
-import io.strimzi.systemtest.resources.specific.OlmResource;
+import io.strimzi.systemtest.resources.operator.specific.OlmResource;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;

File: systemtest/src/test/java/io/strimzi/systemtest/olm/SingleNamespaceST.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.olm;
 
-import io.strimzi.systemtest.resources.specific.OlmResource;
+import io.strimzi.systemtest.resources.operator.specific.OlmResource;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusST.java
Patch:
@@ -33,7 +33,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceDeletionRecoveryST.java
Patch:
@@ -13,7 +13,7 @@
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ReconciliationST.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.enums.CustomResourceStatus;
 import io.strimzi.systemtest.resources.ResourceOperation;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -11,7 +11,7 @@
 import io.strimzi.api.kafka.model.status.KafkaTopicStatus;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.cli.KafkaCmdClient;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicScalabilityST.java
Patch:
@@ -5,7 +5,7 @@
 package io.strimzi.systemtest.operators.topic;
 
 import io.strimzi.systemtest.AbstractST;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserST.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -19,7 +19,7 @@
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaResource;

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerST.java
Patch:
@@ -24,7 +24,7 @@
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -22,7 +22,7 @@
 import io.strimzi.api.kafka.model.ProbeBuilder;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java
Patch:
@@ -16,7 +16,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.metrics.MetricsCollector;

File: systemtest/src/test/java/io/strimzi/systemtest/security/OpaIntegrationST.java
Patch:
@@ -10,7 +10,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -27,7 +27,7 @@
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/security/custom/CustomAuthorizerST.java
Patch:
@@ -13,7 +13,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelTest;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.fabric8.kubernetes.api.model.batch.v1.Job;
 import io.strimzi.systemtest.AbstractST;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.enums.DefaultNetworkPolicy;
 import io.strimzi.systemtest.keycloak.KeycloakInstance;
 import io.strimzi.systemtest.templates.kubernetes.NetworkPolicyTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/specific/ClusterOperationST.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.AbstractST;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.annotations.MultiNodeClusterOnly;
 import io.strimzi.systemtest.annotations.RequiredMinKubeApiVersion;

File: systemtest/src/test/java/io/strimzi/systemtest/specific/HelmChartST.java
Patch:
@@ -8,7 +8,7 @@
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.AbstractST;
-import io.strimzi.systemtest.resources.specific.HelmResource;
+import io.strimzi.systemtest.resources.operator.specific.HelmResource;
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -12,7 +12,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.ParallelNamespaceTest;
 import io.strimzi.systemtest.resources.ResourceItem;
 import io.strimzi.systemtest.resources.ResourceManager;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java
Patch:
@@ -9,7 +9,7 @@
 import io.strimzi.systemtest.enums.OlmInstallationStrategy;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;
-import io.strimzi.systemtest.resources.specific.OlmResource;
+import io.strimzi.systemtest.resources.operator.specific.OlmResource;
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.FileUtils;
 import io.strimzi.systemtest.utils.TestKafkaVersion;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziDowngradeST.java
Patch:
@@ -60,7 +60,7 @@ private void performDowngrade(JsonObject testParameters, ExtensionContext extens
         setupEnvAndUpgradeClusterOperator(extensionContext, testParameters, producerName, consumerName, continuousTopicName, continuousConsumerGroup, testParameters.getString("deployKafkaVersion"), NAMESPACE);
         logPodImages(clusterName);
         // Downgrade CO
-        changeClusterOperator(testParameters, NAMESPACE);
+        changeClusterOperator(testParameters, NAMESPACE, extensionContext);
         // Wait for Kafka cluster rolling update
         waitForKafkaClusterRollingUpdate();
         logPodImages(clusterName);

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceST.java
Patch:
@@ -13,7 +13,7 @@
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/MultipleNamespaceST.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.SetupClusterOperator;
+import io.strimzi.systemtest.resources.operator.SetupClusterOperator;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;

File: operator-common/src/main/java/io/strimzi/operator/common/AbstractOperator.java
Patch:
@@ -563,7 +563,7 @@ private void updateResourceState(Reconciliation reconciliation, boolean ready, T
             LOGGER.debugCr(reconciliation, "Removed metric " + METRICS_PREFIX + "resource.state{}", key);
         }
 
-        if (cr != null) {
+        if (cr != null && Util.matchesSelector(selector(), cr)) {
             resourcesStateCounter.computeIfAbsent(key, tags ->
                     metrics.gauge(METRICS_PREFIX + "resource.state", "Current state of the resource: 1 ready, 0 fail", metricTags)
             );

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -29,7 +29,7 @@
 @JsonPropertyOrder({
         "version", "replicas", "image", "consumer", "producer", "resources", "whitelist", "include", "jvmOptions",
         "logging", "metricsConfig", "tracing", "template"})
-@OneOf({@OneOf.Alternative(@OneOf.Alternative.Property("whitelist")), @OneOf.Alternative(@OneOf.Alternative.Property("include"))})
+@OneOf({@OneOf.Alternative(@OneOf.Alternative.Property("include")), @OneOf.Alternative(@OneOf.Alternative.Property("whitelist"))})
 @EqualsAndHashCode
 public class KafkaMirrorMakerSpec extends Spec implements HasConfigurableMetrics {
     private static final long serialVersionUID = 1L;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -77,7 +77,6 @@ public class EntityUserOperatorTest {
     private final String uoImage = "my-user-operator-image";
     private final String secretPrefix = "strimzi-";
     private final int uoReconciliationInterval = 120;
-    private final int uoZookeeperSessionTimeout = 18;
 
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
     private final String metricsCMName = "metrics-cm";
@@ -92,7 +91,6 @@ public class EntityUserOperatorTest {
             .withWatchedNamespace(uoWatchedNamespace)
             .withImage(uoImage)
             .withReconciliationIntervalSeconds(uoReconciliationInterval)
-            .withZookeeperSessionTimeoutSeconds(uoZookeeperSessionTimeout)
             .withSecretPrefix(secretPrefix)
             .withLivenessProbe(livenessProbe)
             .withReadinessProbe(readinessProbe)

File: api/src/main/java/io/strimzi/api/kafka/Crds.java
Patch:
@@ -155,7 +155,7 @@ private static CustomResourceDefinition crd(Class<? extends CustomResource> cls)
         List<CustomResourceDefinitionVersion> crVersions = new ArrayList<>(versions.size());
         for (String apiVersion : versions)  {
             crVersions.add(new CustomResourceDefinitionVersionBuilder()
-                    .withNewName(apiVersion)
+                    .withName(apiVersion)
                     .withNewSubresources()
                         .withStatus(status)
                     .endSubresources()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CaRenewalTest.java
Patch:
@@ -117,7 +117,7 @@ protected CertAndKey generateSignedCert(Subject subject,
 
         Secret initialSecret = new SecretBuilder()
                 .withNewMetadata()
-                    .withNewName("test-secret")
+                    .withName("test-secret")
                 .endMetadata()
                 .addToData("pod0.crt", Base64.getEncoder().encodeToString("old-cert".getBytes()))
                 .addToData("pod0.key", Base64.getEncoder().encodeToString("old-key".getBytes()))
@@ -203,7 +203,7 @@ protected CertAndKey generateSignedCert(Subject subject,
 
         Secret initialSecret = new SecretBuilder()
                 .withNewMetadata()
-                .withNewName("test-secret")
+                .withName("test-secret")
                 .endMetadata()
                 .addToData("pod0.crt", Base64.getEncoder().encodeToString("old-cert".getBytes()))
                 .addToData("pod0.key", Base64.getEncoder().encodeToString("old-key".getBytes()))
@@ -289,7 +289,7 @@ protected CertAndKey generateSignedCert(Subject subject,
 
         Secret initialSecret = new SecretBuilder()
                 .withNewMetadata()
-                .withNewName("test-secret")
+                .withName("test-secret")
                 .endMetadata()
                 .addToData("pod0.crt", Base64.getEncoder().encodeToString("old-cert".getBytes()))
                 .addToData("pod0.key", Base64.getEncoder().encodeToString("old-key".getBytes()))

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -537,8 +537,8 @@ public void testTemplate() {
                                     .withLabels(podLabels)
                                     .withAnnotations(podAnots)
                                 .endMetadata()
-                                .withNewPriorityClassName("top-priority")
-                                .withNewSchedulerName("my-scheduler")
+                                .withPriorityClassName("top-priority")
+                                .withSchedulerName("my-scheduler")
                                 .withHostAliases(hostAlias1, hostAlias2)
                                 .withAffinity(affinity)
                                 .withTolerations(tolerations)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -226,8 +226,8 @@ public void testTemplate() {
                                             .withLabels(podLabels)
                                             .withAnnotations(podAnots)
                                         .endMetadata()
-                                        .withNewPriorityClassName("top-priority")
-                                        .withNewSchedulerName("my-scheduler")
+                                        .withPriorityClassName("top-priority")
+                                        .withSchedulerName("my-scheduler")
                                         .withTolerations(singletonList(toleration))
                                         .withTopologySpreadConstraints(tsc1, tsc2)
                                         .withEnableServiceLinks(false)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/JmxTransTest.java
Patch:
@@ -241,8 +241,8 @@ public void testTemplate() {
                                     .withLabels(podLabels)
                                     .withAnnotations(podAnots)
                                 .endMetadata()
-                                .withNewPriorityClassName("top-priority")
-                                .withNewSchedulerName("my-scheduler")
+                                .withPriorityClassName("top-priority")
+                                .withSchedulerName("my-scheduler")
                                 .withAffinity(affinity)
                                 .withTolerations(tolerations)
                                 .withEnableServiceLinks(false)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -418,8 +418,8 @@ public void testTemplate() {
                                 .withLabels(podLabels)
                                 .withAnnotations(podAnots)
                             .endMetadata()
-                            .withNewPriorityClassName("top-priority")
-                            .withNewSchedulerName("my-scheduler")
+                            .withPriorityClassName("top-priority")
+                            .withSchedulerName("my-scheduler")
                             .withAffinity(affinity)
                             .withTolerations(tolerations)
                             .withTopologySpreadConstraints(tsc1, tsc2)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -1055,7 +1055,7 @@ public void testWithExternalListenersNodePortWithoutTls()  {
     public void testWithExternalListenersIngress()  {
         GenericKafkaListenerConfigurationBroker broker = new GenericKafkaListenerConfigurationBrokerBuilder()
                 .withBroker(0)
-                .withNewHost("broker-0.mytld.com")
+                .withHost("broker-0.mytld.com")
                 .build();
 
         GenericKafkaListener listener = new GenericKafkaListenerBuilder()
@@ -1064,9 +1064,9 @@ public void testWithExternalListenersIngress()  {
                 .withType(KafkaListenerType.INGRESS)
                 .withTls(true)
                 .withNewConfiguration()
-                    .withNewIngressClass("nginx-ingress")
+                    .withIngressClass("nginx-ingress")
                     .withNewBootstrap()
-                        .withNewHost("bootstrap.mytld.com")
+                        .withHost("bootstrap.mytld.com")
                     .endBootstrap()
                     .withBrokers(broker)
                 .endConfiguration()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectBuildTest.java
Patch:
@@ -416,8 +416,8 @@ public void testTemplate()   {
                                 .withLabels(buildPodLabels)
                                 .withAnnotations(buildPodAnnos)
                             .endMetadata()
-                            .withNewPriorityClassName("top-priority")
-                            .withNewSchedulerName("my-scheduler")
+                            .withPriorityClassName("top-priority")
+                            .withSchedulerName("my-scheduler")
                             .withEnableServiceLinks(false)
                         .endBuildPod()
                         .withNewBuildContainer()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -587,8 +587,8 @@ public void testTemplate() {
                                 .withLabels(podLabels)
                                 .withAnnotations(podAnots)
                             .endMetadata()
-                            .withNewPriorityClassName("top-priority")
-                            .withNewSchedulerName("my-scheduler")
+                            .withPriorityClassName("top-priority")
+                            .withSchedulerName("my-scheduler")
                             .withHostAliases(hostAlias1, hostAlias2)
                             .withTopologySpreadConstraints(tsc1, tsc2)
                             .withEnableServiceLinks(false)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaExporterTest.java
Patch:
@@ -391,7 +391,7 @@ public void testTemplate() {
                                     .withLabels(podLabels)
                                     .withAnnotations(podAnots)
                                 .endMetadata()
-                                .withNewPriorityClassName("top-priority")
+                                .withPriorityClassName("top-priority")
                                 .withNewSchedulerName("my-scheduler")
                                 .withAffinity(affinity)
                                 .withTolerations(tolerations)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -722,8 +722,8 @@ public void testTemplate() {
                                 .withLabels(podLabels)
                                 .withAnnotations(podAnots)
                             .endMetadata()
-                            .withNewPriorityClassName("top-priority")
-                            .withNewSchedulerName("my-scheduler")
+                            .withPriorityClassName("top-priority")
+                            .withSchedulerName("my-scheduler")
                             .withHostAliases(hostAlias1, hostAlias2)
                             .withEnableServiceLinks(false)
                         .endPod()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -552,8 +552,8 @@ public void testTemplate() {
                                 .withLabels(podLabels)
                                 .withAnnotations(podAnots)
                             .endMetadata()
-                            .withNewPriorityClassName("top-priority")
-                            .withNewSchedulerName("my-scheduler")
+                            .withPriorityClassName("top-priority")
+                            .withSchedulerName("my-scheduler")
                             .withHostAliases(hostAlias1, hostAlias2)
                             .withEnableServiceLinks(false)
                         .endPod()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -436,8 +436,8 @@ image, healthDelay, healthTimeout, jmxMetricsConfig, configurationJson, emptyMap
                                     .withLabels(podLabels)
                                     .withAnnotations(podAnots)
                                 .endMetadata()
-                                .withNewPriorityClassName("top-priority")
-                                .withNewSchedulerName("my-scheduler")
+                                .withPriorityClassName("top-priority")
+                                .withSchedulerName("my-scheduler")
                                 .withHostAliases(hostAlias1, hostAlias2)
                                 .withTopologySpreadConstraints(tsc1, tsc2)
                                 .withEnableServiceLinks(false)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorCustomCertTest.java
Patch:
@@ -197,7 +197,7 @@ public Kafka createKafka() {
     public Secret getTlsSecret() {
         return new SecretBuilder()
                 .withNewMetadata()
-                    .withNewName("my-tls-secret")
+                    .withName("my-tls-secret")
                 .endMetadata()
                 .addToData("tls.crt", "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")
                 .addToData("tls.key", "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")
@@ -211,7 +211,7 @@ public String getTlsThumbprint()    {
     public Secret getExternalSecret() {
         return new SecretBuilder()
                 .withNewMetadata()
-                    .withNewName("my-external-secret")
+                    .withName("my-external-secret")
                 .endMetadata()
                 .addToData("tls.crt", "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")
                 .addToData("tls.key", "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")
@@ -221,7 +221,7 @@ public Secret getExternalSecret() {
     public Pod getPod(StatefulSet sts) {
         return new PodBuilder()
                 .withNewMetadataLike(sts.getSpec().getTemplate().getMetadata())
-                    .withNewName(KafkaCluster.kafkaClusterName(clusterName) + "-0")
+                    .withName(KafkaCluster.kafkaClusterName(clusterName) + "-0")
                 .endMetadata()
                 .withNewSpecLike(sts.getSpec().getTemplate().getSpec())
                 .endSpec()

File: mockkube/src/main/java/io/strimzi/test/mockkube/MockKube.java
Patch:
@@ -346,7 +346,7 @@ public KubernetesClient build() {
         when(mockClient.rbac()).thenReturn(rbac);
         roleBindingMockBuilder.build2(mockClient.rbac()::roleBindings);
         roleMockBuilder.build2(mockClient.rbac()::roles);
-        clusterRoleBindingMockBuilder.build2(mockClient.rbac()::clusterRoleBindings);
+        clusterRoleBindingMockBuilder.buildNns(mockClient.rbac()::clusterRoleBindings);
 
         // Openshift group
         OpenShiftClient mockOpenShiftClient = mock(OpenShiftClient.class);

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ClusterRoleBindingOperator.java
Patch:
@@ -7,7 +7,7 @@
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingList;
 import io.fabric8.kubernetes.client.KubernetesClient;
-import io.fabric8.kubernetes.client.dsl.MixedOperation;
+import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.vertx.core.Vertx;
 
@@ -24,7 +24,7 @@ public ClusterRoleBindingOperator(Vertx vertx, KubernetesClient client) {
     }
 
     @Override
-    protected MixedOperation<ClusterRoleBinding, ClusterRoleBindingList, Resource<ClusterRoleBinding>> operation() {
+    protected NonNamespaceOperation<ClusterRoleBinding, ClusterRoleBindingList, Resource<ClusterRoleBinding>> operation() {
         return client.rbac().clusterRoleBindings();
     }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ClusterRoleOperator.java
Patch:
@@ -9,7 +9,7 @@
 import io.fabric8.kubernetes.api.model.rbac.ClusterRole;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleList;
 import io.fabric8.kubernetes.client.KubernetesClient;
-import io.fabric8.kubernetes.client.dsl.MixedOperation;
+import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.vertx.core.Vertx;
 
@@ -28,8 +28,8 @@ public ClusterRoleOperator(Vertx vertx, KubernetesClient client) {
     }
 
     @Override
-    protected MixedOperation<ClusterRole, ClusterRoleList,
-            Resource<ClusterRole>> operation() {
+    protected NonNamespaceOperation<ClusterRole, ClusterRoleList,
+                Resource<ClusterRole>> operation() {
         return client.rbac().clusterRoles();
     }
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -109,7 +109,7 @@ public Future<T> updateStatusAsync(Reconciliation reconciliation, T resource) {
             String name = resource.getMetadata().getName();
 
             try {
-                T result = operation().inNamespace(namespace).withName(name).updateStatus(resource);
+                T result = operation().inNamespace(namespace).withName(name).replaceStatus(resource);
                 LOGGER.infoCr(reconciliation, "Status of {} {} in namespace {} has been updated", resourceKind, name, namespace);
                 future.complete(result);
             } catch (Exception e) {

File: operator-common/src/test/java/io/strimzi/operator/common/UtilTest.java
Patch:
@@ -148,7 +148,7 @@ public void testVarExpansion() {
     public void testMatchesSelector()   {
         Pod testResource = new PodBuilder()
                 .withNewMetadata()
-                    .withNewName("test-pod")
+                    .withName("test-pod")
                 .endMetadata()
                 .withNewSpec()
                 .endSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/model/LabelsTest.java
Patch:
@@ -277,7 +277,7 @@ public void setApiVersion(String apiVersion) {
         expectedLabels.put(Labels.KUBERNETES_PART_OF_LABEL, Labels.APPLICATION_NAME + "-" + instance);
 
         Labels l = Labels.generateDefaultLabels(new ResourceWithMetadata("MyResource", "strimzi.io/v0", new ObjectMetaBuilder()
-            .withNewName(instance)
+            .withName(instance)
             .build()), appName, operatorName);
 
         assertThat(l.toMap(), is(expectedLabels));

File: test/src/main/java/io/strimzi/test/k8s/KubeClient.java
Patch:
@@ -817,15 +817,15 @@ public RoleBinding createOrReplaceRoleBinding(RoleBinding roleBinding) {
     }
 
     public ClusterRoleBinding createOrReplaceClusterRoleBinding(ClusterRoleBinding clusterRoleBinding) {
-        return client.rbac().clusterRoleBindings().inNamespace(getNamespace()).createOrReplace(clusterRoleBinding);
+        return client.rbac().clusterRoleBindings().createOrReplace(clusterRoleBinding);
     }
 
     public Boolean deleteClusterRoleBinding(ClusterRoleBinding clusterRoleBinding) {
-        return client.rbac().clusterRoleBindings().inNamespace(getNamespace()).delete(clusterRoleBinding);
+        return client.rbac().clusterRoleBindings().delete(clusterRoleBinding);
     }
 
     public ClusterRoleBinding getClusterRoleBinding(String name) {
-        return client.rbac().clusterRoleBindings().inNamespace(getNamespace()).withName(name).get();
+        return client.rbac().clusterRoleBindings().withName(name).get();
     }
 
     public List<RoleBinding> listRoleBindings(String namespaceName) {

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -634,7 +634,7 @@ void testDynamicallySetClusterOperatorLoggingLevels(ExtensionContext extensionCo
         long reconciliationSleep = RECONCILIATION_INTERVAL + Duration.ofSeconds(10).toMillis();
         LOGGER.info("Waiting {} ms log not to be empty", reconciliationSleep);
         // wait enough time (at least for reconciliation time + 10) and check whether logs after this time are not empty
-        Thread.sleep(reconciliationSleep);
+        Thread.sleep(reconciliationSleep * 2);
 
         LOGGER.info("Asserting if log will contain no records");
         String coLog = StUtils.getLogFromPodByTime(NAMESPACE, coPodName, STRIMZI_DEPLOYMENT_NAME, "30s");

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -326,6 +326,7 @@ void testSendingMessagesToNonExistingTopic(ExtensionContext extensionContext) {
         created = hasTopicInKafka(topicName, TOPIC_CLUSTER_NAME);
         assertThat(created, is(true));
 
+        KafkaTopicUtils.waitForKafkaTopicCreation(topicName);
         KafkaTopic kafkaTopic = KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(topicName).get();
         assertThat(kafkaTopic, notNullValue());
 

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -432,11 +432,11 @@ void testAddingAndRemovingJbodVolumes(ExtensionContext extensionContext) {
 
     @BeforeAll
     void setup(ExtensionContext extensionContext) {
+        // CO_OPERATION_TIMEOUT_DEFAULT is set here for ensuring that all operations will be fulfilled successfully
         install = new SetupClusterOperator.SetupClusterOperatorBuilder()
             .withExtensionContext(extensionContext)
             .withNamespace(NAMESPACE)
             .withWatchingNamespaces(Constants.WATCH_ALL_NAMESPACES)
-            .withOperationTimeout(Constants.CO_OPERATION_TIMEOUT_SHORT)
             .createInstallation()
             .runInstallation();
     }

File: api/src/main/java/io/strimzi/api/kafka/model/EntityTopicOperatorSpec.java
Patch:
@@ -44,6 +44,7 @@ public class EntityTopicOperatorSpec implements UnknownPropertyPreserving, Seria
     public static final int DEFAULT_FULL_RECONCILIATION_INTERVAL_SECONDS = 120;
     public static final int DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS = 18;
     public static final int DEFAULT_TOPIC_METADATA_MAX_ATTEMPTS = 6;
+    public static final String DEFAULT_SECURITY_PROTOCOL = "SSL";
 
     protected String watchedNamespace;
     protected String image;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -113,6 +113,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_FULL_RECONCILIATION_INTERVAL_MS).withValue(String.valueOf(toReconciliationInterval * 1000)).build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_ZOOKEEPER_SESSION_TIMEOUT_MS).withValue(String.valueOf(toZookeeperSessionTimeout * 1000)).build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_TOPIC_METADATA_MAX_ATTEMPTS).withValue(String.valueOf(toTopicMetadataMaxAttempts)).build());
+        expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_SECURITY_PROTOCOL).withValue(EntityTopicOperatorSpec.DEFAULT_SECURITY_PROTOCOL).build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_TLS_ENABLED).withValue(Boolean.toString(true)).build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_JAVA_OPTS).withValue("-Xms128m").build());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -673,13 +673,13 @@ public void testUserOperatorContainerEnvVars() {
     @ParallelTest
     public void testUserOperatorContainerEnvVarsConflict() {
         ContainerEnvVar envVar1 = new ContainerEnvVar();
-        String testEnvOneKey = EntityUserOperator.ENV_VAR_ZOOKEEPER_CONNECT;
+        String testEnvOneKey = EntityUserOperator.ENV_VAR_FULL_RECONCILIATION_INTERVAL_MS;
         String testEnvOneValue = "test.env.one";
         envVar1.setName(testEnvOneKey);
         envVar1.setValue(testEnvOneValue);
 
         ContainerEnvVar envVar2 = new ContainerEnvVar();
-        String testEnvTwoKey = EntityUserOperator.ENV_VAR_ZOOKEEPER_SESSION_TIMEOUT_MS;
+        String testEnvTwoKey = EntityUserOperator.ENV_VAR_KAFKA_BOOTSTRAP_SERVERS;
         String testEnvTwoValue = "test.env.two";
         envVar2.setName(testEnvTwoKey);
         envVar2.setValue(testEnvTwoValue);

File: systemtest/src/main/java/io/strimzi/systemtest/logs/LogCollector.java
Patch:
@@ -98,7 +98,7 @@ public LogCollector(String testSuiteName, String testCaseName, KubeClient kubeCl
     /**
      * Core method which collects all logs from events, configs-maps, pods, deployment, statefulset, replicaset...in case test fails.
      */
-    public void collect() {
+    public synchronized void collect() {
         final Set<String> namespaces = KubeClusterResource.getInstance().getMapWithSuiteNamespaces().get(this.testSuiteName);
 
         if (namespaces != null) {

File: systemtest/src/test/java/io/strimzi/systemtest/security/custom/CustomAuthorizerST.java
Patch:
@@ -201,6 +201,7 @@ public void setup(ExtensionContext extensionContext) {
                 .editKafka()
                     .withNewKafkaAuthorizationCustom()
                         .withAuthorizerClass(KafkaAuthorizationSimple.AUTHORIZER_CLASS_NAME)
+                        .withSupportsAdminApi(true)
                         .withSuperUsers("CN=" + ADMIN)
                     .endKafkaAuthorizationCustom()
                     .withListeners(new GenericKafkaListenerBuilder()

File: user-operator/src/main/java/io/strimzi/operator/user/operator/KafkaUserOperator.java
Patch:
@@ -128,7 +128,7 @@ protected Future<KafkaUserStatus> createOrUpdate(Reconciliation reconciliation,
         KafkaUserStatus userStatus = new KafkaUserStatus();
 
         try {
-            user = KafkaUserModel.fromCrd(resource, config.getSecretPrefix());
+            user = KafkaUserModel.fromCrd(resource, config.getSecretPrefix(), config.isAclsAdminApiSupported());
             LOGGER.debugCr(reconciliation, "Updating User {} in namespace {}", reconciliation.name(), reconciliation.namespace());
         } catch (Exception e) {
             LOGGER.warnCr(reconciliation, e);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/TracingUtils.java
Patch:
@@ -37,7 +37,7 @@ public static void verify(String namespaceName, String componentJaegerServiceNam
     }
 
     private static void verifyThatServiceIsPresent(String namespaceName, String componentJaegerServiceName, String clientPodName, String jaegerServiceName) {
-        TestUtils.waitFor("Service " + componentJaegerServiceName + " is present", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
+        TestUtils.waitFor("Jaeger service " + componentJaegerServiceName + " to be present", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
             JsonObject jaegerServices = new JsonObject(cmdKubeClient(namespaceName).execInPod(clientPodName, "/bin/bash", "-c", "curl " + jaegerServiceName + ":" + JAEGER_QUERY_PORT + JAEGER_QUERY_SERVICE_ENDPOINT).out());
 
             if (jaegerServices.getJsonArray("data").contains(componentJaegerServiceName)) {
@@ -51,7 +51,7 @@ private static void verifyThatServiceIsPresent(String namespaceName, String comp
     }
 
     private static void verifyThatServiceTracesArePresent(String namespaceName, String componentJaegerServiceName, String clientPodName, String operation, String jaegerServiceName) {
-        TestUtils.waitFor("Service " + componentJaegerServiceName + " has some traces", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
+        TestUtils.waitFor("Jaeger service " + componentJaegerServiceName + " has some traces", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
             String query;
             if (operation == null)  {
                 query = jaegerServiceName + ":" + JAEGER_QUERY_PORT + JAEGER_QUERY_SERVICE_TRACES_ENDPOINT + JAEGER_QUERY_SERVICE_PARAM_SERVICE + componentJaegerServiceName;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
Patch:
@@ -73,6 +73,7 @@ public void testReconciliationInterval() {
                 30_000,
                 120_000,
                 false,
+                true,
                 new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap()),
                 null,
                 null,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -748,6 +748,7 @@ public static ClusterOperatorConfig dummyClusterOperatorConfig(KafkaVersion.Look
                 operationTimeoutMs,
                 300_000,
                 false,
+                true,
                 versions,
                 null,
                 null,
@@ -766,6 +767,7 @@ public static ClusterOperatorConfig dummyClusterOperatorConfigRolesOnly(KafkaVer
                 operationTimeoutMs,
                 300_000,
                 false,
+                true,
                 versions,
                 null,
                 null,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorNonParametrizedTest.java
Patch:
@@ -439,6 +439,7 @@ public void testSelectorLabels(VertxTestContext context) {
                 120_000,
                 300_000,
                 false,
+                true,
                 KafkaVersionTestUtils.getKafkaVersionLookup(),
                 null,
                 null,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -908,6 +908,7 @@ public void testKafkaClusterNotMatchingLabelSelector(VertxTestContext context) {
                 120_000,
                 300_000,
                 false,
+                true,
                 KafkaVersionTestUtils.getKafkaVersionLookup(),
                 null,
                 null,

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaRoller.java
Patch:
@@ -453,10 +453,10 @@ private RestartPlan restartPlan(int podId, Pod pod, RestartContext restartContex
         boolean podStuck = pod != null
                 && pod.getStatus() != null
                 && "Pending".equals(pod.getStatus().getPhase())
-                && pod.getStatus().getConditions().stream().filter(ps ->
+                && pod.getStatus().getConditions().stream().anyMatch(ps ->
                 "PodScheduled".equals(ps.getType())
                         && "Unschedulable".equals(ps.getReason())
-                        && "False".equals(ps.getStatus())).findFirst().isPresent();
+                        && "False".equals(ps.getStatus()));
         if (podStuck && !reasonToRestartPod.contains("Pod has old generation")) {
             // If the pod is unschedulable then deleting it, or trying to open an Admin client to it will make no difference
             // Treat this as fatal because if it's not possible to schedule one pod then it's likely that proceeding

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/FeatureGatesTest.java
Patch:
@@ -18,14 +18,15 @@
 
 @ParallelSuite
 public class FeatureGatesTest {
+
     @ParallelTest
     public void testIndividualFeatureGates() {
         for (FeatureGates.FeatureGate gate : FeatureGates.NONE.allFeatureGates()) {
             FeatureGates enabled = new FeatureGates("+" + gate.getName());
             FeatureGates disabled = new FeatureGates("-" + gate.getName());
 
-            assertThat(enabled.allFeatureGates().stream().filter(g -> gate.getName().equals(g.getName())).findFirst().get().isEnabled(), is(true));
-            assertThat(disabled.allFeatureGates().stream().filter(g -> gate.getName().equals(g.getName())).findFirst().get().isEnabled(), is(false));
+            assertThat(enabled.allFeatureGates().stream().filter(g -> gate.getName().equals(g.getName())).findFirst().orElseThrow().isEnabled(), is(true));
+            assertThat(disabled.allFeatureGates().stream().filter(g -> gate.getName().equals(g.getName())).findFirst().orElseThrow().isEnabled(), is(false));
         }
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -300,8 +300,8 @@ image, healthDelay, healthTimeout, jmxMetricsConfig, singletonMap("foo", "bar"),
 
         EntityUserOperator f = EntityUserOperator.fromCrd(new Reconciliation("test", resource.getKind(), resource.getMetadata().getNamespace(), resource.getMetadata().getName()), kafkaAssembly);
         List<EnvVar> envvar = f.getEnvVars();
-        assertThat(Integer.parseInt(envvar.stream().filter(a -> a.getName().equals(EntityUserOperator.ENV_VAR_CLIENTS_CA_VALIDITY)).findFirst().get().getValue()), is(validity));
-        assertThat(Integer.parseInt(envvar.stream().filter(a -> a.getName().equals(EntityUserOperator.ENV_VAR_CLIENTS_CA_RENEWAL)).findFirst().get().getValue()), is(renewal));
+        assertThat(Integer.parseInt(envvar.stream().filter(a -> a.getName().equals(EntityUserOperator.ENV_VAR_CLIENTS_CA_VALIDITY)).findFirst().orElseThrow().getValue()), is(validity));
+        assertThat(Integer.parseInt(envvar.stream().filter(a -> a.getName().equals(EntityUserOperator.ENV_VAR_CLIENTS_CA_RENEWAL)).findFirst().orElseThrow().getValue()), is(renewal));
     }
 
     @ParallelTest

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectBuildTest.java
Patch:
@@ -447,7 +447,7 @@ public void testTemplate()   {
         assertThat(pod.getSpec().getPriorityClassName(), is("top-priority"));
         assertThat(pod.getSpec().getSchedulerName(), is("my-scheduler"));
         assertThat(pod.getSpec().getEnableServiceLinks(), is(false));
-        assertThat(pod.getSpec().getContainers().get(0).getEnv().stream().filter(env -> "TEST_ENV_VAR".equals(env.getName())).findFirst().get().getValue(), is("testValue"));
+        assertThat(pod.getSpec().getContainers().get(0).getEnv().stream().filter(env -> "TEST_ENV_VAR".equals(env.getName())).findFirst().orElseThrow().getValue(), is("testValue"));
 
         KafkaConnectDockerfile dockerfile = new KafkaConnectDockerfile("my-image:latest", kc.getSpec().getBuild());
         BuildConfig bc = build.generateBuildConfig(dockerfile);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -1303,5 +1303,4 @@ public void testRenewalOfDeploymentCertificatesDelayedRenewalOutsideOfMaintenanc
         assertThat(newSecret.getData(), hasEntry("deployment.p12", Base64.getEncoder().encodeToString("old-keystore".getBytes())));
         assertThat(newSecret.getData(), hasEntry("deployment.password", Base64.getEncoder().encodeToString("old-password".getBytes())));
     }
-
 }
\ No newline at end of file

File: crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java
Patch:
@@ -413,7 +413,9 @@ private ObjectNode buildSpec(ApiVersion crdApiVersion,
             result.put("version", Arrays.stream(crd.versions())
                     .map(v -> ApiVersion.parse(v.name()))
                     .filter(this::shouldIncludeVersion)
-                    .findFirst().map(v -> v.toString()).get());
+                    .findFirst()
+                    .map(ApiVersion::toString)
+                    .orElseThrow());
         }
 
         if (!perVersionSchemas) {

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/HasNoneOfReasons.java
Patch:
@@ -33,7 +33,7 @@ public HasNoneOfReasons(Events... eventReasons) {
     @Override
     @SuppressWarnings("unchecked")
     public boolean matches(Object actualValue) {
-        return !filtered((List<Event>) actualValue).findFirst().isPresent();
+        return filtered((List<Event>) actualValue).findFirst().isEmpty();
     }
 
     private Stream<Event> filtered(List<Event> actualValue) {

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaClientsTemplates.java
Patch:
@@ -198,7 +198,7 @@ private static PodSpec createClientSpec(String namespaceName, boolean tlsListene
 
                 if (tlsListener) {
                     String clusterName = kafkaUser.getMetadata().getLabels().get(Labels.STRIMZI_CLUSTER_LABEL);
-                    String clusterNamespace = KafkaResource.kafkaClient().inAnyNamespace().list().getItems().stream().filter(kafka -> kafka.getMetadata().getName().equals(clusterName)).findFirst().get().getMetadata().getNamespace();
+                    String clusterNamespace = KafkaResource.kafkaClient().inAnyNamespace().list().getItems().stream().filter(kafka -> kafka.getMetadata().getName().equals(clusterName)).findFirst().orElseThrow().getMetadata().getNamespace();
                     String clusterCaSecretName = KafkaUtils.getKafkaTlsListenerCaCertName(clusterNamespace, clusterName, listenerName);
                     String clusterCaSecretVolumeName = "ca-cert-" + kafkaUserName;
                     String caSecretMountPoint = "/opt/kafka/cluster-ca-" + kafkaUserName;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -130,7 +130,7 @@ public static List<ContainerEnvVar> createContainerEnvVarsFromMap(Map<String, St
 
     public static String checkEnvVarInPod(String namespaceName, String podName, String envVarName) {
         return kubeClient(namespaceName).getPod(podName).getSpec().getContainers().get(0).getEnv()
-                .stream().filter(envVar -> envVar.getName().equals(envVarName)).findFirst().get().getValue();
+                .stream().filter(envVar -> envVar.getName().equals(envVarName)).findFirst().orElseThrow().getValue();
     }
 
     public static String checkEnvVarInPod(String podName, String envVarName) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaTopicUtils.java
Patch:
@@ -79,7 +79,7 @@ public static void waitForKafkaTopicCreationByNamePrefix(String namespaceName, S
         TestUtils.waitFor("KafkaTopic creation " + topicNamePrefix, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, READINESS_TIMEOUT,
             () -> KafkaTopicResource.kafkaTopicClient().inNamespace(namespaceName).list().getItems().stream()
                     .filter(topic -> topic.getMetadata().getName().contains(topicNamePrefix))
-                    .findFirst().get().getStatus().getConditions().get(0).getType().equals(Ready.toString())
+                    .findFirst().orElseThrow().getStatus().getConditions().get(0).getType().equals(Ready.toString())
         );
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectBuilderST.java
Patch:
@@ -169,7 +169,7 @@ void testBuildFailsWithWrongChecksumOfArtifact(ExtensionContext extensionContext
         LOGGER.info("Deploying network policies for KafkaConnect");
         NetworkPolicyResource.deployNetworkPolicyForResource(extensionContext, kafkaConnect, KafkaConnectResources.deploymentName(connectClusterName));
 
-        Condition connectCondition = kafkaConnect.getStatus().getConditions().stream().findFirst().get();
+        Condition connectCondition = kafkaConnect.getStatus().getConditions().stream().findFirst().orElseThrow();
 
         assertTrue(connectCondition.getMessage().matches("The Kafka Connect build failed(.*)?"));
         assertThat(connectCondition.getType(), is(NotReady.toString()));
@@ -483,7 +483,7 @@ void setup(ExtensionContext extensionContext) {
         } else {
             LOGGER.warn("For running these tests on K8s you have to have internal registry deployed using `minikube start --insecure-registry '10.0.0.0/24'` and `minikube addons enable registry`");
             Service service = kubeClient("kube-system").getService("registry");
-            outputRegistry = service.getSpec().getClusterIP() + ":" + service.getSpec().getPorts().stream().filter(servicePort -> servicePort.getName().equals("http")).findFirst().get().getPort();
+            outputRegistry = service.getSpec().getClusterIP() + ":" + service.getSpec().getPorts().stream().filter(servicePort -> servicePort.getName().equals("http")).findFirst().orElseThrow().getPort();
         }
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(SHARED_KAFKA_CLUSTER_NAME, 3).build());
     }

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -721,7 +721,7 @@ void testMultiNodeKafkaConnectWithConnectorCreation(ExtensionContext extensionCo
         );
         String podIP = connectStatus.getJsonObject("connector").getString("worker_id").split(":")[0];
         String connectorPodName = kubeClient(namespaceName).listPods().stream().filter(pod ->
-                pod.getStatus().getPodIP().equals(podIP)).findFirst().get().getMetadata().getName();
+                pod.getStatus().getPodIP().equals(podIP)).findFirst().orElseThrow().getMetadata().getName();
 
         internalKafkaClient.assertSentAndReceivedMessages(
             internalKafkaClient.sendMessagesPlain(),

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -154,7 +154,7 @@ void testEODeletion(ExtensionContext extensionContext) {
         Pod pod = kubeClient(namespaceName).listPods(namespaceName).stream()
                 .filter(p -> p.getMetadata().getName().startsWith(KafkaResources.entityOperatorDeploymentName(clusterName)))
                 .findAny()
-                .get();
+                .orElseThrow();
 
         assertThat("Entity operator pod does not exist", pod, notNullValue());
 
@@ -565,9 +565,9 @@ void testJvmAndResources(ExtensionContext extensionContext) {
                 LOGGER.info("Check if -D java options are present in {}", container.getName());
 
                 String javaSystemProp = container.getEnv().stream().filter(envVar ->
-                    envVar.getName().equals("STRIMZI_JAVA_SYSTEM_PROPERTIES")).findFirst().get().getValue();
+                    envVar.getName().equals("STRIMZI_JAVA_SYSTEM_PROPERTIES")).findFirst().orElseThrow().getValue();
                 String javaOpts = container.getEnv().stream().filter(envVar ->
-                    envVar.getName().equals("STRIMZI_JAVA_OPTS")).findFirst().get().getValue();
+                    envVar.getName().equals("STRIMZI_JAVA_OPTS")).findFirst().orElseThrow().getValue();
 
                 assertThat(javaSystemProp, is("-Djavax.net.debug=verbose"));
 

File: systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
Patch:
@@ -488,7 +488,7 @@ private synchronized String configMap(String namespaceName, String configMapName
                 .stream()
                 .filter(key -> key.equals("log4j2.properties") || key.equals("log4j.properties"))
                 .findAny()
-                .get();
+                .orElseThrow();
         return configMapData.get(configMapKey);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerST.java
Patch:
@@ -145,7 +145,7 @@ void testMirrorMaker(ExtensionContext extensionContext) {
         assertThat(kafkaMirrorMakerLogs,
             not(containsString("keytool error: java.io.FileNotFoundException: /opt/kafka/consumer-oauth-certs/**/* (No such file or directory)")));
 
-        String podName = kubeClient(namespaceName).listPodsByNamespace(namespaceName, clusterName).stream().filter(n -> n.getMetadata().getName().startsWith(KafkaMirrorMakerResources.deploymentName(clusterName))).findFirst().get().getMetadata().getName();
+        String podName = kubeClient(namespaceName).listPodsByNamespace(namespaceName, clusterName).stream().filter(n -> n.getMetadata().getName().startsWith(KafkaMirrorMakerResources.deploymentName(clusterName))).findFirst().orElseThrow().getMetadata().getName();
         assertResources(namespaceName, podName, clusterName.concat("-mirror-maker"),
                 "400M", "2", "300M", "1");
         assertExpectedJavaOpts(namespaceName, podName, KafkaMirrorMakerResources.deploymentName(clusterName),

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -593,6 +593,9 @@ protected void beforeEachMayOverride(ExtensionContext extensionContext) {
 
                     cluster.createNamespace(extensionContext, namespaceTestCase);
                     NetworkPolicyResource.applyDefaultNetworkPolicySettings(extensionContext, Collections.singletonList(namespaceTestCase));
+                    if (Environment.SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET != null && !Environment.SYSTEM_TEST_STRIMZI_IMAGE_PULL_SECRET.isEmpty()) {
+                        StUtils.copyImagePullSecret(namespaceTestCase);
+                    }
                 }
             }
         }

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
Patch:
@@ -63,7 +63,6 @@ public class OauthPlainST extends OauthAbstractST {
     private KafkaOauthExampleClients oauthInternalClientJob;
     private KafkaOauthExampleClients oauthInternalClientChecksJob;
     private final String oauthClusterName = "oauth-cluster-plain-name";
-    private final String audienceListenerPort = "9098";
     private final String customClaimListenerPort = "9099";
     private static final String NAMESPACE = "oauth2-plain-cluster-test";
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -444,9 +444,9 @@ void testIntrospectionEndpoint(ExtensionContext extensionContext) {
                         .withType(KafkaListenerType.INTERNAL)
                         .withTls(true)
                         .withNewKafkaListenerAuthenticationOAuth()
-                            .withClientId(OAUTH_KAFKA_CLIENT_NAME)
+                            .withClientId(OAUTH_KAFKA_BROKER_NAME)
                             .withNewClientSecret()
-                                .withSecretName(OAUTH_KAFKA_CLIENT_SECRET)
+                                .withSecretName(OAUTH_KAFKA_BROKER_SECRET)
                                 .withKey(OAUTH_KEY)
                             .endClientSecret()
                             .withAccessTokenIsJwt(false)

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -97,6 +97,7 @@ public interface Constants {
     String INGRESS = "Ingress";
     String CLUSTER_ROLE_BINDING = "ClusterRoleBinding";
     String ROLE_BINDING = "RoleBinding";
+    String ROLE = "Role";
     String DEPLOYMENT_CONFIG = "DeploymentConfig";
     String SECRET = "Secret";
     String KAFKA_EXPORTER_DEPLOYMENT = "KafkaWithExporter";

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/RoleBindingResource.java
Patch:
@@ -33,7 +33,7 @@ public void create(RoleBinding resource) {
     }
     @Override
     public void delete(RoleBinding resource) {
-        ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteRoleBinding(resource.getMetadata().getName());
+        ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteRoleBinding(resource.getMetadata().getNamespace(), resource.getMetadata().getName());
     }
     @Override
     public boolean waitForReadiness(RoleBinding resource) {
@@ -45,7 +45,7 @@ public static RoleBinding roleBinding(ExtensionContext extensionContext, String
         RoleBinding roleBinding = getRoleBindingFromYaml(yamlPath);
         if (Environment.isNamespaceRbacScope()) {
             LOGGER.info("Replacing ClusterRole RoleRef for Role RoleRef");
-            roleBinding.getRoleRef().setKind("Role");
+            roleBinding.getRoleRef().setKind(Constants.ROLE);
         }
 
         return createRoleBinding(

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -597,16 +597,14 @@ void setupEnvironment(ExtensionContext extensionContext) throws Exception {
         cluster.setNamespace(SECOND_NAMESPACE);
 
         NetworkPolicyResource.applyDefaultNetworkPolicySettings(extensionContext, Collections.singletonList(SECOND_NAMESPACE));
-        SetupClusterOperator.applyRoleBindings(extensionContext, FIRST_NAMESPACE, SECOND_NAMESPACE);
-        install.applyClusterOperatorInstallFiles(SECOND_NAMESPACE);
 
         cluster.setNamespace(FIRST_NAMESPACE);
 
         install = new SetupClusterOperator.SetupClusterOperatorBuilder()
             .withExtensionContext(extensionContext)
             .withNamespace(FIRST_NAMESPACE)
             .withWatchingNamespaces(FIRST_NAMESPACE + "," + SECOND_NAMESPACE)
-            .withBindingsNamespaces(Collections.singletonList(FIRST_NAMESPACE))
+            .withBindingsNamespaces(List.of(FIRST_NAMESPACE, SECOND_NAMESPACE))
             .createInstallation()
             .runInstallation();
 

File: config-model-generator/src/main/java/io/strimzi/build/kafka/metadata/KafkaConfigModelGenerator.java
Patch:
@@ -84,7 +84,7 @@ private static Map<String, ConfigModel> configs() throws NoSuchMethodException,
             } else if (key.validator instanceof ConfigDef.ValidList) {
                 descriptor.setItems(validList(key));
             } else if (key.validator instanceof ApiVersionValidator$) {
-                Iterator<ApiVersion> iterator = ((scala.collection.GenIterableLike<ApiVersion, ?>) ApiVersion$.MODULE$.allVersions()).iterator();
+                Iterator<ApiVersion> iterator = ApiVersion$.MODULE$.allVersions().iterator();
                 LinkedHashSet<String> versions = new LinkedHashSet<>();
                 while (iterator.hasNext()) {
                     ApiVersion next = iterator.next();

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/AbstractUpgradeST.java
Patch:
@@ -113,8 +113,7 @@ protected static Stream<Arguments> loadJsonUpgradeData() {
             procedures.put("interBrokerProtocolVersion", testKafkaVersion.protocolVersion());
             data.put("proceduresAfterOperatorUpgrade", procedures);
 
-            // fromVersion is the mid step here, for CO upgrade we'll use this: 'prevVersion' -> 'fromVersion' -> HEAD
-            parameters.add(Arguments.of(data.getString("prevVersion"), data.getString("fromVersion"), "HEAD", data));
+            parameters.add(Arguments.of(data.getString("fromVersion"), "HEAD", data));
         });
 
         return parameters.stream();

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/NetworkPolicyResource.java
Patch:
@@ -171,8 +171,8 @@ public static void allowNetworkPolicySettingsForResource(ExtensionContext extens
             .addToMatchLabels(Constants.KAFKA_CLIENTS_LABEL_KEY, Constants.KAFKA_CLIENTS_LABEL_VALUE)
             .build();
 
-        final String namespaceName = StUtils.isParallelNamespaceTest(extensionContext) ?
-            // if parallel namespace test use namespace from store
+        final String namespaceName = StUtils.isParallelNamespaceTest(extensionContext) && !Environment.isNamespaceRbacScope() ?
+            // if parallel namespace test use namespace from store and if RBAC is enable we don't run tests in parallel mode and with that said we don't create another namespaces
             extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get(Constants.NAMESPACE_KEY).toString() :
             // otherwise use resource namespace
             resource.getMetadata().getNamespace();

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/ConfigProviderST.java
Patch:
@@ -25,6 +25,7 @@
 import io.strimzi.systemtest.templates.crd.KafkaConnectorTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.utils.ClientUtils;
+import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -48,7 +49,7 @@ public class ConfigProviderST extends AbstractST {
     void testConnectWithConnectorUsingConfigProvider(ExtensionContext extensionContext) {
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         final String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());
-        final String namespaceName = extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get(Constants.NAMESPACE_KEY).toString();
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         final String producerName = "producer-" + ClientUtils.generateRandomConsumerGroup();
 
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(clusterName, 3).build());

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/QuotasST.java
Patch:
@@ -12,6 +12,7 @@
 import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
+import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.JobUtils;
 import io.strimzi.test.WaitException;
 import org.apache.logging.log4j.LogManager;
@@ -39,7 +40,7 @@ public class QuotasST extends AbstractST {
     @ParallelNamespaceTest
     @Tag(INTERNAL_CLIENTS_USED)
     void testKafkaQuotasPluginIntegration(ExtensionContext extensionContext) {
-        final String namespaceName = extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get(Constants.NAMESPACE_KEY).toString();
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         final String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());
 
@@ -96,7 +97,7 @@ void setup(ExtensionContext extensionContext) {
 
     @AfterEach
     void afterEach(ExtensionContext extensionContext) throws Exception {
-        final String namespaceName = extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get(Constants.NAMESPACE_KEY).toString();
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         kubeClient(namespaceName).getClient().persistentVolumeClaims().inNamespace(namespaceName).delete();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ReconciliationST.java
Patch:
@@ -30,6 +30,7 @@
 import io.strimzi.systemtest.templates.crd.KafkaRebalanceTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
+import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils;
@@ -64,7 +65,7 @@ public class ReconciliationST extends AbstractST {
 
     @ParallelNamespaceTest
     void testPauseReconciliationInKafkaAndKafkaConnectWithConnector(ExtensionContext extensionContext) {
-        final String namespaceName = extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get(Constants.NAMESPACE_KEY).toString();
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         final String kafkaClientsName = mapWithKafkaClientNames.get(extensionContext.getDisplayName());
 
@@ -131,7 +132,7 @@ void testPauseReconciliationInKafkaAndKafkaConnectWithConnector(ExtensionContext
 
     @ParallelNamespaceTest
     void testPauseReconciliationInKafkaRebalanceAndTopic(ExtensionContext extensionContext) {
-        final String namespaceName = extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get(Constants.NAMESPACE_KEY).toString();
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         final String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserST.java
Patch:
@@ -23,6 +23,7 @@
 import io.strimzi.systemtest.templates.crd.KafkaTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaTopicTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaUserTemplates;
+import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.SecretUtils;
 import io.strimzi.test.TestUtils;
@@ -254,7 +255,7 @@ void testUserWithQuotas(ExtensionContext extensionContext, KafkaUser user) {
 
     @ParallelNamespaceTest
     void testCreatingUsersWithSecretPrefix(ExtensionContext extensionContext) {
-        final String namespaceName = extensionContext.getStore(ExtensionContext.Namespace.GLOBAL).get(Constants.NAMESPACE_KEY).toString();
+        final String namespaceName = StUtils.getNamespaceBasedOnRbac(NAMESPACE, extensionContext);
         final String clusterName = mapWithClusterNames.get(extensionContext.getDisplayName());
         final String topicName = mapWithTestTopics.get(extensionContext.getDisplayName());
 

File: user-operator/src/main/java/io/strimzi/operator/user/model/InvalidCertificateException.java
Patch:
@@ -7,9 +7,9 @@
 /**
  * Represents an exception raised when a certificate Secret is missing
  */
-public class NoCertificateSecretException extends RuntimeException {
+public class InvalidCertificateException extends RuntimeException {
 
-    public NoCertificateSecretException(String message) {
+    public InvalidCertificateException(String message) {
         super(message);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/specific/HelmResource.java
Patch:
@@ -126,7 +126,8 @@ private void clusterOperator(long operationTimeout, long reconciliationInterval)
                 entry("logLevelOverride", Environment.STRIMZI_LOG_LEVEL),
                 entry("fullReconciliationIntervalMs", Long.toString(reconciliationInterval)),
                 entry("operationTimeoutMs", Long.toString(operationTimeout)),
-                entry("featureGates", Environment.STRIMZI_FEATURE_GATES),
+                // As FG is CSV, we need to escape commas for interpretation of helm installation string
+                entry("featureGates", Environment.STRIMZI_FEATURE_GATES.replaceAll(",", "\\\\,")),
                 entry("watchAnyNamespace", this.namespaceToWatch.equals(Constants.WATCH_ALL_NAMESPACES) ? "true" : "false"))
                 .collect(TestUtils.entriesToMap()));
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -126,7 +126,7 @@ public abstract class AbstractModel {
 
     private static final Long DEFAULT_FS_GROUPID = 0L;
 
-    public static final String ANCILLARY_CM_KEY_METRICS = "metrics-config.yml";
+    public static final String ANCILLARY_CM_KEY_METRICS = "metrics-config.json";
     public static final String ANCILLARY_CM_KEY_LOG_CONFIG = "log4j.properties";
 
     public static final String NETWORK_POLICY_KEY_SUFFIX = "-network-policy";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/TestUtils.java
Patch:
@@ -12,7 +12,6 @@
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetrics;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetricsBuilder;
 import io.strimzi.api.kafka.model.status.Status;
-import io.strimzi.operator.cluster.model.AbstractModel;
 
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
@@ -35,12 +34,12 @@ public static JmxPrometheusExporterMetrics getJmxPrometheusExporterMetrics(Strin
         return metricsConfig;
     }
 
-    public static ConfigMap getJmxMetricsCm(String data, String metricsCMName) {
+    public static ConfigMap getJmxMetricsCm(String data, String metricsCMName, String metricsConfigYaml) {
         ConfigMap metricsCM = new ConfigMapBuilder()
                 .withNewMetadata()
                 .withName(metricsCMName)
                 .endMetadata()
-                .withData(singletonMap(AbstractModel.ANCILLARY_CM_KEY_METRICS, data))
+                .withData(singletonMap(metricsConfigYaml, data))
                 .build();
         return metricsCM;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -107,7 +107,7 @@ public class CruiseControlTest {
     private final String minInsyncReplicas = "2";
     private final Map<String, Object> metricsCm = singletonMap("animal", "wombat");
     private final String metricsCMName = "metrics-cm";
-    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics(AbstractModel.ANCILLARY_CM_KEY_METRICS, metricsCMName);
+    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics("metrics-config.yml", metricsCMName);
 
     private final Map<String, Object> kafkaConfig = singletonMap(CruiseControl.MIN_INSYNC_REPLICAS, minInsyncReplicas);
     private final Map<String, Object> zooConfig = singletonMap("foo", "bar");

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -76,7 +76,7 @@ public class EntityUserOperatorTest {
 
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
     private final String metricsCMName = "metrics-cm";
-    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName);
+    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName, "metrics-config.yml");
     private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics(AbstractModel.ANCILLARY_CM_KEY_METRICS, metricsCMName);
     private final List<SystemProperty> javaSystemProperties = new ArrayList<SystemProperty>() {{
             add(new SystemPropertyBuilder().withName("javax.net.debug").withValue("verbose").build());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -134,8 +134,8 @@ public class KafkaClusterTest {
     private final Map<String, Object> metricsCm = singletonMap("animal", "wombat");
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
     private final String metricsCMName = "metrics-cm";
-    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName);
-    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics(AbstractModel.ANCILLARY_CM_KEY_METRICS, metricsCMName);
+    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName, "metrics-config.yml");
+    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics("metrics-config.yml", metricsCMName);
     private final Map<String, Object> configuration = singletonMap("foo", "bar");
     private final InlineLogging kafkaLog = new InlineLogging();
     private final InlineLogging zooLog = new InlineLogging();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -106,8 +106,8 @@ public class KafkaConnectClusterTest {
     private final int healthTimeout = 10;
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
     private final String metricsCMName = "metrics-cm";
-    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName);
-    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics(AbstractModel.ANCILLARY_CM_KEY_METRICS, metricsCMName);
+    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName, "metrics-config.yml");
+    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics("metrics-config.yml", metricsCMName);
     private final String configurationJson = "{\"foo\":\"bar\"}";
     private final String bootstrapServers = "foo-kafka:9092";
     private final String kafkaHeapOpts = "-Xms" + AbstractModel.DEFAULT_JVM_XMS;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -95,8 +95,8 @@ public class KafkaMirrorMaker2ClusterTest {
     private final int healthTimeout = 10;
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
     private final String metricsCMName = "metrics-cm";
-    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName);
-    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics(AbstractModel.ANCILLARY_CM_KEY_METRICS, metricsCMName);
+    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName, "metrics-config.yml");
+    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics("metrics-config.yml", metricsCMName);
     private final String configurationJson = "{\"foo\":\"bar\"}";
     private final String bootstrapServers = "foo-kafka:9092";
     private final String targetClusterAlias = "target";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -76,8 +76,8 @@ public class KafkaMirrorMakerClusterTest {
     private final String image = "my-image:latest";
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
     private final String metricsCMName = "metrics-cm";
-    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName);
-    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics(AbstractModel.ANCILLARY_CM_KEY_METRICS, metricsCMName);
+    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName, "metrics-config.yml");
+    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics("metrics-config.yml", metricsCMName);
 
     private final String producerConfigurationJson = "{\"foo\":\"bar\"}";
     private final String consumerConfigurationJson = "{\"foo\":\"buz\"}";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -104,8 +104,8 @@ public class ZookeeperClusterTest {
     private final Map<String, Object> metricsCm = singletonMap("animal", "wombat");
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
     private final String metricsCMName = "metrics-cm";
-    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName);
-    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics(AbstractModel.ANCILLARY_CM_KEY_METRICS, metricsCMName);
+    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName, "metrics-config.yml");
+    private final JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics("metrics-config.yml", metricsCMName);
     private final Map<String, Object> configurationJson = emptyMap();
     private final InlineLogging kafkaLogConfigJson = new InlineLogging();
     private final InlineLogging zooLogConfigJson = new InlineLogging();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -155,7 +155,7 @@ public class KafkaAssemblyOperatorTest {
     private final String metricsCmJson = "{\"foo\":\"bar\"}";
     private final String metricsCMName = "metrics-cm";
     private final String differentMetricsCMName = "metrics-cm-2";
-    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName);
+    private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName, "metrics-config.yml");
 
     private final KubernetesVersion kubernetesVersion = KubernetesVersion.V1_20;
 
@@ -771,7 +771,7 @@ private Kafka getKafkaAssembly(String clusterName) {
         Map<String, Object> metricsCmJson = metrics ? METRICS_CONFIG : null;
         KafkaExporterSpec exporter = metrics ? new KafkaExporterSpec() : null;
         String metricsCMName = "metrics-cm";
-        JmxPrometheusExporterMetrics jmxMetricsConfig = metrics ? null : io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics(AbstractModel.ANCILLARY_CM_KEY_METRICS, metricsCMName);
+        JmxPrometheusExporterMetrics jmxMetricsConfig = metrics ? null : io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics("metrics-config.yml", metricsCMName);
 
         Kafka resource = ResourceUtils.createKafka(clusterNamespace, clusterName, replicas, image, healthDelay, healthTimeout, jmxMetricsConfig, kafkaConfig, zooConfig, kafkaStorage, zkStorage, LOG_KAFKA_CONFIG, LOG_ZOOKEEPER_CONFIG, exporter, null);
 
@@ -881,7 +881,7 @@ public void testUpdateClusterLogConfig(Params params, VertxTestContext context)
     public void testUpdateZkClusterMetricsConfig(Params params, VertxTestContext context) {
         setFields(params);
         Kafka kafkaAssembly = getKafkaAssembly("bar");
-        JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics(AbstractModel.ANCILLARY_CM_KEY_METRICS, differentMetricsCMName);
+        JmxPrometheusExporterMetrics jmxMetricsConfig = io.strimzi.operator.cluster.TestUtils.getJmxPrometheusExporterMetrics("metrics-config.yml", differentMetricsCMName);
         kafkaAssembly.getSpec().getKafka().setMetricsConfig(jmxMetricsConfig);
         updateCluster(context, getKafkaAssembly("bar"), kafkaAssembly);
     }

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -138,6 +138,7 @@ public interface Constants {
     String PATH_TO_KAFKA_MIRROR_MAKER_2_METRICS_CONFIG = PATH_TO_PACKAGING_EXAMPLES + "/metrics/kafka-mirror-maker-2-metrics.yaml";
 
     String METRICS_CONFIG_YAML_NAME = "metrics-config.yml";
+    String METRICS_CONFIG_JSON_NAME = "metrics-config.json";
 
     /**
      * Default value which allows execution of tests with any tags

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -462,7 +462,7 @@ void testKafkaMetricsSettings() {
 
         PodUtils.verifyThatRunningPodsAreStable(SECOND_NAMESPACE, SECOND_CLUSTER);
         ConfigMap actualCm = kubeClient(SECOND_NAMESPACE).getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(SECOND_CLUSTER));
-        assertThat(actualCm.getData().get(Constants.METRICS_CONFIG_YAML_NAME), is(metricsConfigJson));
+        assertThat(actualCm.getData().get(Constants.METRICS_CONFIG_JSON_NAME), is(metricsConfigJson));
 
         // update metrics
         ConfigMap externalMetricsUpdatedCm = new ConfigMapBuilder()
@@ -476,7 +476,7 @@ void testKafkaMetricsSettings() {
         kubeClient().getClient().configMaps().inNamespace(SECOND_NAMESPACE).createOrReplace(externalMetricsUpdatedCm);
         PodUtils.verifyThatRunningPodsAreStable(SECOND_NAMESPACE, SECOND_CLUSTER);
         actualCm = kubeClient(SECOND_NAMESPACE).getConfigMap(KafkaResources.kafkaMetricsAndLogConfigMapName(SECOND_CLUSTER));
-        assertThat(actualCm.getData().get(Constants.METRICS_CONFIG_YAML_NAME), is(metricsConfigJson.replace("true", "false")));
+        assertThat(actualCm.getData().get(Constants.METRICS_CONFIG_JSON_NAME), is(metricsConfigJson.replace("true", "false")));
     }
 
     @IsolatedTest

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -780,9 +780,9 @@ void testMetricsChange(ExtensionContext extensionContext) throws JsonProcessingE
         Object kafkaMetricsJsonToYaml = yamlReader.readValue(kafkaMetricsConf, Object.class);
         Object zkMetricsJsonToYaml = yamlReader.readValue(zkMetricsConf, Object.class);
         ObjectMapper jsonWriter = new ObjectMapper();
-        assertThat(kubeClient(NAMESPACE).getClient().configMaps().inNamespace(NAMESPACE).withName(KafkaResources.kafkaMetricsAndLogConfigMapName(clusterName)).get().getData().get("metrics-config.yml"),
+        assertThat(kubeClient(NAMESPACE).getClient().configMaps().inNamespace(NAMESPACE).withName(KafkaResources.kafkaMetricsAndLogConfigMapName(clusterName)).get().getData().get(Constants.METRICS_CONFIG_JSON_NAME),
                 is(jsonWriter.writeValueAsString(kafkaMetricsJsonToYaml)));
-        assertThat(kubeClient(NAMESPACE).getClient().configMaps().inNamespace(NAMESPACE).withName(KafkaResources.zookeeperMetricsAndLogConfigMapName(clusterName)).get().getData().get("metrics-config.yml"),
+        assertThat(kubeClient(NAMESPACE).getClient().configMaps().inNamespace(NAMESPACE).withName(KafkaResources.zookeeperMetricsAndLogConfigMapName(clusterName)).get().getData().get(Constants.METRICS_CONFIG_JSON_NAME),
                 is(jsonWriter.writeValueAsString(zkMetricsJsonToYaml)));
 
         LOGGER.info("Check if metrics are present in pod of Kafka and Zookeeper");

File: api/src/main/java/io/strimzi/api/kafka/model/AbstractKafkaConnectSpec.java
Patch:
@@ -158,7 +158,7 @@ public void setTracing(Tracing tracing) {
         this.tracing = tracing;
     }
 
-    @Description("Template for Kafka Connect and Kafka Connect S2I resources. " +
+    @Description("Template for Kafka Connect and Kafka Mirror Maker 2 resources. " +
             "The template allows users to specify how the `Deployment`, `Pods` and `Service` are generated.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public KafkaConnectTemplate getTemplate() {

File: api/src/main/java/io/strimzi/api/kafka/model/template/KafkaConnectTemplate.java
Patch:
@@ -17,7 +17,7 @@
 import java.util.Map;
 
 /**
- * Representation of a template for Kafka Connect and Kafka Connect S2I resources.
+ * Representation of a template for Kafka Connect resources.
  */
 @Buildable(
         editableEnabled = false,

File: api/src/test/java/io/strimzi/api/kafka/model/StructuralCrdIT.java
Patch:
@@ -27,7 +27,6 @@ public class StructuralCrdIT extends AbstractCrdIT {
     Map<String, String> crdFiles = Map.of(
             "kafkas.kafka.strimzi.io", "040-Crd-kafka.yaml",
             "kafkaconnects.kafka.strimzi.io", "041-Crd-kafkaconnect.yaml",
-            "kafkaconnects2is.kafka.strimzi.io", "042-Crd-kafkaconnects2i.yaml",
             "kafkatopics.kafka.strimzi.io", "043-Crd-kafkatopic.yaml",
             "kafkausers.kafka.strimzi.io", "044-Crd-kafkauser.yaml",
             "kafkamirrormakers.kafka.strimzi.io", "045-Crd-kafkamirrormaker.yaml",

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/MainIT.java
Patch:
@@ -59,7 +59,6 @@ public void testCreateClusterRolesCreatesClusterRoles(VertxTestContext context)
         envVars.put(ClusterOperatorConfig.STRIMZI_CREATE_CLUSTER_ROLES, "TRUE");
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_IMAGES, KafkaVersionTestUtils.getKafkaImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
-        envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_S2I_IMAGES, KafkaVersionTestUtils.getKafkaConnectS2iImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ResourceTester.java
Patch:
@@ -43,7 +43,7 @@ class ResourceTester<R extends HasMetadata, M extends AbstractModel> {
     }
 
     ResourceTester(Class<R> cls, Function<R, M> fromK8sResource, String prefix) {
-        this.lookup = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap(), emptyMap());
+        this.lookup = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
         this.cls = cls;
         this.fromK8sResource = (x, y) -> fromK8sResource.apply(x);
         this.prefix = prefix;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -150,7 +150,7 @@ public void test(VertxTestContext context) {
         KafkaConnectAssemblyOperator operator = new KafkaConnectAssemblyOperator(vertx, pfa,
                 new ResourceOperatorSupplier(
                         null, null, null, null, null, null, null, null, null, null, null, null,
-                        null, null, null, null, null, null, null, null, null, null, null, null,
+                        null, null, null, null, null, null, null, null, null,
                         null, null, connectCrdOperator, null, null, null, null, null, metrics, null),
                 ClusterOperatorConfig.fromMap(Collections.emptyMap(), KafkaVersionTestUtils.getKafkaVersionLookup()),
             connect -> new KafkaConnectApiImpl(vertx),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -38,7 +38,7 @@ public class KafkaSetOperatorTest {
 
     @BeforeEach
     public void before() {
-        KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap(), emptyMap());
+        KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
         currectSts = KafkaCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, getResource(), versions).generateStatefulSet(true, null, null);
         desiredSts = KafkaCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, getResource(), versions).generateStatefulSet(true, null, null);
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperatorTest.java
Patch:
@@ -30,7 +30,7 @@ public class ZookeeperSetOperatorTest {
 
     @BeforeEach
     public void before() {
-        KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap(), emptyMap());
+        KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
         a = ZookeeperCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, getResource(), versions).generateStatefulSet(true, null, null);
         b = ZookeeperCluster.fromCrd(Reconciliation.DUMMY_RECONCILIATION, getResource(), versions).generateStatefulSet(true, null, null);
     }

File: operator-common/src/main/java/io/strimzi/operator/common/model/Labels.java
Patch:
@@ -33,7 +33,6 @@ public class Labels {
      * <ul>
      *   <li>Kafka</li>
      *   <li>KafkaConnect</li>
-     *   <li>KafkaConnectS2I</li>
      *   <li>KafkaMirrorMaker</li>
      *   <li>KafkaBridge</li>
      *   <li>KafkaUser</li>

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/NetworkPolicyResource.java
Patch:
@@ -162,8 +162,8 @@ public static void allowNetworkPolicySettingsForKafkaExporter(ExtensionContext e
     }
 
     /**
-     * Method for allowing network policies for Connect or ConnectS2I
-     * @param resource mean Connect or ConnectS2I resource
+     * Method for allowing network policies for Connect
+     * @param resource mean Connect resource
      * @param deploymentName name of resource deployment - for setting strimzi.io/name
      */
     public static void allowNetworkPolicySettingsForResource(ExtensionContext extensionContext, HasMetadata resource, String deploymentName) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/specific/HelmResource.java
Patch:
@@ -88,7 +88,6 @@ private void clusterOperator(long operationTimeout, long reconciliationInterval)
                 entry("tlsSidecarCruiseControl.image.registry", Environment.STRIMZI_REGISTRY),
                 entry("kafka.image.registry", Environment.STRIMZI_REGISTRY),
                 entry("kafkaConnect.image.registry", Environment.STRIMZI_REGISTRY),
-                entry("kafkaConnects2i.image.registry", Environment.STRIMZI_REGISTRY),
                 entry("kafkaMirrorMaker.image.registry", Environment.STRIMZI_REGISTRY),
                 entry("kafkaMirrorMaker2.image.registry", Environment.STRIMZI_REGISTRY),
                 entry("kafkaBridge.image.registry", Environment.STRIMZI_REGISTRY_DEFAULT),
@@ -106,7 +105,6 @@ private void clusterOperator(long operationTimeout, long reconciliationInterval)
                 entry("tlsSidecarCruiseControl.image.repository", Environment.STRIMZI_ORG),
                 entry("kafka.image.repository", Environment.STRIMZI_ORG),
                 entry("kafkaConnect.image.repository", Environment.STRIMZI_ORG),
-                entry("kafkaConnects2i.image.repository", Environment.STRIMZI_ORG),
                 entry("kafkaMirrorMaker.image.repository", Environment.STRIMZI_ORG),
                 entry("kafkaMirrorMaker2.image.repository", Environment.STRIMZI_ORG),
                 entry("kafkaBridge.image.repository", Environment.STRIMZI_ORG_DEFAULT),

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -79,8 +79,6 @@ public final class TestUtils {
 
     public static final String CRD_KAFKA_CONNECT = USER_PATH + "/../packaging/install/cluster-operator/041-Crd-kafkaconnect.yaml";
 
-    public static final String CRD_KAFKA_CONNECT_S2I = USER_PATH + "/../packaging/install/cluster-operator/042-Crd-kafkaconnects2i.yaml";
-
     public static final String CRD_KAFKA_USER = USER_PATH + "/../packaging/install/cluster-operator/044-Crd-kafkauser.yaml";
 
     public static final String CRD_KAFKA_MIRROR_MAKER = USER_PATH + "/../packaging/install/cluster-operator/045-Crd-kafkamirrormaker.yaml";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -156,8 +156,6 @@ private Future<ArgumentCaptor<Secret>> reconcileCa(VertxTestContext context, Kaf
                 supplier, ResourceUtils.dummyClusterOperatorConfig(1L));
         Reconciliation reconciliation = new Reconciliation("test-trigger", Kafka.RESOURCE_KIND, NAMESPACE, NAME);
 
-        Checkpoint async = context.checkpoint();
-
         Promise reconcileCasComplete = Promise.promise();
         op.new ReconciliationState(reconciliation, kafka).reconcileCas(dateSupplier)
             .onComplete(ar -> {
@@ -169,7 +167,6 @@ op.new ReconciliationState(reconciliation, kafka).reconcileCas(dateSupplier)
                 } else {
                     reconcileCasComplete.fail(ar.cause());
                 }
-                async.flag();
             });
         return reconcileCasComplete.future();
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -1372,6 +1372,7 @@ public void testReconcile(Params params, VertxTestContext context) {
 
         Checkpoint fooAsync = context.checkpoint();
         Checkpoint barAsync = context.checkpoint();
+        Checkpoint completeTest = context.checkpoint();
 
         KafkaAssemblyOperator ops = new KafkaAssemblyOperator(vertx, new PlatformFeaturesAvailability(openShift, kubernetesVersion),
                 certManager,
@@ -1392,9 +1393,9 @@ public Future<KafkaStatus> createOrUpdate(Reconciliation reconciliation, Kafka k
             }
         };
 
-        Checkpoint async = context.checkpoint();
+
         // Now try to reconcile all the Kafka clusters
-        ops.reconcileAll("test", kafkaNamespace, context.succeeding(v -> async.flag()));
+        ops.reconcileAll("test", kafkaNamespace, context.succeeding(v -> completeTest.flag()));
     }
 
     @ParameterizedTest

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -742,6 +742,8 @@ public void testReconcile(VertxTestContext context) {
         Set<String> createdOrUpdated = new CopyOnWriteArraySet<>();
 
         Checkpoint asyncCreated = context.checkpoint(2);
+        //Must create all needed checkpoints before flagging anyway, to avoid premature test success
+        Checkpoint async = context.checkpoint();
         KafkaConnectAssemblyOperator ops = new KafkaConnectAssemblyOperator(vertx, new PlatformFeaturesAvailability(true, kubernetesVersion),
                 supplier, ResourceUtils.dummyClusterOperatorConfig(VERSIONS)) {
 
@@ -754,7 +756,7 @@ public Future<KafkaConnectStatus> createOrUpdate(Reconciliation reconciliation,
         };
 
 
-        Checkpoint async = context.checkpoint();
+
         Promise reconciled = Promise.promise();
         // Now try to reconcile all the Kafka Connect clusters
         ops.reconcileAll("test", kcNamespace, ignored -> reconciled.complete());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -130,7 +130,7 @@ private Future<Void> createMirrorMaker2Cluster(VertxTestContext context, KafkaCo
 
         LOGGER.info("Reconciling initially -> create");
         Promise created = Promise.promise();
-        Checkpoint async = context.checkpoint();
+
         kco.reconcile(new Reconciliation("test-trigger", KafkaMirrorMaker2.RESOURCE_KIND, NAMESPACE, CLUSTER_NAME))
             .onComplete(context.succeeding(ar -> context.verify(() -> {
                 if (!reconciliationPaused) {
@@ -143,7 +143,6 @@ private Future<Void> createMirrorMaker2Cluster(VertxTestContext context, KafkaCo
                     verify(mockClient, never()).customResources(KafkaMirrorMaker2.class);
                 }
 
-                async.flag();
                 created.complete();
             })));
         return created.future();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorTest.java
Patch:
@@ -603,6 +603,9 @@ public void testReconcile(VertxTestContext context) {
         Set<String> createdOrUpdated = new CopyOnWriteArraySet<>();
 
         Checkpoint createOrUpdateAsync = context.checkpoint(2);
+        //Must create all checkpoints used before flagging any to avoid premature test success
+        Checkpoint async = context.checkpoint();
+
         KafkaMirrorMaker2AssemblyOperator ops = new KafkaMirrorMaker2AssemblyOperator(vertx, new PlatformFeaturesAvailability(true, kubernetesVersion),
                 supplier, ResourceUtils.dummyClusterOperatorConfig(VERSIONS)) {
 
@@ -614,7 +617,6 @@ public Future<KafkaMirrorMaker2Status> createOrUpdate(Reconciliation reconciliat
             }
         };
 
-        Checkpoint async = context.checkpoint();
         // Now try to reconcile all the Kafka MirrorMaker 2.0 clusters
         ops.reconcileAll("test", kmm2Namespace,
             context.succeeding(v -> context.verify(() -> {

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -147,7 +147,7 @@ public class Environment {
     public static final String OLM_OPERATOR_DEPLOYMENT_NAME_DEFAULT = Constants.STRIMZI_DEPLOYMENT_NAME;
     public static final String OLM_SOURCE_NAME_DEFAULT = "community-operators";
     public static final String OLM_APP_BUNDLE_PREFIX_DEFAULT = "strimzi-cluster-operator";
-    public static final String OLM_OPERATOR_VERSION_DEFAULT = "0.21.1";
+    public static final String OLM_OPERATOR_VERSION_DEFAULT = "0.23.0";
     private static final boolean DEFAULT_TO_DENY_NETWORK_POLICIES_DEFAULT = true;
     private static final ClusterOperatorInstallType CLUSTER_OPERATOR_INSTALL_TYPE_DEFAULT = ClusterOperatorInstallType.BUNDLE;
     private static final boolean LB_FINALIZERS_DEFAULT = false;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectBuildAssemblyOperatorOpenShiftTest.java
Patch:
@@ -259,7 +259,7 @@ public void testBuildFailureOnOpenShift(VertxTestContext context) {
                     .withNewBuild()
                         .withNewDockerOutput()
                             .withImage("my-connect-build:latest")
-                            .withNewPushSecret("my-docker-credentials")
+                            .withPushSecret("my-docker-credentials")
                         .endDockerOutput()
                         .withPlugins(plugin1)
                     .endBuild()
@@ -330,6 +330,7 @@ public void testBuildFailureOnOpenShift(VertxTestContext context) {
                 .build();
 
         ArgumentCaptor<BuildRequest> buildRequestCaptor = ArgumentCaptor.forClass(BuildRequest.class);
+        when(mockBcOps.getAsync(eq(NAMESPACE), anyString())).thenReturn(Future.succeededFuture());
         when(mockBcOps.startBuild(eq(NAMESPACE), eq(KafkaConnectResources.buildConfigName(NAME)), buildRequestCaptor.capture())).thenReturn(Future.succeededFuture(builder));
 
         // Mock and capture Build ops
@@ -356,6 +357,7 @@ public void testBuildFailureOnOpenShift(VertxTestContext context) {
         Checkpoint async = context.checkpoint();
         ops.reconcile(new Reconciliation("test-trigger", KafkaConnect.RESOURCE_KIND, NAMESPACE, NAME))
             .onComplete(context.failing(v -> context.verify(() -> {
+                assertThat(v.getMessage(), is("The Kafka Connect build failed."));
                 async.flag();
             })));
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectApi.java
Patch:
@@ -145,9 +145,9 @@ public interface KafkaConnectApi {
      * @param desiredLogging Desired logging.
      * @param defaultLogging Default logging.
      * @return A Future which completes with the result of the request. If the request was successful,
-     * this returns the list of connector loggers.
+     * this returns whether any loggers were actually changed.
      */
-    Future<Void> updateConnectLoggers(Reconciliation reconciliation, String host, int port, String desiredLogging, OrderedProperties defaultLogging);
+    Future<Boolean> updateConnectLoggers(Reconciliation reconciliation, String host, int port, String desiredLogging, OrderedProperties defaultLogging);
 
     /**
      * Make a {@code GET} request to {@code /admin/loggers}.
@@ -157,7 +157,7 @@ public interface KafkaConnectApi {
      * @return A Future which completes with the result of the request. If the request was successful,
      * this returns the list of connect loggers.
      */
-    Future<Map<String, Map<String, String>>> listConnectLoggers(Reconciliation reconciliation, String host, int port);
+    Future<Map<String, String>> listConnectLoggers(Reconciliation reconciliation, String host, int port);
 
     /**
      * Make a {@code POST} request to {@code /connectors/${connectorName}/restart}.

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -274,7 +274,9 @@ private Future<Void> reconcileMirrorMaker2Connectors(Reconciliation reconciliati
                         return reconcileMirrorMaker2Connector(reconciliation, mirrorMaker2, apiClient, host, connectorName, connectorSpec, mirrorMaker2Status);
                     })                            
                     .collect(Collectors.toList()))
-                    .map((Void) null).compose(i -> apiClient.updateConnectLoggers(reconciliation, host, KafkaConnectCluster.REST_API_PORT, desiredLogging, mirrorMaker2Cluster.getDefaultLogConfig()));
+                    .map((Void) null)
+                    .compose(i -> apiClient.updateConnectLoggers(reconciliation, host, KafkaConnectCluster.REST_API_PORT, desiredLogging, mirrorMaker2Cluster.getDefaultLogConfig()))
+                    .map((Void) null);
     }
 
     @SuppressWarnings("deprecation")

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -79,6 +79,7 @@ public class KafkaBridgeClusterTest {
     private final int healthTimeout = 5;
     private final String bootstrapServers = "foo-kafka:9092";
     private final String kafkaHeapOpts = "-Xms" + AbstractModel.DEFAULT_JVM_XMS;
+    private final String defaultAdminclientConfiguration = "";
     private final String defaultProducerConfiguration = "";
     private final String defaultConsumerConfiguration = "";
 
@@ -121,6 +122,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_METRICS_ENABLED).withValue(String.valueOf(true)).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(String.valueOf(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_BOOTSTRAP_SERVERS).withValue(bootstrapServers).build());
+        expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_ADMIN_CLIENT_CONFIG).withValue(defaultAdminclientConfiguration).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_CONSUMER_CONFIG).withValue(defaultConsumerConfiguration).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_PRODUCER_CONFIG).withValue(defaultProducerConfiguration).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_ID).withValue(cluster).build());

File: api/src/main/java/io/strimzi/api/kafka/model/connect/build/Artifact.java
Patch:
@@ -27,7 +27,8 @@
         {
             @JsonSubTypes.Type(value = JarArtifact.class, name = Artifact.TYPE_JAR),
             @JsonSubTypes.Type(value = TgzArtifact.class, name = Artifact.TYPE_TGZ),
-            @JsonSubTypes.Type(value = ZipArtifact.class, name = Artifact.TYPE_ZIP)
+            @JsonSubTypes.Type(value = ZipArtifact.class, name = Artifact.TYPE_ZIP),
+            @JsonSubTypes.Type(value = OtherArtifact.class, name = Artifact.TYPE_OTHER)
         }
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
@@ -38,6 +39,7 @@ public abstract class Artifact implements UnknownPropertyPreserving, Serializabl
     public static final String TYPE_JAR = "jar";
     public static final String TYPE_TGZ = "tgz";
     public static final String TYPE_ZIP = "zip";
+    public static final String TYPE_OTHER = "other";
 
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AuthenticationUtils.java
Patch:
@@ -266,6 +266,8 @@ public static Map<String, String> getClientAuthenticationProperties(KafkaClientA
                 List<String> options = new ArrayList<>(2);
                 if (oauth.getClientId() != null) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, oauth.getClientId()));
                 if (oauth.getTokenEndpointUri() != null) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, oauth.getTokenEndpointUri()));
+                if (oauth.getScope() != null) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_SCOPE, oauth.getScope()));
+                if (oauth.getAudience() != null) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_AUDIENCE, oauth.getAudience()));
                 if (oauth.isDisableTlsHostnameVerification()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM, ""));
                 if (!oauth.isAccessTokenIsJwt()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_ACCESS_TOKEN_IS_JWT, false));
                 if (oauth.getMaxTokenExpirySeconds() > 0) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, oauth.getMaxTokenExpirySeconds()));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -412,6 +412,8 @@ private String getSecurityProtocol(boolean tls, boolean sasl)   {
         addBooleanOptionIfFalse(options, ServerConfig.OAUTH_CHECK_ISSUER, oauth.isCheckIssuer());
         addBooleanOptionIfTrue(options, ServerConfig.OAUTH_CHECK_AUDIENCE, oauth.isCheckAudience());
         addOption(options, ServerConfig.OAUTH_CUSTOM_CLAIM_CHECK, oauth.getCustomClaimCheck());
+        addOption(options, ServerConfig.OAUTH_SCOPE, oauth.getClientScope());
+        addOption(options, ServerConfig.OAUTH_AUDIENCE, oauth.getClientAudience());
         addOption(options, ServerConfig.OAUTH_JWKS_ENDPOINT_URI, oauth.getJwksEndpointUri());
         if (oauth.getJwksRefreshSeconds() != null && oauth.getJwksRefreshSeconds() > 0) {
             addOption(options, ServerConfig.OAUTH_JWKS_REFRESH_SECONDS, String.valueOf(oauth.getJwksRefreshSeconds()));
@@ -422,7 +424,6 @@ private String getSecurityProtocol(boolean tls, boolean sasl)   {
         if (oauth.getJwksMinRefreshPauseSeconds() != null && oauth.getJwksMinRefreshPauseSeconds() >= 0) {
             addOption(options, ServerConfig.OAUTH_JWKS_REFRESH_MIN_PAUSE_SECONDS, String.valueOf(oauth.getJwksMinRefreshPauseSeconds()));
         }
-        addBooleanOptionIfTrue(options, ServerConfig.OAUTH_CRYPTO_PROVIDER_BOUNCYCASTLE, oauth.isEnableECDSA());
         addOption(options, ServerConfig.OAUTH_INTROSPECTION_ENDPOINT_URI, oauth.getIntrospectionEndpointUri());
         addOption(options, ServerConfig.OAUTH_USERINFO_ENDPOINT_URI, oauth.getUserInfoEndpointUri());
         addOption(options, ServerConfig.OAUTH_USERNAME_CLAIM, oauth.getUserNameClaim());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -808,6 +808,8 @@ public void testGenerateDeploymentWithOAuthWithClientSecret() {
                         new KafkaClientAuthenticationOAuthBuilder()
                                 .withClientId("my-client-id")
                                 .withTokenEndpointUri("http://my-oauth-server")
+                                .withAudience("kafka")
+                                .withScope("all")
                                 .withNewClientSecret()
                                     .withSecretName("my-secret-secret")
                                     .withKey("my-secret-key")
@@ -824,7 +826,7 @@ public void testGenerateDeploymentWithOAuthWithClientSecret() {
         assertThat(cont.getEnv().stream().filter(var -> KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_OAUTH_CLIENT_SECRET.equals(var.getName())).findFirst().orElse(null).getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_OAUTH_CLIENT_SECRET.equals(var.getName())).findFirst().orElse(null).getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_OAUTH_CONFIG.equals(var.getName())).findFirst().orElse(null).getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server")));
+                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ClientConfig.OAUTH_SCOPE, "all", ClientConfig.OAUTH_AUDIENCE, "kafka")));
     }
 
     @ParallelTest

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -1342,6 +1342,8 @@ public void testGenerateDeploymentWithOAuthWithClientSecret() {
                         new KafkaClientAuthenticationOAuthBuilder()
                                 .withClientId("my-client-id")
                                 .withTokenEndpointUri("http://my-oauth-server")
+                                .withAudience("kafka")
+                                .withScope("all")
                                 .withNewClientSecret()
                                     .withSecretName("my-secret-secret")
                                     .withKey("my-secret-key")
@@ -1358,7 +1360,7 @@ public void testGenerateDeploymentWithOAuthWithClientSecret() {
         assertThat(cont.getEnv().stream().filter(var -> KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_OAUTH_CLIENT_SECRET.equals(var.getName())).findFirst().orElse(null).getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_OAUTH_CLIENT_SECRET.equals(var.getName())).findFirst().orElse(null).getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_OAUTH_CONFIG.equals(var.getName())).findFirst().orElse(null).getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server")));
+                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ClientConfig.OAUTH_SCOPE, "all", ClientConfig.OAUTH_AUDIENCE, "kafka")));
     }
 
     @ParallelTest

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -11,6 +11,7 @@
 import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
 import com.fasterxml.jackson.dataformat.yaml.YAMLGenerator;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
@@ -88,6 +89,7 @@
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
 @Group(Constants.STRIMZI_GROUP)
+@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class Kafka extends CustomResource<KafkaSpec, KafkaStatus> implements Namespaced, UnknownPropertyPreserving {
 
     public static final String V1BETA2 = Constants.V1BETA2;
@@ -108,6 +110,7 @@ public class Kafka extends CustomResource<KafkaSpec, KafkaStatus> implements Nam
     public static final List<String> RESOURCE_SHORTNAMES = unmodifiableList(singletonList(SHORT_NAME));
 
     private String apiVersion;
+    private String kind = RESOURCE_KIND;
     private ObjectMeta metadata; // leave it for the generator / builder
     private KafkaSpec spec;
     private Map<String, Object> additionalProperties = new HashMap<>(0);

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridge.java
Patch:
@@ -107,6 +107,7 @@ public class KafkaBridge extends CustomResource<KafkaBridgeSpec, KafkaBridgeStat
     public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
 
     private String apiVersion;
+    private String kind = RESOURCE_KIND;
     private ObjectMeta metadata;
     private KafkaBridgeSpec spec;
     private KafkaBridgeStatus status;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnect.java
Patch:
@@ -11,6 +11,7 @@
 import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
 import com.fasterxml.jackson.dataformat.yaml.YAMLGenerator;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
@@ -81,6 +82,7 @@
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
 @Group(Constants.STRIMZI_GROUP)
+@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaConnect extends CustomResource<KafkaConnectSpec, KafkaConnectStatus> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 
@@ -103,6 +105,7 @@ public class KafkaConnect extends CustomResource<KafkaConnectSpec, KafkaConnectS
     public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
 
     private String apiVersion;
+    private String kind = RESOURCE_KIND;
     private KafkaConnectSpec spec;
     private ObjectMeta metadata;
     private KafkaConnectStatus status;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectS2I.java
Patch:
@@ -12,6 +12,7 @@
 import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
 import com.fasterxml.jackson.dataformat.yaml.YAMLGenerator;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
@@ -87,6 +88,7 @@
 @Group(Constants.STRIMZI_GROUP)
 @Deprecated
 @DeprecatedType(replacedWithType = io.strimzi.api.kafka.model.connect.build.Build.class)
+@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaConnectS2I extends CustomResource<KafkaConnectS2ISpec, KafkaConnectS2IStatus> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 
@@ -109,6 +111,7 @@ public class KafkaConnectS2I extends CustomResource<KafkaConnectS2ISpec, KafkaCo
     public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
 
     private String apiVersion;
+    private String kind = RESOURCE_KIND;
     private ObjectMeta metadata;
     private KafkaConnectS2ISpec spec;
     private KafkaConnectS2IStatus status;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnector.java
Patch:
@@ -7,6 +7,7 @@
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonProperty;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
@@ -88,6 +89,7 @@
 @ToString
 @Version(Constants.V1BETA2)
 @Group(Constants.STRIMZI_GROUP)
+@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaConnector extends CustomResource<KafkaConnectorSpec, KafkaConnectorStatus> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
     public static final String V1BETA2 = Constants.V1BETA2;
@@ -110,6 +112,7 @@ public class KafkaConnector extends CustomResource<KafkaConnectorSpec, KafkaConn
     private Map<String, Object> additionalProperties;
     private ObjectMeta metadata;
     private String apiVersion;
+    private String kind = RESOURCE_KIND;
 
     @Override
     public String getApiVersion() {

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker.java
Patch:
@@ -117,6 +117,7 @@ public class KafkaMirrorMaker extends CustomResource<KafkaMirrorMakerSpec, Kafka
     public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
 
     private String apiVersion;
+    private String kind = RESOURCE_KIND;
     private ObjectMeta metadata;
     private KafkaMirrorMakerSpec spec;
     private KafkaMirrorMakerStatus status;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2.java
Patch:
@@ -10,6 +10,7 @@
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
@@ -80,6 +81,7 @@
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
 @Group(Constants.STRIMZI_GROUP)
+@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaMirrorMaker2 extends CustomResource<KafkaMirrorMaker2Spec, KafkaMirrorMaker2Status> implements Namespaced, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 
@@ -101,6 +103,7 @@ public class KafkaMirrorMaker2 extends CustomResource<KafkaMirrorMaker2Spec, Kaf
     public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
 
     private String apiVersion;
+    private String kind = RESOURCE_KIND;
     private KafkaMirrorMaker2Spec spec;
     private ObjectMeta metadata;
     private KafkaMirrorMaker2Status status;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaRebalance.java
Patch:
@@ -10,6 +10,7 @@
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.Namespaced;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
@@ -69,6 +70,7 @@
 @EqualsAndHashCode
 @Version(Constants.V1BETA2)
 @Group(Constants.STRIMZI_GROUP)
+@SuppressFBWarnings("RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE")
 public class KafkaRebalance extends CustomResource<KafkaRebalanceSpec, KafkaRebalanceStatus> implements Namespaced, UnknownPropertyPreserving {
 
     private static final long serialVersionUID = 1L;
@@ -88,6 +90,7 @@ public class KafkaRebalance extends CustomResource<KafkaRebalanceSpec, KafkaReba
     public static final List<String> RESOURCE_SHORTNAMES = singletonList(SHORT_NAME);
 
     private String apiVersion;
+    private String kind = RESOURCE_KIND;
     private ObjectMeta metadata;
     private KafkaRebalanceSpec spec;
     private KafkaRebalanceStatus status;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaTopic.java
Patch:
@@ -107,6 +107,7 @@ public class KafkaTopic extends CustomResource<KafkaTopicSpec, KafkaTopicStatus>
     public static final List<String> RESOURCE_SHORTNAMES = singletonList(SHORT_NAME);
 
     private String apiVersion;
+    private String kind = RESOURCE_KIND;
     private ObjectMeta metadata;
     private KafkaTopicSpec spec;
     private KafkaTopicStatus status;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUser.java
Patch:
@@ -106,6 +106,7 @@ public class KafkaUser extends CustomResource<KafkaUserSpec, KafkaUserStatus> im
     public static final List<String> RESOURCE_SHORTNAMES = singletonList(SHORT_NAME);
 
     private String apiVersion;
+    private String kind = RESOURCE_KIND;
     private ObjectMeta metadata;
     private KafkaUserSpec spec;
     private Map<String, Object> additionalProperties = new HashMap<>(0);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -53,8 +53,8 @@
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
 import io.fabric8.kubernetes.api.model.apps.StatefulSetBuilder;
 import io.fabric8.kubernetes.api.model.apps.StatefulSetUpdateStrategyBuilder;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudgetBuilder;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudgetBuilder;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBindingBuilder;
 import io.fabric8.kubernetes.api.model.rbac.PolicyRule;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -28,7 +28,7 @@
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyIngressRuleBuilder;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeer;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.ContainerEnvVar;
 import io.strimzi.api.kafka.model.CruiseControlResources;
 import io.strimzi.api.kafka.model.CruiseControlSpec;
@@ -575,7 +575,7 @@ public NetworkPolicy generateNetworkPolicy(String operatorNamespace, Labels oper
         NetworkPolicyIngressRule restApiRule = new NetworkPolicyIngressRuleBuilder()
                 .addNewPort()
                     .withNewPort(REST_API_PORT)
-                    .withNewProtocol("TCP")
+                    .withProtocol("TCP")
                 .endPort()
                 .build();
 
@@ -594,7 +594,7 @@ public NetworkPolicy generateNetworkPolicy(String operatorNamespace, Labels oper
             NetworkPolicyIngressRule metricsRule = new NetworkPolicyIngressRuleBuilder()
                     .addNewPort()
                         .withNewPort(METRICS_PORT)
-                        .withNewProtocol("TCP")
+                        .withProtocol("TCP")
                     .endPort()
                     .withFrom()
                     .build();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -16,7 +16,7 @@
 import io.fabric8.kubernetes.api.model.Volume;
 import io.fabric8.kubernetes.api.model.VolumeMount;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.CertSecretSource;
 import io.strimzi.api.kafka.model.ContainerEnvVar;
 import io.strimzi.api.kafka.model.KafkaBridgeConsumerSpec;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -35,7 +35,7 @@
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyIngressRuleBuilder;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeer;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.fabric8.kubernetes.api.model.rbac.RoleRef;
 import io.fabric8.kubernetes.api.model.rbac.RoleRefBuilder;
@@ -782,7 +782,7 @@ public NetworkPolicy generateNetworkPolicy(boolean connectorOperatorEnabled,
             NetworkPolicyIngressRule restApiRule = new NetworkPolicyIngressRuleBuilder()
                     .addNewPort()
                         .withNewPort(REST_API_PORT)
-                        .withNewProtocol("TCP")
+                        .withProtocol("TCP")
                     .endPort()
                     .build();
 
@@ -819,7 +819,7 @@ public NetworkPolicy generateNetworkPolicy(boolean connectorOperatorEnabled,
                 NetworkPolicyIngressRule metricsRule = new NetworkPolicyIngressRuleBuilder()
                         .addNewPort()
                             .withNewPort(METRICS_PORT)
-                            .withNewProtocol("TCP")
+                            .withProtocol("TCP")
                         .endPort()
                         .withFrom()
                         .build();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -14,7 +14,7 @@
 import io.fabric8.kubernetes.api.model.Volume;
 import io.fabric8.kubernetes.api.model.VolumeMount;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.CertSecretSource;
 import io.strimzi.api.kafka.model.ContainerEnvVar;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ModelUtils.java
Patch:
@@ -464,8 +464,8 @@ public static List<Toleration> removeEmptyValuesFromTolerations(List<Toleration>
     public static AffinityBuilder populateAffinityBuilderWithRackLabelSelector(AffinityBuilder builder, Affinity userAffinity, String topologyKey) {
         // We need to add node affinity to make sure the pods are scheduled only on nodes with the rack label
         NodeSelectorRequirement selector = new NodeSelectorRequirementBuilder()
-                .withNewOperator("Exists")
-                .withNewKey(topologyKey)
+                .withOperator("Exists")
+                .withKey(topologyKey)
                 .build();
 
         if (userAffinity != null

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ProbeGenerator.java
Patch:
@@ -46,7 +46,7 @@ public static io.fabric8.kubernetes.api.model.Probe httpProbe(Probe probeConfig,
         }
         io.fabric8.kubernetes.api.model.Probe probe = defaultBuilder(probeConfig)
                 .withNewHttpGet()
-                    .withNewPath(path)
+                    .withPath(path)
                     .withNewPort(port)
                 .endHttpGet()
                 .build();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -27,7 +27,7 @@
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyIngressRuleBuilder;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeer;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPort;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.ContainerEnvVar;
 import io.strimzi.api.kafka.model.InlineLogging;
 import io.strimzi.api.kafka.model.Kafka;
@@ -418,7 +418,7 @@ public NetworkPolicy generateNetworkPolicy(String operatorNamespace, Labels oper
             NetworkPolicyIngressRule metricsRule = new NetworkPolicyIngressRuleBuilder()
                     .addNewPort()
                         .withNewPort(METRICS_PORT)
-                        .withNewProtocol("TCP")
+                        .withProtocol("TCP")
                     .endPort()
                     .withFrom()
                     .build();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -799,7 +799,7 @@ public void testUserOperatorContainerSecurityContext() {
 
         SecurityContext securityContext = new SecurityContextBuilder()
                 .withPrivileged(false)
-                .withNewReadOnlyRootFilesystem(false)
+                .withReadOnlyRootFilesystem(false)
                 .withAllowPrivilegeEscalation(false)
                 .withRunAsNonRoot(true)
                 .withNewCapabilities()
@@ -836,7 +836,7 @@ public void testTopicOperatorContainerSecurityContext() {
 
         SecurityContext securityContext = new SecurityContextBuilder()
                 .withPrivileged(false)
-                .withNewReadOnlyRootFilesystem(false)
+                .withReadOnlyRootFilesystem(false)
                 .withAllowPrivilegeEscalation(false)
                 .withRunAsNonRoot(true)
                 .withNewCapabilities()
@@ -873,7 +873,7 @@ public void testTlsSidecarContainerSecurityContext() {
 
         SecurityContext securityContext = new SecurityContextBuilder()
                 .withPrivileged(false)
-                .withNewReadOnlyRootFilesystem(false)
+                .withReadOnlyRootFilesystem(false)
                 .withAllowPrivilegeEscalation(false)
                 .withRunAsNonRoot(true)
                 .withNewCapabilities()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/JmxTransTest.java
Patch:
@@ -210,8 +210,8 @@ public void testTemplate() {
                     .withNewRequiredDuringSchedulingIgnoredDuringExecution()
                         .withNodeSelectorTerms(new NodeSelectorTermBuilder()
                                 .addNewMatchExpression()
-                                    .withNewKey("key1")
-                                    .withNewOperator("In")
+                                    .withKey("key1")
+                                    .withOperator("In")
                                     .withValues("value1", "value2")
                                 .endMatchExpression()
                                 .build())
@@ -359,7 +359,7 @@ public void testContainerSecurityContext() {
 
         SecurityContext securityContext = new SecurityContextBuilder()
                 .withPrivileged(false)
-                .withNewReadOnlyRootFilesystem(false)
+                .withReadOnlyRootFilesystem(false)
                 .withAllowPrivilegeEscalation(false)
                 .withRunAsNonRoot(true)
                 .withNewCapabilities()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -25,7 +25,7 @@
 import io.fabric8.kubernetes.api.model.TopologySpreadConstraint;
 import io.fabric8.kubernetes.api.model.TopologySpreadConstraintBuilder;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.CertSecretSource;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
 import io.strimzi.api.kafka.model.ContainerEnvVar;
@@ -370,8 +370,8 @@ public void testTemplate() {
                     .withNewRequiredDuringSchedulingIgnoredDuringExecution()
                         .withNodeSelectorTerms(new NodeSelectorTermBuilder()
                                 .addNewMatchExpression()
-                                    .withNewKey("key1")
-                                    .withNewOperator("In")
+                                    .withKey("key1")
+                                    .withOperator("In")
                                     .withValues("value1", "value2")
                                 .endMatchExpression()
                                 .build())

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -33,7 +33,7 @@
 import io.fabric8.kubernetes.api.model.VolumeMount;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.strimzi.api.kafka.model.CertSecretSource;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
@@ -1238,7 +1238,7 @@ public void testKafkaConnectContainerSecurityContext() {
 
         SecurityContext securityContext = new SecurityContextBuilder()
                 .withPrivileged(false)
-                .withNewReadOnlyRootFilesystem(false)
+                .withReadOnlyRootFilesystem(false)
                 .withAllowPrivilegeEscalation(false)
                 .withRunAsNonRoot(true)
                 .withNewCapabilities()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -31,7 +31,7 @@
 import io.fabric8.kubernetes.api.model.VolumeMount;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.fabric8.openshift.api.model.BinaryBuildSource;
 import io.fabric8.openshift.api.model.BuildConfig;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaExporterTest.java
Patch:
@@ -345,8 +345,8 @@ public void testTemplate() {
                     .withNewRequiredDuringSchedulingIgnoredDuringExecution()
                         .withNodeSelectorTerms(new NodeSelectorTermBuilder()
                                 .addNewMatchExpression()
-                                    .withNewKey("key1")
-                                    .withNewOperator("In")
+                                    .withKey("key1")
+                                    .withOperator("In")
                                     .withValues("value1", "value2")
                                 .endMatchExpression()
                                 .build())

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -27,7 +27,7 @@
 import io.fabric8.kubernetes.api.model.VolumeMount;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.CertSecretSource;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
 import io.strimzi.api.kafka.model.ContainerEnvVar;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -21,7 +21,7 @@
 import io.fabric8.kubernetes.api.model.ServiceAccount;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.PodSecurityContextBuilder;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.CertSecretSource;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
 import io.strimzi.api.kafka.model.ContainerEnvVar;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ModelUtilsTest.java
Patch:
@@ -154,8 +154,8 @@ public void testParsePodTemplate()  {
                     .withNewRequiredDuringSchedulingIgnoredDuringExecution()
                         .withNodeSelectorTerms(new NodeSelectorTermBuilder()
                                 .addNewMatchExpression()
-                                    .withNewKey("key1")
-                                    .withNewOperator("In")
+                                    .withKey("key1")
+                                    .withOperator("In")
                                     .withValues("value1", "value2")
                                 .endMatchExpression()
                                 .build())

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ProbeGeneratorTest.java
Patch:
@@ -67,7 +67,7 @@ public void testHttpProbe() {
         Probe probe = ProbeGenerator.httpProbe(DEFAULT_CONFIG, "path", "1001");
         assertThat(probe, is(new ProbeBuilder()
                 .withNewHttpGet()
-                    .withNewPath("path")
+                    .withPath("path")
                     .withNewPort("1001")
                 .endHttpGet()
                 .withInitialDelaySeconds(1)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -30,7 +30,7 @@
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyIngressRule;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.ContainerEnvVar;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetrics;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetricsBuilder;
@@ -968,7 +968,7 @@ public void testGenerateSTSWithPersistentVolumeEphemeralWithSizeLimit()    {
         Kafka ka = new KafkaBuilder(ResourceUtils.createKafka(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCm, jmxMetricsConfig, configurationJson, zooConfigurationJson))
                 .editSpec()
                     .editZookeeper()
-                        .withNewEphemeralStorage().withNewSizeLimit(sizeLimit).endEphemeralStorage()
+                        .withNewEphemeralStorage().withSizeLimit(sizeLimit).endEphemeralStorage()
                     .endZookeeper()
                 .endSpec()
                 .build();
@@ -1124,7 +1124,7 @@ public void testZookeeperContainerSecurityContext() {
 
         SecurityContext securityContext = new SecurityContextBuilder()
                 .withPrivileged(false)
-                .withNewReadOnlyRootFilesystem(false)
+                .withReadOnlyRootFilesystem(false)
                 .withAllowPrivilegeEscalation(false)
                 .withRunAsNonRoot(true)
                 .withNewCapabilities()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -926,7 +926,7 @@ public void testConnectorNotReadyWhenExceptionFromConnectRestApi() {
         Crds.kafkaConnectOperation(client).inNamespace(NAMESPACE).create(connect);
         waitForConnectReady(connectName);
 
-        // triggered atleast once (Connect creation)
+        // triggered at least once (Connect creation)
         verify(api, atLeastOnce()).list(
                 eq(KafkaConnectResources.qualifiedServiceName(connectName, NAMESPACE)), eq(KafkaConnectCluster.REST_API_PORT));
         verify(api, never()).createOrUpdatePutRequest(any(),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -15,7 +15,7 @@
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
 import io.fabric8.kubernetes.api.model.apps.StatefulSetBuilder;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.fabric8.openshift.api.model.Route;
 import io.fabric8.openshift.api.model.RouteIngressBuilder;
 import io.fabric8.openshift.api.model.RouteStatus;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -8,7 +8,7 @@
 import io.fabric8.kubernetes.api.model.ConfigMapBuilder;
 import io.fabric8.kubernetes.api.model.Service;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.KafkaBridge;
 import io.strimzi.api.kafka.model.KafkaBridgeBuilder;
 import io.strimzi.api.kafka.model.KafkaBridgeConsumerSpec;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -136,7 +136,7 @@ private Future<Void> createConnectCluster(VertxTestContext context, KafkaConnect
                     assertThat(mockClient.apps().deployments().inNamespace(NAMESPACE).withName(KafkaConnectResources.deploymentName(CLUSTER_NAME)).get(), is(notNullValue()));
                     assertThat(mockClient.configMaps().inNamespace(NAMESPACE).withName(KafkaConnectResources.metricsAndLogConfigMapName(CLUSTER_NAME)).get(), is(notNullValue()));
                     assertThat(mockClient.services().inNamespace(NAMESPACE).withName(KafkaConnectResources.serviceName(CLUSTER_NAME)).get(), is(notNullValue()));
-                    assertThat(mockClient.policy().podDisruptionBudget().inNamespace(NAMESPACE).withName(KafkaConnectResources.deploymentName(CLUSTER_NAME)).get(), is(notNullValue()));
+                    assertThat(mockClient.policy().v1beta1().podDisruptionBudget().inNamespace(NAMESPACE).withName(KafkaConnectResources.deploymentName(CLUSTER_NAME)).get(), is(notNullValue()));
                 } else {
                     assertThat(mockClient.apps().deployments().inNamespace(NAMESPACE).withName(KafkaConnectResources.deploymentName(CLUSTER_NAME)).get(), is(nullValue()));
                     verify(mockClient, never()).customResources(KafkaConnect.class);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -9,7 +9,7 @@
 import io.fabric8.kubernetes.api.model.Service;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.KafkaConnectorList;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperatorTest.java
Patch:
@@ -8,7 +8,7 @@
 import io.fabric8.kubernetes.api.model.ConfigMapBuilder;
 import io.fabric8.kubernetes.api.model.Service;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.openshift.api.model.BuildConfig;
 import io.fabric8.openshift.api.model.DeploymentConfig;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -129,7 +129,7 @@ public void test(VertxTestContext context) {
                 return Future.succeededFuture(Crds.kafkaConnectorOperation(client)
                         .inNamespace(namespace)
                         .withName(connectorName)
-                        .patch(invocation.getArgument(1)));
+                        .patch((KafkaConnector) invocation.getArgument(1)));
             } catch (Exception e) {
                 return Future.failedFuture(e);
             }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -137,7 +137,7 @@ private Future<Void> createMirrorMaker2Cluster(VertxTestContext context, KafkaCo
                     assertThat(mockClient.apps().deployments().inNamespace(NAMESPACE).withName(KafkaMirrorMaker2Resources.deploymentName(CLUSTER_NAME)).get(), is(notNullValue()));
                     assertThat(mockClient.configMaps().inNamespace(NAMESPACE).withName(KafkaMirrorMaker2Resources.metricsAndLogConfigMapName(CLUSTER_NAME)).get(), is(notNullValue()));
                     assertThat(mockClient.services().inNamespace(NAMESPACE).withName(KafkaMirrorMaker2Resources.serviceName(CLUSTER_NAME)).get(), is(notNullValue()));
-                    assertThat(mockClient.policy().podDisruptionBudget().inNamespace(NAMESPACE).withName(KafkaMirrorMaker2Resources.deploymentName(CLUSTER_NAME)).get(), is(notNullValue()));
+                    assertThat(mockClient.policy().v1beta1().podDisruptionBudget().inNamespace(NAMESPACE).withName(KafkaMirrorMaker2Resources.deploymentName(CLUSTER_NAME)).get(), is(notNullValue()));
                 } else {
                     assertThat(mockClient.apps().deployments().inNamespace(NAMESPACE).withName(KafkaMirrorMaker2Resources.deploymentName(CLUSTER_NAME)).get(), is(nullValue()));
                     verify(mockClient, never()).customResources(KafkaMirrorMaker2.class);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorTest.java
Patch:
@@ -9,7 +9,7 @@
 import io.fabric8.kubernetes.api.model.Service;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2Resources;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2ClusterSpec;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -7,7 +7,7 @@
 import io.fabric8.kubernetes.api.model.ConfigMap;
 import io.fabric8.kubernetes.api.model.ConfigMapBuilder;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerConsumerSpec;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerConsumerSpecBuilder;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -559,6 +559,7 @@ public void testNewWithMissingHardGoals(VertxTestContext context) throws IOExcep
             })));
     }
 
+
     @Test
     public void testUnknownPropertyInSpec(VertxTestContext context) throws IOException, URISyntaxException {
         MockCruiseControl.setupCCRebalanceResponse(ccServer, 2);
@@ -1244,7 +1245,7 @@ private void mockRebalanceOperator(CrdOperator<KubernetesClient, KafkaRebalance,
                 return Future.succeededFuture(Crds.kafkaRebalanceOperation(client)
                         .inNamespace(namespace)
                         .withName(resource)
-                        .patch(invocation.getArgument(1)));
+                        .patch((KafkaRebalance) invocation.getArgument(1)));
             } catch (Exception e) {
                 return Future.failedFuture(e);
             }
@@ -1256,7 +1257,7 @@ private void mockRebalanceOperator(CrdOperator<KubernetesClient, KafkaRebalance,
                 return Future.succeededFuture(Crds.kafkaRebalanceOperation(client)
                         .inNamespace(namespace)
                         .withName(resource)
-                        .patch(invocation.getArgument(1)));
+                        .patch((KafkaRebalance) invocation.getArgument(1)));
             } catch (Exception e) {
                 return Future.failedFuture(e);
             }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaStatusTest.java
Patch:
@@ -1091,7 +1091,7 @@ public void testModelWarnings(VertxTestContext context) throws ParseException {
                 .editOrNewSpec()
                     .editOrNewKafka()
                         .withNewPersistentClaimStorage()
-                            .withNewSize("100Gi")
+                            .withSize("100Gi")
                         .endPersistentClaimStorage()
                     .endKafka()
                 .endSpec()

File: mockkube/src/main/java/io/strimzi/test/mockkube/DeploymentMockBuilder.java
Patch:
@@ -73,7 +73,7 @@ protected void mockCreate(String resourceName, RollableScalableResource<Deployme
 
     @Override
     protected void mockPatch(String resourceName, RollableScalableResource<Deployment> resource) {
-        when(resource.patch(any())).thenAnswer(invocation -> {
+        when(resource.patch(any(Deployment.class))).thenAnswer(invocation -> {
             Deployment deployment = invocation.getArgument(0);
             String deploymentName = deployment.getMetadata().getName();
             // Initialize the map with empty collection in cases where deployment was initialized with zero replicas

File: mockkube/src/main/java/io/strimzi/test/mockkube/MockBuilder.java
Patch:
@@ -368,8 +368,9 @@ protected void fireWatchers(String resourceName, T resource, Watcher.Action acti
         }
     }
 
+    @SuppressWarnings("unchecked")
     protected void mockPatch(String resourceName, R resource) {
-        when(resource.patch(any())).thenAnswer(invocation -> {
+        when(resource.patch((T) any())).thenAnswer(invocation -> {
             return doPatch(resourceName, resource, invocation.getArgument(0));
         });
     }

File: mockkube/src/main/java/io/strimzi/test/mockkube/StatefulSetMockBuilder.java
Patch:
@@ -98,7 +98,7 @@ private void mockNoncascadingDelete(String resourceName, EditReplacePatchDeletab
     }
 
     private void mockNoncascadingPatch(String resourceName, EditReplacePatchDeletable<StatefulSet> c) {
-        when(c.patch(any())).thenAnswer(patchInvocation -> {
+        when(c.patch(any(StatefulSet.class))).thenAnswer(patchInvocation -> {
             StatefulSet argument = patchInvocation.getArgument(0);
             return doPatch(resourceName, argument, argument.getSpec().getReplicas());
         });

File: mockkube/src/test/java/io/strimzi/test/io/strimzi/test/mockkube/MockKubeTest.java
Patch:
@@ -153,7 +153,7 @@ public void testPodCreateDeleteUnscoped(Class<RT> cls,
         RT resource = (RT) w.lastEvent().resource;
         resource.getMetadata().setResourceVersion(null);
         resource.getMetadata().setGeneration(null);
-        assertThat(pod, is(resource));
+        assertThat(resource, is(pod));
         assertThat(mixedOp.apply(client).delete(pod), is(false));
 
         // TODO createOrReplace(), createOrReplaceWithName()
@@ -187,6 +187,8 @@ public void testPodNameScopedCreateListGetDelete(Class<RT> cls,
         RT item = items.get(0);
         item.getMetadata().setResourceVersion(null);
         item.getMetadata().setGeneration(null);
+
+
         assertThat(item, is(pod));
 
         // List with namespace

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/PodDisruptionBudgetOperator.java
Patch:
@@ -4,8 +4,8 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
-import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudgetList;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudget;
+import io.fabric8.kubernetes.api.model.policy.v1beta1.PodDisruptionBudgetList;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -19,6 +19,6 @@ public PodDisruptionBudgetOperator(Vertx vertx, KubernetesClient client) {
 
     @Override
     protected MixedOperation<PodDisruptionBudget, PodDisruptionBudgetList, Resource<PodDisruptionBudget>> operation() {
-        return client.policy().podDisruptionBudget();
+        return client.policy().v1beta1().podDisruptionBudget();
     }
 }

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ServiceAccountOperatorTest.java
Patch:
@@ -165,7 +165,7 @@ public void testSecretsPatching(VertxTestContext context)   {
         Checkpoint async = context.checkpoint();
         op.reconcile(Reconciliation.DUMMY_RECONCILIATION, NAMESPACE, RESOURCE_NAME, desired)
                 .onComplete(context.succeeding(rr -> {
-                    verify(mockResource, times(1)).patch(any());
+                    verify(mockResource, times(1)).patch(any(ServiceAccount.class));
 
                     assertThat(saCaptor.getValue(), is(notNullValue()));
                     assertThat(saCaptor.getValue().getSecrets().size(), is(2));

File: systemtest/src/main/java/io/strimzi/systemtest/SetupClusterOperator.java
Patch:
@@ -74,7 +74,6 @@ public class SetupClusterOperator {
      * This method install Strimzi Cluster Operator based on environment variable configuration.
      * It can install operator by classic way (apply bundle yamls) or use OLM. For OLM you need to set all other OLM env variables.
      * Don't use this method in tests, where specific configuration of CO is needed.
-     * @param namespace namespace where CO should be installed into
      */
     public SetupClusterOperator runInstallation() {
         if (Environment.isOlmInstall()) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/kafkaclients/KafkaBasicExampleClients.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd.kafkaclients;
 
-import io.fabric8.kubernetes.api.model.batch.JobBuilder;
+import io.fabric8.kubernetes.api.model.batch.v1.JobBuilder;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.resources.ResourceManager;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/kafkaclients/KafkaBridgeExampleClients.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd.kafkaclients;
 
-import io.fabric8.kubernetes.api.model.batch.JobBuilder;
+import io.fabric8.kubernetes.api.model.batch.v1.JobBuilder;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.resources.ResourceManager;
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/kafkaclients/KafkaOauthExampleClients.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd.kafkaclients;
 
-import io.fabric8.kubernetes.api.model.batch.JobBuilder;
+import io.fabric8.kubernetes.api.model.batch.v1.JobBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.keycloak.KeycloakInstance;
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/kafkaclients/KafkaTracingExampleClients.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd.kafkaclients;
 
-import io.fabric8.kubernetes.api.model.batch.JobBuilder;
+import io.fabric8.kubernetes.api.model.batch.v1.JobBuilder;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.resources.ResourceManager;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/JobResource.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.resources.kubernetes;
 
-import io.fabric8.kubernetes.api.model.batch.Job;
+import io.fabric8.kubernetes.api.model.batch.v1.Job;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.ResourceType;
 

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaConnectS2ITemplates.java
Patch:
@@ -68,7 +68,7 @@ public static KafkaConnectS2IBuilder defaultKafkaConnectS2I(KafkaConnectS2I kafk
                 .withReplicas(kafkaConnectReplicas)
                 // Try it without TLS
                 .withNewTls()
-                    .withTrustedCertificates(new CertSecretSourceBuilder().withNewSecretName(kafkaClusterName + "-cluster-ca-cert").withCertificate("ca.crt").build())
+                    .withTrustedCertificates(new CertSecretSourceBuilder().withSecretName(kafkaClusterName + "-cluster-ca-cert").withCertificate("ca.crt").build())
                 .endTls()
                 .withInsecureSourceRepository(true)
                 .withNewInlineLogging()

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaConnectTemplates.java
Patch:
@@ -82,7 +82,7 @@ private static KafkaConnectBuilder defaultKafkaConnect(KafkaConnect kafkaConnect
                 .withBootstrapServers(KafkaResources.tlsBootstrapAddress(kafkaClusterName))
                 .withReplicas(kafkaConnectReplicas)
                 .withNewTls()
-                    .withTrustedCertificates(new CertSecretSourceBuilder().withNewSecretName(kafkaClusterName + "-cluster-ca-cert").withCertificate("ca.crt").build())
+                    .withTrustedCertificates(new CertSecretSourceBuilder().withSecretName(kafkaClusterName + "-cluster-ca-cert").withCertificate("ca.crt").build())
                 .endTls()
                 .addToConfig("group.id", KafkaConnectResources.deploymentName(kafkaClusterName))
                 .addToConfig("offset.storage.topic", KafkaConnectResources.configStorageTopicOffsets(kafkaClusterName))

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaMirrorMaker2Templates.java
Patch:
@@ -71,14 +71,14 @@ private static KafkaMirrorMaker2Builder defaultKafkaMirrorMaker2(KafkaMirrorMake
             targetClusterSpec = new KafkaMirrorMaker2ClusterSpecBuilder(targetClusterSpec)
                 .withBootstrapServers(KafkaResources.tlsBootstrapAddress(kafkaTargetClusterName))
                 .withNewTls()
-                    .withTrustedCertificates(new CertSecretSourceBuilder().withNewSecretName(KafkaResources.clusterCaCertificateSecretName(kafkaTargetClusterName)).withCertificate("ca.crt").build())
+                    .withTrustedCertificates(new CertSecretSourceBuilder().withSecretName(KafkaResources.clusterCaCertificateSecretName(kafkaTargetClusterName)).withCertificate("ca.crt").build())
                 .endTls()
                 .build();
 
             sourceClusterSpec = new KafkaMirrorMaker2ClusterSpecBuilder(sourceClusterSpec)
                 .withBootstrapServers(KafkaResources.tlsBootstrapAddress(kafkaSourceClusterName))
                 .withNewTls()
-                    .withTrustedCertificates(new CertSecretSourceBuilder().withNewSecretName(KafkaResources.clusterCaCertificateSecretName(kafkaSourceClusterName)).withCertificate("ca.crt").build())
+                    .withTrustedCertificates(new CertSecretSourceBuilder().withSecretName(KafkaResources.clusterCaCertificateSecretName(kafkaSourceClusterName)).withCertificate("ca.crt").build())
                 .endTls()
                 .build();
         }

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaTemplates.java
Patch:
@@ -64,13 +64,13 @@ public static KafkaBuilder kafkaPersistent(String name, int kafkaReplicas, int z
             .editSpec()
                 .editKafka()
                     .withNewPersistentClaimStorage()
-                        .withNewSize("100")
+                        .withSize("100")
                         .withDeleteClaim(true)
                     .endPersistentClaimStorage()
                 .endKafka()
                 .editZookeeper()
                     .withNewPersistentClaimStorage()
-                        .withNewSize("100")
+                        .withSize("100")
                         .withDeleteClaim(true)
                     .endPersistentClaimStorage()
                 .endZookeeper()

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/JobUtils.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.utils.kubeUtils.controllers;
 
-import io.fabric8.kubernetes.api.model.batch.JobStatus;
+import io.fabric8.kubernetes.api.model.batch.v1.JobStatus;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.test.TestUtils;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/SecretUtils.java
Patch:
@@ -66,13 +66,13 @@ public static void waitForSecretDeletion(String secretName, Runnable onTimeout)
     public static void createSecret(String namespaceName, String secretName, String dataKey, String dataValue) {
         LOGGER.info("Creating secret {}", secretName);
         kubeClient(namespaceName).createSecret(new SecretBuilder()
-            .withNewApiVersion("v1")
-            .withNewKind("Secret")
+            .withApiVersion("v1")
+            .withKind("Secret")
             .withNewMetadata()
                 .withName(secretName)
                 .withNamespace(namespaceName)
             .endMetadata()
-            .withNewType("Opaque")
+            .withType("Opaque")
                 .withData(Collections.singletonMap(dataKey, dataValue))
             .build());
     }

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -881,7 +881,7 @@ void testConnectTlsAuthWithWeirdUserName(ExtensionContext extensionContext) {
                 .withNewTls()
                     .withTrustedCertificates(new CertSecretSourceBuilder()
                         .withCertificate("ca.crt")
-                        .withNewSecretName(KafkaResources.clusterCaCertificateSecretName(clusterName))
+                        .withSecretName(KafkaResources.clusterCaCertificateSecretName(clusterName))
                         .build())
                 .endTls()
                 .withNewKafkaClientAuthenticationTls()
@@ -957,7 +957,7 @@ void testConnectScramShaAuthWithWeirdUserName(ExtensionContext extensionContext)
                     .withNewTls()
                         .withTrustedCertificates(new CertSecretSourceBuilder()
                                 .withCertificate("ca.crt")
-                                .withNewSecretName(KafkaResources.clusterCaCertificateSecretName(clusterName))
+                                .withSecretName(KafkaResources.clusterCaCertificateSecretName(clusterName))
                                 .build())
                     .endTls()
                 .endSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerST.java
Patch:
@@ -267,7 +267,7 @@ void testKafkaPodPendingDueToRack(ExtensionContext extensionContext) {
 
         NodeSelectorRequirement nsr = new NodeSelectorRequirementBuilder()
                 .withKey("dedicated_test")
-                .withNewOperator("In")
+                .withOperator("In")
                 .withValues("Kafka")
                 .build();
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.security.oauth;
 
-import io.fabric8.kubernetes.api.model.batch.Job;
+import io.fabric8.kubernetes.api.model.batch.v1.Job;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.SetupClusterOperator;
 import io.strimzi.systemtest.enums.DefaultNetworkPolicy;

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -432,8 +432,8 @@ void testIntrospectionEndpoint(ExtensionContext extensionContext) {
         String introspectionKafka = oauthClusterName + "-intro";
 
         CertSecretSource cert = new CertSecretSourceBuilder()
-                .withNewSecretName(KeycloakInstance.KEYCLOAK_SECRET_NAME)
-                .withNewCertificate(KeycloakInstance.KEYCLOAK_SECRET_CERT)
+                .withSecretName(KeycloakInstance.KEYCLOAK_SECRET_NAME)
+                .withCertificate(KeycloakInstance.KEYCLOAK_SECRET_CERT)
                 .build();
 
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaEphemeral(introspectionKafka, 1)

File: systemtest/src/test/java/io/strimzi/systemtest/specific/HelmChartST.java
Patch:
@@ -8,6 +8,7 @@
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.systemtest.annotations.IsolatedTest;
 import io.strimzi.systemtest.AbstractST;
+import io.strimzi.systemtest.resources.specific.HelmResource;
 import io.strimzi.systemtest.templates.crd.KafkaBridgeTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
@@ -30,6 +31,7 @@ class HelmChartST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(HelmChartST.class);
     static final String NAMESPACE = "helm-chart-cluster-test";
+    private HelmResource helmResource = new HelmResource(NAMESPACE);
 
     @IsolatedTest
     void testStrimziComponentsViaHelmChart(ExtensionContext extensionContext) {

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java
Patch:
@@ -96,7 +96,7 @@ private void performUpgradeVerification(JsonObject testParameters, ExtensionCont
         // 2. Approve installation
         //   a) get name of install-plan
         //   b) approve installation
-        olmResource.create(namespace, OlmInstallationStrategy.Manual, fromVersion);
+        olmResource.create(OlmInstallationStrategy.Manual, fromVersion);
 
         String url = testParameters.getString("urlFrom");
         File dir = FileUtils.downloadAndUnzip(url);
@@ -162,7 +162,7 @@ void setup() {
         cluster.setNamespace(namespace);
         cluster.createNamespace(namespace);
 
-        olmResource = new OlmResource();
+        olmResource = new OlmResource(namespace);
     }
 
     @AfterAll

File: systemtest/src/main/java/io/strimzi/systemtest/resources/specific/HelmResource.java
Patch:
@@ -115,7 +115,8 @@ private void clusterOperator(long operationTimeout, long reconciliationInterval)
                 entry("resources.limits.cpu", LIMITS_CPU),
                 entry("logLevelOverride", Environment.STRIMZI_LOG_LEVEL),
                 entry("fullReconciliationIntervalMs", Long.toString(reconciliationInterval)),
-                entry("operationTimeoutMs", Long.toString(operationTimeout)))
+                entry("operationTimeoutMs", Long.toString(operationTimeout)),
+                entry("featureGates", Environment.STRIMZI_FEATURE_GATES))
                 .collect(TestUtils.entriesToMap()));
 
         Path pathToChart = new File(HELM_CHART).toPath();

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaUserTemplates.java
Patch:
@@ -58,13 +58,14 @@ public static KafkaUser kafkaUserWithoutWait(KafkaUser user) {
         return user;
     }
 
-    public static KafkaUserBuilder userWithQuotas(KafkaUser user, Integer prodRate, Integer consRate, Integer requestPerc) {
+    public static KafkaUserBuilder userWithQuotas(KafkaUser user, Integer prodRate, Integer consRate, Integer requestPerc, Double mutRate) {
         return new KafkaUserBuilder(user)
                 .editSpec()
                     .withNewQuotas()
                         .withConsumerByteRate(consRate)
                         .withProducerByteRate(prodRate)
                         .withRequestPercentage(requestPerc)
+                        .withControllerMutationRate(mutRate)
                     .endQuotas()
                 .endSpec();
     }

File: user-operator/src/test/java/io/strimzi/operator/user/ResourceUtils.java
Patch:
@@ -113,11 +113,12 @@ public static KafkaUser createKafkaUserScramSha() {
         return createKafkaUser(new KafkaUserScramSha512ClientAuthentication());
     }
 
-    public static KafkaUser createKafkaUserQuotas(Integer consumerByteRate, Integer producerByteRate, Integer requestPercentage) {
+    public static KafkaUser createKafkaUserQuotas(Integer consumerByteRate, Integer producerByteRate, Integer requestPercentage, Double controllerMutationRate) {
         KafkaUserQuotas kuq = new KafkaUserQuotasBuilder()
                 .withConsumerByteRate(consumerByteRate)
                 .withProducerByteRate(producerByteRate)
                 .withRequestPercentage(requestPercentage)
+                .withControllerMutationRate(controllerMutationRate)
                 .build();
 
         return createKafkaUser(kuq);

File: api-conversion/src/main/java/io/strimzi/kafka/api/conversion/converter/Conversion.java
Patch:
@@ -32,7 +32,7 @@
  * @param <T> The converted type
  */
 public interface Conversion<T> {
-    Logger log = LogManager.getLogger(Conversion.class);
+    Logger LOGGER = LogManager.getLogger(Conversion.class);
 
     Conversion<Object> NOOP = new Conversion<>() {
         @Override

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -33,7 +33,8 @@
  * Cluster Operator configuration
  */
 public class ClusterOperatorConfig {
-    private static final Logger log = LogManager.getLogger(ClusterOperatorConfig.class.getName());
+    private static final Logger LOGGER = LogManager.getLogger(ClusterOperatorConfig.class.getName());
+
 
     public static final String STRIMZI_NAMESPACE = "STRIMZI_NAMESPACE";
     public static final String STRIMZI_FULL_RECONCILIATION_INTERVAL_MS = "STRIMZI_FULL_RECONCILIATION_INTERVAL_MS";
@@ -159,7 +160,7 @@ public static ClusterOperatorConfig fromMap(Map<String, String> map) {
      */
     private static void warningsForRemovedEndVars(Map<String, String> map) {
         if (map.containsKey(STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE))    {
-            log.warn("Kafka TLS sidecar container has been removed and the environment variable {} is not used anymore. " +
+            LOGGER.warn("Kafka TLS sidecar container has been removed and the environment variable {} is not used anymore. " +
                     "You can remove it from the Strimzi Cluster Operator deployment.", STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE);
         }
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperScalerProvider.java
Patch:
@@ -5,6 +5,7 @@
 package io.strimzi.operator.cluster.operator.resource;
 
 import io.fabric8.kubernetes.api.model.Secret;
+import io.strimzi.operator.common.Reconciliation;
 import io.vertx.core.Vertx;
 
 import java.util.function.Function;
@@ -16,6 +17,7 @@ public interface ZookeeperScalerProvider {
     /**
      * Creates an instance of ZookeeperScaler
      *
+     * @param reconciliation                The reconciliation
      * @param vertx                         Vertx instance
      * @param zookeeperConnectionString     Connection string to connect to the right Zookeeper
      * @param zkNodeAddress                 Function for generating the Zookeeper node addresses
@@ -25,5 +27,5 @@ public interface ZookeeperScalerProvider {
      *
      * @return  ZookeeperScaler instance
      */
-    ZookeeperScaler createZookeeperScaler(Vertx vertx, String zookeeperConnectionString, Function<Integer, String> zkNodeAddress, Secret clusterCaCertSecret, Secret coKeySecret, long operationTimeoutMs);
+    ZookeeperScaler createZookeeperScaler(Reconciliation reconciliation, Vertx vertx, String zookeeperConnectionString, Function<Integer, String> zkNodeAddress, Secret clusterCaCertSecret, Secret coKeySecret, long operationTimeoutMs);
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractModelTest.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.api.kafka.model.JvmOptions;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
+import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.test.TestUtils;
 
@@ -35,7 +36,7 @@ public class AbstractModelTest {
     // Implement AbstractModel to test the abstract class
     private class Model extends AbstractModel   {
         public Model(HasMetadata resource) {
-            super(resource, "model-app");
+            super(new Reconciliation("test", resource.getKind(), resource.getMetadata().getNamespace(), resource.getMetadata().getName()), resource, "model-app");
         }
 
         @Override

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -27,6 +27,7 @@
 import io.strimzi.api.kafka.model.storage.Storage;
 import io.strimzi.kafka.oauth.server.ServerConfig;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlConfigurationParameters;
+import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.test.annotations.ParallelSuite;
 import io.strimzi.test.annotations.ParallelTest;
 import org.hamcrest.Description;
@@ -302,7 +303,7 @@ public void testNullUserConfiguration()  {
     @ParallelTest
     public void testEmptyUserConfiguration()  {
         Map<String, Object> userConfiguration = new HashMap<>();
-        KafkaConfiguration kafkaConfiguration = new KafkaConfiguration(userConfiguration.entrySet());
+        KafkaConfiguration kafkaConfiguration = new KafkaConfiguration(Reconciliation.DUMMY_RECONCILIATION, userConfiguration.entrySet());
 
         String configuration = new KafkaBrokerConfigurationBuilder()
                 .withUserConfiguration(kafkaConfiguration)
@@ -319,7 +320,7 @@ public void testUserConfiguration()  {
         userConfiguration.put("transaction.state.log.replication.factor", 3);
         userConfiguration.put("transaction.state.log.min.isr", 2);
 
-        KafkaConfiguration kafkaConfiguration = new KafkaConfiguration(userConfiguration.entrySet());
+        KafkaConfiguration kafkaConfiguration = new KafkaConfiguration(Reconciliation.DUMMY_RECONCILIATION, userConfiguration.entrySet());
 
         String configuration = new KafkaBrokerConfigurationBuilder()
                 .withUserConfiguration(kafkaConfiguration)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConfigurationTests.java
Patch:
@@ -5,6 +5,7 @@
 package io.strimzi.operator.cluster.model;
 
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
+import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.test.annotations.ParallelSuite;
 import io.strimzi.test.annotations.ParallelTest;
 
@@ -19,7 +20,7 @@ public class KafkaConfigurationTests {
     KafkaVersion kafkaVersion = KafkaVersionTestUtils.getKafkaVersionLookup().defaultVersion();
 
     void assertConfigError(String key, Object value, String errorMsg) {
-        KafkaConfiguration kafkaConfiguration = new KafkaConfiguration(singletonMap(key, value).entrySet());
+        KafkaConfiguration kafkaConfiguration = new KafkaConfiguration(Reconciliation.DUMMY_RECONCILIATION, singletonMap(key, value).entrySet());
         assertThat(kafkaConfiguration.validate(kafkaVersion), is(singletonList(errorMsg)));
     }
 
@@ -29,7 +30,7 @@ public void unknownConfigIsNotAnError() {
     }
 
     private void assertNoError(String foo, Object value) {
-        KafkaConfiguration kafkaConfiguration = new KafkaConfiguration(singletonMap(foo, value).entrySet());
+        KafkaConfiguration kafkaConfiguration = new KafkaConfiguration(Reconciliation.DUMMY_RECONCILIATION, singletonMap(foo, value).entrySet());
         kafkaConfiguration.validate(kafkaVersion);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -59,6 +59,7 @@
 import static org.junit.jupiter.api.Assertions.assertFalse;
 import static org.junit.jupiter.api.Assertions.assertTrue;
 import static org.junit.jupiter.api.Assertions.fail;
+import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.anyInt;
 import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Mockito.mock;
@@ -159,7 +160,7 @@ public void testReconcileCreateAndUpdate(VertxTestContext context) {
             .build());
         KafkaConnectApi mock = mock(KafkaConnectApi.class);
         when(mock.list(anyString(), anyInt())).thenReturn(Future.succeededFuture(emptyList()));
-        when(mock.listConnectorPlugins(anyString(), anyInt())).thenReturn(Future.succeededFuture(emptyList()));
+        when(mock.listConnectorPlugins(any(), anyString(), anyInt())).thenReturn(Future.succeededFuture(emptyList()));
 
         Checkpoint async = context.checkpoint();
         createConnectCluster(context, mock, false)
@@ -187,7 +188,7 @@ public void testPauseReconcileUnpause(VertxTestContext context) {
                 .build());
         KafkaConnectApi mock = mock(KafkaConnectApi.class);
         when(mock.list(anyString(), anyInt())).thenReturn(Future.succeededFuture(emptyList()));
-        when(mock.listConnectorPlugins(anyString(), anyInt())).thenReturn(Future.succeededFuture(emptyList()));
+        when(mock.listConnectorPlugins(any(), anyString(), anyInt())).thenReturn(Future.succeededFuture(emptyList()));
 
         Checkpoint async = context.checkpoint();
         createConnectCluster(context, mock, true)

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaRebalanceResource.java
Patch:
@@ -41,7 +41,7 @@ public void delete(KafkaRebalance resource) {
     }
     @Override
     public boolean waitForReadiness(KafkaRebalance resource) {
-        return KafkaRebalanceUtils.waitForKafkaRebalanceCustomResourceState(resource.getMetadata().getName(), KafkaRebalanceState.PendingProposal);
+        return KafkaRebalanceUtils.waitForKafkaRebalanceCustomResourceState(resource.getMetadata().getNamespace(), resource.getMetadata().getName(), KafkaRebalanceState.PendingProposal);
     }
 
     public static MixedOperation<KafkaRebalance, KafkaRebalanceList, Resource<KafkaRebalance>> kafkaRebalanceClient() {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaTopicUtils.java
Patch:
@@ -133,9 +133,9 @@ public static void waitForKafkaTopicPartitionChange(String topicName, int partit
      * @param topicName name of KafkaTopic
      * @param state desired state
      */
-    public static boolean waitForKafkaTopicStatus(String namespaceName, String topicName, Enum<?>  state) {
-        KafkaTopic kafkaTopic = KafkaTopicResource.kafkaTopicClient().inNamespace(namespaceName).withName(topicName).get();
-        return ResourceManager.waitForResourceStatus(KafkaTopicResource.kafkaTopicClient(), kafkaTopic, state);
+    public static boolean waitForKafkaTopicStatus(String namespaceName, String topicName, Enum<?> state) {
+        return ResourceManager.waitForResourceStatus(KafkaTopicResource.kafkaTopicClient(), KafkaTopic.RESOURCE_KIND,
+            namespaceName, topicName, state, ResourceOperation.getTimeoutForResourceReadiness(KafkaTopic.RESOURCE_KIND));
     }
 
     public static boolean waitForKafkaTopicReady(String namespaceName, String topicName) {

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -175,7 +175,7 @@ protected void installClusterOperator(ExtensionContext extensionContext, String
         installClusterOperator(extensionContext, Constants.STRIMZI_DEPLOYMENT_NAME, namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL);
     }
 
-    public void installClusterWideClusterOperator(ExtensionContext extensionContext, String namespace, long operationTimeout, long reconciliationInterval) {
+    public synchronized void installClusterWideClusterOperator(ExtensionContext extensionContext, String namespace, long operationTimeout, long reconciliationInterval) {
         prepareEnvForOperator(extensionContext, namespace);
         // Apply role bindings in CO namespace
         applyBindings(extensionContext, namespace);

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlConfigurationST.java
Patch:
@@ -297,7 +297,7 @@ void testConfigurationPerformanceOptions(ExtensionContext extensionContext) thro
         performanceTuningOpts.forEach((key, value) ->
                 assertThat(containerConfiguration, hasEntry(key, value.toString())));
     }
-    
+
     @BeforeAll
     void setup(ExtensionContext extensionContext) throws Exception {
         installClusterWideClusterOperator(extensionContext, NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL);

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -411,7 +411,7 @@ void testKafkaBridgeMetrics(ExtensionContext extensionContext) {
     @Tag(CRUISE_CONTROL)
     void testCruiseControlMetrics() {
 
-        String cruiseControlMetrics = CruiseControlUtils.callApi(CruiseControlUtils.SupportedHttpMethods.GET, "/metrics");
+        String cruiseControlMetrics = CruiseControlUtils.callApi(FIRST_NAMESPACE, CruiseControlUtils.SupportedHttpMethods.GET, "/metrics");
 
         Matcher regex = Pattern.compile("^([^#].*)\\s+([^\\s]*)$", Pattern.MULTILINE).matcher(cruiseControlMetrics);
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/MultipleClusterOperatorsST.java
Patch:
@@ -175,7 +175,7 @@ void testKafkaCCAndRebalanceWithMultipleCOs(ExtensionContext extensionContext) {
 
         assertThat(StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(clusterName)).size(), is(scaleTo));
 
-        KafkaRebalanceUtils.doRebalancingProcess(clusterName);
+        KafkaRebalanceUtils.doRebalancingProcess(DEFAULT_NAMESPACE, clusterName);
     }
 
     void deployCOInNamespace(ExtensionContext extensionContext, String coName, String coNamespace, EnvVar selectorEnv, boolean multipleNamespaces) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlApi.java
Patch:
@@ -14,7 +14,6 @@ public interface CruiseControlApi {
     String CC_REST_API_ERROR_KEY = "errorMessage";
     String CC_REST_API_PROGRESS_KEY = "progress";
     String CC_REST_API_USER_ID_HEADER = "User-Task-ID";
-    String CC_REST_API_SUMMARY = "summary";
 
     /**
      *  Gets the state of the Cruise Control server.

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectCluster.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.cluster.operator.assembly;
 
-import io.debezium.kafka.KafkaCluster;
 import org.apache.kafka.connect.cli.ConnectDistributed;
 import org.apache.kafka.connect.runtime.Connect;
 
@@ -28,8 +27,8 @@ ConnectCluster addConnectNodes(int numNodes) {
         return this;
     }
 
-    ConnectCluster usingBrokers(KafkaCluster kafkaCluster) {
-        this.brokerList = kafkaCluster.brokerList();
+    ConnectCluster usingBrokers(String bootstrapServers) {
+        this.brokerList = bootstrapServers;
         return this;
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleClusterResource.java
Patch:
@@ -26,6 +26,7 @@ public class AclRuleClusterResource extends AclRuleResource {
     public static final String TYPE_CLUSTER = "cluster";
 
     @Description("Must be `" + TYPE_CLUSTER + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_CLUSTER;

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleTransactionalIdResource.java
Patch:
@@ -31,6 +31,7 @@ public class AclRuleTransactionalIdResource extends AclRuleResource {
     private String name;
 
     @Description("Must be `" + TYPE_TRANSACTIONAL_ID + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_TRANSACTIONAL_ID;

File: api/src/main/java/io/strimzi/api/kafka/model/ExternalLogging.java
Patch:
@@ -31,6 +31,7 @@ public class ExternalLogging extends Logging {
     private ExternalConfigurationReference valueFrom;
 
     @Description("Must be `" + TYPE_EXTERNAL + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_EXTERNAL;

File: api/src/main/java/io/strimzi/api/kafka/model/InlineLogging.java
Patch:
@@ -29,6 +29,7 @@ public class InlineLogging extends Logging {
     private Map<String, String> loggers = null;
 
     @Description("Must be `" + TYPE_INLINE + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_INLINE;

File: api/src/main/java/io/strimzi/api/kafka/model/JmxPrometheusExporterMetrics.java
Patch:
@@ -43,6 +43,7 @@ public void setValueFrom(ExternalConfigurationReference valueFrom) {
     }
 
     @Description("Must be `" + TYPE_JMX_EXPORTER + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_JMX_EXPORTER;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaAuthorizationCustom.java
Patch:
@@ -35,6 +35,7 @@ public class KafkaAuthorizationCustom extends KafkaAuthorization {
     private List<String> superUsers;
 
     @Description("Must be `" + TYPE_CUSTOM + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_CUSTOM;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaAuthorizationSimple.java
Patch:
@@ -35,6 +35,7 @@ public class KafkaAuthorizationSimple extends KafkaAuthorization {
     private List<String> superUsers;
 
     @Description("Must be `" + TYPE_SIMPLE + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_SIMPLE;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaJmxAuthenticationPassword.java
Patch:
@@ -24,6 +24,7 @@ public class KafkaJmxAuthenticationPassword extends KafkaJmxAuthentication {
     public static final String TYPE_PASSWORD = "password";
 
     @Description("Must be `" + TYPE_PASSWORD + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_PASSWORD;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUserScramSha512ClientAuthentication.java
Patch:
@@ -21,6 +21,7 @@ public class KafkaUserScramSha512ClientAuthentication extends KafkaUserAuthentic
     public static final String TYPE_SCRAM_SHA_512 = "scram-sha-512";
 
     @Description("Must be `" + TYPE_SCRAM_SHA_512 + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_SCRAM_SHA_512;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUserTlsClientAuthentication.java
Patch:
@@ -22,6 +22,7 @@ public class KafkaUserTlsClientAuthentication extends KafkaUserAuthentication {
     public static final String TYPE_TLS = "tls";
 
     @Description("Must be `" + TYPE_TLS + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_TLS;

File: api/src/main/java/io/strimzi/api/kafka/model/authentication/KafkaClientAuthenticationOAuth.java
Patch:
@@ -42,6 +42,7 @@ public class KafkaClientAuthenticationOAuth extends KafkaClientAuthentication {
     private boolean accessTokenIsJwt = true;
 
     @Description("Must be `" + TYPE_OAUTH + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_OAUTH;

File: api/src/main/java/io/strimzi/api/kafka/model/authentication/KafkaClientAuthenticationPlain.java
Patch:
@@ -31,6 +31,7 @@ public class KafkaClientAuthenticationPlain extends KafkaClientAuthentication {
     private PasswordSecretSource passwordSecret;
 
     @Description("Must be `" + TYPE_PLAIN + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_PLAIN;

File: api/src/main/java/io/strimzi/api/kafka/model/authentication/KafkaClientAuthenticationScramSha512.java
Patch:
@@ -31,6 +31,7 @@ public class KafkaClientAuthenticationScramSha512 extends KafkaClientAuthenticat
     private PasswordSecretSource passwordSecret;
 
     @Description("Must be `" + TYPE_SCRAM_SHA_512 + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_SCRAM_SHA_512;

File: api/src/main/java/io/strimzi/api/kafka/model/authentication/KafkaClientAuthenticationTls.java
Patch:
@@ -30,6 +30,7 @@ public class KafkaClientAuthenticationTls extends KafkaClientAuthentication {
     private CertAndKeySecretSource certificateAndKey;
 
     @Description("Must be `" + TYPE_TLS + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_TLS;

File: api/src/main/java/io/strimzi/api/kafka/model/connect/build/DockerOutput.java
Patch:
@@ -37,6 +37,7 @@ public class DockerOutput extends Output {
     private List<String> additionalKanikoOptions;
 
     @Description("Must be `" + TYPE_DOCKER + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_DOCKER;

File: api/src/main/java/io/strimzi/api/kafka/model/connect/build/ImageStreamOutput.java
Patch:
@@ -28,6 +28,7 @@ public class ImageStreamOutput extends Output {
     private String image;
 
     @Description("Must be `" + TYPE_IMAGESTREAM + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_IMAGESTREAM;

File: api/src/main/java/io/strimzi/api/kafka/model/connect/build/TgzArtifact.java
Patch:
@@ -25,6 +25,7 @@ public class TgzArtifact extends DownloadableArtifact {
     private static final long serialVersionUID = 1L;
 
     @Description("Must be `" + TYPE_TGZ + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_TGZ;

File: api/src/main/java/io/strimzi/api/kafka/model/connect/build/ZipArtifact.java
Patch:
@@ -25,6 +25,7 @@ public class ZipArtifact extends DownloadableArtifact {
     private static final long serialVersionUID = 1L;
 
     @Description("Must be `" + TYPE_ZIP + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_ZIP;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthenticationOAuth.java
Patch:
@@ -61,6 +61,7 @@ public class KafkaListenerAuthenticationOAuth extends KafkaListenerAuthenticatio
     private String customClaimCheck;
 
     @Description("Must be `" + TYPE_OAUTH + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_OAUTH;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthenticationScramSha512.java
Patch:
@@ -26,6 +26,7 @@ public class KafkaListenerAuthenticationScramSha512 extends KafkaListenerAuthent
     public static final String SCRAM_SHA_512 = "scram-sha-512";
 
     @Description("Must be `" + SCRAM_SHA_512 + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return SCRAM_SHA_512;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthenticationTls.java
Patch:
@@ -26,6 +26,7 @@ public class KafkaListenerAuthenticationTls extends KafkaListenerAuthentication
     public static final String TYPE_TLS = "tls";
 
     @Description("Must be `" + TYPE_TLS + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_TLS;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalIngress.java
Patch:
@@ -37,6 +37,7 @@ public class KafkaListenerExternalIngress extends KafkaListenerExternal {
     private String ingressClass;
 
     @Description("Must be `" + TYPE_INGRESS + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_INGRESS;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalLoadBalancer.java
Patch:
@@ -38,6 +38,7 @@ public class KafkaListenerExternalLoadBalancer extends KafkaListenerExternal {
     private KafkaListenerExternalConfiguration configuration;
 
     @Description("Must be `" + TYPE_LOADBALANCER + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_LOADBALANCER;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalNodePort.java
Patch:
@@ -38,6 +38,7 @@ public class KafkaListenerExternalNodePort extends KafkaListenerExternal {
     private NodePortListenerConfiguration configuration;
 
     @Description("Must be `" + TYPE_NODEPORT + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_NODEPORT;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalRoute.java
Patch:
@@ -37,6 +37,7 @@ public class KafkaListenerExternalRoute extends KafkaListenerExternal {
     private KafkaListenerExternalConfiguration configuration;
 
     @Description("Must be `" + TYPE_ROUTE + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_ROUTE;

File: api/src/main/java/io/strimzi/api/kafka/model/storage/EphemeralStorage.java
Patch:
@@ -30,6 +30,7 @@ public class EphemeralStorage extends SingleVolumeStorage {
     private String sizeLimit;
 
     @Description("Must be `" + TYPE_EPHEMERAL + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_EPHEMERAL;

File: api/src/main/java/io/strimzi/api/kafka/model/storage/JbodStorage.java
Patch:
@@ -26,6 +26,7 @@ public class JbodStorage extends Storage {
     private List<SingleVolumeStorage> volumes;
 
     @Description("Must be `" + TYPE_JBOD + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_JBOD;

File: api/src/main/java/io/strimzi/api/kafka/model/tracing/JaegerTracing.java
Patch:
@@ -27,6 +27,7 @@ public class JaegerTracing extends Tracing {
     public static final String TYPE_JAEGER = "jaeger";
 
     @Description("Must be `" + TYPE_JAEGER + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_JAEGER;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaTopicUtils.java
Patch:
@@ -163,8 +163,7 @@ public static void waitForKafkaTopicsCount(int topicCount, String clusterName) {
     }
 
     public static String describeTopicViaKafkaPod(String topicName, String kafkaPodName, String bootstrapServer) {
-        return cmdKubeClient().execInPod(kafkaPodName, "/bin/bash -c",
-            ".bin/kafka-topics.sh",
+        return cmdKubeClient().execInPod(kafkaPodName, "/opt/kafka/bin/kafka-topics.sh",
             "--topic",
             topicName,
             "--describe",

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ReconciliationST.java
Patch:
@@ -20,6 +20,7 @@
 import io.strimzi.systemtest.resources.crd.KafkaConnectorResource;
 import io.strimzi.systemtest.resources.crd.KafkaRebalanceResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.templates.crd.KafkaClientsTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectTemplates;
 import io.strimzi.systemtest.templates.crd.KafkaConnectorTemplates;
@@ -29,6 +30,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaRebalanceUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
@@ -133,21 +135,19 @@ void testPauseReconciliationInKafkaRebalanceAndTopic(ExtensionContext extensionC
         resourceManager.createResource(extensionContext, KafkaTemplates.kafkaWithCruiseControl(clusterName, 3, 3).build());
         resourceManager.createResource(extensionContext, KafkaTopicTemplates.topic(clusterName, topicName).build());
 
-        /* TODO: after issue with TO and pausing reconciliations in KafkaTopic will be fixed, uncomment these lines
         LOGGER.info("Adding pause annotation into KafkaTopic resource and changing replication factor");
         KafkaTopicResource.replaceTopicResource(topicName, topic -> {
             topic.getMetadata().setAnnotations(PAUSE_ANNO);
             topic.getSpec().setPartitions(SCALE_TO);
         });
 
-        KafkaTopicUtils.waitForKafkaTopicStatus(topicName, CustomResourceStatus.ReconciliationPaused);
+        KafkaTopicUtils.waitForKafkaTopicStatus(namespaceName, topicName, CustomResourceStatus.ReconciliationPaused);
         KafkaTopicUtils.waitForKafkaTopicSpecStability(topicName, KafkaResources.kafkaPodName(clusterName, 0), KafkaResources.plainBootstrapAddress(clusterName));
 
         LOGGER.info("Setting annotation to \"false\", partitions should be scaled to {}", SCALE_TO);
         KafkaTopicResource.replaceTopicResource(topicName,
             topic -> topic.getMetadata().getAnnotations().replace(Annotations.ANNO_STRIMZI_IO_PAUSE_RECONCILIATION, "true", "false"));
         KafkaTopicUtils.waitForKafkaTopicPartitionChange(topicName, SCALE_TO);
-        */
 
         resourceManager.createResource(extensionContext, KafkaRebalanceTemplates.kafkaRebalance(clusterName).build());
 

File: operator-common/src/main/java/io/strimzi/operator/common/model/ResourceVisitor.java
Patch:
@@ -147,7 +147,9 @@ static <M extends AnnotatedElement & Member> void visitProperty(List<String> pat
             } else if (Collection.class.isAssignableFrom(returnType)) {
                 path.add(propertyName);
                 for (Object element : (Collection<?>) propertyValue) {
-                    if (element != null && !element.getClass().isEnum()) {
+                    if (element != null
+                            && !element.getClass().isEnum()
+                            && !isScalar(element.getClass())) {
                         visit(path, element, visitor);
                     }
                 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -101,7 +101,7 @@ public static void main(String[] args) {
     static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeaturesAvailability pfa, ClusterOperatorConfig config) {
         Util.printEnvInfo();
 
-        ResourceOperatorSupplier resourceOperatorSupplier = new ResourceOperatorSupplier(vertx, client, pfa, config.getOperationTimeoutMs());
+        ResourceOperatorSupplier resourceOperatorSupplier = new ResourceOperatorSupplier(vertx, client, pfa, config.featureGates(), config.getOperationTimeoutMs());
 
         OpenSslCertManager certManager = new OpenSslCertManager();
         PasswordGenerator passwordGenerator = new PasswordGenerator(12,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -25,6 +25,7 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.cluster.FeatureGates;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
@@ -154,7 +155,7 @@ public void setup(VertxTestContext testContext) {
                 new DefaultAdminClientProvider(),
                 new DefaultZookeeperScalerProvider(),
                 ResourceUtils.metricsProvider(),
-                pfa, 10_000);
+                pfa, FeatureGates.NONE, 10_000);
         ClusterOperatorConfig config = ClusterOperatorConfig.fromMap(map(
             ClusterOperatorConfig.STRIMZI_KAFKA_IMAGES, KafkaVersionTestUtils.getKafkaImagesEnvVarString(),
             ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString(),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -19,6 +19,7 @@
 import io.strimzi.api.kafka.model.storage.SingleVolumeStorage;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
+import io.strimzi.operator.cluster.FeatureGates;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
@@ -133,7 +134,7 @@ private void init() {
                 new ResourceOperatorSupplier(this.vertx, this.mockClient,
                         ResourceUtils.zookeeperLeaderFinder(this.vertx, this.mockClient),
                         ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(),
-                        ResourceUtils.metricsProvider(), pfa, 60_000L);
+                        ResourceUtils.metricsProvider(), pfa, FeatureGates.NONE, 60_000L);
 
         this.operator = new KafkaAssemblyOperator(this.vertx, pfa, new MockCertManager(),
                 new PasswordGenerator(10, "a", "a"), ros,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorCustomCertTest.java
Patch:
@@ -25,6 +25,7 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.cluster.FeatureGates;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
@@ -130,7 +131,7 @@ public void setup() {
         client.secrets().inNamespace(namespace).create(secret);
         ResourceOperatorSupplier supplier = new ResourceOperatorSupplier(vertx, client, mock(ZookeeperLeaderFinder.class),
                 mock(AdminClientProvider.class), mock(ZookeeperScalerProvider.class),
-                mock(MetricsProvider.class), new PlatformFeaturesAvailability(false, KubernetesVersion.V1_20), 10000);
+                mock(MetricsProvider.class), new PlatformFeaturesAvailability(false, KubernetesVersion.V1_20), FeatureGates.NONE, 10000);
         operator = new MockKafkaAssemblyOperator(vertx, new PlatformFeaturesAvailability(false, kubernetesVersion),
                 certManager,
                 passwordGenerator,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -34,6 +34,7 @@
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperator;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.cluster.FeatureGates;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
@@ -290,7 +291,7 @@ private ResourceOperatorSupplier supplierWithMocks() {
         return new ResourceOperatorSupplier(vertx, client, leaderFinder,
                 ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(),
                 ResourceUtils.metricsProvider(), new PlatformFeaturesAvailability(true, kubernetesVersion),
-                2_000);
+                FeatureGates.NONE, 2_000);
     }
 
     private void assertResourceRequirements(VertxTestContext context, String statefulSetName) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -20,6 +20,7 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.cluster.FeatureGates;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaVersion;
@@ -121,7 +122,7 @@ private Future<Void> createConnectCluster(VertxTestContext context, KafkaConnect
                 new DefaultAdminClientProvider(),
                 new DefaultZookeeperScalerProvider(),
                 ResourceUtils.metricsProvider(),
-                pfa, 60_000L);
+                pfa, FeatureGates.NONE, 60_000L);
         ClusterOperatorConfig config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS);
         this.kco = new KafkaConnectAssemblyOperator(vertx, pfa, supplier, config, foo -> kafkaConnectApi);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -16,6 +16,7 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.cluster.FeatureGates;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaVersion;
@@ -119,7 +120,7 @@ private Future<Void> createMirrorMaker2Cluster(VertxTestContext context, KafkaCo
                 new DefaultAdminClientProvider(),
                 new DefaultZookeeperScalerProvider(),
                 ResourceUtils.metricsProvider(),
-                pfa, 60_000L);
+                pfa, FeatureGates.NONE, 60_000L);
 
         ClusterOperatorConfig config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS);
         kco = new KafkaMirrorMaker2AssemblyOperator(vertx, pfa,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpgradeDowngradeMockTest.java
Patch:
@@ -18,6 +18,7 @@
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.cluster.FeatureGates;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
@@ -118,7 +119,7 @@ private Future<Void> initialize(VertxTestContext context, Kafka initialKafka)
                 .build();
 
         ResourceOperatorSupplier supplier =  new ResourceOperatorSupplier(vertx, client, ResourceUtils.zookeeperLeaderFinder(vertx, client),
-                ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(), ResourceUtils.metricsProvider(), pfa, 2_000);
+                ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(), ResourceUtils.metricsProvider(), pfa, FeatureGates.NONE, 2_000);
 
         ClusterOperatorConfig config = ResourceUtils.dummyClusterOperatorConfig(VERSIONS);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -18,6 +18,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
+import io.strimzi.operator.cluster.FeatureGates;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.Ca;
@@ -180,7 +181,7 @@ ResourceOperatorSupplier supplier(KubernetesClient bootstrapClient) {
                 ResourceUtils.zookeeperLeaderFinder(vertx, bootstrapClient),
                 ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(),
                 ResourceUtils.metricsProvider(), new PlatformFeaturesAvailability(true, KubernetesVersion.V1_16),
-                60_000L);
+                FeatureGates.NONE, 60_000L);
     }
 
     private void startKube() {

File: certificate-manager/src/main/java/io/strimzi/certs/SecretCertProvider.java
Patch:
@@ -126,6 +126,7 @@ public Secret createSecret(String namespace, String name, Map<String, String> da
                     .withAnnotations(annotations)
                     .withOwnerReferences(or)
                 .endMetadata()
+                .withType("Opaque")
                 .withData(data)
                 .build();
 

File: user-operator/src/main/java/io/strimzi/operator/user/model/KafkaUserModel.java
Patch:
@@ -290,6 +290,7 @@ protected Secret createSecret(Map<String, String> data) {
                     .withAnnotations(Util.mergeLabelsOrAnnotations(null, templateSecretAnnotations))
                     .withOwnerReferences(createOwnerReference())
                 .endMetadata()
+                .withType("Opaque")
                 .withData(data)
                 .build();
 

File: systemtest/src/main/java/io/strimzi/systemtest/templates/crd/KafkaClientsTemplates.java
Patch:
@@ -245,7 +245,7 @@ private static PodSpec createClientSpec(String namespaceName, boolean tlsListene
 
     static String saslConfigs(String namespaceName, KafkaUser kafkaUser, String secretPrefix) {
         String secretName = secretPrefix == null ? kafkaUser.getMetadata().getName() : secretPrefix + kafkaUser.getMetadata().getName();
-        Secret secret = ResourceManager.kubeClient().namespace(namespaceName).getSecret(secretName);
+        Secret secret = ResourceManager.kubeClient().getSecret(namespaceName, secretName);
 
         String password = new String(Base64.getDecoder().decode(secret.getData().get("password")), Charset.forName("UTF-8"));
         if (password.isEmpty()) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java
Patch:
@@ -98,7 +98,7 @@ public void start(Promise<Void> start) {
         log.info("Starting ClusterOperator for namespace {}", namespace);
 
         // Configure the executor here, but it is used only in other places
-        getVertx().createSharedWorkerExecutor("kubernetes-ops-pool", 10, TimeUnit.SECONDS.toNanos(120));
+        getVertx().createSharedWorkerExecutor("kubernetes-ops-pool", config.getOperationsThreadPoolSize(), TimeUnit.SECONDS.toNanos(120));
 
         List<Future> watchFutures = new ArrayList<>(8);
         List<AbstractOperator<?, ?, ?, ?>> operators = new ArrayList<>(asList(

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -360,7 +360,7 @@ protected Future<ReconcileResult<StatefulSet>> internalReplace(String namespace,
      */
     public Future<Void> deleteAsync(String namespace, String name, boolean cascading) {
         Promise<Void> result = Promise.promise();
-        vertx.createSharedWorkerExecutor("kubernetes-ops-tool").executeBlocking(
+        vertx.createSharedWorkerExecutor("kubernetes-ops-pool").executeBlocking(
             future -> {
                 try {
                     Boolean deleted = operation().inNamespace(namespace).withName(name).withPropagationPolicy(cascading ? DeletionPropagation.FOREGROUND : DeletionPropagation.ORPHAN).withGracePeriod(-1L).delete();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
Patch:
@@ -80,7 +80,8 @@ public void testReconciliationInterval() {
                 null,
                 ClusterOperatorConfig.RbacScope.CLUSTER,
                 null,
-                "");
+                "",
+                10);
 
         assertThat(config.getNamespaces(), is(singleton("namespace")));
         assertThat(config.getReconciliationIntervalMs(), is(60_000L));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorNonParametrizedTest.java
Patch:
@@ -391,7 +391,8 @@ public void testSelectorLabels(VertxTestContext context) {
                 null,
                 ClusterOperatorConfig.RbacScope.CLUSTER,
                 Labels.fromMap(Map.of("selectorLabel", "value")),
-                "");
+                "",
+                10);
 
         KafkaAssemblyOperator op = new KafkaAssemblyOperator(vertx, new PlatformFeaturesAvailability(false, KubernetesVersion.V1_19), certManager, passwordGenerator,
                 supplier, config);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -910,7 +910,8 @@ public void testKafkaClusterNotMatchingLabelSelector(VertxTestContext context) {
                 null,
                 ClusterOperatorConfig.RbacScope.CLUSTER,
                 Labels.fromMap(Map.of("selectorLabel", "value")),
-                "");
+                "",
+                10);
 
         kcrao = new KafkaRebalanceAssemblyOperator(Vertx.vertx(), pfa, supplier, config);
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ResourceSupport.java
Patch:
@@ -57,7 +57,7 @@ public Future<Void> closeOnWorkerThread(Closeable closeable) {
 
     <T> Future<T> executeBlocking(Handler<Promise<T>> blockingCodeHandler) {
         Promise<T> result = Promise.promise();
-        vertx.createSharedWorkerExecutor("kubernetes-ops-tool")
+        vertx.createSharedWorkerExecutor("kubernetes-ops-pool")
                 .executeBlocking(blockingCodeHandler, true, result);
         return result.future();
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -173,7 +173,6 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
             clusterRoles.put("strimzi-cluster-operator-global", "021-ClusterRole-strimzi-cluster-operator-role.yaml");
             clusterRoles.put("strimzi-kafka-broker", "030-ClusterRole-strimzi-kafka-broker.yaml");
             clusterRoles.put("strimzi-entity-operator", "031-ClusterRole-strimzi-entity-operator.yaml");
-            clusterRoles.put("strimzi-topic-operator", "032-ClusterRole-strimzi-topic-operator.yaml");
             clusterRoles.put("strimzi-kafka-client", "033-ClusterRole-strimzi-kafka-client.yaml");
 
             for (Map.Entry<String, String> clusterRole : clusterRoles.entrySet()) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/MainIT.java
Patch:
@@ -74,7 +74,6 @@ public void testCreateClusterRolesCreatesClusterRoles(VertxTestContext context)
                 assertThat(cro.get("strimzi-cluster-operator-global"), is(notNullValue()));
                 assertThat(cro.get("strimzi-kafka-broker"), is(notNullValue()));
                 assertThat(cro.get("strimzi-entity-operator"), is(notNullValue()));
-                assertThat(cro.get("strimzi-topic-operator"), is(notNullValue()));
                 a.flag();
             })));
     }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -339,8 +339,6 @@ protected static void applyRoleBindings(ExtensionContext extensionContext, Strin
         RoleBindingResource.roleBinding(extensionContext, Constants.PATH_TO_PACKAGING_INSTALL_FILES + "/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml", namespace, bindingsNamespace);
         // 031-RoleBinding
         RoleBindingResource.roleBinding(extensionContext, Constants.PATH_TO_PACKAGING_INSTALL_FILES + "/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml", namespace, bindingsNamespace);
-        // 032-RoleBinding
-        RoleBindingResource.roleBinding(extensionContext, Constants.PATH_TO_PACKAGING_INSTALL_FILES + "/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml", namespace, bindingsNamespace);
     }
 
     protected void assertResources(String namespace, String podName, String containerName, String memoryLimit, String cpuLimit, String memoryRequest, String cpuRequest) {

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ClusterOperatorRbacST.java
Patch:
@@ -115,8 +115,6 @@ private void applyRoleBindingsWithoutCRBs(ExtensionContext extensionContext) {
         RoleBindingResource.roleBinding(extensionContext, TestUtils.USER_PATH + "/../packaging/install/cluster-operator/020-RoleBinding-strimzi-cluster-operator.yaml", NAMESPACE, NAMESPACE);
         // 031-RoleBinding
         RoleBindingResource.roleBinding(extensionContext, TestUtils.USER_PATH + "/../packaging/install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml", NAMESPACE, NAMESPACE);
-        // 032-RoleBinding
-        RoleBindingResource.roleBinding(extensionContext, TestUtils.USER_PATH + "/../packaging/install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml", NAMESPACE, NAMESPACE);
     }
 
     @BeforeAll

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -219,6 +219,9 @@ public final <T extends HasMetadata> void synchronizeResources(ExtensionContext
 
         // sync all resources
         for (ResourceItem resource : resources) {
+            if (resource.getResource() == null) {
+                continue;
+            }
             ResourceType<T> type = findResourceType((T) resource.getResource());
 
             waitResourceCondition((T) resource.getResource(), ResourceCondition.readiness(type));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorUnsupportedFieldsTest.java
Patch:
@@ -21,14 +21,14 @@
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.operator.MockCertManager;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
+import io.strimzi.test.annotations.ParallelTest;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
 import io.vertx.junit5.Checkpoint;
 import io.vertx.junit5.VertxExtension;
 import io.vertx.junit5.VertxTestContext;
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.extension.ExtendWith;
 import org.mockito.ArgumentCaptor;
 
@@ -67,7 +67,7 @@ public static void after() {
      * This test checks that when the unsupported spec.topicOperator is not configured in the Kafka CR, no warning about
      * it will be in the status.
      */
-    @Test
+    @ParallelTest
     public void testNoTopicOperatorWarnings(VertxTestContext context) throws ParseException {
         Kafka kafka = new KafkaBuilder()
                 .withNewMetadata()
@@ -147,7 +147,7 @@ vertx, new PlatformFeaturesAvailability(false, kubernetesVersion),
      * This test checks that when the unsupported spec.topicOperator is configured in the KAfka CR, a warning about it
      * will be in the status.
      */
-    @Test
+    @ParallelTest
     public void testTopicOperatorWarnings(VertxTestContext context) throws ParseException {
         Kafka kafka = new KafkaBuilder()
                 .withNewMetadata()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -31,6 +31,7 @@
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.operator.resource.SecretOperator;
 import io.strimzi.test.TestUtils;
+import io.strimzi.test.annotations.ParallelTest;
 import io.strimzi.test.mockkube.MockKube;
 import io.vertx.core.Future;
 import io.vertx.core.Promise;
@@ -43,7 +44,6 @@
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.extension.ExtendWith;
 
 import java.util.Collections;
@@ -144,7 +144,7 @@ private Future<Void> createConnectCluster(VertxTestContext context, KafkaConnect
         return created.future();
     }
 
-    @Test
+    @ParallelTest
     public void testReconcileCreateAndUpdate(VertxTestContext context) {
         setConnectResource(new KafkaConnectBuilder()
                 .withMetadata(new ObjectMetaBuilder()
@@ -171,7 +171,7 @@ public void testReconcileCreateAndUpdate(VertxTestContext context) {
 
     }
 
-    @Test
+    @ParallelTest
     public void testPauseReconcileUnpause(VertxTestContext context) {
         setConnectResource(new KafkaConnectBuilder()
                 .withMetadata(new ObjectMetaBuilder()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -21,6 +21,7 @@
 import io.strimzi.operator.common.MicrometerMetricsProvider;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
+import io.strimzi.test.annotations.ParallelTest;
 import io.strimzi.test.mockkube.MockKube;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
@@ -37,7 +38,6 @@
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.BeforeEach;
-import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.extension.ExtendWith;
 
 import java.io.IOException;
@@ -110,7 +110,7 @@ public void afterEach() {
         }
     }
 
-    @Test
+    @ParallelTest
     public void test(VertxTestContext context) {
         KafkaConnectApiImpl connectClient = new KafkaConnectApiImpl(vertx);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -28,6 +28,7 @@
 import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.operator.common.operator.resource.SecretOperator;
 import io.strimzi.test.TestUtils;
+import io.strimzi.test.annotations.ParallelTest;
 import io.strimzi.test.mockkube.MockKube;
 import io.vertx.core.Future;
 import io.vertx.core.Promise;
@@ -40,7 +41,6 @@
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.extension.ExtendWith;
 
 import java.util.Collections;
@@ -148,7 +148,7 @@ private Future<Void> createMirrorMaker2Cluster(VertxTestContext context, KafkaCo
         return created.future();
     }
 
-    @Test
+    @ParallelTest
     public void testReconcileUpdate(VertxTestContext context) {
         setMirrorMaker2Resource(new KafkaMirrorMaker2Builder()
                 .withMetadata(new ObjectMetaBuilder()
@@ -174,7 +174,7 @@ public void testReconcileUpdate(VertxTestContext context) {
             .onComplete(context.succeeding(v -> async.flag()));
     }
 
-    @Test
+    @ParallelTest
     public void testPauseReconcile(VertxTestContext context) {
         setMirrorMaker2Resource(new KafkaMirrorMaker2Builder()
                 .withMetadata(new ObjectMetaBuilder()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/TolerationsIT.java
Patch:
@@ -13,13 +13,13 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.operator.cluster.model.ModelUtils;
 import io.strimzi.operator.cluster.operator.resource.StatefulSetDiff;
+import io.strimzi.test.annotations.ParallelTest;
 import io.strimzi.test.k8s.KubeClusterResource;
 import io.vertx.junit5.Checkpoint;
 import io.vertx.junit5.VertxExtension;
 import io.vertx.junit5.VertxTestContext;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
-import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.extension.ExtendWith;
 
 import java.util.ArrayList;
@@ -46,7 +46,7 @@ public void afterEach() {
         cluster.deleteNamespaces();
     }
 
-    @Test
+    @ParallelTest
     public void testEmptyStringValueIntoleration(VertxTestContext context) {
         Toleration t1 = new TolerationBuilder()
                 .withEffect("NoSchedule")

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java
Patch:
@@ -416,7 +416,7 @@ public static void waitForKafkaDeletion(String kafkaClusterName) {
     }
 
     public static String getKafkaTlsListenerCaCertName(String namespace, String clusterName, String listenerName) {
-        List<GenericKafkaListener> listeners = KafkaResource.kafkaClient().inNamespace(namespace).withName(clusterName).get().getSpec().getKafka().getListeners().newOrConverted();
+        List<GenericKafkaListener> listeners = KafkaResource.kafkaClient().inNamespace(namespace).withName(clusterName).get().getSpec().getKafka().getListeners().getGenericKafkaListeners();
 
         GenericKafkaListener tlsListener = listenerName == null || listenerName.isEmpty() ?
             listeners.stream().filter(listener -> Constants.TLS_LISTENER_DEFAULT_NAME.equals(listener.getName())).findFirst().orElseThrow(RuntimeException::new) :
@@ -426,7 +426,7 @@ public static String getKafkaTlsListenerCaCertName(String namespace, String clus
     }
 
     public static String getKafkaExternalListenerCaCertName(String namespace, String clusterName, String listenerName) {
-        List<GenericKafkaListener> listeners = KafkaResource.kafkaClient().inNamespace(namespace).withName(clusterName).get().getSpec().getKafka().getListeners().newOrConverted();
+        List<GenericKafkaListener> listeners = KafkaResource.kafkaClient().inNamespace(namespace).withName(clusterName).get().getSpec().getKafka().getListeners().getGenericKafkaListeners();
 
         GenericKafkaListener external = listenerName == null || listenerName.isEmpty() ?
             listeners.stream().filter(listener -> Constants.EXTERNAL_LISTENER_DEFAULT_NAME.equals(listener.getName())).findFirst().orElseThrow(RuntimeException::new) :

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -1532,7 +1532,7 @@ void testLabelsAndAnnotationForPVC(ExtensionContext extensionContext) {
         LOGGER.info("Check if Kubernetes labels are applied");
         Map<String, String> actualStatefulSetLabels = kubeClient(namespaceName).getStatefulSet(namespaceName, KafkaResources.kafkaStatefulSetName(clusterName)).getMetadata().getLabels();
         assertThat(actualStatefulSetLabels.get("app.kubernetes.io/part-of"), is("some-app"));
-        assertThat(actualStatefulSetLabels.get("app.kubernetes.io/managed-by"), is(not("some-app")));
+        assertThat(actualStatefulSetLabels.get("app.kubernetes.io/managed-by"), is("some-app"));
         LOGGER.info("Kubernetes labels are correctly set and present");
 
         List<PersistentVolumeClaim> pvcs = kubeClient(namespaceName).listPersistentVolumeClaims(namespaceName, clusterName).stream().filter(

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorManualRollingUpdatesTest.java
Patch:
@@ -317,7 +317,7 @@ vertx, new PlatformFeaturesAvailability(false, kubernetesVersion),
                     assertThat(kao.maybeRollKafkaInvocations, is(1));
                     assertThat(kao.kafkaPodNeedsRestart.apply(podWithName("my-cluster-kafka-0")), is(Collections.singletonList("manual rolling update annotation on a pod")));
                     assertThat(kao.kafkaPodNeedsRestart.apply(podWithName("my-cluster-kafka-1")), is(Collections.singletonList("manual rolling update annotation on a pod")));
-                    assertThat(kao.kafkaPodNeedsRestart.apply(podWithName("my-cluster-kafka-2")), is(nullValue()));
+                    assertThat(kao.kafkaPodNeedsRestart.apply(podWithName("my-cluster-kafka-2")), is(Collections.emptyList()));
 
                     async.flag();
                 })));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -59,6 +59,7 @@ public class Main {
     public static void main(String[] args) {
         log.info("ClusterOperator {} is starting", Main.class.getPackage().getImplementationVersion());
         ClusterOperatorConfig config = ClusterOperatorConfig.fromMap(System.getenv());
+        log.info("Cluster Operator configuration is {}", config);
 
         String dnsCacheTtl = System.getenv("STRIMZI_DNS_CACHE_TTL") == null ? "30" : System.getenv("STRIMZI_DNS_CACHE_TTL");
         Security.setProperty("networkaddress.cache.ttl", dnsCacheTtl);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorNonParametrizedTest.java
Patch:
@@ -390,7 +390,8 @@ public void testSelectorLabels(VertxTestContext context) {
                 null,
                 null,
                 ClusterOperatorConfig.RbacScope.CLUSTER,
-                Labels.fromMap(Map.of("selectorLabel", "value")));
+                Labels.fromMap(Map.of("selectorLabel", "value")),
+                "");
 
         KafkaAssemblyOperator op = new KafkaAssemblyOperator(vertx, new PlatformFeaturesAvailability(false, KubernetesVersion.V1_19), certManager, passwordGenerator,
                 supplier, config);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -655,7 +655,7 @@ private void createCluster(VertxTestContext context, Kafka kafka, List<Secret> s
         ArgumentCaptor<String> logNameCaptor = ArgumentCaptor.forClass(String.class);
         when(mockCmOps.reconcile(anyString(), logNameCaptor.capture(), logCaptor.capture())).thenReturn(Future.succeededFuture(ReconcileResult.created(new ConfigMap())));
 
-        ConfigMap metricsCm = kafkaCluster.generateAncillaryConfigMap(new MetricsAndLogging(metricsCM, null), emptySet(), emptySet());
+        ConfigMap metricsCm = kafkaCluster.generateAncillaryConfigMap(new MetricsAndLogging(metricsCM, null), emptySet(), emptySet(), false);
         when(mockCmOps.getAsync(kafkaNamespace, KafkaCluster.metricAndLogConfigsName(kafkaName))).thenReturn(Future.succeededFuture(metricsCm));
         when(mockCmOps.getAsync(kafkaNamespace, metricsCMName)).thenReturn(Future.succeededFuture(metricsCM));
         when(mockCmOps.getAsync(kafkaNamespace, differentMetricsCMName)).thenReturn(Future.succeededFuture(metricsCM));
@@ -991,7 +991,7 @@ private void updateCluster(VertxTestContext context, Kafka originalAssembly, Kaf
                 .endMetadata()
                 .withData(singletonMap("metrics-config.yml", ""))
                 .build();
-        ConfigMap metricsAndLoggingCm = originalKafkaCluster.generateAncillaryConfigMap(new MetricsAndLogging(metricsCm, null), emptySet(), emptySet());
+        ConfigMap metricsAndLoggingCm = originalKafkaCluster.generateAncillaryConfigMap(new MetricsAndLogging(metricsCm, null), emptySet(), emptySet(), false);
         when(mockCmOps.get(clusterNamespace, KafkaCluster.metricAndLogConfigsName(clusterName))).thenReturn(metricsAndLoggingCm);
         when(mockCmOps.getAsync(clusterNamespace, KafkaCluster.metricAndLogConfigsName(clusterName))).thenReturn(Future.succeededFuture(metricsAndLoggingCm));
 
@@ -1134,7 +1134,7 @@ private void updateCluster(VertxTestContext context, Kafka originalAssembly, Kaf
         );
 
         // Mock NetworkPolicy get
-        when(mockPolicyOps.get(clusterNamespace, KafkaCluster.policyName(clusterName))).thenReturn(originalKafkaCluster.generateNetworkPolicy(null, null));
+        when(mockPolicyOps.get(clusterNamespace, KafkaCluster.networkPolicyName(clusterName))).thenReturn(originalKafkaCluster.generateNetworkPolicy(null, null));
         when(mockPolicyOps.get(clusterNamespace, ZookeeperCluster.policyName(clusterName))).thenReturn(originalZookeeperCluster.generateNetworkPolicy(null, null));
 
         // Mock PodDisruptionBudget get

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -833,7 +833,8 @@ public void testKafkaClusterNotMatchingLabelSelector(VertxTestContext context) {
                 null,
                 null,
                 ClusterOperatorConfig.RbacScope.CLUSTER,
-                Labels.fromMap(Map.of("selectorLabel", "value")));
+                Labels.fromMap(Map.of("selectorLabel", "value")),
+                "");
 
         kcrao = new KafkaRebalanceAssemblyOperator(Vertx.vertx(), pfa, supplier, config);
 

File: operator-common/src/main/java/io/strimzi/operator/PlatformFeaturesAvailability.java
Patch:
@@ -259,7 +259,7 @@ public boolean hasIngressV1() {
 
     @Override
     public String toString() {
-        return "ClusterOperatorConfig(" +
+        return "PlatformFeaturesAvailability(" +
                 "KubernetesVersion=" + kubernetesVersion +
                 ",OpenShiftRoutes=" + routes +
                 ",OpenShiftBuilds=" + builds +

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Cluster.java
Patch:
@@ -126,7 +126,6 @@ private static KafkaConnectSpec buildKafkaConnectSpec(KafkaMirrorMaker2Spec spec
                 .withReadinessProbe(spec.getReadinessProbe())
                 .withJvmOptions(spec.getJvmOptions())
                 .withJmxOptions(spec.getJmxOptions())
-                .withMetrics(spec.getMetrics())
                 .withMetricsConfig(spec.getMetricsConfig())
                 .withTracing(spec.getTracing())
                 .withAffinity(spec.getAffinity())

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ModelUtils.java
Patch:
@@ -504,9 +504,6 @@ public static void parseMetrics(AbstractModel model, HasConfigurableMetrics reso
         if (resourceWithMetrics.getMetricsConfig() != null)    {
             model.setMetricsEnabled(true);
             model.setMetricsConfigInCm(resourceWithMetrics.getMetricsConfig());
-        } else if (resourceWithMetrics.getMetrics() != null) {
-            model.setMetricsEnabled(true);
-            model.setMetricsConfig(resourceWithMetrics.getMetrics().entrySet());
         }
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectBuilderST.java
Patch:
@@ -139,7 +139,7 @@ void testBuildFailsWithWrongChecksumOfArtifact(ExtensionContext extensionContext
             .build());
 
         KafkaConnectUtils.waitForConnectNotReady(connectClusterName);
-        KafkaConnectUtils.waitUntilKafkaConnectStatusConditionContainsMessage(connectClusterName, NAMESPACE, "The Kafka Connect build (.*)?failed");
+        KafkaConnectUtils.waitUntilKafkaConnectStatusConditionContainsMessage(connectClusterName, NAMESPACE, "The Kafka Connect build failed(.*)?");
 
         LOGGER.info("Checking if KafkaConnect status condition contains message about build failure");
         KafkaConnect kafkaConnect = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(connectClusterName).get();
@@ -149,7 +149,7 @@ void testBuildFailsWithWrongChecksumOfArtifact(ExtensionContext extensionContext
 
         Condition connectCondition = kafkaConnect.getStatus().getConditions().stream().findFirst().get();
 
-        assertTrue(connectCondition.getMessage().matches("The Kafka Connect build (.*)?failed"));
+        assertTrue(connectCondition.getMessage().matches("The Kafka Connect build failed(.*)?"));
         assertThat(connectCondition.getType(), is(NotReady.toString()));
 
         LOGGER.info("Replacing plugin's checksum with right one");

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerST.java
Patch:
@@ -107,7 +107,7 @@ void testKafkaRollsWhenTopicIsUnderReplicated(ExtensionContext extensionContext)
 
         //Test that CO doesn't have any exceptions in log
         timeMeasuringSystem.stopOperation(operationId, extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName());
-        assertNoCoErrorsLogged(timeMeasuringSystem.getDurationInSeconds(extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName(), operationId));
+        assertNoCoErrorsLogged(NAMESPACE, timeMeasuringSystem.getDurationInSeconds(extensionContext.getRequiredTestClass().getName(), extensionContext.getDisplayName(), operationId));
 
         // scale down
         final int scaledDownReplicas = 3;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -900,6 +900,7 @@ protected PersistentVolumeClaim createPersistentVolumeClaim(int ordinalId, Strin
                     .endResources()
                     .withStorageClassName(storageClass)
                     .withSelector(selector)
+                    .withVolumeMode("Filesystem")
                 .endSpec()
                 .build();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/StorageDiff.java
Patch:
@@ -11,7 +11,7 @@
 import io.strimzi.api.kafka.model.storage.PersistentClaimStorageOverride;
 import io.strimzi.api.kafka.model.storage.SingleVolumeStorage;
 import io.strimzi.api.kafka.model.storage.Storage;
-import io.strimzi.operator.common.operator.resource.AbstractResourceDiff;
+import io.strimzi.operator.common.operator.resource.AbstractJsonDiff;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
@@ -28,7 +28,7 @@
 /**
  * Class for diffing storage configuration
  */
-public class StorageDiff extends AbstractResourceDiff {
+public class StorageDiff extends AbstractJsonDiff {
     private static final Logger log = LogManager.getLogger(StorageDiff.class.getName());
 
     private static final Pattern IGNORABLE_PATHS = Pattern.compile(

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiff.java
Patch:
@@ -21,7 +21,7 @@
 import io.strimzi.operator.cluster.model.KafkaConfiguration;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.common.model.OrderedProperties;
-import io.strimzi.operator.common.operator.resource.AbstractResourceDiff;
+import io.strimzi.operator.common.operator.resource.AbstractJsonDiff;
 import org.apache.kafka.clients.admin.AlterConfigOp;
 import org.apache.kafka.clients.admin.Config;
 import org.apache.kafka.clients.admin.ConfigEntry;
@@ -39,7 +39,7 @@
  *  3b. If entry was removed from desired, add it to the diff with null value.
  *  3c. If custom entry was removed, delete property
  */
-public class KafkaBrokerConfigurationDiff extends AbstractResourceDiff {
+public class KafkaBrokerConfigurationDiff extends AbstractJsonDiff {
 
     private static final Logger log = LogManager.getLogger(KafkaBrokerConfigurationDiff.class);
     private final Collection<AlterConfigOp> diff;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerLoggingConfigurationDiff.java
Patch:
@@ -6,7 +6,7 @@
 package io.strimzi.operator.cluster.operator.resource;
 
 import io.strimzi.operator.common.Util;
-import io.strimzi.operator.common.operator.resource.AbstractResourceDiff;
+import io.strimzi.operator.common.operator.resource.AbstractJsonDiff;
 import org.apache.kafka.clients.admin.AlterConfigOp;
 import org.apache.kafka.clients.admin.Config;
 import org.apache.kafka.clients.admin.ConfigEntry;
@@ -22,7 +22,7 @@
 import java.util.LinkedHashMap;
 import java.util.Map;
 
-public class KafkaBrokerLoggingConfigurationDiff extends AbstractResourceDiff {
+public class KafkaBrokerLoggingConfigurationDiff extends AbstractJsonDiff {
 
     private static final Logger log = LogManager.getLogger(KafkaBrokerLoggingConfigurationDiff.class);
     private final Collection<AlterConfigOp> diff;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetDiff.java
Patch:
@@ -10,7 +10,7 @@
 import io.fabric8.zjsonpatch.JsonDiff;
 import io.strimzi.operator.cluster.model.StorageUtils;
 import io.strimzi.operator.common.Annotations;
-import io.strimzi.operator.common.operator.resource.AbstractResourceDiff;
+import io.strimzi.operator.common.operator.resource.AbstractJsonDiff;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
@@ -19,7 +19,7 @@
 
 import static io.fabric8.kubernetes.client.internal.PatchUtils.patchMapper;
 
-public class StatefulSetDiff extends AbstractResourceDiff {
+public class StatefulSetDiff extends AbstractJsonDiff {
 
     private static final Logger log = LogManager.getLogger(StatefulSetDiff.class.getName());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -42,7 +42,6 @@
  * in addition to the usual operations.
  */
 public abstract class StatefulSetOperator extends AbstractScalableResourceOperator<KubernetesClient, StatefulSet, StatefulSetList, RollableScalableResource<StatefulSet>> {
-
     private static final int NO_GENERATION = -1;
     private static final int INIT_GENERATION = 0;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -815,7 +815,7 @@ image, healthDelay, healthTimeout, metricsCm, jmxMetricsConfig, configuration, e
         assertThat(ext.getSpec().getSelector(), is(kc.getSelectorLabels().toMap()));
         assertThat(ext.getSpec().getPorts(), is(Collections.singletonList(kc.createServicePort(ListenersUtils.BACKWARDS_COMPATIBLE_EXTERNAL_PORT_NAME, 9094, 9094, "TCP"))));
         assertThat(ext.getSpec().getLoadBalancerIP(), is(nullValue()));
-        assertThat(ext.getSpec().getExternalTrafficPolicy(), is(nullValue()));
+        assertThat(ext.getSpec().getExternalTrafficPolicy(), is("Cluster"));
         assertThat(ext.getSpec().getLoadBalancerSourceRanges(), is(emptyList()));
         checkOwnerReference(kc.createOwnerReference(), ext);
 
@@ -828,7 +828,7 @@ image, healthDelay, healthTimeout, metricsCm, jmxMetricsConfig, configuration, e
             assertThat(srv.getSpec().getSelector().get(Labels.KUBERNETES_STATEFULSET_POD_LABEL), is(KafkaCluster.kafkaPodName(cluster, i)));
             assertThat(srv.getSpec().getPorts(), is(Collections.singletonList(kc.createServicePort(ListenersUtils.BACKWARDS_COMPATIBLE_EXTERNAL_PORT_NAME, 9094, 9094, "TCP"))));
             assertThat(srv.getSpec().getLoadBalancerIP(), is(nullValue()));
-            assertThat(srv.getSpec().getExternalTrafficPolicy(), is(nullValue()));
+            assertThat(srv.getSpec().getExternalTrafficPolicy(), is("Cluster"));
             assertThat(srv.getSpec().getLoadBalancerSourceRanges(), is(emptyList()));
             checkOwnerReference(kc.createOwnerReference(), srv);
         }

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/StatusDiff.java
Patch:
@@ -9,15 +9,15 @@
 import com.fasterxml.jackson.databind.SerializationFeature;
 import io.fabric8.zjsonpatch.JsonDiff;
 import io.strimzi.api.kafka.model.status.Status;
-import io.strimzi.operator.common.operator.resource.AbstractResourceDiff;
+import io.strimzi.operator.common.operator.resource.AbstractJsonDiff;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
 import java.util.regex.Pattern;
 
 import static io.fabric8.kubernetes.client.internal.PatchUtils.patchMapper;
 
-public class StatusDiff extends AbstractResourceDiff {
+public class StatusDiff extends AbstractJsonDiff {
 
     private static final Logger log = LogManager.getLogger(StatusDiff.class.getName());
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractJsonDiff.java
Patch:
@@ -7,7 +7,7 @@
 import com.fasterxml.jackson.databind.JsonNode;
 import com.fasterxml.jackson.databind.node.MissingNode;
 
-public abstract class AbstractResourceDiff {
+public abstract class AbstractJsonDiff {
     protected static JsonNode lookupPath(JsonNode source, String path) {
         JsonNode s = source;
         for (String component : path.substring(1).split("/")) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectorUtils.java
Patch:
@@ -70,7 +70,7 @@ public static boolean waitForConnectorReady(String namespaceName, String connect
     }
 
     public static boolean waitForConnectorReady(String connectorName) {
-        return waitForConnectorStatus(kubeClient().getNamespace(), connectorName, Ready);
+        return waitForConnectorReady(kubeClient().getNamespace(), connectorName);
     }
 
     public static boolean waitForConnectorNotReady(String namespaceName, String connectorName) {

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -89,6 +89,7 @@ public interface Constants {
     int USER_OPERATOR_METRICS_PORT = 8081;
     int TOPIC_OPERATOR_METRICS_PORT = 8080;
     int KAFKA_BRIDGE_METRICS_PORT = 8080;
+    int JMX_PORT = 9999;
 
     String DEPLOYMENT = "Deployment";
     String DEPLOYMENT_TYPE = "deployment-type";

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -104,7 +104,6 @@ class ConnectST extends AbstractST {
     private static final Logger LOGGER = LogManager.getLogger(ConnectST.class);
     public static final String NAMESPACE = "connect-cluster-test";
 
-    private static final String CONNECT_TOPIC_NAME = "connect-topic-example";
     private static final String KAFKA_CLIENTS_NAME = "shared-" +  Constants.KAFKA_CLIENTS;
 
     @ParallelNamespaceTest

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/VerifiableClient.java
Patch:
@@ -121,7 +121,7 @@ public VerifiableClient(VerifiableClientBuilder verifiableClientBuilder) {
         this.clientArgumentMap.put(ClientArgument.MAX_MESSAGES, Integer.toString(maxMessages));
         if (kafkaUsername != null) this.clientArgumentMap.put(ClientArgument.USER, kafkaUsername.replace("-", "_"));
 
-        String image = kubeClient().namespace(podNamespace).getPod(this.podName).getSpec().getContainers().get(0).getImage();
+        String image = kubeClient().namespace(podNamespace).getPod(podNamespace, this.podName).getSpec().getContainers().get(0).getImage();
         String clientVersion = image.substring(image.length() - 5);
 
         this.clientArgumentMap.put(allowParameter("2.5.0", clientVersion) ? ClientArgument.BOOTSTRAP_SERVER : ClientArgument.BROKER_LIST, bootstrapServer);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -180,7 +180,6 @@ public final <T extends HasMetadata> void deleteResource(T... resources) {
                 String.format("Timed out deleting %s %s in namespace %s", resource.getKind(), resource.getMetadata().getName(), resource.getMetadata().getNamespace()));
         }
     }
-
     public final <T extends HasMetadata> boolean waitResourceCondition(T resource, Predicate<T> condition) {
         assertNotNull(resource);
         assertNotNull(resource.getMetadata());

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaTopicResource.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.api.kafka.KafkaTopicList;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.systemtest.enums.CustomResourceStatus;
+import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.systemtest.resources.ResourceType;
 import io.strimzi.systemtest.resources.ResourceManager;
 
@@ -39,7 +40,8 @@ public void delete(KafkaTopic resource) {
     }
     @Override
     public boolean waitForReadiness(KafkaTopic resource) {
-        return ResourceManager.waitForResourceStatus(kafkaTopicClient(), resource, CustomResourceStatus.Ready);
+        return ResourceManager.waitForResourceStatus(kafkaTopicClient(), resource.getKind(), resource.getMetadata().getNamespace(),
+            resource.getMetadata().getName(), CustomResourceStatus.Ready, ResourceOperation.getTimeoutForResourceReadiness(resource.getKind()));
     }
 
     public static MixedOperation<KafkaTopic, KafkaTopicList, Resource<KafkaTopic>> kafkaTopicClient() {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java
Patch:
@@ -58,7 +58,7 @@ public static void waitUntilClientReceivedMessagesTls(KafkaClientOperations kafk
     public static void waitTillContinuousClientsFinish(String producerName, String consumerName, String namespace, int messageCount) {
         LOGGER.info("Waiting till producer {} and consumer {} finish", producerName, consumerName);
         TestUtils.waitFor("continuous clients finished", Constants.GLOBAL_POLL_INTERVAL, timeoutForClientFinishJob(messageCount),
-            () -> kubeClient().namespace(namespace).checkSucceededJobStatus(producerName) && kubeClient().namespace(namespace).checkSucceededJobStatus(consumerName));
+            () -> kubeClient().namespace(namespace).checkSucceededJobStatus(namespace, producerName, 1) && kubeClient().namespace(namespace).checkSucceededJobStatus(namespace, consumerName, 1));
     }
 
     public static void waitForClientSuccess(String jobName, String namespace, int messageCount) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -37,7 +38,8 @@ private KafkaConnectUtils() {}
      */
     public static boolean waitForConnectStatus(String namespaceName, String clusterName, Enum<?>  status) {
         KafkaConnect kafkaConnect = KafkaConnectResource.kafkaConnectClient().inNamespace(namespaceName).withName(clusterName).get();
-        return ResourceManager.waitForResourceStatus(KafkaConnectResource.kafkaConnectClient(), kafkaConnect, status);
+        return ResourceManager.waitForResourceStatus(KafkaConnectResource.kafkaConnectClient(),
+            kafkaConnect.getKind(), namespaceName, kafkaConnect.getMetadata().getName(), status, ResourceOperation.getTimeoutForResourceReadiness(kafkaConnect.getKind()));
     }
 
     public static boolean waitForConnectReady(String namespaceName, String clusterName) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java
Patch:
@@ -49,7 +49,7 @@ public static Map<String, String> podSnapshot(LabelSelector selector) {
     }
 
     public static String getFirstContainerImageNameFromPod(String namespaceName, String podName) {
-        return kubeClient(namespaceName).getPod(podName).getSpec().getContainers().get(0).getImage();
+        return kubeClient(namespaceName).getPod(namespaceName, podName).getSpec().getContainers().get(0).getImage();
     }
 
     public static String getFirstContainerImageNameFromPod(String podName) {

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -349,9 +349,9 @@ protected static void applyRoleBindings(ExtensionContext extensionContext, Strin
     }
 
     protected void assertResources(String namespace, String podName, String containerName, String memoryLimit, String cpuLimit, String memoryRequest, String cpuRequest) {
-        Pod po = kubeClient(namespace).getPod(podName);
+        Pod po = kubeClient(namespace).getPod(namespace, podName);
         assertThat("Not found an expected pod  " + podName + " in namespace " + namespace + " but found " +
-            kubeClient(namespace).listPods().stream().map(p -> p.getMetadata().getName()).collect(Collectors.toList()), po, is(notNullValue()));
+            kubeClient(namespace).listPods(namespace).stream().map(p -> p.getMetadata().getName()).collect(Collectors.toList()), po, is(notNullValue()));
 
         Optional optional = po.getSpec().getContainers().stream().filter(c -> c.getName().equals(containerName)).findFirst();
         assertThat("Not found an expected container " + containerName, optional.isPresent(), is(true));

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java
Patch:
@@ -22,6 +22,7 @@
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
+import io.strimzi.systemtest.utils.TestKafkaVersion;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import io.strimzi.test.TestUtils;
@@ -449,8 +450,8 @@ public static String changeOrRemoveKafkaConfiguration(File file, String version,
                 ((ObjectNode) kafkaNode.get("config")).remove("inter.broker.protocol.version");
             } else if (!version.equals("")) {
                 kafkaNode.put("version", version);
-                ((ObjectNode) kafkaNode.get("config")).put("log.message.format.version", version.substring(0, 3));
-                ((ObjectNode) kafkaNode.get("config")).put("inter.broker.protocol.version", version.substring(0, 3));
+                ((ObjectNode) kafkaNode.get("config")).put("log.message.format.version", TestKafkaVersion.getSpecificVersion(version).messageVersion());
+                ((ObjectNode) kafkaNode.get("config")).put("inter.broker.protocol.version", TestKafkaVersion.getSpecificVersion(version).protocolVersion());
             }
             if (logMessageFormat != null) {
                 ((ObjectNode) kafkaNode.get("config")).put("log.message.format.version", logMessageFormat);

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java
Patch:
@@ -67,7 +67,7 @@ void testStrimziUpgrade(ExtensionContext extensionContext) throws IOException {
         JsonArray upgradeData = readUpgradeJson(UPGRADE_JSON_FILE);
         JsonObject latestUpgradeData = upgradeData.getJsonObject(upgradeData.size() - 1);
 
-        List<TestKafkaVersion> testKafkaVersions = TestKafkaVersion.getKafkaVersions();
+        List<TestKafkaVersion> testKafkaVersions = TestKafkaVersion.getSupportedKafkaVersions();
         TestKafkaVersion testKafkaVersion = testKafkaVersions.get(testKafkaVersions.size() - 1);
 
         // Generate procedures and data for OLM upgrade

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziDowngradeST.java
Patch:
@@ -55,10 +55,10 @@ private void performDowngrade(JsonObject testParameters, ExtensionContext extens
         String continuousConsumerGroup = "continuous-consumer-group";
 
         // Setup env
-        setupEnvAndUpgradeClusterOperator(extensionContext, testParameters, producerName, consumerName, continuousTopicName, continuousConsumerGroup, "", NAMESPACE);
+        // We support downgrade only when you didn't upgrade to new inter.broker.protocol.version and log.message.format.version
+        // https://strimzi.io/docs/operators/latest/full/deploying.html#con-target-downgrade-version-str
+        setupEnvAndUpgradeClusterOperator(extensionContext, testParameters, producerName, consumerName, continuousTopicName, continuousConsumerGroup, testParameters.getString("deployKafkaVersion"), NAMESPACE);
         logPodImages(clusterName);
-        //  Upgrade kafka
-        changeKafkaAndLogFormatVersion(testParameters.getJsonObject("proceduresBeforeOperatorDowngrade"), testParameters, clusterName, extensionContext);
         // Downgrade CO
         changeClusterOperator(testParameters, NAMESPACE);
         // Wait for Kafka cluster rolling update

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -191,7 +191,7 @@ void testUpgradeAcrossVersionsWithNoKafkaVersion(ExtensionContext extensionConte
     }
 
     private JsonObject buildDataForUpgradeAcrossVersions() throws IOException {
-        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.getKafkaVersions();
+        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.getSupportedKafkaVersions();
         TestKafkaVersion latestKafkaSupported = sortedVersions.get(sortedVersions.size() - 1);
 
         JsonArray upgradeJson = readUpgradeJson(UPGRADE_JSON_FILE);
@@ -224,7 +224,7 @@ private JsonObject buildDataForUpgradeAcrossVersions() throws IOException {
     }
 
     private JsonObject getDataForStartUpgrade(JsonArray upgradeJson) throws IOException {
-        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.getKafkaVersions();
+        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.getSupportedKafkaVersions();
         List<String> versions = sortedVersions.stream().map(item -> item.version()).collect(Collectors.toList());
 
         Collections.reverse(upgradeJson.getList());

File: systemtest/src/test/java/io/strimzi/systemtest/utils/KafkaVersionUtilsTest.java
Patch:
@@ -16,7 +16,7 @@ public class KafkaVersionUtilsTest {
 
     @ParallelTest
     public void parsingTest() {
-        List<TestKafkaVersion> versions = TestKafkaVersion.getKafkaVersions();
+        List<TestKafkaVersion> versions = TestKafkaVersion.getSupportedKafkaVersions();
         assertTrue(versions.size() > 0);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -39,7 +39,7 @@ public void delete(KafkaConnect resource)    {
     }
     @Override
     public boolean waitForReadiness(KafkaConnect resource) {
-        return KafkaConnectUtils.waitForConnectReady(resource.getMetadata().getName());
+        return KafkaConnectUtils.waitForConnectReady(resource.getMetadata().getNamespace(), resource.getMetadata().getName());
     }
 
     public static MixedOperation<KafkaConnect, KafkaConnectList, Resource<KafkaConnect>> kafkaConnectClient() {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -40,7 +40,7 @@ public void delete(KafkaConnector resource) {
     }
     @Override
     public boolean waitForReadiness(KafkaConnector resource) {
-        return KafkaConnectorUtils.waitForConnectorReady(resource.getMetadata().getName());
+        return KafkaConnectorUtils.waitForConnectorReady(resource.getMetadata().getNamespace(), resource.getMetadata().getName());
     }
 
     public static MixedOperation<KafkaConnector, KafkaConnectorList, Resource<KafkaConnector>> kafkaConnectorClient() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectApi.java
Patch:
@@ -187,7 +187,7 @@ class ConnectRestException extends RuntimeException {
     }
 
     public ConnectRestException(HttpClientResponse response, String message) {
-        this(response.request().method().toString(), response.request().path(), response.statusCode(), response.statusMessage(), message);
+        this(response.request().getMethod().toString(), response.request().path(), response.statusCode(), response.statusMessage(), message);
     }
 
     ConnectRestException(String method, String path, int statusCode, String statusMessage, String message, Throwable cause) {
@@ -196,7 +196,7 @@ public ConnectRestException(HttpClientResponse response, String message) {
     }
 
     public ConnectRestException(HttpClientResponse response, String message, Throwable cause) {
-        this(response.request().method().toString(), response.request().path(), response.statusCode(), response.statusMessage(), message, cause);
+        this(response.request().getMethod().toString(), response.request().path(), response.statusCode(), response.statusMessage(), message, cause);
     }
 
     public int getStatusCode() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperator.java
Patch:
@@ -115,7 +115,7 @@ public Future<Void> maybeRollingUpdate(StatefulSet sts, Function<Pod, List<Strin
                         return maybeRestartPod(sts, KafkaResources.zookeeperPodName(cluster, leader), podRestart);
                     });
                 }
-            }).onComplete(rollFuture);
+            }).onComplete(promise);
         } else {
             rollFuture = Future.succeededFuture();
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -35,7 +35,7 @@
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
-import io.strimzi.operator.common.operator.resource.TimeoutException;
+import io.strimzi.operator.common.operator.resource.NoStackTraceTimeoutException;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.mockkube.MockKube;
 import io.vertx.core.Future;
@@ -978,7 +978,7 @@ public void testCruiseControlTimingOut(VertxTestContext context) throws IOExcept
             .onComplete(context.succeeding(v -> {
                 // the resource moved from New to NotReady (mocked Cruise Control didn't reply on time)
                 assertState(context, kubernetesClient, CLUSTER_NAMESPACE, RESOURCE_NAME,
-                        KafkaRebalanceState.NotReady, TimeoutException.class,
+                        KafkaRebalanceState.NotReady, NoStackTraceTimeoutException.class,
                         "The timeout period of 1000ms has been exceeded while executing POST");
                 checkpoint.flag();
             }));

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicOperator.java
Patch:
@@ -732,7 +732,7 @@ private Future<Void> update3Way(Reconciliation reconciliation, LogContext logCon
                                 Promise<Void> promise = Promise.promise();
                                 configFuture = promise.future();
                                 LOGGER.debug("{}: Updating kafka config with {}", logContext, kafkaDiff);
-                                enqueue(new UpdateKafkaConfig(logContext, result, involvedObject, configFuture));
+                                enqueue(new UpdateKafkaConfig(logContext, result, involvedObject, promise));
                             } else {
                                 LOGGER.debug("{}: No need to update kafka topic with {}", logContext, kafkaDiff);
                                 configFuture = Future.succeededFuture();
@@ -1032,7 +1032,7 @@ private Future<Void> updateStatus(LogContext logContext) {
                             } else {
                                 LOGGER.error("{}: Error setting resource status", logContext, ar.cause());
                             }
-                            statusFuture.handle(ar.map((Void) null));
+                            promise.handle(ar.map((Void) null));
                         });
                     } else {
                         statusFuture = Future.succeededFuture();

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaClientsResource.java
Patch:
@@ -25,7 +25,7 @@ public String getKind() {
     @Override
     public Deployment get(String namespace, String name) {
         String deploymentName = ResourceManager.kubeClient().namespace(namespace).getDeploymentNameByPrefix(name);
-        return deploymentName != null ?  ResourceManager.kubeClient().namespace(namespace).getDeployment(deploymentName) : null;
+        return deploymentName != null ?  ResourceManager.kubeClient().namespace(namespace).getDeployment(namespace, deploymentName) : null;
     }
 
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/DeploymentUtils.java
Patch:
@@ -200,8 +200,8 @@ public static boolean waitForDeploymentAndPodsReady(String namespaceName, String
         waitForDeploymentReady(namespaceName, deploymentName);
 
         LOGGER.info("Waiting for {} Pod(s) of Deployment {} to be ready", expectPods, deploymentName);
-        PodUtils.waitForPodsReady(namespaceName, kubeClient(namespaceName).getDeploymentSelectors(deploymentName), expectPods, true,
-            () -> DeploymentUtils.logCurrentDeploymentStatus(kubeClient(namespaceName).getDeployment(deploymentName), namespaceName));
+        PodUtils.waitForPodsReady(namespaceName, kubeClient(namespaceName).getDeploymentSelectors(namespaceName, deploymentName), expectPods, true,
+            () -> DeploymentUtils.logCurrentDeploymentStatus(kubeClient(namespaceName).getDeployment(namespaceName, deploymentName), namespaceName));
         LOGGER.info("Deployment {} is ready", deploymentName);
         return true;
     }

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -93,7 +93,6 @@
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.Constants.ROLLING_UPDATE;
-import static io.strimzi.systemtest.enums.CustomResourceStatus.NotReady;
 import static io.strimzi.systemtest.security.SystemTestCertManager.STRIMZI_INTERMEDIATE_CA;
 import static io.strimzi.systemtest.security.SystemTestCertManager.convertPrivateKeyToPKCS8File;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
@@ -1288,7 +1287,7 @@ void testKafkaAndKafkaConnectTlsVersion(ExtensionContext extensionContext) {
 
         LOGGER.info("Verifying that Kafka Connect status is NotReady because of different TLS version");
 
-        KafkaConnectUtils.waitForConnectStatus(clusterName, NotReady);
+        KafkaConnectUtils.waitForConnectNotReady(clusterName);
 
         LOGGER.info("Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.");
 

File: api/src/test/java/io/strimzi/api/kafka/model/StructuralCrdIT.java
Patch:
@@ -73,7 +73,7 @@ private void assertApiVersionsAreStructural(String api, ApiVersion crdApiVersion
 
     private void assertApiVersionsAreStructural(String api, ApiVersion crdApiVersion, VersionRange<ApiVersion> shouldBeStructural) {
         Pattern pattern = Pattern.compile("[^.]spec\\.versions\\[([0-9]+)\\]\\.[^,]*?");
-        CustomResourceDefinition crd = cluster.client().getClient().customResourceDefinitions().withName(api).get();
+        CustomResourceDefinition crd = cluster.client().getClient().apiextensions().v1beta1().customResourceDefinitions().withName(api).get();
         // We can't make the following assertion because the current version of fabric8 always requests
         // the CRD using v1beta1 api version, so the apiserver just replaces it and serves it.
         //assertEquals(crdApiVersion, ApiVersion.parse(crd.getApiVersion().replace("apiextensions.k8s.io/", "")));

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ServiceOperator.java
Patch:
@@ -147,7 +147,7 @@ protected void patchHealthCheckPorts(Service current, Service desired) {
      * @param desired   Desired Service
      */
     protected void patchIpFamily(Service current, Service desired) {
-        desired.getSpec().setIpFamily(current.getSpec().getIpFamily());
+        desired.getSpec().setIpFamilies(current.getSpec().getIpFamilies());
     }
 
     /**

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractCustomResourceOperatorIT.java
Patch:
@@ -64,7 +64,6 @@ public abstract class AbstractCustomResourceOperatorIT<C extends KubernetesClien
     protected static KubernetesClient client;
     private static KubeClusterResource cluster;
 
-
     protected abstract CrdOperator<C, T, L> operator();
     protected abstract CustomResourceDefinition getCrd();
     protected abstract String getNamespace();
@@ -73,7 +72,6 @@ public abstract class AbstractCustomResourceOperatorIT<C extends KubernetesClien
     protected abstract T getResourceWithNewReadyStatus(T resourceInCluster);
     protected abstract void assertReady(VertxTestContext context, T modifiedCustomResource);
 
-
     @BeforeAll
     public void before() {
         String namespace = getNamespace();
@@ -95,7 +93,7 @@ public void before() {
         cmdKubeClient().waitForResourceCreation("Namespace", namespace);
 
         log.info("Creating CRD");
-        client.customResourceDefinitions().createOrReplace(getCrd());
+        client.apiextensions().v1beta1().customResourceDefinitions().createOrReplace(getCrd());
         log.info("Created CRD");
     }
 

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorTest.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
-import io.fabric8.kubernetes.client.dsl.base.CustomResourceDefinitionContext;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaList;
 import io.strimzi.api.kafka.model.Kafka;
@@ -72,7 +71,7 @@ protected Kafka resource() {
 
     @Override
     protected void mocker(KubernetesClient mockClient, MixedOperation op) {
-        when(mockClient.customResources(any(CustomResourceDefinitionContext.class), any(), any())).thenReturn(op);
+        when(mockClient.customResources(any(), any())).thenReturn(op);
     }
 
     @Override

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -7,9 +7,7 @@
 import io.apicurio.registry.utils.ConcurrentUtil;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.Watch;
-import io.fabric8.kubernetes.client.dsl.base.CustomResourceDefinitionContext;
 import io.micrometer.prometheus.PrometheusMeterRegistry;
-import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaTopicList;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.operator.common.MicrometerMetricsProvider;
@@ -270,7 +268,7 @@ Future<Void> startWatcher() {
         try {
             LOGGER.debug("Watching KafkaTopics matching {}", config.get(Config.LABELS).labels());
 
-            Session.this.topicWatch = kubeClient.customResources(CustomResourceDefinitionContext.fromCrd(Crds.kafkaTopic()), KafkaTopic.class, KafkaTopicList.class)
+            Session.this.topicWatch = kubeClient.customResources(KafkaTopic.class, KafkaTopicList.class)
                     .inNamespace(config.get(Config.NAMESPACE)).withLabels(config.get(Config.LABELS).labels()).watch(watcher);
             LOGGER.debug("Watching setup");
             promise.complete();

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorBaseIT.java
Patch:
@@ -185,7 +185,7 @@ public void setup() throws Exception {
 
         // We can't delete events, so record the events which exist at the start of the test
         // and then waitForEvents() can ignore those
-        preExistingEvents = kubeClient.events().inNamespace(NAMESPACE).withLabels(labels.labels()).list().
+        preExistingEvents = kubeClient.v1().events().inNamespace(NAMESPACE).withLabels(labels.labels()).list().
                 getItems().stream().
                 map(evt -> evt.getMetadata().getUid()).
                 collect(Collectors.toSet());
@@ -580,7 +580,7 @@ protected void waitFor(BooleanSupplier ready, String message) throws TimeoutExce
 
     protected void waitForEvent(KafkaTopic kafkaTopic, String expectedMessage, TopicOperator.EventType expectedType) throws InterruptedException, ExecutionException, TimeoutException {
         waitFor(() -> {
-            List<Event> items = kubeClient.events().inNamespace(NAMESPACE).withLabels(labels.labels()).list().getItems();
+            List<Event> items = kubeClient.v1().events().inNamespace(NAMESPACE).withLabels(labels.labels()).list().getItems();
             List<Event> filtered = items.stream().
                     filter(evt -> !preExistingEvents.contains(evt.getMetadata().getUid())
                             && "KafkaTopic".equals(evt.getInvolvedObject().getKind())

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConfigurationTests.java
Patch:
@@ -84,7 +84,7 @@ public void passwordType() {
     @Test
     public void invalidVersion() {
         assertConfigError("inter.broker.protocol.version", "dclncswn",
-                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E|\\Q2.5\\E(\\.[0-9]+)*|\\Q2.5-IV0\\E|\\Q2.6\\E(\\.[0-9]+)*|\\Q2.6-IV0\\E|\\Q2.7\\E(\\.[0-9]+)*|\\Q2.7-IV0\\E|\\Q2.7-IV1\\E|\\Q2.7-IV2\\E");
+                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E|\\Q2.5\\E(\\.[0-9]+)*|\\Q2.5-IV0\\E|\\Q2.6\\E(\\.[0-9]+)*|\\Q2.6-IV0\\E|\\Q2.7\\E(\\.[0-9]+)*|\\Q2.7-IV0\\E|\\Q2.7-IV1\\E|\\Q2.7-IV2\\E|\\Q2.8\\E(\\.[0-9]+)*|\\Q2.8-IV0\\E|\\Q2.8-IV1\\E");
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiffTest.java
Patch:
@@ -30,7 +30,7 @@
 public class KafkaBrokerConfigurationDiffTest {
 
     private static final KafkaVersion.Lookup VERSIONS = KafkaVersionTestUtils.getKafkaVersionLookup();
-    private static final String KAFKA_VERSION = "2.7.0";
+    private static final String KAFKA_VERSION = "2.8.0";
     KafkaVersion kafkaVersion = VERSIONS.version(KAFKA_VERSION);
     private int brokerId = 0;
 

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -127,7 +127,7 @@ public class Environment {
     /**
      * Defaults
      */
-    private static final String ST_KAFKA_VERSION_DEFAULT = "2.7.0";
+    private static final String ST_KAFKA_VERSION_DEFAULT = "2.8.0";
     public static final String STRIMZI_ORG_DEFAULT = "strimzi";
     public static final String STRIMZI_TAG_DEFAULT = "latest";
     public static final String STRIMZI_REGISTRY_DEFAULT = "quay.io";

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -857,8 +857,8 @@ void testIdentityReplicationPolicy(ExtensionContext extensionContext) {
         assertNotNull(kafkaTopics.stream().filter(kafkaTopic -> kafkaTopic.equals(originalTopicName)).findAny());
 
         List<String> kafkaTopicSpec = KafkaCmdClient.describeTopicUsingPodCli(namespaceName, kafkaClusterTargetName, 0, originalTopicName);
-        assertThat(kafkaTopicSpec.get(0), equalTo("Topic:" + originalTopicName));
-        assertThat(kafkaTopicSpec.get(1), equalTo("PartitionCount:3"));
+        assertThat(kafkaTopicSpec.stream().filter(token -> token.startsWith("Topic:")).findFirst().orElse(null), equalTo("Topic:" + originalTopicName));
+        assertThat(kafkaTopicSpec.stream().filter(token -> token.startsWith("PartitionCount:")).findFirst().orElse(null), equalTo("PartitionCount:3"));
     }
 
     @ParallelNamespaceTest

File: test-container/src/main/java/io/strimzi/StrimziKafkaContainer.java
Patch:
@@ -10,7 +10,6 @@
 import org.apache.logging.log4j.Logger;
 import org.testcontainers.containers.GenericContainer;
 import org.testcontainers.containers.Network;
-import org.testcontainers.images.PullPolicy;
 import org.testcontainers.images.builder.Transferable;
 
 import java.io.BufferedReader;
@@ -68,7 +67,6 @@ public class StrimziKafkaContainer extends GenericContainer<StrimziKafkaContaine
     public StrimziKafkaContainer(final String version) {
         super("quay.io/strimzi/kafka:" + version);
         super.withNetwork(Network.SHARED);
-        super.withImagePullPolicy(PullPolicy.alwaysPull());
 
         // exposing kafka port from the container
         withExposedPorts(KAFKA_PORT);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -33,7 +33,7 @@ public void create(KafkaConnect resource) {
         kafkaConnectClient().inNamespace(resource.getMetadata().getNamespace()).withName(resource.getMetadata().getName()).createOrReplace(resource);
     }
     @Override
-    public void delete(KafkaConnect resource) {
+    public void delete(KafkaConnect resource)    {
         kafkaConnectClient().inNamespace(resource.getMetadata().getNamespace()).withName(
             resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/StatefulSetUtils.java
Patch:
@@ -37,7 +37,7 @@ private StatefulSetUtils() { }
      * @return A map of pod name to resource version for pods in the given StatefulSet.
      */
     public static Map<String, String> ssSnapshot(String namespaceName, String name) {
-        StatefulSet statefulSet = kubeClient(namespaceName).getStatefulSet(name);
+        StatefulSet statefulSet = kubeClient(namespaceName).getStatefulSet(namespaceName, name);
         LabelSelector selector = statefulSet.getSpec().getSelector();
         return PodUtils.podSnapshot(namespaceName, selector);
     }
@@ -160,7 +160,7 @@ public static void waitForAllStatefulSetPodsReady(String namespaceName, String s
 
         LOGGER.info("Waiting for StatefulSet {} to be ready", statefulSetName);
         TestUtils.waitFor("StatefulSet " + statefulSetName + " to be ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, timeout,
-            () -> kubeClient(namespaceName).getStatefulSetStatus(statefulSetName),
+            () -> kubeClient(namespaceName).getStatefulSetStatus(namespaceName, statefulSetName),
             () -> ResourceManager.logCurrentResourceStatus(KafkaResource.kafkaClient().inNamespace(namespaceName).withName(resourceName).get()));
 
         LOGGER.info("Waiting for {} Pod(s) of StatefulSet {} to be ready", expectPods, statefulSetName);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceType.java
Patch:
@@ -27,7 +27,7 @@ public interface ResourceType<T extends HasMetadata> {
     /**
      * Delete specific resource based on T type using Kubernetes API
      */
-    void delete(T resource) throws Exception;
+    void delete(T resource);
 
     /**
      * Check if this resource is marked as ready or not with wait.

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -33,7 +33,7 @@ public void create(KafkaBridge resource) {
         kafkaBridgeClient().inNamespace(resource.getMetadata().getNamespace()).createOrReplace(resource);
     }
     @Override
-    public void delete(KafkaBridge resource) throws Exception {
+    public void delete(KafkaBridge resource) {
         kafkaBridgeClient().inNamespace(resource.getMetadata().getNamespace()).withName(
             resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaClientsResource.java
Patch:
@@ -33,7 +33,7 @@ public void create(Deployment resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).createOrReplaceDeployment(resource);
     }
     @Override
-    public void delete(Deployment resource) throws Exception {
+    public void delete(Deployment resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteDeployment(resource.getMetadata().getNamespace(), resource.getMetadata().getName());
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -33,7 +33,7 @@ public void create(KafkaConnect resource) {
         kafkaConnectClient().inNamespace(resource.getMetadata().getNamespace()).withName(resource.getMetadata().getName()).createOrReplace(resource);
     }
     @Override
-    public void delete(KafkaConnect resource) throws Exception {
+    public void delete(KafkaConnect resource) {
         kafkaConnectClient().inNamespace(resource.getMetadata().getNamespace()).withName(
             resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -35,7 +35,7 @@ public void create(KafkaConnectS2I resource) {
         kafkaConnectS2IClient().inNamespace(resource.getMetadata().getNamespace()).withName(resource.getMetadata().getName()).createOrReplace(resource);
     }
     @Override
-    public void delete(KafkaConnectS2I resource) throws Exception {
+    public void delete(KafkaConnectS2I resource) {
         kafkaConnectS2IClient().inNamespace(resource.getMetadata().getNamespace()).withName(
             resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -34,7 +34,7 @@ public void create(KafkaConnector resource) {
         kafkaConnectorClient().inNamespace(resource.getMetadata().getNamespace()).createOrReplace(resource);
     }
     @Override
-    public void delete(KafkaConnector resource) throws Exception {
+    public void delete(KafkaConnector resource) {
         kafkaConnectorClient().inNamespace(resource.getMetadata().getNamespace()).withName(
             resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -31,7 +31,7 @@ public void create(KafkaMirrorMaker2 resource) {
         kafkaMirrorMaker2Client().inNamespace(resource.getMetadata().getNamespace()).createOrReplace(resource);
     }
     @Override
-    public void delete(KafkaMirrorMaker2 resource) throws Exception {
+    public void delete(KafkaMirrorMaker2 resource) {
         kafkaMirrorMaker2Client().inNamespace(resource.getMetadata().getNamespace()).withName(
             resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -31,7 +31,7 @@ public void create(KafkaMirrorMaker resource) {
         kafkaMirrorMakerClient().inNamespace(resource.getMetadata().getNamespace()).createOrReplace(resource);
     }
     @Override
-    public void delete(KafkaMirrorMaker resource) throws Exception {
+    public void delete(KafkaMirrorMaker resource) {
         kafkaMirrorMakerClient().inNamespace(resource.getMetadata().getNamespace()).withName(
             resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaRebalanceResource.java
Patch:
@@ -35,7 +35,7 @@ public void create(KafkaRebalance resource) {
         kafkaRebalanceClient().inNamespace(resource.getMetadata().getNamespace()).createOrReplace(resource);
     }
     @Override
-    public void delete(KafkaRebalance resource) throws Exception {
+    public void delete(KafkaRebalance resource) {
         kafkaRebalanceClient().inNamespace(resource.getMetadata().getNamespace()).withName(
             resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -39,7 +39,7 @@ public void create(Kafka resource) {
     }
 
     @Override
-    public void delete(Kafka resource) throws Exception {
+    public void delete(Kafka resource) {
         kafkaClient().inNamespace(resource.getMetadata().getNamespace()).withName(
             resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaTopicResource.java
Patch:
@@ -33,7 +33,7 @@ public void create(KafkaTopic resource) {
         kafkaTopicClient().inNamespace(resource.getMetadata().getNamespace()).createOrReplace(resource);
     }
     @Override
-    public void delete(KafkaTopic resource) throws Exception {
+    public void delete(KafkaTopic resource) {
         kafkaTopicClient().inNamespace(resource.getMetadata().getNamespace()).withName(
             resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaUserResource.java
Patch:
@@ -38,7 +38,7 @@ public void create(KafkaUser resource) {
     }
 
     @Override
-    public void delete(KafkaUser resource) throws Exception {
+    public void delete(KafkaUser resource) {
         kafkaUserClient().inNamespace(resource.getMetadata().getNamespace()).withName(resource.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/ClusterRoleBindingResource.java
Patch:
@@ -31,7 +31,7 @@ public void create(ClusterRoleBinding resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).createOrReplaceClusterRoleBinding(resource);
     }
     @Override
-    public void delete(ClusterRoleBinding resource) throws Exception {
+    public void delete(ClusterRoleBinding resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteClusterRoleBinding(resource);
     }
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/DeploymentResource.java
Patch:
@@ -31,7 +31,7 @@ public void create(Deployment resource) {
         ResourceManager.kubeClient().createOrReplaceDeployment(resource);
     }
     @Override
-    public void delete(Deployment resource) throws Exception {
+    public void delete(Deployment resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteDeployment(resource.getMetadata().getNamespace(), resource.getMetadata().getName());
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/JobResource.java
Patch:
@@ -23,7 +23,7 @@ public void create(Job resource) {
         ResourceManager.kubeClient().createJob(resource);
     }
     @Override
-    public void delete(Job resource) throws Exception {
+    public void delete(Job resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteJob(resource.getMetadata().getName());
     }
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/NetworkPolicyResource.java
Patch:
@@ -46,7 +46,7 @@ public void create(NetworkPolicy resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).createNetworkPolicy(resource);
     }
     @Override
-    public void delete(NetworkPolicy resource) throws Exception {
+    public void delete(NetworkPolicy resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteNetworkPolicy(resource.getMetadata().getName());
     }
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/RoleBindingResource.java
Patch:
@@ -32,7 +32,7 @@ public void create(RoleBinding resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).createOrReplaceRoleBinding(resource);
     }
     @Override
-    public void delete(RoleBinding resource) throws Exception {
+    public void delete(RoleBinding resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteRoleBinding(resource.getMetadata().getName());
     }
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/ServiceResource.java
Patch:
@@ -29,7 +29,7 @@ public void create(Service resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).createService(resource);
     }
     @Override
-    public void delete(Service resource) throws Exception {
+    public void delete(Service resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteService(resource);
     }
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/BundleResource.java
Patch:
@@ -41,7 +41,7 @@ public void create(Deployment resource) {
         ResourceManager.kubeClient().createOrReplaceDeployment(resource);
     }
     @Override
-    public void delete(Deployment resource) throws Exception {
+    public void delete(Deployment resource) {
         ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteDeployment(resource.getMetadata().getName());
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/listener/arraylistener/GenericKafkaListenerConfiguration.java
Patch:
@@ -85,9 +85,9 @@ public void setIngressClass(String ingressClass) {
             "* `InternalIP`\n" +
             "* `Hostname`\n" +
             "\n" +
-            "This field can be used to select the address type which will be used as the preferred type and checked first. " +
-            "In case no address will be found for this address type, the other types will be used in the default order." +
-            "This field can be used only with `nodeport` type listener.")
+            "This field is used to select the preferred address type, which is checked first. " +
+            "If no address is found for this address type, the other types are checked in the default order. " +
+            "This field can only be used with `nodeport` type listener.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public NodeAddressType getPreferredNodePortAddressType() {
         return preferredNodePortAddressType;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaRoller.java
Patch:
@@ -214,7 +214,7 @@ public Future<Void> rollingRestart(Function<Pod, List<String>> podNeedsRestart)
                     allClient.close(Duration.ofSeconds(30));
                 }
             } catch (RuntimeException e) {
-                log.debug("Exception closing the allClient", e);
+                log.debug("{}: Exception closing admin client", reconciliation, e);
             }
             vertx.runOnContext(ignored -> result.handle(ar.map((Void) null)));
         });
@@ -703,7 +703,7 @@ protected Admin adminClient(List<Integer> bootstrapPods, boolean ceShouldBeFatal
     }
 
     protected KafkaAvailability availability(Admin ac) {
-        return new KafkaAvailability(ac);
+        return new KafkaAvailability(ac, reconciliation);
     }
 
     String podName(int podId) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaRollerTest.java
Patch:
@@ -621,7 +621,7 @@ protected Admin adminClient(List<Integer> bootstrapBrokers, boolean b) throws Fo
 
         @Override
         protected KafkaAvailability availability(Admin ac) {
-            return new KafkaAvailability(null) {
+            return new KafkaAvailability(null, null) {
                 @Override
                 protected Future<Set<String>> topicNames() {
                     return succeededFuture(Collections.emptySet());

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/AbstractKafkaClient.java
Patch:
@@ -257,7 +257,9 @@ public String getSecretPrefix() {
     public String getClusterName() {
         return clusterName;
     }
-
+    public String getNamespaceName() {
+        return namespaceName;
+    }
     @Override
     public String toString() {
         return "AbstractKafkaClient{" +

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/VerifiableClient.java
Patch:
@@ -121,7 +121,7 @@ public VerifiableClient(VerifiableClientBuilder verifiableClientBuilder) {
         this.clientArgumentMap.put(ClientArgument.MAX_MESSAGES, Integer.toString(maxMessages));
         if (kafkaUsername != null) this.clientArgumentMap.put(ClientArgument.USER, kafkaUsername.replace("-", "_"));
 
-        String image = kubeClient().getPod(this.podName).getSpec().getContainers().get(0).getImage();
+        String image = kubeClient().namespace(podNamespace).getPod(this.podName).getSpec().getContainers().get(0).getImage();
         String clientVersion = image.substring(image.length() - 5);
 
         this.clientArgumentMap.put(allowParameter("2.5.0", clientVersion) ? ClientArgument.BOOTSTRAP_SERVER : ClientArgument.BROKER_LIST, bootstrapServer);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/DeploymentResource.java
Patch:
@@ -32,12 +32,12 @@ public void create(Deployment resource) {
     }
     @Override
     public void delete(Deployment resource) throws Exception {
-        ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteDeployment(resource.getMetadata().getName());
+        ResourceManager.kubeClient().namespace(resource.getMetadata().getNamespace()).deleteDeployment(resource.getMetadata().getNamespace(), resource.getMetadata().getName());
     }
 
     @Override
     public boolean waitForReadiness(Deployment resource) {
-        return DeploymentUtils.waitForDeploymentAndPodsReady(resource.getMetadata().getName(), resource.getSpec().getReplicas());
+        return DeploymentUtils.waitForDeploymentAndPodsReady(resource.getMetadata().getNamespace(), resource.getMetadata().getName(), resource.getSpec().getReplicas());
     }
 
     public static Deployment getDeploymentFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/kubernetes/NetworkPolicyResource.java
Patch:
@@ -157,7 +157,7 @@ public static void allowNetworkPolicySettingsForResource(ExtensionContext extens
             .addToMatchLabels(Constants.KAFKA_CLIENTS_LABEL_KEY, Constants.KAFKA_CLIENTS_LABEL_VALUE)
             .build();
 
-        if (kubeClient().listPods(labelSelector).size() == 0) {
+        if (kubeClient(resource.getMetadata().getNamespace()).listPods(labelSelector).size() == 0) {
             throw new RuntimeException("You did not create the Kafka Client instance(pod) before using the " + resource.getKind());
         }
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -85,7 +85,7 @@ void testSendSimpleMessage(ExtensionContext extensionContext) {
 
         // Checking labels for Kafka Bridge
         verifyLabelsOnPods(httpBridgeClusterName, "my-bridge", null, "KafkaBridge");
-        verifyLabelsForService(httpBridgeClusterName, "my-bridge", "KafkaBridge");
+        verifyLabelsForService(NAMESPACE, httpBridgeClusterName, "my-bridge", "KafkaBridge");
     }
 
     @ParallelTest

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -379,6 +379,7 @@ public static KafkaCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup vers
 
         result.setReplicas(kafkaClusterSpec.getReplicas());
 
+        validateIntConfigProperty("default.replication.factor", kafkaClusterSpec);
         validateIntConfigProperty("offsets.topic.replication.factor", kafkaClusterSpec);
         validateIntConfigProperty("transaction.state.log.replication.factor", kafkaClusterSpec);
         validateIntConfigProperty("transaction.state.log.min.isr", kafkaClusterSpec);

File: topic-operator/src/main/java/io/strimzi/operator/topic/Topic.java
Patch:
@@ -14,7 +14,7 @@ public class Topic {
 
     public static class Builder {
         private TopicName topicName;
-        private int numPartitions;
+        private int numPartitions = -1;
         private short numReplicas = -1;
         private Map<String, String> config = new HashMap<>();
         private ObjectMeta metadata = new ObjectMeta();

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicDiff.java
Patch:
@@ -228,11 +228,11 @@ public static TopicDiff diff(Topic source, Topic target) {
             throw new IllegalArgumentException();
         }
         Map<String, Difference> differences = new HashMap<>();
-        if (source.getNumPartitions() != target.getNumPartitions()) {
+        if (target.getNumPartitions() != -1 && source.getNumPartitions() != target.getNumPartitions()) {
             NumPartitionsDifference numPartitionsDifference = new NumPartitionsDifference(source.getNumPartitions(), target.getNumPartitions());
             differences.put(numPartitionsDifference.address(), numPartitionsDifference);
         }
-        if (source.getNumReplicas() != target.getNumReplicas()) {
+        if (target.getNumReplicas() != -1 && source.getNumReplicas() != target.getNumReplicas()) {
             NumReplicasDifference numReplicasDifference = new NumReplicasDifference(target.getNumReplicas());
             differences.put(numReplicasDifference.address(), numReplicasDifference);
         }
@@ -375,4 +375,3 @@ public TopicDiff merge(TopicDiff other) {
         return new TopicDiff(union, other.objectMeta);
     }
 }
-

File: api-conversion/src/main/java/io/strimzi/kafka/api/conversion/converter/KafkaConverter.java
Patch:
@@ -72,9 +72,9 @@ public Conversion.InvertibleFunction<ArrayOrObjectKafkaListeners> inverse() {
         Conversion.replaceLogging("/spec/entityOperator/topicOperator/logging", "log4j2.properties"),
         Conversion.replaceLogging("/spec/entityOperator/userOperator/logging", "log4j2.properties"),
         Conversion.replaceLogging("/spec/cruiseControl/logging", "log4j2.properties"),
-        new MetricsConversion<>("/spec/kafka", KafkaClusterSpec.class, "kafka"),
-        new MetricsConversion<>("/spec/zookeeper", ZookeeperClusterSpec.class, "zookeeper"),
-        new MetricsConversion<>("/spec/cruiseControl", CruiseControlSpec.class, "cruise-control")
+        new MetricsConversion<Kafka>("/spec/kafka", KafkaClusterSpec.class, "kafka"),
+        new MetricsConversion<Kafka>("/spec/zookeeper", ZookeeperClusterSpec.class, "zookeeper"),
+        new MetricsConversion<Kafka>("/spec/cruiseControl", CruiseControlSpec.class, "cruise-control")
     );
 
     public KafkaConverter() {

File: api/src/test/java/io/strimzi/api/kafka/model/AbstractCrdIT.java
Patch:
@@ -56,7 +56,7 @@ private void createDelete(File resourceFile) {
         RuntimeException deletionException = null;
         try {
             try {
-                cmdKubeClient().create(resourceFile);
+                cmdKubeClient().create(resourceFile, false);
             } catch (RuntimeException t) {
                 creationException = t;
             }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/QuantitiesTest.java
Patch:
@@ -125,12 +125,12 @@ public void testParse() {
         try {
             parseCpuAsMilliCpus("0.0m");
             fail();
-        } catch (NumberFormatException e) { }
+        } catch (IllegalArgumentException e) { }
 
         try {
             parseCpuAsMilliCpus("0.1m");
             fail();
-        } catch (NumberFormatException e) { }
+        } catch (IllegalArgumentException e) { }
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -117,6 +117,9 @@ void testDeployUndeploy(ExtensionContext extensionContext) {
         Map<String, Object> exceptedConfig = StUtils.loadProperties("group.id=" + KafkaConnectResources.deploymentName(clusterName) + "\n" +
                 "key.converter=org.apache.kafka.connect.json.JsonConverter\n" +
                 "value.converter=org.apache.kafka.connect.json.JsonConverter\n" +
+                "config.storage.replication.factor=-1\n" +
+                "offset.storage.replication.factor=-1\n" +
+                "status.storage.replication.factor=-1\n" +
                 "config.storage.topic=" + KafkaConnectResources.metricsAndLogConfigMapName(clusterName) + "\n" +
                 "status.storage.topic=" + KafkaConnectResources.configStorageTopicStatus(clusterName) + "\n" +
                 "offset.storage.topic=" + KafkaConnectResources.configStorageTopicOffsets(clusterName) + "\n");

File: api/src/main/java/io/strimzi/api/kafka/model/EntityTopicOperatorSpec.java
Patch:
@@ -41,8 +41,8 @@ public class EntityTopicOperatorSpec implements UnknownPropertyPreserving, Seria
     public static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;
     public static final int DEFAULT_ZOOKEEPER_PORT = 2181;
     public static final int DEFAULT_BOOTSTRAP_SERVERS_PORT = 9091;
-    public static final int DEFAULT_FULL_RECONCILIATION_INTERVAL_SECONDS = 90;
-    public static final int DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS = 20;
+    public static final int DEFAULT_FULL_RECONCILIATION_INTERVAL_SECONDS = 120;
+    public static final int DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS = 18;
     public static final int DEFAULT_TOPIC_METADATA_MAX_ATTEMPTS = 6;
 
     protected String watchedNamespace;

File: api/src/main/java/io/strimzi/api/kafka/model/EntityUserOperatorSpec.java
Patch:
@@ -41,7 +41,7 @@ public class EntityUserOperatorSpec implements UnknownPropertyPreserving, Serial
     public static final int DEFAULT_ZOOKEEPER_PORT = 2181;
     public static final int DEFAULT_BOOTSTRAP_SERVERS_PORT = 9091;
     public static final long DEFAULT_FULL_RECONCILIATION_INTERVAL_SECONDS = 120;
-    public static final long DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS = 6;
+    public static final long DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS = 18;
     public static final String DEFAULT_SECRET_PREFIX = "";
 
     private String watchedNamespace;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -62,8 +62,8 @@ public class EntityTopicOperatorTest {
 
     private final String toWatchedNamespace = "my-topic-namespace";
     private final String toImage = "my-topic-operator-image";
-    private final int toReconciliationInterval = 90;
-    private final int toZookeeperSessionTimeout = 20;
+    private final int toReconciliationInterval = 120;
+    private final int toZookeeperSessionTimeout = 18;
     private final int toTopicMetadataMaxAttempts = 3;
 
     private final List<SystemProperty> javaSystemProperties = new ArrayList<SystemProperty>() {{

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -68,8 +68,8 @@ public class EntityUserOperatorTest {
     private final String uoWatchedNamespace = "my-user-namespace";
     private final String uoImage = "my-user-operator-image";
     private final String secretPrefix = "strimzi-";
-    private final int uoReconciliationInterval = 90;
-    private final int uoZookeeperSessionTimeout = 20;
+    private final int uoReconciliationInterval = 120;
+    private final int uoZookeeperSessionTimeout = 18;
 
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
     private final String metricsCMName = "metrics-cm";

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -37,7 +37,7 @@ public interface Constants {
 
     long API_CRUISE_CONTROL_POLL = Duration.ofSeconds(5).toMillis();
     long API_CRUISE_CONTROL_TIMEOUT = Duration.ofMinutes(10).toMillis();
-    long GLOBAL_CRUISE_CONTROL_TIMEOUT = Duration.ofMinutes(1).toMillis();
+    long GLOBAL_CRUISE_CONTROL_TIMEOUT = Duration.ofMinutes(2).toMillis();
 
     long OLM_UPGRADE_INSTALL_PLAN_TIMEOUT = Duration.ofMinutes(15).toMillis();
     long OLM_UPGRADE_INSTALL_PLAN_POLL = Duration.ofMinutes(1).toMillis();

File: topic-operator/src/main/java/io/strimzi/operator/topic/Config.java
Patch:
@@ -144,13 +144,13 @@ private Value(String key, Type<? extends T> type, boolean required) {
     public static final Value<String> ZOOKEEPER_CONNECT = new Value<>(TC_ZK_CONNECT, STRING, true);
 
     /** The zookeeper session timeout. */
-    public static final Value<Long> ZOOKEEPER_SESSION_TIMEOUT_MS = new Value<>(TC_ZK_SESSION_TIMEOUT_MS, DURATION, "20000");
+    public static final Value<Long> ZOOKEEPER_SESSION_TIMEOUT_MS = new Value<>(TC_ZK_SESSION_TIMEOUT_MS, DURATION, "18000");
 
     /** The zookeeper connection timeout. */
-    public static final Value<Long> ZOOKEEPER_CONNECTION_TIMEOUT_MS = new Value<>(TC_ZK_CONNECTION_TIMEOUT_MS, DURATION, "20000");
+    public static final Value<Long> ZOOKEEPER_CONNECTION_TIMEOUT_MS = new Value<>(TC_ZK_CONNECTION_TIMEOUT_MS, DURATION, "18000");
 
     /** The period between full reconciliations. */
-    public static final Value<Long> FULL_RECONCILIATION_INTERVAL_MS = new Value<>(TC_PERIODIC_INTERVAL_MS, DURATION, "900000");
+    public static final Value<Long> FULL_RECONCILIATION_INTERVAL_MS = new Value<>(TC_PERIODIC_INTERVAL_MS, DURATION, "120000");
 
     /** The interbroker throttled rate to use when a topic change requires partition reassignment. */
     public static final Value<Long> REASSIGN_THROTTLE = new Value<>(TC_REASSIGN_THROTTLE, LONG, Long.toString(Long.MAX_VALUE));

File: topic-operator/src/test/java/io/strimzi/operator/topic/ConfigTest.java
Patch:
@@ -44,7 +44,7 @@ public void testEmptyMapThrows() {
     public void testDefaultInput() {
         Map<String, String> map = new HashMap<>(MANDATORY);
         Config c = new Config(map);
-        assertThat(c.get(Config.ZOOKEEPER_SESSION_TIMEOUT_MS).intValue(), is(20_000));
+        assertThat(c.get(Config.ZOOKEEPER_SESSION_TIMEOUT_MS).intValue(), is(18_000));
     }
 
     @Test

File: user-operator/src/main/java/io/strimzi/operator/user/UserOperatorConfig.java
Patch:
@@ -33,7 +33,7 @@ public class UserOperatorConfig {
     public static final long DEFAULT_FULL_RECONCILIATION_INTERVAL_MS = 120_000;
     public static final String DEFAULT_KAFKA_BOOTSTRAP_SERVERS = "localhost:9091";
     public static final String DEFAULT_ZOOKEEPER_CONNECT = "localhost:2181";
-    public static final long DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_MS = 6_000;
+    public static final long DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_MS = 18_000;
     public static final String DEFAULT_SECRET_PREFIX = "";
 
     private final String namespace;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java
Patch:
@@ -418,9 +418,11 @@ public static String changeOrRemoveKafkaConfiguration(File file, String version,
             if (version == null) {
                 kafkaNode.remove("version");
                 ((ObjectNode) kafkaNode.get("config")).remove("log.message.format.version");
+                ((ObjectNode) kafkaNode.get("config")).remove("inter.broker.protocol.version");
             } else if (!version.equals("")) {
                 kafkaNode.put("version", version);
                 ((ObjectNode) kafkaNode.get("config")).put("log.message.format.version", version.substring(0, 3));
+                ((ObjectNode) kafkaNode.get("config")).put("inter.broker.protocol.version", version.substring(0, 3));
             }
             if (logMessageFormat != null) {
                 ((ObjectNode) kafkaNode.get("config")).put("log.message.format.version", logMessageFormat);

File: test/src/main/java/io/strimzi/test/executor/Exec.java
Patch:
@@ -166,7 +166,7 @@ public static ExecResult exec(String input, List<String> command, int timeout, b
                 if (logToOutput || ret != 0) {
                     String log = ret != 0 ? "Failed to exec command" : "Command";
                     LOGGER.info("{}: {}", log, String.join(" ", command));
-                    if (input != null && !input.contains("CusomResourceDefinition")) {
+                    if (input != null && !input.contains("CustomResourceDefinition")) {
                         LOGGER.info("Input: {}", input.trim());
                     }
                     LOGGER.info("RETURN code: {}", ret);

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/KubeCmdClient.java
Patch:
@@ -46,6 +46,8 @@ public interface KubeCmdClient<K extends KubeCmdClient<K>> {
     /** Deletes the resources in the given files. */
     K delete(File... files);
 
+    K createOrReplace(File file);
+
     default K create(String... files) {
         return create(asList(files).stream().map(File::new).collect(toList()).toArray(new File[0]));
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/arraylistener/GenericKafkaListenerConfiguration.java
Patch:
@@ -18,7 +18,6 @@
 import lombok.EqualsAndHashCode;
 
 import java.io.Serializable;
-import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
@@ -43,7 +42,7 @@ public class GenericKafkaListenerConfiguration implements Serializable, UnknownP
     private String ingressClass;
     private NodeAddressType preferredNodePortAddressType;
     private ExternalTrafficPolicy externalTrafficPolicy;
-    private List<String> loadBalancerSourceRanges = new ArrayList<>(0);
+    private List<String> loadBalancerSourceRanges;
     private List<String> finalizers;
     private Boolean useServiceDnsDomain;
     private GenericKafkaListenerConfigurationBootstrap bootstrap;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ListenersUtils.java
Patch:
@@ -535,7 +535,7 @@ public static List<String> loadBalancerSourceRanges(GenericKafkaListener listene
         if (listener.getConfiguration() != null) {
             return listener.getConfiguration().getLoadBalancerSourceRanges();
         } else {
-            return Collections.emptyList();
+            return null;
         }
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/AbstractKafkaClient.java
Patch:
@@ -254,6 +254,9 @@ public String getListenerName() {
     public String getSecretPrefix() {
         return secretPrefix;
     }
+    public String getClusterName() {
+        return clusterName;
+    }
 
     @Override
     public String toString() {

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthExternalKafkaClient.java
Patch:
@@ -9,7 +9,7 @@
 import io.strimzi.systemtest.kafkaclients.KafkaClientOperations;
 import io.strimzi.systemtest.kafkaclients.clientproperties.ConsumerProperties;
 import io.strimzi.systemtest.kafkaclients.clientproperties.ProducerProperties;
-import io.strimzi.systemtest.resources.crd.KafkaResource;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.strimzi.test.WaitException;
 import org.apache.kafka.clients.consumer.OffsetResetStrategy;
 import org.apache.kafka.common.security.auth.SecurityProtocol;
@@ -149,7 +149,7 @@ public int sendMessagesTls(long timeoutMs) {
         IntPredicate msgCntPredicate = x -> x == messageCount;
 
         this.caCertName = this.caCertName == null ?
-            KafkaResource.getKafkaExternalListenerCaCertName(namespaceName, clusterName, listenerName) :
+            KafkaUtils.getKafkaExternalListenerCaCertName(namespaceName, clusterName, listenerName) :
             this.caCertName;
 
         LOGGER.info("Going to use the following CA certificate: {}", caCertName);
@@ -240,7 +240,7 @@ public int receiveMessagesTls(long timeoutMs) {
         IntPredicate msgCntPredicate = x -> x == messageCount;
 
         this.caCertName = this.caCertName == null ?
-            KafkaResource.getKafkaExternalListenerCaCertName(namespaceName, clusterName, listenerName) :
+            KafkaUtils.getKafkaExternalListenerCaCertName(namespaceName, clusterName, listenerName) :
             this.caCertName;
 
         LOGGER.info("Going to use the following CA certificate: {}", caCertName);

File: systemtest/src/main/java/io/strimzi/systemtest/logs/TestExecutionWatcher.java
Patch:
@@ -70,7 +70,7 @@ public void handleAfterAllMethodExecutionException(ExtensionContext extensionCon
 
     public static void collectLogs(String testClass, String testMethod) {
         // Stop test execution time counter in case of failures
-        TimeMeasuringSystem.getInstance().stopOperation(Operation.TEST_EXECUTION);
+        TimeMeasuringSystem.getInstance().stopOperation(Operation.TEST_EXECUTION, testClass, testMethod);
         // Get current date to create a unique folder
         final SimpleDateFormat simpleDateFormat = new SimpleDateFormat("yyyyMMdd_HHmmss");
         simpleDateFormat.setTimeZone(TimeZone.getTimeZone("GMT"));

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaRebalanceUtils.java
Patch:
@@ -49,9 +49,9 @@ private static Condition rebalanceStateCondition(String resourceName) {
         }
     }
 
-    public static void waitForKafkaRebalanceCustomResourceState(String resourceName, KafkaRebalanceState state) {
+    public static boolean waitForKafkaRebalanceCustomResourceState(String resourceName, KafkaRebalanceState state) {
         KafkaRebalance kafkaRebalance = KafkaRebalanceResource.kafkaRebalanceClient().inNamespace(kubeClient().getNamespace()).withName(resourceName).get();
-        ResourceManager.waitForResourceStatus(KafkaRebalanceResource.kafkaRebalanceClient(), kafkaRebalance, state, ResourceOperation.getTimeoutForKafkaRebalanceState(state));
+        return ResourceManager.waitForResourceStatus(KafkaRebalanceResource.kafkaRebalanceClient(), kafkaRebalance, state, ResourceOperation.getTimeoutForKafkaRebalanceState(state));
     }
 
     public static String annotateKafkaRebalanceResource(String resourceName, KafkaRebalanceAnnotation annotation) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/KeycloakUtils.java
Patch:
@@ -5,14 +5,14 @@
 package io.strimzi.systemtest.utils.specific;
 
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.executor.Exec;
 import io.strimzi.test.executor.ExecResult;
 import io.vertx.core.json.JsonArray;
 import io.vertx.core.json.JsonObject;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import org.junit.jupiter.api.extension.ExtensionContext;
 
 import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;
 import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;
@@ -27,9 +27,8 @@ public class KeycloakUtils {
 
     private KeycloakUtils() {}
 
-    public static void deployKeycloak(String namespace) {
+    public static void deployKeycloak(ExtensionContext extensionContext, String namespace) {
         LOGGER.info("Prepare Keycloak in namespace: {}", namespace);
-        ResourceManager.getPointerResources().push(() -> deleteKeycloak(namespace));
 
         // This is needed because from time to time the first try fails on Azure
         TestUtils.waitFor("Keycloak instance readiness", Constants.KEYCLOAK_DEPLOYMENT_POLL, Constants.KEYCLOAK_DEPLOYMENT_TIMEOUT, () -> {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/OlmUtils.java
Patch:
@@ -5,7 +5,7 @@
 package io.strimzi.systemtest.utils.specific;
 
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.resources.operator.OlmResource;
+import io.strimzi.systemtest.resources.specific.OlmResource;
 import io.strimzi.test.TestUtils;
 
 public class OlmUtils {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -37,7 +37,7 @@
 import java.util.function.Consumer;
 
 import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
-import static io.strimzi.systemtest.interfaces.TestSeparator.LOGGER;
+import static io.strimzi.test.interfaces.TestSeparator.LOGGER;
 import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
 import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -37,6 +37,7 @@
 import java.util.function.Consumer;
 
 import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
+import static io.strimzi.systemtest.interfaces.TestSeparator.LOGGER;
 import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
 import static io.strimzi.systemtest.resources.ResourceManager.kubeClient;
 
@@ -242,6 +243,7 @@ public static Kafka createAndWaitForReadiness(Kafka kafka) {
                     if (e.getMessage().contains("object is being deleted")) {
                         return false;
                     } else {
+                        LOGGER.debug("Error found: " + e.getMessage());
                         throw e;
                     }
                 }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/JobUtils.java
Patch:
@@ -48,6 +48,6 @@ public static void deleteJobWithWait(String namespace, String name) {
     public static void waitForJobFailure(String jobName, String namespace, long timeout) {
         LOGGER.info("Waiting for job: {} will be in error state", jobName);
         TestUtils.waitFor("job finished", Constants.GLOBAL_POLL_INTERVAL, timeout,
-            () -> !kubeClient().getJobStatus(jobName));
+            () -> !kubeClient().checkSucceededJobStatus(jobName));
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -72,6 +72,7 @@
 import static org.hamcrest.Matchers.hasItem;
 import static org.hamcrest.Matchers.is;
 import static org.hamcrest.Matchers.nullValue;
+import static org.junit.jupiter.api.Assertions.assertDoesNotThrow;
 import static org.junit.jupiter.api.Assertions.assertNotNull;
 import static org.junit.jupiter.api.Assertions.assertNull;
 import static org.valid4j.matchers.jsonpath.JsonPathMatchers.hasJsonPath;
@@ -1042,12 +1043,12 @@ void testRestoreOffsetsInConsumerGroup() {
         LOGGER.info("There should be no more messages to read. Try to consume at least 1 message. " +
                 "This client job should fail on timeout.");
         initialInternalClientTargetJob.createAndWaitForReadiness(initialInternalClientTargetJob.consumerStrimzi().build());
-        ClientUtils.waitForClientTimeout(targetConsumerName, NAMESPACE, 1);
+        assertDoesNotThrow(() -> ClientUtils.waitForClientTimeout(targetConsumerName, NAMESPACE, 1));
 
         LOGGER.info("As it's Active-Active MM2 mode, there should be no more messages to read from Source cluster" +
                 " topic. This client job should fail on timeout.");
         initialInternalClientSourceJob.createAndWaitForReadiness(initialInternalClientSourceJob.consumerStrimzi().build());
-        ClientUtils.waitForClientTimeout(sourceConsumerName, NAMESPACE, 1);
+        assertDoesNotThrow(() -> ClientUtils.waitForClientTimeout(sourceConsumerName, NAMESPACE, 1));
     }
 
     @BeforeAll

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaConnectorCrdIT.java
Patch:
@@ -20,7 +20,7 @@ public class KafkaConnectorCrdIT extends AbstractCrdIT {
 
     @Test
     void testKafkaConnector() {
-        createDelete(KafkaConnector.class, "KafkaConnector.yaml");
+        createDeleteCustomResource("KafkaConnector.yaml");
     }
 
     @Test

File: api/src/test/java/io/strimzi/api/kafka/model/StructuralCrdIT.java
Patch:
@@ -17,6 +17,7 @@
 import io.fabric8.kubernetes.api.model.apiextensions.v1beta1.CustomResourceDefinitionVersion;
 import io.strimzi.api.annotations.ApiVersion;
 import io.strimzi.api.annotations.VersionRange;
+import io.strimzi.test.TestUtils;
 import org.junit.jupiter.api.Test;
 
 import static org.junit.jupiter.api.Assertions.assertTrue;
@@ -43,7 +44,7 @@ public void v1Beta2IsStructuralWithCrdV1Beta1() {
         for (Map.Entry<String, String> crd : crdFiles.entrySet()) {
             assertApiVersionsAreStructural(crd.getKey(),
                     ApiVersion.V1BETA1,
-                    "./src/test/resources/io/strimzi/api/kafka/model/" + crd.getValue(),
+                    TestUtils.USER_PATH + "/./src/test/resources/io/strimzi/api/kafka/model/" + crd.getValue(),
                     ApiVersion.parseRange("v1beta2+"));
         }
     }
@@ -55,7 +56,7 @@ public void v1Beta2IsStructuralWithCrdV1() {
         for (Map.Entry<String, String> crd : crdFiles.entrySet()) {
             assertApiVersionsAreStructural(crd.getKey(),
                     ApiVersion.V1,
-                    "../packaging/install/cluster-operator/" + crd.getValue(),
+                    TestUtils.USER_PATH + "/../packaging/install/cluster-operator/" + crd.getValue(),
                     ApiVersion.parseRange("v1beta2+"));
         }
     }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -14,7 +14,6 @@
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.interfaces.IndicativeSentences;
-import io.strimzi.systemtest.interfaces.TestSeparator;
 import io.strimzi.systemtest.logs.TestExecutionWatcher;
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.operator.BundleResource;
@@ -27,6 +26,7 @@
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.executor.Exec;
+import io.strimzi.test.interfaces.TestSeparator;
 import io.strimzi.test.k8s.KubeClusterResource;
 import io.strimzi.test.k8s.cluster.Minishift;
 import io.strimzi.test.k8s.cluster.OpenShift;

File: test/src/main/java/io/strimzi/test/interfaces/ExtensionContextParameterResolver.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.interfaces;
+package io.strimzi.test.interfaces;
 
 import org.junit.jupiter.api.extension.ExtensionContext;
 import org.junit.jupiter.api.extension.ParameterContext;

File: test/src/main/java/io/strimzi/test/interfaces/TestSeparator.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.interfaces;
+package io.strimzi.test.interfaces;
 
 import io.strimzi.test.timemeasuring.Operation;
 import io.strimzi.test.timemeasuring.TimeMeasuringSystem;
@@ -34,4 +34,4 @@ default void afterEachTest(ExtensionContext testContext) {
         LOGGER.info(String.format("%s.%s-FINISHED", testContext.getRequiredTestClass().getName(), testContext.getRequiredTestMethod().getName()));
         LOGGER.info(String.join("", Collections.nCopies(76, SEPARATOR_CHAR)));
     }
-}
\ No newline at end of file
+}

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/KubeCmdClient.java
Patch:
@@ -38,6 +38,8 @@ public interface KubeCmdClient<K extends KubeCmdClient<K>> {
     /** Creates the resources in the given files. */
     K create(File... files);
 
+    K create(File file);
+
     /** Creates the resources in the given files. */
     K apply(File... files);
 

File: user-operator/src/main/java/io/strimzi/operator/user/Main.java
Patch:
@@ -84,7 +84,7 @@ static Future<String> run(Vertx vertx, KubernetesClient client, AdminClientProvi
                     SimpleAclOperator aclOperations = new SimpleAclOperator(vertx, adminClient);
                     ScramShaCredentials scramShaCredentials = new ScramShaCredentials(config.getZookeperConnect(), (int) config.getZookeeperSessionTimeoutMs());
                     ScramShaCredentialsOperator scramShaCredentialsOperator = new ScramShaCredentialsOperator(vertx, scramShaCredentials);
-                    KafkaUserQuotasOperator quotasOperator = new KafkaUserQuotasOperator(vertx, config.getZookeperConnect(), (int) config.getZookeeperSessionTimeoutMs());
+                    KafkaUserQuotasOperator quotasOperator = new KafkaUserQuotasOperator(vertx, adminClient);
 
                     KafkaUserOperator kafkaUserOperations = new KafkaUserOperator(vertx,
                             certManager, crdOperations,

File: systemtest/src/main/java/io/strimzi/systemtest/enums/CustomResourceStatus.java
Patch:
@@ -7,5 +7,6 @@
 public enum CustomResourceStatus {
     Ready,
     NotReady,
-    Warning
+    Warning,
+    ReconciliationPaused
 }

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -667,7 +667,7 @@ void testConnectS2IService() {
             .endSpec()
             .build());
 
-        KafkaConnectorResource.createAndWaitForReadiness(KafkaConnectorResource.kafkaConnector(CLUSTER_NAME)
+        KafkaConnectorResource.createAndWaitForReadiness(KafkaConnectorResource.kafkaConnector(kafkaConnectS2IName)
             .editSpec()
                 .withClassName("org.apache.kafka.connect.file.FileStreamSinkConnector")
                 .addToConfig("file", Constants.DEFAULT_SINK_FILE_PATH)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperator.java
Patch:
@@ -833,7 +833,7 @@ private Future<KafkaRebalanceStatus> onStop(Reconciliation reconciliation,
                             KafkaRebalanceStatus kafkaRebalanceStatus = currentKafkaRebalance.getStatus();
                             KafkaRebalanceState currentState;
                             // cluster rebalance is new or it is in one of the others states
-                            if (kafkaRebalanceStatus == null) {
+                            if (kafkaRebalanceStatus == null || kafkaRebalanceStatus.getConditions().stream().filter(cond -> "ReconciliationPaused".equals(cond.getType())).findAny().isPresent()) {
                                 currentState = KafkaRebalanceState.New;
                             } else {
                                 String rebalanceStateType = rebalanceStateConditionType(kafkaRebalanceStatus);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaStatusTest.java
Patch:
@@ -212,7 +212,7 @@ public void testPauseReconciliationsStatus(VertxTestContext context) throws Pars
             assertThat(status.getConditions().size(), is(1));
             assertThat(status.getConditions().get(0).getStatus(), is("True"));
             assertThat(status.getConditions().get(0).getType(), is("ReconciliationPaused"));
-            assertThat(status.getObservedGeneration(), is(0L));
+            assertThat(status.getObservedGeneration(), is(1L));
             async.flag();
         });
     }

File: operator-common/src/main/java/io/strimzi/operator/common/AbstractOperator.java
Patch:
@@ -215,6 +215,7 @@ public final Future<Void> reconcile(Reconciliation reconciliation) {
                     Set<Condition> conditions = validate(cr);
                     conditions.add(StatusUtils.getPausedCondition());
                     status.setConditions(new ArrayList<>(conditions));
+                    status.setObservedGeneration(cr.getStatus() != null ? cr.getStatus().getObservedGeneration() : 0);
 
                     updateStatus(reconciliation, status).onComplete(statusResult -> {
                         if (statusResult.succeeded()) {

File: api/src/test/java/io/strimzi/api/kafka/model/ExamplesTest.java
Patch:
@@ -34,7 +34,7 @@
 
 /**
  * The purpose of this test is to check that all the resources in the
- * {@code ../examples} directory are valid.
+ * {@code ../packaging/examples} directory are valid.
  */
 public class ExamplesTest {
 
@@ -50,13 +50,13 @@ public class ExamplesTest {
      */
     @Test
     public void examples() {
-        validateRecursively(new File(TestUtils.USER_PATH + "/../examples"));
+        validateRecursively(new File(TestUtils.USER_PATH + "/../packaging/examples"));
     }
 
     private void validateRecursively(File directory) {
         for (File f : directory.listFiles()) {
             if (f.isDirectory()) {
-                if (f.getAbsolutePath().contains("examples/metrics/grafana") || f.getAbsolutePath().contains("examples/metrics/prometheus"))  {
+                if (f.getAbsolutePath().contains("packaging/examples/metrics/grafana") || f.getAbsolutePath().contains("packaging/examples/metrics/prometheus"))  {
                     continue;
                 } else {
                     validateRecursively(f);

File: api/src/test/java/io/strimzi/api/kafka/model/StructuralCrdIT.java
Patch:
@@ -43,7 +43,7 @@ public void v1Beta2IsStructuralWithCrdV1Beta1() {
         for (Map.Entry<String, String> crd : crdFiles.entrySet()) {
             assertApiVersionsAreStructural(crd.getKey(),
                     ApiVersion.V1BETA1,
-                    "../install/cluster-operator/" + crd.getValue(),
+                    "../packaging/install/cluster-operator/" + crd.getValue(),
                     ApiVersion.parseRange("v1beta2+"));
         }
     }

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziDowngradeST.java
Patch:
@@ -5,6 +5,7 @@
 package io.strimzi.systemtest.upgrade;
 
 import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.vertx.core.json.JsonObject;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -61,6 +62,8 @@ private void performDowngrade(JsonObject testParameters, ExtensionContext extens
         // Wait for Kafka cluster rolling update
         waitForKafkaClusterRollingUpdate();
         logPodImages(clusterName);
+        // Verify that pods are stable
+        PodUtils.verifyThatRunningPodsAreStable(clusterName);
         checkAllImages(testParameters.getJsonObject("imagesAfterOperatorDowngrade"));
         // Verify upgrade
         verifyProcedure(testParameters, producerName, consumerName, NAMESPACE);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -349,7 +349,7 @@ public void testReconcile(Params params, VertxTestContext context) {
             .compose(v -> operator.reconcile(new Reconciliation("test-trigger", Kafka.RESOURCE_KIND, NAMESPACE, CLUSTER_NAME)))
             .onComplete(context.succeeding(v -> async.flag()));
     }
-    
+
     @ParameterizedTest
     @MethodSource("data")
     public void testReconcileReplacesAllDeletedSecrets(Params params, VertxTestContext context) {

File: mockkube/src/main/java/io/strimzi/test/mockkube/CustomResourceMockBuilder.java
Patch:
@@ -9,12 +9,13 @@
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.client.Watcher;
 import io.fabric8.kubernetes.client.dsl.Resource;
+import io.strimzi.api.kafka.model.status.Status;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
 import java.util.function.Function;
 
-class CustomResourceMockBuilder<T extends CustomResource, L extends KubernetesResource & KubernetesResourceList<T>, S>
+class CustomResourceMockBuilder<T extends CustomResource, L extends KubernetesResource & KubernetesResourceList<T>, S extends Status>
         extends MockBuilder<T, L, Resource<T>> {
 
     private static final Logger LOGGER = LogManager.getLogger(CustomResourceMockBuilder.class);

File: operator-common/src/main/java/io/strimzi/operator/common/Operator.java
Patch:
@@ -51,6 +51,7 @@ public interface Operator {
      */
     default void reconcileAll(String trigger, String namespace, Handler<AsyncResult<Void>> handler) {
         allResourceNames(namespace).onComplete(ar -> {
+            getPausedResourceCounter().set(0);
             if (ar.succeeded()) {
                 reconcileThese(trigger, ar.result(), handler);
                 getPeriodicReconciliationsCounter().increment();
@@ -96,4 +97,6 @@ default Optional<LabelSelector> selector() {
     Counter getPeriodicReconciliationsCounter();
 
     AtomicInteger getResourceCounter();
+
+    AtomicInteger getPausedResourceCounter();
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -109,7 +109,7 @@ public Future<T> updateStatusAsync(T resource) {
 
             try {
                 T result = operation().inNamespace(namespace).withName(name).updateStatus(resource);
-                log.debug("Status of {} {} in namespace {} has been updated", resourceKind, name, namespace);
+                log.info("Status of {} {} in namespace {} has been updated", resourceKind, name, namespace);
                 future.complete(result);
             } catch (Exception e) {
                 log.debug("Caught exception while updating status of {} {} in namespace {}", resourceKind, name, namespace, e);

File: api-conversion/src/main/java/io/strimzi/kafka/api/conversion/converter/KafkaConverter.java
Patch:
@@ -71,7 +71,7 @@ public Conversion.InvertibleFunction<ArrayOrObjectKafkaListeners> inverse() {
         Conversion.replaceLogging("/spec/zookeeper/logging", "log4j.properties"),
         Conversion.replaceLogging("/spec/entityOperator/topicOperator/logging", "log4j2.properties"),
         Conversion.replaceLogging("/spec/entityOperator/userOperator/logging", "log4j2.properties"),
-        Conversion.replaceLogging("/spec/cruiseControl/logging", "log4j.properties"),
+        Conversion.replaceLogging("/spec/cruiseControl/logging", "log4j2.properties"),
         new MetricsConversion<>("/spec/kafka", KafkaClusterSpec.class, "kafka"),
         new MetricsConversion<>("/spec/zookeeper", ZookeeperClusterSpec.class, "zookeeper"),
         new MetricsConversion<>("/spec/cruiseControl", CruiseControlSpec.class, "cruise-control")

File: api/src/main/java/io/strimzi/api/kafka/model/CruiseControlSpec.java
Patch:
@@ -128,7 +128,7 @@ public void setMetricsConfig(MetricsConfig metricsConfig) {
         this.metricsConfig = metricsConfig;
     }
 
-    @Description("Logging configuration (log4j1) for Cruise Control.")
+    @Description("Logging configuration (Log4j 2) for Cruise Control.")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public Logging getLogging() {
         return logging;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControlConfiguration.java
Patch:
@@ -28,6 +28,7 @@ public class CruiseControlConfiguration extends AbstractConfiguration {
     protected static final List<String> CRUISE_CONTROL_GOALS_LIST = Collections.unmodifiableList(
         Arrays.asList(
                 CruiseControlGoals.RACK_AWARENESS_GOAL.toString(),
+                CruiseControlGoals.MIN_TOPIC_LEADERS_PER_BROKER_GOAL.toString(),
                 CruiseControlGoals.REPLICA_CAPACITY_GOAL.toString(),
                 CruiseControlGoals.DISK_CAPACITY_GOAL.toString(),
                 CruiseControlGoals.NETWORK_INBOUND_CAPACITY_GOAL.toString(),
@@ -68,6 +69,7 @@ public class CruiseControlConfiguration extends AbstractConfiguration {
     protected static final List<String> CRUISE_CONTROL_DEFAULT_ANOMALY_DETECTION_GOALS_LIST = Collections.unmodifiableList(
         Arrays.asList(
                 CruiseControlGoals.RACK_AWARENESS_GOAL.toString(),
+                CruiseControlGoals.MIN_TOPIC_LEADERS_PER_BROKER_GOAL.toString(),
                 CruiseControlGoals.REPLICA_CAPACITY_GOAL.toString(),
                 CruiseControlGoals.DISK_CAPACITY_GOAL.toString()
         )

File: operator-common/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlGoals.java
Patch:
@@ -7,6 +7,7 @@
 public enum CruiseControlGoals {
 
     RACK_AWARENESS_GOAL("com.linkedin.kafka.cruisecontrol.analyzer.goals.RackAwareGoal"),
+    MIN_TOPIC_LEADERS_PER_BROKER_GOAL("com.linkedin.kafka.cruisecontrol.analyzer.goals.MinTopicLeadersPerBrokerGoal"),
     REPLICA_CAPACITY_GOAL("com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal"),
     DISK_CAPACITY_GOAL("com.linkedin.kafka.cruisecontrol.analyzer.goals.DiskCapacityGoal"),
     NETWORK_INBOUND_CAPACITY_GOAL("com.linkedin.kafka.cruisecontrol.analyzer.goals.NetworkInboundCapacityGoal"),

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperator.java
Patch:
@@ -436,6 +436,7 @@ private KafkaRebalanceStatus buildRebalanceStatusFromPreviousStatus(KafkaRebalan
 
         return new KafkaRebalanceStatusBuilder()
                 .withSessionId(currentStatus.getSessionId())
+                .withOptimizationResult(currentStatus.getOptimizationResult())
                 .withConditions(conditions)
                 .build();
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -504,7 +504,7 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {
                     return createLog4jProperties(getDefaultLogConfig());
                 }
             } else {
-                if (externalCm.getData().containsKey(((ExternalLogging) logging).getValueFrom().getConfigMapKeyRef().getKey())) {
+                if (externalCm != null && externalCm.getData() != null && externalCm.getData().containsKey(((ExternalLogging) logging).getValueFrom().getConfigMapKeyRef().getKey())) {
                     return maybeAddMonitorIntervalToExternalLogging(externalCm.getData().get(((ExternalLogging) logging).getValueFrom().getConfigMapKeyRef().getKey()));
                 } else {
                     log.warn("ConfigMap {} with external logging configuration does not exist or doesn't contain the configuration under the {} key. Default logging settings are used.",

File: api/src/main/java/io/strimzi/api/kafka/model/AbstractKafkaConnectSpec.java
Patch:
@@ -62,9 +62,9 @@ public Integer getReplicas() {
     }
 
     @Description("Logging configuration for Kafka Connect")
-    @JsonInclude(value = JsonInclude.Include.NON_NULL)
+    @JsonInclude(value = JsonInclude.Include.NON_EMPTY)
     public Logging getLogging() {
-        return logging == null ? new InlineLogging() : logging;
+        return logging;
     }
 
     public void setLogging(Logging logging) {
@@ -116,7 +116,7 @@ public void setLivenessProbe(Probe livenessProbe) {
         this.livenessProbe = livenessProbe;
     }
 
-    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
+    @JsonInclude(JsonInclude.Include.NON_EMPTY)
     @Description("Pod readiness checking.")
     public Probe getReadinessProbe() {
         return readinessProbe;

File: api/src/main/java/io/strimzi/api/kafka/model/AclRule.java
Patch:
@@ -24,7 +24,7 @@
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
-@JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonInclude(JsonInclude.Include.NON_DEFAULT)
 @EqualsAndHashCode
 public class AclRule implements UnknownPropertyPreserving, Serializable {
 
@@ -51,7 +51,7 @@ public AclRule(AclRuleType type, AclRuleResource resource, String host, AclOpera
             "ACL rules with type `allow` are used to allow user to execute the specified operations. " +
             "Default value is `allow`.")
     @DefaultValue("allow")
-    @JsonInclude(value = JsonInclude.Include.NON_NULL)
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public AclRuleType getType() {
         return type;
     }
@@ -72,7 +72,7 @@ public void setResource(AclRuleResource resource) {
 
     @Description("The host from which the action described in the ACL rule is allowed or denied.")
     @DefaultValue("*")
-    @JsonInclude(value = JsonInclude.Include.NON_NULL)
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public String getHost() {
         return host;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleGroupResource.java
Patch:
@@ -18,7 +18,7 @@
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
-@JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonInclude(JsonInclude.Include.NON_DEFAULT)
 @JsonPropertyOrder({"type", "name", "patternType"})
 @EqualsAndHashCode
 public class AclRuleGroupResource extends AclRuleResource {
@@ -30,6 +30,7 @@ public class AclRuleGroupResource extends AclRuleResource {
     private AclResourcePatternType patternType = AclResourcePatternType.LITERAL;
 
     @Description("Must be `" + TYPE_GROUP + "`")
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     @Override
     public String getType() {
         return TYPE_GROUP;
@@ -41,7 +42,7 @@ public String getType() {
             "With `prefix` pattern type, the resource name will be used only as a prefix. " +
             "Default value is `literal`.")
     @DefaultValue("literal")
-    @JsonInclude(value = JsonInclude.Include.NON_NULL)
+    @JsonInclude(value = JsonInclude.Include.NON_DEFAULT)
     public AclResourcePatternType getPatternType() {
         return patternType;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleTransactionalIdResource.java
Patch:
@@ -18,7 +18,7 @@
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
-@JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonInclude(JsonInclude.Include.NON_DEFAULT)
 @JsonPropertyOrder({"type", "name", "patternType"})
 @EqualsAndHashCode
 public class AclRuleTransactionalIdResource extends AclRuleResource {
@@ -52,7 +52,7 @@ public void setName(String name) {
             "With `prefix` pattern type, the resource name will be used only as a prefix. " +
             "Default value is `literal`.")
     @DefaultValue("literal")
-    @JsonInclude(value = JsonInclude.Include.NON_NULL)
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public AclResourcePatternType getPatternType() {
         return patternType;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/CertificateAuthority.java
Patch:
@@ -22,7 +22,7 @@
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
-@JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonInclude(JsonInclude.Include.NON_DEFAULT)
 @JsonPropertyOrder({ "generateCertificateAuthority", "generateSecretOwnerReference", "validityDays", "renewalDays" })
 @EqualsAndHashCode
 public class CertificateAuthority implements UnknownPropertyPreserving, Serializable {
@@ -52,6 +52,7 @@ public void setValidityDays(int validityDays) {
     @Description("If true then Certificate Authority certificates will be generated automatically. " +
             "Otherwise the user will need to provide a Secret with the CA certificate. " +
             "Default is true.")
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public boolean isGenerateCertificateAuthority() {
         return generateCertificateAuthority;
     }
@@ -65,6 +66,7 @@ public void setGenerateCertificateAuthority(boolean generateCertificateAuthority
             "If `false`, the `ownerReference` is disabled. " +
             "If the `Kafka` resource is deleted when `false`, the CA Secrets are retained and available for reuse. " +
             "Default is `true`.")
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public boolean isGenerateSecretOwnerReference() {
         return generateSecretOwnerReference;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/EntityOperatorSpec.java
Patch:
@@ -31,7 +31,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({
         "topicOperator", "userOperator", "affinity",
-        "tolerations", "tlsSidecar"})
+        "tolerations", "tlsSidecar", "template"})
 @EqualsAndHashCode
 public class EntityOperatorSpec implements UnknownPropertyPreserving, Serializable {
 

File: api/src/main/java/io/strimzi/api/kafka/model/EntityUserOperatorSpec.java
Patch:
@@ -26,7 +26,7 @@
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
-@JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonInclude(JsonInclude.Include.NON_DEFAULT)
 @JsonPropertyOrder({"watchedNamespace", "image",
         "reconciliationIntervalSeconds", "zookeeperSessionTimeoutSeconds",
         "secretPrefix", "livenessProbe", "readinessProbe",
@@ -76,6 +76,7 @@ public void setImage(String image) {
 
     @Description("Interval between periodic reconciliations.")
     @Minimum(0)
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public long getReconciliationIntervalSeconds() {
         return reconciliationIntervalSeconds;
     }
@@ -86,6 +87,7 @@ public void setReconciliationIntervalSeconds(long reconciliationIntervalSeconds)
 
     @Description("Timeout for the ZooKeeper session")
     @Minimum(0)
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public long getZookeeperSessionTimeoutSeconds() {
         return zookeeperSessionTimeoutSeconds;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/JvmOptions.java
Patch:
@@ -59,6 +59,7 @@ public void setXms(String xms) {
     }
 
     @Description("Specifies whether the Garbage Collection logging is enabled. The default is false.")
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public boolean isGcLoggingEnabled() {
         return gcLoggingEnabled;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -109,7 +109,7 @@ public class Kafka extends CustomResource<KafkaSpec, KafkaStatus> implements Nam
     public static final List<String> RESOURCE_SHORTNAMES = unmodifiableList(singletonList(SHORT_NAME));
 
     private String apiVersion;
-    private ObjectMeta metadata;
+    private ObjectMeta metadata; // leave it for the generator / builder
     private KafkaSpec spec;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
     private KafkaStatus status;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -37,8 +37,8 @@
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({
-        "replicas", "image", "storage",
-        "listeners", "authorization", "config",
+        "version", "replicas", "image", "listeners",
+        "config", "storage", "authorization",
         "rack", "brokerRackInitImage",
         "affinity", "tolerations",
         "livenessProbe", "readinessProbe",

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java
Patch:
@@ -23,7 +23,7 @@
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({ "replicas", "version", "image",
+@JsonPropertyOrder({ "version", "replicas", "image",
         "bootstrapServers", "tls", "authentication", "config", "resources",
         "livenessProbe", "readinessProbe", "jvmOptions", "jmxOptions",
         "affinity", "tolerations", "logging", "metrics", "tracing",

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2ClusterSpec.java
Patch:
@@ -27,7 +27,7 @@
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({ "alias", "bootstrapServers", "config", "tls", "authentication"})
+@JsonPropertyOrder({ "alias", "bootstrapServers", "tls", "authentication", "config"})
 @EqualsAndHashCode
 public class KafkaMirrorMaker2ClusterSpec implements UnknownPropertyPreserving, Serializable {
 
@@ -64,8 +64,8 @@ public void setAuthentication(KafkaClientAuthentication authentication) {
         this.authentication = authentication;
     }
 
-
     @Description("The MirrorMaker 2.0 cluster config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
+    @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public Map<String, Object> getConfig() {
         return config;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2MirrorSpec.java
Patch:
@@ -23,7 +23,7 @@
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({"sourceCluster", "targetCluster", "sourceConnector", "checkpointConnector", "heartbeatConnector", "topicsPattern", "topicsBlacklistPattern", "groupsPattern", "groupsBlacklistPattern"})
+@JsonPropertyOrder({"sourceCluster", "targetCluster", "sourceConnector", "heartbeatConnector", "checkpointConnector", "topicsPattern", "topicsBlacklistPattern", "groupsPattern", "groupsBlacklistPattern"})
 @EqualsAndHashCode
 public class KafkaMirrorMaker2MirrorSpec implements Serializable, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2Spec.java
Patch:
@@ -19,7 +19,7 @@
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({"replicas", "version", "image", "connectCluster", 
+@JsonPropertyOrder({"version", "replicas", "image", "connectCluster",
         "clusters", "mirrors", "resources", 
         "livenessProbe", "readinessProbe", "jvmOptions", "jmxOptions",
         "affinity", "tolerations", "logging", "metrics", "tracing", 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerClientSpec.java
Patch:
@@ -43,6 +43,7 @@ public void setAuthentication(KafkaClientAuthentication authentication) {
         this.authentication = authentication;
     }
 
+    @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public Map<String, Object> getConfig() {
         return config;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerConsumerSpec.java
Patch:
@@ -22,7 +22,7 @@
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({"numStreams", "offsetCommitInterval", "groupId", "bootstrapServers", "logging"})
+@JsonPropertyOrder({"numStreams", "offsetCommitInterval", "bootstrapServers", "groupId", "logging"})
 @EqualsAndHashCode(callSuper = true)
 public class KafkaMirrorMakerConsumerSpec extends KafkaMirrorMakerClientSpec {
     private static final long serialVersionUID = 1L;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -31,8 +31,8 @@
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({
-        "replicas", "image", "whitelist",
-        "consumer", "producer", "resources",
+        "version", "replicas", "image", "consumer",
+        "producer", "resources", "whitelist",
         "affinity", "tolerations", "jvmOptions",
         "logging", "metrics", "metricsConfig", "tracing", "template"})
 @EqualsAndHashCode

File: api/src/main/java/io/strimzi/api/kafka/model/Probe.java
Patch:
@@ -22,7 +22,7 @@
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
-@JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonInclude(JsonInclude.Include.NON_DEFAULT)
 @EqualsAndHashCode
 public class Probe implements UnknownPropertyPreserving, Serializable {
 
@@ -46,6 +46,7 @@ public Probe(int initialDelaySeconds, int timeoutSeconds) {
     @Description("The initial delay before first the health is first checked. Default to 15 seconds. Minimum value is 0.")
     @Minimum(0)
     @DefaultValue("15")
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public int getInitialDelaySeconds() {
         return initialDelaySeconds;
     }
@@ -57,6 +58,7 @@ public void setInitialDelaySeconds(int initialDelaySeconds) {
     @Description("The timeout for each attempted health check. Default to 5 seconds. Minimum value is 1.")
     @Minimum(1)
     @DefaultValue("5")
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public int getTimeoutSeconds() {
         return timeoutSeconds;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/TlsSidecar.java
Patch:
@@ -22,7 +22,7 @@
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
-@JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonInclude(JsonInclude.Include.NON_DEFAULT)
 @EqualsAndHashCode(callSuper = true)
 public class TlsSidecar extends Sidecar {
     private static final long serialVersionUID = 1L;
@@ -38,7 +38,7 @@ public class TlsSidecar extends Sidecar {
     @Description("The log level for the TLS sidecar. " +
             "Default value is `notice`.")
     @DefaultValue("notice")
-    @JsonInclude(value = JsonInclude.Include.NON_NULL)
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public TlsSidecarLogLevel getLogLevel() {
         return logLevel;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/storage/PersistentClaimStorage.java
Patch:
@@ -24,7 +24,7 @@
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
 @JsonPropertyOrder({"type", "size", "storageClass", "selector", "deleteClaim"})
-@JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonInclude(JsonInclude.Include.NON_DEFAULT)
 @EqualsAndHashCode
 public class PersistentClaimStorage extends SingleVolumeStorage {
 
@@ -40,6 +40,7 @@ public class PersistentClaimStorage extends SingleVolumeStorage {
 
     @Description("Must be `" + TYPE_PERSISTENT_CLAIM + "`")
     @Override
+    @JsonInclude(JsonInclude.Include.NON_NULL)
     public String getType() {
         return TYPE_PERSISTENT_CLAIM;
     }
@@ -89,6 +90,7 @@ public void setSelector(Map<String, String> selector) {
 
     @Description("Specifies if the persistent volume claim has to be deleted when the cluster is un-deployed.")
     @JsonProperty(defaultValue = "false")
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public boolean isDeleteClaim() {
         return deleteClaim;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/template/PodTemplate.java
Patch:
@@ -34,7 +34,7 @@
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
-@JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonInclude(JsonInclude.Include.NON_DEFAULT)
 @JsonPropertyOrder({"metadata", "imagePullSecrets", "securityContext", "terminationGracePeriodSeconds", "affinity",
         "tolerations", "topologySpreadConstraint", "priorityClassName", "schedulerName", "hostAliases"})
 @EqualsAndHashCode
@@ -93,7 +93,7 @@ public void setImagePullSecrets(List<LocalObjectReference> imagePullSecrets) {
             "A zero value indicates delete immediately. " +
             "You might need to increase the grace period for very large Kafka clusters, so that the Kafka brokers have enough time to transfer their work to another broker before they are terminated. " +
             "Defaults to 30 seconds.")
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
+    @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     @DefaultValue("30")
     @Minimum(0)
     public int getTerminationGracePeriodSeconds() {

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -27,6 +27,7 @@ public interface Constants {
 
     long TIMEOUT_TEARDOWN = Duration.ofSeconds(10).toMillis();
     long GLOBAL_TIMEOUT = Duration.ofMinutes(5).toMillis();
+    long GLOBAL_CMD_CLIENT_TIMEOUT = Duration.ofMinutes(5).toMillis();
     long GLOBAL_STATUS_TIMEOUT = Duration.ofMinutes(3).toMillis();
     long GLOBAL_POLL_INTERVAL = Duration.ofSeconds(1).toMillis();
     long GLOBAL_POLL_INTERVAL_MEDIUM = Duration.ofSeconds(10).toMillis();
@@ -41,7 +42,6 @@ public interface Constants {
     long OLM_UPGRADE_INSTALL_PLAN_TIMEOUT = Duration.ofMinutes(15).toMillis();
     long OLM_UPGRADE_INSTALL_PLAN_POLL = Duration.ofMinutes(1).toMillis();
 
-
     long GLOBAL_CLIENTS_POLL = Duration.ofSeconds(15).toMillis();
     long GLOBAL_CLIENTS_TIMEOUT = Duration.ofMinutes(2).toMillis();
     long HUGE_CLIENTS_TIMEOUT = Duration.ofMinutes(30).toMillis();
@@ -53,7 +53,7 @@ public interface Constants {
     long RECONCILIATION_INTERVAL = Duration.ofSeconds(30).toMillis();
     long LOGGING_RELOADING_INTERVAL = Duration.ofSeconds(30).toMillis();
 
-    // Heycloak
+    // Keycloak
     long KEYCLOAK_DEPLOYMENT_POLL = Duration.ofSeconds(5).toMillis();
     long KEYCLOAK_DEPLOYMENT_TIMEOUT = Duration.ofMinutes(10).toMillis();
 

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -127,7 +127,7 @@ public class Environment {
     public static final String OPERATOR_IMAGE_PULL_POLICY_ENV_DEFAULT = Constants.ALWAYS_IMAGE_PULL_POLICY;
     public static final String OLM_OPERATOR_NAME_DEFAULT = "strimzi-kafka-operator";
     public static final String OLM_OPERATOR_DEPLOYMENT_NAME_DEFAULT = Constants.STRIMZI_DEPLOYMENT_NAME;
-    public static final String OLM_SOURCE_NAME_DEFAULT = "strimzi-source";
+    public static final String OLM_SOURCE_NAME_DEFAULT = "community-operators";
     public static final String OLM_APP_BUNDLE_PREFIX_DEFAULT = "strimzi-cluster-operator";
     public static final String OLM_OPERATOR_VERSION_DEFAULT = "0.21.1";
     private static final boolean DEFAULT_TO_DENY_NETWORK_POLICIES_DEFAULT = true;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/TestKafkaVersion.java
Patch:
@@ -99,7 +99,7 @@ public int compareTo(TestKafkaVersion o) {
      * -1 if version1 &lt; version2;
      * 1 if version1 &gt; version2.
      */
-    public int compareDottedVersions(String version1, String version2) {
+    public static int compareDottedVersions(String version1, String version2) {
         String[] components = version1.split("\\.");
         String[] otherComponents = version2.split("\\.");
         for (int i = 0; i < Math.min(components.length, otherComponents.length); i++) {

File: api/src/main/java/io/strimzi/api/kafka/model/CruiseControlSpec.java
Patch:
@@ -100,7 +100,7 @@ public void setConfig(Map<String, Object> config) {
         this.config = config;
     }
 
-    @DeprecatedProperty(movedToPath = "spec.cruiseControl.metricsConfig")
+    @DeprecatedProperty(movedToPath = "spec.cruiseControl.metricsConfig", removalVersion = "v1beta2")
     @PresentInVersions("v1alpha1-v1beta1")
     @Deprecated
     @JsonInclude(JsonInclude.Include.NON_EMPTY)

File: api/src/main/java/io/strimzi/api/kafka/model/ExternalLogging.java
Patch:
@@ -37,7 +37,7 @@ public String getType() {
     }
 
     @Description("The name of the `ConfigMap` from which to get the logging configuration.")
-    @DeprecatedProperty(description = "Replaced with valueFrom", removalVersion = "v1beta2")
+    @DeprecatedProperty(movedToPath = "valueFrom", removalVersion = "v1beta2")
     @Deprecated
     @PresentInVersions("v1alpha1-v1beta1")
     public String getName() {

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -86,15 +86,15 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
-@Version(Constants.V1BETA1)
+@Version(Constants.V1BETA2)
 @Group(Constants.STRIMZI_GROUP)
 public class Kafka extends CustomResource<KafkaSpec, KafkaStatus> implements Namespaced, UnknownPropertyPreserving {
 
     public static final String V1BETA2 = Constants.V1BETA2;
     public static final String V1BETA1 = Constants.V1BETA1;
     public static final String V1ALPHA1 = Constants.V1ALPHA1;
-    public static final List<String> VERSIONS = unmodifiableList(asList(V1BETA2, V1BETA1, V1ALPHA1));
     public static final String CONSUMED_VERSION = V1BETA1;
+    public static final List<String> VERSIONS = unmodifiableList(asList(V1BETA2, V1BETA1, V1ALPHA1));
     private static final long serialVersionUID = 1L;
 
     public static final String SCOPE = "Namespaced";

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaSpec.java
Patch:
@@ -67,7 +67,8 @@ public void setZookeeper(ZookeeperClusterSpec zookeeper) {
     @PresentInVersions("v1alpha1-v1beta1")
     @Deprecated
     @DeprecatedProperty(
-            movedToPath = "spec.entityOperator.topicOperator"
+            movedToPath = "spec.entityOperator.topicOperator",
+            removalVersion = "v1beta2"
     )
     @Description("Configuration of the Topic Operator")
     public TopicOperatorSpec getTopicOperator() {

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListeners.java
Patch:
@@ -30,7 +30,7 @@
 @JsonPropertyOrder({"plain", "tls", "external"})
 @EqualsAndHashCode
 @Deprecated
-@DeprecatedType(replacedWithType = io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener.class)
+@DeprecatedType(replacedWithType = io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener.class, removalVersion = "v1beta2")
 @Description("Refer to link:{BookURLUsingPrevious}[previous documentation] for example configuration.")
 public class KafkaListeners implements UnknownPropertyPreserving, Serializable {
     private static final long serialVersionUID = 1L;

File: api/src/main/java/io/strimzi/api/kafka/model/template/KafkaClusterTemplate.java
Patch:
@@ -184,7 +184,7 @@ public void setKafkaContainer(ContainerTemplate kafkaContainer) {
     }
 
     @PresentInVersions("v1alpha1-v1beta1")
-    @DeprecatedProperty
+    @DeprecatedProperty(removalVersion = "v1beta2")
     @Deprecated
     @Description("Template for the Kafka broker TLS sidecar container")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)

File: api/src/main/java/io/strimzi/api/kafka/model/template/ZookeeperClusterTemplate.java
Patch:
@@ -114,7 +114,7 @@ public void setZookeeperContainer(ContainerTemplate zookeeperContainer) {
     }
 
     @PresentInVersions("v1alpha1-v1beta1")
-    @DeprecatedProperty
+    @DeprecatedProperty(removalVersion = "v1beta2")
     @Deprecated
     @Description("Template for the Zookeeper server TLS sidecar container. " +
             "The TLS sidecar is not used anymore and this option will be ignored.")

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaBridgeCrdOperatorIT.java
Patch:
@@ -50,7 +50,6 @@ protected String getNamespace() {
     @Override
     protected KafkaBridge getResource(String resourceName) {
         return new KafkaBridgeBuilder()
-                .withApiVersion(KafkaBridge.RESOURCE_GROUP + "/" + KafkaBridge.V1ALPHA1)
                 .withNewMetadata()
                 .withName(resourceName)
                 .withNamespace(getNamespace())

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectCrdOperatorIT.java
Patch:
@@ -47,7 +47,6 @@ protected String getNamespace() {
     @Override
     protected KafkaConnect getResource(String resourceName) {
         return new KafkaConnectBuilder()
-                .withApiVersion(KafkaConnect.RESOURCE_GROUP + "/" + KafkaConnect.V1BETA1)
                 .withNewMetadata()
                     .withName(resourceName)
                     .withNamespace(getNamespace())

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectS2ICrdOperatorIT.java
Patch:
@@ -48,7 +48,6 @@ protected String getNamespace() {
     @Override
     protected KafkaConnectS2I getResource(String resourceName) {
         return new KafkaConnectS2IBuilder()
-                .withApiVersion(KafkaConnectS2I.RESOURCE_GROUP + "/" + KafkaConnectS2I.V1BETA1)
                 .withNewMetadata()
                 .withName(resourceName)
                 .withNamespace(getNamespace())

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectorCrdOperatorIT.java
Patch:
@@ -47,7 +47,6 @@ protected String getNamespace() {
     @Override
     protected KafkaConnector getResource(String resourceName) {
         return new KafkaConnectorBuilder()
-                .withApiVersion(KafkaConnector.RESOURCE_GROUP + "/" + KafkaConnector.V1ALPHA1)
                 .withNewMetadata()
                     .withName(resourceName)
                     .withNamespace(getNamespace())

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorIT.java
Patch:
@@ -49,7 +49,6 @@ protected String getNamespace() {
     @Override
     protected Kafka getResource(String resourceName) {
         return new KafkaBuilder()
-                .withApiVersion(Kafka.RESOURCE_GROUP + "/" + Kafka.V1BETA1)
                 .withNewMetadata()
                     .withName(resourceName)
                     .withNamespace(getNamespace())

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaMirrorMaker2CrdOperatorIT.java
Patch:
@@ -47,7 +47,6 @@ protected String getNamespace() {
     @Override
     protected KafkaMirrorMaker2 getResource(String resourceName) {
         return new KafkaMirrorMaker2Builder()
-                .withApiVersion(KafkaMirrorMaker2.RESOURCE_GROUP + "/" + KafkaMirrorMaker2.V1ALPHA1)
                 .withNewMetadata()
                     .withName(resourceName)
                     .withNamespace(getNamespace())

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaMirrorMakerCrdOperatorIT.java
Patch:
@@ -48,7 +48,6 @@ protected String getNamespace() {
     @Override
     protected KafkaMirrorMaker getResource(String resourceName) {
         return new KafkaMirrorMakerBuilder()
-                .withApiVersion(KafkaMirrorMaker.RESOURCE_GROUP + "/" + KafkaMirrorMaker.V1BETA1)
                 .withNewMetadata()
                     .withName(resourceName)
                     .withNamespace(getNamespace())

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaUserCrdOperatorIT.java
Patch:
@@ -47,7 +47,6 @@ protected String getNamespace() {
     @Override
     protected KafkaUser getResource(String resourceName) {
         return new KafkaUserBuilder()
-                .withApiVersion(KafkaUser.RESOURCE_GROUP + "/" + KafkaUser.V1BETA1)
                 .withNewMetadata()
                     .withName(resourceName)
                     .withNamespace(getNamespace())

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -29,7 +29,7 @@ public class KafkaBridgeResource {
     public static final String PATH_TO_KAFKA_BRIDGE_METRICS_CONFIG = TestUtils.USER_PATH + "/../examples/metrics/kafka-bridge-metrics.yaml";
 
     public static MixedOperation<KafkaBridge, KafkaBridgeList, Resource<KafkaBridge>> kafkaBridgeClient() {
-        return Crds.kafkaBridgeOperation(ResourceManager.kubeClient().getClient());
+        return Crds.kafkaBridgeV1Beta2Operation(ResourceManager.kubeClient().getClient());
     }
 
     public static KafkaBridgeBuilder kafkaBridge(String name, String bootstrap, int kafkaBridgeReplicas) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -33,7 +33,7 @@ public class KafkaConnectResource {
     public static final String PATH_TO_KAFKA_CONNECT_CONFIG = TestUtils.USER_PATH + "/../examples/connect/kafka-connect.yaml";
 
     public static MixedOperation<KafkaConnect, KafkaConnectList, Resource<KafkaConnect>> kafkaConnectClient() {
-        return Crds.kafkaConnectOperation(ResourceManager.kubeClient().getClient());
+        return Crds.kafkaConnectV1Beta2Operation(ResourceManager.kubeClient().getClient());
     }
 
     public static KafkaConnectBuilder kafkaConnect(String name, int kafkaConnectReplicas) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -31,7 +31,7 @@
 public class KafkaConnectS2IResource {
 
     public static MixedOperation<KafkaConnectS2I, KafkaConnectS2IList, Resource<KafkaConnectS2I>> kafkaConnectS2IClient() {
-        return Crds.kafkaConnectS2iOperation(ResourceManager.kubeClient().getClient());
+        return Crds.kafkaConnectS2iV1Beta2Operation(ResourceManager.kubeClient().getClient());
     }
 
     public static KafkaConnectS2IBuilder kafkaConnectS2I(String name, String clusterName, int kafkaConnectS2IReplicas) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -26,7 +26,7 @@ public class KafkaConnectorResource {
     public static final String PATH_TO_KAFKA_CONNECTOR_CONFIG = TestUtils.USER_PATH + "/../examples/connect/source-connector.yaml";
 
     public static MixedOperation<KafkaConnector, KafkaConnectorList, Resource<KafkaConnector>> kafkaConnectorClient() {
-        return Crds.kafkaConnectorOperation(ResourceManager.kubeClient().getClient());
+        return Crds.kafkaConnectorV1Beta2Operation(ResourceManager.kubeClient().getClient());
     }
 
     public static KafkaConnectorBuilder kafkaConnector(String name) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -33,7 +33,7 @@ public class KafkaMirrorMaker2Resource {
     public static final String PATH_TO_KAFKA_MIRROR_MAKER_2_CONFIG = TestUtils.USER_PATH + "/../examples/mirror-maker/kafka-mirror-maker-2.yaml";
 
     public static MixedOperation<KafkaMirrorMaker2, KafkaMirrorMaker2List, Resource<KafkaMirrorMaker2>> kafkaMirrorMaker2Client() {
-        return Crds.kafkaMirrorMaker2Operation(ResourceManager.kubeClient().getClient());
+        return Crds.kafkaMirrorMaker2V1Beta2Operation(ResourceManager.kubeClient().getClient());
     }
 
     public static KafkaMirrorMaker2Builder kafkaMirrorMaker2(String name, String targetClusterName, String sourceClusterName, int kafkaMirrorMaker2Replicas, boolean tlsListener) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -29,7 +29,7 @@ public class KafkaMirrorMakerResource {
     public static final String PATH_TO_KAFKA_MIRROR_MAKER_CONFIG = TestUtils.USER_PATH + "/../examples/mirror-maker/kafka-mirror-maker.yaml";
 
     public static MixedOperation<KafkaMirrorMaker, KafkaMirrorMakerList, Resource<KafkaMirrorMaker>> kafkaMirrorMakerClient() {
-        return Crds.mirrorMakerOperation(ResourceManager.kubeClient().getClient());
+        return Crds.mirrorMakerV1Beta2Operation(ResourceManager.kubeClient().getClient());
     }
 
     public static KafkaMirrorMakerBuilder kafkaMirrorMaker(String name, String sourceBootstrapServer, String targetBootstrapServer, String groupId, int mirrorMakerReplicas, boolean tlsListener) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaRebalanceResource.java
Patch:
@@ -28,7 +28,7 @@ public class KafkaRebalanceResource {
     public static final String PATH_TO_KAFKA_REBALANCE_CONFIG = TestUtils.USER_PATH + "/../examples/cruise-control/kafka-rebalance.yaml";
 
     public static MixedOperation<KafkaRebalance, KafkaRebalanceList, Resource<KafkaRebalance>> kafkaRebalanceClient() {
-        return Crds.kafkaRebalanceOperation(ResourceManager.kubeClient().getClient());
+        return Crds.kafkaRebalanceV1Beta2Operation(ResourceManager.kubeClient().getClient());
     }
 
     public static KafkaRebalanceBuilder kafkaRebalance(String name) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -46,7 +46,7 @@ public class KafkaResource {
     private static final String PATH_TO_KAFKA_PERSISTENT_CONFIG = TestUtils.USER_PATH + "/../examples/kafka/kafka-persistent.yaml";
 
     public static MixedOperation<Kafka, KafkaList, Resource<Kafka>> kafkaClient() {
-        return Crds.kafkaOperation(ResourceManager.kubeClient().getClient());
+        return Crds.kafkaV1Beta2Operation(ResourceManager.kubeClient().getClient());
     }
 
     public static KafkaBuilder kafkaEphemeral(String clusterName, int kafkaReplicas) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaTopicResource.java
Patch:
@@ -26,7 +26,7 @@ public class KafkaTopicResource {
     public static final String PATH_TO_KAFKA_TOPIC_CONFIG = TestUtils.USER_PATH + "/../examples/topic/kafka-topic.yaml";
 
     public static MixedOperation<KafkaTopic, KafkaTopicList, Resource<KafkaTopic>> kafkaTopicClient() {
-        return Crds.topicOperation(ResourceManager.kubeClient().getClient());
+        return Crds.topicV1Beta2Operation(ResourceManager.kubeClient().getClient());
     }
 
     public static KafkaTopicBuilder topic(String clusterName, String topicName) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaUserResource.java
Patch:
@@ -23,7 +23,7 @@ public class KafkaUserResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaUserResource.class);
 
     public static MixedOperation<KafkaUser, KafkaUserList, Resource<KafkaUser>> kafkaUserClient() {
-        return Crds.kafkaUserOperation(ResourceManager.kubeClient().getClient());
+        return Crds.kafkaUserV1Beta2Operation(ResourceManager.kubeClient().getClient());
     }
 
     public static KafkaUserBuilder tlsUser(String clusterName, String name) {

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -166,6 +166,7 @@ protected void installClusterOperator(String namespace) {
     public void applyClusterOperatorInstallFiles(String namespace) {
         clusterOperatorConfigs.clear();
         Map<File, String> operatorFiles = Arrays.stream(new File(CO_INSTALL_DIR).listFiles()).sorted()
+                .filter(File::isFile)
                 .filter(file ->
                         !file.getName().matches(".*(Binding|Deployment)-.*"))
                 .collect(Collectors.toMap(
@@ -174,14 +175,14 @@ public void applyClusterOperatorInstallFiles(String namespace) {
                     (x, y) -> x,
                     LinkedHashMap::new));
         for (Map.Entry<File, String> entry : operatorFiles.entrySet()) {
-            LOGGER.info("Applying configuration file: {}", entry.getKey());
+            LOGGER.info("Creating configuration file: {}", entry.getKey());
             String fileContents = entry.getValue();
             if (Environment.isNamespaceRbacScope()) {
                 fileContents = switchClusterRolesToRoles(fileContents);
 
             }
             clusterOperatorConfigs.push(entry.getKey().getPath());
-            cmdKubeClient().namespace(namespace).applyContent(fileContents);
+            cmdKubeClient().namespace(namespace).replaceContent(fileContents);
         }
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/AbstractUpgradeST.java
Patch:
@@ -234,11 +234,11 @@ protected void changeClusterOperator(JsonObject testParameters, String namespace
     protected void copyModifyApply(File root, String namespace) {
         Arrays.stream(Objects.requireNonNull(root.listFiles())).sorted().forEach(f -> {
             if (f.getName().matches(".*RoleBinding.*")) {
-                cmdKubeClient().applyContent(TestUtils.changeRoleBindingSubject(f, namespace));
+                cmdKubeClient().replaceContent(TestUtils.changeRoleBindingSubject(f, namespace));
             } else if (f.getName().matches(".*Deployment.*")) {
-                cmdKubeClient().applyContent(StUtils.changeDeploymentNamespace(f, namespace));
+                cmdKubeClient().replaceContent(StUtils.changeDeploymentNamespace(f, namespace));
             } else {
-                cmdKubeClient().apply(f);
+                cmdKubeClient().replaceContent(TestUtils.getContent(f, TestUtils::toYamlString));
             }
         });
     }

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicSerialization.java
Patch:
@@ -149,7 +149,7 @@ public static KafkaTopic toTopicResource(Topic topic, Labels labels) {
                     .build();
         }
 
-        KafkaTopic kt = new KafkaTopicBuilder().withApiVersion(KafkaTopic.RESOURCE_GROUP + "/" + KafkaTopic.V1BETA1)
+        KafkaTopic kt = new KafkaTopicBuilder()
                 .withMetadata(om)
                 // TODO .withUid()
                 .withNewSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationST.java
Patch:
@@ -255,7 +255,7 @@ void testSuperUserWithOauthAuthorization() {
             ((KafkaAuthorizationKeycloak) kafka.getSpec().getKafka().getAuthorization()).setSuperUsers(superUsers);
         });
 
-        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(oauthClusterName), 3, kafkaPods);
+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(oauthClusterName), 1, kafkaPods);
 
         LOGGER.info("Verifying that team B is able to write to topic starting with 'x-' and break authorization rule");
 
@@ -459,9 +459,10 @@ void testClusterVerification() {
 
     @BeforeAll
     void setUp()  {
+        setupCoAndKeycloak();
         keycloakInstance.setRealm(TEST_REALM, true);
 
-        KafkaResource.createAndWaitForReadiness(KafkaResource.kafkaEphemeral(oauthClusterName, 3)
+        KafkaResource.createAndWaitForReadiness(KafkaResource.kafkaEphemeral(oauthClusterName, 1, 1)
             .editSpec()
                 .editKafka()
                     .withNewListeners()

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -94,6 +94,7 @@ void testProducerConsumerConnect() {
 
         KafkaConnectResource.createAndWaitForReadiness(KafkaConnectResource.kafkaConnect(oauthClusterName, 1)
                 .editSpec()
+                    .withConfig(connectorConfig)
                     .addToConfig("key.converter.schemas.enable", false)
                     .addToConfig("value.converter.schemas.enable", false)
                     .addToConfig("key.converter", "org.apache.kafka.connect.storage.StringConverter")
@@ -394,6 +395,7 @@ void testIntrospectionEndpoint() {
 
     @BeforeAll
     void setUp() {
+        setupCoAndKeycloak();
         keycloakInstance.setRealm("internal", true);
 
         LOGGER.info("Keycloak settings {}", keycloakInstance.toString());
@@ -409,7 +411,7 @@ void setUp() {
             .withOAuthTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
             .build();
 
-        KafkaResource.createAndWaitForReadiness(KafkaResource.kafkaEphemeral(oauthClusterName, 3)
+        KafkaResource.createAndWaitForReadiness(KafkaResource.kafkaEphemeral(oauthClusterName, 1, 1)
             .editSpec()
                 .editKafka()
                     .withNewListeners()

File: test-container/src/main/java/io/strimzi/StrimziKafkaContainer.java
Patch:
@@ -65,7 +65,7 @@ public class StrimziKafkaContainer extends GenericContainer<StrimziKafkaContaine
     }
 
     public StrimziKafkaContainer(final String version) {
-        super("strimzi/kafka:" + version);
+        super("quay.io/strimzi/kafka:" + version);
         super.withNetwork(Network.SHARED);
 
         // exposing kafka port from the container

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -131,14 +131,14 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
                 new KafkaBridgeAssemblyOperator(vertx, pfa, certManager, passwordGenerator, resourceOperatorSupplier, config);
 
         KafkaRebalanceAssemblyOperator kafkaRebalanceAssemblyOperator =
-                new KafkaRebalanceAssemblyOperator(vertx, pfa, resourceOperatorSupplier);
+                new KafkaRebalanceAssemblyOperator(vertx, pfa, resourceOperatorSupplier, config);
 
         List<Future> futures = new ArrayList<>(config.getNamespaces().size());
         for (String namespace : config.getNamespaces()) {
             Promise<String> prom = Promise.promise();
             futures.add(prom.future());
             ClusterOperator operator = new ClusterOperator(namespace,
-                    config.getReconciliationIntervalMs(),
+                    config,
                     client,
                     kafkaClusterOperations,
                     kafkaConnectClusterOperations,
@@ -151,7 +151,7 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
             vertx.deployVerticle(operator,
                 res -> {
                     if (res.succeeded()) {
-                        log.info("Cluster Operator verticle started in namespace {}", namespace);
+                        log.info("Cluster Operator verticle started in namespace {} with label selector {}", namespace, config.getCustomResourceSelector());
                     } else {
                         log.error("Cluster Operator verticle in namespace {} failed to start", namespace, res.cause());
                         System.exit(1);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -75,7 +75,7 @@ protected AbstractAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability pfa
                                        AbstractWatchableStatusedResourceOperator<C, T, L, R> resourceOperator,
                                        ResourceOperatorSupplier supplier,
                                        ClusterOperatorConfig config) {
-        super(vertx, kind, resourceOperator, supplier.metricsProvider);
+        super(vertx, kind, resourceOperator, supplier.metricsProvider, config.getCustomResourceSelector());
         this.pfa = pfa;
         this.certManager = certManager;
         this.passwordGenerator = passwordGenerator;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -182,7 +182,7 @@ public void setup(VertxTestContext testContext) {
                 return kafkaConnectS2iOperator.createWatch(NAMESPACE, e -> testContext.failNow(e));
             })
             .onComplete(testContext.succeeding())
-            .compose(watch -> AbstractConnectOperator.createConnectorWatch(kafkaConnectOperator, kafkaConnectS2iOperator, NAMESPACE))
+            .compose(watch -> AbstractConnectOperator.createConnectorWatch(kafkaConnectOperator, kafkaConnectS2iOperator, NAMESPACE, null))
             .onComplete(testContext.succeeding(v -> async.flag()));
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalIngress.java
Patch:
@@ -80,8 +80,7 @@ public void setConfiguration(IngressListenerConfiguration configuration) {
         this.configuration = configuration;
     }
 
-    @Description("Configures the `Ingress` class that defines which `Ingress` controller will be used. " +
-            "If not set, the `Ingress` class is set to `nginx`.")
+    @Description("Configures the `Ingress` class that defines which `Ingress` controller will be used.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     @JsonProperty("class")
     public String getIngressClass() {

File: api/src/main/java/io/strimzi/api/kafka/model/listener/arraylistener/GenericKafkaListenerConfiguration.java
Patch:
@@ -62,8 +62,8 @@ public void setBrokerCertChainAndKey(CertAndKeySecretSource brokerCertChainAndKe
     }
 
     @Description("Configures the `Ingress` class that defines which `Ingress` controller will be used. " +
-            "If not set, the `Ingress` class is set to `nginx`. " +
-            "This field can be used only with `ingress` type listener.")
+            "This field can be used only with `ingress` type listener. " +
+            "If not specified, the default Ingress controller will be used.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     @JsonProperty("class")
     public String getIngressClass() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -80,6 +80,7 @@
 import io.strimzi.operator.common.operator.resource.DeploymentOperator;
 import io.strimzi.operator.common.operator.resource.ImageStreamOperator;
 import io.strimzi.operator.common.operator.resource.IngressOperator;
+import io.strimzi.operator.common.operator.resource.IngressV1Beta1Operator;
 import io.strimzi.operator.common.operator.resource.NetworkPolicyOperator;
 import io.strimzi.operator.common.operator.resource.NodeOperator;
 import io.strimzi.operator.common.operator.resource.PodDisruptionBudgetOperator;
@@ -751,6 +752,7 @@ public static ResourceOperatorSupplier supplierWithMocks(boolean openShift) {
                 mock(PodDisruptionBudgetOperator.class),
                 mock(PodOperator.class),
                 mock(IngressOperator.class),
+                mock(IngressV1Beta1Operator.class),
                 mock(ImageStreamOperator.class),
                 mock(BuildConfigOperator.class),
                 mock(BuildOperator.class),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -157,7 +157,7 @@ public class KafkaAssemblyOperatorTest {
     private final String differentMetricsCMName = "metrics-cm-2";
     private final ConfigMap metricsCM = io.strimzi.operator.cluster.TestUtils.getJmxMetricsCm(metricsCmJson, metricsCMName);
 
-    private final KubernetesVersion kubernetesVersion = KubernetesVersion.V1_16;
+    private final KubernetesVersion kubernetesVersion = KubernetesVersion.V1_20;
 
     private static boolean openShift;
     private static boolean metrics;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -164,7 +164,7 @@ public void test(VertxTestContext context) {
 
         KafkaConnectAssemblyOperator operator = new KafkaConnectAssemblyOperator(vertx, pfa,
                 new ResourceOperatorSupplier(
-                        null, null, null, null, null, null, null, null, null, null, null,
+                        null, null, null, null, null, null, null, null, null, null, null, null,
                         null, null, null, null, null, null, null, null, null, null, null, null,
                         null, null, connectCrdOperator, null, null, null, null, null, metrics, null),
                 ClusterOperatorConfig.fromMap(Collections.emptyMap(), KafkaVersionTestUtils.getKafkaVersionLookup()),

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/IngressOperator.java
Patch:
@@ -4,8 +4,8 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.extensions.Ingress;
-import io.fabric8.kubernetes.api.model.extensions.IngressList;
+import io.fabric8.kubernetes.api.model.networking.v1.Ingress;
+import io.fabric8.kubernetes.api.model.networking.v1.IngressList;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -28,7 +28,7 @@ public IngressOperator(Vertx vertx, KubernetesClient client) {
 
     @Override
     protected MixedOperation<Ingress, IngressList, Resource<Ingress>> operation() {
-        return client.extensions().ingresses();
+        return client.network().v1().ingresses();
     }
 
     /**

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -9,7 +9,7 @@
 import io.fabric8.kubernetes.api.model.Pod;
 import io.fabric8.kubernetes.api.model.PodCondition;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
-import io.fabric8.kubernetes.api.model.extensions.Ingress;
+import io.fabric8.kubernetes.api.model.networking.v1.Ingress;
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.client.CustomResourceList;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;

File: test/src/main/java/io/strimzi/test/k8s/KubeClient.java
Patch:
@@ -23,7 +23,7 @@
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
 import io.fabric8.kubernetes.api.model.batch.Job;
 import io.fabric8.kubernetes.api.model.batch.JobList;
-import io.fabric8.kubernetes.api.model.extensions.Ingress;
+import io.fabric8.kubernetes.api.model.networking.v1.Ingress;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRole;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.fabric8.kubernetes.api.model.rbac.Role;
@@ -492,11 +492,11 @@ public List<Secret> listSecrets(String labelKey, String labelValue) {
     // =============================
 
     public Ingress createIngress(Ingress ingress) {
-        return client.extensions().ingresses().inNamespace(getNamespace()).createOrReplace(ingress);
+        return client.network().v1().ingresses().inNamespace(getNamespace()).createOrReplace(ingress);
     }
 
     public Boolean deleteIngress(Ingress ingress) {
-        return client.extensions().ingresses().inNamespace(getNamespace()).delete(ingress);
+        return client.network().v1().ingresses().inNamespace(getNamespace()).delete(ingress);
     }
 
     // =============================

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -355,6 +355,7 @@ private String getSecurityProtocol(boolean tls, boolean sasl)   {
         addOption(options, ServerConfig.OAUTH_VALID_ISSUER_URI, oauth.getValidIssuerUri());
         addBooleanOptionIfFalse(options, ServerConfig.OAUTH_CHECK_ISSUER, oauth.isCheckIssuer());
         addBooleanOptionIfTrue(options, ServerConfig.OAUTH_CHECK_AUDIENCE, oauth.isCheckAudience());
+        addOption(options, ServerConfig.OAUTH_CUSTOM_CLAIM_CHECK, oauth.getCustomClaimCheck());
         addOption(options, ServerConfig.OAUTH_JWKS_ENDPOINT_URI, oauth.getJwksEndpointUri());
         if (oauth.getJwksRefreshSeconds() != null && oauth.getJwksRefreshSeconds() > 0) {
             addOption(options, ServerConfig.OAUTH_JWKS_REFRESH_SECONDS, String.valueOf(oauth.getJwksRefreshSeconds()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -1031,6 +1031,7 @@ public void testOauthConfigurationWithClientSecret()  {
                     .withNewValidIssuerUri("https://valid-issuer")
                     .withNewIntrospectionEndpointUri("https://intro")
                     .withCheckAudience(true)
+                    .withCustomClaimCheck("'kafka-user' in @.roles.client-roles.kafka")
                     .withNewClientId("my-oauth-client")
                     .withNewClientSecret()
                         .withNewSecretName("my-secret")
@@ -1058,7 +1059,7 @@ public void testOauthConfigurationWithClientSecret()  {
                 "ssl.secure.random.implementation=SHA1PRNG",
                 "ssl.endpoint.identification.algorithm=HTTPS",
                 "listener.name.plain-9092.oauthbearer.sasl.server.callback.handler.class=io.strimzi.kafka.oauth.server.JaasServerOauthValidatorCallbackHandler",
-                "listener.name.plain-9092.oauthbearer.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required unsecuredLoginStringClaim_sub=\"thePrincipalName\" oauth.client.id=\"my-oauth-client\" oauth.valid.issuer.uri=\"https://valid-issuer\" oauth.check.audience=\"true\" oauth.introspection.endpoint.uri=\"https://intro\" oauth.client.secret=\"${STRIMZI_PLAIN_9092_OAUTH_CLIENT_SECRET}\";",
+                "listener.name.plain-9092.oauthbearer.sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required unsecuredLoginStringClaim_sub=\"thePrincipalName\" oauth.client.id=\"my-oauth-client\" oauth.valid.issuer.uri=\"https://valid-issuer\" oauth.check.audience=\"true\" oauth.custom.claim.check=\"'kafka-user' in @.roles.client-roles.kafka\" oauth.introspection.endpoint.uri=\"https://intro\" oauth.client.secret=\"${STRIMZI_PLAIN_9092_OAUTH_CLIENT_SECRET}\";",
                 "listener.name.plain-9092.sasl.enabled.mechanisms=OAUTHBEARER",
                 "principal.builder.class=io.strimzi.kafka.oauth.server.OAuthKafkaPrincipalBuilder"));
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java
Patch:
@@ -69,10 +69,10 @@ public static void clusterOperator(String namespace, long operationTimeout, long
         if (fromVersion != null) {
             createAndModifySubscription(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy, fromVersion);
             // must be strimzi-cluster-operator.v0.18.0
-            csvName = Environment.OLM_APP_BUNDLE_PREFIX + "." + fromVersion;
+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + ".v" + fromVersion;
         } else {
             createAndModifySubscriptionLatestRelease(namespace, operationTimeout, reconciliationInterval, olmInstallationStrategy);
-            csvName = Environment.OLM_APP_BUNDLE_PREFIX + "." + Environment.OLM_OPERATOR_LATEST_RELEASE_VERSION;
+            csvName = Environment.OLM_APP_BUNDLE_PREFIX + ".v" + Environment.OLM_OPERATOR_LATEST_RELEASE_VERSION;
         }
 
         // manual installation needs approval with patch

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java
Patch:
@@ -90,7 +90,7 @@ private void performUpgradeVerification(JsonObject testParameters) throws IOExce
         // 2. Approve installation
         //   a) get name of install-plan
         //   b) approve installation
-        OlmResource.clusterOperator(namespace, OlmInstallationStrategy.Manual, "v" + fromVersion);
+        OlmResource.clusterOperator(namespace, OlmInstallationStrategy.Manual, fromVersion);
 
         String url = testParameters.getString("urlFrom");
         File dir = FileUtils.downloadAndUnzip(url);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -354,6 +354,7 @@ private String getSecurityProtocol(boolean tls, boolean sasl)   {
         addOption(options, ServerConfig.OAUTH_CLIENT_ID, oauth.getClientId());
         addOption(options, ServerConfig.OAUTH_VALID_ISSUER_URI, oauth.getValidIssuerUri());
         addBooleanOptionIfFalse(options, ServerConfig.OAUTH_CHECK_ISSUER, oauth.isCheckIssuer());
+        addBooleanOptionIfTrue(options, ServerConfig.OAUTH_CHECK_AUDIENCE, oauth.isCheckAudience());
         addOption(options, ServerConfig.OAUTH_JWKS_ENDPOINT_URI, oauth.getJwksEndpointUri());
         if (oauth.getJwksRefreshSeconds() != null && oauth.getJwksRefreshSeconds() > 0) {
             addOption(options, ServerConfig.OAUTH_JWKS_REFRESH_SECONDS, String.valueOf(oauth.getJwksRefreshSeconds()));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -217,7 +217,7 @@ public static EntityTopicOperator fromCrd(Kafka kafkaAssembly) {
                 result.setOwnerReference(kafkaAssembly);
                 String image = topicOperatorSpec.getImage();
                 if (image == null) {
-                    image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE, "strimzi/operator:latest");
+                    image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE, "quay.io/strimzi/operator:latest");
                 }
                 result.setImage(image);
                 result.setWatchedNamespace(topicOperatorSpec.getWatchedNamespace() != null ? topicOperatorSpec.getWatchedNamespace() : namespace);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -227,7 +227,7 @@ public static EntityUserOperator fromCrd(Kafka kafkaAssembly) {
                 result.setOwnerReference(kafkaAssembly);
                 String image = userOperatorSpec.getImage();
                 if (image == null) {
-                    image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_USER_OPERATOR_IMAGE, "strimzi/operator:latest");
+                    image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_USER_OPERATOR_IMAGE, "quay.io/strimzi/operator:latest");
                 }
                 result.setImage(image);
                 result.setWatchedNamespace(userOperatorSpec.getWatchedNamespace() != null ? userOperatorSpec.getWatchedNamespace() : namespace);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/JmxTrans.java
Patch:
@@ -123,7 +123,7 @@ public static JmxTrans fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup versions
 
             String image = spec.getImage();
             if (image == null) {
-                image = System.getenv().getOrDefault(STRIMZI_DEFAULT_JMXTRANS_IMAGE, "strimzi/jmxtrans:latest");
+                image = System.getenv().getOrDefault(STRIMZI_DEFAULT_JMXTRANS_IMAGE, "quay.io/strimzi/jmxtrans:latest");
             }
             result.setImage(image);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -153,7 +153,7 @@ public static KafkaBridgeCluster fromCrd(KafkaBridge kafkaBridge, KafkaVersion.L
         }
         String image = spec.getImage();
         if (image == null) {
-            image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE, "strimzi/kafka-bridge:latest");
+            image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE, "quay.io/strimzi/kafka-bridge:latest");
         }
         kafkaBridgeCluster.setImage(image);
         kafkaBridgeCluster.setReplicas(spec.getReplicas());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -267,7 +267,7 @@ private KafkaCluster(HasMetadata resource) {
         this.logAndMetricsConfigVolumeName = "kafka-metrics-and-logging";
         this.logAndMetricsConfigMountPath = "/opt/kafka/custom-config/";
 
-        this.initImage = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_INIT_IMAGE, "strimzi/operator:latest");
+        this.initImage = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_INIT_IMAGE, "quay.io/strimzi/operator:latest");
     }
 
     public static String kafkaClusterName(String cluster) {
@@ -403,7 +403,7 @@ public static KafkaCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup vers
 
         String initImage = kafkaClusterSpec.getBrokerRackInitImage();
         if (initImage == null) {
-            initImage = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_INIT_IMAGE, "strimzi/operator:latest");
+            initImage = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_INIT_IMAGE, "quay.io/strimzi/operator:latest");
         }
         result.setInitImage(initImage);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -239,7 +239,7 @@ protected static <C extends KafkaConnectCluster> C fromSpec(KafkaConnectSpec spe
 
         String initImage = spec.getClientRackInitImage();
         if (initImage == null) {
-            initImage = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_INIT_IMAGE, "strimzi/operator:latest");
+            initImage = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_INIT_IMAGE, "quay.io/strimzi/operator:latest");
         }
         kafkaConnect.setInitImage(initImage);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -164,7 +164,7 @@ public void testFromCrdDefault() {
         EntityTopicOperator entityTopicOperator = EntityTopicOperator.fromCrd(resource);
 
         assertThat(entityTopicOperator.getWatchedNamespace(), is(namespace));
-        assertThat(entityTopicOperator.getImage(), is("strimzi/operator:latest"));
+        assertThat(entityTopicOperator.getImage(), is("quay.io/strimzi/operator:latest"));
         assertThat(entityTopicOperator.getReconciliationIntervalMs(), is(EntityTopicOperatorSpec.DEFAULT_FULL_RECONCILIATION_INTERVAL_SECONDS * 1000));
         assertThat(entityTopicOperator.getZookeeperSessionTimeoutMs(), is(EntityTopicOperatorSpec.DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS * 1000));
         assertThat(entityTopicOperator.getTopicMetadataMaxAttempts(), is(EntityTopicOperatorSpec.DEFAULT_TOPIC_METADATA_MAX_ATTEMPTS));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -185,7 +185,7 @@ public void testFromCrdDefault() {
         EntityUserOperator entityUserOperator = EntityUserOperator.fromCrd(resource);
 
         assertThat(entityUserOperator.getWatchedNamespace(), is(namespace));
-        assertThat(entityUserOperator.getImage(), is("strimzi/operator:latest"));
+        assertThat(entityUserOperator.getImage(), is("quay.io/strimzi/operator:latest"));
         assertThat(entityUserOperator.getReconciliationIntervalMs(), is(EntityUserOperatorSpec.DEFAULT_FULL_RECONCILIATION_INTERVAL_SECONDS * 1000));
         assertThat(entityUserOperator.getZookeeperSessionTimeoutMs(), is(EntityUserOperatorSpec.DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS * 1000));
         assertThat(entityUserOperator.readinessProbeOptions.getInitialDelaySeconds(), is(EntityUserOperatorSpec.DEFAULT_HEALTHCHECK_DELAY));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -128,7 +128,7 @@ protected List<EnvVar> getExpectedEnvVars() {
     public void testDefaultValues() {
         KafkaBridgeCluster kbc = KafkaBridgeCluster.fromCrd(ResourceUtils.createEmptyKafkaBridge(namespace, cluster), VERSIONS);
 
-        assertThat(kbc.image, is("strimzi/kafka-bridge:latest"));
+        assertThat(kbc.image, is("quay.io/strimzi/kafka-bridge:latest"));
         assertThat(kbc.replicas, is(KafkaBridgeCluster.DEFAULT_REPLICAS));
         assertThat(kbc.readinessProbeOptions.getInitialDelaySeconds(), is(KafkaBridgeCluster.DEFAULT_HEALTHCHECK_DELAY));
         assertThat(kbc.readinessProbeOptions.getTimeoutSeconds(), is(KafkaBridgeCluster.DEFAULT_HEALTHCHECK_TIMEOUT));

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/kafkaclients/KafkaBasicExampleClients.java
Patch:
@@ -179,6 +179,7 @@ public JobBuilder defaultProducerStrimzi() {
                 .withName(producerName)
             .endMetadata()
             .withNewSpec()
+                .withBackoffLimit(0)
                 .withNewTemplate()
                     .withNewMetadata()
                     .withLabels(producerLabels)
@@ -246,6 +247,7 @@ public JobBuilder defaultConsumerStrimzi() {
                 .withName(consumerName)
             .endMetadata()
             .withNewSpec()
+                .withBackoffLimit(0)
                 .withNewTemplate()
                     .withNewMetadata()
                         .withLabels(consumerLabels)

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/kafkaclients/KafkaBridgeExampleClients.java
Patch:
@@ -119,6 +119,7 @@ public JobBuilder producerStrimziBridge() {
                 .withName(producerName)
             .endMetadata()
             .withNewSpec()
+                .withBackoffLimit(0)
                 .withNewTemplate()
                     .withNewMetadata()
                         .withLabels(producerLabels)
@@ -168,6 +169,7 @@ public JobBuilder consumerStrimziBridge() {
                 .withName(consumerName)
             .endMetadata()
             .withNewSpec()
+                .withBackoffLimit(0)
                 .withNewTemplate()
                     .withNewMetadata()
                         .withLabels(consumerLabels)

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java
Patch:
@@ -77,7 +77,7 @@ public static void waitForPodsReady(LabelSelector selector, int expectPods, bool
                     return false;
                 }
                 if (pods.size() != expectPods) {
-                    LOGGER.debug("Expected pods not ready");
+                    LOGGER.debug("Expected pods {} are not ready", selector);
                     return false;
                 }
                 for (Pod pod : pods) {

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/KubeCmdClient.java
Patch:
@@ -24,6 +24,8 @@ public interface KubeCmdClient<K extends KubeCmdClient<K>> {
 
     String defaultNamespace();
     String defaultOlmNamespace();
+    String defaultOlmSourceNamespace();
+
 
     /** Deletes the resources by resource name. */
     K deleteByName(String resourceType, String resourceName);

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaAuthorizationKeycloak.java
Patch:
@@ -33,7 +33,6 @@ public class KafkaAuthorizationKeycloak extends KafkaAuthorization {
     public static final String TYPE_KEYCLOAK = "keycloak";
 
     public static final String AUTHORIZER_CLASS_NAME = "io.strimzi.kafka.oauth.server.authorizer.KeycloakRBACAuthorizer";
-    public static final String PRINCIPAL_BUILDER_CLASS_NAME = "io.strimzi.kafka.oauth.server.authorizer.JwtKafkaPrincipalBuilder";
 
     private String clientId;
     private String tokenEndpointUri;

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
Patch:
@@ -422,6 +422,8 @@ void setUp() {
                                 .withJwksRefreshSeconds(keycloakInstance.getJwksRefreshSeconds())
                                 .withJwksEndpointUri(keycloakInstance.getJwksEndpointUri())
                                 .withUserNameClaim(keycloakInstance.getUserNameClaim())
+                                .withEnablePlain(true)
+                                .withTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
                             .endKafkaListenerAuthenticationOAuth()
                         .endGenericKafkaListener()
                     .endListeners()

File: api/src/main/java/io/strimzi/api/kafka/model/ExternalConfigurationReference.java
Patch:
@@ -16,22 +16,22 @@
 import java.util.Map;
 
 /**
- * Representation for metrics configuration
+ * Representation for a value read from a given key of a config map in the same namespace as the referrer.
  */
 @Buildable(
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
 @JsonInclude(JsonInclude.Include.NON_DEFAULT)
 @EqualsAndHashCode
-public class ExternalConfigurationMetrics implements Serializable, UnknownPropertyPreserving {
+public class ExternalConfigurationReference implements Serializable, UnknownPropertyPreserving {
 
     private static final long serialVersionUID = 1L;
 
     private ConfigMapKeySelector configMapKeyRef;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
-    @Description("Reference to the key in the ConfigMap containing the metrics configuration.")
+    @Description("Reference to the key in the ConfigMap containing the configuration.")
     @KubeLink(group = "core", version = "v1", kind = "configmapkeyselector")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public ConfigMapKeySelector getConfigMapKeyRef() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -78,6 +78,7 @@
 import io.strimzi.api.kafka.model.template.KafkaClusterTemplate;
 import io.strimzi.certs.CertAndKey;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlConfigurationParameters;
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.PasswordGenerator;
@@ -1923,8 +1924,8 @@ public String getBrokersConfiguration() {
         return this.brokersConfiguration;
     }
 
-    public ConfigMap generateAncillaryConfigMap(ConfigMap externalLoggingCm, ConfigMap externalMetricsCm, Set<String> advertisedHostnames, Set<String> advertisedPorts)   {
-        ConfigMap cm = generateMetricsAndLogConfigMap(externalLoggingCm, externalMetricsCm);
+    public ConfigMap generateAncillaryConfigMap(MetricsAndLogging metricsAndLogging, Set<String> advertisedHostnames, Set<String> advertisedPorts)   {
+        ConfigMap cm = generateMetricsAndLogConfigMap(metricsAndLogging);
 
         this.brokersConfiguration = generateBrokerConfiguration();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -163,9 +163,9 @@ protected Future<KafkaConnectStatus> createOrUpdate(Reconciliation reconciliatio
                 .compose(i -> connectBuild(namespace, build, buildState))
                 .compose(i -> deploymentOperations.scaleDown(namespace, connect.getName(), connect.getReplicas()))
                 .compose(scale -> serviceOperations.reconcile(namespace, connect.getServiceName(), connect.generateService()))
-                .compose(i -> connectMetricsAndLoggingConfigMap(namespace, connect))
+                .compose(i -> Util.metricsAndLogging(configMapOperations, namespace, connect.getLogging(), connect.getMetricsConfigInCm()))
                 .compose(metricsAndLoggingCm -> {
-                    ConfigMap logAndMetricsConfigMap = connect.generateMetricsAndLogConfigMap(metricsAndLoggingCm.loggingCm, metricsAndLoggingCm.metricsCm);
+                    ConfigMap logAndMetricsConfigMap = connect.generateMetricsAndLogConfigMap(metricsAndLoggingCm);
                     annotations.put(Annotations.ANNO_STRIMZI_LOGGING_DYNAMICALLY_UNCHANGEABLE_HASH,
                             Util.stringHash(Util.getLoggingDynamicallyUnmodifiableEntries(logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG))));
                     desiredLogging.set(logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -140,9 +140,9 @@ public Future<KafkaConnectS2IStatus> createOrUpdate(Reconciliation reconciliatio
                 .compose(i -> networkPolicyOperator.reconcile(namespace, connect.getName(), connect.generateNetworkPolicy(pfa.isNamespaceAndPodSelectorNetworkPolicySupported(), isUseResources(kafkaConnectS2I), operatorNamespace, operatorNamespaceLabels)))
                 .compose(i -> deploymentConfigOperations.scaleDown(namespace, connect.getName(), connect.getReplicas()))
                 .compose(scale -> serviceOperations.reconcile(namespace, connect.getServiceName(), connect.generateService()))
-                .compose(i -> connectMetricsAndLoggingConfigMap(namespace, connect))
+                .compose(i -> Util.metricsAndLogging(configMapOperations, namespace, connect.getLogging(), connect.getMetricsConfigInCm()))
                 .compose(metricsAndLoggingCm -> {
-                    ConfigMap logAndMetricsConfigMap = connect.generateMetricsAndLogConfigMap(metricsAndLoggingCm.loggingCm, metricsAndLoggingCm.metricsCm);
+                    ConfigMap logAndMetricsConfigMap = connect.generateMetricsAndLogConfigMap(metricsAndLoggingCm);
                     annotations.put(Annotations.ANNO_STRIMZI_LOGGING_DYNAMICALLY_UNCHANGEABLE_HASH,
                             Util.stringHash(Util.getLoggingDynamicallyUnmodifiableEntries(logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG))));
                     desiredLogging.set(logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -151,9 +151,9 @@ protected Future<KafkaMirrorMaker2Status> createOrUpdate(Reconciliation reconcil
                 .compose(i -> networkPolicyOperator.reconcile(namespace, mirrorMaker2Cluster.getName(), mirrorMaker2Cluster.generateNetworkPolicy(pfa.isNamespaceAndPodSelectorNetworkPolicySupported(), true, operatorNamespace, operatorNamespaceLabels)))
                 .compose(i -> deploymentOperations.scaleDown(namespace, mirrorMaker2Cluster.getName(), mirrorMaker2Cluster.getReplicas()))
                 .compose(scale -> serviceOperations.reconcile(namespace, mirrorMaker2Cluster.getServiceName(), mirrorMaker2Cluster.generateService()))
-                .compose(i -> connectMetricsAndLoggingConfigMap(namespace, mirrorMaker2Cluster))
+                .compose(i -> Util.metricsAndLogging(configMapOperations, namespace, mirrorMaker2Cluster.getLogging(), mirrorMaker2Cluster.getMetricsConfigInCm()))
                 .compose(metricsAndLoggingCm -> {
-                    ConfigMap logAndMetricsConfigMap = mirrorMaker2Cluster.generateMetricsAndLogConfigMap(metricsAndLoggingCm.loggingCm, metricsAndLoggingCm.metricsCm);
+                    ConfigMap logAndMetricsConfigMap = mirrorMaker2Cluster.generateMetricsAndLogConfigMap(metricsAndLoggingCm);
                     annotations.put(Annotations.ANNO_STRIMZI_LOGGING_DYNAMICALLY_UNCHANGEABLE_HASH,
                             Util.stringHash(Util.getLoggingDynamicallyUnmodifiableEntries(logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG))));
                     desiredLogging.set(logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -73,6 +73,7 @@
 import io.strimzi.certs.OpenSslCertManager;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
+import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlConfigurationParameters;
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.Util;
@@ -171,14 +172,14 @@ public void testMetricsConfigMapDeprecatedMetrics() {
 
         KafkaCluster kc = KafkaCluster.fromCrd(kafkaAssembly, VERSIONS);
 
-        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(null, null);
+        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(new MetricsAndLogging(null, null));
         checkMetricsConfigMap(metricsCm);
         checkOwnerReference(kc.createOwnerReference(), metricsCm);
     }
 
     @Test
     public void testMetricsConfigMap() {
-        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(null, metricsCM);
+        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(new MetricsAndLogging(metricsCM, null));
         checkMetricsConfigMap(metricsCm);
         checkOwnerReference(kc.createOwnerReference(), metricsCm);
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -57,6 +57,7 @@
 import io.strimzi.kafka.oauth.server.ServerConfig;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
+import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.test.TestUtils;
@@ -150,13 +151,13 @@ public void testMetricsConfigMapDeprecatedMetrics() {
                 .endSpec()
                 .build();
         KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(resource, VERSIONS);
-        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(null, null);
+        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(new MetricsAndLogging(null, null));
         checkMetricsConfigMap(metricsCm);
     }
 
     @Test
     public void testMetricsConfigMap() {
-        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(null, metricsCM);
+        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(new MetricsAndLogging(metricsCM, null));
         checkMetricsConfigMap(metricsCm);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -58,6 +58,7 @@
 import io.strimzi.kafka.oauth.server.ServerConfig;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
+import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.test.TestUtils;
@@ -146,13 +147,13 @@ public void testMetricsConfigMapDeprecatedMetrics() {
         KafkaConnectS2I resource = ResourceUtils.createKafkaConnectS2I(namespace, cluster, replicas, image,
                 healthDelay, healthTimeout, null, metricsCmJson, configurationJson, insecureSourceRepo, bootstrapServers, buildResourceRequirements);
         KafkaConnectS2ICluster kc = KafkaConnectS2ICluster.fromCrd(resource, VERSIONS);
-        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(null, null);
+        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(new MetricsAndLogging(null, null));
         checkMetricsConfigMap(metricsCm);
     }
 
     @Test
     public void testMetricsConfigMap() {
-        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(null, metricsCM);
+        ConfigMap metricsCm = kc.generateMetricsAndLogConfigMap(new MetricsAndLogging(metricsCM, null));
         checkMetricsConfigMap(metricsCm);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -42,6 +42,7 @@
 import io.strimzi.kafka.oauth.server.ServerConfig;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
+import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.test.TestUtils;
 import org.junit.jupiter.api.Test;
@@ -137,13 +138,13 @@ public void testMetricsConfigMapDeprecatedMetrics() {
                 .build();
 
         KafkaMirrorMakerCluster mm = KafkaMirrorMakerCluster.fromCrd(resource, VERSIONS);
-        ConfigMap metricsCm = mm.generateMetricsAndLogConfigMap(null, null);
+        ConfigMap metricsCm = mm.generateMetricsAndLogConfigMap(new MetricsAndLogging(null, null));
         checkMetricsConfigMap(metricsCm);
     }
 
     @Test
     public void testMetricsConfigMap() {
-        ConfigMap metricsCm = mm.generateMetricsAndLogConfigMap(null, metricsCM);
+        ConfigMap metricsCm = mm.generateMetricsAndLogConfigMap(new MetricsAndLogging(metricsCM, null));
         checkMetricsConfigMap(metricsCm);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -48,6 +48,7 @@
 import io.strimzi.certs.OpenSslCertManager;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
+import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.model.OrderedProperties;
@@ -117,15 +118,15 @@ public void testMetricsConfigMapDeprecatedMetrics() {
         Kafka ka = ResourceUtils.createKafka(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCm, null, configurationJson, zooConfigurationJson, null, null, kafkaLogConfigJson, zooLogConfigJson, null, null);
         ZookeeperCluster zc = ZookeeperCluster.fromCrd(ka, VERSIONS);
 
-        ConfigMap metricsCm = zc.generateConfigurationConfigMap(null, null);
+        ConfigMap metricsCm = zc.generateConfigurationConfigMap(new MetricsAndLogging(null, null));
         checkMetricsConfigMap(metricsCm);
         checkOwnerReference(zc.createOwnerReference(), metricsCm);
     }
 
 
     @Test
     public void testMetricsConfigMap() {
-        ConfigMap metricsCm = zc.generateConfigurationConfigMap(null, metricsCM);
+        ConfigMap metricsCm = zc.generateConfigurationConfigMap(new MetricsAndLogging(metricsCM, null));
         checkMetricsConfigMap(metricsCm);
         checkOwnerReference(zc.createOwnerReference(), metricsCm);
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -67,6 +67,7 @@
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.cluster.operator.resource.StatefulSetDiff;
 import io.strimzi.operator.cluster.operator.resource.ZookeeperSetOperator;
+import io.strimzi.operator.common.MetricsAndLogging;
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
@@ -654,7 +655,7 @@ private void createCluster(VertxTestContext context, Kafka kafka, List<Secret> s
         ArgumentCaptor<String> logNameCaptor = ArgumentCaptor.forClass(String.class);
         when(mockCmOps.reconcile(anyString(), logNameCaptor.capture(), logCaptor.capture())).thenReturn(Future.succeededFuture(ReconcileResult.created(new ConfigMap())));
 
-        ConfigMap metricsCm = kafkaCluster.generateAncillaryConfigMap(null, metricsCM, emptySet(), emptySet());
+        ConfigMap metricsCm = kafkaCluster.generateAncillaryConfigMap(new MetricsAndLogging(metricsCM, null), emptySet(), emptySet());
         when(mockCmOps.getAsync(kafkaNamespace, KafkaCluster.metricAndLogConfigsName(kafkaName))).thenReturn(Future.succeededFuture(metricsCm));
         when(mockCmOps.getAsync(kafkaNamespace, metricsCMName)).thenReturn(Future.succeededFuture(metricsCM));
         when(mockCmOps.getAsync(kafkaNamespace, differentMetricsCMName)).thenReturn(Future.succeededFuture(metricsCM));
@@ -990,7 +991,7 @@ private void updateCluster(VertxTestContext context, Kafka originalAssembly, Kaf
                 .endMetadata()
                 .withData(singletonMap("metrics-config.yml", ""))
                 .build();
-        ConfigMap metricsAndLoggingCm = originalKafkaCluster.generateAncillaryConfigMap(null, metricsCm, emptySet(), emptySet());
+        ConfigMap metricsAndLoggingCm = originalKafkaCluster.generateAncillaryConfigMap(new MetricsAndLogging(metricsCm, null), emptySet(), emptySet());
         when(mockCmOps.get(clusterNamespace, KafkaCluster.metricAndLogConfigsName(clusterName))).thenReturn(metricsAndLoggingCm);
         when(mockCmOps.getAsync(clusterNamespace, KafkaCluster.metricAndLogConfigsName(clusterName))).thenReturn(Future.succeededFuture(metricsAndLoggingCm));
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorUnsupportedFieldsTest.java
Patch:
@@ -212,7 +212,7 @@ vertx, new PlatformFeaturesAvailability(false, kubernetesVersion),
                             .filter(condition -> "Warning".equals(condition.getType()) && "TopicOperator".equals(condition.getReason()))
                             .findFirst().orElse(null);
                     assertThat(toWarning, is(notNullValue()));
-                    assertThat(toWarning.getMessage(), containsString("Kafka.spec.topicOperator is not supported anymore. Topic operator should be configured at path spec.entityOperator.topicOperator."));
+                    assertThat(toWarning.getMessage(), containsString("Kafka.spec.topicOperator is not supported anymore. Topic operator should be configured using spec.entityOperator.topicOperator."));
 
                     async.flag();
                 })));

File: crd-generator/src/main/java/io/strimzi/crdgenerator/DocGenerator.java
Patch:
@@ -290,16 +290,16 @@ private void addTypesFromAlternatives(List<Property> alternatives, LinkedHashSet
     }
 
     private String getDeprecation(Property property, DeprecatedProperty deprecated) {
-        String msg = String.format("*The property `%s` has been deprecated.",
+        String msg = String.format("*The `%s` property has been deprecated",
                 property.getName());
         if (!deprecated.movedToPath().isEmpty()) {
-            msg += " This feature should now be configured at path `" + deprecated.movedToPath() + "`.";
+            msg += ", and should now be configured using `" + deprecated.movedToPath() + "`.";
         }
         if (!deprecated.description().isEmpty()) {
             msg += deprecated.description() + " ";
         }
         if (!deprecated.removalVersion().isEmpty()) {
-            msg += " This property is scheduled for removal in version " + deprecated.removalVersion() + ".";
+            msg += ". The Property " + property.getName() + " is scheduled for removal in version " + deprecated.removalVersion() + ".";
         }
         msg += "* ";
         return msg;

File: operator-common/src/main/java/io/strimzi/operator/common/model/ValidationVisitor.java
Patch:
@@ -78,18 +78,18 @@ private <M extends AnnotatedElement & Member> void checkForDeprecated(List<Strin
         DeprecatedProperty deprecated = member.getAnnotation(DeprecatedProperty.class);
         if (deprecated != null
             && isPresent(member, propertyValue)) {
-            String msg = String.format("In API version %s the property %s at path %s has been deprecated. ",
+            String msg = String.format("In API version %s the %s property at path %s has been deprecated",
                     resource.getApiVersion(),
                     propertyName,
                     path(path, propertyName));
             if (!deprecated.movedToPath().isEmpty()) {
-                msg += "This feature should now be configured at path " + deprecated.movedToPath() + ".";
+                msg += ", and should now be configured using " + deprecated.movedToPath() + ".";
             }
             if (!deprecated.description().isEmpty()) {
                 msg += " " + deprecated.description();
             }
             if (!deprecated.removalVersion().isEmpty()) {
-                msg += " This property is scheduled for removal in version " + deprecated.removalVersion() + ".";
+                msg += ". This property is scheduled for removal in version " + deprecated.removalVersion() + ".";
             }
 
             warningConditions.add(StatusUtils.buildWarningCondition("DeprecatedFields", msg, transitionTime));

File: operator-common/src/main/java/io/strimzi/operator/common/AbstractOperator.java
Patch:
@@ -274,7 +274,7 @@ public final Future<Void> reconcile(Reconciliation reconciliation) {
         return result.future();
     }
 
-    private void addWarningsToStatus(Status status, Set<Condition> unknownAndDeprecatedConditions)   {
+    protected void addWarningsToStatus(Status status, Set<Condition> unknownAndDeprecatedConditions)   {
         if (status != null)  {
             status.addConditions(unknownAndDeprecatedConditions);
         }
@@ -388,8 +388,9 @@ protected final <T> Future<T> withLock(Reconciliation reconciliation, long lockT
      * if the resource can safely be reconciled (e.g. it merely using deprecated API).
      * @param resource The custom resource
      * @throws InvalidResourceException if the resource cannot be safely reconciled.
+     * @return set of conditions
      */
-    /*test*/ Set<Condition> validate(T resource) {
+    /*test*/ public Set<Condition> validate(T resource) {
         if (resource != null) {
             Set<Condition> warningConditions = new LinkedHashSet<>(0);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -97,6 +97,9 @@ private void init() {
                     .withNewKafka()
                         .withReplicas(3)
                         .withNewListeners()
+                            .withNewKafkaListeners()
+                                .withPlain(null)
+                            .endKafkaListeners()
                         .endListeners()
                         .withNewJbodStorage()
                             .withVolumes(volumes)

File: operator-common/src/main/java/io/strimzi/operator/KubernetesVersion.java
Patch:
@@ -22,6 +22,8 @@ public class KubernetesVersion implements Comparable<KubernetesVersion> {
     public static final KubernetesVersion V1_12 = new KubernetesVersion(1, 12);
     public static final KubernetesVersion V1_13 = new KubernetesVersion(1, 13);
     public static final KubernetesVersion V1_14 = new KubernetesVersion(1, 14);
+    public static final KubernetesVersion V1_16 = new KubernetesVersion(1, 16);
+
 
     public static final KubernetesVersion MINIMAL_SUPPORTED_VERSION = V1_9;
     public static final int MINIMAL_SUPPORTED_MAJOR = MINIMAL_SUPPORTED_VERSION.major;

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectS2IST.java
Patch:
@@ -638,7 +638,7 @@ void testChangeConnectS2IConfig() {
         assertThat(actualVersion, is(TestKafkaVersion.getKafkaVersions().get(1).version()));
 
         LOGGER.info("===== CONNECTS2I CERT CHANGE =====");
-        InputStream secretInputStream = getClass().getClassLoader().getResourceAsStream("security-st-certs/cluster-ca.crt");
+        InputStream secretInputStream = getClass().getClassLoader().getResourceAsStream("security-st-certs/expired-cluster-ca.crt");
         String clusterCaCert = TestUtils.readResource(secretInputStream);
         SecretUtils.createSecret("my-secret", "ca.crt", new String(Base64.getEncoder().encode(clusterCaCert.getBytes()), StandardCharsets.US_ASCII));
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -525,7 +525,7 @@ private void createKafkaCluster() {
     @Tag(INTERNAL_CLIENTS_USED)
     void testAutoRenewCaCertsTriggerByExpiredCertificate() {
         // 1. Create the Secrets already, and a certificate that's already expired
-        InputStream secretInputStream = getClass().getClassLoader().getResourceAsStream("security-st-certs/cluster-ca.crt");
+        InputStream secretInputStream = getClass().getClassLoader().getResourceAsStream("security-st-certs/expired-cluster-ca.crt");
         String clusterCaCert = TestUtils.readResource(secretInputStream);
         SecretUtils.createSecret(clusterCaCertificateSecretName(clusterName), "ca.crt", new String(Base64.getEncoder().encode(clusterCaCert.getBytes()), StandardCharsets.US_ASCII));
 
@@ -1057,7 +1057,7 @@ void testCaRenewalBreakInMiddle() {
         Map<String, String> kafkaPods = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(clusterName));
         Map<String, String> eoPods = DeploymentUtils.depSnapshot(KafkaResources.entityOperatorDeploymentName(clusterName));
 
-        InputStream secretInputStream = getClass().getClassLoader().getResourceAsStream("security-st-certs/cluster-ca.crt");
+        InputStream secretInputStream = getClass().getClassLoader().getResourceAsStream("security-st-certs/expired-cluster-ca.crt");
         String clusterCaCert = TestUtils.readResource(secretInputStream);
         SecretUtils.createSecret(clusterCaCertificateSecretName(clusterName), "ca.crt", new String(Base64.getEncoder().encode(clusterCaCert.getBytes()), StandardCharsets.US_ASCII));
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java
Patch:
@@ -140,7 +140,7 @@ void testNetworkPoliciesWithPlainListener() {
         });
 
         LOGGER.info("Check metrics exported by Kafka Exporter");
-        Map<String, String> kafkaExporterMetricsData = MetricsUtils.collectKafkaExporterPodsMetrics(clusterName);
+        Map<String, String> kafkaExporterMetricsData = MetricsUtils.collectKafkaExporterPodsMetrics(allowedKafkaClientsPodName, clusterName);
         assertThat("Kafka Exporter metrics should be non-empty", kafkaExporterMetricsData.size() > 0);
         for (Map.Entry<String, String> entry : kafkaExporterMetricsData.entrySet()) {
             assertThat("Value from collected metric should be non-empty", !entry.getValue().isEmpty());

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -32,6 +32,7 @@
 import io.strimzi.systemtest.resources.operator.BundleResource;
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
@@ -250,9 +251,6 @@ public void testRackAwareConnectCorrectDeployment() {
 
         KubernetesResource.deployNetworkPolicyForResource(kc, KafkaConnectResources.deploymentName(clusterName));
 
-        String topicName = "topic-test-rack-aware";
-        KafkaTopicResource.createAndWaitForReadiness(KafkaTopicResource.topic(clusterName, topicName).build());
-
         List<String> connectPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);
         for (String connectPodName : connectPods) {
             Affinity connectPodSpecAffinity = kubeClient().getDeployment(KafkaConnectResources.deploymentName(clusterName)).getSpec().getTemplate().getSpec().getAffinity();
@@ -265,6 +263,8 @@ public void testRackAwareConnectCorrectDeployment() {
             assertThat(connectPodNodeSelectorRequirement.getKey(), is(rackKey));
             assertThat(connectPodNodeSelectorRequirement.getOperator(), is("Exists"));
 
+            String topicName = "rw-" + KafkaTopicUtils.generateRandomNameOfTopic();
+            KafkaTopicResource.createAndWaitForReadiness(KafkaTopicResource.topic(clusterName, topicName).build());
             KafkaConnectUtils.sendReceiveMessagesThroughConnect(connectPodName, topicName, kafkaClientsPodName, NAMESPACE, clusterName);
         }
 

File: crd-generator/src/main/java/io/strimzi/crdgenerator/DocGenerator.java
Patch:
@@ -416,10 +416,12 @@ private void appendDescription(Class<?> cls) throws IOException {
                 throw new RuntimeException("Class " + cls.getCanonicalName() + " has @DescribeFile annotation, but file " + filename + " does not exist!");
             }
 
+            out.append("xref:type-").append(cls.getSimpleName()).append("-schema-{context}[Full list of `").append(cls.getSimpleName()).append("` schema properties]").append(NL);
+            out.append(NL);
             out.append("include::../" + filename + "[leveloffset=+1]").append(NL);
             out.append(NL);
             out.append("[id='type-").append(cls.getSimpleName()).append("-schema-{context}']").append(NL);
-            out.append("==== Schema reference").append(NL);
+            out.append("==== `").append(cls.getSimpleName()).append("` schema properties").append(NL);
             out.append(NL);
 
         } else if (description != null) {

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -85,7 +85,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
-@Version(Constants.V1BETA2)
+@Version(Constants.V1BETA1)
 @Group(Constants.STRIMZI_GROUP)
 public class Kafka extends CustomResource<KafkaSpec, KafkaStatus> implements UnknownPropertyPreserving {
 

File: api/src/main/java/io/strimzi/api/kafka/model/Constants.java
Patch:
@@ -15,6 +15,7 @@ public class Constants {
 
     public static final String CRD_KIND = "CustomResourceDefinition";
     public static final String STRIMZI_CATEGORY = "strimzi";
+    public static final String STRIMZI_GROUP = "kafka.strimzi.io";
 
     public static final String FABRIC8_KUBERNETES_API = "io.fabric8.kubernetes.api.builder";
 

File: api/src/main/java/io/strimzi/api/kafka/model/CruiseControlSpec.java
Patch:
@@ -22,7 +22,7 @@
 @Buildable(
         editableEnabled = false,
         generateBuilderPackage = false,
-        builderPackage = "io.fabric8.kubernetes.api.builder"
+        builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({

File: api/src/main/java/io/strimzi/api/kafka/model/balancing/BrokerCapacity.java
Patch:
@@ -6,6 +6,7 @@
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import io.strimzi.api.kafka.model.Constants;
 import io.strimzi.api.kafka.model.UnknownPropertyPreserving;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.strimzi.crdgenerator.annotations.Maximum;
@@ -26,7 +27,7 @@
 @Buildable(
         editableEnabled = false,
         generateBuilderPackage = false,
-        builderPackage = "io.fabric8.kubernetes.api.builder"
+        builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"disk", "cpuUtilization", "inboundNetwork", "outboundNetwork"})

File: api/src/main/java/io/strimzi/api/kafka/model/template/CruiseControlTemplate.java
Patch:
@@ -6,6 +6,7 @@
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import io.strimzi.api.kafka.model.Constants;
 import io.strimzi.api.kafka.model.UnknownPropertyPreserving;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
@@ -21,7 +22,7 @@
 @Buildable(
         editableEnabled = false,
         generateBuilderPackage = false,
-        builderPackage = "io.fabric8.kubernetes.api.builder"
+        builderPackage = Constants.FABRIC8_KUBERNETES_API
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({

File: api/src/test/java/io/strimzi/api/kafka/model/ApiEvolutionCrdIT.java
Patch:
@@ -337,15 +337,15 @@ private void assertIsListListener(Kafka kafka) {
         assertEquals("someValue", kafkaSpec.getConfig().get("some.kafka.config"));
     }
 
-    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta1Op() {
+    private NonNamespaceOperation<Kafka, KafkaList, Resource<Kafka>> v1beta1Op() {
         return Crds.kafkaV1Beta1Operation(cluster.client().getClient()).inNamespace(NAMESPACE);
     }
 
-    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1beta2Op() {
+    private NonNamespaceOperation<Kafka, KafkaList, Resource<Kafka>> v1beta2Op() {
         return Crds.kafkaV1Beta2Operation(cluster.client().getClient()).inNamespace(NAMESPACE);
     }
 
-    private NonNamespaceOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> v1Op() {
+    private NonNamespaceOperation<Kafka, KafkaList, Resource<Kafka>> v1Op() {
         return Crds.kafkaV1Operation(cluster.client().getClient()).inNamespace(NAMESPACE);
     }
 

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaBridgeCrdIT.java
Patch:
@@ -43,7 +43,7 @@ void testKafkaBridgeMinimal() {
 
     @Test
     void testKafkaBridgeWithExtraProperty() {
-        createDelete(KafkaMirrorMaker.class, "KafkaBridge-with-extra-property.yaml");
+        createDelete(KafkaBridge.class, "KafkaBridge-with-extra-property.yaml");
     }
 
     @Test

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -29,7 +29,6 @@
 import io.strimzi.api.kafka.model.CertAndKeySecretSource;
 import io.strimzi.api.kafka.model.CertificateAuthority;
 import io.strimzi.api.kafka.model.Constants;
-import io.strimzi.api.kafka.model.DoneableKafka;
 import io.strimzi.api.kafka.model.ExternalLogging;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetrics;
 import io.strimzi.api.kafka.model.Kafka;
@@ -164,7 +163,7 @@
  * </ul>
  */
 @SuppressWarnings({"checkstyle:ClassDataAbstractionCoupling", "checkstyle:ClassFanOutComplexity", "checkstyle:JavaNCSS"})
-public class KafkaAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>, KafkaSpec, KafkaStatus> {
+public class KafkaAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, Kafka, KafkaList, Resource<Kafka>, KafkaSpec, KafkaStatus> {
     private static final Logger log = LogManager.getLogger(KafkaAssemblyOperator.class.getName());
 
     private final long operationTimeoutMs;
@@ -184,7 +183,7 @@ public class KafkaAssemblyOperator extends AbstractAssemblyOperator<KubernetesCl
     private final IngressOperator ingressOperations;
     private final StorageClassOperator storageClassOperator;
     private final NodeOperator nodeOperator;
-    private final CrdOperator<KubernetesClient, Kafka, KafkaList, DoneableKafka> crdOperator;
+    private final CrdOperator<KubernetesClient, Kafka, KafkaList> crdOperator;
     private final ZookeeperScalerProvider zkScalerProvider;
     private final AdminClientProvider adminClientProvider;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -9,7 +9,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.KafkaBridgeList;
-import io.strimzi.api.kafka.model.DoneableKafkaBridge;
 import io.strimzi.api.kafka.model.ExternalLogging;
 import io.strimzi.api.kafka.model.KafkaBridge;
 import io.strimzi.api.kafka.model.KafkaBridgeSpec;
@@ -42,7 +41,7 @@
  *     <li>A Kafka Bridge Deployment and related Services</li>
  * </ul>
  */
-public class KafkaBridgeAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, KafkaBridge, KafkaBridgeList, DoneableKafkaBridge, Resource<KafkaBridge, DoneableKafkaBridge>, KafkaBridgeSpec, KafkaBridgeStatus> {
+public class KafkaBridgeAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, KafkaBridge, KafkaBridgeList, Resource<KafkaBridge>, KafkaBridgeSpec, KafkaBridgeStatus> {
     private static final Logger log = LogManager.getLogger(KafkaBridgeAssemblyOperator.class.getName());
 
     private final DeploymentOperator deploymentOperations;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -35,7 +35,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.KafkaMirrorMaker2List;
-import io.strimzi.api.kafka.model.DoneableKafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.KafkaConnectorSpec;
 import io.strimzi.api.kafka.model.KafkaConnectorSpecBuilder;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2;
@@ -80,7 +79,7 @@
  *     <li>A set of MirrorMaker 2.0 connectors</li>
  * </ul>
  */
-public class KafkaMirrorMaker2AssemblyOperator extends AbstractConnectOperator<KubernetesClient, KafkaMirrorMaker2, KafkaMirrorMaker2List, DoneableKafkaMirrorMaker2, Resource<KafkaMirrorMaker2, DoneableKafkaMirrorMaker2>, KafkaMirrorMaker2Spec, KafkaMirrorMaker2Status> {
+public class KafkaMirrorMaker2AssemblyOperator extends AbstractConnectOperator<KubernetesClient, KafkaMirrorMaker2, KafkaMirrorMaker2List, Resource<KafkaMirrorMaker2>, KafkaMirrorMaker2Spec, KafkaMirrorMaker2Status> {
     private static final Logger log = LogManager.getLogger(KafkaMirrorMaker2AssemblyOperator.class.getName());
     private final DeploymentOperator deploymentOperations;
     private final NetworkPolicyOperator networkPolicyOperator;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -9,7 +9,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.KafkaMirrorMakerList;
-import io.strimzi.api.kafka.model.DoneableKafkaMirrorMaker;
 import io.strimzi.api.kafka.model.ExternalLogging;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetrics;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
@@ -46,7 +45,7 @@
  *     <li>A Kafka Mirror Maker Deployment and related Services</li>
  * </ul>
  */
-public class KafkaMirrorMakerAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList, DoneableKafkaMirrorMaker, Resource<KafkaMirrorMaker, DoneableKafkaMirrorMaker>, KafkaMirrorMakerSpec, KafkaMirrorMakerStatus> {
+public class KafkaMirrorMakerAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList, Resource<KafkaMirrorMaker>, KafkaMirrorMakerSpec, KafkaMirrorMakerStatus> {
 
     private static final Logger log = LogManager.getLogger(KafkaMirrorMakerAssemblyOperator.class.getName());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -9,7 +9,6 @@
 import io.fabric8.kubernetes.api.model.PersistentVolumeClaim;
 import io.fabric8.kubernetes.api.model.Pod;
 import io.fabric8.kubernetes.api.model.Secret;
-import io.fabric8.kubernetes.api.model.apps.DoneableStatefulSet;
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
 import io.fabric8.kubernetes.api.model.apps.StatefulSetList;
 import io.fabric8.kubernetes.client.KubernetesClient;
@@ -42,7 +41,7 @@
  * Operations for {@code StatefulSets}s, which supports {@link #maybeRollingUpdate(StatefulSet, Function)}
  * in addition to the usual operations.
  */
-public abstract class StatefulSetOperator extends AbstractScalableResourceOperator<KubernetesClient, StatefulSet, StatefulSetList, DoneableStatefulSet, RollableScalableResource<StatefulSet, DoneableStatefulSet>> {
+public abstract class StatefulSetOperator extends AbstractScalableResourceOperator<KubernetesClient, StatefulSet, StatefulSetList, RollableScalableResource<StatefulSet>> {
 
     private static final int NO_GENERATION = -1;
     private static final int INIT_GENERATION = 0;
@@ -80,7 +79,7 @@ public StatefulSetOperator(Vertx vertx, KubernetesClient client, long operationT
     }
 
     @Override
-    protected MixedOperation<StatefulSet, StatefulSetList, DoneableStatefulSet, RollableScalableResource<StatefulSet, DoneableStatefulSet>> operation() {
+    protected MixedOperation<StatefulSet, StatefulSetList, RollableScalableResource<StatefulSet>> operation() {
         return client.apps().statefulSets();
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -9,7 +9,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaList;
-import io.strimzi.api.kafka.model.DoneableKafka;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.storage.JbodStorage;
@@ -122,7 +121,7 @@ private void init() {
 
         // setting up a mock Kubernetes client
         this.mockClient = new MockKube()
-                .withCustomResourceDefinition(kafkaAssemblyCrd, Kafka.class, KafkaList.class, DoneableKafka.class)
+                .withCustomResourceDefinition(kafkaAssemblyCrd, Kafka.class, KafkaList.class)
                 .end()
                 .build();
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -9,7 +9,6 @@
 import io.micrometer.core.instrument.MeterRegistry;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaConnectorList;
-import io.strimzi.api.kafka.model.DoneableKafkaConnector;
 import io.strimzi.api.kafka.model.KafkaConnector;
 import io.strimzi.api.kafka.model.KafkaConnectorBuilder;
 import io.strimzi.operator.KubernetesVersion;
@@ -116,7 +115,7 @@ public void test(VertxTestContext context) {
         KafkaConnectApiImpl connectClient = new KafkaConnectApiImpl(vertx);
 
         KubernetesClient client = new MockKube()
-                .withCustomResourceDefinition(Crds.kafkaConnector(), KafkaConnector.class, KafkaConnectorList.class, DoneableKafkaConnector.class)
+                .withCustomResourceDefinition(Crds.kafkaConnector(), KafkaConnector.class, KafkaConnectorList.class)
                 .end()
                 .build();
         PlatformFeaturesAvailability pfa = new PlatformFeaturesAvailability(false, KubernetesVersion.V1_14);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaMirrorMaker2List;
-import io.strimzi.api.kafka.model.DoneableKafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2Builder;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2Resources;
@@ -88,7 +87,7 @@ private void setMirrorMaker2Resource(KafkaMirrorMaker2 mirrorMaker2Resource) {
         }
         mockKube = new MockKube();
         mockClient = mockKube
-                .withCustomResourceDefinition(Crds.kafkaMirrorMaker2(), KafkaMirrorMaker2.class, KafkaMirrorMaker2List.class, DoneableKafkaMirrorMaker2.class, KafkaMirrorMaker2::getStatus, KafkaMirrorMaker2::setStatus)
+                .withCustomResourceDefinition(Crds.kafkaMirrorMaker2(), KafkaMirrorMaker2.class, KafkaMirrorMaker2List.class, KafkaMirrorMaker2::getStatus, KafkaMirrorMaker2::setStatus)
                     .withInitialInstances(Collections.singleton(mirrorMaker2Resource))
                 .end()
                 .build();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceStateMachineTest.java
Patch:
@@ -6,7 +6,6 @@
 
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.KafkaRebalanceList;
-import io.strimzi.api.kafka.model.DoneableKafkaRebalance;
 import io.strimzi.api.kafka.model.KafkaRebalance;
 import io.strimzi.api.kafka.model.KafkaRebalanceBuilder;
 import io.strimzi.api.kafka.model.KafkaRebalanceSpec;
@@ -165,8 +164,7 @@ public String cruiseControlHost(String clusterName, String clusterNamespace) {
 
         CrdOperator<KubernetesClient,
                 KafkaRebalance,
-                KafkaRebalanceList,
-                DoneableKafkaRebalance> mockRebalanceOps = supplier.kafkaRebalanceOperator;
+                KafkaRebalanceList> mockRebalanceOps = supplier.kafkaRebalanceOperator;
 
         when(mockRebalanceOps.get(CLUSTER_NAMESPACE, RESOURCE_NAME)).thenReturn(kcRebalance);
         when(mockRebalanceOps.getAsync(CLUSTER_NAMESPACE, RESOURCE_NAME)).thenReturn(Future.succeededFuture(kcRebalance));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -12,7 +12,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaList;
-import io.strimzi.api.kafka.model.DoneableKafka;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
@@ -138,7 +137,7 @@ public void beforeEach(VertxTestContext context) throws InterruptedException, Ex
         CustomResourceDefinition kafkaAssemblyCrd = Crds.kafka();
 
         KubernetesClient bootstrapClient = new MockKube()
-                .withCustomResourceDefinition(kafkaAssemblyCrd, Kafka.class, KafkaList.class, DoneableKafka.class)
+                .withCustomResourceDefinition(kafkaAssemblyCrd, Kafka.class, KafkaList.class)
                 .withInitialInstances(Collections.singleton(cluster))
                 .end()
                 .build();
@@ -188,7 +187,7 @@ private void startKube() {
         CustomResourceDefinition kafkaAssemblyCrd = Crds.kafka();
 
         this.mockClient = new MockKube()
-                .withCustomResourceDefinition(kafkaAssemblyCrd, Kafka.class, KafkaList.class, DoneableKafka.class)
+                .withCustomResourceDefinition(kafkaAssemblyCrd, Kafka.class, KafkaList.class)
                 .withInitialInstances(Collections.singleton(cluster))
                 .end()
                 .withInitialStatefulSets(set(zkSts, kafkaSts))

File: crd-generator/src/main/java/io/strimzi/crdgenerator/Property.java
Patch:
@@ -100,14 +100,15 @@ private static String propertyName(Method getterMethod) {
         }
     }
 
+    @SuppressWarnings("checkstyle:CyclomaticComplexity")
     static Map<String, Property> properties(ApiVersion crApiVersion, Class<?> crdClass) {
         TreeMap<String, Property> unordered = new TreeMap<>();
         for (Method method : crdClass.getMethods()) {
             Class<?> returnType = method.getReturnType();
             boolean isGetter = isGetterName(method)
                     && method.getParameterCount() == 0
                     && !returnType.equals(void.class);
-            boolean isNotInherited = !hasMethod(CustomResource.class, method)
+            boolean isNotInherited = !(hasMethod(CustomResource.class, method) && !method.getName().equals("getSpec") && !method.getName().equals("getStatus"))
                     && !hasMethod(HasMetadata.class, method)
                     && !method.isBridge();
             boolean isNotIgnored = !hasJsonIgnore(method)

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/BuildOperator.java
Patch:
@@ -8,15 +8,14 @@
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.openshift.api.model.Build;
 import io.fabric8.openshift.api.model.BuildList;
-import io.fabric8.openshift.api.model.DoneableBuild;
 import io.fabric8.openshift.client.OpenShiftClient;
 import io.fabric8.openshift.client.dsl.BuildResource;
 import io.vertx.core.Vertx;
 
 /**
  * Operations for {@code Build}s.
  */
-public class BuildOperator extends AbstractResourceOperator<OpenShiftClient, Build, BuildList, DoneableBuild, BuildResource<Build, DoneableBuild, String, LogWatch>> {
+public class BuildOperator extends AbstractResourceOperator<OpenShiftClient, Build, BuildList, BuildResource<Build, LogWatch>> {
     /**
      * Constructor
      *
@@ -28,7 +27,7 @@ public BuildOperator(Vertx vertx, OpenShiftClient client) {
     }
 
     @Override
-    protected MixedOperation<Build, BuildList, DoneableBuild, BuildResource<Build, DoneableBuild, String, LogWatch>> operation() {
+    protected MixedOperation<Build, BuildList, BuildResource<Build, LogWatch>> operation() {
         return client.builds();
     }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ConfigMapOperator.java
Patch:
@@ -6,7 +6,6 @@
 
 import io.fabric8.kubernetes.api.model.ConfigMap;
 import io.fabric8.kubernetes.api.model.ConfigMapList;
-import io.fabric8.kubernetes.api.model.DoneableConfigMap;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -19,7 +18,7 @@
 /**
  * Operations for {@code ConfigMap}s.
  */
-public class ConfigMapOperator extends AbstractResourceOperator<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>> {
+public class ConfigMapOperator extends AbstractResourceOperator<KubernetesClient, ConfigMap, ConfigMapList, Resource<ConfigMap>> {
     /**
      * Constructor
      * @param vertx The Vertx instance
@@ -30,7 +29,7 @@ public ConfigMapOperator(Vertx vertx, KubernetesClient client) {
     }
 
     @Override
-    protected MixedOperation<ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>> operation() {
+    protected MixedOperation<ConfigMap, ConfigMapList, Resource<ConfigMap>> operation() {
         return client.configMaps();
     }
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/DeploymentOperator.java
Patch:
@@ -7,7 +7,6 @@
 import io.fabric8.kubernetes.api.model.Pod;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.apps.DeploymentList;
-import io.fabric8.kubernetes.api.model.apps.DoneableDeployment;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.RollableScalableResource;
@@ -19,7 +18,7 @@
 /**
  * Operations for {@code Deployment}s.
  */
-public class DeploymentOperator extends AbstractScalableResourceOperator<KubernetesClient, Deployment, DeploymentList, DoneableDeployment, RollableScalableResource<Deployment, DoneableDeployment>> {
+public class DeploymentOperator extends AbstractScalableResourceOperator<KubernetesClient, Deployment, DeploymentList, RollableScalableResource<Deployment>> {
 
     private final PodOperator podOperations;
 
@@ -38,7 +37,7 @@ public DeploymentOperator(Vertx vertx, KubernetesClient client, PodOperator podO
     }
 
     @Override
-    protected MixedOperation<Deployment, DeploymentList, DoneableDeployment, RollableScalableResource<Deployment, DoneableDeployment>> operation() {
+    protected MixedOperation<Deployment, DeploymentList, RollableScalableResource<Deployment>> operation() {
         return client.apps().deployments();
     }
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/EndpointOperator.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.DoneableEndpoints;
 import io.fabric8.kubernetes.api.model.Endpoints;
 import io.fabric8.kubernetes.api.model.EndpointsList;
 import io.fabric8.kubernetes.client.KubernetesClient;
@@ -15,7 +14,7 @@
 /**
  * Operations for {@code Endpoint}s.
  */
-public class EndpointOperator extends AbstractReadyResourceOperator<KubernetesClient, Endpoints, EndpointsList, DoneableEndpoints, Resource<Endpoints, DoneableEndpoints>> {
+public class EndpointOperator extends AbstractReadyResourceOperator<KubernetesClient, Endpoints, EndpointsList, Resource<Endpoints>> {
     /**
      * Constructor
      * @param vertx The Vertx instance
@@ -26,7 +25,7 @@ public class EndpointOperator extends AbstractReadyResourceOperator<KubernetesCl
     }
 
     @Override
-    protected MixedOperation<Endpoints, EndpointsList, DoneableEndpoints, Resource<Endpoints, DoneableEndpoints>> operation() {
+    protected MixedOperation<Endpoints, EndpointsList, Resource<Endpoints>> operation() {
         return client.endpoints();
     }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ImageStreamOperator.java
Patch:
@@ -6,7 +6,6 @@
 
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
-import io.fabric8.openshift.api.model.DoneableImageStream;
 import io.fabric8.openshift.api.model.ImageStream;
 import io.fabric8.openshift.api.model.ImageStreamList;
 import io.fabric8.openshift.client.OpenShiftClient;
@@ -15,7 +14,7 @@
 /**
  * Operations for {@code ImageStream}s.
  */
-public class ImageStreamOperator extends AbstractResourceOperator<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>> {
+public class ImageStreamOperator extends AbstractResourceOperator<OpenShiftClient, ImageStream, ImageStreamList, Resource<ImageStream>> {
     /**
      * Constructor
      * @param vertx The Vertx instance
@@ -26,7 +25,7 @@ public ImageStreamOperator(Vertx vertx, OpenShiftClient client) {
     }
 
     @Override
-    protected MixedOperation<ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>> operation() {
+    protected MixedOperation<ImageStream, ImageStreamList, Resource<ImageStream>> operation() {
         return client.imageStreams();
     }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/NetworkPolicyOperator.java
Patch:
@@ -4,23 +4,22 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.networking.v1.DoneableNetworkPolicy;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyList;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.vertx.core.Vertx;
 
-public class NetworkPolicyOperator extends AbstractResourceOperator<KubernetesClient, NetworkPolicy, NetworkPolicyList, DoneableNetworkPolicy, Resource<NetworkPolicy, DoneableNetworkPolicy>> {
+public class NetworkPolicyOperator extends AbstractResourceOperator<KubernetesClient, NetworkPolicy, NetworkPolicyList, Resource<NetworkPolicy>> {
 
     public NetworkPolicyOperator(Vertx vertx, KubernetesClient client) {
         super(vertx, client, "NetworkPolicy");
 
     }
 
     @Override
-    protected MixedOperation<NetworkPolicy, NetworkPolicyList, DoneableNetworkPolicy, Resource<NetworkPolicy, DoneableNetworkPolicy>> operation() {
+    protected MixedOperation<NetworkPolicy, NetworkPolicyList, Resource<NetworkPolicy>> operation() {
         return client.network().networkPolicies();
     }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/NodeOperator.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.DoneableNode;
 import io.fabric8.kubernetes.api.model.Node;
 import io.fabric8.kubernetes.api.model.NodeList;
 import io.fabric8.kubernetes.client.KubernetesClient;
@@ -13,7 +12,7 @@
 import io.vertx.core.Vertx;
 
 public class NodeOperator extends AbstractNonNamespacedResourceOperator<KubernetesClient,
-        Node, NodeList, DoneableNode, Resource<Node, DoneableNode>> {
+        Node, NodeList, Resource<Node>> {
 
     /**
      * Constructor.
@@ -25,7 +24,7 @@ public NodeOperator(Vertx vertx, KubernetesClient client) {
     }
 
     @Override
-    protected NonNamespaceOperation<Node, NodeList, DoneableNode, Resource<Node, DoneableNode>> operation() {
+    protected NonNamespaceOperation<Node, NodeList, Resource<Node>> operation() {
         return client.nodes();
     }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/PodDisruptionBudgetOperator.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.policy.DoneablePodDisruptionBudget;
 import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
 import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudgetList;
 import io.fabric8.kubernetes.client.KubernetesClient;
@@ -13,15 +12,15 @@
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
 
-public class PodDisruptionBudgetOperator extends AbstractResourceOperator<KubernetesClient, PodDisruptionBudget, PodDisruptionBudgetList, DoneablePodDisruptionBudget, Resource<PodDisruptionBudget, DoneablePodDisruptionBudget>> {
+public class PodDisruptionBudgetOperator extends AbstractResourceOperator<KubernetesClient, PodDisruptionBudget, PodDisruptionBudgetList, Resource<PodDisruptionBudget>> {
 
     public PodDisruptionBudgetOperator(Vertx vertx, KubernetesClient client) {
         super(vertx, client, "PodDisruptionBudget");
 
     }
 
     @Override
-    protected MixedOperation<PodDisruptionBudget, PodDisruptionBudgetList, DoneablePodDisruptionBudget, Resource<PodDisruptionBudget, DoneablePodDisruptionBudget>> operation() {
+    protected MixedOperation<PodDisruptionBudget, PodDisruptionBudgetList, Resource<PodDisruptionBudget>> operation() {
         return client.policy().podDisruptionBudget();
     }
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/PvcOperator.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.DoneablePersistentVolumeClaim;
 import io.fabric8.kubernetes.api.model.PersistentVolumeClaim;
 import io.fabric8.kubernetes.api.model.PersistentVolumeClaimList;
 import io.fabric8.kubernetes.client.KubernetesClient;
@@ -16,7 +15,7 @@
 /**
  * Operations for {@code PersistentVolumeClaim}s.
  */
-public class PvcOperator extends AbstractResourceOperator<KubernetesClient, PersistentVolumeClaim, PersistentVolumeClaimList, DoneablePersistentVolumeClaim, Resource<PersistentVolumeClaim, DoneablePersistentVolumeClaim>> {
+public class PvcOperator extends AbstractResourceOperator<KubernetesClient, PersistentVolumeClaim, PersistentVolumeClaimList, Resource<PersistentVolumeClaim>> {
     /**
      * Constructor
      * @param vertx The Vertx instance
@@ -27,7 +26,7 @@ public PvcOperator(Vertx vertx, KubernetesClient client) {
     }
 
     @Override
-    protected MixedOperation<PersistentVolumeClaim, PersistentVolumeClaimList, DoneablePersistentVolumeClaim, Resource<PersistentVolumeClaim, DoneablePersistentVolumeClaim>> operation() {
+    protected MixedOperation<PersistentVolumeClaim, PersistentVolumeClaimList, Resource<PersistentVolumeClaim>> operation() {
         return client.persistentVolumeClaims();
     }
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/SecretOperator.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.DoneableSecret;
 import io.fabric8.kubernetes.api.model.Secret;
 import io.fabric8.kubernetes.api.model.SecretList;
 import io.fabric8.kubernetes.client.KubernetesClient;
@@ -15,7 +14,7 @@
 /**
  * Operations for {@code Secret}s.
  */
-public class SecretOperator extends AbstractResourceOperator<KubernetesClient, Secret, SecretList, DoneableSecret, Resource<Secret, DoneableSecret>> {
+public class SecretOperator extends AbstractResourceOperator<KubernetesClient, Secret, SecretList, Resource<Secret>> {
 
     /**
      * Constructor
@@ -27,7 +26,7 @@ public SecretOperator(Vertx vertx, KubernetesClient client) {
     }
 
     @Override
-    protected MixedOperation<Secret, SecretList, DoneableSecret, Resource<Secret, DoneableSecret>> operation() {
+    protected MixedOperation<Secret, SecretList, Resource<Secret>> operation() {
         return client.secrets();
     }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ServiceAccountOperator.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.DoneableServiceAccount;
 import io.fabric8.kubernetes.api.model.ServiceAccount;
 import io.fabric8.kubernetes.api.model.ServiceAccountList;
 import io.fabric8.kubernetes.client.KubernetesClient;
@@ -13,7 +12,7 @@
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
 
-public class ServiceAccountOperator extends AbstractResourceOperator<KubernetesClient, ServiceAccount, ServiceAccountList, DoneableServiceAccount, Resource<ServiceAccount, DoneableServiceAccount>> {
+public class ServiceAccountOperator extends AbstractResourceOperator<KubernetesClient, ServiceAccount, ServiceAccountList, Resource<ServiceAccount>> {
 
     /**
      * Constructor
@@ -25,7 +24,7 @@ public ServiceAccountOperator(Vertx vertx, KubernetesClient client) {
     }
 
     @Override
-    protected MixedOperation<ServiceAccount, ServiceAccountList, DoneableServiceAccount, Resource<ServiceAccount, DoneableServiceAccount>> operation() {
+    protected MixedOperation<ServiceAccount, ServiceAccountList, Resource<ServiceAccount>> operation() {
         return client.serviceAccounts();
     }
 

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/BuildConfigOperatorTest.java
Patch:
@@ -10,7 +10,6 @@
 import io.fabric8.openshift.api.model.BuildConfigBuilder;
 import io.fabric8.openshift.api.model.BuildConfigList;
 import io.fabric8.openshift.api.model.BuildTriggerPolicy;
-import io.fabric8.openshift.api.model.DoneableBuildConfig;
 import io.fabric8.openshift.client.OpenShiftClient;
 import io.fabric8.openshift.client.dsl.BuildConfigResource;
 import io.vertx.core.Vertx;
@@ -20,7 +19,7 @@
 import static org.mockito.Mockito.when;
 
 public class BuildConfigOperatorTest extends AbstractResourceOperatorTest<OpenShiftClient, BuildConfig,
-        BuildConfigList, DoneableBuildConfig, BuildConfigResource<BuildConfig, DoneableBuildConfig, Void, Build>> {
+        BuildConfigList, BuildConfigResource<BuildConfig, Void, Build>> {
 
     @Override
     protected void mocker(OpenShiftClient mockClient, MixedOperation mockCms) {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/BuildOperatorTest.java
Patch:
@@ -9,14 +9,13 @@
 import io.fabric8.openshift.api.model.Build;
 import io.fabric8.openshift.api.model.BuildBuilder;
 import io.fabric8.openshift.api.model.BuildList;
-import io.fabric8.openshift.api.model.DoneableBuild;
 import io.fabric8.openshift.client.OpenShiftClient;
 import io.fabric8.openshift.client.dsl.BuildResource;
 import io.vertx.core.Vertx;
 
 import static org.mockito.Mockito.when;
 
-public class BuildOperatorTest extends AbstractResourceOperatorTest<OpenShiftClient, Build, BuildList, DoneableBuild, BuildResource<Build, DoneableBuild, String, LogWatch>> {
+public class BuildOperatorTest extends AbstractResourceOperatorTest<OpenShiftClient, Build, BuildList, BuildResource<Build, LogWatch>> {
 
     @Override
     protected void mocker(OpenShiftClient mockClient, MixedOperation mockCms) {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ConfigMapOperatorTest.java
Patch:
@@ -7,7 +7,6 @@
 import io.fabric8.kubernetes.api.model.ConfigMap;
 import io.fabric8.kubernetes.api.model.ConfigMapBuilder;
 import io.fabric8.kubernetes.api.model.ConfigMapList;
-import io.fabric8.kubernetes.api.model.DoneableConfigMap;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -18,15 +17,15 @@
 import static java.util.Collections.singletonMap;
 import static org.mockito.Mockito.when;
 
-public class ConfigMapOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>> {
+public class ConfigMapOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, ConfigMap, ConfigMapList, Resource<ConfigMap>> {
 
     @Override
     protected void  mocker(KubernetesClient mockClient, MixedOperation mockCms) {
         when(mockClient.configMaps()).thenReturn(mockCms);
     }
 
     @Override
-    protected AbstractResourceOperator<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>> createResourceOperations(Vertx vertx, KubernetesClient mockClient) {
+    protected AbstractResourceOperator<KubernetesClient, ConfigMap, ConfigMapList, Resource<ConfigMap>> createResourceOperations(Vertx vertx, KubernetesClient mockClient) {
         return new ConfigMapOperator(vertx, mockClient);
     }
 

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/DeploymentConfigOperatorTest.java
Patch:
@@ -9,7 +9,6 @@
 import io.fabric8.openshift.api.model.DeploymentConfig;
 import io.fabric8.openshift.api.model.DeploymentConfigBuilder;
 import io.fabric8.openshift.api.model.DeploymentConfigList;
-import io.fabric8.openshift.api.model.DoneableDeploymentConfig;
 import io.fabric8.openshift.client.OpenShiftClient;
 import io.fabric8.openshift.client.dsl.DeployableScalableResource;
 import io.vertx.core.Vertx;
@@ -19,8 +18,7 @@
 import static org.mockito.Mockito.when;
 
 public class DeploymentConfigOperatorTest extends ScalableResourceOperatorTest<OpenShiftClient, DeploymentConfig,
-        DeploymentConfigList, DoneableDeploymentConfig,
-        DeployableScalableResource<DeploymentConfig, DoneableDeploymentConfig>> {
+        DeploymentConfigList, DeployableScalableResource<DeploymentConfig>> {
 
     @Override
     protected Class<OpenShiftClient> clientType() {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/DeploymentOperatorTest.java
Patch:
@@ -7,7 +7,6 @@
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.apps.DeploymentBuilder;
 import io.fabric8.kubernetes.api.model.apps.DeploymentList;
-import io.fabric8.kubernetes.api.model.apps.DoneableDeployment;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.AppsAPIGroupDSL;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
@@ -18,8 +17,7 @@
 import static org.mockito.Mockito.when;
 
 public class DeploymentOperatorTest extends
-        ScalableResourceOperatorTest<KubernetesClient, Deployment, DeploymentList,
-                                DoneableDeployment, RollableScalableResource<Deployment, DoneableDeployment>> {
+        ScalableResourceOperatorTest<KubernetesClient, Deployment, DeploymentList, RollableScalableResource<Deployment>> {
 
     @Override
     protected Class<KubernetesClient> clientType() {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/EndpointOperatorTest.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.DoneableEndpoints;
 import io.fabric8.kubernetes.api.model.Endpoints;
 import io.fabric8.kubernetes.api.model.EndpointsBuilder;
 import io.fabric8.kubernetes.api.model.EndpointsList;
@@ -15,7 +14,7 @@
 
 import static org.mockito.Mockito.when;
 
-public class EndpointOperatorTest extends AbtractReadyResourceOperatorTest<KubernetesClient, Endpoints, EndpointsList, DoneableEndpoints, Resource<Endpoints, DoneableEndpoints>> {
+public class EndpointOperatorTest extends AbtractReadyResourceOperatorTest<KubernetesClient, Endpoints, EndpointsList, Resource<Endpoints>> {
 
     @Override
     protected Class<KubernetesClient> clientType() {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ImageStreamOperatorTest.java
Patch:
@@ -6,7 +6,6 @@
 
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
-import io.fabric8.openshift.api.model.DoneableImageStream;
 import io.fabric8.openshift.api.model.ImageStream;
 import io.fabric8.openshift.api.model.ImageStreamBuilder;
 import io.fabric8.openshift.api.model.ImageStreamList;
@@ -15,7 +14,7 @@
 
 import static org.mockito.Mockito.when;
 
-public class ImageStreamOperatorTest extends AbstractResourceOperatorTest<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>> {
+public class ImageStreamOperatorTest extends AbstractResourceOperatorTest<OpenShiftClient, ImageStream, ImageStreamList, Resource<ImageStream>> {
 
     @Override
     protected Class<OpenShiftClient> clientType() {
@@ -38,7 +37,7 @@ protected void mocker(OpenShiftClient mockClient, MixedOperation op) {
     }
 
     @Override
-    protected AbstractResourceOperator<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>> createResourceOperations(Vertx vertx, OpenShiftClient mockClient) {
+    protected AbstractResourceOperator<OpenShiftClient, ImageStream, ImageStreamList, Resource<ImageStream>> createResourceOperations(Vertx vertx, OpenShiftClient mockClient) {
         return new ImageStreamOperator(vertx, mockClient);
     }
 

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/IngressOperatorTest.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.extensions.DoneableIngress;
 import io.fabric8.kubernetes.api.model.extensions.Ingress;
 import io.fabric8.kubernetes.api.model.extensions.IngressBuilder;
 import io.fabric8.kubernetes.api.model.extensions.IngressList;
@@ -18,7 +17,7 @@
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 
-public class IngressOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, Ingress, IngressList, DoneableIngress, Resource<Ingress, DoneableIngress>> {
+public class IngressOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, Ingress, IngressList, Resource<Ingress>> {
     @Override
     protected Class<KubernetesClient> clientType() {
         return KubernetesClient.class;
@@ -48,7 +47,7 @@ protected void mocker(KubernetesClient mockClient, MixedOperation op) {
     }
 
     @Override
-    protected AbstractResourceOperator<KubernetesClient, Ingress, IngressList, DoneableIngress, Resource<Ingress, DoneableIngress>> createResourceOperations(Vertx vertx, KubernetesClient mockClient) {
+    protected AbstractResourceOperator<KubernetesClient, Ingress, IngressList, Resource<Ingress>> createResourceOperations(Vertx vertx, KubernetesClient mockClient) {
         return new IngressOperator(vertx, mockClient);
     }
 }

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaBridgeCrdOperatorIT.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaBridgeList;
-import io.strimzi.api.kafka.model.DoneableKafkaBridge;
 import io.strimzi.api.kafka.model.InlineLogging;
 import io.strimzi.api.kafka.model.KafkaBridge;
 import io.strimzi.api.kafka.model.KafkaBridgeBuilder;
@@ -30,12 +29,12 @@
  * test them against real clusters.
  */
 @ExtendWith(VertxExtension.class)
-public class KafkaBridgeCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaBridge, KafkaBridgeList, DoneableKafkaBridge> {
+public class KafkaBridgeCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaBridge, KafkaBridgeList> {
     protected static final Logger log = LogManager.getLogger(KafkaBridgeCrdOperatorIT.class);
 
     @Override
     protected CrdOperator operator() {
-        return new CrdOperator(vertx, client, KafkaBridge.class, KafkaBridgeList.class, DoneableKafkaBridge.class, Crds.kafkaBridge());
+        return new CrdOperator(vertx, client, KafkaBridge.class, KafkaBridgeList.class, Crds.kafkaBridge());
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectCrdOperatorIT.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaConnectList;
-import io.strimzi.api.kafka.model.DoneableKafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectBuilder;
 import io.vertx.junit5.VertxExtension;
@@ -27,12 +26,12 @@
  * test them against real clusters.
  */
 @ExtendWith(VertxExtension.class)
-public class KafkaConnectCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaConnect, KafkaConnectList, DoneableKafkaConnect> {
+public class KafkaConnectCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaConnect, KafkaConnectList> {
     protected static final Logger log = LogManager.getLogger(KafkaConnectCrdOperatorIT.class);
 
     @Override
     protected CrdOperator operator() {
-        return new CrdOperator(vertx, client, KafkaConnect.class, KafkaConnectList.class, DoneableKafkaConnect.class, Crds.kafkaConnect());
+        return new CrdOperator(vertx, client, KafkaConnect.class, KafkaConnectList.class, Crds.kafkaConnect());
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectS2ICrdOperatorIT.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaConnectS2IList;
-import io.strimzi.api.kafka.model.DoneableKafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaConnectS2IBuilder;
 import io.vertx.junit5.VertxExtension;
@@ -27,12 +26,12 @@
  * test them against real clusters.
  */
 @ExtendWith(VertxExtension.class)
-public class KafkaConnectS2ICrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaConnectS2I, KafkaConnectS2IList, DoneableKafkaConnectS2I> {
+public class KafkaConnectS2ICrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaConnectS2I, KafkaConnectS2IList> {
     protected static final Logger log = LogManager.getLogger(KafkaConnectS2ICrdOperatorIT.class);
 
     @Override
     protected CrdOperator operator() {
-        return new CrdOperator(vertx, client, KafkaConnectS2I.class, KafkaConnectS2IList.class, DoneableKafkaConnectS2I.class, Crds.kafkaConnectS2I());
+        return new CrdOperator(vertx, client, KafkaConnectS2I.class, KafkaConnectS2IList.class, Crds.kafkaConnectS2I());
 
     }
 

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectorCrdOperatorIT.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaConnectorList;
-import io.strimzi.api.kafka.model.DoneableKafkaConnector;
 import io.strimzi.api.kafka.model.KafkaConnector;
 import io.strimzi.api.kafka.model.KafkaConnectorBuilder;
 import io.vertx.junit5.VertxExtension;
@@ -27,12 +26,12 @@
  * test them against real clusters.
  */
 @ExtendWith(VertxExtension.class)
-public class KafkaConnectorCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaConnector, KafkaConnectorList, DoneableKafkaConnector> {
+public class KafkaConnectorCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaConnector, KafkaConnectorList> {
     protected static final Logger log = LogManager.getLogger(KafkaConnectorCrdOperatorIT.class);
 
     @Override
     protected CrdOperator operator() {
-        return new CrdOperator(vertx, client, KafkaConnector.class, KafkaConnectorList.class, DoneableKafkaConnector.class, Crds.kafkaConnector());
+        return new CrdOperator(vertx, client, KafkaConnector.class, KafkaConnectorList.class, Crds.kafkaConnector());
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorIT.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaList;
-import io.strimzi.api.kafka.model.DoneableKafka;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;
@@ -29,12 +28,12 @@
  * test them against real clusters.
  */
 @ExtendWith(VertxExtension.class)
-public class KafkaCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, Kafka, KafkaList, DoneableKafka> {
+public class KafkaCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, Kafka, KafkaList> {
     protected static final Logger log = LogManager.getLogger(KafkaCrdOperatorIT.class);
 
     @Override
     protected CrdOperator operator() {
-        return new CrdOperator(vertx, client, Kafka.class, KafkaList.class, DoneableKafka.class, Crds.kafka());
+        return new CrdOperator(vertx, client, Kafka.class, KafkaList.class, Crds.kafka());
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaMirrorMaker2CrdOperatorIT.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaMirrorMaker2List;
-import io.strimzi.api.kafka.model.DoneableKafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2Builder;
 import io.vertx.junit5.VertxExtension;
@@ -27,12 +26,12 @@
  * test them against real clusters.
  */
 @ExtendWith(VertxExtension.class)
-public class KafkaMirrorMaker2CrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaMirrorMaker2, KafkaMirrorMaker2List, DoneableKafkaMirrorMaker2> {
+public class KafkaMirrorMaker2CrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaMirrorMaker2, KafkaMirrorMaker2List> {
     protected static final Logger log = LogManager.getLogger(KafkaMirrorMaker2CrdOperatorIT.class);
 
     @Override
     protected CrdOperator operator() {
-        return new CrdOperator(vertx, client, KafkaMirrorMaker2.class, KafkaMirrorMaker2List.class, DoneableKafkaMirrorMaker2.class, Crds.kafkaMirrorMaker2());
+        return new CrdOperator(vertx, client, KafkaMirrorMaker2.class, KafkaMirrorMaker2List.class, Crds.kafkaMirrorMaker2());
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaMirrorMakerCrdOperatorIT.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaMirrorMakerList;
-import io.strimzi.api.kafka.model.DoneableKafkaMirrorMaker;
 import io.strimzi.api.kafka.model.InlineLogging;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerBuilder;
@@ -28,12 +27,12 @@
  * test them against real clusters.
  */
 @ExtendWith(VertxExtension.class)
-public class KafkaMirrorMakerCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList, DoneableKafkaMirrorMaker> {
+public class KafkaMirrorMakerCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList> {
     protected static final Logger log = LogManager.getLogger(KafkaMirrorMakerCrdOperatorIT.class);
 
     @Override
     protected CrdOperator operator() {
-        return new CrdOperator(vertx, client, KafkaMirrorMaker.class, KafkaMirrorMakerList.class, DoneableKafkaMirrorMaker.class, Crds.kafkaMirrorMaker());
+        return new CrdOperator(vertx, client, KafkaMirrorMaker.class, KafkaMirrorMakerList.class, Crds.kafkaMirrorMaker());
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaUserCrdOperatorIT.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaUserList;
-import io.strimzi.api.kafka.model.DoneableKafkaUser;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.KafkaUserBuilder;
 import io.vertx.junit5.VertxExtension;
@@ -27,12 +26,12 @@
  * test them against real clusters.
  */
 @ExtendWith(VertxExtension.class)
-public class KafkaUserCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaUser, KafkaUserList, DoneableKafkaUser> {
+public class KafkaUserCrdOperatorIT extends AbstractCustomResourceOperatorIT<KubernetesClient, KafkaUser, KafkaUserList> {
     protected static final Logger log = LogManager.getLogger(KafkaUserCrdOperatorIT.class);
 
     @Override
     protected CrdOperator operator() {
-        return new CrdOperator(vertx, client, KafkaUser.class, KafkaUserList.class, DoneableKafkaUser.class, Crds.kafkaUser());
+        return new CrdOperator(vertx, client, KafkaUser.class, KafkaUserList.class, Crds.kafkaUser());
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/PodOperatorTest.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.DoneablePod;
 import io.fabric8.kubernetes.api.model.Pod;
 import io.fabric8.kubernetes.api.model.PodBuilder;
 import io.fabric8.kubernetes.api.model.PodList;
@@ -28,7 +27,7 @@
 import static org.mockito.Mockito.when;
 
 public class PodOperatorTest extends
-        AbtractReadyResourceOperatorTest<KubernetesClient, Pod, PodList, DoneablePod, PodResource<Pod, DoneablePod>> {
+        AbtractReadyResourceOperatorTest<KubernetesClient, Pod, PodList, PodResource<Pod>> {
     @Test
     public void testCreateReadUpdate(VertxTestContext context) {
         vertx.createSharedWorkerExecutor("kubernetes-ops-pool", 10);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/PvcOperatorTest.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.DoneablePersistentVolumeClaim;
 import io.fabric8.kubernetes.api.model.LabelSelector;
 import io.fabric8.kubernetes.api.model.PersistentVolumeClaim;
 import io.fabric8.kubernetes.api.model.PersistentVolumeClaimBuilder;
@@ -23,7 +22,7 @@
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 
-public class PvcOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, PersistentVolumeClaim, PersistentVolumeClaimList, DoneablePersistentVolumeClaim, Resource<PersistentVolumeClaim, DoneablePersistentVolumeClaim>> {
+public class PvcOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, PersistentVolumeClaim, PersistentVolumeClaimList, Resource<PersistentVolumeClaim>> {
 
     @Override
     protected Class<KubernetesClient> clientType() {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/RouteOperatorTest.java
Patch:
@@ -6,7 +6,6 @@
 
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
-import io.fabric8.openshift.api.model.DoneableRoute;
 import io.fabric8.openshift.api.model.Route;
 import io.fabric8.openshift.api.model.RouteBuilder;
 import io.fabric8.openshift.api.model.RouteList;
@@ -15,7 +14,7 @@
 
 import static org.mockito.Mockito.when;
 
-public class RouteOperatorTest extends AbstractResourceOperatorTest<OpenShiftClient, Route, RouteList, DoneableRoute, Resource<Route, DoneableRoute>> {
+public class RouteOperatorTest extends AbstractResourceOperatorTest<OpenShiftClient, Route, RouteList, Resource<Route>> {
     @Override
     protected Class<OpenShiftClient> clientType() {
         return OpenShiftClient.class;
@@ -37,7 +36,7 @@ protected void mocker(OpenShiftClient mockClient, MixedOperation op) {
     }
 
     @Override
-    protected AbstractResourceOperator<OpenShiftClient, Route, RouteList, DoneableRoute, Resource<Route, DoneableRoute>> createResourceOperations(Vertx vertx, OpenShiftClient mockClient) {
+    protected AbstractResourceOperator<OpenShiftClient, Route, RouteList, Resource<Route>> createResourceOperations(Vertx vertx, OpenShiftClient mockClient) {
         return new RouteOperator(vertx, mockClient);
     }
 }

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/SecretOperatorTest.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.DoneableSecret;
 import io.fabric8.kubernetes.api.model.Secret;
 import io.fabric8.kubernetes.api.model.SecretBuilder;
 import io.fabric8.kubernetes.api.model.SecretList;
@@ -16,7 +15,7 @@
 import static java.util.Collections.singletonMap;
 import static org.mockito.Mockito.when;
 
-public class SecretOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, Secret, SecretList, DoneableSecret, Resource<Secret, DoneableSecret>> {
+public class SecretOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, Secret, SecretList, Resource<Secret>> {
 
 
     @Override
@@ -47,7 +46,7 @@ protected void mocker(KubernetesClient mockClient, MixedOperation op) {
     }
 
     @Override
-    protected AbstractResourceOperator<KubernetesClient, Secret, SecretList, DoneableSecret, Resource<Secret, DoneableSecret>> createResourceOperations(Vertx vertx, KubernetesClient mockClient) {
+    protected AbstractResourceOperator<KubernetesClient, Secret, SecretList, Resource<Secret>> createResourceOperations(Vertx vertx, KubernetesClient mockClient) {
         return new SecretOperator(vertx, mockClient);
     }
 }

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ServiceOperatorTest.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.DoneableService;
 import io.fabric8.kubernetes.api.model.IntOrString;
 import io.fabric8.kubernetes.api.model.Service;
 import io.fabric8.kubernetes.api.model.ServiceBuilder;
@@ -24,7 +23,7 @@
 
 import java.util.Map;
 
-public class ServiceOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, Service, ServiceList, DoneableService, ServiceResource<Service, DoneableService>> {
+public class ServiceOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, Service, ServiceList, ServiceResource<Service>> {
 
     @Override
     protected Class<KubernetesClient> clientType() {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/StorageClassOperatorIT.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.storage.DoneableStorageClass;
 import io.fabric8.kubernetes.api.model.storage.StorageClass;
 import io.fabric8.kubernetes.api.model.storage.StorageClassBuilder;
 import io.fabric8.kubernetes.api.model.storage.StorageClassList;
@@ -20,10 +19,10 @@
 
 @ExtendWith(VertxExtension.class)
 public class StorageClassOperatorIT extends AbstractNonNamespacedResourceOperatorIT<KubernetesClient,
-        StorageClass, StorageClassList, DoneableStorageClass, Resource<StorageClass, DoneableStorageClass>> {
+        StorageClass, StorageClassList, Resource<StorageClass>> {
 
     @Override
-    protected AbstractNonNamespacedResourceOperator<KubernetesClient, StorageClass, StorageClassList, DoneableStorageClass, Resource<StorageClass, DoneableStorageClass>> operator() {
+    protected AbstractNonNamespacedResourceOperator<KubernetesClient, StorageClass, StorageClassList, Resource<StorageClass>> operator() {
         return new StorageClassOperator(vertx, client);
     }
 

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/StorageClassOperatorTest.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
-import io.fabric8.kubernetes.api.model.storage.DoneableStorageClass;
 import io.fabric8.kubernetes.api.model.storage.StorageClass;
 import io.fabric8.kubernetes.api.model.storage.StorageClassBuilder;
 import io.fabric8.kubernetes.api.model.storage.StorageClassList;
@@ -19,7 +18,7 @@
 import static org.mockito.Mockito.when;
 
 public class StorageClassOperatorTest extends AbstractNonNamespacedResourceOperatorTest<KubernetesClient,
-        StorageClass, StorageClassList, DoneableStorageClass, Resource<StorageClass, DoneableStorageClass>> {
+        StorageClass, StorageClassList, Resource<StorageClass>> {
 
     @Override
     protected void mocker(KubernetesClient mockClient, MixedOperation op) {
@@ -30,7 +29,7 @@ protected void mocker(KubernetesClient mockClient, MixedOperation op) {
 
     @Override
     protected AbstractNonNamespacedResourceOperator<KubernetesClient, StorageClass, StorageClassList,
-            DoneableStorageClass, Resource<StorageClass, DoneableStorageClass>> createResourceOperations(
+            Resource<StorageClass>> createResourceOperations(
                     Vertx vertx, KubernetesClient mockClient) {
         return new StorageClassOperator(vertx, mockClient) {
             @Override

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -10,7 +10,6 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaBridgeList;
-import io.strimzi.api.kafka.model.DoneableKafkaBridge;
 import io.strimzi.api.kafka.model.KafkaBridge;
 import io.strimzi.api.kafka.model.KafkaBridgeBuilder;
 import io.strimzi.api.kafka.model.KafkaBridgeResources;
@@ -29,7 +28,7 @@ public class KafkaBridgeResource {
     public static final String PATH_TO_KAFKA_BRIDGE_CONFIG = TestUtils.USER_PATH + "/../examples/bridge/kafka-bridge.yaml";
     public static final String PATH_TO_KAFKA_BRIDGE_METRICS_CONFIG = TestUtils.USER_PATH + "/../examples/metrics/kafka-bridge-metrics.yaml";
 
-    public static MixedOperation<KafkaBridge, KafkaBridgeList, DoneableKafkaBridge, Resource<KafkaBridge, DoneableKafkaBridge>> kafkaBridgeClient() {
+    public static MixedOperation<KafkaBridge, KafkaBridgeList, Resource<KafkaBridge>> kafkaBridgeClient() {
         return Crds.kafkaBridgeOperation(ResourceManager.kubeClient().getClient());
     }
 
@@ -126,6 +125,6 @@ private static KafkaBridge deleteLater(KafkaBridge kafkaBridge) {
     }
 
     public static void replaceBridgeResource(String resourceName, Consumer<KafkaBridge> editor) {
-        ResourceManager.replaceCrdResource(KafkaBridge.class, KafkaBridgeList.class, DoneableKafkaBridge.class, resourceName, editor);
+        ResourceManager.replaceCrdResource(KafkaBridge.class, KafkaBridgeList.class, resourceName, editor);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -12,7 +12,6 @@
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaConnectList;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
-import io.strimzi.api.kafka.model.DoneableKafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectBuilder;
 import io.strimzi.api.kafka.model.KafkaConnectResources;
@@ -33,7 +32,7 @@
 public class KafkaConnectResource {
     public static final String PATH_TO_KAFKA_CONNECT_CONFIG = TestUtils.USER_PATH + "/../examples/connect/kafka-connect.yaml";
 
-    public static MixedOperation<KafkaConnect, KafkaConnectList, DoneableKafkaConnect, Resource<KafkaConnect, DoneableKafkaConnect>> kafkaConnectClient() {
+    public static MixedOperation<KafkaConnect, KafkaConnectList, Resource<KafkaConnect>> kafkaConnectClient() {
         return Crds.kafkaConnectOperation(ResourceManager.kubeClient().getClient());
     }
 
@@ -131,7 +130,7 @@ private static KafkaConnect deleteLater(KafkaConnect kafkaConnect) {
     }
 
     public static void replaceKafkaConnectResource(String resourceName, Consumer<KafkaConnect> editor) {
-        ResourceManager.replaceCrdResource(KafkaConnect.class, KafkaConnectList.class, DoneableKafkaConnect.class, resourceName, editor);
+        ResourceManager.replaceCrdResource(KafkaConnect.class, KafkaConnectList.class, resourceName, editor);
     }
 
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -11,7 +11,6 @@
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaConnectS2IList;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
-import io.strimzi.api.kafka.model.DoneableKafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaConnectS2IBuilder;
 import io.strimzi.api.kafka.model.KafkaConnectS2IResources;
@@ -29,7 +28,7 @@
 
 public class KafkaConnectS2IResource {
 
-    public static MixedOperation<KafkaConnectS2I, KafkaConnectS2IList, DoneableKafkaConnectS2I, Resource<KafkaConnectS2I, DoneableKafkaConnectS2I>> kafkaConnectS2IClient() {
+    public static MixedOperation<KafkaConnectS2I, KafkaConnectS2IList, Resource<KafkaConnectS2I>> kafkaConnectS2IClient() {
         return Crds.kafkaConnectS2iOperation(ResourceManager.kubeClient().getClient());
     }
 
@@ -102,6 +101,6 @@ private static KafkaConnectS2I deleteLater(KafkaConnectS2I kafkaConnectS2I) {
     }
 
     public static void replaceConnectS2IResource(String resourceName, Consumer<KafkaConnectS2I> editor) {
-        ResourceManager.replaceCrdResource(KafkaConnectS2I.class, KafkaConnectS2IList.class, DoneableKafkaConnectS2I.class, resourceName, editor);
+        ResourceManager.replaceCrdResource(KafkaConnectS2I.class, KafkaConnectS2IList.class, resourceName, editor);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -10,7 +10,6 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaConnectorList;
-import io.strimzi.api.kafka.model.DoneableKafkaConnector;
 import io.strimzi.api.kafka.model.KafkaConnector;
 import io.strimzi.api.kafka.model.KafkaConnectorBuilder;
 import io.strimzi.operator.common.model.Labels;
@@ -26,7 +25,7 @@
 public class KafkaConnectorResource {
     public static final String PATH_TO_KAFKA_CONNECTOR_CONFIG = TestUtils.USER_PATH + "/../examples/connect/source-connector.yaml";
 
-    public static MixedOperation<KafkaConnector, KafkaConnectorList, DoneableKafkaConnector, Resource<KafkaConnector, DoneableKafkaConnector>> kafkaConnectorClient() {
+    public static MixedOperation<KafkaConnector, KafkaConnectorList, Resource<KafkaConnector>> kafkaConnectorClient() {
         return Crds.kafkaConnectorOperation(ResourceManager.kubeClient().getClient());
     }
 
@@ -91,6 +90,6 @@ private static KafkaConnector deleteLater(KafkaConnector kafkaConnector) {
     }
 
     public static void replaceKafkaConnectorResource(String resourceName, Consumer<KafkaConnector> editor) {
-        ResourceManager.replaceCrdResource(KafkaConnector.class, KafkaConnectorList.class, DoneableKafkaConnector.class, resourceName, editor);
+        ResourceManager.replaceCrdResource(KafkaConnector.class, KafkaConnectorList.class, resourceName, editor);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -12,7 +12,6 @@
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaMirrorMaker2List;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
-import io.strimzi.api.kafka.model.DoneableKafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2Builder;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2ClusterSpec;
@@ -33,7 +32,7 @@
 public class KafkaMirrorMaker2Resource {
     public static final String PATH_TO_KAFKA_MIRROR_MAKER_2_CONFIG = TestUtils.USER_PATH + "/../examples/mirror-maker/kafka-mirror-maker-2.yaml";
 
-    public static MixedOperation<KafkaMirrorMaker2, KafkaMirrorMaker2List, DoneableKafkaMirrorMaker2, Resource<KafkaMirrorMaker2, DoneableKafkaMirrorMaker2>> kafkaMirrorMaker2Client() {
+    public static MixedOperation<KafkaMirrorMaker2, KafkaMirrorMaker2List, Resource<KafkaMirrorMaker2>> kafkaMirrorMaker2Client() {
         return Crds.kafkaMirrorMaker2Operation(ResourceManager.kubeClient().getClient());
     }
 
@@ -143,7 +142,7 @@ private static KafkaMirrorMaker2 deleteLater(KafkaMirrorMaker2 kafkaMirrorMaker2
     }
 
     public static void replaceKafkaMirrorMaker2Resource(String resourceName, Consumer<KafkaMirrorMaker2> editor) {
-        ResourceManager.replaceCrdResource(KafkaMirrorMaker2.class, KafkaMirrorMaker2List.class, DoneableKafkaMirrorMaker2.class, resourceName, editor);
+        ResourceManager.replaceCrdResource(KafkaMirrorMaker2.class, KafkaMirrorMaker2List.class, resourceName, editor);
     }
 
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -10,7 +10,6 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaMirrorMakerList;
-import io.strimzi.api.kafka.model.DoneableKafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
@@ -29,7 +28,7 @@
 public class KafkaMirrorMakerResource {
     public static final String PATH_TO_KAFKA_MIRROR_MAKER_CONFIG = TestUtils.USER_PATH + "/../examples/mirror-maker/kafka-mirror-maker.yaml";
 
-    public static MixedOperation<KafkaMirrorMaker, KafkaMirrorMakerList, DoneableKafkaMirrorMaker, Resource<KafkaMirrorMaker, DoneableKafkaMirrorMaker>> kafkaMirrorMakerClient() {
+    public static MixedOperation<KafkaMirrorMaker, KafkaMirrorMakerList, Resource<KafkaMirrorMaker>> kafkaMirrorMakerClient() {
         return Crds.mirrorMakerOperation(ResourceManager.kubeClient().getClient());
     }
 
@@ -103,6 +102,6 @@ private static KafkaMirrorMaker deleteLater(KafkaMirrorMaker kafkaMirrorMaker) {
     }
 
     public static void replaceMirrorMakerResource(String resourceName, Consumer<KafkaMirrorMaker> editor) {
-        ResourceManager.replaceCrdResource(KafkaMirrorMaker.class, KafkaMirrorMakerList.class, DoneableKafkaMirrorMaker.class, resourceName, editor);
+        ResourceManager.replaceCrdResource(KafkaMirrorMaker.class, KafkaMirrorMakerList.class, resourceName, editor);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaRebalanceResource.java
Patch:
@@ -10,7 +10,6 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaRebalanceList;
-import io.strimzi.api.kafka.model.DoneableKafkaRebalance;
 import io.strimzi.api.kafka.model.KafkaRebalance;
 import io.strimzi.api.kafka.model.KafkaRebalanceBuilder;
 import io.strimzi.api.kafka.model.balancing.KafkaRebalanceState;
@@ -28,7 +27,7 @@
 public class KafkaRebalanceResource {
     public static final String PATH_TO_KAFKA_REBALANCE_CONFIG = TestUtils.USER_PATH + "/../examples/cruise-control/kafka-rebalance.yaml";
 
-    public static MixedOperation<KafkaRebalance, KafkaRebalanceList, DoneableKafkaRebalance, Resource<KafkaRebalance, DoneableKafkaRebalance>> kafkaRebalanceClient() {
+    public static MixedOperation<KafkaRebalance, KafkaRebalanceList, Resource<KafkaRebalance>> kafkaRebalanceClient() {
         return Crds.kafkaRebalanceOperation(ResourceManager.kubeClient().getClient());
     }
 
@@ -90,6 +89,6 @@ private static KafkaRebalance deleteLater(KafkaRebalance kafkaRebalance) {
     }
 
     public static void replaceKafkaRebalanceResource(String resourceName, Consumer<KafkaRebalance> editor) {
-        ResourceManager.replaceCrdResource(KafkaRebalance.class, KafkaRebalanceList.class, DoneableKafkaRebalance.class, resourceName, editor);
+        ResourceManager.replaceCrdResource(KafkaRebalance.class, KafkaRebalanceList.class, resourceName, editor);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -14,7 +14,6 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaList;
-import io.strimzi.api.kafka.model.DoneableKafka;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetrics;
 import io.strimzi.api.kafka.model.JmxPrometheusExporterMetricsBuilder;
 import io.strimzi.api.kafka.model.Kafka;
@@ -46,7 +45,7 @@ public class KafkaResource {
     private static final String PATH_TO_KAFKA_EPHEMERAL_CONFIG = TestUtils.USER_PATH + "/../examples/kafka/kafka-ephemeral.yaml";
     private static final String PATH_TO_KAFKA_PERSISTENT_CONFIG = TestUtils.USER_PATH + "/../examples/kafka/kafka-persistent.yaml";
 
-    public static MixedOperation<Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> kafkaClient() {
+    public static MixedOperation<Kafka, KafkaList, Resource<Kafka>> kafkaClient() {
         return Crds.kafkaOperation(ResourceManager.kubeClient().getClient());
     }
 
@@ -305,7 +304,7 @@ private static Kafka deleteLater(Kafka kafka) {
     }
 
     public static void replaceKafkaResource(String resourceName, Consumer<Kafka> editor) {
-        ResourceManager.replaceCrdResource(Kafka.class, KafkaList.class, DoneableKafka.class, resourceName, editor);
+        ResourceManager.replaceCrdResource(Kafka.class, KafkaList.class, resourceName, editor);
     }
 
     public static String getKafkaTlsListenerCaCertName(String namespace, String clusterName, String listenerName) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaTopicResource.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaTopicList;
-import io.strimzi.api.kafka.model.DoneableKafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopicBuilder;
 import io.strimzi.operator.common.model.Labels;
@@ -26,7 +25,7 @@ public class KafkaTopicResource {
 
     public static final String PATH_TO_KAFKA_TOPIC_CONFIG = TestUtils.USER_PATH + "/../examples/topic/kafka-topic.yaml";
 
-    public static MixedOperation<KafkaTopic, KafkaTopicList, DoneableKafkaTopic, Resource<KafkaTopic, DoneableKafkaTopic>> kafkaTopicClient() {
+    public static MixedOperation<KafkaTopic, KafkaTopicList, Resource<KafkaTopic>> kafkaTopicClient() {
         return Crds.topicOperation(ResourceManager.kubeClient().getClient());
     }
 
@@ -85,6 +84,6 @@ private static KafkaTopic deleteLater(KafkaTopic kafkaTopic) {
     }
 
     public static void replaceTopicResource(String resourceName, Consumer<KafkaTopic> editor) {
-        ResourceManager.replaceCrdResource(KafkaTopic.class, KafkaTopicList.class, DoneableKafkaTopic.class, resourceName, editor);
+        ResourceManager.replaceCrdResource(KafkaTopic.class, KafkaTopicList.class, resourceName, editor);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaUserResource.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaUserList;
-import io.strimzi.api.kafka.model.DoneableKafkaUser;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.KafkaUserBuilder;
 import io.strimzi.operator.common.model.Labels;
@@ -23,7 +22,7 @@
 public class KafkaUserResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaUserResource.class);
 
-    public static MixedOperation<KafkaUser, KafkaUserList, DoneableKafkaUser, Resource<KafkaUser, DoneableKafkaUser>> kafkaUserClient() {
+    public static MixedOperation<KafkaUser, KafkaUserList, Resource<KafkaUser>> kafkaUserClient() {
         return Crds.kafkaUserOperation(ResourceManager.kubeClient().getClient());
     }
 
@@ -84,6 +83,6 @@ public static KafkaUserBuilder userWithQuota(KafkaUser user, Integer prodRate, I
     }
 
     public static void replaceUserResource(String resourceName, Consumer<KafkaUser> editor) {
-        ResourceManager.replaceCrdResource(KafkaUser.class, KafkaUserList.class, DoneableKafkaUser.class, resourceName, editor);
+        ResourceManager.replaceCrdResource(KafkaUser.class, KafkaUserList.class, resourceName, editor);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/DeploymentUtils.java
Patch:
@@ -35,7 +35,7 @@ private DeploymentUtils() { }
 
     /**
      * Log actual status of deployment with pods
-     * @param deployment - every DoneableDeployment, that HasMetadata and has status (fabric8 status)
+     * @param deployment - every Deployment, that HasMetadata and has status (fabric8 status)
      **/
     public static void logCurrentDeploymentStatus(Deployment deployment) {
         if (deployment != null) {

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -19,7 +19,6 @@
 import io.fabric8.kubernetes.client.dsl.base.CustomResourceDefinitionContext;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaTopicList;
-import io.strimzi.api.kafka.model.DoneableKafkaTopic;
 import io.strimzi.api.kafka.model.EntityOperatorSpec;
 import io.strimzi.api.kafka.model.EntityTopicOperatorSpec;
 import io.strimzi.api.kafka.model.EntityUserOperatorSpec;
@@ -1800,7 +1799,7 @@ protected void tearDownEnvironmentAfterEach() throws Exception {
             .filter(p -> p.getMetadata().getName().startsWith(OPENSHIFT_CLUSTER_NAME))
             .forEach(p -> PodUtils.deletePodWithWait(p.getMetadata().getName()));
 
-        kubeClient().getClient().customResources(CustomResourceDefinitionContext.fromCrd(Crds.kafkaTopic()), KafkaTopic.class, KafkaTopicList.class, DoneableKafkaTopic.class).inNamespace(NAMESPACE).delete();
+        kubeClient().getClient().customResources(CustomResourceDefinitionContext.fromCrd(Crds.kafkaTopic()), KafkaTopic.class, KafkaTopicList.class).inNamespace(NAMESPACE).delete();
         kubeClient().getClient().persistentVolumeClaims().inNamespace(NAMESPACE).delete();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.fabric8.kubernetes.api.model.EnvVar;
 import io.fabric8.kubernetes.api.model.EnvVarBuilder;
+import io.fabric8.kubernetes.api.model.NamespaceBuilder;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicy;
 import io.fabric8.kubernetes.api.model.networking.v1.NetworkPolicyPeerBuilder;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
@@ -282,11 +283,11 @@ void testNPWhenOperatorIsInDifferentNamespaceThanOperand() {
             .endSpec()
             .build());
 
-        kubeClient().getClient().namespaces().withName(NAMESPACE).edit()
+        kubeClient().getClient().namespaces().withName(NAMESPACE).edit(ns -> new NamespaceBuilder()
             .editMetadata()
                 .addToLabels(labels)
             .endMetadata()
-            .done();
+            .build());
 
         cluster.setNamespace(secondNamespace);
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/K8sTopicWatcher.java
Patch:
@@ -5,8 +5,8 @@
 package io.strimzi.operator.topic;
 
 import io.fabric8.kubernetes.api.model.ObjectMeta;
-import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.Watcher;
+import io.fabric8.kubernetes.client.WatcherException;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.vertx.core.AsyncResult;
 import io.vertx.core.Future;
@@ -80,7 +80,7 @@ public boolean shouldReconcile(KafkaTopic kafkaTopic, ObjectMeta metadata) {
     }
 
     @Override
-    public void onClose(KubernetesClientException exception) {
+    public void onClose(WatcherException exception) {
         LOGGER.debug("Closing {}", this);
         if (exception != null) {
             LOGGER.debug("Restarting  topic watcher due to ", exception);

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -11,7 +11,6 @@
 import io.micrometer.prometheus.PrometheusMeterRegistry;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaTopicList;
-import io.strimzi.api.kafka.model.DoneableKafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.operator.common.MicrometerMetricsProvider;
 import io.strimzi.operator.common.Util;
@@ -259,7 +258,7 @@ Future<Void> startWatcher() {
         try {
             LOGGER.debug("Watching KafkaTopics matching {}", config.get(Config.LABELS).labels());
 
-            Session.this.topicWatch = kubeClient.customResources(CustomResourceDefinitionContext.fromCrd(Crds.kafkaTopic()), KafkaTopic.class, KafkaTopicList.class, DoneableKafkaTopic.class)
+            Session.this.topicWatch = kubeClient.customResources(CustomResourceDefinitionContext.fromCrd(Crds.kafkaTopic()), KafkaTopic.class, KafkaTopicList.class)
                     .inNamespace(config.get(Config.NAMESPACE)).withLabels(config.get(Config.LABELS).labels()).watch(watcher);
             LOGGER.debug("Watching setup");
             promise.complete();

File: topic-operator/src/test/java/io/strimzi/operator/topic/K8sImplTest.java
Patch:
@@ -57,9 +57,9 @@ public void testList(VertxTestContext context) {
                 .build());
 
         KubernetesClient mockClient = mock(KubernetesClient.class);
-        MixedOperation<KafkaTopic, KafkaTopicList, TopicOperator.DeleteKafkaTopic, Resource<KafkaTopic, TopicOperator.DeleteKafkaTopic>> mockResources = mock(MixedOperation.class);
-        when(mockClient.customResources(any(CustomResourceDefinitionContext.class), any(Class.class), any(Class.class), any(Class.class))).thenReturn(mockResources);
-        when(mockClient.customResources(any(CustomResourceDefinition.class), any(Class.class), any(Class.class), any(Class.class))).thenReturn(mockResources);
+        MixedOperation<KafkaTopic, KafkaTopicList, Resource<KafkaTopic>> mockResources = mock(MixedOperation.class);
+        when(mockClient.customResources(any(CustomResourceDefinitionContext.class), any(Class.class), any(Class.class))).thenReturn(mockResources);
+        when(mockClient.customResources(any(CustomResourceDefinition.class), any(Class.class), any(Class.class))).thenReturn(mockResources);
         when(mockResources.withLabels(any())).thenReturn(mockResources);
         when(mockResources.inNamespace(any())).thenReturn(mockResources);
         when(mockResources.list()).thenAnswer(invocation -> {

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorBaseIT.java
Patch:
@@ -9,9 +9,9 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
+import io.fabric8.kubernetes.client.dsl.base.CustomResourceDefinitionContext;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaTopicList;
-import io.strimzi.api.kafka.model.DoneableKafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopicBuilder;
 import io.strimzi.api.kafka.model.status.Condition;
@@ -584,8 +584,8 @@ protected void waitForEvent(KafkaTopic kafkaTopic, String expectedMessage, Topic
         }, "Expected an error event");
     }
 
-    protected MixedOperation<KafkaTopic, KafkaTopicList, DoneableKafkaTopic, Resource<KafkaTopic, DoneableKafkaTopic>> operation() {
-        return kubeClient.customResources(Crds.kafkaTopic(), KafkaTopic.class, KafkaTopicList.class, DoneableKafkaTopic.class);
+    protected MixedOperation<KafkaTopic, KafkaTopicList, Resource<KafkaTopic>> operation() {
+        return kubeClient.customResources(CustomResourceDefinitionContext.fromCrd(Crds.kafkaTopic()), KafkaTopic.class, KafkaTopicList.class);
     }
 
     protected void waitForTopicInKafka(String topicName) throws InterruptedException, ExecutionException, TimeoutException {

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorIT.java
Patch:
@@ -20,6 +20,7 @@
 import io.fabric8.kubernetes.api.model.Status;
 import io.fabric8.kubernetes.api.model.StatusBuilder;
 import io.fabric8.kubernetes.client.KubernetesClientException;
+import io.fabric8.kubernetes.client.WatcherException;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopicBuilder;
 import kafka.server.KafkaConfig$;
@@ -318,7 +319,7 @@ public void testRecreateTopicWatcher() throws InterruptedException, ExecutionExc
                 .withCode(HttpURLConnection.HTTP_GONE)
                 .withNewMessage("pokazene")
                 .build();
-        KubernetesClientException e = new KubernetesClientException(status);
+        WatcherException e = new WatcherException(status.toString());
         LOGGER.info("stopping TW");
         session.topicWatch.close();
         session.topicsWatcher.stop();

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorMockTest.java
Patch:
@@ -10,7 +10,6 @@
 import io.micrometer.prometheus.PrometheusMeterRegistry;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaTopicList;
-import io.strimzi.api.kafka.model.DoneableKafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopicBuilder;
 import io.strimzi.operator.common.model.Labels;
@@ -91,7 +90,7 @@ public static void after() throws InterruptedException {
     public void createMockKube(VertxTestContext context) throws Exception {
         MockKube mockKube = new MockKube();
         mockKube.withCustomResourceDefinition(Crds.kafkaTopic(),
-                        KafkaTopic.class, KafkaTopicList.class, DoneableKafkaTopic.class, KafkaTopic::getStatus, KafkaTopic::setStatus);
+                        KafkaTopic.class, KafkaTopicList.class, KafkaTopic::getStatus, KafkaTopic::setStatus);
         kubeClient = mockKube.build();
 
         kafkaCluster = new KafkaCluster();

File: user-operator/src/main/java/io/strimzi/operator/user/Main.java
Patch:
@@ -10,7 +10,6 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaUserList;
-import io.strimzi.api.kafka.model.DoneableKafkaUser;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.certs.OpenSslCertManager;
 import io.strimzi.operator.common.AdminClientProvider;
@@ -79,7 +78,7 @@ static Future<String> run(Vertx vertx, KubernetesClient client, AdminClientProvi
 
         OpenSslCertManager certManager = new OpenSslCertManager();
         SecretOperator secretOperations = new SecretOperator(vertx, client);
-        CrdOperator<KubernetesClient, KafkaUser, KafkaUserList, DoneableKafkaUser> crdOperations = new CrdOperator<>(vertx, client, KafkaUser.class, KafkaUserList.class, DoneableKafkaUser.class, Crds.kafkaUser());
+        CrdOperator<KubernetesClient, KafkaUser, KafkaUserList> crdOperations = new CrdOperator<>(vertx, client, KafkaUser.class, KafkaUserList.class, Crds.kafkaUser());
         return createAdminClient(adminClientProvider, config, secretOperations)
                 .compose(adminClient -> {
                     SimpleAclOperator aclOperations = new SimpleAclOperator(vertx, adminClient);

File: user-operator/src/main/java/io/strimzi/operator/user/operator/KafkaUserOperator.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.api.model.Secret;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.KafkaUserList;
-import io.strimzi.api.kafka.model.DoneableKafkaUser;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.KafkaUserQuotas;
 import io.strimzi.api.kafka.model.KafkaUserSpec;
@@ -48,7 +47,7 @@
  * Operator for a Kafka Users.
  */
 public class KafkaUserOperator extends AbstractOperator<KafkaUser, KafkaUserSpec, KafkaUserStatus,
-        CrdOperator<KubernetesClient, KafkaUser, KafkaUserList, DoneableKafkaUser>> {
+        CrdOperator<KubernetesClient, KafkaUser, KafkaUserList>> {
     private static final Logger log = LogManager.getLogger(KafkaUserOperator.class.getName());
 
     private final SecretOperator secretOperations;
@@ -79,7 +78,7 @@ public class KafkaUserOperator extends AbstractOperator<KafkaUser, KafkaUserSpec
      */
     public KafkaUserOperator(Vertx vertx,
                              CertManager certManager,
-                             CrdOperator<KubernetesClient, KafkaUser, KafkaUserList, DoneableKafkaUser> crdOperator,
+                             CrdOperator<KubernetesClient, KafkaUser, KafkaUserList> crdOperator,
                              Labels labels,
                              SecretOperator secretOperations,
                              ScramShaCredentialsOperator scramShaCredentialOperator,

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -376,8 +376,9 @@ private void performUpgrade(JsonObject testParameters, int produceMessagesCount,
 
         if (testParameters.getBoolean("generateTopics")) {
             // Check that topics weren't deleted/duplicated during upgrade procedures
-            assertThat("KafkaTopic list doesn't have expected size", KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).list().getItems().size(), is(expectedTopicCount));
             List<KafkaTopic> kafkaTopicList = KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).list().getItems();
+            int additionalTopics = testParameters.getInt("additionalTopics", 0);
+            assertThat("KafkaTopic list doesn't have expected size", kafkaTopicList.size(), is(expectedTopicCount + additionalTopics));
             assertThat("KafkaTopic " + topicName + " is not in expected topic list",
                     kafkaTopicList.contains(KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(topicName).get()), is(true));
             for (int x = 0; x < upgradeTopicCount; x++) {

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicOperator.java
Patch:
@@ -60,7 +60,7 @@ class TopicOperator {
     private final Vertx vertx;
     private final Labels labels;
     private final String namespace;
-    private TopicStore topicStore;
+    private final TopicStore topicStore;
     private final Config config;
     private final ConcurrentHashMap<TopicName, Integer> inflight = new ConcurrentHashMap<>();
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/ZkWatcher.java
Patch:
@@ -74,7 +74,7 @@ protected void addChild(String child) {
         Handler<AsyncResult<byte[]>> handler = dataResult -> {
             if (dataResult.succeeded()) {
                 this.children.compute(child, (k, v) -> {
-                    if (v) {
+                    if (v != null && v) {
                         this.notifyOperator(child);
                     }
                     return true;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -3521,7 +3521,7 @@ private final Future<ReconciliationState> getCruiseControlDescription() {
                     metricsCm = Future.succeededFuture(null);
                 }
 
-                CompositeFuture.join(metricsCm, loggingCmFut).compose(metricsAndLoggingCm -> {
+                return CompositeFuture.join(metricsCm, loggingCmFut).compose(metricsAndLoggingCm -> {
                     ConfigMap logAndMetricsConfigMap = cruiseControl.generateMetricsAndLogConfigMap(metricsAndLoggingCm.resultAt(1), metricsAndLoggingCm.resultAt(0));
 
                     Map<String, String> annotations = singletonMap(CruiseControl.ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(ANCILLARY_CM_KEY_LOG_CONFIG));

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectS2ISpec.java
Patch:
@@ -20,7 +20,7 @@
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({ "replicas", "image", "buildResources",
-        "livenessProbe", "readinessProbe", "jvmOptions",
+        "livenessProbe", "readinessProbe", "jvmOptions",  "jmxOptions",
         "affinity", "logging", "metrics", "template"})
 @EqualsAndHashCode(callSuper = true)
 public class KafkaConnectS2ISpec extends KafkaConnectSpec {

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java
Patch:
@@ -25,7 +25,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({ "replicas", "version", "image",
         "bootstrapServers", "tls", "authentication", "config", "resources",
-        "livenessProbe", "readinessProbe", "jvmOptions",
+        "livenessProbe", "readinessProbe", "jvmOptions", "jmxOptions",
         "affinity", "tolerations", "logging", "metrics", "tracing",
         "template", "externalConfiguration"})
 @EqualsAndHashCode(callSuper = true, doNotUseGetters = true)

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaJmxOptions.java
Patch:
@@ -25,7 +25,7 @@ public class KafkaJmxOptions implements UnknownPropertyPreserving, Serializable
     private KafkaJmxAuthentication authentication;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
-    @Description("Authentication configuration for connecting to the Kafka JMX port")
+    @Description("Authentication configuration for connecting to the JMX port")
     @JsonProperty("authentication")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     public KafkaJmxAuthentication getAuthentication() {

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2Spec.java
Patch:
@@ -21,7 +21,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"replicas", "version", "image", "connectCluster", 
         "clusters", "mirrors", "resources", 
-        "livenessProbe", "readinessProbe", "jvmOptions",
+        "livenessProbe", "readinessProbe", "jvmOptions", "jmxOptions",
         "affinity", "tolerations", "logging", "metrics", "tracing", 
         "template", "externalConfiguration"})
 @EqualsAndHashCode(callSuper = true, doNotUseGetters = true)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Cluster.java
Patch:
@@ -125,6 +125,7 @@ private static KafkaConnectSpec buildKafkaConnectSpec(KafkaMirrorMaker2Spec spec
                 .withLivenessProbe(spec.getLivenessProbe())
                 .withReadinessProbe(spec.getReadinessProbe())
                 .withJvmOptions(spec.getJvmOptions())
+                .withJmxOptions(spec.getJmxOptions())
                 .withMetrics(spec.getMetrics())
                 .withMetricsConfig(spec.getMetricsConfig())
                 .withTracing(spec.getTracing())

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -174,6 +174,7 @@ protected Future<KafkaConnectStatus> createOrUpdate(Reconciliation reconciliatio
                     desiredLogging.set(logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG));
                     return configMapOperations.reconcile(namespace, connect.getAncillaryConfigMapName(), logAndMetricsConfigMap);
                 })
+                .compose(i -> kafkaConnectJmxSecret(namespace, kafkaConnect.getMetadata().getName(), connect))
                 .compose(i -> podDisruptionBudgetOperator.reconcile(namespace, connect.getName(), connect.generatePodDisruptionBudget()))
                 .compose(i -> {
                     if (buildState.desiredBuildRevision != null) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -150,6 +150,7 @@ public Future<KafkaConnectS2IStatus> createOrUpdate(Reconciliation reconciliatio
                     desiredLogging.set(logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG));
                     return configMapOperations.reconcile(namespace, connect.getAncillaryConfigMapName(), logAndMetricsConfigMap);
                 })
+                .compose(i -> kafkaConnectJmxSecret(namespace, connect.getName(), connect))
                 .compose(i -> deploymentConfigOperations.reconcile(namespace, connect.getName(), connect.generateDeploymentConfig(annotations, pfa.isOpenshift(), imagePullPolicy, imagePullSecrets)))
                 .compose(i -> imagesStreamOperations.reconcile(namespace, KafkaConnectS2IResources.sourceImageStreamName(connect.getCluster()), connect.generateSourceImageStream()))
                 .compose(i -> imagesStreamOperations.reconcile(namespace, KafkaConnectS2IResources.targetImageStreamName(connect.getCluster()), connect.generateTargetImageStream()))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -160,6 +160,7 @@ protected Future<KafkaMirrorMaker2Status> createOrUpdate(Reconciliation reconcil
                     desiredLogging.set(logAndMetricsConfigMap.getData().get(AbstractModel.ANCILLARY_CM_KEY_LOG_CONFIG));
                     return configMapOperations.reconcile(namespace, mirrorMaker2Cluster.getAncillaryConfigMapName(), logAndMetricsConfigMap);
                 })
+                .compose(i -> kafkaConnectJmxSecret(namespace, mirrorMaker2Cluster.getName(), mirrorMaker2Cluster))
                 .compose(i -> podDisruptionBudgetOperator.reconcile(namespace, mirrorMaker2Cluster.getName(), mirrorMaker2Cluster.generatePodDisruptionBudget()))
                 .compose(i -> deploymentOperations.reconcile(namespace, mirrorMaker2Cluster.getName(), mirrorMaker2Cluster.generateDeployment(annotations, pfa.isOpenshift(), imagePullPolicy, imagePullSecrets)))
                 .compose(i -> deploymentOperations.scaleUp(namespace, mirrorMaker2Cluster.getName(), mirrorMaker2Cluster.getReplicas()))

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/JobUtils.java
Patch:
@@ -35,7 +35,7 @@ public static void waitForJobDeletion(String name) {
      * @param name name of the job
      */
     public static void deleteJobWithWait(String namespace, String name) {
-        kubeClient().deleteJob(name);
+        kubeClient(namespace).deleteJob(name);
         waitForJobDeletion(name);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -143,7 +143,7 @@ protected void installClusterOperator(String namespace, List<String> bindingsNam
                 applyBindings(namespace, bindingsNamespaces);
             }
             // 060-Deployment
-            BundleResource.clusterOperator(namespace, operationTimeout, reconciliationInterval).done();
+            BundleResource.create(BundleResource.clusterOperator(namespace, operationTimeout, reconciliationInterval).build());
         }
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeAbstractST.java
Patch:
@@ -29,7 +29,7 @@ public class HttpBridgeAbstractST extends AbstractST {
     protected WebClient client;
     protected static KafkaBridgeExampleClients kafkaBridgeClientJob;
 
-    void deployClusterOperator(String namespace) throws Exception {
+    void deployClusterOperator(String namespace) {
         ResourceManager.setClassResources();
         installClusterOperator(namespace);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlApiST.java
Patch:
@@ -111,10 +111,10 @@ void testCruiseControlBasicAPIRequests()  {
     }
 
     @BeforeAll
-    void setup() throws Exception {
+    void setup() {
         ResourceManager.setClassResources();
         installClusterOperator(NAMESPACE);
 
-        KafkaResource.kafkaWithCruiseControl(cruiseControlApiClusterName, 3, 3).done();
+        KafkaResource.create(KafkaResource.kafkaWithCruiseControl(cruiseControlApiClusterName, 3, 3).build());
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlConfigurationST.java
Patch:
@@ -285,10 +285,10 @@ void testConfigurationPerformanceOptions() throws IOException {
     }
     
     @BeforeAll
-    void setup() throws Exception {
+    void setup() {
         ResourceManager.setClassResources();
         installClusterOperator(NAMESPACE);
 
-        KafkaResource.kafkaWithCruiseControl(CRUISE_CONTROL_CONFIGURATION_CLUSTER_NAME, 3, 3).done();
+        KafkaResource.create(KafkaResource.kafkaWithCruiseControl(CRUISE_CONTROL_CONFIGURATION_CLUSTER_NAME, 3, 3).build());
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationSharedST.java
Patch:
@@ -179,11 +179,11 @@ private static Map<String, Object> generateTestCases(String kafkaVersion) {
     }
 
     @BeforeAll
-    void setup() throws Exception {
+    void setup() {
         ResourceManager.setClassResources();
         installClusterOperator(NAMESPACE);
 
         LOGGER.info("Deploying shared Kafka across all test cases!");
-        KafkaResource.kafkaPersistent(dynamicConfigurationSharedClusterName, 3).done();
+        KafkaResource.create(KafkaResource.kafkaPersistent(dynamicConfigurationSharedClusterName, 3).build());
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAbstractST.java
Patch:
@@ -48,14 +48,14 @@ void doTestDeployExampleKafka() {
     void doTestDeployExampleKafkaUser() {
         String userKafkaName = "user-kafka";
         // KafkaUser example needs Kafka with authorization
-        KafkaResource.kafkaEphemeral(userKafkaName, 1, 1)
+        KafkaResource.create(KafkaResource.kafkaEphemeral(userKafkaName, 1, 1)
             .editSpec()
                 .editKafka()
                     .withNewKafkaAuthorizationSimple()
                     .endKafkaAuthorizationSimple()
                 .endKafka()
             .endSpec()
-            .done();
+            .build());
         JsonObject kafkaUserResource = OlmResource.getExampleResources().get(KafkaUser.RESOURCE_KIND);
         kafkaUserResource.getJsonObject("metadata").getJsonObject("labels").put(Labels.STRIMZI_CLUSTER_LABEL, userKafkaName);
         cmdKubeClient().applyContent(kafkaUserResource.toString());
@@ -109,7 +109,7 @@ void doTestDeployExampleKafkaMirrorMaker2() {
 
     void doTestDeployExampleKafkaRebalance() {
         String cruiseControlClusterName = "cruise-control";
-        KafkaResource.kafkaWithCruiseControl(cruiseControlClusterName, 3, 3).done();
+        KafkaResource.create(KafkaResource.kafkaWithCruiseControl(cruiseControlClusterName, 3, 3).build());
         JsonObject kafkaRebalanceResource = OlmResource.getExampleResources().get(KafkaRebalance.RESOURCE_KIND);
         kafkaRebalanceResource.getJsonObject("metadata").getJsonObject("labels").put(Labels.STRIMZI_CLUSTER_LABEL, cruiseControlClusterName);
         cmdKubeClient().applyContent(kafkaRebalanceResource.toString());

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceRbacScopeOperatorST.java
Patch:
@@ -39,11 +39,11 @@ void testNamespacedRbacScopeDeploysRoles() {
         assumeTrue(Environment.isNamespaceRbacScope());
         prepareEnvironment();
 
-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 3)
+        KafkaResource.create(KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 3)
                 .editMetadata()
                     .addToLabels("app", "strimzi")
                 .endMetadata()
-                .done();
+                .build());
 
         // Wait for Kafka to be Ready to ensure all potentially erroneous ClusterRole applications have happened
         KafkaUtils.waitForKafkaReady(CLUSTER_NAME);
@@ -63,6 +63,6 @@ private void prepareEnvironment() {
         prepareEnvForOperator(NAMESPACE);
         applyBindings(NAMESPACE);
         // 060-Deployment
-        BundleResource.clusterOperator(NAMESPACE).done();
+        BundleResource.create(BundleResource.clusterOperator(NAMESPACE).build());
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java
Patch:
@@ -54,7 +54,7 @@ public class OauthAbstractST extends AbstractST {
     protected WebClient client;
 
     @BeforeAll
-    void setup() throws Exception {
+    void setup() {
         ResourceManager.setClassResources();
         installClusterOperator(NAMESPACE);
         KubernetesResource.applyDefaultNetworkPolicy(NAMESPACE, DefaultNetworkPolicy.DEFAULT_TO_ALLOW);

File: systemtest/src/test/java/io/strimzi/systemtest/specific/HelmChartST.java
Patch:
@@ -27,8 +27,8 @@ class HelmChartST extends AbstractST {
 
     @Test
     void testDeployKafkaClusterViaHelmChart() {
-        KafkaResource.kafkaEphemeral(clusterName, 3).done();
-        KafkaTopicResource.topic(clusterName, TOPIC_NAME).done();
+        KafkaResource.create(KafkaResource.kafkaEphemeral(clusterName, 3).build());
+        KafkaTopicResource.create(KafkaTopicResource.topic(clusterName, TOPIC_NAME).build());
         StatefulSetUtils.waitForAllStatefulSetPodsReady(KafkaResources.zookeeperStatefulSetName(clusterName), 3);
         StatefulSetUtils.waitForAllStatefulSetPodsReady(KafkaResources.kafkaStatefulSetName(clusterName), 3);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java
Patch:
@@ -106,8 +106,8 @@ private void performUpgradeVerification(String fromVersion, String toVersion, Js
             ResourceManager.setMethodResources();
         }
 
-        kafkaBasicClientJob.producerStrimzi().done();
-        kafkaBasicClientJob.consumerStrimzi().done();
+        kafkaBasicClientJob.create(kafkaBasicClientJob.producerStrimzi().build());
+        kafkaBasicClientJob.create(kafkaBasicClientJob.consumerStrimzi().build());
 
         String clusterOperatorDeploymentName = ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_DEPLOYMENT_NAME);
         LOGGER.info("Old deployment name of cluster operator is {}", clusterOperatorDeploymentName);

File: systemtest/src/test/java/io/strimzi/systemtest/utils/KafkaVersionUtilsTest.java
Patch:
@@ -13,7 +13,7 @@
 public class KafkaVersionUtilsTest {
 
     @Test
-    public void parsingTest() throws Exception {
+    public void parsingTest() {
         List<TestKafkaVersion> versions = TestKafkaVersion.getKafkaVersions();
         assertTrue(versions.size() > 0);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -181,7 +181,7 @@ public void applyClusterOperatorInstallFiles(String namespace) {
 
             }
             clusterOperatorConfigs.push(entry.getKey().getPath());
-            cmdKubeClient().clientWithAdmin().namespace(namespace).applyContent(fileContents);
+            cmdKubeClient().namespace(namespace).applyContent(fileContents);
         }
     }
 
@@ -204,7 +204,7 @@ public void deleteClusterOperatorInstallFiles() {
         while (!clusterOperatorConfigs.empty()) {
             String clusterOperatorConfig = clusterOperatorConfigs.pop();
             LOGGER.info("Deleting configuration file: {}", clusterOperatorConfig);
-            cmdKubeClient().clientWithAdmin().delete(clusterOperatorConfig);
+            cmdKubeClient().delete(clusterOperatorConfig);
         }
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -958,7 +958,7 @@ void testKafkaBridgeService() {
      */
     void deleteJaeger() {
         while (!jaegerConfigs.empty()) {
-            cmdKubeClient().clientWithAdmin().namespace(cluster.getNamespace()).deleteContent(jaegerConfigs.pop());
+            cmdKubeClient().namespace(cluster.getNamespace()).deleteContent(jaegerConfigs.pop());
         }
     }
 
@@ -979,7 +979,7 @@ private void deployJaeger() {
                 fileContents = switchClusterRolesToRoles(fileContents);
             }
             jaegerConfigs.push(fileContents);
-            cmdKubeClient().clientWithAdmin().namespace(cluster.getNamespace()).applyContent(fileContents);
+            cmdKubeClient().namespace(cluster.getNamespace()).applyContent(fileContents);
         }
 
         installJaegerInstance();
@@ -1021,7 +1021,7 @@ void installJaegerInstance() {
                 fileContents = switchClusterRolesToRoles(fileContents);
             }
             jaegerConfigs.push(fileContents);
-            cmdKubeClient().clientWithAdmin().namespace(cluster.getNamespace()).applyContent(fileContents);
+            cmdKubeClient().namespace(cluster.getNamespace()).applyContent(fileContents);
         }
     }
 

File: test/src/main/java/io/strimzi/test/k8s/KubeClusterResource.java
Patch:
@@ -196,7 +196,7 @@ public void createCustomResources(String... resources) {
         for (String resource : resources) {
             LOGGER.info("Creating resources {} in Namespace {}", resource, getNamespace());
             deploymentResources.add(resource);
-            cmdKubeClient().clientWithAdmin().namespace(getNamespace()).create(resource);
+            cmdKubeClient().namespace(getNamespace()).create(resource);
         }
     }
 

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/BaseCmdKubeClient.java
Patch:
@@ -63,13 +63,12 @@ public void close() { }
 
     private static final Context NOOP = new Context();
 
-    @Override
-    public abstract K clientWithAdmin();
-
     protected Context defaultContext() {
         return NOOP;
     }
 
+    // Admin contex tis not implemented now, because it's not needed
+    // In case it will be neded in future, we should change the kubeconfig and apply it for both oc and kubectl
     protected Context adminContext() {
         return defaultContext();
     }

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -169,8 +169,6 @@ void testCreateTopicViaAdminClient() throws ExecutionException, InterruptedExcep
     @Tag(NODEPORT_SUPPORTED)
     @Test
     void testCreateDeleteCreate() throws InterruptedException {
-        String clusterName = CLUSTER_NAME + "-sdkvnsdkjn";
-
         KafkaResource.kafkaEphemeral(clusterName, 3, 3)
                 .editSpec()
                     .editKafka()

File: topic-operator/src/main/java/io/strimzi/operator/topic/K8sTopicWatcher.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.Watcher;
 import io.strimzi.api.kafka.model.KafkaTopic;
-import io.strimzi.api.kafka.model.status.KafkaTopicStatus;
 import io.vertx.core.AsyncResult;
 import io.vertx.core.Future;
 import io.vertx.core.Handler;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/CruiseControlUtils.java
Patch:
@@ -66,11 +66,12 @@ public static String callApi(SupportedHttpMethods method, String endpoint) {
 
     @SuppressWarnings("BooleanExpressionComplexity")
     public static void verifyCruiseControlMetricReporterConfigurationInKafkaConfigMapIsPresent(Properties kafkaProperties) {
+        String kafkaClusterName = kafkaProperties.getProperty("cluster-name");
         TestUtils.waitFor("Verify that kafka configuration " + kafkaProperties.toString() + " has correct cruise control metric reporter properties",
             Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_CRUISE_CONTROL_TIMEOUT, () ->
             kafkaProperties.getProperty(CruiseControlConfigurationParameters.METRICS_TOPIC_NAME.getValue()).equals("strimzi.cruisecontrol.metrics") &&
             kafkaProperties.getProperty(CruiseControlConfigurationParameters.METRICS_REPORTER_SSL_ENDPOINT_ID_ALGO.getValue()).equals("HTTPS") &&
-            kafkaProperties.getProperty(CruiseControlConfigurationParameters.METRICS_REPORTER_BOOTSTRAP_SERVERS.getValue()).equals("my-cluster-kafka-brokers:9091") &&
+            kafkaProperties.getProperty(CruiseControlConfigurationParameters.METRICS_REPORTER_BOOTSTRAP_SERVERS.getValue()).equals(kafkaClusterName + "-kafka-brokers:9091") &&
             kafkaProperties.getProperty(CruiseControlConfigurationParameters.METRICS_REPORTER_SECURITY_PROTOCOL.getValue()).equals("SSL") &&
             kafkaProperties.getProperty(CruiseControlConfigurationParameters.METRICS_REPORTER_SSL_KEYSTORE_TYPE.getValue()).equals("PKCS12") &&
             kafkaProperties.getProperty(CruiseControlConfigurationParameters.METRICS_REPORTER_SSL_KEYSTORE_LOCATION.getValue()).equals("/tmp/kafka/cluster.keystore.p12") &&
@@ -143,6 +144,7 @@ public static Properties getKafkaCruiseControlMetricsReporterConfiguration(Strin
                 cruiseControlProperties.put(entry.getKey(), entry.getValue());
             }
         }
+        cruiseControlProperties.put("cluster-name", clusterName);
 
         return cruiseControlProperties;
     }

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeAbstractST.java
Patch:
@@ -20,7 +20,7 @@ public class HttpBridgeAbstractST extends AbstractST {
 
     public static int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;
     public static String kafkaClientsPodName = "";
-    public static String bridgeServiceName = KafkaBridgeResources.serviceName(CLUSTER_NAME);
+    public static String bridgeServiceName = KafkaBridgeResources.serviceName(clusterName);
     public static String bridgeUrl = "";
 
     public static String producerName = "bridge-producer";
@@ -39,7 +39,7 @@ void createBridgeClient() {
         kafkaBridgeClientJob = new KafkaBridgeExampleClients.Builder()
             .withProducerName(producerName)
             .withConsumerName(consumerName)
-            .withBootstrapAddress(KafkaBridgeResources.serviceName(CLUSTER_NAME))
+            .withBootstrapAddress(KafkaBridgeResources.serviceName(clusterName))
             .withTopicName(TOPIC_NAME)
             .withMessageCount(MESSAGE_COUNT)
             .withPort(bridgePort)

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlApiST.java
Patch:
@@ -29,8 +29,8 @@ public class CruiseControlApiST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(CruiseControlApiST.class);
     private static final String NAMESPACE = "cruise-control-api-test";
-
     private static final String CRUISE_CONTROL_NAME = "Cruise Control";
+    private final String cruiseControlApiClusterName = "cruise-control-api-cluster-name";
 
     @Test
     void testCruiseControlBasicAPIRequests()  {
@@ -115,6 +115,6 @@ void setup() throws Exception {
         ResourceManager.setClassResources();
         installClusterOperator(NAMESPACE);
 
-        KafkaResource.kafkaWithCruiseControl(CLUSTER_NAME, 3, 3).done();
+        KafkaResource.kafkaWithCruiseControl(cruiseControlApiClusterName, 3, 3).done();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/specific/ClusterOperationST.java
Patch:
@@ -46,7 +46,7 @@ void testAvailabilityDuringNodeDrain() {
         List<String> continuousConsumerGroups = IntStream.range(0, size).boxed().map(i -> "continuous-consumer-group-" + i).collect(Collectors.toList());
         int continuousClientsMessageCount = 300;
 
-        KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 3)
+        KafkaResource.kafkaPersistent(clusterName, 3, 3)
                 .editOrNewSpec()
                     .editEntityOperator()
                         .editUserOperator()
@@ -56,7 +56,7 @@ void testAvailabilityDuringNodeDrain() {
                 .endSpec()
                 .done();
 
-        topicNames.forEach(topicName -> KafkaTopicResource.topic(CLUSTER_NAME, topicName, 3, 3, 2).done());
+        topicNames.forEach(topicName -> KafkaTopicResource.topic(clusterName, topicName, 3, 3, 2).done());
 
         String producerAdditionConfiguration = "delivery.timeout.ms=20000\nrequest.timeout.ms=20000";
         KafkaBasicExampleClients kafkaBasicClientResource;
@@ -65,7 +65,7 @@ void testAvailabilityDuringNodeDrain() {
             kafkaBasicClientResource = new KafkaBasicExampleClients.Builder()
                 .withProducerName(producerNames.get(i))
                 .withConsumerName(consumerNames.get(i))
-                .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))
+                .withBootstrapAddress(KafkaResources.plainBootstrapAddress(clusterName))
                 .withTopicName(topicNames.get(i))
                 .withMessageCount(continuousClientsMessageCount)
                 .withAdditionalConfig(producerAdditionConfiguration)

File: api/src/main/java/io/strimzi/api/kafka/model/template/KafkaConnectTemplate.java
Patch:
@@ -38,7 +38,7 @@ public class KafkaConnectTemplate implements Serializable, UnknownPropertyPreser
     private ContainerTemplate connectContainer;
     private ContainerTemplate initContainer;
     private ContainerTemplate buildContainer;
-    private MetadataTemplate buildConfig;
+    private ResourceTemplate buildConfig;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Description("Template for Kafka Connect `Deployment`.")
@@ -126,11 +126,11 @@ public void setBuildContainer(ContainerTemplate buildContainer) {
     @Description("Template for the Kafka Connect BuildConfig used to build new container images. " +
             "The BuildConfig is used only on OpenShift.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public MetadataTemplate getBuildConfig() {
+    public ResourceTemplate getBuildConfig() {
         return buildConfig;
     }
 
-    public void setBuildConfig(MetadataTemplate buildConfig) {
+    public void setBuildConfig(ResourceTemplate buildConfig) {
         this.buildConfig = buildConfig;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -63,6 +63,7 @@ public class ClusterOperatorConfig {
     public static final String STRIMZI_DEFAULT_KAFKA_INIT_IMAGE = "STRIMZI_DEFAULT_KAFKA_INIT_IMAGE";
     public static final String STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE = "STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE";
     public static final String STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE = "STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE";
+    public static final String STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE = "STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE";
 
     public static final long DEFAULT_FULL_RECONCILIATION_INTERVAL_MS = 120_000;
     public static final long DEFAULT_OPERATION_TIMEOUT_MS = 300_000;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -72,6 +72,7 @@
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.operator.MockCertManager;
 import io.strimzi.operator.common.operator.resource.BuildConfigOperator;
+import io.strimzi.operator.common.operator.resource.BuildOperator;
 import io.strimzi.operator.common.operator.resource.ClusterRoleBindingOperator;
 import io.strimzi.operator.common.operator.resource.ConfigMapOperator;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
@@ -752,6 +753,7 @@ public static ResourceOperatorSupplier supplierWithMocks(boolean openShift) {
                 mock(IngressOperator.class),
                 mock(ImageStreamOperator.class),
                 mock(BuildConfigOperator.class),
+                mock(BuildOperator.class),
                 mock(DeploymentConfigOperator.class),
                 mock(CrdOperator.class),
                 mock(CrdOperator.class),
@@ -766,6 +768,7 @@ public static ResourceOperatorSupplier supplierWithMocks(boolean openShift) {
                 zookeeperScalerProvider(),
                 metricsProvider(),
                 adminClientProvider());
+
         when(supplier.serviceAccountOperations.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.roleBindingOperations.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.roleOperations.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -166,7 +166,7 @@ public void test(VertxTestContext context) {
         KafkaConnectAssemblyOperator operator = new KafkaConnectAssemblyOperator(vertx, pfa,
                 new ResourceOperatorSupplier(
                         null, null, null, null, null, null, null, null, null, null, null,
-                        null, null, null, null, null, null, null, null, null, null, null,
+                        null, null, null, null, null, null, null, null, null, null, null, null,
                         null, null, connectCrdOperator, null, null, null, null, null, metrics, null),
                 ClusterOperatorConfig.fromMap(Collections.emptyMap(), KafkaVersionTestUtils.getKafkaVersionLookup()),
             connect -> new KafkaConnectApiImpl(vertx),

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ResourceSupport.java
Patch:
@@ -55,7 +55,7 @@ public Future<Void> closeOnWorkerThread(Closeable closeable) {
             });
     }
 
-    private <T> Future<T> executeBlocking(Handler<Promise<T>> blockingCodeHandler) {
+    <T> Future<T> executeBlocking(Handler<Promise<T>> blockingCodeHandler) {
         Promise<T> result = Promise.promise();
         vertx.createSharedWorkerExecutor("kubernetes-ops-tool")
                 .executeBlocking(blockingCodeHandler, true, result);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaRollerTest.java
Patch:
@@ -585,7 +585,7 @@ private TestingKafkaRoller(StatefulSet sts, Secret clusterCaCertSecret, Secret c
                                   int... controllers) {
             super(KafkaRollerTest.vertx, new Reconciliation("test", "Kafka", stsNamespace(), clusterName()), podOps, 500, 1000,
                 () -> new BackOff(10L, 2, 4),
-                sts, clusterCaCertSecret, coKeySecret, "", "", KafkaVersionTestUtils.getLatestVersion());
+                sts, clusterCaCertSecret, coKeySecret, "", "", KafkaVersionTestUtils.getLatestVersion(), true);
             this.controllers = controllers;
             this.controllerCall = 0;
             Objects.requireNonNull(acOpenException);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -646,7 +646,8 @@ public Admin createAdminClient(String bootstrapHostnames, Secret clusterCaCertSe
                     Constructor<DescribeClusterResult> declaredConstructor = DescribeClusterResult.class.getDeclaredConstructor(KafkaFuture.class, KafkaFuture.class, KafkaFuture.class, KafkaFuture.class);
                     declaredConstructor.setAccessible(true);
                     KafkaFuture<Node> objectKafkaFuture = KafkaFutureImpl.completedFuture(new Node(0, "localhost", 9091));
-                    dcr = declaredConstructor.newInstance(null, objectKafkaFuture, null, null);
+                    KafkaFuture<String> stringKafkaFuture = KafkaFutureImpl.completedFuture("CLUSTERID");
+                    dcr = declaredConstructor.newInstance(null, objectKafkaFuture, stringKafkaFuture, null);
                 } catch (ReflectiveOperationException e) {
                     throw new RuntimeException(e);
                 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -149,6 +149,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                             .withPriorityClassName(templatePodPriorityClassName)
                             .withSchedulerName(templatePodSchedulerName)
                             .withHostAliases(templatePodHostAliases)
+                            .withTopologySpreadConstraints(templatePodTopologySpreadConstraints)
                         .endSpec()
                     .endTemplate()
                     .withTriggers(configChangeTrigger, imageChangeTrigger)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ModelUtils.java
Patch:
@@ -258,6 +258,7 @@ public static void parsePodTemplate(AbstractModel model, PodTemplate pod)   {
             model.templatePodPriorityClassName = pod.getPriorityClassName();
             model.templatePodSchedulerName = pod.getSchedulerName();
             model.templatePodHostAliases = pod.getHostAliases();
+            model.templatePodTopologySpreadConstraints = pod.getTopologySpreadConstraints();
         }
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -580,7 +580,7 @@ public void testConnectorConnectConnectorConnect() {
         verify(api, times(2)).list(
                 eq(KafkaConnectResources.qualifiedServiceName(connectName, NAMESPACE)), eq(KafkaConnectCluster.REST_API_PORT));
         // triggered three times (Connect creation, Connector Status update, Connect Status update)
-        verify(api, times(3)).createOrUpdatePutRequest(
+        verify(api, times(4)).createOrUpdatePutRequest(
                 eq(KafkaConnectResources.qualifiedServiceName(connectName, NAMESPACE)), eq(KafkaConnectCluster.REST_API_PORT),
                 eq(connectorName), any());
         assertThat(runningConnectors.keySet(), is(Collections.singleton(key("cluster-connect-api.ns.svc", connectorName))));

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/NodeOperatorIT.java
Patch:
@@ -39,6 +39,7 @@ protected Node getOriginal()  {
                 .endMetadata()
                 .withNewSpec()
                     .withNewUnschedulable(true)
+                    .withNewPodCIDR("172.16.3.0/24")
                 .endSpec()
                 .build();
     }
@@ -52,6 +53,7 @@ protected Node getModified()  {
                 .endMetadata()
                 .withNewSpec()
                     .withNewUnschedulable(true)
+                    .withNewPodCIDR("172.16.3.0/24")
                 .endSpec()
                 .build();
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractModelTest.java
Patch:
@@ -203,10 +203,10 @@ public void testDetermineImagePullPolicy()  {
         assertThat(am.determineImagePullPolicy(ImagePullPolicy.IFNOTPRESENT, "docker.io/repo/image:tag"), is(ImagePullPolicy.IFNOTPRESENT.toString()));
         assertThat(am.determineImagePullPolicy(ImagePullPolicy.IFNOTPRESENT, "docker.io/repo/image:latest"), is(ImagePullPolicy.IFNOTPRESENT.toString()));
         assertThat(am.determineImagePullPolicy(ImagePullPolicy.NEVER, "docker.io/repo/image:tag"), is(ImagePullPolicy.NEVER.toString()));
-        assertThat(am.determineImagePullPolicy(ImagePullPolicy.NEVER, "docker.io/repo/image:latest-kafka-2.6.0"), is(ImagePullPolicy.NEVER.toString()));
+        assertThat(am.determineImagePullPolicy(ImagePullPolicy.NEVER, "docker.io/repo/image:latest-kafka-2.7.0"), is(ImagePullPolicy.NEVER.toString()));
         assertThat(am.determineImagePullPolicy(null, "docker.io/repo/image:latest"), is(ImagePullPolicy.ALWAYS.toString()));
         assertThat(am.determineImagePullPolicy(null, "docker.io/repo/image:not-so-latest"), is(ImagePullPolicy.IFNOTPRESENT.toString()));
-        assertThat(am.determineImagePullPolicy(null, "docker.io/repo/image:latest-kafka-2.6.0"), is(ImagePullPolicy.ALWAYS.toString()));
+        assertThat(am.determineImagePullPolicy(null, "docker.io/repo/image:latest-kafka-2.7.0"), is(ImagePullPolicy.ALWAYS.toString()));
     }
 
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConfigurationTests.java
Patch:
@@ -84,7 +84,7 @@ public void passwordType() {
     @Test
     public void invalidVersion() {
         assertConfigError("inter.broker.protocol.version", "dclncswn",
-                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E|\\Q2.5\\E(\\.[0-9]+)*|\\Q2.5-IV0\\E|\\Q2.6\\E(\\.[0-9]+)*|\\Q2.6-IV0\\E");
+                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E|\\Q2.5\\E(\\.[0-9]+)*|\\Q2.5-IV0\\E|\\Q2.6\\E(\\.[0-9]+)*|\\Q2.6-IV0\\E|\\Q2.7\\E(\\.[0-9]+)*|\\Q2.7-IV0\\E|\\Q2.7-IV1\\E|\\Q2.7-IV2\\E");
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiffTest.java
Patch:
@@ -30,7 +30,7 @@
 public class KafkaBrokerConfigurationDiffTest {
 
     private static final KafkaVersion.Lookup VERSIONS = KafkaVersionTestUtils.getKafkaVersionLookup();
-    private static final String KAFKA_VERSION = "2.6.0";
+    private static final String KAFKA_VERSION = "2.7.0";
     KafkaVersion kafkaVersion = VERSIONS.version(KAFKA_VERSION);
     private int brokerId = 0;
 

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -105,7 +105,7 @@ public class Environment {
 
     private static final String SKIP_TEARDOWN_ENV = "SKIP_TEARDOWN";
 
-    private static final String ST_KAFKA_VERSION_DEFAULT = "2.6.0";
+    private static final String ST_KAFKA_VERSION_DEFAULT = "2.7.0";
     public static final String STRIMZI_ORG_DEFAULT = "strimzi";
     public static final String STRIMZI_TAG_DEFAULT = "latest";
     public static final String STRIMZI_REGISTRY_DEFAULT = "quay.io";

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserST.java
Patch:
@@ -191,7 +191,7 @@ void testUserWithQuotas(KafkaUser user) {
         LOGGER.debug("Command for kafka-configs.sh {}", command);
 
         ExecResult result = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), "/bin/bash", "-c", command);
-        assertThat(result.out().contains("Configs for user-principal '" + userName + "' are"), is(true));
+        assertThat(result.out().contains("Quota configs for user-principal '" + userName + "' are"), is(true));
         assertThat(result.out().contains("request_percentage=" + reqPerc), is(true));
         assertThat(result.out().contains("producer_byte_rate=" + prodRate), is(true));
         assertThat(result.out().contains("consumer_byte_rate=" + consRate), is(true));

File: api/src/main/java/io/strimzi/api/kafka/model/listener/arraylistener/GenericKafkaListenerConfiguration.java
Patch:
@@ -124,7 +124,7 @@ public void setLoadBalancerSourceRanges(List<String> loadBalancerSourceRanges) {
     }
 
     @Description("Configures whether the Kubernetes service DNS domain should be used or not. " +
-            "If set to `true`, the generated addresses with contain the service DNS domain suffix " +
+            "If set to `true`, the generated addresses will contain the service DNS domain suffix " +
             "(by default `.cluster.local`, can be configured using environment variable `KUBERNETES_SERVICE_DNS_DOMAIN`). " +
             "Defaults to `false`." +
             "This field can be used only with `internal` type listener.")

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -1095,7 +1095,6 @@ public void testJvmOptions() {
                     .withNewJvmOptions()
                         .withNewXms("512m")
                         .withNewXmx("1024m")
-                        .withNewServer(true)
                         .withXx(xx)
                     .endJvmOptions()
                 .endSpec()
@@ -1104,7 +1103,6 @@ public void testJvmOptions() {
 
         Deployment dep = kc.generateDeployment(Collections.EMPTY_MAP, true, null, null);
         Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-        assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-server"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:+UseG1GC"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:MaxGCPauseMillis=20"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_HEAP_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-Xmx1024m"), is(true));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -1067,7 +1067,6 @@ public void testJvmOptions() {
                     .withNewJvmOptions()
                         .withNewXms("512m")
                         .withNewXmx("1024m")
-                        .withNewServer(true)
                         .withXx(xx)
                     .endJvmOptions()
                 .endSpec()
@@ -1076,7 +1075,6 @@ public void testJvmOptions() {
 
         DeploymentConfig dep = kc.generateDeploymentConfig(Collections.EMPTY_MAP, true, null, null);
         Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-        assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-server"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:+UseG1GC"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:MaxGCPauseMillis=20"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_HEAP_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-Xmx1024m"), is(true));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -1156,7 +1156,6 @@ public void testJvmOptions() {
                     .withNewJvmOptions()
                         .withNewXms("512m")
                         .withNewXmx("1024m")
-                        .withNewServer(true)
                         .withXx(xx)
                     .endJvmOptions()
                 .endSpec()
@@ -1165,7 +1164,6 @@ public void testJvmOptions() {
 
         Deployment dep = kmm2.generateDeployment(Collections.EMPTY_MAP, true, null, null);
         Container cont = getContainer(dep);
-        assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-server"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:+UseG1GC"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:MaxGCPauseMillis=20"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_HEAP_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-Xmx1024m"), is(true));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -751,7 +751,6 @@ public void testJvmOptions() {
                     .withNewJvmOptions()
                         .withNewXms("512m")
                         .withNewXmx("1024m")
-                        .withNewServer(true)
                         .withXx(xx)
                     .endJvmOptions()
                 .endSpec()
@@ -760,7 +759,6 @@ public void testJvmOptions() {
 
         Deployment dep = mmc.generateDeployment(Collections.EMPTY_MAP, true, null, null);
         Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
-        assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-server"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:+UseG1GC"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:MaxGCPauseMillis=20"), is(true));
         assertThat(cont.getEnv().stream().filter(env -> "KAFKA_HEAP_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-Xmx1024m"), is(true));

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -272,7 +272,7 @@ private List<List<String>> commandLines(String podName, String containerName, St
         return result;
     }
 
-    protected void assertExpectedJavaOpts(String podName, String containerName, String expectedXmx, String expectedXms, String expectedServer, String expectedXx) {
+    protected void assertExpectedJavaOpts(String podName, String containerName, String expectedXmx, String expectedXms, String expectedXx) {
         List<List<String>> cmdLines = commandLines(podName, containerName, "java");
         assertThat("Expected exactly 1 java process to be running", cmdLines.size(), is(1));
         List<String> cmd = cmdLines.get(0);
@@ -287,8 +287,6 @@ protected void assertExpectedJavaOpts(String podName, String containerName, Stri
             assertCmdOption(cmd, expectedXmx);
         if (expectedXms != null)
             assertCmdOption(cmd, expectedXms);
-        if (expectedServer != null)
-            assertCmdOption(cmd, expectedServer);
         if (expectedXx != null)
             assertCmdOption(cmd, expectedXx);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectS2IST.java
Patch:
@@ -348,7 +348,6 @@ void testJvmAndResources() {
                 .withNewJvmOptions()
                     .withXmx("200m")
                     .withXms("200m")
-                    .withServer(true)
                     .withXx(jvmOptionsXX)
                 .endJvmOptions()
             .endSpec().build());
@@ -381,7 +380,7 @@ void testJvmAndResources() {
         assertResources(NAMESPACE, podName, kafkaConnectS2IName + "-connect",
             "400M", "2", "300M", "1");
         assertExpectedJavaOpts(podName, kafkaConnectS2IName + "-connect",
-            "-Xmx200m", "-Xms200m", "-server", "-XX:+UseG1GC");
+            "-Xmx200m", "-Xms200m", "-XX:+UseG1GC");
 
         KafkaConnectS2IResource.deleteKafkaConnectS2IWithoutWait(kafkaConnectS2IName);
         DeploymentConfigUtils.waitForDeploymentConfigDeletion(KafkaConnectS2IResources.deploymentName(kafkaConnectS2IName));

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -325,7 +325,6 @@ void testJvmAndResources() {
                     .withNewJvmOptions()
                         .withXmx("200m")
                         .withXms("200m")
-                        .withServer(true)
                         .withXx(jvmOptionsXX)
                     .endJvmOptions()
                 .endSpec()
@@ -335,7 +334,7 @@ void testJvmAndResources() {
         assertResources(NAMESPACE, podName, KafkaConnectResources.deploymentName(CLUSTER_NAME),
                 "400M", "2", "300M", "1");
         assertExpectedJavaOpts(podName, KafkaConnectResources.deploymentName(CLUSTER_NAME),
-                "-Xmx200m", "-Xms200m", "-server", "-XX:+UseG1GC");
+                "-Xmx200m", "-Xms200m", "-XX:+UseG1GC");
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerST.java
Patch:
@@ -130,7 +130,6 @@ void testMirrorMaker() {
                 .withNewJvmOptions()
                     .withXmx("200m")
                     .withXms("200m")
-                    .withServer(true)
                     .withXx(jvmOptionsXX)
                 .endJvmOptions()
                 .endSpec().done();
@@ -151,7 +150,7 @@ void testMirrorMaker() {
         assertResources(NAMESPACE, podName, CLUSTER_NAME.concat("-mirror-maker"),
                 "400M", "2", "300M", "1");
         assertExpectedJavaOpts(podName, KafkaMirrorMakerResources.deploymentName(CLUSTER_NAME),
-                "-Xmx200m", "-Xms200m", "-server", "-XX:+UseG1GC");
+                "-Xmx200m", "-Xms200m", "-XX:+UseG1GC");
 
         timeMeasuringSystem.stopOperation(timeMeasuringSystem.getOperationID());
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/PrometheusST.java
Patch:
@@ -13,6 +13,7 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.Test;
 
@@ -28,6 +29,7 @@
 @Tag(REGRESSION)
 @Tag(PROMETHEUS)
 @Tag(METRICS)
+@Disabled
 public class PrometheusST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(PrometheusST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/security/NetworkPoliciesST.java
Patch:
@@ -40,6 +40,7 @@
 
 import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;
+import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.CoreMatchers.not;
@@ -49,6 +50,7 @@
 import static org.junit.jupiter.api.Assumptions.assumeTrue;
 
 @Tag(NETWORKPOLICIES_SUPPORTED)
+@Tag(REGRESSION)
 public class NetworkPoliciesST extends AbstractST {
     public static final String NAMESPACE = "np-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(NetworkPoliciesST.class);

File: api/src/main/java/io/strimzi/api/kafka/model/CruiseControlSpec.java
Patch:
@@ -89,7 +89,8 @@ public void setBrokerCapacity(BrokerCapacity brokerCapacity) {
 
     @Description("The Cruise Control configuration. For a full list of configuration options refer to" +
             " https://github.com/linkedin/cruise-control/wiki/Configurations. Note that properties " +
-            "with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
+            "with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES +
+            " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public Map<String, Object> getConfig() {
         return config;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -1402,9 +1402,8 @@ protected void addContainerEnvsToExistingEnvs(List<EnvVar> existingEnvs, List<Co
     protected ClusterRoleBinding getClusterRoleBinding(String name, Subject subject, RoleRef roleRef) {
         return new ClusterRoleBindingBuilder()
                 .withNewMetadata()
-                .withName(name)
-                .withOwnerReferences(createOwnerReference())
-                .withLabels(labels.toMap())
+                    .withName(name)
+                    .withLabels(labels.toMap())
                 .endMetadata()
                 .withSubjects(subject)
                 .withRoleRef(roleRef)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -97,5 +97,4 @@ protected AbstractAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability pfa
     protected Future<Boolean> delete(Reconciliation reconciliation) {
         return Future.succeededFuture(Boolean.FALSE);
     }
-
 }

File: systemtest/src/test/java/io/strimzi/systemtest/operators/ClusterOperatorRbacST.java
Patch:
@@ -47,14 +47,14 @@ void testCRBDeletionErrorIsIgnoredWhenRackAwarenessIsNotEnabled() {
 
         LOGGER.info("CO log should contain some information about ignoring forbidden access to CRB for Kafka");
         String log = cmdKubeClient().execInCurrentNamespace(false, "logs", coPodName).out();
-        assertTrue(log.contains("Ignoring forbidden access to ClusterRoleBindings which seems not needed while Kafka rack awareness is disabled."));
+        assertTrue(log.contains("Ignoring forbidden access to ClusterRoleBindings resource which does not seem to be required."));
 
         LOGGER.info("Deploying KafkaConnect: {} without rack awareness, the CR should be deployed without error", CLUSTER_NAME);
         KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1, false).done();
 
         LOGGER.info("CO log should contain some information about ignoring forbidden access to CRB for KafkaConnect");
         log = cmdKubeClient().execInCurrentNamespace(false, "logs", coPodName, "--tail", "50").out();
-        assertTrue(log.contains("Ignoring forbidden access to ClusterRoleBindings which seems not needed while Kafka Connect rack awareness is disabled."));
+        assertTrue(log.contains("Ignoring forbidden access to ClusterRoleBindings resource which does not seem to be required."));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -1197,7 +1197,7 @@ void testHostAliases() {
             .withHostnames(aliasHostname)
             .build();
 
-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)
+        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
             .editSpec()
                 .withNewTemplate()
                     .withNewPod()

File: systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
Patch:
@@ -248,7 +248,7 @@ void testKafkaLogSetting() {
 
     @Test
     void testConnectLogSetting() {
-        KafkaConnectResource.kafkaConnect(CONNECT_NAME, CLUSTER_NAME, 1)
+        KafkaConnectResource.kafkaConnect(CONNECT_NAME, CLUSTER_NAME, 1, true)
             .editSpec()
                 .withNewInlineLogging()
                     .withLoggers(CONNECT_LOGGERS)

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -588,7 +588,7 @@ void testDynamicallySetConnectLoggingLevels() {
         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3).done();
         KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();
         String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();
-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, CLUSTER_NAME, 1)
+        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
                 .editSpec()
                 .withInlineLogging(ilOff)
                 .endSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -172,7 +172,7 @@ void testRackAwareConnectWrongDeployment() {
         List<String> connectWrongPods = kubeClient().listPodNames(Labels.STRIMZI_KIND_LABEL, KafkaConnect.RESOURCE_KIND);
         String connectWrongPodName = connectWrongPods.get(0);
         LOGGER.info("Waiting for ClusterOperator to get timeout operation of incorrectly set up KafkaConnect");
-        KafkaConnectUtils.waitForPodCondition("TimeoutException", "NotReady", NAMESPACE, CLUSTER_NAME);
+        KafkaConnectUtils.waitForKafkaConnectCondition("TimeoutException", "NotReady", NAMESPACE, CLUSTER_NAME);
 
         kc = KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get();
         PodStatus kcWrongStatus = kubeClient().getPod(connectWrongPodName).getStatus();

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -20,7 +20,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
 import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;
-import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;
@@ -88,7 +87,7 @@ void testManualTriggeringRollingUpdate() {
         producerAdditionConfiguration = producerAdditionConfiguration.concat("\ntransactional.id=" + continuousTopicName + ".1");
         producerAdditionConfiguration = producerAdditionConfiguration.concat("\nenable.idempotence=true");
 
-        KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()
+        KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBasicExampleClients.Builder()
             .withProducerName(producerName)
             .withConsumerName(consumerName)
             .withBootstrapAddress(KafkaResources.plainBootstrapAddress(clusterName))

File: systemtest/src/test/java/io/strimzi/systemtest/specific/ClusterOperationST.java
Patch:
@@ -12,7 +12,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;
-import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;
 import io.strimzi.systemtest.utils.ClientUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -63,7 +62,7 @@ void testAvailabilityDuringNodeDrain() {
         KafkaBasicExampleClients kafkaBasicClientResource;
 
         for (int i = 0; i < size; i++) {
-            kafkaBasicClientResource = new KafkaBridgeExampleClients.Builder()
+            kafkaBasicClientResource = new KafkaBasicExampleClients.Builder()
                 .withProducerName(producerNames.get(i))
                 .withConsumerName(consumerNames.get(i))
                 .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/OlmUpgradeST.java
Patch:
@@ -10,7 +10,6 @@
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;
-import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;
 import io.strimzi.systemtest.resources.operator.OlmResource;
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.FileUtils;
@@ -49,7 +48,7 @@ public class OlmUpgradeST extends AbstractUpgradeST {
     private final String consumerName = "consumer";
     private final String topicUpgradeName = "topic-upgrade";
     private final int messageUpgradeCount =  50_000; // 10k ~= 23s, 50k ~= 115s
-    private final KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()
+    private final KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBasicExampleClients.Builder()
         .withProducerName(producerName)
         .withConsumerName(consumerName)
         .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -21,7 +21,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
 import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;
-import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;
 import io.strimzi.systemtest.resources.operator.BundleResource;
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.FileUtils;
@@ -282,7 +281,7 @@ private void performUpgrade(JsonObject testParameters, int produceMessagesCount,
 
             String producerAdditionConfiguration = "delivery.timeout.ms=20000\nrequest.timeout.ms=20000";
 
-            KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()
+            KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBasicExampleClients.Builder()
                 .withProducerName(producerName)
                 .withConsumerName(consumerName)
                 .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java
Patch:
@@ -11,7 +11,6 @@
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBasicExampleClients;
-import io.strimzi.systemtest.resources.crd.kafkaclients.KafkaBridgeExampleClients;
 import io.strimzi.systemtest.resources.operator.BundleResource;
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.TestKafkaVersion;
@@ -146,7 +145,7 @@ void runVersionChange(TestKafkaVersion initialVersion, TestKafkaVersion newVersi
             KafkaTopicResource.topic(CLUSTER_NAME, continuousTopicName, 3, 3, 2).done();
             String producerAdditionConfiguration = "delivery.timeout.ms=20000\nrequest.timeout.ms=20000";
 
-            KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()
+            KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBasicExampleClients.Builder()
                 .withProducerName(producerName)
                 .withConsumerName(consumerName)
                 .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -533,7 +533,7 @@ Future<ReconciliationState> initialStatus() {
          * practice to the status.
          */
         Future<ReconciliationState> checkKafkaSpec() {
-            KafkaSpecChecker checker = new KafkaSpecChecker(kafkaAssembly.getSpec(), kafkaCluster, zkCluster);
+            KafkaSpecChecker checker = new KafkaSpecChecker(kafkaAssembly.getSpec(), versions, kafkaCluster, zkCluster);
             List<Condition> warnings = checker.run();
             kafkaStatus.addConditions(warnings);
             return Future.succeededFuture(this);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -190,6 +190,7 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl
                     .withVersion(Environment.ST_KAFKA_VERSION)
                     .withReplicas(kafkaReplicas)
                     .addToConfig("log.message.format.version", TestKafkaVersion.getKafkaVersionsInMap().get(Environment.ST_KAFKA_VERSION).protocolVersion())
+                    .addToConfig("inter.broker.protocol.version", TestKafkaVersion.getKafkaVersionsInMap().get(Environment.ST_KAFKA_VERSION).protocolVersion())
                     .addToConfig("offsets.topic.replication.factor", Math.min(kafkaReplicas, 3))
                     .addToConfig("transaction.state.log.min.isr", Math.min(kafkaReplicas, 2))
                     .addToConfig("transaction.state.log.replication.factor", Math.min(kafkaReplicas, 3))

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -181,6 +181,7 @@ void testUpgradeKafkaWithoutVersion() throws IOException {
                 .editKafka()
                     .withVersion(null)
                     .addToConfig("log.message.format.version", getValueForLastKafkaVersionInFile(previousKafkaVersionsYaml, "format"))
+                    .addToConfig("inter.broker.protocol.version", getValueForLastKafkaVersionInFile(previousKafkaVersionsYaml, "protocol"))
                 .endKafka()
             .endSpec()
             .done();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -166,6 +166,7 @@ protected static String defaultBootstrapServers(String cluster) {
         return KafkaCluster.serviceName(cluster) + ":" + DEFAULT_BOOTSTRAP_SERVERS_PORT;
     }
 
+    @SuppressWarnings("deprecation")
     public static CruiseControl fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup versions) {
         CruiseControl cruiseControl = null;
         CruiseControlSpec spec  = kafkaAssembly.getSpec().getCruiseControl();
@@ -214,6 +215,7 @@ public static CruiseControl fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup ver
                 cruiseControl.setMetricsEnabled(true);
                 cruiseControl.setMetricsConfig(metrics.entrySet());
             }
+            cruiseControl.setMetricsConfigInCm(spec.getMetricsConfig());
 
             if (spec.getReadinessProbe() != null) {
                 cruiseControl.setReadinessProbe(spec.getReadinessProbe());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -171,6 +171,7 @@ public static KafkaConnectCluster fromCrd(KafkaConnect kafkaConnect, KafkaVersio
      * from the instantiation of the (subclass of) KafkaConnectCluster,
      * thus permitting reuse of the setter-calling code for subclasses.
      */
+    @SuppressWarnings("deprecation")
     protected static <C extends KafkaConnectCluster> C fromSpec(KafkaConnectSpec spec,
                                                                 KafkaVersion.Lookup versions,
                                                                 C kafkaConnect) {
@@ -222,7 +223,7 @@ protected static <C extends KafkaConnectCluster> C fromSpec(KafkaConnectSpec spe
             kafkaConnect.setMetricsEnabled(true);
             kafkaConnect.setMetricsConfig(metrics.entrySet());
         }
-
+        kafkaConnect.setMetricsConfigInCm(spec.getMetricsConfig());
         kafkaConnect.setBootstrapServers(spec.getBootstrapServers());
 
         kafkaConnect.setTls(spec.getTls());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Cluster.java
Patch:
@@ -126,6 +126,7 @@ private static KafkaConnectSpec buildKafkaConnectSpec(KafkaMirrorMaker2Spec spec
                 .withReadinessProbe(spec.getReadinessProbe())
                 .withJvmOptions(spec.getJvmOptions())
                 .withMetrics(spec.getMetrics())
+                .withMetricsConfig(spec.getMetricsConfig())
                 .withTracing(spec.getTracing())
                 .withAffinity(spec.getAffinity())
                 .withTolerations(spec.getTolerations())

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -123,6 +123,7 @@ protected KafkaMirrorMakerCluster(HasMetadata resource) {
         this.logAndMetricsConfigMountPath = "/opt/kafka/custom-config/";
     }
 
+    @SuppressWarnings("deprecation")
     public static KafkaMirrorMakerCluster fromCrd(KafkaMirrorMaker kafkaMirrorMaker, KafkaVersion.Lookup versions) {
         KafkaMirrorMakerCluster kafkaMirrorMakerCluster = new KafkaMirrorMakerCluster(kafkaMirrorMaker);
 
@@ -160,6 +161,7 @@ public static KafkaMirrorMakerCluster fromCrd(KafkaMirrorMaker kafkaMirrorMaker,
                 kafkaMirrorMakerCluster.setMetricsEnabled(true);
                 kafkaMirrorMakerCluster.setMetricsConfig(metrics.entrySet());
             }
+            kafkaMirrorMakerCluster.setMetricsConfigInCm(spec.getMetricsConfig());
 
             /*setClientAuth(kafkaMirrorMakerCluster, spec.getConsumer());
             setClientAuth(kafkaMirrorMakerCluster, spec.getProducer());*/

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractModelTest.java
Patch:
@@ -214,4 +214,5 @@ public void testDetermineImagePullPolicy()  {
         assertThat(am.determineImagePullPolicy(null, "docker.io/repo/image:not-so-latest"), is(ImagePullPolicy.IFNOTPRESENT.toString()));
         assertThat(am.determineImagePullPolicy(null, "docker.io/repo/image:latest-kafka-2.6.0"), is(ImagePullPolicy.ALWAYS.toString()));
     }
+
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -578,7 +578,6 @@ public void testReconcile(VertxTestContext context) {
                 .build();
         Map<String, Object> metricsCm = new HashMap<>();
         metricsCm.put("foo", "bar");
-
         KafkaMirrorMaker foo = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, "foo", image, producer, consumer, whitelist, metricsCm);
         KafkaMirrorMaker bar = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, "bar", image, producer, consumer, whitelist, metricsCm);
 
@@ -710,7 +709,6 @@ public void testCreateOrUpdateZeroReplica(VertxTestContext context) {
                 .build();
         Map<String, Object> metricsCm = new HashMap<>();
         metricsCm.put("foo", "bar");
-
         KafkaMirrorMaker kmm = ResourceUtils.createKafkaMirrorMaker(kmmNamespace, kmmName, image, 0, producer, consumer, whitelist, metricsCm);
 
         when(mockMirrorOps.get(kmmNamespace, kmmName)).thenReturn(kmm);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -183,7 +183,7 @@ private Map<String, List> upgrade(VertxTestContext context, Map<String, String>
         });
 
         ConfigMapOperator cmo = supplier.configMapOperations;
-        when(cmo.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kafkaCluster.generateAncillaryConfigMap(null, emptySet(), emptySet())));
+        when(cmo.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kafkaCluster.generateAncillaryConfigMap(null, null, emptySet(), emptySet())));
 
         when(cmo.reconcile(anyString(), anyString(), any(ConfigMap.class))).thenAnswer(invocation -> {
             //reconcileExceptions.accept(states.size());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -50,7 +50,6 @@
 import java.util.concurrent.TimeoutException;
 
 import static io.strimzi.test.TestUtils.set;
-import static java.util.Collections.emptyMap;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 
@@ -120,7 +119,7 @@ public void beforeEach(VertxTestContext context) throws InterruptedException, Ex
                             .withStorageClass("foo")
                             .withDeleteClaim(true)
                         .endPersistentClaimStorage()
-                        .withMetrics(emptyMap())
+                        .withMetrics(Collections.emptyMap())
                     .endKafka()
                     .withNewZookeeper()
                         .withReplicas(3)
@@ -129,7 +128,7 @@ public void beforeEach(VertxTestContext context) throws InterruptedException, Ex
                             .withStorageClass("foo")
                             .withDeleteClaim(true)
                         .endPersistentClaimStorage()
-                        .withMetrics(emptyMap())
+                        .withMetrics(Collections.emptyMap())
                     .endZookeeper()
                     .withNewTopicOperator()
                     .endTopicOperator()

File: operator-common/src/main/java/io/strimzi/operator/common/model/ResourceVisitor.java
Patch:
@@ -147,7 +147,9 @@ static <M extends AnnotatedElement & Member> void visitProperty(List<String> pat
             } else if (Collection.class.isAssignableFrom(returnType)) {
                 path.add(propertyName);
                 for (Object element : (Collection<?>) propertyValue) {
-                    visit(path, element, visitor);
+                    if (element != null) {
+                        visit(path, element, visitor);
+                    }
                 }
                 path.remove(path.size() - 1);
             } else if (!isScalar(returnType)

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.systemtest.interfaces.IndicativeSentences;
 import io.strimzi.systemtest.interfaces.TestSeparator;
 import io.strimzi.systemtest.logs.TestExecutionWatcher;
 import io.strimzi.systemtest.resources.KubernetesResource;
@@ -37,6 +38,7 @@
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.DisplayNameGeneration;
 import org.junit.jupiter.api.TestInstance;
 import org.junit.jupiter.api.extension.ExtendWith;
 import org.junit.jupiter.api.extension.ExtensionContext;
@@ -65,6 +67,7 @@
 
 @TestInstance(TestInstance.Lifecycle.PER_CLASS)
 @ExtendWith(TestExecutionWatcher.class)
+@DisplayNameGeneration(IndicativeSentences.class)
 public abstract class AbstractST implements TestSeparator {
 
     static {

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -120,7 +120,7 @@ public class Environment {
     public static final String OLM_APP_BUNDLE_PREFIX_DEFAULT = "strimzi-cluster-operator";
     public static final String OLM_OPERATOR_VERSION_DEFAULT = "v0.19.0";
     public static final String OLM_LATEST_CONTAINER_IMAGE_TAG_DEFAULT = "6.6.6";
-    private static final String DEFAULT_TO_DENY_NETWORK_POLICIES_DEFAULT = "true";
+    private static final boolean DEFAULT_TO_DENY_NETWORK_POLICIES_DEFAULT = true;
     private static final String CLUSTER_OPERATOR_INSTALL_TYPE_DEFAULT = "bundle";
 
     private static String config;
@@ -150,7 +150,7 @@ public class Environment {
     public static final String OLM_OPERATOR_LATEST_RELEASE_VERSION = getOrDefault(OLM_OPERATOR_VERSION_ENV, OLM_OPERATOR_VERSION_DEFAULT);
     public static final String OLM_LATEST_CONTAINER_IMAGE_TAG = getOrDefault(OLM_LATEST_CONTAINER_IMAGE_TAG_ENV, OLM_LATEST_CONTAINER_IMAGE_TAG_DEFAULT);
     // NetworkPolicy variable
-    public static final String DEFAULT_TO_DENY_NETWORK_POLICIES = getOrDefault(DEFAULT_TO_DENY_NETWORK_POLICIES_ENV, DEFAULT_TO_DENY_NETWORK_POLICIES_DEFAULT);
+    public static final boolean DEFAULT_TO_DENY_NETWORK_POLICIES = getOrDefault(DEFAULT_TO_DENY_NETWORK_POLICIES_ENV, Boolean::parseBoolean, DEFAULT_TO_DENY_NETWORK_POLICIES_DEFAULT);
     // ClusterOperator installation type variable
     public static final String CLUSTER_OPERATOR_INSTALL_TYPE = getOrDefault(CLUSTER_OPERATOR_INSTALL_TYPE_ENV, CLUSTER_OPERATOR_INSTALL_TYPE_DEFAULT);
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -263,7 +263,7 @@ public static Service deployBridgeNodePortService(String bridgeExternalService,
 
     public static void applyDefaultNetworkPolicySettings(List<String> namespaces) {
         for (String namespace : namespaces) {
-            if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {
+            if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES) {
                 applyDefaultNetworkPolicy(namespace, DefaultNetworkPolicy.DEFAULT_TO_DENY);
             } else {
                 applyDefaultNetworkPolicy(namespace, DefaultNetworkPolicy.DEFAULT_TO_ALLOW);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -98,7 +98,7 @@ private static KafkaBridgeBuilder defaultKafkaBridge(KafkaBridge kafkaBridge, St
     }
 
     private static DoneableKafkaBridge deployKafkaBridge(KafkaBridge kafkaBridge) {
-        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {
+        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES) {
             KubernetesResource.allowNetworkPolicySettingsForResource(kafkaBridge, KafkaBridgeResources.deploymentName(kafkaBridge.getMetadata().getName()));
         }
         return new DoneableKafkaBridge(kafkaBridge, kB -> {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -83,7 +83,7 @@ private static KafkaConnectBuilder defaultKafkaConnect(KafkaConnect kafkaConnect
     }
 
     private static DoneableKafkaConnect deployKafkaConnect(KafkaConnect kafkaConnect) {
-        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {
+        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES) {
             KubernetesResource.allowNetworkPolicySettingsForResource(kafkaConnect, KafkaConnectResources.deploymentName(kafkaConnect.getMetadata().getName()));
         }
         return new DoneableKafkaConnect(kafkaConnect, kC -> {
@@ -112,7 +112,7 @@ public static KafkaConnect kafkaConnectWithoutWait(KafkaConnect kafkaConnect) {
 
 
     public static void allowNetworkPolicyForKafkaConnect(KafkaConnect kafkaConnect) {
-        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {
+        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES) {
             KubernetesResource.allowNetworkPolicySettingsForResource(kafkaConnect, KafkaConnectResources.deploymentName(kafkaConnect.getMetadata().getName()));
         }
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -67,7 +67,7 @@ public static KafkaConnectS2IBuilder defaultKafkaConnectS2I(KafkaConnectS2I kafk
     }
 
     private static DoneableKafkaConnectS2I deployKafkaConnectS2I(KafkaConnectS2I kafkaConnectS2I) {
-        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES.equals(Boolean.TRUE.toString())) {
+        if (Environment.DEFAULT_TO_DENY_NETWORK_POLICIES) {
             KubernetesResource.allowNetworkPolicySettingsForResource(kafkaConnectS2I, KafkaConnectS2IResources.deploymentName(kafkaConnectS2I.getMetadata().getName()));
         }
         return new DoneableKafkaConnectS2I(kafkaConnectS2I, kC -> {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -421,13 +421,13 @@ public static KafkaCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup vers
 
         KafkaConfiguration configuration = new KafkaConfiguration(kafkaClusterSpec.getConfig().entrySet());
         // If  required Cruise Control metric reporter configurations are missing set them using Kafka defaults
-        if (configuration.getConfigOption(CruiseControlConfigurationParameters.METRICS_TOPIC_NUM_PARTITIONS.getName()) == null) {
+        if (configuration.getConfigOption(CruiseControlConfigurationParameters.METRICS_TOPIC_NUM_PARTITIONS.getValue()) == null) {
             result.ccNumPartitions = configuration.getConfigOption(KAFKA_NUM_PARTITIONS_CONFIG_FIELD, CRUISE_CONTROL_DEFAULT_NUM_PARTITIONS);
         }
-        if (configuration.getConfigOption(CruiseControlConfigurationParameters.METRICS_TOPIC_REPLICATION_FACTOR.getName()) == null) {
+        if (configuration.getConfigOption(CruiseControlConfigurationParameters.METRICS_TOPIC_REPLICATION_FACTOR.getValue()) == null) {
             result.ccReplicationFactor = configuration.getConfigOption(KAFKA_REPLICATION_FACTOR_CONFIG_FIELD, CRUISE_CONTROL_DEFAULT_REPLICATION_FACTOR);
         }
-        if (configuration.getConfigOption(CruiseControlConfigurationParameters.METRICS_TOPIC_MIN_ISR.getName()) == null) {
+        if (configuration.getConfigOption(CruiseControlConfigurationParameters.METRICS_TOPIC_MIN_ISR.getValue()) == null) {
             result.ccMinInSyncReplicas = "1";
         } else {
             // If the user has set the CC minISR but it is higher than the set number of replicas for the metrics topics then we need to abort and make

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -779,7 +779,7 @@ public void testGoalsCheck() {
                 "com.linkedin.kafka.cruisecontrol.analyzer.goals.ReplicaCapacityGoal";
 
         Map<String, Object> customGoalConfig = (Map) configuration.asOrderedProperties().asMap();
-        customGoalConfig.put(CRUISE_CONTROL_DEFAULT_GOALS_CONFIG_KEY.getName(), customGoals);
+        customGoalConfig.put(CRUISE_CONTROL_DEFAULT_GOALS_CONFIG_KEY.getValue(), customGoals);
 
         CruiseControlSpec ccSpecWithCustomGoals = new CruiseControlSpecBuilder()
                 .withImage(ccImage)
@@ -801,7 +801,7 @@ public void testGoalsCheck() {
 
         String anomalyDetectionGoals =  cruiseControlWithCustomGoals
                 .getConfiguration().asOrderedProperties().asMap()
-                .get(CRUISE_CONTROL_ANOMALY_DETECTION_CONFIG_KEY.getName());
+                .get(CRUISE_CONTROL_ANOMALY_DETECTION_CONFIG_KEY.getValue());
 
         assertThat(anomalyDetectionGoals, is(customGoals));
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -3647,8 +3647,8 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
     public void testCruiseControlWithMinISRgtReplicas() {
         Map<String, Object> config = new HashMap<>();
         int minInsyncReplicas = 2;
-        config.put(CruiseControlConfigurationParameters.METRICS_TOPIC_REPLICATION_FACTOR.getName(), 1);
-        config.put(CruiseControlConfigurationParameters.METRICS_TOPIC_MIN_ISR.getName(), minInsyncReplicas);
+        config.put(CruiseControlConfigurationParameters.METRICS_TOPIC_REPLICATION_FACTOR.getValue(), 1);
+        config.put(CruiseControlConfigurationParameters.METRICS_TOPIC_MIN_ISR.getValue(), minInsyncReplicas);
 
         Kafka kafkaAssembly = new KafkaBuilder(ResourceUtils.createKafka(namespace, cluster, replicas,
                 image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -212,6 +212,8 @@ public static void applyRoleBindings(String namespace, List<String> bindingsName
             KubernetesResource.roleBinding(TestUtils.USER_PATH + "/../install/cluster-operator/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml", namespace, bindingsNamespace);
             // 032-RoleBinding
             KubernetesResource.roleBinding(TestUtils.USER_PATH + "/../install/cluster-operator/032-RoleBinding-strimzi-cluster-operator-topic-operator-delegation.yaml", namespace, bindingsNamespace);
+            // 033-ClusterRoleBinding
+            KubernetesResource.clusterRoleBinding(TestUtils.USER_PATH + "/../install/cluster-operator/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml", namespace, bindingsNamespace);
         }
     }
 

File: api/src/test/java/io/strimzi/api/kafka/model/AbstractCrdIT.java
Patch:
@@ -137,6 +137,6 @@ protected void waitForCrd(String resource, String name) {
 
     @BeforeEach
     public void setupTests() {
-        cluster.before();
+        cluster.cluster();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -71,7 +71,7 @@ public abstract class AbstractST implements TestSeparator {
         Crds.registerCustomKinds();
     }
 
-    protected KubeClusterResource cluster = KubeClusterResource.getInstance();
+    protected KubeClusterResource cluster;
     protected static TimeMeasuringSystem timeMeasuringSystem = TimeMeasuringSystem.getInstance();
     private static final Logger LOGGER = LogManager.getLogger(AbstractST.class);
 
@@ -642,6 +642,7 @@ void createTestResources(ExtensionContext testContext) {
 
     @BeforeAll
     void setTestClassName(ExtensionContext testContext) {
+        cluster = KubeClusterResource.getInstance();
         if (testContext.getTestClass().isPresent()) {
             testClass = testContext.getTestClass().get().getName();
         }

File: test/src/main/java/io/strimzi/test/k8s/cluster/KubeCluster.java
Patch:
@@ -77,16 +77,17 @@ static KubeCluster bootstrap() throws NoClusterException {
                     cluster = kc;
                     break;
                 } else {
-                    logger.debug("Cluster {} is not running", kc);
+                    logger.warn("Cluster {} is not running!", kc);
                 }
             } else {
-                logger.debug("Cluster {} is not installed", kc);
+                logger.warn("Cluster {} is not installed!", kc);
             }
         }
         if (cluster == null) {
             throw new NoClusterException(
                     "Unable to find a cluster; tried " + Arrays.toString(clusters));
         }
+        logger.info("Using cluster: {}", cluster);
         return cluster;
     }
 

File: test/src/main/java/io/strimzi/test/k8s/exceptions/NoClusterException.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.test.k8s.exceptions;
 
-public class NoClusterException extends Exception {
+public class NoClusterException extends RuntimeException {
     public NoClusterException(String message) {
         super(message);
     }

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorBaseIT.java
Patch:
@@ -148,7 +148,7 @@ public static void teardownKubeCluster() {
     @BeforeEach
     public void setup() throws Exception {
         LOGGER.info("Setting up test");
-        cluster.before();
+        cluster.cluster();
         int counts = 3;
         do {
             try {

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationST.java
Patch:
@@ -298,6 +298,7 @@ void testSessionReAuthentication() {
         KafkaTopicResource.topic(CLUSTER_NAME, topicAName).done();
 
         teamAOauthClientJob = teamAOauthClientJob.toBuilder()
+            .withUserName(TEAM_A_CLIENT)
             .withTopicName(topicXName)
             .withMessageCount(MESSAGE_COUNT)
             .build();
@@ -458,7 +459,7 @@ void testClusterVerification() {
     void setUp()  {
         keycloakInstance.setRealm(TEST_REALM, true);
 
-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 1)
+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)
             .editSpec()
                 .editKafka()
                     .withNewListeners()

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
Patch:
@@ -394,7 +394,7 @@ void setUp() {
             .withOAuthTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
             .build();
 
-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 1)
+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)
             .editSpec()
                 .editKafka()
                     .withNewListeners()

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -399,7 +399,7 @@ void setUp() {
             .withOAuthTokenEndpointUri(keycloakInstance.getOauthTokenEndpointUri())
             .build();
 
-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 1)
+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)
             .editSpec()
                 .editKafka()
                     .withNewListeners()

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -56,7 +56,8 @@ public class KafkaClusterSpec implements UnknownPropertyPreserving, Serializable
 
     public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols,"
             + "cruise.control.metrics.topic.num.partitions, cruise.control.metrics.topic.replication.factor, cruise.control.metrics.topic.retention.ms,"
-            + "cruise.control.metrics.topic.auto.create.retries, cruise.control.metrics.topic.auto.create.timeout.ms";
+            + "cruise.control.metrics.topic.auto.create.retries, cruise.control.metrics.topic.auto.create.timeout.ms,"
+            + "cruise.control.metrics.topic.min.insync.replicas";
 
     protected Storage storage;
 

File: crd-generator/src/test/java/io/strimzi/crdgenerator/ExampleCrd.java
Patch:
@@ -293,6 +293,6 @@ public Type1OrType2 getTypedAlternatives() {
     }
 
     public void setTypedAlternatives(Type1OrType2 alternatives) {
-        this.typedAlternatives = typedAlternatives;
+        this.typedAlternatives = alternatives;
     }
 }

File: crd-generator/src/test/java/io/strimzi/crdgenerator/Type1OrType2.java
Patch:
@@ -31,13 +31,13 @@ public class Type1OrType2 {
     private Type2 type2Value;
 
     public Type1OrType2(Type1 type1Value)   {
-        type1Value = type1Value;
+        this.type1Value = type1Value;
         type2Value = null;
     }
 
     public Type1OrType2(Type2 type2Value)   {
         type1Value = null;
-        type2Value = type2Value;
+        this.type2Value = type2Value;
     }
 
     @Alternative

File: mockkube/src/main/java/io/strimzi/test/mockkube/CustomResourceMockBuilder.java
Patch:
@@ -35,7 +35,6 @@ public void updateStatus(String namespace, String name, T resource) {
             S status = getStatus.apply(copyResource(resource));
             LOGGER.debug("Updating status on {} to {}", resourceTypeClass.getSimpleName(), status);
             T t = incrementResourceVersion(copyResource(db.get(name)));
-            getStatus.apply(t);
             mockedCrd.setStatus().accept(t, status);
             db.put(name, t);
             fireWatchers(name, t, Watcher.Action.MODIFIED, "updateStatus");

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/SecretUtils.java
Patch:
@@ -157,7 +157,7 @@ public static void deleteSecretWithWait(String secretName, String namespace) {
         kubeClient().getClient().secrets().inNamespace(namespace).withName(secretName).delete();
 
         LOGGER.info("Waiting for Secret: {} to be deleted", secretName);
-        TestUtils.waitFor(String.format("Deletion of secret: {}", secretName), Constants.GLOBAL_POLL_INTERVAL, DELETION_TIMEOUT,
+        TestUtils.waitFor(String.format("Deletion of secret: %s", secretName), Constants.GLOBAL_POLL_INTERVAL, DELETION_TIMEOUT,
             () -> kubeClient().getSecret(secretName) == null);
 
         LOGGER.info("Secret: {} successfully deleted", secretName);

File: systemtest/src/test/java/io/strimzi/systemtest/specific/ClusterOperationST.java
Patch:
@@ -67,7 +67,7 @@ void testAvailabilityDuringNodeDrain() {
                 .withProducerName(producerNames.get(i))
                 .withConsumerName(consumerNames.get(i))
                 .withBootstrapAddress(KafkaResources.plainBootstrapAddress(CLUSTER_NAME))
-                .withTopicName(topicNames.get(producerNames.indexOf(i)))
+                .withTopicName(topicNames.get(i))
                 .withMessageCount(continuousClientsMessageCount)
                 .withAdditionalConfig(producerAdditionConfiguration)
                 .withConsumerGroup(continuousConsumerGroups.get(i))

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicOperator.java
Patch:
@@ -96,7 +96,7 @@ public Event(HasMetadata involvedObject, String message, EventType eventType, Ha
         @Override
         public void handle(Void v) {
             EventBuilder evtb = new EventBuilder();
-            final String eventTime = ZonedDateTime.now().format(DateTimeFormatter.ofPattern("YYYY-MM-dd'T'HH:mm:ss'Z'"));
+            final String eventTime = ZonedDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd'T'HH:mm:ss'Z'"));
             
             if (involvedObject != null) {
                 evtb.withNewInvolvedObject()

File: api/src/main/java/io/strimzi/api/kafka/model/listener/arraylistener/GenericKafkaListenerConfiguration.java
Patch:
@@ -112,7 +112,7 @@ public void setExternalTrafficPolicy(ExternalTrafficPolicy externalTrafficPolicy
     @Description("A list of CIDR ranges (for example `10.0.0.0/8` or `130.211.204.1/32`) from which clients can connect to load balancer type listeners. " +
             "If supported by the platform, traffic through the loadbalancer is restricted to the specified CIDR ranges. " +
             "This field is applicable only for loadbalancer type services and is ignored if the cloud provider does not support the feature. " +
-            "For more information, see https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/" +
+            "For more information, see https://v1-17.docs.kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/. " +
             "This field can be used only with `loadbalancer` type listener.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<String> getLoadBalancerSourceRanges() {

File: api/src/main/java/io/strimzi/api/kafka/model/template/ExternalServiceTemplate.java
Patch:
@@ -68,7 +68,7 @@ public void setExternalTrafficPolicy(ExternalTrafficPolicy externalTrafficPolicy
     @Description("A list of CIDR ranges (for example `10.0.0.0/8` or `130.211.204.1/32`) from which clients can connect to load balancer type listeners. " +
             "If supported by the platform, traffic through the loadbalancer is restricted to the specified CIDR ranges. " +
             "This field is applicable only for loadbalancer type services and is ignored if the cloud provider does not support the feature. " +
-            "For more information, see https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/")
+            "For more information, see https://v1-17.docs.kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/. ")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     @DeprecatedProperty
     @Deprecated

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -165,7 +165,7 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
     /*test*/ static Future<Void> maybeCreateClusterRoles(Vertx vertx, ClusterOperatorConfig config, KubernetesClient client)  {
         if (config.isCreateClusterRoles()) {
             List<Future> futures = new ArrayList<>();
-            ClusterRoleOperator cro = new ClusterRoleOperator(vertx, client, config.getOperationTimeoutMs());
+            ClusterRoleOperator cro = new ClusterRoleOperator(vertx, client);
 
             Map<String, String> clusterRoles = new HashMap<String, String>() {
                 {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -45,9 +45,8 @@
  * can proceed at once.</p>
  */
 public abstract class AbstractAssemblyOperator<C extends KubernetesClient, T extends CustomResource & HasSpecAndStatus<P, S>,
-        L extends KubernetesResourceList/*<T>*/, D extends Doneable<T>, R extends Resource<T, D>, P extends Spec, S extends Status>
+        L extends KubernetesResourceList<T>, D extends Doneable<T>, R extends Resource<T, D>, P extends Spec, S extends Status>
     extends AbstractOperator<T, P, S, AbstractWatchableStatusedResourceOperator<C, T, L, D, R>> {
-
     protected final PlatformFeaturesAvailability pfa;
     protected final SecretOperator secretOperations;
     protected final CertManager certManager;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ResourceOperatorSupplier.java
Patch:
@@ -117,7 +117,7 @@ public ResourceOperatorSupplier(Vertx vertx, KubernetesClient client, ZookeeperL
                 new DeploymentOperator(vertx, client),
                 new ServiceAccountOperator(vertx, client),
                 new RoleBindingOperator(vertx, client),
-                new ClusterRoleBindingOperator(vertx, client, operationTimeoutMs),
+                new ClusterRoleBindingOperator(vertx, client),
                 new NetworkPolicyOperator(vertx, client),
                 new PodDisruptionBudgetOperator(vertx, client),
                 new PodOperator(vertx, client),
@@ -133,8 +133,8 @@ public ResourceOperatorSupplier(Vertx vertx, KubernetesClient client, ZookeeperL
                 new CrdOperator<>(vertx, client, KafkaConnector.class, KafkaConnectorList.class, DoneableKafkaConnector.class, Crds.kafkaConnector()),
                 new CrdOperator<>(vertx, client, KafkaMirrorMaker2.class, KafkaMirrorMaker2List.class, DoneableKafkaMirrorMaker2.class, Crds.kafkaMirrorMaker2()),
                 new CrdOperator<>(vertx, client, KafkaRebalance.class, KafkaRebalanceList.class, DoneableKafkaRebalance.class, Crds.kafkaRebalance()),
-                new StorageClassOperator(vertx, client, operationTimeoutMs),
-                new NodeOperator(vertx, client, operationTimeoutMs),
+                new StorageClassOperator(vertx, client),
+                new NodeOperator(vertx, client),
                 zkScalerProvider,
                 metricsProvider,
                 adminClientProvider);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/MainIT.java
Patch:
@@ -65,7 +65,7 @@ public void testCreateClusterRolesCreatesClusterRoles(VertxTestContext context)
 
         ClusterOperatorConfig config = ClusterOperatorConfig.fromMap(envVars, KafkaVersionTestUtils.getKafkaVersionLookup());
 
-        ClusterRoleOperator cro = new ClusterRoleOperator(vertx, client, 100);
+        ClusterRoleOperator cro = new ClusterRoleOperator(vertx, client);
 
         Checkpoint a = context.checkpoint();
         Main.maybeCreateClusterRoles(vertx, config, client)

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractReadyResourceOperator.java
Patch:
@@ -24,7 +24,7 @@
  */
 public abstract class AbstractReadyResourceOperator<C extends KubernetesClient,
             T extends HasMetadata,
-            L extends KubernetesResourceList/*<T>*/,
+            L extends KubernetesResourceList<T>,
             D extends Doneable<T>,
             R extends Resource<T, D>>
         extends AbstractResourceOperator<C, T, L, D, R> {

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractScalableResourceOperator.java
Patch:
@@ -27,7 +27,7 @@
  */
 public abstract class AbstractScalableResourceOperator<C extends KubernetesClient,
             T extends HasMetadata,
-            L extends KubernetesResourceList/*<T>*/,
+            L extends KubernetesResourceList<T>,
             D extends Doneable<T>,
             R extends ScalableResource<T, D>>
         extends AbstractReadyResourceOperator<C, T, L, D, R> {

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractWatchableResourceOperator.java
Patch:
@@ -20,7 +20,7 @@
 public abstract class AbstractWatchableResourceOperator<
         C extends KubernetesClient,
         T extends HasMetadata,
-        L extends KubernetesResourceList/*<T>*/,
+        L extends KubernetesResourceList<T>,
         D extends Doneable<T>,
         R extends Resource<T, D>>
         extends AbstractResourceOperator<C, T, L, D, R> {

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractWatchableStatusedResourceOperator.java
Patch:
@@ -25,7 +25,7 @@
 public abstract class AbstractWatchableStatusedResourceOperator<
         C extends KubernetesClient,
         T extends HasMetadata,
-        L extends KubernetesResourceList/*<T>*/,
+        L extends KubernetesResourceList<T>,
         D extends Doneable<T>,
         R extends Resource<T, D>>
         extends AbstractWatchableResourceOperator<C, T, L, D, R> {

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/NodeOperator.java
Patch:
@@ -19,10 +19,9 @@ public class NodeOperator extends AbstractNonNamespacedResourceOperator<Kubernet
      * Constructor.
      * @param vertx The Vertx instance.
      * @param client The Kubernetes client.
-     * @param operationTimeoutMs The timeout in milliseconds.
      */
-    public NodeOperator(Vertx vertx, KubernetesClient client, long operationTimeoutMs) {
-        super(vertx, client, "ClusterRoleBinding", operationTimeoutMs);
+    public NodeOperator(Vertx vertx, KubernetesClient client) {
+        super(vertx, client, "Node");
     }
 
     @Override

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/StorageClassOperator.java
Patch:
@@ -19,11 +19,10 @@ public class StorageClassOperator extends AbstractNonNamespacedResourceOperator<
      * Constructor.
      * @param vertx The Vertx instance.
      * @param client The Kubernetes client.
-     * @param operationTimeoutMs The timeout in milliseconds.
      */
 
-    public StorageClassOperator(Vertx vertx, KubernetesClient client, long operationTimeoutMs) {
-        super(vertx, client, "StorageClass", operationTimeoutMs);
+    public StorageClassOperator(Vertx vertx, KubernetesClient client) {
+        super(vertx, client, "StorageClass");
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbtractReadyResourceOperatorTest.java
Patch:
@@ -30,7 +30,7 @@
 import static org.mockito.Mockito.when;
 
 public abstract class AbtractReadyResourceOperatorTest<C extends KubernetesClient, T extends HasMetadata,
-        L extends KubernetesResourceList, D extends Doneable<T>, R extends Resource<T, D>> extends AbstractResourceOperatorTest<C, T, L, D, R> {
+        L extends KubernetesResourceList<T>, D extends Doneable<T>, R extends Resource<T, D>> extends AbstractResourceOperatorTest<C, T, L, D, R> {
 
     @Override
     protected abstract AbstractReadyResourceOperator<C, T, L, D, R> createResourceOperations(Vertx vertx, C mockClient);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ClusterRoleBindingOperatorIT.java
Patch:
@@ -32,7 +32,7 @@ public class ClusterRoleBindingOperatorIT extends AbstractNonNamespacedResourceO
     protected AbstractNonNamespacedResourceOperator<KubernetesClient,
             ClusterRoleBinding, ClusterRoleBindingList, DoneableClusterRoleBinding,
             Resource<ClusterRoleBinding, DoneableClusterRoleBinding>> operator() {
-        return new ClusterRoleBindingOperator(vertx, client, 10_000);
+        return new ClusterRoleBindingOperator(vertx, client);
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ClusterRoleOperatorIT.java
Patch:
@@ -30,7 +30,7 @@ public class ClusterRoleOperatorIT extends AbstractNonNamespacedResourceOperator
     protected AbstractNonNamespacedResourceOperator<KubernetesClient,
             ClusterRole, ClusterRoleList, DoneableClusterRole,
             Resource<ClusterRole, DoneableClusterRole>> operator() {
-        return new ClusterRoleOperator(vertx, client, 10_000);
+        return new ClusterRoleOperator(vertx, client);
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/NodeOperatorIT.java
Patch:
@@ -27,7 +27,7 @@ public class NodeOperatorIT extends AbstractNonNamespacedResourceOperatorIT<Kube
     protected AbstractNonNamespacedResourceOperator<KubernetesClient,
             Node, NodeList, DoneableNode,
             Resource<Node, DoneableNode>> operator() {
-        return new NodeOperator(vertx, client, 10_000);
+        return new NodeOperator(vertx, client);
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ScalableResourceOperatorTest.java
Patch:
@@ -12,7 +12,7 @@
 
 public abstract class ScalableResourceOperatorTest<C extends KubernetesClient,
             T extends HasMetadata,
-            L extends KubernetesResourceList,
+            L extends KubernetesResourceList<T>,
             D extends Doneable<T>,
             R extends Resource<T, D>>
         extends AbtractReadyResourceOperatorTest<C, T, L, D, R> {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/StorageClassOperatorIT.java
Patch:
@@ -24,7 +24,7 @@ public class StorageClassOperatorIT extends AbstractNonNamespacedResourceOperato
 
     @Override
     protected AbstractNonNamespacedResourceOperator<KubernetesClient, StorageClass, StorageClassList, DoneableStorageClass, Resource<StorageClass, DoneableStorageClass>> operator() {
-        return new StorageClassOperator(vertx, client, 10_000);
+        return new StorageClassOperator(vertx, client);
     }
 
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/LogHasNoUnexpectedErrors.java
Patch:
@@ -78,7 +78,8 @@ enum LogWhiteList {
         RECONCILIATION_TIMEOUT("ERROR Abstract.*Operator:[0-9]+ - Reconciliation.*"),
         ASSEMBLY_OPERATOR_RECONCILIATION_TIMEOUT("ERROR .*AssemblyOperator:[0-9]+ - Reconciliation.*[fF]ailed.*"),
         WATCHER_CLOSED_EXCEPTION("ERROR AbstractOperator:.+ - Watcher closed with exception in namespace .*"),
-        CONCURRENT_RESOURCE_DELETION("io.strimzi.operator.cluster.operator.resource.ConcurrentDeletionException");
+        CONCURRENT_RESOURCE_DELETION("io.strimzi.operator.cluster.operator.resource.ConcurrentDeletionException"),
+        RECOVERY_STS_DELETION("java\\.lang\\.IllegalStateException: Can't wait for StatefulSet: recovery-cluster-(kafka|zookeeper) in namespace: recovery-cluster-test to scale. Resource is no longer available.");
 
         final String name;
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserST.java
Patch:
@@ -20,6 +20,7 @@
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;
+import io.strimzi.systemtest.utils.kubeUtils.objects.SecretUtils;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.executor.ExecResult;
 import org.apache.kafka.common.security.auth.SecurityProtocol;
@@ -321,6 +322,8 @@ void testCreatingUsersWithSecretPrefix() {
         KafkaUserUtils.waitForKafkaUserDeletion(scramShaUserName);
 
         LOGGER.info("Checking if secrets are deleted");
+        SecretUtils.waitForSecretDeletion(tlsSecret.getMetadata().getName());
+        SecretUtils.waitForSecretDeletion(scramShaSecret.getMetadata().getName());
         assertNull(kubeClient().getSecret(tlsSecret.getMetadata().getName()));
         assertNull(kubeClient().getSecret(scramShaSecret.getMetadata().getName()));
     }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -112,7 +112,7 @@ public abstract class AbstractST implements TestSeparator {
      * Don't use this method in tests, where specific configuration of CO is needed.
      * @param namespace namespace where CO should be installed into
      */
-    protected void installClusterOperator(String namespace, List<String> bindingsNamespaces, long operationTimeout, long reconciliationInterval) throws Exception {
+    protected void installClusterOperator(String namespace, List<String> bindingsNamespaces, long operationTimeout, long reconciliationInterval) {
         if (Environment.isOlmInstall()) {
             LOGGER.info("Going to install ClusterOperator via OLM");
             cluster.setNamespace(namespace);

File: systemtest/src/test/java/io/strimzi/systemtest/olm/AllNamespacesST.java
Patch:
@@ -76,7 +76,7 @@ void testDeployExampleKafkaRebalance() {
     }
 
     @BeforeAll
-    void setup() throws Exception {
+    void setup() {
         ResourceManager.setClassResources();
         cluster.setNamespace(cluster.getDefaultOlmNamespace());
         OlmResource.clusterOperator(cluster.getDefaultOlmNamespace());

File: systemtest/src/test/java/io/strimzi/systemtest/olm/SingleNamespaceST.java
Patch:
@@ -80,7 +80,7 @@ void testDeployExampleKafkaRebalance() {
     }
 
     @BeforeAll
-    void setup() throws Exception {
+    void setup() {
         ResourceManager.setClassResources();
         cluster.setNamespace(NAMESPACE);
         cluster.createNamespace(NAMESPACE);

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -106,7 +106,7 @@ public class Environment {
     private static final String ST_KAFKA_VERSION_DEFAULT = "2.6.0";
     public static final String STRIMZI_ORG_DEFAULT = "strimzi";
     public static final String STRIMZI_TAG_DEFAULT = "latest";
-    public static final String STRIMZI_REGISTRY_DEFAULT = "docker.io";
+    public static final String STRIMZI_REGISTRY_DEFAULT = "quay.io";
     private static final String TEST_LOG_DIR_DEFAULT = TestUtils.USER_PATH + "/../systemtest/target/logs/";
     private static final String STRIMZI_LOG_LEVEL_DEFAULT = "DEBUG";
     static final String KUBERNETES_DOMAIN_DEFAULT = ".nip.io";

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/ListenersST.java
Patch:
@@ -706,7 +706,7 @@ void testCustomChainCertificatesForNodePort() {
         );
 
         // Deploy client pod with custom certificates and collect messages from internal TLS listener
-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, false, customListenerName, aliceUser).done();
+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, false, customListenerName, null, aliceUser).done();
 
         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()
             .withUsingPodName(kubeClient().listPodsByPrefixInName(CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName())

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -705,6 +705,6 @@ void testMetricsChange() {
     @BeforeAll
     void setup() throws Exception {
         ResourceManager.setClassResources();
-        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_SHORT);
+        installClusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_DEFAULT);
     }
 }

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -207,8 +207,8 @@ public void handle(Long oldTimerId) {
                         if (!stopped) {
                             timerId = null;
                             boolean isInitialReconcile = oldTimerId == null;
+                            topicOperator.getPeriodicReconciliationsCounter().increment();
                             topicOperator.reconcileAllTopics(isInitialReconcile ? "initial " : "periodic ").onComplete(result -> {
-                                topicOperator.getPeriodicReconciliationsCounter().increment();
                                 if (isInitialReconcile) {
                                     initReconcilePromise.complete();
                                 }

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorTest.java
Patch:
@@ -139,7 +139,7 @@ public void testOnKafkaTopicAdded_ignorable(VertxTestContext context) {
         KafkaTopic kafkaTopic = new KafkaTopicBuilder().withMetadata(new ObjectMetaBuilder().withName("non-topic").build()).build();
 
         Checkpoint async = context.checkpoint();
-        K8sTopicWatcher w = new K8sTopicWatcher(topicOperator, Future.succeededFuture());
+        K8sTopicWatcher w = new K8sTopicWatcher(topicOperator, Future.succeededFuture(), () -> { });
         w.eventReceived(ADDED, kafkaTopic);
         mockKafka.assertEmpty(context);
         mockTopicStore.assertEmpty(context);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -174,6 +174,7 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
                     put("strimzi-kafka-broker", "030-ClusterRole-strimzi-kafka-broker.yaml");
                     put("strimzi-entity-operator", "031-ClusterRole-strimzi-entity-operator.yaml");
                     put("strimzi-topic-operator", "032-ClusterRole-strimzi-topic-operator.yaml");
+                    put("strimzi-kafka-client", "033-ClusterRole-strimzi-kafka-client.yaml");
                 }
             };
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1564,7 +1564,7 @@ public ClusterRoleBinding generateClusterRoleBinding(String assemblyNamespace) {
                     .withKind("ClusterRole")
                     .build();
 
-            return getClusterRoleBinding(ks, roleRef);
+            return getClusterRoleBinding(KafkaResources.initContainerClusterRoleBindingName(cluster, namespace), ks, roleRef);
         } else {
             return null;
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -798,7 +798,6 @@ public Tracing getTracing() {
      * @return The cluster role binding.
      */
     public ClusterRoleBinding generateClusterRoleBinding() {
-
         if (rack == null) {
             return null;
         }
@@ -815,7 +814,7 @@ public ClusterRoleBinding generateClusterRoleBinding() {
                 .withKind("ClusterRole")
                 .build();
 
-        return getClusterRoleBinding(subject, roleRef);
+        return getClusterRoleBinding(KafkaConnectResources.initContainerClusterRoleBindingName(cluster, namespace), subject, roleRef);
     }
 
     @Override

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -1695,7 +1695,7 @@ Future<ReconciliationState> kafkaInitServiceAccount() {
         Future<ReconciliationState> kafkaInitClusterRoleBinding() {
             ClusterRoleBinding desired = kafkaCluster.generateClusterRoleBinding(namespace);
             Future<ReconcileResult<ClusterRoleBinding>> fut = clusterRoleBindingOperations.reconcile(
-                    KafkaCluster.initContainerClusterRoleBindingName(namespace, name), desired);
+                    KafkaResources.initContainerClusterRoleBindingName(name, namespace), desired);
 
             Promise replacementPromise = Promise.promise();
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -43,6 +43,7 @@
 import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloakBuilder;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.KafkaJmxOptionsBuilder;
+import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.Rack;
 import io.strimzi.api.kafka.model.RackBuilder;
 import io.strimzi.api.kafka.model.SystemProperty;
@@ -2848,7 +2849,7 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
         KafkaCluster kc = KafkaCluster.fromCrd(kafkaAssembly, VERSIONS);
         ClusterRoleBinding crb = kc.generateClusterRoleBinding(testNamespace);
 
-        assertThat(crb.getMetadata().getName(), is(KafkaCluster.initContainerClusterRoleBindingName(testNamespace, cluster)));
+        assertThat(crb.getMetadata().getName(), is(KafkaResources.initContainerClusterRoleBindingName(cluster, testNamespace)));
         assertThat(crb.getMetadata().getNamespace(), is(nullValue()));
         assertThat(crb.getSubjects().get(0).getNamespace(), is(testNamespace));
         assertThat(crb.getSubjects().get(0).getName(), is(kc.getServiceAccountName()));
@@ -2870,7 +2871,7 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
         KafkaCluster kc = KafkaCluster.fromCrd(kafkaAssembly, VERSIONS);
         ClusterRoleBinding crb = kc.generateClusterRoleBinding(testNamespace);
 
-        assertThat(crb.getMetadata().getName(), is(KafkaCluster.initContainerClusterRoleBindingName(testNamespace, cluster)));
+        assertThat(crb.getMetadata().getName(), is(KafkaResources.initContainerClusterRoleBindingName(cluster, testNamespace)));
         assertThat(crb.getMetadata().getNamespace(), is(nullValue()));
         assertThat(crb.getSubjects().get(0).getNamespace(), is(testNamespace));
         assertThat(crb.getSubjects().get(0).getName(), is(kc.getServiceAccountName()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -1432,7 +1432,7 @@ public void testClusterRoleBindingRack() {
         KafkaConnectCluster kafkaConnectCluster = KafkaConnectCluster.fromCrd(kafkaConnect, VERSIONS);
         ClusterRoleBinding crb = kafkaConnectCluster.generateClusterRoleBinding();
 
-        assertThat(crb.getMetadata().getName(), is(KafkaConnectCluster.initContainerClusterRoleBindingName(testNamespace, cluster)));
+        assertThat(crb.getMetadata().getName(), is(KafkaConnectResources.initContainerClusterRoleBindingName(cluster, testNamespace)));
         assertThat(crb.getMetadata().getNamespace(), is(nullValue()));
         assertThat(crb.getSubjects().get(0).getNamespace(), is(testNamespace));
         assertThat(crb.getSubjects().get(0).getName(), is(kafkaConnectCluster.getServiceAccountName()));

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/MultipleListenersST.java
Patch:
@@ -44,7 +44,7 @@
 public class MultipleListenersST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(MultipleListenersST.class);
-    public static final String NAMESPACE = "multi-listener-namespace";
+    public static final String NAMESPACE = "multi-listener";
 
     // only 4 type of listeners
     private Map<KafkaListenerType, List<GenericKafkaListener>> testCases = new HashMap<>(4);
@@ -292,7 +292,7 @@ private Map<KafkaListenerType, List<GenericKafkaListener>> generateTestCases() {
                         boolean stochasticCommunication = ThreadLocalRandom.current().nextInt(2) == 0;
 
                         testCaseListeners.add(new GenericKafkaListenerBuilder()
-                            .withName(KafkaListenerType.LOADBALANCER.toValue() + j)
+                            .withName(KafkaListenerType.LOADBALANCER.toValue().substring(0, 5) + j)
                             .withPort(11900 + j)
                             .withType(KafkaListenerType.LOADBALANCER)
                             .withTls(stochasticCommunication)

File: api/src/main/java/io/strimzi/api/kafka/model/connect/ExternalConfigurationEnvVarSource.java
Patch:
@@ -48,7 +48,7 @@ public void setSecretKeyRef(SecretKeySelector secretKeyRef) {
         this.secretKeyRef = secretKeyRef;
     }
 
-    @Description("Refernce to a key in a ConfigMap.")
+    @Description("Reference to a key in a ConfigMap.")
     @KubeLink(group = "core", version = "v1", kind = "configmapkeyselector")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public ConfigMapKeySelector getConfigMapKeyRef() {

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -201,7 +201,7 @@ void testDiscoveryAnnotation() {
         Service bridgeService = kubeClient().getService(KafkaBridgeResources.serviceName(CLUSTER_NAME));
         String bridgeServiceDiscoveryAnnotation = bridgeService.getMetadata().getAnnotations().get("strimzi.io/discovery");
         JsonArray serviceDiscoveryArray = new JsonArray(bridgeServiceDiscoveryAnnotation);
-        assertThat(serviceDiscoveryArray, is(StUtils.expectedServiceDiscoveryInfo(8080, "http", "none")));
+        assertThat(serviceDiscoveryArray, is(StUtils.expectedServiceDiscoveryInfo(8080, "http", "none", false)));
     }
 
     @Test

File: user-operator/src/main/java/io/strimzi/operator/user/Main.java
Patch:
@@ -90,7 +90,8 @@ static Future<String> run(Vertx vertx, KubernetesClient client, AdminClientProvi
                     KafkaUserOperator kafkaUserOperations = new KafkaUserOperator(vertx,
                             certManager, crdOperations,
                             config.getLabels(),
-                            secretOperations, scramShaCredentialsOperator, quotasOperator, aclOperations, config.getCaCertSecretName(), config.getCaKeySecretName(), config.getCaNamespace());
+                            secretOperations, scramShaCredentialsOperator, quotasOperator, aclOperations, config.getCaCertSecretName(), config.getCaKeySecretName(), config.getCaNamespace(),
+                            config.getSecretPrefix());
 
                     Promise<String> promise = Promise.promise();
                     UserOperator operator = new UserOperator(config.getNamespace(),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -1537,7 +1537,7 @@ public void testGenerateBrokerSecretExternalWithManyDNS() throws CertificatePars
 
     private Secret generateBrokerSecret(Set<String> externalBootstrapAddress, Map<Integer, Set<String>> externalAddresses) {
         ClusterCa clusterCa = new ClusterCa(new OpenSslCertManager(), new PasswordGenerator(10, "a", "a"), cluster, null, null);
-        clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), null, true);
+        clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), emptyMap(), emptyMap(), null, true);
 
         kc.generateCertificates(kafkaAssembly, clusterCa, externalBootstrapAddress, externalAddresses, true);
         return kc.generateBrokersSecret();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -338,7 +338,7 @@ public void checkOwnerReference(OwnerReference ownerRef, HasMetadata resource)
     @Test
     public void testGenerateBrokerSecret() throws CertificateParsingException {
         ClusterCa clusterCa = new ClusterCa(new OpenSslCertManager(), new PasswordGenerator(10, "a", "a"), cluster, null, null);
-        clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), null, true);
+        clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), emptyMap(), emptyMap(), null, true);
 
         Secret secret = zc.generateNodesSecret(clusterCa, ka, true);
         assertThat(secret.getData().keySet(), is(set(

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/ServiceUtils.java
Patch:
@@ -98,7 +98,7 @@ public static void waitUntilAddressIsReachable(String address) {
         TestUtils.waitFor("", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,
             () -> {
                 try {
-                    InetAddress.getByName(kubeClient().getService("my-cluster-kafka-external-bootstrap").getStatus().getLoadBalancer().getIngress().get(0).getHostname());
+                    InetAddress.getByName(address);
                     return true;
                 } catch (IOException e) {
                     return false;

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/BackwardsCompatibleListenersST.java
Patch:
@@ -220,7 +220,7 @@ void testLoadBalancerTls() {
         KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();
         KafkaUserResource.tlsUser(CLUSTER_NAME, kafkaUsername).done();
 
-        ServiceUtils.waitUntilAddressIsReachable(kubeClient().getService(KafkaResources.externalBootstrapServiceName(CLUSTER_NAME)).getStatus().getLoadBalancer().getIngress().get(0).getHostname());
+        ServiceUtils.waitUntilAddressIsReachable(KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getListeners().get(0).getAddresses().get(0).getHost());
 
         BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()
                 .withTopicName(topicName)
@@ -229,6 +229,7 @@ void testLoadBalancerTls() {
                 .withMessageCount(MESSAGE_COUNT)
                 .withKafkaUsername(kafkaUsername)
                 .withSecurityProtocol(SecurityProtocol.SSL)
+                .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)
                 .build();
 
         basicExternalKafkaClient.verifyProducedAndConsumedMessages(
@@ -268,6 +269,7 @@ void testRouteTls() {
                 .withMessageCount(MESSAGE_COUNT)
                 .withKafkaUsername(kafkaUsername)
                 .withSecurityProtocol(SecurityProtocol.SSL)
+                .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)
                 .build();
 
         basicExternalKafkaClient.verifyProducedAndConsumedMessages(

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/listeners/ListenersST.java
Patch:
@@ -500,7 +500,7 @@ void testLoadBalancer() {
             .endSpec()
             .done();
 
-        ServiceUtils.waitUntilAddressIsReachable(kubeClient().getService(KafkaResources.externalBootstrapServiceName(CLUSTER_NAME)).getStatus().getLoadBalancer().getIngress().get(0).getHostname());
+        ServiceUtils.waitUntilAddressIsReachable(KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getListeners().get(0).getAddresses().get(0).getHost());
 
         BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()
             .withTopicName(TOPIC_NAME)
@@ -540,7 +540,7 @@ void testLoadBalancerTls() {
 
         KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();
 
-        ServiceUtils.waitUntilAddressIsReachable(kubeClient().getService(KafkaResources.externalBootstrapServiceName(CLUSTER_NAME)).getStatus().getLoadBalancer().getIngress().get(0).getHostname());
+        ServiceUtils.waitUntilAddressIsReachable(KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getListeners().get(0).getAddresses().get(0).getHost());
 
         BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()
             .withTopicName(TOPIC_NAME)
@@ -1698,7 +1698,7 @@ void testCustomCertRouteAndTlsRollingUpdate() {
             basicExternalKafkaClient.receiveMessagesTls()
         );
 
-        basicExternalKafkaClient = basicExternalKafkaClient.toBuilder()
+        internalKafkaClient = internalKafkaClient.toBuilder()
             .withConsumerGroupName("consumer-group-certs-92")
             .withMessageCount(MESSAGE_COUNT * 5)
             .build();

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -756,6 +756,7 @@ void testNetworkPoliciesWithPlainListener() {
             .withMessageCount(MESSAGE_COUNT)
             .withKafkaUsername(userName)
             .withSecurityProtocol(SecurityProtocol.PLAINTEXT)
+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)
             .build();
 
         internalKafkaClient.checkProducedAndConsumedMessages(
@@ -844,6 +845,7 @@ void testNetworkPoliciesWithTlsListener() {
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
             .withKafkaUsername(userName)
+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)
             .build();
 
         internalKafkaClient.checkProducedAndConsumedMessages(

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -105,6 +105,7 @@ void testRackAware() {
             .withNamespaceName(NAMESPACE)
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
+            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)
             .build();
 
         basicExternalKafkaClient.verifyProducedAndConsumedMessages(
@@ -153,6 +154,7 @@ void testLoadBalancerIpOverride() {
             .withNamespaceName(NAMESPACE)
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
+            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)
             .build();
 
         basicExternalKafkaClient.verifyProducedAndConsumedMessages(
@@ -223,6 +225,7 @@ void testLoadBalancerSourceRanges() {
             .withNamespaceName(NAMESPACE)
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
+            .withListenerName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)
             .build();
 
         basicExternalKafkaClient.verifyProducedAndConsumedMessages(

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -441,7 +441,7 @@ private List<VolumeMount> getExternalConfigurationVolumeMounts()    {
                     log.warn("Volume {} with external Kafka Connect configuration has to contain exactly one volume source reference to either ConfigMap or Secret", name);
                 } else  if (volume.getConfigMap() != null || volume.getSecret() != null) {
                     VolumeMount volumeMount = new VolumeMountBuilder()
-                            .withName(EXTERNAL_CONFIGURATION_VOLUME_NAME_PREFIX + name)
+                            .withName(VolumeUtils.getValidVolumeName(EXTERNAL_CONFIGURATION_VOLUME_NAME_PREFIX + name))
                             .withMountPath(EXTERNAL_CONFIGURATION_VOLUME_MOUNT_BASE_PATH + name)
                             .build();
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeCorsST.java
Patch:
@@ -74,7 +74,7 @@ void testCorsOriginAllowed() {
 
         url = bridgeUrl + "/consumers/" + groupId + "/instances/" + kafkaBridgeUser + "/subscription";
         headers = BridgeUtils.addHeadersToString(Collections.singletonMap("Origin", ALLOWED_ORIGIN));
-        response = cmdKubeClient().execInPod(kafkaClientsPodName, "/bin/bash", "-c", BridgeUtils.buildCurlCommand(HttpMethod.POST, url, headers, "")).out().trim();
+        response = cmdKubeClient().execInPod(kafkaClientsPodName, "/bin/bash", "-c", BridgeUtils.buildCurlCommand(HttpMethod.GET, url, headers, "")).out().trim();
         LOGGER.info("Response from Bridge: {}", response);
 
         assertThat(response, containsString("404"));

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -103,7 +103,7 @@ void testTlsAuthWithWeirdUsername() {
     private void testWeirdUsername(String weirdUserName, KafkaListenerAuthentication auth, KafkaBridgeSpec spec, SecurityProtocol securityProtocol) {
         String aliceUser = "alice";
 
-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)
+        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)
             .editSpec()
                 .editKafka()
                     .withNewListeners()

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractReadyResourceOperator.java
Patch:
@@ -58,6 +58,8 @@ public boolean isReady(String namespace, String name) {
             if (Readiness.isReadinessApplicable(resource.getClass())) {
                 return Boolean.TRUE.equals(resourceOp.isReady());
             } else {
+                log.warn("Method isReady was called on resource {} of kind {} on which readiness is not applicable.",
+                        resource.getMetadata().getName(), resource.getKind());
                 return true;
             }
         } else {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/DeploymentConfigUtils.java
Patch:
@@ -114,7 +114,7 @@ public static void waitForDeploymentConfigReady(String depConfigName) {
 
         TestUtils.waitFor(String.format("Wait for DeploymentConfig: %s will be ready", depConfigName),
             Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, READINESS_TIMEOUT,
-            () -> kubeClient().getDeploymentConfigStatus(depConfigName),
+            () -> kubeClient().getDeploymentConfigReadiness(depConfigName),
             () -> {
                 if (kubeClient().getDeploymentConfig(depConfigName) != null) {
                     LOGGER.info(kubeClient().getDeploymentConfig(depConfigName));

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectS2IST.java
Patch:
@@ -241,6 +241,7 @@ void testSecretsWithKafkaConnectS2IWithTlsAndScramShaAuthentication() {
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
             .withKafkaUsername(userName)
+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)
             .build();
 
         String kafkaConnectS2IPodName = kubeClient().listPods(Labels.STRIMZI_KIND_LABEL, KafkaConnectS2I.RESOURCE_KIND).get(0).getMetadata().getName();
@@ -493,6 +494,7 @@ void testMultiNodeKafkaConnectS2IWithConnectorCreation() {
             .withNamespaceName(NAMESPACE)
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)
             .build();
 
         String execConnectPod =  kubeClient().listPods(Labels.STRIMZI_KIND_LABEL, KafkaConnectS2I.RESOURCE_KIND).get(0).getMetadata().getName();

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/Consumer.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.kafkaclients.externalClients;
 
-import io.strimzi.systemtest.kafkaclients.KafkaClientProperties;
+import io.strimzi.systemtest.kafkaclients.clientproperties.ConsumerProperties;
 import io.vertx.core.Vertx;
 import io.vertx.kafka.client.consumer.KafkaConsumer;
 import org.apache.kafka.clients.consumer.ConsumerConfig;
@@ -17,13 +17,13 @@
 
 public class Consumer extends ClientHandlerBase<Integer> implements AutoCloseable {
     private static final Logger LOGGER = LogManager.getLogger(Consumer.class);
-    private final KafkaClientProperties properties;
+    private final ConsumerProperties properties;
     private final AtomicInteger numReceived = new AtomicInteger(0);
     private final String topic;
     private final String clientName;
     private final KafkaConsumer<String, String> consumer;
 
-    Consumer(KafkaClientProperties properties, CompletableFuture<Integer> resultPromise, IntPredicate msgCntPredicate, String topic, String clientName) {
+    Consumer(ConsumerProperties properties, CompletableFuture<Integer> resultPromise, IntPredicate msgCntPredicate, String topic, String clientName) {
         super(resultPromise, msgCntPredicate);
         this.properties = properties;
         this.topic = topic;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/VerifiableClient.java
Patch:
@@ -147,6 +147,8 @@ public VerifiableClient(VerifiableClientBuilder verifiableClientBuilder) {
             }
         }
 
+        LOGGER.debug("This is all args {}, which are set.", this.clientArgumentMap);
+
         this.setArguments(this.clientArgumentMap);
         this.executable = ClientType.getCommand(clientType);
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -13,6 +13,7 @@
 import io.fabric8.kubernetes.api.model.ConfigMap;
 import io.strimzi.api.kafka.model.ContainerEnvVar;
 import io.strimzi.api.kafka.model.ContainerEnvVarBuilder;
+import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.vertx.core.json.JsonArray;
 import io.vertx.core.json.JsonObject;
@@ -191,7 +192,7 @@ public static List<String> getLinesWithoutCommentsAndEmptyLines(String config) {
     public static JsonArray expectedServiceDiscoveryInfo(int port, String protocol, String auth) {
         JsonObject jsonObject = new JsonObject();
         jsonObject.put("port", port);
-        jsonObject.put("tls", port == 9093);
+        jsonObject.put(Constants.TLS_LISTENER_DEFAULT_NAME, port == 9093);
         jsonObject.put("protocol", protocol);
         jsonObject.put("auth", auth);
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -12,6 +12,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.status.KafkaBridgeStatus;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
 import io.strimzi.systemtest.utils.ClientUtils;
@@ -67,6 +68,7 @@ void testSendSimpleMessage() {
             .withMessageCount(MESSAGE_COUNT)
             .withKafkaUsername(USER_NAME)
             .withUsingPodName(kafkaClientsPodName)
+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)
             .build();
 
         assertThat(internalKafkaClient.receiveMessagesPlain(), is(MESSAGE_COUNT));
@@ -90,6 +92,7 @@ void testReceiveSimpleMessage() {
             .withMessageCount(MESSAGE_COUNT)
             .withKafkaUsername(USER_NAME)
             .withUsingPodName(kafkaClientsPodName)
+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)
             .build();
 
         assertThat(internalKafkaClient.sendMessagesPlain(), is(MESSAGE_COUNT));

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectS2IST.java
Patch:
@@ -188,7 +188,7 @@ void testSecretsWithKafkaConnectS2IWithTlsAndScramShaAuthentication() {
                 .editKafka()
                     .withNewListeners()
                         .addNewGenericKafkaListener()
-                            .withName("tls")
+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)
                             .withPort(9093)
                             .withType(KafkaListenerType.INTERNAL)
                             .withTls(true)

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -181,9 +181,9 @@ void testKafkaExporterDataAfterExchange() {
             .withNamespaceName(NAMESPACE)
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(5000)
+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)
             .build();
 
-        internalKafkaClient.setPodName(defaultKafkaClientsPodName);
         internalKafkaClient.checkProducedAndConsumedMessages(
             internalKafkaClient.sendMessagesPlain(),
             internalKafkaClient.receiveMessagesPlain()

File: systemtest/src/test/java/io/strimzi/systemtest/operators/user/UserST.java
Patch:
@@ -99,7 +99,7 @@ void testUpdateUser() {
 
         assertThat(kafkaUserAsJson, hasJsonPath("$.metadata.name", equalTo(USER_NAME)));
         assertThat(kafkaUserAsJson, hasJsonPath("$.metadata.namespace", equalTo(NAMESPACE)));
-        assertThat(kafkaUserAsJson, hasJsonPath("$.spec.authentication.type", equalTo("tls")));
+        assertThat(kafkaUserAsJson, hasJsonPath("$.spec.authentication.type", equalTo(Constants.TLS_LISTENER_DEFAULT_NAME)));
 
         long observedGeneration = KafkaUserResource.kafkaUserClient().inNamespace(kubeClient().getNamespace()).withName(USER_NAME).get().getStatus().getObservedGeneration();
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationST.java
Patch:
@@ -8,6 +8,7 @@
 import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloak;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
+import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.keycloak.KeycloakInstance;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
@@ -283,7 +284,7 @@ void setUp()  {
                 .editKafka()
                     .withNewListeners()
                         .addNewGenericKafkaListener()
-                            .withName("tls")
+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)
                             .withPort(9093)
                             .withType(KafkaListenerType.INTERNAL)
                             .withTls(true)

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -196,7 +196,7 @@ void testMirrorMaker() {
                 .editKafka()
                     .withNewListeners()
                         .addNewGenericKafkaListener()
-                            .withName("tls")
+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)
                             .withPort(9093)
                             .withType(KafkaListenerType.INTERNAL)
                             .withTls(true)
@@ -215,7 +215,7 @@ void testMirrorMaker() {
                             .endKafkaListenerAuthenticationOAuth()
                         .endGenericKafkaListener()
                         .addNewGenericKafkaListener()
-                            .withName("external")
+                            .withName(Constants.EXTERNAL_LISTENER_DEFAULT_NAME)
                             .withPort(9094)
                             .withType(KafkaListenerType.NODEPORT)
                             .withTls(true)
@@ -404,7 +404,7 @@ void setUp() {
                 .editKafka()
                     .withNewListeners()
                         .addNewGenericKafkaListener()
-                            .withName("tls")
+                            .withName(Constants.TLS_LISTENER_DEFAULT_NAME)
                             .withPort(9093)
                             .withType(KafkaListenerType.INTERNAL)
                             .withTls(true)

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java
Patch:
@@ -115,6 +115,7 @@ void deployKafkaConnectorWithSink(String clusterName, String namespace, String t
             .withNamespaceName(namespace)
             .withClusterName(clusterName)
             .withMessageCount(MESSAGE_COUNT)
+            .withListenerName(Constants.PLAIN_LISTENER_DEFAULT_NAME)
             .build();
 
         int sent = internalKafkaClient.sendMessagesPlain();

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceST.java
Patch:
@@ -170,6 +170,7 @@ void testUserInDifferentNamespace() {
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
             .withKafkaUsername(USER_NAME)
+            .withListenerName(Constants.TLS_LISTENER_DEFAULT_NAME)
             .build();
 
         LOGGER.info("Checking produced and consumed messages to pod:{}", defaultKafkaClientsPodName);

File: operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java
Patch:
@@ -83,6 +83,9 @@ public Admin createAdminClient(String bootstrapHostnames, Secret clusterCaCertSe
                 }
 
                 p.setProperty(AdminClientConfig.METADATA_MAX_AGE_CONFIG, "30000");
+                p.setProperty(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, "10000");
+                p.setProperty(AdminClientConfig.RETRIES_CONFIG, "3");
+                p.setProperty(AdminClientConfig.DEFAULT_API_TIMEOUT_MS_CONFIG, "40000");
 
                 ac = Admin.create(p);
             } finally {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -216,7 +216,9 @@ public Future<Void> maybeRollKafka(StatefulSet sts, Function<Pod, List<String>>
                         }
                     }
                 }
-                .kafkaVersionChange();
+                .kafkaVersionChangeCheck()
+                .compose(res -> res.kafkaVersionChange(false));
+
         AtomicReference<UpgradeException> ex = new AtomicReference<>();
         future.onComplete(ar -> {
             if (ar.failed()) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectApi.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.strimzi.api.kafka.model.connect.ConnectorPlugin;
 import io.strimzi.operator.common.BackOff;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.vertx.core.Future;
 import io.vertx.core.http.HttpClientResponse;
 import io.vertx.core.json.JsonObject;
@@ -120,11 +121,11 @@ public interface KafkaConnectApi {
      * @param host The host to make the request to.
      * @param port The port to make the request to.
      * @param desiredLogging Desired logging.
+     * @param defaultLogging Default logging.
      * @return A Future which completes with the result of the request. If the request was successful,
      * this returns the list of connector loggers.
      */
-    Future<Void> updateConnectLoggers(String host, int port, String desiredLogging);
-
+    Future<Void> updateConnectLoggers(String host, int port, String desiredLogging, OrderedProperties defaultLogging);
 
     /**
      * Make a {@code GET} request to {@code /admin/loggers}.

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -146,7 +146,7 @@ protected Future<KafkaConnectStatus> createOrUpdate(Reconciliation reconciliatio
                 .compose(i -> deploymentOperations.scaleUp(namespace, connect.getName(), connect.getReplicas()))
                 .compose(i -> deploymentOperations.waitForObserved(namespace, connect.getName(), 1_000, operationTimeoutMs))
                 .compose(i -> connectHasZeroReplicas ? Future.succeededFuture() : deploymentOperations.readiness(namespace, connect.getName(), 1_000, operationTimeoutMs))
-                .compose(i -> reconcileConnectors(reconciliation, kafkaConnect, kafkaConnectStatus, connectHasZeroReplicas, desiredLogging))
+                .compose(i -> reconcileConnectors(reconciliation, kafkaConnect, kafkaConnectStatus, connectHasZeroReplicas, desiredLogging, connect.getDefaultLogConfig()))
                 .onComplete(reconciliationResult -> {
                     StatusUtils.setStatusConditionAndObservedGeneration(kafkaConnect, kafkaConnectStatus, reconciliationResult);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -157,7 +157,7 @@ public Future<KafkaConnectS2IStatus> createOrUpdate(Reconciliation reconciliatio
                 .compose(i -> deploymentConfigOperations.scaleUp(namespace, connect.getName(), connect.getReplicas()))
                 .compose(i -> deploymentConfigOperations.waitForObserved(namespace, connect.getName(), 1_000, operationTimeoutMs))
                 .compose(i -> connectHasZeroReplicas ? Future.succeededFuture() : deploymentConfigOperations.readiness(namespace, connect.getName(), 1_000, operationTimeoutMs))
-                .compose(i -> reconcileConnectors(reconciliation, kafkaConnectS2I, kafkaConnectS2Istatus, connectHasZeroReplicas, desiredLogging))
+                .compose(i -> reconcileConnectors(reconciliation, kafkaConnectS2I, kafkaConnectS2Istatus, connectHasZeroReplicas, desiredLogging, connect.getDefaultLogConfig()))
                 .onComplete(reconciliationResult -> {
                     StatusUtils.setStatusConditionAndObservedGeneration(kafkaConnectS2I, kafkaConnectS2Istatus, reconciliationResult);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -261,7 +261,7 @@ private Future<Void> reconcileMirrorMaker2Connectors(Reconciliation reconciliati
                         return reconcileMirrorMaker2Connector(reconciliation, mirrorMaker2, apiClient, host, connectorName, connectorSpec, mirrorMaker2Status);
                     })                            
                     .collect(Collectors.toList()))
-                    .map((Void) null).compose(i -> apiClient.updateConnectLoggers(host, KafkaConnectCluster.REST_API_PORT, desiredLogging));
+                    .map((Void) null).compose(i -> apiClient.updateConnectLoggers(host, KafkaConnectCluster.REST_API_PORT, desiredLogging, mirrorMaker2Cluster.getDefaultLogConfig()));
     }
 
     private static void prepareMirrorMaker2ConnectorConfig(KafkaMirrorMaker2MirrorSpec mirror, KafkaMirrorMaker2ClusterSpec sourceCluster, KafkaMirrorMaker2ClusterSpec targetCluster, KafkaConnectorSpec connectorSpec, KafkaMirrorMaker2Cluster mirrorMaker2Cluster) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiff.java
Patch:
@@ -98,6 +98,8 @@ public boolean canBeUpdatedDynamically() {
         for (AlterConfigOp entry : diff) {
             if (isEntryReadOnly(entry.configEntry())) {
                 result = false;
+                log.debug("Configuration can't be updated dynamically due to: {}", entry);
+                break;
             }
         }
         return result;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -37,6 +37,7 @@
 import io.strimzi.operator.common.DefaultAdminClientProvider;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.operator.common.operator.resource.SecretOperator;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.mockkube.MockKube;
@@ -172,7 +173,7 @@ public void setup(VertxTestContext testContext) {
                     .build();
             return Future.succeededFuture(Collections.singletonList(connectorPlugin));
         });
-        when(api.updateConnectLoggers(anyString(), anyInt(), anyString())).thenReturn(Future.succeededFuture());
+        when(api.updateConnectLoggers(anyString(), anyInt(), anyString(), any(OrderedProperties.class))).thenReturn(Future.succeededFuture());
         when(api.getConnectorConfig(any(), any(), anyInt(), any())).thenAnswer(invocation -> {
             String host = invocation.getArgument(1);
             String connectorName = invocation.getArgument(3);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -24,6 +24,7 @@
 import io.strimzi.operator.common.BackOff;
 import io.strimzi.operator.common.DefaultAdminClientProvider;
 import io.strimzi.operator.common.Reconciliation;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.operator.common.operator.resource.SecretOperator;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.mockkube.MockKube;
@@ -47,6 +48,7 @@
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.CoreMatchers.notNullValue;
 import static org.hamcrest.MatcherAssert.assertThat;
+import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.anyInt;
 import static org.mockito.ArgumentMatchers.anyString;
 import static org.mockito.Mockito.mock;
@@ -147,7 +149,7 @@ public void testReconcileUpdate(VertxTestContext context) {
             .build());
         KafkaConnectApi mock = mock(KafkaConnectApi.class);
         when(mock.list(anyString(), anyInt())).thenReturn(Future.succeededFuture(emptyList()));
-        when(mock.updateConnectLoggers(anyString(), anyInt(), anyString())).thenReturn(Future.succeededFuture());
+        when(mock.updateConnectLoggers(anyString(), anyInt(), anyString(), any(OrderedProperties.class))).thenReturn(Future.succeededFuture());
 
         Checkpoint async = context.checkpoint();
         createMirrorMaker2Cluster(context, mock)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerLoggingConfigurationDiffTest.java
Patch:
@@ -95,7 +95,8 @@ String getRealisticDesiredConfig() {
                 "log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\n" +
                 "log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\n" +
                 "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %m (%c) [%t]%n\n" +
-                "log4j.rootLogger=INFO, CONSOLE\n" +
+                "root.logger.level=INFO\n " +
+                "log4j.rootLogger=${root.logger.level}, CONSOLE\n" +
                 "log4j.logger.org.I0Itec.zkclient.ZkClient=INFO\n" +
                 "log4j.logger.org.apache.zookeeper=INFO\n" +
                 "log4j.logger.kafka=DEBUG\n" +

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -501,7 +501,7 @@ void testExternalLoggingChangeTriggerRollingUpdate() {
 
         String loggersConfig = "log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\n" +
                 "log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\n" +
-                "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %m (%c) [%t]%n\n" +
+                "log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} %p %m (%c) [%t]\n" +
                 "kafka.root.logger.level=INFO\n" +
                 "log4j.rootLogger=${kafka.root.logger.level}, CONSOLE\n" +
                 "log4j.logger.org.I0Itec.zkclient.ZkClient=INFO\n" +
@@ -540,7 +540,7 @@ void testExternalLoggingChangeTriggerRollingUpdate() {
         zkPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME), 3, zkPods);
         kafkaPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaPods);
 
-        configMapLoggers.getData().put("log4j.properties", loggersConfig.replace("INFO", "DEBUG"));
+        configMapLoggers.getData().put("log4j.properties", loggersConfig.replace("%p %m (%c) [%t]", "%p %m (%c) [%t]%n"));
         configMapLoggers.getData().put("log4j2.properties", loggersConfig.replace("INFO", "DEBUG"));
         kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapLoggers);
 

File: api/src/main/java/io/strimzi/api/kafka/model/Constants.java
Patch:
@@ -8,6 +8,8 @@
 public class Constants {
     public static final String RESOURCE_GROUP_NAME = "kafka.strimzi.io";
 
+    public static final String V1 = "v1";
+    public static final String V1BETA2 = "v1beta2";
     public static final String V1BETA1 = "v1beta1";
     public static final String V1ALPHA1 = "v1alpha1";
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridge.java
Patch:
@@ -31,7 +31,6 @@
 
 @JsonDeserialize
 @Crd(
-        apiVersion = KafkaBridge.CRD_API_VERSION,
         spec = @Crd.Spec(
                 names = @Crd.Spec.Names(
                         kind = KafkaBridge.RESOURCE_KIND,
@@ -41,7 +40,6 @@
                 ),
                 group = KafkaBridge.RESOURCE_GROUP,
                 scope = KafkaBridge.SCOPE,
-                version = KafkaBridge.V1ALPHA1,
                 versions = {
                         @Crd.Spec.Version(
                                 name = KafkaBridge.V1ALPHA1,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnect.java
Patch:
@@ -31,7 +31,6 @@
 
 @JsonDeserialize
 @Crd(
-        apiVersion = KafkaConnect.CRD_API_VERSION,
         spec = @Crd.Spec(
                 names = @Crd.Spec.Names(
                         kind = KafkaConnect.RESOURCE_KIND,
@@ -41,7 +40,6 @@
                 ),
                 group = KafkaConnect.RESOURCE_GROUP,
                 scope = KafkaConnect.SCOPE,
-                version = KafkaConnect.V1BETA1,
                 versions = {
                         @Crd.Spec.Version(
                                 name = KafkaConnect.V1BETA1,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectS2I.java
Patch:
@@ -34,7 +34,6 @@
         using = JsonDeserializer.None.class
 )
 @Crd(
-        apiVersion = KafkaConnectS2I.CRD_API_VERSION,
         spec = @Crd.Spec(
                 names = @Crd.Spec.Names(
                         kind = KafkaConnectS2I.RESOURCE_KIND,
@@ -44,7 +43,6 @@
                 ),
                 group = KafkaConnectS2I.RESOURCE_GROUP,
                 scope = KafkaConnectS2I.SCOPE,
-                version = KafkaConnectS2I.V1BETA1,
                 versions = {
                         @Crd.Spec.Version(
                                 name = KafkaConnectS2I.V1BETA1,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnector.java
Patch:
@@ -28,7 +28,6 @@
 import static java.util.Collections.unmodifiableList;
 
 @Crd(
-        apiVersion = KafkaConnector.CRD_API_VERSION,
         spec = @Crd.Spec(
                 names = @Crd.Spec.Names(
                         kind = KafkaConnector.RESOURCE_KIND,
@@ -38,7 +37,6 @@
                 ),
                 group = KafkaConnector.RESOURCE_GROUP,
                 scope = KafkaConnector.SCOPE,
-                version = KafkaConnector.V1ALPHA1,
                 versions = {
                         @Crd.Spec.Version(
                                 name = KafkaConnector.V1ALPHA1,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker.java
Patch:
@@ -31,7 +31,6 @@
 
 @JsonDeserialize
 @Crd(
-        apiVersion = KafkaMirrorMaker.CRD_API_VERSION,
         spec = @Crd.Spec(
                 names = @Crd.Spec.Names(
                         kind = KafkaMirrorMaker.RESOURCE_KIND,
@@ -41,7 +40,6 @@
                 ),
                 group = KafkaMirrorMaker.RESOURCE_GROUP,
                 scope = KafkaMirrorMaker.SCOPE,
-                version = KafkaMirrorMaker.V1BETA1,
                 versions = {
                         @Crd.Spec.Version(
                                 name = KafkaMirrorMaker.V1BETA1,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2.java
Patch:
@@ -30,7 +30,6 @@
 
 @JsonDeserialize
 @Crd(
-        apiVersion = KafkaMirrorMaker2.CRD_API_VERSION,
         spec = @Crd.Spec(
                 names = @Crd.Spec.Names(
                         kind = KafkaMirrorMaker2.RESOURCE_KIND,
@@ -40,7 +39,6 @@
                 ),
                 group = KafkaMirrorMaker2.RESOURCE_GROUP,
                 scope = KafkaMirrorMaker2.SCOPE,
-                version = KafkaMirrorMaker2.V1ALPHA1,
                 versions = {
                         @Crd.Spec.Version(
                                 name = KafkaMirrorMaker2.V1ALPHA1,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaRebalance.java
Patch:
@@ -30,7 +30,6 @@
 
 @JsonDeserialize
 @Crd(
-        apiVersion = KafkaRebalance.CRD_API_VERSION,
         spec = @Crd.Spec(
                 names = @Crd.Spec.Names(
                         kind = KafkaRebalance.RESOURCE_KIND,
@@ -40,7 +39,6 @@
                 ),
                 group = KafkaRebalance.RESOURCE_GROUP,
                 scope = KafkaRebalance.SCOPE,
-                version = KafkaRebalance.V1ALPHA1,
                 versions = {
                         @Crd.Spec.Version(
                                 name = KafkaRebalance.V1ALPHA1,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaSpec.java
Patch:
@@ -11,6 +11,7 @@
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
 import io.strimzi.api.annotations.DeprecatedProperty;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.PresentInVersions;
 import io.sundr.builder.annotations.Buildable;
 import lombok.EqualsAndHashCode;
 
@@ -63,6 +64,7 @@ public void setZookeeper(ZookeeperClusterSpec zookeeper) {
         this.zookeeper = zookeeper;
     }
 
+    @PresentInVersions("v1alpha1-v1beta1")
     @Deprecated
     @DeprecatedProperty(
             movedToPath = "spec.entityOperator.topicOperator"

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaTopic.java
Patch:
@@ -32,7 +32,6 @@
 
 @JsonDeserialize
 @Crd(
-        apiVersion = KafkaTopic.CRD_API_VERSION,
         spec = @Crd.Spec(
                 names = @Crd.Spec.Names(
                         kind = KafkaTopic.RESOURCE_KIND,
@@ -42,7 +41,6 @@
                 ),
                 group = KafkaTopic.RESOURCE_GROUP,
                 scope = KafkaTopic.SCOPE,
-                version = KafkaTopic.V1BETA1,
                 versions = {
                         @Crd.Spec.Version(
                                 name = KafkaTopic.V1BETA1,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUser.java
Patch:
@@ -30,7 +30,6 @@
 
 @JsonDeserialize
 @Crd(
-        apiVersion = KafkaUser.CRD_API_VERSION,
         spec = @Crd.Spec(
                 names = @Crd.Spec.Names(
                         kind = KafkaUser.RESOURCE_KIND,
@@ -40,7 +39,6 @@
                 ),
                 group = KafkaUser.RESOURCE_GROUP,
                 scope = KafkaUser.SCOPE,
-                version = KafkaUser.V1BETA1,
                 versions = {
                         @Crd.Spec.Version(
                                 name = KafkaUser.V1BETA1,

File: api/src/main/java/io/strimzi/api/kafka/model/template/KafkaClusterTemplate.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.model.Constants;
 import io.strimzi.api.kafka.model.UnknownPropertyPreserving;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.PresentInVersions;
 import io.sundr.builder.annotations.Buildable;
 import lombok.EqualsAndHashCode;
 
@@ -180,6 +181,7 @@ public void setKafkaContainer(ContainerTemplate kafkaContainer) {
         this.kafkaContainer = kafkaContainer;
     }
 
+    @PresentInVersions("v1alpha1-v1beta1")
     @DeprecatedProperty
     @Deprecated
     @Description("Template for the Kafka broker TLS sidecar container")

File: api/src/main/java/io/strimzi/api/kafka/model/template/ZookeeperClusterTemplate.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.model.Constants;
 import io.strimzi.api.kafka.model.UnknownPropertyPreserving;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.PresentInVersions;
 import io.sundr.builder.annotations.Buildable;
 import lombok.EqualsAndHashCode;
 
@@ -112,6 +113,7 @@ public void setZookeeperContainer(ContainerTemplate zookeeperContainer) {
         this.zookeeperContainer = zookeeperContainer;
     }
 
+    @PresentInVersions("v1alpha1-v1beta1")
     @DeprecatedProperty
     @Deprecated
     @Description("Template for the Zookeeper server TLS sidecar container. " +

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaTest.java
Patch:
@@ -61,7 +61,7 @@ public void testOldListenerSerialization() throws URISyntaxException {
                     .endZookeeper()
                     .withNewKafka()
                         .withReplicas(1)
-                        .withListeners(new ArrayOrObjectKafkaListeners(null, listeners))
+                        .withListeners(new ArrayOrObjectKafkaListeners(listeners))
                         .withNewEphemeralStorage()
                         .endEphemeralStorage()
                     .endKafka()
@@ -101,7 +101,7 @@ public void testNewListenerSerialization() throws URISyntaxException {
                     .endZookeeper()
                     .withNewKafka()
                         .withReplicas(1)
-                        .withListeners(new ArrayOrObjectKafkaListeners(listeners, null))
+                        .withListeners(new ArrayOrObjectKafkaListeners(listeners))
                         .withNewEphemeralStorage()
                         .endEphemeralStorage()
                     .endKafka()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -375,7 +375,7 @@ public static Kafka createKafka(String namespace, String name, int replicas,
 
         KafkaClusterSpec kafkaClusterSpec = new KafkaClusterSpec();
         kafkaClusterSpec.setReplicas(replicas);
-        kafkaClusterSpec.setListeners(new ArrayOrObjectKafkaListeners(emptyList(), null));
+        kafkaClusterSpec.setListeners(new ArrayOrObjectKafkaListeners(emptyList()));
         kafkaClusterSpec.setImage(image);
         if (kafkaLogging != null) {
             kafkaClusterSpec.setLogging(kafkaLogging);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterOAuthValidationTest.java
Patch:
@@ -82,7 +82,7 @@ public void testOAuthAuthnAuthz() {
                     .withNewKafka()
                         .withReplicas(3)
                         .withStorage(new EphemeralStorage())
-                        .withListeners(new ArrayOrObjectKafkaListeners(listeners, null))
+                        .withListeners(new ArrayOrObjectKafkaListeners(listeners))
                         .withAuthorization(new KafkaAuthorizationKeycloakBuilder()
                                 .withTokenEndpointUri("http://token-endpoint")
                                 .withClientId("my-client-id")
@@ -123,7 +123,7 @@ public void testOAuthAuthzWithoutAuthn() {
                         .withNewKafka()
                             .withReplicas(3)
                             .withStorage(new EphemeralStorage())
-                            .withListeners(new ArrayOrObjectKafkaListeners(listeners, null))
+                            .withListeners(new ArrayOrObjectKafkaListeners(listeners))
                             .withAuthorization(new KafkaAuthorizationKeycloakBuilder()
                                     .withTokenEndpointUri("http://token-endpoint")
                                     .withClientId("my-client-id")

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorUnsupportedFieldsTest.java
Patch:
@@ -160,7 +160,7 @@ public void testTopicOperatorWarnings(VertxTestContext context) throws ParseExce
                 .withNewSpec()
                     .withNewKafka()
                         .withReplicas(3)
-                        .withListeners(new ArrayOrObjectKafkaListeners(null, new KafkaListenersBuilder()
+                        .withListeners(new ArrayOrObjectKafkaListeners(new KafkaListenersBuilder()
                                 .withNewPlain()
                                 .endPlain()
                                 .build()))

File: crd-generator/src/main/java/io/strimzi/crdgenerator/annotations/Alternative.java
Patch:
@@ -15,4 +15,5 @@
 @Retention(RetentionPolicy.RUNTIME)
 @Target({ElementType.METHOD, ElementType.FIELD})
 public @interface Alternative {
+    String apiVersion() default "all";
 }

File: crd-generator/src/test/java/io/strimzi/crdgenerator/DocGeneratorTest.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.crdgenerator;
 
+import io.strimzi.api.annotations.ApiVersion;
 import org.junit.jupiter.api.Test;
 
 import java.io.IOException;
@@ -23,7 +24,7 @@ public class DocGeneratorTest {
     public void simpleTest() throws IOException, ClassNotFoundException, URISyntaxException {
         assertThat(classInherits(Class.forName("io.strimzi.crdgenerator.KubeLinker"), Linker.class), is(notNullValue()));
         StringWriter w = new StringWriter();
-        DocGenerator crdGenerator = new DocGenerator(1, singletonList(ExampleCrd.class), w, new KubeLinker("{KubeApiReferenceBase}"));
+        DocGenerator crdGenerator = new DocGenerator(ApiVersion.V1, 1, singletonList(ExampleCrd.class), w, new KubeLinker("{KubeApiReferenceBase}"));
         crdGenerator.generate(ExampleCrd.class);
         String s = w.toString();
         assertEquals(CrdTestUtils.readResource("simpleTest.adoc"), s);

File: crd-generator/src/test/java/io/strimzi/crdgenerator/ExampleCrd.java
Patch:
@@ -23,15 +23,13 @@
 import java.util.Map;
 
 @Crd(
-    apiVersion = "apiextensions.k8s.io/v1beta1",
     spec = @Crd.Spec(
         group = "crdgenerator.strimzi.io",
         names = @Crd.Spec.Names(
             kind = "Example",
             plural = "examples",
             categories = {"strimzi"}),
         scope = "Namespaced",
-        version = "v1alpha1",
     versions = {
         @Crd.Spec.Version(name = "v1alpha1", served = true, storage = true),
         @Crd.Spec.Version(name = "v1beta1", served = true, storage = false)

File: crd-generator/src/test/java/io/strimzi/crdgenerator/ExampleWithSubresourcesCrd.java
Patch:
@@ -8,15 +8,13 @@
 import io.strimzi.crdgenerator.annotations.Crd;
 
 @Crd(
-    apiVersion = "apiextensions.k8s.io/v1beta1",
     spec = @Crd.Spec(
         group = "crdgenerator.strimzi.io",
         names = @Crd.Spec.Names(
             kind = "ExampleWithSubresources",
             plural = "exampleswithsubresources",
             categories = {"strimzi"}),
         scope = "Namespaced",
-        version = "v1alpha1",
     versions = {
         @Crd.Spec.Version(name = "v1alpha1", served = true, storage = true),
         @Crd.Spec.Version(name = "v1beta1", served = true, storage = false)

File: crd-generator/src/test/java/io/strimzi/crdgenerator/PropertyTest.java
Patch:
@@ -15,7 +15,7 @@
 public class PropertyTest {
 
     private static PropertyType propertyType(Class<?> cls, String propertyNAme) {
-        return properties(cls).get(propertyNAme).getType();
+        return properties(null, cls).get(propertyNAme).getType();
     }
 
     @Test

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorIT.java
Patch:
@@ -58,7 +58,7 @@ protected Kafka getResource(String resourceName) {
                 .withNewSpec()
                     .withNewKafka()
                         .withReplicas(1)
-                        .withListeners(new ArrayOrObjectKafkaListeners(null, new KafkaListenersBuilder()
+                        .withListeners(new ArrayOrObjectKafkaListeners(new KafkaListenersBuilder()
                                 .withNewPlain()
                                 .endPlain()
                                 .build()))

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorTest.java
Patch:
@@ -62,7 +62,7 @@ protected Kafka resource() {
                 .withNewSpec()
                     .withNewKafka()
                         .withReplicas(1)
-                        .withListeners(new ArrayOrObjectKafkaListeners(null, new KafkaListenersBuilder()
+                        .withListeners(new ArrayOrObjectKafkaListeners(new KafkaListenersBuilder()
                                 .withNewPlain()
                                 .endPlain()
                                 .build()))

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -997,7 +997,7 @@ void testRegenerateCertExternalAddressChange() {
                             .withType(KafkaListenerType.LOADBALANCER)
                             .withTls(true)
                             .build()
-            ), null);
+            ));
             kafka.getSpec().getKafka().setListeners(lst);
         });
 

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -615,7 +615,7 @@ void testTriggerRollingUpdateAfterOverrideBootstrap() throws CertificateExceptio
                                         .endBootstrap()
                                     .endConfiguration()
                                     .build()
-                    ), null));
+                    )));
         });
 
         StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaPods);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/QuantitiesTest.java
Patch:
@@ -26,6 +26,8 @@ public void testParseMemory() {
         assertThat(parseMemory("1Ki"), is(1024L));
         assertThat(parseMemory("512Ki"), is(512 * 1024L));
         assertThat(parseMemory("1e6"), is(1_000_000L));
+        assertThat(parseMemory("3060164198400m"), is(parseMemory("2.85Gi")));
+        assertThat(parseMemory("3081639034880m"), is(parseMemory("2.87Gi")));
 
         assertThat(parseMemory("0"), is(0L));
         assertThat(parseMemory("0K"), is(0L));

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -78,7 +78,7 @@ void testManualTriggeringRollingUpdate() {
 
         KafkaBasicExampleClients kafkaBasicClientJob = new KafkaBridgeExampleClients.Builder()
             .withProducerName(producerName)
-            .withConsumerGroup(consumerName)
+            .withConsumerName(consumerName)
             .withBootstrapAddress(KafkaResources.plainBootstrapAddress(clusterName))
             .withTopicName(continuousTopicName)
             .withMessageCount(continuousClientsMessageCount)

File: api/src/main/java/io/strimzi/api/kafka/model/listener/arraylistener/GenericKafkaListener.java
Patch:
@@ -37,7 +37,8 @@
 public class GenericKafkaListener implements UnknownPropertyPreserving, Serializable {
     private static final long serialVersionUID = 1L;
 
-    public final static String LISTENER_NAME_REGEX = "^[a-z0-9]{1,25}$";
+    // maximal port name length is 15. The prefix of generic port name is 'tcp-'
+    public final static String LISTENER_NAME_REGEX = "^[a-z0-9]{1,11}$";
 
     private String name;
     private int port;
@@ -51,7 +52,7 @@ public class GenericKafkaListener implements UnknownPropertyPreserving, Serializ
     @Description("Name of the listener. " +
             "The name will be used to identify the listener and the related Kubernetes objects. " +
             "The name has to be unique within given a Kafka cluster. " +
-            "The name can consist of lowercase characters and numbers and be up to 25 characters long.")
+            "The name can consist of lowercase characters and numbers and be up to 11 characters long.")
     @JsonProperty(required = true)
     @Pattern(LISTENER_NAME_REGEX)
     public String getName() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ListenersValidatorTest.java
Patch:
@@ -171,7 +171,7 @@ public void testInvalidNames() {
                 .build();
 
         List<GenericKafkaListener> listeners = asList(listener1, listener2, listener3);
-        assertThat(ListenersValidator.validateAndGetErrorMessages(3, listeners), containsInAnyOrder("listener names [listener 1, LISTENER2, listener12345678901234567890] are invalid and do not match the pattern ^[a-z0-9]{1,25}$"));
+        assertThat(ListenersValidator.validateAndGetErrorMessages(3, listeners), containsInAnyOrder("listener names [listener 1, LISTENER2, listener12345678901234567890] are invalid and do not match the pattern ^[a-z0-9]{1,11}$"));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/dynamicconfiguration/DynamicConfigurationIsolatedST.java
Patch:
@@ -219,7 +219,7 @@ void testUpdateToExternalListenerCausesRollingRestartUsingExternalClients() {
         KafkaResource.kafkaPersistent(CLUSTER_NAME, KAFKA_REPLICAS, 1)
             .editSpec()
                 .editKafka()
-                    .editListeners()
+                    .withNewListeners()
                         .addNewGenericKafkaListener()
                             .withName("external")
                             .withPort(9094)
@@ -295,7 +295,7 @@ void testUpdateToExternalListenerCausesRollingRestartUsingExternalClients() {
 
         basicExternalKafkaClientTls.verifyProducedAndConsumedMessages(
                 basicExternalKafkaClientTls.sendMessagesTls(),
-                basicExternalKafkaClientTls.sendMessagesTls()
+                basicExternalKafkaClientTls.receiveMessagesTls()
         );
 
         assertThrows(Exception.class, () -> {

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -637,6 +637,7 @@ void testMirrorMaker2CorrectlyMirrorsHeaders() {
         String targetConsumerName = "target-consumer";
         String sourceExampleTopic = "source-example-topic";
         String targetExampleTopic = kafkaClusterSourceName + "." + sourceExampleTopic;
+        int messageCount = 30;
 
         // Deploy source kafka
         KafkaResource.kafkaEphemeral(kafkaClusterSourceName, 1, 1).done();
@@ -650,11 +651,11 @@ void testMirrorMaker2CorrectlyMirrorsHeaders() {
         //deploying example clients for checking if mm2 will mirror messages with headers
 
         KafkaBasicClientResource targetKafkaClientsJob = new KafkaBasicClientResource("", targetConsumerName,
-            KafkaResources.plainBootstrapAddress(kafkaClusterTargetName), targetExampleTopic, MESSAGE_COUNT, "", ClientUtils.generateRandomConsumerGroup(), 0);
+            KafkaResources.plainBootstrapAddress(kafkaClusterTargetName), targetExampleTopic, messageCount, "", ClientUtils.generateRandomConsumerGroup(), 1000);
         targetKafkaClientsJob.consumerStrimzi().done();
 
         KafkaBasicClientResource sourceKafkaClientsJob = new KafkaBasicClientResource(sourceProducerName, "",
-            KafkaResources.plainBootstrapAddress(kafkaClusterSourceName), sourceExampleTopic, MESSAGE_COUNT, "", ClientUtils.generateRandomConsumerGroup(), 0);
+            KafkaResources.plainBootstrapAddress(kafkaClusterSourceName), sourceExampleTopic, messageCount, "", ClientUtils.generateRandomConsumerGroup(), 1000);
 
         sourceKafkaClientsJob.producerStrimzi()
             .editSpec()

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -14,7 +14,6 @@
 import io.fabric8.kubernetes.api.model.Doneable;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
-import io.strimzi.api.kafka.model.status.HasStatus;
 import io.strimzi.api.kafka.model.status.KafkaStatus;
 import io.strimzi.crdgenerator.annotations.Crd;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -76,7 +75,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
-public class Kafka extends CustomResource implements UnknownPropertyPreserving, HasStatus<KafkaStatus> {
+public class Kafka extends CustomResource implements HasSpecAndStatus<KafkaSpec, KafkaStatus>, UnknownPropertyPreserving {
 
     public static final String V1BETA1 = Constants.V1BETA1;
     public static final String V1ALPHA1 = Constants.V1ALPHA1;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridge.java
Patch:
@@ -12,7 +12,6 @@
 import io.fabric8.kubernetes.api.model.Doneable;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
-import io.strimzi.api.kafka.model.status.HasStatus;
 import io.strimzi.api.kafka.model.status.KafkaBridgeStatus;
 import io.strimzi.crdgenerator.annotations.Crd;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -84,8 +83,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
-public class KafkaBridge extends CustomResource implements UnknownPropertyPreserving, HasStatus<KafkaBridgeStatus> {
-
+public class KafkaBridge extends CustomResource implements HasSpecAndStatus<KafkaBridgeSpec, KafkaBridgeStatus>, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 
     public static final String SCOPE = "Namespaced";

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnect.java
Patch:
@@ -14,7 +14,6 @@
 import io.fabric8.kubernetes.api.model.Doneable;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
-import io.strimzi.api.kafka.model.status.HasStatus;
 import io.strimzi.api.kafka.model.status.KafkaConnectStatus;
 import io.strimzi.crdgenerator.annotations.Crd;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -81,8 +80,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
-public class KafkaConnect extends CustomResource implements UnknownPropertyPreserving, HasStatus<KafkaConnectStatus> {
-
+public class KafkaConnect extends CustomResource implements HasSpecAndStatus<KafkaConnectSpec, KafkaConnectStatus>, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 
     public static final String SCOPE = "Namespaced";

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectS2I.java
Patch:
@@ -15,7 +15,6 @@
 import io.fabric8.kubernetes.api.model.Doneable;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
-import io.strimzi.api.kafka.model.status.HasStatus;
 import io.strimzi.api.kafka.model.status.KafkaConnectS2IStatus;
 import io.strimzi.crdgenerator.annotations.Crd;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -84,8 +83,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
-public class KafkaConnectS2I extends CustomResource implements UnknownPropertyPreserving, HasStatus<KafkaConnectS2IStatus> {
-
+public class KafkaConnectS2I extends CustomResource implements HasSpecAndStatus<KafkaConnectS2ISpec, KafkaConnectS2IStatus>, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 
     public static final String SCOPE = "Namespaced";

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker.java
Patch:
@@ -12,7 +12,6 @@
 import io.fabric8.kubernetes.api.model.Doneable;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
-import io.strimzi.api.kafka.model.status.HasStatus;
 import io.strimzi.api.kafka.model.status.KafkaMirrorMakerStatus;
 import io.strimzi.crdgenerator.annotations.Crd;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -96,7 +95,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
-public class KafkaMirrorMaker extends CustomResource implements UnknownPropertyPreserving, HasStatus<KafkaMirrorMakerStatus> {
+public class KafkaMirrorMaker extends CustomResource implements HasSpecAndStatus<KafkaMirrorMakerSpec, KafkaMirrorMakerStatus>, UnknownPropertyPreserving {
 
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2.java
Patch:
@@ -13,7 +13,6 @@
 import io.fabric8.kubernetes.api.model.Doneable;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
-import io.strimzi.api.kafka.model.status.HasStatus;
 import io.strimzi.api.kafka.model.status.KafkaMirrorMaker2Status;
 import io.strimzi.crdgenerator.annotations.Crd;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -76,8 +75,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({ "apiVersion", "kind", "metadata", "spec", "status" })
 @EqualsAndHashCode
-public class KafkaMirrorMaker2 extends CustomResource implements UnknownPropertyPreserving, HasStatus<KafkaMirrorMaker2Status> {
-
+public class KafkaMirrorMaker2 extends CustomResource implements HasSpecAndStatus<KafkaMirrorMaker2Spec, KafkaMirrorMaker2Status>, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 
     public static final String SCOPE = "Namespaced";

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaRebalance.java
Patch:
@@ -13,7 +13,6 @@
 import io.fabric8.kubernetes.api.model.Doneable;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
-import io.strimzi.api.kafka.model.status.HasStatus;
 import io.strimzi.api.kafka.model.status.KafkaRebalanceStatus;
 import io.strimzi.crdgenerator.annotations.Crd;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -71,7 +70,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
-public class KafkaRebalance extends CustomResource implements UnknownPropertyPreserving, HasStatus<KafkaRebalanceStatus> {
+public class KafkaRebalance extends CustomResource implements HasSpecAndStatus<KafkaRebalanceSpec, KafkaRebalanceStatus>, UnknownPropertyPreserving {
 
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUser.java
Patch:
@@ -12,7 +12,6 @@
 import io.fabric8.kubernetes.api.model.Doneable;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.client.CustomResource;
-import io.strimzi.api.kafka.model.status.HasStatus;
 import io.strimzi.api.kafka.model.status.KafkaUserStatus;
 import io.strimzi.crdgenerator.annotations.Crd;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -87,8 +86,7 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"apiVersion", "kind", "metadata", "spec", "status"})
 @EqualsAndHashCode
-public class KafkaUser extends CustomResource implements UnknownPropertyPreserving, HasStatus<KafkaUserStatus> {
-
+public class KafkaUser extends CustomResource implements HasSpecAndStatus<KafkaUserSpec, KafkaUserStatus>, UnknownPropertyPreserving {
     private static final long serialVersionUID = 1L;
 
     public static final String SCOPE = "Namespaced";

File: api/src/main/java/io/strimzi/api/kafka/model/status/HasStatus.java
Patch:
@@ -5,5 +5,6 @@
 package io.strimzi.api.kafka.model.status;
 
 public interface HasStatus<S extends Status> {
+    void setStatus(S status);
     S getStatus();
 }

File: api/src/main/java/io/strimzi/api/kafka/model/status/Status.java
Patch:
@@ -14,6 +14,7 @@
 
 import java.io.Serializable;
 import java.util.ArrayList;
+import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.List;
@@ -57,7 +58,7 @@ public void addCondition(Condition condition) {
         setConditions(Collections.unmodifiableList(newConditions));
     }
 
-    public void addConditions(List<Condition> conditions) {
+    public void addConditions(Collection<Condition> conditions) {
         List<Condition> newConditions = prepareConditionsUpdate();
         newConditions.addAll(conditions);
         setConditions(Collections.unmodifiableList(newConditions));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java
Patch:
@@ -101,13 +101,13 @@ public void start(Promise<Void> start) {
         getVertx().createSharedWorkerExecutor("kubernetes-ops-pool", 10, TimeUnit.SECONDS.toNanos(120));
 
         List<Future> watchFutures = new ArrayList<>(8);
-        List<AbstractOperator<?, ?>> operators = new ArrayList<>(asList(
+        List<AbstractOperator<?, ?, ?, ?>> operators = new ArrayList<>(asList(
                 kafkaAssemblyOperator, kafkaMirrorMakerAssemblyOperator,
                 kafkaConnectAssemblyOperator, kafkaBridgeAssemblyOperator, kafkaMirrorMaker2AssemblyOperator));
         if (kafkaConnectS2IAssemblyOperator != null) {
             operators.add(kafkaConnectS2IAssemblyOperator);
         }
-        for (AbstractOperator<?, ?> operator : operators) {
+        for (AbstractOperator<?, ?, ?, ?> operator : operators) {
             watchFutures.add(operator.createWatch(namespace, operator.recreateWatch(namespace)).compose(w -> {
                 log.info("Opened watch for {} operator", operator.kind());
                 watchByKind.put(operator.kind(), w);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -387,7 +387,7 @@ public void testConnectNotReadyWithoutSpec() {
                     .withName(connectName)
                 .endMetadata()
                 .done();
-        waitForConnectNotReady(connectName, "InvalidResourceException", "spec property is required");
+        waitForConnectNotReady(connectName, "InvalidResourceException", "Spec cannot be null");
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -36,6 +36,7 @@
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener;
 import io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListenerBuilder;
 import io.strimzi.api.kafka.model.listener.arraylistener.KafkaListenerType;
+import io.strimzi.api.kafka.model.status.KafkaStatus;
 import io.strimzi.api.kafka.model.storage.EphemeralStorage;
 import io.strimzi.api.kafka.model.storage.PersistentClaimStorage;
 import io.strimzi.api.kafka.model.storage.PersistentClaimStorageBuilder;
@@ -1356,7 +1357,7 @@ public void testReconcile(Params params, VertxTestContext context) {
                 supplier,
                 config) {
             @Override
-            public Future<Void> createOrUpdate(Reconciliation reconciliation, Kafka kafkaAssembly) {
+            public Future<KafkaStatus> createOrUpdate(Reconciliation reconciliation, Kafka kafkaAssembly) {
                 String name = kafkaAssembly.getMetadata().getName();
                 if ("foo".equals(name)) {
                     fooAsync.flag();
@@ -1441,7 +1442,7 @@ public void testReconcileAllNamespaces(Params params, VertxTestContext context)
                 supplier,
                 config) {
             @Override
-            public Future<Void> createOrUpdate(Reconciliation reconciliation, Kafka kafkaAssembly) {
+            public Future<KafkaStatus> createOrUpdate(Reconciliation reconciliation, Kafka kafkaAssembly) {
                 String name = kafkaAssembly.getMetadata().getName();
                 if ("foo".equals(name)) {
                     fooAsync.flag();

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -36,7 +36,7 @@ public class CrdOperator<C extends KubernetesClient,
             T extends CustomResource,
             L extends CustomResourceList<T>,
             D extends Doneable<T>>
-        extends AbstractWatchableResourceOperator<C, T, L, D, Resource<T, D>> {
+        extends AbstractWatchableStatusedResourceOperator<C, T, L, D, Resource<T, D>> {
 
     private final Class<T> cls;
     private final Class<L> listCls;

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlApiST.java
Patch:
@@ -13,10 +13,8 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.MethodOrderer;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.Test;
-import org.junit.jupiter.api.TestMethodOrder;
 
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.CRUISE_CONTROL;
@@ -28,7 +26,6 @@
 
 @Tag(REGRESSION)
 @Tag(CRUISE_CONTROL)
-@TestMethodOrder(MethodOrderer.OrderAnnotation.class)
 public class CruiseControlApiST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(CruiseControlApiST.class);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1625,7 +1625,7 @@ public NetworkPolicy generateNetworkPolicy(boolean namespaceAndPodSelectorNetwor
                     .endPodSelector()
                     .build();
 
-            List<NetworkPolicyPeer> clientsPortPeers = new ArrayList<>(4);
+            List<NetworkPolicyPeer> clientsPortPeers = new ArrayList<>(5);
             clientsPortPeers.add(clusterOperatorPeer);
             clientsPortPeers.add(kafkaClusterPeer);
             clientsPortPeers.add(entityOperatorPeer);

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/ListenersST.java
Patch:
@@ -484,7 +484,7 @@ void testLoadBalancer() {
                         .addNewGenericKafkaListener()
                             .withName("external")
                             .withPort(9094)
-                            .withType(KafkaListenerType.NODEPORT)
+                            .withType(KafkaListenerType.LOADBALANCER)
                             .withTls(false)
                         .endGenericKafkaListener()
                     .endListeners()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -140,6 +140,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                             .withSecurityContext(templateSecurityContext)
                             .withPriorityClassName(templatePodPriorityClassName)
                             .withSchedulerName(templatePodSchedulerName)
+                            .withHostAliases(templatePodHostAliases)
                         .endSpec()
                     .endTemplate()
                     .withTriggers(configChangeTrigger, imageChangeTrigger)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ModelUtils.java
Patch:
@@ -255,6 +255,7 @@ public static void parsePodTemplate(AbstractModel model, PodTemplate pod)   {
             model.templateSecurityContext = pod.getSecurityContext();
             model.templatePodPriorityClassName = pod.getPriorityClassName();
             model.templatePodSchedulerName = pod.getSchedulerName();
+            model.templatePodHostAliases = pod.getHostAliases();
         }
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/CruiseControlUtils.java
Patch:
@@ -50,7 +50,7 @@ public enum SupportedHttpMethods {
     public static String callApi(SupportedHttpMethods method, CruiseControlEndpoints endpoint) {
         String ccPodName = PodUtils.getFirstPodNameContaining(CONTAINER_NAME);
 
-        return cmdKubeClient().execInPodContainer(ccPodName, CONTAINER_NAME, "/bin/bash", "-c",
+        return cmdKubeClient().execInPodContainer(false, ccPodName, CONTAINER_NAME, "/bin/bash", "-c",
             "curl -X" + method.name() + " localhost:" + CRUISE_CONTROL_DEFAULT_PORT + endpoint.toString()).out();
     }
 
@@ -59,7 +59,7 @@ public static String callApi(SupportedHttpMethods method, CruiseControlEndpoints
     public static String callApi(SupportedHttpMethods method, String endpoint) {
         String ccPodName = PodUtils.getFirstPodNameContaining(CONTAINER_NAME);
 
-        return cmdKubeClient().execInPodContainer(ccPodName, CONTAINER_NAME, "/bin/bash", "-c",
+        return cmdKubeClient().execInPodContainer(false, ccPodName, CONTAINER_NAME, "/bin/bash", "-c",
             "curl -X" + method.name() + " localhost:" + CRUISE_CONTROL_METRICS_PORT + endpoint).out();
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectS2IST.java
Patch:
@@ -201,6 +201,7 @@ void testSecretsWithKafkaConnectS2IWithTlsAndScramShaAuthentication() {
         final String userName = KafkaUserUtils.generateRandomNameOfKafkaUser();
         final String kafkaConnectS2IName = "kafka-connect-s2i-name-2";
 
+        KafkaTopicResource.topic(CLUSTER_NAME, CONNECT_S2I_TOPIC_NAME).done();
         KafkaUser user = KafkaUserResource.scramShaUser(CLUSTER_NAME, userName).done();
 
         KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + "-tls-" + Constants.KAFKA_CLIENTS, user).done();
@@ -228,8 +229,6 @@ void testSecretsWithKafkaConnectS2IWithTlsAndScramShaAuthentication() {
                 .endSpec()
                 .done();
 
-        KafkaTopicResource.topic(CLUSTER_NAME, CONNECT_S2I_TOPIC_NAME).done();
-
         final String tlsKafkaClientsPodName =
                 ResourceManager.kubeClient().listPodsByPrefixInName(CLUSTER_NAME + "-tls-" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();
 

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -773,6 +773,7 @@ void testConnectTlsAuthWithWeirdUserName() {
                 .endSpec()
                 .done();
 
+        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
         KafkaUserResource.tlsUser(CLUSTER_NAME, weirdUserName).done();
 
         KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
@@ -835,6 +836,7 @@ void testConnectScramShaAuthWithWeirdUserName() {
                 .endSpec()
                 .done();
 
+        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
         KafkaUserResource.scramShaUser(CLUSTER_NAME, weirdUserName).done();
 
         KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
@@ -867,7 +869,6 @@ void testConnectScramShaAuthWithWeirdUserName() {
     }
 
     void testConnectAuthorizationWithWeirdUserName(String userName, SecurityProtocol securityProtocol) {
-        KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
         String connectorPodName = kubeClient().listPodsByPrefixInName(CLUSTER_NAME + "-connect").get(0).getMetadata().getName();
 
         KafkaConnectorResource.kafkaConnector(CLUSTER_NAME)

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMaker2ST.java
Patch:
@@ -152,6 +152,7 @@ void testMirrorMaker2() {
                     .endMirror()
                 .endSpec()
                 .done();
+
         LOGGER.info("Looks like the mirrormaker2 cluster my-cluster deployed OK");
 
         String podName = PodUtils.getPodNameByPrefix(KafkaMirrorMaker2Resources.deploymentName(CLUSTER_NAME));

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerST.java
Patch:
@@ -342,6 +342,9 @@ void testMirrorMakerTlsScramSha() {
                 .endKafka()
             .endSpec().done();
 
+        // Deploy topic
+        KafkaTopicResource.topic(kafkaClusterSourceName, TOPIC_NAME).done();
+
         // Create Kafka user for source cluster
         KafkaUser userSource = KafkaUserResource.scramShaUser(kafkaClusterSourceName, kafkaUserSource).done();
 
@@ -421,9 +424,6 @@ void testMirrorMakerTlsScramSha() {
                 .endProducer()
             .endSpec().done();
 
-        // Deploy topic
-        KafkaTopicResource.topic(kafkaClusterSourceName, TOPIC_NAME).done();
-
         internalKafkaClient.setTopicName(TOPIC_NAME);
         internalKafkaClient.setClusterName(kafkaClusterSourceName);
         internalKafkaClient.setKafkaUsername(userSource.getMetadata().getName());

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/BundleResource.java
Patch:
@@ -51,9 +51,6 @@ private static DeploymentBuilder defaultClusterOperator(String namespace, long o
         // Update images
         for (EnvVar envVar : envVars) {
             switch (envVar.getName()) {
-                case "STRIMZI_LOG_LEVEL":
-                    envVar.setValue(Environment.STRIMZI_LOG_LEVEL);
-                    break;
                 case "STRIMZI_NAMESPACE":
                     envVar.setValue(namespace);
                     envVar.setValueFrom(null);
@@ -76,6 +73,7 @@ private static DeploymentBuilder defaultClusterOperator(String namespace, long o
         }
 
         envVars.add(new EnvVar("STRIMZI_IMAGE_PULL_POLICY", Environment.COMPONENTS_IMAGE_PULL_POLICY, null));
+        envVars.add(new EnvVar("STRIMZI_LOG_LEVEL", Environment.STRIMZI_LOG_LEVEL, null));
         // Apply updated env variables
         clusterOperator.getSpec().getTemplate().getSpec().getContainers().get(0).setEnv(envVars);
 

File: test/src/main/java/io/strimzi/test/k8s/HelmClient.java
Patch:
@@ -44,11 +44,11 @@ public HelmClient install(Path chart, String releaseName, Map<String, String> va
         String values = Stream.of(valuesMap).flatMap(m -> m.entrySet().stream())
                 .map(entry -> String.format("%s=%s", entry.getKey(), entry.getValue()))
                 .collect(Collectors.joining(","));
-        Exec.exec(wait(namespace(command("install",
+        Exec.exec(null, wait(namespace(command("install",
                 releaseName,
                 "--set-string", values,
                 "--timeout", INSTALL_TIMEOUT_SECONDS,
-                chart.toString()))));
+                chart.toString()))), 0, true, true);
         return this;
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListeners.java
Patch:
@@ -6,6 +6,7 @@
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import io.strimzi.api.annotations.DeprecatedType;
 import io.strimzi.api.kafka.model.Constants;
 import io.strimzi.api.kafka.model.UnknownPropertyPreserving;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -30,6 +31,8 @@
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"plain", "tls", "external"})
 @EqualsAndHashCode
+@Deprecated
+@DeprecatedType(replacedWithType = io.strimzi.api.kafka.model.listener.arraylistener.GenericKafkaListener.class)
 public class KafkaListeners implements UnknownPropertyPreserving, Serializable {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/status/ListenerStatus.java
Patch:
@@ -56,10 +56,10 @@ public List<ListenerAddress> getAddresses() {
 
     public void setAddresses(List<ListenerAddress> addresses) {
         this.addresses = addresses;
-        if ((addresses == null) || addresses.isEmpty()) {
+        if (addresses == null || addresses.isEmpty()) {
             bootstrapServers = null;
         } else {
-            bootstrapServers = addresses.stream().map(a -> a.getHost() + ":" + a.getPort()).collect(Collectors.joining(","));
+            bootstrapServers = addresses.stream().map(a -> a.getHost() + ":" + a.getPort()).distinct().collect(Collectors.joining(","));
         }
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ModelUtils.java
Patch:
@@ -58,6 +58,7 @@ public class ModelUtils {
     private ModelUtils() {}
 
     protected static final Logger log = LogManager.getLogger(ModelUtils.class.getName());
+    public static final String TLS_SIDECAR_LOG_LEVEL = "TLS_SIDECAR_LOG_LEVEL";
 
     /**
      * @param certificateAuthority The CA configuration.
@@ -122,8 +123,6 @@ public static Map<String, String> getContainerEnv(StatefulSet sts, String contai
         throw new KafkaUpgradeException("Could not find '" + containerName + "' container in StatefulSet " + sts.getMetadata().getName());
     }
 
-    public static final String TLS_SIDECAR_LOG_LEVEL = "TLS_SIDECAR_LOG_LEVEL";
-
     static EnvVar tlsSidecarLogEnvVar(TlsSidecar tlsSidecar) {
         return AbstractModel.buildEnvVar(TLS_SIDECAR_LOG_LEVEL,
                 (tlsSidecar != null && tlsSidecar.getLogLevel() != null ?

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -150,7 +150,7 @@ public void testGenerateService()   {
         Service svc = kbc.generateService();
 
         assertThat(svc.getSpec().getType(), is("ClusterIP"));
-        assertThat(svc.getMetadata().getLabels(), is(expectedServiceLabels(kbc.getServiceName())));
+        assertThat(svc.getMetadata().getLabels(), is(expectedServiceLabels(kbc.getName())));
         assertThat(svc.getSpec().getSelector(), is(expectedSelectorLabels()));
         assertThat(svc.getSpec().getPorts().size(), is(1));
         assertThat(svc.getSpec().getPorts().get(0).getPort(), is(Integer.valueOf(KafkaBridgeCluster.DEFAULT_REST_API_PORT)));
@@ -925,7 +925,7 @@ public void testDifferentHttpPort()   {
         Service svc = kb.generateService();
 
         assertThat(svc.getSpec().getType(), is("ClusterIP"));
-        assertThat(svc.getMetadata().getLabels(), is(expectedServiceLabels(kb.getServiceName())));
+        assertThat(svc.getMetadata().getLabels(), is(expectedServiceLabels(kb.getName())));
         assertThat(svc.getSpec().getSelector(), is(expectedSelectorLabels()));
         assertThat(svc.getSpec().getPorts().get(0).getPort(), is(Integer.valueOf(1874)));
         assertThat(svc.getSpec().getPorts().get(0).getName(), is(KafkaBridgeCluster.REST_API_PORT_NAME));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -105,6 +105,8 @@ private void init() {
                 .withNewSpec()
                     .withNewKafka()
                         .withReplicas(3)
+                        .withNewListeners()
+                        .endListeners()
                         .withNewJbodStorage()
                             .withVolumes(volumes)
                         .endJbodStorage()

File: crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java
Patch:
@@ -601,13 +601,14 @@ private ObjectNode addSimpleTypeConstraints(ObjectNode result, Property property
             result.set("enum", stringArray(Property.subtypeNames(property.getDeclaringClass())));
         }
 
-        Deprecated deprecated = property.getAnnotation(Deprecated.class);
+        // The deprecated field cannot be set in Kube OpenAPI v3 schema. But we should keep this code for future when it might be possible.
+        /*Deprecated deprecated = property.getAnnotation(Deprecated.class);
         if (deprecated == null) {
             deprecated = property.getType().getType().getAnnotation(Deprecated.class);
         }
         if (deprecated != null) {
             result.put("deprecated", true);
-        }
+        }*/
 
         return result;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -70,7 +70,7 @@ public static DoneableJob deployNewJob(Job job) {
             TestUtils.waitFor("Job creation " + job.getMetadata().getName(), Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, CR_CREATION_TIMEOUT,
                 () -> {
                     try {
-                        ResourceManager.kubeClient().getClient().batch().jobs().inNamespace(kubeClient().getNamespace()).createOrReplace(kubernetesJob);
+                        ResourceManager.kubeClient().createJob(kubernetesJob);
                         return true;
                     } catch (KubernetesClientException e) {
                         if (e.getMessage().contains("object is being deleted")) {

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAbstractST.java
Patch:
@@ -78,9 +78,9 @@ void setup() throws Exception {
     @AfterEach
     void tearDown() {
 
-        for (Job job : kubeClient().getClient().batch().jobs().inNamespace(NAMESPACE).list().getItems()) {
+        for (Job job : kubeClient().getJobList().getItems()) {
             LOGGER.info("Deleting {} job", job.getMetadata().getName());
-            JobUtils.deleteJob(NAMESPACE, job.getMetadata().getName());
+            JobUtils.deleteJobWithWait(NAMESPACE, job.getMetadata().getName());
         }
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
Patch:
@@ -186,7 +186,7 @@ void testProducerConsumerMirrorMaker() {
             Constants.GLOBAL_CLIENTS_POLL, Constants.TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS,
             () -> {
                 LOGGER.info("Deleting the Job");
-                JobUtils.deleteJob(NAMESPACE, OAUTH_CONSUMER_NAME);
+                JobUtils.deleteJobWithWait(NAMESPACE, OAUTH_CONSUMER_NAME);
 
                 LOGGER.info("Creating new client with new consumer-group and also to point on {} cluster", targetKafkaCluster);
                 KafkaOauthClientsResource kafkaOauthClientJob = new KafkaOauthClientsResource(OAUTH_PRODUCER_NAME, OAUTH_CONSUMER_NAME,
@@ -288,7 +288,7 @@ void testProducerConsumerMirrorMaker2() {
             Duration.ofSeconds(30).toMillis(), Constants.TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS,
             () -> {
                 LOGGER.info("Deleting the Job {}", OAUTH_CONSUMER_NAME);
-                JobUtils.deleteJob(NAMESPACE, OAUTH_CONSUMER_NAME);
+                JobUtils.deleteJobWithWait(NAMESPACE, OAUTH_CONSUMER_NAME);
 
                 LOGGER.info("Creating new client with new consumer-group and also to point on {} cluster", kafkaTargetClusterName);
                 KafkaOauthClientsResource kafkaOauthClientJob = new KafkaOauthClientsResource(OAUTH_PRODUCER_NAME, OAUTH_CONSUMER_NAME,

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -288,7 +288,7 @@ void testMirrorMaker() {
         KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();
         KafkaUserUtils.waitForKafkaUserCreation(USER_NAME);
 
-        JobUtils.deleteJob(NAMESPACE, OAUTH_PRODUCER_NAME);
+        JobUtils.deleteJobWithWait(NAMESPACE, OAUTH_PRODUCER_NAME);
 
         LOGGER.info("Creating new client with new consumer-group and also to point on {} cluster", targetKafkaCluster);
 

File: systemtest/src/test/java/io/strimzi/systemtest/specific/ClusterOperationST.java
Patch:
@@ -78,8 +78,8 @@ void testAvailabilityDuringNodeDrain() {
         });
 
         producerNames.forEach(producerName -> ClientUtils.waitTillContinuousClientsFinish(producerName, consumerNames.get(producerName.indexOf(producerName)), NAMESPACE, continuousClientsMessageCount));
-        producerNames.forEach(producerName -> kubeClient().getClient().batch().jobs().inNamespace(NAMESPACE).withName(producerName).delete());
-        consumerNames.forEach(consumerName -> kubeClient().getClient().batch().jobs().inNamespace(NAMESPACE).withName(consumerName).delete());
+        producerNames.forEach(producerName -> kubeClient().deleteJob(producerName));
+        consumerNames.forEach(consumerName -> kubeClient().deleteJob(consumerName));
     }
 
     @BeforeAll

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -377,8 +377,8 @@ private void performUpgrade(JsonObject testParameters, int produceMessagesCount,
             ClientUtils.waitTillContinuousClientsFinish(producerName, consumerName, NAMESPACE, continuousClientsMessageCount);
             // ##############################
             // Delete jobs to make same names available for next upgrade run during chain upgrade
-            kubeClient().getClient().batch().jobs().inNamespace(NAMESPACE).withName(producerName).delete();
-            kubeClient().getClient().batch().jobs().inNamespace(NAMESPACE).withName(consumerName).delete();
+            kubeClient().deleteJob(producerName);
+            kubeClient().deleteJob(consumerName);
         }
 
         // Check errors in CO log

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -458,7 +458,7 @@ protected List<EnvVar> getEnvVars() {
         }
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateCruiseControlContainerEnvVars);
 
@@ -499,7 +499,7 @@ protected List<EnvVar> getTlsSidecarEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_ZOOKEEPER_CONNECT, zookeeperConnect));
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateTlsSidecarContainerEnvVars);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -287,7 +287,7 @@ protected List<EnvVar> getTlsSidecarEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_ZOOKEEPER_CONNECT, zookeeperConnect));
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateTlsSidecarContainerEnvVars);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -265,7 +265,7 @@ protected List<EnvVar> getEnvVars() {
         EntityOperator.javaOptions(varList, getJvmOptions(), javaSystemProperties);
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -284,7 +284,7 @@ protected List<EnvVar> getEnvVars() {
         EntityOperator.javaOptions(varList, getJvmOptions(), javaSystemProperties);
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/JmxTrans.java
Patch:
@@ -263,7 +263,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_JMXTRANS_LOGGING_LEVEL, loggingLevel));
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -411,7 +411,7 @@ protected List<EnvVar> getEnvVars() {
         }
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -517,7 +517,7 @@ protected List<EnvVar> getInitContainerEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_KAFKA_INIT_RACK_TOPOLOGY_KEY, rack.getTopologyKey()));
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateInitContainerEnvVars);
 
@@ -584,7 +584,7 @@ protected List<EnvVar> getEnvVars() {
         }
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         varList.addAll(getExternalConfigurationEnvVars());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaExporter.java
Patch:
@@ -215,7 +215,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_KAFKA_EXPORTER_ENABLE_SARAMA, String.valueOf(saramaLoggingEnabled)));
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -400,7 +400,7 @@ protected List<EnvVar> getEnvVars() {
                 String.valueOf(readinessProbeOptions.getPeriodSeconds() != null ? readinessProbeOptions.getPeriodSeconds() : DEFAULT_HEALTHCHECK_PERIOD)));
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -128,7 +128,7 @@ public static String headlessServiceName(String cluster) {
      * @return              DNS name of the pod
      */
     public static String podDnsName(String namespace, String cluster, int podId) {
-        return ModelUtils.podDnsName(
+        return DnsNameGenerator.podDnsName(
                 namespace,
                 ZookeeperCluster.headlessServiceName(cluster),
                 ZookeeperCluster.zookeeperPodName(cluster, podId));
@@ -146,7 +146,7 @@ public static String podDnsName(String namespace, String cluster, int podId) {
      * @return              DNS name of the pod without the cluster domain suffix
      */
     public static String podDnsNameWithoutSuffix(String namespace, String cluster, int podId) {
-        return ModelUtils.podDnsNameWithoutClusterDomain(
+        return DnsNameGenerator.podDnsNameWithoutClusterDomain(
                 namespace,
                 ZookeeperCluster.headlessServiceName(cluster),
                 ZookeeperCluster.zookeeperPodName(cluster, podId));
@@ -550,7 +550,7 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_ZOOKEEPER_CONFIGURATION, configuration.getConfiguration()));
 
         // Add shared environment variables used for all containers
-        varList.addAll(getSharedEnvVars());
+        varList.addAll(getRequiredEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateZookeeperContainerEnvVars);
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeCorsST.java
Patch:
@@ -37,7 +37,6 @@
 public class HttpBridgeCorsST extends HttpBridgeAbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeCorsST.class);
-    private static final String NAMESPACE = "bridge-cors-cluster-test";
 
     private static final String ALLOWED_ORIGIN = "https://strimzi.io";
     private static final String NOT_ALLOWED_ORIGIN = "https://evil.io";

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeKafkaExternalListenersST.java
Patch:
@@ -44,7 +44,6 @@
 @Tag(EXTERNAL_CLIENTS_USED)
 class HttpBridgeKafkaExternalListenersST extends HttpBridgeAbstractST {
     private static final String BRIDGE_EXTERNAL_SERVICE = CLUSTER_NAME + "-bridge-external-service";
-    private static final String NAMESPACE = "bridge-external-cluster-test";
 
     @Test
     void testScramShaAuthWithWeirdUsername() {
@@ -146,7 +145,7 @@ private void testWeirdUsername(String weirdUserName, KafkaListenerAuthentication
         Service service = KafkaBridgeUtils.createBridgeNodePortService(CLUSTER_NAME, NAMESPACE, BRIDGE_EXTERNAL_SERVICE);
         KubernetesResource.createServiceResource(service, NAMESPACE).done();
 
-        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();
+        kafkaBridgeClientJob.consumerStrimziBridge().done();
 
         BasicExternalKafkaClient basicExternalKafkaClient = new BasicExternalKafkaClient.Builder()
             .withTopicName(TOPIC_NAME)

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -48,14 +48,13 @@
 @Tag(INTERNAL_CLIENTS_USED)
 class HttpBridgeST extends HttpBridgeAbstractST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeST.class);
-    private static final String NAMESPACE = "bridge-cluster-test";
 
     @Test
     void testSendSimpleMessage() {
         // Create topic
         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
 
-        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();
+        kafkaBridgeClientJob.producerStrimziBridge().done();
         ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);
 
         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()
@@ -78,7 +77,7 @@ void testSendSimpleMessage() {
     void testReceiveSimpleMessage() {
         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
 
-        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();
+        kafkaBridgeClientJob.consumerStrimziBridge().done();
 
         // Send messages to Kafka
         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -45,7 +45,7 @@ void testSendSimpleMessageTlsScramSha() {
         // Create topic
         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
 
-        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();
+        kafkaBridgeClientJob.producerStrimziBridge().done();
         ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);
 
         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()
@@ -65,7 +65,7 @@ void testSendSimpleMessageTlsScramSha() {
     void testReceiveSimpleMessageTlsScramSha() {
         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
 
-        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();
+        kafkaBridgeClientJob.consumerStrimziBridge().done();
 
         // Send messages to Kafka
         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -37,14 +37,13 @@
 @Tag(INTERNAL_CLIENTS_USED)
 class HttpBridgeTlsST extends HttpBridgeAbstractST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeTlsST.class);
-    private static final String NAMESPACE = "bridge-tls-cluster-test";
 
     @Test
     void testSendSimpleMessageTls() {
         // Create topic
         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
 
-        KafkaClientsResource.producerStrimziBridge(producerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();
+        kafkaBridgeClientJob.producerStrimziBridge().done();
         ClientUtils.waitForClientSuccess(producerName, NAMESPACE, MESSAGE_COUNT);
 
         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()
@@ -64,7 +63,7 @@ void testSendSimpleMessageTls() {
     void testReceiveSimpleMessageTls() {
         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
 
-        KafkaClientsResource.consumerStrimziBridge(consumerName, bridgeServiceName, bridgePort, TOPIC_NAME, MESSAGE_COUNT).done();
+        kafkaBridgeClientJob.consumerStrimziBridge().done();
 
         // Send messages to Kafka
         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -263,8 +263,8 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withName(TLS_SIDECAR_NAME)
                 .withImage(tlsSidecarImage)
                 .withCommand("/opt/stunnel/entity_operator_stunnel_run.sh")
-                .withLivenessProbe(ModelUtils.tlsSidecarLivenessProbe(tlsSidecar))
-                .withReadinessProbe(ModelUtils.tlsSidecarReadinessProbe(tlsSidecar))
+                .withLivenessProbe(ProbeGenerator.tlsSidecarLivenessProbe(tlsSidecar))
+                .withReadinessProbe(ProbeGenerator.tlsSidecarReadinessProbe(tlsSidecar))
                 .withResources(tlsSidecar != null ? tlsSidecar.getResources() : null)
                 .withEnv(getTlsSidecarEnvVars())
                 .withVolumeMounts(VolumeUtils.createVolumeMount(TLS_SIDECAR_EO_CERTS_VOLUME_NAME, TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT),

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -29,7 +29,6 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import static io.strimzi.operator.cluster.model.ModelUtils.createHttpProbe;
 import static java.util.Arrays.asList;
 import static java.util.Collections.singletonList;
 
@@ -242,8 +241,8 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withArgs("/opt/strimzi/bin/topic_operator_run.sh")
                 .withEnv(getEnvVars())
                 .withPorts(singletonList(createContainerPort(HEALTHCHECK_PORT_NAME, HEALTHCHECK_PORT, "TCP")))
-                .withLivenessProbe(createHttpProbe(livenessPath + "healthy", HEALTHCHECK_PORT_NAME, livenessProbeOptions))
-                .withReadinessProbe(createHttpProbe(readinessPath + "ready", HEALTHCHECK_PORT_NAME, readinessProbeOptions))
+                .withLivenessProbe(ProbeGenerator.httpProbe(livenessProbeOptions, livenessPath + "healthy", HEALTHCHECK_PORT_NAME))
+                .withReadinessProbe(ProbeGenerator.httpProbe(readinessProbeOptions, readinessPath + "ready", HEALTHCHECK_PORT_NAME))
                 .withResources(getResources())
                 .withVolumeMounts(getVolumeMounts())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -30,7 +30,6 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import static io.strimzi.operator.cluster.model.ModelUtils.createHttpProbe;
 import static java.util.Arrays.asList;
 import static java.util.Collections.singletonList;
 
@@ -256,8 +255,8 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withArgs("/opt/strimzi/bin/user_operator_run.sh")
                 .withEnv(getEnvVars())
                 .withPorts(singletonList(createContainerPort(HEALTHCHECK_PORT_NAME, HEALTHCHECK_PORT, "TCP")))
-                .withLivenessProbe(createHttpProbe(livenessPath + "healthy", HEALTHCHECK_PORT_NAME, livenessProbeOptions))
-                .withReadinessProbe(createHttpProbe(readinessPath + "ready", HEALTHCHECK_PORT_NAME, readinessProbeOptions))
+                .withLivenessProbe(ProbeGenerator.httpProbe(livenessProbeOptions, livenessPath + "healthy", HEALTHCHECK_PORT_NAME))
+                .withReadinessProbe(ProbeGenerator.httpProbe(readinessProbeOptions, readinessPath + "ready", HEALTHCHECK_PORT_NAME))
                 .withResources(getResources())
                 .withVolumeMounts(getVolumeMounts())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/JmxTrans.java
Patch:
@@ -315,7 +315,7 @@ protected static io.fabric8.kubernetes.api.model.Probe jmxTransReadinessProbe(io
         String internalBootstrapServiceName = KafkaCluster.headlessServiceName(clusterName);
         String metricsPortValue = String.valueOf(KafkaCluster.JMX_PORT);
         kafkaJmxMetricsReadinessProbe = kafkaJmxMetricsReadinessProbe == null ? DEFAULT_JMX_TRANS_PROBE : kafkaJmxMetricsReadinessProbe;
-        return ModelUtils.createExecProbe(Arrays.asList("/opt/jmx/jmxtrans_readiness_check.sh", internalBootstrapServiceName, metricsPortValue), kafkaJmxMetricsReadinessProbe);
+        return ProbeGenerator.execProbe(kafkaJmxMetricsReadinessProbe, Arrays.asList("/opt/jmx/jmxtrans_readiness_check.sh", internalBootstrapServiceName, metricsPortValue));
     }
 
     private JmxTransServer convertSpecToServers(JmxTransSpec spec, String brokerServiceName) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -338,8 +338,8 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withCommand("/opt/strimzi/bin/docker/kafka_bridge_run.sh")
                 .withEnv(getEnvVars())
                 .withPorts(getContainerPortList())
-                .withLivenessProbe(ModelUtils.createHttpProbe(livenessPath, REST_API_PORT_NAME, livenessProbeOptions))
-                .withReadinessProbe(ModelUtils.createHttpProbe(readinessPath, REST_API_PORT_NAME, readinessProbeOptions))
+                .withLivenessProbe(ProbeGenerator.httpProbe(livenessProbeOptions, livenessPath, REST_API_PORT_NAME))
+                .withReadinessProbe(ProbeGenerator.httpProbe(readinessProbeOptions, readinessPath, REST_API_PORT_NAME))
                 .withVolumeMounts(getVolumeMounts())
                 .withResources(getResources())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1661,11 +1661,11 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withEnv(getEnvVars())
                 .withVolumeMounts(getVolumeMounts())
                 .withPorts(getContainerPortList())
-                .withLivenessProbe(ModelUtils.newProbeBuilder(livenessProbeOptions)
+                .withLivenessProbe(ProbeGenerator.defaultBuilder(livenessProbeOptions)
                         .withNewExec()
                             .withCommand("/opt/kafka/kafka_liveness.sh")
                         .endExec().build())
-                .withReadinessProbe(ModelUtils.newProbeBuilder(readinessProbeOptions)
+                .withReadinessProbe(ProbeGenerator.defaultBuilder(readinessProbeOptions)
                         .withNewExec()
                             // The kafka-agent will create /var/opt/kafka/kafka-ready in the container
                             .withCommand("test", "-f", "/var/opt/kafka/kafka-ready")

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaExporter.java
Patch:
@@ -189,8 +189,8 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withCommand("/opt/kafka-exporter/kafka_exporter_run.sh")
                 .withEnv(getEnvVars())
                 .withPorts(getContainerPortList())
-                .withLivenessProbe(ModelUtils.createHttpProbe(livenessPath, METRICS_PORT_NAME, livenessProbeOptions))
-                .withReadinessProbe(ModelUtils.createHttpProbe(readinessPath, METRICS_PORT_NAME, readinessProbeOptions))
+                .withLivenessProbe(ProbeGenerator.httpProbe(livenessProbeOptions, livenessPath, METRICS_PORT_NAME))
+                .withReadinessProbe(ProbeGenerator.httpProbe(readinessProbeOptions, readinessPath, METRICS_PORT_NAME))
                 .withResources(getResources())
                 .withVolumeMounts(VolumeUtils.createVolumeMount(KAFKA_EXPORTER_CERTS_VOLUME_NAME, KAFKA_EXPORTER_CERTS_VOLUME_MOUNT),
                         VolumeUtils.createVolumeMount(CLUSTER_CA_CERTS_VOLUME_NAME, CLUSTER_CA_CERTS_VOLUME_MOUNT))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -523,8 +523,8 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withEnv(getEnvVars())
                 .withVolumeMounts(getVolumeMounts())
                 .withPorts(getContainerPortList())
-                .withLivenessProbe(ModelUtils.createExecProbe(Collections.singletonList(livenessPath), livenessProbeOptions))
-                .withReadinessProbe(ModelUtils.createExecProbe(Collections.singletonList(readinessPath), readinessProbeOptions))
+                .withLivenessProbe(ProbeGenerator.execProbe(livenessProbeOptions, Collections.singletonList(livenessPath)))
+                .withReadinessProbe(ProbeGenerator.execProbe(readinessProbeOptions, Collections.singletonList(readinessPath)))
                 .withResources(getResources())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))
                 .withSecurityContext(templateZookeeperContainerSecurityContext)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlApiImpl.java
Patch:
@@ -121,7 +121,7 @@ public Future<CruiseControlRebalanceResponse> rebalance(String host, int port, R
                             CruiseControlRebalanceResponse ccResponse = new CruiseControlRebalanceResponse(userTaskID, json);
                             if (json.containsKey(CC_REST_API_PROGRESS_KEY)) {
                                 // If the response contains a "progress" key then the rebalance proposal has not yet completed processing
-                                ccResponse.setProposalIsStillCalculating(true);
+                                ccResponse.setProposalStillCalaculating(true);
                             } else {
                                 result.fail(new CruiseControlRestException(
                                         "Error for request: " + host + ":" + port + path +

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceStateMachineTest.java
Patch:
@@ -70,7 +70,7 @@ public class KafkaRebalanceStateMachineTest {
 
     @BeforeAll
     public static void before() throws IOException, URISyntaxException {
-        ccServer = MockCruiseControl.getCCServer(CruiseControl.REST_API_PORT);
+        ccServer = MockCruiseControl.server(CruiseControl.REST_API_PORT);
     }
 
     @AfterAll

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/MockCruiseControlTest.java
Patch:
@@ -32,7 +32,7 @@ public class MockCruiseControlTest {
 
     @BeforeAll
     public static void startUp() throws IOException, URISyntaxException {
-        ccServer = MockCruiseControl.getCCServer(PORT);
+        ccServer = MockCruiseControl.server(PORT);
     }
 
     @BeforeEach

File: operator-common/src/main/java/io/strimzi/operator/common/Annotations.java
Patch:
@@ -28,8 +28,8 @@ public class Annotations {
 
     public static final String STRIMZI_IO_USE_CONNECTOR_RESOURCES = STRIMZI_DOMAIN + "use-connector-resources";
     public static final String ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE = STRIMZI_DOMAIN + "manual-rolling-update";
-    // this annotation with related possible values (approve, stop, refresh) is set by the user for interacting
-    // with the rebalance operator in order to start, stop or refresh rebalacing proposals and operations
+    // This annotation with related possible values (approve, stop, refresh) is set by the user for interacting
+    // with the rebalance operator in order to start, stop, or refresh rebalancing proposals and operations.
     public static final String ANNO_STRIMZI_IO_REBALANCE = STRIMZI_DOMAIN + "rebalance";
     @Deprecated
     public static final String ANNO_OP_STRIMZI_IO_MANUAL_ROLLING_UPDATE = "operator." + Annotations.STRIMZI_DOMAIN + "manual-rolling-update";

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Cluster.java
Patch:
@@ -141,7 +141,7 @@ protected String getDefaultLogConfigFileName() {
     }
 
     @Override
-    protected String getServiceAccountName() {
+    public String getServiceAccountName() {
         return KafkaMirrorMaker2Resources.serviceAccountName(cluster);
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractConnectOperator.java
Patch:
@@ -52,6 +52,7 @@
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.operator.common.operator.resource.ClusterRoleBindingOperator;
 import io.strimzi.operator.common.operator.resource.ConfigMapOperator;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
 import io.strimzi.operator.common.operator.resource.PodDisruptionBudgetOperator;
@@ -93,6 +94,7 @@ public abstract class AbstractConnectOperator<C extends KubernetesClient, T exte
     private final Function<Vertx, KafkaConnectApi> connectClientProvider;
     protected final ImagePullPolicy imagePullPolicy;
     protected final ConfigMapOperator configMapOperations;
+    protected final ClusterRoleBindingOperator clusterRoleBindingOperations;
     protected final ServiceOperator serviceOperations;
     protected final PodDisruptionBudgetOperator podDisruptionBudgetOperator;
     protected final List<LocalObjectReference> imagePullSecrets;
@@ -116,6 +118,7 @@ public AbstractConnectOperator(Vertx vertx, PlatformFeaturesAvailability pfa, St
         this.connectorOperator = supplier.kafkaConnectorOperator;
         this.connectClientProvider = connectClientProvider;
         this.configMapOperations = supplier.configMapOperations;
+        this.clusterRoleBindingOperations = supplier.clusterRoleBindingOperator;
         this.serviceOperations = supplier.serviceOperations;
         this.serviceAccountOperations = supplier.serviceAccountOperations;
         this.podDisruptionBudgetOperator = supplier.podDisruptionBudgetOperator;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -1670,7 +1670,7 @@ Future<ReconciliationState> withKafkaDiff(Future<ReconcileResult<StatefulSet>> r
 
         Future<ReconciliationState> kafkaInitServiceAccount() {
             return withVoid(serviceAccountOperations.reconcile(namespace,
-                    KafkaCluster.initContainerServiceAccountName(kafkaCluster.getCluster()),
+                    kafkaCluster.getServiceAccountName(),
                     kafkaCluster.generateServiceAccount()));
         }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -2536,7 +2536,7 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
         assertThat(crb.getMetadata().getName(), is(KafkaCluster.initContainerClusterRoleBindingName(testNamespace, cluster)));
         assertThat(crb.getMetadata().getNamespace(), is(nullValue()));
         assertThat(crb.getSubjects().get(0).getNamespace(), is(testNamespace));
-        assertThat(crb.getSubjects().get(0).getName(), is(KafkaCluster.initContainerServiceAccountName(cluster)));
+        assertThat(crb.getSubjects().get(0).getName(), is(kc.getServiceAccountName()));
     }
 
     @Test
@@ -2558,7 +2558,7 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
         assertThat(crb.getMetadata().getName(), is(KafkaCluster.initContainerClusterRoleBindingName(testNamespace, cluster)));
         assertThat(crb.getMetadata().getNamespace(), is(nullValue()));
         assertThat(crb.getSubjects().get(0).getNamespace(), is(testNamespace));
-        assertThat(crb.getSubjects().get(0).getName(), is(KafkaCluster.initContainerServiceAccountName(cluster)));
+        assertThat(crb.getSubjects().get(0).getName(), is(kc.getServiceAccountName()));
     }
 
     @Test

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/ClientArgument.java
Patch:
@@ -24,6 +24,7 @@ public enum ClientArgument {
 
     // Producer
     BOOTSTRAP_SERVER("--bootstrap-server"),
+    BROKER_LIST("--broker-list"),
     PRODUCER_CONFIG("--producer.config"),
     ACKS("--acks"),
     TIMEOUT("--timeout"),

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthExternalKafkaClient.java
Patch:
@@ -218,7 +218,7 @@ public int receiveMessagesPlain(long timeoutMs) {
     }
 
     public int receiveMessagesTls() {
-        return sendMessagesTls(Constants.GLOBAL_CLIENTS_TIMEOUT);
+        return receiveMessagesTls(Constants.GLOBAL_CLIENTS_TIMEOUT);
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -371,6 +371,9 @@ void testDynamicallySetBridgeLoggingLevels() throws InterruptedException {
         ilOff.setLoggers(loggers);
 
         KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1).done();
+
+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();
+
         KafkaBridgeResource.kafkaBridge(CLUSTER_NAME, KafkaResources.tlsBootstrapAddress(CLUSTER_NAME), 1)
                 .editSpec()
                     .withInlineLogging(ilOff)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -110,7 +110,6 @@ public abstract class AbstractModel {
      */
     public static final String ANNO_STRIMZI_IO_STORAGE = Annotations.STRIMZI_DOMAIN + "storage";
     public static final String ANNO_STRIMZI_IO_DELETE_CLAIM = Annotations.STRIMZI_DOMAIN + "delete-claim";
-    public static final String ANNO_STRIMZI_LOGGING_HASH = Annotations.STRIMZI_DOMAIN + "logging-hash";
 
     @Deprecated
     public static final String ANNO_CO_STRIMZI_IO_DELETE_CLAIM = ClusterOperator.STRIMZI_CLUSTER_OPERATOR_DOMAIN + "/delete-claim";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiffTest.java
Patch:
@@ -7,7 +7,6 @@
 
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.common.Util;
 import io.strimzi.test.TestUtils;
 import org.apache.kafka.clients.admin.AlterConfigOp;
 import org.apache.kafka.clients.admin.Config;
@@ -74,7 +73,7 @@ private Config getCurrentConfiguration(List<ConfigEntry> additional) {
     }
 
     private void assertConfig(KafkaBrokerConfigurationDiff kcd, ConfigEntry ce) {
-        Collection<AlterConfigOp> brokerDiffConf = kcd.getConfigDiff().get(Util.getBrokersConfig(brokerId));
+        Collection<AlterConfigOp> brokerDiffConf = kcd.getConfigDiff();
         long appearances = brokerDiffConf.stream().filter(entry -> entry.configEntry().name().equals(ce.name())).count();
         Optional<AlterConfigOp> en = brokerDiffConf.stream().filter(entry -> entry.configEntry().name().equals(ce.name())).findFirst();
         assertThat(appearances, is(1L));

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -167,7 +167,7 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl
                         .withNewTls().endTls()
                     .endListeners()
                     .withNewInlineLogging()
-                        .addToLoggers("kafka.root.logger.level", "DEBUG")
+                        .addToLoggers("log4j.rootLogger", "DEBUG")
                     .endInlineLogging()
                 .endKafka()
                 .editZookeeper()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.operator.cluster.operator.resource;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.api.model.PersistentVolumeClaim;
 import io.fabric8.kubernetes.api.model.Pod;
@@ -333,7 +334,7 @@ protected Future<ReconcileResult<StatefulSet>> internalReplace(String namespace,
             long pollingIntervalMs = 1_000;
             long timeoutMs = operationTimeoutMs;
 
-            operation().inNamespace(namespace).withName(name).cascading(cascading).withGracePeriod(-1L).delete();
+            operation().inNamespace(namespace).withName(name).withPropagationPolicy(cascading ? DeletionPropagation.FOREGROUND : DeletionPropagation.ORPHAN).withGracePeriod(-1L).delete();
 
             Future<Void> deletedFut = waitFor(namespace, name, "deleted", pollingIntervalMs, timeoutMs, (ignore1, ignore2) -> {
                 StatefulSet sts = get(namespace, name);
@@ -372,7 +373,7 @@ public Future<Void> deleteAsync(String namespace, String name, boolean cascading
         vertx.createSharedWorkerExecutor("kubernetes-ops-tool").executeBlocking(
             future -> {
                 try {
-                    Boolean deleted = operation().inNamespace(namespace).withName(name).cascading(cascading).withGracePeriod(-1L).delete();
+                    Boolean deleted = operation().inNamespace(namespace).withName(name).withPropagationPolicy(cascading ? DeletionPropagation.FOREGROUND : DeletionPropagation.ORPHAN).withGracePeriod(-1L).delete();
 
                     if (deleted) {
                         log.debug("{} {} in namespace {} has been deleted", resourceKind, name, namespace);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
Patch:
@@ -14,6 +14,7 @@
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.NonNamespaceOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
+import io.fabric8.kubernetes.client.dsl.base.CustomResourceDefinitionContext;
 import io.fabric8.openshift.client.OpenShiftClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
@@ -147,7 +148,7 @@ private void startStop(VertxTestContext context, String namespaces, boolean open
         }
         when(mockCrds.withName(KafkaConnectS2I.CRD_NAME)).thenReturn(mockResource);
         when(client.customResourceDefinitions()).thenReturn(mockCrds);
-        when(client.customResources(any(), any(), any(), any())).thenReturn(mockCms);
+        when(client.customResources(any(CustomResourceDefinitionContext.class), any(), any(), any())).thenReturn(mockCms);
 
         List<String> namespaceList = asList(namespaces.split(" *,+ *"));
         for (String namespace: namespaceList) {
@@ -229,7 +230,7 @@ private void startStopAllNamespaces(VertxTestContext context, String namespaces,
         }
         when(mockCrds.withName(KafkaConnectS2I.CRD_NAME)).thenReturn(mockResource);
         when(client.customResourceDefinitions()).thenReturn(mockCrds);
-        when(client.customResources(any(), any(), any(), any())).thenReturn(mockCms);
+        when(client.customResources(any(CustomResourceDefinitionContext.class), any(), any(), any())).thenReturn(mockCms);
 
         FilterWatchListMultiDeletable mockFilteredCms = mock(FilterWatchListMultiDeletable.class);
         when(mockFilteredCms.withLabels(any())).thenReturn(mockFilteredCms);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -442,7 +442,8 @@ public static KafkaConnectS2I createEmptyKafkaConnectS2I(String namespace, Strin
                     .withNamespace(namespace)
                     .withLabels(TestUtils.map(Labels.KUBERNETES_DOMAIN + "part-of", "tests",
                             "my-user-label", "cromulent"))
-                    .build())
+                    .withAnnotations(emptyMap())
+                .build())
                 .withNewSpec()
                 .endSpec()
                 .build();
@@ -458,6 +459,7 @@ public static KafkaConnect createEmptyKafkaConnect(String namespace, String name
                         .withNamespace(namespace)
                         .withLabels(TestUtils.map(Labels.KUBERNETES_DOMAIN + "part-of", "tests",
                                 "my-user-label", "cromulent"))
+                        .withAnnotations(emptyMap())
                         .build())
                 .withNewSpec()
                 .endSpec()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -358,7 +358,7 @@ public void testDefaultImagePullSecrets() {
         EntityOperator eo = EntityOperator.fromCrd(resource, VERSIONS);
 
         Deployment dep = eo.generateDeployment(true, Collections.EMPTY_MAP, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().size(), is(0));
+        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets(), is(nullValue()));
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -525,7 +525,7 @@ public void testDefaultImagePullSecrets() {
         KafkaBridgeCluster kbc = KafkaBridgeCluster.fromCrd(resource, VERSIONS);
 
         Deployment dep = kbc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().size(), is(0));
+        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets(), is(nullValue()));
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -894,7 +894,7 @@ public void testDefaultImagePullSecrets() {
         KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(resource, VERSIONS);
 
         Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().size(), is(0));
+        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets(), is(nullValue()));
     }
 
     @Test
@@ -1334,7 +1334,7 @@ public void testNetworkPolicyWithConnectorOperator() {
         assertThat(np.getSpec().getIngress().get(0).getFrom().get(0).getPodSelector().getMatchLabels(), is(kc.getSelectorLabels().toMap()));
         assertThat(np.getSpec().getIngress().get(0).getFrom().get(0).getNamespaceSelector(), is(nullValue()));
         assertThat(np.getSpec().getIngress().get(0).getFrom().get(1).getPodSelector().getMatchLabels(), is(singletonMap(Labels.STRIMZI_KIND_LABEL, "cluster-operator")));
-        assertThat(np.getSpec().getIngress().get(0).getFrom().get(1).getNamespaceSelector().getMatchLabels(), is(emptyMap()));
+        assertThat(np.getSpec().getIngress().get(0).getFrom().get(1).getNamespaceSelector().getMatchLabels(), is(nullValue()));
         assertThat(np.getSpec().getIngress().get(1).getPorts().size(), is(1));
         assertThat(np.getSpec().getIngress().get(1).getPorts().get(0).getPort().getIntVal(), is(KafkaConnectCluster.METRICS_PORT));
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -282,7 +282,7 @@ public void testGenerateBuildConfig() {
         assertThat(bc.getSpec().getSuccessfulBuildsHistoryLimit(), is(new Integer(5)));
         assertThat(bc.getSpec().getFailedBuildsHistoryLimit(), is(new Integer(5)));
         assertThat(bc.getSpec().getResources().getLimits().get("cpu").getAmount(), is("42"));
-        assertThat(bc.getSpec().getResources().getRequests().get("mem").getAmount(), is("4Gi"));
+        assertThat(bc.getSpec().getResources().getRequests().get("mem"), is(new Quantity("4", "Gi")));
         checkOwnerReference(kc.createOwnerReference(), bc);
     }
 
@@ -870,7 +870,7 @@ public void testDefaultImagePullSecrets() {
         KafkaConnectS2ICluster kc = KafkaConnectS2ICluster.fromCrd(resource, VERSIONS);
 
         DeploymentConfig dep = kc.generateDeploymentConfig(Collections.EMPTY_MAP, true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().size(), is(0));
+        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets(), is(nullValue()));
     }
 
     @Test
@@ -1275,7 +1275,7 @@ public void testNetworkPolicyWithConnectorOperator() {
         assertThat(np.getSpec().getIngress().get(0).getFrom().get(0).getPodSelector().getMatchLabels(), is(kc.getSelectorLabels().toMap()));
         assertThat(np.getSpec().getIngress().get(0).getFrom().get(0).getNamespaceSelector(), is(nullValue()));
         assertThat(np.getSpec().getIngress().get(0).getFrom().get(1).getPodSelector().getMatchLabels(), is(singletonMap(Labels.STRIMZI_KIND_LABEL, "cluster-operator")));
-        assertThat(np.getSpec().getIngress().get(0).getFrom().get(1).getNamespaceSelector().getMatchLabels(), is(emptyMap()));
+        assertThat(np.getSpec().getIngress().get(0).getFrom().get(1).getNamespaceSelector().getMatchLabels(), is(nullValue()));
         assertThat(np.getSpec().getIngress().get(1).getPorts().size(), is(1));
         assertThat(np.getSpec().getIngress().get(1).getPorts().get(0).getPort().getIntVal(), is(KafkaConnectCluster.METRICS_PORT));
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -1003,7 +1003,7 @@ public void testDefaultImagePullSecrets() {
         KafkaMirrorMaker2Cluster kmm2 = KafkaMirrorMaker2Cluster.fromCrd(resource, VERSIONS);
 
         Deployment dep = kmm2.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().size(), is(0));
+        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets(), is(nullValue()));
     }
 
     @Test
@@ -1442,7 +1442,7 @@ public void testNetworkPolicy() {
         assertThat(np.getSpec().getIngress().get(0).getFrom().get(0).getPodSelector().getMatchLabels(), is(kc.getSelectorLabels().toMap()));
         assertThat(np.getSpec().getIngress().get(0).getFrom().get(0).getNamespaceSelector(), is(nullValue()));
         assertThat(np.getSpec().getIngress().get(0).getFrom().get(1).getPodSelector().getMatchLabels(), is(singletonMap(Labels.STRIMZI_KIND_LABEL, "cluster-operator")));
-        assertThat(np.getSpec().getIngress().get(0).getFrom().get(1).getNamespaceSelector().getMatchLabels(), is(emptyMap()));
+        assertThat(np.getSpec().getIngress().get(0).getFrom().get(1).getNamespaceSelector().getMatchLabels(), is(nullValue()));
         assertThat(np.getSpec().getIngress().get(1).getPorts().size(), is(1));
         assertThat(np.getSpec().getIngress().get(1).getPorts().get(0).getPort().getIntVal(), is(KafkaConnectCluster.METRICS_PORT));
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -601,7 +601,7 @@ public void testDefaultImagePullSecrets() {
         KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(resource, VERSIONS);
 
         Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
-        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets().size(), is(0));
+        assertThat(dep.getSpec().getTemplate().getSpec().getImagePullSecrets(), is(nullValue()));
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/VolumeUtilsTest.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.operator.cluster.model;
 
+import io.fabric8.kubernetes.api.model.Quantity;
 import org.junit.jupiter.api.Test;
 
 import io.fabric8.kubernetes.api.model.Volume;
@@ -17,7 +18,7 @@ public class VolumeUtilsTest {
     @Test
     public void testCreateEmptyDirVolumeWithSizeLimit() {
         Volume volume = VolumeUtils.createEmptyDirVolume("bar", "1Gi");
-        assertThat(volume.getEmptyDir().getSizeLimit().getAmount(), is("1Gi"));
+        assertThat(volume.getEmptyDir().getSizeLimit(), is(new Quantity("1", "Gi")));
     }
 
     @Test

File: crd-generator/src/main/java/io/strimzi/crdgenerator/annotations/Crd.java
Patch:
@@ -4,8 +4,6 @@
  */
 package io.strimzi.crdgenerator.annotations;
 
-import io.fabric8.kubernetes.api.model.extensions.Scale;
-
 import java.lang.annotation.ElementType;
 import java.lang.annotation.Retention;
 import java.lang.annotation.RetentionPolicy;

File: mockkube/src/main/java/io/strimzi/test/mockkube/DeploymentMockBuilder.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.test.mockkube;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.DoneablePod;
 import io.fabric8.kubernetes.api.model.Pod;
 import io.fabric8.kubernetes.api.model.PodBuilder;
@@ -41,7 +42,7 @@ public DeploymentMockBuilder(Map<String, Deployment> depDb, MixedOperation<Pod,
 
     @Override
     protected void mockCreate(String resourceName, RollableScalableResource<Deployment, DoneableDeployment> resource) {
-        when(resource.create(any())).thenAnswer(invocation -> {
+        when(resource.create(any(Deployment.class))).thenAnswer(invocation -> {
             checkNotExists(resourceName);
             Deployment deployment = invocation.getArgument(0);
             LOGGER.debug("create {} {} -> {}", resourceType, resourceName, deployment);
@@ -115,7 +116,7 @@ protected void mockPatch(String resourceName, RollableScalableResource<Deploymen
                 // delete the first "old" Pod if there is one still remaining
                 if (podsForDeployments.get(deploymentName).size() > 0) {
                     String podToDelete = podsForDeployments.get(deploymentName).remove(0);
-                    mockPods.inNamespace(deployment.getMetadata().getNamespace()).withName(podToDelete).cascading(true).delete();
+                    mockPods.inNamespace(deployment.getMetadata().getNamespace()).withName(podToDelete).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
                 }
 
             }

File: mockkube/src/main/java/io/strimzi/test/mockkube/ServiceMockBuilder.java
Patch:
@@ -31,7 +31,7 @@ public ServiceMockBuilder(Map<String, Service> svcDb, Map<String, Endpoints> end
     /** Override Service creation to also create Endpoints */
     @Override
     protected void mockCreate(String resourceName, ServiceResource<Service, DoneableService> resource) {
-        when(resource.create(any())).thenAnswer(i -> {
+        when(resource.create(any(Service.class))).thenAnswer(i -> {
             Service argument = i.getArgument(0);
             db.put(resourceName, copyResource(argument));
             LOGGER.debug("create {} (and endpoint) {} ", resourceType, resourceName);

File: mockkube/src/test/java/io/strimzi/test/io/strimzi/test/mockkube/MockKubeRegressionTest.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.test.io.strimzi.test.mockkube;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.Pod;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.KubernetesClientException;
@@ -73,7 +74,7 @@ public void onClose(KubernetesClientException cause) {
 
             }
         });
-        client.pods().inNamespace("ns").withName(ns.get(0).getMetadata().getName()).cascading(true).delete();
+        client.pods().inNamespace("ns").withName(ns.get(0).getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
 
         assertThat(deleted.get(), is(true));
         assertThat(recreated.get(), is(true));
@@ -82,7 +83,7 @@ public void onClose(KubernetesClientException cause) {
         ns = client.pods().inNamespace("ns").list().getItems();
         assertThat(ns, hasSize(3));
 
-        client.apps().statefulSets().inNamespace("ns").withName("foo").cascading(true).delete();
+        client.apps().statefulSets().inNamespace("ns").withName("foo").withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
 
     }
 }

File: mockkube/src/test/java/io/strimzi/test/io/strimzi/test/mockkube/MockKubeTest.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.test.io.strimzi.test.mockkube;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.Doneable;
 import io.fabric8.kubernetes.api.model.HasMetadata;
 import io.fabric8.kubernetes.api.model.KubernetesResource;
@@ -236,7 +237,7 @@ public void testPodNameScopedCreateListGetDelete(Class<RT> cls,
         // TODO assertNull(gotResource);
 
         // Delete
-        assertThat(mixedOp.apply(client).withName(pod.getMetadata().getName()).cascading(true).delete(), is(true));
+        assertThat(mixedOp.apply(client).withName(pod.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete(), is(true));
         assertThat(w.lastEvent().action, is(Watcher.Action.DELETED));
         RT resource = (RT) w.lastEvent().resource;
         resource.getMetadata().setResourceVersion(null);
@@ -249,7 +250,7 @@ public void testPodNameScopedCreateListGetDelete(Class<RT> cls,
         gotResource = mixedOp.apply(client).withName(pod.getMetadata().getName()).get();
         assertThat(gotResource, is(nullValue()));
 
-        assertThat(mixedOp.apply(client).withName(pod.getMetadata().getName()).cascading(true).delete(), is(false));
+        assertThat(mixedOp.apply(client).withName(pod.getMetadata().getName()).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete(), is(false));
 
         // TODO Delete off a withLabels query, delete off a inNamespace
         // TODO inAnyNamespace()

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractNonNamespacedResourceOperator.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.HasMetadata;
 import io.fabric8.kubernetes.api.model.KubernetesResourceList;
 import io.fabric8.kubernetes.client.KubernetesClient;
@@ -173,7 +174,7 @@ protected Future<ReconcileResult<T>> internalPatch(String name, T current, T des
 
     protected Future<ReconcileResult<T>> internalPatch(String name, T current, T desired, boolean cascading) {
         try {
-            T result = operation().withName(name).cascading(cascading).patch(desired);
+            T result = operation().withName(name).withPropagationPolicy(cascading ? DeletionPropagation.FOREGROUND : DeletionPropagation.ORPHAN).patch(desired);
             log.debug("{} {} has been patched", resourceKind, name);
             return Future.succeededFuture(wasChanged(current, result) ?
                     ReconcileResult.patched(result) : ReconcileResult.noop(result));

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractResourceOperator.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.HasMetadata;
 import io.fabric8.kubernetes.api.model.KubernetesResourceList;
 import io.fabric8.kubernetes.api.model.LabelSelector;
@@ -145,7 +146,7 @@ protected Future<ReconcileResult<T>> internalDelete(String namespace, String nam
 
     protected Future<ReconcileResult<T>> internalDelete(String namespace, String name, boolean cascading) {
         try {
-            operation().inNamespace(namespace).withName(name).cascading(cascading).withGracePeriod(-1L).delete();
+            operation().inNamespace(namespace).withName(name).withPropagationPolicy(cascading ? DeletionPropagation.FOREGROUND : DeletionPropagation.ORPHAN).withGracePeriod(-1L).delete();
             log.debug("{} {} in namespace {} has been deleted", resourceKind, name, namespace);
             return Future.succeededFuture(ReconcileResult.deleted());
         } catch (Exception e) {
@@ -164,7 +165,7 @@ protected Future<ReconcileResult<T>> internalPatch(String namespace, String name
 
     protected Future<ReconcileResult<T>> internalPatch(String namespace, String name, T current, T desired, boolean cascading) {
         try {
-            T result = operation().inNamespace(namespace).withName(name).cascading(cascading).patch(desired);
+            T result = operation().inNamespace(namespace).withName(name).withPropagationPolicy(cascading ? DeletionPropagation.FOREGROUND : DeletionPropagation.ORPHAN).patch(desired);
             log.debug("{} {} in namespace {} has been patched", resourceKind, name, namespace);
             return Future.succeededFuture(wasChanged(current, result) ? ReconcileResult.patched(result) : ReconcileResult.noop(result));
         } catch (Exception e) {

File: operator-common/src/test/java/io/strimzi/operator/PlatformFeaturesAvailabilityTest.java
Patch:
@@ -7,7 +7,6 @@
 import io.fabric8.kubernetes.client.DefaultKubernetesClient;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.VersionInfo;
-import io.strimzi.operator.common.Util;
 import io.vertx.core.Vertx;
 import io.vertx.core.http.HttpMethod;
 import io.vertx.core.http.HttpServer;
@@ -185,7 +184,7 @@ public void versionInfoFromMap(VertxTestContext context) throws ParseException {
                 "compiler=gc\n" +
                 "platform=linux/amd64";
 
-        VersionInfo vi = new VersionInfo(Util.parseMap(version));
+        VersionInfo vi = PlatformFeaturesAvailability.parseVersionInfo(version);
 
         context.verify(() -> {
             assertThat(vi.getMajor(), is("1"));

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ClusterRoleBindingOperatorIT.java
Patch:
@@ -49,9 +49,10 @@ protected ClusterRoleBinding getOriginal()  {
                 .withKind("ClusterRole")
                 .build();
 
+
         return new ClusterRoleBindingBuilder()
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withLabels(singletonMap("state", "new"))
                 .endMetadata()
                     .withSubjects(ks)
@@ -76,7 +77,7 @@ protected ClusterRoleBinding getModified()  {
 
         return new ClusterRoleBindingBuilder()
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withLabels(singletonMap("state", "modified"))
                 .endMetadata()
                 .withSubjects(ks)

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ClusterRoleOperatorIT.java
Patch:
@@ -43,7 +43,7 @@ protected ClusterRole getOriginal()  {
 
         return new ClusterRoleBuilder()
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withLabels(singletonMap("state", "new"))
                 .endMetadata()
                 .withRules(rule)
@@ -60,7 +60,7 @@ protected ClusterRole getModified()  {
 
         return new ClusterRoleBuilder()
                 .withNewMetadata()
-                .withName(RESOURCE_NAME)
+                .withName(resourceName)
                 .withLabels(singletonMap("state", "modified"))
                 .endMetadata()
                 .withRules(rule)

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaBridgeCrdOperatorIT.java
Patch:
@@ -48,11 +48,12 @@ protected String getNamespace() {
         return "bridge-crd-it-namespace";
     }
 
-    protected KafkaBridge getResource() {
+    @Override
+    protected KafkaBridge getResource(String resourceName) {
         return new KafkaBridgeBuilder()
                 .withApiVersion(KafkaBridge.RESOURCE_GROUP + "/" + KafkaBridge.V1ALPHA1)
                 .withNewMetadata()
-                .withName(RESOURCE_NAME)
+                .withName(resourceName)
                 .withNamespace(getNamespace())
                 .endMetadata()
                 .withNewSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectCrdOperatorIT.java
Patch:
@@ -46,11 +46,11 @@ protected String getNamespace() {
     }
 
     @Override
-    protected KafkaConnect getResource() {
+    protected KafkaConnect getResource(String resourceName) {
         return new KafkaConnectBuilder()
                 .withApiVersion(KafkaConnect.RESOURCE_GROUP + "/" + KafkaConnect.V1BETA1)
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withNamespace(getNamespace())
                 .endMetadata()
                 .withNewSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectS2ICrdOperatorIT.java
Patch:
@@ -46,11 +46,12 @@ protected String getNamespace() {
         return "kafka-connects2i-crd-it-namespace";
     }
 
-    protected KafkaConnectS2I getResource() {
+    @Override
+    protected KafkaConnectS2I getResource(String resourceName) {
         return new KafkaConnectS2IBuilder()
                 .withApiVersion(KafkaConnectS2I.RESOURCE_GROUP + "/" + KafkaConnectS2I.V1BETA1)
                 .withNewMetadata()
-                .withName(RESOURCE_NAME)
+                .withName(resourceName)
                 .withNamespace(getNamespace())
                 .endMetadata()
                 .withNewSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectorCrdOperatorIT.java
Patch:
@@ -46,11 +46,11 @@ protected String getNamespace() {
     }
 
     @Override
-    protected KafkaConnector getResource() {
+    protected KafkaConnector getResource(String resourceName) {
         return new KafkaConnectorBuilder()
                 .withApiVersion(KafkaConnector.RESOURCE_GROUP + "/" + KafkaConnector.V1ALPHA1)
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withNamespace(getNamespace())
                 .endMetadata()
                 .withNewSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorIT.java
Patch:
@@ -45,11 +45,12 @@ protected String getNamespace() {
         return "kafka-crd-it-namespace";
     }
 
-    protected Kafka getResource() {
+    @Override
+    protected Kafka getResource(String resourceName) {
         return new KafkaBuilder()
                 .withApiVersion(Kafka.RESOURCE_GROUP + "/" + Kafka.V1BETA1)
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withNamespace(getNamespace())
                 .endMetadata()
                 .withNewSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorTest.java
Patch:
@@ -8,6 +8,7 @@
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
+import io.fabric8.kubernetes.client.dsl.base.CustomResourceDefinitionContext;
 import io.fabric8.kubernetes.client.dsl.base.OperationSupport;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaList;
@@ -79,7 +80,7 @@ protected Kafka resource() {
 
     @Override
     protected void mocker(KubernetesClient mockClient, MixedOperation op) {
-        when(mockClient.customResources(any(), any(), any(), any())).thenReturn(op);
+        when(mockClient.customResources(any(CustomResourceDefinitionContext.class), any(), any(), any())).thenReturn(op);
     }
 
     @Override

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaMirrorMaker2CrdOperatorIT.java
Patch:
@@ -45,11 +45,12 @@ protected String getNamespace() {
         return "kafka-mirror-maker-2-crd-it-namespace";
     }
 
-    protected KafkaMirrorMaker2 getResource() {
+    @Override
+    protected KafkaMirrorMaker2 getResource(String resourceName) {
         return new KafkaMirrorMaker2Builder()
                 .withApiVersion(KafkaMirrorMaker2.RESOURCE_GROUP + "/" + KafkaMirrorMaker2.V1ALPHA1)
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withNamespace(getNamespace())
                 .endMetadata()
                 .withNewSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaUserCrdOperatorIT.java
Patch:
@@ -45,11 +45,12 @@ protected String getNamespace() {
         return "kafka-user-crd-it-namespace";
     }
 
-    protected KafkaUser getResource() {
+    @Override
+    protected KafkaUser getResource(String resourceName) {
         return new KafkaUserBuilder()
                 .withApiVersion(KafkaUser.RESOURCE_GROUP + "/" + KafkaUser.V1BETA1)
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withNamespace(getNamespace())
                 .endMetadata()
                 .withNewSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/NodeOperatorIT.java
Patch:
@@ -34,7 +34,7 @@ Resource<Node, DoneableNode>> operator() {
     protected Node getOriginal()  {
         return new NodeBuilder()
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withLabels(singletonMap("foo", "bar"))
                 .endMetadata()
                 .withNewSpec()
@@ -47,7 +47,7 @@ protected Node getOriginal()  {
     protected Node getModified()  {
         return new NodeBuilder()
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withLabels(singletonMap("bar", "foo"))
                 .endMetadata()
                 .withNewSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/RoleBindingOperatorIT.java
Patch:
@@ -49,7 +49,7 @@ protected RoleBinding getOriginal()  {
 
         return new RoleBindingBuilder()
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withNamespace(namespace)
                     .withLabels(singletonMap("state", "new"))
                 .endMetadata()
@@ -75,7 +75,7 @@ protected RoleBinding getModified()  {
 
         return new RoleBindingBuilder()
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withNamespace(namespace)
                     .withLabels(singletonMap("state", "modified"))
                 .endMetadata()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ServiceAccountOperatorTest.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.operator.common.operator.resource;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.DoneableServiceAccount;
 import io.fabric8.kubernetes.api.model.ServiceAccount;
 import io.fabric8.kubernetes.api.model.ServiceAccountBuilder;
@@ -72,7 +73,7 @@ public void createWhenExistsIsAPatch(VertxTestContext context, boolean cascade)
         ServiceAccount resource = resource();
         Resource mockResource = mock(resourceType());
         when(mockResource.get()).thenReturn(resource);
-        when(mockResource.cascading(cascade)).thenReturn(mockResource);
+        when(mockResource.withPropagationPolicy(cascade ? DeletionPropagation.FOREGROUND : DeletionPropagation.ORPHAN)).thenReturn(mockResource);
 
         NonNamespaceOperation mockNameable = mock(NonNamespaceOperation.class);
         when(mockNameable.withName(matches(resource.getMetadata().getName()))).thenReturn(mockResource);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/StorageClassOperatorIT.java
Patch:
@@ -31,7 +31,7 @@ protected AbstractNonNamespacedResourceOperator<KubernetesClient, StorageClass,
     protected StorageClass getOriginal()  {
         return new StorageClassBuilder()
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withLabels(singletonMap("state", "new"))
                 .endMetadata()
                 .withReclaimPolicy("Delete")
@@ -46,7 +46,7 @@ protected StorageClass getModified()  {
         // Most of the fields seem to be immutable, we patch only labels
         return new StorageClassBuilder()
                 .withNewMetadata()
-                    .withName(RESOURCE_NAME)
+                    .withName(resourceName)
                     .withLabels(singletonMap("state", "modified"))
                 .endMetadata()
                 .withReclaimPolicy("Delete")

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -125,7 +126,7 @@ public static KafkaBridge kafkaBridgeWithoutWait(KafkaBridge kafkaBridge) {
     }
 
     public static void deleteKafkaBridgeWithoutWait(String resourceName) {
-        kafkaBridgeClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
+        kafkaBridgeClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }
 
     private static KafkaBridge getKafkaBridgeFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -110,7 +111,7 @@ public static KafkaConnect kafkaConnectWithoutWait(KafkaConnect kafkaConnect) {
     }
 
     public static void deleteKafkaConnectWithoutWait(String resourceName) {
-        kafkaConnectClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
+        kafkaConnectClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }
 
     private static KafkaConnect getKafkaConnectFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -94,7 +95,7 @@ public static KafkaConnectS2I kafkaConnectS2IWithoutWait(KafkaConnectS2I kafkaCo
     }
 
     public static void deleteKafkaConnectS2IWithoutWait(String resourceName) {
-        kafkaConnectS2IClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
+        kafkaConnectS2IClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }
 
     private static KafkaConnectS2I getKafkaConnectS2IFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -65,7 +66,7 @@ public static KafkaConnector kafkaConnectorWithoutWait(KafkaConnector kafkaConne
     }
 
     public static void deleteKafkaConnectorWithoutWait(String connectorName) {
-        kafkaConnectorClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(connectorName).cascading(true).delete();
+        kafkaConnectorClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(connectorName).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }
 
     private static DoneableKafkaConnector deployKafkaConnector(KafkaConnector kafkaConnector) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -127,7 +128,7 @@ public static KafkaMirrorMaker2 kafkaMirrorMaker2WithoutWait(KafkaMirrorMaker2 k
     }
 
     public static void deleteKafkaMirrorMaker2WithoutWait(String resourceName) {
-        kafkaMirrorMaker2Client().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
+        kafkaMirrorMaker2Client().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }
 
     private static KafkaMirrorMaker2 getKafkaMirrorMaker2FromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -104,7 +105,7 @@ public static KafkaMirrorMaker kafkaMirrorMakerWithoutWait(KafkaMirrorMaker kafk
     }
 
     public static void deleteKafkaMirrorMakerWithoutWait(String resourceName) {
-        kafkaMirrorMakerClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
+        kafkaMirrorMakerClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }
 
     private static KafkaMirrorMaker getKafkaMirrorMakerFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaRebalanceResource.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -69,7 +70,7 @@ public static KafkaRebalance kafkaRebalanceWithoutWait(KafkaRebalance kafkaRebal
     }
 
     public static void deleteKafkaRebalanceWithoutWait(String resourceName) {
-        kafkaRebalanceClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
+        kafkaRebalanceClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }
 
     private static KafkaRebalance getKafkaRebalanceFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.resources.crd;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -235,7 +236,7 @@ public static Kafka kafkaWithCruiseControlWithoutWait(String name, int kafkaRepl
      * @param resourceName kafka cluster name
      */
     public static void deleteKafkaWithoutWait(String resourceName) {
-        kafkaClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
+        kafkaClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }
 
     private static Kafka getKafkaFromYaml(String yamlPath) {

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectS2IST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.connect;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.LabelSelector;
 import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
 import io.fabric8.kubernetes.api.model.Quantity;
@@ -342,7 +343,7 @@ void testJvmAndResources() {
         TestUtils.waitFor("build status: Pending", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_AVAILABILITY_TEST,
             () -> kubeClient().getClient().adapt(OpenShiftClient.class).builds().inNamespace(NAMESPACE).withName(kafkaConnectS2IName + "-connect-1").get().getStatus().getPhase().equals("Pending"));
 
-        kubeClient().getClient().adapt(OpenShiftClient.class).builds().inNamespace(NAMESPACE).withName(kafkaConnectS2IName + "-connect-1").cascading(true).delete();
+        kubeClient().getClient().adapt(OpenShiftClient.class).builds().inNamespace(NAMESPACE).withName(kafkaConnectS2IName + "-connect-1").withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
 
         KafkaConnectS2IResource.replaceConnectS2IResource(kafkaConnectS2IName, kc -> {
             kc.getSpec().setBuildResources(new ResourceRequirementsBuilder()

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.connect;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.Quantity;
 import io.fabric8.kubernetes.api.model.ResourceRequirementsBuilder;
 import io.strimzi.api.kafka.Crds;
@@ -249,7 +250,7 @@ void testKafkaConnectWithPlainAndScramShaAuthentication() {
 
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_PATH, "99");
 
-        KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(CONNECT_TOPIC_NAME).cascading(true).delete();
+        KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(CONNECT_TOPIC_NAME).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
         LOGGER.info("Topic {} deleted", CONNECT_TOPIC_NAME);
         KafkaTopicUtils.waitForKafkaTopicDeletion(CONNECT_TOPIC_NAME);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -13,6 +13,7 @@
 import io.fabric8.kubernetes.api.model.Secret;
 import io.fabric8.kubernetes.api.model.Service;
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
+import io.fabric8.kubernetes.client.dsl.base.CustomResourceDefinitionContext;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaTopicList;
 import io.strimzi.api.kafka.model.DoneableKafkaTopic;
@@ -1972,7 +1973,7 @@ void setup() throws Exception {
     @Override
     protected void tearDownEnvironmentAfterEach() throws Exception {
         super.tearDownEnvironmentAfterEach();
-        kubeClient().getClient().customResources(Crds.kafkaTopic(), KafkaTopic.class, KafkaTopicList.class, DoneableKafkaTopic.class).inNamespace(NAMESPACE).delete();
+        kubeClient().getClient().customResources(CustomResourceDefinitionContext.fromCrd(Crds.kafkaTopic()), KafkaTopic.class, KafkaTopicList.class, DoneableKafkaTopic.class).inNamespace(NAMESPACE).delete();
         kubeClient().getClient().persistentVolumeClaims().inNamespace(NAMESPACE).delete();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/operators/CustomResourceStatusST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.operators;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.Quantity;
 import io.fabric8.kubernetes.api.model.ResourceRequirementsBuilder;
 import io.fabric8.kubernetes.api.model.Service;
@@ -316,7 +317,7 @@ void testKafkaConnectorWithoutClusterConfig() {
 
         KafkaConnectorUtils.waitForConnectorNotReady(CLUSTER_NAME);
 
-        KafkaConnectorResource.kafkaConnectorClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).cascading(true).delete();
+        KafkaConnectorResource.kafkaConnectorClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.operators.topic;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
@@ -253,7 +254,7 @@ void testDeleteTopicEnableFalse() {
 
         String topicUid = KafkaTopicUtils.topicSnapshot(topicName);
         LOGGER.info("Going to delete topic {}", topicName);
-        KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(topicName).cascading(true).delete();
+        KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(topicName).withPropagationPolicy(DeletionPropagation.FOREGROUND).delete();
         LOGGER.info("Topic {} deleted", topicName);
 
         KafkaTopicUtils.waitTopicHasRolled(topicName, topicUid);

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.rollingupdate;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.operator.common.Annotations;
@@ -96,7 +97,7 @@ void testManualTriggeringRollingUpdate() {
         LOGGER.info("Annotate Kafka StatefulSet {} with manual rolling update annotation", kafkaName);
         timeMeasuringSystem.setOperationID(timeMeasuringSystem.startTimeMeasuring(Operation.ROLLING_UPDATE));
         // set annotation to trigger Kafka rolling update
-        kubeClient().statefulSet(kafkaName).cascading(false).edit()
+        kubeClient().statefulSet(kafkaName).withPropagationPolicy(DeletionPropagation.ORPHAN).edit()
             .editMetadata()
                 .addToAnnotations(Annotations.ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE, "true")
             .endMetadata()
@@ -121,7 +122,7 @@ void testManualTriggeringRollingUpdate() {
         assertThat(received, is(sent));
 
         // set annotation to trigger Zookeeper rolling update
-        kubeClient().statefulSet(zkName).cascading(false).edit()
+        kubeClient().statefulSet(zkName).withPropagationPolicy(DeletionPropagation.ORPHAN).edit()
             .editMetadata()
                 .addToAnnotations(Annotations.ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE, "true")
             .endMetadata()

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.rollingupdate;
 
+import io.fabric8.kubernetes.api.model.DeletionPropagation;
 import io.fabric8.kubernetes.api.model.Event;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.operator.common.Annotations;
@@ -87,7 +88,7 @@ void testKafkaRollsWhenTopicIsUnderReplicated() {
         kafkaPods = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));
 
         // set annotation to trigger Kafka rolling update
-        kubeClient().statefulSet(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME)).cascading(false).edit()
+        kubeClient().statefulSet(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME)).withPropagationPolicy(DeletionPropagation.ORPHAN).edit()
             .editMetadata()
                 .addToAnnotations(Annotations.ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE, "true")
             .endMetadata()
@@ -111,7 +112,7 @@ void testKafkaTopicRFLowerThanMinInSyncReplicas() {
         LOGGER.info("Annotate Kafka StatefulSet {} with manual rolling update annotation", kafkaName);
         timeMeasuringSystem.setOperationID(timeMeasuringSystem.startTimeMeasuring(Operation.ROLLING_UPDATE));
         // set annotation to trigger Kafka rolling update
-        kubeClient().statefulSet(kafkaName).cascading(false).edit()
+        kubeClient().statefulSet(kafkaName).withPropagationPolicy(DeletionPropagation.ORPHAN).edit()
             .editMetadata()
                 .addToAnnotations(Annotations.ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE, "true")
             .endMetadata()

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -130,6 +130,7 @@ public void handle(Long inflightTimerId) {
         }, stop);
     }
 
+    @SuppressWarnings("deprecation")
     @Override
     public void start(Promise<Void> start) {
         LOGGER.info("Starting");

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicOperator.java
Patch:
@@ -95,7 +95,7 @@ public Event(HasMetadata involvedObject, String message, EventType eventType, Ha
 
         @Override
         public void handle(Void v) {
-            EventBuilder evtb = new EventBuilder().withApiVersion("v1");
+            EventBuilder evtb = new EventBuilder();
             final String eventTime = ZonedDateTime.now().format(DateTimeFormatter.ofPattern("YYYY-MM-dd'T'HH:mm:ss'Z'"));
             
             if (involvedObject != null) {

File: topic-operator/src/test/java/io/strimzi/operator/topic/K8sImplTest.java
Patch:
@@ -9,6 +9,7 @@
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
+import io.fabric8.kubernetes.client.dsl.base.CustomResourceDefinitionContext;
 import io.strimzi.api.kafka.KafkaTopicList;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopicBuilder;
@@ -57,6 +58,7 @@ public void testList(VertxTestContext context) {
 
         KubernetesClient mockClient = mock(KubernetesClient.class);
         MixedOperation<KafkaTopic, KafkaTopicList, TopicOperator.DeleteKafkaTopic, Resource<KafkaTopic, TopicOperator.DeleteKafkaTopic>> mockResources = mock(MixedOperation.class);
+        when(mockClient.customResources(any(CustomResourceDefinitionContext.class), any(Class.class), any(Class.class), any(Class.class))).thenReturn(mockResources);
         when(mockClient.customResources(any(CustomResourceDefinition.class), any(Class.class), any(Class.class), any(Class.class))).thenReturn(mockResources);
         when(mockResources.withLabels(any())).thenReturn(mockResources);
         when(mockResources.inNamespace(any())).thenReturn(mockResources);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractConfiguration.java
Patch:
@@ -5,6 +5,7 @@
 
 package io.strimzi.operator.cluster.model;
 
+import io.strimzi.operator.common.model.OrderedProperties;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -60,6 +60,7 @@
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.vertx.core.json.JsonObject;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -24,6 +24,7 @@
 import io.strimzi.api.kafka.model.Probe;
 import io.strimzi.api.kafka.model.ProbeBuilder;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.common.model.OrderedProperties;
 
 import java.util.ArrayList;
 import java.util.List;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -25,6 +25,7 @@
 import io.strimzi.api.kafka.model.Probe;
 import io.strimzi.api.kafka.model.ProbeBuilder;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.common.model.OrderedProperties;
 
 import java.util.ArrayList;
 import java.util.List;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -38,6 +38,7 @@
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.vertx.core.json.JsonArray;
 import io.vertx.core.json.JsonObject;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiff.java
Patch:
@@ -19,7 +19,7 @@
 import io.strimzi.kafka.config.model.Scope;
 import io.strimzi.operator.cluster.model.KafkaConfiguration;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.model.OrderedProperties;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.operator.resource.AbstractResourceDiff;
 import org.apache.kafka.clients.admin.AlterConfigOp;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractConfigurationTest.java
Patch:
@@ -9,6 +9,7 @@
 import java.util.Map;
 
 import io.strimzi.operator.common.InvalidConfigParameterException;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.vertx.core.json.JsonObject;
 import org.junit.jupiter.api.Test;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -46,6 +46,7 @@
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.test.TestUtils;
 import org.junit.jupiter.api.Test;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -50,6 +50,7 @@
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.test.TestUtils;
 import org.junit.jupiter.api.Test;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -46,6 +46,7 @@
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.test.TestUtils;
 import org.junit.jupiter.api.Test;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -41,6 +41,7 @@
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.model.Labels;
+import io.strimzi.operator.common.model.OrderedProperties;
 import io.strimzi.test.TestUtils;
 import org.junit.jupiter.api.Test;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -172,6 +172,7 @@ public void setup(VertxTestContext testContext) {
                     .build();
             return Future.succeededFuture(Collections.singletonList(connectorPlugin));
         });
+        when(api.updateConnectLoggers(anyString(), anyInt(), anyString())).thenReturn(Future.succeededFuture());
         when(api.getConnectorConfig(any(), any(), anyInt(), any())).thenAnswer(invocation -> {
             String host = invocation.getArgument(1);
             String connectorName = invocation.getArgument(3);

File: operator-common/src/main/java/io/strimzi/operator/common/Annotations.java
Patch:
@@ -18,6 +18,7 @@ public class Annotations {
 
     public static final String STRIMZI_DOMAIN = "strimzi.io/";
     public static final String STRIMZI_LOGGING_ANNOTATION = STRIMZI_DOMAIN + "logging";
+    public static final String ANNO_STRIMZI_LOGGING_DYNAMICALLY_UNCHANGEABLE_HASH = STRIMZI_DOMAIN + "logging-appenders-hash";
     public static final String STRIMZI_IO_USE_CONNECTOR_RESOURCES = STRIMZI_DOMAIN + "use-connector-resources";
     public static final String ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE = STRIMZI_DOMAIN + "manual-rolling-update";
     // this annotation with related possible values (approve, stop, refresh) is set by the user for interacting

File: operator-common/src/main/java/io/strimzi/operator/common/model/OrderedProperties.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster.model;
+package io.strimzi.operator.common.model;
 
 import io.strimzi.operator.common.InvalidConfigParameterException;
 import java.io.BufferedReader;

File: operator-common/src/test/java/io/strimzi/operator/common/model/OrderedPropertiesTest.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster.model;
+package io.strimzi.operator.common.model;
 
 import org.junit.jupiter.api.Test;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -3258,6 +3258,7 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
                                         .withClientId("my-client-id")
                                         .withValidIssuerUri("http://valid-issuer")
                                         .withIntrospectionEndpointUri("http://introspection")
+                                        .withMaxSecondsWithoutReauthentication(3600)
                                         .withNewClientSecret()
                                             .withSecretName("my-secret-secret")
                                             .withKey("my-secret-key")
@@ -3273,6 +3274,8 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
                                 .withTokenEndpointUri("http://token-endpoint-uri")
                                 .withDisableTlsHostnameVerification(true)
                                 .withDelegateToKafkaAcls(false)
+                                .withGrantsRefreshPeriodSeconds(90)
+                                .withGrantsRefreshPoolSize(4)
                                 .withTlsTrustedCertificates(cert1, cert2)
                                 .build())
                 .endKafka()

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthExternalKafkaClient.java
Patch:
@@ -145,6 +145,8 @@ public int sendMessagesTls(long timeoutMs) {
 
         KafkaClientProperties properties = this.clientProperties;
 
+        LOGGER.info("This is client.id={}, client.secret.name={}, oauthTokenEndpointUri={}", clientId, clientSecretName, oauthTokenEndpointUri);
+
         if (properties == null || properties.getProperties().isEmpty()) {
             properties = new KafkaClientProperties.KafkaClientPropertiesBuilder()
                 .withNamespaceName(namespaceName)

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -231,7 +231,7 @@ public static <T extends HasMetadata> T deleteLater(MixedOperation<T, ?, ?, ?> o
                     kubeClient().deleteIngress((Ingress) resource);
                 });
                 break;
-            default :
+            default:
                 pointerResources.push(() -> {
                     LOGGER.info("Deleting {} {} in namespace {}",
                             resource.getKind(), resource.getMetadata().getName(), resource.getMetadata().getNamespace());

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/ClientArgument.java
Patch:
@@ -23,7 +23,7 @@ public enum ClientArgument {
     ASSIGMENT_STRATEGY("--assignment-strategy"),
 
     // Producer
-    BROKER_LIST("--broker-list"),
+    BOOTSTRAP_SERVER("--bootstrap-server"),
     PRODUCER_CONFIG("--producer.config"),
     ACKS("--acks"),
     TIMEOUT("--timeout"),

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/VerifiableClient.java
Patch:
@@ -128,7 +128,7 @@ public VerifiableClient(VerifiableClientBuilder verifiableClientBuilder) {
 
         this.setAllowedArguments(this.clientType);
         this.clientArgumentMap = new ClientArgumentMap();
-        this.clientArgumentMap.put(ClientArgument.BROKER_LIST, bootstrapServer);
+        this.clientArgumentMap.put(ClientArgument.BOOTSTRAP_SERVER, bootstrapServer);
         this.clientArgumentMap.put(ClientArgument.TOPIC, topicName);
         this.clientArgumentMap.put(ClientArgument.MAX_MESSAGES, Integer.toString(maxMessages));
         if (kafkaUsername != null) this.clientArgumentMap.put(ClientArgument.USER,  kafkaUsername.replace("-", "_"));
@@ -298,7 +298,7 @@ protected void setAllowedArguments(ClientType clientType) {
         switch (clientType) {
             case CLI_KAFKA_VERIFIABLE_PRODUCER:
                 allowedArguments.add(ClientArgument.TOPIC);
-                allowedArguments.add(ClientArgument.BROKER_LIST);
+                allowedArguments.add(ClientArgument.BOOTSTRAP_SERVER);
                 allowedArguments.add(ClientArgument.MAX_MESSAGES);
                 allowedArguments.add(ClientArgument.THROUGHPUT);
                 allowedArguments.add(ClientArgument.ACKS);
@@ -309,7 +309,7 @@ protected void setAllowedArguments(ClientType clientType) {
                 allowedArguments.add(ClientArgument.USER);
                 break;
             case CLI_KAFKA_VERIFIABLE_CONSUMER:
-                allowedArguments.add(ClientArgument.BROKER_LIST);
+                allowedArguments.add(ClientArgument.BOOTSTRAP_SERVER);
                 allowedArguments.add(ClientArgument.TOPIC);
                 allowedArguments.add(ClientArgument.GROUP_ID);
                 allowedArguments.add(ClientArgument.MAX_MESSAGES);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -281,7 +281,7 @@ public static void allowNetworkPolicySettingsForResource(HasMetadata resource, S
                 .build();
 
         if (kubeClient().listPods(labelSelector).size() == 0) {
-            throw new RuntimeException("You did not create the Kafka Client instance(pod) before using the Kafka Connect");
+            throw new RuntimeException("You did not create the Kafka Client instance(pod) before using the " + resource.getKind());
         }
 
         LOGGER.info("Apply NetworkPolicy access to {} from pods with LabelSelector {}", deploymentName, labelSelector);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java
Patch:
@@ -61,7 +61,7 @@ public static void waitForClientSuccess(String jobName, String namespace, int me
     }
 
     private static long timeoutForClientFinishJob(int messagesCount) {
-        // need to add at least 1-2minutes for finishing the job
+        // need to add at least 2minutes for finishing the job
         return (long) messagesCount * 1000 + Duration.ofMinutes(2).toMillis();
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/RecoveryST.java
Patch:
@@ -7,6 +7,7 @@
 import io.strimzi.api.kafka.model.KafkaBridgeResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.AbstractST;
+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.ConfigMapUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
@@ -233,6 +234,7 @@ void setup() throws Exception {
 
     void deployTestSpecificResources() {
         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 1).done();
+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();
         KafkaBridgeResource.kafkaBridge(CLUSTER_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), 1).done();
     }
 }

File: api/src/main/java/io/strimzi/api/kafka/model/TopicOperatorSpec.java
Patch:
@@ -7,6 +7,7 @@
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.fabric8.kubernetes.api.model.Affinity;
+import io.strimzi.api.annotations.DeprecatedType;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.strimzi.crdgenerator.annotations.KubeLink;
 import io.sundr.builder.annotations.Buildable;
@@ -16,6 +17,7 @@
  * Representation of a Strimzi-managed Topic Operator deployment.
  */
 @Deprecated
+@DeprecatedType(replacedWithType = io.strimzi.api.kafka.model.EntityTopicOperatorSpec.class)
 @Buildable(
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API

File: crd-generator/src/test/java/io/strimzi/crdgenerator/DocGeneratorTest.java
Patch:
@@ -15,6 +15,7 @@
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.CoreMatchers.notNullValue;
 import static org.hamcrest.MatcherAssert.assertThat;
+import static org.junit.jupiter.api.Assertions.assertEquals;
 
 public class DocGeneratorTest {
 
@@ -25,6 +26,6 @@ public void simpleTest() throws IOException, ClassNotFoundException, URISyntaxEx
         DocGenerator crdGenerator = new DocGenerator(1, singletonList(ExampleCrd.class), w, new KubeLinker("{KubeApiReferenceBase}"));
         crdGenerator.generate(ExampleCrd.class);
         String s = w.toString();
-        assertThat(CrdTestUtils.readResource("simpleTest.adoc"), is(s));
+        assertEquals(CrdTestUtils.readResource("simpleTest.adoc"), s);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -63,7 +63,6 @@ private static KafkaConnectBuilder defaultKafkaConnect(KafkaConnect kafkaConnect
                 .withName(name)
                 .withNamespace(ResourceManager.kubeClient().getNamespace())
                 .withClusterName(kafkaClusterName)
-                .addToLabels("type", "kafka-connect")
             .endMetadata()
             .editOrNewSpec()
                 .withVersion(Environment.ST_KAFKA_VERSION)

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -49,7 +49,6 @@ public static KafkaConnectS2IBuilder defaultKafkaConnectS2I(KafkaConnectS2I kafk
                 .withName(name)
                 .withNamespace(ResourceManager.kubeClient().getNamespace())
                 .withClusterName(kafkaClusterName)
-                .addToLabels("type", "kafka-connect-s2i")
             .endMetadata()
             .editSpec()
                 .withVersion(Environment.ST_KAFKA_VERSION)

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -87,8 +87,8 @@ public static DoneableKafka kafkaJBOD(String name, int kafkaReplicas, JbodStorag
 
     public static DoneableKafka kafkaJBOD(String name, int kafkaReplicas, int zookeeperReplicas, JbodStorage jbodStorage) {
         Kafka kafka = getKafkaFromYaml(PATH_TO_KAFKA_PERSISTENT_CONFIG);
-        return deployKafka(defaultKafka(kafka, name, kafkaReplicas, zookeeperReplicas).
-            editSpec()
+        return deployKafka(defaultKafka(kafka, name, kafkaReplicas, zookeeperReplicas)
+            .editSpec()
                 .editKafka()
                     .withStorage(jbodStorage)
                 .endKafka()

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/KafkaST.java
Patch:
@@ -1899,7 +1899,7 @@ void verifyVolumeNamesAndLabels(int kafkaReplicas, int diskCountPerReplica, int
                     pvcs.add(volumeName);
                     LOGGER.info("Checking labels for volume:" + volumeName);
                     assertThat(volume.getMetadata().getLabels().get(Labels.STRIMZI_CLUSTER_LABEL), is(CLUSTER_NAME));
-                    assertThat(volume.getMetadata().getLabels().get(Labels.STRIMZI_KIND_LABEL), is("Kafka"));
+                    assertThat(volume.getMetadata().getLabels().get(Labels.STRIMZI_KIND_LABEL), is(Kafka.RESOURCE_KIND));
                     assertThat(volume.getMetadata().getLabels().get(Labels.STRIMZI_NAME_LABEL), is(CLUSTER_NAME.concat("-kafka")));
                     assertThat(volume.getSpec().getResources().getRequests().get("storage").getAmount(), is(diskSizeGi + "Gi"));
                 });

File: systemtest/src/test/java/io/strimzi/systemtest/security/OpaIntegrationST.java
Patch:
@@ -105,9 +105,6 @@ void setup() throws Exception {
         cmdKubeClient().apply(FileUtils.updateNamespaceOfYamlFile("../systemtest/src/test/resources/opa/opa.yaml", NAMESPACE));
 
         KafkaResource.kafkaEphemeral(CLUSTER_NAME,  3, 1)
-            .editMetadata()
-                .addToLabels("type", "kafka-ephemeral")
-            .endMetadata()
             .editSpec()
                 .editKafka()
                     .withNewKafkaAuthorizationOpa()

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.status.Condition;
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
@@ -101,7 +102,7 @@ void deployKafkaConnectorWithSink(String clusterName, String namespace, String t
             .endSpec().done();
         KafkaConnectorUtils.waitForConnectorReady(clusterName);
 
-        String kafkaConnectPodName = kubeClient().listPods("type", connectLabel).get(0).getMetadata().getName();
+        String kafkaConnectPodName = kubeClient().listPods(Labels.STRIMZI_KIND_LABEL, connectLabel).get(0).getMetadata().getName();
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
         KafkaClientsResource.deployKafkaClients(false, clusterName + "-" + Constants.KAFKA_CLIENTS).done();

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/CruiseControlUtils.java
Patch:
@@ -29,9 +29,9 @@ public class CruiseControlUtils {
 
     private static final Logger LOGGER = LogManager.getLogger(CruiseControlUtils.class);
 
-    private static final String CRUISE_CONTROL_METRICS_TOPIC = "strimzi.cruisecontrol.metrics"; // partitions 1 , rf - 1
-    private static final String CRUISE_CONTROL_MODEL_TRAINING_SAMPLES_TOPIC = "strimzi.cruisecontrol.modeltrainingsamples"; // partitions 32 , rf - 2
-    private static final String CRUISE_CONTROL_PARTITION_METRICS_SAMPLES_TOPIC = "strimzi.cruisecontrol.partitionmetricsamples"; // partitions 32 , rf - 2
+    public static final String CRUISE_CONTROL_METRICS_TOPIC = "strimzi.cruisecontrol.metrics"; // partitions 1 , rf - 1
+    public static final String CRUISE_CONTROL_MODEL_TRAINING_SAMPLES_TOPIC = "strimzi.cruisecontrol.modeltrainingsamples"; // partitions 32 , rf - 2
+    public static final String CRUISE_CONTROL_PARTITION_METRICS_SAMPLES_TOPIC = "strimzi.cruisecontrol.partitionmetricsamples"; // partitions 32 , rf - 2
 
     private static final int CRUISE_CONTROL_DEFAULT_PORT = 9090;
     private static final int CRUISE_CONTROL_METRICS_PORT = 9404;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -48,7 +48,7 @@ public class KafkaClusterSpec implements UnknownPropertyPreserving, Serializable
 
     public static final String FORBIDDEN_PREFIXES = "listeners, advertised., broker., listener., host.name, port, "
             + "inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, "
-            + "zookeeper.connect, zookeeper.set.acl, authorizer., super.user, "
+            + "zookeeper.connect, zookeeper.set.acl, zookeeper.ssl, zookeeper.clientCnxnSocket, authorizer., super.user, "
             + "cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers";
 
     public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols,"
@@ -144,6 +144,8 @@ public void setLogging(Logging logging) {
         this.logging = logging;
     }
 
+    @DeprecatedProperty
+    @Deprecated
     @Description("TLS sidecar configuration")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     public TlsSidecar getTlsSidecar() {

File: api/src/main/java/io/strimzi/api/kafka/model/template/KafkaClusterTemplate.java
Patch:
@@ -6,6 +6,7 @@
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import io.strimzi.api.annotations.DeprecatedProperty;
 import io.strimzi.api.kafka.model.Constants;
 import io.strimzi.api.kafka.model.UnknownPropertyPreserving;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -179,6 +180,8 @@ public void setKafkaContainer(ContainerTemplate kafkaContainer) {
         this.kafkaContainer = kafkaContainer;
     }
 
+    @DeprecatedProperty
+    @Deprecated
     @Description("Template for the Kafka broker TLS sidecar container")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public ContainerTemplate getTlsSidecarContainer() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiff.java
Patch:
@@ -64,6 +64,8 @@ public class KafkaBrokerConfigurationDiff extends AbstractResourceDiff {
             + "|.*-909[1-4]\\.sasl\\.enabled\\.mechanisms"
             + "|advertised\\.listeners"
             + "|zookeeper\\.connect"
+            + "|zookeeper\\.ssl\\..*"
+            + "|zookeeper\\.clientCnxnSocket"
             + "|broker\\.rack)$");
 
     public KafkaBrokerConfigurationDiff(Config brokerConfigs, String desired, KafkaVersion kafkaVersion, int brokerId) {

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -85,7 +85,6 @@ public abstract class AbstractST implements TestSeparator {
     protected static final String TO_IMAGE = "STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE";
     protected static final String UO_IMAGE = "STRIMZI_DEFAULT_USER_OPERATOR_IMAGE";
     protected static final String KAFKA_INIT_IMAGE = "STRIMZI_DEFAULT_KAFKA_INIT_IMAGE";
-    protected static final String TLS_SIDECAR_KAFKA_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE";
     protected static final String TLS_SIDECAR_EO_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE";
     protected static final String TEST_TOPIC_NAME = "test-topic";
 
@@ -608,8 +607,6 @@ protected void testDockerImagesForKafkaCluster(String clusterName, String namesp
         for (int i = 0; i < kafkaPods; i++) {
             String imgFromPod = PodUtils.getContainerImageNameFromPod(KafkaResources.kafkaPodName(clusterName, i), "kafka");
             assertThat("Kafka pod " + i + " uses wrong image", TestUtils.parseImageMap(imgFromDeplConf.get(KAFKA_IMAGE_MAP)).get(kafkaVersion), is(imgFromPod));
-            imgFromPod = PodUtils.getContainerImageNameFromPod(KafkaResources.kafkaPodName(clusterName, i), "tls-sidecar");
-            assertThat("Kafka TLS side car for pod " + i + " uses wrong image", imgFromDeplConf.get(TLS_SIDECAR_KAFKA_IMAGE), is(imgFromPod));
             if (rackAwareEnabled) {
                 String initContainerImage = PodUtils.getInitContainerImageName(KafkaResources.kafkaPodName(clusterName, i));
                 assertThat(initContainerImage, is(imgFromDeplConf.get(KAFKA_INIT_IMAGE)));

File: api/src/main/java/io/strimzi/api/kafka/model/AclRule.java
Patch:
@@ -16,7 +16,7 @@
 import java.util.Map;
 
 /**
- * A representation of a single ACL rule for SimpleAclAuthorizer
+ * A representation of a single ACL rule for AclAuthorizer
  */
 @Buildable(
         editableEnabled = false,

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleResource.java
Patch:
@@ -15,7 +15,7 @@
 import java.util.Map;
 
 /**
- * A representation of a single ACL rule for SimpleAclAuthorizer
+ * A representation of a single ACL rule for AclAuthorizer
  */
 @JsonTypeInfo(use = JsonTypeInfo.Id.NAME,
         include = JsonTypeInfo.As.EXISTING_PROPERTY,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaAuthorization.java
Patch:
@@ -34,7 +34,7 @@ public abstract class KafkaAuthorization implements UnknownPropertyPreserving, S
 
     @Description("Authorization type. " +
             "Currently, the supported types are `simple`, `keycloak`, and `opa`. " +
-            "`simple` authorization type uses Kafka's `kafka.security.auth.SimpleAclAuthorizer` class for authorization. " +
+            "`simple` authorization type uses Kafka's `kafka.security.authorizer.AclAuthorizer` class for authorization. " +
             "`keycloak` authorization type uses Keycloak Authorization Services for authorization. " +
             "`opa` authorization type uses Open Policy Agent based authorization.")
     public abstract String getType();

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaAuthorizationSimple.java
Patch:
@@ -28,7 +28,7 @@ public class KafkaAuthorizationSimple extends KafkaAuthorization {
 
     public static final String TYPE_SIMPLE = "simple";
 
-    public static final String AUTHORIZER_CLASS_NAME = "kafka.security.auth.SimpleAclAuthorizer";
+    public static final String AUTHORIZER_CLASS_NAME = "kafka.security.authorizer.AclAuthorizer";
 
     private List<String> superUsers;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUserAuthorization.java
Patch:
@@ -30,7 +30,7 @@ public abstract class KafkaUserAuthorization implements UnknownPropertyPreservin
 
     @Description("Authorization type. " +
             "Currently the only supported type is `simple`. " +
-            "`simple` authorization type uses Kafka's `kafka.security.auth.SimpleAclAuthorizer` class for authorization.")
+            "`simple` authorization type uses Kafka's `kafka.security.authorizer.AclAuthorizer` class for authorization.")
     public abstract String getType();
 
     @Override

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -145,7 +145,7 @@ public void testSimpleAuthorizationWithSuperUsers()  {
                 .withAuthorization("my-cluster", auth)
                 .build();
 
-        assertThat(configuration, isEquivalent("authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer\n" +
+        assertThat(configuration, isEquivalent("authorizer.class.name=kafka.security.authorizer.AclAuthorizer\n" +
                 "super.users=User:CN=my-cluster-kafka,O=io.strimzi;User:CN=my-cluster-entity-operator,O=io.strimzi;User:CN=my-cluster-kafka-exporter,O=io.strimzi;User:CN=my-cluster-cruise-control,O=io.strimzi;User:CN=cluster-operator,O=io.strimzi;User:jakub;User:CN=kuba"));
     }
 
@@ -158,7 +158,7 @@ public void testSimpleAuthorizationWithoutSuperUsers()  {
                 .withAuthorization("my-cluster", auth)
                 .build();
 
-        assertThat(configuration, isEquivalent("authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer\n" +
+        assertThat(configuration, isEquivalent("authorizer.class.name=kafka.security.authorizer.AclAuthorizer\n" +
                 "super.users=User:CN=my-cluster-kafka,O=io.strimzi;User:CN=my-cluster-entity-operator,O=io.strimzi;User:CN=my-cluster-kafka-exporter,O=io.strimzi;User:CN=my-cluster-cruise-control,O=io.strimzi;User:CN=cluster-operator,O=io.strimzi"));
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractModelTest.java
Patch:
@@ -232,9 +232,9 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
         assertThat(am.determineImagePullPolicy(ImagePullPolicy.IFNOTPRESENT, "docker.io/repo/image:tag"), is(ImagePullPolicy.IFNOTPRESENT.toString()));
         assertThat(am.determineImagePullPolicy(ImagePullPolicy.IFNOTPRESENT, "docker.io/repo/image:latest"), is(ImagePullPolicy.IFNOTPRESENT.toString()));
         assertThat(am.determineImagePullPolicy(ImagePullPolicy.NEVER, "docker.io/repo/image:tag"), is(ImagePullPolicy.NEVER.toString()));
-        assertThat(am.determineImagePullPolicy(ImagePullPolicy.NEVER, "docker.io/repo/image:latest-kafka-2.5.0"), is(ImagePullPolicy.NEVER.toString()));
+        assertThat(am.determineImagePullPolicy(ImagePullPolicy.NEVER, "docker.io/repo/image:latest-kafka-2.6.0"), is(ImagePullPolicy.NEVER.toString()));
         assertThat(am.determineImagePullPolicy(null, "docker.io/repo/image:latest"), is(ImagePullPolicy.ALWAYS.toString()));
         assertThat(am.determineImagePullPolicy(null, "docker.io/repo/image:not-so-latest"), is(ImagePullPolicy.IFNOTPRESENT.toString()));
-        assertThat(am.determineImagePullPolicy(null, "docker.io/repo/image:latest-kafka-2.5.0"), is(ImagePullPolicy.ALWAYS.toString()));
+        assertThat(am.determineImagePullPolicy(null, "docker.io/repo/image:latest-kafka-2.6.0"), is(ImagePullPolicy.ALWAYS.toString()));
     }
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConfigurationTests.java
Patch:
@@ -84,7 +84,7 @@ public void passwordType() {
     @Test
     public void invalidVersion() {
         assertConfigError("inter.broker.protocol.version", "dclncswn",
-                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E|\\Q2.5\\E(\\.[0-9]+)*|\\Q2.5-IV0\\E");
+                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E|\\Q2.5\\E(\\.[0-9]+)*|\\Q2.5-IV0\\E|\\Q2.6\\E(\\.[0-9]+)*|\\Q2.6-IV0\\E");
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaVersionTest.java
Patch:
@@ -26,7 +26,6 @@ public void parsingTest() throws Exception {
         KafkaVersion defaultVersion = KafkaVersion.parseKafkaVersions(
                 new StringReader(KafkaVersionTestUtils.getKafkaVersionYaml()), map);
         assertThat(defaultVersion.version(), is(KafkaVersionTestUtils.DEFAULT_KAFKA_VERSION));
-        assertThat(map.size(), is(3));
         assertThat(map.containsKey(KafkaVersionTestUtils.LATEST_KAFKA_VERSION), is(true));
         assertThat(map.get(KafkaVersionTestUtils.LATEST_KAFKA_VERSION).version(), is(KafkaVersionTestUtils.LATEST_KAFKA_VERSION));
         assertThat(map.get(KafkaVersionTestUtils.LATEST_KAFKA_VERSION).protocolVersion(), is(KafkaVersionTestUtils.LATEST_PROTOCOL_VERSION));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectApiTest.java
Patch:
@@ -62,9 +62,6 @@ public void beforeEach() throws IOException, InterruptedException {
         cluster.deleteDataUponShutdown(true);
         cluster.usingDirectory(Files.createTempDirectory("operator-integration-test").toFile());
         cluster.startup();
-        cluster.createTopics(getClass().getSimpleName() + "-offsets",
-                getClass().getSimpleName() + "-config",
-                getClass().getSimpleName() + "-status");
 
         // Start a N node connect cluster
         Map<String, String> workerProps = new HashMap<>();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiffTest.java
Patch:
@@ -31,7 +31,7 @@
 public class KafkaBrokerConfigurationDiffTest {
 
     private static final KafkaVersion.Lookup VERSIONS = KafkaVersionTestUtils.getKafkaVersionLookup();
-    private static final String KAFKA_VERSION = "2.5.0";
+    private static final String KAFKA_VERSION = "2.6.0";
     KafkaVersion kafkaVersion = VERSIONS.version(KAFKA_VERSION);
     private int brokerId = 0;
 

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -97,7 +97,7 @@ public class Environment {
 
     private static final String SKIP_TEARDOWN_ENV = "SKIP_TEARDOWN";
 
-    private static final String ST_KAFKA_VERSION_DEFAULT = "2.5.0";
+    private static final String ST_KAFKA_VERSION_DEFAULT = "2.6.0";
     public static final String STRIMZI_ORG_DEFAULT = "strimzi";
     public static final String STRIMZI_TAG_DEFAULT = "latest";
     public static final String STRIMZI_REGISTRY_DEFAULT = "docker.io";

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -426,14 +426,14 @@ public static <T extends HasMetadata & HasStatus> void logCurrentResourceStatus(
      * @param status - desired status
      * @return returns CR
      */
-    public static <T extends HasMetadata & HasStatus> T waitForResourceStatus(MixedOperation<T, ?, ?, ?> operation, T resource, String status, long resourceTimeout) {
+    public static <T extends HasMetadata & HasStatus> T waitForResourceStatus(MixedOperation<T, ?, ?, ?> operation, T resource, Enum<?> status, long resourceTimeout) {
         LOGGER.info("Wait for {}: {} will have desired state: {}", resource.getKind(), resource.getMetadata().getName(), status);
 
         TestUtils.waitFor(String.format("Wait for %s: %s will have desired state: %s", resource.getKind(), resource.getMetadata().getName(), status),
             Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, resourceTimeout,
             () -> operation.inNamespace(resource.getMetadata().getNamespace())
                     .withName(resource.getMetadata().getName())
-                    .get().getStatus().getConditions().stream().anyMatch(condition -> condition.getType().equals(status)),
+                    .get().getStatus().getConditions().stream().anyMatch(condition -> condition.getType().equals(status.toString())),
             () -> logCurrentResourceStatus(operation.inNamespace(resource.getMetadata().getNamespace())
                     .withName(resource.getMetadata().getName())
                     .get()));
@@ -442,7 +442,7 @@ public static <T extends HasMetadata & HasStatus> T waitForResourceStatus(MixedO
         return resource;
     }
 
-    public static <T extends HasMetadata & HasStatus> T waitForResourceStatus(MixedOperation<T, ?, ?, ?> operation, T resource, String status) {
+    public static <T extends HasMetadata & HasStatus> T waitForResourceStatus(MixedOperation<T, ?, ?, ?> operation, T resource, Enum<?> status) {
         long resourceTimeout = ResourceOperation.getTimeoutForResourceReadiness(resource.getKind());
         return waitForResourceStatus(operation, resource, status, resourceTimeout);
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -18,6 +18,7 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
 
 public class KafkaBridgeResource {
@@ -126,7 +127,7 @@ private static KafkaBridge getKafkaBridgeFromYaml(String yamlPath) {
     }
 
     private static KafkaBridge waitFor(KafkaBridge kafkaBridge) {
-        return ResourceManager.waitForResourceStatus(kafkaBridgeClient(), kafkaBridge, "Ready");
+        return ResourceManager.waitForResourceStatus(kafkaBridgeClient(), kafkaBridge, Ready);
     }
 
     private static KafkaBridge deleteLater(KafkaBridge kafkaBridge) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -23,6 +23,7 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
 
 public class KafkaConnectResource {
@@ -118,7 +119,7 @@ private static KafkaConnect getKafkaConnectFromYaml(String yamlPath) {
     }
 
     private static KafkaConnect waitFor(KafkaConnect kafkaConnect) {
-        return ResourceManager.waitForResourceStatus(kafkaConnectClient(), kafkaConnect, "Ready");
+        return ResourceManager.waitForResourceStatus(kafkaConnectClient(), kafkaConnect, Ready);
     }
 
     private static KafkaConnect deleteLater(KafkaConnect kafkaConnect) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -23,6 +23,7 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
 
 public class KafkaConnectS2IResource {
@@ -102,7 +103,7 @@ private static KafkaConnectS2I getKafkaConnectS2IFromYaml(String yamlPath) {
     }
 
     private static KafkaConnectS2I waitFor(KafkaConnectS2I kafkaConnectS2I) {
-        return ResourceManager.waitForResourceStatus(kafkaConnectS2IClient(), kafkaConnectS2I, "Ready");
+        return ResourceManager.waitForResourceStatus(kafkaConnectS2IClient(), kafkaConnectS2I, Ready);
     }
 
     private static KafkaConnectS2I deleteLater(KafkaConnectS2I kafkaConnectS2I) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -19,6 +19,7 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
 
 public class KafkaConnectorResource {
@@ -92,7 +93,7 @@ private static KafkaConnector getKafkaConnectorFromYaml(String yamlPath) {
     }
 
     private static KafkaConnector waitFor(KafkaConnector kafkaConnector) {
-        return ResourceManager.waitForResourceStatus(kafkaConnectorClient(), kafkaConnector, "Ready");
+        return ResourceManager.waitForResourceStatus(kafkaConnectorClient(), kafkaConnector, Ready);
     }
 
     private static KafkaConnector deleteLater(KafkaConnector kafkaConnector) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -23,6 +23,7 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
 
 public class KafkaMirrorMaker2Resource {
@@ -134,7 +135,7 @@ private static KafkaMirrorMaker2 getKafkaMirrorMaker2FromYaml(String yamlPath) {
     }
 
     private static KafkaMirrorMaker2 waitFor(KafkaMirrorMaker2 kafkaMirrorMaker2) {
-        return ResourceManager.waitForResourceStatus(kafkaMirrorMaker2Client(), kafkaMirrorMaker2, "Ready");
+        return ResourceManager.waitForResourceStatus(kafkaMirrorMaker2Client(), kafkaMirrorMaker2, Ready);
     }
 
     private static KafkaMirrorMaker2 deleteLater(KafkaMirrorMaker2 kafkaMirrorMaker2) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -22,6 +22,7 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
 
 public class KafkaMirrorMakerResource {
@@ -111,7 +112,7 @@ private static KafkaMirrorMaker getKafkaMirrorMakerFromYaml(String yamlPath) {
     }
 
     private static KafkaMirrorMaker waitFor(KafkaMirrorMaker kafkaMirrorMaker) {
-        return ResourceManager.waitForResourceStatus(kafkaMirrorMakerClient(), kafkaMirrorMaker, "Ready");
+        return ResourceManager.waitForResourceStatus(kafkaMirrorMakerClient(), kafkaMirrorMaker, Ready);
     }
 
     private static KafkaMirrorMaker deleteLater(KafkaMirrorMaker kafkaMirrorMaker) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaRebalanceResource.java
Patch:
@@ -78,7 +78,7 @@ private static KafkaRebalance getKafkaRebalanceFromYaml(String yamlPath) {
 
     private static KafkaRebalance waitFor(KafkaRebalance kafkaRebalance) {
         long timeout = ResourceOperation.getTimeoutForKafkaRebalanceState(KafkaRebalanceState.PendingProposal);
-        return ResourceManager.waitForResourceStatus(kafkaRebalanceClient(), kafkaRebalance, KafkaRebalanceState.PendingProposal.toString(), timeout);
+        return ResourceManager.waitForResourceStatus(kafkaRebalanceClient(), kafkaRebalance, KafkaRebalanceState.PendingProposal, timeout);
     }
 
     private static KafkaRebalance deleteLater(KafkaRebalance kafkaRebalance) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -32,6 +32,7 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
 
 public class KafkaResource {
@@ -226,7 +227,7 @@ private static Kafka waitFor(Kafka kafka) {
         if (kafka.getSpec().getCruiseControl() != null) {
             timeout += ResourceOperation.getTimeoutForResourceReadiness(Constants.KAFKA_CRUISE_CONTROL_DEPLOYMENT);
         }
-        return ResourceManager.waitForResourceStatus(kafkaClient(), kafka, "Ready", timeout);
+        return ResourceManager.waitForResourceStatus(kafkaClient(), kafka, Ready, timeout);
     }
 
     private static Kafka deleteLater(Kafka kafka) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaTopicResource.java
Patch:
@@ -19,6 +19,8 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
+
 public class KafkaTopicResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaTopicResource.class);
 
@@ -77,7 +79,7 @@ private static KafkaTopic getKafkaTopicFromYaml(String yamlPath) {
     }
 
     private static KafkaTopic waitFor(KafkaTopic kafkaTopic) {
-        return ResourceManager.waitForResourceStatus(kafkaTopicClient(), kafkaTopic, "Ready");
+        return ResourceManager.waitForResourceStatus(kafkaTopicClient(), kafkaTopic, Ready);
     }
 
     private static KafkaTopic deleteLater(KafkaTopic kafkaTopic) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaUserResource.java
Patch:
@@ -18,6 +18,8 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
+
 public class KafkaUserResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaUserResource.class);
 
@@ -67,7 +69,7 @@ public static KafkaUser kafkaUserWithoutWait(KafkaUser user) {
     }
 
     private static KafkaUser waitFor(KafkaUser kafkaUser) {
-        return ResourceManager.waitForResourceStatus(kafkaUserClient(), kafkaUser, "Ready");
+        return ResourceManager.waitForResourceStatus(kafkaUserClient(), kafkaUser, Ready);
     }
 
     private static KafkaUser deleteLater(KafkaUser kafkaUser) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaRebalanceUtils.java
Patch:
@@ -48,7 +48,7 @@ private static Condition rebalanceStateCondition(String resourceName) {
 
     public static void waitForKafkaRebalanceCustomResourceState(String resourceName, KafkaRebalanceState state) {
         KafkaRebalance kafkaRebalance = KafkaRebalanceResource.kafkaRebalanceClient().inNamespace(kubeClient().getNamespace()).withName(resourceName).get();
-        ResourceManager.waitForResourceStatus(KafkaRebalanceResource.kafkaRebalanceClient(), kafkaRebalance, state.toString(), ResourceOperation.getTimeoutForKafkaRebalanceState(state));
+        ResourceManager.waitForResourceStatus(KafkaRebalanceResource.kafkaRebalanceClient(), kafkaRebalance, state, ResourceOperation.getTimeoutForKafkaRebalanceState(state));
     }
 
     public static String annotateKafkaRebalanceResource(String resourceName, KafkaRebalanceAnnotation annotation) {

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -559,13 +559,13 @@ void verifyLabelsForRoleBindings(String clusterName, String appName) {
         );
     }
 
-    protected void verifyCRStatusCondition(Condition condition, String status, String type) {
+    protected void verifyCRStatusCondition(Condition condition, String status, Enum<?> type) {
         verifyCRStatusCondition(condition, null, null, status, type);
     }
 
-    protected void verifyCRStatusCondition(Condition condition, String message, String reason, String status, String type) {
+    protected void verifyCRStatusCondition(Condition condition, String message, String reason, String status, Enum<?> type) {
         assertThat(condition.getStatus(), is(status));
-        assertThat(condition.getType(), is(type));
+        assertThat(condition.getType(), is(type.toString()));
 
         if (condition.getMessage() != null && condition.getReason() != null) {
             assertThat(condition.getMessage(), containsString(message));

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -36,6 +36,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
@@ -249,7 +250,7 @@ void testScaleBridgeToZero() {
         KafkaBridgeStatus bridgeStatus = KafkaBridgeResource.kafkaBridgeClient().inNamespace(NAMESPACE).withName(bridgeName).get().getStatus();
 
         assertThat(bridgePods.size(), is(0));
-        assertThat(bridgeStatus.getConditions().get(0).getType(), is("Ready"));
+        assertThat(bridgeStatus.getConditions().get(0).getType(), is(Ready.toString()));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/mirrormaker/MirrorMakerST.java
Patch:
@@ -46,6 +46,7 @@
 import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.MIRROR_MAKER;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.containsString;
@@ -691,7 +692,7 @@ void testScaleMirrorMakerToZero() {
         long actualObsGen = KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getObservedGeneration();
 
         assertThat(mmPods.size(), is(0));
-        assertThat(mmStatus.getConditions().get(0).getType(), is("Ready"));
+        assertThat(mmStatus.getConditions().get(0).getType(), is(Ready.toString()));
         assertThat(actualObsGen, is(not(oldObsGen)));
     }
     

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -38,6 +38,7 @@
 
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static java.util.Collections.singletonList;
@@ -214,7 +215,7 @@ void testSendingMessagesToNonExistingTopic() {
         created = hasTopicInKafka(TOPIC_NAME);
         assertThat(created, is(true));
 
-        assertThat(KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(TOPIC_NAME).get().getStatus().getConditions().get(0).getType(), is("Ready"));
+        assertThat(KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(TOPIC_NAME).get().getStatus().getConditions().get(0).getType(), is(Ready.toString()));
         LOGGER.info("Topic successfully created");
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -75,6 +75,7 @@
 import static io.strimzi.systemtest.Constants.NETWORKPOLICIES_SUPPORTED;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.systemtest.enums.CustomResourceStatus.NotReady;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static java.util.Arrays.asList;
 import static java.util.Collections.singletonMap;
@@ -1285,7 +1286,7 @@ void testKafkaAndKafkaConnectTlsVersion() {
 
         LOGGER.info("Verifying that Kafka Connect status is NotReady because of different TLS version");
 
-        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, "NotReady");
+        KafkaConnectUtils.waitForConnectStatus(CLUSTER_NAME, NotReady);
 
         LOGGER.info("Replacing Kafka Connect config to the newest(TLSv1.2) one same as the Kafka broker has.");
 

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java
Patch:
@@ -25,6 +25,7 @@
 import java.util.HashMap;
 import java.util.Map;
 
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
@@ -47,13 +48,13 @@ void checkKafkaInDiffNamespaceThanCO(String clusterName, String namespace) {
                     .getStatus().getConditions().get(0);
             LOGGER.info("Kafka condition status: {}", kafkaCondition.getStatus());
             LOGGER.info("Kafka condition type: {}", kafkaCondition.getType());
-            return kafkaCondition.getType().equals("Ready");
+            return kafkaCondition.getType().equals(Ready.toString());
         });
 
         Condition kafkaCondition = KafkaResource.kafkaClient().inNamespace(namespace).withName(clusterName).get()
                 .getStatus().getConditions().get(0);
 
-        assertThat(kafkaCondition.getType(), is("Ready"));
+        assertThat(kafkaCondition.getType(), is(Ready.toString()));
         cluster.setNamespace(previousNamespace);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceST.java
Patch:
@@ -37,6 +37,7 @@
 import static io.strimzi.systemtest.Constants.CONNECT_COMPONENTS;
 import static io.strimzi.systemtest.Constants.CONNECT_S2I;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.systemtest.enums.CustomResourceStatus.Ready;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.hasItems;
@@ -140,7 +141,7 @@ void testUserInDifferentNamespace() {
         LOGGER.info("KafkaUser condition status: {}", kafkaCondition.getStatus());
         LOGGER.info("KafkaUser condition type: {}", kafkaCondition.getType());
 
-        assertThat(kafkaCondition.getType(), is("Ready"));
+        assertThat(kafkaCondition.getType(), is(Ready.toString()));
 
         List<Secret> secretsOfSecondNamespace = kubeClient(SECOND_NAMESPACE).listSecrets();
 

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.api.kafka.model.KafkaConnectS2IResources;
 import io.strimzi.api.kafka.model.KafkaConnector;
 import io.strimzi.api.kafka.model.KafkaResources;
+import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.PasswordSecretSourceBuilder;
 import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;
@@ -170,7 +171,7 @@ void testKafkaConnectWithFileSinkPlugin() {
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_PATH, "99");
 
         LOGGER.info("Deleting topic {} from CR", CONNECT_TOPIC_NAME);
-        cmdKubeClient().deleteByName("kafkatopic", CONNECT_TOPIC_NAME);
+        cmdKubeClient().deleteByName(KafkaTopic.CRD_NAME, CONNECT_TOPIC_NAME);
         KafkaTopicUtils.waitForKafkaTopicDeletion(CONNECT_TOPIC_NAME);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -356,6 +356,7 @@ private void assertCoMetricNotNull(String metric, String kind, HashMap<String, S
 
     @BeforeAll
     void setupEnvironment() throws Exception {
+        LOGGER.info("Setting up Environment for MetricsST");
         ResourceManager.setClassResources();
         installClusterOperator(NAMESPACE);
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -69,7 +69,7 @@ public class ResourceManager {
 
     private static final Logger LOGGER = LogManager.getLogger(ResourceManager.class);
 
-    public static final String STRIMZI_PATH_TO_CO_CONFIG = "../install/cluster-operator/050-Deployment-strimzi-cluster-operator.yaml";
+    public static final String STRIMZI_PATH_TO_CO_CONFIG = "../install/cluster-operator/060-Deployment-strimzi-cluster-operator.yaml";
     public static final long CR_CREATION_TIMEOUT = ResourceOperation.getTimeoutForResourceReadiness();
 
     private static Stack<Runnable> classResources = new Stack<>();

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/BundleResource.java
Patch:
@@ -20,7 +20,7 @@
 public class BundleResource {
     private static final Logger LOGGER = LogManager.getLogger(BundleResource.class);
 
-    public static final String PATH_TO_CO_CONFIG = "../install/cluster-operator/050-Deployment-strimzi-cluster-operator.yaml";
+    public static final String PATH_TO_CO_CONFIG = "../install/cluster-operator/060-Deployment-strimzi-cluster-operator.yaml";
 
     public static DoneableDeployment clusterOperator(String namespace, long operationTimeout) {
         return KubernetesResource.deployNewDeployment(defaultCLusterOperator(namespace, operationTimeout, Constants.RECONCILIATION_INTERVAL).build());

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -125,7 +125,7 @@ protected void installClusterOperator(String namespace, List<String> bindingsNam
             LOGGER.info("Going to install ClusterOperator via Yaml bundle");
             prepareEnvForOperator(namespace, bindingsNamespaces);
             applyRoleBindings(namespace, bindingsNamespaces);
-            // 050-Deployment
+            // 060-Deployment
             BundleResource.clusterOperator(namespace, operationTimeout, reconciliationInterval).done();
         }
     }

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceDeletionRecoveryST.java
Patch:
@@ -175,7 +175,7 @@ private void prepareEnvironmentForRecovery(String topicName, int messageCount) {
         // Setup Test environment with Kafka and store some messages
         prepareEnvForOperator(NAMESPACE);
         applyRoleBindings(NAMESPACE);
-        // 050-Deployment
+        // 060-Deployment
         BundleResource.clusterOperator(NAMESPACE).done();
         KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 3)
             .editSpec()
@@ -229,7 +229,7 @@ private void recreateClusterOperator() {
         // Recreate CO
         cluster.applyClusterOperatorInstallFiles();
         applyRoleBindings(NAMESPACE);
-        // 050-Deployment
+        // 060-Deployment
         BundleResource.clusterOperator(NAMESPACE).done();
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -254,7 +254,7 @@ void setup() {
         prepareEnvForOperator(NAMESPACE);
 
         applyRoleBindings(NAMESPACE);
-        // 050-Deployment
+        // 060-Deployment
         BundleResource.clusterOperator(NAMESPACE).done();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -392,7 +392,7 @@ private void copyModifyApply(File root) {
         Arrays.stream(Objects.requireNonNull(root.listFiles())).sorted().forEach(f -> {
             if (f.getName().matches(".*RoleBinding.*")) {
                 cmdKubeClient().applyContent(TestUtils.changeRoleBindingSubject(f, NAMESPACE));
-            } else if (f.getName().matches("050-Deployment.*")) {
+            } else if (f.getName().matches("060-Deployment.*")) {
                 cmdKubeClient().applyContent(TestUtils.changeDeploymentNamespaceUpgrade(f, NAMESPACE));
             } else {
                 cmdKubeClient().apply(f);

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java
Patch:
@@ -227,7 +227,7 @@ void setup() {
         prepareEnvForOperator(NAMESPACE);
 
         applyRoleBindings(NAMESPACE);
-        // 050-Deployment
+        // 060-Deployment
         BundleResource.clusterOperator(NAMESPACE).done();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceST.java
Patch:
@@ -199,7 +199,7 @@ private void deployTestSpecificResources() {
         List<ClusterRoleBinding> clusterRoleBindingList = KubernetesResource.clusterRoleBindingsForAllNamespaces(CO_NAMESPACE);
         clusterRoleBindingList.forEach(clusterRoleBinding ->
                 KubernetesResource.clusterRoleBinding(clusterRoleBinding, CO_NAMESPACE));
-        // 050-Deployment
+        // 060-Deployment
         BundleResource.clusterOperator("*").done();
 
         String previousNamespace = cluster.setNamespace(THIRD_NAMESPACE);

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/MultipleNamespaceST.java
Patch:
@@ -71,7 +71,7 @@ private void deployTestSpecificResources() {
 
         applyRoleBindings(CO_NAMESPACE);
         applyRoleBindings(CO_NAMESPACE, SECOND_NAMESPACE);
-        // 050-Deployment
+        // 060-Deployment
         BundleResource.clusterOperator(String.join(",", CO_NAMESPACE, SECOND_NAMESPACE)).done();
 
         cluster.setNamespace(SECOND_NAMESPACE);

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -378,7 +378,7 @@ public static String changeDeploymentNamespaceUpgrade(File deploymentFile, Strin
         YAMLMapper mapper = new YAMLMapper();
         try {
             JsonNode node = mapper.readTree(deploymentFile);
-            // Change the docker org of the images in the 050-deployment.yaml
+            // Change the docker org of the images in the 060-deployment.yaml
             ObjectNode containerNode = (ObjectNode) node.at("/spec/template/spec/containers").get(0);
             for (JsonNode envVar : containerNode.get("env")) {
                 String varName = envVar.get("name").textValue();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -156,7 +156,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                 .compose(i -> deploymentOperations.scaleUp(namespace, mirrorMaker2Cluster.getName(), mirrorMaker2Cluster.getReplicas()))
                 .compose(i -> deploymentOperations.waitForObserved(namespace, mirrorMaker2Cluster.getName(), 1_000, operationTimeoutMs))
                 .compose(i -> mirrorMaker2HasZeroReplicas ? Future.succeededFuture() : deploymentOperations.readiness(namespace, mirrorMaker2Cluster.getName(), 1_000, operationTimeoutMs))
-                .compose(i -> reconcileConnectors(reconciliation, kafkaMirrorMaker2, mirrorMaker2Cluster, kafkaMirrorMaker2Status))
+                .compose(i -> mirrorMaker2HasZeroReplicas ? Future.succeededFuture() : reconcileConnectors(reconciliation, kafkaMirrorMaker2, mirrorMaker2Cluster, kafkaMirrorMaker2Status))
                 .map((Void) null)
                 .onComplete(reconciliationResult -> {
                     StatusUtils.setStatusConditionAndObservedGeneration(kafkaMirrorMaker2, kafkaMirrorMaker2Status, reconciliationResult);

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlConfigurationST.java
Patch:
@@ -214,6 +214,7 @@ void testConfigurationReflection() throws IOException {
         assertThat(containerConfiguration.getProperty("default.goals"), is(fileConfiguration.getProperty("default.goals")));
         assertThat(containerConfiguration.getProperty("partition.metrics.window.ms"), is(fileConfiguration.getProperty("partition.metrics.window.ms")));
         assertThat(containerConfiguration.getProperty("goals"), is(fileConfiguration.getProperty("goals")));
+        assertThat(containerConfiguration.getProperty("cruise.control.metrics.reporter.kubernetes.mode"), is(fileConfiguration.getProperty("cruise.control.metrics.reporter.kubernetes.mode")));
     }
 
     @Order(5)

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridge.java
Patch:
@@ -102,7 +102,7 @@ public class KafkaBridge extends CustomResource implements UnknownPropertyPreser
     public static final List<String> RESOURCE_SHORTNAMES = singletonList(SHORT_NAME);
     public static final String SPEC_REPLICAS_PATH = ".spec.replicas";
     public static final String STATUS_REPLICAS_PATH = ".status.replicas";
-    public static final String LABEL_SELECTOR_PATH = ".status.selector";
+    public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
 
     private String apiVersion;
     private ObjectMeta metadata;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnect.java
Patch:
@@ -100,7 +100,7 @@ public class KafkaConnect extends CustomResource implements UnknownPropertyPrese
     public static final List<String> RESOURCE_SHORTNAMES = singletonList(SHORT_NAME);
     public static final String SPEC_REPLICAS_PATH = ".spec.replicas";
     public static final String STATUS_REPLICAS_PATH = ".status.replicas";
-    public static final String LABEL_SELECTOR_PATH = ".status.selector";
+    public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
 
     private String apiVersion;
     private KafkaConnectSpec spec;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectS2I.java
Patch:
@@ -103,7 +103,7 @@ public class KafkaConnectS2I extends CustomResource implements UnknownPropertyPr
     public static final List<String> RESOURCE_SHORTNAMES = singletonList(SHORT_NAME);
     public static final String SPEC_REPLICAS_PATH = ".spec.replicas";
     public static final String STATUS_REPLICAS_PATH = ".status.replicas";
-    public static final String LABEL_SELECTOR_PATH = ".status.selector";
+    public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
 
     private String apiVersion;
     private ObjectMeta metadata;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker.java
Patch:
@@ -115,7 +115,7 @@ public class KafkaMirrorMaker extends CustomResource implements UnknownPropertyP
     public static final List<String> RESOURCE_SHORTNAMES = singletonList(SHORT_NAME);
     public static final String SPEC_REPLICAS_PATH = ".spec.replicas";
     public static final String STATUS_REPLICAS_PATH = ".status.replicas";
-    public static final String LABEL_SELECTOR_PATH = ".status.selector";
+    public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
 
     private String apiVersion;
     private ObjectMeta metadata;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2.java
Patch:
@@ -94,7 +94,7 @@ public class KafkaMirrorMaker2 extends CustomResource implements UnknownProperty
     public static final List<String> RESOURCE_SHORTNAMES = singletonList(SHORT_NAME);
     public static final String SPEC_REPLICAS_PATH = ".spec.replicas";
     public static final String STATUS_REPLICAS_PATH = ".status.replicas";
-    public static final String LABEL_SELECTOR_PATH = ".status.selector";
+    public static final String LABEL_SELECTOR_PATH = ".status.labelSelector";
 
     private String apiVersion;
     private KafkaMirrorMaker2Spec spec;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -5,7 +5,6 @@
 package io.strimzi.operator.cluster.operator.assembly;
 
 import io.fabric8.kubernetes.api.model.ConfigMap;
-import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
 import io.fabric8.kubernetes.api.model.ServiceAccount;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -109,7 +108,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge
                 }
 
                 kafkaBridgeStatus.setReplicas(bridge.getReplicas());
-                kafkaBridgeStatus.setPodSelector(new LabelSelectorBuilder().withMatchLabels(bridge.getSelectorLabels().toMap()).build());
+                kafkaBridgeStatus.setLabelSelector(bridge.getSelectorLabels().toSelectorString());
 
                 updateStatus(assemblyResource, reconciliation, kafkaBridgeStatus).onComplete(statusResult -> {
                     // If both features succeeded, createOrUpdate succeeded as well

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -5,7 +5,6 @@
 package io.strimzi.operator.cluster.operator.assembly;
 
 import io.fabric8.kubernetes.api.model.ConfigMap;
-import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
 import io.fabric8.kubernetes.api.model.ServiceAccount;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -156,7 +155,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
                     }
 
                     kafkaConnectStatus.setReplicas(connect.getReplicas());
-                    kafkaConnectStatus.setPodSelector(new LabelSelectorBuilder().withMatchLabels(connect.getSelectorLabels().toMap()).build());
+                    kafkaConnectStatus.setLabelSelector(connect.getSelectorLabels().toSelectorString());
 
                     this.maybeUpdateStatusCommon(resourceOperator, kafkaConnect, reconciliation, kafkaConnectStatus,
                         (connect1, status) -> new KafkaConnectBuilder(connect1).withStatus(status).build()).onComplete(statusResult -> {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -5,7 +5,6 @@
 package io.strimzi.operator.cluster.operator.assembly;
 
 import io.fabric8.kubernetes.api.model.ConfigMap;
-import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
 import io.fabric8.kubernetes.api.model.ServiceAccount;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -166,7 +165,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
                     }
 
                     kafkaConnectS2Istatus.setReplicas(connect.getReplicas());
-                    kafkaConnectS2Istatus.setPodSelector(new LabelSelectorBuilder().withMatchLabels(connect.getSelectorLabels().toMap()).build());
+                    kafkaConnectS2Istatus.setLabelSelector(connect.getSelectorLabels().toSelectorString());
 
                     updateStatus(kafkaConnectS2I, reconciliation, kafkaConnectS2Istatus).onComplete(statusResult -> {
                         // If both features succeeded, createOrUpdate succeeded as well

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -13,7 +13,6 @@
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
-import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.operator.resource.NetworkPolicyOperator;
 
@@ -162,7 +161,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                     kafkaMirrorMaker2Status.setUrl(KafkaMirrorMaker2Resources.url(mirrorMaker2Cluster.getCluster(), namespace, KafkaMirrorMaker2Cluster.REST_API_PORT));
 
                     kafkaMirrorMaker2Status.setReplicas(mirrorMaker2Cluster.getReplicas());
-                    kafkaMirrorMaker2Status.setPodSelector(new LabelSelectorBuilder().withMatchLabels(mirrorMaker2Cluster.getSelectorLabels().toMap()).build());
+                    kafkaMirrorMaker2Status.setLabelSelector(mirrorMaker2Cluster.getSelectorLabels().toSelectorString());
 
                     this.maybeUpdateStatusCommon(resourceOperator, kafkaMirrorMaker2, reconciliation, kafkaMirrorMaker2Status,
                         (mirrormaker2, status) -> new KafkaMirrorMaker2Builder(mirrormaker2).withStatus(status).build()).onComplete(statusResult -> {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -5,7 +5,6 @@
 package io.strimzi.operator.cluster.operator.assembly;
 
 import io.fabric8.kubernetes.api.model.ConfigMap;
-import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
 import io.fabric8.kubernetes.api.model.ServiceAccount;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -110,7 +109,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                         StatusUtils.setStatusConditionAndObservedGeneration(assemblyResource, kafkaMirrorMakerStatus, reconciliationResult);
 
                         kafkaMirrorMakerStatus.setReplicas(mirror.getReplicas());
-                        kafkaMirrorMakerStatus.setPodSelector(new LabelSelectorBuilder().withMatchLabels(mirror.getSelectorLabels().toMap()).build());
+                        kafkaMirrorMakerStatus.setLabelSelector(mirror.getSelectorLabels().toSelectorString());
 
                         updateStatus(assemblyResource, reconciliation, kafkaMirrorMakerStatus).onComplete(statusResult -> {
                             // If both features succeeded, createOrUpdate succeeded as well

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -178,7 +178,7 @@ public void testCreateOrUpdateCreatesCluster(VertxTestContext context) {
                 List<KafkaBridge> capturedStatuses = bridgeCaptor.getAllValues();
                 assertThat(capturedStatuses.get(0).getStatus().getUrl(), is("http://foo-bridge-service.test.svc:8080"));
                 assertThat(capturedStatuses.get(0).getStatus().getReplicas(), is(bridge.getReplicas()));
-                assertThat(capturedStatuses.get(0).getStatus().getPodSelector().getMatchLabels(), is(bridge.getSelectorLabels().toMap()));
+                assertThat(capturedStatuses.get(0).getStatus().getLabelSelector(), is(bridge.getSelectorLabels().toSelectorString()));
                 assertThat(capturedStatuses.get(0).getStatus().getConditions().get(0).getStatus(), is("True"));
                 assertThat(capturedStatuses.get(0).getStatus().getConditions().get(0).getType(), is("Ready"));
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -192,7 +192,7 @@ public void createKafkaConnectCluster(VertxTestContext context, KafkaConnect kc,
 
                 assertThat(connectStatus.getUrl(), is("http://foo-connect-api.test.svc:8083"));
                 assertThat(connectStatus.getReplicas(), is(connect.getReplicas()));
-                assertThat(connectStatus.getPodSelector().getMatchLabels(), is(connect.getSelectorLabels().toMap()));
+                assertThat(connectStatus.getLabelSelector(), is(connect.getSelectorLabels().toSelectorString()));
                 assertThat(connectStatus.getConditions().get(0).getStatus(), is("True"));
                 assertThat(connectStatus.getConditions().get(0).getType(), is("Ready"));
 
@@ -854,7 +854,7 @@ public void assertCreateClusterWitDuplicateOlderConnect(VertxTestContext context
                 KafkaConnectStatus connectStatus = capturedConnects.get(0).getStatus();
                 assertThat(connectStatus.getUrl(), is("http://foo-connect-api.test.svc:8083"));
                 assertThat(connectStatus.getReplicas(), is(connect.getReplicas()));
-                assertThat(connectStatus.getPodSelector().getMatchLabels(), is(connect.getSelectorLabels().toMap()));
+                assertThat(connectStatus.getLabelSelector(), is(connect.getSelectorLabels().toSelectorString()));
                 assertThat(connectStatus.getConditions().get(0).getStatus(), is("True"));
                 assertThat(connectStatus.getConditions().get(0).getType(), is("Ready"));
                 if (connectorOperator) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorTest.java
Patch:
@@ -168,7 +168,7 @@ public void testCreateCluster(VertxTestContext context) {
                 List<KafkaMirrorMaker2> capturedMirrorMaker2s = mirrorMaker2Captor.getAllValues();
                 assertThat(capturedMirrorMaker2s.get(0).getStatus().getUrl(), is("http://foo-mirrormaker2-api.test.svc:8083"));
                 assertThat(capturedMirrorMaker2s.get(0).getStatus().getReplicas(), is(mirrorMaker2.getReplicas()));
-                assertThat(capturedMirrorMaker2s.get(0).getStatus().getPodSelector().getMatchLabels(), is(mirrorMaker2.getSelectorLabels().toMap()));
+                assertThat(capturedMirrorMaker2s.get(0).getStatus().getLabelSelector(), is(mirrorMaker2.getSelectorLabels().toSelectorString()));
                 assertThat(capturedMirrorMaker2s.get(0).getStatus().getConditions().get(0).getStatus(), is("True"));
                 assertThat(capturedMirrorMaker2s.get(0).getStatus().getConditions().get(0).getType(), is("Ready"));
                 async.flag();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -174,7 +174,7 @@ public void testCreateCluster(VertxTestContext context) {
                 assertThat(capturedMM, hasSize(1));
                 KafkaMirrorMaker mm = capturedMM.get(0);
                 assertThat(mm.getStatus().getReplicas(), is(mirror.getReplicas()));
-                assertThat(mm.getStatus().getPodSelector().getMatchLabels(), is(mirror.getSelectorLabels().toMap()));
+                assertThat(mm.getStatus().getLabelSelector(), is(mirror.getSelectorLabels().toSelectorString()));
                 assertThat(mm.getStatus().getConditions().get(0).getType(), is("Ready"));
                 assertThat(mm.getStatus().getConditions().get(0).getStatus(), is("True"));
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/JmxTransTest.java
Patch:
@@ -77,7 +77,7 @@ public class JmxTransTest {
                     .build())
             .build();
 
-    private final Kafka kafkaAssembly = new KafkaBuilder(ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCm, configuration, kafkaLog, zooLog))
+    private final Kafka kafkaAssembly = new KafkaBuilder(ResourceUtils.createKafka(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCm, configuration, kafkaLog, zooLog))
             .editSpec()
                 .withJmxTrans(jmxTransSpec)
                 .editKafka().withJmxOptions(new KafkaJmxOptionsBuilder()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -68,7 +68,7 @@ public class KafkaBridgeClusterTest {
     private final String defaultProducerConfiguration = "";
     private final String defaultConsumerConfiguration = "";
 
-    private final KafkaBridge resource = new KafkaBridgeBuilder(ResourceUtils.createEmptyKafkaBridgeCluster(namespace, cluster))
+    private final KafkaBridge resource = new KafkaBridgeBuilder(ResourceUtils.createEmptyKafkaBridge(namespace, cluster))
             .withNewSpec()
                 .withEnableMetrics(true)
                 .withImage(image)
@@ -120,7 +120,7 @@ protected List<EnvVar> getExpectedEnvVars() {
 
     @Test
     public void testDefaultValues() {
-        KafkaBridgeCluster kbc = KafkaBridgeCluster.fromCrd(ResourceUtils.createEmptyKafkaBridgeCluster(namespace, cluster), VERSIONS);
+        KafkaBridgeCluster kbc = KafkaBridgeCluster.fromCrd(ResourceUtils.createEmptyKafkaBridge(namespace, cluster), VERSIONS);
 
         assertThat(kbc.image, is("strimzi/kafka-bridge:latest"));
         assertThat(kbc.replicas, is(KafkaBridgeCluster.DEFAULT_REPLICAS));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -94,7 +94,7 @@ public class KafkaConnectClusterTest {
     private final OrderedProperties expectedConfiguration = new OrderedProperties()
             .addMapPairs(defaultConfiguration.asMap())
             .addPair("foo", "bar");
-    private final KafkaConnect resource = new KafkaConnectBuilder(ResourceUtils.createEmptyKafkaConnectCluster(namespace, cluster))
+    private final KafkaConnect resource = new KafkaConnectBuilder(ResourceUtils.createEmptyKafkaConnect(namespace, cluster))
             .withNewSpec()
             .withMetrics((Map<String, Object>) TestUtils.fromJson(metricsCmJson, Map.class))
             .withConfig((Map<String, Object>) TestUtils.fromJson(configurationJson, Map.class))
@@ -149,7 +149,7 @@ protected List<EnvVar> getExpectedEnvVars() {
 
     @Test
     public void testDefaultValues() {
-        KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(ResourceUtils.createEmptyKafkaConnectCluster(namespace, cluster), VERSIONS);
+        KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(ResourceUtils.createEmptyKafkaConnect(namespace, cluster), VERSIONS);
 
         assertThat(kc.image, is(KafkaVersionTestUtils.DEFAULT_KAFKA_CONNECT_IMAGE));
         assertThat(kc.replicas, is(KafkaConnectCluster.DEFAULT_REPLICAS));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -100,7 +100,7 @@ public class KafkaConnectS2IClusterTest {
             .build();
 
 
-    private final KafkaConnectS2I resource = ResourceUtils.createKafkaConnectS2ICluster(namespace, cluster, replicas, image,
+    private final KafkaConnectS2I resource = ResourceUtils.createKafkaConnectS2I(namespace, cluster, replicas, image,
             healthDelay, healthTimeout, metricsCmJson, configurationJson, insecureSourceRepo, bootstrapServers, buildResourceRequirements);
 
     private final KafkaConnectS2ICluster kc = KafkaConnectS2ICluster.fromCrd(resource, VERSIONS);
@@ -146,7 +146,7 @@ protected List<EnvVar> getExpectedEnvVars() {
 
     @Test
     public void testDefaultValues() {
-        KafkaConnectS2ICluster kc = KafkaConnectS2ICluster.fromCrd(ResourceUtils.createEmptyKafkaConnectS2ICluster(namespace, cluster), VERSIONS);
+        KafkaConnectS2ICluster kc = KafkaConnectS2ICluster.fromCrd(ResourceUtils.createEmptyKafkaConnectS2I(namespace, cluster), VERSIONS);
 
         assertThat(kc.image, is(KafkaConnectS2IResources.deploymentName(cluster) + ":latest"));
         assertThat(kc.replicas, is(KafkaConnectS2ICluster.DEFAULT_REPLICAS));
@@ -307,7 +307,7 @@ public void testGenerateSourceImageStream() {
 
     @Test
     public void testInsecureSourceRepo() {
-        KafkaConnectS2ICluster kc = KafkaConnectS2ICluster.fromCrd(ResourceUtils.createKafkaConnectS2ICluster(namespace, cluster, replicas, image,
+        KafkaConnectS2ICluster kc = KafkaConnectS2ICluster.fromCrd(ResourceUtils.createKafkaConnectS2I(namespace, cluster, replicas, image,
                 healthDelay, healthTimeout,  metricsCmJson, configurationJson, true, bootstrapServers, buildResourceRequirements), VERSIONS);
 
         assertThat(kc.isInsecureSourceRepository(), is(true));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -99,7 +99,7 @@ public class KafkaMirrorMaker2ClusterTest {
             .withBootstrapServers(bootstrapServers)
             .withConfig((Map<String, Object>) TestUtils.fromJson(configurationJson, Map.class))
             .build();
-    private final KafkaMirrorMaker2 resource = new KafkaMirrorMaker2Builder(ResourceUtils.createEmptyKafkaMirrorMaker2Cluster(namespace, cluster))
+    private final KafkaMirrorMaker2 resource = new KafkaMirrorMaker2Builder(ResourceUtils.createEmptyKafkaMirrorMaker2(namespace, cluster))
             .withNewSpec()
             .withMetrics((Map<String, Object>) TestUtils.fromJson(metricsCmJson, Map.class))
             .withImage(image)
@@ -158,7 +158,7 @@ private Container getContainer(Deployment dep) {
 
     @Test
     public void testDefaultValues() {
-        KafkaMirrorMaker2Cluster kmm2 = KafkaMirrorMaker2Cluster.fromCrd(ResourceUtils.createEmptyKafkaMirrorMaker2Cluster(namespace, cluster), VERSIONS);
+        KafkaMirrorMaker2Cluster kmm2 = KafkaMirrorMaker2Cluster.fromCrd(ResourceUtils.createEmptyKafkaMirrorMaker2(namespace, cluster), VERSIONS);
 
         assertThat(kmm2.image, is(KafkaVersionTestUtils.DEFAULT_KAFKA_CONNECT_IMAGE));
         assertThat(kmm2.replicas, is(KafkaMirrorMaker2Cluster.DEFAULT_REPLICAS));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -88,7 +88,7 @@ public class KafkaMirrorMakerClusterTest {
             .withOffsetCommitInterval(offsetCommitInterval)
             .withConfig((Map<String, Object>) TestUtils.fromJson(consumerConfigurationJson, Map.class))
             .build();
-    private final KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(ResourceUtils.createEmptyKafkaMirrorMakerCluster(namespace, cluster))
+    private final KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(ResourceUtils.createEmptyKafkaMirrorMaker(namespace, cluster))
             .withNewSpec()
             .withImage(image)
             .withReplicas(replicas)
@@ -164,7 +164,7 @@ public void testDefaultValues() {
                 .withNumStreams(numStreams)
                 .build();
 
-        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(ResourceUtils.createEmptyKafkaMirrorMakerCluster(namespace, cluster))
+        KafkaMirrorMaker resource = new KafkaMirrorMakerBuilder(ResourceUtils.createEmptyKafkaMirrorMaker(namespace, cluster))
                 .withNewSpec()
                     .withReplicas(replicas)
                     .withProducer(producer)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -99,7 +99,7 @@ public class KafkaRebalanceAssemblyOperatorTest {
             .build();
 
     private final Kafka kafka =
-            new KafkaBuilder(ResourceUtils.createKafkaCluster(CLUSTER_NAMESPACE, CLUSTER_NAME, replicas, image, healthDelay, healthTimeout))
+            new KafkaBuilder(ResourceUtils.createKafka(CLUSTER_NAMESPACE, CLUSTER_NAME, replicas, image, healthDelay, healthTimeout))
                     .editSpec()
                         .editKafka()
                             .withVersion(version)
@@ -763,7 +763,7 @@ public void testNoCruiseControl(VertxTestContext context) {
 
         // build a Kafka cluster without the cruiseControl definition
         Kafka kafka =
-                new KafkaBuilder(ResourceUtils.createKafkaCluster(CLUSTER_NAMESPACE, CLUSTER_NAME, replicas, image, healthDelay, healthTimeout))
+                new KafkaBuilder(ResourceUtils.createKafka(CLUSTER_NAMESPACE, CLUSTER_NAME, replicas, image, healthDelay, healthTimeout))
                         .editSpec()
                             .editKafka()
                                 .withVersion(version)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -45,13 +45,13 @@ public void before() {
     }
 
     private Kafka getResource() {
-        String clusterCmName = "foo";
-        String clusterCmNamespace = "test";
+        String kafkaName = "foo";
+        String kafkaNamespace = "test";
         int replicas = 3;
         String image = "bar";
         int healthDelay = 120;
         int healthTimeout = 30;
-        return new KafkaBuilder(ResourceUtils.createKafkaCluster(clusterCmNamespace, clusterCmName,
+        return new KafkaBuilder(ResourceUtils.createKafka(kafkaNamespace, kafkaName,
                 replicas, image, healthDelay, healthTimeout))
                 .editSpec()
                     .editKafka()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/CruiseControlTest.java
Patch:
@@ -149,6 +149,7 @@ private Map<String, String> expectedLabels()    {
 
     private List<EnvVar> getExpectedEnvVars() {
         List<EnvVar> expected = new ArrayList<>();
+        expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_CRUISE_CONTROL_METRICS_ENABLED).withValue(Boolean.toString(CruiseControl.DEFAULT_CRUISE_CONTROL_METRICS_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_STRIMZI_KAFKA_BOOTSTRAP_SERVERS).withValue(CruiseControl.defaultBootstrapServers(cluster)).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(CruiseControl.ENV_VAR_MIN_INSYNC_REPLICAS).withValue(minInsyncReplicas).build());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -50,7 +50,6 @@ public class KafkaMirrorMakerCluster extends AbstractModel {
     protected static final String OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT_PRODUCER = "/opt/kafka/producer-oauth-certs/";
 
     // Configuration defaults
-    protected static final int DEFAULT_REPLICAS = 3;
     private static final int DEFAULT_HEALTHCHECK_DELAY = 60;
     private static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;
     private static final int DEFAULT_HEALTHCHECK_PERIOD = 10;
@@ -117,7 +116,6 @@ protected KafkaMirrorMakerCluster(HasMetadata resource) {
         this.name = KafkaMirrorMakerResources.deploymentName(cluster);
         this.serviceName = KafkaMirrorMakerResources.serviceName(cluster);
         this.ancillaryConfigMapName = KafkaMirrorMakerResources.metricsAndLogConfigMapName(cluster);
-        this.replicas = DEFAULT_REPLICAS;
         this.readinessPath = "/";
         this.readinessProbeOptions = READINESS_PROBE_OPTIONS;
         this.livenessPath = "/";
@@ -133,8 +131,8 @@ public static KafkaMirrorMakerCluster fromCrd(KafkaMirrorMaker kafkaMirrorMaker,
         KafkaMirrorMakerCluster kafkaMirrorMakerCluster = new KafkaMirrorMakerCluster(kafkaMirrorMaker);
 
         KafkaMirrorMakerSpec spec = kafkaMirrorMaker.getSpec();
-        kafkaMirrorMakerCluster.setReplicas(spec != null && spec.getReplicas() > 0 ? spec.getReplicas() : DEFAULT_REPLICAS);
         if (spec != null) {
+            kafkaMirrorMakerCluster.setReplicas(spec.getReplicas());
             kafkaMirrorMakerCluster.setResources(spec.getResources());
 
             if (spec.getReadinessProbe() != null) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -95,6 +95,8 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
         Map<String, String> annotations = new HashMap<>(1);
         annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(mirror.ANCILLARY_CM_KEY_LOG_CONFIG));
 
+        boolean mirrorHasZeroReplicas = mirror.getReplicas() == 0;
+
         log.debug("{}: Updating Kafka Mirror Maker cluster", reconciliation);
         mirrorMakerServiceAccount(namespace, mirror)
                 .compose(i -> deploymentOperations.scaleDown(namespace, mirror.getName(), mirror.getReplicas()))
@@ -103,7 +105,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                 .compose(i -> deploymentOperations.reconcile(namespace, mirror.getName(), mirror.generateDeployment(annotations, pfa.isOpenshift(), imagePullPolicy, imagePullSecrets)))
                 .compose(i -> deploymentOperations.scaleUp(namespace, mirror.getName(), mirror.getReplicas()))
                 .compose(i -> deploymentOperations.waitForObserved(namespace, mirror.getName(), 1_000, operationTimeoutMs))
-                .compose(i -> deploymentOperations.readiness(namespace, mirror.getName(), 1_000, operationTimeoutMs))
+                .compose(i -> mirrorHasZeroReplicas ? Future.succeededFuture() : deploymentOperations.readiness(namespace, mirror.getName(), 1_000, operationTimeoutMs))
                 .onComplete(reconciliationResult -> {
                         StatusUtils.setStatusConditionAndObservedGeneration(assemblyResource, kafkaMirrorMakerStatus, reconciliationResult);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -91,6 +91,7 @@ public KafkaBrokerConfigurationBuilder withCruiseControl(String clusterName, Cru
             writer.println("cruise.control.metrics.reporter.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12");
             writer.println("cruise.control.metrics.reporter.ssl.truststore.password=${CERTS_STORE_PASSWORD}");
             writer.println("cruise.control.metrics.topic.auto.create=true");
+            writer.println("cruise.control.metrics.reporter.kubernetes.mode=true");
             if (numPartitions != null) {
                 writer.println("cruise.control.metrics.topic.num.partitions=" + numPartitions);
             }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -83,6 +83,7 @@ public void testCruiseControl()  {
                 "cruise.control.metrics.reporter.ssl.truststore.location=/tmp/kafka/cluster.truststore.p12\n" +
                 "cruise.control.metrics.reporter.ssl.truststore.password=${CERTS_STORE_PASSWORD}\n" +
                 "cruise.control.metrics.topic.auto.create=true\n" +
+                "cruise.control.metrics.reporter.kubernetes.mode=true\n" +
                 "cruise.control.metrics.topic.num.partitions=1\n" +
                 "cruise.control.metrics.topic.replication.factor=1"));
     }

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlApiST.java
Patch:
@@ -76,8 +76,7 @@ void testRebalance() {
         assertThat(response, containsString("DiskCapacityGoal"));
         assertThat(response, containsString("NetworkInboundCapacityGoal"));
         assertThat(response, containsString("NetworkOutboundCapacityGoal"));
-        // TODO: This Goal is currently not working properly on Kubernetes. It will be added in once this issue is fixed: https://github.com/linkedin/cruise-control/issues/1242
-        //assertThat(response, containsString("CpuCapacityGoal"));
+        assertThat(response, containsString("CpuCapacityGoal"));
         assertThat(response, containsString("ReplicaDistributionGoal"));
         assertThat(response, containsString("DiskUsageDistributionGoal"));
         assertThat(response, containsString("NetworkInboundUsageDistributionGoal"));

File: systemtest/src/test/java/io/strimzi/systemtest/connect/ConnectST.java
Patch:
@@ -24,6 +24,7 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
+import io.strimzi.systemtest.annotations.OpenShiftOnly;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
@@ -618,6 +619,7 @@ void testCustomAndUpdatedValues() {
 
     @Test
     @Tag(CONNECTOR_OPERATOR)
+    @OpenShiftOnly
     void testKafkaConnectorWithConnectAndConnectS2IWithSameName() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String connectClusterName = "connect-cluster";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -33,6 +33,7 @@
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlRestException;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.MockCruiseControl;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
@@ -909,7 +910,7 @@ private KafkaRebalance annotate(KubernetesClient kubernetesClient, String namesp
 
         KafkaRebalance patchedKr = new KafkaRebalanceBuilder(kafkaRebalance)
                 .editMetadata()
-                    .addToAnnotations(KafkaRebalanceAssemblyOperator.ANNO_STRIMZI_IO_REBALANCE, annotationValue.toString())
+                    .addToAnnotations(Annotations.ANNO_STRIMZI_IO_REBALANCE, annotationValue.toString())
                 .endMetadata()
                 .build();
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceStateMachineTest.java
Patch:
@@ -24,6 +24,7 @@
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlApiImpl;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.MockCruiseControl;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.RebalanceOptions;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
@@ -126,7 +127,7 @@ private KafkaRebalance createKafkaRebalance(KafkaRebalanceState currentState,
                             .withName(RESOURCE_NAME)
                             .withNamespace(CLUSTER_NAMESPACE)
                             .withLabels(Collections.singletonMap(Labels.STRIMZI_CLUSTER_LABEL, CLUSTER_NAME))
-                            .withAnnotations(Collections.singletonMap(KafkaRebalanceAssemblyOperator.ANNO_STRIMZI_IO_REBALANCE, userAnnotation == null ? "none" : userAnnotation))
+                            .withAnnotations(Collections.singletonMap(Annotations.ANNO_STRIMZI_IO_REBALANCE, userAnnotation == null ? "none" : userAnnotation))
                         .endMetadata()
                         .withSpec(rebalanceSpec);
 

File: operator-common/src/main/java/io/strimzi/operator/common/Annotations.java
Patch:
@@ -20,6 +20,9 @@ public class Annotations {
     public static final String STRIMZI_LOGGING_ANNOTATION = STRIMZI_DOMAIN + "logging";
     public static final String STRIMZI_IO_USE_CONNECTOR_RESOURCES = STRIMZI_DOMAIN + "use-connector-resources";
     public static final String ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE = STRIMZI_DOMAIN + "manual-rolling-update";
+    // this annotation with related possible values (approve, stop, refresh) is set by the user for interacting
+    // with the rebalance operator in order to start, stop or refresh rebalacing proposals and operations
+    public static final String ANNO_STRIMZI_IO_REBALANCE = STRIMZI_DOMAIN + "rebalance";
     @Deprecated
     public static final String ANNO_OP_STRIMZI_IO_MANUAL_ROLLING_UPDATE = "operator." + Annotations.STRIMZI_DOMAIN + "manual-rolling-update";
 

File: config-model-generator/src/main/java/io/strimzi/build/kafka/metadata/KafkaConfigModelGenerator.java
Patch:
@@ -84,7 +84,7 @@ private static Map<String, ConfigModel> configs() throws NoSuchMethodException,
             } else if (key.validator instanceof ConfigDef.ValidList) {
                 descriptor.setItems(validList(key));
             } else if (key.validator instanceof ApiVersionValidator$) {
-                Iterator<ApiVersion> iterator = ApiVersion$.MODULE$.allVersions().iterator();
+                Iterator<ApiVersion> iterator = ((scala.collection.GenIterableLike<ApiVersion, ?>) ApiVersion$.MODULE$.allVersions()).iterator();
                 LinkedHashSet<String> versions = new LinkedHashSet<>();
                 while (iterator.hasNext()) {
                     ApiVersion next = iterator.next();

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -160,7 +160,7 @@ void testLoadBalancerIpOverride() {
     @Tag(REGRESSION)
     void testDeployUnsupportedKafka() {
         String nonExistingVersion = "6.6.6";
-        String nonExistingVersionMessage = "Unsupported Kafka.spec.kafka.version: " + nonExistingVersion + ". Supported versions are.*";
+        String nonExistingVersionMessage = "Version " + nonExistingVersion + " is not supported. Supported versions are.*";
 
         KafkaResource.kafkaWithoutWait(KafkaResource.defaultKafka(CLUSTER_NAME, 1, 1)
             .editSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AbstractNamespaceST.java
Patch:
@@ -74,8 +74,8 @@ void deployNewTopic(String topicNamespace, String kafkaClusterNamespace, String
         LOGGER.info("Creating topic {} in namespace {}", topic, topicNamespace);
         cluster.setNamespace(topicNamespace);
         cmdKubeClient().create(new File(TOPIC_EXAMPLES_DIR));
-        cluster.setNamespace(kafkaClusterNamespace);
         KafkaTopicUtils.waitForKafkaTopicReady(topic);
+        cluster.setNamespace(kafkaClusterNamespace);
     }
 
     void deleteNewTopic(String namespace, String topic) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -39,14 +39,15 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 
 public class KubernetesResource {
     private static final Logger LOGGER = LogManager.getLogger(KubernetesResource.class);
 
     public static DoneableDeployment deployNewDeployment(Deployment deployment) {
         return new DoneableDeployment(deployment, co -> {
-            TestUtils.waitFor("Deployment creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, Constants.TIMEOUT_FOR_CR_CREATION,
+            TestUtils.waitFor("Deployment creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, CR_CREATION_TIMEOUT,
                 () -> {
                     try {
                         ResourceManager.kubeClient().createOrReplaceDeployment(co);
@@ -66,7 +67,7 @@ public static DoneableDeployment deployNewDeployment(Deployment deployment) {
 
     public static DoneableJob deployNewJob(Job job) {
         return new DoneableJob(job, kubernetesJob -> {
-            TestUtils.waitFor("Job creation " + job.getMetadata().getName(), Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, Constants.TIMEOUT_FOR_CR_CREATION,
+            TestUtils.waitFor("Job creation " + job.getMetadata().getName(), Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, CR_CREATION_TIMEOUT,
                 () -> {
                     try {
                         ResourceManager.kubeClient().getClient().batch().jobs().inNamespace(kubeClient().getNamespace()).createOrReplace(kubernetesJob);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -18,6 +18,8 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
+
 public class KafkaBridgeResource {
 
     public static final String PATH_TO_KAFKA_BRIDGE_CONFIG = "../examples/bridge/kafka-bridge.yaml";
@@ -92,7 +94,7 @@ private static KafkaBridgeBuilder defaultKafkaBridge(KafkaBridge kafkaBridge, St
 
     private static DoneableKafkaBridge deployKafkaBridge(KafkaBridge kafkaBridge) {
         return new DoneableKafkaBridge(kafkaBridge, kB -> {
-            TestUtils.waitFor("KafkaBridge creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, Constants.TIMEOUT_FOR_CR_CREATION,
+            TestUtils.waitFor("KafkaBridge creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, CR_CREATION_TIMEOUT,
                 () -> {
                     try {
                         kafkaBridgeClient().inNamespace(ResourceManager.kubeClient().getNamespace()).createOrReplace(kB);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -23,6 +23,8 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
+
 public class KafkaConnectResource {
     public static final String PATH_TO_KAFKA_CONNECT_CONFIG = "../examples/connect/kafka-connect.yaml";
     public static final String PATH_TO_KAFKA_CONNECT_METRICS_CONFIG = "../examples/metrics/kafka-connect-metrics.yaml";
@@ -84,7 +86,7 @@ private static DoneableKafkaConnect deployKafkaConnect(KafkaConnect kafkaConnect
             KubernetesResource.allowNetworkPolicySettingsForResource(kafkaConnect, KafkaConnectResources.deploymentName(kafkaConnect.getMetadata().getName()));
         }
         return new DoneableKafkaConnect(kafkaConnect, kC -> {
-            TestUtils.waitFor("KafkaConnect creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, Constants.TIMEOUT_FOR_CR_CREATION,
+            TestUtils.waitFor("KafkaConnect creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, CR_CREATION_TIMEOUT,
                 () -> {
                     try {
                         kafkaConnectClient().inNamespace(ResourceManager.kubeClient().getNamespace()).createOrReplace(kC);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -23,6 +23,8 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
+
 public class KafkaConnectS2IResource {
     public static final String PATH_TO_KAFKA_CONNECT_S2I_CONFIG = "../examples/connect/kafka-connect-s2i.yaml";
 
@@ -68,7 +70,7 @@ private static DoneableKafkaConnectS2I deployKafkaConnectS2I(KafkaConnectS2I kaf
             KubernetesResource.allowNetworkPolicySettingsForResource(kafkaConnectS2I, KafkaConnectS2IResources.deploymentName(kafkaConnectS2I.getMetadata().getName()));
         }
         return new DoneableKafkaConnectS2I(kafkaConnectS2I, kC -> {
-            TestUtils.waitFor("KafkaConnect creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, Constants.TIMEOUT_FOR_CR_CREATION,
+            TestUtils.waitFor("KafkaConnect creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, CR_CREATION_TIMEOUT,
                 () -> {
                     try {
                         kafkaConnectS2IClient().inNamespace(ResourceManager.kubeClient().getNamespace()).createOrReplace(kC);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -19,6 +19,8 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
+
 public class KafkaConnectorResource {
     public static final String PATH_TO_KAFKA_CONNECTOR_CONFIG = "../examples/connect/source-connector.yaml";
 
@@ -67,7 +69,7 @@ public static void deleteKafkaConnectorWithoutWait(String connectorName) {
 
     private static DoneableKafkaConnector deployKafkaConnector(KafkaConnector kafkaConnector) {
         return new DoneableKafkaConnector(kafkaConnector, kC -> {
-            TestUtils.waitFor("KafkaConnector creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, Constants.TIMEOUT_FOR_CR_CREATION,
+            TestUtils.waitFor("KafkaConnector creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, CR_CREATION_TIMEOUT,
                 () -> {
                     try {
                         kafkaConnectorClient().inNamespace(ResourceManager.kubeClient().getNamespace()).createOrReplace(kC);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -23,6 +23,8 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
+
 public class KafkaMirrorMaker2Resource {
     public static final String PATH_TO_KAFKA_MIRROR_MAKER_2_CONFIG = "../examples/mirror-maker/kafka-mirror-maker-2.yaml";
     public static final String PATH_TO_KAFKA_MIRROR_MAKER_2_METRICS_CONFIG = "../examples/metrics/kafka-mirror-maker-2-metrics.yaml";
@@ -100,7 +102,7 @@ private static KafkaMirrorMaker2Builder defaultKafkaMirrorMaker2(KafkaMirrorMake
 
     private static DoneableKafkaMirrorMaker2 deployKafkaMirrorMaker2(KafkaMirrorMaker2 kafkaMirrorMaker2) {
         return new DoneableKafkaMirrorMaker2(kafkaMirrorMaker2, kC -> {
-            TestUtils.waitFor("KafkaMirrorMaker2 creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, Constants.TIMEOUT_FOR_CR_CREATION,
+            TestUtils.waitFor("KafkaMirrorMaker2 creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, CR_CREATION_TIMEOUT,
                 () -> {
                     try {
                         kafkaMirrorMaker2Client().inNamespace(ResourceManager.kubeClient().getNamespace()).createOrReplace(kC);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -22,6 +22,8 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
+
 public class KafkaMirrorMakerResource {
     public static final String PATH_TO_KAFKA_MIRROR_MAKER_CONFIG = "../examples/mirror-maker/kafka-mirror-maker.yaml";
 
@@ -77,7 +79,7 @@ private static KafkaMirrorMakerBuilder defaultKafkaMirrorMaker(KafkaMirrorMaker
 
     private static DoneableKafkaMirrorMaker deployKafkaMirrorMaker(KafkaMirrorMaker kafkaMirrorMaker) {
         return new DoneableKafkaMirrorMaker(kafkaMirrorMaker, kB -> {
-            TestUtils.waitFor("KafkaMirrorMaker creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, Constants.TIMEOUT_FOR_CR_CREATION,
+            TestUtils.waitFor("KafkaMirrorMaker creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, CR_CREATION_TIMEOUT,
                 () -> {
                     try {
                         kafkaMirrorMakerClient().inNamespace(ResourceManager.kubeClient().getNamespace()).createOrReplace(kB);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaRebalanceResource.java
Patch:
@@ -18,6 +18,8 @@
 
 import java.util.function.Consumer;
 
+import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
+
 public class KafkaRebalanceResource {
     public static final String PATH_TO_KAFKA_REBALANCE_CONFIG = "../examples/cruise-control/kafka-rebalance.yaml";
 
@@ -41,7 +43,7 @@ private static KafkaRebalance defaultKafkaRebalance(KafkaRebalance kafkaRebalanc
 
     private static DoneableKafkaRebalance deployKafkaRebalance(KafkaRebalance kafkaRebalance) {
         return new DoneableKafkaRebalance(kafkaRebalance, kB -> {
-            TestUtils.waitFor("KafkaRebalance creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, Constants.TIMEOUT_FOR_CR_CREATION,
+            TestUtils.waitFor("KafkaRebalance creation", Constants.POLL_INTERVAL_FOR_RESOURCE_CREATION, CR_CREATION_TIMEOUT,
                 () -> {
                     try {
                         kafkaRebalanceClient().inNamespace(ResourceManager.kubeClient().getNamespace()).createOrReplace(kB);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java
Patch:
@@ -22,6 +22,8 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
+import static io.strimzi.systemtest.resources.ResourceManager.CR_CREATION_TIMEOUT;
+
 public class OlmResource {
     private static final Logger LOGGER = LogManager.getLogger(OlmResource.class);
 
@@ -58,7 +60,7 @@ public static void clusterOperator(String namespace, long operationTimeout, long
 
         ResourceManager.cmdKubeClient().apply(subscriptionFile);
         // Make sure that operator will be deleted
-        TestUtils.waitFor("Cluster Operator deployment creation", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_RESOURCE_CREATION,
+        TestUtils.waitFor("Cluster Operator deployment creation", Constants.GLOBAL_POLL_INTERVAL, CR_CREATION_TIMEOUT,
             () -> ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_NAME) != null);
         String deploymentName = ResourceManager.kubeClient().getDeploymentNameByPrefix(Environment.OLM_OPERATOR_NAME);
         ResourceManager.setCoDeploymentName(deploymentName);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUserUtils.java
Patch:
@@ -56,7 +56,7 @@ public static void waitForKafkaUserDeletion(String userName) {
 
     public static void waitForKafkaUserIncreaseObserverGeneration(long observation, String userName) {
         TestUtils.waitFor("increase observation generation from " + observation + " for user " + userName,
-            Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_SECRET_CREATION,
+            Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,
             () -> observation < KafkaUserResource.kafkaUserClient()
                 .inNamespace(kubeClient().getNamespace()).withName(userName).get().getStatus().getObservedGeneration());
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/StatefulSetUtils.java
Patch:
@@ -186,7 +186,7 @@ public static void waitForStatefulSetLabelsChange(String statefulSetName, Map<St
             if (!(isStrimziTag || isK8sTag)) {
                 LOGGER.info("Waiting for Stateful set label change {} -> {}", entry.getKey(), entry.getValue());
                 TestUtils.waitFor("Waits for StatefulSet label change " + entry.getKey() + " -> " + entry.getValue(), Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS,
-                    Constants.TIMEOUT_FOR_RESOURCE_READINESS, () ->
+                    Constants.GLOBAL_TIMEOUT, () ->
                         kubeClient().getStatefulSet(statefulSetName).getMetadata().getLabels().get(entry.getKey()).equals(entry.getValue())
                 );
             }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java
Patch:
@@ -103,7 +103,7 @@ public static void waitForPodsReady(LabelSelector selector, int expectPods, bool
     }
 
     public static void waitForPodUpdate(String podName, Date startTime) {
-        TestUtils.waitFor(podName + " update", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS, () ->
+        TestUtils.waitFor(podName + " update", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.GLOBAL_TIMEOUT, () ->
             startTime.before(kubeClient().getCreationTimestampForPod(podName))
         );
     }

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -108,7 +108,7 @@ void testManualTriggeringRollingUpdate() {
         StatefulSetUtils.waitTillSsHasRolled(kafkaName, 3, kafkaPods);
 
         // wait when annotation will be removed
-        TestUtils.waitFor("CO removes rolling update annotation", Constants.WAIT_FOR_ROLLING_UPDATE_INTERVAL, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("CO removes rolling update annotation", Constants.WAIT_FOR_ROLLING_UPDATE_INTERVAL, Constants.GLOBAL_TIMEOUT,
             () -> kubeClient().getStatefulSet(kafkaName).getMetadata().getAnnotations() == null
                 || !kubeClient().getStatefulSet(kafkaName).getMetadata().getAnnotations().containsKey(Annotations.ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE));
 
@@ -133,7 +133,7 @@ void testManualTriggeringRollingUpdate() {
         StatefulSetUtils.waitTillSsHasRolled(zkName, 3, zkPods);
 
         // wait when annotation will be removed
-        TestUtils.waitFor("CO removes rolling update annotation", Constants.WAIT_FOR_ROLLING_UPDATE_INTERVAL, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("CO removes rolling update annotation", Constants.WAIT_FOR_ROLLING_UPDATE_INTERVAL, Constants.GLOBAL_TIMEOUT,
             () -> kubeClient().getStatefulSet(zkName).getMetadata().getAnnotations() == null
                 || !kubeClient().getStatefulSet(zkName).getMetadata().getAnnotations().containsKey(Annotations.ANNO_STRIMZI_IO_MANUAL_ROLLING_UPDATE));
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/PrometheusST.java
Patch:
@@ -80,7 +80,6 @@ void setup() throws IOException {
 
         DeploymentUtils.waitForDeploymentAndPodsReady("prometheus-operator", 1);
 
-        cmdKubeClient().apply(FileUtils.updateNamespaceOfYamlFile("../examples/metrics/prometheus-install/strimzi-service-monitor.yaml", NAMESPACE));
         cmdKubeClient().apply(FileUtils.updateNamespaceOfYamlFile("../examples/metrics/prometheus-install/strimzi-pod-monitor.yaml", NAMESPACE));
         cmdKubeClient().apply(FileUtils.updateNamespaceOfYamlFile("../examples/metrics/prometheus-install/prometheus-rules.yaml", NAMESPACE));
         cmdKubeClient().apply(FileUtils.updateNamespaceOfYamlFile("../examples/metrics/prometheus-install/alert-manager.yaml", NAMESPACE));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -265,6 +265,7 @@ Future<Void> reconcile(ReconciliationState reconcileState)  {
         reconcileState.initialStatus()
                 .compose(state -> state.reconcileCas(this::dateSupplier))
                 .compose(state -> state.clusterOperatorSecret(this::dateSupplier))
+                .compose(state -> state.getKafkaClusterDescription())
                 // Roll everything if a new CA is added to the trust store.
                 .compose(state -> state.rollingUpdateForNewCaKey())
                 .compose(state -> state.getZookeeperDescription())
@@ -290,7 +291,6 @@ Future<Void> reconcile(ReconciliationState reconcileState)  {
                 .compose(state -> state.zkHeadlessServiceEndpointReadiness())
                 .compose(state -> state.zkPersistentClaimDeletion())
 
-                .compose(state -> state.getKafkaClusterDescription())
                 .compose(state -> state.checkKafkaSpec())
                 .compose(state -> state.kafkaModelWarnings())
                 .compose(state -> state.kafkaManualPodCleaning())

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaBrokerConfigurationDiff.java
Patch:
@@ -131,15 +131,15 @@ private static boolean isIgnorableProperty(String key) {
     /**
      * Computes diff between two maps. Entries in IGNORABLE_PROPERTIES are skipped
      * @param brokerId id of compared broker
-     * @param desired desired configuration
+     * @param desired desired configuration, may be null if the related ConfigMap does not exist yet or no changes are required
      * @param brokerConfigs current configuration
      * @param configModel default configuration for {@code kafkaVersion} of broker
      * @return KafkaConfiguration containing all entries which were changed from current in desired configuration
      */
     private static Collection<AlterConfigOp> diff(int brokerId, String desired,
                                                   Config brokerConfigs,
                                                   Map<String, ConfigModel> configModel) {
-        if (brokerConfigs == null) {
+        if (brokerConfigs == null || desired == null) {
             return Collections.emptyList();
         }
         Map<String, String> currentMap;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Configuration.java
Patch:
@@ -23,13 +23,14 @@ public class KafkaMirrorMaker2Configuration extends AbstractConfiguration {
         FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(KafkaMirrorMaker2ClusterSpec.FORBIDDEN_PREFIXES);
         FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(KafkaMirrorMaker2ClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
 
-        DEFAULTS = new HashMap<>(8);
+        DEFAULTS = new HashMap<>(9);
         DEFAULTS.put("group.id", "mirrormaker2-cluster");
         DEFAULTS.put("offset.storage.topic", "mirrormaker2-cluster-offsets");
         DEFAULTS.put("config.storage.topic", "mirrormaker2-cluster-configs");
         DEFAULTS.put("status.storage.topic", "mirrormaker2-cluster-status");
         DEFAULTS.put("key.converter", "org.apache.kafka.connect.converters.ByteArrayConverter");
         DEFAULTS.put("value.converter", "org.apache.kafka.connect.converters.ByteArrayConverter");
+        DEFAULTS.put("header.converter", "org.apache.kafka.connect.converters.ByteArrayConverter");
         DEFAULTS.put("config.providers", "file");
         DEFAULTS.put("config.providers.file.class", "org.apache.kafka.common.config.provider.FileConfigProvider");
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -89,7 +89,8 @@ public class KafkaMirrorMaker2ClusterTest {
             .addPair("offset.storage.topic", "mirrormaker2-cluster-offsets")
             .addPair("config.providers", "file")
             .addPair("value.converter", "org.apache.kafka.connect.converters.ByteArrayConverter")
-            .addPair("key.converter", "org.apache.kafka.connect.converters.ByteArrayConverter");
+            .addPair("key.converter", "org.apache.kafka.connect.converters.ByteArrayConverter")
+            .addPair("header.converter", "org.apache.kafka.connect.converters.ByteArrayConverter");
     private final OrderedProperties expectedConfiguration = new OrderedProperties()
             .addMapPairs(defaultConfiguration.asMap())
             .addPair("foo", "bar");

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -10,7 +10,7 @@
  * Interface for keep global constants used across system tests.
  */
 public interface Constants {
-    long TIMEOUT_FOR_DEPLOYMENT_CONFIG_READINESS = Duration.ofMinutes(7).toMillis();
+    long TIMEOUT_FOR_RESOURCE_RECOVERY = Duration.ofMinutes(6).toMillis();
     long TIMEOUT_FOR_RESOURCE_CREATION = Duration.ofMinutes(5).toMillis();
     long TIMEOUT_FOR_SECRET_CREATION = Duration.ofMinutes(2).toMillis();
     long TIMEOUT_FOR_RESOURCE_READINESS = Duration.ofMinutes(14).toMillis();
@@ -42,6 +42,7 @@ public interface Constants {
     long GLOBAL_STATUS_TIMEOUT = Duration.ofMinutes(3).toMillis();
     long CONNECT_STATUS_TIMEOUT = Duration.ofMinutes(5).toMillis();
     long GLOBAL_POLL_INTERVAL = Duration.ofSeconds(1).toMillis();
+    long GLOBAL_POLL_INTERVAL_MEDIUM = Duration.ofSeconds(10).toMillis();
     long PRODUCER_POLL_INTERVAL = Duration.ofSeconds(30).toMillis();
     long PRODUCER_TIMEOUT = Duration.ofSeconds(25).toMillis();
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceOperation.java
Patch:
@@ -64,9 +64,10 @@ public static long getTimeoutForKafkaRebalanceState(KafkaRebalanceState state) {
     }
 
     /**
-     * rollingUpdateTimeout returns a reasonable timeout in milliseconds for a number of pods in a quorum to roll on update
+     * timeoutForPodsOperation returns a reasonable timeout in milliseconds for a number of pods in a quorum to roll on update,
+     *  scale up or create
      */
-    public static long rollingUpdateTimeout(int numberOfPods) {
+    public static long timeoutForPodsOperation(int numberOfPods) {
         return Duration.ofMinutes(5).toMillis() * Math.max(1, numberOfPods);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaTopicUtils.java
Patch:
@@ -85,7 +85,7 @@ public static void waitForKafkaTopicDeletion(String topicName) {
 
     public static void waitForKafkaTopicPartitionChange(String topicName, int partitions) {
         LOGGER.info("Waiting for KafkaTopic change {}", topicName);
-        TestUtils.waitFor("KafkaTopic change " + topicName, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("KafkaTopic change " + topicName, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.GLOBAL_TIMEOUT,
             () -> KafkaTopicResource.kafkaTopicClient().inNamespace(kubeClient().getNamespace()).withName(topicName).get().getSpec().getPartitions() == partitions,
             () -> LOGGER.info(KafkaTopicResource.kafkaTopicClient().inNamespace(kubeClient().getNamespace()).withName(topicName).get())
         );

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/ConfigMapUtils.java
Patch:
@@ -31,7 +31,7 @@ private ConfigMapUtils() { }
      */
     public static void waitForConfigMapRecovery(String name, String configMapUid) {
         LOGGER.info("Waiting for config map {}-{} recovery in namespace {}", name, configMapUid, kubeClient().getNamespace());
-        TestUtils.waitFor("Config map " + name + " to be recovered", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("Config map " + name + " to be recovered", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_RECOVERY,
             () -> !kubeClient().getConfigMapUid(name).equals(configMapUid));
         LOGGER.info("Config map {} was recovered", name);
     }
@@ -44,7 +44,7 @@ public static void waitForConfigMapLabelsChange(String configMapName, Map<String
             if (!(isStrimziTag || isK8sTag)) {
                 LOGGER.info("Waiting for ConfigMap {} label change {} -> {}", configMapName, entry.getKey(), entry.getValue());
                 TestUtils.waitFor("ConfigMap label change " + entry.getKey() + " -> " + entry.getValue(), Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS,
-                    Constants.TIMEOUT_FOR_RESOURCE_READINESS, () ->
+                    Constants.GLOBAL_TIMEOUT, () ->
                         kubeClient().getConfigMap(configMapName).getMetadata().getLabels().get(entry.getKey()).equals(entry.getValue())
                 );
             }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/DeploymentConfigUtils.java
Patch:
@@ -65,7 +65,7 @@ public static boolean depConfigHasRolled(String name, Map<String, String> snapsh
     public static Map<String, String> waitTillDepConfigHasRolled(String depConfigName, Map<String, String> snapshot) {
         LOGGER.info("Waiting for DeploymentConfig {} rolling update", depConfigName);
         TestUtils.waitFor("DeploymentConfig roll of " + depConfigName,
-            Constants.WAIT_FOR_ROLLING_UPDATE_INTERVAL, ResourceOperation.rollingUpdateTimeout(snapshot.size()), () -> depConfigHasRolled(depConfigName, snapshot));
+            Constants.WAIT_FOR_ROLLING_UPDATE_INTERVAL, ResourceOperation.timeoutForPodsOperation(snapshot.size()), () -> depConfigHasRolled(depConfigName, snapshot));
         waitForDeploymentConfigReady(depConfigName);
         LOGGER.info("DeploymentConfig {} rolling update finished", depConfigName);
         return depConfigSnapshot(depConfigName);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/DeploymentUtils.java
Patch:
@@ -128,7 +128,7 @@ public static boolean depHasRolled(String name, Map<String, String> snapshot) {
     public static Map<String, String> waitTillDepHasRolled(String name, int expectedPods, Map<String, String> snapshot) {
         LOGGER.info("Waiting for Deployment {} rolling update", name);
         TestUtils.waitFor("Deployment " + name + " rolling update",
-            Constants.WAIT_FOR_ROLLING_UPDATE_INTERVAL, ResourceOperation.rollingUpdateTimeout(expectedPods), () -> depHasRolled(name, snapshot));
+            Constants.WAIT_FOR_ROLLING_UPDATE_INTERVAL, ResourceOperation.timeoutForPodsOperation(expectedPods), () -> depHasRolled(name, snapshot));
         waitForDeploymentReady(name);
         PodUtils.waitForPodsReady(kubeClient().getDeployment(name).getSpec().getSelector(), expectedPods, true);
         LOGGER.info("Deployment {} rolling update finished", name);
@@ -141,7 +141,7 @@ public static Map<String, String> waitTillDepHasRolled(String name, int expected
      */
     public static void waitForDeploymentRecovery(String name, String deploymentUid) {
         LOGGER.info("Waiting for Deployment {}-{} recovery in namespace {}", name, deploymentUid, kubeClient().getNamespace());
-        TestUtils.waitFor("deployment " + name + " to be recovered", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("deployment " + name + " to be recovered", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_RECOVERY,
             () -> !kubeClient().getDeploymentUid(name).equals(deploymentUid));
         LOGGER.info("Deployment {} was recovered", name);
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/StatefulSetUtils.java
Patch:
@@ -102,7 +102,7 @@ public static boolean ssHasRolled(String name, Map<String, String> snapshot) {
     public static Map<String, String> waitTillSsHasRolled(String name, Map<String, String> snapshot) {
         LOGGER.info("Waiting for StatefulSet {} rolling update", name);
         TestUtils.waitFor("StatefulSet " + name + " rolling update",
-            Constants.WAIT_FOR_ROLLING_UPDATE_INTERVAL, ResourceOperation.rollingUpdateTimeout(snapshot.size()), () -> {
+            Constants.WAIT_FOR_ROLLING_UPDATE_INTERVAL, ResourceOperation.timeoutForPodsOperation(snapshot.size()), () -> {
                 try {
                     return ssHasRolled(name, snapshot);
                 } catch (Exception e) {
@@ -172,7 +172,7 @@ public static void waitForStatefulSetDeletion(String name) {
      */
     public static void waitForStatefulSetRecovery(String name, String statefulSetUid) {
         LOGGER.info("Waiting for StatefulSet {}-{} recovery in namespace {}", name, statefulSetUid, kubeClient().getNamespace());
-        TestUtils.waitFor("StatefulSet " + name + " to be recovered", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("StatefulSet " + name + " to be recovered", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_RECOVERY,
             () -> !kubeClient().getStatefulSetUid(name).equals(statefulSetUid));
         LOGGER.info("StatefulSet {} was recovered", name);
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java
Patch:
@@ -63,7 +63,7 @@ public static void waitForPodsReady(LabelSelector selector, int expectPods, bool
         int[] counter = {0};
 
         TestUtils.waitFor("All pods matching " + selector + "to be ready",
-            Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, ResourceOperation.rollingUpdateTimeout(expectPods),
+            Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, ResourceOperation.timeoutForPodsOperation(expectPods),
             () -> {
                 List<Pod> pods = kubeClient().listPods(selector);
                 if (pods.isEmpty() && expectPods == 0) {
@@ -132,7 +132,7 @@ public static String getFirstPodNameContaining(String searchTerm) {
     public static void waitForPod(String name) {
         LOGGER.info("Waiting when Pod {} will be ready", name);
 
-        TestUtils.waitFor("pod " + name + " to be ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_CREATION,
+        TestUtils.waitFor("pod " + name + " to be ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, ResourceOperation.timeoutForPodsOperation(1),
             () -> {
                 List<ContainerStatus> statuses =  kubeClient().getPod(name).getStatus().getContainerStatuses();
                 for (ContainerStatus containerStatus : statuses) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/ServiceUtils.java
Patch:
@@ -32,7 +32,7 @@ public static void waitForServiceLabelsChange(String serviceName, Map<String, St
             if (!(isStrimziTag || isK8sTag)) {
                 LOGGER.info("Waiting for Service label change {} -> {}", entry.getKey(), entry.getValue());
                 TestUtils.waitFor("Service label change " + entry.getKey() + " -> " + entry.getValue(), Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS,
-                    Constants.TIMEOUT_FOR_RESOURCE_READINESS, () ->
+                    Constants.GLOBAL_TIMEOUT, () ->
                         kubeClient().getService(serviceName).getMetadata().getLabels().get(entry.getKey()).equals(entry.getValue())
                 );
             }
@@ -87,7 +87,7 @@ public static void waitForServiceDeletion(String serviceName) {
     public static void waitForServiceRecovery(String serviceName, String serviceUid) {
         LOGGER.info("Waiting when Service {}-{} in namespace {} will be recovered", serviceName, serviceUid, kubeClient().getNamespace());
 
-        TestUtils.waitFor("Service " + serviceName + " to be recovered", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("Service " + serviceName + " to be recovered", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_RECOVERY,
             () -> !kubeClient().getServiceUid(serviceName).equals(serviceUid));
         LOGGER.info("{} in namespace {} is recovered", serviceName, kubeClient().getNamespace());
     }

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeCorsST.java
Patch:
@@ -32,9 +32,9 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.CoreMatchers.hasItem;
 
-public class HttpBridgeCors extends HttpBridgeAbstractST {
+public class HttpBridgeCorsST extends HttpBridgeAbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(HttpBridgeCors.class);
+    private static final Logger LOGGER = LogManager.getLogger(HttpBridgeCorsST.class);
     public static final String NAMESPACE = "bridge-cluster-test";
     private static final String CORS_ORIGIN = "https://strimzi.io";
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -120,7 +120,7 @@ void testReceiveSimpleMessage() throws Exception {
         }
         assertThat("Sent message count is not equal with received message count", bridgeResponse.size(), is(MESSAGE_COUNT));
         // Delete consumer
-        assertThat(deleteConsumer(bridgeHost, bridgePort, groupId, name), is(true));
+        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, groupId, name, client), is(true));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -122,7 +122,7 @@ void testReceiveSimpleMessageTlsScramSha() throws Exception {
 
         assertThat("Sent message count is not equal with received message count", bridgeResponse.size(), is(MESSAGE_COUNT));
         // Delete consumer
-        assertThat(deleteConsumer(bridgeHost, bridgePort, groupId, name), is(true));
+        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, groupId, name, client), is(true));
     }
 
     @Test
@@ -177,7 +177,7 @@ void testScramShaAuthWithWeirdNamedUser() throws Exception {
         }
         assertThat("Sent message count is not equal with received message count", bridgeResponse.size(), is(MESSAGE_COUNT));
         // Delete consumer
-        assertThat(deleteConsumer(bridgeHost, bridgePort, groupId, aliceUser), is(true));
+        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, groupId, aliceUser, client), is(true));
     }
 
     @BeforeAll

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -122,7 +122,7 @@ void testReceiveSimpleMessageTls() throws Exception {
         }
         assertThat("Sent message count is not equal with received message count", bridgeResponse.size(), is(MESSAGE_COUNT));
         // Delete consumer
-        assertThat(deleteConsumer(bridgeHost, bridgePort, groupId, USER_NAME), is(true));
+        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, groupId, USER_NAME, client), is(true));
     }
 
     @Test
@@ -178,7 +178,7 @@ void testTlsAuthWithWeirdNamedUser() throws Exception {
         }
         assertThat("Sent message count is not equal with received message count", bridgeResponse.size(), is(MESSAGE_COUNT));
         // Delete consumer
-        assertThat(deleteConsumer(bridgeHost, bridgePort, groupId, aliceUser), is(true));
+        assertThat(BridgeUtils.deleteConsumer(bridgeHost, bridgePort, groupId, aliceUser, client), is(true));
     }
 
     @BeforeAll

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -286,7 +286,7 @@ boolean hasTopicInCRK8s(KafkaTopic kafkaTopic, String topicName) {
     }
 
     void verifyTopicViaKafka(String topicName, int topicPartitions) {
-        TestUtils.waitFor("Describing topic " + topicName + " using pod CLI", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("Describing topic " + topicName + " using pod CLI", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.GLOBAL_TIMEOUT,
             () -> {
                 try {
                     List<String> topicInfo =  KafkaCmdClient.describeTopicUsingPodCli(CLUSTER_NAME, 0, topicName);

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerST.java
Patch:
@@ -82,6 +82,7 @@ void testKafkaRollsWhenTopicIsUnderReplicated() {
         StatefulSetUtils.waitForAllStatefulSetPodsReady(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), scaledDownReplicas);
 
         PodUtils.verifyThatRunningPodsAreStable(CLUSTER_NAME);
+        kafkaPods = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));
 
         // set annotation to trigger Kafka rolling update
         kubeClient().statefulSet(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME)).cascading(false).edit()

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.logs.TestExecutionWatcher;
 import io.strimzi.systemtest.resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
@@ -277,7 +278,8 @@ private void performUpgrade(JsonObject testParameters, int produceMessagesCount,
 
         // Wait until user will be created
         SecretUtils.waitForSecretReady(userName);
-        TestUtils.waitFor("KafkaUser " + userName + " availability", 10_000L, 120_000L,
+        TestUtils.waitFor("KafkaUser " + userName + " availability", Constants.GLOBAL_POLL_INTERVAL_MEDIUM,
+            ResourceOperation.getTimeoutForResourceReadiness(KafkaUser.RESOURCE_KIND),
             () -> !cmdKubeClient().getResourceAsYaml("kafkauser", userName).equals(""));
 
         // Deploy clients and exchange messages

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceDeletionRecoveryST.java
Patch:
@@ -249,9 +249,6 @@ private void deleteAndRecreateNamespace() {
         cluster.createNamespace(NAMESPACE);
     }
 
-    @Override
-    protected void recreateTestEnv(String coNamespace, List<String> bindingsNamespaces) { }
-
     @BeforeAll
     void createStorageClass() {
         kubeClient().getClient().storage().storageClasses().inNamespace(NAMESPACE).withName(storageClassName).delete();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractConfiguration.java
Patch:
@@ -168,7 +168,7 @@ public String getConfiguration() {
      * in value returned by subsequent calls to getConfiguration()
      * @return A map of keys to values.
      */
-    OrderedProperties asOrderedProperties() {
+    public OrderedProperties asOrderedProperties() {
         return options;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperator.java
Patch:
@@ -17,6 +17,7 @@
 import org.apache.logging.log4j.Logger;
 
 import java.util.ArrayList;
+import java.util.List;
 import java.util.function.Function;
 
 
@@ -67,7 +68,7 @@ public static boolean needsRollingUpdate(StatefulSetDiff diff) {
     }
 
     @Override
-    public Future<Void> maybeRollingUpdate(StatefulSet sts, Function<Pod, String> podRestart, Secret clusterCaSecret, Secret coKeySecret) {
+    public Future<Void> maybeRollingUpdate(StatefulSet sts, Function<Pod, List<String>> podRestart, Secret clusterCaSecret, Secret coKeySecret) {
         String namespace = sts.getMetadata().getNamespace();
         String name = sts.getMetadata().getName();
         final int replicas = sts.getSpec().getReplicas();
@@ -78,7 +79,7 @@ public Future<Void> maybeRollingUpdate(StatefulSet sts, Function<Pod, String> po
         String cluster = sts.getMetadata().getLabels().get(Labels.STRIMZI_CLUSTER_LABEL);
         for (int i = 0; i < replicas; i++) {
             Pod pod = podOperations.get(sts.getMetadata().getNamespace(), KafkaResources.zookeeperPodName(cluster, i));
-            String zkPodRestart = podRestart.apply(pod);
+            List<String> zkPodRestart = podRestart.apply(pod);
             zkRoll |= zkPodRestart != null && !zkPodRestart.isEmpty();
             pods.add(pod);
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -694,7 +694,7 @@ public static ResourceOperatorSupplier supplierWithMocks(boolean openShift) {
                 mock(IngressOperator.class), mock(ImageStreamOperator.class), mock(BuildConfigOperator.class),
                 mock(DeploymentConfigOperator.class), mock(CrdOperator.class), mock(CrdOperator.class), mock(CrdOperator.class),
                 mock(CrdOperator.class), mock(CrdOperator.class), mock(CrdOperator.class), mock(CrdOperator.class), mock(CrdOperator.class),
-                mock(StorageClassOperator.class), mock(NodeOperator.class), zookeeperScalerProvider(), metricsProvider());
+                mock(StorageClassOperator.class), mock(NodeOperator.class), zookeeperScalerProvider(), metricsProvider(), adminClientProvider());
         when(supplier.serviceAccountOperations.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.roleBindingOperations.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.clusterRoleBindingOperator.reconcile(anyString(), any())).thenReturn(Future.succeededFuture());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -167,7 +167,7 @@ public void test(VertxTestContext context) {
                 new ResourceOperatorSupplier(
                         null, null, null, null, null, null, null, null, null, null, null,
                         null, null, null, null, null, null, null, null, null, null, null,
-                        null, connectCrdOperator, null, null, null, null, null, metrics),
+                        null, connectCrdOperator, null, null, null, null, null, metrics, null),
                 ClusterOperatorConfig.fromMap(Collections.emptyMap(), KafkaVersionTestUtils.getKafkaVersionLookup()),
             connect -> new KafkaConnectApiImpl(vertx),
             connectCluster.getPort() + 2

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractResourceDiff.java
Patch:
@@ -8,7 +8,7 @@
 import com.fasterxml.jackson.databind.node.MissingNode;
 
 public abstract class AbstractResourceDiff {
-    protected JsonNode lookupPath(JsonNode source, String path) {
+    protected static JsonNode lookupPath(JsonNode source, String path) {
         JsonNode s = source;
         for (String component : path.substring(1).split("/")) {
             if (s.isArray()) {

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -182,7 +182,7 @@ void testCustomAndUpdatedValues() {
                 .endLivenessProbe()
             .endSpec().done();
 
-        Map<String, String> connectSnapshot = DeploymentUtils.depSnapshot(KafkaBridgeResources.deploymentName(bridgeName));
+        Map<String, String> bridgeSnapshot = DeploymentUtils.depSnapshot(KafkaBridgeResources.deploymentName(bridgeName));
 
         // Remove variable which is already in use
         envVarGeneral.remove(usedVariable);
@@ -212,7 +212,7 @@ void testCustomAndUpdatedValues() {
             kb.getSpec().getReadinessProbe().setFailureThreshold(updatedFailureThreshold);
         });
 
-        DeploymentUtils.waitTillDepHasRolled(KafkaBridgeResources.deploymentName(bridgeName), 1, connectSnapshot);
+        DeploymentUtils.waitTillDepHasRolled(KafkaBridgeResources.deploymentName(bridgeName), 1, bridgeSnapshot);
 
         LOGGER.info("Verify values after update");
         checkReadinessLivenessProbe(KafkaBridgeResources.deploymentName(bridgeName), KafkaBridgeResources.deploymentName(bridgeName), updatedInitialDelaySeconds, updatedTimeoutSeconds,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeResources.java
Patch:
@@ -31,8 +31,8 @@ public static String serviceName(String clusterName) {
     }
 
     /**
-     * Returns the name of the Kafka Bridge metrics and log {@code ConfigMap} for a {@code KafkaBrdige} cluster of the given name.
-     * @param clusterName  The {@code metadata.name} of the {@code KafkaBrdige} resource.
+     * Returns the name of the Kafka Bridge metrics and log {@code ConfigMap} for a {@code KafkaBridge} cluster of the given name.
+     * @param clusterName  The {@code metadata.name} of the {@code KafkaBridge} resource.
      * @return The name of the corresponding Kafka Bridge metrics and log {@code ConfigMap}.
      */
     public static String metricsAndLogConfigMapName(String clusterName) {

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -77,6 +77,7 @@ public interface Constants {
      */
     String KAFKA_CLIENTS_LABEL_KEY = "user-test-app";
     String KAFKA_CLIENTS_LABEL_VALUE = "kafka-clients";
+    String KAFKA_BRIDGE_CLIENTS_LABEL_VALUE = "kafka-clients";
 
     String KAFKA_CLIENTS = "kafka-clients";
     String STRIMZI_DEPLOYMENT_NAME = "strimzi-cluster-operator";
@@ -92,6 +93,7 @@ public interface Constants {
     int CLUSTER_OPERATOR_METRICS_PORT = 8080;
     int USER_OPERATOR_METRICS_PORT = 8081;
     int TOPIC_OPERATOR_METRICS_PORT = 8080;
+    int KAFKA_BRIDGE_METRICS_PORT = 8080;
 
     String DEPLOYMENT = "Deployment";
     String SERVICE = "Service";

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/BridgeUtils.java
Patch:
@@ -81,7 +81,7 @@ public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridge
                             String kafkaTopic = jsonResponse.getString("topic");
                             int kafkaPartition = jsonResponse.getInteger("partition");
                             String key = jsonResponse.getString("key");
-                            String value = jsonResponse.getString("value");
+                            Object value = jsonResponse.getValue("value");
                             long offset = jsonResponse.getLong("offset");
                             LOGGER.debug("Received msg: topic:{} partition:{} key:{} value:{} offset{}", kafkaTopic, kafkaPartition, key, value, offset);
                         }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/operator/OlmResource.java
Patch:
@@ -2,10 +2,11 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.resources;
+package io.strimzi.systemtest.resources.operator;
 
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
+import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.k8s.KubeClusterResource;

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -14,9 +14,9 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
+import io.strimzi.systemtest.resources.operator.BundleResource;
 import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
@@ -134,7 +134,7 @@ void testJSONFormatLogging() {
         kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapOperators);
         kubeClient().getClient().configMaps().inNamespace(NAMESPACE).createOrReplace(configMapCO);
 
-        KubernetesResource.clusterOperator(NAMESPACE)
+        BundleResource.clusterOperator(NAMESPACE)
             .editOrNewSpec()
                 .editOrNewTemplate()
                     .editOrNewSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/olm/AllNamespacesST.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.olm;
 
-import io.strimzi.systemtest.resources.OlmResource;
+import io.strimzi.systemtest.resources.operator.OlmResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAbstractST.java
Patch:
@@ -13,7 +13,7 @@
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.systemtest.AbstractST;
-import io.strimzi.systemtest.resources.OlmResource;
+import io.strimzi.systemtest.resources.operator.OlmResource;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectS2IUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;

File: systemtest/src/test/java/io/strimzi/systemtest/olm/SingleNamespaceST.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.olm;
 
-import io.strimzi.systemtest.resources.OlmResource;
+import io.strimzi.systemtest.resources.operator.OlmResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceDeletionRecoveryST.java
Patch:
@@ -14,11 +14,11 @@
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
-import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
+import io.strimzi.systemtest.resources.operator.BundleResource;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.NamespaceUtils;
@@ -182,7 +182,7 @@ private void prepareEnvironmentForRecovery(String topicName, int messageCount) {
         prepareEnvForOperator(NAMESPACE);
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        KubernetesResource.clusterOperator(NAMESPACE).done();
+        BundleResource.clusterOperator(NAMESPACE).done();
         KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 3)
             .editSpec()
                 .editKafka()
@@ -237,7 +237,7 @@ private void recreateClusterOperator() {
         cluster.applyClusterOperatorInstallFiles();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        KubernetesResource.clusterOperator(NAMESPACE).done();
+        BundleResource.clusterOperator(NAMESPACE).done();
     }
 
     private void deleteAndRecreateNamespace() {

File: systemtest/src/test/java/io/strimzi/systemtest/specific/HelmChartST.java
Patch:
@@ -5,6 +5,7 @@
 package io.strimzi.systemtest.specific;
 
 import io.strimzi.api.kafka.model.KafkaResources;
+import io.strimzi.systemtest.resources.operator.HelmResource;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import org.apache.logging.log4j.LogManager;
@@ -39,18 +40,17 @@ void testDeployKafkaClusterViaHelmChart() {
     void setup() {
         LOGGER.info("Creating resources before the test class");
         cluster.createNamespace(NAMESPACE);
-        deployClusterOperatorViaHelmChart();
+        HelmResource.clusterOperator();
     }
 
     @Override
     protected void tearDownEnvironmentAfterAll() {
-        deleteClusterOperatorViaHelmChart();
         cluster.deleteNamespaces();
     }
 
     @Override
     protected void recreateTestEnv(String coNamespace, List<String> bindingsNamespaces) {
-        deleteClusterOperatorViaHelmChart();
+        HelmResource.clusterOperator();
         cluster.deleteNamespaces();
         cluster.createNamespace(NAMESPACE);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -15,9 +15,9 @@
 import io.strimzi.api.kafka.model.listener.LoadBalancerListenerBrokerOverrideBuilder;
 import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
-import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
+import io.strimzi.systemtest.resources.operator.BundleResource;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.strimzi.test.executor.Exec;
 import org.apache.logging.log4j.LogManager;
@@ -253,6 +253,6 @@ void setup() {
 
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        KubernetesResource.clusterOperator(NAMESPACE).done();
+        BundleResource.clusterOperator(NAMESPACE).done();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -12,12 +12,12 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.logs.TestExecutionWatcher;
-import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
+import io.strimzi.systemtest.resources.operator.BundleResource;
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.FileUtils;
 import io.strimzi.systemtest.utils.StUtils;
@@ -189,7 +189,7 @@ void testUpgradeKafkaWithoutVersion() throws IOException {
         applyRoleBindings(NAMESPACE);
 
         kubeClient().getClient().apps().deployments().inNamespace(NAMESPACE).withName(ResourceManager.getCoDeploymentName()).delete();
-        kubeClient().getClient().apps().deployments().inNamespace(NAMESPACE).withName(ResourceManager.getCoDeploymentName()).create(KubernetesResource.defaultClusterOperator(NAMESPACE).build());
+        kubeClient().getClient().apps().deployments().inNamespace(NAMESPACE).withName(ResourceManager.getCoDeploymentName()).create(BundleResource.defaultClusterOperator(NAMESPACE).build());
 
         DeploymentUtils.waitTillDepHasRolled(ResourceManager.getCoDeploymentName(), 1, operatorSnapshot);
         StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java
Patch:
@@ -7,11 +7,11 @@
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.AbstractST;
-import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
+import io.strimzi.systemtest.resources.operator.BundleResource;
 import io.strimzi.systemtest.utils.ClientUtils;
 import io.strimzi.systemtest.utils.TestKafkaVersion;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
@@ -228,6 +228,6 @@ void setup() {
 
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        KubernetesResource.clusterOperator(NAMESPACE).done();
+        BundleResource.clusterOperator(NAMESPACE).done();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceST.java
Patch:
@@ -21,6 +21,7 @@
 import io.strimzi.systemtest.resources.crd.KafkaConnectS2IResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
+import io.strimzi.systemtest.resources.operator.BundleResource;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
@@ -202,7 +203,7 @@ private void deployTestSpecificResources() {
         clusterRoleBindingList.forEach(clusterRoleBinding ->
                 KubernetesResource.clusterRoleBinding(clusterRoleBinding, CO_NAMESPACE));
         // 050-Deployment
-        KubernetesResource.clusterOperator("*").done();
+        BundleResource.clusterOperator("*").done();
 
         String previousNamespace = cluster.setNamespace(THIRD_NAMESPACE);
 

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/MultipleNamespaceST.java
Patch:
@@ -5,12 +5,12 @@
 package io.strimzi.systemtest.watcher;
 
 import io.strimzi.systemtest.cli.KafkaCmdClient;
+import io.strimzi.systemtest.resources.operator.BundleResource;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.Test;
-import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 
@@ -72,7 +72,7 @@ private void deployTestSpecificResources() {
         applyRoleBindings(CO_NAMESPACE);
         applyRoleBindings(CO_NAMESPACE, SECOND_NAMESPACE);
         // 050-Deployment
-        KubernetesResource.clusterOperator(String.join(",", CO_NAMESPACE, SECOND_NAMESPACE)).done();
+        BundleResource.clusterOperator(String.join(",", CO_NAMESPACE, SECOND_NAMESPACE)).done();
 
         cluster.setNamespace(SECOND_NAMESPACE);
 

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/ListenersST.java
Patch:
@@ -248,7 +248,7 @@ void testSendMessagesTlsScramSha() {
         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)
                 .editSpec()
                     .editKafka()
-                        .editListeners()
+                        .withNewListeners()
                             .editOrNewTls()
                                 .withNewKafkaListenerAuthenticationScramSha512Auth()
                                 .endKafkaListenerAuthenticationScramSha512Auth()

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceOperation.java
Patch:
@@ -67,6 +67,6 @@ public static long getTimeoutForKafkaRebalanceState(KafkaRebalanceState state) {
      * rollingUpdateTimeout returns a reasonable timeout in milliseconds for a number of pods in a quorum to roll on update
      */
     public static long rollingUpdateTimeout(int numberOfPods) {
-        return Duration.ofMinutes(5).toMillis() * numberOfPods;
+        return Duration.ofMinutes(5).toMillis() * Math.max(1, numberOfPods);
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -505,8 +505,6 @@ protected void verifyLabelsOnPods(String clusterName, String podType, String app
             .filter(pod -> pod.getMetadata().getName().startsWith(clusterName.concat("-" + podType)))
             .forEach(pod -> {
                 LOGGER.info("Verifying labels for pod: " + pod.getMetadata().getName());
-                assertThat(pod.getMetadata().getLabels().get("app"), is(appName));
-                assertThat(pod.getMetadata().getLabels().get("pod-template-hash").matches("[0-9A-Fa-f]+"), is(true));
                 assertThat(pod.getMetadata().getLabels().get(Labels.STRIMZI_CLUSTER_LABEL), is(clusterName));
                 assertThat(pod.getMetadata().getLabels().get(Labels.STRIMZI_KIND_LABEL), is(kind));
                 assertThat(pod.getMetadata().getLabels().get(Labels.STRIMZI_NAME_LABEL), is(clusterName.concat("-" + podType)));

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -65,6 +65,7 @@ public interface Constants {
     long CO_OPERATION_TIMEOUT_WAIT = CO_OPERATION_TIMEOUT_SHORT + Duration.ofSeconds(80).toMillis();
     long CO_OPERATION_TIMEOUT_POLL = Duration.ofSeconds(2).toMillis();
     long RECONCILIATION_INTERVAL = Duration.ofSeconds(30).toMillis();
+    long LOGGING_RELOADING_INTERVAL = Duration.ofSeconds(30).toMillis();
 
     // stability count ensures that after some reconciliation we have some additional time
     int GLOBAL_STABILITY_OFFSET_COUNT = 20;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java
Patch:
@@ -9,12 +9,12 @@
 import io.fabric8.kubernetes.api.model.Pod;
 import io.fabric8.kubernetes.client.internal.readiness.Readiness;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
-import java.time.Duration;
 import java.util.Date;
 import java.util.List;
 import java.util.Map;
@@ -63,7 +63,7 @@ public static void waitForPodsReady(LabelSelector selector, int expectPods, bool
         int[] counter = {0};
 
         TestUtils.waitFor("All pods matching " + selector + "to be ready",
-            Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Duration.ofMinutes(6).toMillis(),
+            Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, ResourceOperation.rollingUpdateTimeout(expectPods),
             () -> {
                 List<Pod> pods = kubeClient().listPods(selector);
                 if (pods.isEmpty() && expectPods == 0) {
@@ -132,7 +132,7 @@ public static String getFirstPodNameContaining(String searchTerm) {
     public static void waitForPod(String name) {
         LOGGER.info("Waiting when Pod {} will be ready", name);
 
-        TestUtils.waitFor("pod " + name + " to be ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Duration.ofMinutes(6).toMillis(),
+        TestUtils.waitFor("pod " + name + " to be ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_CREATION,
             () -> {
                 List<ContainerStatus> statuses =  kubeClient().getPod(name).getStatus().getContainerStatuses();
                 for (ContainerStatus containerStatus : statuses) {

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -90,6 +90,7 @@ public class StrimziUpgradeST extends AbstractST {
     void testUpgradeStrimziVersion(JsonObject parameters) throws Exception {
 
         assumeTrue(StUtils.isAllowOnCurrentEnvironment(parameters.getJsonObject("environmentInfo").getString("flakyEnvVariable")));
+        assumeTrue(StUtils.isAllowedOnCurrentK8sVersion(parameters.getJsonObject("environmentInfo").getString("maxK8sVersion")));
 
         try {
             performUpgrade(parameters, MESSAGE_COUNT, MESSAGE_COUNT);
@@ -130,7 +131,8 @@ void testChainUpgrade() throws Exception {
 
         try {
             for (JsonValue testParameters : parameters) {
-                if (StUtils.isAllowOnCurrentEnvironment(testParameters.asJsonObject().getJsonObject("environmentInfo").getString("flakyEnvVariable"))) {
+                if (StUtils.isAllowOnCurrentEnvironment(testParameters.asJsonObject().getJsonObject("environmentInfo").getString("flakyEnvVariable")) &&
+                    StUtils.isAllowedOnCurrentK8sVersion(testParameters.asJsonObject().getJsonObject("environmentInfo").getString("maxK8sVersion"))) {
                     performUpgrade(testParameters.asJsonObject(), MESSAGE_COUNT, consumedMessagesCount);
                     consumedMessagesCount = consumedMessagesCount + MESSAGE_COUNT;
                 } else {

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeAbstractST.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.bridge;
 
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.vertx.core.Vertx;
 import io.vertx.ext.web.client.WebClient;
@@ -37,8 +37,8 @@
 @Tag(REGRESSION)
 @Tag(NODEPORT_SUPPORTED)
 @Tag(EXTERNAL_CLIENTS_USED)
-public class HttpBridgeBaseST extends BaseST {
-    private static final Logger LOGGER = LogManager.getLogger(HttpBridgeBaseST.class);
+public class HttpBridgeAbstractST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(HttpBridgeAbstractST.class);
 
     protected WebClient client;
     protected String bridgeExternalService = CLUSTER_NAME + "-bridge-external-service";

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeCors.java
Patch:
@@ -32,7 +32,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.CoreMatchers.hasItem;
 
-public class HttpBridgeCors extends HttpBridgeBaseST {
+public class HttpBridgeCors extends HttpBridgeAbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeCors.class);
     public static final String NAMESPACE = "bridge-cluster-test";

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -43,7 +43,7 @@
 import static org.hamcrest.CoreMatchers.not;
 import static org.hamcrest.MatcherAssert.assertThat;
 
-class HttpBridgeST extends HttpBridgeBaseST {
+class HttpBridgeST extends HttpBridgeAbstractST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeST.class);
 
     public static final String NAMESPACE = "bridge-cluster-test";

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -49,7 +49,7 @@
 @Tag(NODEPORT_SUPPORTED)
 @Tag(EXTERNAL_CLIENTS_USED)
 @ExtendWith(VertxExtension.class)
-class HttpBridgeScramShaST extends HttpBridgeBaseST {
+class HttpBridgeScramShaST extends HttpBridgeAbstractST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);
 
     private String bridgeHost = "";

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -49,7 +49,7 @@
 @Tag(NODEPORT_SUPPORTED)
 @Tag(EXTERNAL_CLIENTS_USED)
 @ExtendWith(VertxExtension.class)
-class HttpBridgeTlsST extends HttpBridgeBaseST {
+class HttpBridgeTlsST extends HttpBridgeAbstractST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeTlsST.class);
 
     private String bridgeHost = "";

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlApiST.java
Patch:
@@ -4,9 +4,9 @@
  */
 package io.strimzi.systemtest.cruisecontrol;
 
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlEndpoints;
 import io.strimzi.operator.cluster.operator.resource.cruisecontrol.CruiseControlUserTaskStatus;
-import io.strimzi.systemtest.BaseST;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.utils.specific.CruiseControlUtils;
@@ -32,7 +32,7 @@
 @Tag(REGRESSION)
 @Tag(CRUISE_CONTROL)
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
-public class CruiseControlApiST extends BaseST {
+public class CruiseControlApiST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(CruiseControlApiST.class);
     private static final String NAMESPACE = "cruise-control-api-test";

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlConfigurationST.java
Patch:
@@ -11,7 +11,7 @@
 import io.strimzi.api.kafka.model.CruiseControlSpec;
 import io.strimzi.api.kafka.model.CruiseControlSpecBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
@@ -52,7 +52,7 @@
 @Tag(REGRESSION)
 @Tag(CRUISE_CONTROL)
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
-public class CruiseControlConfigurationST extends BaseST {
+public class CruiseControlConfigurationST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(CruiseControlConfigurationST.class);
     private static final String NAMESPACE = "cruise-control-configuration-test";

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlIsolatedST.java
Patch:
@@ -5,9 +5,9 @@
 package io.strimzi.systemtest.cruisecontrol;
 
 import io.strimzi.api.kafka.model.KafkaTopicSpec;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.api.kafka.operator.assembly.KafkaRebalanceAnnotation;
 import io.strimzi.api.kafka.operator.assembly.KafkaRebalanceState;
-import io.strimzi.systemtest.BaseST;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaRebalanceResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
@@ -29,7 +29,7 @@
 
 @Tag(REGRESSION)
 @Tag(CRUISE_CONTROL)
-public class CruiseControlIsolatedST extends BaseST {
+public class CruiseControlIsolatedST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(CruiseControlIsolatedST.class);
     private static final String NAMESPACE = "cruise-control-isolated-test";

File: systemtest/src/test/java/io/strimzi/systemtest/log/LogSettingST.java
Patch:
@@ -14,7 +14,7 @@
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2Resources;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerResources;
 import io.strimzi.api.kafka.model.KafkaResources;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;
 import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
@@ -63,7 +63,7 @@
 @Tag(BRIDGE)
 @Tag(CONNECT_COMPONENTS)
 @TestMethodOrder(OrderAnnotation.class)
-class LogSettingST extends BaseST {
+class LogSettingST extends AbstractST {
     static final String NAMESPACE = "log-setting-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(LogSettingST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/log/LoggingChangeST.java
Patch:
@@ -10,7 +10,7 @@
 import io.fabric8.kubernetes.api.model.VolumeMountBuilder;
 import io.strimzi.api.kafka.model.ExternalLoggingBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
@@ -32,7 +32,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 
 @Tag(REGRESSION)
-class LoggingChangeST extends BaseST {
+class LoggingChangeST extends AbstractST {
     static final String NAMESPACE = "logging-change-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(LoggingChangeST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.fabric8.kubernetes.api.model.LabelSelector;
 import io.strimzi.api.kafka.model.KafkaExporterResources;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.crd.KafkaMirrorMaker2Resource;
@@ -51,7 +51,7 @@
 @Tag(REGRESSION)
 @Tag(ACCEPTANCE)
 @Tag(METRICS)
-public class MetricsST extends BaseST {
+public class MetricsST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(MetricsST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/PrometheusST.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.metrics;
 
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.utils.FileUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
@@ -28,7 +28,7 @@
 @Tag(REGRESSION)
 @Tag(PROMETHEUS)
 @Tag(METRICS)
-public class PrometheusST extends BaseST {
+public class PrometheusST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(PrometheusST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/olm/AllNamespacesST.java
Patch:
@@ -15,7 +15,7 @@
 import org.junit.jupiter.api.TestMethodOrder;
 
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
-public class AllNamespacesST extends OlmBaseST {
+public class AllNamespacesST extends OlmAbstractST {
 
     public static final String NAMESPACE = "olm-namespace";
 

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmAbstractST.java
Patch:
@@ -12,7 +12,7 @@
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaUser;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.resources.OlmResource;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectS2IUtils;
@@ -32,8 +32,8 @@
 
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 
-public class OlmBaseST extends BaseST {
-    private static final Logger LOGGER = LogManager.getLogger(OlmBaseST.class);
+public class OlmAbstractST extends AbstractST {
+    private static final Logger LOGGER = LogManager.getLogger(OlmAbstractST.class);
 
     void doTestDeployExampleKafka() {
         JsonObject kafkaResource = OlmResource.getExampleResources().get(Kafka.RESOURCE_KIND);

File: systemtest/src/test/java/io/strimzi/systemtest/olm/SingleNamespaceST.java
Patch:
@@ -15,7 +15,7 @@
 import org.junit.jupiter.api.TestMethodOrder;
 
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
-public class SingleNamespaceST extends OlmBaseST {
+public class SingleNamespaceST extends OlmAbstractST {
 
     public static final String NAMESPACE = "olm-namespace";
 

File: systemtest/src/test/java/io/strimzi/systemtest/operators/NamespaceDeletionRecoveryST.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.recovery;
+package io.strimzi.systemtest.operators;
 
 import io.fabric8.kubernetes.api.model.PersistentVolume;
 import io.fabric8.kubernetes.api.model.PersistentVolumeClaim;
@@ -11,7 +11,7 @@
 import io.strimzi.api.kafka.model.EntityOperatorSpecBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.KafkaTopic;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.KubernetesResource;
@@ -39,7 +39,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 
 @Tag(RECOVERY)
-class NamespaceDeletionRecoveryST extends BaseST {
+class NamespaceDeletionRecoveryST extends AbstractST {
 
     static final String NAMESPACE = "namespace-recovery-cluster-test";
     static final String CLUSTER_NAME = "recovery-cluster";

File: systemtest/src/test/java/io/strimzi/systemtest/operators/RecoveryST.java
Patch:
@@ -2,10 +2,11 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest;
+package io.strimzi.systemtest.operators;
 
 import io.strimzi.api.kafka.model.KafkaBridgeResources;
 import io.strimzi.api.kafka.model.KafkaResources;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.ConfigMapUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
@@ -28,7 +29,7 @@
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 
 @Tag(REGRESSION)
-class RecoveryST extends BaseST {
+class RecoveryST extends AbstractST {
 
     static final String NAMESPACE = "recovery-cluster-test";
     static final String CLUSTER_NAME = "recovery-cluster";

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicST.java
Patch:
@@ -2,11 +2,11 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.topic;
+package io.strimzi.systemtest.operators.topic;
 
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.operator.common.model.Labels;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.kafkaclients.AbstractKafkaClient;
@@ -49,7 +49,7 @@
 import static org.hamcrest.Matchers.notNullValue;
 
 @Tag(REGRESSION)
-public class TopicST extends BaseST {
+public class TopicST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(TopicST.class);
     static final String NAMESPACE = "topic-cluster-test";

File: systemtest/src/test/java/io/strimzi/systemtest/operators/topic/TopicScalabilityST.java
Patch:
@@ -2,9 +2,9 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.topic;
+package io.strimzi.systemtest.operators.topic;
 
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
@@ -20,7 +20,7 @@
 import static io.strimzi.systemtest.Constants.SCALABILITY;
 
 @Tag(SCALABILITY)
-public class TopicScalabilityST extends BaseST {
+public class TopicScalabilityST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(TopicScalabilityST.class);
     private static final int NUMBER_OF_TOPICS = 1000;

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -7,7 +7,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.operator.common.Annotations;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
@@ -40,7 +40,7 @@
 
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
-class AlternativeReconcileTriggersST extends BaseST {
+class AlternativeReconcileTriggersST extends AbstractST {
     private static final Logger LOGGER = LogManager.getLogger(RollingUpdateST.class);
 
     static final String NAMESPACE = "alternative-reconcile-triggers-cluster-test";

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/KafkaRollerST.java
Patch:
@@ -7,7 +7,7 @@
 import io.fabric8.kubernetes.api.model.Event;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.operator.common.Annotations;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
@@ -40,7 +40,7 @@
 
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
-class KafkaRollerST extends BaseST {
+class KafkaRollerST extends AbstractST {
     private static final Logger LOGGER = LogManager.getLogger(RollingUpdateST.class);
     static final String NAMESPACE = "kafka-roller-cluster-test";
 

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePort;
 import io.strimzi.api.kafka.model.listener.KafkaListenerExternalNodePortBuilder;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
@@ -69,7 +69,7 @@
 
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
-class RollingUpdateST extends BaseST {
+class RollingUpdateST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(RollingUpdateST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/OpaIntegrationST.java
Patch:
@@ -5,7 +5,7 @@
 package io.strimzi.systemtest.security;
 
 import io.strimzi.api.kafka.model.KafkaUser;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.resources.ResourceManager;
@@ -35,7 +35,7 @@
 
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
-public class OpaIntegrationST extends BaseST {
+public class OpaIntegrationST extends AbstractST {
     public static final String NAMESPACE = "opa-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(OpaIntegrationST.class);
     private static final String OPA_SUPERUSER = "arnost";

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -17,7 +17,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.operator.cluster.model.Ca;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
@@ -85,7 +85,7 @@
 import static org.junit.jupiter.api.Assertions.assertThrows;
 
 @Tag(REGRESSION)
-class SecurityST extends BaseST {
+class SecurityST extends AbstractST {
 
     public static final String NAMESPACE = "security-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(SecurityST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthAuthorizationST.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.oauth;
+package io.strimzi.systemtest.security.oauth;
 
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
 import io.strimzi.api.kafka.model.KafkaAuthorizationKeycloak;
@@ -44,7 +44,7 @@
 @Tag(NODEPORT_SUPPORTED)
 @Tag(EXTERNAL_CLIENTS_USED)
 @TestMethodOrder(MethodOrderer.OrderAnnotation.class)
-public class OauthAuthorizationST extends OauthBaseST {
+public class OauthAuthorizationST extends OauthAbstractST {
 
     private OauthExternalKafkaClient teamAOauthKafkaClient;
     private OauthExternalKafkaClient teamBOauthKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthPlainST.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.oauth;
+package io.strimzi.systemtest.security.oauth;
 
 import io.fabric8.kubernetes.api.model.Service;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2ClusterSpec;
@@ -63,7 +63,7 @@
 @Tag(REGRESSION)
 @Tag(NODEPORT_SUPPORTED)
 @Tag(EXTERNAL_CLIENTS_USED)
-public class OauthPlainST extends OauthBaseST {
+public class OauthPlainST extends OauthAbstractST {
 
     private OauthExternalKafkaClient oauthExternalKafkaClient;
 

File: systemtest/src/test/java/io/strimzi/systemtest/security/oauth/OauthTlsST.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.oauth;
+package io.strimzi.systemtest.security.oauth;
 
 import io.fabric8.kubernetes.api.model.Service;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
@@ -64,7 +64,7 @@
 @Tag(REGRESSION)
 @Tag(NODEPORT_SUPPORTED)
 @Tag(EXTERNAL_CLIENTS_USED)
-public class OauthTlsST extends OauthBaseST {
+public class OauthTlsST extends OauthAbstractST {
 
     private OauthExternalKafkaClient oauthExternalKafkaClientTls;
 

File: systemtest/src/test/java/io/strimzi/systemtest/specific/HelmChartST.java
Patch:
@@ -2,9 +2,10 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest;
+package io.strimzi.systemtest.specific;
 
 import io.strimzi.api.kafka.model.KafkaResources;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -19,7 +20,7 @@
 import static io.strimzi.systemtest.Constants.HELM;
 
 @Tag(HELM)
-class HelmChartST extends BaseST {
+class HelmChartST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(HelmChartST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/specific/OpenShiftTemplatesST.java
Patch:
@@ -2,14 +2,15 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest;
+package io.strimzi.systemtest.specific;
 
 import io.strimzi.api.kafka.model.storage.JbodStorage;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.storage.PersistentClaimStorage;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectS2IResource;
@@ -42,7 +43,7 @@
 @OpenShiftOnly
 @Tag(REGRESSION)
 @Tag(ACCEPTANCE)
-public class OpenShiftTemplatesST extends BaseST {
+public class OpenShiftTemplatesST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(OpenShiftTemplatesST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -13,7 +13,7 @@
 import io.strimzi.api.kafka.model.listener.LoadBalancerListenerBootstrapOverrideBuilder;
 import io.strimzi.api.kafka.model.listener.LoadBalancerListenerBrokerOverride;
 import io.strimzi.api.kafka.model.listener.LoadBalancerListenerBrokerOverrideBuilder;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.kafkaclients.externalClients.BasicExternalKafkaClient;
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
@@ -48,7 +48,7 @@
 import static org.junit.jupiter.api.Assertions.assertThrows;
 
 @Tag(SPECIFIC)
-public class SpecificST extends BaseST {
+public class SpecificST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(SpecificST.class);
     public static final String NAMESPACE = "specific-cluster-test";

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -10,7 +10,7 @@
 import io.strimzi.api.kafka.model.KafkaConnectResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.KafkaTopic;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
@@ -74,7 +74,7 @@
 @Tag(TRACING)
 @Tag(INTERNAL_CLIENTS_USED)
 @ExtendWith(VertxExtension.class)
-public class TracingST extends BaseST {
+public class TracingST extends AbstractST {
 
     private static final String NAMESPACE = "tracing-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(TracingST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -8,7 +8,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaUser;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
 import io.strimzi.systemtest.logs.TestExecutionWatcher;
@@ -57,7 +57,7 @@
 import static org.junit.jupiter.api.Assumptions.assumeTrue;
 
 @Tag(UPGRADE)
-public class StrimziUpgradeST extends BaseST {
+public class StrimziUpgradeST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(StrimziUpgradeST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.model.KafkaResources;
-import io.strimzi.systemtest.BaseST;
+import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
@@ -33,7 +33,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 
 @Tag(UPGRADE)
-public class ZookeeperUpgradeST extends BaseST {
+public class ZookeeperUpgradeST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(ZookeeperUpgradeST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/AllNamespaceST.java
Patch:
@@ -2,14 +2,15 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest;
+package io.strimzi.systemtest.watcher;
 
 import io.fabric8.kubernetes.api.model.Secret;
 import io.fabric8.kubernetes.api.model.SecretBuilder;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.operator.common.Annotations;
+import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;

File: systemtest/src/test/java/io/strimzi/systemtest/watcher/MultipleNamespaceST.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest;
+package io.strimzi.systemtest.watcher;
 
 import io.strimzi.systemtest.cli.KafkaCmdClient;
 import org.apache.logging.log4j.LogManager;

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/KubeCmdClient.java
Patch:
@@ -100,6 +100,8 @@ default K delete(String... files) {
      */
     ExecResult execInPodContainer(String pod, String container, String... command);
 
+    ExecResult execInPodContainer(boolean logToOutput, String pod, String container, String... command);
+
     /**
      * Execute the given {@code command}.
      * @param command The command

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerConsumerSpec.java
Patch:
@@ -6,9 +6,9 @@
 
 
 import com.fasterxml.jackson.annotation.JsonInclude;
-import io.strimzi.crdgenerator.annotations.DescriptionFile;
 import com.fasterxml.jackson.annotation.JsonProperty;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import io.strimzi.crdgenerator.annotations.DescriptionFile;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.strimzi.crdgenerator.annotations.Minimum;
 import io.sundr.builder.annotations.Buildable;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -14,6 +14,7 @@
 import io.strimzi.api.kafka.model.template.KafkaMirrorMakerTemplate;
 import io.strimzi.api.kafka.model.tracing.Tracing;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.DescriptionFile;
 import io.strimzi.crdgenerator.annotations.KubeLink;
 import io.strimzi.crdgenerator.annotations.Minimum;
 import io.sundr.builder.annotations.Buildable;
@@ -24,6 +25,7 @@
 import java.util.List;
 import java.util.Map;
 
+@DescriptionFile
 @Buildable(
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -435,7 +435,7 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {
     public ConfigMap generateMetricsAndLogConfigMap(ConfigMap externalConfigMap) {
         Map<String, String> data = new HashMap<>(2);
         data.put(getAncillaryConfigMapKeyLogConfig(), parseLogging(getLogging(), externalConfigMap));
-        if (isMetricsEnabled()) {
+        if (isMetricsEnabled() && getMetricsConfig() != null) {
             HashMap<String, Object> m = new HashMap<>();
             for (Map.Entry<String, Object> entry : getMetricsConfig()) {
                 m.put(entry.getKey(), entry.getValue());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -522,7 +522,7 @@ public static KafkaMirrorMaker createKafkaMirrorMakerCluster(String clusterCmNam
                 .build();
     }
 
-    public static KafkaBridge createKafkaBridgeCluster(String clusterCmNamespace, String clusterCmName, String image, int replicas, String bootstrapservers, KafkaBridgeProducerSpec producer, KafkaBridgeConsumerSpec consumer, KafkaBridgeHttpConfig http, Map<String, Object> metricsCm) {
+    public static KafkaBridge createKafkaBridgeCluster(String clusterCmNamespace, String clusterCmName, String image, int replicas, String bootstrapservers, KafkaBridgeProducerSpec producer, KafkaBridgeConsumerSpec consumer, KafkaBridgeHttpConfig http, boolean enableMetrics) {
         return new KafkaBridgeBuilder()
                 .withMetadata(new ObjectMetaBuilder()
                         .withName(clusterCmName)
@@ -536,7 +536,7 @@ public static KafkaBridge createKafkaBridgeCluster(String clusterCmNamespace, St
                     .withBootstrapServers(bootstrapservers)
                     .withProducer(producer)
                     .withConsumer(consumer)
-                    .withMetrics(metricsCm)
+                    .withEnableMetrics(enableMetrics)
                     .withHttp(http)
                 .endSpec()
                 .build();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -36,6 +36,7 @@
 import io.strimzi.api.kafka.model.template.KafkaBridgeTemplate;
 import io.strimzi.api.kafka.model.tracing.Tracing;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.model.Labels;
 import io.vertx.core.json.JsonArray;
 import io.vertx.core.json.JsonObject;
@@ -192,7 +193,7 @@ public static KafkaBridgeCluster fromCrd(KafkaBridge kafkaBridge, KafkaVersion.L
             ModelUtils.parsePodTemplate(kafkaBridgeCluster, template.getPod());
 
             if (template.getApiService() != null && template.getApiService().getMetadata() != null)  {
-                kafkaBridgeCluster.templateServiceLabels = mergeLabelsOrAnnotations(template.getApiService().getMetadata().getLabels(),
+                kafkaBridgeCluster.templateServiceLabels = Util.mergeLabelsOrAnnotations(template.getApiService().getMetadata().getLabels(),
                         ModelUtils.getCustomLabelsOrAnnotations(CO_ENV_VAR_CUSTOM_LABELS));
                 kafkaBridgeCluster.templateServiceAnnotations = template.getApiService().getMetadata().getAnnotations();
             }
@@ -234,7 +235,7 @@ public Service generateService() {
             ports.add(createServicePort(METRICS_PORT_NAME, METRICS_PORT, METRICS_PORT, "TCP"));
         }
 
-        return createDiscoverableService("ClusterIP", ports, mergeLabelsOrAnnotations(getDiscoveryAnnotation(port), templateServiceAnnotations, ModelUtils.getCustomLabelsOrAnnotations(CO_ENV_VAR_CUSTOM_ANNOTATIONS)));
+        return createDiscoverableService("ClusterIP", ports, Util.mergeLabelsOrAnnotations(getDiscoveryAnnotation(port), templateServiceAnnotations, ModelUtils.getCustomLabelsOrAnnotations(CO_ENV_VAR_CUSTOM_ANNOTATIONS)));
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -53,6 +53,7 @@
 import io.strimzi.api.kafka.model.connect.ExternalConfigurationVolumeSource;
 import io.strimzi.api.kafka.model.template.KafkaConnectTemplate;
 import io.strimzi.api.kafka.model.tracing.Tracing;
+import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.model.Labels;
 
 import java.util.ArrayList;
@@ -289,7 +290,7 @@ public Service generateService() {
             ports.add(createServicePort(METRICS_PORT_NAME, METRICS_PORT, METRICS_PORT, "TCP"));
         }
 
-        return createService("ClusterIP", ports, mergeLabelsOrAnnotations(prometheusAnnotations(), templateServiceAnnotations));
+        return createService("ClusterIP", ports, Util.mergeLabelsOrAnnotations(prometheusAnnotations(), templateServiceAnnotations));
     }
 
     protected List<ContainerPort> getContainerPortList() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -31,6 +31,7 @@
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaConnectS2IResources;
 import io.strimzi.api.kafka.model.KafkaConnectS2ISpec;
+import io.strimzi.operator.common.Util;
 
 import java.util.List;
 import java.util.Map;
@@ -119,7 +120,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                 .withNewMetadata()
                     .withName(name)
                     .withLabels(getLabelsWithStrimziName(name, templateDeploymentLabels).toMap())
-                    .withAnnotations(mergeLabelsOrAnnotations(null, templateDeploymentAnnotations))
+                    .withAnnotations(Util.mergeLabelsOrAnnotations(null, templateDeploymentAnnotations))
                     .withNamespace(namespace)
                     .withOwnerReferences(createOwnerReference())
                 .endMetadata()
@@ -128,7 +129,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                     .withSelector(getSelectorLabels().toMap())
                     .withNewTemplate()
                         .withNewMetadata()
-                            .withAnnotations(mergeLabelsOrAnnotations(annotations, templatePodAnnotations))
+                            .withAnnotations(Util.mergeLabelsOrAnnotations(annotations, templatePodAnnotations))
                             .withLabels(getLabelsWithStrimziName(name, templatePodLabels).toMap())
                         .endMetadata()
                         .withNewSpec()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaExporter.java
Patch:
@@ -27,6 +27,7 @@
 import io.strimzi.api.kafka.model.ProbeBuilder;
 import io.strimzi.api.kafka.model.template.KafkaExporterTemplate;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
+import io.strimzi.operator.common.Util;
 
 import java.util.ArrayList;
 import java.util.Collections;
@@ -162,7 +163,7 @@ public Service generateService() {
         List<ServicePort> ports = new ArrayList<>(1);
 
         ports.add(createServicePort(METRICS_PORT_NAME, METRICS_PORT, METRICS_PORT, "TCP"));
-        return createService("ClusterIP", ports, mergeLabelsOrAnnotations(prometheusAnnotations(), templateServiceAnnotations));
+        return createService("ClusterIP", ports, Util.mergeLabelsOrAnnotations(prometheusAnnotations(), templateServiceAnnotations));
     }
 
     protected List<ContainerPort> getContainerPortList() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -45,6 +45,7 @@
 import io.strimzi.api.kafka.model.storage.Storage;
 import io.strimzi.api.kafka.model.template.ZookeeperClusterTemplate;
 import io.strimzi.certs.CertAndKey;
+import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.operator.resource.StatusUtils;
 
@@ -298,7 +299,7 @@ public static ZookeeperCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup
             }
 
             if (template.getPersistentVolumeClaim() != null && template.getPersistentVolumeClaim().getMetadata() != null) {
-                zk.templatePersistentVolumeClaimLabels = mergeLabelsOrAnnotations(template.getPersistentVolumeClaim().getMetadata().getLabels(),
+                zk.templatePersistentVolumeClaimLabels = Util.mergeLabelsOrAnnotations(template.getPersistentVolumeClaim().getMetadata().getLabels(),
                         zk.templateStatefulSetLabels);
                 zk.templatePersistentVolumeClaimAnnotations = template.getPersistentVolumeClaim().getMetadata().getAnnotations();
             }
@@ -356,7 +357,7 @@ public Service generateService() {
         }
         ports.add(createServicePort(CLIENT_TLS_PORT_NAME, CLIENT_TLS_PORT, CLIENT_TLS_PORT, "TCP"));
 
-        return createService("ClusterIP", ports, mergeLabelsOrAnnotations(prometheusAnnotations(), templateServiceAnnotations));
+        return createService("ClusterIP", ports, Util.mergeLabelsOrAnnotations(prometheusAnnotations(), templateServiceAnnotations));
     }
 
     public static String policyName(String cluster) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -74,6 +74,7 @@
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.PasswordGenerator;
+import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.test.TestUtils;
 import org.junit.jupiter.api.Test;
@@ -206,7 +207,7 @@ public void testGenerateService() {
         assertThat(headful.getSpec().getPorts().get(3).getPort(), is(new Integer(KafkaCluster.METRICS_PORT)));
         assertThat(headful.getSpec().getPorts().get(3).getProtocol(), is("TCP"));
 
-        assertThat(headful.getMetadata().getAnnotations(), is(AbstractModel.mergeLabelsOrAnnotations(kc.getInternalDiscoveryAnnotation(), kc.prometheusAnnotations())));
+        assertThat(headful.getMetadata().getAnnotations(), is(Util.mergeLabelsOrAnnotations(kc.getInternalDiscoveryAnnotation(), kc.prometheusAnnotations())));
 
         assertThat(headful.getMetadata().getLabels().containsKey(Labels.STRIMZI_DISCOVERY_LABEL), is(true));
         assertThat(headful.getMetadata().getLabels().get(Labels.STRIMZI_DISCOVERY_LABEL), is("true"));

File: systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java
Patch:
@@ -43,7 +43,7 @@ public static void waitUntilClientReceivedMessagesTls(KafkaClientOperations kafk
     }
 
     public static void waitTillContinuousClientsFinish(String producerName, String consumerName, String namespace, int messageCount) {
-        long timeout = (long) (messageCount / 2) * 1000;
+        long timeout = (long) messageCount * 1000;
         LOGGER.info("Waiting till producer {} and consumer {} finish for the following {} ms", producerName, consumerName, timeout);
         TestUtils.waitFor("continuous clients finished", Constants.GLOBAL_POLL_INTERVAL, timeout,
             () -> kubeClient().getClient().batch().jobs().inNamespace(namespace).withName(producerName).get().getStatus().getSucceeded().equals(1) &&

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/AlternativeReconcileTriggersST.java
Patch:
@@ -41,7 +41,6 @@
 @Tag(REGRESSION)
 @Tag(INTERNAL_CLIENTS_USED)
 class AlternativeReconcileTriggersST extends BaseST {
-
     private static final Logger LOGGER = LogManager.getLogger(RollingUpdateST.class);
 
     static final String NAMESPACE = "alternative-reconcile-triggers-cluster-test";
@@ -68,7 +67,7 @@ void testManualTriggeringRollingUpdate() {
         // ##############################
         // Setup topic, which has 3 replicas and 2 min.isr to see if producer will be able to work during rolling update
         KafkaTopicResource.topic(CLUSTER_NAME, continuousTopicName, 3, 3, 2).done();
-        String producerAdditionConfiguration = "delivery.timeout.ms=10000\nrequest.timeout.ms=10000";
+        String producerAdditionConfiguration = "delivery.timeout.ms=20000\nrequest.timeout.ms=20000";
         KafkaClientsResource.producerStrimzi(producerName, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), continuousTopicName, continuousClientsMessageCount, producerAdditionConfiguration).done();
         KafkaClientsResource.consumerStrimzi(consumerName, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), continuousTopicName, continuousClientsMessageCount).done();
         // ##############################

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -267,7 +267,7 @@ private void performUpgrade(JsonObject testParameters, int produceMessagesCount,
                 // Add continuous topic to expectedTopicCunt which will be check after upgrade procedures
                 expectedTopicCount += 1;
             }
-            String producerAdditionConfiguration = "delivery.timeout.ms=10000\nrequest.timeout.ms=10000";
+            String producerAdditionConfiguration = "delivery.timeout.ms=20000\nrequest.timeout.ms=20000";
             KafkaClientsResource.producerStrimzi(producerName, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), continuousTopicName, continuousClientsMessageCount, producerAdditionConfiguration).done();
             KafkaClientsResource.consumerStrimzi(consumerName, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), continuousTopicName, continuousClientsMessageCount, "", continuousConsumerGroup).done();
             // ##############################

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java
Patch:
@@ -109,7 +109,7 @@ void runVersionChange(TestKafkaVersion initialVersion, TestKafkaVersion newVersi
             // ##############################
             // Setup topic, which has 3 replicas and 2 min.isr to see if producer will be able to work during rolling update
             KafkaTopicResource.topic(CLUSTER_NAME, continuousTopicName, 3, 3, 2).done();
-            String producerAdditionConfiguration = "delivery.timeout.ms=10000\nrequest.timeout.ms=10000";
+            String producerAdditionConfiguration = "delivery.timeout.ms=20000\nrequest.timeout.ms=20000";
             KafkaClientsResource.producerStrimzi(producerName, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), continuousTopicName, continuousClientsMessageCount, producerAdditionConfiguration).done();
             KafkaClientsResource.consumerStrimzi(consumerName, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), continuousTopicName, continuousClientsMessageCount).done();
             // ##############################

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -1203,7 +1203,7 @@ protected String determineImagePullPolicy(ImagePullPolicy requestedImagePullPoli
         }
     }
 
-    String getAncillaryConfigMapKeyLogConfig() {
+    public String getAncillaryConfigMapKeyLogConfig() {
         return ANCILLARY_CM_KEY_LOG_CONFIG;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -183,7 +183,7 @@ protected String getDefaultLogConfigFileName() {
     }
 
     @Override
-    String getAncillaryConfigMapKeyLogConfig() {
+    public String getAncillaryConfigMapKeyLogConfig() {
         return "log4j2.properties";
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -188,7 +188,7 @@ protected String getDefaultLogConfigFileName() {
     }
 
     @Override
-    String getAncillaryConfigMapKeyLogConfig() {
+    public String getAncillaryConfigMapKeyLogConfig() {
         return "log4j2.properties";
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -2819,12 +2819,12 @@ private final Future<ReconciliationState> getEntityOperatorDescription() {
 
                             if (topicOperator != null)  {
                                 this.topicOperatorMetricsAndLogsConfigMap = topicOperator.generateMetricsAndLogConfigMap(toCm);
-                                configAnnotation += this.topicOperatorMetricsAndLogsConfigMap.getData().get("log4j2.properties");
+                                configAnnotation += this.topicOperatorMetricsAndLogsConfigMap.getData().get(topicOperator.getAncillaryConfigMapKeyLogConfig());
                             }
 
                             if (userOperator != null)   {
                                 this.userOperatorMetricsAndLogsConfigMap = userOperator.generateMetricsAndLogConfigMap(uoCm);
-                                configAnnotation += this.userOperatorMetricsAndLogsConfigMap.getData().get("log4j2.properties");
+                                configAnnotation += this.userOperatorMetricsAndLogsConfigMap.getData().get(userOperator.getAncillaryConfigMapKeyLogConfig());
                             }
 
                             Map<String, String> annotations = new HashMap<>(1);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -90,7 +90,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge
                 null);
 
         Map<String, String> annotations = new HashMap<>(1);
-        annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(bridge.ANCILLARY_CM_KEY_LOG_CONFIG));
+        annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(bridge.getAncillaryConfigMapKeyLogConfig()));
 
         boolean bridgeHasZeroReplicas = bridge.getReplicas() == 0;
         log.debug("{}: Updating Kafka Bridge cluster", reconciliation);

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlIsolatedST.java
Patch:
@@ -20,6 +20,7 @@
 
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.CRUISE_CONTROL;
+import static io.strimzi.systemtest.Constants.FLAKY;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -68,6 +69,7 @@ void testAutoCreationOfCruiseControlTopics() {
 
     @Test
     @Tag(ACCEPTANCE)
+    @Tag(FLAKY)
     void testCruiseControlWithRebalanceResource() {
         KafkaResource.kafkaWithCruiseControl(CLUSTER_NAME, 3, 3).done();
         KafkaRebalanceResource.kafkaRebalance(CLUSTER_NAME).done();

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -36,6 +36,7 @@
 import java.util.concurrent.ExecutionException;
 import java.util.regex.Pattern;
 
+import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.METRICS;
 import static io.strimzi.systemtest.Constants.REGRESSION;
@@ -48,6 +49,7 @@
 import static org.hamcrest.Matchers.notNullValue;
 
 @Tag(REGRESSION)
+@Tag(ACCEPTANCE)
 @Tag(METRICS)
 public class MetricsST extends BaseST {
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -92,7 +92,7 @@ private static DeploymentBuilder defaultCLusterOperator(String namespace, long o
                     break;
                 default:
                     if (envVar.getName().contains("KAFKA_BRIDGE_IMAGE")) {
-                        envVar.setValue(Environment.BRIDGE_IMAGE);
+                        envVar.setValue(Environment.useLatestReleasedBridge() ? envVar.getValue() : Environment.BRIDGE_IMAGE);
                     } else if (envVar.getName().contains("STRIMZI_DEFAULT")) {
                         envVar.setValue(StUtils.changeOrgAndTag(envVar.getValue()));
                     } else if (envVar.getName().contains("IMAGES")) {

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -114,7 +114,7 @@ void testKafkaStatus() {
         });
 
         LOGGER.info("Wait until cluster will be in NotReady state ...");
-        KafkaUtils.waitForKafkaReady(CLUSTER_NAME);
+        KafkaUtils.waitForKafkaNotReady(CLUSTER_NAME);
 
         LOGGER.info("Recovery cluster to Ready state ...");
         KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -171,7 +171,7 @@ void testDeployUnsupportedKafka() {
 
         LOGGER.info("Kafka with version {} deployed.", nonExistingVersion);
 
-        KafkaUtils.waitForKafkaReady(CLUSTER_NAME);
+        KafkaUtils.waitForKafkaNotReady(CLUSTER_NAME);
         KafkaUtils.waitUntilKafkaStatusConditionContainsMessage(CLUSTER_NAME, NAMESPACE, nonExistingVersionMessage);
 
         KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).delete();

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/MetricsUtils.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2Resources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.test.executor.Exec;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -91,7 +92,7 @@ public static HashMap<String, String> collectTopicOperatorPodMetrics(String clus
     }
 
     public static HashMap<String, String> collectClusterOperatorPodMetrics() {
-        LabelSelector coSelector = kubeClient().getDeploymentSelectors(Constants.STRIMZI_DEPLOYMENT_NAME);
+        LabelSelector coSelector = kubeClient().getDeploymentSelectors(ResourceManager.getCoDeploymentName());
         return collectMetricsFromPods(coSelector, Constants.CLUSTER_OPERATOR_METRICS_PORT, "/metrics");
     }
 

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -153,6 +153,7 @@ public static String indent(String s) {
 
     public static String getFileAsString(String filePath) {
         try {
+            LOGGER.info(filePath);
             return new String(Files.readAllBytes(Paths.get(filePath)), "UTF-8");
         } catch (IOException e) {
             LOGGER.info("File with path {} not found", filePath);
@@ -458,4 +459,4 @@ public static <T> T doRequestTillSuccess(int retry, Callable<T> fn, Optional<Run
             }
         }
     }
-}
\ No newline at end of file
+}

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/KubeCmdClient.java
Patch:
@@ -23,6 +23,7 @@
 public interface KubeCmdClient<K extends KubeCmdClient<K>> {
 
     String defaultNamespace();
+    String defaultOlmNamespace();
 
     /** Deletes the resources by resource name. */
     K deleteByName(String resourceType, String resourceName);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -417,7 +417,7 @@ public static <T extends HasMetadata & HasStatus> T waitForResourceStatus(MixedO
         LOGGER.info("Wait for {}: {} will have desired state: {}", resource.getKind(), resource.getMetadata().getName(), status);
 
         TestUtils.waitFor(String.format("Wait for %s: %s will have desired state: %s", resource.getKind(), resource.getMetadata().getName(), status),
-            Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+            Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, resourceTimeout,
             () -> operation.inNamespace(resource.getMetadata().getNamespace())
                     .withName(resource.getMetadata().getName())
                     .get().getStatus().getConditions().stream().anyMatch(condition -> condition.getType().equals(status)),
@@ -428,7 +428,8 @@ public static <T extends HasMetadata & HasStatus> T waitForResourceStatus(MixedO
     }
 
     public static <T extends HasMetadata & HasStatus> T waitForResourceStatus(MixedOperation<T, ?, ?, ?> operation, T resource, String status) {
-        return waitForResourceStatus(operation, resource, status, Constants.TIMEOUT_FOR_RESOURCE_READINESS);
+        long resourceTimeout = ResourceOperation.getTimeoutForResourceReadiness(resource.getKind());
+        return waitForResourceStatus(operation, resource, status, resourceTimeout);
     }
 
     private static Deployment getDeploymentFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectorUtils.java
Patch:
@@ -7,6 +7,7 @@
 import io.strimzi.api.kafka.model.KafkaConnector;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.systemtest.resources.crd.KafkaConnectorResource;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -18,6 +19,7 @@
 public class KafkaConnectorUtils {
 
     private static final Logger LOGGER = LogManager.getLogger(KafkaConnectorUtils.class);
+    private static final long READINESS_TIMEOUT = ResourceOperation.getTimeoutForResourceReadiness(KafkaConnector.RESOURCE_KIND);
 
     private KafkaConnectorUtils() {}
 
@@ -70,7 +72,7 @@ public static String getCreatedConnectors(String connectPodName) {
     }
 
     public static void waitForConnectorCreation(String connectS2IPodName, String connectorName) {
-        TestUtils.waitFor(connectorName + " connector creation", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT, () -> {
+        TestUtils.waitFor(connectorName + " connector creation", Constants.GLOBAL_POLL_INTERVAL, READINESS_TIMEOUT, () -> {
             String availableConnectors = getCreatedConnectors(connectS2IPodName);
             return availableConnectors.contains(connectorName);
         }, () -> ResourceManager.logCurrentResourceStatus(KafkaConnectorResource.kafkaConnectorClient().inNamespace(kubeClient().getNamespace()).withName(connectorName).get()));

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/DeploymentConfigUtils.java
Patch:
@@ -7,6 +7,7 @@
 import io.fabric8.kubernetes.api.model.LabelSelector;
 import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -21,6 +22,7 @@
 public class DeploymentConfigUtils {
 
     private static final Logger LOGGER = LogManager.getLogger(DeploymentConfigUtils.class);
+    private static final long READINESS_TIMEOUT = ResourceOperation.getTimeoutForResourceReadiness(Constants.DEPLOYMENT_CONFIG);
 
     /**
      * Returns a map of pod name to resource version for the pods currently in the given DeploymentConfig.
@@ -110,7 +112,7 @@ public static void waitForDeploymentConfigReady(String depConfigName) {
         LOGGER.info("Wait for DeploymentConfig: {} will be ready", depConfigName);
 
         TestUtils.waitFor(String.format("Wait for DeploymentConfig: %s will be ready", depConfigName),
-            Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+            Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, READINESS_TIMEOUT,
             () -> kubeClient().getDeploymentConfigStatus(depConfigName),
             () -> {
                 if (kubeClient().getDeploymentConfig(depConfigName) != null) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/DeploymentUtils.java
Patch:
@@ -10,6 +10,7 @@
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.apps.DeploymentCondition;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -27,6 +28,7 @@
 public class DeploymentUtils {
 
     private static final Logger LOGGER = LogManager.getLogger(DeploymentUtils.class);
+    private static final long READINESS_TIMEOUT = ResourceOperation.getTimeoutForResourceReadiness(Constants.DEPLOYMENT);
 
     private DeploymentUtils() { }
 
@@ -148,7 +150,7 @@ public static void waitForDeploymentReady(String deploymentName) {
         LOGGER.info("Wait for Deployment: {} will be ready", deploymentName);
 
         TestUtils.waitFor(String.format("Wait for Deployment: %s will be ready", deploymentName),
-            Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+            Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, READINESS_TIMEOUT,
             () -> kubeClient().getDeploymentStatus(deploymentName),
             () -> DeploymentUtils.logCurrentDeploymentStatus(kubeClient().getDeployment(deploymentName)));
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/StatefulSetUtils.java
Patch:
@@ -9,6 +9,7 @@
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
@@ -24,6 +25,7 @@
 public class StatefulSetUtils {
 
     private static final Logger LOGGER = LogManager.getLogger(StatefulSetUtils.class);
+    private static final long READINESS_TIMEOUT = ResourceOperation.getTimeoutForResourceReadiness(Constants.STATEFUL_SET);
 
     private StatefulSetUtils() { }
 
@@ -135,7 +137,7 @@ public static void waitForAllStatefulSetPodsReady(String statefulSetName, int ex
         String resourceName = statefulSetName.contains("-kafka") ? statefulSetName.replace("-kafka", "") : statefulSetName.replace("-zookeeper", "");
 
         LOGGER.info("Waiting for StatefulSet {} to be ready", statefulSetName);
-        TestUtils.waitFor("StatefulSet " + statefulSetName + " to be ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("StatefulSet " + statefulSetName + " to be ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, READINESS_TIMEOUT,
             () -> kubeClient().getStatefulSetStatus(statefulSetName),
             () -> ResourceManager.logCurrentResourceStatus(KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(resourceName).get()));
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/SecretUtils.java
Patch:
@@ -8,6 +8,7 @@
 import io.fabric8.kubernetes.api.model.SecretBuilder;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.resources.ResourceOperation;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -28,6 +29,7 @@
 public class SecretUtils {
 
     private static final Logger LOGGER = LogManager.getLogger(SecretUtils.class);
+    private static final long READINESS_TIMEOUT = ResourceOperation.getTimeoutForResourceReadiness(Constants.SECRET);
 
     private SecretUtils() { }
 
@@ -37,7 +39,7 @@ public static void waitForSecretReady(String secretName) {
 
     public static void waitForSecretReady(String secretName, Runnable onTimeout) {
         LOGGER.info("Waiting for Secret {}", secretName);
-        TestUtils.waitFor("Expected secret " + secretName + " exists", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_SECRET_CREATION,
+        TestUtils.waitFor("Expected secret " + secretName + " exists", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, READINESS_TIMEOUT,
             () -> kubeClient().getSecret(secretName) != null,
             onTimeout);
         LOGGER.info("Secret {} created", secretName);

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlApiST.java
Patch:
@@ -77,7 +77,8 @@ void testRebalance() {
         assertThat(response, containsString("DiskCapacityGoal"));
         assertThat(response, containsString("NetworkInboundCapacityGoal"));
         assertThat(response, containsString("NetworkOutboundCapacityGoal"));
-        assertThat(response, containsString("CpuCapacityGoal"));
+        // TODO: This Goal is currently not working properly on Kubernetes. It will be added in once this issue is fixed: https://github.com/linkedin/cruise-control/issues/1242
+        //assertThat(response, containsString("CpuCapacityGoal"));
         assertThat(response, containsString("ReplicaDistributionGoal"));
         assertThat(response, containsString("DiskUsageDistributionGoal"));
         assertThat(response, containsString("NetworkInboundUsageDistributionGoal"));

File: crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java
Patch:
@@ -63,7 +63,7 @@
  * <p>The tool works by recursing through class properties (in the JavaBeans sense)
  * and the types of those properties, guided by the annotations.</p>
  *
- * <h3>Annotations</h3>
+ * <h2>Annotations</h2>
  * <dl>
  *     <dt>@{@link Crd}</dt>
  *     <dd>Annotates the top level class which represents an instance of the custom resource.
@@ -121,7 +121,7 @@
  *
  * </dl>
  *
- * <h3>Polymorphism</h3>
+ * <h2>Polymorphism</h2>
  * <p>Although true OpenAPI Schema Objects have some support for polymorphism via
  * {@code discriminator} and {@code oneOf}, CRD validation schemas don't support
  * {@code discriminator} or references which means CRD validation

File: api/src/main/java/io/strimzi/api/kafka/model/status/KafkaRebalanceStatus.java
Patch:
@@ -29,8 +29,6 @@
 @ToString(callSuper = true)
 public class KafkaRebalanceStatus extends Status {
 
-    public static final String REBALANCE_STATUS_CONDITION_TYPE = "State";
-
     private static final long serialVersionUID = 1L;
 
     private String sessionId;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaRebalanceAssemblyOperatorTest.java
Patch:
@@ -939,7 +939,7 @@ private void assertState(KafkaRebalance kafkaRebalance, KafkaRebalanceAssemblyOp
         assertThat(kafkaRebalance.getStatus().getConditions(), notNullValue());
         Condition stateCondition = kcrao.rebalanceStateCondition(kafkaRebalance.getStatus());
         assertThat(stateCondition, notNullValue());
-        assertThat(stateCondition.getStatus(), is(state.toString()));
+        assertThat(stateCondition.getType(), is(state.toString()));
     }
 
     private void assertState(KafkaRebalance kafkaRebalance, KafkaRebalanceAssemblyOperator.State state,

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.systemtest;
 
-import io.strimzi.api.kafka.model.KafkaMirrorMakerResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
@@ -15,7 +14,7 @@
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
-import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -66,7 +65,7 @@ void checkMirrorMakerForKafkaInDifNamespaceThanCO(String sourceClusterName) {
         KafkaMirrorMakerResource.kafkaMirrorMaker(CLUSTER_NAME, kafkaSourceName, kafkaTargetName, "my-group", 1, false).done();
 
         LOGGER.info("Waiting for creation {} in namespace {}", CLUSTER_NAME + "-mirror-maker", SECOND_NAMESPACE);
-        DeploymentUtils.waitForDeploymentAndPodsReady(KafkaMirrorMakerResources.deploymentName(CLUSTER_NAME), 1);
+        KafkaMirrorMakerUtils.waitForKafkaMirrorMakerReady(CLUSTER_NAME);
         cluster.setNamespace(previousNamespace);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -35,6 +35,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentConfigUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
@@ -688,7 +689,7 @@ void testKafkaConnectorWithConnectAndConnectS2IWithSameName() {
         KafkaConnectS2IUtils.waitForConnectS2INotReady(CLUSTER_NAME);
 
         KafkaConnectS2IResource.kafkaConnectS2IClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).delete();
-        DeploymentUtils.waitForDeploymentConfigDeletion(KafkaConnectS2IResources.deploymentName(CLUSTER_NAME));
+        DeploymentConfigUtils.waitForDeploymentConfigDeletion(KafkaConnectS2IResources.deploymentName(CLUSTER_NAME));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/rollingupdate/RollingUpdateST.java
Patch:
@@ -604,7 +604,7 @@ void testTriggerRollingUpdateAfterOverrideBootstrap() throws CertificateExceptio
         });
 
         StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaPods);
-        KafkaUtils.waitUntilKafkaCRIsReady(CLUSTER_NAME);
+        KafkaUtils.waitForKafkaReady(CLUSTER_NAME);
 
         String bootstrapAddressDns = ((KafkaListenerExternalNodePort) Crds.kafkaOperation(kubeClient().getClient())
                 .inNamespace(kubeClient().getNamespace()).withName(CLUSTER_NAME).get().getSpec().getKafka()

File: systemtest/src/test/java/io/strimzi/systemtest/topic/TopicST.java
Patch:
@@ -152,7 +152,7 @@ void testCreateTopicViaAdminClient() throws ExecutionException, InterruptedExcep
 
         LOGGER.info("Verify that corresponding {} KafkaTopic custom resources were created and topic is in Ready state", 1);
         KafkaTopicUtils.waitForKafkaTopicCreation(TOPIC_NAME);
-        KafkaTopicUtils.waitForKafkaTopicStatus(TOPIC_NAME, "Ready");
+        KafkaTopicUtils.waitForKafkaTopicReady(TOPIC_NAME);
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/topic/TopicScalabilityST.java
Patch:
@@ -44,7 +44,7 @@ void testBigAmountOfTopicsCreatingViaK8s() {
             String currentTopic = topicName + i;
             LOGGER.debug("Verifying that {} topic CR has Ready status", currentTopic);
 
-            KafkaTopicUtils.waitForKafkaTopicStatus(currentTopic, "Ready");
+            KafkaTopicUtils.waitForKafkaTopicReady(currentTopic);
         }
 
         LOGGER.info("Verifying that we created {} topics", NUMBER_OF_TOPICS);

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -48,7 +48,7 @@
                         @Crd.Spec.Version(name = Kafka.V1ALPHA1, served = true, storage = false)
                 },
                 subresources = @Crd.Spec.Subresources(
-                               status = @Crd.Spec.Subresources.Status()
+                        status = @Crd.Spec.Subresources.Status()
                 ),
                 additionalPrinterColumns = {
                         @Crd.Spec.AdditionalPrinterColumn(

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -180,6 +180,8 @@ public void testCreateOrUpdateCreatesCluster(VertxTestContext context) {
                 // Verify status
                 List<KafkaBridge> capturedStatuses = bridgeCaptor.getAllValues();
                 assertThat(capturedStatuses.get(0).getStatus().getUrl(), is("http://foo-bridge-service.test.svc:8080"));
+                assertThat(capturedStatuses.get(0).getStatus().getReplicas(), is(bridge.getReplicas()));
+                assertThat(capturedStatuses.get(0).getStatus().getPodSelector().getMatchLabels(), is(bridge.getSelectorLabels().toMap()));
                 assertThat(capturedStatuses.get(0).getStatus().getConditions().get(0).getStatus(), is("True"));
                 assertThat(capturedStatuses.get(0).getStatus().getConditions().get(0).getType(), is("Ready"));
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -223,6 +223,7 @@ private void assertConnectorIsRunning(VertxTestContext context, KubernetesClient
             KafkaConnector kafkaConnector = Crds.kafkaConnectorOperation(client).inNamespace(namespace).withName(connectorName).get();
             assertThat(kafkaConnector, notNullValue());
             assertThat(kafkaConnector.getStatus(), notNullValue());
+            assertThat(kafkaConnector.getStatus().getTasksMax(), is(1));
             assertThat(kafkaConnector.getStatus().getConnectorStatus(), notNullValue());
             assertThat(kafkaConnector.getStatus().getConnectorStatus().get("connector"), instanceOf(Map.class));
             assertThat(((Map) kafkaConnector.getStatus().getConnectorStatus().get("connector")).get("state"), is("RUNNING"));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorTest.java
Patch:
@@ -167,6 +167,8 @@ public void testCreateCluster(VertxTestContext context) {
                 // Verify status
                 List<KafkaMirrorMaker2> capturedMirrorMaker2s = mirrorMaker2Captor.getAllValues();
                 assertThat(capturedMirrorMaker2s.get(0).getStatus().getUrl(), is("http://foo-mirrormaker2-api.test.svc:8083"));
+                assertThat(capturedMirrorMaker2s.get(0).getStatus().getReplicas(), is(mirrorMaker2.getReplicas()));
+                assertThat(capturedMirrorMaker2s.get(0).getStatus().getPodSelector().getMatchLabels(), is(mirrorMaker2.getSelectorLabels().toMap()));
                 assertThat(capturedMirrorMaker2s.get(0).getStatus().getConditions().get(0).getStatus(), is("True"));
                 assertThat(capturedMirrorMaker2s.get(0).getStatus().getConditions().get(0).getType(), is("Ready"));
                 async.flag();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -173,6 +173,8 @@ public void testCreateCluster(VertxTestContext context) {
                 List<KafkaMirrorMaker> capturedMM = statusCaptor.getAllValues();
                 assertThat(capturedMM, hasSize(1));
                 KafkaMirrorMaker mm = capturedMM.get(0);
+                assertThat(mm.getStatus().getReplicas(), is(mirror.getReplicas()));
+                assertThat(mm.getStatus().getPodSelector().getMatchLabels(), is(mirror.getSelectorLabels().toMap()));
                 assertThat(mm.getStatus().getConditions().get(0).getType(), is("Ready"));
                 assertThat(mm.getStatus().getConditions().get(0).getStatus(), is("True"));
 

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlIsolatedST.java
Patch:
@@ -24,6 +24,7 @@
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.Test;
 
+import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.CRUISE_CONTROL;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.resources.ResourceManager.cmdKubeClient;
@@ -85,6 +86,7 @@ void testManuallyCreateMetricsReporterTopic() {
     }
 
     @Test
+    @Tag(ACCEPTANCE)
     void testCruiseControlWithRebalanceResource() {
         KafkaResource.kafkaWithCruiseControl(CLUSTER_NAME, 3, 3).done();
         KafkaRebalanceResource.kafkaRebalance(CLUSTER_NAME).done();

File: test/src/main/java/io/strimzi/test/k8s/cluster/KubeCluster.java
Patch:
@@ -56,6 +56,9 @@ static KubeCluster bootstrap() throws NoClusterException {
                 case "minikube":
                     clusters = new KubeCluster[]{new Minikube()};
                     break;
+                case "kubernetes":
+                    clusters = new KubeCluster[]{new Kubernetes()};
+                    break;
                 case "minishift":
                     clusters = new KubeCluster[]{new Minishift()};
                     break;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -418,8 +418,8 @@ public static <T extends HasMetadata & HasStatus> T waitForResourceStatus(MixedO
         TestUtils.waitFor(String.format("Wait for %s: %s will have desired state: %s", resource.getKind(), resource.getMetadata().getName(), status),
             Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> operation.inNamespace(resource.getMetadata().getNamespace())
-            .withName(resource.getMetadata().getName())
-            .get().getStatus().getConditions().stream().anyMatch(condition -> condition.getType().equals(status)),
+                    .withName(resource.getMetadata().getName())
+                    .get().getStatus().getConditions().stream().anyMatch(condition -> condition.getStatus().equals(status)),
             () -> logCurrentResourceStatus(resource));
 
         LOGGER.info("{}:{} is in desired state: {}", resource.getKind(), resource.getMetadata().getName(), status);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -20,7 +20,7 @@
 
 public class KafkaBridgeResource {
 
-    public static final String PATH_TO_KAFKA_BRIDGE_CONFIG = "../examples/kafka-bridge/kafka-bridge.yaml";
+    public static final String PATH_TO_KAFKA_BRIDGE_CONFIG = "../examples/bridge/kafka-bridge.yaml";
 
     public static MixedOperation<KafkaBridge, KafkaBridgeList, DoneableKafkaBridge, Resource<KafkaBridge, DoneableKafkaBridge>> kafkaBridgeClient() {
         return Crds.kafkaBridgeOperation(ResourceManager.kubeClient().getClient());

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -24,7 +24,7 @@
 import java.util.function.Consumer;
 
 public class KafkaConnectResource {
-    public static final String PATH_TO_KAFKA_CONNECT_CONFIG = "../examples/kafka-connect/kafka-connect.yaml";
+    public static final String PATH_TO_KAFKA_CONNECT_CONFIG = "../examples/connect/kafka-connect.yaml";
     public static final String PATH_TO_KAFKA_CONNECT_METRICS_CONFIG = "../examples/metrics/kafka-connect-metrics.yaml";
 
     public static MixedOperation<KafkaConnect, KafkaConnectList, DoneableKafkaConnect, Resource<KafkaConnect, DoneableKafkaConnect>> kafkaConnectClient() {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -24,7 +24,7 @@
 import java.util.function.Consumer;
 
 public class KafkaConnectS2IResource {
-    public static final String PATH_TO_KAFKA_CONNECT_S2I_CONFIG = "../examples/kafka-connect/kafka-connect-s2i.yaml";
+    public static final String PATH_TO_KAFKA_CONNECT_S2I_CONFIG = "../examples/connect/kafka-connect-s2i.yaml";
 
     public static MixedOperation<KafkaConnectS2I, KafkaConnectS2IList, DoneableKafkaConnectS2I, Resource<KafkaConnectS2I, DoneableKafkaConnectS2I>> kafkaConnectS2IClient() {
         return Crds.kafkaConnectS2iOperation(ResourceManager.kubeClient().getClient());

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -20,7 +20,7 @@
 import java.util.function.Consumer;
 
 public class KafkaConnectorResource {
-    public static final String PATH_TO_KAFKA_CONNECTOR_CONFIG = "../examples/connector/source-connector.yaml";
+    public static final String PATH_TO_KAFKA_CONNECTOR_CONFIG = "../examples/connect/source-connector.yaml";
 
     public static MixedOperation<KafkaConnector, KafkaConnectorList, DoneableKafkaConnector, Resource<KafkaConnector, DoneableKafkaConnector>> kafkaConnectorClient() {
         return Crds.kafkaConnectorOperation(ResourceManager.kubeClient().getClient());

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -24,7 +24,7 @@
 import java.util.function.Consumer;
 
 public class KafkaMirrorMaker2Resource {
-    public static final String PATH_TO_KAFKA_MIRROR_MAKER_2_CONFIG = "../examples/kafka-mirror-maker-2/kafka-mirror-maker-2.yaml";
+    public static final String PATH_TO_KAFKA_MIRROR_MAKER_2_CONFIG = "../examples/mirror-maker/kafka-mirror-maker-2.yaml";
     public static final String PATH_TO_KAFKA_MIRROR_MAKER_2_METRICS_CONFIG = "../examples/metrics/kafka-mirror-maker-2-metrics.yaml";
 
     public static MixedOperation<KafkaMirrorMaker2, KafkaMirrorMaker2List, DoneableKafkaMirrorMaker2, Resource<KafkaMirrorMaker2, DoneableKafkaMirrorMaker2>> kafkaMirrorMaker2Client() {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -23,7 +23,7 @@
 import java.util.function.Consumer;
 
 public class KafkaMirrorMakerResource {
-    public static final String PATH_TO_KAFKA_MIRROR_MAKER_CONFIG = "../examples/kafka-mirror-maker/kafka-mirror-maker.yaml";
+    public static final String PATH_TO_KAFKA_MIRROR_MAKER_CONFIG = "../examples/mirror-maker/kafka-mirror-maker.yaml";
 
     public static MixedOperation<KafkaMirrorMaker, KafkaMirrorMakerList, DoneableKafkaMirrorMaker, Resource<KafkaMirrorMaker, DoneableKafkaMirrorMaker>> kafkaMirrorMakerClient() {
         return Crds.mirrorMakerOperation(ResourceManager.kubeClient().getClient());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -78,7 +78,9 @@ public KafkaBrokerConfigurationBuilder withCruiseControl(String clusterName, Cru
             printSectionHeader("Cruise Control configuration");
             writer.println("cruise.control.metrics.topic=strimzi.cruisecontrol.metrics");
             writer.println("cruise.control.metrics.reporter.ssl.endpoint.identification.algorithm=HTTPS");
-            writer.println("cruise.control.metrics.reporter.bootstrap.servers=" + KafkaResources.bootstrapServiceName(clusterName) + ":9091");
+            // using the brokers service because the Admin client, in the Cruise Control metrics reporter, is not able to connect
+            // to the pods behind the bootstrap one when they are not ready during startup.
+            writer.println("cruise.control.metrics.reporter.bootstrap.servers=" + KafkaResources.brokersServiceName(clusterName) + ":9091");
             writer.println("cruise.control.metrics.reporter.security.protocol=SSL");
             writer.println("cruise.control.metrics.reporter.ssl.keystore.type=PKCS12");
             writer.println("cruise.control.metrics.reporter.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12");

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -73,7 +73,7 @@ public void testCruiseControl()  {
         assertThat(configuration, isEquivalent(
                 "cruise.control.metrics.topic=strimzi.cruisecontrol.metrics\n" +
                 "cruise.control.metrics.reporter.ssl.endpoint.identification.algorithm=HTTPS\n" +
-                "cruise.control.metrics.reporter.bootstrap.servers=my-cluster-kafka-bootstrap:9091\n" +
+                "cruise.control.metrics.reporter.bootstrap.servers=my-cluster-kafka-brokers:9091\n" +
                 "cruise.control.metrics.reporter.security.protocol=SSL\n" +
                 "cruise.control.metrics.reporter.ssl.keystore.type=PKCS12\n" +
                 "cruise.control.metrics.reporter.ssl.keystore.location=/tmp/kafka/cluster.keystore.p12\n" +

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/CruiseControlUtils.java
Patch:
@@ -69,7 +69,7 @@ public static void verifyCruiseControlMetricReporterConfigurationInKafkaConfigMa
             Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_CRUISE_CONTROL_TIMEOUT, () ->
             kafkaProperties.getProperty("cruise.control.metrics.topic").equals("strimzi.cruisecontrol.metrics") &&
             kafkaProperties.getProperty("cruise.control.metrics.reporter.ssl.endpoint.identification.algorithm").equals("HTTPS") &&
-            kafkaProperties.getProperty("cruise.control.metrics.reporter.bootstrap.servers").equals("my-cluster-kafka-bootstrap:9091") &&
+            kafkaProperties.getProperty("cruise.control.metrics.reporter.bootstrap.servers").equals("my-cluster-kafka-brokers:9091") &&
             kafkaProperties.getProperty("cruise.control.metrics.reporter.security.protocol").equals("SSL") &&
             kafkaProperties.getProperty("cruise.control.metrics.reporter.ssl.keystore.type").equals("PKCS12") &&
             kafkaProperties.getProperty("cruise.control.metrics.reporter.ssl.keystore.location").equals("/tmp/kafka/cluster.keystore.p12") &&

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlIsolatedST.java
Patch:
@@ -18,6 +18,7 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.Test;
 
@@ -39,6 +40,7 @@ public class CruiseControlIsolatedST extends BaseST {
 
 
     @Test
+    @Disabled
     void testManuallyCreateMetricsReporterTopic() {
         KafkaResource.kafkaWithCruiseControlWithoutWaitAutoCreateTopicsDisable(CLUSTER_NAME, 3, 3);
 

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -986,7 +986,7 @@ void testRemoveUserAndTopicOperatorsFromEntityOperator() {
             k.getSpec().getEntityOperator().setUserOperator(null);
         });
 
-        PodUtils.waitUntilPodReplicasCount(eoDeploymentName, 0);
+        PodUtils.waitUntilPodStabilityReplicasCount(eoDeploymentName, 0);
 
         KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {
             k.getSpec().getEntityOperator().setTopicOperator(new EntityTopicOperatorSpec());

File: systemtest/src/test/java/io/strimzi/systemtest/cruisecontrol/CruiseControlConfigurationST.java
Patch:
@@ -17,6 +17,7 @@
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
+import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.systemtest.utils.specific.CruiseControlUtils;
 import io.strimzi.test.WaitException;
 import io.vertx.core.json.JsonObject;
@@ -110,8 +111,8 @@ void testDeployAndUnDeployCruiseControl() throws IOException {
         LOGGER.info("Verifying that in {} is not present in the Kafka cluster", CRUISE_CONTROL_NAME);
         assertThat(KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getCruiseControl(), nullValue());
 
-        LOGGER.info("Verifying that {} pod is not present", CRUISE_CONTROL_NAME);
-        assertThat(kubeClient().listPodsByPrefixInName(CRUISE_CONTROL_POD_PREFIX).size(), is(0));
+        LOGGER.info("Verifying that {} pod is not present", CRUISE_CONTROL_POD_PREFIX);
+        PodUtils.waitUntilPodStabilityReplicasCount(CRUISE_CONTROL_POD_PREFIX, 0);
 
         LOGGER.info("Verifying that in Kafka config map there is no configuration to cruise control metric reporter");
         assertThrows(WaitException.class, () -> CruiseControlUtils.verifyCruiseControlMetricReporterConfigurationInKafkaConfigMapIsPresent(CruiseControlUtils.getKafkaCruiseControlMetricsReporterConfiguration(CLUSTER_NAME)));

File: api/src/main/java/io/strimzi/api/kafka/model/AbstractKafkaConnectSpec.java
Patch:
@@ -97,6 +97,7 @@ public void setImage(String image) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     @Description("The maximum limits for CPU and memory resources and the requested initial resources.")
     public ResourceRequirements getResources() {
         return resources;

File: api/src/main/java/io/strimzi/api/kafka/model/CruiseControlSpec.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.model.balancing.BrokerCapacity;
 import io.strimzi.api.kafka.model.template.CruiseControlTemplate;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.KubeLink;
 import io.sundr.builder.annotations.Buildable;
 import java.io.Serializable;
 import java.util.HashMap;
@@ -113,6 +114,7 @@ public void setJvmOptions(JvmOptions jvmOptions) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     @Description("CPU and memory resources to reserve for the Cruise Control container")
     public ResourceRequirements getResources() {
         return resources;

File: api/src/main/java/io/strimzi/api/kafka/model/EntityTopicOperatorSpec.java
Patch:
@@ -8,6 +8,7 @@
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.fabric8.kubernetes.api.model.ResourceRequirements;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.KubeLink;
 import io.strimzi.crdgenerator.annotations.Minimum;
 import io.sundr.builder.annotations.Buildable;
 import lombok.EqualsAndHashCode;
@@ -103,6 +104,7 @@ public void setTopicMetadataMaxAttempts(int topicMetadataMaxAttempts) {
     }
 
     @Description("CPU and memory resources to reserve.")
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     public ResourceRequirements getResources() {
         return resources;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/EntityUserOperatorSpec.java
Patch:
@@ -8,6 +8,7 @@
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.fabric8.kubernetes.api.model.ResourceRequirements;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.KubeLink;
 import io.strimzi.crdgenerator.annotations.Minimum;
 import io.sundr.builder.annotations.Buildable;
 import lombok.EqualsAndHashCode;
@@ -90,6 +91,7 @@ public void setZookeeperSessionTimeoutSeconds(long zookeeperSessionTimeoutSecond
     }
 
     @Description("CPU and memory resources to reserve.")
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     public ResourceRequirements getResources() {
         return resources;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/JmxTransSpec.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.api.kafka.model.template.JmxTransQueryTemplate;
 import io.strimzi.api.kafka.model.template.JmxTransTemplate;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.KubeLink;
 import io.sundr.builder.annotations.Buildable;
 import lombok.EqualsAndHashCode;
 
@@ -89,6 +90,7 @@ public void setKafkaQueries(List<JmxTransQueryTemplate> kafkaQueries) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     @Description("CPU and memory resources to reserve.")
     public ResourceRequirements getResources() {
         return resources;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeSpec.java
Patch:
@@ -12,6 +12,7 @@
 import io.strimzi.api.kafka.model.template.KafkaBridgeTemplate;
 import io.strimzi.api.kafka.model.tracing.Tracing;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.KubeLink;
 import io.strimzi.crdgenerator.annotations.Minimum;
 import io.sundr.builder.annotations.Buildable;
 import io.vertx.core.cli.annotations.DefaultValue;
@@ -99,6 +100,7 @@ public void setJvmOptions(JvmOptions jvmOptions) {
 
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     @Description("CPU and memory resources to reserve.")
     public ResourceRequirements getResources() {
         return resources;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -175,6 +175,7 @@ public void setImage(String image) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     @Description("CPU and memory resources to reserve.")
     public ResourceRequirements getResources() {
         return resources;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectS2ISpec.java
Patch:
@@ -8,6 +8,7 @@
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.fabric8.kubernetes.api.model.ResourceRequirements;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.KubeLink;
 import io.sundr.builder.annotations.Buildable;
 import lombok.EqualsAndHashCode;
 
@@ -29,6 +30,7 @@ public class KafkaConnectS2ISpec extends KafkaConnectSpec {
     private boolean insecureSourceRepository = false;
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     @Description("CPU and memory resources to reserve.")
     public ResourceRequirements getBuildResources() {
         return buildResources;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaExporterSpec.java
Patch:
@@ -9,6 +9,7 @@
 import io.fabric8.kubernetes.api.model.ResourceRequirements;
 import io.strimzi.api.kafka.model.template.KafkaExporterTemplate;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.KubeLink;
 import io.sundr.builder.annotations.Buildable;
 import lombok.EqualsAndHashCode;
 
@@ -99,6 +100,7 @@ public void setLogging(String logging) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     @Description("CPU and memory resources to reserve.")
     public ResourceRequirements getResources() {
         return resources;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -190,6 +190,7 @@ public void setTolerations(List<Toleration> tolerations) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     @Description("CPU and memory resources to reserve.")
     public ResourceRequirements getResources() {
         return resources;

File: api/src/main/java/io/strimzi/api/kafka/model/Sidecar.java
Patch:
@@ -7,6 +7,7 @@
 import com.fasterxml.jackson.annotation.JsonInclude;
 import io.fabric8.kubernetes.api.model.ResourceRequirements;
 import io.strimzi.crdgenerator.annotations.Description;
+import io.strimzi.crdgenerator.annotations.KubeLink;
 import io.sundr.builder.annotations.Buildable;
 import lombok.EqualsAndHashCode;
 
@@ -42,6 +43,7 @@ public void setImage(String image) {
         this.image = image;
     }
 
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     @Description("CPU and memory resources to reserve.")
     public ResourceRequirements getResources() {
         return resources;

File: api/src/main/java/io/strimzi/api/kafka/model/ZookeeperClusterSpec.java
Patch:
@@ -135,6 +135,7 @@ public void setImage(String image) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
+    @KubeLink(group = "core", version = "v1", kind = "resourcerequirements")
     @Description("CPU and memory resources to reserve.")
     public ResourceRequirements getResources() {
         return resources;

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -80,7 +80,7 @@ public class StrimziUpgradeST extends BaseST {
     private final String topicName = "my-topic";
     private final String userName = "my-user";
 
-    private final String latestReleasedOperator = "https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.17.0/strimzi-0.17.0.zip";
+    private final String latestReleasedOperator = "https://github.com/strimzi/strimzi-kafka-operator/releases/download/0.18.0/strimzi-0.18.0.zip";
 
     @ParameterizedTest()
     @JsonFileSource(resources = "/StrimziUpgradeST.json")
@@ -178,7 +178,7 @@ void testChainUpgrade() throws Exception {
     void testUpgradeKafkaWithoutVersion() throws IOException {
         File dir = FileUtils.downloadAndUnzip(latestReleasedOperator);
 
-        coDir = new File(dir, "strimzi-0.17.0/install/cluster-operator/");
+        coDir = new File(dir, "strimzi-0.18.0/install/cluster-operator/");
 
         // Modify + apply installation files
         copyModifyApply(coDir);

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -110,8 +110,6 @@ public void handle(Long inflightTimerId) {
             };
             longHandler.handle(null);
             promise.future().compose(ignored -> {
-                LOGGER.debug("Stopping kafka {}", kafka);
-                kafka.stop();
 
                 LOGGER.debug("Disconnecting from zookeeper {}", zk);
                 zk.disconnect(zkResult -> {

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicOperator.java
Patch:
@@ -1250,7 +1250,7 @@ Future<?> reconcileAllTopics(String reconciliationType) {
                     }));
                 } else {
                     // Topic exists in kube, but not in Kafka
-                    LOGGER.debug("{}: Topic {} exists in Kafka, but not Kubernetes", logContext, topicName, logTopic(kt));
+                    LOGGER.debug("{}: Topic {} exists in Kubernetes, but not Kafka", logContext, topicName, logTopic(kt));
                     futs.add(reconcileWithKubeTopic(logContext, kt, reconciliationType, new ResourceName(kt), topic.getTopicName()).compose(r -> {
                         // if success then add to success
                         reconcileState.succeeded.add(topicName);

File: api/src/main/java/io/strimzi/api/kafka/model/ZookeeperClusterSpec.java
Patch:
@@ -47,7 +47,7 @@ public class ZookeeperClusterSpec implements UnknownPropertyPreserving, Serializ
             "quorum.auth, requireClientAuthScheme, snapshot.trust.empty, standaloneEnabled, " +
             "reconfigEnabled, 4lw.commands.whitelist, secureClientPort, ssl., serverCnxnFactory, sslQuorum";
     public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.protocol, ssl.quorum.protocol, ssl.enabledProtocols, " +
-            "ssl.quorum.enabledProtocols, ssl.ciphersuites, ssl.quorum.ciphersuites";
+            "ssl.quorum.enabledProtocols, ssl.ciphersuites, ssl.quorum.ciphersuites, ssl.hostnameVerification, ssl.quorum.hostnameVerification";
 
     public static final int DEFAULT_REPLICAS = 3;
 

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -61,6 +61,7 @@
 import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.MIRROR_MAKER;
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.Constants.TRACING;
 import static io.strimzi.test.TestUtils.getFileAsString;
@@ -743,6 +744,7 @@ void testConnectS2IService() {
         KafkaTopicUtils.waitForKafkaTopicDeletion(TEST_TOPIC_NAME);
     }
 
+    @Tag(NODEPORT_SUPPORTED)
     @Test
     void testKafkaBridgeService(Vertx vertx) throws Exception {
         WebClient client = WebClient.create(vertx, new WebClientOptions().setSsl(false));

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeSpec.java
Patch:
@@ -34,8 +34,9 @@
 public class KafkaBridgeSpec implements UnknownPropertyPreserving, Serializable {
 
     private static final long serialVersionUID = 1L;
+    private static final int DEFAULT_REPLICAS = 1;
 
-    private int replicas;
+    private int replicas = DEFAULT_REPLICAS;
 
     private String image;
     private KafkaBridgeHttpConfig http;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -158,7 +158,7 @@ public static KafkaBridgeCluster fromCrd(KafkaBridge kafkaBridge, KafkaVersion.L
             image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE, "strimzi/kafka-bridge:latest");
         }
         kafkaBridgeCluster.setImage(image);
-        kafkaBridgeCluster.setReplicas(spec.getReplicas() > 0 ? spec.getReplicas() : DEFAULT_REPLICAS);
+        kafkaBridgeCluster.setReplicas(spec.getReplicas());
         kafkaBridgeCluster.setBootstrapServers(spec.getBootstrapServers());
         kafkaBridgeCluster.setKafkaConsumerConfiguration(spec.getConsumer());
         kafkaBridgeCluster.setKafkaProducerConfiguration(spec.getProducer());

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -76,8 +76,8 @@ public static KafkaBridge kafkaBridgeWithoutWait(KafkaBridge kafkaBridge) {
         return kafkaBridge;
     }
 
-    public static void deleteKafkaBridgeWithoutWait(KafkaBridge kafkaBridge) {
-        kafkaBridgeClient().inNamespace(ResourceManager.kubeClient().getNamespace()).delete(kafkaBridge);
+    public static void deleteKafkaBridgeWithoutWait(String resourceName) {
+        kafkaBridgeClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
     }
 
     private static KafkaBridge getKafkaBridgeFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -107,8 +107,8 @@ public static KafkaConnect kafkaConnectWithoutWait(KafkaConnect kafkaConnect) {
         return kafkaConnect;
     }
 
-    public static void deleteKafkaConnectWithoutWait(KafkaConnect kafkaConnect) {
-        kafkaConnectClient().inNamespace(ResourceManager.kubeClient().getNamespace()).delete(kafkaConnect);
+    public static void deleteKafkaConnectWithoutWait(String resourceName) {
+        kafkaConnectClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
     }
 
     private static KafkaConnect getKafkaConnectFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -91,8 +91,8 @@ public static KafkaConnectS2I kafkaConnectS2IWithoutWait(KafkaConnectS2I kafkaCo
         return kafkaConnectS2I;
     }
 
-    public static void deleteKafkaConnectS2IWithoutWait(KafkaConnectS2I kafkaConnectS2I) {
-        kafkaConnectS2IClient().inNamespace(ResourceManager.kubeClient().getNamespace()).delete(kafkaConnectS2I);
+    public static void deleteKafkaConnectS2IWithoutWait(String resourceName) {
+        kafkaConnectS2IClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
     }
 
     private static KafkaConnectS2I getKafkaConnectS2IFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -59,7 +59,10 @@ public static KafkaConnectorBuilder defaultKafkaConnector(KafkaConnector kafkaCo
     public static KafkaConnector kafkaConnectorWithoutWait(KafkaConnector kafkaConnector) {
         kafkaConnectorClient().inNamespace(ResourceManager.kubeClient().getNamespace()).createOrReplace(kafkaConnector);
         return kafkaConnector;
+    }
 
+    public static void deleteKafkaConnectorWithoutWait(String connectorName) {
+        kafkaConnectorClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(connectorName).cascading(true).delete();
     }
 
     private static DoneableKafkaConnector deployKafkaConnector(KafkaConnector kafkaConnector) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -123,9 +123,8 @@ public static KafkaMirrorMaker2 kafkaMirrorMaker2WithoutWait(KafkaMirrorMaker2 k
         return kafkaMirrorMaker2;
     }
 
-    public static void deleteKafkaMirrorMaker2WithoutWait(KafkaMirrorMaker2 kafkaMirrorMaker2) {
-        String clusterName = kafkaMirrorMaker2.getMetadata().getName();
-        kafkaMirrorMaker2Client().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(clusterName).cascading(true).delete();
+    public static void deleteKafkaMirrorMaker2WithoutWait(String resourceName) {
+        kafkaMirrorMaker2Client().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
     }
 
     private static KafkaMirrorMaker2 getKafkaMirrorMaker2FromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -100,8 +100,8 @@ public static KafkaMirrorMaker kafkaMirrorMakerWithoutWait(KafkaMirrorMaker kafk
         return kafkaMirrorMaker;
     }
 
-    public static void deleteKafkaMirrorMakerWithoutWait(KafkaMirrorMaker kafkaMirrorMaker) {
-        kafkaMirrorMakerClient().inNamespace(ResourceManager.kubeClient().getNamespace()).delete(kafkaMirrorMaker);
+    public static void deleteKafkaMirrorMakerWithoutWait(String resourceName) {
+        kafkaMirrorMakerClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
     }
 
     private static KafkaMirrorMaker getKafkaMirrorMakerFromYaml(String yamlPath) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -200,10 +200,10 @@ public static Kafka kafkaWithoutWait(Kafka kafka) {
     /**
      * This method is used for delete specific Kafka cluster without wait for all resources deletion.
      * It can be use for example for delete Kafka cluster CR with unsupported Kafka version.
-     * @param kafka kafka cluster specification
+     * @param resourceName kafka cluster name
      */
-    public static void deleteKafkaWithoutWait(Kafka kafka) {
-        kafkaClient().inNamespace(ResourceManager.kubeClient().getNamespace()).delete(kafka);
+    public static void deleteKafkaWithoutWait(String resourceName) {
+        kafkaClient().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(resourceName).cascading(true).delete();
     }
 
     private static Kafka getKafkaFromYaml(String yamlPath) {

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -15,7 +15,6 @@
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaConnectS2IResources;
 import io.strimzi.api.kafka.model.KafkaConnectTlsBuilder;
-import io.strimzi.api.kafka.model.KafkaMirrorMaker2Resources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.connect.ConnectorPlugin;
@@ -376,8 +375,8 @@ void testJvmAndResources() {
             }
         });
 
-        KafkaConnectS2IResource.deleteKafkaConnectS2IWithoutWait(kafkaConnectS2I);
-        DeploymentUtils.waitForDeploymentDeletion(KafkaMirrorMaker2Resources.deploymentName(CLUSTER_NAME));
+        KafkaConnectS2IResource.deleteKafkaConnectS2IWithoutWait(kafkaConnectS2IName);
+        DeploymentUtils.waitForDeploymentDeletion(KafkaConnectS2IResources.deploymentName(kafkaConnectS2IName));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -367,7 +367,7 @@ void testKafkaMirrorMaker2WrongBootstrap() {
 
         KafkaMirrorMaker2Utils.waitForKafkaMirrorMaker2NotReady(CLUSTER_NAME);
 
-        KafkaMirrorMaker2Resource.deleteKafkaMirrorMaker2WithoutWait(kafkaMirrorMaker2);
+        KafkaMirrorMaker2Resource.deleteKafkaMirrorMaker2WithoutWait(CLUSTER_NAME);
         DeploymentUtils.waitForDeploymentDeletion(KafkaMirrorMakerResources.deploymentName(CLUSTER_NAME));
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -92,7 +92,7 @@ public void setVersion(String version) {
         this.version = version;
     }
 
-    @Description("The kafka broker config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
+    @Description("Kafka broker config properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public Map<String, Object> getConfig() {
         return config;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2ClusterSpec.java
Patch:
@@ -5,6 +5,7 @@
 package io.strimzi.api.kafka.model;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
+import io.strimzi.crdgenerator.annotations.DescriptionFile;
 import com.fasterxml.jackson.annotation.JsonProperty;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 
@@ -20,6 +21,7 @@
 
 import static java.util.Collections.emptyMap;
 
+@DescriptionFile
 @Buildable(
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerConsumerSpec.java
Patch:
@@ -6,6 +6,7 @@
 
 
 import com.fasterxml.jackson.annotation.JsonInclude;
+import io.strimzi.crdgenerator.annotations.DescriptionFile;
 import com.fasterxml.jackson.annotation.JsonProperty;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.strimzi.crdgenerator.annotations.Description;
@@ -15,6 +16,7 @@
 
 import java.util.Map;
 
+@DescriptionFile
 @Buildable(
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerProducerSpec.java
Patch:
@@ -5,13 +5,15 @@
 package io.strimzi.api.kafka.model;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
+import io.strimzi.crdgenerator.annotations.DescriptionFile;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
 import lombok.EqualsAndHashCode;
 
 import java.util.Map;
 
+@DescriptionFile
 @Buildable(
         editableEnabled = false,
         builderPackage = Constants.FABRIC8_KUBERNETES_API

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConfiguration.java
Patch:
@@ -21,7 +21,6 @@
 import java.util.Set;
 import java.util.stream.Collectors;
 
-import static java.util.Arrays.asList;
 import static java.util.Collections.emptyList;
 
 /**
@@ -35,8 +34,8 @@ public class KafkaConfiguration extends AbstractConfiguration {
     private static final List<String> FORBIDDEN_PREFIX_EXCEPTIONS;
 
     static {
-        FORBIDDEN_PREFIXES = asList(KafkaClusterSpec.FORBIDDEN_PREFIXES.split(", "));
-        FORBIDDEN_PREFIX_EXCEPTIONS = asList(KafkaClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS.split(", "));
+        FORBIDDEN_PREFIXES = AbstractConfiguration.splitPrefixesToList(KafkaClusterSpec.FORBIDDEN_PREFIXES);
+        FORBIDDEN_PREFIX_EXCEPTIONS = AbstractConfiguration.splitPrefixesToList(KafkaClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS);
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/CruiseControlRestException.java
Patch:
@@ -7,7 +7,7 @@
 /**
  * Represents an exception related to Cruise Control REST API interaction
  */
-class CruiseControlRestException extends RuntimeException {
+public class CruiseControlRestException extends RuntimeException {
 
     public CruiseControlRestException(String message) {
         super(message);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/cruisecontrol/MockCruiseControlTest.java
Patch:
@@ -47,7 +47,7 @@ public static void stop() {
 
     private void runTest(Vertx vertx, VertxTestContext context, String userTaskID, int pendingCalls) throws IOException, URISyntaxException {
 
-        MockCruiseControl.setupCCUserTasksResponse(ccServer, pendingCalls);
+        MockCruiseControl.setupCCUserTasksResponseNoGoals(ccServer, 0, pendingCalls);
 
         CruiseControlApi client = new CruiseControlApiImpl(vertx);
 
@@ -107,7 +107,7 @@ public void testMockCCServerPendingCallsOverride(Vertx vertx, VertxTestContext c
         int pendingCalls2 = 4;
         Checkpoint secondPending = context.checkpoint(pendingCalls2);
 
-        MockCruiseControl.setupCCUserTasksResponse(ccServer, pendingCalls1);
+        MockCruiseControl.setupCCUserTasksResponseNoGoals(ccServer, 0, pendingCalls1);
 
         Future<CruiseControlUserTaskResponse> statusFuture = client.getUserTaskStatus(HOST, PORT, userTaskID);
 
@@ -133,7 +133,7 @@ public void testMockCCServerPendingCallsOverride(Vertx vertx, VertxTestContext c
         statusFuture = statusFuture.compose(response -> {
             try {
                 ccServer.reset();
-                MockCruiseControl.setupCCUserTasksResponse(ccServer, pendingCalls2);
+                MockCruiseControl.setupCCUserTasksResponseNoGoals(ccServer, 0, pendingCalls2);
             } catch (IOException e) {
                 return Future.failedFuture(e);
             } catch (URISyntaxException e) {

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -124,7 +124,8 @@ public static KafkaMirrorMaker2 kafkaMirrorMaker2WithoutWait(KafkaMirrorMaker2 k
     }
 
     public static void deleteKafkaMirrorMaker2WithoutWait(KafkaMirrorMaker2 kafkaMirrorMaker2) {
-        kafkaMirrorMaker2Client().inNamespace(ResourceManager.kubeClient().getNamespace()).delete(kafkaMirrorMaker2);
+        String clusterName = kafkaMirrorMaker2.getMetadata().getName();
+        kafkaMirrorMaker2Client().inNamespace(ResourceManager.kubeClient().getNamespace()).withName(clusterName).cascading(true).delete();
     }
 
     private static KafkaMirrorMaker2 getKafkaMirrorMaker2FromYaml(String yamlPath) {

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -32,9 +32,10 @@
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
-import static org.hamcrest.Matchers.emptyString;
+import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.is;
+import static org.hamcrest.Matchers.not;
 import static org.hamcrest.Matchers.notNullValue;
 import static org.valid4j.matchers.jsonpath.JsonPathMatchers.hasJsonPath;
 
@@ -181,7 +182,7 @@ void testUserWithQuotas(KafkaUser user) {
         KafkaUserUtils.waitForKafkaUserDeletion(user.getMetadata().getName());
 
         ExecResult resultAfterDelete = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), "/bin/bash", "-c", command);
-        assertThat(resultAfterDelete.out(), emptyString());
+        assertThat(resultAfterDelete.out(), not(containsString(userName)));
 
         TestUtils.waitFor("user " + userName + " will be deleted from Zookeeper", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT, () -> {
             ExecResult zkResult = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), "/bin/bash", "-c", zkListCommand);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaRollerTest.java
Patch:
@@ -518,7 +518,7 @@ Future<Boolean> canRoll(int podId) {
         }
 
         @Override
-        int controller(int podId, Admin ac, long timeout, TimeUnit unit) throws ForceableProblem {
+        int controller(int podId, Admin ac, long timeout, TimeUnit unit, RestartContext restartContext) throws ForceableProblem {
             if (controllerException != null) {
                 throw new ForceableProblem("An error while trying to determine the cluster controller from pod " + podName(podId), controllerException);
             } else {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -294,6 +294,9 @@ protected List<EnvVar> getTlsSidecarEnvVars() {
         varList.add(ModelUtils.tlsSidecarLogEnvVar(tlsSidecar));
         varList.add(buildEnvVar(ENV_VAR_ZOOKEEPER_CONNECT, zookeeperConnect));
 
+        // Add shared environment variables used for all containers
+        varList.addAll(getSharedEnvVars());
+
         addContainerEnvsToExistingEnvs(varList, templateTlsSidecarContainerEnvVars);
 
         return varList;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -264,6 +264,9 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
         EntityOperator.javaOptions(varList, getJvmOptions(), javaSystemProperties);
 
+        // Add shared environment variables used for all containers
+        varList.addAll(getSharedEnvVars());
+
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 
         return varList;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -283,6 +283,9 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
         EntityOperator.javaOptions(varList, getJvmOptions(), javaSystemProperties);
 
+        // Add shared environment variables used for all containers
+        varList.addAll(getSharedEnvVars());
+
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 
         return varList;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/JmxTrans.java
Patch:
@@ -262,6 +262,9 @@ protected List<EnvVar> getEnvVars() {
         }
         varList.add(buildEnvVar(ENV_VAR_JMXTRANS_LOGGING_LEVEL, loggingLevel));
 
+        // Add shared environment variables used for all containers
+        varList.addAll(getSharedEnvVars());
+
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 
         return varList;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -403,6 +403,9 @@ protected List<EnvVar> getEnvVars() {
             varList.add(buildEnvVar(ENV_VAR_STRIMZI_TRACING, tracing.getType()));
         }
 
+        // Add shared environment variables used for all containers
+        varList.addAll(getSharedEnvVars());
+
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 
         return varList;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -501,6 +501,9 @@ protected List<EnvVar> getEnvVars() {
             varList.add(buildEnvVar(ENV_VAR_STRIMZI_TRACING, tracing.getType()));
         }
 
+        // Add shared environment variables used for all containers
+        varList.addAll(getSharedEnvVars());
+
         varList.addAll(getExternalConfigurationEnvVars());
 
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaExporter.java
Patch:
@@ -251,6 +251,9 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_KAFKA_EXPORTER_KAFKA_SERVER, KafkaCluster.serviceName(cluster) + ":" + KafkaCluster.REPLICATION_PORT));
         varList.add(buildEnvVar(ENV_VAR_KAFKA_EXPORTER_ENABLE_SARAMA, String.valueOf(saramaLoggingEnabled)));
 
+        // Add shared environment variables used for all containers
+        varList.addAll(getSharedEnvVars());
+
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 
         return varList;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -408,6 +408,9 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_STRIMZI_READINESS_PERIOD,
                 String.valueOf(readinessProbeOptions.getPeriodSeconds() != null ? readinessProbeOptions.getPeriodSeconds() : DEFAULT_HEALTHCHECK_PERIOD)));
 
+        // Add shared environment variables used for all containers
+        varList.addAll(getSharedEnvVars());
+
         addContainerEnvsToExistingEnvs(varList, templateContainerEnvVars);
 
         return varList;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -324,6 +324,9 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_TLS_ENABLED, Boolean.toString(true)));
         varList.add(buildEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
 
+        // Add shared environment variables used for all containers
+        varList.addAll(getSharedEnvVars());
+
         return varList;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -560,6 +560,9 @@ protected List<EnvVar> getEnvVars() {
         jvmPerformanceOptions(varList);
         varList.add(buildEnvVar(ENV_VAR_ZOOKEEPER_CONFIGURATION, configuration.getConfiguration()));
 
+        // Add shared environment variables used for all containers
+        varList.addAll(getSharedEnvVars());
+
         addContainerEnvsToExistingEnvs(varList, templateZookeeperContainerEnvVars);
 
         return varList;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -48,10 +48,11 @@ public class KafkaClusterSpec implements UnknownPropertyPreserving, Serializable
 
     public static final String FORBIDDEN_PREFIXES = "listeners, advertised., broker., listener., host.name, port, "
             + "inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, "
-            + "zookeeper.connect, zookeeper.set.acl, authorizer., super.user"
+            + "zookeeper.connect, zookeeper.set.acl, authorizer., super.user, "
             + "cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers";
 
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols,"
+            + "cruise.control.metrics.topic.num.partitions, cruise.control.metrics.topic.replication.factor, cruise.control.metrics.topic.retention.ms";
 
     protected Storage storage;
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/Producer.java
Patch:
@@ -64,7 +64,7 @@ private void sendNext(KafkaProducer<String, String> producer, String topic) {
         if (msgCntPredicate.negate().test(numSent.get())) {
 
             KafkaProducerRecord<String, String> record =
-                    KafkaProducerRecord.create(topic, "\"Sending messages\": \"Hello-world - " + numSent.get() + "\"");
+                    KafkaProducerRecord.create(topic, "\"Hello-world - " + numSent.get() + "\"");
 
             producer.send(record, done -> {
                 if (done.succeeded()) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java
Patch:
@@ -55,7 +55,7 @@ public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodN
 
     public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodName, String sinkFileName) {
         waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, sinkFileName,
-                "\"Sending messages\": \"Hello-world - 99\"");
+                "\"Hello-world - 99\"");
     }
 
     /**

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -59,8 +59,8 @@ void testTopicOperatorWatchingOtherNamespace() {
         List<String> topics = KafkaCmdClient.listTopicsUsingPodCli(CLUSTER_NAME, 0);
         assertThat(topics, not(hasItems(TOPIC_NAME)));
 
-        deployNewTopic(SECOND_NAMESPACE, THIRD_NAMESPACE, TOPIC_NAME);
-        deleteNewTopic(SECOND_NAMESPACE, TOPIC_NAME);
+        deployNewTopic(SECOND_NAMESPACE, THIRD_NAMESPACE, EXAMPLE_TOPIC_NAME);
+        deleteNewTopic(SECOND_NAMESPACE, EXAMPLE_TOPIC_NAME);
         cluster.setNamespace(previousNamespace);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -107,6 +107,8 @@ public abstract class BaseST implements TestSeparator {
 
     public static final int MESSAGE_COUNT = 100;
     public static final String TOPIC_NAME = KafkaTopicUtils.generateRandomNameOfTopic();
+    public static final String EXAMPLE_TOPIC_NAME = "my-topic";
+
     public static final String USER_NAME = KafkaUserUtils.generateRandomNameOfKafkaUser();
 
     private HelmClient helmClient() {

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -455,7 +455,9 @@ void testKafkaConnectorWithConnectS2IAndConnectWithSameName() {
         KafkaConnectorUtils.waitForConnectorCreation(connectS2IPodName, connectorName);
         KafkaConnectorUtils.waitForConnectorStability(connectorName, connectS2IPodName);
         KafkaConnectUtils.waitForConnectNotReady(CLUSTER_NAME);
+
         KafkaConnectResource.kafkaConnectClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).delete();
+        DeploymentUtils.waitForDeploymentDeletion(KafkaConnectResources.deploymentName(CLUSTER_NAME));
     }
 
     @Test
@@ -503,7 +505,7 @@ void testMultiNodeKafkaConnectS2IWithConnectorCreation() {
                 "curl", "-X", "GET", "http://localhost:8083/connectors/" + CLUSTER_NAME + "/status").out()
         );
         String podIP = connectStatus.getJsonObject("connector").getString("worker_id").split(":")[0];
-        String connectorPodName = kubeClient().listPods().stream().filter(pod ->
+        String connectorPodName = kubeClient().listPods("type", "kafka-connect-s2i").stream().filter(pod ->
                 pod.getStatus().getPodIP().equals(podIP)).findFirst().get().getMetadata().getName();
 
         internalKafkaClient.assertSentAndReceivedMessages(

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -9,6 +9,7 @@
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
 import io.strimzi.api.kafka.model.KafkaConnectResources;
+import io.strimzi.api.kafka.model.KafkaConnectS2IResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.PasswordSecretSourceBuilder;
@@ -683,7 +684,9 @@ void testKafkaConnectorWithConnectAndConnectS2IWithSameName() {
         KafkaConnectorUtils.waitForConnectorCreation(connectPodName, connectorName);
         KafkaConnectorUtils.waitForConnectorStability(connectorName, connectPodName);
         KafkaConnectS2IUtils.waitForConnectS2INotReady(CLUSTER_NAME);
+
         KafkaConnectS2IResource.kafkaConnectS2IClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).delete();
+        DeploymentUtils.waitForDeploymentConfigDeletion(KafkaConnectS2IResources.deploymentName(CLUSTER_NAME));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/MultipleNamespaceST.java
Patch:
@@ -35,10 +35,10 @@ void testTopicOperatorWatchingOtherNamespace() {
         LOGGER.info("Deploying TO to watch a different namespace that it is deployed in");
         cluster.setNamespace(SECOND_NAMESPACE);
         List<String> topics = KafkaCmdClient.listTopicsUsingPodCli(CLUSTER_NAME, 0);
-        assertThat(topics, not(hasItems(TOPIC_NAME)));
+        assertThat(topics, not(hasItems(EXAMPLE_TOPIC_NAME)));
 
-        deployNewTopic(CO_NAMESPACE, SECOND_NAMESPACE, TOPIC_NAME);
-        deleteNewTopic(CO_NAMESPACE, TOPIC_NAME);
+        deployNewTopic(CO_NAMESPACE, SECOND_NAMESPACE, EXAMPLE_TOPIC_NAME);
+        deleteNewTopic(CO_NAMESPACE, EXAMPLE_TOPIC_NAME);
         cluster.setNamespace(CO_NAMESPACE);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -175,6 +175,8 @@ void testDeployUnsupportedKafka() {
 
         KafkaUtils.waitUntilKafkaCRIsNotReady(CLUSTER_NAME);
         KafkaUtils.waitUntilKafkaStatusConditionContainsMessage(CLUSTER_NAME, NAMESPACE, nonExistingVersionMessage);
+
+        KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).delete();
     }
 
     @Test

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -166,7 +166,7 @@ public Map<String, CertAndKey> generateBrokerCerts(Kafka kafka, Set<String> exte
             sbjAltNames.put("DNS.7", String.format("%s.%s.svc", KafkaCluster.headlessServiceName(cluster), namespace));
             sbjAltNames.put("DNS.8", String.format("%s.%s.svc.%s", KafkaCluster.headlessServiceName(cluster), namespace, ModelUtils.KUBERNETES_SERVICE_DNS_DOMAIN));
             sbjAltNames.put("DNS.9", KafkaCluster.podDnsName(namespace, cluster, i));
-            sbjAltNames.put("DNS.10", KafkaCluster.podDnsNameWithoutSuffix(namespace, cluster, i));
+            sbjAltNames.put("DNS.10", KafkaCluster.podDnsNameWithoutClusterDomain(namespace, cluster, i));
             int nextDnsId = 11;
             int nextIpId = 1;
 

File: api/src/main/java/io/strimzi/api/kafka/model/AbstractConnectorSpec.java
Patch:
@@ -73,7 +73,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/CertSecretSource.java
Patch:
@@ -60,7 +60,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/GenericSecretSource.java
Patch:
@@ -59,7 +59,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/InlineLogging.java
Patch:
@@ -9,7 +9,6 @@
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
 
-import java.util.HashMap;
 import java.util.Map;
 
 /**
@@ -27,7 +26,7 @@ public class InlineLogging extends Logging {
 
     public static final String TYPE_INLINE = "inline";
 
-    private Map<String, String> loggers = new HashMap<>();
+    private Map<String, String> loggers = null;
 
     @Description("Must be `" + TYPE_INLINE + "`")
     @Override

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaAuthorization.java
Patch:
@@ -44,7 +44,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridge.java
Patch:
@@ -149,7 +149,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeClientSpec.java
Patch:
@@ -44,7 +44,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeTls.java
Patch:
@@ -48,7 +48,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectTls.java
Patch:
@@ -48,7 +48,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnector.java
Patch:
@@ -132,7 +132,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker.java
Patch:
@@ -162,7 +162,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2ClusterSpec.java
Patch:
@@ -100,7 +100,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2MirrorSpec.java
Patch:
@@ -130,7 +130,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2Tls.java
Patch:
@@ -48,7 +48,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerClientSpec.java
Patch:
@@ -79,7 +79,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerTls.java
Patch:
@@ -50,7 +50,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaTopic.java
Patch:
@@ -154,7 +154,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaTopicSpec.java
Patch:
@@ -96,7 +96,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUser.java
Patch:
@@ -153,7 +153,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUserAuthentication.java
Patch:
@@ -40,7 +40,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUserAuthorization.java
Patch:
@@ -41,7 +41,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUserQuotas.java
Patch:
@@ -75,7 +75,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUserSpec.java
Patch:
@@ -72,7 +72,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/PasswordSecretSource.java
Patch:
@@ -60,7 +60,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/TlsClientAuthentication.java
Patch:
@@ -32,7 +32,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/authentication/KafkaClientAuthentication.java
Patch:
@@ -51,7 +51,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/ExternalListenerBrokerOverride.java
Patch:
@@ -75,7 +75,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthentication.java
Patch:
@@ -54,7 +54,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternal.java
Patch:
@@ -70,7 +70,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalConfiguration.java
Patch:
@@ -54,7 +54,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerPlain.java
Patch:
@@ -72,7 +72,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerTls.java
Patch:
@@ -81,7 +81,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListeners.java
Patch:
@@ -74,7 +74,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/LoadBalancerListenerOverride.java
Patch:
@@ -64,7 +64,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/NodePortListenerBootstrapOverride.java
Patch:
@@ -61,7 +61,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/NodePortListenerOverride.java
Patch:
@@ -64,7 +64,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/RouteListenerOverride.java
Patch:
@@ -64,7 +64,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/TlsListenerConfiguration.java
Patch:
@@ -53,7 +53,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/status/Condition.java
Patch:
@@ -92,7 +92,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/status/KafkaMirrorMaker2Status.java
Patch:
@@ -31,7 +31,7 @@
 public class KafkaMirrorMaker2Status extends KafkaConnectStatus {
     private static final long serialVersionUID = 1L;
 
-    private List<Map<String, Object>> connectors = new ArrayList<>();
+    private List<Map<String, Object>> connectors = new ArrayList<>(3);
 
     @Description("List of MirrorMaker 2.0 connector statuses, as reported by the Kafka Connect REST API.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)

File: api/src/main/java/io/strimzi/api/kafka/model/status/ListenerAddress.java
Patch:
@@ -63,7 +63,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/status/ListenerStatus.java
Patch:
@@ -87,7 +87,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/status/Status.java
Patch:
@@ -47,7 +47,7 @@ public void setConditions(List<Condition> conditions) {
 
     private List<Condition> prepareConditionsUpdate() {
         List<Condition> oldConditions = getConditions();
-        List<Condition> newConditions = oldConditions != null ? new ArrayList<>(oldConditions) : new ArrayList<>();
+        List<Condition> newConditions = oldConditions != null ? new ArrayList<>(oldConditions) : new ArrayList<>(0);
         return newConditions;
     }
 
@@ -81,7 +81,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/storage/PersistentClaimStorageOverride.java
Patch:
@@ -64,7 +64,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/tracing/Tracing.java
Patch:
@@ -43,7 +43,7 @@ public Map<String, Object> getAdditionalProperties() {
     @Override
     public void setAdditionalProperty(String name, Object value) {
         if (this.additionalProperties == null) {
-            this.additionalProperties = new HashMap<>();
+            this.additionalProperties = new HashMap<>(1);
         }
         this.additionalProperties.put(name, value);
     }

File: certificate-manager/src/main/java/io/strimzi/certs/SecretCertProvider.java
Patch:
@@ -88,7 +88,7 @@ public Secret createSecret(String namespace, String name,
                                byte[] store, byte[] storePassword,
                                Map<String, String> labels, Map<String, String> annotations,
                                OwnerReference ownerReference) {
-        Map<String, String> data = new HashMap<>();
+        Map<String, String> data = new HashMap<>(4);
 
         Base64.Encoder encoder = Base64.getEncoder();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java
Patch:
@@ -103,7 +103,7 @@ public void start(Promise<Void> start) {
         // Configure the executor here, but it is used only in other places
         getVertx().createSharedWorkerExecutor("kubernetes-ops-pool", 10, TimeUnit.SECONDS.toNanos(120));
 
-        List<Future> watchFutures = new ArrayList<>();
+        List<Future> watchFutures = new ArrayList<>(8);
         List<AbstractOperator<?, ?>> operators = new ArrayList<>(asList(
                 kafkaAssemblyOperator, kafkaMirrorMakerAssemblyOperator,
                 kafkaConnectAssemblyOperator, kafkaBridgeAssemblyOperator, kafkaMirrorMaker2AssemblyOperator));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -127,7 +127,7 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
         KafkaBridgeAssemblyOperator kafkaBridgeAssemblyOperator =
                 new KafkaBridgeAssemblyOperator(vertx, pfa, certManager, passwordGenerator, resourceOperatorSupplier, config);
 
-        List<Future> futures = new ArrayList<>();
+        List<Future> futures = new ArrayList<>(config.getNamespaces().size());
         for (String namespace : config.getNamespaces()) {
             Promise<String> prom = Promise.promise();
             futures.add(prom.future());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AuthenticationUtils.java
Patch:
@@ -242,7 +242,7 @@ public static void configureClientAuthenticationEnvVars(KafkaClientAuthenticatio
      * @return Map of name/value pairs
      */
     public static Map<String, String> getClientAuthenticationProperties(KafkaClientAuthentication authentication) {
-        Map<String, String> properties = new HashMap<>();
+        Map<String, String> properties = new HashMap<>(3);
         
         if (authentication != null) {
             if (authentication instanceof KafkaClientAuthenticationTls) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -126,7 +126,7 @@ public Map<String, CertAndKey> generateZkCerts(Kafka kafka, boolean isMaintenanc
         String cluster = kafka.getMetadata().getName();
         String namespace = kafka.getMetadata().getNamespace();
         Function<Integer, Subject> subjectFn = i -> {
-            Map<String, String> sbjAltNames = new HashMap<>();
+            Map<String, String> sbjAltNames = new HashMap<>(6);
             sbjAltNames.put("DNS.1", ZookeeperCluster.serviceName(cluster));
             sbjAltNames.put("DNS.2", String.format("%s.%s", ZookeeperCluster.serviceName(cluster), namespace));
             sbjAltNames.put("DNS.3", String.format("%s.%s.svc", ZookeeperCluster.serviceName(cluster), namespace));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -358,7 +358,7 @@ public Deployment generateDeployment(boolean isOpenShift, Map<String, String> an
 
     @Override
     protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
-        List<Container> containers = new ArrayList<>();
+        List<Container> containers = new ArrayList<>(2);
         Container container = new ContainerBuilder()
                 .withName(CRUISE_CONTROL_CONTAINER_NAME)
                 .withImage(getImage())

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControlConfiguration.java
Patch:
@@ -49,7 +49,7 @@ public class CruiseControlConfiguration extends AbstractConfiguration {
     private static final List<String> FORBIDDEN_PREFIX_EXCEPTIONS;
 
     static {
-        CC_DEFAULT_PROPERTIES_MAP = new HashMap<>();
+        CC_DEFAULT_PROPERTIES_MAP = new HashMap<>(7);
         CC_DEFAULT_PROPERTIES_MAP.put("partition.metrics.window.ms", Integer.toString(300_000));
         CC_DEFAULT_PROPERTIES_MAP.put("num.partition.metrics.windows", "1");
         CC_DEFAULT_PROPERTIES_MAP.put("broker.metrics.window.ms", Integer.toString(300_000));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -253,7 +253,7 @@ public Deployment generateDeployment(boolean isOpenShift, Map<String, String> an
 
     @Override
     protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
-        List<Container> containers = new ArrayList<>();
+        List<Container> containers = new ArrayList<>(3);
 
         if (topicOperator != null) {
             containers.addAll(topicOperator.getContainers(imagePullPolicy));
@@ -300,7 +300,7 @@ protected List<EnvVar> getTlsSidecarEnvVars() {
     }
 
     private List<Volume> getVolumes(boolean isOpenShift) {
-        List<Volume> volumeList = new ArrayList<>();
+        List<Volume> volumeList = new ArrayList<>(4);
         if (topicOperator != null) {
             volumeList.addAll(topicOperator.getVolumes());
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -337,7 +337,7 @@ public Deployment generateDeployment(Map<String, String> annotations, boolean is
     @Override
     protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
 
-        List<Container> containers = new ArrayList<>();
+        List<Container> containers = new ArrayList<>(1);
 
         Container container = new ContainerBuilder()
                 .withName(name)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeConsumerConfiguration.java
Patch:
@@ -25,7 +25,7 @@ public class KafkaBridgeConsumerConfiguration extends AbstractConfiguration {
     static {
         FORBIDDEN_PREFIXES = asList(KafkaBridgeConsumerSpec.FORBIDDEN_PREFIXES.split(", "));
         FORBIDDEN_PREFIX_EXCEPTIONS = asList(KafkaBridgeConsumerSpec.FORBIDDEN_PREFIX_EXCEPTIONS.split(", "));
-        DEFAULTS = new HashMap<>();
+        DEFAULTS = new HashMap<>(0);
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeProducerConfiguration.java
Patch:
@@ -25,7 +25,7 @@ public class KafkaBridgeProducerConfiguration extends AbstractConfiguration {
     static {
         FORBIDDEN_PREFIXES = asList(KafkaBridgeProducerSpec.FORBIDDEN_PREFIXES.split(", "));
         FORBIDDEN_PREFIX_EXCEPTIONS = asList(KafkaBridgeProducerSpec.FORBIDDEN_PREFIX_EXCEPTIONS.split(", "));
-        DEFAULTS = new HashMap<>();
+        DEFAULTS = new HashMap<>(0);
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -437,7 +437,7 @@ public Deployment generateDeployment(Map<String, String> annotations, boolean is
     @Override
     protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
 
-        List<Container> containers = new ArrayList<>();
+        List<Container> containers = new ArrayList<>(1);
 
         Container container = new ContainerBuilder()
                 .withName(name)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectConfiguration.java
Patch:
@@ -25,7 +25,7 @@ public class KafkaConnectConfiguration extends AbstractConfiguration {
         FORBIDDEN_PREFIXES = asList(KafkaConnectSpec.FORBIDDEN_PREFIXES.split(", "));
         FORBIDDEN_PREFIX_EXCEPTIONS = asList(KafkaConnectSpec.FORBIDDEN_PREFIX_EXCEPTIONS.split(", "));
 
-        DEFAULTS = new HashMap<>();
+        DEFAULTS = new HashMap<>(6);
         DEFAULTS.put("group.id", "connect-cluster");
         DEFAULTS.put("offset.storage.topic", "connect-cluster-offsets");
         DEFAULTS.put("config.storage.topic", "connect-cluster-configs");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaExporter.java
Patch:
@@ -218,7 +218,7 @@ public Deployment generateDeployment(boolean isOpenShift, ImagePullPolicy imageP
 
     @Override
     protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
-        List<Container> containers = new ArrayList<>();
+        List<Container> containers = new ArrayList<>(1);
 
         Container container = new ContainerBuilder()
                 .withName(name)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2Configuration.java
Patch:
@@ -25,7 +25,7 @@ public class KafkaMirrorMaker2Configuration extends AbstractConfiguration {
         FORBIDDEN_PREFIXES = asList(KafkaMirrorMaker2ClusterSpec.FORBIDDEN_PREFIXES.split(", "));
         FORBIDDEN_PREFIX_EXCEPTIONS = asList(KafkaMirrorMaker2ClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS.split(", "));
 
-        DEFAULTS = new HashMap<>();
+        DEFAULTS = new HashMap<>(8);
         DEFAULTS.put("group.id", "mirrormaker2-cluster");
         DEFAULTS.put("offset.storage.topic", "mirrormaker2-cluster-offsets");
         DEFAULTS.put("config.storage.topic", "mirrormaker2-cluster-configs");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -316,7 +316,7 @@ public Deployment generateDeployment(Map<String, String> annotations, boolean is
     @Override
     protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
 
-        List<Container> containers = new ArrayList<>();
+        List<Container> containers = new ArrayList<>(1);
 
         Container container = new ContainerBuilder()
                 .withName(name)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerConsumerConfiguration.java
Patch:
@@ -24,7 +24,7 @@ public class KafkaMirrorMakerConsumerConfiguration extends AbstractConfiguration
     static {
         FORBIDDEN_PREFIXES = asList(KafkaMirrorMakerConsumerSpec.FORBIDDEN_PREFIXES.split(", "));
         FORBIDDEN_PREFIX_EXCEPTIONS = asList(KafkaMirrorMakerConsumerSpec.FORBIDDEN_PREFIX_EXCEPTIONS.split(", "));
-        DEFAULTS = new HashMap<>();
+        DEFAULTS = new HashMap<>(0);
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerProducerConfiguration.java
Patch:
@@ -24,7 +24,7 @@ public class KafkaMirrorMakerProducerConfiguration extends AbstractConfiguration
     static {
         FORBIDDEN_PREFIXES = asList(KafkaMirrorMakerProducerSpec.FORBIDDEN_PREFIXES.split(", "));
         FORBIDDEN_PREFIX_EXCEPTIONS = asList(KafkaMirrorMakerProducerSpec.FORBIDDEN_PREFIX_EXCEPTIONS.split(", "));
-        DEFAULTS = new HashMap<>();
+        DEFAULTS = new HashMap<>(0);
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ModelUtils.java
Patch:
@@ -225,7 +225,7 @@ static EnvVar tlsSidecarLogEnvVar(TlsSidecar tlsSidecar) {
 
     public static Secret buildSecret(ClusterCa clusterCa, Secret secret, String namespace, String secretName,
             String commonName, String keyCertName, Labels labels, OwnerReference ownerReference, boolean isMaintenanceTimeWindowsSatisfied) {
-        Map<String, String> data = new HashMap<>();
+        Map<String, String> data = new HashMap<>(4);
         CertAndKey certAndKey = null;
         boolean shouldBeRegenerated = false;
         List<String> reasons = new ArrayList<>(2);
@@ -428,7 +428,7 @@ public static String getJavaSystemPropertiesToString(List<SystemProperty> javaSy
         if (javaSystemProperties == null) {
             return null;
         }
-        List<String> javaSystemPropertiesList = new ArrayList<>();
+        List<String> javaSystemPropertiesList = new ArrayList<>(javaSystemProperties.size());
         for (SystemProperty property: javaSystemProperties) {
             javaSystemPropertiesList.add("-D" + property.getName() + "=" + property.getValue());
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/VolumeUtils.java
Patch:
@@ -172,7 +172,7 @@ public static Volume createEmptyDirVolume(String name, String sizeLimit) {
      * @return The PVC created
      */
     public static PersistentVolumeClaim createPersistentVolumeClaimTemplate(String name, PersistentClaimStorage storage) {
-        Map<String, Quantity> requests = new HashMap<>();
+        Map<String, Quantity> requests = new HashMap<>(1);
         requests.put("storage", new Quantity(storage.getSize(), null));
 
         LabelSelector selector = null;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperConfiguration.java
Patch:
@@ -27,7 +27,7 @@ public class ZookeeperConfiguration extends AbstractConfiguration {
         FORBIDDEN_PREFIXES = asList(ZookeeperClusterSpec.FORBIDDEN_PREFIXES.split(", "));
         FORBIDDEN_PREFIX_EXCEPTIONS = asList(ZookeeperClusterSpec.FORBIDDEN_PREFIX_EXCEPTIONS.split(", "));
 
-        Map<String, String> config = new HashMap<>();
+        Map<String, String> config = new HashMap<>(4);
         config.put("tickTime", "2000");
         config.put("initLimit", "5");
         config.put("syncLimit", "2");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -2579,7 +2579,7 @@ Future<Void> maybeCleanPodAndPvc(StatefulSetOperator stsOperator, StatefulSet st
                                                     .filter(pvc -> pvc.getMetadata().getName().endsWith(podName))
                                                     .collect(Collectors.toList());
                                         } else {
-                                            deletePvcs = new ArrayList<>();
+                                            deletePvcs = new ArrayList<>(0);
                                         }
 
                                         List<PersistentVolumeClaim> createPvcs = desiredPvcs
@@ -2906,7 +2906,7 @@ private final Future<ReconciliationState> getEntityOperatorDescription() {
                                 configAnnotation += this.userOperatorMetricsAndLogsConfigMap.getData().get("log4j2.properties");
                             }
 
-                            Map<String, String> annotations = new HashMap<>();
+                            Map<String, String> annotations = new HashMap<>(1);
                             annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, configAnnotation);
 
                             this.eoDeployment = entityOperator.generateDeployment(pfa.isOpenshift(), annotations, imagePullPolicy, imagePullSecrets);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -88,7 +88,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge
                 configMapOperations.get(namespace, ((ExternalLogging) bridge.getLogging()).getName()) :
                 null);
 
-        Map<String, String> annotations = new HashMap<>();
+        Map<String, String> annotations = new HashMap<>(1);
         annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(bridge.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Bridge cluster", reconciliation);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -111,7 +111,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
                 configMapOperations.get(namespace, ((ExternalLogging) connect.getLogging()).getName()) :
                 null);
 
-        Map<String, String> annotations = new HashMap<>();
+        Map<String, String> annotations = new HashMap<>(1);
         annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Connect cluster", reconciliation);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -116,7 +116,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
                 configMapOperations.get(namespace, ((ExternalLogging) connect.getLogging()).getName()) :
                 null);
 
-        HashMap<String, String> annotations = new HashMap<>();
+        HashMap<String, String> annotations = new HashMap<>(1);
         annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         boolean connectHasZeroReplicas = connect.getReplicas() == 0;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -77,7 +77,7 @@ public class KafkaMirrorMaker2AssemblyOperator extends AbstractConnectOperator<K
     public static final String MIRRORMAKER2_SOURCE_CONNECTOR_SUFFIX = ".MirrorSourceConnector";
     public static final String MIRRORMAKER2_CHECKPOINT_CONNECTOR_SUFFIX = ".MirrorCheckpointConnector";
     public static final String MIRRORMAKER2_HEARTBEAT_CONNECTOR_SUFFIX = ".MirrorHeartbeatConnector";
-    private static final Map<String, Function<KafkaMirrorMaker2MirrorSpec, KafkaMirrorMaker2ConnectorSpec>> MIRRORMAKER2_CONNECTORS = new HashMap<>();
+    private static final Map<String, Function<KafkaMirrorMaker2MirrorSpec, KafkaMirrorMaker2ConnectorSpec>> MIRRORMAKER2_CONNECTORS = new HashMap<>(3);
 
     static {
         MIRRORMAKER2_CONNECTORS.put(MIRRORMAKER2_SOURCE_CONNECTOR_SUFFIX, KafkaMirrorMaker2MirrorSpec::getSourceConnector);
@@ -140,7 +140,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                 configMapOperations.get(namespace, ((ExternalLogging) mirrorMaker2Cluster.getLogging()).getName()) :
                 null);
 
-        Map<String, String> annotations = new HashMap<>();
+        Map<String, String> annotations = new HashMap<>(1);
         annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(mirrorMaker2Cluster.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka MirrorMaker 2.0 cluster", reconciliation);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -91,7 +91,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                 configMapOperations.get(namespace, ((ExternalLogging) mirror.getLogging()).getName()) :
                 null);
 
-        Map<String, String> annotations = new HashMap<>();
+        Map<String, String> annotations = new HashMap<>(1);
         annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(mirror.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Mirror Maker cluster", reconciliation);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperator.java
Patch:
@@ -74,7 +74,7 @@ public Future<Void> maybeRollingUpdate(StatefulSet sts, Function<Pod, String> po
         log.debug("Considering rolling update of {}/{}", namespace, name);
 
         boolean zkRoll = false;
-        ArrayList<Pod> pods = new ArrayList<>();
+        ArrayList<Pod> pods = new ArrayList<>(replicas);
         String cluster = sts.getMetadata().getLabels().get(Labels.STRIMZI_CLUSTER_LABEL);
         for (int i = 0; i < replicas; i++) {
             Pod pod = podOperations.get(sts.getMetadata().getNamespace(), KafkaResources.zookeeperPodName(cluster, i));

File: user-operator/src/main/java/io/strimzi/operator/user/model/KafkaUserModel.java
Patch:
@@ -134,15 +134,15 @@ public static KafkaUserModel fromCrd(CertManager certManager,
      */
     public Secret generateSecret()  {
         if (authentication instanceof KafkaUserTlsClientAuthentication) {
-            Map<String, String> data = new HashMap<>();
+            Map<String, String> data = new HashMap<>(5);
             data.put("ca.crt", caCert);
             data.put("user.key", userCertAndKey.keyAsBase64String());
             data.put("user.crt", userCertAndKey.certAsBase64String());
             data.put("user.p12", userCertAndKey.keyStoreAsBase64String());
             data.put("user.password", userCertAndKey.storePasswordAsBase64String());
             return createSecret(data);
         } else if (authentication instanceof KafkaUserScramSha512ClientAuthentication) {
-            Map<String, String> data = new HashMap<>();
+            Map<String, String> data = new HashMap<>(1);
             data.put(KafkaUserModel.KEY_PASSWORD, Base64.getEncoder().encodeToString(scramSha512Password.getBytes(StandardCharsets.US_ASCII)));
             return createSecret(data);
         } else {

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -986,7 +986,6 @@ void testRemoveUserAndTopicOperatorsFromEntityOperator() {
         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3).done();
 
         String eoDeploymentName = KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME);
-        String eoPodName = kubeClient().listPodsByPrefixInName(eoDeploymentName).get(0).getMetadata().getName();
 
         KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {
             k.getSpec().getEntityOperator().setTopicOperator(null);
@@ -996,7 +995,7 @@ void testRemoveUserAndTopicOperatorsFromEntityOperator() {
         //Waiting when EO pod will be deleted
         DeploymentUtils.waitForDeploymentDeletion(eoDeploymentName);
         ReplicaSetUtils.waitForReplicaSetDeletion(eoDeploymentName);
-        PodUtils.waitForPodDeletion(eoPodName);
+        PodUtils.waitForPodDeletion(eoDeploymentName);
 
         //Checking that EO was removed
         assertThat(kubeClient().listPodsByPrefixInName(eoDeploymentName).size(), is(0));

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -54,6 +54,7 @@
 
 import java.io.File;
 import java.io.IOException;
+import java.io.InputStream;
 import java.nio.charset.StandardCharsets;
 import java.util.Base64;
 import java.util.HashMap;
@@ -595,7 +596,8 @@ void testChangeConnectS2IConfig() {
         assertThat(actualVersion, is(TestKafkaVersion.getKafkaVersions().get(1).version()));
 
         LOGGER.info("===== CONNECTS2I CERT CHANGE =====");
-        String clusterCaCert = TestUtils.readResource(getClass(), "cluster-ca.crt");
+        InputStream secretInputStream = getClass().getClassLoader().getResourceAsStream("security-st-certs/cluster-ca.crt");
+        String clusterCaCert = TestUtils.readResource(secretInputStream);
         SecretUtils.createSecret("my-secret", "ca.crt", new String(Base64.getEncoder().encode(clusterCaCert.getBytes()), StandardCharsets.US_ASCII));
 
         CertSecretSource certSecretSource = new CertSecretSourceBuilder()

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -36,7 +36,6 @@ public abstract class AbstractNamespaceST extends BaseST {
 
     static final String CO_NAMESPACE = "co-namespace-test";
     static final String SECOND_NAMESPACE = "second-namespace-test";
-    static final String USER_NAME = "my-user";
     private static final String TOPIC_EXAMPLES_DIR = "../examples/topic/kafka-topic.yaml";
 
     void checkKafkaInDiffNamespaceThanCO(String clusterName, String namespace) {

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -166,7 +166,6 @@ void testUserInDifferentNamespace() {
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
             .withKafkaUsername(USER_NAME)
-            .withConsumerGroupName(CONSUMER_GROUP_NAME)
             .build();
 
         LOGGER.info("Checking produced and consumed messages to pod:{}", defaultKafkaClientsPodName);

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -84,12 +84,11 @@
 class CustomResourceStatusST extends BaseST {
     static final String NAMESPACE = "status-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(CustomResourceStatusST.class);
-    private static final String TOPIC_NAME = "status-topic";
     private static final String CONNECTS2I_CLUSTER_NAME = CLUSTER_NAME + "-s2i";
 
     @Test
     @Tag(NODEPORT_SUPPORTED)
-    void testKafkaStatus() throws Exception {
+    void testKafkaStatus() {
         LOGGER.info("Checking status of deployed kafka cluster");
         KafkaUtils.waitUntilKafkaCRIsReady(CLUSTER_NAME);
 
@@ -98,7 +97,6 @@ void testKafkaStatus() throws Exception {
             .withNamespaceName(NAMESPACE)
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
-            .withConsumerGroupName(CONSUMER_GROUP_NAME + "-" + rng.nextInt(Integer.MAX_VALUE))
             .build();
 
         basicExternalKafkaClient.verifyProducedAndConsumedMessages(

File: systemtest/src/test/java/io/strimzi/systemtest/HelmChartST.java
Patch:
@@ -25,7 +25,6 @@ class HelmChartST extends BaseST {
 
     static final String NAMESPACE = "helm-chart-cluster-test";
     private static final String CLUSTER_NAME = "my-cluster";
-    private static final String TOPIC_NAME = "test-topic";
 
     @Test
     void testDeployKafkaClusterViaHelmChart() {

File: systemtest/src/test/java/io/strimzi/systemtest/MirrorMakerST.java
Patch:
@@ -55,7 +55,6 @@ public class MirrorMakerST extends BaseST {
     private static final Logger LOGGER = LogManager.getLogger(MirrorMakerST.class);
 
     public static final String NAMESPACE = "mm-cluster-test";
-    private static final String TOPIC_NAME = "test-topic";
     private final int messagesCount = 200;
     private String kafkaClusterSourceName = CLUSTER_NAME + "-source";
     private String kafkaClusterTargetName = CLUSTER_NAME + "-target";

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -57,7 +57,7 @@ class HttpBridgeTlsST extends HttpBridgeBaseST {
 
     @Test
     void testSendSimpleMessageTls() throws Exception {
-        String topicName = "topic-simple-send";
+        String topicName = KafkaTopicUtils.generateRandomNameOfTopic();
         // Create topic
         KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();
 
@@ -80,7 +80,7 @@ void testSendSimpleMessageTls() throws Exception {
 
     @Test
     void testReceiveSimpleMessageTls() throws Exception {
-        String topicName = "topic-simple-receive";
+        String topicName = KafkaTopicUtils.generateRandomNameOfTopic();
         // Create topic
         KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();
         KafkaTopicUtils.waitForKafkaTopicCreation(topicName);
@@ -127,7 +127,7 @@ void testReceiveSimpleMessageTls() throws Exception {
 
     @Test
     void testTlsAuthWithWeirdNamedUser() throws Exception {
-        String topicName = "topic" + rng.nextInt(Integer.MAX_VALUE);
+        String topicName = KafkaTopicUtils.generateRandomNameOfTopic();
         String groupId = "my-group-" + rng.nextInt(Integer.MAX_VALUE);
 
         // Create weird named user with . and maximum of 64 chars -> TLS

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/PrometheusST.java
Patch:
@@ -34,7 +34,6 @@ public class PrometheusST extends BaseST {
 
     public static final String NAMESPACE = "prometheus-test";
 
-    private static final String PROMETHEUS = "prometheus";
     private static final String PROMETHEUS_POD = "prometheus-prometheus-0";
     private static final String ALERTMANAGER = "alertmanager";
     private static final String ALERTMANAGER_POD = "alertmanager-alertmanager-0";

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthBaseST.java
Patch:
@@ -44,9 +44,6 @@ public class OauthBaseST extends BaseST {
 
     public static final String NAMESPACE = "oauth2-cluster-test";
     protected static final Logger LOGGER = LogManager.getLogger(OauthBaseST.class);
-
-    protected static final String TOPIC_NAME = "my-topic";
-
     protected static final String OAUTH_CLIENT_NAME = "hello-world-producer";
     protected static final String OAUTH_CLIENT_SECRET = "hello-world-producer-secret";
     protected static final String OAUTH_KAFKA_CLIENT_NAME = "kafka-broker";

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java
Patch:
@@ -411,7 +411,6 @@ void setUp() {
             .withNamespaceName(NAMESPACE)
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
-            .withConsumerGroupName(CONSUMER_GROUP_NAME + "-" + rng.nextInt(Integer.MAX_VALUE))
             .withOauthClientId(OAUTH_CLIENT_NAME)
             .withClientSecretName(OAUTH_CLIENT_SECRET)
             .withOauthTokenEndpointUri(oauthTokenEndpointUri)

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -352,7 +352,6 @@ void setUp() {
             .withNamespaceName(NAMESPACE)
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
-            .withConsumerGroupName(CONSUMER_GROUP_NAME + "-" + rng.nextInt(Integer.MAX_VALUE))
             .withOauthClientId(OAUTH_CLIENT_NAME)
             .withKafkaUsername(OAUTH_CLIENT_NAME)
             .withClientSecretName(OAUTH_CLIENT_SECRET)

File: systemtest/src/test/java/io/strimzi/systemtest/recovery/NamespaceDeletionRecoveryST.java
Patch:
@@ -50,7 +50,7 @@ class NamespaceDeletionRecoveryST extends BaseST {
 
     @Test
     void testTopicAvailable() {
-        String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
+        String topicName = KafkaTopicUtils.generateRandomNameOfTopic();
 
         prepareEnvironmentForRecovery(topicName, MESSAGE_COUNT);
 
@@ -108,7 +108,7 @@ void testTopicAvailable() {
 
     @Test
     void testTopicNotAvailable() throws InterruptedException {
-        String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
+        String topicName = KafkaTopicUtils.generateRandomNameOfTopic();
 
         prepareEnvironmentForRecovery(topicName, MESSAGE_COUNT);
 

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -272,7 +272,6 @@ private void performUpgrade(JsonObject testParameters, int produceMessagesCount,
             .withClusterName(kafkaClusterName)
             .withKafkaUsername(userName)
             .withMessageCount(produceMessagesCount)
-            .withConsumerGroupName(CONSUMER_GROUP_NAME + "-" + rng.nextInt(Integer.MAX_VALUE))
             .build();
 
         int sent = internalKafkaClient.sendMessagesTls();

File: systemtest/src/test/java/io/strimzi/systemtest/security/SecurityST.java
Patch:
@@ -659,7 +659,7 @@ void testCertRegeneratedAfterInternalCAisDeleted() {
             kubeClient().deleteSecret(s.getMetadata().getName());
         }
 
-        PodUtils.waitUntilPodsStability(kubeClient().listPodsByPrefixInName(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME)));
+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));
         StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaPods);
 
         for (Secret s : secrets) {
@@ -1340,7 +1340,7 @@ void testKafkaAndKafkaConnectTlsVersion() {
 
         LOGGER.info("Verifying that Kafka Connect is stable");
 
-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));
+        PodUtils.verifyThatRunningPodsAreStable(KafkaConnectResources.deploymentName(CLUSTER_NAME));
 
         LOGGER.info("Verifying that Kafka Connect status is Ready because of same TLS version");
 
@@ -1400,7 +1400,7 @@ void testKafkaAndKafkaConnectCipherSuites() {
 
         LOGGER.info("Verifying that Kafka Connect is stable");
 
-        PodUtils.waitUntilPodsByNameStability(KafkaConnectResources.deploymentName(CLUSTER_NAME));
+        PodUtils.verifyThatRunningPodsAreStable(KafkaConnectResources.deploymentName(CLUSTER_NAME));
 
         LOGGER.info("Verifying that Kafka Connect status is Ready because of the same cipher suites complexity of algorithm");
 

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java
Patch:
@@ -149,7 +149,7 @@ void runVersionChange(TestKafkaVersion initialVersion, TestKafkaVersion newVersi
 
         LOGGER.info("Deployment of Kafka (" + newVersion.version() + ") complete");
 
-        PodUtils.waitUntilPodsStability(kubeClient().listPodsByPrefixInName(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME)));
+        PodUtils.verifyThatRunningPodsAreStable(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));
 
         // Extract the zookeeper version number from the jars in the lib directory
         zkResult = cmdKubeClient().execInPodContainer(KafkaResources.zookeeperPodName(CLUSTER_NAME, 0),

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest;
 
-import io.strimzi.api.kafka.model.KafkaMirrorMaker2Resources;
+import io.strimzi.api.kafka.model.KafkaMirrorMakerResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
@@ -67,7 +67,7 @@ void checkMirrorMakerForKafkaInDifNamespaceThanCO(String sourceClusterName) {
         KafkaMirrorMakerResource.kafkaMirrorMaker(CLUSTER_NAME, kafkaSourceName, kafkaTargetName, "my-group", 1, false).done();
 
         LOGGER.info("Waiting for creation {} in namespace {}", CLUSTER_NAME + "-mirror-maker", SECOND_NAMESPACE);
-        DeploymentUtils.waitForDeploymentAndPodsReady(KafkaMirrorMaker2Resources.deploymentName(CLUSTER_NAME), 1);
+        DeploymentUtils.waitForDeploymentAndPodsReady(KafkaMirrorMakerResources.deploymentName(CLUSTER_NAME), 1);
         cluster.setNamespace(previousNamespace);
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -44,7 +44,6 @@ public class ClusterOperatorConfig {
     public static final String STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES = "STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES";
     public static final String STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE";
     public static final String STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE";
-    public static final String STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE";
     public static final String STRIMZI_DEFAULT_TLS_SIDECAR_CRUISE_CONTROL_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_CRUISE_CONTROL_IMAGE";
     public static final String STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE = "STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE";
     public static final String STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE = "STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE";

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -374,7 +374,7 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {
      * @return The generated ConfigMap.
      */
     public ConfigMap generateMetricsAndLogConfigMap(ConfigMap cm) {
-        Map<String, String> data = new HashMap<>();
+        Map<String, String> data = new HashMap<>(2);
         data.put(getAncillaryConfigMapKeyLogConfig(), parseLogging(getLogging(), cm));
         if (isMetricsEnabled()) {
             HashMap<String, Object> m = new HashMap<>();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -34,7 +34,6 @@
 import io.strimzi.api.kafka.model.ContainerEnvVar;
 import io.strimzi.api.kafka.model.CruiseControlResources;
 import io.strimzi.api.kafka.model.CruiseControlSpec;
-import io.strimzi.api.kafka.model.EntityOperatorSpec;
 import io.strimzi.api.kafka.model.InlineLogging;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaClusterSpec;
@@ -152,7 +151,7 @@ protected void setTlsSidecar(TlsSidecar tlsSidecar) {
     }
 
     protected static String defaultZookeeperConnect(String cluster) {
-        return ZookeeperCluster.serviceName(cluster) + ":" + EntityOperatorSpec.DEFAULT_ZOOKEEPER_PORT;
+        return ZookeeperCluster.serviceName(cluster) + ":" + ZookeeperCluster.CLIENT_TLS_PORT;
     }
 
     protected static String defaultBootstrapServers(String cluster) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -99,7 +99,7 @@ public static String entityOperatorName(String cluster) {
     }
 
     protected static String defaultZookeeperConnect(String cluster) {
-        return ZookeeperCluster.serviceName(cluster) + ":" + EntityOperatorSpec.DEFAULT_ZOOKEEPER_PORT;
+        return ZookeeperCluster.serviceName(cluster) + ":" + ZookeeperCluster.CLIENT_TLS_PORT;
     }
 
     public void setZookeeperConnect(String zookeeperConnect) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -287,7 +287,7 @@ private KafkaCluster(HasMetadata resource) {
         this.readinessProbeOptions = DEFAULT_HEALTHCHECK_OPTIONS;
         this.isMetricsEnabled = DEFAULT_KAFKA_METRICS_ENABLED;
 
-        setZookeeperConnect(ZookeeperCluster.serviceName(cluster) + ":2181");
+        setZookeeperConnect(ZookeeperCluster.serviceName(cluster) + ":" + ZookeeperCluster.CLIENT_TLS_PORT);
 
         this.mountPath = "/var/lib/kafka";
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -192,7 +192,7 @@ public static String roleBindingName(String cluster) {
     }
 
     protected static String defaultZookeeperConnect(String cluster) {
-        return ZookeeperCluster.serviceName(cluster) + ":" + io.strimzi.api.kafka.model.TopicOperatorSpec.DEFAULT_ZOOKEEPER_PORT;
+        return ZookeeperCluster.serviceName(cluster) + ":" + ZookeeperCluster.CLIENT_TLS_PORT;
     }
 
     protected static String defaultBootstrapServers(String cluster) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperLeaderFinder.java
Patch:
@@ -309,6 +309,6 @@ protected String host(Pod pod) {
 
     /** The port number for connecting to zookeeper in the given pod. */
     protected int port(Pod pod) {
-        return 2181;
+        return ZookeeperCluster.CLIENT_TLS_PORT;
     }
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -115,6 +115,7 @@
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.function.Function;
 
 import static java.util.Collections.emptyMap;
 import static java.util.Collections.singleton;
@@ -645,7 +646,7 @@ public Admin createAdminClient(String hostname, Secret clusterCaCertSecret, Secr
     public static ZookeeperScalerProvider zookeeperScalerProvider() {
         return new ZookeeperScalerProvider() {
             @Override
-            public ZookeeperScaler createZookeeperScaler(Vertx vertx, String zookeeperConnectionString, Secret clusterCaCertSecret, Secret coKeySecret, long operationTimeoutMs) {
+            public ZookeeperScaler createZookeeperScaler(Vertx vertx, String zookeeperConnectionString, Function<Integer, String> zkNodeAddress, Secret clusterCaCertSecret, Secret coKeySecret, long operationTimeoutMs) {
                 ZookeeperScaler mockZooScaler = mock(ZookeeperScaler.class);
                 when(mockZooScaler.scale(anyInt())).thenReturn(Future.succeededFuture());
                 return mockZooScaler;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -463,7 +463,7 @@ private void checkStatefulSet(StatefulSet sts, Kafka cm, boolean isOpenShift) {
         // checks on the TLS sidecar
         Container tlsSidecarContainer = containers.get(1);
         assertThat(tlsSidecarContainer.getImage(), is(image));
-        assertThat(AbstractModel.containerEnvVars(tlsSidecarContainer).get(KafkaCluster.ENV_VAR_KAFKA_ZOOKEEPER_CONNECT), is(ZookeeperCluster.serviceName(cluster) + ":2181"));
+        assertThat(AbstractModel.containerEnvVars(tlsSidecarContainer).get(KafkaCluster.ENV_VAR_KAFKA_ZOOKEEPER_CONNECT), is(ZookeeperCluster.serviceName(cluster) + ":" + ZookeeperCluster.CLIENT_TLS_PORT));
         assertThat(AbstractModel.containerEnvVars(tlsSidecarContainer).get(ModelUtils.TLS_SIDECAR_LOG_LEVEL), is(TlsSidecarLogLevel.NOTICE.toValue()));
         assertThat(tlsSidecarContainer.getVolumeMounts().get(0).getName(), is(KafkaCluster.BROKER_CERTS_VOLUME));
         assertThat(tlsSidecarContainer.getVolumeMounts().get(0).getMountPath(), is(KafkaCluster.TLS_SIDECAR_KAFKA_CERTS_VOLUME_MOUNT));

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java
Patch:
@@ -69,7 +69,7 @@ public static void waitForZkMntr(String clusterName, Pattern pattern, int... pod
 
         for (int podIndex : podIndexes) {
             String zookeeperPod = KafkaResources.zookeeperPodName(clusterName, podIndex);
-            String zookeeperPort = String.valueOf(2181 * 10 + podIndex);
+            String zookeeperPort = String.valueOf(12181);
             waitFor("mntr", pollMs, timeoutMs, () -> {
                     try {
                         String output = cmdKubeClient().execInPod(zookeeperPod,

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -83,7 +83,6 @@ public abstract class BaseST implements TestSeparator {
     protected static final String TO_IMAGE = "STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE";
     protected static final String UO_IMAGE = "STRIMZI_DEFAULT_USER_OPERATOR_IMAGE";
     protected static final String KAFKA_INIT_IMAGE = "STRIMZI_DEFAULT_KAFKA_INIT_IMAGE";
-    protected static final String TLS_SIDECAR_ZOOKEEPER_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE";
     protected static final String TLS_SIDECAR_KAFKA_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE";
     protected static final String TLS_SIDECAR_EO_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE";
     protected static final String TEST_TOPIC_NAME = "test-topic";
@@ -694,8 +693,6 @@ protected void testDockerImagesForKafkaCluster(String clusterName, String namesp
         for (int i = 0; i < zkPods; i++) {
             String imgFromPod = PodUtils.getContainerImageNameFromPod(KafkaResources.zookeeperPodName(clusterName, i), "zookeeper");
             assertThat("Zookeeper pod " + i + " uses wrong image", TestUtils.parseImageMap(imgFromDeplConf.get(KAFKA_IMAGE_MAP)).get(kafkaVersion), is(imgFromPod));
-            imgFromPod = PodUtils.getContainerImageNameFromPod(KafkaResources.zookeeperPodName(clusterName, i), "tls-sidecar");
-            assertThat("Zookeeper TLS side car for pod " + i + " uses wrong image", imgFromDeplConf.get(TLS_SIDECAR_ZOOKEEPER_IMAGE), is(imgFromPod));
         }
 
         //Verifying docker image for kafka pods

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -183,7 +183,7 @@ void testUpgradeKafkaWithoutVersion() throws IOException {
         // Modify + apply installation files
         copyModifyApply(coDir);
 
-        KafkaResource.kafkaPersistent(CLUSTER_NAME, 1, 1)
+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 3)
             .editSpec()
                 .editKafka()
                     .withVersion(null)
@@ -203,7 +203,7 @@ void testUpgradeKafkaWithoutVersion() throws IOException {
         kubeClient().getClient().apps().deployments().inNamespace(NAMESPACE).withName("strimzi-cluster-operator").create(KubernetesResource.defaultClusterOperator(NAMESPACE).build());
 
         DeploymentUtils.waitTillDepHasRolled("strimzi-cluster-operator", 1, operatorSnapshot);
-        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 1, kafkaSnapshot);
+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);
         DeploymentUtils.waitTillDepHasRolled(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), 1, eoSnapshot);
 
         assertThat(kubeClient().getStatefulSet(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME)).getSpec().getTemplate().getSpec().getContainers()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java
Patch:
@@ -155,12 +155,12 @@ private String image(final String crImage, final String crVersion, Map<String, S
                 if (crVersion == null) {
                     image = images.get(defaultVersion().version());
                     if (image == null) {
-                        throw new NoImageException("No image for default version " + defaultVersion());
+                        throw new NoImageException("No image for default version " + defaultVersion() + " in " + images.toString());
                     }
                 } else {
                     image = images.get(crVersion);
                     if (image == null) {
-                        throw new NoImageException("No image for version " + crVersion);
+                        throw new NoImageException("No image for version " + crVersion + " in " + images.toString());
                     }
                 }
             } else {

File: operator-common/src/main/java/io/strimzi/operator/PlatformFeaturesAvailability.java
Patch:
@@ -121,7 +121,7 @@ private static Future<VersionInfo> getVersionInfoFromKubernetes(Vertx vertx, Kub
             try {
                 request.complete(client.getVersion());
             } catch (Exception e) {
-                log.error("Detection of Kuberetes version failed.", e);
+                log.error("Detection of Kubernetes version failed.", e);
                 request.fail(e);
             }
         }, promise);

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicSerialization.java
Patch:
@@ -224,7 +224,8 @@ public static Topic fromTopicMetadata(TopicMetadata meta) {
                 .withNumReplicas((short) meta.getDescription().partitions().get(0).replicas().size())
                 .withMetadata(null);
         for (ConfigEntry entry: meta.getConfig().entries()) {
-            if (!entry.isDefault()) {
+            if (entry.source() != ConfigEntry.ConfigSource.DEFAULT_CONFIG
+                && entry.source() != ConfigEntry.ConfigSource.STATIC_BROKER_CONFIG) {
                 builder.withConfigEntry(entry.name(), entry.value());
             }
         }

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorTest.java
Patch:
@@ -1048,7 +1048,7 @@ public void testReconcileAllTopics_getResourceFails(VertxTestContext context) {
         Future<?> reconcileFuture = topicOperator.reconcileAllTopics("periodic");
 
         reconcileFuture.setHandler(context.failing(e -> {
-            context.verify(() -> assertThat(e.getMessage(), is("Error getting KafkaTopic my-topic during periodic reconciliation")));
+            context.verify(() -> assertThat(e.getMessage(), is("Error getting topic my-topic from topic store during periodic reconciliation")));
             context.verify(() -> assertThat(e.getCause(), is(error)));
             context.verify(() -> {
                 MeterRegistry registry = metrics.meterRegistry();

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -82,6 +82,7 @@ public interface Constants {
     int COMPONENTS_METRICS_PORT = 9404;
     int CLUSTER_OPERATOR_METRICS_PORT = 8080;
     int USER_OPERATOR_METRICS_PORT = 8081;
+    int TOPIC_OPERATOR_METRICS_PORT = 8080;
 
     String DEPLOYMENT = "Deployment";
     String SERVICE = "Service";

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.api.kafka.model.DoneableKafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.operator.common.Util;
+import io.strimzi.operator.common.MicrometerMetricsProvider;
 import io.strimzi.operator.topic.zk.Zk;
 import io.vertx.core.AbstractVerticle;
 import io.vertx.core.Future;
@@ -182,7 +183,7 @@ public void start(Promise<Void> start) {
 
                 LOGGER.debug("Using TopicStore {}", topicStore);
 
-                this.topicOperator = new TopicOperator(vertx, kafka, k8s, topicStore, labels, namespace, config);
+                this.topicOperator = new TopicOperator(vertx, kafka, k8s, topicStore, labels, namespace, config, new MicrometerMetricsProvider());
                 LOGGER.debug("Using Operator {}", topicOperator);
 
                 this.topicConfigsWatcher = new TopicConfigsWatcher(topicOperator);
@@ -223,6 +224,7 @@ public void handle(Long oldTimerId) {
                             timerId = null;
                             boolean isInitialReconcile = oldTimerId == null;
                             topicOperator.reconcileAllTopics(isInitialReconcile ? "initial " : "periodic ").setHandler(result -> {
+                                topicOperator.getPeriodicReconciliationsCounter().increment();
                                 if (isInitialReconcile) {
                                     initReconcilePromise.complete();
                                 }

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -79,6 +79,8 @@ public final class TestUtils {
 
     public static final String CRD_KAFKA_MIRROR_MAKER_2 = "../install/cluster-operator/048-Crd-kafkamirrormaker2.yaml";
 
+    public static final String CRD_KAFKA_CONNECTOR = "../install/cluster-operator/047-Crd-kafkaconnector.yaml";
+
     private TestUtils() {
         // All static methods
     }

File: test/src/main/java/io/strimzi/test/k8s/HelmClient.java
Patch:
@@ -22,7 +22,7 @@ public class HelmClient {
     private static final Logger LOGGER = LogManager.getLogger(HelmClient.class);
 
     private static final String HELM_CMD = "helm";
-    private static final String INSTALL_TIMEOUT_SECONDS = "60";
+    private static final String INSTALL_TIMEOUT_SECONDS = "90";
 
     private boolean initialized;
     private String namespace;

File: test/src/main/java/io/strimzi/test/k8s/KubeClusterResource.java
Patch:
@@ -43,7 +43,7 @@ public class KubeClusterResource {
 
     private static final Logger LOGGER = LogManager.getLogger(KubeClusterResource.class);
 
-    private static final String CO_INSTALL_DIR = "../install/cluster-operator";
+    public static final String CO_INSTALL_DIR = "../install/cluster-operator";
 
     private KubeCluster kubeCluster;
     private KubeCmdClient cmdClient;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/StatefulSetUtils.java
Patch:
@@ -8,8 +8,8 @@
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
-import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -137,11 +137,11 @@ public static void waitForAllStatefulSetPodsReady(String statefulSetName, int ex
         LOGGER.info("Waiting for StatefulSet {} to be ready", statefulSetName);
         TestUtils.waitFor("StatefulSet " + statefulSetName + " to be ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> kubeClient().getStatefulSetStatus(statefulSetName),
-            () -> StUtils.logCurrentStatus(KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(resourceName).get()));
+            () -> ResourceManager.logCurrentResourceStatus(KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(resourceName).get()));
 
         LOGGER.info("Waiting for {} Pod(s) of StatefulSet {} to be ready", expectPods, statefulSetName);
         PodUtils.waitForPodsReady(kubeClient().getStatefulSetSelectors(statefulSetName), expectPods, true,
-            () -> StUtils.logCurrentStatus(KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(resourceName).get()));
+            () -> ResourceManager.logCurrentResourceStatus(KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(resourceName).get()));
         LOGGER.info("StatefulSet {} is ready", statefulSetName);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/topic/TopicST.java
Patch:
@@ -54,7 +54,7 @@
 public class TopicST extends BaseST {
 
     private static final Logger LOGGER = LogManager.getLogger(TopicST.class);
-    private static final String NAMESPACE = "topic-cluster-test";
+    static final String NAMESPACE = "topic-cluster-test";
 
     @Test
     void testMoreReplicasThanAvailableBrokers() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/CruiseControl.java
Patch:
@@ -162,6 +162,7 @@ protected static String defaultBootstrapServers(String cluster) {
     public static CruiseControl fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup versions) {
         CruiseControl cruiseControl = null;
         CruiseControlSpec spec  = kafkaAssembly.getSpec().getCruiseControl();
+        KafkaClusterSpec kafkaClusterSpec = kafkaAssembly.getSpec().getKafka();
 
         if (spec != null) {
             cruiseControl = new CruiseControl(kafkaAssembly);
@@ -170,7 +171,7 @@ public static CruiseControl fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup ver
             cruiseControl.setReplicas(DEFAULT_REPLICAS);
             String image = spec.getImage();
             if (image == null) {
-                image = System.getenv().get(ClusterOperatorConfig.STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE);
+                image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE, versions.kafkaImage(kafkaClusterSpec.getImage(), versions.defaultVersion().version()));
             }
             cruiseControl.setImage(image);
 
@@ -181,7 +182,6 @@ public static CruiseControl fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup ver
 
             String tlsSideCarImage = tlsSidecar.getImage();
             if (tlsSideCarImage == null) {
-                KafkaClusterSpec kafkaClusterSpec = kafkaAssembly.getSpec().getKafka();
                 tlsSideCarImage = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_TLS_SIDECAR_CRUISE_CONTROL_IMAGE, versions.kafkaImage(kafkaClusterSpec.getImage(), versions.defaultVersion().version()));
             }
 
@@ -191,7 +191,6 @@ public static CruiseControl fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup ver
 
             cruiseControl = updateConfiguration(spec, cruiseControl);
 
-            KafkaClusterSpec kafkaClusterSpec = kafkaAssembly.getSpec().getKafka();
             KafkaConfiguration configuration = new KafkaConfiguration(kafkaClusterSpec.getConfig().entrySet());
             if (configuration.getConfigOption(MIN_INSYNC_REPLICAS) != null) {
                 cruiseControl.minInsyncReplicas = configuration.getConfigOption(MIN_INSYNC_REPLICAS);

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.KafkaTopicList;
 import io.strimzi.api.kafka.model.DoneableKafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopic;
+import io.strimzi.operator.common.Util;
 import io.strimzi.operator.topic.zk.Zk;
 import io.vertx.core.AbstractVerticle;
 import io.vertx.core.Future;
@@ -65,7 +66,7 @@ public Session(KubernetesClient kubeClient, Config config) {
         this.config = config;
         StringBuilder sb = new StringBuilder(System.lineSeparator());
         for (Config.Value<?> v: Config.keys()) {
-            sb.append("\t").append(v.key).append(": ").append(config.get(v)).append(System.lineSeparator());
+            sb.append("\t").append(v.key).append(": ").append(Util.maskPassword(v.key, config.get(v).toString())).append(System.lineSeparator());
         }
         LOGGER.info("Using config:{}", sb.toString());
         setupMetrics();

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/DeploymentUtils.java
Patch:
@@ -115,7 +115,7 @@ public static Map<String, String> waitTillDepHasRolled(String name, int expected
 
     /**
      * Method to wait when DeploymentConfig will be recreated after rolling update
-     * @param clusterName Kafka Connect S2I cluster name
+     * @param clusterName DeploymentConfig name
      * @param snapshot Snapshot of pods for DeploymentConfig before the rolling update
      * @return The snapshot of the DeploymentConfig after rolling update with Uid for every pod
      */

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/ReplicaSetUtils.java
Patch:
@@ -24,7 +24,7 @@ private ReplicaSetUtils() { }
      */
     public static void waitForReplicaSetDeletion(String name) {
         LOGGER.debug("Waiting for ReplicaSet of Deployment {} deletion", name);
-        TestUtils.waitFor("StatefulSet " + name + " to be deleted", Constants.POLL_INTERVAL_FOR_RESOURCE_DELETION, Constants.TIMEOUT_FOR_RESOURCE_DELETION,
+        TestUtils.waitFor("ReplicaSet " + name + " to be deleted", Constants.POLL_INTERVAL_FOR_RESOURCE_DELETION, Constants.TIMEOUT_FOR_RESOURCE_DELETION,
             () -> {
                 if (!kubeClient().replicaSetExists(name)) {
                     return true;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/SecretUtils.java
Patch:
@@ -36,11 +36,11 @@ public static void waitForSecretReady(String secretName) {
     }
 
     public static void waitForSecretReady(String secretName, Runnable onTimeout) {
-        LOGGER.info("Waiting for KafkaUser secret {}", secretName);
+        LOGGER.info("Waiting for Secret {}", secretName);
         TestUtils.waitFor("Expected secret " + secretName + " exists", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_SECRET_CREATION,
             () -> kubeClient().getSecret(secretName) != null,
             onTimeout);
-        LOGGER.info("KafkaUser secret {} created", secretName);
+        LOGGER.info("Secret {} created", secretName);
     }
 
     public static void createSecret(String secretName, String dataKey, String dataValue) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/ServiceUtils.java
Patch:
@@ -22,7 +22,7 @@ public class ServiceUtils {
 
     private ServiceUtils() { }
 
-    public static void waitForKafkaServiceLabelsChange(String serviceName, Map<String, String> labels) {
+    public static void waitForServiceLabelsChange(String serviceName, Map<String, String> labels) {
         for (Map.Entry<String, String> entry : labels.entrySet()) {
             boolean isK8sTag = entry.getKey().equals("controller-revision-hash") || entry.getKey().equals("statefulset.kubernetes.io/pod-name");
             boolean isStrimziTag = entry.getKey().startsWith(Labels.STRIMZI_DOMAIN);
@@ -37,7 +37,7 @@ public static void waitForKafkaServiceLabelsChange(String serviceName, Map<Strin
         }
     }
 
-    public static void waitForKafkaServiceLabelsDeletion(String serviceName, String... labelKeys) {
+    public static void waitForServiceLabelsDeletion(String serviceName, String... labelKeys) {
         for (final String labelKey : labelKeys) {
             LOGGER.info("Service label {} change to {}", labelKey, null);
             TestUtils.waitFor("Service label" + labelKey + " change to " + null, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS,

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java
Patch:
@@ -245,7 +245,7 @@ public static void waitUntilPodsByNameStability(String podNamePrefix) {
     }
 
     /**
-     * * Waits until all matching pods are {@linkplain #verifyThatPodsAreStable(Supplier, int[])} stable} in the "Running" phase.
+     * * Waits until all matching pods are {@linkplain #verifyThatPodsAreStable(Supplier)} stable} in the "Running" phase.
      * @param pods all pods that will be verified
      */
     public static void waitUntilPodsStability(List<Pod> pods) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConfigurationTests.java
Patch:
@@ -84,11 +84,11 @@ public void passwordType() {
     @Test
     public void invalidVersion() {
         assertConfigError("inter.broker.protocol.version", "dclncswn",
-                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E");
+                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E|\\Q2.5\\E(\\.[0-9]+)*|\\Q2.5-IV0\\E");
     }
 
     @Test
     public void validVersion() {
-        assertNoError("inter.broker.protocol.version", "2.3-IV0");
+        assertNoError("inter.broker.protocol.version", "2.5-IV0");
     }
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMaker2ClusterTest.java
Patch:
@@ -1249,7 +1249,7 @@ public void testGenerateDeploymentWithOldVersion() {
         assertThrows(InvalidResourceException.class, () -> {
             KafkaMirrorMaker2 resource = new KafkaMirrorMaker2Builder(this.resource)
                     .editSpec()
-                        .withVersion("2.3.1")  
+                        .withVersion("2.3.1")
                     .endSpec()
                     .build();
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaVersionTest.java
Patch:
@@ -26,7 +26,7 @@ public void parsingTest() throws Exception {
         KafkaVersion defaultVersion = KafkaVersion.parseKafkaVersions(
                 new StringReader(KafkaVersionTestUtils.getKafkaVersionYaml()), map);
         assertThat(defaultVersion.version(), is(KafkaVersionTestUtils.DEFAULT_KAFKA_VERSION));
-        assertThat(map.size(), is(4));
+        assertThat(map.size(), is(3));
         assertThat(map.containsKey(KafkaVersionTestUtils.LATEST_KAFKA_VERSION), is(true));
         assertThat(map.get(KafkaVersionTestUtils.LATEST_KAFKA_VERSION).version(), is(KafkaVersionTestUtils.LATEST_KAFKA_VERSION));
         assertThat(map.get(KafkaVersionTestUtils.LATEST_KAFKA_VERSION).protocolVersion(), is(KafkaVersionTestUtils.LATEST_PROTOCOL_VERSION));

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -76,7 +76,7 @@ public class Environment {
 
     private static final String SKIP_TEARDOWN_ENV = "SKIP_TEARDOWN";
 
-    private static final String ST_KAFKA_VERSION_DEFAULT = "2.4.1";
+    private static final String ST_KAFKA_VERSION_DEFAULT = "2.5.0";
     public static final String STRIMZI_ORG_DEFAULT = "strimzi";
     public static final String STRIMZI_TAG_DEFAULT = "latest";
     public static final String STRIMZI_REGISTRY_DEFAULT = "docker.io";

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java
Patch:
@@ -88,7 +88,7 @@ void runVersionChange(TestKafkaVersion initialVersion, TestKafkaVersion newVersi
             kafkaPods = StatefulSetUtils.ssSnapshot(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME));
 
             // Wait for log.message.format.version change
-            if (!sameMinorVersion) {
+            if (!sameMinorVersion && testInfo.getDisplayName().contains("Downgrade"))   {
                 KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {
                     LOGGER.info("Kafka config before updating '{}'", kafka.getSpec().getKafka().getConfig().toString());
                     Map<String, Object> config = kafka.getSpec().getKafka().getConfig();

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -422,7 +422,7 @@ private static ClusterRoleBinding getClusterRoleBindingFromYaml(String yamlPath)
 
     private static Deployment waitFor(Deployment deployment) {
         String deploymentName = deployment.getMetadata().getName();
-        DeploymentUtils.waitForDeploymentReady(deploymentName, deployment.getSpec().getReplicas());
+        DeploymentUtils.waitForDeploymentAndPodsReady(deploymentName, deployment.getSpec().getReplicas());
         return deployment;
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/OlmResource.java
Patch:
@@ -63,7 +63,7 @@ public static void deleteOlm(String deploymentName, String namespace, String csv
 
     private static void waitFor(String deploymentName, String namespace, int replicas) {
         LOGGER.info("Waiting for deployment {} in namespace {}", deploymentName, namespace);
-        DeploymentUtils.waitForDeploymentReady(deploymentName, replicas);
+        DeploymentUtils.waitForDeploymentAndPodsReady(deploymentName, replicas);
         LOGGER.info("Deployment {} in namespace {} is ready", deploymentName, namespace);
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -12,9 +12,8 @@
 import io.strimzi.api.kafka.model.DoneableKafkaBridge;
 import io.strimzi.api.kafka.model.KafkaBridge;
 import io.strimzi.api.kafka.model.KafkaBridgeBuilder;
-import io.strimzi.api.kafka.model.KafkaBridgeResources;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -93,7 +92,7 @@ private static KafkaBridge waitFor(KafkaBridge kafkaBridge) {
         String kafkaBridgeCrName = kafkaBridge.getMetadata().getName();
 
         LOGGER.info("Waiting for KafkaBridge {}", kafkaBridgeCrName);
-        DeploymentUtils.waitForDeploymentReady(KafkaBridgeResources.deploymentName(kafkaBridgeCrName), kafkaBridge.getSpec().getReplicas());
+        KafkaBridgeUtils.waitForKafkaBridgeReady(kafkaBridgeCrName);
         LOGGER.info("KafkaBridge {} is ready", kafkaBridgeCrName);
 
         return kafkaBridge;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -18,7 +18,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.resources.KubernetesResource;
-import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -124,7 +124,7 @@ private static KafkaConnect waitFor(KafkaConnect kafkaConnect) {
         String kafkaConnectCrName = kafkaConnect.getMetadata().getName();
 
         LOGGER.info("Waiting for KafkaConnect {}", kafkaConnectCrName);
-        DeploymentUtils.waitForDeploymentReady(KafkaConnectResources.deploymentName(kafkaConnectCrName), kafkaConnect.getSpec().getReplicas());
+        KafkaConnectUtils.waitForConnectReady(kafkaConnectCrName);
         LOGGER.info("KafkaConnect {} is ready", kafkaConnectCrName);
 
         return kafkaConnect;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -108,7 +108,7 @@ private static KafkaConnectS2I waitFor(KafkaConnectS2I kafkaConnectS2I) {
         String kafkaConnectS2ICrName = kafkaConnectS2I.getMetadata().getName();
 
         LOGGER.info("Waiting for KafkaConnectS2I {}", kafkaConnectS2ICrName);
-        KafkaConnectS2IUtils.waitForConnectS2IStatus(kafkaConnectS2ICrName, "Ready");
+        KafkaConnectS2IUtils.waitForConnectS2IReady(kafkaConnectS2ICrName);
         LOGGER.info("KafkaConnectS2I {} is ready", kafkaConnectS2ICrName);
 
         return kafkaConnectS2I;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -95,7 +95,7 @@ private static KafkaConnector waitFor(KafkaConnector kafkaConnector) {
         String kafkaConnectorCrName = kafkaConnector.getMetadata().getName();
 
         LOGGER.info("Waiting for KafkaConnector {}", kafkaConnectorCrName);
-        KafkaConnectorUtils.waitForConnectorStatus(kafkaConnectorCrName, "Ready");
+        KafkaConnectorUtils.waitForConnectorReady(kafkaConnectorCrName);
         LOGGER.info("KafkaConnector {} is ready", kafkaConnectorCrName);
 
         return kafkaConnector;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -15,11 +15,10 @@
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2Builder;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2ClusterSpec;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2ClusterSpecBuilder;
-import io.strimzi.api.kafka.model.KafkaMirrorMaker2Resources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMaker2Utils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -141,7 +140,7 @@ private static KafkaMirrorMaker2 waitFor(KafkaMirrorMaker2 kafkaMirrorMaker2) {
         String kafkaMirrorMaker2CrName = kafkaMirrorMaker2.getMetadata().getName();
 
         LOGGER.info("Waiting for KafkaMirrorMaker2 {}", kafkaMirrorMaker2CrName);
-        DeploymentUtils.waitForDeploymentReady(KafkaMirrorMaker2Resources.deploymentName(kafkaMirrorMaker2CrName), kafkaMirrorMaker2.getSpec().getReplicas());
+        KafkaMirrorMaker2Utils.waitForKafkaMirrorMaker2Ready(kafkaMirrorMaker2CrName);
         LOGGER.info("KafkaMirrorMaker2 {} is ready", kafkaMirrorMaker2CrName);
 
         return kafkaMirrorMaker2;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -12,11 +12,10 @@
 import io.strimzi.api.kafka.model.DoneableKafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerBuilder;
-import io.strimzi.api.kafka.model.KafkaMirrorMakerResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaMirrorMakerUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.kafka.clients.consumer.ConsumerConfig;
 import org.apache.kafka.clients.producer.ProducerConfig;
@@ -118,7 +117,7 @@ private static KafkaMirrorMaker waitFor(KafkaMirrorMaker kafkaMirrorMaker) {
         String kafkaMirrorMakerCrName = kafkaMirrorMaker.getMetadata().getName();
 
         LOGGER.info("Waiting for KafkaMirrorMaker {}", kafkaMirrorMakerCrName);
-        DeploymentUtils.waitForDeploymentReady(KafkaMirrorMakerResources.deploymentName(kafkaMirrorMakerCrName), kafkaMirrorMaker.getSpec().getReplicas());
+        KafkaMirrorMakerUtils.waitForKafkaMirrorMakerReady(kafkaMirrorMakerCrName);
         LOGGER.info("KafkaMirrorMaker {} is ready", kafkaMirrorMakerCrName);
 
         return kafkaMirrorMaker;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.systemtest.utils.kafkaUtils;
 
-import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.api.kafka.model.status.ListenerStatus;
@@ -49,7 +48,7 @@ public static void waitUntilKafkaStatus(String clusterName, String state) {
         LOGGER.info("Wait until Kafka CR will be in state: {}", state);
         TestUtils.waitFor("Waiting for Kafka resource status is: " + state, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
             List<Condition> conditions =
-                    Crds.kafkaOperation(kubeClient().getClient()).inNamespace(kubeClient().getNamespace()).withName(clusterName)
+                   KafkaResource.kafkaClient().inNamespace(kubeClient().getNamespace()).withName(clusterName)
                             .get().getStatus().getConditions().stream().filter(condition -> !condition.getType().equals("Warning"))
                             .collect(Collectors.toList());
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/DeploymentUtils.java
Patch:
@@ -163,8 +163,8 @@ public static void waitForDeploymentReady(String name) {
      * @param name The name of the Deployment.
      * @param expectPods The expected number of pods.
      */
-    public static void waitForDeploymentReady(String name, int expectPods) {
-        LOGGER.info("Waiting for Deployment {}", name);
+    public static void waitForDeploymentAndPodsReady(String name, int expectPods) {
+        LOGGER.debug("Waiting for Deployment {}", name);
         TestUtils.waitFor("deployment " + name + " pods to be ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> kubeClient().getDeploymentStatus(name),
             () -> DeploymentUtils.logCurrentDeploymentStatus(kubeClient().getDeployment(name)));

File: systemtest/src/test/java/io/strimzi/systemtest/RecoveryST.java
Patch:
@@ -47,7 +47,7 @@ void testRecoveryFromEntityOperatorDeletion() {
 
         LOGGER.info("Waiting for recovery {}", entityOperatorDeploymentName);
         DeploymentUtils.waitForDeploymentRecovery(entityOperatorDeploymentName, entityOperatorDeploymentUid);
-        DeploymentUtils.waitForDeploymentReady(entityOperatorDeploymentName, 1);
+        DeploymentUtils.waitForDeploymentAndPodsReady(entityOperatorDeploymentName, 1);
 
         timeMeasuringSystem.stopOperation(timeMeasuringSystem.getOperationID());
     }

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -63,7 +63,6 @@ void testUserWithNameMoreThan64Chars() {
 
         // Create sasl user with long name, shouldn't fail
         KafkaUserResource.scramShaUser(CLUSTER_NAME, saslUserWithLongName).done();
-        KafkaUserUtils.waitForKafkaUserCreation(saslUserWithLongName);
 
         KafkaUserResource.kafkaUserWithoutWait(KafkaUserResource.defaultUser(CLUSTER_NAME, userWithLongName)
             .withNewSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/PrometheusST.java
Patch:
@@ -84,7 +84,7 @@ void setup() throws IOException {
         SecretUtils.waitForSecretReady("additional-scrape-configs");
         SecretUtils.waitForSecretReady("alertmanager-alertmanager");
 
-        DeploymentUtils.waitForDeploymentReady("prometheus-operator", 1);
+        DeploymentUtils.waitForDeploymentAndPodsReady("prometheus-operator", 1);
 
         cmdKubeClient().apply(FileUtils.updateNamespaceOfYamlFile("../examples/metrics/prometheus-install/strimzi-service-monitor.yaml", NAMESPACE));
         cmdKubeClient().apply(FileUtils.updateNamespaceOfYamlFile("../examples/metrics/prometheus-install/strimzi-pod-monitor.yaml", NAMESPACE));

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java
Patch:
@@ -17,6 +17,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.HttpUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;
 import io.strimzi.test.TestUtils;
@@ -118,7 +119,7 @@ void testProducerConsumerConnect() {
 
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_PATH, "http://localhost:8083");
+        KafkaConnectorUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_PATH, "http://localhost:8083");
 
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_PATH);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -20,6 +20,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.HttpUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;
@@ -130,7 +131,7 @@ void testProducerConsumerConnect() {
 
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        KafkaConnectUtils.createFileSinkConnector(defaultKafkaClientsPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
+        KafkaConnectorUtils.createFileSinkConnector(defaultKafkaClientsPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
 
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_PATH);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/olm/OlmBaseST.java
Patch:
@@ -73,23 +73,23 @@ void doTestDeployExampleKafkaConnectS2I() {
     void doTestDeployExampleKafkaBridge() {
         JsonObject kafkaBridgeResource = OlmResource.getExampleResources().get(KafkaBridge.RESOURCE_KIND);
         cmdKubeClient().applyContent(kafkaBridgeResource.toString());
-        KafkaBridgeUtils.waitUntilKafkaBridgeStatus(kafkaBridgeResource.getJsonObject("metadata").getString("name"), "Ready");
+        KafkaBridgeUtils.waitForKafkaBridgeReady(kafkaBridgeResource.getJsonObject("metadata").getString("name"));
     }
 
     void doTestDeployExampleKafkaMirrorMaker() {
         JsonObject kafkaMirroMakerResource = OlmResource.getExampleResources().get(KafkaMirrorMaker.RESOURCE_KIND);
         cmdKubeClient().applyContent(kafkaMirroMakerResource.toString()
                 .replace("my-source-cluster-kafka-bootstrap", "my-cluster-kafka-bootstrap")
                 .replace("my-target-cluster-kafka-bootstrap", "my-cluster-kafka-bootstrap"));
-        KafkaMirrorMakerUtils.waitUntilKafkaMirrorMakerStatus(kafkaMirroMakerResource.getJsonObject("metadata").getString("name"), "Ready");
+        KafkaMirrorMakerUtils.waitForKafkaMirrorMakerReady(kafkaMirroMakerResource.getJsonObject("metadata").getString("name"));
     }
 
     void doTestDeployExampleKafkaMirrorMaker2() {
         JsonObject kafkaMirrorMaker2Resource = OlmResource.getExampleResources().get(KafkaMirrorMaker2.RESOURCE_KIND);
         cmdKubeClient().applyContent(kafkaMirrorMaker2Resource.toString()
                 .replace("my-cluster-source-kafka-bootstrap", "my-cluster-kafka-bootstrap")
                 .replace("my-cluster-target-kafka-bootstrap", "my-cluster-kafka-bootstrap"));
-        KafkaMirrorMaker2Utils.waitUntilKafkaMirrorMaker2Status(kafkaMirrorMaker2Resource.getJsonObject("metadata").getString("name"), "Ready");
+        KafkaMirrorMaker2Utils.waitForKafkaMirrorMaker2Ready(kafkaMirrorMaker2Resource.getJsonObject("metadata").getString("name"));
     }
 
     @AfterAll

File: systemtest/src/test/java/io/strimzi/systemtest/recovery/NamespaceDeletionRecoveryST.java
Patch:
@@ -155,7 +155,7 @@ void testTopicNotAvailable() throws InterruptedException {
                 .endUserOperator().build());
         });
 
-        DeploymentUtils.waitForDeploymentReady(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), 1);
+        DeploymentUtils.waitForDeploymentAndPodsReady(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), 1);
 
         KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).done();
 

File: systemtest/src/test/java/io/strimzi/systemtest/topic/TopicST.java
Patch:
@@ -200,9 +200,6 @@ void testDeleteTopicEnableFalse() {
 
         KafkaTopicResource.topic(isolatedKafkaCluster, topicName).done();
 
-        KafkaTopicUtils.waitForKafkaTopicCreation(topicName);
-        LOGGER.info("Topic {} was created", topicName);
-
         String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(isolatedKafkaCluster + "-" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();
 
         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -16,6 +16,7 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.HttpUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;
 import io.strimzi.systemtest.utils.specific.TracingUtils;
@@ -717,7 +718,7 @@ void testConnectS2IService() {
         String execPodName = kubeClient().listPodsByPrefixInName(KAFKA_CLIENTS_NAME).get(0).getMetadata().getName();
 
         LOGGER.info("Creating FileSink connect via Pod:{}", execPodName);
-        KafkaConnectUtils.createFileSinkConnector(execPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_PATH,
+        KafkaConnectorUtils.createFileSinkConnector(execPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_PATH,
                 KafkaConnectResources.url(kafkaConnectS2IName, NAMESPACE, 8083));
 
         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -224,7 +224,7 @@ private void performUpgrade(JsonObject testParameters, int produceMessagesCount,
         copyModifyApply(coDir);
 
         LOGGER.info("Waiting for CO deployment");
-        DeploymentUtils.waitForDeploymentReady("strimzi-cluster-operator", 1);
+        DeploymentUtils.waitForDeploymentAndPodsReady("strimzi-cluster-operator", 1);
         LOGGER.info("CO ready");
 
         // In chainUpgrade we want to setup Kafka only at the begging and then upgrade it via CO
@@ -239,7 +239,7 @@ private void performUpgrade(JsonObject testParameters, int produceMessagesCount,
             LOGGER.info("Waiting for Kafka StatefulSet");
             StatefulSetUtils.waitForAllStatefulSetPodsReady(CLUSTER_NAME + "-kafka", 3);
             LOGGER.info("Waiting for EO Deployment");
-            DeploymentUtils.waitForDeploymentReady(CLUSTER_NAME + "-entity-operator", 1);
+            DeploymentUtils.waitForDeploymentAndPodsReady(CLUSTER_NAME + "-entity-operator", 1);
         }
         // We don't need to update KafkaUser during chain upgrade this way
         if (KafkaUserResource.kafkaUserClient().inNamespace(NAMESPACE).withName(userName).get() == null) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -2038,7 +2038,7 @@ public NetworkPolicy generateNetworkPolicy(boolean namespaceAndPodSelectorNetwor
                     .build();
 
             NetworkPolicyPeer kafkaExporterPeer = new NetworkPolicyPeerBuilder()
-                    .withNewPodSelector() // cluster operator
+                    .withNewPodSelector() // kafka exporter
                         .addToMatchLabels(Labels.STRIMZI_NAME_LABEL, KafkaExporter.kafkaExporterName(cluster))
                     .endPodSelector()
                     .build();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -599,7 +599,7 @@ public NetworkPolicy generateNetworkPolicy(boolean namespaceAndPodSelectorNetwor
             List<NetworkPolicyIngressRule> rules = new ArrayList<>(2);
 
             // Give CO access to the REST API
-            NetworkPolicyIngressRule replicationRule = new NetworkPolicyIngressRuleBuilder()
+            NetworkPolicyIngressRule restApiRule = new NetworkPolicyIngressRuleBuilder()
                     .addNewPort()
                     .withNewPort(REST_API_PORT)
                     .endPort()
@@ -630,10 +630,10 @@ public NetworkPolicy generateNetworkPolicy(boolean namespaceAndPodSelectorNetwor
                         .build();
                 peers.add(clusterOperatorPeer);
 
-                replicationRule.setFrom(peers);
+                restApiRule.setFrom(peers);
             }
 
-            rules.add(replicationRule);
+            rules.add(restApiRule);
 
             // If metrics are enabled, we have to open them as well. Otherwise they will be blocked.
             if (isMetricsEnabled) {

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -48,7 +48,9 @@ public class KafkaClusterSpec implements UnknownPropertyPreserving, Serializable
 
     public static final String FORBIDDEN_PREFIXES = "listeners, advertised., broker., listener., host.name, port, "
             + "inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, "
-            + "zookeeper.connect, zookeeper.set.acl, authorizer., super.user";
+            + "zookeeper.connect, zookeeper.set.acl, authorizer., super.user"
+            + "cruise.control.metrics.topic, cruise.control.metrics.reporter.bootstrap.servers";
+
     public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
 
     protected Storage storage;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -45,11 +45,13 @@ public class ClusterOperatorConfig {
     public static final String STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE";
     public static final String STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE";
     public static final String STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE";
+    public static final String STRIMZI_DEFAULT_TLS_SIDECAR_CRUISE_CONTROL_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_CRUISE_CONTROL_IMAGE";
     public static final String STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE = "STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE";
     public static final String STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE = "STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE";
     public static final String STRIMZI_DEFAULT_USER_OPERATOR_IMAGE = "STRIMZI_DEFAULT_USER_OPERATOR_IMAGE";
     public static final String STRIMZI_DEFAULT_KAFKA_INIT_IMAGE = "STRIMZI_DEFAULT_KAFKA_INIT_IMAGE";
     public static final String STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE = "STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE";
+    public static final String STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE = "STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE";
 
     public static final long DEFAULT_FULL_RECONCILIATION_INTERVAL_MS = 120_000;
     public static final long DEFAULT_OPERATION_TIMEOUT_MS = 300_000;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/StorageUtilsTest.java
Patch:
@@ -25,6 +25,8 @@ public void testSizeConversion() {
         assertThat(StorageUtils.parseMemory("100T"), is(100L * 1_000L * 1_000L * 1_000L * 1_000L));
         assertThat(StorageUtils.parseMemory("100Pi"), is(100L * 1_024L * 1_024L * 1_024L * 1_024L * 1_024L));
         assertThat(StorageUtils.parseMemory("100P"), is(100L * 1_000L * 1_000L * 1_000L * 1_000L * 1_000L));
+        assertThat(StorageUtils.parseMemory("100.5P"), is((long) (100.5 * 1_000L * 1_000L * 1_000L * 1_000L * 1_000L)));
+        assertThat(StorageUtils.parseMemory("2.1e6"), is((long) (2.1 * 1_000L * 1_000L)));
 
         assertThat(StorageUtils.parseMemory("100Gi") == StorageUtils.parseMemory("100Gi"), is(true));
         assertThat(StorageUtils.parseMemory("1000Gi") > StorageUtils.parseMemory("100Gi"), is(true));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/TopicOperatorTest.java
Patch:
@@ -94,7 +94,7 @@ public class TopicOperatorTest {
             .withTlsSidecar(tlsSidecar)
             .build();
 
-    private final Kafka resource = ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCm, kafkaConfig, zooConfig, kafkaStorage, zkStorage, topicOperator, kafkaLogJson, zooLogJson, null);
+    private final Kafka resource = ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCm, kafkaConfig, zooConfig, kafkaStorage, zkStorage, topicOperator, kafkaLogJson, zooLogJson, null, null);
     private final TopicOperator tc = TopicOperator.fromCrd(resource, VERSIONS);
 
     private List<EnvVar> getExpectedEnvVars() {
@@ -124,7 +124,7 @@ public void testFromConfigMapNoConfig() {
     public void testFromConfigMapDefaultConfig() {
         Kafka resource = ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image,
                 healthDelay, healthTimeout, metricsCm, kafkaConfig, zooConfig,
-                kafkaStorage, zkStorage, new TopicOperatorSpec(), kafkaLogJson, zooLogJson, null);
+                kafkaStorage, zkStorage, new TopicOperatorSpec(), kafkaLogJson, zooLogJson, null, null);
         TopicOperator tc = TopicOperator.fromCrd(resource, VERSIONS);
         assertThat(tc.getImage(), is("strimzi/operator:latest"));
         assertThat(tc.getWatchedNamespace(), is(namespace));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -109,7 +109,7 @@ public class ZookeeperClusterTest {
             .withReadinessProbe(new ProbeBuilder().withInitialDelaySeconds(tlsHealthDelay).withTimeoutSeconds(tlsHealthTimeout).build())
             .build();
 
-    private final Kafka ka = new KafkaBuilder(ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, configurationJson, zooConfigurationJson, null, null, null, kafkaLogConfigJson, zooLogConfigJson, null))
+    private final Kafka ka = new KafkaBuilder(ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, configurationJson, zooConfigurationJson, null, null, null, kafkaLogConfigJson, zooLogConfigJson, null, null))
             .editSpec()
                 .editZookeeper()
                     .withTlsSidecar(tlsSidecar)

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -119,7 +119,7 @@ public class Environment {
     private Environment() { }
 
     static {
-        String debugFormat = "{}:{}";
+        String debugFormat = "{}: {}";
         LOGGER.info("Used environment variables:");
         LOGGER.info(debugFormat, STRIMZI_ORG_ENV, STRIMZI_ORG);
         LOGGER.info(debugFormat, STRIMZI_TAG_ENV, STRIMZI_TAG);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -92,9 +92,9 @@ private static KafkaBridge getKafkaBridgeFromYaml(String yamlPath) {
     private static KafkaBridge waitFor(KafkaBridge kafkaBridge) {
         String kafkaBridgeCrName = kafkaBridge.getMetadata().getName();
 
-        LOGGER.info("Waiting for Kafka Bridge {}", kafkaBridgeCrName);
+        LOGGER.info("Waiting for KafkaBridge {}", kafkaBridgeCrName);
         DeploymentUtils.waitForDeploymentReady(KafkaBridgeResources.deploymentName(kafkaBridgeCrName), kafkaBridge.getSpec().getReplicas());
-        LOGGER.info("Kafka Bridge {} is ready", kafkaBridgeCrName);
+        LOGGER.info("KafkaBridge {} is ready", kafkaBridgeCrName);
 
         return kafkaBridge;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -123,9 +123,9 @@ private static KafkaConnect getKafkaConnectFromYaml(String yamlPath) {
     private static KafkaConnect waitFor(KafkaConnect kafkaConnect) {
         String kafkaConnectCrName = kafkaConnect.getMetadata().getName();
 
-        LOGGER.info("Waiting for Kafka Connect {}", kafkaConnectCrName);
+        LOGGER.info("Waiting for KafkaConnect {}", kafkaConnectCrName);
         DeploymentUtils.waitForDeploymentReady(KafkaConnectResources.deploymentName(kafkaConnectCrName), kafkaConnect.getSpec().getReplicas());
-        LOGGER.info("Kafka Connect {} is ready", kafkaConnectCrName);
+        LOGGER.info("KafkaConnect {} is ready", kafkaConnectCrName);
 
         return kafkaConnect;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -107,9 +107,9 @@ private static KafkaConnectS2I getKafkaConnectS2IFromYaml(String yamlPath) {
     private static KafkaConnectS2I waitFor(KafkaConnectS2I kafkaConnectS2I) {
         String kafkaConnectS2ICrName = kafkaConnectS2I.getMetadata().getName();
 
-        LOGGER.info("Waiting for Kafka ConnectS2I {}", kafkaConnectS2ICrName);
+        LOGGER.info("Waiting for KafkaConnectS2I {}", kafkaConnectS2ICrName);
         KafkaConnectS2IUtils.waitForConnectS2IStatus(kafkaConnectS2ICrName, "Ready");
-        LOGGER.info("Kafka ConnectS2I {} is ready", kafkaConnectS2ICrName);
+        LOGGER.info("KafkaConnectS2I {} is ready", kafkaConnectS2ICrName);
 
         return kafkaConnectS2I;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -94,9 +94,9 @@ private static KafkaConnector getKafkaConnectorFromYaml(String yamlPath) {
     private static KafkaConnector waitFor(KafkaConnector kafkaConnector) {
         String kafkaConnectorCrName = kafkaConnector.getMetadata().getName();
 
-        LOGGER.info("Waiting for Kafka Connector {}", kafkaConnectorCrName);
+        LOGGER.info("Waiting for KafkaConnector {}", kafkaConnectorCrName);
         KafkaConnectorUtils.waitForConnectorStatus(kafkaConnectorCrName, "Ready");
-        LOGGER.info("Kafka Connector {} is ready", kafkaConnectorCrName);
+        LOGGER.info("KafkaConnector {} is ready", kafkaConnectorCrName);
 
         return kafkaConnector;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -140,9 +140,9 @@ private static KafkaMirrorMaker2 getKafkaMirrorMaker2FromYaml(String yamlPath) {
     private static KafkaMirrorMaker2 waitFor(KafkaMirrorMaker2 kafkaMirrorMaker2) {
         String kafkaMirrorMaker2CrName = kafkaMirrorMaker2.getMetadata().getName();
 
-        LOGGER.info("Waiting for Kafka MirrorMaker2 {}", kafkaMirrorMaker2CrName);
+        LOGGER.info("Waiting for KafkaMirrorMaker2 {}", kafkaMirrorMaker2CrName);
         DeploymentUtils.waitForDeploymentReady(KafkaMirrorMaker2Resources.deploymentName(kafkaMirrorMaker2CrName), kafkaMirrorMaker2.getSpec().getReplicas());
-        LOGGER.info("Kafka MirrorMaker2 {} is ready", kafkaMirrorMaker2CrName);
+        LOGGER.info("KafkaMirrorMaker2 {} is ready", kafkaMirrorMaker2CrName);
 
         return kafkaMirrorMaker2;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -117,9 +117,9 @@ private static KafkaMirrorMaker getKafkaMirrorMakerFromYaml(String yamlPath) {
     private static KafkaMirrorMaker waitFor(KafkaMirrorMaker kafkaMirrorMaker) {
         String kafkaMirrorMakerCrName = kafkaMirrorMaker.getMetadata().getName();
 
-        LOGGER.info("Waiting for Kafka MirrorMaker {}", kafkaMirrorMakerCrName);
+        LOGGER.info("Waiting for KafkaMirrorMaker {}", kafkaMirrorMakerCrName);
         DeploymentUtils.waitForDeploymentReady(KafkaMirrorMakerResources.deploymentName(kafkaMirrorMakerCrName), kafkaMirrorMaker.getSpec().getReplicas());
-        LOGGER.info("Kafka MirrorMaker {} is ready", kafkaMirrorMakerCrName);
+        LOGGER.info("KafkaMirrorMaker {} is ready", kafkaMirrorMakerCrName);
 
         return kafkaMirrorMaker;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaTopicResource.java
Patch:
@@ -80,9 +80,9 @@ private static KafkaTopic getKafkaTopicFromYaml(String yamlPath) {
     private static KafkaTopic waitFor(KafkaTopic kafkaTopic) {
         String kafkaTopicCrName = kafkaTopic.getMetadata().getName();
 
-        LOGGER.info("Waiting for Kafka Topic {}", kafkaTopicCrName);
+        LOGGER.info("Waiting for KafkaTopic {}", kafkaTopicCrName);
         KafkaTopicUtils.waitForKafkaTopicCreation(kafkaTopicCrName);
-        LOGGER.info("Kafka Topic {} is ready", kafkaTopicCrName);
+        LOGGER.info("KafkaTopic {} is ready", kafkaTopicCrName);
 
         return kafkaTopic;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaUserResource.java
Patch:
@@ -70,9 +70,9 @@ public static KafkaUser kafkaUserWithoutWait(KafkaUser user) {
     private static KafkaUser waitFor(KafkaUser kafkaUser) {
         String kafkaUserCrName = kafkaUser.getMetadata().getName();
 
-        LOGGER.info("Waiting for Kafka User {}", kafkaUserCrName);
+        LOGGER.info("Waiting for KafkaUser {}", kafkaUserCrName);
         KafkaUserUtils.waitForKafkaUserCreation(kafkaUserCrName);
-        LOGGER.info("Kafka User {} is ready", kafkaUserCrName);
+        LOGGER.info("KafkaUser {} is ready", kafkaUserCrName);
 
         return kafkaUser;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java
Patch:
@@ -32,7 +32,7 @@ public static void waitUntilClientReceivedMessagesTls(KafkaClientOperations kafk
                     receivedMessages = kafkaClient.receiveMessagesTls(Constants.GLOBAL_CLIENTS_TIMEOUT);
                     return receivedMessages == exceptedMessages;
                 } catch (Exception e) {
-                    LOGGER.info("Client not received excepted messages {}, instead received only {}!", exceptedMessages, receivedMessages);
+                    LOGGER.warn("Client not received excepted messages {}, instead received only {}!", exceptedMessages, receivedMessages);
                     return false;
                 }
             });

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaBridgeUtils.java
Patch:
@@ -65,10 +65,10 @@ public static void checkSendResponse(JsonObject response, int messageCount) {
     }
 
     public static void waitUntilKafkaBridgeStatus(String clusterName, String state) {
-        LOGGER.info("Waiting till Kafka Bridge CR will be in state: {}", state);
+        LOGGER.info("Wait until KafkaBridge {} will be in state: {}", clusterName, state);
         TestUtils.waitFor("Waiting for Kafka resource status is: " + state, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,
             () -> KafkaBridgeResource.kafkaBridgeClient().inNamespace(kubeClient().getNamespace()).withName(clusterName).get().getStatus().getConditions().get(0).getType().equals(state)
         );
-        LOGGER.info("Kafka Bridge CR is in state: {}", state);
+        LOGGER.info("KafkaBridge {}} is in state: {}", clusterName, state);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectorUtils.java
Patch:
@@ -45,12 +45,12 @@ public static void waitForConnectorStability(String connectorName, String connec
     }
 
     public static void waitForConnectorStatus(String name, String state) {
-        LOGGER.info("Waiting for Kafka Connector {}", name);
-        TestUtils.waitFor(" Kafka Connector " + name + " is ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        LOGGER.info("Wait until KafkaConnector {} will be in state: {}", name, state);
+        TestUtils.waitFor(" KafkaConnector " + name + " is ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> KafkaConnectorResource.kafkaConnectorClient().inNamespace(kubeClient().getNamespace())
                     .withName(name).get().getStatus().getConditions().get(0).getType().equals(state),
             () -> StUtils.logCurrentStatus(KafkaConnectorResource.kafkaConnectorClient().inNamespace(kubeClient().getNamespace()).withName(name).get()));
-        LOGGER.info("Kafka Connector {} is ready", name);
+        LOGGER.info("KafkaConnector {} is {}", name, state);
     }
 
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaMirrorMaker2Utils.java
Patch:
@@ -19,11 +19,11 @@ public class KafkaMirrorMaker2Utils {
     private KafkaMirrorMaker2Utils() {}
 
     public static void waitUntilKafkaMirrorMaker2Status(String clusterName, String state) {
-        LOGGER.info("Waiting till Kafka MirrorMaker2 CR will be in state: {}", state);
-        TestUtils.waitFor("Waiting for Kafka resource status is: " + state, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,
+        LOGGER.info("Wait until KafkaMirrorMaker2 will be in state: {}", state);
+        TestUtils.waitFor("KafkaMirrorMaker2 resource status is: " + state, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,
             () -> KafkaMirrorMaker2Resource.kafkaMirrorMaker2Client().inNamespace(kubeClient().getNamespace())
                 .withName(clusterName).get().getStatus().getConditions().get(0).getType().equals(state)
         );
-        LOGGER.info("Kafka MirrorMaker2 CR is in state: {}", state);
+        LOGGER.info("KafkaMirrorMaker2 is in state: {}", state);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaMirrorMakerUtils.java
Patch:
@@ -19,11 +19,11 @@ public class KafkaMirrorMakerUtils {
     private KafkaMirrorMakerUtils() {}
 
     public static void waitUntilKafkaMirrorMakerStatus(String clusterName, String state) {
-        LOGGER.info("Waiting till Kafka MirrorMaker CR will be in state: {}", state);
+        LOGGER.info("Wait until KafkaMirrorMaker CR will be in state: {}", state);
         TestUtils.waitFor("Waiting for Kafka resource status is: " + state, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,
             () -> KafkaMirrorMakerResource.kafkaMirrorMakerClient().inNamespace(kubeClient().getNamespace())
                 .withName(clusterName).get().getStatus().getConditions().get(0).getType().equals(state)
         );
-        LOGGER.info("Kafka MirrorMaker CR is in state: {}", state);
+        LOGGER.info("KafkaMirrorMaker CR is in state: {}", state);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaUtils.java
Patch:
@@ -46,7 +46,7 @@ public static void waitUntilKafkaCRIsNotReady(String clusterName) {
     }
 
     public static void waitUntilKafkaStatus(String clusterName, String state) {
-        LOGGER.info("Waiting till Kafka CR will be in state: {}", state);
+        LOGGER.info("Wait until Kafka CR will be in state: {}", state);
         TestUtils.waitFor("Waiting for Kafka resource status is: " + state, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
             List<Condition> conditions =
                     Crds.kafkaOperation(kubeClient().getClient()).inNamespace(kubeClient().getNamespace()).withName(clusterName)

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/ReplicaSetUtils.java
Patch:
@@ -23,7 +23,7 @@ private ReplicaSetUtils() { }
      * @param name The name of the ReplicaSet
      */
     public static void waitForReplicaSetDeletion(String name) {
-        LOGGER.debug("Waiting for deletion of ReplicaSet of Deployment {}", name);
+        LOGGER.debug("Waiting for ReplicaSet of Deployment {} deletion", name);
         TestUtils.waitFor("StatefulSet " + name + " to be deleted", Constants.POLL_INTERVAL_FOR_RESOURCE_DELETION, Constants.TIMEOUT_FOR_RESOURCE_DELETION,
             () -> {
                 if (!kubeClient().replicaSetExists(name)) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/NamespaceUtils.java
Patch:
@@ -18,9 +18,10 @@ public class NamespaceUtils {
     private NamespaceUtils() { }
 
     public static void waitForNamespaceDeletion(String name) {
-        LOGGER.info("Waiting when Namespace {} to be deleted", name);
+        LOGGER.info("Waiting for Namespace {} deletion", name);
 
         TestUtils.waitFor("namespace " + name, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> kubeClient().getNamespace(name) == null);
+        LOGGER.info("Namespace {} was deleted", name);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/MetricsUtils.java
Patch:
@@ -50,7 +50,7 @@ public static String collectMetrics(String podName, int port, String metricsPath
         int ret = exec.execute(null, executableCommand, 20_000);
 
         synchronized (LOCK) {
-            LOGGER.info("Metrics collection for pod {} return code - {}", podName, ret);
+            LOGGER.info("Metrics collection for Pod {} finished with return code: {}", podName, ret);
         }
         return exec.out();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/specific/TracingUtils.java
Patch:
@@ -31,7 +31,7 @@ public static void verify(String jaegerServiceName, String clientPodName) {
     }
 
     private static void verifyThatServiceIsPresent(String jaegerServiceName, String clientPodName) {
-        TestUtils.waitFor("Wait until service" + jaegerServiceName + " is present", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
+        TestUtils.waitFor("Service" + jaegerServiceName + " is present", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
             JsonObject jaegerServices = new JsonObject(cmdKubeClient().execInPod(clientPodName, "/bin/bash", "-c", "curl " + JAEGER_QUERY_SERVICE + ":" + JAEGER_QUERY_PORT + JAEGER_QUERY_SERVICE_ENDPOINT).out());
 
             LOGGER.info("Jaeger services {}", jaegerServices.getJsonArray("data").contains(jaegerServiceName));
@@ -40,7 +40,7 @@ private static void verifyThatServiceIsPresent(String jaegerServiceName, String
     }
 
     private static void verifyThatServiceTracesArePresent(String jaegerServiceName, String clientPodName) {
-        TestUtils.waitFor("Wait until service" + jaegerServiceName + " has some traces", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
+        TestUtils.waitFor("Service" + jaegerServiceName + " has some traces", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
             JsonObject jaegerServicesTraces = new JsonObject(cmdKubeClient().execInPod(clientPodName,
                 "/bin/bash", "-c", "curl " + JAEGER_QUERY_SERVICE + ":" + JAEGER_QUERY_PORT + JAEGER_QUERY_SERVICE_TRACES_ENDPOINT + jaegerServiceName).out());
             JsonArray traces = jaegerServicesTraces.getJsonArray("data");

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -81,7 +81,7 @@ void testKafkaInDifferentNsThanClusterOperator() {
      */
     @Test
     void testDeployMirrorMakerAcrossMultipleNamespace() {
-        LOGGER.info("Deploying Kafka MirrorMaker in different namespace than CO when CO watches all namespaces");
+        LOGGER.info("Deploying KafkaMirrorMaker in different namespace than CO when CO watches all namespaces");
         checkMirrorMakerForKafkaInDifNamespaceThanCO(SECOND_CLUSTER_NAME);
     }
 
@@ -143,8 +143,8 @@ void testUserInDifferentNamespace() {
         KafkaUserUtils.waitForKafkaUserCreation(USER_NAME);
         Condition kafkaCondition = KafkaUserResource.kafkaUserClient().inNamespace(SECOND_NAMESPACE).withName(USER_NAME)
                 .get().getStatus().getConditions().get(0);
-        LOGGER.info("Kafka User condition status: {}", kafkaCondition.getStatus());
-        LOGGER.info("Kafka User condition type: {}", kafkaCondition.getType());
+        LOGGER.info("KafkaUser condition status: {}", kafkaCondition.getStatus());
+        LOGGER.info("KafkaUser condition type: {}", kafkaCondition.getType());
 
         assertThat(kafkaCondition.getType(), is("Ready"));
 

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -236,7 +236,7 @@ void testSecretsWithKafkaConnectS2IWithTlsAndScramShaAuthentication() {
         String kafkaConnectS2IPodName = kubeClient().listPods("type", "kafka-connect-s2i").get(0).getMetadata().getName();
         String kafkaConnectS2ILogs = kubeClient().logs(kafkaConnectS2IPodName);
 
-        LOGGER.info("Verifying that in kafka connect logs are everything fine");
+        LOGGER.info("Verifying that in KafkaConnect logs not contain ERRORs");
         assertThat(kafkaConnectS2ILogs, not(containsString("ERROR")));
 
         LOGGER.info("Creating FileStreamSink connector via pod {} with topic {}", tlsKafkaClientsPodName, CONNECT_S2I_TOPIC_NAME);
@@ -354,7 +354,7 @@ void testJvmAndResources() {
                     .build());
         });
 
-        TestUtils.waitFor("Kafka Connect CR change", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("KafkaConnect change", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> kubeClient().getClient().adapt(OpenShiftClient.class).buildConfigs().inNamespace(NAMESPACE).withName(kafkaConnectS2IName + "-connect").get().getSpec().getResources().getRequests().get("cpu").equals(new Quantity("1")));
 
         cmdKubeClient().exec("start-build", KafkaConnectS2IResources.deploymentName(kafkaConnectS2IName), "-n", NAMESPACE);

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -214,7 +214,7 @@ void testKafkaConnectWithPlainAndScramShaAuthentication() throws InterruptedExce
 
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        LOGGER.info("Verifying that in kafka connect logs are everything fine");
+        LOGGER.info("Verifying that KafkaConnect pod logs don't contain ERRORs");
         assertThat(kafkaConnectLogs, not(containsString("ERROR")));
 
         LOGGER.info("Creating FileStreamSink connector via pod {} with topic {}", kafkaClientsPodName, CONNECT_TOPIC_NAME);
@@ -407,7 +407,7 @@ void testSecretsWithKafkaConnectWithTlsAndTlsClientAuthentication() {
 
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        LOGGER.info("Verifying that in kafka connect logs are everything fine");
+        LOGGER.info("Verifying that KafkaConnect pod logs don't contain ERRORs");
         assertThat(kafkaConnectLogs, not(containsString("ERROR")));
 
         LOGGER.info("Creating FileStreamSink connector via pod {} with topic {}", kafkaClientsPodName, CONNECT_TOPIC_NAME);
@@ -488,7 +488,7 @@ void testSecretsWithKafkaConnectWithTlsAndScramShaAuthentication() {
         String kafkaConnectPodName = kubeClient().listPods("type", "kafka-connect").get(0).getMetadata().getName();
         String kafkaConnectLogs = kubeClient().logs(kafkaConnectPodName);
 
-        LOGGER.info("Verifying that in kafka connect logs are everything fine");
+        LOGGER.info("Verifying that KafkaConnect pod logs don't contain ERRORs");
         assertThat(kafkaConnectLogs, not(containsString("ERROR")));
 
         LOGGER.info("Creating FileStreamSink connector via pod {} with topic {}", kafkaClientsPodName, CONNECT_TOPIC_NAME);

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -1904,7 +1904,7 @@ void testMessagesAreStoredInDisk() {
             .withConsumerGroupName(CONSUMER_GROUP_NAME + "-" + rng.nextInt(Integer.MAX_VALUE))
             .build();
 
-        TestUtils.waitFor("Wait for kafka topic creation inside kafka pod", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,
+        TestUtils.waitFor("KafkaTopic creation inside kafka pod", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT,
             () -> !cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), "/bin/bash",
                         "-c", "cd /var/lib/kafka/data/kafka-log0; ls -1 | sed -n '/test/p'").out().equals(""));
 

File: systemtest/src/test/java/io/strimzi/systemtest/LogSettingST.java
Patch:
@@ -200,13 +200,13 @@ void testLoggersKafkaConnect() {
     @Test
     @Order(6)
     void testLoggersMirrorMaker() {
-        assertThat("Mirror maker's log level is set properly", checkLoggersLevel(MIRROR_MAKER_LOGGERS, MM_MAP), is(true));
+        assertThat("KafkaMirrorMaker's log level is set properly", checkLoggersLevel(MIRROR_MAKER_LOGGERS, MM_MAP), is(true));
     }
 
     @Test
     @Order(7)
     void testLoggersMirrorMaker2() {
-        assertThat("Mirror maker2's log level is set properly", checkLoggersLevel(MIRROR_MAKER_LOGGERS, MM2_MAP), is(true));
+        assertThat("KafkaMirrorMaker2's log level is set properly", checkLoggersLevel(MIRROR_MAKER_LOGGERS, MM2_MAP), is(true));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/MultipleNamespaceST.java
Patch:
@@ -56,7 +56,7 @@ void testKafkaInDifferentNsThanClusterOperator() {
      */
     @Test
     void testDeployMirrorMakerAcrossMultipleNamespace() {
-        LOGGER.info("Deploying Kafka MirrorMaker in different namespace than CO when CO watches multiple namespaces");
+        LOGGER.info("Deploying KafkaMirrorMaker in different namespace than CO when CO watches multiple namespaces");
         checkMirrorMakerForKafkaInDifNamespaceThanCO(CLUSTER_NAME);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -235,7 +235,7 @@ void testDiscoveryAnnotation() {
 
     @BeforeAll
     void createClassResources() throws InterruptedException {
-        LOGGER.info("Deploy Kafka and Kafka Bridge before tests");
+        LOGGER.info("Deploy Kafka and KafkaBridge before tests");
         // Deploy kafka
         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)
             .editSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -187,7 +187,7 @@ void testScramShaAuthWithWeirdNamedUser() throws Exception {
 
     @BeforeAll
     void setup() throws InterruptedException {
-        LOGGER.info("Deploy Kafka and Kafka Bridge before tests");
+        LOGGER.info("Deploy Kafka and KafkaBridge before tests");
 
         KafkaListenerAuthenticationTls auth = new KafkaListenerAuthenticationTls();
         KafkaListenerTls listenerTls = new KafkaListenerTls();

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -183,7 +183,7 @@ void testTlsAuthWithWeirdNamedUser() throws Exception {
 
     @BeforeAll
     void createClassResources() throws InterruptedException {
-        LOGGER.info("Deploy Kafka and Kafka Bridge before tests");
+        LOGGER.info("Deploy Kafka and KafkaBridge before tests");
 
         // Deploy kafka
         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 1, 1)

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -118,21 +118,21 @@ void testZookeeperWatchersCount() {
     void testKafkaConnectRequests() {
         Pattern connectRequests = Pattern.compile("kafka_connect_node_request_total\\{clientid=\".*\",} ([\\d.][^\\n]+)");
         ArrayList<Double> values = MetricsUtils.collectSpecificMetric(connectRequests, kafkaConnectMetricsData);
-        assertThat("Kafka Connect requests count doesn't match expected value", values.stream().mapToDouble(i -> i).sum() > 0);
+        assertThat("KafkaConnect requests count doesn't match expected value", values.stream().mapToDouble(i -> i).sum() > 0);
     }
 
     @Test
     void testKafkaConnectResponse() {
         Pattern connectResponse = Pattern.compile("kafka_connect_node_response_total\\{clientid=\".*\",} ([\\d.][^\\n]+)");
         ArrayList<Double> values = MetricsUtils.collectSpecificMetric(connectResponse, kafkaConnectMetricsData);
-        assertThat("Kafka Connect response count doesn't match expected value", values.stream().mapToDouble(i -> i).sum() > 0);
+        assertThat("KafkaConnect response count doesn't match expected value", values.stream().mapToDouble(i -> i).sum() > 0);
     }
 
     @Test
     void testKafkaConnectIoNetwork() {
         Pattern connectIoNetwork = Pattern.compile("kafka_connect_network_io_total\\{clientid=\".*\",} ([\\d.][^\\n]+)");
         ArrayList<Double> values = MetricsUtils.collectSpecificMetric(connectIoNetwork, kafkaConnectMetricsData);
-        assertThat("Kafka Connect IO network count doesn't match expected value", values.stream().mapToDouble(i -> i).sum() > 0);
+        assertThat("KafkaConnect IO network count doesn't match expected value", values.stream().mapToDouble(i -> i).sum() > 0);
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java
Patch:
@@ -79,7 +79,7 @@ void testProducerConsumer() {
         );
     }
 
-    @Description("As an oauth kafka connect, I should be able to sink messages from kafka broker topic.")
+    @Description("As an oauth KafkaConnect, I should be able to sink messages from kafka broker topic.")
     @Test
     @Tag(CONNECT)
     @Tag(CONNECT_COMPONENTS)

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -68,8 +68,8 @@ public class OauthTlsST extends OauthBaseST {
     private OauthExternalKafkaClient oauthExternalKafkaClientTls;
 
     @Description(
-            "As an oauth producer, i am able to produce messages to the kafka broker\n" +
-            "As an oauth consumer, i am able to consumer messages from the kafka broker using encrypted communication")
+            "As an oauth producer, I am able to produce messages to the kafka broker\n" +
+            "As an oauth consumer, I am able to consumer messages from the kafka broker using encrypted communication")
     @Test
     void testProducerConsumer() {
         oauthExternalKafkaClientTls.verifyProducedAndConsumedMessages(
@@ -78,7 +78,7 @@ void testProducerConsumer() {
         );
     }
 
-    @Description("As an oauth kafka connect, i am able to sink messages from kafka broker topic using encrypted communication.")
+    @Description("As an oauth KafkaConnect, I am able to sink messages from kafka broker topic using encrypted communication.")
     @Test
     @Tag(CONNECT)
     @Tag(CONNECT_COMPONENTS)

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -256,7 +256,7 @@ private void performUpgrade(JsonObject testParameters, int produceMessagesCount,
 
         // Wait until user will be created
         SecretUtils.waitForSecretReady(userName);
-        TestUtils.waitFor("Kafka User " + userName + "availability", 10_000L, 120_000L,
+        TestUtils.waitFor("KafkaUser " + userName + "availability", 10_000L, 120_000L,
             () -> !cmdKubeClient().getResourceAsYaml("kafkauser", userName).equals(""));
 
         // Deploy clients and exchange messages

File: systemtest/src/test/java/io/strimzi/systemtest/OpenShiftTemplatesST.java
Patch:
@@ -110,7 +110,6 @@ void testStrimziEphemeralWithCustomParameters() {
                 "KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR", "5",
                 "KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR", "5"));
 
-        //TODO Add assertions to check that Kafka brokers have a custom configuration
         Kafka kafka = getKafka(clusterName);
         assertThat(kafka, is(notNullValue()));
 

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -796,7 +796,7 @@ void testTriggerRollingUpdateAfterOverrideBootstrap() throws CertificateExceptio
 
         KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {
 
-            LOGGER.info("Adding new bootstrap dns:{} to external listeners", bootstrapDns);
+            LOGGER.info("Adding new bootstrap dns: {} to external listeners", bootstrapDns);
             kafka.getSpec().getKafka().getListeners().setExternal(
                 new KafkaListenerExternalNodePortBuilder()
                     .withNewOverrides()
@@ -830,8 +830,6 @@ void testTriggerRollingUpdateAfterOverrideBootstrap() throws CertificateExceptio
 
         LOGGER.info("Verifying that new DNS is inside kafka CR");
         assertThat(bootstrapAddressDns, is(bootstrapDns));
-
-        // TODO: send and recv messages via this new bootstrap (after client builder) https://github.com/strimzi/strimzi-kafka-operator/pull/2520
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaVersionTest.java
Patch:
@@ -26,7 +26,7 @@ public void parsingTest() throws Exception {
         KafkaVersion defaultVersion = KafkaVersion.parseKafkaVersions(
                 new StringReader(KafkaVersionTestUtils.getKafkaVersionYaml()), map);
         assertThat(defaultVersion.version(), is(KafkaVersionTestUtils.DEFAULT_KAFKA_VERSION));
-        assertThat(map.size(), is(3));
+        assertThat(map.size(), is(4));
         assertThat(map.containsKey(KafkaVersionTestUtils.LATEST_KAFKA_VERSION), is(true));
         assertThat(map.get(KafkaVersionTestUtils.LATEST_KAFKA_VERSION).version(), is(KafkaVersionTestUtils.LATEST_KAFKA_VERSION));
         assertThat(map.get(KafkaVersionTestUtils.LATEST_KAFKA_VERSION).protocolVersion(), is(KafkaVersionTestUtils.LATEST_PROTOCOL_VERSION));

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -76,7 +76,7 @@ public class Environment {
 
     private static final String SKIP_TEARDOWN_ENV = "SKIP_TEARDOWN";
 
-    private static final String ST_KAFKA_VERSION_DEFAULT = "2.4.0";
+    private static final String ST_KAFKA_VERSION_DEFAULT = "2.4.1";
     public static final String STRIMZI_ORG_DEFAULT = "strimzi";
     public static final String STRIMZI_TAG_DEFAULT = "latest";
     public static final String STRIMZI_REGISTRY_DEFAULT = "docker.io";

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/StrimziUpgradeST.java
Patch:
@@ -208,7 +208,7 @@ void testUpgradeKafkaWithoutVersion() throws IOException {
         DeploymentUtils.waitTillDepHasRolled(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), 1, eoSnapshot);
 
         assertThat(kubeClient().getStatefulSet(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME)).getSpec().getTemplate().getSpec().getContainers()
-                .stream().filter(c -> c.getName().equals("kafka")).findFirst().get().getImage(), containsString("2.4.0"));
+                .stream().filter(c -> c.getName().equals("kafka")).findFirst().get().getImage(), containsString("2.4.1"));
     }
 
     private void performUpgrade(JsonObject testParameters, int produceMessagesCount, int consumeMessagesCount) throws IOException {

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -147,7 +147,7 @@ void testKafkaConnectWithFileSinkPlugin() {
         KafkaConnectUtils.createFileSinkConnector(kafkaClientsPodName, CONNECT_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
 
         InternalKafkaClient internalKafkaClient = new InternalKafkaClient.Builder()
-            .withUsingPodName(kafkaConnectPodName)
+            .withUsingPodName(kafkaClientsPodName)
             .withTopicName(CONNECT_TOPIC_NAME)
             .withNamespaceName(NAMESPACE)
             .withClusterName(CLUSTER_NAME)

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -867,6 +867,7 @@ void testClusterCaRemovedTriggersRollingUpdate() {
 
         // some kind of accident happened and the CA secret has been deleted
         kubeClient().deleteSecret(KafkaResources.clusterCaKeySecretName(CLUSTER_NAME));
+        StatefulSetUtils.waitTillSsHasRolled(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME), 3, zkPods);
         StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaPods);
 
         assertThat(kubeClient(NAMESPACE).getSecret(CLUSTER_NAME + "-zookeeper-nodes").getData().get(CLUSTER_NAME + "-zookeeper-0.crt"), is(not(zkCrtBeforeAccident)));

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/LogHasNoUnexpectedErrors.java
Patch:
@@ -74,7 +74,8 @@ enum LogWhiteList {
         // This is whitelisted cause it's no real problem when this error appears, components are being created even after timeout
         RECONCILIATION_TIMEOUT("ERROR Abstract.*Operator:[0-9]+ - Reconciliation.*"),
         ASSEMBLY_OPERATOR_RECONCILIATION_TIMEOUT("ERROR .*AssemblyOperator:[0-9]+ - Reconciliation.*[fF]ailed.*"),
-        WATCHER_CLOSED_EXCEPTION("ERROR AbstractOperator:.+ - Watcher closed with exception in namespace .*");
+        WATCHER_CLOSED_EXCEPTION("ERROR AbstractOperator:.+ - Watcher closed with exception in namespace .*"),
+        CONCURRENT_RESOURCE_DELETION("io.strimzi.operator.cluster.operator.resource.ConcurrentDeletionException");
 
         final String name;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -2667,7 +2667,7 @@ Future<Void> cleanPodAndPvc(StatefulSetOperator stsOperator, StatefulSet sts, St
                         // We have to wait for the pod to be actually deleted
                         log.debug("{}: Checking if Pod {} has been deleted", reconciliation, podName);
 
-                        Future<Void> waitForDeletion = podOperations.waitFor(namespace, podName, pollingIntervalMs, timeoutMs, (ignore1, ignore2) -> {
+                        Future<Void> waitForDeletion = podOperations.waitFor(namespace, podName, "deleted", pollingIntervalMs, timeoutMs, (ignore1, ignore2) -> {
                             Pod deletion = podOperations.get(namespace, podName);
                             log.trace("Checking if Pod {} in namespace {} has been deleted or recreated", podName, namespace);
                             return deletion == null;
@@ -2686,7 +2686,7 @@ Future<Void> cleanPodAndPvc(StatefulSetOperator stsOperator, StatefulSet sts, St
 
                             log.debug("{}: Checking if PVC {} for Pod {} has been deleted", reconciliation, pvcName, podName);
 
-                            Future<Void> waitForDeletion = pvcOperations.waitFor(namespace, pvcName, pollingIntervalMs, timeoutMs, (ignore1, ignore2) -> {
+                            Future<Void> waitForDeletion = pvcOperations.waitFor(namespace, pvcName, "deleted", pollingIntervalMs, timeoutMs, (ignore1, ignore2) -> {
                                 PersistentVolumeClaim deletion = pvcOperations.get(namespace, pvcName);
                                 log.trace("Checking if {} {} in namespace {} has been deleted", pvc.getKind(), pvcName, namespace);
                                 return deletion == null || (deletion.getMetadata() != null && !uid.equals(deletion.getMetadata().getUid()));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -325,7 +325,7 @@ protected Future<ReconcileResult<StatefulSet>> internalReplace(String namespace,
 
             operation().inNamespace(namespace).withName(name).cascading(cascading).withGracePeriod(-1L).delete();
 
-            Future<Void> deletedFut = waitFor(namespace, name, pollingIntervalMs, timeoutMs, (ignore1, ignore2) -> {
+            Future<Void> deletedFut = waitFor(namespace, name, "deleted", pollingIntervalMs, timeoutMs, (ignore1, ignore2) -> {
                 StatefulSet sts = get(namespace, name);
                 log.trace("Checking if {} {} in namespace {} has been deleted", resourceKind, name, namespace);
                 return sts == null;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperScaler.java
Patch:
@@ -141,6 +141,7 @@ private Future<ZooKeeperAdmin> connect()    {
 
             Util.waitFor(vertx,
                 String.format("ZooKeeperAdmin connection to %s", zookeeperConnectionString),
+                "connected",
                 1_000,
                 operationTimeoutMs,
                 () -> zkAdmin.getState().isAlive() && zkAdmin.getState().isConnected())

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperatorTest.java
Patch:
@@ -419,7 +419,7 @@ protected boolean shouldIncrementGeneration(StatefulSetDiff diff) {
             }
 
             @Override
-            public Future<Void> waitFor(String namespace, String name, long pollIntervalMs, final long timeoutMs, BiPredicate<String, String> predicate) {
+            public Future<Void> waitFor(String namespace, String name, String logState, long pollIntervalMs, final long timeoutMs, BiPredicate<String, String> predicate) {
                 return Future.succeededFuture();
             }
         };

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractNonNamespacedResourceOperator.java
Patch:
@@ -281,14 +281,16 @@ protected List<T> listInAnyNamespace(Labels selector) {
      * is ready.
      *
      * @param name The resource name.
+     * @param logState The state we are waiting for use in log messages
      * @param pollIntervalMs The poll interval in milliseconds.
      * @param timeoutMs The timeout, in milliseconds.
      * @param predicate The predicate.
      * @return a future that completes when the resource identified by the given {@code name} is ready.
      */
-    public Future<Void> waitFor(String name, long pollIntervalMs, final long timeoutMs, Predicate<String> predicate) {
+    public Future<Void> waitFor(String name, String logState, long pollIntervalMs, final long timeoutMs, Predicate<String> predicate) {
         return Util.waitFor(vertx,
             String.format("%s resource %s", resourceKind, name),
+            logState,
             pollIntervalMs,
             timeoutMs,
             () -> predicate.test(name));

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/DeploymentConfigOperator.java
Patch:
@@ -59,7 +59,7 @@ protected Future<ReconcileResult<DeploymentConfig>> internalPatch(String namespa
      * generation sequence number of the desired state.
      */
     public Future<Void> waitForObserved(String namespace, String name, long pollIntervalMs, long timeoutMs) {
-        return waitFor(namespace, name, pollIntervalMs, timeoutMs, this::isObserved);
+        return waitFor(namespace, name, "observed", pollIntervalMs, timeoutMs, this::isObserved);
     }
 
     /**

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/DeploymentOperator.java
Patch:
@@ -97,7 +97,7 @@ protected Future<ReconcileResult<Deployment>> internalPatch(String namespace, St
      * generation sequence number of the desired state.
      */
     public Future<Void> waitForObserved(String namespace, String name, long pollIntervalMs, long timeoutMs) {
-        return waitFor(namespace, name, pollIntervalMs, timeoutMs, this::isObserved);
+        return waitFor(namespace, name, "observed", pollIntervalMs, timeoutMs, this::isObserved);
     }
 
     /**

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/PodOperator.java
Patch:
@@ -71,7 +71,7 @@ public Future<Void> restart(String logContext, Pod pod, long timeoutMs) {
         log.debug("{}: Waiting for pod {} to be deleted", logContext, podName);
         Future<Void> podReconcileFuture =
                 reconcile(namespace, podName, null).compose(ignore -> {
-                    Future<Void> del = waitFor(namespace, podName, pollingIntervalMs, timeoutMs, (ignore1, ignore2) -> {
+                    Future<Void> del = waitFor(namespace, podName, "deleted", pollingIntervalMs, timeoutMs, (ignore1, ignore2) -> {
                         // predicate - changed generation means pod has been updated
                         String newUid = getPodUid(get(namespace, podName));
                         boolean done = !deleted.equals(newUid);

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/RouteOperator.java
Patch:
@@ -41,7 +41,7 @@ protected MixedOperation<Route, RouteList, DoneableRoute, Resource<Route, Doneab
      * @return A future that succeeds when the Route has an assigned address.
      */
     public Future<Void> hasAddress(String namespace, String name, long pollIntervalMs, long timeoutMs) {
-        return waitFor(namespace, name, pollIntervalMs, timeoutMs, this::isAddressReady);
+        return waitFor(namespace, name, "addressable", pollIntervalMs, timeoutMs, this::isAddressReady);
     }
 
     /**

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ServiceOperator.java
Patch:
@@ -116,7 +116,7 @@ public Future<Void> endpointReadiness(String namespace, Service desired, long po
      * @return A future that succeeds when the Service has an assigned address.
      */
     public Future<Void> hasIngressAddress(String namespace, String name, long pollIntervalMs, long timeoutMs) {
-        return waitFor(namespace, name, pollIntervalMs, timeoutMs, this::isIngressAddressReady);
+        return waitFor(namespace, name, "addressable", pollIntervalMs, timeoutMs, this::isIngressAddressReady);
     }
 
     /**

File: topic-operator/src/main/java/io/strimzi/operator/topic/K8sImpl.java
Patch:
@@ -94,7 +94,7 @@ public Future<Void> deleteResource(ResourceName resourceName) {
                     LOGGER.warn("KafkaTopic {} could not be deleted, since it doesn't seem to exist", resourceName.toString());
                     future.complete();
                 } else {
-                    Util.waitFor(vertx, "sync resource deletion " + resourceName, 1000, Long.MAX_VALUE, () -> {
+                    Util.waitFor(vertx, "sync resource deletion " + resourceName, "deleted", 1000, Long.MAX_VALUE, () -> {
                         KafkaTopic kafkaTopic = operation().inNamespace(namespace).withName(resourceName.toString()).get();
                         boolean notExists = kafkaTopic == null;
                         LOGGER.debug("KafkaTopic {} deleted {}", resourceName.toString(), notExists);

File: topic-operator/src/main/java/io/strimzi/operator/topic/KafkaImpl.java
Patch:
@@ -225,7 +225,7 @@ public Future<Void> deleteTopic(TopicName topicName) {
                 Collections.singleton(topicName.toString())).values().get(topicName.toString());
         queueWork(new UniWork<>("deleteTopic", future, handler));
         return handler.future().compose(ig ->
-                Util.waitFor(vertx, "deleted sync " + topicName, 1000, 120_000, () -> {
+                Util.waitFor(vertx, "deleted sync " + topicName, "deleted", 1000, 120_000, () -> {
                     try {
                         return adminClient.describeTopics(Collections.singleton(topicName.toString())).all().get().get(topicName.toString()) == null;
                     } catch (ExecutionException e) {

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -53,7 +53,7 @@ public class Environment {
     /**
      * Image pull policy env var for Components images (Kafka, Bridge, ...)
      */
-    private static final String COMPONENTS_IMAGE_PULL_POLICY_ENV = "IMAGE_PULL_POLICY";
+    private static final String COMPONENTS_IMAGE_PULL_POLICY_ENV = "COMPONENTS_IMAGE_PULL_POLICY";
     /**
      * Image pull policy env var for Operator images
      */

File: systemtest/src/test/java/io/strimzi/systemtest/MirrorMakerST.java
Patch:
@@ -269,8 +269,6 @@ void testMirrorMakerTlsAuthenticated() {
             .endSpec()
             .done();
 
-        timeMeasuringSystem.stopOperation(timeMeasuringSystem.getOperationID());
-
         internalKafkaClient.setTopicName(topicSourceName);
         internalKafkaClient.setClusterName(kafkaClusterSourceName);
         internalKafkaClient.setKafkaUsername(userSource.getMetadata().getName());

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -72,7 +72,7 @@ public interface Constants {
     String KAFKA_CLIENTS = "kafka-clients";
     String STRIMZI_DEPLOYMENT_NAME = "strimzi-cluster-operator";
     String ALWAYS_IMAGE_PULL_POLICY = "Always";
-    String IF_NOT_PRESENT_IMAGE_PULL_POLICY = "Always";
+    String IF_NOT_PRESENT_IMAGE_PULL_POLICY = "IfNotPresent";
 
     /**
      * Constants for specific ports

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -170,6 +170,7 @@ void testUserInDifferentNamespace() {
             .withNamespaceName(THIRD_NAMESPACE)
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
+            .withKafkaUsername(USER_NAME)
             .withConsumerGroupName(CONSUMER_GROUP_NAME)
             .build();
 

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -231,8 +231,8 @@ void testKafkaConnectWithPlainAndScramShaAuthentication() throws InterruptedExce
             .build();
 
         internalKafkaClient.checkProducedAndConsumedMessages(
-                internalKafkaClient.sendMessagesTls(),
-                internalKafkaClient.receiveMessagesTls()
+                internalKafkaClient.sendMessagesPlain(),
+                internalKafkaClient.receiveMessagesPlain()
         );
 
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_PATH, "99");

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -514,7 +514,7 @@ void verifyLabelsForCRDs() {
         kubeClient().listCustomResourceDefinition().stream()
             .filter(crd -> crd.getMetadata().getName().startsWith("kafka"))
             .forEach(crd -> {
-                LOGGER.info("Verifying labels for custom resource {]", crd.getMetadata().getName());
+                LOGGER.info("Verifying labels for custom resource {}", crd.getMetadata().getName());
                 assertThat(crd.getMetadata().getLabels().get("app"), is("strimzi"));
             });
     }

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/KubeCmdClient.java
Patch:
@@ -9,6 +9,7 @@
 import java.io.File;
 import java.util.Date;
 import java.util.List;
+import java.util.Map;
 
 import static java.util.Arrays.asList;
 import static java.util.stream.Collectors.toList;
@@ -127,6 +128,8 @@ default K delete(String... files) {
 
     String getResourceAsYaml(String resourceType, String resourceName);
 
+    void createResourceAndApply(String template, Map<String, String> params);
+
     String describe(String resourceType, String resourceName);
 
     default String logs(String pod) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -88,6 +88,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                 .withVolumeMounts(getVolumeMounts())
                 .withResources(getResources())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, image))
+                .withSecurityContext(templateContainerSecurityContext)
                 .build();
 
         DeploymentTriggerPolicy configChangeTrigger = new DeploymentTriggerPolicyBuilder()

File: systemtest/src/main/java/io/strimzi/systemtest/utils/FileUtils.java
Patch:
@@ -106,7 +106,7 @@ public static File updateNamespaceOfYamlFile(String pathToOrigin, String namespa
             encoded = Files.readAllBytes(Paths.get(pathToOrigin));
 
             String yaml = new String(encoded, StandardCharsets.UTF_8);
-            yaml = yaml.replaceAll("namespace: .*", "namespace: " + namespace);
+            yaml = yaml.replaceAll("myproject", namespace);
 
             osw.write(yaml);
             return yamlFile.toPath().toFile();

File: api/src/main/java/io/strimzi/api/kafka/model/EntityUserOperatorSpec.java
Patch:
@@ -36,6 +36,7 @@ public class EntityUserOperatorSpec implements UnknownPropertyPreserving, Serial
     public static final int DEFAULT_HEALTHCHECK_DELAY = 10;
     public static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;
     public static final int DEFAULT_ZOOKEEPER_PORT = 2181;
+    public static final int DEFAULT_BOOTSTRAP_SERVERS_PORT = 9091;
     public static final long DEFAULT_FULL_RECONCILIATION_INTERVAL_SECONDS = 120;
     public static final long DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS = 6;
 

File: systemtest/src/test/java/io/strimzi/systemtest/MirrorMaker2ST.java
Patch:
@@ -225,10 +225,8 @@ void testMirrorMaker2TlsAndTlsClientAuth() {
 
         // Create Kafka user
         KafkaUser userSource = KafkaUserResource.tlsUser(kafkaClusterSourceName, kafkaUserSourceName).done();
-        SecretUtils.waitForSecretReady(kafkaUserSourceName);
 
         KafkaUser userTarget = KafkaUserResource.tlsUser(kafkaClusterTargetName, kafkaUserTargetName).done();
-        SecretUtils.waitForSecretReady(kafkaUserTargetName);
 
         KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, userSource, userTarget).done();
 

File: systemtest/src/test/java/io/strimzi/systemtest/MirrorMakerST.java
Patch:
@@ -197,10 +197,8 @@ void testMirrorMakerTlsAuthenticated() {
 
         // Create Kafka user
         KafkaUser userSource = KafkaUserResource.tlsUser(kafkaClusterSourceName, kafkaSourceUserName).done();
-        SecretUtils.waitForSecretReady(kafkaSourceUserName);
 
         KafkaUser userTarget = KafkaUserResource.tlsUser(kafkaClusterTargetName, kafkaTargetUserName).done();
-        SecretUtils.waitForSecretReady(kafkaTargetUserName);
 
         // Initialize CertSecretSource with certificate and secret names for consumer
         CertSecretSource certSecretSource = new CertSecretSource();

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -279,8 +279,7 @@ void testKafkaAndZookeeperScaleUpScaleDown() {
                 .endKafka()
             .endSpec().done();
 
-        String userName = "alice";
-        KafkaUser user = KafkaUserResource.tlsUser(CLUSTER_NAME, userName).done();
+        KafkaUser user = KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();
 
         testDockerImagesForKafkaCluster(CLUSTER_NAME, NAMESPACE, 3, 1, false);
         // kafka cluster already deployed
@@ -304,7 +303,7 @@ void testKafkaAndZookeeperScaleUpScaleDown() {
             .withNamespaceName(NAMESPACE)
             .withClusterName(CLUSTER_NAME)
             .withMessageCount(MESSAGE_COUNT)
-            .withKafkaUsername(userName)
+            .withKafkaUsername(USER_NAME)
             .withConsumerGroupName(CONSUMER_GROUP_NAME + "-" + rng.nextInt(Integer.MAX_VALUE))
             .build();
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -12,7 +12,6 @@
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.HttpUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
-import io.strimzi.systemtest.utils.kubeUtils.objects.SecretUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;
 import io.vertx.core.json.JsonArray;
 import io.vertx.core.json.JsonObject;
@@ -144,7 +143,6 @@ void createClassResources() throws InterruptedException {
 
         // Create Kafka user
         KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();
-        SecretUtils.waitForSecretReady(USER_NAME);
 
         // Initialize CertSecretSource with certificate and secret names for consumer
         CertSecretSource certSecret = new CertSecretSource();

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeConsumerSpec.java
Patch:
@@ -21,9 +21,10 @@ public class KafkaBridgeConsumerSpec extends KafkaBridgeClientSpec {
     private static final long serialVersionUID = 1L;
 
     public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, group.id, sasl., security.";
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
 
     @Override
-    @Description("The Kafka consumer configuration used for consumer instances created by the bridge. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
+    @Description("The Kafka consumer configuration used for consumer instances created by the bridge. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     public Map<String, Object> getConfig() {
         return config;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeProducerSpec.java
Patch:
@@ -21,9 +21,10 @@ public class KafkaBridgeProducerSpec extends KafkaBridgeClientSpec {
     private static final long serialVersionUID = 1L;
 
     public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, sasl., security.";
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
 
     @Override
-    @Description("The Kafka producer configuration used for producer instances created by the bridge. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
+    @Description("The Kafka producer configuration used for producer instances created by the bridge. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     public Map<String, Object> getConfig() {
         return config;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -49,7 +49,7 @@ public class KafkaClusterSpec implements UnknownPropertyPreserving, Serializable
     public static final String FORBIDDEN_PREFIXES = "listeners, advertised., broker., listener., host.name, port, "
             + "inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, "
             + "zookeeper.connect, zookeeper.set.acl, authorizer., super.user";
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, ssl.cipher.suites";
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
 
     protected Storage storage;
 
@@ -89,7 +89,7 @@ public void setVersion(String version) {
         this.version = version;
     }
 
-    @Description("The kafka broker config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
+    @Description("The kafka broker config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public Map<String, Object> getConfig() {
         return config;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java
Patch:
@@ -31,15 +31,15 @@ public class KafkaConnectSpec extends AbstractKafkaConnectSpec {
     private static final long serialVersionUID = 1L;
 
     public static final String FORBIDDEN_PREFIXES = "ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers, consumer.interceptor.classes, producer.interceptor.classes";
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm";
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
 
     private Map<String, Object> config = new HashMap<>(0);
 
     private String bootstrapServers;
     private KafkaConnectTls tls;
     private KafkaClientAuthentication authentication;
 
-    @Description("The Kafka Connect configuration. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
+    @Description("The Kafka Connect configuration. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     public Map<String, Object> getConfig() {
         return config;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2ClusterSpec.java
Patch:
@@ -30,7 +30,7 @@
 public class KafkaMirrorMaker2ClusterSpec implements UnknownPropertyPreserving, Serializable {
 
     public static final String FORBIDDEN_PREFIXES = "ssl., sasl., security., listeners, plugin.path, rest., bootstrap.servers, consumer.interceptor.classes, producer.interceptor.classes";
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm";
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
 
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerConsumerSpec.java
Patch:
@@ -26,7 +26,7 @@ public class KafkaMirrorMakerConsumerSpec extends KafkaMirrorMakerClientSpec {
     private static final long serialVersionUID = 1L;
 
     public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, group.id, sasl., security., interceptor.classes";
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm";
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
 
     private Integer numStreams;
 
@@ -35,7 +35,7 @@ public class KafkaMirrorMakerConsumerSpec extends KafkaMirrorMakerClientSpec {
     private Integer offsetCommitInterval;
 
     @Override
-    @Description("The MirrorMaker consumer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
+    @Description("The MirrorMaker consumer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     public Map<String, Object> getConfig() {
         return config;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerProducerSpec.java
Patch:
@@ -25,7 +25,7 @@ public class KafkaMirrorMakerProducerSpec extends KafkaMirrorMakerClientSpec {
     private Boolean abortOnSendFailure;
 
     public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, sasl., security., interceptor.classes";
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm";
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "ssl.endpoint.identification.algorithm, ssl.cipher.suites, ssl.protocol, ssl.enabled.protocols";
 
     @Description("Flag to set the MirrorMaker to exit on a failed send. Default value is `true`.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
@@ -38,7 +38,7 @@ public void setAbortOnSendFailure(Boolean abortOnSendFailure) {
     }
 
     @Override
-    @Description("The MirrorMaker producer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
+    @Description("The MirrorMaker producer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES + " (with the exception of: " + FORBIDDEN_PREFIX_EXCEPTIONS + ").")
     public Map<String, Object> getConfig() {
         return config;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeConsumerConfiguration.java
Patch:
@@ -19,12 +19,12 @@
 public class KafkaBridgeConsumerConfiguration extends AbstractConfiguration {
 
     private static final List<String> FORBIDDEN_OPTIONS;
-
+    private static final List<String> EXCEPTIONS;
     private static final Map<String, String> DEFAULTS;
 
     static {
         FORBIDDEN_OPTIONS = asList(KafkaBridgeConsumerSpec.FORBIDDEN_PREFIXES.split(", "));
-
+        EXCEPTIONS = asList(KafkaBridgeConsumerSpec.FORBIDDEN_PREFIX_EXCEPTIONS.split(", "));
         DEFAULTS = new HashMap<>();
     }
 
@@ -35,6 +35,6 @@ public class KafkaBridgeConsumerConfiguration extends AbstractConfiguration {
      * @param jsonOptions     Json object with configuration options as key ad value pairs.
      */
     public KafkaBridgeConsumerConfiguration(Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(jsonOptions, FORBIDDEN_OPTIONS, DEFAULTS);
+        super(jsonOptions, FORBIDDEN_OPTIONS, EXCEPTIONS, DEFAULTS);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeProducerConfiguration.java
Patch:
@@ -19,12 +19,12 @@
 public class KafkaBridgeProducerConfiguration extends AbstractConfiguration {
 
     private static final List<String> FORBIDDEN_OPTIONS;
-
+    private static final List<String> EXCEPTIONS;
     private static final Map<String, String> DEFAULTS;
 
     static {
         FORBIDDEN_OPTIONS = asList(KafkaBridgeProducerSpec.FORBIDDEN_PREFIXES.split(", "));
-
+        EXCEPTIONS = asList(KafkaBridgeProducerSpec.FORBIDDEN_PREFIX_EXCEPTIONS.split(", "));
         DEFAULTS = new HashMap<>();
     }
 
@@ -35,6 +35,6 @@ public class KafkaBridgeProducerConfiguration extends AbstractConfiguration {
      * @param jsonOptions     Json object with configuration options as key ad value pairs.
      */
     public KafkaBridgeProducerConfiguration(Iterable<Map.Entry<String, Object>> jsonOptions) {
-        super(jsonOptions, FORBIDDEN_OPTIONS, DEFAULTS);
+        super(jsonOptions, FORBIDDEN_OPTIONS, EXCEPTIONS, DEFAULTS);
     }
 }

File: test/src/main/java/io/strimzi/test/WaitException.java
Patch:
@@ -4,8 +4,8 @@
  */
 package io.strimzi.test;
 
-public class TimeoutException extends RuntimeException {
-    public TimeoutException(String message) {
+public class WaitException extends RuntimeException {
+    public WaitException(String message) {
         super(message);
     }
-}
+}
\ No newline at end of file

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/ClientHandlerBase.java
Patch:
@@ -29,4 +29,7 @@ public void start() {
 
     protected abstract void handleClient();
 
+    public CompletableFuture<T> getResultPromise() {
+        return resultPromise;
+    }
 }
\ No newline at end of file

File: systemtest/src/main/java/io/strimzi/systemtest/utils/ClientUtils.java
Patch:
@@ -24,7 +24,7 @@ public class ClientUtils {
     // ensuring that object can not be created outside of class
     private ClientUtils() {}
 
-    public static void waitUntilClientReceivedMessagesTls(KafkaClientOperations<Integer> kafkaClient, int exceptedMessages) {
+    public static void waitUntilClientReceivedMessagesTls(KafkaClientOperations kafkaClient, int exceptedMessages) {
         TestUtils.waitFor("Kafka " + kafkaClient.toString() + " client received messages", Constants.GLOBAL_CLIENTS_POLL, Constants.GLOBAL_TIMEOUT,
             () -> {
                 int receivedMessages = 0;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -49,7 +49,7 @@ public class KafkaClusterSpec implements UnknownPropertyPreserving, Serializable
     public static final String FORBIDDEN_PREFIXES = "listeners, advertised., broker., listener., host.name, port, "
             + "inter.broker.listener.name, sasl., ssl., security., password., principal.builder.class, log.dir, "
             + "zookeeper.connect, zookeeper.set.acl, authorizer., super.user";
-    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms";
+    public static final String FORBIDDEN_PREFIX_EXCEPTIONS = "zookeeper.connection.timeout.ms, ssl.cipher.suites";
 
     protected Storage storage;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AuthenticationUtils.java
Patch:
@@ -267,7 +267,7 @@ public static Map<String, String> getClientAuthenticationProperties(KafkaClientA
                 if (oauth.getClientId() != null) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, oauth.getClientId()));
                 if (oauth.getTokenEndpointUri() != null) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, oauth.getTokenEndpointUri()));
                 if (oauth.isDisableTlsHostnameVerification()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM, ""));
-                if (!oauth.isAccessTokenIsJwt()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_TOKENS_NOT_JWT, true));
+                if (!oauth.isAccessTokenIsJwt()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_ACCESS_TOKEN_IS_JWT, false));
                 if (oauth.getMaxTokenExpirySeconds() > 0) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, oauth.getMaxTokenExpirySeconds()));
 
                 properties.put(OAUTH_CONFIG, String.join(" ", options));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -353,8 +353,8 @@ private String getSecurityProtocol(boolean tls, boolean sasl)   {
         if (oauth.isEnableECDSA()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_CRYPTO_PROVIDER_BOUNCYCASTLE, true));
         if (oauth.getIntrospectionEndpointUri() != null) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_INTROSPECTION_ENDPOINT_URI, oauth.getIntrospectionEndpointUri()));
         if (oauth.getUserNameClaim() != null) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_USERNAME_CLAIM, oauth.getUserNameClaim()));
-        if (!oauth.isAccessTokenIsJwt()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_TOKENS_NOT_JWT, true));
-        if (!oauth.isCheckAccessTokenType()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_VALIDATION_SKIP_TYPE_CHECK, true));
+        if (!oauth.isAccessTokenIsJwt()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_ACCESS_TOKEN_IS_JWT, false));
+        if (!oauth.isCheckAccessTokenType()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_CHECK_ACCESS_TOKEN_TYPE, false));
         if (oauth.isDisableTlsHostnameVerification()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM, ""));
 
         return options;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -875,7 +875,7 @@ public void testGenerateDeploymentWithOAuthUsingOpaqueTokens() {
         assertThat(cont.getEnv().stream().filter(var -> KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_OAUTH_CLIENT_SECRET.equals(var.getName())).findFirst().orElse(null).getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_OAUTH_CLIENT_SECRET.equals(var.getName())).findFirst().orElse(null).getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_OAUTH_CONFIG.equals(var.getName())).findFirst().orElse(null).getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ClientConfig.OAUTH_TOKENS_NOT_JWT, "true", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, "600")));
+                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ClientConfig.OAUTH_ACCESS_TOKEN_IS_JWT, "false", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, "600")));
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -885,8 +885,8 @@ public void testOAuthOptions()  {
         expectedOptions.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_CRYPTO_PROVIDER_BOUNCYCASTLE, true));
         expectedOptions.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_INTROSPECTION_ENDPOINT_URI, "http://introspection-endpoint"));
         expectedOptions.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_USERNAME_CLAIM, "preferred_username"));
-        expectedOptions.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_TOKENS_NOT_JWT, true));
-        expectedOptions.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_VALIDATION_SKIP_TYPE_CHECK, true));
+        expectedOptions.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_ACCESS_TOKEN_IS_JWT, false));
+        expectedOptions.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_CHECK_ACCESS_TOKEN_TYPE, false));
         expectedOptions.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM, ""));
 
         List<String> actualOptions = KafkaBrokerConfigurationBuilder.getOAuthOptions(auth);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -1390,13 +1390,13 @@ public void testGenerateDeploymentWithOAuthUsingOpaqueTokens() {
         assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElse(null).getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_CONSUMER.equals(var.getName())).findFirst().orElse(null).getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_CONSUMER.equals(var.getName())).findFirst().orElse(null).getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ClientConfig.OAUTH_TOKENS_NOT_JWT, "true", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, "600")));
+                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ClientConfig.OAUTH_ACCESS_TOKEN_IS_JWT, "false", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, "600")));
 
         assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_SASL_MECHANISM_PRODUCER.equals(var.getName())).findFirst().orElse(null).getValue(), is("oauth"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElse(null).getValueFrom().getSecretKeyRef().getName(), is("my-secret-secret"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CLIENT_SECRET_PRODUCER.equals(var.getName())).findFirst().orElse(null).getValueFrom().getSecretKeyRef().getKey(), is("my-secret-key"));
         assertThat(cont.getEnv().stream().filter(var -> KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OAUTH_CONFIG_PRODUCER.equals(var.getName())).findFirst().orElse(null).getValue().trim(),
-                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ClientConfig.OAUTH_TOKENS_NOT_JWT, "true", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, "600")));
+                is(String.format("%s=\"%s\" %s=\"%s\" %s=\"%s\" %s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, "my-client-id", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, "http://my-oauth-server", ClientConfig.OAUTH_ACCESS_TOKEN_IS_JWT, "false", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, "600")));
     }
 
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
Patch:
@@ -67,11 +67,11 @@ private static Map<String, String> buildEnv(String namespaces) {
 
     @BeforeAll
     public static void before() {
-        vertx = Vertx.vertx(new VertxOptions().setMetricsOptions(
+        VertxOptions options = new VertxOptions().setMetricsOptions(
                 new MicrometerMetricsOptions()
                         .setPrometheusOptions(new VertxPrometheusOptions().setEnabled(true))
-                        .setEnabled(true)
-        ));
+                        .setEnabled(true));
+        vertx = Vertx.vertx(options);
     }
 
     @AfterAll

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -116,9 +116,7 @@ public static void before() {
 
     @AfterAll
     public static void after() {
-        if (vertx != null) {
-            vertx.close();
-        }
+        vertx.close();
     }
 
     private Future<ArgumentCaptor<Secret>> reconcileCa(VertxTestContext context, CertificateAuthority clusterCa, CertificateAuthority clientsCa) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -136,9 +136,7 @@ public static void before() {
 
     @AfterAll
     public static void after() {
-        if (vertx != null) {
-            vertx.close();
-        }
+        vertx.close();
     }
 
     @BeforeEach

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -209,12 +209,12 @@ public void setFields(KafkaAssemblyOperatorMockTest.Params params) {
     private Kafka cluster;
 
     @BeforeAll
-    static void before() {
+    public static void before() {
         vertx = Vertx.vertx();
     }
 
     @AfterAll
-    static void after() {
+    public static void after() {
         vertx.close();
         ResourceUtils.cleanUpTemporaryTLSFiles();
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaRollerTest.java
Patch:
@@ -63,12 +63,12 @@ public class KafkaRollerTest {
     private List<String> restarted;
 
     @BeforeAll
-    public static void startVertx() {
+    public static void before() {
         vertx = Vertx.vertx();
     }
 
     @AfterAll
-    public static void stopVertx() {
+    public static void after() {
         vertx.close();
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ZookeeperLeaderFinderTest.java
Patch:
@@ -73,12 +73,12 @@ public class ZookeeperLeaderFinderTest {
     private static final int MAX_ATTEMPTS = 4;
 
     @BeforeAll
-    public static void initVertx() {
+    public static void before() {
         vertx = Vertx.vertx();
     }
 
     @AfterAll
-    public static void closeVertx() {
+    public static void after() {
         vertx.close();
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ZookeeperScalerTest.java
Patch:
@@ -60,12 +60,12 @@ public class ZookeeperScalerTest {
             .build();
 
     @BeforeAll
-    public static void initVertx() {
+    public static void before() {
         vertx = Vertx.vertx();
     }
 
     @AfterAll
-    public static void closeVertx() {
+    public static void after() {
         vertx.close();
     }
 

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractCustomResourceOperatorIT.java
Patch:
@@ -101,9 +101,7 @@ public void before() {
 
     @AfterAll
     public void after() {
-        if (vertx != null) {
-            vertx.close();
-        }
+        vertx.close();
 
         String namespace = getNamespace();
         if (kubeClient().getNamespace(namespace) != null && System.getenv("SKIP_TEARDOWN") == null) {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractNonNamespacedResourceOperatorIT.java
Patch:
@@ -46,9 +46,7 @@ public static void before() {
 
     @AfterAll
     public static void after() {
-        if (vertx != null) {
-            vertx.close();
-        }
+        vertx.close();
     }
 
     abstract AbstractNonNamespacedResourceOperator<C, T, L, D, R> operator();

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractResourceOperatorIT.java
Patch:
@@ -68,9 +68,7 @@ public static void before() {
 
     @AfterAll
     public static void after() {
-        if (vertx != null) {
-            vertx.close();
-        }
+        vertx.close();
         if (kubeClient().getNamespace(namespace) != null && System.getenv("SKIP_TEARDOWN") == null) {
             log.warn("Deleting namespace {} after tests run", namespace);
             kubeClient().deleteNamespace(namespace);

File: topic-operator/src/test/java/io/strimzi/operator/topic/K8sImplTest.java
Patch:
@@ -36,16 +36,15 @@ public class K8sImplTest {
     private static Vertx vertx;
 
     @BeforeAll
-    public static void initVertx() {
+    public static void before() {
         vertx = Vertx.vertx();
     }
 
     @AfterAll
-    public static void closeVertx() {
+    public static void after() {
         vertx.close();
     }
 
-
     @Test
     public void testList(VertxTestContext context) {
         Checkpoint async = context.checkpoint();

File: systemtest/src/test/java/io/strimzi/systemtest/MirrorMaker2ST.java
Patch:
@@ -326,6 +326,9 @@ void testMirrorMaker2TlsAndScramSha512Auth() {
                 .endKafka()
             .endSpec().done();
 
+        // Deploy topic
+        KafkaTopicResource.topic(kafkaClusterSourceName, topicSourceName, 3).done();
+
         // Create Kafka user for source cluster
         KafkaUser userSource = KafkaUserResource.scramShaUser(kafkaClusterSourceName, kafkaUserSource).done();
         SecretUtils.waitForSecretReady(kafkaUserSource);
@@ -408,9 +411,6 @@ void testMirrorMaker2TlsAndScramSha512Auth() {
                 .endMirror()
             .endSpec().done();
 
-        // Deploy topic
-        KafkaTopicResource.topic(kafkaClusterSourceName, topicSourceName, 3).done();
-
         int sent = internalKafkaClient.sendMessagesTls(topicSourceName, NAMESPACE, kafkaClusterSourceName, userSource.getMetadata().getName(), messagesCount, "TLS");
 
         internalKafkaClient.checkProducedAndConsumedMessages(

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java
Patch:
@@ -288,7 +288,7 @@ InvalidResourceException asInvalidResourceException(String version, NoImageExcep
          */
         public void validateKafkaMirrorMakerImages(Iterable<String> versions) throws NoImageException {
             for (String version : versions) {
-                image(null, version, kafkaConnectImages, ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES);
+                image(null, version, kafkaMirrorMakerImages, ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES);
             }
         }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -138,7 +138,8 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
                     kafkaConnectS2IClusterOperations,
                     kafkaMirrorMakerAssemblyOperator,
                     kafkaMirrorMaker2AssemblyOperator,
-                    kafkaBridgeAssemblyOperator);
+                    kafkaBridgeAssemblyOperator,
+                    resourceOperatorSupplier.metricsProvider);
             vertx.deployVerticle(operator,
                 res -> {
                     if (res.succeeded()) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -75,7 +75,7 @@ protected AbstractAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability pfa
                                        AbstractWatchableResourceOperator<C, T, L, D, R> resourceOperator,
                                        ResourceOperatorSupplier supplier,
                                        ClusterOperatorConfig config) {
-        super(vertx, kind, resourceOperator);
+        super(vertx, kind, resourceOperator, supplier.metricsProvider);
         this.pfa = pfa;
         this.certManager = certManager;
         this.passwordGenerator = passwordGenerator;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
Patch:
@@ -71,7 +71,7 @@ private static Map<String, String> buildEnv(String namespaces) {
     }
 
     @BeforeAll
-    public static void createClient() {
+    public static void before() {
         vertx = Vertx.vertx(new VertxOptions().setMetricsOptions(
                 new MicrometerMetricsOptions()
                         .setPrometheusOptions(new VertxPrometheusOptions().setEnabled(true))
@@ -80,7 +80,7 @@ public static void createClient() {
     }
 
     @AfterAll
-    public static void closeClient() {
+    public static void after() {
         vertx.close();
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -109,12 +109,12 @@ public void clearSecrets() {
     }
 
     @BeforeAll
-    public static void initVertx() {
+    public static void before() {
         vertx = Vertx.vertx();
     }
 
     @AfterAll
-    public static void closeVertx() {
+    public static void after() {
         if (vertx != null) {
             vertx.close();
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -124,7 +124,7 @@ private void init() {
                 new ResourceOperatorSupplier(this.vertx, this.mockClient,
                         ResourceUtils.zookeeperLeaderFinder(this.vertx, this.mockClient),
                         ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(),
-                        pfa, 60_000L);
+                        ResourceUtils.metricsProvider(), pfa, 60_000L);
 
         this.kao = new KafkaAssemblyOperator(this.vertx, pfa, new MockCertManager(), new PasswordGenerator(10, "a", "a"), ros, ResourceUtils.dummyClusterOperatorConfig(VERSIONS, 2_000));
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaStatusTest.java
Patch:
@@ -82,9 +82,7 @@ public static void before() {
 
     @AfterAll
     public static void after() {
-        if (vertx != null) {
-            vertx.close();
-        }
+        vertx.close();
     }
 
     public Kafka getKafkaCrd() throws ParseException {

File: user-operator/src/main/java/io/strimzi/operator/user/operator/KafkaUserOperator.java
Patch:
@@ -16,6 +16,7 @@
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.model.StatusDiff;
 import io.strimzi.operator.common.AbstractOperator;
+import io.strimzi.operator.common.MicrometerMetricsProvider;
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
@@ -82,7 +83,7 @@ public KafkaUserOperator(Vertx vertx,
                              ScramShaCredentialsOperator scramShaCredentialOperator,
                              KafkaUserQuotasOperator kafkaUserQuotasOperator,
                              SimpleAclOperator aclOperations, String caCertName, String caKeyName, String caNamespace) {
-        super(vertx, "User", crdOperator);
+        super(vertx, "KafkaUser", crdOperator, new MicrometerMetricsProvider());
         this.certManager = certManager;
         Map<String, String> matchLabels = labels.toMap();
         this.selector = matchLabels.isEmpty() ? Optional.empty() : Optional.of(new LabelSelector(null, matchLabels));

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaUserResource.java
Patch:
@@ -88,8 +88,8 @@ private static KafkaUser deleteLater(KafkaUser kafkaUser) {
         return ResourceManager.deleteLater(kafkaUserClient(), kafkaUser);
     }
 
-    public static DoneableKafkaUser userWithQuota(String clusterName, String userName, Integer prodRate, Integer consRate, Integer requestPerc) {
-        return user(defaultUser(clusterName, userName)
+    public static DoneableKafkaUser userWithQuota(KafkaUser user, Integer prodRate, Integer consRate, Integer requestPerc) {
+        return user(new KafkaUserBuilder(user)
                 .editSpec()
                     .withNewQuotas()
                         .withConsumerByteRate(consRate)

File: user-operator/src/main/java/io/strimzi/operator/user/operator/KafkaUserOperator.java
Patch:
@@ -293,9 +293,9 @@ protected Future<Boolean> delete(Reconciliation reconciliation) {
         return CompositeFuture.join(secretOperations.reconcile(namespace, KafkaUserModel.getSecretName(user), null),
                 aclOperations.reconcile(KafkaUserModel.getTlsUserName(user), null),
                 aclOperations.reconcile(KafkaUserModel.getScramUserName(user), null),
-                kafkaUserQuotasOperator.reconcile(KafkaUserModel.getTlsUserName(user), null),
-                kafkaUserQuotasOperator.reconcile(KafkaUserModel.getScramUserName(user), null),
-                scramShaCredentialOperator.reconcile(KafkaUserModel.getScramUserName(user), null))
+                scramShaCredentialOperator.reconcile(KafkaUserModel.getScramUserName(user), null)
+                        .compose(ignore -> kafkaUserQuotasOperator.reconcile(KafkaUserModel.getTlsUserName(user), null))
+                        .compose(ignore -> kafkaUserQuotasOperator.reconcile(KafkaUserModel.getScramUserName(user), null)))
             .map(Boolean.TRUE);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -1020,7 +1020,7 @@ void testEntityOperatorWithoutTopicOperator() {
     }
 
     @Test
-        void testEntityOperatorWithoutUserOperator() {
+    void testEntityOperatorWithoutUserOperator() {
         LOGGER.info("Deploying Kafka cluster without UO in EO");
         timeMeasuringSystem.setOperationID(timeMeasuringSystem.startTimeMeasuring(Operation.CLUSTER_DEPLOYMENT));
         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3)

File: systemtest/src/test/java/io/strimzi/systemtest/OpenShiftTemplatesST.java
Patch:
@@ -31,7 +31,6 @@
 import java.util.List;
 
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.test.TestUtils.map;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
@@ -69,7 +68,6 @@ public KafkaConnectS2I getKafkaConnectS2I(String clusterName) {
     }
 
     @Test
-    @Tag(NODEPORT_SUPPORTED)
     void testStrimziEphemeral() {
         String clusterName = "foo";
         oc.newApp("strimzi-ephemeral", map("CLUSTER_NAME", clusterName,

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -577,8 +577,6 @@ void testAutoRenewCaCertsTriggerByExpiredCertificate() {
     }
 
     @Test
-    @Tag(NODEPORT_SUPPORTED)
-    @Tag(EXTERNAL_CLIENTS_USED)
     void testCertRenewalInMaintenanceWindow() {
         String secretName = CLUSTER_NAME + "-cluster-ca-cert";
         LocalDateTime maintenanceWindowStart = LocalDateTime.now().withSecond(0);

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -25,7 +25,6 @@
 import java.util.List;
 
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
-import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.Constants.SCALABILITY;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
@@ -127,14 +126,12 @@ void testUpdateUser() {
     }
 
     @Tag(SCALABILITY)
-    @Tag(NODEPORT_SUPPORTED)
     @Test
     void testBigAmountOfScramShaUsers() {
         createBigAmountOfUsers("SCRAM_SHA");
     }
 
     @Tag(SCALABILITY)
-    @Tag(NODEPORT_SUPPORTED)
     @Test
     void testBigAmountOfTlsUsers() {
         createBigAmountOfUsers("TLS");

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -14,7 +14,7 @@
 import io.strimzi.api.kafka.model.KafkaConnectorBuilder;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -93,7 +93,7 @@ private static KafkaConnector getKafkaConnectorFromYaml(String yamlPath) {
 
     private static KafkaConnector waitFor(KafkaConnector kafkaConnector) {
         LOGGER.info("Waiting for Kafka Connector {}", kafkaConnector.getMetadata().getName());
-        KafkaConnectUtils.waitForConnectorReady(kafkaConnector.getMetadata().getName());
+        KafkaConnectorUtils.waitForConnectorStatus(kafkaConnector.getMetadata().getName(), "Ready");
         LOGGER.info("Kafka Connector {} is ready", kafkaConnector.getMetadata().getName());
         return kafkaConnector;
     }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectorResource;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectorUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -100,7 +101,7 @@ void deployKafkaConnectorWithSink(String clusterName, String namespace, String t
                 .withClassName("org.apache.kafka.connect.file.FileStreamSinkConnector")
                 .withConfig(connectorConfig)
             .endSpec().done();
-        KafkaConnectUtils.waitForConnectorReady(clusterName);
+        KafkaConnectorUtils.waitForConnectorStatus(clusterName, "Ready");
 
         String kafkaConnectPodName = kubeClient().listPods("type", connectLabel).get(0).getMetadata().getName();
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/DeploymentUtils.java
Patch:
@@ -226,7 +226,7 @@ public static void waitForNoRollingUpdate(String deploymentName, Map<String, Str
      * Wait until the given DeploymentConfig is ready.
      * @param name The name of the DeploymentConfig.
      */
-    public static void waitForDeploymentConfigReady(String name, int expectPods) {
+    public static Map<String, String> waitForDeploymentConfigReady(String name, int expectPods) {
         LOGGER.debug("Waiting until DeploymentConfig {} is ready", name);
         TestUtils.waitFor("DeploymentConfig " + name + " to be ready", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> kubeClient().getDeploymentConfigStatus(name));
@@ -237,5 +237,7 @@ public static void waitForDeploymentConfigReady(String name, int expectPods) {
         LabelSelector deploymentConfigSelector =
                 new LabelSelectorBuilder().addToMatchLabels(kubeClient().getDeploymentConfigSelectors(name)).build();
         PodUtils.waitForPodsReady(deploymentConfigSelector, expectPods, true);
+
+        return depConfigSnapshot(name);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractConnectOperator.java
Patch:
@@ -116,7 +116,7 @@ public AbstractConnectOperator(Vertx vertx, PlatformFeaturesAvailability pfa, St
     @Override
     protected Future<Boolean> delete(Reconciliation reconciliation) {
         // When deleting KafkaConnect we need to update the status of all selected KafkaConnector
-        return connectorOperator.listAsync(reconciliation.namespace(), Labels.forCluster(reconciliation.name())).compose(connectors -> {
+        return connectorOperator.listAsync(reconciliation.namespace(), Labels.forStrimziCluster(reconciliation.name())).compose(connectors -> {
             List<Future> connectorFutures = new ArrayList<>();
             for (KafkaConnector connector : connectors) {
                 connectorFutures.add(maybeUpdateConnectorStatus(reconciliation, connector, null,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaExporterTest.java
Patch:
@@ -96,9 +96,9 @@ private Map<String, String> expectedLabels(String name)    {
                 "my-user-label", "cromulent",
                 Labels.STRIMZI_KIND_LABEL, Kafka.RESOURCE_KIND,
                 Labels.STRIMZI_NAME_LABEL, name,
-                Labels.KUBERNETES_NAME_LABEL, Labels.KUBERNETES_NAME,
+                Labels.KUBERNETES_NAME_LABEL, KafkaExporter.APPLICATION_NAME,
                 Labels.KUBERNETES_INSTANCE_LABEL, this.cluster,
-                Labels.KUBERNETES_PART_OF_LABEL, this.cluster,
+                Labels.KUBERNETES_PART_OF_LABEL, Labels.APPLICATION_NAME + "-" + this.cluster,
                 Labels.KUBERNETES_MANAGED_BY_LABEL, AbstractModel.STRIMZI_CLUSTER_OPERATOR_NAME);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -117,9 +117,9 @@ private Map<String, String> expectedLabels(String name)    {
                 "my-user-label", "cromulent",
                 Labels.STRIMZI_KIND_LABEL, KafkaMirrorMaker.RESOURCE_KIND,
                 Labels.STRIMZI_NAME_LABEL, name,
-                Labels.KUBERNETES_NAME_LABEL, Labels.KUBERNETES_NAME,
+                Labels.KUBERNETES_NAME_LABEL, KafkaMirrorMakerCluster.APPLICATION_NAME,
                 Labels.KUBERNETES_INSTANCE_LABEL, this.cluster,
-                Labels.KUBERNETES_PART_OF_LABEL, this.cluster,
+                Labels.KUBERNETES_PART_OF_LABEL, Labels.APPLICATION_NAME + "-" + this.cluster,
                 Labels.KUBERNETES_MANAGED_BY_LABEL, AbstractModel.STRIMZI_CLUSTER_OPERATOR_NAME);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -132,9 +132,9 @@ private Map<String, String> expectedLabels()    {
             "my-user-label", "cromulent",
             Labels.STRIMZI_NAME_LABEL, ZookeeperCluster.zookeeperClusterName(cluster),
             Labels.STRIMZI_KIND_LABEL, Kafka.RESOURCE_KIND,
-            Labels.KUBERNETES_NAME_LABEL, Labels.KUBERNETES_NAME,
+            Labels.KUBERNETES_NAME_LABEL, ZookeeperCluster.APPLICATION_NAME,
             Labels.KUBERNETES_INSTANCE_LABEL, this.cluster,
-            Labels.KUBERNETES_PART_OF_LABEL, this.cluster,
+            Labels.KUBERNETES_PART_OF_LABEL, Labels.APPLICATION_NAME + "-" + this.cluster,
             Labels.KUBERNETES_MANAGED_BY_LABEL, AbstractModel.STRIMZI_CLUSTER_OPERATOR_NAME);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -299,7 +299,7 @@ private Set<String> expectedPvcs(Kafka kafka) {
 
     private List<PersistentVolumeClaim> getPvcs(String namespace, String name) {
         String kafkaStsName = KafkaCluster.kafkaClusterName(name);
-        Labels pvcSelector = Labels.forCluster(name).withKind(Kafka.RESOURCE_KIND).withName(kafkaStsName);
+        Labels pvcSelector = Labels.forStrimziCluster(name).withStrimziKind(Kafka.RESOURCE_KIND).withStrimziName(kafkaStsName);
         return mockClient.persistentVolumeClaims().inNamespace(namespace).withLabels(pvcSelector.toMap())
                 .list().getItems();
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -206,7 +206,7 @@ public void before() {
                 .withMetadata(new ObjectMetaBuilder()
                         .withName(CLUSTER_NAME)
                         .withNamespace(NAMESPACE)
-                        .withLabels(Labels.userLabels(TestUtils.map("foo", "bar")).toMap())
+                        .withLabels(TestUtils.map("foo", "bar"))
                         .build())
                 .withNewSpec()
                     .withNewKafka()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -591,15 +591,15 @@ public void testReconcile(VertxTestContext context) throws InterruptedException,
         when(mockBridgeOps.get(eq(clusterCmNamespace), eq("bar"))).thenReturn(bar);
 
         // providing the list of ALL Deployments for all the Kafka Bridge clusters
-        Labels newLabels = Labels.forKind(KafkaBridge.RESOURCE_KIND);
+        Labels newLabels = Labels.forStrimziKind(KafkaBridge.RESOURCE_KIND);
         when(mockDcOps.list(eq(clusterCmNamespace), eq(newLabels))).thenReturn(
                 asList(KafkaBridgeCluster.fromCrd(bar,
                         VERSIONS).generateDeployment(new HashMap<String, String>(), true, null, null)));
         when(mockDcOps.readiness(anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
         when(mockDcOps.waitForObserved(anyString(), anyString(), anyLong(), anyLong())).thenReturn(Future.succeededFuture());
 
         // providing the list Deployments for already "existing" Kafka Bridge clusters
-        Labels barLabels = Labels.forCluster("bar");
+        Labels barLabels = Labels.forStrimziCluster("bar");
         when(mockDcOps.list(eq(clusterCmNamespace), eq(barLabels))).thenReturn(
                 asList(KafkaBridgeCluster.fromCrd(bar,
                         VERSIONS).generateDeployment(new HashMap<String, String>(), true, null, null))

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -26,7 +26,6 @@
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
-import io.strimzi.operator.common.model.Labels;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.mockkube.MockKube;
 import io.vertx.core.Future;
@@ -138,7 +137,7 @@ public void testCreateUpdate(VertxTestContext context) throws InterruptedExcepti
                 .withMetadata(new ObjectMetaBuilder()
                         .withName(CLUSTER_NAME)
                         .withNamespace(NAMESPACE)
-                        .withLabels(Labels.userLabels(TestUtils.map("foo", "bar")).toMap())
+                        .withLabels(TestUtils.map("foo", "bar"))
                         .build())
                 .withNewSpec()
                 .withReplicas(replicas)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -670,12 +670,12 @@ public void testReconcile(VertxTestContext context) throws InterruptedException,
         when(mockConnectS2IOps.getAsync(clusterCmNamespace, "bar")).thenReturn(Future.succeededFuture(null));
 
         // providing the list of ALL Deployments for all the Kafka Connect clusters
-        Labels newLabels = Labels.forKind(KafkaConnect.RESOURCE_KIND);
+        Labels newLabels = Labels.forStrimziKind(KafkaConnect.RESOURCE_KIND);
         when(mockDcOps.list(eq(clusterCmNamespace), eq(newLabels))).thenReturn(
                 asList(KafkaConnectCluster.fromCrd(bar, VERSIONS).generateDeployment(new HashMap<String, String>(), true, null, null)));
 
         // providing the list Deployments for already "existing" Kafka Connect clusters
-        Labels barLabels = Labels.forCluster("bar");
+        Labels barLabels = Labels.forStrimziCluster("bar");
         when(mockDcOps.list(eq(clusterCmNamespace), eq(barLabels))).thenReturn(
                 asList(KafkaConnectCluster.fromCrd(bar, VERSIONS).generateDeployment(new HashMap<String, String>(), true, null, null))
         );

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperatorTest.java
Patch:
@@ -792,12 +792,12 @@ public void testReconcile(VertxTestContext context) throws InterruptedException,
         when(mockConnectS2IOps.updateStatusAsync(any(KafkaConnectS2I.class))).thenReturn(Future.succeededFuture());
 
         // providing the list of ALL DeploymentConfigs for all the Kafka Connect S2I clusters
-        Labels newLabels = Labels.forKind(KafkaConnectS2I.RESOURCE_KIND);
+        Labels newLabels = Labels.forStrimziKind(KafkaConnectS2I.RESOURCE_KIND);
         when(mockDcOps.list(eq(clusterCmNamespace), eq(newLabels))).thenReturn(
                 asList(KafkaConnectS2ICluster.fromCrd(bar, VERSIONS).generateDeploymentConfig(new HashMap<String, String>(), true, null, null)));
 
         // providing the list DeploymentConfigs for already "existing" Kafka Connect S2I clusters
-        Labels barLabels = Labels.forCluster("bar");
+        Labels barLabels = Labels.forStrimziCluster("bar");
         when(mockDcOps.list(eq(clusterCmNamespace), eq(barLabels))).thenReturn(
                 asList(KafkaConnectS2ICluster.fromCrd(bar, VERSIONS).generateDeploymentConfig(new HashMap<String, String>(), true, null, null))
         );

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorMockTest.java
Patch:
@@ -20,7 +20,6 @@
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
-import io.strimzi.operator.common.model.Labels;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.mockkube.MockKube;
 import io.vertx.core.Future;
@@ -129,7 +128,7 @@ public void testCreateUpdate(VertxTestContext context) throws InterruptedExcepti
                 .withMetadata(new ObjectMetaBuilder()
                         .withName(CLUSTER_NAME)
                         .withNamespace(NAMESPACE)
-                        .withLabels(Labels.userLabels(TestUtils.map("foo", "bar")).toMap())
+                        .withLabels(TestUtils.map("foo", "bar"))
                         .build())
                 .withNewSpec()
                 .withReplicas(replicas)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorTest.java
Patch:
@@ -567,12 +567,12 @@ public void testReconcile(VertxTestContext context) throws InterruptedException,
         when(mockMirrorMaker2Ops.get(eq(clusterCmNamespace), eq("bar"))).thenReturn(bar);
 
         // providing the list of ALL Deployments for all the Kafka MirrorMaker 2.0 clusters
-        Labels newLabels = Labels.forKind(KafkaMirrorMaker2.RESOURCE_KIND);
+        Labels newLabels = Labels.forStrimziKind(KafkaMirrorMaker2.RESOURCE_KIND);
         when(mockDcOps.list(eq(clusterCmNamespace), eq(newLabels))).thenReturn(
                 asList(KafkaMirrorMaker2Cluster.fromCrd(bar, VERSIONS).generateDeployment(new HashMap<String, String>(), true, null, null)));
 
         // providing the list Deployments for already "existing" Kafka MirrorMaker 2.0 clusters
-        Labels barLabels = Labels.forCluster("bar");
+        Labels barLabels = Labels.forStrimziCluster("bar");
         when(mockDcOps.list(eq(clusterCmNamespace), eq(barLabels))).thenReturn(
                 asList(KafkaMirrorMaker2Cluster.fromCrd(bar, VERSIONS).generateDeployment(new HashMap<String, String>(), true, null, null))
         );

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -599,13 +599,13 @@ public void testReconcile(VertxTestContext context) throws InterruptedException,
         when(mockMirrorOps.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture());
 
         // providing the list of ALL Deployments for all the Kafka Mirror Maker clusters
-        Labels newLabels = Labels.forKind(KafkaMirrorMaker.RESOURCE_KIND);
+        Labels newLabels = Labels.forStrimziKind(KafkaMirrorMaker.RESOURCE_KIND);
         when(mockDcOps.list(eq(clusterCmNamespace), eq(newLabels))).thenReturn(
                 asList(KafkaMirrorMakerCluster.fromCrd(bar,
                         VERSIONS).generateDeployment(new HashMap<String, String>(), true, null, null)));
 
         // providing the list Deployments for already "existing" Kafka Mirror Maker clusters
-        Labels barLabels = Labels.forCluster("bar");
+        Labels barLabels = Labels.forStrimziCluster("bar");
         when(mockDcOps.list(eq(clusterCmNamespace), eq(barLabels))).thenReturn(
                 asList(KafkaMirrorMakerCluster.fromCrd(bar,
                         VERSIONS).generateDeployment(new HashMap<String, String>(), true, null, null))

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/DeploymentOperator.java
Patch:
@@ -73,7 +73,7 @@ public Future<Void> rollingUpdate(String namespace, String name, long operationT
      * @return A Future which will complete once all the pods has been deleted.
      */
     public Future<ReconcileResult<Pod>> deletePod(String namespace, String name) {
-        Labels labels = Labels.fromMap(null).withName(name);
+        Labels labels = Labels.EMPTY.withStrimziName(name);
         String podName = podOperations.list(namespace, labels).get(0).getMetadata().getName();
         return podOperations.reconcile(namespace, podName, null);
     }

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorMockTest.java
Patch:
@@ -177,7 +177,7 @@ public void testCreatedWithoutTopicNameInKube(VertxTestContext context) throws I
                 .withNewMetadata()
                 .withName("my-topic")
                 .addToLabels(Labels.STRIMZI_KIND_LABEL, "topic")
-                .addToLabels(Labels.KUBERNETES_NAME_LABEL, Labels.KUBERNETES_NAME)
+                .addToLabels(Labels.KUBERNETES_NAME_LABEL, "topic-operator")
                 .endMetadata()
                 .withNewSpec()
                 .withPartitions(1)

File: user-operator/src/main/java/io/strimzi/operator/user/model/KafkaUserModel.java
Patch:
@@ -77,7 +77,7 @@ public class KafkaUserModel {
     protected KafkaUserModel(String namespace, String name, Labels labels) {
         this.namespace = namespace;
         this.name = name;
-        this.labels = labels.withKubernetesName()
+        this.labels = labels.withKubernetesName(KAFKA_USER_OPERATOR_NAME)
             .withKubernetesInstance(name)
             .withKubernetesPartOf(name)
             .withKubernetesManagedBy(KAFKA_USER_OPERATOR_NAME);
@@ -102,7 +102,7 @@ public static KafkaUserModel fromCrd(CertManager certManager,
                                          Secret userSecret) {
         KafkaUserModel result = new KafkaUserModel(kafkaUser.getMetadata().getNamespace(),
                 kafkaUser.getMetadata().getName(),
-                Labels.fromResource(kafkaUser).withKind(kafkaUser.getKind()));
+                Labels.fromResource(kafkaUser).withStrimziKind(kafkaUser.getKind()));
         result.setOwnerReference(kafkaUser);
         result.setAuthentication(kafkaUser.getSpec().getAuthentication());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -71,7 +71,6 @@ public KafkaBridgeAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability pfa
     protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge assemblyResource) {
         Promise<Void> createOrUpdatePromise = Promise.promise();
         String namespace = reconciliation.namespace();
-        String name = reconciliation.name();
         KafkaBridgeCluster bridge;
         KafkaBridgeStatus kafkaBridgeStatus = new KafkaBridgeStatus();
         if (assemblyResource.getSpec() == null) {
@@ -92,7 +91,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge
         Map<String, String> annotations = new HashMap<>();
         annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(bridge.ANCILLARY_CM_KEY_LOG_CONFIG));
 
-        log.debug("{}: Updating Kafka Bridge cluster", reconciliation, name, namespace);
+        log.debug("{}: Updating Kafka Bridge cluster", reconciliation);
         kafkaBridgeServiceAccount(namespace, bridge)
             .compose(i -> deploymentOperations.scaleDown(namespace, bridge.getName(), bridge.getReplicas()))
             .compose(scale -> serviceOperations.reconcile(namespace, bridge.getServiceName(), bridge.generateService()))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -90,7 +90,6 @@ public KafkaConnectAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability pf
     protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnect kafkaConnect) {
         Promise<Void> createOrUpdatePromise = Promise.promise();
         String namespace = reconciliation.namespace();
-        String name = reconciliation.name();
         KafkaConnectCluster connect;
         KafkaConnectStatus kafkaConnectStatus = new KafkaConnectStatus();
         try {
@@ -115,7 +114,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
         Map<String, String> annotations = new HashMap<>();
         annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
 
-        log.debug("{}: Updating Kafka Connect cluster", reconciliation, name, namespace);
+        log.debug("{}: Updating Kafka Connect cluster", reconciliation);
 
         Future<KafkaConnectS2I> connectS2ICheck;
         if (connectS2IOperations != null)   {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -95,7 +95,6 @@ public KafkaConnectS2IAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability
     @Override
     public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2I kafkaConnectS2I) {
         Promise<Void> createOrUpdatePromise = Promise.promise();
-        String name = reconciliation.name();
         String namespace = reconciliation.namespace();
         KafkaConnectS2ICluster connect;
         KafkaConnectS2IStatus kafkaConnectS2Istatus = new KafkaConnectS2IStatus();
@@ -120,7 +119,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
         HashMap<String, String> annotations = new HashMap<>();
         annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
 
-        log.debug("{}: Updating Kafka Connect S2I cluster", reconciliation, name, namespace);
+        log.debug("{}: Updating Kafka Connect S2I cluster", reconciliation);
 
         connectOperations.getAsync(kafkaConnectS2I.getMetadata().getNamespace(), kafkaConnectS2I.getMetadata().getName())
                 .compose(otherConnect -> {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -73,7 +73,6 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
         Promise<Void> createOrUpdatePromise = Promise.promise();
 
         String namespace = reconciliation.namespace();
-        String name = reconciliation.name();
         KafkaMirrorMakerCluster mirror;
         KafkaMirrorMakerStatus kafkaMirrorMakerStatus = new KafkaMirrorMakerStatus();
         if (assemblyResource.getSpec() == null) {
@@ -95,7 +94,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
         Map<String, String> annotations = new HashMap<>();
         annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(mirror.ANCILLARY_CM_KEY_LOG_CONFIG));
 
-        log.debug("{}: Updating Kafka Mirror Maker cluster", reconciliation, name, namespace);
+        log.debug("{}: Updating Kafka Mirror Maker cluster", reconciliation);
         mirrorMakerServiceAccount(namespace, mirror)
                 .compose(i -> deploymentOperations.scaleDown(namespace, mirror.getName(), mirror.getReplicas()))
                 .compose(i -> configMapOperations.reconcile(namespace, mirror.getAncillaryConfigName(), logAndMetricsConfigMap))

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -32,6 +32,7 @@
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
 import io.strimzi.systemtest.utils.ClientUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
@@ -1242,6 +1243,8 @@ void testCaRenewalBreakInMiddle() {
                 .endClusterCa()
             .endSpec().done();
 
+        KafkaUtils.waitUntilKafkaStatus(CLUSTER_NAME, "Ready");
+
         String userName = "alice";
         KafkaUser user = KafkaUserResource.tlsUser(CLUSTER_NAME, userName).done();
         String topicName = TOPIC_NAME + "-" + rng.nextInt(Integer.MAX_VALUE);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -124,7 +124,7 @@ public abstract class AbstractModel {
     protected String name;
 
     protected static final int METRICS_PORT = 9404;
-    protected static final String METRICS_PORT_NAME = "prometheus";
+    protected static final String METRICS_PORT_NAME = "tcp-prometheus";
     protected boolean isMetricsEnabled;
 
     protected static final int JMX_PORT = 9999;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -27,6 +27,7 @@
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.TestKafkaVersion;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import io.strimzi.test.TestUtils;
@@ -124,7 +125,7 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl
                 .editKafka()
                     .withVersion(Environment.ST_KAFKA_VERSION)
                     .withReplicas(kafkaReplicas)
-                    .addToConfig("log.message.format.version", Environment.ST_KAFKA_VERSION.substring(0, 3))
+                    .addToConfig("log.message.format.version", TestKafkaVersion.getKafkaVersionsInMap().get(Environment.ST_KAFKA_VERSION).protocolVersion())
                     .addToConfig("offsets.topic.replication.factor", Math.min(kafkaReplicas, 3))
                     .addToConfig("transaction.state.log.min.isr", Math.min(kafkaReplicas, 2))
                     .addToConfig("transaction.state.log.replication.factor", Math.min(kafkaReplicas, 3))

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java
Patch:
@@ -38,7 +38,7 @@ public class ZookeeperUpgradeST extends BaseST {
 
     @Test
     void testKafkaClusterUpgrade(TestInfo testinfo) throws IOException, InterruptedException {
-        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.parseKafkaVersions();
+        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.getKafkaVersions();
 
         TestKafkaVersion initialVersion = sortedVersions.get(sortedVersions.size() - 2);
         TestKafkaVersion newVersion = sortedVersions.get(sortedVersions.size() - 1);
@@ -48,7 +48,7 @@ void testKafkaClusterUpgrade(TestInfo testinfo) throws IOException, InterruptedE
 
     @Test
     void testKafkaClusterDowngrade(TestInfo testInfo) throws IOException, InterruptedException {
-        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.parseKafkaVersions();
+        List<TestKafkaVersion> sortedVersions = TestKafkaVersion.getKafkaVersions();
 
         TestKafkaVersion initialVersion = sortedVersions.get(sortedVersions.size() - 1);
         TestKafkaVersion newVersion = sortedVersions.get(sortedVersions.size() - 2);

File: systemtest/src/test/java/io/strimzi/systemtest/utils/KafkaVersionUtilsTest.java
Patch:
@@ -5,15 +5,16 @@
 package io.strimzi.systemtest.utils;
 
 import org.junit.jupiter.api.Test;
-import static org.junit.jupiter.api.Assertions.assertTrue;
 
 import java.util.List;
 
+import static org.junit.jupiter.api.Assertions.assertTrue;
+
 public class KafkaVersionUtilsTest {
 
     @Test
     public void parsingTest() throws Exception {
-        List<TestKafkaVersion> versions = TestKafkaVersion.parseKafkaVersions();
+        List<TestKafkaVersion> versions = TestKafkaVersion.getKafkaVersions();
         assertTrue(versions.size() > 0);
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -56,6 +56,7 @@
 import static io.strimzi.systemtest.Constants.CONNECTOR_OPERATOR;
 import static io.strimzi.systemtest.Constants.CONNECT_COMPONENTS;
 import static io.strimzi.systemtest.Constants.CONNECT_S2I;
+import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
@@ -358,6 +359,7 @@ void testJvmAndResources() {
 
     @Test
     @Tag(CONNECTOR_OPERATOR)
+    @Tag(ACCEPTANCE)
     void testKafkaConnectorWithConnectS2IAndConnectWithSameName() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String connectClusterName = "connect-cluster";

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -126,7 +126,6 @@ private void testDockerImagesForKafkaConnect() {
     }
 
     @Test
-    @Tag(ACCEPTANCE)
     @Tag(TRAVIS)
     @Tag(NODEPORT_SUPPORTED)
     @Tag(EXTERNAL_CLIENTS_USED)
@@ -687,6 +686,7 @@ void testKafkaConnectorWithConnectAndConnectS2IWithSameName() {
     @Test
     @Tag(CONNECTOR_OPERATOR)
     @Tag(INTERNAL_CLIENTS_USED)
+    @Tag(ACCEPTANCE)
     void testMultiNodeKafkaConnectWithConnectorCreation() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String connectClusterName = "connect-cluster";

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -33,6 +33,7 @@
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
+import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.BRIDGE;
 import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
@@ -43,6 +44,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 
 @Tag(BRIDGE)
+@Tag(ACCEPTANCE)
 @Tag(REGRESSION)
 @Tag(NODEPORT_SUPPORTED)
 @Tag(EXTERNAL_CLIENTS_USED)

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/ListenersST.java
Patch:
@@ -33,6 +33,7 @@
 import java.util.concurrent.TimeUnit;
 
 import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
+import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
@@ -259,6 +260,7 @@ void testCustomChainCertificatesForLoadBalancer() throws Exception {
     }
 
     @Test
+    @Tag(ACCEPTANCE)
     @OpenShiftOnly
     void testCustomSoloCertificatesForRoute() throws Exception {
         String topicName = "test-topic-" + rng.nextInt(Integer.MAX_VALUE);

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -48,6 +48,7 @@
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
+import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.CONNECT;
 import static io.strimzi.systemtest.Constants.CONNECT_COMPONENTS;
@@ -63,6 +64,7 @@
 import static org.hamcrest.Matchers.greaterThan;
 
 @Tag(OAUTH)
+@Tag(ACCEPTANCE)
 @Tag(REGRESSION)
 @Tag(NODEPORT_SUPPORTED)
 @Tag(EXTERNAL_CLIENTS_USED)

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -63,6 +63,7 @@
 import static io.strimzi.systemtest.Constants.CONNECT_COMPONENTS;
 import static io.strimzi.systemtest.Constants.CONNECT_S2I;
 import static io.strimzi.systemtest.Constants.MIRROR_MAKER;
+import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.Constants.TRACING;
@@ -401,6 +402,7 @@ void testProducerConsumerService() {
     }
 
     @Test
+    @Tag(ACCEPTANCE)
     void testProducerConsumerStreamsService() {
         Map<String, Object> configOfSourceKafka = new HashMap<>();
         configOfSourceKafka.put("offsets.topic.replication.factor", "1");

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -49,6 +49,7 @@ public interface Constants {
     long GLOBAL_TRACING_POLL = Duration.ofSeconds(30).toMillis();
     long GLOBAL_TRACING_TIMEOUT =  Duration.ofMinutes(7).toMillis();
 
+    long GLOBAL_CLIENTS_POLL = Duration.ofSeconds(15).toMillis();
     long GLOBAL_CLIENTS_TIMEOUT = Duration.ofMinutes(2).toMillis();
     long GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT = Duration.ofSeconds(10).toMillis();
 

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -52,6 +52,7 @@
 
 import static io.strimzi.api.kafka.model.KafkaResources.kafkaStatefulSetName;
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.k8s.Events.Created;
 import static io.strimzi.systemtest.k8s.Events.Killing;
@@ -68,6 +69,7 @@
 import static org.junit.jupiter.api.Assertions.assertEquals;
 
 @Tag(REGRESSION)
+@Tag(INTERNAL_CLIENTS_USED)
 class RollingUpdateST extends BaseST {
 
     private static final Logger LOGGER = LogManager.getLogger(RecoveryST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -36,6 +36,7 @@
 import java.util.concurrent.TimeUnit;
 
 import static io.strimzi.systemtest.Constants.BRIDGE;
+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
@@ -45,6 +46,7 @@
 @Tag(BRIDGE)
 @Tag(REGRESSION)
 @Tag(NODEPORT_SUPPORTED)
+@Tag(EXTERNAL_CLIENTS_USED)
 @ExtendWith(VertxExtension.class)
 class HttpBridgeST extends HttpBridgeBaseST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -37,6 +37,7 @@
 import java.util.concurrent.TimeUnit;
 
 import static io.strimzi.systemtest.Constants.BRIDGE;
+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;
@@ -47,6 +48,7 @@
 @Tag(BRIDGE)
 @Tag(REGRESSION)
 @Tag(NODEPORT_SUPPORTED)
+@Tag(EXTERNAL_CLIENTS_USED)
 @ExtendWith(VertxExtension.class)
 class HttpBridgeScramShaST extends HttpBridgeBaseST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -34,6 +34,7 @@
 import java.util.concurrent.TimeUnit;
 
 import static io.strimzi.systemtest.Constants.BRIDGE;
+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;
@@ -44,6 +45,7 @@
 @Tag(BRIDGE)
 @Tag(REGRESSION)
 @Tag(NODEPORT_SUPPORTED)
+@Tag(EXTERNAL_CLIENTS_USED)
 @ExtendWith(VertxExtension.class)
 class HttpBridgeTlsST extends HttpBridgeBaseST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeTlsST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/ListenersST.java
Patch:
@@ -32,6 +32,7 @@
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
@@ -42,6 +43,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 
 @Tag(REGRESSION)
+@Tag(INTERNAL_CLIENTS_USED)
 public class ListenersST extends BaseST {
     private static final Logger LOGGER = LogManager.getLogger(ListenersST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -33,6 +33,7 @@
 import java.util.concurrent.ExecutionException;
 import java.util.regex.Pattern;
 
+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
@@ -124,6 +125,7 @@ void testKafkaConnectIoNetwork() {
     }
 
     @Test
+    @Tag(INTERNAL_CLIENTS_USED)
     void testKafkaExporterDataAfterExchange() {
         KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).done();
 

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthAuthorizationST.java
Patch:
@@ -33,6 +33,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 
+import static io.strimzi.systemtest.Constants.EXTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.OAUTH;
 import static io.strimzi.systemtest.Constants.REGRESSION;
@@ -43,6 +44,7 @@
 @Tag(OAUTH)
 @Tag(REGRESSION)
 @Tag(NODEPORT_SUPPORTED)
+@Tag(EXTERNAL_CLIENTS_USED)
 public class OauthAuthorizationST extends OauthBaseST {
 
     private OauthKafkaClient teamAOauthKafkaClient = (OauthKafkaClient) ClientFactory.getClient(EClientType.OAUTH);

File: systemtest/src/test/java/io/strimzi/systemtest/recovery/NamespaceDeletionRecoveryST.java
Patch:
@@ -31,13 +31,15 @@
 import java.util.List;
 import java.util.Random;
 
+import static io.strimzi.systemtest.Constants.INTERNAL_CLIENTS_USED;
 import static io.strimzi.systemtest.Constants.RECOVERY;
 import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 
 @Tag(RECOVERY)
+@Tag(INTERNAL_CLIENTS_USED)
 class NamespaceDeletionRecoveryST extends BaseST {
 
     static final String NAMESPACE = "namespace-recovery-cluster-test";

File: operator-common/src/main/java/io/strimzi/operator/common/DefaultAdminClientProvider.java
Patch:
@@ -22,10 +22,10 @@ public class DefaultAdminClientProvider implements AdminClientProvider {
 
     @Override
     public Admin createAdminClient(String hostname, Secret clusterCaCertSecret, Secret keyCertSecret, String keyCertName) {
-
         Admin ac;
-        String trustStorePassword = new String(Util.decodeFromSecret(clusterCaCertSecret, Ca.CA_STORE_PASSWORD), StandardCharsets.US_ASCII);
-        File truststoreFile = Util.createFileStore(getClass().getName(), "ts", Util.decodeFromSecret(clusterCaCertSecret, Ca.CA_STORE));
+        PasswordGenerator pg = new PasswordGenerator(12);
+        String trustStorePassword = pg.generate();
+        File truststoreFile = Util.createFileTrustStore(getClass().getName(), "ts", Ca.cert(clusterCaCertSecret, Ca.CA_CRT), trustStorePassword.toCharArray());
         try {
             String keyStorePassword = new String(Util.decodeFromSecret(keyCertSecret, keyCertName + ".password"), StandardCharsets.US_ASCII);
             File keystoreFile = Util.createFileStore(getClass().getName(), "ts", Util.decodeFromSecret(keyCertSecret, keyCertName + ".p12"));

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -124,6 +124,7 @@ private static KafkaBuilder defaultKafka(Kafka kafka, String name, int kafkaRepl
                 .editKafka()
                     .withVersion(Environment.ST_KAFKA_VERSION)
                     .withReplicas(kafkaReplicas)
+                    .addToConfig("log.message.format.version", Environment.ST_KAFKA_VERSION.substring(0, 3))
                     .addToConfig("offsets.topic.replication.factor", Math.min(kafkaReplicas, 3))
                     .addToConfig("transaction.state.log.min.isr", Math.min(kafkaReplicas, 2))
                     .addToConfig("transaction.state.log.replication.factor", Math.min(kafkaReplicas, 3))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -125,6 +125,7 @@ public Map<String, CertAndKey> generateZkCerts(Kafka kafka, boolean isMaintenanc
             sbjAltNames.put("DNS.3", String.format("%s.%s.svc", ZookeeperCluster.serviceName(cluster), namespace));
             sbjAltNames.put("DNS.4", String.format("%s.%s.svc.%s", ZookeeperCluster.serviceName(cluster), namespace, ModelUtils.KUBERNETES_SERVICE_DNS_DOMAIN));
             sbjAltNames.put("DNS.5", ZookeeperCluster.podDnsName(namespace, cluster, i));
+            sbjAltNames.put("DNS.6", ZookeeperCluster.podDnsNameWithoutSuffix(namespace, cluster, i));
 
             Subject subject = new Subject();
             subject.setOrganizationName("io.strimzi");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperLeaderFinder.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.operator.cluster.model.Ca;
 import io.strimzi.operator.cluster.model.ZookeeperCluster;
 import io.strimzi.operator.common.BackOff;
+import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.operator.resource.SecretOperator;
 import io.vertx.core.Future;
@@ -117,7 +118,7 @@ protected PemKeyCertOptions keyCertOptions(Secret coCertKeySecret) {
                                             "cluster-operator.key", "cluster-operator.crt",
                                         "cluster-operator.p12", "cluster-operator.password");
         if (coCertKey == null) {
-            throw StatefulSetOperator.missingSecretFuture(coCertKeySecret.getMetadata().getNamespace(), coCertKeySecret.getMetadata().getName());
+            throw Util.missingSecretException(coCertKeySecret.getMetadata().getNamespace(), coCertKeySecret.getMetadata().getName());
         }
         CertificateFactory x509 = x509Factory();
         try {
@@ -143,7 +144,7 @@ Future<Integer> findZookeeperLeader(String cluster, String namespace, List<Pod>
         Future<Secret> clusterCaKeySecretFuture = secretOperator.getAsync(namespace, clusterCaSecretName);
         return clusterCaKeySecretFuture.compose(clusterCaCertificateSecret -> {
             if (clusterCaCertificateSecret  == null) {
-                return Future.failedFuture(StatefulSetOperator.missingSecretFuture(namespace, clusterCaSecretName));
+                return Future.failedFuture(Util.missingSecretException(namespace, clusterCaSecretName));
             }
             try {
                 NetClientOptions netClientOptions = clientOptions(coKeySecret, clusterCaCertificateSecret);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -362,6 +362,7 @@ public void testGenerateBrokerSecret() throws CertificateParsingException {
         X509Certificate cert = Ca.cert(secret, "foo-zookeeper-0.crt");
         assertThat(cert.getSubjectDN().getName(), is("CN=foo-zookeeper, O=io.strimzi"));
         assertThat(new HashSet<Object>(cert.getSubjectAlternativeNames()), is(set(
+                asList(2, "foo-zookeeper-0.foo-zookeeper-nodes.test.svc"),
                 asList(2, "foo-zookeeper-0.foo-zookeeper-nodes.test.svc.cluster.local"),
                 asList(2, "foo-zookeeper-client"),
                 asList(2, "foo-zookeeper-client.test"),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -123,7 +123,7 @@ private void init() {
         ResourceOperatorSupplier ros =
                 new ResourceOperatorSupplier(this.vertx, this.mockClient,
                         ResourceUtils.zookeeperLeaderFinder(this.vertx, this.mockClient),
-                        ResourceUtils.adminClientProvider(),
+                        ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(),
                         pfa, 60_000L);
 
         this.kao = new KafkaAssemblyOperator(this.vertx, pfa, new MockCertManager(), new PasswordGenerator(10, "a", "a"), ros, ResourceUtils.dummyClusterOperatorConfig(VERSIONS, 2_000));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -251,7 +251,7 @@ public static void cleanUp() {
     private ResourceOperatorSupplier supplierWithMocks() {
         ZookeeperLeaderFinder leaderFinder = ResourceUtils.zookeeperLeaderFinder(vertx, mockClient);
         return new ResourceOperatorSupplier(vertx, mockClient, leaderFinder,
-                ResourceUtils.adminClientProvider(),
+                ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(),
                 new PlatformFeaturesAvailability(true, kubernetesVersion), 2_000);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectorIT.java
Patch:
@@ -133,7 +133,7 @@ public void test(VertxTestContext context) throws InterruptedException {
                 new ResourceOperatorSupplier(
                         null, null, null, null, null, null, null, null, null, null, null,
                         null, null, null, null, null, null, null, null, null, null, null,
-                        null, connectCrdOperator, null, null, null),
+                        null, connectCrdOperator, null, null, null, null),
                 ClusterOperatorConfig.fromMap(Collections.emptyMap(), KafkaVersionTestUtils.getKafkaVersionLookup()),
             connect -> new KafkaConnectApiImpl(vertx),
             connectCluster.getPort() + 2) { };

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -162,7 +162,7 @@ public void afterEach() {
     ResourceOperatorSupplier supplier(KubernetesClient bootstrapClient) {
         return new ResourceOperatorSupplier(vertx, bootstrapClient,
                 ResourceUtils.zookeeperLeaderFinder(vertx, bootstrapClient),
-                ResourceUtils.adminClientProvider(),
+                ResourceUtils.adminClientProvider(), ResourceUtils.zookeeperScalerProvider(),
                 new PlatformFeaturesAvailability(true, KubernetesVersion.V1_9), 60_000L);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperatorTest.java
Patch:
@@ -60,9 +60,9 @@ public void testNotNeedsRollingUpdateIdentical() {
     }
 
     @Test
-    public void testNeedsRollingUpdateReplicas() {
+    public void testNotNeedsRollingUpdateReplicas() {
         a.getSpec().setReplicas(b.getSpec().getReplicas() + 1);
-        assertThat(ZookeeperSetOperator.needsRollingUpdate(diff()), is(true));
+        assertThat(ZookeeperSetOperator.needsRollingUpdate(diff()), is(false));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -34,7 +34,6 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.Test;
 
@@ -342,8 +341,6 @@ void testKafkaWontRollUpBecauseTopic() {
     }
 
     @Test
-    @Disabled("Zookeeper scaleUp/scaleDown is currently covered by manual procedure for Kafka 2.4.x. " +
-            "This should be removed after implementation of Zookeeper Dynamic configuration")
     void testZookeeperScaleUpScaleDown() {
         int messageCount = 50;
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaStatusTest.java
Patch:
@@ -28,6 +28,7 @@
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.KubernetesVersion;
+import io.strimzi.operator.cluster.model.ModelUtils;
 import io.strimzi.operator.cluster.operator.resource.KafkaSetOperator;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.PasswordGenerator;
@@ -112,7 +113,7 @@ public Kafka getKafkaCrd() throws ParseException {
                 .withNewStatus()
                     .withObservedGeneration(1L)
                     .withConditions(new ConditionBuilder()
-                            .withNewLastTransitionTime(new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ssZ").format(new SimpleDateFormat("yyyy-MM-dd hh:mm:ss").parse("2011-01-01 00:00:00")))
+                            .withNewLastTransitionTime(ModelUtils.formatTimestamp(new SimpleDateFormat("yyyy-MM-dd hh:mm:ss").parse("2011-01-01 00:00:00")))
                             .withNewType("NotReady")
                             .withNewStatus("True")
                             .build())

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -196,7 +196,7 @@ public void setup(VertxTestContext testContext) throws InterruptedException {
             return remove != null ? Future.succeededFuture() : Future.failedFuture("No such connector " + connectorName);
         });
         when(api.statusWithBackOff(any(), any(), anyInt(), anyString())).thenAnswer(invocation -> {
-            String host = invocation.getArgument(0);
+            String host = invocation.getArgument(1);
             System.err.println("###### status " + host);
             return kafkaConnectApiStatusMock(invocation.getArgument(1), invocation.getArgument(2), invocation.getArgument(3));
         });

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/VerifiableClient.java
Patch:
@@ -98,7 +98,7 @@ private boolean runClient(long timeoutMs, boolean logToOutput) {
             synchronized (lock) {
                 LOGGER.info("{} {} Return code - {}", this.getClass().getSimpleName(), clientType,  ret);
                 if (logToOutput) {
-                    LOGGER.debug("{} {} stdout : {}", this.getClass().getSimpleName(), clientType, executor.out());
+                    LOGGER.info("{} {} stdout : {}", this.getClass().getSimpleName(), clientType, executor.out());
                     if (ret == 0) {
                         parseToList(executor.out());
                     } else if (!executor.err().isEmpty()) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -82,7 +82,7 @@ public KafkaConnectS2IAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability
                                            ResourceOperatorSupplier supplier,
                                            ClusterOperatorConfig config,
                                            Function<Vertx, KafkaConnectApi> connectClientProvider) {
-        super(vertx, pfa, KafkaConnectS2I.RESOURCE_KIND, supplier.connectS2IOperator, supplier, config, connectClientProvider);
+        super(vertx, pfa, KafkaConnectS2I.RESOURCE_KIND, supplier.connectS2IOperator, supplier, config, connectClientProvider, KafkaConnectCluster.REST_API_PORT);
         this.deploymentConfigOperations = supplier.deploymentConfigOperations;
         this.imagesStreamOperations = supplier.imagesStreamOperations;
         this.buildConfigOperations = supplier.buildConfigOperations;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -107,7 +107,7 @@ public KafkaMirrorMaker2AssemblyOperator(Vertx vertx, PlatformFeaturesAvailabili
                                         ResourceOperatorSupplier supplier,
                                         ClusterOperatorConfig config,
                                         Function<Vertx, KafkaConnectApi> connectClientProvider) {
-        super(vertx, pfa, KafkaMirrorMaker2.RESOURCE_KIND, supplier.mirrorMaker2Operator, supplier, config, connectClientProvider);
+        super(vertx, pfa, KafkaMirrorMaker2.RESOURCE_KIND, supplier.mirrorMaker2Operator, supplier, config, connectClientProvider, KafkaConnectCluster.REST_API_PORT);
         this.deploymentOperations = supplier.deploymentOperations;
         this.networkPolicyOperator = supplier.networkPolicyOperator;
         this.versions = config.versions();

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/LogHasNoUnexpectedErrors.java
Patch:
@@ -74,7 +74,7 @@ enum LogWhiteList {
         // This is whitelisted cause it's no real problem when this error appears, components are being created even after timeout
         RECONCILIATION_TIMEOUT("ERROR Abstract.*Operator:[0-9]+ - Reconciliation.*"),
         ASSEMBLY_OPERATOR_RECONCILIATION_TIMEOUT("ERROR .*AssemblyOperator:[0-9]+ - Reconciliation.*[fF]ailed.*"),
-        WATCHER_CLOSED_EXCEPTION("ERROR AbstractOperator:* - Watcher closed with exception in namespace *");
+        WATCHER_CLOSED_EXCEPTION("ERROR AbstractOperator:.+ - Watcher closed with exception in namespace .*");
 
         final String name;
 

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/ListenersST.java
Patch:
@@ -785,9 +785,7 @@ void testCustomCertRouteAndTlsRollingUpdate() throws Exception {
         assertThat(received, is(50));
 
         KafkaResource.replaceKafkaResource(CLUSTER_NAME, kafka -> {
-            kafka.getSpec().getKafka().getListeners().setExternal(new KafkaListenerExternalNodePortBuilder()
-                .withTls(true)
-                .build());
+            kafka.getSpec().getKafka().getListeners().setExternal(new KafkaListenerExternalRouteBuilder().build());
         });
 
         StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaSnapshot);

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -408,8 +408,7 @@ void testKafkaConnectorWithConnectS2IAndConnectWithSameName() {
             kc.getMetadata().getAnnotations().remove(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES);
         });
 
-        String execPodName = KafkaResources.kafkaPodName(CLUSTER_NAME, 0);
-        KafkaConnectUtils.createFileSinkConnector(execPodName, topicName, Constants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
+        KafkaConnectUtils.createFileSinkConnector(kafkaClientsPodName, topicName, Constants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
         KafkaConnectUtils.waitForConnectorCreation(connectS2IPodName, "sink-test");
 
         // Wait for Cluster Operator reconciliation

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -205,13 +205,12 @@ void testSecretsWithKafkaConnectS2IWithTlsAndScramShaAuthentication() {
 
         String kafkaConnectS2IPodName = kubeClient().listPods("type", "kafka-connect-s2i").get(0).getMetadata().getName();
         String kafkaConnectS2ILogs = kubeClient().logs(kafkaConnectS2IPodName);
-        String execPod = KafkaResources.kafkaPodName(CLUSTER_NAME, 0);
 
         LOGGER.info("Verifying that in kafka connect logs are everything fine");
         assertThat(kafkaConnectS2ILogs, not(containsString("ERROR")));
 
-        LOGGER.info("Creating FileStreamSink connector via pod {} with topic {}", execPod, CONNECT_S2I_TOPIC_NAME);
-        KafkaConnectUtils.createFileSinkConnector(execPod, CONNECT_S2I_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(kafkaConnectS2IName, NAMESPACE, 8083));
+        LOGGER.info("Creating FileStreamSink connector via pod {} with topic {}", defaultKafkaClientsPodName, CONNECT_S2I_TOPIC_NAME);
+        KafkaConnectUtils.createFileSinkConnector(defaultKafkaClientsPodName, CONNECT_S2I_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_PATH, KafkaConnectResources.url(kafkaConnectS2IName, NAMESPACE, 8083));
 
         internalKafkaClient.checkProducedAndConsumedMessages(
                 internalKafkaClient.sendMessagesTls(CONNECT_S2I_TOPIC_NAME, NAMESPACE, CLUSTER_NAME, userName, MESSAGE_COUNT, "TLS"),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperatorTest.java
Patch:
@@ -135,7 +135,7 @@ protected Future<?> podReadiness(String namespace, StatefulSet desired, long pol
 
     @Override
     @Test
-    public void createWhenExistsIsAPatch(VertxTestContext context) {
+    public void testCreateWhenExistsIsAPatch(VertxTestContext context) {
         createWhenExistsIsAPatch(context, false);
     }
 

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/BuildConfigOperatorTest.java
Patch:
@@ -55,7 +55,7 @@ protected BuildConfig resource() {
 
     @Override
     @Test
-    public void createWhenExistsIsAPatch(VertxTestContext context) {
+    public void testCreateWhenExistsIsAPatch(VertxTestContext context) {
         createWhenExistsIsAPatch(context, false);
     }
 }

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ClusterRoleOperatorIT.java
Patch:
@@ -19,6 +19,7 @@
 import static java.util.Collections.singletonMap;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.Matchers.hasSize;
 
 @ExtendWith(VertxExtension.class)
 public class ClusterRoleOperatorIT extends AbstractNonNamespacedResourceOperatorIT<KubernetesClient,
@@ -71,7 +72,7 @@ protected void assertResources(VertxTestContext context, ClusterRole expected, C
         context.verify(() -> {
             assertThat(actual.getMetadata().getName(), is(expected.getMetadata().getName()));
             assertThat(actual.getMetadata().getLabels(), is(expected.getMetadata().getLabels()));
-            assertThat(actual.getRules().size(), is(expected.getRules().size()));
+            assertThat(actual.getRules(), hasSize(expected.getRules().size()));
             assertThat(actual.getRules().get(0).getApiGroups(), is(expected.getRules().get(0).getApiGroups()));
             assertThat(actual.getRules().get(0).getResources(), is(expected.getRules().get(0).getResources()));
             assertThat(actual.getRules().get(0).getVerbs(), is(expected.getRules().get(0).getVerbs()));

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ServiceAccountOperatorTest.java
Patch:
@@ -63,7 +63,7 @@ protected AbstractResourceOperator<KubernetesClient, ServiceAccount, ServiceAcco
 
     @Override
     @Test
-    public void createWhenExistsIsAPatch(VertxTestContext context) {
+    public void testCreateWhenExistsIsAPatch(VertxTestContext context) {
         createWhenExistsIsAPatch(context, true);
     }
     @Override

File: systemtest/src/main/java/io/strimzi/systemtest/logs/LogCollector.java
Patch:
@@ -91,7 +91,7 @@ public void collectReplicaSets() {
 
     public void collectStrimzi() {
         LOGGER.info("Collecting CR in namespaces {}", namespace);
-        String crData = cmdKubeClient().exec("get", "strimzi", "-o", "yaml").out();
+        String crData = cmdKubeClient().exec(false, "get", "strimzi", "-o", "yaml").out();
         writeFile(logDir + "/strimzi-custom-resources.log", crData);
     }
 }

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/Kubectl.java
Patch:
@@ -33,7 +33,7 @@ public String defaultNamespace() {
     }
 
     @Override
-    protected String cmd() {
+    public String cmd() {
         return KUBECTL;
     }
 

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/Oc.java
Patch:
@@ -81,7 +81,7 @@ public Oc newApp(String template, Map<String, String> params) {
     }
 
     @Override
-    protected String cmd() {
+    public String cmd() {
         return OC;
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -50,6 +50,7 @@ public interface Constants {
     long GLOBAL_TRACING_TIMEOUT =  Duration.ofMinutes(7).toMillis();
 
     long GLOBAL_CLIENTS_TIMEOUT = Duration.ofMinutes(2).toMillis();
+    long GLOBAL_CLIENTS_EXCEPT_ERROR_TIMEOUT = Duration.ofSeconds(10).toMillis();
 
     long CO_OPERATION_TIMEOUT_DEFAULT = Duration.ofMinutes(5).toMillis();
     long CO_OPERATION_TIMEOUT_SHORT = Duration.ofSeconds(30).toMillis();

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -7,7 +7,7 @@
 import io.fabric8.kubernetes.api.model.DoneableService;
 import io.fabric8.kubernetes.api.model.EnvVar;
 import io.fabric8.kubernetes.api.model.HasMetadata;
-import io.fabric8.kubernetes.api.model.LabelSelectorBuilder;
+import io.fabric8.kubernetes.api.model.LabelSelector;
 import io.fabric8.kubernetes.api.model.Service;
 import io.fabric8.kubernetes.api.model.ServiceBuilder;
 import io.fabric8.kubernetes.api.model.apps.Deployment;
@@ -332,7 +332,7 @@ public static void applyDefaultNetworkPolicySettings(List<String> namespaces) {
      */
     public static void allowNetworkPolicySettingsForResource(HasMetadata resource, String deploymentName, String clusterName) {
         String clientsDeploymentName = clusterName + "-" + Constants.KAFKA_CLIENTS;
-        Map<String, String> labels = kubeClient().listPodsByPrefixInName(clientsDeploymentName).get(0).getMetadata().getLabels();
+        LabelSelector labelSelector = kubeClient().getDeployment(clientsDeploymentName).getSpec().getSelector();
 
         LOGGER.info("Apply NetworkPolicy access to {} from {}", deploymentName, clientsDeploymentName);
 
@@ -345,7 +345,7 @@ public static void allowNetworkPolicySettingsForResource(HasMetadata resource, S
                 .withNewSpec()
                     .addNewIngress()
                         .addNewFrom()
-                            .withPodSelector(new LabelSelectorBuilder().addToMatchLabels(labels).build())
+                            .withPodSelector(labelSelector)
                         .endFrom()
                         .addNewPort()
                             .withNewPort(8083)

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -83,6 +83,7 @@ void testDeployMirrorMakerAcrossMultipleNamespace() {
     void testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String previousNamespace = cluster.setNamespace(SECOND_NAMESPACE);
+        KafkaClientsResource.deployKafkaClients(false, SECOND_CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).done();
         // Deploy Kafka Connect in other namespace than CO
         KafkaConnectResource.kafkaConnect(SECOND_CLUSTER_NAME, 1)
             .editMetadata()
@@ -98,6 +99,7 @@ void testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO() {
     void testDeployKafkaConnectS2IAndKafkaConnectorInOtherNamespaceThanCO() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String previousNamespace = cluster.setNamespace(SECOND_NAMESPACE);
+        KafkaClientsResource.deployKafkaClients(false, SECOND_CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).done();
         // Deploy Kafka Connect in other namespace than CO
         KafkaConnectS2IResource.kafkaConnectS2I(SECOND_CLUSTER_NAME, SECOND_CLUSTER_NAME, 1)
             .editMetadata()

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -36,6 +36,7 @@
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;
+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectS2IResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectorResource;
@@ -376,6 +377,7 @@ void deployTestSpecificResources() {
             .done();
 
         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();
     }
 
     void logCurrentStatus(Condition kafkaCondition, String resource) {

File: systemtest/src/test/java/io/strimzi/systemtest/LogSettingST.java
Patch:
@@ -15,6 +15,7 @@
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaBridgeResource;
+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaMirrorMaker2Resource;
 import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
@@ -413,6 +414,8 @@ void setup() {
             .endSpec()
             .done();
 
+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();
+
         KafkaConnectResource.kafkaConnect(CONNECT_NAME, CLUSTER_NAME, 1)
             .editSpec()
                 .withNewInlineLogging()

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -200,6 +200,7 @@ void setupEnvironment() throws InterruptedException {
         // 050-Deployment
         KubernetesResource.clusterOperator(NAMESPACE).done();
         KafkaResource.kafkaWithMetrics(CLUSTER_NAME, 3, 3).done();
+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();
         KafkaConnectResource.kafkaConnectWithMetrics(CLUSTER_NAME, 1, false).done();
         KafkaTopicResource.topic(CLUSTER_NAME, "test-topic", 7, 2).done();
         // Wait for Metrics refresh/values change

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.systemtest.kafkaclients.ClientFactory;
 import io.strimzi.systemtest.kafkaclients.EClientType;
 import io.strimzi.systemtest.kafkaclients.externalClients.OauthKafkaClient;
+import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
 import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
@@ -89,6 +90,8 @@ void testProducerConsumerConnect() throws IOException, KeyStoreException, Interr
         assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));
         assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));
 
+        KafkaClientsResource.deployKafkaClients(false, KAFKA_CLIENTS_NAME).done();
+
         KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
                 .editMetadata()
                     .addToLabels("type", "kafka-connect")

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -131,7 +131,7 @@ void testLoadBalancerIpOverride() throws Exception {
     @Tag(REGRESSION)
     void testDeployUnsupportedKafka() {
         String nonExistingVersion = "6.6.6";
-        String nonExistingVersionMessage = "Version " + nonExistingVersion + " is not supported.*";
+        String nonExistingVersionMessage = "Unsupported Kafka.spec.kafka.version: " + nonExistingVersion + ". Supported versions are.*";
 
         KafkaResource.kafkaWithoutWait(KafkaResource.defaultKafka(CLUSTER_NAME, 1, 1)
                 .editSpec()

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -82,7 +82,7 @@ public interface Constants {
      */
     String KAFKA_BRIDGE_JSON = "application/vnd.kafka.v2+json";
 
-    String DEFAULT_SINK_FILE_NAME = "/tmp/test-file-sink.txt";
+    String DEFAULT_SINK_FILE_PATH = "/tmp/test-file-sink.txt";
 
     int HTTP_BRIDGE_DEFAULT_PORT = 8080;
     int HTTP_JAEGER_DEFAULT_TCP_PORT = 5778;

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -91,7 +91,7 @@ void deployKafkaConnectorWithSink(String clusterName, String namespace, String t
         // Deploy Kafka Connector
         Map<String, Object> connectorConfig = new HashMap<>();
         connectorConfig.put("topics", topicName);
-        connectorConfig.put("file", Constants.DEFAULT_SINK_FILE_NAME);
+        connectorConfig.put("file", Constants.DEFAULT_SINK_FILE_PATH);
         connectorConfig.put("key.converter", "org.apache.kafka.connect.storage.StringConverter");
         connectorConfig.put("value.converter", "org.apache.kafka.connect.storage.StringConverter");
 
@@ -110,6 +110,6 @@ void deployKafkaConnectorWithSink(String clusterName, String namespace, String t
         internalKafkaClient.setPodName(kafkaClientsPodName);
         int sent = internalKafkaClient.sendMessages(topicName, namespace, clusterName, MESSAGE_COUNT);
         assertThat(sent, Matchers.is(MESSAGE_COUNT));
-        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_NAME, "99");
+        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_PATH, "99");
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -84,7 +84,7 @@ void testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String previousNamespace = cluster.setNamespace(SECOND_NAMESPACE);
         // Deploy Kafka Connect in other namespace than CO
-        KafkaConnectResource.kafkaConnect(SECOND_CLUSTER_NAME, 1, false)
+        KafkaConnectResource.kafkaConnect(SECOND_CLUSTER_NAME, 1)
             .editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata().done();
@@ -99,7 +99,7 @@ void testDeployKafkaConnectS2IAndKafkaConnectorInOtherNamespaceThanCO() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String previousNamespace = cluster.setNamespace(SECOND_NAMESPACE);
         // Deploy Kafka Connect in other namespace than CO
-        KafkaConnectS2IResource.kafkaConnectS2I(SECOND_CLUSTER_NAME, SECOND_CLUSTER_NAME, 1, false)
+        KafkaConnectS2IResource.kafkaConnectS2I(SECOND_CLUSTER_NAME, SECOND_CLUSTER_NAME, 1)
             .editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata().done();

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -202,7 +202,7 @@ void testKafkaBridgeStatus() {
     @Test
     void testKafkaConnectAndConnectorStatus() {
         String connectUrl = KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083);
-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1, false)
+        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
             .editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata().done();
@@ -254,7 +254,7 @@ void testKafkaConnectAndConnectorStatus() {
     void testKafkaConnectS2IStatus() {
         String connectS2IDeploymentConfigName = KafkaConnectS2IResources.deploymentName(CONNECTS2I_CLUSTER_NAME);
         String connectS2IUrl = KafkaConnectS2IResources.url(CONNECTS2I_CLUSTER_NAME, NAMESPACE, 8083);
-        KafkaConnectS2IResource.kafkaConnectS2I(CONNECTS2I_CLUSTER_NAME, CLUSTER_NAME, 1, true)
+        KafkaConnectS2IResource.kafkaConnectS2I(CONNECTS2I_CLUSTER_NAME, CLUSTER_NAME, 1)
             .editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata().done();

File: systemtest/src/test/java/io/strimzi/systemtest/LogSettingST.java
Patch:
@@ -413,7 +413,7 @@ void setup() {
             .endSpec()
             .done();
 
-        KafkaConnectResource.kafkaConnect(CONNECT_NAME, CLUSTER_NAME, 1, true)
+        KafkaConnectResource.kafkaConnect(CONNECT_NAME, CLUSTER_NAME, 1)
             .editSpec()
                 .withNewInlineLogging()
                     .withLoggers(CONNECT_LOGGERS)

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -154,7 +154,7 @@ void testUserWithQuotas() {
 
         // Create user with correct name
         KafkaUserResource.userWithQuota(CLUSTER_NAME, userName, prodRate, consRate, reqPerc).done();
-        SecretUtils.waitForSecretReady(userName);
+        KafkaUserUtils.waitForKafkaUserCreation(userName);
 
         String messageUserWasAdded = "User " + userName + " in namespace " + NAMESPACE + " was ADDED";
 

File: systemtest/src/test/java/io/strimzi/systemtest/kafka/ListenersST.java
Patch:
@@ -672,8 +672,8 @@ void testCustomCertRouteAndTlsRollingUpdate() throws Exception {
             .editSpec()
                 .editKafka()
                     .editListeners()
-                        .withNewKafkaListenerExternalNodePort()
-                        .endKafkaListenerExternalNodePort()
+                        .withNewKafkaListenerExternalRoute()
+                        .endKafkaListenerExternalRoute()
                     .endListeners()
                 .endKafka()
             .endSpec().done();

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/LogHasNoUnexpectedErrors.java
Patch:
@@ -73,7 +73,8 @@ enum LogWhiteList {
         OPERATION_TIMEOUT("Util:[0-9]+ - Exceeded timeout of.*while waiting for.*"),
         // This is whitelisted cause it's no real problem when this error appears, components are being created even after timeout
         RECONCILIATION_TIMEOUT("ERROR Abstract.*Operator:[0-9]+ - Reconciliation.*"),
-        ASSEMBLY_OPERATOR_RECONCILIATION_TIMEOUT("ERROR .*AssemblyOperator:[0-9]+ - Reconciliation.*[fF]ailed.*");
+        ASSEMBLY_OPERATOR_RECONCILIATION_TIMEOUT("ERROR .*AssemblyOperator:[0-9]+ - Reconciliation.*[fF]ailed.*"),
+        WATCHER_CLOSED_EXCEPTION("ERROR AbstractOperator:* - Watcher closed with exception in namespace *");
 
         final String name;
 

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -84,7 +84,7 @@ void testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String previousNamespace = cluster.setNamespace(SECOND_NAMESPACE);
         // Deploy Kafka Connect in other namespace than CO
-        KafkaConnectResource.kafkaConnect(SECOND_CLUSTER_NAME, 1)
+        KafkaConnectResource.kafkaConnect(SECOND_CLUSTER_NAME, 1, false)
             .editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata().done();
@@ -99,7 +99,7 @@ void testDeployKafkaConnectS2IAndKafkaConnectorInOtherNamespaceThanCO() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String previousNamespace = cluster.setNamespace(SECOND_NAMESPACE);
         // Deploy Kafka Connect in other namespace than CO
-        KafkaConnectS2IResource.kafkaConnectS2I(SECOND_CLUSTER_NAME, SECOND_CLUSTER_NAME, 1)
+        KafkaConnectS2IResource.kafkaConnectS2I(SECOND_CLUSTER_NAME, SECOND_CLUSTER_NAME, 1, false)
             .editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata().done();

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -126,6 +126,8 @@ protected void prepareEnvForOperator(String clientNamespace, List<String> namesp
         cluster.createNamespaces(clientNamespace, namespaces);
         cluster.createCustomResources(resources);
         cluster.applyClusterOperatorInstallFiles();
+        KubernetesResource.applyDefaultNetworkPolicySettings(clientNamespace, namespaces);
+
         // This is needed in case you are using internal kubernetes registry and you want to pull images from there
         for (String namespace : namespaces) {
             Exec.exec(null, Arrays.asList("oc", "policy", "add-role-to-group", "system:image-puller", "system:serviceaccounts:" + namespace, "-n", Environment.STRIMZI_ORG), 0, false, false);

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -202,7 +202,7 @@ void testKafkaBridgeStatus() {
     @Test
     void testKafkaConnectAndConnectorStatus() {
         String connectUrl = KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083);
-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
+        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1, false)
             .editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata().done();
@@ -254,7 +254,7 @@ void testKafkaConnectAndConnectorStatus() {
     void testKafkaConnectS2IStatus() {
         String connectS2IDeploymentConfigName = KafkaConnectS2IResources.deploymentName(CONNECTS2I_CLUSTER_NAME);
         String connectS2IUrl = KafkaConnectS2IResources.url(CONNECTS2I_CLUSTER_NAME, NAMESPACE, 8083);
-        KafkaConnectS2IResource.kafkaConnectS2I(CONNECTS2I_CLUSTER_NAME, CLUSTER_NAME, 1)
+        KafkaConnectS2IResource.kafkaConnectS2I(CONNECTS2I_CLUSTER_NAME, CLUSTER_NAME, 1, true)
             .editMetadata()
                 .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata().done();

File: systemtest/src/test/java/io/strimzi/systemtest/LogSettingST.java
Patch:
@@ -416,7 +416,7 @@ void setup() {
             .endSpec()
             .done();
 
-        KafkaConnectResource.kafkaConnect(CONNECT_NAME, CLUSTER_NAME, 1)
+        KafkaConnectResource.kafkaConnect(CONNECT_NAME, CLUSTER_NAME, 1, true)
             .editSpec()
                 .withNewInlineLogging()
                     .withLoggers(CONNECT_LOGGERS)

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -200,7 +200,7 @@ void setupEnvironment() throws InterruptedException {
         // 050-Deployment
         KubernetesResource.clusterOperator(NAMESPACE).done();
         KafkaResource.kafkaWithMetrics(CLUSTER_NAME, 3, 3).done();
-        KafkaConnectResource.kafkaConnectWithMetrics(CLUSTER_NAME, 1).done();
+        KafkaConnectResource.kafkaConnectWithMetrics(CLUSTER_NAME, 1, false).done();
         KafkaTopicResource.topic(CLUSTER_NAME, "test-topic", 7, 2).done();
         // Wait for Metrics refresh/values change
         Thread.sleep(60_000);

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthBaseST.java
Patch:
@@ -8,6 +8,7 @@
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
 import io.strimzi.systemtest.BaseST;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.enums.DefaultNetworkPolicy;
 import io.strimzi.systemtest.utils.kubeUtils.objects.SecretUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;
 import io.strimzi.test.executor.Exec;
@@ -79,6 +80,7 @@ public class OauthBaseST extends BaseST {
     void setup() throws InterruptedException {
         ResourceManager.setClassResources();
         prepareEnvForOperator(NAMESPACE);
+        KubernetesResource.applyDefaultNetworkPolicy(NAMESPACE, DefaultNetworkPolicy.DEFAULT_TO_ALLOW);
 
         applyRoleBindings(NAMESPACE);
         // 050-Deployment

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java
Patch:
@@ -87,7 +87,7 @@ void testProducerConsumerConnect() throws IOException, InterruptedException, Exe
         assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));
         assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));
 
-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
+        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1, true)
                 .editMetadata()
                     .addToLabels("type", "kafka-connect")
                 .endMetadata()

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -90,7 +90,7 @@ void testProducerConsumerConnect() throws IOException, KeyStoreException, Interr
         assertThat(producer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));
         assertThat(consumer.get(2, TimeUnit.MINUTES), is(MESSAGE_COUNT));
 
-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
+        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1, false)
                 .editMetadata()
                     .addToLabels("type", "kafka-connect")
                 .endMetadata()

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -193,7 +193,7 @@ void testConnectService() throws Exception {
         configOfKafkaConnect.put("key.converter.schemas.enable", "false");
         configOfKafkaConnect.put("value.converter.schemas.enable", "false");
 
-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
+        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1, false)
                 .withNewSpec()
                     .withConfig(configOfKafkaConnect)
                     .withNewJaegerTracing()
@@ -671,7 +671,7 @@ void testProducerConsumerMirrorMakerConnectStreamsService() throws Exception {
         configOfKafkaConnect.put("key.converter.schemas.enable", "false");
         configOfKafkaConnect.put("value.converter.schemas.enable", "false");
 
-        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1)
+        KafkaConnectResource.kafkaConnect(CLUSTER_NAME, 1, false)
                 .withNewSpec()
                     .withConfig(configOfKafkaConnect)
                     .withNewJaegerTracing()
@@ -765,7 +765,7 @@ void testConnectS2IService() throws Exception {
         configOfKafkaConnectS2I.put("key.converter", "org.apache.kafka.connect.storage.StringConverter");
         configOfKafkaConnectS2I.put("value.converter", "org.apache.kafka.connect.storage.StringConverter");
 
-        KafkaConnectS2IResource.kafkaConnectS2I(kafkaConnectS2IName, CLUSTER_NAME, 1)
+        KafkaConnectS2IResource.kafkaConnectS2I(kafkaConnectS2IName, CLUSTER_NAME, 1, true)
                 .editMetadata()
                     .addToLabels("type", "kafka-connect-s2i")
                 .endMetadata()

File: systemtest/src/test/java/io/strimzi/systemtest/upgrade/ZookeeperUpgradeST.java
Patch:
@@ -123,12 +123,13 @@ void runVersionChange(TestKafkaVersion initialVersion, TestKafkaVersion newVersi
 
         kafkaPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), kafkaPods);
         LOGGER.info("2nd Kafka roll (update) is complete");
-        kafkaPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);
-        LOGGER.info("3rd Kafka roll (update) is complete");
 
         if (testInfo.getDisplayName().contains("Upgrade")) {
             StatefulSetUtils.waitTillSsHasRolled(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME), zkReplicas, zkPods);
             LOGGER.info("2nd Zookeeper roll (update) is complete");
+        } else if (testInfo.getDisplayName().contains("Downgrade")) {
+            kafkaPods = StatefulSetUtils.waitTillSsHasRolled(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), kafkaReplicas, kafkaPods);
+            LOGGER.info("3rd Kafka roll (update) is complete");
         }
 
         LOGGER.info("Deployment of Kafka (" + newVersion.version() + ") complete");

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -29,7 +29,7 @@ public class KafkaConnectResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaConnectResource.class);
 
     public static final String PATH_TO_KAFKA_CONNECT_CONFIG = "../examples/kafka-connect/kafka-connect.yaml";
-    public static final String PATH_TO_KAFKA_CONNECT_METRICS_CONFIG = "../metrics/examples/kafka/kafka-connect-metrics.yaml";
+    public static final String PATH_TO_KAFKA_CONNECT_METRICS_CONFIG = "../examples/metrics/kafka-connect-metrics.yaml";
 
     public static MixedOperation<KafkaConnect, KafkaConnectList, DoneableKafkaConnect, Resource<KafkaConnect, DoneableKafkaConnect>> kafkaConnectClient() {
         return Crds.kafkaConnectOperation(ResourceManager.kubeClient().getClient());

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -31,7 +31,7 @@ public class KafkaMirrorMaker2Resource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaMirrorMaker2Resource.class);
 
     public static final String PATH_TO_KAFKA_MIRROR_MAKER_2_CONFIG = "../examples/kafka-mirror-maker-2/kafka-mirror-maker-2.yaml";
-    public static final String PATH_TO_KAFKA_MIRROR_MAKER_2_METRICS_CONFIG = "../metrics/examples/kafka/kafka-mirror-maker-2-metrics.yaml";
+    public static final String PATH_TO_KAFKA_MIRROR_MAKER_2_METRICS_CONFIG = "../examples/metrics/kafka-mirror-maker-2-metrics.yaml";
 
     public static MixedOperation<KafkaMirrorMaker2, KafkaMirrorMaker2List, DoneableKafkaMirrorMaker2, Resource<KafkaMirrorMaker2, DoneableKafkaMirrorMaker2>> kafkaMirrorMaker2Client() {
         return Crds.kafkaMirrorMaker2Operation(ResourceManager.kubeClient().getClient());

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -38,7 +38,7 @@
 public class KafkaResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaResource.class);
 
-    private static final String PATH_TO_KAFKA_METRICS_CONFIG = "../metrics/examples/kafka/kafka-metrics.yaml";
+    private static final String PATH_TO_KAFKA_METRICS_CONFIG = "../examples/metrics/kafka-metrics.yaml";
     private static final String PATH_TO_KAFKA_EPHEMERAL_CONFIG = "../examples/kafka/kafka-ephemeral.yaml";
     private static final String PATH_TO_KAFKA_PERSISTENT_CONFIG = "../examples/kafka/kafka-persistent.yaml";
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -49,6 +49,9 @@ private static KafkaBridgeBuilder defaultKafkaBridge(KafkaBridge kafkaBridge, St
             .editSpec()
                 .withBootstrapServers(bootstrap)
                 .withReplicas(kafkaBridgeReplicas)
+                .withNewInlineLogging()
+                    .addToLoggers("bridge.root.logger", "DEBUG")
+                .endInlineLogging()
             .endSpec();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -77,6 +77,9 @@ private static KafkaConnectBuilder defaultKafkaConnect(KafkaConnect kafkaConnect
                 .addToConfig("offset.storage.topic", KafkaConnectResources.configStorageTopicOffsets(kafkaClusterName))
                 .addToConfig("config.storage.topic", KafkaConnectResources.metricsAndLogConfigMapName(kafkaClusterName))
                 .addToConfig("status.storage.topic", KafkaConnectResources.configStorageTopicStatus(kafkaClusterName))
+                .withNewInlineLogging()
+                    .addToLoggers("connect.root.logger.level", "DEBUG")
+                .endInlineLogging()
             .endSpec();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -60,6 +60,9 @@ public static KafkaConnectS2IBuilder defaultKafkaConnectS2I(KafkaConnectS2I kafk
                     .withTrustedCertificates(new CertSecretSourceBuilder().withNewSecretName(kafkaClusterName + "-cluster-ca-cert").withCertificate("ca.crt").build())
                 .endTls()
                 .withInsecureSourceRepository(true)
+                .withNewInlineLogging()
+                    .addToLoggers("connect.root.logger.level", "DEBUG")
+                .endInlineLogging()
             .endSpec();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMaker2Resource.java
Patch:
@@ -98,6 +98,9 @@ private static KafkaMirrorMaker2Builder defaultKafkaMirrorMaker2(KafkaMirrorMake
                     .withSourceCluster(kafkaSourceClusterName)
                     .withTargetCluster(kafkaTargetClusterName)
                 .endMirror()
+                .withNewInlineLogging()
+                    .addToLoggers("connect.root.logger.level", "DEBUG")
+                .endInlineLogging()
             .endSpec();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -74,6 +74,9 @@ private static KafkaMirrorMakerBuilder defaultKafkaMirrorMaker(KafkaMirrorMaker
                 .endProducer()
                 .withReplicas(kafkaMirrorMakerReplicas)
                 .withWhitelist(".*")
+                .withNewInlineLogging()
+                    .addToLoggers("mirrormaker.root.logger", "DEBUG")
+                .endInlineLogging()
             .endSpec();
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -326,7 +326,7 @@ void testJvmAndResources() {
         TestUtils.waitFor("Kafka Connect CR change", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> kubeClient().getClient().adapt(OpenShiftClient.class).buildConfigs().inNamespace(NAMESPACE).withName(kafkaConnectS2IName + "-connect").get().getSpec().getResources().getRequests().get("cpu").equals(new Quantity("1")));
 
-        cmdKubeClient().exec("oc", "start-build", KafkaConnectS2IResources.deploymentName(kafkaConnectS2IName), "-n", NAMESPACE);
+        cmdKubeClient().exec("start-build", KafkaConnectS2IResources.deploymentName(kafkaConnectS2IName), "-n", NAMESPACE);
 
         KafkaConnectS2IUtils.waitForConnectS2IStatus(kafkaConnectS2IName, "Ready");
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaAvailability.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.vertx.core.Future;
 import io.vertx.core.Promise;
-import org.apache.kafka.clients.admin.AdminClient;
+import org.apache.kafka.clients.admin.Admin;
 import org.apache.kafka.clients.admin.Config;
 import org.apache.kafka.clients.admin.ConfigEntry;
 import org.apache.kafka.clients.admin.ListTopicsOptions;
@@ -35,10 +35,10 @@ class KafkaAvailability {
 
     private static final Logger log = LogManager.getLogger(KafkaAvailability.class.getName());
 
-    private final AdminClient ac;
+    private final Admin ac;
     private final Future<Collection<TopicDescription>> descriptions;
 
-    KafkaAvailability(AdminClient ac) {
+    KafkaAvailability(Admin ac) {
         this.ac = ac;
         // 1. Get all topic names
         Future<Set<String>> topicNames = topicNames();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperator.java
Patch:
@@ -8,6 +8,7 @@
 import io.fabric8.kubernetes.api.model.Secret;
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
 import io.fabric8.kubernetes.client.KubernetesClient;
+import io.strimzi.operator.common.AdminClientProvider;
 import io.strimzi.operator.common.BackOff;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ResourceOperatorSupplier.java
Patch:
@@ -27,7 +27,9 @@
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker2;
 import io.strimzi.operator.PlatformFeaturesAvailability;
+import io.strimzi.operator.common.AdminClientProvider;
 import io.strimzi.operator.common.BackOff;
+import io.strimzi.operator.common.DefaultAdminClientProvider;
 import io.strimzi.operator.common.operator.resource.BuildConfigOperator;
 import io.strimzi.operator.common.operator.resource.ClusterRoleBindingOperator;
 import io.strimzi.operator.common.operator.resource.ConfigMapOperator;

File: topic-operator/src/main/java/io/strimzi/operator/topic/KafkaImpl.java
Patch:
@@ -225,7 +225,7 @@ public Future<Void> deleteTopic(TopicName topicName) {
                 Collections.singleton(topicName.toString())).values().get(topicName.toString());
         queueWork(new UniWork<>("deleteTopic", future, handler));
         return handler.future().compose(ig ->
-                Util.waitFor(vertx, "deleted sync " + topicName, Long.MAX_VALUE, 1000, () -> {
+                Util.waitFor(vertx, "deleted sync " + topicName, 1000, 120_000, () -> {
                     try {
                         return adminClient.describeTopics(Collections.singleton(topicName.toString())).all().get().get(topicName.toString()) == null;
                     } catch (ExecutionException e) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -28,7 +28,6 @@
 import io.strimzi.api.kafka.model.ProbeBuilder;
 import io.strimzi.api.kafka.model.TlsSidecar;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.model.Labels;
 
 import java.util.ArrayList;
@@ -54,7 +53,6 @@ public class TopicOperator extends AbstractModel {
     protected static final String TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT = "/etc/tls-sidecar/eo-certs/";
     protected static final String TLS_SIDECAR_CA_CERTS_VOLUME_NAME = "cluster-ca-certs";
     protected static final String TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT = "/etc/tls-sidecar/cluster-ca-certs/";
-    public static final String ANNO_STRIMZI_IO_LOGGING = Annotations.STRIMZI_DOMAIN + "/logging";
 
     protected static final String METRICS_AND_LOG_CONFIG_SUFFIX = NAME_SUFFIX + "-config";
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -46,7 +46,6 @@
  */
 public class KafkaBridgeAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, KafkaBridge, KafkaBridgeList, DoneableKafkaBridge, Resource<KafkaBridge, DoneableKafkaBridge>> {
     private static final Logger log = LogManager.getLogger(KafkaBridgeAssemblyOperator.class.getName());
-    public static final String ANNO_STRIMZI_IO_LOGGING = Annotations.STRIMZI_DOMAIN + "/logging";
 
     private final DeploymentOperator deploymentOperations;
     private final KafkaVersion.Lookup versions;
@@ -91,7 +90,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge
                 null);
 
         Map<String, String> annotations = new HashMap<>();
-        annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(bridge.ANCILLARY_CM_KEY_LOG_CONFIG));
+        annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(bridge.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Bridge cluster", reconciliation, name, namespace);
         kafkaBridgeServiceAccount(namespace, bridge)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -25,6 +25,7 @@
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
 import io.strimzi.operator.common.operator.resource.DeploymentOperator;
@@ -106,7 +107,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
                 null);
 
         Map<String, String> annotations = new HashMap<>();
-        annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
+        annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Connect cluster", reconciliation, name, namespace);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -27,6 +27,7 @@
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.model.StatusDiff;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.operator.resource.BuildConfigOperator;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
@@ -117,7 +118,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
                 null);
 
         HashMap<String, String> annotations = new HashMap<>();
-        annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
+        annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Connect S2I cluster", reconciliation, name, namespace);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperator.java
Patch:
@@ -11,7 +11,9 @@
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.operator.resource.NetworkPolicyOperator;
+
 import org.apache.kafka.clients.admin.AdminClientConfig;
 import org.apache.kafka.common.config.SaslConfigs;
 import org.apache.kafka.common.config.SslConfigs;
@@ -137,7 +139,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                 null);
 
         Map<String, String> annotations = new HashMap<>();
-        annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(mirrorMaker2Cluster.ANCILLARY_CM_KEY_LOG_CONFIG));
+        annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(mirrorMaker2Cluster.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka MirrorMaker 2.0 cluster", reconciliation, name, namespace);
         log.info("{}: Updating Kafka MirrorMaker 2.0 cluster {} in {}", reconciliation, name, namespace);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -47,7 +47,6 @@
 public class KafkaMirrorMakerAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList, DoneableKafkaMirrorMaker, Resource<KafkaMirrorMaker, DoneableKafkaMirrorMaker>> {
 
     private static final Logger log = LogManager.getLogger(KafkaMirrorMakerAssemblyOperator.class.getName());
-    public static final String ANNO_STRIMZI_IO_LOGGING = Annotations.STRIMZI_DOMAIN + "/logging";
 
     private final DeploymentOperator deploymentOperations;
     private final KafkaVersion.Lookup versions;
@@ -94,7 +93,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                 null);
 
         Map<String, String> annotations = new HashMap<>();
-        annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(mirror.ANCILLARY_CM_KEY_LOG_CONFIG));
+        annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, logAndMetricsConfigMap.getData().get(mirror.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Mirror Maker cluster", reconciliation, name, namespace);
         mirrorMakerServiceAccount(namespace, mirror)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetDiff.java
Patch:
@@ -22,9 +22,11 @@ public class StatefulSetDiff extends AbstractResourceDiff {
 
     private static final Logger log = LogManager.getLogger(StatefulSetDiff.class.getName());
 
+    private static final String SHORTENED_STRIMZI_DOMAIN = Annotations.STRIMZI_DOMAIN.substring(0, Annotations.STRIMZI_DOMAIN.length() - 1);
+
     private static final Pattern IGNORABLE_PATHS = Pattern.compile(
         "^(/spec/revisionHistoryLimit"
-        + "|/spec/template/metadata/annotations/" + Annotations.STRIMZI_DOMAIN + "~1generation"
+        + "|/spec/template/metadata/annotations/" + SHORTENED_STRIMZI_DOMAIN + "~1generation"
         + "|/spec/template/spec/initContainers/[0-9]+/resources"
         + "|/spec/template/spec/initContainers/[0-9]+/terminationMessagePath"
         + "|/spec/template/spec/initContainers/[0-9]+/terminationMessagePolicy"

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -22,6 +22,7 @@
 import io.strimzi.operator.cluster.model.KafkaBridgeCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
@@ -167,7 +168,7 @@ public void testCreateCluster(VertxTestContext context) {
             Deployment dc = capturedDc.get(0);
             context.verify(() -> assertThat(dc.getMetadata().getName(), is(bridge.getName())));
             Map annotations = new HashMap();
-            annotations.put("strimzi.io/logging", LOGGING_CONFIG);
+            annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, LOGGING_CONFIG);
             context.verify(() -> assertThat("Deployments are not equal", dc, is(bridge.generateDeployment(annotations, true, null, null))));
 
             // Verify PodDisruptionBudget
@@ -368,7 +369,7 @@ public void testUpdateCluster(VertxTestContext context) {
             Deployment dc = capturedDc.get(0);
             context.verify(() -> assertThat(dc.getMetadata().getName(), is(compareTo.getName())));
             Map<String, String> annotations = new HashMap();
-            annotations.put("strimzi.io/logging", loggingCm.getData().get(compareTo.ANCILLARY_CM_KEY_LOG_CONFIG));
+            annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, loggingCm.getData().get(compareTo.ANCILLARY_CM_KEY_LOG_CONFIG));
             context.verify(() -> assertThat("Deployments are not equal", dc, is(compareTo.generateDeployment(annotations, true, null, null))));
 
             // Verify PodDisruptionBudget

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMaker2AssemblyOperatorTest.java
Patch:
@@ -20,6 +20,7 @@
 import io.strimzi.operator.cluster.model.KafkaMirrorMaker2Cluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.operator.resource.ConfigMapOperator;
@@ -157,7 +158,7 @@ public void testCreateCluster(VertxTestContext context) {
             Deployment dc = capturedDc.get(0);
             context.verify(() -> assertThat(dc.getMetadata().getName(), is(mirrorMaker2.getName())));
             Map annotations = new HashMap();
-            annotations.put("strimzi.io/logging", LOGGING_CONFIG);
+            annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, LOGGING_CONFIG);
             context.verify(() -> assertThat("Deployments are not equal", dc, is(mirrorMaker2.generateDeployment(annotations, true, null, null))));
 
             // Verify PodDisruptionBudget
@@ -351,7 +352,7 @@ public void testUpdateCluster(VertxTestContext context) {
             Deployment dc = capturedDc.get(0);
             context.verify(() -> assertThat(dc.getMetadata().getName(), is(compareTo.getName())));
             Map<String, String> annotations = new HashMap();
-            annotations.put("strimzi.io/logging", loggingCm.getData().get(compareTo.ANCILLARY_CM_KEY_LOG_CONFIG));
+            annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, loggingCm.getData().get(compareTo.ANCILLARY_CM_KEY_LOG_CONFIG));
             context.verify(() -> assertThat("Deployments are not equal", dc, is(compareTo.generateDeployment(annotations, true, null, null))));
 
             // Verify PodDisruptionBudget

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -22,6 +22,7 @@
 import io.strimzi.operator.cluster.model.KafkaMirrorMakerCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
@@ -162,7 +163,7 @@ public void testCreateCluster(VertxTestContext context) {
             Deployment dc = capturedDc.get(0);
             context.verify(() -> assertThat(dc.getMetadata().getName(), is(mirror.getName())));
             Map annotations = new HashMap();
-            annotations.put("strimzi.io/logging", LOGGING_CONFIG);
+            annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, LOGGING_CONFIG);
             context.verify(() -> assertThat("Deployments are not equal", dc, is(mirror.generateDeployment(annotations, true, null, null))));
 
             // Verify PodDisruptionBudget
@@ -355,7 +356,7 @@ public void testUpdateCluster(VertxTestContext context) {
             Deployment dc = capturedDc.get(0);
             context.verify(() -> assertThat(dc.getMetadata().getName(), is(compareTo.getName())));
             Map<String, String> annotations = new HashMap();
-            annotations.put("strimzi.io/logging", loggingCm.getData().get(compareTo.ANCILLARY_CM_KEY_LOG_CONFIG));
+            annotations.put(Annotations.STRIMZI_LOGGING_ANNOTATION, loggingCm.getData().get(compareTo.ANCILLARY_CM_KEY_LOG_CONFIG));
             context.verify(() -> assertThat("Deployments are not equal", dc, is(compareTo.generateDeployment(annotations, true, null, null))));
 
             // Verify PodDisruptionBudget

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/StatusUtils.java
Patch:
@@ -6,6 +6,7 @@
 package io.strimzi.operator.common.operator.resource;
 
 import io.fabric8.kubernetes.client.CustomResource;
+import io.strimzi.api.kafka.model.Constants;
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.api.kafka.model.status.ConditionBuilder;
 import io.strimzi.api.kafka.model.status.Status;
@@ -17,7 +18,7 @@
 import java.util.Collections;
 
 public class StatusUtils {
-    private static final String V1ALPHA1 = "kafka.strimzi.io/v1alpha1";
+    private static final String V1ALPHA1 = Constants.RESOURCE_GROUP_NAME + "/" + Constants.V1ALPHA1;
 
     /**
      * Returns the current timestamp in ISO 8601 format, for example "2019-07-23T09:08:12.356Z".

File: operator-common/src/test/java/io/strimzi/operator/common/model/LabelsTest.java
Patch:
@@ -153,7 +153,7 @@ public void testWithInvalidUserLabels()   {
             Map userLabelsWithStrimzi = new HashMap<String, String>(2);
             userLabelsWithStrimzi.put("key1", "value1");
             userLabelsWithStrimzi.put("key2", "value2");
-            userLabelsWithStrimzi.put("strimzi.io/something", "value3");
+            userLabelsWithStrimzi.put(Labels.STRIMZI_DOMAIN + "something", "value3");
 
             Labels nonNullLabels = Labels.EMPTY.withUserLabels(userLabelsWithStrimzi);
         });

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaBridgeCrdOperatorIT.java
Patch:
@@ -108,7 +108,7 @@ public static void after() {
 
     protected KafkaBridge getResource() {
         return new KafkaBridgeBuilder()
-                .withApiVersion("kafka.strimzi.io/v1alpha1")
+                .withApiVersion(KafkaBridge.RESOURCE_GROUP + "/" + KafkaBridge.V1ALPHA1)
                 .withNewMetadata()
                 .withName(RESOURCE_NAME)
                 .withNamespace(namespace)

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectCrdOperatorIT.java
Patch:
@@ -107,7 +107,7 @@ public static void after() {
 
     protected KafkaConnect getResource() {
         return new KafkaConnectBuilder()
-                .withApiVersion("kafka.strimzi.io/v1beta1")
+                .withApiVersion(KafkaConnect.RESOURCE_GROUP + "/" + KafkaConnect.V1BETA1)
                 .withNewMetadata()
                 .withName(RESOURCE_NAME)
                 .withNamespace(namespace)

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectS2IcrdOperatorIT.java
Patch:
@@ -107,10 +107,10 @@ public static void after() {
 
     protected KafkaConnectS2I getResource() {
         return new KafkaConnectS2IBuilder()
-                .withApiVersion("kafka.strimzi.io/v1beta1")
+                .withApiVersion(KafkaConnectS2I.RESOURCE_GROUP + "/" + KafkaConnectS2I.V1BETA1)
                 .withNewMetadata()
-                .withName(RESOURCE_NAME)
-                .withNamespace(namespace)
+                    .withName(RESOURCE_NAME)
+                    .withNamespace(namespace)
                 .endMetadata()
                 .withNewSpec()
                 .endSpec()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorIT.java
Patch:
@@ -107,7 +107,7 @@ public static void after() {
 
     protected Kafka getResource() {
         return new KafkaBuilder()
-                .withApiVersion("kafka.strimzi.io/v1beta1")
+                .withApiVersion(Kafka.RESOURCE_GROUP + "/" + Kafka.V1BETA1)
                 .withNewMetadata()
                     .withName(RESOURCE_NAME)
                     .withNamespace(namespace)

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaMirrorMaker2CrdOperatorIT.java
Patch:
@@ -107,7 +107,7 @@ public static void after() {
 
     protected KafkaMirrorMaker2 getResource() {
         return new KafkaMirrorMaker2Builder()
-                .withApiVersion("kafka.strimzi.io/v1alpha1")
+                .withApiVersion(KafkaMirrorMaker2.RESOURCE_GROUP + "/" + KafkaMirrorMaker2.V1ALPHA1)
                 .withNewMetadata()
                 .withName(RESOURCE_NAME)
                 .withNamespace(namespace)

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaMirrorMakerCrdOperatorIT.java
Patch:
@@ -108,7 +108,7 @@ public static void after() {
 
     protected KafkaMirrorMaker getResource() {
         return new KafkaMirrorMakerBuilder()
-                .withApiVersion("kafka.strimzi.io/v1beta1")
+                .withApiVersion(KafkaMirrorMaker.RESOURCE_GROUP + "/" + KafkaMirrorMaker.V1BETA1)
                 .withNewMetadata()
                     .withName(RESOURCE_NAME)
                     .withNamespace(namespace)

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaUserCrdOperatorIT.java
Patch:
@@ -107,7 +107,7 @@ public static void after() {
 
     protected KafkaUser getResource() {
         return new KafkaUserBuilder()
-                .withApiVersion("kafka.strimzi.io/v1beta1")
+                .withApiVersion(KafkaUser.RESOURCE_GROUP + "/" + KafkaUser.V1BETA1)
                 .withNewMetadata()
                     .withName(RESOURCE_NAME)
                     .withNamespace(namespace)

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaClientsResource.java
Patch:
@@ -17,6 +17,7 @@
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.KafkaUserScramSha512ClientAuthentication;
 import io.strimzi.api.kafka.model.KafkaUserTlsClientAuthentication;
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
@@ -151,7 +152,7 @@ private static PodSpec createClientSpec(boolean tlsListener, String kafkaClients
                 }
 
                 if (tlsListener) {
-                    String clusterName = kafkaUser.getMetadata().getLabels().get("strimzi.io/cluster");
+                    String clusterName = kafkaUser.getMetadata().getLabels().get(Labels.STRIMZI_CLUSTER_LABEL);
                     String clusterNamespace = KafkaResource.kafkaClient().inAnyNamespace().list().getItems().stream().filter(kafka -> kafka.getMetadata().getName().equals(clusterName)).findFirst().get().getMetadata().getNamespace();
                     String clusterCaSecretName = KafkaResource.getKafkaTlsListenerCaCertName(clusterNamespace, clusterName);
                     String clusterCaSecretVolumeName = "ca-cert-" + kafkaUserName;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -12,6 +12,7 @@
 import io.strimzi.api.kafka.model.DoneableKafkaConnector;
 import io.strimzi.api.kafka.model.KafkaConnector;
 import io.strimzi.api.kafka.model.KafkaConnectorBuilder;
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.test.TestUtils;
@@ -53,7 +54,7 @@ public static KafkaConnectorBuilder defaultKafkaConnector(KafkaConnector kafkaCo
             .editOrNewMetadata()
                 .withName(name)
                 .withNamespace(ResourceManager.kubeClient().getNamespace())
-                .addToLabels("strimzi.io/cluster", kafkaConnectClusterName)
+                .addToLabels(Labels.STRIMZI_CLUSTER_LABEL, kafkaConnectClusterName)
             .endMetadata()
             .editOrNewSpec()
                 .withTasksMax(maxTasks)

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaTopicResource.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.api.kafka.model.DoneableKafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopicBuilder;
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -50,7 +51,7 @@ public static KafkaTopicBuilder defaultTopic(String clusterName, String topicNam
             .withNewMetadata()
                 .withName(topicName)
                 .withNamespace(ResourceManager.kubeClient().getNamespace())
-                .addToLabels("strimzi.io/cluster", clusterName)
+                .addToLabels(Labels.STRIMZI_CLUSTER_LABEL, clusterName)
             .endMetadata()
             .editSpec()
                 .withPartitions(partitions)

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaUserResource.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.api.kafka.model.DoneableKafkaUser;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.KafkaUserBuilder;
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.utils.kubeUtils.objects.SecretUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -53,7 +54,7 @@ public static KafkaUserBuilder defaultUser(String clusterName, String name) {
                 .withClusterName(clusterName)
                 .withName(name)
                 .withNamespace(ResourceManager.kubeClient().getNamespace())
-                .addToLabels("strimzi.io/cluster", clusterName)
+                .addToLabels(Labels.STRIMZI_CLUSTER_LABEL, clusterName)
             .endMetadata();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/ConfigMapUtils.java
Patch:
@@ -5,6 +5,8 @@
 package io.strimzi.systemtest.utils.kubeUtils.controllers;
 
 import io.fabric8.kubernetes.api.model.ConfigMap;
+
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -48,7 +50,7 @@ public static void waitForConfigMapRecovery(String name, String configMapUid) {
     public static void waitForKafkaConfigMapLabelsChange(String configMapName, Map<String, String> labels) {
         for (Map.Entry<String, String> entry : labels.entrySet()) {
             boolean isK8sTag = entry.getKey().equals("controller-revision-hash") || entry.getKey().equals("statefulset.kubernetes.io/pod-name");
-            boolean isStrimziTag = entry.getKey().startsWith("strimzi.io/");
+            boolean isStrimziTag = entry.getKey().startsWith(Labels.STRIMZI_DOMAIN);
             // ignoring strimzi.io and k8s labels
             if (!(isStrimziTag || isK8sTag)) {
                 LOGGER.info("Waiting for Kafka config map label change {} -> {}", entry.getKey(), entry.getValue());

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/StatefulSetUtils.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.fabric8.kubernetes.api.model.LabelSelector;
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
 import io.strimzi.test.TestUtils;
@@ -170,7 +171,7 @@ public static void waitForStatefulSetRecovery(String name, String statefulSetUid
     public static void waitForKafkaStatefulSetLabelsChange(String statefulSetName, Map<String, String> labels) {
         for (Map.Entry<String, String> entry : labels.entrySet()) {
             boolean isK8sTag = entry.getKey().equals("controller-revision-hash") || entry.getKey().equals("statefulset.kubernetes.io/pod-name");
-            boolean isStrimziTag = entry.getKey().startsWith("strimzi.io/");
+            boolean isStrimziTag = entry.getKey().startsWith(Labels.STRIMZI_DOMAIN);
             // ignoring strimzi.io and k8s labels
             if (!(isStrimziTag || isK8sTag)) {
                 LOGGER.info("Waiting for Kafka stateful set label change {} -> {}", entry.getKey(), entry.getValue());

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/ServiceUtils.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.utils.kubeUtils.objects;
 
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -24,7 +25,7 @@ private ServiceUtils() { }
     public static void waitForKafkaServiceLabelsChange(String serviceName, Map<String, String> labels) {
         for (Map.Entry<String, String> entry : labels.entrySet()) {
             boolean isK8sTag = entry.getKey().equals("controller-revision-hash") || entry.getKey().equals("statefulset.kubernetes.io/pod-name");
-            boolean isStrimziTag = entry.getKey().startsWith("strimzi.io/");
+            boolean isStrimziTag = entry.getKey().startsWith(Labels.STRIMZI_DOMAIN);
             // ignoring strimzi.io and k8s labels
             if (!(isStrimziTag || isK8sTag)) {
                 LOGGER.info("Waiting for Kafka service label change {} -> {}", entry.getKey(), entry.getValue());

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -9,6 +9,7 @@
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.status.Condition;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
@@ -85,7 +86,7 @@ void testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO() {
         // Deploy Kafka Connect in other namespace than CO
         KafkaConnectResource.kafkaConnect(SECOND_CLUSTER_NAME, 1)
             .editMetadata()
-                .addToAnnotations("strimzi.io/use-connector-resources", "true")
+                .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata().done();
         // Deploy Kafka Connector
         deployKafkaConnectorWithSink(SECOND_CLUSTER_NAME, SECOND_NAMESPACE, topicName, "kafka-connect");
@@ -100,7 +101,7 @@ void testDeployKafkaConnectS2IAndKafkaConnectorInOtherNamespaceThanCO() {
         // Deploy Kafka Connect in other namespace than CO
         KafkaConnectS2IResource.kafkaConnectS2I(SECOND_CLUSTER_NAME, SECOND_CLUSTER_NAME, 1)
             .editMetadata()
-                .addToAnnotations("strimzi.io/use-connector-resources", "true")
+                .addToAnnotations(Annotations.STRIMZI_IO_USE_CONNECTOR_RESOURCES, "true")
             .endMetadata().done();
         // Deploy Kafka Connector
         deployKafkaConnectorWithSink(SECOND_CLUSTER_NAME, SECOND_NAMESPACE, topicName, "kafka-connect-s2i");

File: systemtest/src/test/java/io/strimzi/systemtest/MirrorMaker2ST.java
Patch:
@@ -15,6 +15,7 @@
 import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationScramSha512;
 import io.strimzi.api.kafka.model.listener.KafkaListenerAuthenticationTls;
 import io.strimzi.api.kafka.model.listener.KafkaListenerTls;
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaClientsResource;
@@ -256,7 +257,7 @@ private void testDockerImagesForKafkaMirrorMaker2() {
         LOGGER.info("Verifying docker image names");
         Map<String, String> imgFromDeplConf = getImagesFromConfig();
         //Verifying docker image for kafka mirrormaker2
-        String mirrormaker2ImageName = PodUtils.getFirstContainerImageNameFromPod(kubeClient().listPods("strimzi.io/kind", "KafkaMirrorMaker2").
+        String mirrormaker2ImageName = PodUtils.getFirstContainerImageNameFromPod(kubeClient().listPods(Labels.STRIMZI_KIND_LABEL, "KafkaMirrorMaker2").
                 get(0).getMetadata().getName());
 
         String mirrormaker2Version = Crds.kafkaMirrorMaker2Operation(kubeClient().getClient()).inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getSpec().getVersion();

File: systemtest/src/test/java/io/strimzi/systemtest/TopicST.java
Patch:
@@ -5,6 +5,7 @@
 package io.strimzi.systemtest;
 
 import io.strimzi.api.kafka.model.KafkaTopic;
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
@@ -54,7 +55,7 @@ void testMoreReplicasThanAvailableBrokers() {
         assertThat("Topic doesn't exists in Kafka itself", !hasTopicInKafka(topicName));
 
         // Checking TO logs
-        String tOPodName = cmdKubeClient().listResourcesByLabel("pod", "strimzi.io/name=my-cluster-entity-operator").get(0);
+        String tOPodName = cmdKubeClient().listResourcesByLabel("pod", Labels.STRIMZI_NAME_LABEL + "=my-cluster-entity-operator").get(0);
         String errorMessage = "Replication factor: 5 larger than available brokers: 3";
 
         PodUtils.waitUntilMessageIsInLogs(tOPodName, "topic-operator", errorMessage);

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -9,6 +9,7 @@
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.KafkaUserScramSha512ClientAuthentication;
 import io.strimzi.api.kafka.model.status.Condition;
+import io.strimzi.operator.common.model.Labels;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaUserUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.SecretUtils;
 import io.strimzi.test.TestUtils;
@@ -158,7 +159,7 @@ void testUserWithQuotas() {
         String messageUserWasAdded = "User " + userName + " in namespace " + NAMESPACE + " was ADDED";
 
         // Checking UO logs
-        String entityOperatorPodName = kubeClient().listPods("strimzi.io/name", KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME)).get(0).getMetadata().getName();
+        String entityOperatorPodName = kubeClient().listPods(Labels.STRIMZI_NAME_LABEL, KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME)).get(0).getMetadata().getName();
         String uOlogs = kubeClient().logs(entityOperatorPodName, "user-operator");
         assertThat(uOlogs.contains(messageUserWasAdded), is(true));
 

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorBaseIT.java
Patch:
@@ -82,8 +82,7 @@ public abstract class TopicOperatorBaseIT {
 
     protected static String oldNamespace;
 
-    protected final Labels labels = Labels.fromString(
-            "strimzi.io/kind=topic");
+    protected final Labels labels = Labels.fromString(io.strimzi.operator.common.model.Labels.STRIMZI_KIND_LABEL + "=topic");
 
     public static final String NAMESPACE = "topic-operator-it";
 
@@ -265,7 +264,7 @@ protected Map<String, String> topicOperatorConfig() {
         m.put(Config.ZOOKEEPER_CONNECT.key, "localhost:" + zkPort(kafkaCluster));
         m.put(Config.ZOOKEEPER_CONNECTION_TIMEOUT_MS.key, "30000");
         m.put(Config.NAMESPACE.key, NAMESPACE);
-        m.put(Config.TC_RESOURCE_LABELS, "strimzi.io/kind=topic");
+        m.put(Config.TC_RESOURCE_LABELS, io.strimzi.operator.common.model.Labels.STRIMZI_KIND_LABEL + "=topic");
         m.put(Config.FULL_RECONCILIATION_INTERVAL_MS.key, "20000");
         return m;
     }

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -1434,7 +1434,7 @@ void testLabelModificationDoesNotBreakCluster() throws Exception {
         labels.put(labelKeys[0], labelValues[0]);
         labels.put(labelKeys[1], labelValues[1]);
 
-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 1)
+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 3, 1)
                 .editMetadata()
                     .withLabels(labels)
                 .endMetadata()

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -396,7 +396,7 @@ void autoReplaceSomeKeysTriggeredByAnno(final List<String> secrets,
         }
         if (kafkaShouldRoll) {
             LOGGER.info("Wait for kafka to rolling restart (1)...");
-            kafkaPods = StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), 3, kafkaPods);
+            kafkaPods = StatefulSetUtils.waitTillSsHasRolled(kafkaStatefulSetName(CLUSTER_NAME), kafkaPods);
         }
         if (eoShouldRoll) {
             LOGGER.info("Wait for EO to rolling restart (1)...");

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -153,7 +153,7 @@ public static Map<String, Object> loadProperties(String keyValuePairs) {
             actual.load(new StringReader(keyValuePairs));
             return (Map) actual;
         } catch (IOException e) {
-            throw new AssertionError("Invalid Properties definiton", e);
+            throw new AssertionError("Invalid Properties definition", e);
         }
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -110,6 +110,6 @@ void deployKafkaConnectorWithSink(String clusterName, String namespace, String t
         internalKafkaClient.setPodName(kafkaClientsPodName);
         int sent = internalKafkaClient.sendMessages(topicName, namespace, clusterName, MESSAGE_COUNT);
         assertThat(sent, Matchers.is(MESSAGE_COUNT));
-        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_NAME);
+        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_NAME, "99");
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/MirrorMakerST.java
Patch:
@@ -135,7 +135,7 @@ void testMirrorMaker() throws Exception {
      */
     @Test
     @Tag(ACCEPTANCE)
-    void testMirrorMakerTlsAuthenticated() throws Exception {
+    void testMirrorMakerTlsAuthenticated() {
         timeMeasuringSystem.setOperationID(timeMeasuringSystem.startTimeMeasuring(Operation.MM_DEPLOYMENT));
         String topicSourceName = TOPIC_NAME + "-source" + "-" + rng.nextInt(Integer.MAX_VALUE);
         String kafkaSourceUserName = "my-user-source";
@@ -241,7 +241,7 @@ void testMirrorMakerTlsAuthenticated() throws Exception {
      * Test mirroring messages by Mirror Maker over tls transport using scram-sha auth
      */
     @Test
-    void testMirrorMakerTlsScramSha() throws InterruptedException {
+    void testMirrorMakerTlsScramSha() {
         timeMeasuringSystem.setOperationID(timeMeasuringSystem.startTimeMeasuring(Operation.MM_DEPLOYMENT));
         String topicName = TOPIC_NAME + "-" + rng.nextInt(Integer.MAX_VALUE);
         String kafkaUserSource = "my-user-source";
@@ -361,7 +361,7 @@ void testMirrorMakerTlsScramSha() throws InterruptedException {
     }
 
     @Test
-    void testWhiteList() throws InterruptedException {
+    void testWhiteList() {
         String topicName = "whitelist-topic";
         String topicNotInWhitelist = "non-whitelist-topic";
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -204,4 +204,4 @@ public static List<String> getLinesWithoutCommentsAndEmptyLines(String config) {
         }
         return validLines;
     }
-}
+}
\ No newline at end of file

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -51,6 +51,7 @@ public interface Constants {
 
     long CO_OPERATION_TIMEOUT_DEFAULT = Duration.ofMinutes(5).toMillis();
     long CO_OPERATION_TIMEOUT_SHORT = Duration.ofSeconds(30).toMillis();
+    long CO_OPERATION_TIMEOUT_MEDIUM = Duration.ofMinutes(2).toMillis();
     long CO_OPERATION_TIMEOUT_WAIT = CO_OPERATION_TIMEOUT_SHORT + Duration.ofSeconds(80).toMillis();
     long CO_OPERATION_TIMEOUT_POLL = Duration.ofSeconds(2).toMillis();
     long RECONCILIATION_INTERVAL = Duration.ofSeconds(30).toMillis();

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/controllers/StatefulSetUtils.java
Patch:
@@ -119,7 +119,6 @@ public static Map<String, String> waitTillSsHasRolled(String name, Map<String, S
     public static Map<String, String> waitTillSsHasRolled(String name, int expectedPods, Map<String, String> snapshot) {
         waitTillSsHasRolled(name, snapshot);
         waitForAllStatefulSetPodsReady(name, expectedPods);
-        LOGGER.info("StatefulSet {} rolling update finished", name);
         return ssSnapshot(name);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -214,7 +214,7 @@ void testCustomAndUpdatedValues() {
         int updatedPeriodSeconds = 5;
         int updatedFailureThreshold = 1;
 
-        KafkaResource.kafkaEphemeral(CLUSTER_NAME, 2)
+        KafkaResource.kafkaPersistent(CLUSTER_NAME, 2)
             .editSpec()
                 .editKafka()
                     .withNewTlsSidecar()

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/Producer.java
Patch:
@@ -50,7 +50,7 @@ private void sendNext(KafkaProducer<String, String> producer, String topic) {
         if (msgCntPredicate.negate().test(numSent.get())) {
 
             KafkaProducerRecord<String, String> record =
-                    KafkaProducerRecord.create(topic, String.valueOf("Sending messages: Hello-world - " + numSent.get()));
+                    KafkaProducerRecord.create(topic, String.valueOf("\"Sending messages\": \"Hello-world - " + numSent.get() + "\""));
 
             producer.send(record, done -> {
                 if (done.succeeded()) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/HttpUtils.java
Patch:
@@ -125,15 +125,17 @@ public static JsonArray receiveMessagesHttpRequest(String bridgeHost, int bridge
                         if (response.body().size() > 0) {
                             for (int i = 0; i < response.body().size(); i++) {
                                 JsonObject jsonResponse = response.body().getJsonObject(i);
+                                LOGGER.info("This is jsonResponse object {}", jsonResponse.toString());
                                 String kafkaTopic = jsonResponse.getString("topic");
                                 int kafkaPartition = jsonResponse.getInteger("partition");
                                 String key = jsonResponse.getString("key");
-                                int value = jsonResponse.getInteger("value");
+                                String value = jsonResponse.getString("value");
                                 long offset = jsonResponse.getLong("offset");
                                 LOGGER.debug("Received msg: topic:{} partition:{} key:{} value:{} offset{}", kafkaTopic, kafkaPartition, key, value, offset);
                             }
                             LOGGER.info("Received {} messages from the bridge", response.body().size());
                         } else {
+                            LOGGER.info("Received body:{}", response.body());
                             LOGGER.debug("Received 0 messages, going to consume again");
                         }
                         future.complete(response.body());

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectUtils.java
Patch:
@@ -59,7 +59,7 @@ public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodN
 
     public static void waitForMessagesInKafkaConnectFileSink(String kafkaConnectPodName, String sinkFileName) {
         waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, sinkFileName,
-                "Sending messages: Hello-world - 99");
+                "\"Sending messages\": \"Hello-world - 99\"");
     }
 
     public static String getCreatedConnectors(String connectPodName) {

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -108,8 +108,8 @@ void deployKafkaConnectorWithSink(String clusterName, String namespace, String t
         KafkaClientsResource.deployKafkaClients(false, clusterName + "-" + Constants.KAFKA_CLIENTS).done();
         final String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(clusterName + "-" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();
         internalKafkaClient.setPodName(kafkaClientsPodName);
-        int sent = internalKafkaClient.sendMessages(topicName, namespace, clusterName, 100);
-        assertThat(sent, Matchers.is(10));
+        int sent = internalKafkaClient.sendMessages(topicName, namespace, clusterName, MESSAGE_COUNT);
+        assertThat(sent, Matchers.is(MESSAGE_COUNT));
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_NAME);
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -79,7 +79,7 @@ void testDeployMirrorMakerAcrossMultipleNamespace() {
     }
 
     @Test
-    void testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO() throws Exception {
+    void testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String previousNamespace = cluster.setNamespace(SECOND_NAMESPACE);
         // Deploy Kafka Connect in other namespace than CO
@@ -94,7 +94,7 @@ void testDeployKafkaConnectAndKafkaConnectorInOtherNamespaceThanCO() throws Exce
     }
 
     @Test
-    void testDeployKafkaConnectS2IAndKafkaConnectorInOtherNamespaceThanCO() throws Exception {
+    void testDeployKafkaConnectS2IAndKafkaConnectorInOtherNamespaceThanCO() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         String previousNamespace = cluster.setNamespace(SECOND_NAMESPACE);
         // Deploy Kafka Connect in other namespace than CO
@@ -120,7 +120,7 @@ void testUOWatchingOtherNamespace() {
     }
 
     @Test
-    void testUserInDifferentNamespace() throws Exception {
+    void testUserInDifferentNamespace() {
         String startingNamespace = cluster.setNamespace(SECOND_NAMESPACE);
         KafkaUser user = KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();
 

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -61,7 +61,7 @@ class RollingUpdateST extends BaseST {
     private static final Pattern ZK_SERVER_STATE = Pattern.compile("zk_server_state\\s+(leader|follower)");
 
     @Test
-    void testRecoveryDuringZookeeperRollingUpdate() throws Exception {
+    void testRecoveryDuringZookeeperRollingUpdate() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         int messageCount = 50;
 
@@ -120,7 +120,7 @@ void testRecoveryDuringZookeeperRollingUpdate() throws Exception {
     }
 
     @Test
-    void testRecoveryDuringKafkaRollingUpdate() throws Exception {
+    void testRecoveryDuringKafkaRollingUpdate() {
         String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
         int messageCount = 50;
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -74,7 +74,6 @@ void testSendSimpleMessage() throws Exception {
 
     @Test
     void testReceiveSimpleMessage() throws Exception {
-        int messageCount = 50;
         String topicName = "topic-simple-receive";
         // Create topic
         KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();
@@ -97,14 +96,14 @@ void testReceiveSimpleMessage() throws Exception {
         // Subscribe
         assertThat(HttpUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, groupId, name, client), is(true));
         // Send messages to Kafka
-        kafkaClient.sendMessages(CLUSTER_NAME, NAMESPACE, topicName, messageCount);
+        kafkaClient.sendMessages(topicName, NAMESPACE, CLUSTER_NAME, MESSAGE_COUNT);
         // Try to consume messages
         JsonArray bridgeResponse = HttpUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, groupId, name, client);
         if (bridgeResponse.size() == 0) {
             // Real consuming
             bridgeResponse = HttpUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, groupId, name, client);
         }
-        assertThat("Sent message count is not equal with received message count", bridgeResponse.size(), is(messageCount));
+        assertThat("Sent message count is not equal with received message count", bridgeResponse.size(), is(MESSAGE_COUNT));
         // Delete consumer
         assertThat(deleteConsumer(bridgeHost, bridgePort, groupId, name), is(true));
     }

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -709,7 +709,6 @@ void testProducerConsumerMirrorMakerConnectStreamsService() throws Exception {
         cmdKubeClient().execInPod(kafkaConnectPodName, "/bin/bash", "-c", "curl -X POST -H \"Content-Type: application/json\" --data "
                 + "'" + connectorConfig + "'" + " http://localhost:8083/connectors");
 
-
         Future<Integer> producer = externalBasicKafkaClient.sendMessages(TEST_TOPIC_NAME, NAMESPACE, kafkaClusterTargetName, MESSAGE_COUNT);
         Future<Integer> consumer = externalBasicKafkaClient.receiveMessages(TEST_TOPIC_NAME, NAMESPACE, kafkaClusterTargetName, MESSAGE_COUNT);
 
@@ -801,7 +800,8 @@ void testConnectS2IService() throws Exception {
         String execPodName = KafkaResources.kafkaPodName(CLUSTER_NAME, 0);
 
         LOGGER.info("Creating FileSink connect via Pod:{}", execPodName);
-        KafkaConnectUtils.createFileSinkConnector(execPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(kafkaConnectS2IName, NAMESPACE, 8083));
+        KafkaConnectUtils.createFileSinkConnector(execPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME,
+                KafkaConnectResources.url(kafkaConnectS2IName, NAMESPACE, 8083));
 
         Future<Integer> producer = externalBasicKafkaClient.sendMessages(TEST_TOPIC_NAME, NAMESPACE, CLUSTER_NAME, MESSAGE_COUNT);
         Future<Integer> consumer = externalBasicKafkaClient.receiveMessages(TEST_TOPIC_NAME, NAMESPACE, CLUSTER_NAME, MESSAGE_COUNT);

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -763,6 +763,8 @@ void testConnectS2IService() throws Exception {
         Map<String, Object> configOfKafkaConnectS2I = new HashMap<>();
         configOfKafkaConnectS2I.put("key.converter.schemas.enable", "false");
         configOfKafkaConnectS2I.put("value.converter.schemas.enable", "false");
+        configOfKafkaConnectS2I.put("key.converter", "org.apache.kafka.connect.storage.StringConverter");
+        configOfKafkaConnectS2I.put("value.converter", "org.apache.kafka.connect.storage.StringConverter");
 
         KafkaConnectS2IResource.kafkaConnectS2I(kafkaConnectS2IName, CLUSTER_NAME, 1)
                 .editMetadata()

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/NamespaceUtils.java
Patch:
@@ -21,6 +21,6 @@ public static void waitForNamespaceDeletion(String name) {
         LOGGER.info("Waiting when Namespace {} to be deleted", name);
 
         TestUtils.waitFor("namespace " + name, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
-            () -> !kubeClient().getNamespaceStatus(name));
+            () -> kubeClient().getNamespace(name) == null);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -348,8 +348,8 @@ private String getSecurityProtocol(boolean tls, boolean sasl)   {
         if (oauth.getClientId() != null) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_CLIENT_ID, oauth.getClientId()));
         if (oauth.getValidIssuerUri() != null) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_VALID_ISSUER_URI, oauth.getValidIssuerUri()));
         if (oauth.getJwksEndpointUri() != null) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_JWKS_ENDPOINT_URI, oauth.getJwksEndpointUri()));
-        if (oauth.getJwksRefreshSeconds() > 0) options.add(String.format("%s=\"%d\"", ServerConfig.OAUTH_JWKS_REFRESH_SECONDS, oauth.getJwksRefreshSeconds()));
-        if (oauth.getJwksExpirySeconds() > 0) options.add(String.format("%s=\"%d\"", ServerConfig.OAUTH_JWKS_EXPIRY_SECONDS, oauth.getJwksExpirySeconds()));
+        if (oauth.getJwksRefreshSeconds() != null && oauth.getJwksRefreshSeconds() > 0) options.add(String.format("%s=\"%d\"", ServerConfig.OAUTH_JWKS_REFRESH_SECONDS, oauth.getJwksRefreshSeconds()));
+        if (oauth.getJwksRefreshSeconds() != null && oauth.getJwksExpirySeconds() > 0) options.add(String.format("%s=\"%d\"", ServerConfig.OAUTH_JWKS_EXPIRY_SECONDS, oauth.getJwksExpirySeconds()));
         if (oauth.isEnableECDSA()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_CRYPTO_PROVIDER_BOUNCYCASTLE, true));
         if (oauth.getIntrospectionEndpointUri() != null) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_INTROSPECTION_ENDPOINT_URI, oauth.getIntrospectionEndpointUri()));
         if (oauth.getUserNameClaim() != null) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_USERNAME_CLAIM, oauth.getUserNameClaim()));

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaClientsResource.java
Patch:
@@ -447,7 +447,7 @@ public static DoneableDeployment deployKeycloak() {
                         .withContainers()
                         .addNewContainer()
                             .withName(keycloakName + "pod")
-                            .withImage("jboss/keycloak")
+                            .withImage("jboss/keycloak:8.0.1")
                             .withPorts(
                                 new ContainerPortBuilder()
                                     .withName("http")

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -1391,7 +1391,6 @@ Future<ReconciliationState> zkScaleUpInSmallSteps() {
         Future<ReconciliationState> zkScaleUp() {
             if (zkScalingUp) {
                 return zkSetOperations.scaleUp(namespace, zkCluster.getName(), zkCluster.getReplicas())
-                        .compose(ignore -> podOperations.readiness(namespace, zkCluster.getPodName(zkCluster.getReplicas() - 1), 1_000, operationTimeoutMs))
                         .map(this);
             } else {
                 return Future.succeededFuture(this);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -102,7 +102,7 @@ public abstract class AbstractModel {
     @Deprecated
     public static final String ANNO_CO_STRIMZI_IO_DELETE_CLAIM = "cluster.operator.strimzi.io/delete-claim";
 
-    public static final String ANNO_STRIMZI_CM_GENERATION = Annotations.STRIMZI_DOMAIN + "/cm-generation";
+    public static final String ANNO_STRIMZI_LOGGING_HASH = Annotations.STRIMZI_DOMAIN + "/logging-hash";
 
     protected final String cluster;
     protected final String namespace;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -146,7 +146,7 @@ private Map<String, List> upgrade(VertxTestContext context, Map<String, String>
         states.put("sts", new ArrayList<StatefulSet>(2));
         states.put("cm", new ArrayList<ConfigMap>(2));
 
-        StatefulSet kafkaSts = initialSs != null ? initialSs : kafkaCluster.generateStatefulSet(false, null, null, -1L);
+        StatefulSet kafkaSts = initialSs != null ? initialSs : kafkaCluster.generateStatefulSet(false, null, null);
 
         when(kso.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kafkaSts));
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -40,8 +40,8 @@ public class KafkaSetOperatorTest {
     @BeforeEach
     public void before() {
         KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap(), emptyMap());
-        a = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null, -1L);
-        b = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null, -1L);
+        a = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null);
+        b = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null);
     }
 
     private Kafka getResource() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -1435,7 +1435,7 @@ Future<ReconciliationState> withZkAncillaryCmChanged(boolean onlyMetricsSettingC
                 if (onlyMetricsSettingChanged) {
                     log.debug("Only metrics setting changed - not triggering rolling update");
                 }
-                if (rr != null && rr.resource() != null) {
+                if (rr != null && rr.resource() != null && rr.resource().getMetadata() != null) {
                     this.zkAncillaryCmGeneration = rr.resource().getMetadata().getGeneration() == null ? Long.valueOf(0L) : rr.resource().getMetadata().getGeneration();
                 } else {
                     this.zkAncillaryCmGeneration = 0L;
@@ -1469,7 +1469,7 @@ Future<ReconciliationState> withKafkaAncillaryCmChanged(boolean onlyMetricsSetti
                 if (onlyMetricsSettingChanged) {
                     log.debug("Only metrics setting changed - not triggering rolling update");
                 }
-                if (rr != null && rr.resource() != null) {
+                if (rr != null && rr.resource() != null && rr.resource().getMetadata() != null) {
                     this.kafkaAncillaryCmGeneration = rr.resource().getMetadata().getGeneration() == null ? Long.valueOf(0L) : rr.resource().getMetadata().getGeneration();
                 } else {
                     this.kafkaAncillaryCmGeneration = 0L;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -438,6 +438,7 @@ public StatefulSet generateStatefulSet(boolean isOpenShift, ImagePullPolicy imag
 
         return createStatefulSet(
                 Collections.singletonMap(ANNO_STRIMZI_IO_STORAGE, ModelUtils.encodeStorageToJson(storage)),
+                Collections.emptyMap(),
                 getVolumes(isOpenShift),
                 getVolumeClaims(),
                 getMergedAffinity(),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -146,7 +146,7 @@ private Map<String, List> upgrade(VertxTestContext context, Map<String, String>
         states.put("sts", new ArrayList<StatefulSet>(2));
         states.put("cm", new ArrayList<ConfigMap>(2));
 
-        StatefulSet kafkaSts = initialSs != null ? initialSs : kafkaCluster.generateStatefulSet(false, null, null);
+        StatefulSet kafkaSts = initialSs != null ? initialSs : kafkaCluster.generateStatefulSet(false, null, null, -1L);
 
         when(kso.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(kafkaSts));
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -40,8 +40,8 @@ public class KafkaSetOperatorTest {
     @BeforeEach
     public void before() {
         KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap(), emptyMap());
-        a = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null);
-        b = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null);
+        a = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null, -1L);
+        b = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null, -1L);
     }
 
     private Kafka getResource() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperatorTest.java
Patch:
@@ -375,6 +375,8 @@ public void testInternalReplace(VertxTestContext context)   {
         Resource mockResource = mock(resourceType());
         when(mockResource.get()).thenReturn(sts1);
         when(mockResource.cascading(eq(false))).thenReturn(mockERPD);
+        when(mockResource.create(any())).thenReturn(sts1);
+
 
         PodOperator podOperator = mock(PodOperator.class);
         when(podOperator.waitFor(anyString(), anyString(), anyLong(), anyLong(), any(BiPredicate.class))).thenReturn(Future.succeededFuture());

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractNonNamespacedResourceOperatorTest.java
Patch:
@@ -93,6 +93,7 @@ public void createWhenExistsIsAPatch(VertxTestContext context, boolean cascade)
         Resource mockResource = mock(resourceType());
         when(mockResource.get()).thenReturn(resource);
         when(mockResource.cascading(cascade)).thenReturn(mockResource);
+        when(mockResource.patch(any())).thenReturn(resource);
 
         NonNamespaceOperation mockNameable = mock(NonNamespaceOperation.class);
         when(mockNameable.withName(matches(resource.getMetadata().getName()))).thenReturn(mockResource);
@@ -154,6 +155,7 @@ public void successfulCreation(VertxTestContext context) {
         T resource = resource();
         Resource mockResource = mock(resourceType());
         when(mockResource.get()).thenReturn(null);
+        when(mockResource.create(any())).thenReturn(resource);
 
         NonNamespaceOperation mockNameable = mock(NonNamespaceOperation.class);
         when(mockNameable.withName(matches(resource.getMetadata().getName()))).thenReturn(mockResource);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractResourceOperatorTest.java
Patch:
@@ -90,6 +90,7 @@ public void createWhenExistsIsAPatch(VertxTestContext context, boolean cascade)
         Resource mockResource = mock(resourceType());
         when(mockResource.get()).thenReturn(resource);
         when(mockResource.cascading(cascade)).thenReturn(mockResource);
+        when(mockResource.patch(any())).thenReturn(resource);
 
         NonNamespaceOperation mockNameable = mock(NonNamespaceOperation.class);
         when(mockNameable.withName(matches(resource.getMetadata().getName()))).thenReturn(mockResource);
@@ -151,6 +152,7 @@ public void successfulCreation(VertxTestContext context) {
         T resource = resource();
         Resource mockResource = mock(resourceType());
         when(mockResource.get()).thenReturn(null);
+        when(mockResource.create(any())).thenReturn(resource);
 
         NonNamespaceOperation mockNameable = mock(NonNamespaceOperation.class);
         when(mockNameable.withName(matches(resource.getMetadata().getName()))).thenReturn(mockResource);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/PodDisruptionBudgetOperatorTest.java
Patch:
@@ -74,6 +74,7 @@ public void createWhenExistsIsAPatch(VertxTestContext context, boolean cascade)
         PodDisruptionBudget resource = resource();
         Resource mockResource = mock(resourceType());
         when(mockResource.get()).thenReturn(resource);
+        when(mockResource.create(any())).thenReturn(resource);
 
         Deletable mockDeletable = mock(Deletable.class);
         EditReplacePatchDeletable mockERPD = mock(EditReplacePatchDeletable.class);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilder.java
Patch:
@@ -72,7 +72,7 @@ public KafkaBrokerConfigurationBuilder withBrokerId()   {
     public KafkaBrokerConfigurationBuilder withRackId(Rack rack)   {
         if (rack != null) {
             printSectionHeader("Rack ID");
-            writer.println("rack.id=${STRIMZI_RACK_ID}");
+            writer.println("broker.rack=${STRIMZI_RACK_ID}");
             writer.println();
         }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -65,7 +65,7 @@ public void testRackId()  {
                 .withRackId(new Rack("failure-domain.kubernetes.io/zone"))
                 .build();
 
-        assertThat(configuration, isEquivalent("rack.id=${STRIMZI_RACK_ID}"));
+        assertThat(configuration, isEquivalent("broker.rack=${STRIMZI_RACK_ID}"));
     }
 
     @Test
@@ -76,7 +76,7 @@ public void testRackAndBrokerId()  {
                 .build();
 
         assertThat(configuration, isEquivalent("broker.id=${STRIMZI_BROKER_ID}\n" +
-                                                                "rack.id=${STRIMZI_RACK_ID}"));
+                                                                "broker.rack=${STRIMZI_RACK_ID}"));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -72,7 +72,7 @@ public abstract class BaseST implements TestSeparator {
     }
 
     protected KubeClusterResource cluster = KubeClusterResource.getInstance();
-    protected KafkaClient kafkaClient = (KafkaClient) ClientFactory.getClient(EClientType.BASIC);
+    protected KafkaClient externalBasicKafkaClient = (KafkaClient) ClientFactory.getClient(EClientType.BASIC);
     protected InternalKafkaClient internalKafkaClient = (InternalKafkaClient) ClientFactory.getClient(EClientType.INTERNAL);
 
     protected static final String CLUSTER_NAME = "my-cluster";
@@ -108,6 +108,7 @@ public abstract class BaseST implements TestSeparator {
 
     public static final int MESSAGE_COUNT = 100;
     public static final String TOPIC_NAME = "my-topic";
+    public static final String USER_NAME = "user-name-example";
 
     private HelmClient helmClient() {
         return cluster.helmClient().namespace(cluster.getNamespace());

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -73,7 +73,7 @@ class CustomResourceStatusST extends BaseST {
     void testKafkaStatus() throws Exception {
         LOGGER.info("Checking status of deployed kafka cluster");
         waitForKafkaStatus("Ready");
-        kafkaClient.sendAndRecvMessages(NAMESPACE, TOPIC_NAME);
+        externalBasicKafkaClient.sendAndRecvMessages(NAMESPACE, TOPIC_NAME);
         assertKafkaStatus(1, "my-cluster-kafka-bootstrap.status-cluster-test.svc");
 
         KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -68,7 +68,7 @@ void testRackAware() throws Exception {
         String uid = kubeClient().getPodUid(KafkaResources.kafkaPodName(CLUSTER_NAME, 0));
         List<Event> events = kubeClient().listEvents(uid);
         assertThat(events, hasAllOfReasons(Scheduled, Pulled, Created, Started));
-        kafkaClient.sendAndRecvMessages(NAMESPACE);
+        externalBasicKafkaClient.sendAndRecvMessages(NAMESPACE);
     }
 
 
@@ -106,7 +106,7 @@ void testLoadBalancerIpOverride() throws Exception {
         assertThat("Kafka External bootstrap doesn't contain correct loadBalancer address", kubeClient().getService(KafkaResources.externalBootstrapServiceName(CLUSTER_NAME)).getSpec().getLoadBalancerIP(), is(bootstrapOverrideIP));
         assertThat("Kafka Broker-0 service doesn't contain correct loadBalancer address", kubeClient().getService(KafkaResources.brokerSpecificService(CLUSTER_NAME, 0)).getSpec().getLoadBalancerIP(), is(brokerOverrideIP));
 
-        kafkaClient.sendAndRecvMessages(NAMESPACE);
+        externalBasicKafkaClient.sendAndRecvMessages(NAMESPACE);
     }
 
     @Test

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker2.java
Patch:
@@ -25,6 +25,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.api.kafka.Crds.STRIMZI_CATEGORY;
 import static java.util.Arrays.asList;
 import static java.util.Collections.singletonList;
 import static java.util.Collections.unmodifiableList;
@@ -36,7 +37,8 @@
                 names = @Crd.Spec.Names(
                         kind = KafkaMirrorMaker2.RESOURCE_KIND,
                         plural = KafkaMirrorMaker2.RESOURCE_PLURAL,
-                        shortNames = {KafkaMirrorMaker2.SHORT_NAME}
+                        shortNames = {KafkaMirrorMaker2.SHORT_NAME},
+                        categories = {STRIMZI_CATEGORY}
                 ),
                 group = KafkaMirrorMaker2.RESOURCE_GROUP,
                 scope = KafkaMirrorMaker2.SCOPE,

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -124,7 +124,6 @@ void testUserInDifferentNamespace() throws Exception {
         String startingNamespace = cluster.setNamespace(SECOND_NAMESPACE);
         KafkaUser user = KafkaUserResource.tlsUser(CLUSTER_NAME, USER_NAME).done();
 
-        SecretUtils.waitForSecretReady(USER_NAME);
         KafkaUserUtils.waitForKafkaUserCreation(USER_NAME);
         Condition kafkaCondition = KafkaUserResource.kafkaUserClient().inNamespace(SECOND_NAMESPACE).withName(USER_NAME)
                 .get().getStatus().getConditions().get(0);

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -482,7 +482,6 @@ void verifyLabelsOnCOPod() {
 
         Map<String, String> coLabels = kubeClient().listPods("name", "strimzi-cluster-operator").get(0).getMetadata().getLabels();
         assertThat(coLabels.get("name"), is("strimzi-cluster-operator"));
-        assertThat(coLabels.get("pod-template-hash").matches("\\d+"), is(true));
         assertThat(coLabels.get("strimzi.io/kind"), is("cluster-operator"));
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -126,8 +126,8 @@ void testUserInDifferentNamespace() throws Exception {
 
         SecretUtils.waitForSecretReady(USER_NAME);
         KafkaUserUtils.waitForKafkaUserCreation(USER_NAME);
-        Condition kafkaCondition = KafkaUserResource.kafkaUserClient().inNamespace(SECOND_NAMESPACE).withName(USER_NAME).get()
-                .getStatus().getConditions().get(0);
+        Condition kafkaCondition = KafkaUserResource.kafkaUserClient().inNamespace(SECOND_NAMESPACE).withName(USER_NAME)
+                .get().getStatus().getConditions().get(0);
         LOGGER.info("Kafka User condition status: {}", kafkaCondition.getStatus());
         LOGGER.info("Kafka User condition type: {}", kafkaCondition.getType());
 

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -72,8 +72,8 @@ public abstract class BaseST implements TestSeparator {
     }
 
     protected KubeClusterResource cluster = KubeClusterResource.getInstance();
-    protected KafkaClient kafkaClient = (KafkaClient) ClientFactory.getClient(EClientType.BASIC.getClientType());
-    protected InternalKafkaClient internalKafkaClient = (InternalKafkaClient) ClientFactory.getClient(EClientType.INTERNAL.getClientType());
+    protected KafkaClient kafkaClient = (KafkaClient) ClientFactory.getClient(EClientType.BASIC);
+    protected InternalKafkaClient internalKafkaClient = (InternalKafkaClient) ClientFactory.getClient(EClientType.INTERNAL);
 
     protected static final String CLUSTER_NAME = "my-cluster";
 

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -87,7 +87,7 @@ class SecurityST extends BaseST {
     public static final String STRIMZI_IO_FORCE_RENEW = "strimzi.io/force-renew";
     public static final String STRIMZI_IO_FORCE_REPLACE = "strimzi.io/force-replace";
 
-    private InternalKafkaClient internalKafkaClient = (InternalKafkaClient) ClientFactory.getClient(EClientType.INTERNAL.getClientType());
+    private InternalKafkaClient internalKafkaClient = (InternalKafkaClient) ClientFactory.getClient(EClientType.INTERNAL);
     private int messagesCount = 200;
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeBaseST.java
Patch:
@@ -42,7 +42,7 @@ public class HttpBridgeBaseST extends BaseST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeBaseST.class);
 
     protected WebClient client;
-    protected KafkaClient kafkaClient = (KafkaClient) ClientFactory.getClient(EClientType.BASIC.getClientType());
+    protected KafkaClient kafkaClient = (KafkaClient) ClientFactory.getClient(EClientType.BASIC);
 
     protected String bridgeExternalService = CLUSTER_NAME + "-bridge-external-service";
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -49,7 +49,7 @@ public class MetricsST extends BaseST {
 
     private static final Logger LOGGER = LogManager.getLogger(MetricsST.class);
 
-    protected InternalKafkaClient internalKafkaClient = (InternalKafkaClient) ClientFactory.getClient(EClientType.BASIC.getClientType());
+    protected InternalKafkaClient internalKafkaClient = (InternalKafkaClient) ClientFactory.getClient(EClientType.BASIC);
 
     public static final String NAMESPACE = "metrics-cluster-test";
     private final Object lock = new Object();

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -1210,7 +1210,7 @@ void testKafkaJBODDeleteClaimsFalse() {
         // kafka cluster already deployed
         verifyVolumeNamesAndLabels(kafkaReplicas, jbodStorage.getVolumes().size(), diskSizeGi);
         LOGGER.info("Deleting cluster");
-        cmdKubeClient().deleteByName("kafka", CLUSTER_NAME).waitForResourceDeletion("Kafka", CLUSTER_NAME);
+        cmdKubeClient().deleteByName("kafka", CLUSTER_NAME).waitForResourceDeletion("pod", KafkaResources.kafkaPodName(CLUSTER_NAME, 0));
         LOGGER.info("Waiting for Kafka pods deletion");
         PodUtils.waitForKafkaClusterPodsDeletion(CLUSTER_NAME);
         verifyPVCDeletion(kafkaReplicas, jbodStorage);

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -553,7 +553,6 @@ void testAutoRenewCaCertsTriggerByExpiredCertificate() throws Exception {
                 internalKafkaClient.sendMessages(topicName, NAMESPACE, CLUSTER_NAME, messagesCount),
                 internalKafkaClient.receiveMessages(topicName, NAMESPACE, CLUSTER_NAME, messagesCount, CONSUMER_GROUP_NAME)
         );
-
     }
 
     @SuppressWarnings("unchecked")
@@ -686,7 +685,6 @@ void testCertRenewalInMaintenanceWindow() throws Exception {
                 internalKafkaClient.sendMessages(topicName, NAMESPACE, CLUSTER_NAME, messagesCount),
                 internalKafkaClient.receiveMessages(topicName, NAMESPACE, CLUSTER_NAME, messagesCount, CONSUMER_GROUP_NAME)
         );
-
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.resources.KubernetesResource;
+import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
 import io.strimzi.systemtest.resources.crd.KafkaConnectS2IResource;
 import io.strimzi.systemtest.resources.crd.KafkaResource;
@@ -204,6 +205,8 @@ void setupEnvironment() {
     @Override
     protected void recreateTestEnv(String coNamespace, List<String> bindingsNamespaces) {
         teardownEnvForOperator();
+        ResourceManager.setClassResources();
         deployTestSpecificResources();
+        ResourceManager.setMethodResources();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -210,7 +210,7 @@ void testSecretsWithKafkaConnectS2IWithTlsAndScramShaAuthentication() throws Exc
         assertThat(kafkaConnectS2ILogs, not(containsString("ERROR")));
 
         LOGGER.info("Creating FileStreamSink connector via pod {} with topic {}", execPod, CONNECT_S2I_TOPIC_NAME);
-        KafkaConnectUtils.createFileSinkConnector(execPod, CONNECT_S2I_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
+        KafkaConnectUtils.createFileSinkConnector(execPod, CONNECT_S2I_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(kafkaConnectS2IName, NAMESPACE, 8083));
 
         kafkaClient.sendAndRecvMessagesScramSha(userName, NAMESPACE, CLUSTER_NAME, CONNECT_S2I_TOPIC_NAME, 2);
 

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -787,7 +787,7 @@ void testConnectS2IService() throws Exception {
         String execPodName = KafkaResources.kafkaPodName(CLUSTER_NAME, 0);
 
         LOGGER.info("Creating FileSink connect via Pod:{}", execPodName);
-        KafkaConnectUtils.createFileSinkConnector(execPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
+        KafkaConnectUtils.createFileSinkConnector(execPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(kafkaConnectS2IName, NAMESPACE, 8083));
 
         kafkaClient.sendAndRecvMessages(NAMESPACE, CLUSTER_NAME, TEST_TOPIC_NAME, 10);
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/EClientType.java
Patch:
@@ -7,7 +7,7 @@
 public enum EClientType {
 
     BASIC("BASIC"),
-    EXTERNAL("EXTERNAL"),
+    INTERNAL("INTERNAL"),
     TRACING("TRACING"),
     OAUTH("OAUTH");
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/ClientHandlerBase.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalclients;
+package io.strimzi.systemtest.kafkaclients.externalClients;
 
 import io.vertx.core.AbstractVerticle;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/Consumer.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalclients;
+package io.strimzi.systemtest.kafkaclients.externalClients;
 
 import io.vertx.kafka.client.consumer.KafkaConsumer;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClient.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalclients;
+package io.strimzi.systemtest.kafkaclients.externalClients;
 
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.kafkaclients.EClientType;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/KafkaClientProperties.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalclients;
+package io.strimzi.systemtest.kafkaclients.externalClients;
 
 import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.LoadBalancerIngress;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/OauthKafkaClient.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalclients;
+package io.strimzi.systemtest.kafkaclients.externalClients;
 
 import io.strimzi.systemtest.kafkaclients.IKafkaClient;
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/Producer.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalclients;
+package io.strimzi.systemtest.kafkaclients.externalClients;
 
 import io.vertx.kafka.client.producer.KafkaProducer;
 import io.vertx.kafka.client.producer.KafkaProducerRecord;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalClients/TracingKafkaClient.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.internalclients;
+package io.strimzi.systemtest.kafkaclients.externalClients;
 
 import io.strimzi.systemtest.kafkaclients.IKafkaClient;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/ClientArgument.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.externalclient;
+package io.strimzi.systemtest.kafkaclients.internalClients;
 
 /**
  * Enum with argument for external clients

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/ClientArgumentMap.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.externalclient;
+package io.strimzi.systemtest.kafkaclients.internalClients;
 
 import java.util.ArrayList;
 import java.util.HashMap;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/ClientType.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.externalclient;
+package io.strimzi.systemtest.kafkaclients.internalClients;
 
 public enum ClientType {
     CLI_KAFKA_VERIFIABLE_PRODUCER,

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalClients/VerifiableClient.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.externalclient;
+package io.strimzi.systemtest.kafkaclients.internalClients;
 
 import io.strimzi.test.executor.Exec;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -108,8 +108,8 @@ void deployKafkaConnectorWithSink(String clusterName, String namespace, String t
 
         KafkaClientsResource.deployKafkaClients(false, clusterName + "-" + Constants.KAFKA_CLIENTS).done();
         final String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(clusterName + "-" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();
-        externalKafkaClient.setPodName(kafkaClientsPodName);
-        int sent = externalKafkaClient.sendMessages(topicName, namespace, clusterName, 10);
+        internalKafkaClient.setPodName(kafkaClientsPodName);
+        int sent = internalKafkaClient.sendMessages(topicName, namespace, clusterName, 10);
         assertThat(sent, Matchers.is(10));
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, Constants.DEFAULT_SINK_FILE_NAME);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -14,8 +14,8 @@
 import io.strimzi.systemtest.interfaces.TestSeparator;
 import io.strimzi.systemtest.kafkaclients.ClientFactory;
 import io.strimzi.systemtest.kafkaclients.EClientType;
-import io.strimzi.systemtest.kafkaclients.externalclient.ExternalKafkaClient;
-import io.strimzi.systemtest.kafkaclients.internalclients.KafkaClient;
+import io.strimzi.systemtest.kafkaclients.internalClients.InternalKafkaClient;
+import io.strimzi.systemtest.kafkaclients.externalClients.KafkaClient;
 import io.strimzi.systemtest.logs.TestExecutionWatcher;
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
@@ -73,7 +73,7 @@ public abstract class BaseST implements TestSeparator {
 
     protected KubeClusterResource cluster = KubeClusterResource.getInstance();
     protected KafkaClient kafkaClient = (KafkaClient) ClientFactory.getClient(EClientType.BASIC.getClientType());
-    protected ExternalKafkaClient externalKafkaClient = (ExternalKafkaClient) ClientFactory.getClient(EClientType.EXTERNAL.getClientType());
+    protected InternalKafkaClient internalKafkaClient = (InternalKafkaClient) ClientFactory.getClient(EClientType.INTERNAL.getClientType());
 
     protected static final String CLUSTER_NAME = "my-cluster";
 

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -10,7 +10,6 @@
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.model.KafkaConnectResources;
 import io.strimzi.api.kafka.model.KafkaResources;
-import io.strimzi.systemtest.kafkaclients.internalclients.KafkaClient;
 import io.strimzi.systemtest.resources.KubernetesResource;
 import io.strimzi.systemtest.resources.ResourceManager;
 import io.strimzi.systemtest.resources.crd.KafkaConnectResource;
@@ -19,6 +18,7 @@
 import io.strimzi.systemtest.resources.crd.KafkaResource;
 import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 import io.strimzi.systemtest.resources.crd.KafkaUserResource;
+import io.strimzi.systemtest.kafkaclients.externalClients.KafkaClient;
 import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectS2IUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;

File: systemtest/src/test/java/io/strimzi/systemtest/TopicST.java
Patch:
@@ -226,9 +226,9 @@ void testDeleteTopicEnableFalse() throws Exception {
         LOGGER.info("Topic {} was created", topicName);
 
         String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();
-        externalKafkaClient.setPodName(kafkaClientsPodName);
+        internalKafkaClient.setPodName(kafkaClientsPodName);
 
-        int sent = externalKafkaClient.sendMessages(topicName, NAMESPACE, CLUSTER_NAME, 50);
+        int sent = internalKafkaClient.sendMessages(topicName, NAMESPACE, CLUSTER_NAME, 50);
 
         String topicUid = KafkaTopicUtils.topicSnapshot(topicName);
         LOGGER.info("Going to delete topic {}", topicName);
@@ -241,7 +241,7 @@ void testDeleteTopicEnableFalse() throws Exception {
         KafkaTopicUtils.waitForKafkaTopicCreation(topicName);
         LOGGER.info("Topic {} recreated", topicName);
 
-        int received = externalKafkaClient.receiveMessages(topicName, NAMESPACE, CLUSTER_NAME, 50, CONSUMER_GROUP_NAME);
+        int received = internalKafkaClient.receiveMessages(topicName, NAMESPACE, CLUSTER_NAME, 50, CONSUMER_GROUP_NAME);
         assertThat(received, is(sent));
 
     }

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeBaseST.java
Patch:
@@ -9,7 +9,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.kafkaclients.ClientFactory;
 import io.strimzi.systemtest.kafkaclients.EClientType;
-import io.strimzi.systemtest.kafkaclients.internalclients.KafkaClient;
+import io.strimzi.systemtest.kafkaclients.externalClients.KafkaClient;
 import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;
 import io.vertx.core.Vertx;
 import io.vertx.core.json.JsonArray;

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -55,7 +55,8 @@ public interface Constants {
 
     String KAFKA_CLIENTS = "kafka-clients";
     String STRIMZI_DEPLOYMENT_NAME = "strimzi-cluster-operator";
-    String IMAGE_PULL_POLICY = "Always";
+    String ALWAYS_IMAGE_PULL_POLICY = "Always";
+    String IF_NOT_PRESENT_IMAGE_PULL_POLICY = "IfNotPresent";
 
     int HTTP_KEYCLOAK_DEFAULT_PORT = 8080;
     int HTTPS_KEYCLOAK_DEFAULT_PORT = 8443;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -86,7 +86,7 @@ private static DeploymentBuilder defaultCLusterOperator(String namespace, long o
             }
         }
 
-        envVars.add(new EnvVar("STRIMZI_IMAGE_PULL_POLICY", Environment.IMAGE_PULL_POLICY, null));
+        envVars.add(new EnvVar("STRIMZI_IMAGE_PULL_POLICY", Environment.COMPONENTS_IMAGE_PULL_POLICY, null));
         // Apply updated env variables
         clusterOperator.getSpec().getTemplate().getSpec().getContainers().get(0).setEnv(envVars);
 
@@ -99,7 +99,7 @@ private static DeploymentBuilder defaultCLusterOperator(String namespace, long o
                     .editSpec()
                         .editFirstContainer()
                             .withImage(StUtils.changeOrgAndTag(coImage))
-                            .withImagePullPolicy(Constants.IMAGE_PULL_POLICY)
+                            .withImagePullPolicy(Environment.OPERATOR_IMAGE_PULL_POLICY)
                         .endContainer()
                     .endSpec()
                 .endTemplate()

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaClientsResource.java
Patch:
@@ -73,7 +73,7 @@ private static PodSpec createClientSpec(boolean tlsListener, String kafkaClients
             .withImage(Environment.TEST_CLIENT_IMAGE)
             .withCommand("sleep")
             .withArgs("infinity")
-            .withImagePullPolicy(Environment.IMAGE_PULL_POLICY);
+            .withImagePullPolicy(Environment.COMPONENTS_IMAGE_PULL_POLICY);
 
         String producerConfiguration = ProducerConfig.ACKS_CONFIG + "=all\n";
         String consumerConfiguration = ConsumerConfig.AUTO_OFFSET_RESET_CONFIG + "=earliest\n";

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -327,7 +327,7 @@ public void deployClusterOperatorViaHelmChart() {
         Map<String, String> values = Collections.unmodifiableMap(Stream.of(
             entry("imageRepositoryOverride", dockerOrg),
             entry("imageTagOverride", dockerTag),
-            entry("image.pullPolicy", Constants.IMAGE_PULL_POLICY),
+            entry("image.pullPolicy", Environment.OPERATOR_IMAGE_PULL_POLICY),
             entry("resources.requests.memory", REQUESTS_MEMORY),
             entry("resources.requests.cpu", REQUESTS_CPU),
             entry("resources.limits.memory", LIMITS_MEMORY),

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -204,12 +204,13 @@ void testSecretsWithKafkaConnectS2IWithTlsAndScramShaAuthentication() throws Exc
 
         String kafkaConnectS2IPodName = kubeClient().listPods("type", "kafka-connect-s2i").get(0).getMetadata().getName();
         String kafkaConnectS2ILogs = kubeClient().logs(kafkaConnectS2IPodName);
+        String execPod = KafkaResources.kafkaPodName(CLUSTER_NAME, 0);
 
         LOGGER.info("Verifying that in kafka connect logs are everything fine");
         assertThat(kafkaConnectS2ILogs, not(containsString("ERROR")));
 
-        LOGGER.info("Creating FileStreamSink connector in pod {} with topic {}", kafkaConnectS2IPodName, CONNECT_S2I_TOPIC_NAME);
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectS2IPodName, CONNECT_S2I_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
+        LOGGER.info("Creating FileStreamSink connector via pod {} with topic {}", execPod, CONNECT_S2I_TOPIC_NAME);
+        KafkaConnectUtils.createFileSinkConnector(execPod, CONNECT_S2I_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
 
         kafkaClient.sendAndRecvMessagesScramSha(userName, NAMESPACE, CLUSTER_NAME, CONNECT_S2I_TOPIC_NAME, 2);
 

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java
Patch:
@@ -136,10 +136,11 @@ void testProducerConsumerConnect() {
                 .done();
 
         String kafkaConnectPodName = kubeClient().listPods("type", "kafka-connect").get(0).getMetadata().getName();
+        String execPodName = KafkaResources.kafkaPodName(CLUSTER_NAME, 0);
 
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
+        KafkaConnectUtils.createFileSinkConnector(execPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
 
         String message = "Hello world - " + END_MESSAGE_OFFSET;
 

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -140,10 +140,11 @@ void testProducerConsumerConnect() {
                 .done();
 
         String kafkaConnectPodName = kubeClient().listPods("type", "kafka-connect").get(0).getMetadata().getName();
+        String execPodName = KafkaResources.kafkaPodName(CLUSTER_NAME, 0);
 
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
+        KafkaConnectUtils.createFileSinkConnector(execPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
 
         String message = "Hello world - " + END_MESSAGE_OFFSET;
 

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -784,9 +784,10 @@ void testConnectS2IService() throws Exception {
                 .done();
 
         String kafkaConnectS2IPodName = kubeClient().listPods("type", "kafka-connect-s2i").get(0).getMetadata().getName();
+        String execPodName = KafkaResources.kafkaPodName(CLUSTER_NAME, 0);
 
-        LOGGER.info("Creating FileSink connect in Pod:{}", kafkaConnectS2IPodName);
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectS2IPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
+        LOGGER.info("Creating FileSink connect via Pod:{}", execPodName);
+        KafkaConnectUtils.createFileSinkConnector(execPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
 
         kafkaClient.sendAndRecvMessages(NAMESPACE, CLUSTER_NAME, TEST_TOPIC_NAME, 10);
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaAuthorization.java
Patch:
@@ -22,6 +22,7 @@
         property = "type")
 @JsonSubTypes({
         @JsonSubTypes.Type(name = KafkaAuthorizationSimple.TYPE_SIMPLE, value = KafkaAuthorizationSimple.class),
+        @JsonSubTypes.Type(name = KafkaAuthorizationKeycloak.TYPE_KEYCLOAK, value = KafkaAuthorizationKeycloak.class)
 })
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @EqualsAndHashCode

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -648,7 +648,7 @@ protected void verifyCRStatusCondition(Condition condition, String message, Stri
         }
     }
 
-    void assertNoCoErrorsLogged(long sinceSeconds) {
+    protected void assertNoCoErrorsLogged(long sinceSeconds) {
         LOGGER.info("Search in strimzi-cluster-operator log for errors in last {} seconds", sinceSeconds);
         String clusterOperatorLog = cmdKubeClient().searchInLog("deploy", "strimzi-cluster-operator", sinceSeconds, "Exception", "Error", "Throwable");
         assertThat(clusterOperatorLog, logHasNoUnexpectedErrors());

File: systemtest/src/test/java/io/strimzi/systemtest/RecoveryST.java
Patch:
@@ -249,7 +249,7 @@ protected void recreateTestEnv(String coNamespace, List<String> bindingsNamespac
     }
 
     @Override
-    void assertNoCoErrorsLogged(long sinceSeconds) {
+    protected void assertNoCoErrorsLogged(long sinceSeconds) {
         LOGGER.info("No search in strimzi-cluster-operator log for errors");
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -106,7 +106,7 @@ void deployKafkaConnectorWithSink(String clusterName, String namespace, String t
         String kafkaConnectPodName = kubeClient().listPods("type", connectLabel).get(0).getMetadata().getName();
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        KafkaClientsResource.deployKafkaClients(false, clusterName + "-" + Constants.KAFKA_CLIENTS, clusterName, namespace).done();
+        KafkaClientsResource.deployKafkaClients(false, clusterName + "-" + Constants.KAFKA_CLIENTS).done();
         final String kafkaClientsPodName = kubeClient().listPodsByPrefixInName(clusterName + "-" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();
         externalKafkaClient.setPodName(kafkaClientsPodName);
         int sent = externalKafkaClient.sendMessages(topicName, namespace, clusterName, 10);

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -458,7 +458,7 @@ void assertThatRollingUpdatedFinished(String rolledComponent, String stableCompo
     }
 
     void deployTestSpecificResources() {
-        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, CLUSTER_NAME, NAMESPACE).done();
+        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).done();
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/StrimziUpgradeST.java
Patch:
@@ -424,7 +424,7 @@ void logPodImages() {
 
     void deployClients(String image, KafkaUser kafkaUser) {
         // Deploy new clients
-        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, CLUSTER_NAME, NAMESPACE, kafkaUser)
+        KafkaClientsResource.deployKafkaClients(true, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, kafkaUser)
             .editSpec()
                 .editTemplate()
                     .editSpec()

File: systemtest/src/test/java/io/strimzi/systemtest/TopicST.java
Patch:
@@ -218,7 +218,7 @@ void testDeleteTopicEnableFalse() throws Exception {
             .endSpec()
             .done();
 
-        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, CLUSTER_NAME, NAMESPACE).done();
+        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).done();
 
         KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -125,7 +125,7 @@ void testKafkaConnectIoNetwork() {
 
     @Test
     void testKafkaExporterDataAfterExchange() throws InterruptedException {
-        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, CLUSTER_NAME, NAMESPACE).done();
+        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).done();
 
         final String defaultKafkaClientsPodName =
             ResourceManager.kubeClient().listPodsByPrefixInName("my-cluster" + "-" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();

File: api/src/test/java/io/strimzi/api/kafka/model/AbstractCrdTest.java
Patch:
@@ -35,7 +35,7 @@ protected void assertDesiredResource(R k, String resource) throws IOException {
         String content = TestUtils.readResource(getClass(), resource);
         if (content != null) {
             String ssStr = TestUtils.toYamlString(k);
-            assertThat(content.trim(), is(ssStr.trim()));
+            assertThat(ssStr.trim(), is(content.trim()));
         } else {
             fail("The resource " + resource + " does not exist");
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -25,7 +25,6 @@
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
-import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.operator.resource.CrdOperator;
 import io.strimzi.operator.common.operator.resource.DeploymentOperator;
@@ -50,7 +49,6 @@
 public class KafkaConnectAssemblyOperator extends AbstractConnectOperator<KubernetesClient, KafkaConnect, KafkaConnectList, DoneableKafkaConnect, Resource<KafkaConnect, DoneableKafkaConnect>, KafkaConnectStatus> {
 
     private static final Logger log = LogManager.getLogger(KafkaConnectAssemblyOperator.class.getName());
-    public static final String ANNO_STRIMZI_IO_LOGGING = Annotations.STRIMZI_DOMAIN + "/logging";
     private final DeploymentOperator deploymentOperations;
     private final KafkaVersion.Lookup versions;
     private final CrdOperator<OpenShiftClient, KafkaConnectS2I, KafkaConnectS2IList, DoneableKafkaConnectS2I> connectS2IOperations;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
Patch:
@@ -34,6 +34,7 @@ public class ClusterOperatorConfigTest {
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_S2I_IMAGES, KafkaVersionTestUtils.getKafkaConnectS2iImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
+        envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
     }
 
     @Test
@@ -53,7 +54,7 @@ public void testDefaultConfig() {
     @Test
     public void testReconciliationInterval() {
 
-        ClusterOperatorConfig config = new ClusterOperatorConfig(singleton("namespace"), 60_000, 30_000, false, new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap()), null, null);
+        ClusterOperatorConfig config = new ClusterOperatorConfig(singleton("namespace"), 60_000, 30_000, false, new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap(), emptyMap()), null, null);
 
         assertThat(config.getNamespaces(), is(singleton("namespace")));
         assertThat(config.getReconciliationIntervalMs(), is(60_000L));
@@ -89,6 +90,7 @@ private Map<String, String> envWithImages() {
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_S2I_IMAGES, KafkaVersionTestUtils.getKafkaConnectS2iImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
+        envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
         return envVars;
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
Patch:
@@ -64,6 +64,7 @@ private static Map<String, String> buildEnv(String namespaces) {
         env.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
         env.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_S2I_IMAGES, KafkaVersionTestUtils.getKafkaConnectS2iImagesEnvVarString());
         env.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
+        env.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
         return env;
     }
 
@@ -190,7 +191,7 @@ private void startStop(VertxTestContext context, String namespaces, boolean open
         }
 
 
-        if (numWatchers.get() > (openShift ? 7 : 5) * namespaceList.size()) { // we do not have connectS2I on k8s
+        if (numWatchers.get() > (openShift ? 8 : 6) * namespaceList.size()) { // we do not have connectS2I on k8s
             context.failNow(new Throwable("Looks like there were more watchers than namespaces"));
         }
         context.completeNow();
@@ -270,7 +271,7 @@ private void startStopAllNamespaces(VertxTestContext context, String namespaces,
             }
         }
 
-        if (numWatchers.get() > (openShift ? 7 : 5)) { // we do not have connectS2I on k8s
+        if (numWatchers.get() > (openShift ? 8 : 6)) { // we do not have connectS2I on k8s
             context.failNow(new Throwable("Looks like there were more watchers than should be"));
         }
         context.completeNow();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/MainIT.java
Patch:
@@ -56,6 +56,7 @@ public void testCreateClusterRoles(VertxTestContext context) {
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_S2I_IMAGES, KafkaVersionTestUtils.getKafkaConnectS2iImagesEnvVarString());
         envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMakerImagesEnvVarString());
+        envVars.put(ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString());
 
         ClusterOperatorConfig config = ClusterOperatorConfig.fromMap(envVars, KafkaVersionTestUtils.getKafkaVersionLookup());
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConfigurationTests.java
Patch:
@@ -84,7 +84,7 @@ public void passwordType() {
     @Test
     public void invalidVersion() {
         assertConfigError("inter.broker.protocol.version", "dclncswn",
-                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E");
+                "inter.broker.protocol.version has value 'dclncswn' which does not match the required pattern: \\Q0.8.0\\E(\\.[0-9]+)*|\\Q0.8.0\\E|\\Q0.8.1\\E(\\.[0-9]+)*|\\Q0.8.1\\E|\\Q0.8.2\\E(\\.[0-9]+)*|\\Q0.8.2\\E|\\Q0.9.0\\E(\\.[0-9]+)*|\\Q0.9.0\\E|\\Q0.10.0\\E(\\.[0-9]+)*|\\Q0.10.0-IV0\\E|\\Q0.10.0-IV1\\E|\\Q0.10.1\\E(\\.[0-9]+)*|\\Q0.10.1-IV0\\E|\\Q0.10.1-IV1\\E|\\Q0.10.1-IV2\\E|\\Q0.10.2\\E(\\.[0-9]+)*|\\Q0.10.2-IV0\\E|\\Q0.11.0\\E(\\.[0-9]+)*|\\Q0.11.0-IV0\\E|\\Q0.11.0-IV1\\E|\\Q0.11.0-IV2\\E|\\Q1.0\\E(\\.[0-9]+)*|\\Q1.0-IV0\\E|\\Q1.1\\E(\\.[0-9]+)*|\\Q1.1-IV0\\E|\\Q2.0\\E(\\.[0-9]+)*|\\Q2.0-IV0\\E|\\Q2.0-IV1\\E|\\Q2.1\\E(\\.[0-9]+)*|\\Q2.1-IV0\\E|\\Q2.1-IV1\\E|\\Q2.1-IV2\\E|\\Q2.2\\E(\\.[0-9]+)*|\\Q2.2-IV0\\E|\\Q2.2-IV1\\E|\\Q2.3\\E(\\.[0-9]+)*|\\Q2.3-IV0\\E|\\Q2.3-IV1\\E|\\Q2.4\\E(\\.[0-9]+)*|\\Q2.4-IV0\\E|\\Q2.4-IV1\\E");
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ResourceTester.java
Patch:
@@ -43,7 +43,7 @@ class ResourceTester<R extends HasMetadata, M extends AbstractModel> {
     }
 
     ResourceTester(Class<R> cls, Function<R, M> fromK8sResource, String prefix) {
-        this.lookup = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
+        this.lookup = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap(), emptyMap());
         this.cls = cls;
         this.fromK8sResource = (x, y) -> fromK8sResource.apply(x);
         this.prefix = prefix;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/TopicOperatorTest.java
Patch:
@@ -47,6 +47,7 @@ public class TopicOperatorTest {
             KafkaVersionTestUtils.getKafkaImageMap(),
             emptyMap(),
             emptyMap(),
+            emptyMap(),
             emptyMap()) { };
 
     private final String namespace = "test";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -75,6 +75,7 @@ public class ZookeeperClusterTest {
             KafkaVersionTestUtils.getKafkaImageMap(),
             emptyMap(),
             emptyMap(),
+            emptyMap(),
             emptyMap()) { };
     private final String namespace = "test";
     private final String cluster = "foo";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/ConnectorMockTest.java
Patch:
@@ -177,6 +177,7 @@ public void setup(VertxTestContext testContext) throws InterruptedException {
             ClusterOperatorConfig.STRIMZI_KAFKA_IMAGES, KafkaVersionTestUtils.getKafkaImagesEnvVarString(),
             ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_IMAGES, KafkaVersionTestUtils.getKafkaConnectImagesEnvVarString(),
             ClusterOperatorConfig.STRIMZI_KAFKA_CONNECT_S2I_IMAGES, KafkaVersionTestUtils.getKafkaConnectS2iImagesEnvVarString(),
+            ClusterOperatorConfig.STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES, KafkaVersionTestUtils.getKafkaMirrorMaker2ImagesEnvVarString(),
             ClusterOperatorConfig.STRIMZI_FULL_RECONCILIATION_INTERVAL_MS, Long.toString(Long.MAX_VALUE)),
                 KafkaVersionTestUtils.getKafkaVersionLookup());
         kafkaConnectOperator = new KafkaConnectAssemblyOperator(vertx,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -63,6 +63,7 @@ public class JbodStorageTest {
             KafkaVersionTestUtils.getKafkaImageMap(),
             emptyMap(),
             emptyMap(),
+            emptyMap(), 
             emptyMap()) { };
 
     private Vertx vertx;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -39,7 +39,7 @@ public class KafkaSetOperatorTest {
 
     @BeforeEach
     public void before() {
-        KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
+        KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap(), emptyMap());
         a = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null);
         b = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null);
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperatorTest.java
Patch:
@@ -30,7 +30,7 @@ public class ZookeeperSetOperatorTest {
 
     @BeforeEach
     public void before() {
-        KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
+        KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap(), emptyMap());
         a = ZookeeperCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null);
         b = ZookeeperCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null, null);
     }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -22,6 +22,7 @@
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaConnector;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
+import io.strimzi.api.kafka.model.KafkaMirrorMaker2;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.vertx.core.Future;
@@ -79,6 +80,8 @@ public CrdOperator(Vertx vertx, C client, Class<T> cls, Class<L> listCls, Class<
             this.plural = KafkaTopic.RESOURCE_PLURAL;
         } else if (cls.equals(KafkaConnector.class)) {
             this.plural = KafkaConnector.RESOURCE_PLURAL;
+        } else if (cls.equals(KafkaMirrorMaker2.class)) {
+            this.plural = KafkaMirrorMaker2.RESOURCE_PLURAL;
         } else {
             this.plural = null;
         }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaClientsResource.java
Patch:
@@ -154,8 +154,9 @@ private static PodSpec createClientSpec(boolean tlsListener, String kafkaClients
                             .endVolume();
                 }
 
-                if (tlsListener) {
-                    String clusterCaSecretName = KafkaResource.getKafkaTlsListenerCaCertName(kafkaClusterNamespace, kafkaClusterName);
+                if (tlsListener) {                    
+                    String clusterName = kafkaClusterName != null ? kafkaClusterName : kafkaUser.getMetadata().getClusterName();
+                    String clusterCaSecretName = KafkaResource.getKafkaTlsListenerCaCertName(kafkaClusterNamespace, clusterName);
                     String clusterCaSecretVolumeName = "ca-cert-" + kafkaUserName;
                     String caSecretMountPoint = "/opt/kafka/cluster-ca-" + kafkaUserName;
 

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -75,6 +75,8 @@ public final class TestUtils {
 
     public static final String CRD_KAFKA_BRIDGE = "../install/cluster-operator/046-Crd-kafkabridge.yaml";
 
+    public static final String CRD_KAFKA_MIRROR_MAKER_2 = "../install/cluster-operator/048-Crd-kafkamirrormaker2.yaml";
+
     private TestUtils() {
         // All static methods
     }

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.fabric8.kubernetes.api.model.Service;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
+import io.strimzi.api.kafka.model.KafkaConnectResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
@@ -135,7 +136,7 @@ void testProducerConsumerConnect() {
 
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME);
+        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
 
         String message = "Hello world - " + END_MESSAGE_OFFSET;
 

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.fabric8.kubernetes.api.model.Service;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
+import io.strimzi.api.kafka.model.KafkaConnectResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
@@ -142,7 +143,7 @@ void testProducerConsumerConnect() {
 
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME);
+        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
 
         String message = "Hello world - " + END_MESSAGE_OFFSET;
 

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -10,6 +10,7 @@
 import io.restassured.http.ContentType;
 import io.restassured.path.json.JsonPath;
 import io.restassured.response.Response;
+import io.strimzi.api.kafka.model.KafkaConnectResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.BaseST;
 import io.strimzi.systemtest.Constants;
@@ -791,7 +792,7 @@ void testConnectS2IService() throws Exception {
         String kafkaConnectS2IPodName = kubeClient().listPods("type", "kafka-connect-s2i").get(0).getMetadata().getName();
 
         LOGGER.info("Creating FileSink connect in Pod:{}", kafkaConnectS2IPodName);
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectS2IPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME);
+        KafkaConnectUtils.createFileSinkConnector(kafkaConnectS2IPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME, KafkaConnectResources.url(CLUSTER_NAME, NAMESPACE, 8083));
 
         kafkaClient.sendAndRecvMessages(NAMESPACE, CLUSTER_NAME, TEST_TOPIC_NAME, 10);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/JmxTrans.java
Patch:
@@ -205,8 +205,8 @@ public List<Volume> getVolumes() {
     private List<VolumeMount> getVolumeMounts() {
         List<VolumeMount> volumeMountList = new ArrayList<>();
 
-        volumeMountList.add(createVolumeMount(logAndMetricsConfigVolumeName, logAndMetricsConfigMountPath));
-        volumeMountList.add(createVolumeMount(JMXTRANS_VOLUME_NAME, JMX_FILE_PATH));
+        volumeMountList.add(VolumeUtils.createVolumeMount(logAndMetricsConfigVolumeName, logAndMetricsConfigMountPath));
+        volumeMountList.add(VolumeUtils.createVolumeMount(JMXTRANS_VOLUME_NAME, JMX_FILE_PATH));
         return volumeMountList;
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaJmxOptions.java
Patch:
@@ -47,4 +47,3 @@ public void setAdditionalProperty(String name, Object value) {
         this.additionalProperties.put(name, value);
     }
 }
-

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaJmxOptionsTest.java
Patch:
@@ -35,4 +35,4 @@ public void testNoJmxOpts() {
         assertThat(opts.getAuthentication(),  is(nullValue()));
         assertThat(opts.getAdditionalProperties(),  is(Collections.emptyMap()));
     }
-}
+}
\ No newline at end of file

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -19,16 +19,17 @@
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.KafkaList;
 import io.strimzi.api.kafka.model.DoneableKafka;
-import io.strimzi.api.kafka.model.storage.EphemeralStorage;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
+import io.strimzi.api.kafka.model.storage.EphemeralStorage;
 import io.strimzi.api.kafka.model.storage.PersistentClaimStorage;
 import io.strimzi.api.kafka.model.storage.PersistentClaimStorageBuilder;
 import io.strimzi.api.kafka.model.storage.SingleVolumeStorage;
 import io.strimzi.api.kafka.model.storage.Storage;
+import io.strimzi.operator.KubernetesVersion;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ClusterOperator;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
@@ -37,7 +38,6 @@
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.model.TopicOperator;
 import io.strimzi.operator.cluster.model.ZookeeperCluster;
-import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.cluster.operator.resource.StatefulSetOperator;
 import io.strimzi.operator.cluster.operator.resource.ZookeeperLeaderFinder;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -270,9 +270,9 @@ public List<Volume> getVolumes() {
     }
 
     private List<VolumeMount> getVolumeMounts() {
-        return asList(createVolumeMount(logAndMetricsConfigVolumeName, logAndMetricsConfigMountPath),
-            createVolumeMount(EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT),
-            createVolumeMount(EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT));
+        return asList(VolumeUtils.createVolumeMount(logAndMetricsConfigVolumeName, logAndMetricsConfigMountPath),
+            VolumeUtils.createVolumeMount(EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT),
+            VolumeUtils.createVolumeMount(EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT));
     }
 
     public RoleBinding generateRoleBinding(String namespace, String watchedNamespace) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -268,7 +268,7 @@ public List<Volume> getVolumes() {
     }
 
     private List<VolumeMount> getVolumeMounts() {
-        return singletonList(createVolumeMount(logAndMetricsConfigVolumeName, logAndMetricsConfigMountPath));
+        return singletonList(VolumeUtils.createVolumeMount(logAndMetricsConfigVolumeName, logAndMetricsConfigMountPath));
     }
 
     public RoleBinding generateRoleBinding(String namespace, String watchedNamespace) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -270,7 +270,7 @@ protected List<Volume> getVolumes(boolean isOpenShift) {
                 for (CertSecretSource certSecretSource : trustedCertificates) {
                     // skipping if a volume with same Secret name was already added
                     if (!volumeList.stream().anyMatch(v -> v.getName().equals(certSecretSource.getSecretName()))) {
-                        volumeList.add(createSecretVolume(certSecretSource.getSecretName(), certSecretSource.getSecretName(), isOpenShift));
+                        volumeList.add(VolumeUtils.createSecretVolume(certSecretSource.getSecretName(), certSecretSource.getSecretName(), isOpenShift));
                     }
                 }
             }
@@ -283,7 +283,7 @@ protected List<Volume> getVolumes(boolean isOpenShift) {
 
     protected List<VolumeMount> getVolumeMounts() {
         List<VolumeMount> volumeMountList = new ArrayList<>(1);
-        volumeMountList.add(createVolumeMount(logAndMetricsConfigVolumeName, logAndMetricsConfigMountPath));
+        volumeMountList.add(VolumeUtils.createVolumeMount(logAndMetricsConfigVolumeName, logAndMetricsConfigMountPath));
 
         if (tls != null) {
             List<CertSecretSource> trustedCertificates = tls.getTrustedCertificates();
@@ -292,7 +292,7 @@ protected List<VolumeMount> getVolumeMounts() {
                 for (CertSecretSource certSecretSource : trustedCertificates) {
                     // skipping if a volume mount with same Secret name was already added
                     if (!volumeMountList.stream().anyMatch(vm -> vm.getName().equals(certSecretSource.getSecretName()))) {
-                        volumeMountList.add(createVolumeMount(certSecretSource.getSecretName(),
+                        volumeMountList.add(VolumeUtils.createVolumeMount(certSecretSource.getSecretName(),
                                 TLS_CERTS_BASE_VOLUME_MOUNT + certSecretSource.getSecretName()));
                     }
                 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -276,7 +276,7 @@ protected List<Volume> getVolumes(boolean isOpenShift) {
                 for (CertSecretSource certSecretSource : trustedCertificates) {
                     // skipping if a volume with same Secret name was already added
                     if (!volumeList.stream().anyMatch(v -> v.getName().equals(certSecretSource.getSecretName()))) {
-                        volumeList.add(createSecretVolume(certSecretSource.getSecretName(), certSecretSource.getSecretName(), isOpenShift));
+                        volumeList.add(VolumeUtils.createSecretVolume(certSecretSource.getSecretName(), certSecretSource.getSecretName(), isOpenShift));
                     }
                 }
             }
@@ -334,7 +334,7 @@ private List<Volume> getExternalConfigurationVolumes(boolean isOpenShift)  {
 
     protected List<VolumeMount> getVolumeMounts() {
         List<VolumeMount> volumeMountList = new ArrayList<>(1);
-        volumeMountList.add(createVolumeMount(logAndMetricsConfigVolumeName, logAndMetricsConfigMountPath));
+        volumeMountList.add(VolumeUtils.createVolumeMount(logAndMetricsConfigVolumeName, logAndMetricsConfigMountPath));
 
         if (tls != null) {
             List<CertSecretSource> trustedCertificates = tls.getTrustedCertificates();
@@ -343,7 +343,7 @@ protected List<VolumeMount> getVolumeMounts() {
                 for (CertSecretSource certSecretSource : trustedCertificates) {
                     // skipping if a volume mount with same Secret name was already added
                     if (!volumeMountList.stream().anyMatch(vm -> vm.getName().equals(certSecretSource.getSecretName()))) {
-                        volumeMountList.add(createVolumeMount(certSecretSource.getSecretName(),
+                        volumeMountList.add(VolumeUtils.createVolumeMount(certSecretSource.getSecretName(),
                                 TLS_CERTS_BASE_VOLUME_MOUNT + certSecretSource.getSecretName()));
                     }
                 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBrokerConfigurationBuilderTest.java
Patch:
@@ -171,7 +171,7 @@ public void testEphemeralStorageLogDirs()  {
                 .build();
 
         String configuration = new KafkaBrokerConfigurationBuilder()
-                .withLogDirs(ModelUtils.getDataVolumeMountPaths(storage, "/var/lib/kafka"))
+                .withLogDirs(VolumeUtils.getDataVolumeMountPaths(storage, "/var/lib/kafka"))
                 .build();
 
         assertThat(configuration, isEquivalent("log.dirs=/var/lib/kafka/data/kafka-log${STRIMZI_BROKER_ID}"));
@@ -186,7 +186,7 @@ public void testPersistentStorageLogDirs()  {
                 .build();
 
         String configuration = new KafkaBrokerConfigurationBuilder()
-                .withLogDirs(ModelUtils.getDataVolumeMountPaths(storage, "/var/lib/kafka"))
+                .withLogDirs(VolumeUtils.getDataVolumeMountPaths(storage, "/var/lib/kafka"))
                 .build();
 
         assertThat(configuration, isEquivalent("log.dirs=/var/lib/kafka/data/kafka-log${STRIMZI_BROKER_ID}"));
@@ -218,7 +218,7 @@ public void testJbodStorageLogDirs()  {
                 .build();
 
         String configuration = new KafkaBrokerConfigurationBuilder()
-                .withLogDirs(ModelUtils.getDataVolumeMountPaths(storage, "/var/lib/kafka"))
+                .withLogDirs(VolumeUtils.getDataVolumeMountPaths(storage, "/var/lib/kafka"))
                 .build();
 
         assertThat(configuration, isEquivalent("log.dirs=/var/lib/kafka/data-1/kafka-log${STRIMZI_BROKER_ID},/var/lib/kafka/data-2/kafka-log${STRIMZI_BROKER_ID},/var/lib/kafka/data-5/kafka-log${STRIMZI_BROKER_ID}"));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -22,8 +22,8 @@
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.model.ModelUtils;
 import io.strimzi.operator.KubernetesVersion;
+import io.strimzi.operator.cluster.model.VolumeUtils;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.PasswordGenerator;
@@ -143,7 +143,7 @@ public void testCreatePersistentVolumeClaims(VertxTestContext context) {
                 for (SingleVolumeStorage volume : this.volumes) {
                     if (volume instanceof PersistentClaimStorage) {
                         context.verify(() -> assertThat(pvcs.stream().anyMatch(pvc -> {
-                            String pvcName = ModelUtils.getVolumePrefix(volume.getId()) + "-"
+                            String pvcName = VolumeUtils.getVolumePrefix(volume.getId()) + "-"
                                     + KafkaCluster.kafkaPodName(NAME, podId);
                             boolean isDeleteClaim = ((PersistentClaimStorage) volume).isDeleteClaim();
 

File: systemtest/src/main/java/io/strimzi/systemtest/cli/KafkaCmdClient.java
Patch:
@@ -41,7 +41,7 @@ public static List<String> describeTopicUsingPodCli(String clusterName, int zkPo
         String podName = KafkaResources.zookeeperPodName(clusterName, zkPodId);
         int port = 2181 * 10 + zkPodId;
         return Arrays.asList(cmdKubeClient().execInPod(podName, "/bin/bash", "-c",
-            "bin/kafka-topics.sh --zookeeper localhost:" + port + " --describe --topic " + topic).out().split("\\s+"));
+            "bin/kafka-topics.sh --zookeeper localhost:" + port + " --describe --topic " + topic).out().replace(": ", ":").split("\\s+"));
     }
 
     public static String updateTopicPartitionsCountUsingPodCli(String clusterName, int zkPodId, String topic, int partitions) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorCustomCertTest.java
Patch:
@@ -422,8 +422,8 @@ public MockKafkaAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability pfa,
         Future<Void> reconcile(ReconciliationState reconcileState)  {
             return reconcileState.reconcileCas(this::dateSupplier)
                     .compose(state -> state.getKafkaClusterDescription())
-                    .compose(state -> state.getCustomTlsListenerThumbprint())
-                    .compose(state -> state.getCustomExternalListenerThumbprint())
+                    .compose(state -> state.customTlsListenerCertificate())
+                    .compose(state -> state.customExternalListenerCertificate())
                     .compose(state -> state.kafkaStatefulSet())
                     .compose(state -> state.kafkaRollingUpdate())
                     .map((Void) null);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaStatusTest.java
Patch:
@@ -1041,5 +1041,6 @@ Future<Void> reconcile(ReconciliationState reconcileState)  {
                     .compose(state -> state.kafkaNodePortExternalListenerStatus())
                     .map((Void) null);
         }
+
     }
 }

File: api/src/main/java/io/strimzi/api/kafka/model/status/KafkaConnectS2IStatus.java
Patch:
@@ -23,7 +23,7 @@
 @JsonPropertyOrder({ "conditions", "observedGeneration", "url", "connectorPlugins", "buildConfigName" })
 @EqualsAndHashCode(callSuper = true)
 @ToString(callSuper = true)
-public class KafkaConnectS2Istatus extends KafkaConnectStatus {
+public class KafkaConnectS2IStatus extends KafkaConnectStatus {
     private static final long serialVersionUID = 1L;
 
     private String buildConfigName;

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -13,7 +13,7 @@
 import io.strimzi.api.kafka.model.KafkaConnectS2IResources;
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.connect.ConnectorPlugin;
-import io.strimzi.api.kafka.model.status.KafkaConnectS2Istatus;
+import io.strimzi.api.kafka.model.status.KafkaConnectS2IStatus;
 import io.strimzi.systemtest.annotations.OpenShiftOnly;
 import io.strimzi.systemtest.resources.crd.KafkaConnectorResource;
 import io.strimzi.systemtest.utils.FileUtils;
@@ -362,8 +362,8 @@ private String deployConnectS2IWithMongoDb(String kafkaConnectS2IName) {
     }
 
     private void checkConnectorInStatus(String namespace, String kafkaConnectS2IName) {
-        KafkaConnectS2Istatus kafkaConnectS2Istatus = KafkaConnectS2IResource.kafkaConnectS2IClient().inNamespace(namespace).withName(kafkaConnectS2IName).get().getStatus();
-        List<ConnectorPlugin> pluginsList = kafkaConnectS2Istatus.getConnectorPlugins();
+        KafkaConnectS2IStatus kafkaConnectS2IStatus = KafkaConnectS2IResource.kafkaConnectS2IClient().inNamespace(namespace).withName(kafkaConnectS2IName).get().getStatus();
+        List<ConnectorPlugin> pluginsList = kafkaConnectS2IStatus.getConnectorPlugins();
         assertThat(pluginsList, notNullValue());
         List<String> pluginsClasses = pluginsList.stream().map(p -> p.getConnectorClass()).collect(Collectors.toList());
         assertThat(pluginsClasses, hasItems("org.apache.kafka.connect.file.FileStreamSinkConnector",

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -18,7 +18,7 @@
 import io.strimzi.api.kafka.model.connect.ConnectorPlugin;
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.api.kafka.model.status.KafkaBridgeStatus;
-import io.strimzi.api.kafka.model.status.KafkaConnectS2Istatus;
+import io.strimzi.api.kafka.model.status.KafkaConnectS2IStatus;
 import io.strimzi.api.kafka.model.status.KafkaConnectStatus;
 import io.strimzi.api.kafka.model.status.KafkaConnectorStatus;
 import io.strimzi.api.kafka.model.status.KafkaMirrorMakerStatus;
@@ -438,7 +438,7 @@ void assertKafkaConnectStatus(long expectedObservedGeneration, String expectedUr
     }
 
     void assertKafkaConnectS2IStatus(long expectedObservedGeneration, String expectedUrl, String expectedConfigName) {
-        KafkaConnectS2Istatus kafkaConnectS2IStatus = KafkaConnectS2IResource.kafkaConnectS2IClient().inNamespace(NAMESPACE).withName(CONNECTS2I_CLUSTER_NAME).get().getStatus();
+        KafkaConnectS2IStatus kafkaConnectS2IStatus = KafkaConnectS2IResource.kafkaConnectS2IClient().inNamespace(NAMESPACE).withName(CONNECTS2I_CLUSTER_NAME).get().getStatus();
         assertThat("Kafka ConnectS2I cluster status has incorrect Observed Generation", kafkaConnectS2IStatus.getObservedGeneration(), is(expectedObservedGeneration));
         assertThat("Kafka ConnectS2I cluster status has incorrect URL", kafkaConnectS2IStatus.getUrl(), is(expectedUrl));
         assertThat("Kafka ConnectS2I cluster status has incorrect BuildConfigName", kafkaConnectS2IStatus.getBuildConfigName(), is(expectedConfigName));

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -76,6 +76,8 @@ public interface Constants {
      */
     String KAFKA_BRIDGE_JSON = "application/vnd.kafka.v2+json";
 
+    String DEFAULT_SINK_FILE_NAME = "/tmp/test-file-sink.txt";
+
     int HTTP_BRIDGE_DEFAULT_PORT = 8080;
     int HTTP_JAEGER_DEFAULT_TCP_PORT = 5778;
     int HTTP_JAEGER_DEFAULT_NODE_PORT = 32480;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -63,6 +63,7 @@ private static KafkaConnectBuilder defaultKafkaConnect(KafkaConnect kafkaConnect
                 .withName(name)
                 .withNamespace(ResourceManager.kubeClient().getNamespace())
                 .withClusterName(kafkaClusterName)
+                .addToLabels("type", "kafka-connect")
             .endMetadata()
             .editOrNewSpec()
                 .withVersion(Environment.ST_KAFKA_VERSION)

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -49,6 +49,7 @@ public static KafkaConnectS2IBuilder defaultKafkaConnectS2I(KafkaConnectS2I kafk
                 .withName(name)
                 .withNamespace(ResourceManager.kubeClient().getNamespace())
                 .withClusterName(kafkaClusterName)
+                .addToLabels("type", "kafka-connect-s2i")
             .endMetadata()
             .editSpec()
                 .withVersion(Environment.ST_KAFKA_VERSION)

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -206,13 +206,13 @@ void testSecretsWithKafkaConnectS2IWithTlsAndScramShaAuthentication() throws Exc
         assertThat(kafkaConnectS2ILogs, not(containsString("ERROR")));
 
         LOGGER.info("Creating FileStreamSink connector in pod {} with topic {}", kafkaConnectS2IPodName, CONNECT_S2I_TOPIC_NAME);
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectS2IPodName, CONNECT_S2I_TOPIC_NAME);
+        KafkaConnectUtils.createFileSinkConnector(kafkaConnectS2IPodName, CONNECT_S2I_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME);
 
         kafkaClient.sendAndRecvMessagesScramSha(userName, NAMESPACE, CLUSTER_NAME, CONNECT_S2I_TOPIC_NAME, 2);
 
-        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectS2IPodName);
+        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectS2IPodName, Constants.DEFAULT_SINK_FILE_NAME);
 
-        assertThat(cmdKubeClient().execInPod(kafkaConnectS2IPodName, "/bin/bash", "-c", "cat /tmp/test-file-sink.txt").out(),
+        assertThat(cmdKubeClient().execInPod(kafkaConnectS2IPodName, "/bin/bash", "-c", "cat " + Constants.DEFAULT_SINK_FILE_NAME).out(),
                 containsString("0\n1\n"));
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java
Patch:
@@ -7,6 +7,7 @@
 import io.fabric8.kubernetes.api.model.Service;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
+import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.HttpUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
@@ -134,13 +135,13 @@ void testProducerConsumerConnect() {
 
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME);
+        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME);
 
         String message = "Hello world - " + END_MESSAGE_OFFSET;
 
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, message);
 
-        assertThat(cmdKubeClient().execInPod(kafkaConnectPodName, "/bin/bash", "-c", "cat /tmp/test-file-sink.txt").out(),
+        assertThat(cmdKubeClient().execInPod(kafkaConnectPodName, "/bin/bash", "-c", "cat " + Constants.DEFAULT_SINK_FILE_NAME).out(),
                 containsString(message));
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -7,6 +7,7 @@
 import io.fabric8.kubernetes.api.model.Service;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
+import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.HttpUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
@@ -141,13 +142,13 @@ void testProducerConsumerConnect() {
 
         KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
 
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME);
+        KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME);
 
         String message = "Hello world - " + END_MESSAGE_OFFSET;
 
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName, message);
 
-        assertThat(cmdKubeClient().execInPod(kafkaConnectPodName, "/bin/bash", "-c", "cat /tmp/test-file-sink.txt").out(),
+        assertThat(cmdKubeClient().execInPod(kafkaConnectPodName, "/bin/bash", "-c", "cat " + Constants.DEFAULT_SINK_FILE_NAME).out(),
                 containsString(message));
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -791,11 +791,11 @@ void testConnectS2IService() throws Exception {
         String kafkaConnectS2IPodName = kubeClient().listPods("type", "kafka-connect-s2i").get(0).getMetadata().getName();
 
         LOGGER.info("Creating FileSink connect in Pod:{}", kafkaConnectS2IPodName);
-        KafkaConnectUtils.createFileSinkConnector(kafkaConnectS2IPodName, TEST_TOPIC_NAME);
+        KafkaConnectUtils.createFileSinkConnector(kafkaConnectS2IPodName, TEST_TOPIC_NAME, Constants.DEFAULT_SINK_FILE_NAME);
 
         kafkaClient.sendAndRecvMessages(NAMESPACE, CLUSTER_NAME, TEST_TOPIC_NAME, 10);
 
-        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectS2IPodName);
+        KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectS2IPodName, Constants.DEFAULT_SINK_FILE_NAME);
 
         HttpUtils.waitUntilServiceWithNameIsReady(RestAssured.baseURI, JAEGER_PRODUCER_SERVICE, JAEGER_CONSUMER_SERVICE,
                 JAEGER_KAFKA_CONNECT_S2I_SERVICE);

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalclient/ExternalKafkaClient.java
Patch:
@@ -80,7 +80,7 @@ private Integer sendMessages(String topicName, String namespace, String clusterN
      */
     @Override
     public Integer sendMessagesTls(String topicName, String namespace, String clusterName, String kafkaUsername, int messageCount, String securityProtocol) throws InterruptedException {
-        LOGGER.info("Sending messages to pod:{}", this.podName);
+        LOGGER.info("Sending messages to pod: {}", this.podName);
         return sendMessages(topicName, namespace, clusterName, kafkaUsername, messageCount, securityProtocol, this.podName);
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -99,7 +99,7 @@ private static DeploymentBuilder defaultCLusterOperator(String namespace, long o
                     .editSpec()
                         .editFirstContainer()
                             .withImage(StUtils.changeOrgAndTag(coImage))
-                            .withImagePullPolicy(Environment.IMAGE_PULL_POLICY)
+                            .withImagePullPolicy(Constants.IMAGE_PULL_POLICY)
                         .endContainer()
                     .endSpec()
                 .endTemplate()

File: systemtest/src/test/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -102,7 +102,7 @@ public abstract class BaseST implements TestSeparator {
     protected String testClass;
     protected String testName;
 
-    Random rng = new Random();
+    protected Random rng = new Random();
 
     private HelmClient helmClient() {
         return cluster.helmClient().namespace(cluster.getNamespace());

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -459,7 +459,7 @@ void assertThatRollingUpdatedFinished(String rolledComponent, String stableCompo
     }
 
     void deployTestSpecificResources() {
-        KafkaClientsResource.deployKafkaClients(CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).done();
+        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, CLUSTER_NAME, NAMESPACE).done();
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/TopicST.java
Patch:
@@ -216,7 +216,7 @@ void testDeleteTopicEnableFalse() throws Exception {
             .endSpec()
             .done();
 
-        KafkaClientsResource.deployKafkaClients(CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).done();
+        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, CLUSTER_NAME, NAMESPACE).done();
 
         KafkaTopicResource.topic(CLUSTER_NAME, topicName).done();
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -130,7 +130,7 @@ void testKafkaConnectIoNetwork() {
 
     @Test
     void testKafkaExporterDataAfterExchange() throws InterruptedException {
-        KafkaClientsResource.deployKafkaClients(CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS).done();
+        KafkaClientsResource.deployKafkaClients(false, CLUSTER_NAME + "-" + Constants.KAFKA_CLIENTS, CLUSTER_NAME, NAMESPACE).done();
 
         final String defaultKafkaClientsPodName =
             ResourceManager.kubeClient().listPodsByPrefixInName("my-cluster" + "-" + Constants.KAFKA_CLIENTS).get(0).getMetadata().getName();

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -125,7 +125,8 @@ void testDeployUnsupportedKafka() {
 
         LOGGER.info("Kafka with version {} deployed.", nonExistingVersion);
 
-        KafkaUtils.waitUntilKafkaStatusConditionIsNotReady(CLUSTER_NAME, nonExistingVersionMessage);
+        KafkaUtils.waitUntilKafkaCRIsNotReady(CLUSTER_NAME);
+        KafkaUtils.waitUntilKafkaStatusConditionContainsMessage(CLUSTER_NAME, NAMESPACE, nonExistingVersionMessage);
 
         Condition condition = KafkaResource.kafkaClient().inNamespace(NAMESPACE).withName(CLUSTER_NAME).get().getStatus().getConditions().get(0);
 

File: test/src/main/java/io/strimzi/test/k8s/KubeClient.java
Patch:
@@ -347,7 +347,7 @@ public boolean getDeploymentConfigStatus(String deploymentConfigName) {
     }
 
     public Secret createSecret(Secret secret) {
-        return client.secrets().inNamespace(getNamespace()).create(secret);
+        return client.secrets().inNamespace(getNamespace()).createOrReplace(secret);
     }
 
     public Secret patchSecret(String secretName, Secret secret) {

File: api/src/main/java/io/strimzi/api/kafka/Crds.java
Patch:
@@ -43,6 +43,7 @@
 public class Crds {
 
     public static final String CRD_KIND = "CustomResourceDefinition";
+    public static final String STRIMZI_CATEGORY = "strimzi";
 
     @SuppressWarnings("unchecked")
     private static final Class<? extends CustomResource>[] CRDS = new Class[] {

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -26,6 +26,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.api.kafka.Crds.STRIMZI_CATEGORY;
 import static java.util.Arrays.asList;
 import static java.util.Collections.singletonList;
 import static java.util.Collections.unmodifiableList;
@@ -37,7 +38,8 @@
                 names = @Crd.Spec.Names(
                         kind = Kafka.RESOURCE_KIND,
                         plural = Kafka.RESOURCE_PLURAL,
-                        shortNames = {Kafka.SHORT_NAME}
+                        shortNames = {Kafka.SHORT_NAME},
+                        categories = {STRIMZI_CATEGORY}
                 ),
                 group = Kafka.RESOURCE_GROUP,
                 scope = Kafka.SCOPE,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridge.java
Patch:
@@ -25,6 +25,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.api.kafka.Crds.STRIMZI_CATEGORY;
 import static java.util.Arrays.asList;
 import static java.util.Collections.emptyMap;
 import static java.util.Collections.singletonList;
@@ -37,7 +38,8 @@
                 names = @Crd.Spec.Names(
                         kind = KafkaBridge.RESOURCE_KIND,
                         plural = KafkaBridge.RESOURCE_PLURAL,
-                        shortNames = {KafkaBridge.SHORT_NAME}
+                        shortNames = {KafkaBridge.SHORT_NAME},
+                        categories = {STRIMZI_CATEGORY}
                 ),
                 group = KafkaBridge.RESOURCE_GROUP,
                 scope = KafkaBridge.SCOPE,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnect.java
Patch:
@@ -26,6 +26,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.api.kafka.Crds.STRIMZI_CATEGORY;
 import static java.util.Arrays.asList;
 import static java.util.Collections.singletonList;
 import static java.util.Collections.unmodifiableList;
@@ -37,7 +38,8 @@
                 names = @Crd.Spec.Names(
                         kind = KafkaConnect.RESOURCE_KIND,
                         plural = KafkaConnect.RESOURCE_PLURAL,
-                        shortNames = {KafkaConnect.SHORT_NAME}
+                        shortNames = {KafkaConnect.SHORT_NAME},
+                        categories = {STRIMZI_CATEGORY}
                 ),
                 group = KafkaConnect.RESOURCE_GROUP,
                 scope = KafkaConnect.SCOPE,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectS2I.java
Patch:
@@ -27,6 +27,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.api.kafka.Crds.STRIMZI_CATEGORY;
 import static java.util.Arrays.asList;
 import static java.util.Collections.singletonList;
 import static java.util.Collections.unmodifiableList;
@@ -40,7 +41,8 @@
                 names = @Crd.Spec.Names(
                         kind = KafkaConnectS2I.RESOURCE_KIND,
                         plural = KafkaConnectS2I.RESOURCE_PLURAL,
-                        shortNames = {KafkaConnectS2I.SHORT_NAME}
+                        shortNames = {KafkaConnectS2I.SHORT_NAME},
+                        categories = {STRIMZI_CATEGORY}
                 ),
                 group = KafkaConnectS2I.RESOURCE_GROUP,
                 scope = KafkaConnectS2I.SCOPE,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnector.java
Patch:
@@ -23,6 +23,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.api.kafka.Crds.STRIMZI_CATEGORY;
 import static java.util.Arrays.asList;
 import static java.util.Collections.emptyMap;
 import static java.util.Collections.unmodifiableList;
@@ -33,7 +34,8 @@
                 names = @Crd.Spec.Names(
                         kind = KafkaConnector.RESOURCE_KIND,
                         plural = KafkaConnector.RESOURCE_PLURAL,
-                        shortNames = {KafkaConnector.SHORT_NAME}
+                        shortNames = {KafkaConnector.SHORT_NAME},
+                        categories = {STRIMZI_CATEGORY}
                 ),
                 group = KafkaConnector.RESOURCE_GROUP,
                 scope = KafkaConnector.SCOPE,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMaker.java
Patch:
@@ -25,6 +25,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.api.kafka.Crds.STRIMZI_CATEGORY;
 import static java.util.Arrays.asList;
 import static java.util.Collections.emptyMap;
 import static java.util.Collections.singletonList;
@@ -37,7 +38,8 @@
                 names = @Crd.Spec.Names(
                         kind = KafkaMirrorMaker.RESOURCE_KIND,
                         plural = KafkaMirrorMaker.RESOURCE_PLURAL,
-                        shortNames = {KafkaMirrorMaker.SHORT_NAME}
+                        shortNames = {KafkaMirrorMaker.SHORT_NAME},
+                        categories = {STRIMZI_CATEGORY}
                 ),
                 group = KafkaMirrorMaker.RESOURCE_GROUP,
                 scope = KafkaMirrorMaker.SCOPE,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaTopic.java
Patch:
@@ -25,6 +25,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.api.kafka.Crds.STRIMZI_CATEGORY;
 import static java.util.Arrays.asList;
 import static java.util.Collections.emptyMap;
 import static java.util.Collections.singletonList;
@@ -37,7 +38,8 @@
                 names = @Crd.Spec.Names(
                         kind = KafkaTopic.RESOURCE_KIND,
                         plural = KafkaTopic.RESOURCE_PLURAL,
-                        shortNames = {KafkaTopic.SHORT_NAME}
+                        shortNames = {KafkaTopic.SHORT_NAME},
+                        categories = {STRIMZI_CATEGORY}
                 ),
                 group = KafkaTopic.RESOURCE_GROUP,
                 scope = KafkaTopic.SCOPE,

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUser.java
Patch:
@@ -24,6 +24,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.api.kafka.Crds.STRIMZI_CATEGORY;
 import static java.util.Arrays.asList;
 import static java.util.Collections.emptyMap;
 import static java.util.Collections.singletonList;
@@ -36,7 +37,8 @@
                 names = @Crd.Spec.Names(
                         kind = KafkaUser.RESOURCE_KIND,
                         plural = KafkaUser.RESOURCE_PLURAL,
-                        shortNames = {KafkaUser.SHORT_NAME}
+                        shortNames = {KafkaUser.SHORT_NAME},
+                        categories = {STRIMZI_CATEGORY}
                 ),
                 group = KafkaUser.RESOURCE_GROUP,
                 scope = KafkaUser.SCOPE,

File: crd-generator/src/test/java/io/strimzi/crdgenerator/ExampleCrd.java
Patch:
@@ -27,7 +27,8 @@
         group = "crdgenerator.strimzi.io",
         names = @Crd.Spec.Names(
             kind = "Example",
-            plural = "examples"),
+            plural = "examples",
+            categories = {"strimzi"}),
         scope = "Namespaced",
         version = "v1alpha1",
     versions = {

File: crd-generator/src/test/java/io/strimzi/crdgenerator/TopicCrd.java
Patch:
@@ -16,7 +16,7 @@
 
 import static java.util.Arrays.asList;
 
-@Crd(apiVersion = "v1beta1", spec = @Crd.Spec(group = "strimzi.io", names = @Crd.Spec.Names(kind = "Topic", plural = "topics"), scope = "Namespaced", version = "v1alpha1"))
+@Crd(apiVersion = "v1beta1", spec = @Crd.Spec(group = "strimzi.io", names = @Crd.Spec.Names(kind = "Topic", plural = "topics", categories = "strimzi"), scope = "Namespaced", version = "v1alpha1"))
 public class TopicCrd extends CustomResource {
 
     public String name;

File: api/src/main/java/io/strimzi/api/kafka/model/status/KafkaConnectS2Istatus.java
Patch:
@@ -20,7 +20,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({ "conditions", "observedGeneration", "url", "buildConfigName" })
+@JsonPropertyOrder({ "conditions", "observedGeneration", "url", "connectorPlugins", "buildConfigName" })
 @EqualsAndHashCode(callSuper = true)
 @ToString(callSuper = true)
 public class KafkaConnectS2Istatus extends KafkaConnectStatus {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -42,7 +42,7 @@
  *     <li>A Kafka Connect Deployment and related Services</li>
  * </ul>
  */
-public class KafkaConnectAssemblyOperator extends AbstractConnectOperator<KubernetesClient, KafkaConnect, KafkaConnectList, DoneableKafkaConnect, Resource<KafkaConnect, DoneableKafkaConnect>> {
+public class KafkaConnectAssemblyOperator extends AbstractConnectOperator<KubernetesClient, KafkaConnect, KafkaConnectList, DoneableKafkaConnect, Resource<KafkaConnect, DoneableKafkaConnect>, KafkaConnectStatus> {
 
     private static final Logger log = LogManager.getLogger(KafkaConnectAssemblyOperator.class.getName());
     public static final String ANNO_STRIMZI_IO_LOGGING = Annotations.STRIMZI_DOMAIN + "/logging";
@@ -109,7 +109,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
                 .compose(i -> deploymentOperations.scaleUp(namespace, connect.getName(), connect.getReplicas()))
                 .compose(i -> deploymentOperations.waitForObserved(namespace, connect.getName(), 1_000, operationTimeoutMs))
                 .compose(i -> deploymentOperations.readiness(namespace, connect.getName(), 1_000, operationTimeoutMs))
-                .compose(i -> reconcileConnectors(reconciliation, kafkaConnect))
+                .compose(i -> reconcileConnectors(reconciliation, kafkaConnect, kafkaConnectStatus))
                 .setHandler(reconciliationResult -> {
                     StatusUtils.setStatusConditionAndObservedGeneration(kafkaConnect, kafkaConnectStatus, reconciliationResult);
                     kafkaConnectStatus.setUrl(KafkaConnectResources.url(connect.getCluster(), namespace, KafkaConnectCluster.REST_API_PORT));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -140,6 +140,7 @@ public void testCreateUpdate(VertxTestContext context) throws InterruptedExcepti
             .build());
         KafkaConnectApi mock = mock(KafkaConnectApi.class);
         when(mock.list(anyString(), anyInt())).thenReturn(Future.succeededFuture(emptyList()));
+        when(mock.listConnectorPlugins(anyString(), anyInt())).thenReturn(Future.succeededFuture(emptyList()));
         KafkaConnectAssemblyOperator kco = createConnectCluster(context,
                 mock);
         LOGGER.info("Reconciling again -> update");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractConnectOperator.java
Patch:
@@ -180,7 +180,7 @@ public void eventReceived(Action action, KafkaConnector kafkaConnector) {
                                                 }
                                                 return connectOperator.withLock(reconciliation, LOCK_TIMEOUT_MS,
                                                     () -> connectOperator.reconcileConnector(reconciliation,
-                                                                KafkaConnectResources.serviceName(connectName), apiClient,
+                                                                KafkaConnectResources.qualifiedServiceName(connectName, connectNamespace), apiClient,
                                                                 isUseResources(connect),
                                                                 kafkaConnector.getMetadata().getName(), action == Action.DELETED ? null : kafkaConnector)
                                                             .compose(reconcileResult -> {
@@ -196,7 +196,7 @@ public void eventReceived(Action action, KafkaConnector kafkaConnector) {
 
                                                 return connectS2IOperator.withLock(reconciliation, LOCK_TIMEOUT_MS,
                                                     () -> connectS2IOperator.reconcileConnector(reconciliation,
-                                                                KafkaConnectResources.serviceName(connectName), apiClient,
+                                                                KafkaConnectResources.qualifiedServiceName(connectName, connectNamespace), apiClient,
                                                                 isUseResources(connectS2i),
                                                                 kafkaConnector.getMetadata().getName(), action == Action.DELETED ? null : kafkaConnector)
                                                             .compose(reconcileResult -> {
@@ -250,7 +250,7 @@ private static NoSuchResourceException noConnectCluster(String connectNamespace,
     protected Future<Void> reconcileConnectors(Reconciliation reconciliation, T connect) {
         String connectName = connect.getMetadata().getName();
         String namespace = connect.getMetadata().getNamespace();
-        String host = KafkaConnectResources.serviceName(connectName);
+        String host = KafkaConnectResources.qualifiedServiceName(connectName, namespace);
         KafkaConnectApi apiClient = connectClientProvider.apply(vertx);
         boolean useResources = isUseResources(connect);
         return CompositeFuture.join(apiClient.list(host, KafkaConnectCluster.REST_API_PORT),

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractConnectOperator.java
Patch:
@@ -40,6 +40,7 @@
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.AbstractOperator;
 import io.strimzi.operator.common.Annotations;
+import io.strimzi.operator.common.BackOff;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.Util;
 import io.strimzi.operator.common.model.Labels;
@@ -265,7 +266,7 @@ private Future<Void> reconcileConnector(Reconciliation reconciliation, String ho
                 Promise<Void> promise = Promise.promise();
                 apiClient.createOrUpdatePutRequest(host, KafkaConnectCluster.REST_API_PORT,
                         connectorName, asJson(connector.getSpec()))
-                        .compose(ignored -> apiClient.status(host, KafkaConnectCluster.REST_API_PORT,
+                        .compose(ignored -> apiClient.statusWithBackOff(new BackOff(200L, 2, 6), host, KafkaConnectCluster.REST_API_PORT,
                                 connectorName))
                         .compose(status -> {
                             Object path = ((Map) status.getOrDefault("connector", emptyMap())).get("state");

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -77,6 +77,8 @@ public interface Constants {
     String KAFKA_BRIDGE_JSON = "application/vnd.kafka.v2+json";
 
     int HTTP_BRIDGE_DEFAULT_PORT = 8080;
+    int HTTP_JAEGER_DEFAULT_TCP_PORT = 5778;
+    int HTTP_JAEGER_DEFAULT_NODE_PORT = 32480;
 
     /**
      * Default value which allows execution of tests with any tags

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalclient/ClientArgument.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.api;
+package io.strimzi.systemtest.kafkaclients.externalclient;
 
 /**
  * Enum with argument for external clients

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalclient/ClientArgumentMap.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.api;
+package io.strimzi.systemtest.kafkaclients.externalclient;
 
 import java.util.ArrayList;
 import java.util.HashMap;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalclient/ClientType.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.api;
+package io.strimzi.systemtest.kafkaclients.externalclient;
 
 public enum ClientType {
     CLI_KAFKA_VERIFIABLE_PRODUCER,

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/externalclient/VerifiableClient.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.api;
+package io.strimzi.systemtest.kafkaclients.externalclient;
 
 import io.strimzi.test.executor.Exec;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalclients/ClientHandlerBase.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.lib;
+package io.strimzi.systemtest.kafkaclients.internalclients;
 
 import io.vertx.core.AbstractVerticle;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalclients/Consumer.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.lib;
+package io.strimzi.systemtest.kafkaclients.internalclients;
 
 import io.vertx.kafka.client.consumer.KafkaConsumer;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/internalclients/Producer.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.kafkaclients.lib;
+package io.strimzi.systemtest.kafkaclients.internalclients;
 
 import io.vertx.kafka.client.producer.KafkaProducer;
 import io.vertx.kafka.client.producer.KafkaProducerRecord;
@@ -44,7 +44,6 @@ protected void handleClient() {
         } else {
             sendNext(producer, topic);
         }
-
     }
 
     private void sendNext(KafkaProducer<String, String> producer, String topic) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaBridgeUtils.java
Patch:
@@ -41,7 +41,7 @@ public static Service createBridgeNodePortService(String clusterName, String nam
         map.put("strimzi.io/name", clusterName + "-bridge");
 
         // Create node port service for expose bridge outside Kubernetes
-        return KubernetesResource.getSystemtestsServiceResource(serviceName, Constants.HTTP_BRIDGE_DEFAULT_PORT, namespace)
+        return KubernetesResource.getSystemtestsServiceResource(serviceName, Constants.HTTP_BRIDGE_DEFAULT_PORT, namespace, "TCP")
                     .editSpec()
                         .withType("NodePort")
                         .withSelector(map)

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -21,7 +21,7 @@
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 
-public abstract class AbstractNamespaceST extends MessagingBaseST {
+public abstract class AbstractNamespaceST extends BaseST {
 
     private static final Logger LOGGER = LogManager.getLogger(AbstractNamespaceST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -118,7 +118,8 @@ void testUserInDifferentNamespace() throws Exception {
                 copySecret(s, THIRD_NAMESPACE, USER_NAME);
             }
         }
-        waitForClusterAvailabilityTls(USER_NAME, THIRD_NAMESPACE, CLUSTER_NAME);
+
+        kafkaClient.sendAndRecvMessagesTls(USER_NAME, THIRD_NAMESPACE, CLUSTER_NAME);
 
         cluster.setNamespace(startingNamespace);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -51,7 +51,7 @@
 
 @OpenShiftOnly
 @Tag(REGRESSION)
-class ConnectS2IST extends MessagingBaseST {
+class ConnectS2IST extends BaseST {
 
     public static final String NAMESPACE = "connect-s2i-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(ConnectS2IST.class);
@@ -183,7 +183,7 @@ void testSecretsWithKafkaConnectS2IWithTlsAndScramShaAuthentication() throws Exc
         LOGGER.info("Creating FileStreamSink connector in pod {} with topic {}", kafkaConnectS2IPodName, CONNECT_S2I_TOPIC_NAME);
         KafkaConnectUtils.createFileSinkConnector(kafkaConnectS2IPodName, CONNECT_S2I_TOPIC_NAME);
 
-        waitForClusterAvailabilityScramSha(userName, NAMESPACE, CLUSTER_NAME, CONNECT_S2I_TOPIC_NAME, 2);
+        kafkaClient.sendAndRecvMessagesScramSha(userName, NAMESPACE, CLUSTER_NAME, CONNECT_S2I_TOPIC_NAME, 2);
 
         KafkaConnectUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectS2IPodName);
 

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -59,7 +59,7 @@
 import static org.hamcrest.core.StringContains.containsString;
 
 @Tag(REGRESSION)
-class CustomResourceStatusST extends MessagingBaseST {
+class CustomResourceStatusST extends BaseST {
     static final String NAMESPACE = "status-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(CustomResourceStatusST.class);
     private static final String TOPIC_NAME = "status-topic";
@@ -70,7 +70,7 @@ class CustomResourceStatusST extends MessagingBaseST {
     void testKafkaStatus() throws Exception {
         LOGGER.info("Checking status of deployed kafka cluster");
         waitForKafkaStatus("Ready");
-        waitForClusterAvailability(NAMESPACE, TOPIC_NAME);
+        kafkaClient.sendAndRecvMessages(NAMESPACE, TOPIC_NAME);
         assertKafkaStatus(1, "my-cluster-kafka-bootstrap.status-cluster-test.svc");
 
         KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -61,7 +61,7 @@ void testSendSimpleMessage() throws Exception {
         JsonObject records = HttpUtils.generateHttpMessages(messageCount);
         JsonObject response = HttpUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, topicName, client);
         KafkaBridgeUtils.checkSendResponse(response, messageCount);
-        receiveMessagesExternal(NAMESPACE, topicName, messageCount);
+        kafkaClient.receiveMessagesExternal(CLUSTER_NAME, NAMESPACE, topicName, messageCount);
 
         // Checking labels for Kafka Bridge
         verifyLabelsOnPods(CLUSTER_NAME, "my-bridge", null, "KafkaBridge");
@@ -93,7 +93,7 @@ void testReceiveSimpleMessage() throws Exception {
         // Subscribe
         assertThat(HttpUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, groupId, name, client), is(true));
         // Send messages to Kafka
-        sendMessagesExternal(NAMESPACE, topicName, messageCount);
+        kafkaClient.sendMessagesExternal(CLUSTER_NAME, NAMESPACE, topicName, messageCount);
         // Try to consume messages
         JsonArray bridgeResponse = HttpUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, groupId, name, client);
         if (bridgeResponse.size() == 0) {

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -59,7 +59,7 @@ void testSendSimpleMessageTls() throws Exception {
         JsonObject records = HttpUtils.generateHttpMessages(messageCount);
         JsonObject response = HttpUtils.sendMessagesHttpRequest(records, bridgeHost, bridgePort, topicName, client);
         KafkaBridgeUtils.checkSendResponse(response, messageCount);
-        receiveMessagesExternalTls(NAMESPACE, topicName, messageCount, userName);
+        kafkaClient.receiveMessagesExternalTls(CLUSTER_NAME, NAMESPACE, topicName, messageCount, userName);
     }
 
     @Test
@@ -87,7 +87,7 @@ void testReceiveSimpleMessageTls() throws Exception {
         // Subscribe
         assertThat(HttpUtils.subscribeHttpConsumer(topics, bridgeHost, bridgePort, groupId, name, client), is(true));
         // Send messages to Kafka
-        sendMessagesExternalTls(NAMESPACE, topicName, messageCount, userName);
+        kafkaClient.sendMessagesExternalTls(CLUSTER_NAME, NAMESPACE, topicName, messageCount, userName);
         // Try to consume messages
         JsonArray bridgeResponse = HttpUtils.receiveMessagesHttpRequest(bridgeHost, bridgePort, groupId, name, client);
         if (bridgeResponse.size() == 0) {

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthBaseST.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.fabric8.kubernetes.api.model.Service;
 import io.strimzi.api.kafka.model.CertSecretSourceBuilder;
-import io.strimzi.systemtest.MessagingBaseST;
+import io.strimzi.systemtest.BaseST;
 import io.strimzi.systemtest.utils.kubeUtils.objects.SecretUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;
 import io.strimzi.test.executor.Exec;
@@ -37,7 +37,7 @@
 @Tag(REGRESSION)
 @Tag(NODEPORT_SUPPORTED)
 @ExtendWith(VertxExtension.class)
-public class OauthBaseST extends MessagingBaseST {
+public class OauthBaseST extends BaseST {
 
     public static final String NAMESPACE = "oauth2-cluster-test";
     protected static final Logger LOGGER = LogManager.getLogger(OauthBaseST.class);

File: mockkube/src/main/java/io/strimzi/test/mockkube/DeploymentMockBuilder.java
Patch:
@@ -111,7 +111,7 @@ protected void mockPatch(String resourceName, RollableScalableResource<Deploymen
                 // delete the first "old" Pod if there is one still remaining
                 if (podsForDeployments.get(deployment.getMetadata().getName()).size() > 0) {
                     String podToDelete = podsForDeployments.get(deployment.getMetadata().getName()).remove(0);
-                    mockPods.inNamespace(deployment.getMetadata().getNamespace()).withName(podToDelete).delete();
+                    mockPods.inNamespace(deployment.getMetadata().getNamespace()).withName(podToDelete).cascading(true).delete();
                 }
 
             }

File: mockkube/src/main/java/io/strimzi/test/mockkube/MockBuilder.java
Patch:
@@ -343,7 +343,7 @@ protected void checkDoesExist(String resourceName) {
     }
 
     protected void mockDelete(String resourceName, R resource) {
-        when(resource.delete()).thenAnswer(i -> {
+        when(resource.cascading(true).delete()).thenAnswer(i -> {
             return doDelete(resourceName);
         });
     }

File: mockkube/src/main/java/io/strimzi/test/mockkube/StatefulSetMockBuilder.java
Patch:
@@ -193,14 +193,14 @@ private void doRecreatePod(String namespace,
 
     @Override
     protected void mockDelete(String resourceName, RollableScalableResource<StatefulSet, DoneableStatefulSet> resource) {
-        when(resource.delete()).thenAnswer(i -> {
+        when(resource.cascading(true).delete()).thenAnswer(i -> {
             LOGGER.debug("delete {} {}", resourceType, resourceName);
             StatefulSet removed = db.remove(resourceName);
             if (removed != null) {
                 fireWatchers(resourceName, removed, Watcher.Action.DELETED, "delete");
                 for (Map.Entry<String, Pod> pod : new HashMap<>(podDb).entrySet()) {
                     if (pod.getKey().matches(resourceName + "-[0-9]+")) {
-                        mockPods.inNamespace(removed.getMetadata().getNamespace()).withName(pod.getKey()).delete();
+                        mockPods.inNamespace(removed.getMetadata().getNamespace()).withName(pod.getKey()).cascading(true).delete();
                     }
                 }
             }
@@ -226,7 +226,7 @@ private StatefulSet doPatch(String resourceName, StatefulSet argument) {
             LOGGER.debug("scaling down {} {} from {} to {}", resourceType, resourceName, oldScale, newScale);
             for (int i = oldScale - 1; i >= newScale; i--) {
                 String newPodName = argument.getMetadata().getName() + "-" + i;
-                mockPods.inNamespace(argument.getMetadata().getNamespace()).withName(newPodName).delete();
+                mockPods.inNamespace(argument.getMetadata().getNamespace()).withName(newPodName).cascading(true).delete();
             }
         } else {
             db.put(resourceName, copyResource(argument));

File: mockkube/src/test/java/io/strimzi/test/io/strimzi/test/mockkube/MockKubeRegressionTest.java
Patch:
@@ -72,7 +72,7 @@ public void onClose(KubernetesClientException cause) {
 
             }
         });
-        client.pods().inNamespace("ns").withName(ns.get(0).getMetadata().getName()).delete();
+        client.pods().inNamespace("ns").withName(ns.get(0).getMetadata().getName()).cascading(true).delete();
 
         assertThat(deleted.get(), is(true));
         assertThat(recreated.get(), is(true));
@@ -81,7 +81,7 @@ public void onClose(KubernetesClientException cause) {
         ns = client.pods().inNamespace("ns").list().getItems();
         assertThat(ns.size(), is(3));
 
-        client.apps().statefulSets().inNamespace("ns").withName("foo").delete();
+        client.apps().statefulSets().inNamespace("ns").withName("foo").cascading(true).delete();
 
     }
 }

File: mockkube/src/test/java/io/strimzi/test/io/strimzi/test/mockkube/MockKubeTest.java
Patch:
@@ -243,7 +243,7 @@ public void podNameScopedCreateListGetDelete(Class<RT> cls,
         // TODO assertNull(gotResource);
 
         // Delete
-        assertThat(mixedOp.apply(client).withName(pod.getMetadata().getName()).delete(), is(true));
+        assertThat(mixedOp.apply(client).withName(pod.getMetadata().getName()).cascading(true).delete(), is(true));
         assertThat(w.lastEvent().action, is(Watcher.Action.DELETED));
         RT resource = (RT) w.lastEvent().resource;
         resource.getMetadata().setResourceVersion(null);
@@ -256,7 +256,7 @@ public void podNameScopedCreateListGetDelete(Class<RT> cls,
         gotResource = mixedOp.apply(client).withName(pod.getMetadata().getName()).get();
         assertThat(gotResource, is(nullValue()));
 
-        assertThat(mixedOp.apply(client).withName(pod.getMetadata().getName()).delete(), is(false));
+        assertThat(mixedOp.apply(client).withName(pod.getMetadata().getName()).cascading(true).delete(), is(false));
 
         // TODO Delete off a withLabels query, delete off a inNamespace
         // TODO inAnyNamespace()

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaBridgeCrdOperatorIT.java
Patch:
@@ -123,7 +123,7 @@ protected KafkaBridge getResource() {
     private Future<Void> deleteResource()    {
         // The resource has to be deleted this was and not using reconcile due to https://github.com/fabric8io/kubernetes-client/pull/1325
         // Fix this override when project is using fabric8 version > 4.1.1
-        kafkaBridgeOperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).delete();
+        kafkaBridgeOperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).cascading(true).delete();
 
         return kafkaBridgeOperator.waitFor(namespace, RESOURCE_NAME, 1_000, 60_000, (ignore1, ignore2) -> {
             KafkaBridge deletion = kafkaBridgeOperator.get(namespace, RESOURCE_NAME);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectCrdOperatorIT.java
Patch:
@@ -122,7 +122,7 @@ protected KafkaConnect getResource() {
     private Future<Void> deleteResource()    {
         // The resource has to be deleted this was and not using reconcile due to https://github.com/fabric8io/kubernetes-client/pull/1325
         // Fix this override when project is using fabric8 version > 4.1.1
-        kafkaConnectOperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).delete();
+        kafkaConnectOperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).cascading(true).delete();
 
         return kafkaConnectOperator.waitFor(namespace, RESOURCE_NAME, 1_000, 60_000, (ignore1, ignore2) -> {
             KafkaConnect deletion = kafkaConnectOperator.get(namespace, RESOURCE_NAME);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectS2IcrdOperatorIT.java
Patch:
@@ -122,7 +122,7 @@ protected KafkaConnectS2I getResource() {
     private Future<Void> deleteResource()    {
         // The resource has to be deleted this was and not using reconcile due to https://github.com/fabric8io/kubernetes-client/pull/1325
         // Fix this override when project is using fabric8 version > 4.1.1
-        kafkaConnectS2Ioperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).delete();
+        kafkaConnectS2Ioperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).cascading(true).delete();
 
         return kafkaConnectS2Ioperator.waitFor(namespace, RESOURCE_NAME, 1_000, 60_000, (ignore1, ignore2) -> {
             KafkaConnectS2I deletion = kafkaConnectS2Ioperator.get(namespace, RESOURCE_NAME);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaCrdOperatorIT.java
Patch:
@@ -136,7 +136,7 @@ protected Kafka getResource() {
     private Future<Void> deleteResource()    {
         // The resource has to be deleted this was and not using reconcile due to https://github.com/fabric8io/kubernetes-client/pull/1325
         // Fix this override when project is using fabric8 version > 4.1.1
-        kafkaOperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).delete();
+        kafkaOperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).cascading(true).delete();
 
         return kafkaOperator.waitFor(namespace, RESOURCE_NAME, 1_000, 60_000, (ignore1, ignore2) -> {
             Kafka deletion = kafkaOperator.get(namespace, RESOURCE_NAME);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaMirrorMakerCrdOperatorIT.java
Patch:
@@ -123,7 +123,7 @@ protected KafkaMirrorMaker getResource() {
     private Future<Void> deleteResource()    {
         // The resource has to be deleted this was and not using reconcile due to https://github.com/fabric8io/kubernetes-client/pull/1325
         // Fix this override when project is using fabric8 version > 4.1.1
-        kafkaMirrorMakerOperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).delete();
+        kafkaMirrorMakerOperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).cascading(true).delete();
 
         return kafkaMirrorMakerOperator.waitFor(namespace, RESOURCE_NAME, 1_000, 60_000, (ignore1, ignore2) -> {
             KafkaMirrorMaker deletion = kafkaMirrorMakerOperator.get(namespace, RESOURCE_NAME);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaUserCrdOperatorIT.java
Patch:
@@ -122,7 +122,7 @@ protected KafkaUser getResource() {
     private Future<Void> deleteResource()    {
         // The resource has to be deleted this was and not using reconcile due to https://github.com/fabric8io/kubernetes-client/pull/1325
         // Fix this override when project is using fabric8 version > 4.1.1
-        kafkaUserOperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).delete();
+        kafkaUserOperator.operation().inNamespace(namespace).withName(RESOURCE_NAME).cascading(true).delete();
 
         return kafkaUserOperator.waitFor(namespace, RESOURCE_NAME, 1_000, 60_000, (ignore1, ignore2) -> {
             KafkaUser deletion = kafkaUserOperator.get(namespace, RESOURCE_NAME);

File: systemtest/src/test/java/io/strimzi/systemtest/TopicST.java
Patch:
@@ -228,7 +228,7 @@ void testDeleteTopicEnableFalse() throws Exception {
 
         String topicUid = KafkaTopicUtils.topicSnapshot(topicName);
         LOGGER.info("Going to delete topic {}", topicName);
-        KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(topicName).delete();
+        KafkaTopicResource.kafkaTopicClient().inNamespace(NAMESPACE).withName(topicName).cascading(true).delete();
         LOGGER.info("Topic {} deleted", topicName);
 
         KafkaTopicUtils.waitTopicHasRolled(topicName, topicUid);

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorBaseIT.java
Patch:
@@ -218,7 +218,7 @@ public void teardown() throws InterruptedException, TimeoutException, ExecutionE
 
                 // Wait for the operator to delete all the existing topics in Kafka
                 for (KafkaTopic item : items) {
-                    operation().inNamespace(NAMESPACE).withName(item.getMetadata().getName()).delete();
+                    operation().inNamespace(NAMESPACE).withName(item.getMetadata().getName()).cascading(true).delete();
                     waitForTopicInKube(item.getMetadata().getName(), false);
                 }
             }

File: user-operator/src/main/java/io/strimzi/operator/user/operator/KafkaUserOperator.java
Patch:
@@ -290,6 +290,8 @@ protected Future<Boolean> delete(Reconciliation reconciliation) {
         return CompositeFuture.join(secretOperations.reconcile(namespace, KafkaUserModel.getSecretName(user), null),
                 aclOperations.reconcile(KafkaUserModel.getTlsUserName(user), null),
                 aclOperations.reconcile(KafkaUserModel.getScramUserName(user), null),
+                kafkaUserQuotasOperator.reconcile(KafkaUserModel.getTlsUserName(user), null),
+                kafkaUserQuotasOperator.reconcile(KafkaUserModel.getScramUserName(user), null),
                 scramShaCredentialOperator.reconcile(KafkaUserModel.getScramUserName(user), null))
             .map(Boolean.TRUE);
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaRoller.java
Patch:
@@ -425,7 +425,7 @@ int controller(int podId, AdminClient ac, long timeout, TimeUnit unit) throws Fo
         } catch (TimeoutException e) {
             throw new ForceableProblem("Error while trying to determine the cluster controller from pod " + podName(podId), e);
         }
-        int id = Node.noNode().equals(controllerNode) ? -1 : controllerNode.id();
+        int id = controllerNode == null || Node.noNode().equals(controllerNode) ? -1 : controllerNode.id();
         log.debug("controller is {}", id);
         return id;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -2296,7 +2296,8 @@ public String getPreferredNodeAddressType() {
         if (isExposedWithNodePort()) {
             KafkaListenerExternalNodePort listener = (KafkaListenerExternalNodePort) listeners.getExternal();
 
-            if (listener.getConfiguration() != null) {
+            if (listener.getConfiguration() != null
+                    && listener.getConfiguration().getPreferredAddressType() != null) {
                 return listener.getConfiguration().getPreferredAddressType().toValue();
             }
         }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -47,7 +47,7 @@ private StUtils() { }
     public static void waitForReconciliation(String testClass, String testName, String namespace) {
         LOGGER.info("Waiting for reconciliation");
         String reconciliation = timeMeasuringSystem.startOperation(Operation.NEXT_RECONCILIATION);
-        TestUtils.waitFor("Wait till another rolling update starts", Constants.CO_OPERATION_TIMEOUT_POLL, Constants.RECONCILIATION_INTERVAL + 20000,
+        TestUtils.waitFor("Wait till another rolling update starts", Constants.CO_OPERATION_TIMEOUT_POLL, Constants.RECONCILIATION_INTERVAL + 30000,
             () -> !cmdKubeClient().searchInLog("deploy", "strimzi-cluster-operator",
                 timeMeasuringSystem.getCurrentDuration(testClass, testName, reconciliation),
                 "'Triggering periodic reconciliation for namespace " + namespace + "'").isEmpty());

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kubeUtils/objects/PodUtils.java
Patch:
@@ -143,7 +143,7 @@ public static void waitForPodDeletion(String name) {
     }
 
     public static void waitUntilPodsCountIsPresent(String podNamePrefix, int numberOfPods) {
-        LOGGER.info("Waiting till pods with prefix {} count is present", podNamePrefix);
+        LOGGER.info("Waiting till {} pods with prefix {} are present", numberOfPods, podNamePrefix);
         TestUtils.waitFor("", Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_STATUS_TIMEOUT,
             () -> kubeClient().listPodsByPrefixInName(podNamePrefix).size() == numberOfPods);
         LOGGER.info("Pods with count {} are present", numberOfPods);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -138,7 +138,7 @@
  *     <li>Optionally, a TopicOperator Deployment</li>
  * </ul>
  */
-@SuppressWarnings({"checkstyle:ClassFanOutComplexity"})
+@SuppressWarnings({"checkstyle:ClassDataAbstractionCoupling", "checkstyle:ClassFanOutComplexity"})
 public class KafkaAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, Kafka, KafkaList, DoneableKafka, Resource<Kafka, DoneableKafka>> {
     private static final Logger log = LogManager.getLogger(KafkaAssemblyOperator.class.getName());
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaAuthorizationSimple.java
Patch:
@@ -29,6 +29,8 @@ public class KafkaAuthorizationSimple extends KafkaAuthorization {
 
     public static final String TYPE_SIMPLE = "simple";
 
+    public static final String AUTHORIZER_CLASS_NAME = "kafka.security.auth.SimpleAclAuthorizer";
+
     private List<String> superUsers;
 
     @Description("Must be `" + TYPE_SIMPLE + "`")

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -158,7 +158,8 @@ public Map<String, CertAndKey> generateBrokerCerts(Kafka kafka, Set<String> exte
             sbjAltNames.put("DNS.7", String.format("%s.%s.svc", KafkaCluster.headlessServiceName(cluster), namespace));
             sbjAltNames.put("DNS.8", String.format("%s.%s.svc.%s", KafkaCluster.headlessServiceName(cluster), namespace, ModelUtils.KUBERNETES_SERVICE_DNS_DOMAIN));
             sbjAltNames.put("DNS.9", KafkaCluster.podDnsName(namespace, cluster, i));
-            int nextDnsId = 10;
+            sbjAltNames.put("DNS.10", KafkaCluster.podDnsNameWithoutSuffix(namespace, cluster, i));
+            int nextDnsId = 11;
             int nextIpId = 1;
 
             if (externalBootstrapAddresses != null)   {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -276,7 +276,7 @@ protected List<Volume> getVolumes(boolean isOpenShift) {
             }
         }
 
-        AuthenticationUtils.configureClientAuthenticationVolumes(authentication, volumeList, isOpenShift);
+        AuthenticationUtils.configureClientAuthenticationVolumes(authentication, volumeList, "oauth-certs", isOpenShift);
 
         return volumeList;
     }
@@ -299,7 +299,7 @@ protected List<VolumeMount> getVolumeMounts() {
             }
         }
 
-        AuthenticationUtils.configureClientAuthenticationVolumeMounts(authentication, volumeMountList, TLS_CERTS_BASE_VOLUME_MOUNT, PASSWORD_VOLUME_MOUNT, OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT);
+        AuthenticationUtils.configureClientAuthenticationVolumeMounts(authentication, volumeMountList, TLS_CERTS_BASE_VOLUME_MOUNT, PASSWORD_VOLUME_MOUNT, OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT, "oauth-certs");
 
         return volumeMountList;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -282,7 +282,7 @@ protected List<Volume> getVolumes(boolean isOpenShift) {
             }
         }
 
-        AuthenticationUtils.configureClientAuthenticationVolumes(authentication, volumeList, isOpenShift);
+        AuthenticationUtils.configureClientAuthenticationVolumes(authentication, volumeList, "oauth-certs", isOpenShift);
 
         volumeList.addAll(getExternalConfigurationVolumes(isOpenShift));
 
@@ -350,7 +350,7 @@ protected List<VolumeMount> getVolumeMounts() {
             }
         }
 
-        AuthenticationUtils.configureClientAuthenticationVolumeMounts(authentication, volumeMountList, TLS_CERTS_BASE_VOLUME_MOUNT, PASSWORD_VOLUME_MOUNT, OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT);
+        AuthenticationUtils.configureClientAuthenticationVolumeMounts(authentication, volumeMountList, TLS_CERTS_BASE_VOLUME_MOUNT, PASSWORD_VOLUME_MOUNT, OAUTH_TLS_CERTS_BASE_VOLUME_MOUNT, "oauth-certs");
 
         volumeMountList.addAll(getExternalConfigurationVolumeMounts());
 

File: kafka-init/src/main/java/io/strimzi/kafka/init/Main.java
Patch:
@@ -33,7 +33,6 @@ public static void main(String[] args) {
             if (!writer.writeExternalAddress()) {
                 System.exit(1);
             }
-            writer.writeExternalBrokerAddresses();
         }
 
         client.close();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -127,7 +127,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                 .endMetadata()
                 .withNewSpec()
                     .withReplicas(replicas)
-                    .withSelector(getSelectorLabels())
+                    .withSelector(getSelectorLabelsAsMap())
                     .withNewTemplate()
                         .withNewMetadata()
                             .withAnnotations(mergeLabelsOrAnnotations(annotations, templatePodAnnotations))

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -68,6 +68,7 @@
 import io.strimzi.operator.common.operator.resource.ImageStreamOperator;
 import io.strimzi.operator.common.operator.resource.IngressOperator;
 import io.strimzi.operator.common.operator.resource.NetworkPolicyOperator;
+import io.strimzi.operator.common.operator.resource.NodeOperator;
 import io.strimzi.operator.common.operator.resource.PodDisruptionBudgetOperator;
 import io.strimzi.operator.common.operator.resource.PodOperator;
 import io.strimzi.operator.common.operator.resource.PvcOperator;
@@ -622,7 +623,7 @@ public static ResourceOperatorSupplier supplierWithMocks(boolean openShift) {
                 mock(IngressOperator.class), mock(ImageStreamOperator.class), mock(BuildConfigOperator.class),
                 mock(DeploymentConfigOperator.class), mock(CrdOperator.class), mock(CrdOperator.class), mock(CrdOperator.class),
                 mock(CrdOperator.class), mock(CrdOperator.class), mock(CrdOperator.class),
-                mock(StorageClassOperator.class));
+                mock(StorageClassOperator.class), mock(NodeOperator.class));
         when(supplier.serviceAccountOperations.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.roleBindingOperations.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.clusterRoleBindingOperator.reconcile(anyString(), any())).thenReturn(Future.succeededFuture());

File: kafka-init/src/main/java/io/strimzi/kafka/init/InitWriter.java
Patch:
@@ -7,6 +7,8 @@
 import io.fabric8.kubernetes.api.model.NodeAddress;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import java.util.Arrays;
+
+import io.strimzi.operator.cluster.model.NodeUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
@@ -61,7 +63,7 @@ public boolean writeExternalAddress() {
 
         List<NodeAddress> addresses = client.nodes().withName(config.getNodeName()).get().getStatus().getAddresses();
         log.info("NodeLabels = {}", addresses);
-        String externalAddress = findAddress(addresses);
+        String externalAddress = NodeUtils.findAddress(addresses, config.getAddressType());
 
         if (externalAddress == null) {
             log.error("External address not found");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -41,7 +41,6 @@ public class ClusterOperatorConfig {
     public static final String STRIMZI_KAFKA_CONNECT_IMAGES = "STRIMZI_KAFKA_CONNECT_IMAGES";
     public static final String STRIMZI_KAFKA_CONNECT_S2I_IMAGES = "STRIMZI_KAFKA_CONNECT_S2I_IMAGES";
     public static final String STRIMZI_KAFKA_MIRROR_MAKER_IMAGES = "STRIMZI_KAFKA_MIRROR_MAKER_IMAGES";
-    public static final String STRIMZI_DEFAULT_ZOOKEEPER_IMAGE = "STRIMZI_DEFAULT_ZOOKEEPER_IMAGE";
     public static final String STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE";
     public static final String STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE";
     public static final String STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE";
@@ -103,7 +102,7 @@ public static ClusterOperatorConfig fromMap(Map<String, String> map) {
      * @param lookup KafkaVersion.Lookup instance with the supported Kafka version information
      * @return  Cluster Operator configuration instance
      */
-    static ClusterOperatorConfig fromMap(Map<String, String> map, KafkaVersion.Lookup lookup) {
+    public static ClusterOperatorConfig fromMap(Map<String, String> map, KafkaVersion.Lookup lookup) {
         Set<String> namespaces = parseNamespaceList(map.get(ClusterOperatorConfig.STRIMZI_NAMESPACE));
         long reconciliationInterval = parseReconciliationInerval(map.get(ClusterOperatorConfig.STRIMZI_FULL_RECONCILIATION_INTERVAL_MS));
         long operationTimeout = parseOperationTimeout(map.get(ClusterOperatorConfig.STRIMZI_OPERATION_TIMEOUT_MS));

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -61,7 +61,7 @@ public class Environment {
 
     private static final String SKIP_TEARDOWN_ENV = "SKIP_TEARDOWN";
 
-    private static final String ST_KAFKA_VERSION_DEFAULT = "2.3.1";
+    private static final String ST_KAFKA_VERSION_DEFAULT = "2.4.0";
     public static final String STRIMZI_ORG_DEFAULT = "strimzi";
     public static final String STRIMZI_TAG_DEFAULT = "latest";
     public static final String STRIMZI_REGISTRY_DEFAULT = "docker.io";

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -173,10 +173,11 @@ void testUserWithQuotas() {
         String uOlogs = kubeClient().logs(entityOperatorPodName, "user-operator");
         assertThat(uOlogs.contains(messageUserWasAdded), is(true));
 
-        String command = "sh bin/kafka-configs.sh --zookeeper " + "localhost:2181" + " --describe --entity-type users --entity-name " + userName;
+        String command = "sh bin/kafka-configs.sh --zookeeper " + "localhost:2181" + " --describe --entity-type users";
         LOGGER.debug("Command for kafka-configs.sh {}", command);
 
         ExecResult result = cmdKubeClient().execInPod(KafkaResources.kafkaPodName(CLUSTER_NAME, 0), "/bin/bash", "-c", command);
+        assertThat(result.out().contains("Configs for user-principal 'CN=" + userName + "' are"), is(true));
         assertThat(result.out().contains("request_percentage=" + reqPerc), is(true));
         assertThat(result.out().contains("producer_byte_rate=" + prodRate), is(true));
         assertThat(result.out().contains("consumer_byte_rate=" + consRate), is(true));

File: user-operator/src/main/java/io/strimzi/operator/user/operator/KafkaUserQuotasOperator.java
Patch:
@@ -77,7 +77,7 @@ public void createOrUpdate(String username, KafkaUserQuotas quotas) {
             JsonNode diff = null;
             try {
                 ObjectMapper objectMapper = new ObjectMapper();
-                diff = JsonDiff.asJson(objectMapper.readTree(data), objectMapper.readTree(quotas.toString()));
+                diff = JsonDiff.asJson(objectMapper.readTree(data), objectMapper.readTree(createUserJson(quotas)));
             } catch (IOException e) {
                 e.printStackTrace();
             }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -119,7 +119,7 @@ private Map<String, String> expectedLabels(String name)    {
     }
 
     private Map<String, String> expectedSelectorLabels()    {
-        return Labels.fromMap(expectedLabels()).strimziLabels().toMap();
+        return Labels.fromMap(expectedLabels()).strimziSelectorLabels().toMap();
     }
 
     private Map<String, String> expectedLabels()    {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -124,7 +124,7 @@ private Map<String, String> expectedLabels(String name)    {
     }
 
     private Map<String, String> expectedSelectorLabels()    {
-        return Labels.fromMap(expectedLabels()).strimziLabels().toMap();
+        return Labels.fromMap(expectedLabels()).strimziSelectorLabels().toMap();
     }
 
     private Map<String, String> expectedLabels()    {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaExporterTest.java
Patch:
@@ -102,7 +102,7 @@ private Map<String, String> expectedLabels(String name)    {
     }
 
     private Map<String, String> expectedSelectorLabels()    {
-        return Labels.fromMap(expectedLabels()).strimziLabels().toMap();
+        return Labels.fromMap(expectedLabels()).strimziSelectorLabels().toMap();
     }
 
     private Map<String, String> expectedLabels()    {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -124,7 +124,7 @@ private Map<String, String> expectedLabels(String name)    {
     }
 
     private Map<String, String> expectedSelectorLabels()    {
-        return Labels.fromMap(expectedLabels()).strimziLabels().toMap();
+        return Labels.fromMap(expectedLabels()).strimziSelectorLabels().toMap();
     }
 
     private Map<String, String> expectedLabels()    {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -122,7 +122,7 @@ private void checkMetricsConfigMap(ConfigMap metricsCm) {
     }
 
     private Map<String, String> expectedSelectorLabels()    {
-        return Labels.fromMap(expectedLabels()).strimziLabels().toMap();
+        return Labels.fromMap(expectedLabels()).strimziSelectorLabels().toMap();
     }
 
     private Map<String, String> expectedLabels()    {

File: operator-common/src/test/java/io/strimzi/operator/common/model/LabelsTest.java
Patch:
@@ -79,21 +79,22 @@ public void testParseInvalidLabels3()   {
     }
 
     @Test
-    public void testStrimziLabels()   {
+    public void testStrimziSelectorLabels()   {
         Map sourceMap = new HashMap<String, String>(5);
         sourceMap.put(Labels.STRIMZI_CLUSTER_LABEL, "my-cluster");
         sourceMap.put("key1", "value1");
         sourceMap.put(Labels.STRIMZI_KIND_LABEL, "Kafka");
         sourceMap.put("key2", "value2");
         sourceMap.put(Labels.STRIMZI_NAME_LABEL, "my-cluster-kafka");
+        sourceMap.put(Labels.STRIMZI_DISCOVERY_LABEL, "true");
         Labels labels = Labels.fromMap(sourceMap);
 
         Map expected = new HashMap<String, String>(2);
         expected.put(Labels.STRIMZI_CLUSTER_LABEL, "my-cluster");
         expected.put(Labels.STRIMZI_KIND_LABEL, "Kafka");
         expected.put(Labels.STRIMZI_NAME_LABEL, "my-cluster-kafka");
 
-        assertThat(labels.strimziLabels().toMap(), is(expected));
+        assertThat(labels.strimziSelectorLabels().toMap(), is(expected));
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -1219,7 +1219,7 @@ private Secret generateBrokerSecret(Set<String> externalBootstrapAddress, Map<In
         ClusterCa clusterCa = new ClusterCa(new OpenSslCertManager(), new PasswordGenerator(10, "a", "a"), cluster, null, null);
         clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), null, true);
 
-        kc.generateCertificates(kafkaAssembly, clusterCa, externalBootstrapAddress, externalAddresses);
+        kc.generateCertificates(kafkaAssembly, clusterCa, externalBootstrapAddress, externalAddresses, true);
         return kc.generateBrokersSecret();
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaExporterTest.java
Patch:
@@ -286,7 +286,7 @@ public void testExporterNotDeployed() {
 
         assertThat(ke.generateDeployment(true, null, null), is(nullValue()));
         assertThat(ke.generateService(), is(nullValue()));
-        assertThat(ke.generateSecret(null), is(nullValue()));
+        assertThat(ke.generateSecret(null, true), is(nullValue()));
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -338,7 +338,7 @@ public void testGenerateBrokerSecret() throws CertificateParsingException {
         ClusterCa clusterCa = new ClusterCa(new OpenSslCertManager(), new PasswordGenerator(10, "a", "a"), cluster, null, null);
         clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), null, true);
 
-        Secret secret = zc.generateNodesSecret(clusterCa, ka);
+        Secret secret = zc.generateNodesSecret(clusterCa, ka, true);
         assertThat(secret.getData().keySet(), is(set(
                 "foo-zookeeper-0.crt",  "foo-zookeeper-0.key", "foo-zookeeper-0.p12", "foo-zookeeper-0.password",
                 "foo-zookeeper-1.crt", "foo-zookeeper-1.key", "foo-zookeeper-1.p12", "foo-zookeeper-1.password",

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -210,6 +210,9 @@ public class KafkaCluster extends AbstractModel {
      */
     public static final String ANNO_STRIMZI_IO_TO_VERSION = Annotations.STRIMZI_DOMAIN + "/to-version";
 
+    public static final String ANNO_STRIMZI_CUSTOM_CERT_THUMBPRINT_TLS_LISTENER = Annotations.STRIMZI_DOMAIN + "/custom-cert-tls-listener-thumbprint";
+    public static final String ANNO_STRIMZI_CUSTOM_CERT_THUMBPRINT_EXTERNAL_LISTENER = Annotations.STRIMZI_DOMAIN + "/custom-cert-external-listener-thumbprint";
+
     // Env vars for JMX service
     protected static final String ENV_VAR_KAFKA_JMX_ENABLED = "KAFKA_JMX_ENABLED";
 

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/Ca.java
Patch:
@@ -790,7 +790,7 @@ public static X509Certificate cert(Secret secret, String key)  {
         try {
             return x509Certificate(bytes);
         } catch (CertificateException e) {
-            throw new RuntimeException("Certificate in data." + key.replace(".", "\\.") + " of Secret " + secret.getMetadata().getName(), e);
+            throw new RuntimeException("Failed to decode certificate in data." + key.replace(".", "\\.") + " of Secret " + secret.getMetadata().getName(), e);
         }
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalNodePort.java
Patch:
@@ -36,7 +36,7 @@ public class KafkaListenerExternalNodePort extends KafkaListenerExternal {
     private boolean tls = true;
     private List<NetworkPolicyPeer> networkPolicyPeers;
     private NodePortListenerOverride overrides;
-    private KafkaListenerExternalConfiguration configuration;
+    private NodePortListenerConfiguration configuration;
 
     @Description("Must be `" + TYPE_NODEPORT + "`")
     @Override
@@ -85,11 +85,11 @@ public void setNetworkPolicyPeers(List<NetworkPolicyPeer> networkPolicyPeers) {
     }
 
     @Description("External listener configuration")
-    public KafkaListenerExternalConfiguration getConfiguration() {
+    public NodePortListenerConfiguration getConfiguration() {
         return configuration;
     }
 
-    public void setConfiguration(KafkaListenerExternalConfiguration configuration) {
+    public void setConfiguration(NodePortListenerConfiguration configuration) {
         this.configuration = configuration;
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/api/VerifiableClient.java
Patch:
@@ -62,13 +62,13 @@ public List<String> getMessages() {
      */
     public void setArguments(ClientArgumentMap args) {
         arguments.clear();
-        String test;
+        String argument;
         for (ClientArgument arg : args.getArguments()) {
             if (validateArgument(arg)) {
                 for (String value : args.getValues(arg)) {
                     if (arg.equals(ClientArgument.USER)) {
-                        test = String.format("%s=%s", arg.command(), value);
-                        arguments.add(test);
+                        argument = String.format("%s=%s", arg.command(), value);
+                        arguments.add(argument);
                     } else {
                         arguments.add(arg.command());
                         if (!value.isEmpty()) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/kafkaUtils/KafkaConnectS2IUtils.java
Patch:
@@ -25,7 +25,7 @@ private KafkaConnectS2IUtils() {}
      */
     public static void waitForConnectS2IStatus(String name, String status) {
         LOGGER.info("Waiting for Kafka Connect S2I {} state: {}", name, status);
-        TestUtils.waitFor("Test " + name, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("Kafka Connect S2I " + name + " state: " + status, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> Crds.kafkaConnectS2iOperation(kubeClient().getClient()).inNamespace(kubeClient().getNamespace()).withName(name).get().getStatus().getConditions().get(0).getType().equals(status));
         LOGGER.info("Kafka Connect S2I {} is in desired state: {}", name, status);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -213,7 +213,7 @@ void testJvmAndResources() {
         Map<String, String> jvmOptionsXX = new HashMap<>();
         jvmOptionsXX.put("UseG1GC", "true");
 
-        KafkaConnectS2I kafkaConnectS2i = KafkaConnectS2IResource.kafkaConnectS2IWithoutWait(KafkaConnectS2IResource.kafkaConnectS2I(kafkaConnectS2IName, CLUSTER_NAME, 1)
+        KafkaConnectS2I kafkaConnectS2i = KafkaConnectS2IResource.kafkaConnectS2IWithoutWait(KafkaConnectS2IResource.defaultKafkaConnectS2I(kafkaConnectS2IName, CLUSTER_NAME, 1)
             .editMetadata()
                 .addToLabels("type", "kafka-connect")
             .endMetadata()
@@ -236,7 +236,7 @@ void testJvmAndResources() {
                     .withServer(true)
                     .withXx(jvmOptionsXX)
                 .endJvmOptions()
-            .endSpec().done());
+            .endSpec().build());
 
         KafkaConnectS2IUtils.waitForConnectS2IStatus(kafkaConnectS2IName, "NotReady");
 
@@ -254,7 +254,7 @@ void testJvmAndResources() {
                     .build());
         });
 
-        TestUtils.waitFor("Test", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
+        TestUtils.waitFor("Kafka Connect CR change", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> kubeClient().getClient().adapt(OpenShiftClient.class).buildConfigs().inNamespace(NAMESPACE).withName(kafkaConnectS2IName + "-connect").get().getSpec().getResources().getRequests().get("cpu").equals(new Quantity("1")));
 
         cmdKubeClient().exec("oc", "start-build", KafkaConnectS2IResources.deploymentName(kafkaConnectS2IName), "-n", NAMESPACE);

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -950,11 +950,11 @@ void testTopicWithoutLabels() {
         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3).done();
 
         // Creating topic without any label
-        KafkaTopicResource.topic(CLUSTER_NAME, "topic-without-labels")
+        KafkaTopicResource.topicWithoutWait(KafkaTopicResource.defaultTopic(CLUSTER_NAME, "topic-without-labels", 1, 1, 1)
             .editMetadata()
                 .withLabels(null)
             .endMetadata()
-            .done();
+            .build());
 
         // Checking that resource was created
         assertThat(cmdKubeClient().list("kafkatopic"), hasItems("topic-without-labels"));
@@ -1192,6 +1192,7 @@ void verifyVolumeNamesAndLabels(int kafkaReplicas, int diskCountPerReplica, int
         ArrayList pvcs = new ArrayList();
 
         kubeClient().listPersistentVolumeClaims().stream()
+                .filter(pvc -> pvc.getMetadata().getName().contains("kafka"))
                 .forEach(volume -> {
                     String volumeName = volume.getMetadata().getName();
                     pvcs.add(volumeName);

File: systemtest/src/test/java/io/strimzi/systemtest/TopicST.java
Patch:
@@ -45,7 +45,8 @@ void testMoreReplicasThanAvailableBrokers() {
         int topicPartitions = 5;
 
         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3, 1).done();
-        KafkaTopic kafkaTopic =  KafkaTopicResource.topic(CLUSTER_NAME, topicName, topicPartitions, topicReplicationFactor).done();
+        KafkaTopic kafkaTopic =
+                KafkaTopicResource.topicWithoutWait(KafkaTopicResource.defaultTopic(CLUSTER_NAME, topicName, topicPartitions, topicReplicationFactor, 1).build());
 
         assertThat("Topic exists in Kafka CR (Kubernetes)", hasTopicInCRK8s(kafkaTopic, topicName));
         assertThat("Topic doesn't exists in Kafka itself", !hasTopicInKafka(topicName));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AuthenticationUtils.java
Patch:
@@ -168,6 +168,9 @@ public static void configureClientAuthenticationEnvVars(KafkaClientAuthenticatio
                 if (oauth.getClientId() != null) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_CLIENT_ID, oauth.getClientId()));
                 if (oauth.getTokenEndpointUri() != null) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_TOKEN_ENDPOINT_URI, oauth.getTokenEndpointUri()));
                 if (oauth.isDisableTlsHostnameVerification()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM, ""));
+                if (!oauth.isAccessTokenIsJwt()) options.add(String.format("%s=\"%s\"", ServerConfig.OAUTH_TOKENS_NOT_JWT, true));
+                if (oauth.getMaxTokenExpirySeconds() > 0) options.add(String.format("%s=\"%s\"", ClientConfig.OAUTH_MAX_TOKEN_EXPIRY_SECONDS, oauth.getMaxTokenExpirySeconds()));
+
                 varList.add(AbstractModel.buildEnvVar(envVarNamer.apply("OAUTH_CONFIG"), String.join(" ", options)));
 
                 if (oauth.getClientSecret() != null)    {

File: operator-common/src/main/java/io/strimzi/operator/PlatformFeaturesAvailability.java
Patch:
@@ -55,9 +55,9 @@ public static Future<PlatformFeaturesAvailability> create(Vertx vertx, Kubernete
             return checkApiAvailability(vertx, httpClient, client.getMasterUrl().toString(), "image.openshift.io", "v1");
         }).compose(supported -> {
             pfa.setImages(supported);
-            pfaPromise.complete(pfa);
-            return pfaPromise.future();
-        });
+            return Future.succeededFuture(pfa);
+        })
+        .setHandler(pfaPromise);
 
         return pfaPromise.future();
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -47,7 +47,7 @@ public static KafkaConnectS2IBuilder defaultKafkaConnectS2I(KafkaConnectS2I kafk
             .endMetadata()
             .editSpec()
                 .withVersion(Environment.ST_KAFKA_VERSION)
-                .withBootstrapServers(KafkaResources.plainBootstrapAddress(name))
+                .withBootstrapServers(KafkaResources.tlsBootstrapAddress(kafkaClusterName))
                 .withReplicas(kafkaConnectReplicas)
                 // Try it without TLS
                 .withNewTls()

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -182,6 +182,7 @@ void setupEnvironment() {
 
     @Override
     protected void recreateTestEnv(String coNamespace, List<String> bindingsNamespaces) {
+        teardownEnvForOperator();
         deployTestSpecificResources();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -139,6 +139,6 @@ void setup() {
 
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        KubernetesResource.clusterOperator(NAMESPACE).done();
+        KubernetesResource.clusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_SHORT).done();
     }
 }

File: test/src/main/java/io/strimzi/test/k8s/KubeClusterResource.java
Patch:
@@ -95,6 +95,7 @@ private static void initNamespaces() {
     public void applyClusterOperatorInstallFiles() {
         timeMeasuringSystem.setTestName(testClass, testClass);
         timeMeasuringSystem.startOperation(Operation.CO_CREATION);
+        clusterOperatorConfigs.clear();
         Map<File, String> operatorFiles = Arrays.stream(new File(CO_INSTALL_DIR).listFiles()).sorted().filter(file ->
                 !file.getName().matches(".*(Binding|Deployment)-.*")
         ).collect(Collectors.toMap(file -> file, f -> TestUtils.getContent(f, TestUtils::toYamlString), (x, y) -> x, LinkedHashMap::new));
@@ -232,6 +233,7 @@ public void deleteNamespaces() {
             cmdKubeClient().waitForResourceDeletion("Namespace", namespace);
         }
         deploymentNamespaces.clear();
+        bindingsNamespaces = null;
         LOGGER.info("Using namespace {}", testNamespace);
         setNamespace(testNamespace);
     }

File: test/src/main/java/io/strimzi/test/k8s/cmdClient/KubeCmdClient.java
Patch:
@@ -73,7 +73,7 @@ default K delete(String... files) {
      */
     ExecResult execInPod(String pod, String... command);
 
-    List<String> execInCurrentNamespace(String... commands);
+    ExecResult execInCurrentNamespace(String... commands);
 
     /**
      * Execute the given {@code command} in the given {@code container} which is deployed in {@code pod}.

File: systemtest/src/main/java/io/strimzi/systemtest/interfaces/TestSeparator.java
Patch:
@@ -22,15 +22,15 @@ public interface TestSeparator {
 
     @BeforeEach
     default void beforeEachTest(TestInfo testInfo) {
-        TimeMeasuringSystem.setTestName(testInfo.getTestClass().get().getName(), testInfo.getTestMethod().get().getName());
-        TimeMeasuringSystem.startOperation(Operation.TEST_EXECUTION);
+        TimeMeasuringSystem.getInstance().setTestName(testInfo.getTestClass().get().getName(), testInfo.getTestMethod().get().getName());
+        TimeMeasuringSystem.getInstance().startOperation(Operation.TEST_EXECUTION);
         LOGGER.info(String.join("", Collections.nCopies(76, SEPARATOR_CHAR)));
         LOGGER.info(String.format("%s.%s-STARTED", testInfo.getTestClass().get().getName(), testInfo.getTestMethod().get().getName()));
     }
 
     @AfterEach
     default void afterEachTest(TestInfo testInfo) {
-        TimeMeasuringSystem.stopOperation(Operation.TEST_EXECUTION);
+        TimeMeasuringSystem.getInstance().stopOperation(Operation.TEST_EXECUTION);
         LOGGER.info(String.format("%s.%s-FINISHED", testInfo.getTestClass().get().getName(), testInfo.getTestMethod().get().getName()));
         LOGGER.info(String.join("", Collections.nCopies(76, SEPARATOR_CHAR)));
     }

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/api/ClientArgument.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.clients.api;
+package io.strimzi.systemtest.kafkaclients.api;
 
 /**
  * Enum with argument for external clients

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/api/ClientArgumentMap.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.clients.api;
+package io.strimzi.systemtest.kafkaclients.api;
 
 import java.util.ArrayList;
 import java.util.HashMap;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/api/ClientType.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.clients.api;
+package io.strimzi.systemtest.kafkaclients.api;
 
 public enum ClientType {
     CLI_KAFKA_VERIFIABLE_PRODUCER,

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/api/VerifiableClient.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.clients.api;
+package io.strimzi.systemtest.kafkaclients.api;
 
 import io.strimzi.test.executor.Exec;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/lib/ClientHandlerBase.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.clients.lib;
+package io.strimzi.systemtest.kafkaclients.lib;
 
 import io.vertx.core.AbstractVerticle;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/lib/Consumer.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.clients.lib;
+package io.strimzi.systemtest.kafkaclients.lib;
 
 import io.vertx.kafka.client.consumer.KafkaConsumer;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/lib/KafkaClient.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.clients.lib;
+package io.strimzi.systemtest.kafkaclients.lib;
 
 import io.vertx.core.Vertx;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/lib/KafkaClientProperties.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.clients.lib;
+package io.strimzi.systemtest.kafkaclients.lib;
 
 import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.LoadBalancerIngress;

File: systemtest/src/main/java/io/strimzi/systemtest/kafkaclients/lib/Producer.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.clients.lib;
+package io.strimzi.systemtest.kafkaclients.lib;
 
 import io.vertx.kafka.client.producer.KafkaProducer;
 import io.vertx.kafka.client.producer.KafkaProducerRecord;

File: systemtest/src/main/java/io/strimzi/systemtest/listeners/ExecutionListener.java
Patch:
@@ -13,6 +13,6 @@ public class ExecutionListener implements TestExecutionListener {
 
     @Override
     public void testPlanExecutionFinished(TestPlan testPlan) {
-        TimeMeasuringSystem.printAndSaveResults(Environment.TEST_LOG_DIR);
+        TimeMeasuringSystem.getInstance().printAndSaveResults(Environment.TEST_LOG_DIR);
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.status.Condition;
+import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
@@ -20,7 +21,7 @@
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 
-public abstract class AbstractNamespaceST extends AbstractST {
+public abstract class AbstractNamespaceST extends MessagingBaseST {
 
     private static final Logger LOGGER = LogManager.getLogger(AbstractNamespaceST.class);
 
@@ -68,7 +69,7 @@ void deployNewTopic(String topicNamespace, String kafkaClusterNamespace, String
         cmdKubeClient().create(new File(TOPIC_EXAMPLES_DIR));
         TestUtils.waitFor("wait for 'my-topic' to be created in Kafka", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_TOPIC_CREATION, () -> {
             cluster.setNamespace(kafkaClusterNamespace);
-            List<String> topics2 = listTopicsUsingPodCLI(CLUSTER_NAME, 0);
+            List<String> topics2 = KafkaCmdClient.listTopicsUsingPodCli(CLUSTER_NAME, 0);
             return topics2.contains(topic);
         });
     }

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -9,6 +9,7 @@
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.strimzi.api.kafka.model.KafkaConnectResources;
 import io.strimzi.api.kafka.model.status.Condition;
+import io.strimzi.systemtest.cli.KafkaCmdClient;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.SecretUtils;
 import org.apache.logging.log4j.LogManager;
@@ -47,7 +48,7 @@ class AllNamespaceST extends AbstractNamespaceST {
     void testTopicOperatorWatchingOtherNamespace() {
         LOGGER.info("Deploying TO to watch a different namespace that it is deployed in");
         String previousNamespace = cluster.setNamespace(THIRD_NAMESPACE);
-        List<String> topics = listTopicsUsingPodCLI(CLUSTER_NAME, 0);
+        List<String> topics = KafkaCmdClient.listTopicsUsingPodCli(CLUSTER_NAME, 0);
         assertThat(topics, not(hasItems(TOPIC_NAME)));
 
         deployNewTopic(SECOND_NAMESPACE, THIRD_NAMESPACE, TOPIC_NAME);

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -49,7 +49,7 @@
 
 @OpenShiftOnly
 @Tag(REGRESSION)
-class ConnectS2IST extends AbstractST {
+class ConnectS2IST extends MessagingBaseST {
 
     public static final String NAMESPACE = "connect-s2i-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(ConnectS2IST.class);
@@ -190,7 +190,7 @@ void testCustomAndUpdatedValues() {
         checkSpecificVariablesInContainer(connectPodName, KafkaConnectS2IResources.deploymentName(kafkaConnectS2IName), envVarGeneral);
 
         LOGGER.info("Updating values in ConnectS2I container");
-        replaceConnectS2IResource(kafkaConnectS2IName, kc -> {
+        KafkaConnectS2IResource.replaceConnectS2IResource(kafkaConnectS2IName, kc -> {
             kc.getSpec().getTemplate().getConnectContainer().setEnv(StUtils.createContainerEnvVarsFromMap(envVarUpdated));
         });
 
@@ -244,7 +244,7 @@ void testJvmAndResources() {
 
         kubeClient().getClient().adapt(OpenShiftClient.class).builds().inNamespace(NAMESPACE).withName(kafkaConnectS2IName + "-connect-1").cascading(true).delete();
 
-        replaceConnectS2IResource(kafkaConnectS2IName, kc -> {
+        KafkaConnectS2IResource.replaceConnectS2IResource(kafkaConnectS2IName, kc -> {
             kc.getSpec().setBuildResources(new ResourceRequirementsBuilder()
                     .addToLimits("memory", new Quantity("1000M"))
                     .addToLimits("cpu", new Quantity("1"))

File: systemtest/src/test/java/io/strimzi/systemtest/HelmChartST.java
Patch:
@@ -19,7 +19,7 @@
 import static io.strimzi.systemtest.Constants.HELM;
 
 @Tag(HELM)
-class HelmChartST extends AbstractST {
+class HelmChartST extends BaseST {
 
     private static final Logger LOGGER = LogManager.getLogger(HelmChartST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/MultipleNamespaceST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest;
 
+import io.strimzi.systemtest.cli.KafkaCmdClient;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
@@ -33,7 +34,7 @@ class MultipleNamespaceST extends AbstractNamespaceST {
     void testTopicOperatorWatchingOtherNamespace() {
         LOGGER.info("Deploying TO to watch a different namespace that it is deployed in");
         cluster.setNamespace(SECOND_NAMESPACE);
-        List<String> topics = listTopicsUsingPodCLI(CLUSTER_NAME, 0);
+        List<String> topics = KafkaCmdClient.listTopicsUsingPodCli(CLUSTER_NAME, 0);
         assertThat(topics, not(hasItems(TOPIC_NAME)));
 
         deployNewTopic(CO_NAMESPACE, SECOND_NAMESPACE, TOPIC_NAME);

File: systemtest/src/test/java/io/strimzi/systemtest/OpenShiftTemplatesST.java
Patch:
@@ -49,7 +49,7 @@
 @OpenShiftOnly
 @Tag(REGRESSION)
 @Tag(ACCEPTANCE)
-public class OpenShiftTemplatesST extends AbstractST {
+public class OpenShiftTemplatesST extends BaseST {
 
     private static final Logger LOGGER = LogManager.getLogger(OpenShiftTemplatesST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -801,7 +801,7 @@ void testTlsHostnameVerificationWithKafkaConnect() {
         assertThat("CrashLoopBackOff", is(kubeClient().getPod(kafkaConnectPodName).getStatus().getContainerStatuses()
                 .get(0).getState().getWaiting().getReason()));
 
-        replaceKafkaConnectResource(CLUSTER_NAME, kc -> {
+        KafkaConnectResource.replaceKafkaConnectResource(CLUSTER_NAME, kc -> {
             kc.getSpec().getConfig().put("ssl.endpoint.identification.algorithm", "");
         });
 
@@ -875,7 +875,7 @@ void testTlsHostnameVerificationWithMirrorMaker() {
         LOGGER.info("Mirror maker with config {} will connect to producer with address {}:9093", "ssl.endpoint.identification.algorithm", ipOfTargetBootstrapService);
 
         LOGGER.info("Adding configuration {} to the mirror maker...", "ssl.endpoint.identification.algorithm");
-        replaceMirrorMakerResource(CLUSTER_NAME, mm -> {
+        KafkaMirrorMakerResource.replaceMirrorMakerResource(CLUSTER_NAME, mm -> {
             mm.getSpec().getConsumer().getConfig().put("ssl.endpoint.identification.algorithm", ""); // disable hostname verification
             mm.getSpec().getProducer().getConfig().put("ssl.endpoint.identification.algorithm", ""); // disable hostname verification
         });

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -39,7 +39,7 @@
 import static org.valid4j.matchers.jsonpath.JsonPathMatchers.hasJsonPath;
 
 @Tag(REGRESSION)
-class UserST extends AbstractST {
+class UserST extends BaseST {
 
     public static final String NAMESPACE = "user-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(UserST.class);
@@ -115,7 +115,7 @@ void testUpdateUser() {
         long observedGeneration = KafkaUserResource.kafkaUserClient().inNamespace(kubeClient().getNamespace()).withName(kafkaUser).get().getStatus().getObservedGeneration();
         LOGGER.info("observation: {}", observedGeneration);
 
-        replaceUserResource(kafkaUser, ku -> {
+        KafkaUserResource.replaceUserResource(kafkaUser, ku -> {
             ku.getMetadata().setResourceVersion(null);
             ku.getSpec().setAuthentication(new KafkaUserScramSha512ClientAuthentication());
         });

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -170,10 +170,10 @@ void testCustomAndUpdatedValues() {
                 periodSeconds, successThreshold, failureThreshold);
         checkSpecificVariablesInContainer(KafkaBridgeResources.deploymentName(bridgeName), KafkaBridgeResources.deploymentName(bridgeName), envVarGeneral);
 
-        StUtils.checkCOlogForUsedVariable(usedVariable);
+        StUtils.checkCologForUsedVariable(usedVariable);
 
         LOGGER.info("Updating values in Bridge container");
-        replaceBridgeResource(bridgeName, kb -> {
+        KafkaBridgeResource.replaceBridgeResource(bridgeName, kb -> {
             kb.getSpec().getTemplate().getBridgeContainer().setEnv(StUtils.createContainerEnvVarsFromMap(envVarUpdated));
             kb.getSpec().getProducer().setConfig(producerConfig);
             kb.getSpec().getConsumer().setConfig(consumerConfig);

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -148,7 +148,7 @@ void testKafkaExporterDifferentSetting() throws InterruptedException, ExecutionE
 
         Map<String, String> kafkaExporterSnapshot = DeploymentUtils.depSnapshot(KafkaExporterResources.deploymentName(CLUSTER_NAME));
 
-        replaceKafkaResource(CLUSTER_NAME, k -> {
+        KafkaResource.replaceKafkaResource(CLUSTER_NAME, k -> {
             k.getSpec().getKafkaExporter().setGroupRegex("my-group.*");
             k.getSpec().getKafkaExporter().setTopicRegex(TEST_TOPIC_NAME);
         });

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/PrometheusST.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.systemtest.metrics;
 
-import io.strimzi.systemtest.AbstractST;
+import io.strimzi.systemtest.BaseST;
 import io.strimzi.systemtest.utils.FileUtils;
 import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils;
@@ -23,7 +23,7 @@
 import static org.hamcrest.MatcherAssert.assertThat;
 
 @Tag(PROMETHEUS)
-public class PrometheusST extends AbstractST {
+public class PrometheusST extends BaseST {
 
     private static final Logger LOGGER = LogManager.getLogger(PrometheusST.class);
 

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -11,8 +11,8 @@
 import io.restassured.path.json.JsonPath;
 import io.restassured.response.Response;
 import io.strimzi.api.kafka.model.KafkaResources;
-import io.strimzi.systemtest.AbstractST;
 import io.strimzi.systemtest.Constants;
+import io.strimzi.systemtest.MessagingBaseST;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaBridgeUtils;
 import io.strimzi.systemtest.utils.HttpUtils;
 import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
@@ -67,7 +67,7 @@
 @Tag(REGRESSION)
 @Tag(TRACING)
 @ExtendWith(VertxExtension.class)
-public class TracingST extends AbstractST {
+public class TracingST extends MessagingBaseST {
 
     private static final String NAMESPACE = "tracing-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(TracingST.class);

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicOperator.java
Patch:
@@ -352,8 +352,6 @@ public String toString() {
         }
     }
 
-    protected static final String KAFKA_TOPIC_OPERATOR_NAME = "strimzi-kafka-topic-operator";
-
     public TopicOperator(Vertx vertx, Kafka kafka,
                          K8s k8s,
                          TopicStore topicStore,

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorIT.java
Patch:
@@ -287,7 +287,7 @@ public void testKafkaTopicWithOwnerRef() throws InterruptedException, ExecutionE
         assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getOwnerReferences().get(0).getUid(), is(uid));
         assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getAnnotations().size(), is(1));
         assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getAnnotations().get("iam"), is("groot"));
-        assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().size(), is(5));
+        assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().size(), is(2));
         assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().get("iam"), is("root"));
 
         // edit kafka topic
@@ -309,7 +309,7 @@ public void testKafkaTopicWithOwnerRef() throws InterruptedException, ExecutionE
         topicResource = TopicSerialization.toTopicResource(topic3, labels);
         createKafkaTopicResource(topicResource);
         assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getOwnerReferences().get(0).getUid(), is(uid));
-        assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().size(), is(6));
+        assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().size(), is(3));
         assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().get("stan"), is("lee"));
         assertThat(operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().get("iam"), is("root"));
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperator.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.operator.common.model.Labels;
 import io.vertx.core.Future;
+import io.vertx.core.Promise;
 import io.vertx.core.Vertx;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -89,7 +90,8 @@ public Future<Void> maybeRollingUpdate(StatefulSet sts, Predicate<Pod> podRestar
         final Future<Void> rollFuture;
         if (zkRoll) {
             // Find the leader
-            rollFuture = Future.future();
+            Promise<Void> promise = Promise.promise();
+            rollFuture = promise.future();
             Future<Integer> leaderFuture = leaderFinder.findZookeeperLeader(cluster, namespace, pods, coKeySecret);
             leaderFuture.compose(leader -> {
                 log.debug("Zookeeper leader is " + (leader == ZookeeperLeaderFinder.UNKNOWN_LEADER ? "unknown" : "pod " + leader));

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/PodOperator.java
Patch:
@@ -13,6 +13,7 @@
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.PodResource;
 import io.vertx.core.Future;
+import io.vertx.core.Promise;
 import io.vertx.core.Vertx;
 
 /**
@@ -60,7 +61,7 @@ public Future<Void> restart(String logContext, Pod pod, long timeoutMs) {
         long pollingIntervalMs = 1_000;
         String namespace = pod.getMetadata().getNamespace();
         String podName = pod.getMetadata().getName();
-        Future<Void> deleteFinished = Future.future();
+        Promise<Void> deleteFinished = Promise.promise();
         log.info("{}: Rolling pod {}", logContext, podName);
 
         // Determine generation of deleted pod
@@ -88,7 +89,7 @@ public Future<Void> restart(String logContext, Pod pod, long timeoutMs) {
             }
             deleteFinished.handle(deleteResult);
         });
-        return deleteFinished;
+        return deleteFinished.future();
     }
 
     private static String getPodUid(Pod resource) {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractResourceOperatorTest.java
Patch:
@@ -195,8 +195,8 @@ public void creationThrows(VertxTestContext context) {
 
         Checkpoint async = context.checkpoint();
         op.createOrUpdate(resource).setHandler(ar -> {
-            assertThat(ar.failed(), is(true));
-            assertThat(ar.cause(), is(ex));
+            context.verify(() -> assertThat(ar.failed(), is(true)));
+            context.verify(() -> assertThat(ar.cause(), is(ex)));
             async.flag();
         });
     }

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaBridgeCrdIT.java
Patch:
@@ -27,7 +27,7 @@ public class KafkaBridgeCrdIT extends AbstractCrdIT {
     public static final String NAMESPACE = "kafkabridge-crd-it";
 
     @Test
-    void testKafkaMirrorMakerV1alpha1() {
+    void testKafkaBridgeV1alpha1() {
         assumeKube1_11Plus();
         createDelete(KafkaBridge.class, "KafkaBridgeV1alpha1.yaml");
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalIngress.java
Patch:
@@ -71,7 +71,7 @@ public void setNetworkPolicyPeers(List<NetworkPolicyPeer> networkPolicyPeers) {
         this.networkPolicyPeers = networkPolicyPeers;
     }
 
-    @Description("Overrides for external bootstrap and broker services and externally advertised addresses")
+    @Description("External listener configuration")
     public IngressListenerConfiguration getConfiguration() {
         return configuration;
     }

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java
Patch:
@@ -132,6 +132,8 @@ void testProducerConsumerConnect() {
 
         String kafkaConnectPodName = kubeClient().listPods("type", "kafka-connect").get(0).getMetadata().getName();
 
+        KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
+
         KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME);
 
         String message = "Hello world - " + END_MESSAGE_OFFSET;

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -139,6 +139,8 @@ void testProducerConsumerConnect() {
 
         String kafkaConnectPodName = kubeClient().listPods("type", "kafka-connect").get(0).getMetadata().getName();
 
+        KafkaConnectUtils.waitUntilKafkaConnectRestApiIsAvailable(kafkaConnectPodName);
+
         KafkaConnectUtils.createFileSinkConnector(kafkaConnectPodName, TOPIC_NAME);
 
         String message = "Hello world - " + END_MESSAGE_OFFSET;

File: operator-common/src/main/java/io/strimzi/operator/common/OperatorWatcher.java
Patch:
@@ -31,6 +31,7 @@ class OperatorWatcher<T extends HasMetadata> implements Watcher<T> {
     @Override
     public void eventReceived(Action action, T resource) {
         String name = resource.getMetadata().getName();
+        String namespace = resource.getMetadata().getNamespace();
         switch (action) {
             case ADDED:
             case DELETED:

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -373,6 +373,7 @@ public static Kafka createKafkaCluster(String clusterCmNamespace, String cluster
         if (metricsCm != null) {
             kafkaClusterSpec.setMetrics(metricsCm);
         }
+
         if (kafkaConfiguration != null) {
             kafkaClusterSpec.setConfig(kafkaConfiguration);
         }

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -159,7 +159,7 @@ void testUserWithQuotas() {
 
         // Create user with correct name
         KafkaUserResource.userWithQuota(CLUSTER_NAME, userName, prodRate, consRate, reqPerc).done();
-        StUtils.waitForSecretReady(userName);
+        SecretUtils.waitForSecretReady(userName);
 
         String messageUserWasAdded = "User " + userName + " in namespace " + NAMESPACE + " was ADDED";
 

File: user-operator/src/main/java/io/strimzi/operator/user/Main.java
Patch:
@@ -15,6 +15,7 @@
 import io.strimzi.operator.common.operator.resource.CrdOperator;
 import io.strimzi.operator.common.operator.resource.SecretOperator;
 import io.strimzi.operator.user.operator.KafkaUserOperator;
+import io.strimzi.operator.user.operator.KafkaUserQuotasOperator;
 import io.strimzi.operator.user.operator.ScramShaCredentials;
 import io.strimzi.operator.user.operator.ScramShaCredentialsOperator;
 import io.strimzi.operator.user.operator.SimpleAclOperator;
@@ -63,11 +64,12 @@ static Future<String> run(Vertx vertx, KubernetesClient client, SimpleAclAuthori
         SimpleAclOperator aclOperations = new SimpleAclOperator(vertx, authorizer);
         ScramShaCredentials scramShaCredentials = new ScramShaCredentials(config.getZookeperConnect(), (int) config.getZookeeperSessionTimeoutMs());
         ScramShaCredentialsOperator scramShaCredentialsOperator = new ScramShaCredentialsOperator(vertx, scramShaCredentials);
+        KafkaUserQuotasOperator quotasOperator = new KafkaUserQuotasOperator(vertx, config.getZookeperConnect(), (int) config.getZookeeperSessionTimeoutMs());
 
         KafkaUserOperator kafkaUserOperations = new KafkaUserOperator(vertx,
                 certManager, crdOperations,
                 config.getLabels(),
-                secretOperations, scramShaCredentialsOperator, aclOperations, config.getCaCertSecretName(), config.getCaKeySecretName(), config.getCaNamespace());
+                secretOperations, scramShaCredentialsOperator, quotasOperator, aclOperations, config.getCaCertSecretName(), config.getCaKeySecretName(), config.getCaNamespace());
 
         Future<String> fut = Future.future();
         UserOperator operator = new UserOperator(config.getNamespace(),

File: user-operator/src/main/java/io/strimzi/operator/user/operator/ScramShaCredentials.java
Patch:
@@ -23,7 +23,7 @@
  * Utility class for managing Scram credentials
  */
 public class ScramShaCredentials {
-    private static final Logger log = LogManager.getLogger(SimpleAclOperator.class.getName());
+    private static final Logger log = LogManager.getLogger(ScramShaCredentials.class.getName());
 
     private final static int ITERATIONS = 4096;
     private final static int CONNECTION_TIMEOUT = 30_000;

File: systemtest/src/main/java/io/strimzi/systemtest/logs/LogCollector.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.utils;
+package io.strimzi.systemtest.logs;
 
 import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.strimzi.test.k8s.KubeClient;

File: systemtest/src/main/java/io/strimzi/systemtest/logs/TestExecutionWatcher.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest.utils;
+package io.strimzi.systemtest.logs;
 
 import io.strimzi.systemtest.Environment;
 import org.apache.logging.log4j.LogManager;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -22,6 +22,7 @@
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
 import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -298,7 +299,7 @@ private static ClusterRoleBinding getClusterRoleBindingFromYaml(String yamlPath)
 
     private static Deployment waitFor(Deployment deployment) {
         LOGGER.info("Waiting for deployment {}", deployment.getMetadata().getName());
-        StUtils.waitForDeploymentReady(deployment.getMetadata().getName(), deployment.getSpec().getReplicas());
+        DeploymentUtils.waitForDeploymentReady(deployment.getMetadata().getName(), deployment.getSpec().getReplicas());
         LOGGER.info("Deployment {} is ready", deployment.getMetadata().getName());
         return deployment;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -13,7 +13,7 @@
 import io.strimzi.api.kafka.model.KafkaBridge;
 import io.strimzi.api.kafka.model.KafkaBridgeBuilder;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -85,7 +85,7 @@ private static KafkaBridge getKafkaBridgeFromYaml(String yamlPath) {
 
     private static KafkaBridge waitFor(KafkaBridge kafkaBridge) {
         LOGGER.info("Waiting for Kafka Bridge {}", kafkaBridge.getMetadata().getName());
-        StUtils.waitForDeploymentReady(kafkaBridge.getMetadata().getName() + "-bridge", kafkaBridge.getSpec().getReplicas());
+        DeploymentUtils.waitForDeploymentReady(kafkaBridge.getMetadata().getName() + "-bridge", kafkaBridge.getSpec().getReplicas());
         LOGGER.info("Kafka Bridge {} is ready", kafkaBridge.getMetadata().getName());
         return kafkaBridge;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -98,7 +98,7 @@ private static KafkaConnect getKafkaConnectFromYaml(String yamlPath) {
 
     private static KafkaConnect waitFor(KafkaConnect kafkaConnect) {
         LOGGER.info("Waiting for Kafka Connect {}", kafkaConnect.getMetadata().getName());
-        StUtils.waitForDeploymentReady(kafkaConnect.getMetadata().getName() + "-connect", kafkaConnect.getSpec().getReplicas());
+        DeploymentUtils.waitForDeploymentReady(kafkaConnect.getMetadata().getName() + "-connect", kafkaConnect.getSpec().getReplicas());
         LOGGER.info("Kafka Connect {} is ready", kafkaConnect.getMetadata().getName());
         return kafkaConnect;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -16,7 +16,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectS2IUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -90,7 +90,7 @@ private static KafkaConnectS2I getKafkaConnectS2IFromYaml(String yamlPath) {
 
     private static KafkaConnectS2I waitFor(KafkaConnectS2I kafkaConnectS2I) {
         LOGGER.info("Waiting for Kafka ConnectS2I {}", kafkaConnectS2I.getMetadata().getName());
-        StUtils.waitForConnectS2IStatus(kafkaConnectS2I.getMetadata().getName(), "Ready");
+        KafkaConnectS2IUtils.waitForConnectS2IStatus(kafkaConnectS2I.getMetadata().getName(), "Ready");
         LOGGER.info("Kafka ConnectS2I {} is ready", kafkaConnectS2I.getMetadata().getName());
         return kafkaConnectS2I;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -13,7 +13,7 @@
 import io.strimzi.api.kafka.model.KafkaConnector;
 import io.strimzi.api.kafka.model.KafkaConnectorBuilder;
 import io.strimzi.systemtest.Constants;
-import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaConnectUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -80,7 +80,7 @@ private static KafkaConnector getKafkaConnectorFromYaml(String yamlPath) {
 
     private static KafkaConnector waitFor(KafkaConnector kafkaConnector) {
         LOGGER.info("Waiting for Kafka Connector {}", kafkaConnector.getMetadata().getName());
-        StUtils.waitForConnectorReady(kafkaConnector.getMetadata().getName());
+        KafkaConnectUtils.waitForConnectorReady(kafkaConnector.getMetadata().getName());
         LOGGER.info("Kafka Connector {} is ready", kafkaConnector.getMetadata().getName());
         return kafkaConnector;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -15,7 +15,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.Environment;
-import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.kafka.clients.consumer.ConsumerConfig;
 import org.apache.kafka.clients.producer.ProducerConfig;
@@ -100,7 +100,7 @@ private static KafkaMirrorMaker getKafkaMirrorMakerFromYaml(String yamlPath) {
 
     private static KafkaMirrorMaker waitFor(KafkaMirrorMaker kafkaMirrorMaker) {
         LOGGER.info("Waiting for Kafka MirrorMaker {}", kafkaMirrorMaker.getMetadata().getName());
-        StUtils.waitForDeploymentReady(kafkaMirrorMaker.getMetadata().getName() + "-mirror-maker", kafkaMirrorMaker.getSpec().getReplicas());
+        DeploymentUtils.waitForDeploymentReady(kafkaMirrorMaker.getMetadata().getName() + "-mirror-maker", kafkaMirrorMaker.getSpec().getReplicas());
         LOGGER.info("Kafka MirrorMaker {} is ready", kafkaMirrorMaker.getMetadata().getName());
         return kafkaMirrorMaker;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaTopicResource.java
Patch:
@@ -11,7 +11,7 @@
 import io.strimzi.api.kafka.model.DoneableKafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopicBuilder;
-import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kafkaUtils.KafkaTopicUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -67,7 +67,7 @@ private static KafkaTopic getKafkaTopicFromYaml(String yamlPath) {
 
     private static KafkaTopic waitFor(KafkaTopic kafkaTopic) {
         LOGGER.info("Waiting for Kafka Topic {}", kafkaTopic.getMetadata().getName());
-        StUtils.waitForKafkaTopicCreation(kafkaTopic.getMetadata().getName());
+        KafkaTopicUtils.waitForKafkaTopicCreation(kafkaTopic.getMetadata().getName());
         LOGGER.info("Kafka Topic {} is ready", kafkaTopic.getMetadata().getName());
         return kafkaTopic;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaUserResource.java
Patch:
@@ -11,7 +11,7 @@
 import io.strimzi.api.kafka.model.DoneableKafkaUser;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.api.kafka.model.KafkaUserBuilder;
-import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kubeUtils.objects.SecretUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -69,7 +69,7 @@ private static KafkaUser getKafkaUserFromYaml(String yamlPath) {
 
     private static KafkaUser waitFor(KafkaUser kafkaUser) {
         LOGGER.info("Waiting for Kafka User {}", kafkaUser.getMetadata().getName());
-        StUtils.waitForSecretReady(kafkaUser.getMetadata().getName());
+        SecretUtils.waitForSecretReady(kafkaUser.getMetadata().getName());
         LOGGER.info("Kafka User {} is ready", kafkaUser.getMetadata().getName());
         return kafkaUser;
     }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -6,7 +6,7 @@
 
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.status.Condition;
-import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kubeUtils.controllers.DeploymentUtils;
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -58,7 +58,7 @@ void checkMirrorMakerForKafkaInDifNamespaceThanCO(String sourceClusterName) {
         KafkaMirrorMakerResource.kafkaMirrorMaker(CLUSTER_NAME, kafkaSourceName, kafkaTargetName, "my-group", 1, false).done();
 
         LOGGER.info("Waiting for creation {} in namespace {}", CLUSTER_NAME + "-mirror-maker", SECOND_NAMESPACE);
-        StUtils.waitForDeploymentReady(CLUSTER_NAME + "-mirror-maker", 1);
+        DeploymentUtils.waitForDeploymentReady(CLUSTER_NAME + "-mirror-maker", 1);
         cluster.setNamespace(previousNamespace);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -39,7 +39,7 @@
 import io.strimzi.api.kafka.model.status.Condition;
 import io.strimzi.systemtest.clients.lib.KafkaClient;
 import io.strimzi.systemtest.interfaces.TestSeparator;
-import io.strimzi.systemtest.utils.TestExecutionWatcher;
+import io.strimzi.systemtest.logs.TestExecutionWatcher;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.k8s.HelmClient;
 import io.strimzi.test.k8s.exceptions.KubeClusterException;
@@ -581,7 +581,7 @@ void verifyLabelsForRoleBindings(String clusterName, String appName) {
 
     /**
      * Wait till all pods in specific namespace being deleted and recreate testing environment in case of some pods cannot be deleted.
-     * This method is {@Deprecated} and it should be removed in the future. Instead of use this method, you should use method {@link io.strimzi.systemtest.utils.StUtils#waitForPodDeletion(String)}
+     * This method is {@Deprecated} and it should be removed in the future. Instead of use this method, you should use method {@link io.strimzi.systemtest.utils.kubeUtils.objects.PodUtils#waitForPodDeletion(String)}
      * which should be used by default in deletion process for all components (it force pod deletion via executor instead of fabric8 client, which seems to be unstable).
      * @param time timeout in miliseconds
      * @throws Exception exception

File: systemtest/src/test/java/io/strimzi/systemtest/HelmChartST.java
Patch:
@@ -5,7 +5,7 @@
 package io.strimzi.systemtest;
 
 import io.strimzi.api.kafka.model.KafkaResources;
-import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kubeUtils.controllers.StatefulSetUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
@@ -31,8 +31,8 @@ class HelmChartST extends AbstractST {
     void testDeployKafkaClusterViaHelmChart() {
         KafkaResource.kafkaEphemeral(CLUSTER_NAME, 3).done();
         KafkaTopicResource.topic(CLUSTER_NAME, TOPIC_NAME).done();
-        StUtils.waitForAllStatefulSetPodsReady(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME), 3);
-        StUtils.waitForAllStatefulSetPodsReady(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3);
+        StatefulSetUtils.waitForAllStatefulSetPodsReady(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME), 3);
+        StatefulSetUtils.waitForAllStatefulSetPodsReady(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3);
     }
 
     @BeforeAll

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeBaseST.java
Patch:
@@ -7,7 +7,7 @@
 import io.fabric8.kubernetes.api.model.Service;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.MessagingBaseST;
-import io.strimzi.systemtest.utils.StUtils;
+import io.strimzi.systemtest.utils.kubeUtils.objects.ServiceUtils;
 import io.vertx.core.Vertx;
 import io.vertx.core.json.JsonArray;
 import io.vertx.core.json.JsonObject;
@@ -102,7 +102,7 @@ protected void deployBridgeNodePortService() throws InterruptedException {
                 .withSelector(map)
                 .endSpec().build();
         KubernetesResource.createServiceResource(service, getBridgeNamespace()).done();
-        StUtils.waitForNodePortService(bridgeExternalService);
+        ServiceUtils.waitForNodePortService(bridgeExternalService);
     }
 
     protected void checkSendResponse(JsonObject response, int messageCount) {

File: systemtest/src/main/java/io/strimzi/systemtest/BaseST.java
Patch:
@@ -6,8 +6,8 @@
 
 import io.strimzi.test.k8s.KubeClusterResource;
 import org.junit.jupiter.api.TestInstance;
-import resources.KubernetesResource;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.KubernetesResource;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 import java.util.Arrays;
 import java.util.Collections;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/KubernetesResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources;
+package io.strimzi.systemtest.resources;
 
 import io.fabric8.kubernetes.api.model.DoneableService;
 import io.fabric8.kubernetes.api.model.EnvVar;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/ResourceManager.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources;
+package io.strimzi.systemtest.resources;
 
 import io.fabric8.kubernetes.api.model.EnvVar;
 import io.fabric8.kubernetes.api.model.HasMetadata;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaBridgeResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources.crd;
+package io.strimzi.systemtest.resources.crd;
 
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
@@ -17,7 +17,7 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 public class KafkaBridgeResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaBridgeResource.class);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaClientsResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources.crd;
+package io.strimzi.systemtest.resources.crd;
 
 import io.fabric8.kubernetes.api.model.ContainerBuilder;
 import io.fabric8.kubernetes.api.model.ContainerPortBuilder;
@@ -19,8 +19,8 @@
 import org.apache.kafka.clients.consumer.ConsumerConfig;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.KubernetesResource;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.KubernetesResource;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 import java.nio.charset.Charset;
 import java.util.Base64;

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources.crd;
+package io.strimzi.systemtest.resources.crd;
 
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
@@ -19,7 +19,7 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 public class KafkaConnectResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaConnectResource.class);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectS2IResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources.crd;
+package io.strimzi.systemtest.resources.crd;
 
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
@@ -20,7 +20,7 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 public class KafkaConnectS2IResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaConnectS2IResource.class);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaConnectorResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources.crd;
+package io.strimzi.systemtest.resources.crd;
 
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
@@ -17,7 +17,7 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 public class KafkaConnectorResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaConnectorResource.class);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaMirrorMakerResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources.crd;
+package io.strimzi.systemtest.resources.crd;
 
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
@@ -21,7 +21,7 @@
 import org.apache.kafka.clients.producer.ProducerConfig;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 public class KafkaMirrorMakerResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaMirrorMakerResource.class);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources.crd;
+package io.strimzi.systemtest.resources.crd;
 
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
@@ -20,7 +20,7 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 public class KafkaResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaResource.class);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaTopicResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources.crd;
+package io.strimzi.systemtest.resources.crd;
 
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -15,7 +15,7 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 public class KafkaTopicResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaTopicResource.class);

File: systemtest/src/main/java/io/strimzi/systemtest/resources/crd/KafkaUserResource.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package resources.crd;
+package io.strimzi.systemtest.resources.crd;
 
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -15,7 +15,7 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 public class KafkaUserResource {
     private static final Logger LOGGER = LogManager.getLogger(KafkaUserResource.class);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/BridgeUtils.java
Patch:
@@ -10,7 +10,7 @@
 import io.vertx.core.json.JsonObject;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.KubernetesResource;
+import io.strimzi.systemtest.resources.KubernetesResource;
 
 import java.util.HashMap;
 import java.util.Map;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -26,7 +26,7 @@
 import io.strimzi.test.timemeasuring.TimeMeasuringSystem;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.crd.KafkaUserResource;
+import io.strimzi.systemtest.resources.crd.KafkaUserResource;
 
 import java.io.BufferedReader;
 import java.io.File;

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -10,8 +10,8 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import resources.crd.KafkaMirrorMakerResource;
-import resources.crd.KafkaResource;
+import io.strimzi.systemtest.resources.crd.KafkaMirrorMakerResource;
+import io.strimzi.systemtest.resources.crd.KafkaResource;
 
 import java.io.File;
 import java.util.List;

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -54,7 +54,7 @@
 import org.junit.jupiter.api.TestInfo;
 import org.junit.jupiter.api.extension.ExtendWith;
 import org.junit.jupiter.api.extension.ExtensionContext;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 import java.io.File;
 import java.io.IOException;

File: systemtest/src/test/java/io/strimzi/systemtest/HelmChartST.java
Patch:
@@ -11,8 +11,8 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.Test;
-import resources.crd.KafkaResource;
-import resources.crd.KafkaTopicResource;
+import io.strimzi.systemtest.resources.crd.KafkaResource;
+import io.strimzi.systemtest.resources.crd.KafkaTopicResource;
 
 import java.util.List;
 

File: systemtest/src/test/java/io/strimzi/systemtest/MultipleNamespaceST.java
Patch:
@@ -9,9 +9,9 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.Test;
-import resources.KubernetesResource;
-import resources.ResourceManager;
-import resources.crd.KafkaResource;
+import io.strimzi.systemtest.resources.KubernetesResource;
+import io.strimzi.systemtest.resources.ResourceManager;
+import io.strimzi.systemtest.resources.crd.KafkaResource;
 
 import java.util.Arrays;
 import java.util.List;

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -15,9 +15,9 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.Test;
-import resources.KubernetesResource;
-import resources.ResourceManager;
-import resources.crd.KafkaResource;
+import io.strimzi.systemtest.resources.KubernetesResource;
+import io.strimzi.systemtest.resources.ResourceManager;
+import io.strimzi.systemtest.resources.crd.KafkaResource;
 
 import java.util.List;
 import java.util.Map;

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeBaseST.java
Patch:
@@ -18,8 +18,8 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.BeforeAll;
-import resources.KubernetesResource;
-import resources.ResourceManager;
+import io.strimzi.systemtest.resources.KubernetesResource;
+import io.strimzi.systemtest.resources.ResourceManager;
 
 import java.util.HashMap;
 import java.util.List;

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -18,9 +18,9 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Tag;
 import org.junit.jupiter.api.Test;
-import resources.KubernetesResource;
-import resources.ResourceManager;
-import resources.crd.KafkaResource;
+import io.strimzi.systemtest.resources.KubernetesResource;
+import io.strimzi.systemtest.resources.ResourceManager;
+import io.strimzi.systemtest.resources.crd.KafkaResource;
 
 import java.util.List;
 

File: systemtest/src/main/java/io/strimzi/systemtest/listeners/ExecutionListener.java
Patch:
@@ -4,16 +4,15 @@
  */
 package io.strimzi.systemtest.listeners;
 
+import io.strimzi.systemtest.Environment;
 import io.strimzi.test.timemeasuring.TimeMeasuringSystem;
 import org.junit.platform.launcher.TestExecutionListener;
 import org.junit.platform.launcher.TestPlan;
 
-import static io.strimzi.systemtest.AbstractST.TEST_LOG_DIR;
-
 public class ExecutionListener implements TestExecutionListener {
 
     @Override
     public void testPlanExecutionFinished(TestPlan testPlan) {
-        TimeMeasuringSystem.printAndSaveResults(TEST_LOG_DIR);
+        TimeMeasuringSystem.printAndSaveResults(Environment.TEST_LOG_DIR);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/LogHasNoUnexpectedErrors.java
Patch:
@@ -68,9 +68,6 @@ enum LogWhiteList {
         CAUGHT_EXCEPTION_FOR_NETWORK_POLICY("Caught exception while patching NetworkPolicy"
                 + "(?s)(.*?)"
                 + "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: PATCH"),
-        // fabric8 now throws exceptions, which doesn't influence kafka scaleup/scaledown
-        FABRIC_EIGHT_SCALEUP_ERROR("ERROR StatefulSetOperationsImpl:[0-9]+ - Error while waiting for resource to be scaled."),
-        FABRIC_EIGHT_STATEFUL_SET_SCALEUP_ERROR("ERROR StatefulSetOperationsImpl:[0-9]+ - 0/.* pod(s).*after waiting for 0 seconds so giving up"),
         // This happen from time to time during CO startup, it doesn't influence CO behavior
         EXIT_ON_OUT_OF_MEMORY("ExitOnOutOfMemoryError"),
         OPERATION_TIMEOUT("Util:[0-9]+ - Exceeded timeout of.*while waiting for.*"),

File: systemtest/src/main/java/io/strimzi/systemtest/utils/BridgeUtils.java
Patch:
@@ -10,11 +10,11 @@
 import io.vertx.core.json.JsonObject;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
+import resources.KubernetesResource;
 
 import java.util.HashMap;
 import java.util.Map;
 
-import static io.strimzi.systemtest.Resources.getSystemtestsServiceResource;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -39,7 +39,7 @@ public static Service createBridgeNodePortService(String clusterName, String nam
         map.put("strimzi.io/name", clusterName + "-bridge");
 
         // Create node port service for expose bridge outside Kubernetes
-        return getSystemtestsServiceResource(serviceName, Constants.HTTP_BRIDGE_DEFAULT_PORT, namespace)
+        return KubernetesResource.getSystemtestsServiceResource(serviceName, Constants.HTTP_BRIDGE_DEFAULT_PORT, namespace)
                     .editSpec()
                         .withType("NodePort")
                         .withSelector(map)

File: systemtest/src/test/java/io/strimzi/systemtest/StrimziUpgradeST.java
Patch:
@@ -132,7 +132,7 @@ void upgradeStrimziVersion(JsonObject parameters) throws Exception {
         } finally {
             // Get current date to create a unique folder
             String currentDate = new SimpleDateFormat("yyyyMMdd_HHmmss").format(Calendar.getInstance().getTime());
-            String logDir = TEST_LOG_DIR + testClass + currentDate;
+            String logDir = Environment.TEST_LOG_DIR + testClass + currentDate;
 
             LogCollector logCollector = new LogCollector(kubeClient(), new File(logDir));
             logCollector.collectEvents();

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/PrometheusST.java
Patch:
@@ -70,11 +70,10 @@ public void testSecretsCreated() {
     protected void recreateTestEnv(String coNamespace, List<String> bindingsNamespaces) { }
 
     @BeforeAll
-    void setupEnvironment() {
+    void setup() {
         LOGGER.info("Creating resources before the test class");
         prepareEnvForOperator(NAMESPACE);
 
-        createTestClassResources();
         cmdKubeClient().apply(StUtils.downloadYamlAndReplaceNameSpace("https://raw.githubusercontent.com/coreos/prometheus-operator/master/bundle.yaml", NAMESPACE));
 
         StUtils.createSecretFromFile("../metrics/examples/prometheus/additional-properties/prometheus-additional.yaml", "prometheus-additional.yaml", "additional-scrape-configs", NAMESPACE);

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -33,6 +33,7 @@
 import static io.strimzi.systemtest.Constants.BRIDGE;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -43,7 +44,6 @@
 @ExtendWith(VertxExtension.class)
 class HttpBridgeScramShaST extends HttpBridgeBaseST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);
-    private static final String NAMESPACE = "bridge-cluster-test-scram-sha";
 
     private String bridgeHost = "";
     private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -31,6 +31,7 @@
 import static io.strimzi.systemtest.Constants.BRIDGE;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.systemtest.bridge.HttpBridgeST.NAMESPACE;
 import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -41,7 +42,6 @@
 @ExtendWith(VertxExtension.class)
 class HttpBridgeTlsST extends HttpBridgeBaseST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeTlsST.class);
-    private static final String NAMESPACE = "bridge-cluster-test-tls";
 
     private String bridgeHost = "";
     private int bridgePort = Constants.HTTP_BRIDGE_DEFAULT_PORT;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/MainIT.java
Patch:
@@ -7,8 +7,8 @@
 import io.fabric8.kubernetes.client.DefaultKubernetesClient;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.operator.common.operator.resource.ClusterRoleOperator;
-import io.strimzi.test.k8s.KubeCluster;
-import io.strimzi.test.k8s.NoClusterException;
+import io.strimzi.test.k8s.cluster.KubeCluster;
+import io.strimzi.test.k8s.exceptions.NoClusterException;
 import io.vertx.core.Vertx;
 import io.vertx.junit5.Checkpoint;
 import io.vertx.junit5.VertxExtension;

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractNonNamespacedResourceOperatorIT.java
Patch:
@@ -9,8 +9,8 @@
 import io.fabric8.kubernetes.client.DefaultKubernetesClient;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.Resource;
-import io.strimzi.test.k8s.KubeCluster;
-import io.strimzi.test.k8s.NoClusterException;
+import io.strimzi.test.k8s.cluster.KubeCluster;
+import io.strimzi.test.k8s.exceptions.NoClusterException;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
 import io.vertx.junit5.Checkpoint;

File: systemtest/src/main/java/io/strimzi/systemtest/MessagingBaseST.java
Patch:
@@ -16,6 +16,7 @@
 
 import static io.strimzi.systemtest.clients.api.ClientType.CLI_KAFKA_VERIFIABLE_CONSUMER;
 import static io.strimzi.systemtest.clients.api.ClientType.CLI_KAFKA_VERIFIABLE_PRODUCER;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
 
 /**

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -1049,6 +1049,7 @@ private DoneableRoleBinding roleBinding(RoleBinding roleBinding, String clientNa
     }
 
     DoneableClusterRoleBinding clusterRoleBinding(String yamlPath, String namespace, String clientNamespace) {
+        LOGGER.info("CLUSTER ROLE BINDING in namespace {}", namespace);
         return clusterRoleBinding(defaultClusterRoleBinding(yamlPath, namespace).build(), clientNamespace);
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/annotations/OpenShiftOnlyCondition.java
Patch:
@@ -5,8 +5,8 @@
 package io.strimzi.systemtest.annotations;
 
 import io.strimzi.test.k8s.KubeClusterResource;
-import io.strimzi.test.k8s.Minishift;
-import io.strimzi.test.k8s.OpenShift;
+import io.strimzi.test.k8s.cluster.Minishift;
+import io.strimzi.test.k8s.cluster.OpenShift;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 import org.junit.jupiter.api.extension.ConditionEvaluationResult;

File: systemtest/src/main/java/io/strimzi/systemtest/clients/api/VerifiableClient.java
Patch:
@@ -15,7 +15,7 @@
 import java.util.Objects;
 import java.util.concurrent.ExecutionException;
 
-import static io.strimzi.test.BaseITST.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 
 /**
  * Class represent verifiable kafka client which keeps common features of kafka clients

File: systemtest/src/main/java/io/strimzi/systemtest/clients/lib/KafkaClientProperties.java
Patch:
@@ -31,7 +31,7 @@
 import java.util.Properties;
 
 import static io.strimzi.api.kafka.model.KafkaResources.externalBootstrapServiceName;
-import static io.strimzi.test.BaseITST.kubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.junit.jupiter.api.Assertions.fail;
 
 @SuppressFBWarnings("REC_CATCH_EXCEPTION")

File: systemtest/src/main/java/io/strimzi/systemtest/utils/BridgeUtils.java
Patch:
@@ -15,7 +15,7 @@
 import java.util.Map;
 
 import static io.strimzi.systemtest.Resources.getSystemtestsServiceResource;
-import static io.strimzi.test.BaseITST.kubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/LogCollector.java
Patch:
@@ -11,8 +11,8 @@
 
 import java.io.File;
 
-import static io.strimzi.test.BaseITST.cmdKubeClient;
 import static io.strimzi.test.TestUtils.writeFile;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
 
 public class LogCollector {
     private static final Logger LOGGER = LogManager.getLogger(LogCollector.class);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/MetricsUtils.java
Patch:
@@ -22,8 +22,8 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import static io.strimzi.test.BaseITST.cmdKubeClient;
-import static io.strimzi.test.BaseITST.kubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 
 public class MetricsUtils {
 

File: systemtest/src/main/java/io/strimzi/systemtest/utils/TestExecutionWatcher.java
Patch:
@@ -16,7 +16,7 @@
 import java.util.TimeZone;
 
 import static io.strimzi.systemtest.AbstractST.TEST_LOG_DIR;
-import static io.strimzi.test.BaseITST.kubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 
 public class TestExecutionWatcher implements AfterTestExecutionCallback, LifecycleMethodExecutionExceptionHandler {
     private static final Logger LOGGER = LogManager.getLogger(TestExecutionWatcher.class);

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -30,6 +30,8 @@
 
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.not;
@@ -60,7 +62,7 @@ void testDeployS2IWithMongoDBPlugin() {
         File dir = StUtils.downloadAndUnzip("https://repo1.maven.org/maven2/io/debezium/debezium-connector-mongodb/0.7.5/debezium-connector-mongodb-0.7.5-plugin.zip");
 
         // Start a new image build using the plugins directory
-        cmdKubeClient().exec("oc", "start-build", KafkaConnectS2IResources.deploymentName(kafkaConnectS2IName), "--from-dir", dir.getAbsolutePath(), "-n", NAMESPACE);
+        cmdKubeClient().execInCurrentNamespace("start-build", KafkaConnectS2IResources.deploymentName(kafkaConnectS2IName), "--from-dir", dir.getAbsolutePath());
         // Wait for rolling update connect pods
         StUtils.waitTillDepConfigHasRolled(kafkaConnectS2IName, connectSnapshot);
         String connectS2IPodName = kubeClient().listPods("type", "kafka-connect-s2i").get(0).getMetadata().getName();

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -42,6 +42,8 @@
 import static io.strimzi.systemtest.k8s.Events.Unhealthy;
 import static io.strimzi.systemtest.matchers.Matchers.hasAllOfReasons;
 import static io.strimzi.systemtest.matchers.Matchers.hasNoneOfReasons;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.greaterThanOrEqualTo;

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -39,6 +39,7 @@
 import static io.strimzi.api.kafka.model.KafkaResources.externalBootstrapServiceName;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 

File: systemtest/src/test/java/io/strimzi/systemtest/LogSettingST.java
Patch:
@@ -29,7 +29,9 @@
 import java.util.stream.Collectors;
 
 import static io.strimzi.systemtest.Constants.REGRESSION;
-import static io.strimzi.test.k8s.BaseCmdKubeClient.STATEFUL_SET;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
+import static io.strimzi.test.k8s.cmdClient.BaseCmdKubeClient.STATEFUL_SET;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.CoreMatchers.notNullValue;
 import static org.hamcrest.MatcherAssert.assertThat;

File: systemtest/src/test/java/io/strimzi/systemtest/MirrorMakerST.java
Patch:
@@ -34,6 +34,7 @@
 
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.is;
 

File: systemtest/src/test/java/io/strimzi/systemtest/RecoveryST.java
Patch:
@@ -20,6 +20,7 @@
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.BRIDGE;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 
 @Tag(REGRESSION)
 class RecoveryST extends AbstractST {

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -24,6 +24,7 @@
 
 import static io.strimzi.systemtest.Constants.CO_OPERATION_TIMEOUT_SHORT;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 

File: systemtest/src/test/java/io/strimzi/systemtest/TopicST.java
Patch:
@@ -17,6 +17,8 @@
 
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.Constants.SCALABILITY;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.hasItem;

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -23,6 +23,7 @@
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.Constants.SCALABILITY;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.is;

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -31,6 +31,7 @@
 import static io.strimzi.systemtest.Constants.BRIDGE;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -33,6 +33,7 @@
 import static io.strimzi.systemtest.Constants.BRIDGE;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -31,6 +31,7 @@
 import static io.strimzi.systemtest.Constants.BRIDGE;
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/MetricsST.java
Patch:
@@ -28,6 +28,8 @@
 import java.util.regex.Pattern;
 
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.is;
 import static org.hamcrest.Matchers.isEmptyString;

File: systemtest/src/test/java/io/strimzi/systemtest/metrics/PrometheusST.java
Patch:
@@ -15,6 +15,8 @@
 import java.util.List;
 
 import static io.strimzi.systemtest.Constants.PROMETHEUS;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
 
 @Tag(PROMETHEUS)

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthBaseST.java
Patch:
@@ -24,6 +24,8 @@
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.OAUTH;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 
 @Tag(OAUTH)
 @Tag(REGRESSION)

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthPlainST.java
Patch:
@@ -26,6 +26,8 @@
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.OAUTH;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.greaterThan;

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -25,6 +25,8 @@
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.OAUTH;
 import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.containsString;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.greaterThan;

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -31,6 +31,8 @@
 import static io.strimzi.systemtest.k8s.Events.Scheduled;
 import static io.strimzi.systemtest.k8s.Events.Started;
 import static io.strimzi.systemtest.matchers.Matchers.hasAllOfReasons;
+import static io.strimzi.test.k8s.KubeClusterResource.cmdKubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 

File: test/src/main/java/io/strimzi/test/executor/Exec.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.test.executor;
 
-import io.strimzi.test.k8s.KubeClusterException;
+import io.strimzi.test.k8s.exceptions.KubeClusterException;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 

File: test/src/main/java/io/strimzi/test/k8s/KubeClient.java
Patch:
@@ -53,7 +53,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;
 
-import static io.strimzi.test.BaseITST.kubeClient;
+import static io.strimzi.test.k8s.KubeClusterResource.kubeClient;
 
 public class KubeClient {
 

File: test/src/main/java/io/strimzi/test/k8s/exceptions/KubeClusterException.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.test.k8s;
+package io.strimzi.test.k8s.exceptions;
 
 import io.strimzi.test.executor.ExecResult;
 

File: test/src/main/java/io/strimzi/test/k8s/exceptions/NoClusterException.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.test.k8s;
+package io.strimzi.test.k8s.exceptions;
 
 public class NoClusterException extends Exception {
     public NoClusterException(String message) {

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/LogHasNoUnexpectedErrors.java
Patch:
@@ -31,7 +31,7 @@ public boolean matches(Object actualValue) {
             // It's match start of the line which contains date in format yyyy-mm-dd hh:mm:ss
             String logLineSplitPattern = "[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2}";
             for (String line : ((String) actualValue).split(logLineSplitPattern)) {
-                if (line.contains("DEBUG") || line.contains("WARN")) {
+                if (line.contains("DEBUG") || line.contains("WARN") || line.contains("INFO")) {
                     continue;
                 }
                 String lineLowerCase = line.toLowerCase(Locale.ENGLISH);
@@ -76,7 +76,7 @@ enum LogWhiteList {
         OPERATION_TIMEOUT("Util:[0-9]+ - Exceeded timeout of.*while waiting for.*"),
         // This is whitelisted cause it's no real problem when this error appears, components are being created even after timeout
         RECONCILIATION_TIMEOUT("ERROR Abstract.*Operator:[0-9]+ - Reconciliation.*"),
-        ASSEMBLY_OPERATOR_RECONCILIATION_TIMEOUT("ERROR .*AssemblyOperator:[0-9]+ - Reconciliation.*failed.*");
+        ASSEMBLY_OPERATOR_RECONCILIATION_TIMEOUT("ERROR .*AssemblyOperator:[0-9]+ - Reconciliation.*[fF]ailed.*");
 
         final String name;
 

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -880,7 +880,7 @@ void testTlsHostnameVerificationWithMirrorMaker() {
     }
 
     @Test
-    void testAclRuleWrite() throws Exception {
+    void testAclRuleReadAndWrite() throws Exception {
         final String kafkaUserWrite = "kafka-user-write";
         final String kafkaUserRead = "kafka-user-read";
         final String topicName = "my-topic-name-1";

File: systemtest/src/main/java/io/strimzi/systemtest/HttpBridgeBaseST.java
Patch:
@@ -108,7 +108,7 @@ protected void checkSendResponse(JsonObject response, int messageCount) {
         for (int i = 0; i < messageCount; i++) {
             JsonObject metadata = offsets.getJsonObject(i);
             assertThat(metadata.getInteger("partition"), is(0));
-            assertThat(metadata.getLong("offset"), is(i));
+            assertThat(metadata.getInteger("offset"), is(i));
             LOGGER.debug("offset size: {}, partition: {}, offset size: {}", offsets.size(), metadata.getInteger("partition"), metadata.getLong("offset"));
         }
     }

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -113,7 +113,7 @@ void assertThatRollingUpdatedFinished(String rolledComponent, String stableCompo
                 .filter(p -> p.getMetadata().getName().startsWith(rolledComponent))
                 .map(p -> p.getStatus().getPhase()).sorted().collect(Collectors.toList());
 
-        assertThat(rolledComponent + "is fine", podStatuses.contains("Pending"));
+        assertThat(rolledComponent + " is fine", podStatuses.contains("Pending"));
 
         Map<String, Long> statusCount = podStatuses.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));
         LOGGER.info("{} pods statutes: {}", rolledComponent, statusCount);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1077,6 +1077,8 @@ public Secret generateBrokersSecret() {
             CertAndKey cert = brokerCerts.get(KafkaCluster.kafkaPodName(cluster, i));
             data.put(KafkaCluster.kafkaPodName(cluster, i) + ".key", cert.keyAsBase64String());
             data.put(KafkaCluster.kafkaPodName(cluster, i) + ".crt", cert.certAsBase64String());
+            data.put(KafkaCluster.kafkaPodName(cluster, i) + ".p12", cert.keyStoreAsBase64String());
+            data.put(KafkaCluster.kafkaPodName(cluster, i) + ".password", cert.storePasswordAsBase64String());
         }
         return createSecret(KafkaCluster.brokersSecretName(cluster), data);
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -466,6 +466,8 @@ public Secret generateNodesSecret(ClusterCa clusterCa, Kafka kafka) {
                 CertAndKey cert = certs.get(ZookeeperCluster.zookeeperPodName(cluster, i));
                 data.put(ZookeeperCluster.zookeeperPodName(cluster, i) + ".key", cert.keyAsBase64String());
                 data.put(ZookeeperCluster.zookeeperPodName(cluster, i) + ".crt", cert.certAsBase64String());
+                data.put(ZookeeperCluster.zookeeperPodName(cluster, i) + ".p12", cert.keyStoreAsBase64String());
+                data.put(ZookeeperCluster.zookeeperPodName(cluster, i) + ".password", cert.storePasswordAsBase64String());
             }
 
         } catch (IOException e) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperLeaderFinder.java
Patch:
@@ -112,7 +112,9 @@ private RuntimeException corruptCertificate(Secret secret, String certKey, Certi
      * and return the PemKeyCertOptions for using it for TLS authentication.
      */
     protected PemKeyCertOptions keyCertOptions(Secret coCertKeySecret) {
-        CertAndKey coCertKey = Ca.asCertAndKey(coCertKeySecret, "cluster-operator.key", "cluster-operator.crt");
+        CertAndKey coCertKey = Ca.asCertAndKey(coCertKeySecret,
+                                            "cluster-operator.key", "cluster-operator.crt",
+                                        "cluster-operator.p12", "cluster-operator.password");
         if (coCertKey == null) {
             throw StatefulSetOperator.missingSecretFuture(coCertKeySecret.getMetadata().getNamespace(), coCertKeySecret.getMetadata().getName());
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -340,9 +340,9 @@ public void testGenerateBrokerSecret() throws CertificateParsingException {
 
         Secret secret = zc.generateNodesSecret(clusterCa, ka);
         assertThat(secret.getData().keySet(), is(set(
-                "foo-zookeeper-0.crt",  "foo-zookeeper-0.key",
-                "foo-zookeeper-1.crt", "foo-zookeeper-1.key",
-                "foo-zookeeper-2.crt", "foo-zookeeper-2.key")));
+                "foo-zookeeper-0.crt",  "foo-zookeeper-0.key", "foo-zookeeper-0.p12", "foo-zookeeper-0.password",
+                "foo-zookeeper-1.crt", "foo-zookeeper-1.key", "foo-zookeeper-1.p12", "foo-zookeeper-1.password",
+                "foo-zookeeper-2.crt", "foo-zookeeper-2.key", "foo-zookeeper-2.p12", "foo-zookeeper-2.password")));
         X509Certificate cert = Ca.cert(secret, "foo-zookeeper-0.crt");
         assertThat(cert.getSubjectDN().getName(), is("CN=foo-zookeeper, O=io.strimzi"));
         assertThat(new HashSet<Object>(cert.getSubjectAlternativeNames()), is(set(

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ZookeeperLeaderFinderTest.java
Patch:
@@ -260,7 +260,9 @@ public void testSecretsCorrupted() {
                         .withNamespace(NAMESPACE)
                         .endMetadata()
                         .withData(map("cluster-operator.key", "notacert",
-                                "cluster-operator.crt", "notacert"))
+                                "cluster-operator.crt", "notacert",
+                                "cluster-operator.p12", "notatruststore",
+                                "cluster-operator.password", "notapassword"))
                         .build()).cause();
         assertThat(cause instanceof RuntimeException, is(true));
         assertThat(cause.getMessage(), is("Bad/corrupt certificate found in data.cluster-operator\\.crt of Secret testcluster-cluster-operator-certs in namespace testns"));

File: user-operator/src/test/java/io/strimzi/operator/user/ResourceUtils.java
Patch:
@@ -110,6 +110,8 @@ public static Secret createUserSecretTls()  {
                 .addToData("ca.crt", Base64.getEncoder().encodeToString("clients-ca-crt".getBytes()))
                 .addToData("user.key", Base64.getEncoder().encodeToString("expected-key".getBytes()))
                 .addToData("user.crt", Base64.getEncoder().encodeToString("expected-crt".getBytes()))
+                .addToData("user.p12", Base64.getEncoder().encodeToString("expected-p12".getBytes()))
+                .addToData("user.password", Base64.getEncoder().encodeToString("expected-password".getBytes()))
                 .build();
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/clients/lib/KafkaClientProperties.java
Patch:
@@ -124,9 +124,9 @@ private static Properties sharedClientProperties(String namespace, String cluste
         try {
             Secret clusterCaCertSecret = kubeClient(namespace).getSecret(KafkaResources.clusterCaCertificateSecretName(clusterName));
 
-            String tsPassword = new String(Base64.getDecoder().decode(clusterCaCertSecret.getData().get("truststore.password")), StandardCharsets.US_ASCII);
+            String tsPassword = new String(Base64.getDecoder().decode(clusterCaCertSecret.getData().get("ca.password")), StandardCharsets.US_ASCII);
             File tsFile = File.createTempFile(KafkaClientProperties.class.getName(), ".truststore");
-            String truststore = clusterCaCertSecret.getData().get("truststore.p12");
+            String truststore = clusterCaCertSecret.getData().get("ca.p12");
             Files.write(tsFile.toPath(), Base64.getDecoder().decode(truststore));
             tsFile.deleteOnExit();
             properties.setProperty(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG, "PKCS12");

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorIT.java
Patch:
@@ -12,6 +12,7 @@
 import io.fabric8.kubernetes.client.KubernetesClientException;
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopicBuilder;
+import io.vertx.junit5.Timeout;
 import io.vertx.junit5.VertxExtension;
 import io.vertx.junit5.VertxTestContext;
 import kafka.server.KafkaConfig$;
@@ -27,6 +28,7 @@
 import java.util.Map;
 import java.util.Properties;
 import java.util.concurrent.ExecutionException;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 
 import static java.util.Collections.emptyMap;
@@ -35,6 +37,7 @@
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 
+@Timeout(value = 10, timeUnit = TimeUnit.MINUTES)
 @ExtendWith(VertxExtension.class)
 public class TopicOperatorIT extends TopicOperatorBaseIT {
 

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorReplicationIT.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.strimzi.api.kafka.model.KafkaTopicBuilder;
 import io.vertx.junit5.Checkpoint;
+import io.vertx.junit5.Timeout;
 import io.vertx.junit5.VertxExtension;
 import io.vertx.junit5.VertxTestContext;
 import kafka.admin.ReassignPartitionsCommand;
@@ -23,11 +24,13 @@
 import java.io.PrintStream;
 import java.util.Map;
 import java.util.Properties;
+import java.util.concurrent.TimeUnit;
 
 import static java.util.Arrays.asList;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 
+@Timeout(value = 10, timeUnit = TimeUnit.MINUTES)
 @ExtendWith(VertxExtension.class)
 public class TopicOperatorReplicationIT extends TopicOperatorBaseIT {
 

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorTopicDeletionDisabledIT.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.strimzi.api.kafka.model.KafkaTopic;
 import io.vertx.core.Future;
+import io.vertx.junit5.Timeout;
 import io.vertx.junit5.VertxExtension;
 import io.vertx.junit5.VertxTestContext;
 import kafka.server.KafkaConfig$;
@@ -14,8 +15,10 @@
 
 import java.util.Properties;
 import java.util.concurrent.ExecutionException;
+import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 
+@Timeout(value = 10, timeUnit = TimeUnit.MINUTES)
 @ExtendWith(VertxExtension.class)
 public class TopicOperatorTopicDeletionDisabledIT extends TopicOperatorBaseIT {
 

File: systemtest/src/main/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -82,11 +82,11 @@
 import static io.strimzi.test.TestUtils.indent;
 import static io.strimzi.test.TestUtils.waitFor;
 import static java.util.Arrays.asList;
+import static org.hamcrest.CoreMatchers.containsString;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.CoreMatchers.notNullValue;
 import static org.hamcrest.CoreMatchers.nullValue;
 import static org.hamcrest.MatcherAssert.assertThat;
-import static org.hamcrest.Matchers.containsString;
 import static org.junit.jupiter.api.Assertions.fail;
 
 @SuppressWarnings("checkstyle:ClassFanOutComplexity")

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -47,7 +47,7 @@ public interface Constants {
     long GLOBAL_TRACING_POLL = Duration.ofSeconds(30).toMillis();
     long GLOBAL_TRACING_TIMEOUT =  Duration.ofMinutes(7).toMillis();
 
-    long CO_OPERATION_TIMEOUT_DEFAULT = TIMEOUT_FOR_RESOURCE_READINESS;
+    long CO_OPERATION_TIMEOUT_DEFAULT = Duration.ofMinutes(5).toMillis();
     long CO_OPERATION_TIMEOUT_SHORT = Duration.ofSeconds(30).toMillis();
     long CO_OPERATION_TIMEOUT_WAIT = CO_OPERATION_TIMEOUT_SHORT + Duration.ofSeconds(80).toMillis();
     long CO_OPERATION_TIMEOUT_POLL = Duration.ofSeconds(2).toMillis();

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -904,7 +904,7 @@ public DoneableDeployment clusterOperator(String namespace, long operationTimeou
     }
 
     public DoneableDeployment clusterOperator(String namespace) {
-        return createNewDeployment(defaultCLusterOperator(namespace, Constants.CONNECT_STATUS_TIMEOUT, Constants.RECONCILIATION_INTERVAL).build());
+        return createNewDeployment(defaultCLusterOperator(namespace, Constants.CO_OPERATION_TIMEOUT_DEFAULT, Constants.RECONCILIATION_INTERVAL).build());
     }
 
     private DeploymentBuilder defaultCLusterOperator(String namespace, long operationTimeout, long reconciliationInterval) {

File: systemtest/src/main/java/io/strimzi/systemtest/AbstractResources.java
Patch:
@@ -123,7 +123,7 @@ MixedOperation<KafkaTopic, KafkaTopicList, DoneableKafkaTopic, Resource<KafkaTop
                         KafkaTopic.class, KafkaTopicList.class, DoneableKafkaTopic.class);
     }
 
-    MixedOperation<KafkaUser, KafkaUserList, DoneableKafkaUser, Resource<KafkaUser, DoneableKafkaUser>> kafkaUser() {
+    public MixedOperation<KafkaUser, KafkaUserList, DoneableKafkaUser, Resource<KafkaUser, DoneableKafkaUser>> kafkaUser() {
         return client()
                 .customResources(Crds.kafkaUser(),
                         KafkaUser.class, KafkaUserList.class, DoneableKafkaUser.class);

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -49,7 +49,7 @@ public interface Constants {
 
     long CO_OPERATION_TIMEOUT_DEFAULT = TIMEOUT_FOR_RESOURCE_READINESS;
     long CO_OPERATION_TIMEOUT_SHORT = Duration.ofSeconds(30).toMillis();
-    long CO_OPERATION_TIMEOUT_WAIT = CO_OPERATION_TIMEOUT_SHORT + Duration.ofSeconds(20).toMillis();
+    long CO_OPERATION_TIMEOUT_WAIT = CO_OPERATION_TIMEOUT_SHORT + Duration.ofSeconds(80).toMillis();
     long CO_OPERATION_TIMEOUT_POLL = Duration.ofSeconds(2).toMillis();
     long RECONCILIATION_INTERVAL = Duration.ofSeconds(30).toMillis();
 

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -22,6 +22,7 @@
 import java.util.function.Function;
 import java.util.stream.Collectors;
 
+import static io.strimzi.systemtest.Constants.CO_OPERATION_TIMEOUT_SHORT;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -143,7 +144,7 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        testClassResources().clusterOperator(NAMESPACE).done();
+        testClassResources().clusterOperator(NAMESPACE, CO_OPERATION_TIMEOUT_SHORT).done();
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -140,6 +140,7 @@ void testConnectService() throws Exception {
                     .editKafka()
                         .editListeners()
                             .withNewKafkaListenerExternalNodePort()
+                                .withTls(false)
                             .endKafkaListenerExternalNodePort()
                         .endListeners()
                         .withConfig(configOfKafka)

File: certificate-manager/src/test/java/io/strimzi/certs/SecretCertProviderTest.java
Patch:
@@ -54,7 +54,7 @@ public void testKeyAndCertInSecret() throws Exception {
         Secret secret = secretCertProvider.createSecret("my-namespace", "my-secret",
                 "ca.key", "ca.crt",
                 key, cert,
-                "truststore.p12", "truststore.password",
+                "ca.p12", "ca.password",
                 store, "123456",
                 emptyMap(), emptyMap(), ownerReference);
 
@@ -65,8 +65,8 @@ public void testKeyAndCertInSecret() throws Exception {
         assertThat(secret.getData().size(), is(4));
         assertThat(Arrays.equals(Files.readAllBytes(key.toPath()), decoder.decode(secret.getData().get("ca.key"))), is(true));
         assertThat(Arrays.equals(Files.readAllBytes(cert.toPath()), decoder.decode(secret.getData().get("ca.crt"))), is(true));
-        assertThat(Arrays.equals(Files.readAllBytes(store.toPath()), decoder.decode(secret.getData().get("truststore.p12"))), is(true));
-        assertThat(new String(decoder.decode(secret.getData().get("truststore.password"))), is("123456"));
+        assertThat(Arrays.equals(Files.readAllBytes(store.toPath()), decoder.decode(secret.getData().get("ca.p12"))), is(true));
+        assertThat(new String(decoder.decode(secret.getData().get("ca.password"))), is("123456"));
 
         key.delete();
         cert.delete();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -210,8 +210,8 @@ public static Secret createInitialCaCertSecret(String clusterNamespace, String c
                     .withLabels(Labels.forCluster(clusterName).withKind(Kafka.RESOURCE_KIND).toMap())
                 .endMetadata()
                 .addToData("ca.crt", caCert)
-                .addToData("truststore.p12", caStore)
-                .addToData("truststore.password", caStorePassword)
+                .addToData("ca.p12", caStore)
+                .addToData("ca.password", caStorePassword)
                 .build();
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -144,7 +144,9 @@ op.new ReconciliationState(reconciliation, kafka).reconcileCas(dateSupplier).set
             error.set(ar.cause());
             async.flag();
         });
-        context.awaitCompletion(60, TimeUnit.SECONDS);
+        if (!context.awaitCompletion(60, TimeUnit.SECONDS)) {
+            context.failNow(new Throwable("Test timeout"));
+        }
 
         if (error.get() != null) {
             Throwable t = error.get();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -1257,7 +1257,9 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, Kafka kafkaAss
             ignored -> { }
         );
 
-        context.awaitCompletion(60, TimeUnit.SECONDS);
+        if (!context.awaitCompletion(60, TimeUnit.SECONDS)) {
+            context.failNow(new Throwable("Test timeout"));
+        }
 
         context.verify(() -> assertThat(createdOrUpdated, is(new HashSet(asList("foo", "bar")))));
     }

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorTest.java
Patch:
@@ -197,7 +197,9 @@ private TopicOperator resourceAdded(VertxTestContext context, Exception createEx
             }
             async.flag();
         });
-        context.awaitCompletion(60, TimeUnit.SECONDS);
+        if (!context.awaitCompletion(60, TimeUnit.SECONDS)) {
+            context.failNow(new Throwable("Test timeout"));
+        }
 
         return topicOperator;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -133,7 +133,6 @@ public void before(VertxTestContext context) throws InterruptedException, Execut
             createAsync.complete(true);
         });
         createAsync.get(60, TimeUnit.SECONDS);
-        context.completeNow();
         LOGGER.info("bootstrap reconciliation complete");
 
         this.kafkaSs = bootstrapClient.apps().statefulSets().inNamespace(NAMESPACE).withName(KafkaCluster.kafkaClusterName(CLUSTER_NAME)).get();
@@ -150,6 +149,7 @@ public void before(VertxTestContext context) throws InterruptedException, Execut
         this.clusterCaKey = bootstrapClient.secrets().inNamespace(NAMESPACE).withName(KafkaResources.clusterCaKeySecretName(CLUSTER_NAME)).get();
         this.clientsCaCert = bootstrapClient.secrets().inNamespace(NAMESPACE).withName(KafkaResources.clientsCaCertificateSecretName(CLUSTER_NAME)).get();
         this.clientsCaKey = bootstrapClient.secrets().inNamespace(NAMESPACE).withName(KafkaResources.clientsCaKeySecretName(CLUSTER_NAME)).get();
+        context.completeNow();
     }
 
     ResourceOperatorSupplier supplier(KubernetesClient bootstrapClient) {

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorReplicationIT.java
Patch:
@@ -123,6 +123,7 @@ public void testKafkaTopicModifiedChangedReplication(VertxTestContext context) t
         // And check that the status is ready
         assertStatusReady(context, topicName);
         async.flag();
+        context.completeNow();
     }
 
     ByteArrayOutputStream baos = new ByteArrayOutputStream();

File: topic-operator/src/test/java/io/strimzi/operator/topic/zk/ZkImplTest.java
Patch:
@@ -51,6 +51,7 @@ public void teardown(VertxTestContext context) {
         if (this.zkServer != null) {
             this.zkServer.close();
         }
+        context.completeNow();
         vertx.close();
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/EntityOperatorJvmOptions.java
Patch:
@@ -27,11 +27,11 @@ public class EntityOperatorJvmOptions implements UnknownPropertyPreserving, Seri
 
     private static final long serialVersionUID = 1L;
 
-    private boolean gcLoggingEnabled = true;
+    private boolean gcLoggingEnabled = false;
 
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
-    @Description("Specifies whether the Garbage Collection logging is enabled. The default is true.")
+    @Description("Specifies whether the Garbage Collection logging is enabled. The default is false.")
     public boolean isGcLoggingEnabled() {
         return gcLoggingEnabled;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/JvmOptions.java
Patch:
@@ -32,7 +32,7 @@ public class JvmOptions implements UnknownPropertyPreserving, Serializable {
     private String xmx;
     private String xms;
     private Boolean server;
-    private boolean gcLoggingEnabled = true;
+    private boolean gcLoggingEnabled = false;
     private Map<String, String> xx;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
@@ -68,7 +68,7 @@ public void setServer(Boolean server) {
         this.server = server;
     }
 
-    @Description("Specifies whether the Garbage Collection logging is enabled. The default is true.")
+    @Description("Specifies whether the Garbage Collection logging is enabled. The default is false.")
     public boolean isGcLoggingEnabled() {
         return gcLoggingEnabled;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -86,6 +86,7 @@ public abstract class AbstractModel {
     protected static final Logger log = LogManager.getLogger(AbstractModel.class.getName());
 
     protected static final String DEFAULT_JVM_XMS = "128M";
+    protected static final boolean DEFAULT_JVM_GC_LOGGING_ENABLED = false;
 
     private static final Long DEFAULT_FS_GROUPID = 0L;
 
@@ -105,9 +106,6 @@ public abstract class AbstractModel {
     @Deprecated
     public static final String ANNO_CO_STRIMZI_IO_DELETE_CLAIM = "cluster.operator.strimzi.io/delete-claim";
 
-    protected static final String DEFAULT_KAFKA_GC_LOG_ENABLED = String.valueOf(true);
-    protected static final String DEFAULT_STRIMZI_GC_LOG_ENABED = String.valueOf(true);
-
     protected final String cluster;
     protected final String namespace;
     protected final Labels labels;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -217,7 +217,7 @@ public static EntityTopicOperator fromCrd(Kafka kafkaAssembly) {
                 result.setZookeeperSessionTimeoutMs(topicOperatorSpec.getZookeeperSessionTimeoutSeconds() * 1_000);
                 result.setTopicMetadataMaxAttempts(topicOperatorSpec.getTopicMetadataMaxAttempts());
                 result.setLogging(topicOperatorSpec.getLogging());
-                result.setGcLoggingEnabled(topicOperatorSpec.getJvmOptions() == null ? true : topicOperatorSpec.getJvmOptions().isGcLoggingEnabled());
+                result.setGcLoggingEnabled(topicOperatorSpec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : topicOperatorSpec.getJvmOptions().isGcLoggingEnabled());
                 result.setResources(topicOperatorSpec.getResources());
                 if (topicOperatorSpec.getReadinessProbe() != null) {
                     result.setReadinessProbe(topicOperatorSpec.getReadinessProbe());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -203,7 +203,7 @@ public static EntityUserOperator fromCrd(Kafka kafkaAssembly) {
                 result.setReconciliationIntervalMs(userOperatorSpec.getReconciliationIntervalSeconds() * 1_000);
                 result.setZookeeperSessionTimeoutMs(userOperatorSpec.getZookeeperSessionTimeoutSeconds() * 1_000);
                 result.setLogging(userOperatorSpec.getLogging());
-                result.setGcLoggingEnabled(userOperatorSpec.getJvmOptions() == null ? true : userOperatorSpec.getJvmOptions().isGcLoggingEnabled());
+                result.setGcLoggingEnabled(userOperatorSpec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : userOperatorSpec.getJvmOptions().isGcLoggingEnabled());
                 result.setResources(userOperatorSpec.getResources());
                 if (userOperatorSpec.getReadinessProbe() != null) {
                     result.setReadinessProbe(userOperatorSpec.getReadinessProbe());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -142,7 +142,7 @@ public static KafkaBridgeCluster fromCrd(KafkaBridge kafkaBridge, KafkaVersion.L
         kafkaBridgeCluster.tracing = spec.getTracing();
         kafkaBridgeCluster.setResources(spec.getResources());
         kafkaBridgeCluster.setLogging(spec.getLogging());
-        kafkaBridgeCluster.setGcLoggingEnabled(spec.getJvmOptions() == null ? true : spec.getJvmOptions().isGcLoggingEnabled());
+        kafkaBridgeCluster.setGcLoggingEnabled(spec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : spec.getJvmOptions().isGcLoggingEnabled());
         String image = spec.getImage();
         if (image == null) {
             image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE, "strimzi/kafka-bridge:latest");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -385,7 +385,7 @@ public static KafkaCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup vers
         Logging logging = kafkaClusterSpec.getLogging();
         result.setLogging(logging == null ? new InlineLogging() : logging);
 
-        result.setGcLoggingEnabled(kafkaClusterSpec.getJvmOptions() == null ? true : kafkaClusterSpec.getJvmOptions().isGcLoggingEnabled());
+        result.setGcLoggingEnabled(kafkaClusterSpec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : kafkaClusterSpec.getJvmOptions().isGcLoggingEnabled());
 
         result.setJvmOptions(kafkaClusterSpec.getJvmOptions());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -158,7 +158,7 @@ protected static <C extends KafkaConnectCluster> C fromSpec(KafkaConnectSpec spe
 
         kafkaConnect.setResources(spec.getResources());
         kafkaConnect.setLogging(spec.getLogging());
-        kafkaConnect.setGcLoggingEnabled(spec.getJvmOptions() == null ? true : spec.getJvmOptions().isGcLoggingEnabled());
+        kafkaConnect.setGcLoggingEnabled(spec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : spec.getJvmOptions().isGcLoggingEnabled());
         kafkaConnect.setJvmOptions(spec.getJvmOptions());
         if (spec.getReadinessProbe() != null) {
             kafkaConnect.setReadinessProbe(spec.getReadinessProbe());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -157,7 +157,7 @@ public static KafkaMirrorMakerCluster fromCrd(KafkaMirrorMaker kafkaMirrorMaker,
             kafkaMirrorMakerCluster.setImage(versions.kafkaMirrorMakerImage(spec.getImage(), spec.getVersion()));
 
             kafkaMirrorMakerCluster.setLogging(spec.getLogging());
-            kafkaMirrorMakerCluster.setGcLoggingEnabled(spec.getJvmOptions() == null ? true : spec.getJvmOptions().isGcLoggingEnabled());
+            kafkaMirrorMakerCluster.setGcLoggingEnabled(spec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : spec.getJvmOptions().isGcLoggingEnabled());
             kafkaMirrorMakerCluster.setJvmOptions(spec.getJvmOptions());
 
             Map<String, Object> metrics = spec.getMetrics();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -237,7 +237,7 @@ public static TopicOperator fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup ver
             result.setZookeeperSessionTimeoutMs(tcConfig.getZookeeperSessionTimeoutSeconds() * 1_000);
             result.setTopicMetadataMaxAttempts(tcConfig.getTopicMetadataMaxAttempts());
             result.setLogging(tcConfig.getLogging());
-            result.setGcLoggingEnabled(tcConfig.getJvmOptions() == null ? true : tcConfig.getJvmOptions().isGcLoggingEnabled());
+            result.setGcLoggingEnabled(tcConfig.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : tcConfig.getJvmOptions().isGcLoggingEnabled());
             result.setResources(tcConfig.getResources());
             result.setUserAffinity(tcConfig.getAffinity());
             result.setTlsSidecar(tcConfig.getTlsSidecar());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -199,7 +199,7 @@ public static ZookeeperCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup
 
         Logging logging = zookeeperClusterSpec.getLogging();
         zk.setLogging(logging == null ? new InlineLogging() : logging);
-        zk.setGcLoggingEnabled(zookeeperClusterSpec.getJvmOptions() == null ? true : zookeeperClusterSpec.getJvmOptions().isGcLoggingEnabled());
+        zk.setGcLoggingEnabled(zookeeperClusterSpec.getJvmOptions() == null ? DEFAULT_JVM_GC_LOGGING_ENABLED : zookeeperClusterSpec.getJvmOptions().isGcLoggingEnabled());
 
         Map<String, Object> metrics = zookeeperClusterSpec.getMetrics();
         if (metrics != null) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -98,7 +98,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_ZOOKEEPER_SESSION_TIMEOUT_MS).withValue(String.valueOf(toZookeeperSessionTimeout * 1000)).build());
         expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_TOPIC_METADATA_MAX_ATTEMPTS).withValue(String.valueOf(toTopicMetadataMaxAttempts)).build());
         expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_TLS_ENABLED).withValue(Boolean.toString(true)).build());
-        expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(EntityTopicOperator.DEFAULT_STRIMZI_GC_LOG_ENABED).build());
+        expected.add(new EnvVarBuilder().withName(EntityTopicOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
         return expected;
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -98,7 +98,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_KEY_SECRET_NAME).withValue(KafkaCluster.clientsCaKeySecretName(cluster)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_CERT_SECRET_NAME).withValue(KafkaCluster.clientsCaCertSecretName(cluster)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_NAMESPACE).withValue(namespace).build());
-        expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(KafkaCluster.DEFAULT_STRIMZI_GC_LOG_ENABED).build());
+        expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_VALIDITY).withValue(Integer.toString(CertificateAuthority.DEFAULT_CERTS_VALIDITY_DAYS)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_RENEWAL).withValue(Integer.toString(CertificateAuthority.DEFAULT_CERTS_RENEWAL_DAYS)).build());
         return expected;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -108,7 +108,7 @@ protected List<EnvVar> getExpectedEnvVars() {
 
         List<EnvVar> expected = new ArrayList<>();
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_METRICS_ENABLED).withValue(String.valueOf(true)).build());
-        expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(String.valueOf(true)).build());
+        expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(String.valueOf(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_BOOTSTRAP_SERVERS).withValue(bootstrapServers).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_CONSUMER_CONFIG).withValue(defaultConsumerConfiguration).build());
         expected.add(new EnvVarBuilder().withName(KafkaBridgeCluster.ENV_VAR_KAFKA_BRIDGE_PRODUCER_CONFIG).withValue(defaultProducerConfiguration).build());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -366,7 +366,7 @@ private void checkStatefulSet(StatefulSet ss, Kafka cm, boolean isOpenShift) {
         assertThat(containers.get(0).getReadinessProbe().getSuccessThreshold(), is(new Integer(4)));
         assertThat(containers.get(0).getReadinessProbe().getPeriodSeconds(), is(new Integer(33)));
         assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(KafkaCluster.ENV_VAR_KAFKA_CONFIGURATION), is("foo=bar" + LINE_SEPARATOR));
-        assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(KafkaCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(KafkaCluster.DEFAULT_KAFKA_GC_LOG_ENABLED));
+        assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(KafkaCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)));
         assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(KafkaCluster.ENV_VAR_KAFKA_LOG_DIRS),
                 is(kc.dataVolumeMountPaths.stream().map(volumeMount -> volumeMount.getMountPath()).collect(Collectors.joining(","))));
         assertThat(containers.get(0).getVolumeMounts().get(2).getName(), is(KafkaCluster.BROKER_CERTS_VOLUME));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -132,7 +132,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_CONFIGURATION).withValue(expectedConfiguration.asPairs()).build());
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_METRICS_ENABLED).withValue(String.valueOf(true)).build());
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_BOOTSTRAP_SERVERS).withValue(bootstrapServers).build());
-        expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(KafkaConnectCluster.DEFAULT_KAFKA_GC_LOG_ENABLED).build());
+        expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(AbstractModel.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
         return expected;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -136,7 +136,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_CONFIGURATION).withValue(expectedConfiguration.asPairs()).build());
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_METRICS_ENABLED).withValue(String.valueOf(true)).build());
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_BOOTSTRAP_SERVERS).withValue(bootstrapServers).build());
-        expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(KafkaConnectCluster.DEFAULT_KAFKA_GC_LOG_ENABLED).build());
+        expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(AbstractModel.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
         return expected;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -145,7 +145,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_NUMSTREAMS).withValue(Integer.toString(numStreams)).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_OFFSET_COMMIT_INTERVAL).withValue(Integer.toString(offsetCommitInterval)).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_ABORT_ON_SEND_FAILURE).withValue(Boolean.toString(abortOnSendFailure)).build());
-        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(KafkaMirrorMakerCluster.DEFAULT_KAFKA_GC_LOG_ENABLED).build());
+        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_LIVENESS_PERIOD).withValue("10").build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_STRIMZI_READINESS_PERIOD).withValue("10").build());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/TopicOperatorTest.java
Patch:
@@ -106,7 +106,7 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_ZOOKEEPER_SESSION_TIMEOUT_MS).withValue(String.valueOf(tcZookeeperSessionTimeout * 1000)).build());
         expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_TOPIC_METADATA_MAX_ATTEMPTS).withValue(String.valueOf(tcTopicMetadataMaxAttempts)).build());
         expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_TLS_ENABLED).withValue(Boolean.toString(true)).build());
-        expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(TopicOperator.DEFAULT_STRIMZI_GC_LOG_ENABED).build());
+        expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_STRIMZI_GC_LOG_ENABLED).withValue(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)).build());
 
         return expected;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -265,7 +265,7 @@ private void checkStatefulSet(StatefulSet ss) {
         OrderedProperties actual = new OrderedProperties()
                 .addStringPairs(AbstractModel.containerEnvVars(containers.get(0)).get(ZookeeperCluster.ENV_VAR_ZOOKEEPER_CONFIGURATION));
         assertThat(actual, is(expectedConfig));
-        assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(ZookeeperCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(ZookeeperCluster.DEFAULT_KAFKA_GC_LOG_ENABLED));
+        assertThat(AbstractModel.containerEnvVars(containers.get(0)).get(ZookeeperCluster.ENV_VAR_STRIMZI_KAFKA_GC_LOG_ENABLED), is(Boolean.toString(AbstractModel.DEFAULT_JVM_GC_LOGGING_ENABLED)));
         // checks on the TLS sidecar container
         Container tlsSidecarContainer = containers.get(1);
         assertThat(tlsSidecarContainer.getImage(), is(image));

File: api/src/main/java/io/strimzi/api/kafka/model/EntityTopicOperatorSpec.java
Patch:
@@ -83,7 +83,7 @@ public void setReconciliationIntervalSeconds(int reconciliationIntervalSeconds)
         this.reconciliationIntervalSeconds = reconciliationIntervalSeconds;
     }
 
-    @Description("Timeout for the Zookeeper session")
+    @Description("Timeout for the ZooKeeper session")
     @Minimum(0)
     public int getZookeeperSessionTimeoutSeconds() {
         return zookeeperSessionTimeoutSeconds;

File: api/src/main/java/io/strimzi/api/kafka/model/EntityUserOperatorSpec.java
Patch:
@@ -79,7 +79,7 @@ public void setReconciliationIntervalSeconds(long reconciliationIntervalSeconds)
         this.reconciliationIntervalSeconds = reconciliationIntervalSeconds;
     }
 
-    @Description("Timeout for the Zookeeper session")
+    @Description("Timeout for the ZooKeeper session")
     @Minimum(0)
     public long getZookeeperSessionTimeoutSeconds() {
         return zookeeperSessionTimeoutSeconds;

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -57,7 +57,7 @@
                         ),
                         @Crd.Spec.AdditionalPrinterColumn(
                                 name = "Desired ZK replicas",
-                                description = "The desired number of Zookeeper replicas in the cluster",
+                                description = "The desired number of ZooKeeper replicas in the cluster",
                                 jsonPath = ".spec.zookeeper.replicas",
                                 type = "integer"
                         )
@@ -125,7 +125,7 @@ public void setMetadata(ObjectMeta metadata) {
         super.setMetadata(metadata);
     }
 
-    @Description("The specification of the Kafka and Zookeeper clusters, and Topic Operator.")
+    @Description("The specification of the Kafka and ZooKeeper clusters, and Topic Operator.")
     public KafkaSpec getSpec() {
         return spec;
     }
@@ -134,7 +134,7 @@ public void setSpec(KafkaSpec spec) {
         this.spec = spec;
     }
 
-    @Description("The status of the Kafka and Zookeeper clusters, and Topic Operator.")
+    @Description("The status of the Kafka and ZooKeeper clusters, and Topic Operator.")
     public KafkaStatus getStatus() {
         return status;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaSpec.java
Patch:
@@ -57,7 +57,7 @@ public void setKafka(KafkaClusterSpec kafka) {
         this.kafka = kafka;
     }
 
-    @Description("Configuration of the Zookeeper cluster")
+    @Description("Configuration of the ZooKeeper cluster")
     @JsonProperty(required = true)
     public ZookeeperClusterSpec getZookeeper() {
         return zookeeper;

File: certificate-manager/src/test/java/io/strimzi/certs/OpenSslCertManagerTest.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.certs;
 
+import org.junit.jupiter.api.Assumptions;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Test;
 
@@ -34,7 +35,7 @@ public class OpenSslCertManagerTest {
 
     @BeforeAll
     public static void before() throws CertificateException {
-        assertThat(System.getProperty("os.name").contains("nux"), is(true));
+        Assumptions.assumeTrue(System.getProperty("os.name").contains("nux"));
         certFactory = CertificateFactory.getInstance("X.509");
         ssl = new OpenSslCertManager();
     }

File: certificate-manager/src/test/java/io/strimzi/certs/SecretCertProviderTest.java
Patch:
@@ -7,6 +7,7 @@
 import io.fabric8.kubernetes.api.model.OwnerReference;
 import io.fabric8.kubernetes.api.model.OwnerReferenceBuilder;
 import io.fabric8.kubernetes.api.model.Secret;
+import org.junit.jupiter.api.Assumptions;
 import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.BeforeAll;
 
@@ -27,7 +28,7 @@ public class SecretCertProviderTest {
 
     @BeforeAll
     public static void before() {
-        assertThat(System.getProperty("os.name").contains("nux"), is(true));
+        Assumptions.assumeTrue(System.getProperty("os.name").contains("nux"));
         ssl = new OpenSslCertManager();
         secretCertProvider = new SecretCertProvider();
         ownerReference = new OwnerReferenceBuilder()

File: api/src/test/java/io/strimzi/api/kafka/model/ExamplesTest.java
Patch:
@@ -17,7 +17,7 @@
 import io.fabric8.kubernetes.api.model.rbac.ClusterRoleBinding;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.test.TestUtils;
-import org.junit.Test;
+import org.junit.jupiter.api.Test;
 
 import java.io.File;
 import java.io.IOException;
@@ -31,7 +31,8 @@
 import java.util.regex.Pattern;
 import java.util.stream.Collectors;
 
-import static org.junit.Assert.fail;
+import static org.junit.jupiter.api.Assertions.fail;
+
 
 /**
  * The purpose of this test is to check that all the resources in the

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaUserCrdIT.java
Patch:
@@ -10,7 +10,8 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Test;
 
-import static org.junit.jupiter.api.Assertions.assertTrue;
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.MatcherAssert.assertThat;
 
 /**
  * The purpose of this test is to confirm that we can create a
@@ -47,7 +48,7 @@ void testKafkaUserWithMissingRequired() {
         try {
             createDelete(KafkaUser.class, "KafkaUser-with-missing-required.yaml");
         } catch (KubeClusterException.InvalidResource e) {
-            assertTrue(e.getMessage().contains("spec.authentication in body is required"));
+            assertThat(e.getMessage().contains("spec.authentication in body is required"), is(true));
         }
     }
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/BuildConfigOperator.java
Patch:
@@ -35,6 +35,7 @@ protected MixedOperation<BuildConfig, BuildConfigList, DoneableBuildConfig, Buil
     @Override
     protected Future<ReconcileResult<BuildConfig>> internalPatch(String namespace, String name, BuildConfig current, BuildConfig desired) {
         desired.getSpec().setTriggers(current.getSpec().getTriggers());
-        return super.internalPatch(namespace, name, current, desired);
+        // Cascading needs to be set to false to make sure the Builds are not deleted during reconciliation
+        return super.internalPatch(namespace, name, current, desired, false);
     }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/PasswordGenerator.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.user.operator;
+package io.strimzi.operator.common;
 
 import java.security.SecureRandom;
 

File: operator-common/src/test/java/io/strimzi/operator/common/PasswordGeneratorTest.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.user.operator;
+package io.strimzi.operator.common;
 
 import org.junit.Test;
 

File: user-operator/src/main/java/io/strimzi/operator/user/operator/KafkaUserOperator.java
Patch:
@@ -15,6 +15,7 @@
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.model.StatusDiff;
 import io.strimzi.operator.common.AbstractOperator;
+import io.strimzi.operator.common.PasswordGenerator;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.model.NamespaceAndName;
@@ -30,7 +31,7 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
-import java.nio.charset.Charset;
+import java.nio.charset.StandardCharsets;
 import java.util.Base64;
 import java.util.Collection;
 import java.util.List;
@@ -164,7 +165,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaUser r
         String password = null;
 
         if (desired != null && desired.getData().get("password") != null)   {
-            password = new String(Base64.getDecoder().decode(desired.getData().get("password")), Charset.forName("US-ASCII"));
+            password = new String(Base64.getDecoder().decode(desired.getData().get("password")), StandardCharsets.US_ASCII);
         }
 
         Set<SimpleAclRule> tlsAcls = null;

File: user-operator/src/test/java/io/strimzi/operator/user/model/KafkaUserModelTest.java
Patch:
@@ -17,7 +17,7 @@
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.operator.MockCertManager;
 import io.strimzi.operator.user.ResourceUtils;
-import io.strimzi.operator.user.operator.PasswordGenerator;
+import io.strimzi.operator.common.PasswordGenerator;
 import org.junit.Test;
 
 import java.util.Base64;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -263,8 +263,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withVolumeMounts(createVolumeMount(TLS_SIDECAR_EO_CERTS_VOLUME_NAME, TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT),
                         createVolumeMount(TLS_SIDECAR_CA_CERTS_VOLUME_NAME, TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT))
                 .withLifecycle(new LifecycleBuilder().withNewPreStop().withNewExec()
-                            .withCommand("/opt/stunnel/entity_operator_stunnel_pre_stop.sh",
-                                    String.valueOf(templateTerminationGracePeriodSeconds))
+                            .withCommand("/opt/stunnel/entity_operator_stunnel_pre_stop.sh")
                         .endExec().endPreStop().build())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, tlsSidecarImage))
                 .build();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1411,8 +1411,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withVolumeMounts(createVolumeMount(BROKER_CERTS_VOLUME, TLS_SIDECAR_KAFKA_CERTS_VOLUME_MOUNT),
                         createVolumeMount(CLUSTER_CA_CERTS_VOLUME, TLS_SIDECAR_CLUSTER_CA_CERTS_VOLUME_MOUNT))
                 .withLifecycle(new LifecycleBuilder().withNewPreStop()
-                        .withNewExec().withCommand("/opt/stunnel/kafka_stunnel_pre_stop.sh",
-                                String.valueOf(templateTerminationGracePeriodSeconds))
+                        .withNewExec().withCommand("/opt/stunnel/kafka_stunnel_pre_stop.sh")
                         .endExec().endPreStop().build())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, tlsSidecarImage))
                 .build();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -512,8 +512,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                                 createContainerPort(LEADER_ELECTION_PORT_NAME, LEADER_ELECTION_PORT, "TCP"),
                                 createContainerPort(CLIENT_PORT_NAME, CLIENT_PORT, "TCP")))
                 .withLifecycle(new LifecycleBuilder().withNewPreStop()
-                        .withNewExec().withCommand("/opt/stunnel/zookeeper_stunnel_pre_stop.sh",
-                                String.valueOf(templateTerminationGracePeriodSeconds))
+                        .withNewExec().withCommand("/opt/stunnel/zookeeper_stunnel_pre_stop.sh")
                         .endExec().endPreStop().build())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, tlsSidecarImage))
                 .build();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetDiff.java
Patch:
@@ -41,7 +41,6 @@ public class StatefulSetDiff extends AbstractResourceDiff {
         + "|/spec/template/spec/dnsPolicy"
         + "|/spec/template/spec/restartPolicy"
         + "|/spec/template/spec/securityContext"
-        + "|/spec/template/spec/terminationGracePeriodSeconds"
         + "|/spec/template/spec/volumes/[0-9]+/configMap/defaultMode"
         + "|/spec/template/spec/volumes/[0-9]+/secret/defaultMode"
         + "|/spec/volumeClaimTemplates/[0-9]+/status"

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -222,7 +222,6 @@ public void testGracePeriod() {
         assertEquals(Long.valueOf(123), dep.getSpec().getTemplate().getSpec().getTerminationGracePeriodSeconds());
         assertNotNull(dep.getSpec().getTemplate().getSpec().getContainers().get(2).getLifecycle());
         assertTrue(dep.getSpec().getTemplate().getSpec().getContainers().get(2).getLifecycle().getPreStop().getExec().getCommand().contains("/opt/stunnel/entity_operator_stunnel_pre_stop.sh"));
-        assertTrue(dep.getSpec().getTemplate().getSpec().getContainers().get(2).getLifecycle().getPreStop().getExec().getCommand().contains("123"));
     }
 
     @Test
@@ -241,7 +240,6 @@ public void testDefaultGracePeriod() {
         assertEquals(Long.valueOf(30), dep.getSpec().getTemplate().getSpec().getTerminationGracePeriodSeconds());
         assertNotNull(dep.getSpec().getTemplate().getSpec().getContainers().get(2).getLifecycle());
         assertTrue(dep.getSpec().getTemplate().getSpec().getContainers().get(2).getLifecycle().getPreStop().getExec().getCommand().contains("/opt/stunnel/entity_operator_stunnel_pre_stop.sh"));
-        assertTrue(dep.getSpec().getTemplate().getSpec().getContainers().get(2).getLifecycle().getPreStop().getExec().getCommand().contains("30"));
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -1455,7 +1455,6 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
         Lifecycle lifecycle = ss.getSpec().getTemplate().getSpec().getContainers().get(1).getLifecycle();
         assertNotNull(lifecycle);
         assertTrue(lifecycle.getPreStop().getExec().getCommand().contains("/opt/stunnel/kafka_stunnel_pre_stop.sh"));
-        assertTrue(lifecycle.getPreStop().getExec().getCommand().contains("123"));
     }
 
     @Test
@@ -1470,7 +1469,6 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
         Lifecycle lifecycle = ss.getSpec().getTemplate().getSpec().getContainers().get(1).getLifecycle();
         assertNotNull(lifecycle);
         assertTrue(lifecycle.getPreStop().getExec().getCommand().contains("/opt/stunnel/kafka_stunnel_pre_stop.sh"));
-        assertTrue(lifecycle.getPreStop().getExec().getCommand().contains("30"));
     }
 
     /**

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -463,7 +463,6 @@ image, healthDelay, healthTimeout, metricsCmJson, configurationJson, emptyMap())
         Lifecycle lifecycle = ss.getSpec().getTemplate().getSpec().getContainers().get(1).getLifecycle();
         assertNotNull(lifecycle);
         assertTrue(lifecycle.getPreStop().getExec().getCommand().contains("/opt/stunnel/zookeeper_stunnel_pre_stop.sh"));
-        assertTrue(lifecycle.getPreStop().getExec().getCommand().contains("123"));
     }
 
     @Test
@@ -478,7 +477,6 @@ image, healthDelay, healthTimeout, metricsCmJson, configurationJson, emptyMap())
         Lifecycle lifecycle = ss.getSpec().getTemplate().getSpec().getContainers().get(1).getLifecycle();
         assertNotNull(lifecycle);
         assertTrue(lifecycle.getPreStop().getExec().getCommand().contains("/opt/stunnel/zookeeper_stunnel_pre_stop.sh"));
-        assertTrue(lifecycle.getPreStop().getExec().getCommand().contains("30"));
     }
 
     @Test

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -51,6 +51,7 @@ public interface Constants {
     long CO_OPERATION_TIMEOUT_SHORT = Duration.ofSeconds(30).toMillis();
     long CO_OPERATION_TIMEOUT_WAIT = CO_OPERATION_TIMEOUT_SHORT + Duration.ofSeconds(20).toMillis();
     long CO_OPERATION_TIMEOUT_POLL = Duration.ofSeconds(2).toMillis();
+    long RECONCILIATION_INTERVAL = Duration.ofSeconds(30).toMillis();
 
     String KAFKA_CLIENTS = "kafka-clients";
     String STRIMZI_DEPLOYMENT_NAME = "strimzi-cluster-operator";

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -68,7 +68,6 @@ public class Environment {
     private static final String TEST_LOG_DIR_DEFAULT = "../systemtest/target/logs/";
     private static final String STRIMZI_LOG_LEVEL_DEFAULT = "DEBUG";
     static final String KUBERNETES_DOMAIN_DEFAULT = ".nip.io";
-    private static final String STRIMZI_FULL_RECONCILIATION_INTERVAL_MS_DEFAULT = "30000";
     private static final String IMAGE_PULL_POLICY_ENV_DEFAULT = "IfNotPresent";
     public static final int KAFKA_CLIENTS_DEFAULT_PORT = 4242;
 
@@ -79,7 +78,6 @@ public class Environment {
     static final String ST_KAFKA_VERSION = System.getenv().getOrDefault(ST_KAFKA_VERSION_ENV, ST_KAFKA_VERSION_DEFAULT);
     static final String STRIMZI_LOG_LEVEL = System.getenv().getOrDefault(STRIMZI_LOG_LEVEL_ENV, STRIMZI_LOG_LEVEL_DEFAULT);
     static final String KUBERNETES_DOMAIN = System.getenv().getOrDefault(KUBERNETES_DOMAIN_ENV, KUBERNETES_DOMAIN_DEFAULT);
-    public static final String STRIMZI_FULL_RECONCILIATION_INTERVAL_MS = System.getenv().getOrDefault(STRIMZI_FULL_RECONCILIATION_INTERVAL_MS_ENV, STRIMZI_FULL_RECONCILIATION_INTERVAL_MS_DEFAULT);
     static final String SKIP_TEARDOWN = System.getenv(SKIP_TEARDOWN_ENV);
     // variables for test-client image
     private static final String TEST_CLIENT_IMAGE_DEFAULT = STRIMZI_REGISTRY + "/" + STRIMZI_ORG + "/test-client:" + STRIMZI_TAG + "-kafka-" + ST_KAFKA_VERSION;

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicOperator.java
Patch:
@@ -351,6 +351,8 @@ public String toString() {
         }
     }
 
+    protected static final String KAFKA_TOPIC_OPERATOR_NAME = "strimzi-kafka-topic-operator";
+
     public TopicOperator(Vertx vertx, Kafka kafka,
                          K8s k8s,
                          TopicStore topicStore,

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorIT.java
Patch:
@@ -211,7 +211,7 @@ public void testCreateTwoResourcesManagingOneTopic(TestContext context) {
         operation().inNamespace(NAMESPACE).create(topicResource);
 
         waitForEvent(context, topicResource,
-                "Failure processing KafkaTopic watch event ADDED on resource two-resources-one-topic with labels {strimzi.io/kind=topic}: " +
+                "Failure processing KafkaTopic watch event ADDED on resource two-resources-one-topic with labels \\{.*\\}: " +
                         "Topic 'two-resources-one-topic' is already managed via KafkaTopic 'two-resources-one-topic-1' it cannot also be managed via the KafkaTopic 'two-resources-one-topic'",
                 TopicOperator.EventType.WARNING);
     }
@@ -289,7 +289,7 @@ public void testKafkaTopicWithOwnerRef(TestContext context) {
         assertEquals(uid, operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getOwnerReferences().get(0).getUid());
         assertEquals(1, operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getAnnotations().size());
         assertEquals("groot", operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getAnnotations().get("iam"));
-        assertEquals(2, operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().size());
+        assertEquals(5, operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().size());
         assertEquals("root", operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().get("iam"));
 
         // edit kafka topic
@@ -311,7 +311,7 @@ public void testKafkaTopicWithOwnerRef(TestContext context) {
         topicResource = TopicSerialization.toTopicResource(topic3, labels);
         createKafkaTopicResource(context, topicResource);
         assertEquals(uid, operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getOwnerReferences().get(0).getUid());
-        assertEquals(3, operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().size());
+        assertEquals(6, operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().size());
         assertEquals("lee", operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().get("stan"));
         assertEquals("root", operation().inNamespace(NAMESPACE).withName(topicName).get().getMetadata().getLabels().get("iam"));
     }

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorMockTest.java
Patch:
@@ -157,6 +157,7 @@ public void testCreatedWithoutTopicNameInKube(TestContext context) {
                 .withNewMetadata()
                 .withName("my-topic")
                 .addToLabels("strimzi.io/kind", "topic")
+                .addToLabels(io.strimzi.operator.common.model.Labels.KUBERNETES_NAME_LABEL, io.strimzi.operator.common.model.Labels.KUBERNETES_NAME)
                 .endMetadata()
                 .withNewSpec()
                 .withPartitions(1)

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaBridgeCrdIT.java
Patch:
@@ -10,7 +10,7 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Test;
 
-import static org.junit.Assert.assertTrue;
+import static org.junit.jupiter.api.Assertions.assertTrue;
 
 /**
  * The purpose of this test is to confirm that we can create a
@@ -43,7 +43,7 @@ void testKafkaBridgeWithMissingRequired() {
         try {
             createDelete(KafkaBridge.class, "KafkaBridge-with-missing-required-property.yaml");
         } catch (KubeClusterException.InvalidResource e) {
-            assertTrue(e.getMessage(), e.getMessage().contains("spec.bootstrapServers in body is required"));
+            assertTrue(e.getMessage().contains("spec.bootstrapServers in body is required"));
         }
     }
 

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaConnectCrdIT.java
Patch:
@@ -10,7 +10,7 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Test;
 
-import static org.junit.Assert.assertTrue;
+import static org.junit.jupiter.api.Assertions.assertTrue;
 
 /**
  * The purpose of this test is to confirm that we can create a
@@ -47,7 +47,7 @@ void testKafkaConnectWithMissingRequired() {
         try {
             createDelete(KafkaConnect.class, "KafkaConnect-with-missing-required-property.yaml");
         } catch (KubeClusterException.InvalidResource e) {
-            assertTrue(e.getMessage(), e.getMessage().contains("spec.bootstrapServers in body is required"));
+            assertTrue(e.getMessage().contains("spec.bootstrapServers in body is required"));
         }
     }
 

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaCrdIT.java
Patch:
@@ -10,7 +10,7 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Test;
 
-import static org.junit.Assert.assertTrue;
+import static org.junit.jupiter.api.Assertions.assertTrue;
 
 /**
  * The purpose of this test is to confirm that we can create a

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaTopicCrdIT.java
Patch:
@@ -10,7 +10,7 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Test;
 
-import static org.junit.Assert.assertTrue;
+import static org.junit.jupiter.api.Assertions.assertTrue;
 
 /**
  * The purpose of this test is to confirm that we can create a

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaUserCrdIT.java
Patch:
@@ -10,7 +10,7 @@
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Test;
 
-import static org.junit.Assert.assertTrue;
+import static org.junit.jupiter.api.Assertions.assertTrue;
 
 /**
  * The purpose of this test is to confirm that we can create a

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -133,7 +133,7 @@ void createClassResources() throws InterruptedException {
         // Initialize CertSecretSource with certificate and secret names for consumer
         CertSecretSource certSecret = new CertSecretSource();
         certSecret.setCertificate("ca.crt");
-        certSecret.setSecretName(clusterCaCertSecretName(CLUSTER_NAME));
+        certSecret.setSecretName(KafkaResources.clusterCaCertificateSecretName(CLUSTER_NAME));
 
         // Deploy http bridge
         testClassResources().kafkaBridge(CLUSTER_NAME, KafkaResources.tlsBootstrapAddress(CLUSTER_NAME), 1, Constants.HTTP_BRIDGE_DEFAULT_PORT)

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -126,7 +126,7 @@ void createClassResources() throws InterruptedException {
         // Initialize CertSecretSource with certificate and secret names for consumer
         CertSecretSource certSecret = new CertSecretSource();
         certSecret.setCertificate("ca.crt");
-        certSecret.setSecretName(clusterCaCertSecretName(CLUSTER_NAME));
+        certSecret.setSecretName(KafkaResources.clusterCaCertificateSecretName(CLUSTER_NAME));
 
         // Deploy http bridge
         testClassResources().kafkaBridge(CLUSTER_NAME, KafkaResources.tlsBootstrapAddress(CLUSTER_NAME), 1, Constants.HTTP_BRIDGE_DEFAULT_PORT)

File: systemtest/src/test/java/io/strimzi/systemtest/oauth/OauthTlsST.java
Patch:
@@ -153,7 +153,7 @@ void testProducerConsumerBridge(Vertx vertx) throws InterruptedException, Timeou
                 .withTrustedCertificates(
                         new CertSecretSourceBuilder()
                                 .withCertificate("ca.crt")
-                                .withSecretName(clusterCaCertSecretName(CLUSTER_NAME)).build())
+                                .withSecretName(KafkaResources.clusterCaCertificateSecretName(CLUSTER_NAME)).build())
                 .endTls()
                 .withNewKafkaClientAuthenticationOAuth()
                 .withTokenEndpointUri(oauthTokenEndpointUri)
@@ -302,7 +302,7 @@ private void deployKafkaStreamsOauthTls() {
                 .withName("CA_CRT")
                 .withNewValueFrom()
                 .withNewSecretKeyRef()
-                .withName(clusterCaCertSecretName(CLUSTER_NAME))
+                .withName(KafkaResources.clusterCaCertificateSecretName(CLUSTER_NAME))
                 .withKey("ca.crt")
                 .endSecretKeyRef()
                 .endValueFrom()

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -587,7 +587,7 @@ public static void waitForKafkaUserDeletion(String userName) {
 
     public static void waitForKafkaUserCreationError(String userName, String eoPodName) {
         String errorMessage = "InvalidResourceException: Users with TLS client authentication can have a username (name of the KafkaUser custom resource) only up to 64 characters long.";
-        final String messageUserWasNotAdded = "KafkaUser(" + kubeClient().getNamespace() + "/" + userName + "): createOrUpdate failed";
+        final String messageUserWasNotAdded = "User(" + kubeClient().getNamespace() + "/" + userName + "): createOrUpdate failed";
         TestUtils.waitFor("User operator has expected error", Constants.GLOBAL_POLL_INTERVAL, 60000,
             () -> {
                 String logs = kubeClient().logs(eoPodName, "user-operator");

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -144,7 +144,7 @@ void testKafkaMirrorMakerStatusWrongBootstrap() {
 
     @Test
     void testKafkaBridgeStatus() {
-        String bridgeUrl = "http://my-cluster-bridge-bridge-service.status-cluster-test.svc:8080";
+        String bridgeUrl = "http://my-cluster-bridge-service.status-cluster-test.svc:8080";
         testMethodResources().kafkaBridge(CLUSTER_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), 1, Constants.HTTP_BRIDGE_DEFAULT_PORT).done();
         waitForKafkaBridgeStatus("Ready");
         assertKafkaBridgeStatus(1, bridgeUrl);
@@ -223,7 +223,7 @@ void createClassResources() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        testClassResources().clusterOperator(NAMESPACE).done();
+        testClassResources().clusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_SHORT).done();
 
         deployTestSpecificResources();
     }

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -253,7 +253,6 @@ void autoRenewSomeCaCertsTriggeredByAnno(
 
     @Test
     @OpenShiftOnly
-    @Tag(ACCEPTANCE)
     void testAutoRenewClusterCaCertsTriggeredByAnno() throws Exception {
         autoRenewSomeCaCertsTriggeredByAnno(asList(
                 clusterCaCertificateSecretName(CLUSTER_NAME)),
@@ -267,7 +266,6 @@ void testAutoRenewClusterCaCertsTriggeredByAnno() throws Exception {
 
     @Test
     @OpenShiftOnly
-    @Tag(ACCEPTANCE)
     void testAutoRenewClientsCaCertsTriggeredByAnno() throws Exception {
         autoRenewSomeCaCertsTriggeredByAnno(asList(
                 clientsCaCertificateSecretName(CLUSTER_NAME)),

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -47,7 +47,7 @@ void testUserWithNameMoreThan64Chars() {
         testMethodResources().tlsUser(CLUSTER_NAME, userWithCorrectName).done();
         StUtils.waitForSecretReady(userWithCorrectName);
 
-        String messageUserWasAdded = "KafkaUser " + userWithCorrectName + " in namespace " + NAMESPACE + " was ADDED";
+        String messageUserWasAdded = "User " + userWithCorrectName + " in namespace " + NAMESPACE + " was ADDED";
         String errorMessage = "InvalidResourceException: Users with TLS client authentication can have a username (name of the KafkaUser custom resource) only up to 64 characters long.";
 
         // Checking UO logs
@@ -62,7 +62,7 @@ void testUserWithNameMoreThan64Chars() {
 
         // Checking UO logs
         uOlogs = kubeClient().logs(entityOperatorPodName, "user-operator");
-        messageUserWasAdded = "KafkaUser " + saslUserWithLongName + " in namespace " + NAMESPACE + " was ADDED";
+        messageUserWasAdded = "User " + saslUserWithLongName + " in namespace " + NAMESPACE + " was ADDED";
         assertThat(uOlogs, containsString(messageUserWasAdded));
         assertThat(uOlogs, not(containsString(errorMessage)));
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -43,7 +43,6 @@
 import io.strimzi.api.kafka.model.connect.ExternalConfigurationEnvVarSource;
 import io.strimzi.api.kafka.model.connect.ExternalConfigurationVolumeSource;
 import io.strimzi.api.kafka.model.template.KafkaConnectTemplate;
-import io.strimzi.api.kafka.model.tracing.JaegerTracing;
 import io.strimzi.api.kafka.model.tracing.Tracing;
 import io.strimzi.operator.common.model.Labels;
 
@@ -146,7 +145,7 @@ protected static <C extends KafkaConnectCluster> C fromSpec(KafkaConnectSpec spe
         kafkaConnect.tracing = spec.getTracing();
 
         KafkaConnectConfiguration config = new KafkaConnectConfiguration(spec.getConfig().entrySet());
-        if (kafkaConnect.tracing != null && JaegerTracing.TYPE_JAEGER.equals(kafkaConnect.tracing.getType()))   {
+        if (kafkaConnect.tracing != null)   {
             config.setConfigOption("consumer.interceptor.classes", "io.opentracing.contrib.kafka.TracingConsumerInterceptor");
             config.setConfigOption("producer.interceptor.classes", "io.opentracing.contrib.kafka.TracingProducerInterceptor");
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -32,7 +32,6 @@
 import io.strimzi.api.kafka.model.Probe;
 import io.strimzi.api.kafka.model.ProbeBuilder;
 import io.strimzi.api.kafka.model.template.KafkaMirrorMakerTemplate;
-import io.strimzi.api.kafka.model.tracing.JaegerTracing;
 import io.strimzi.api.kafka.model.tracing.Tracing;
 import io.strimzi.operator.common.model.Labels;
 
@@ -352,7 +351,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
     private KafkaMirrorMakerConsumerConfiguration getConsumerConfiguration()    {
         KafkaMirrorMakerConsumerConfiguration config = new KafkaMirrorMakerConsumerConfiguration(consumer.getConfig().entrySet());
 
-        if (tracing != null && JaegerTracing.TYPE_JAEGER.equals(tracing.getType())) {
+        if (tracing != null) {
             config.setConfigOption("interceptor.classes", "io.opentracing.contrib.kafka.TracingConsumerInterceptor");
         }
 
@@ -362,7 +361,7 @@ private KafkaMirrorMakerConsumerConfiguration getConsumerConfiguration()    {
     private KafkaMirrorMakerProducerConfiguration getProducerConfiguration()    {
         KafkaMirrorMakerProducerConfiguration config = new KafkaMirrorMakerProducerConfiguration(producer.getConfig().entrySet());
 
-        if (tracing != null && JaegerTracing.TYPE_JAEGER.equals(tracing.getType())) {
+        if (tracing != null) {
             config.setConfigOption("interceptor.classes", "io.opentracing.contrib.kafka.TracingProducerInterceptor");
         }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractModelTest.java
Patch:
@@ -246,7 +246,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
             }
         };
         Volume volume = am.createEmptyDirVolume("bar", null);
-        Assert.assertNull(volume.getEmptyDir().getSizeLimit().getAmount());
+        Assert.assertNull(volume.getEmptyDir().getSizeLimit());
     }
 
     @Test
@@ -263,6 +263,6 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
             }
         };
         Volume volume = am.createEmptyDirVolume("bar", "");
-        Assert.assertNull(volume.getEmptyDir().getSizeLimit().getAmount());
+        Assert.assertNull(volume.getEmptyDir().getSizeLimit());
     }
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -302,7 +302,7 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
                 .build();
         KafkaCluster kc = KafkaCluster.fromCrd(kafkaAssembly, VERSIONS);
         StatefulSet ss = kc.generateStatefulSet(false, null, null);
-        assertNull(ss.getSpec().getTemplate().getSpec().getVolumes().get(0).getEmptyDir().getSizeLimit().getAmount());
+        assertNull(ss.getSpec().getTemplate().getSpec().getVolumes().get(0).getEmptyDir().getSizeLimit());
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -976,7 +976,7 @@ public void testGenerateSTSWithPersistentVolumeEphemeral()    {
         ZookeeperCluster zc = ZookeeperCluster.fromCrd(ka, VERSIONS);
 
         StatefulSet ss = zc.generateStatefulSet(false, null, null);
-        assertNull(ss.getSpec().getTemplate().getSpec().getVolumes().get(0).getEmptyDir().getSizeLimit().getAmount());
+        assertNull(ss.getSpec().getTemplate().getSpec().getVolumes().get(0).getEmptyDir().getSizeLimit());
     }
 
     @Test

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeResources.java
Patch:
@@ -50,12 +50,12 @@ public static String serviceAccountName(String clusterName) {
 
     /**
      * Returns the URL of the Kafka Bridge for a {@code KafkaBridge} cluster of the given name.
-     * @param bridgeName  The {@code metadata.name} of the {@code KafkaBridge} resource.
+     * @param clusterName  The {@code metadata.name} of the {@code KafkaBridge} resource.
      * @param namespace The namespace where the {@code KafkaBridge} cluster is running.
      * @param port The port on which the {@code KafkaBridge} is available.
      * @return The URL of {@code KafkaBridge}.
      */
-    public static String url(String bridgeName, String namespace, int port) {
-        return "http://" + serviceName(bridgeName) + "." + namespace + ".svc:" + port;
+    public static String url(String clusterName, String namespace, int port) {
+        return "http://" + serviceName(clusterName) + "." + namespace + ".svc:" + port;
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -108,7 +108,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge
                 if (bridge.getHttp() != null) {
                     port = bridge.getHttp().getPort();
                 }
-                kafkaBridgeStatus.setUrl(KafkaBridgeResources.url(bridge.getName(), namespace, port));
+                kafkaBridgeStatus.setUrl(KafkaBridgeResources.url(bridge.getCluster(), namespace, port));
 
                 updateStatus(assemblyResource, reconciliation, kafkaBridgeStatus).setHandler(statusResult -> {
                     // If both features succeeded, createOrUpdate succeeded as well

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -172,7 +172,7 @@ public void testCreateCluster(TestContext context) {
 
             // Verify status
             List<KafkaBridge> capturedStatuses = bridgeCaptor.getAllValues();
-            context.assertEquals(capturedStatuses.get(0).getStatus().getUrl(), "http://foo-bridge-bridge-service.test.svc:8080");
+            context.assertEquals(capturedStatuses.get(0).getStatus().getUrl(), "http://foo-bridge-service.test.svc:8080");
             context.assertEquals(capturedStatuses.get(0).getStatus().getConditions().get(0).getStatus(), "True");
             context.assertEquals(capturedStatuses.get(0).getStatus().getConditions().get(0).getType(), "Ready");
 
@@ -667,7 +667,7 @@ public void testCreateClusterStatusNotReady(TestContext context) {
 
             // Verify status
             List<KafkaBridge> capturedStatuses = bridgeCaptor.getAllValues();
-            context.assertEquals(capturedStatuses.get(0).getStatus().getUrl(), "http://foo-bridge-bridge-service.test.svc:8080");
+            context.assertEquals(capturedStatuses.get(0).getStatus().getUrl(), "http://foo-bridge-service.test.svc:8080");
             context.assertEquals(capturedStatuses.get(0).getStatus().getConditions().get(0).getStatus(), "True");
             context.assertEquals(capturedStatuses.get(0).getStatus().getConditions().get(0).getType(), "NotReady");
 

File: systemtest/src/main/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -668,7 +668,7 @@ protected void recreateTestEnv(String coNamespace, List<String> bindingsNamespac
 
         applyRoleBindings(coNamespace, bindingsNamespaces);
         // 050-Deployment
-        testClassResources().clusterOperator(coNamespace, operationTimeout).done();
+        testClassResources().clusterOperator(coNamespace).done();
     }
 
     /**
@@ -953,6 +953,7 @@ protected void tearDownEnvironmentAfterAll() {
 
     @AfterEach
     void teardownEnvironmentMethod(ExtensionContext context) throws Exception {
+        assertNoCoErrorsLogged(0);
         if (Environment.SKIP_TEARDOWN == null) {
             if (context.getExecutionException().isPresent()) {
                 LOGGER.info("Test execution contains exception, going to recreate test environment");

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -223,7 +223,7 @@ void createClassResources() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        testClassResources().clusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_SHORT).done();
+        testClassResources().clusterOperator(NAMESPACE).done();
 
         deployTestSpecificResources();
     }

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -918,6 +918,7 @@ void testRemoveUserOperatorFromEntityOperator() {
         //Waiting when EO pod will be recreated without UO
         StUtils.waitForPodDeletion(eoPodName);
         StUtils.waitForDeploymentReady(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), 1);
+        StUtils.waitUntilPodContainersCount(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME), 2);
 
         //Checking that UO was removed
         kubeClient().listPodsByPrefixInName(KafkaResources.entityOperatorDeploymentName(CLUSTER_NAME)).forEach(pod -> {
@@ -1955,6 +1956,7 @@ void createTestResources() {
 
     @AfterEach
     void deleteTestResources() throws Exception {
+        kubeClient().getClient().persistentVolumeClaims().inNamespace(NAMESPACE).delete();
         deleteTestMethodResources();
         waitForDeletion(Constants.TIMEOUT_TEARDOWN);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -143,7 +143,7 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        testClassResources().clusterOperator(NAMESPACE, Constants.CO_OPERATION_TIMEOUT_SHORT).done();
+        testClassResources().clusterOperator(NAMESPACE).done();
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -47,6 +47,7 @@
 @Tag(NODEPORT_SUPPORTED)
 @Tag(REGRESSION)
 @Tag(TRACING)
+@Tag(REGRESSION)
 public class TracingST extends AbstractST {
 
     private static final String NAMESPACE = "tracing-cluster-test";

File: test/src/main/java/io/strimzi/test/BaseITST.java
Patch:
@@ -157,7 +157,7 @@ protected void createNamespaces(String useNamespace, List<String> namespaces) {
         bindingsNamespaces = namespaces;
         for (String namespace: namespaces) {
 
-            if (kubeClient().getNamespace(namespace) != null) {
+            if (kubeClient().getNamespace(namespace) != null && System.getenv("SKIP_TEARDOWN") == null) {
                 LOGGER.warn("Namespace {} is already created, going to delete it", namespace);
                 kubeClient().deleteNamespace(namespace);
                 cmdKubeClient().waitForResourceDeletion("Namespace", namespace);

File: test/src/main/java/io/strimzi/test/k8s/KubeClient.java
Patch:
@@ -363,11 +363,11 @@ public boolean deleteSecret(String secretName) {
     }
 
     public Service createService(Service service) {
-        return client.services().inNamespace(getNamespace()).create(service);
+        return client.services().inNamespace(getNamespace()).createOrReplace(service);
     }
 
     public Ingress createIngress(Ingress ingress) {
-        return client.extensions().ingresses().inNamespace(getNamespace()).create(ingress);
+        return client.extensions().ingresses().inNamespace(getNamespace()).createOrReplace(ingress);
     }
 
     public Boolean deleteIngress(Ingress ingress) {

File: systemtest/src/main/java/io/strimzi/systemtest/MessagingBaseST.java
Patch:
@@ -31,7 +31,7 @@ public class MessagingBaseST extends AbstractST {
      * Simple availability check for kafka cluster
      * @param clusterName cluster name
      */
-    void availabilityTest(String clusterName) throws Exception {
+    public void availabilityTest(String clusterName) throws Exception {
         availabilityTest(100, clusterName, false, "my-topic", null);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/tracing/TracingST.java
Patch:
@@ -36,13 +36,16 @@
 import static io.restassured.RestAssured.given;
 
 import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
+import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.Constants.TRACING;
 import static io.strimzi.test.TestUtils.getFileAsString;
 import static org.hamcrest.CoreMatchers.hasItem;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.anything;
 import static org.hamcrest.Matchers.greaterThan;
 
+@Tag(NODEPORT_SUPPORTED)
+@Tag(REGRESSION)
 @Tag(TRACING)
 public class TracingST extends AbstractST {
 
@@ -556,7 +559,6 @@ void testProducerConsumerMirrorMakerConnectStreamsService() throws Exception {
         final String kafkaClusterSourceName = CLUSTER_NAME + "-source";
         final String kafkaClusterTargetName = CLUSTER_NAME + "-target";
 
-        testMethodResources().kafkaEphemeral(kafkaClusterSourceName, 1, 1).done();
         testMethodResources().kafkaEphemeral(kafkaClusterTargetName, 1, 1)
                 .editSpec()
                     .editKafka()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConfigurationTests.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.operator.cluster.model;
 
+import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import org.junit.Test;
 
 import static java.util.Collections.singletonList;
@@ -12,8 +13,7 @@
 
 public class KafkaConfigurationTests {
 
-    KafkaVersion kafkaVersion = new KafkaVersion.Lookup(
-            null, null, null, null).defaultVersion();
+    KafkaVersion kafkaVersion = KafkaVersionTestUtils.getKafkaVersionLookup().defaultVersion();
 
     void assertConfigError(String key, Object value, String errorMsg) {
         KafkaConfiguration kafkaConfiguration = new KafkaConfiguration(singletonMap(key, value).entrySet());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -16,6 +16,7 @@
 import io.strimzi.api.kafka.model.KafkaBridgeResources;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
+import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaBridgeCluster;
@@ -66,8 +67,8 @@
 @RunWith(VertxUnitRunner.class)
 public class KafkaBridgeAssemblyOperatorTest {
 
-    private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(Collections.emptyMap(),
-            Collections.emptyMap(), Collections.emptyMap(), Collections.emptyMap());
+    private static final KafkaVersion.Lookup VERSIONS = KafkaVersionTestUtils.getKafkaVersionLookup();
+
     protected static Vertx vertx;
     private static final String METRICS_CONFIG = "{\"foo\":\"bar\"}";
     private static final String LOGGING_CONFIG = AbstractModel.getOrderedProperties("kafkaBridgeDefaultLoggingProperties")

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -17,6 +17,7 @@
 import io.strimzi.api.kafka.model.KafkaMirrorMakerResources;
 import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
+import io.strimzi.operator.cluster.KafkaVersionTestUtils;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaMirrorMakerCluster;
@@ -67,7 +68,7 @@
 @RunWith(VertxUnitRunner.class)
 public class KafkaMirrorMakerAssemblyOperatorTest {
 
-    private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(Collections.emptyMap(), Collections.emptyMap(), Collections.emptyMap(), Collections.singletonMap("2.0.0", "strimzi/kafka-mirror-maker:latest-kafka-2.0.0"));
+    private static final KafkaVersion.Lookup VERSIONS = KafkaVersionTestUtils.getKafkaVersionLookup();
     protected static Vertx vertx;
     private static final String METRICS_CONFIG = "{\"foo\":\"bar\"}";
     private static final String LOGGING_CONFIG = AbstractModel.getOrderedProperties("mirrorMakerDefaultLoggingProperties")

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -530,6 +530,7 @@ private KafkaConnectS2IBuilder defaultKafkaConnectS2I(String name, String kafkaC
                 .withNewTls()
                 .withTrustedCertificates(new CertSecretSourceBuilder().withNewSecretName(kafkaClusterName + "-cluster-ca-cert").withCertificate("ca.crt").build())
                 .endTls()
+                .withInsecureSourceRepository(true)
             .endSpec();
     }
 
@@ -564,12 +565,12 @@ private KafkaMirrorMakerBuilder defaultMirrorMaker(String name, String sourceBoo
             .withNewSpec()
                 .withVersion(KAFKA_VERSION)
                 .withNewConsumer()
-                    .withBootstrapServers(tlsListener ? sourceBootstrapServer + "-kafka-bootstrap:9093" : sourceBootstrapServer + "-kafka-bootstrap:9092")
+                    .withBootstrapServers(tlsListener ? KafkaResources.tlsBootstrapAddress(sourceBootstrapServer) : KafkaResources.plainBootstrapAddress(sourceBootstrapServer))
                     .withGroupId(groupId)
                     .addToConfig(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest")
                 .endConsumer()
                 .withNewProducer()
-                    .withBootstrapServers(tlsListener ? targetBootstrapServer + "-kafka-bootstrap:9093" : targetBootstrapServer + "-kafka-bootstrap:9092")
+                .withBootstrapServers(tlsListener ? KafkaResources.tlsBootstrapAddress(targetBootstrapServer) : KafkaResources.plainBootstrapAddress(targetBootstrapServer))
                     .addToConfig(ProducerConfig.ACKS_CONFIG, "all")
                 .endProducer()
                 .withResources(new ResourceRequirementsBuilder()

File: systemtest/src/test/java/io/strimzi/systemtest/HelmChartST.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest;
 
+import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.systemtest.utils.StUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -29,8 +30,8 @@ class HelmChartST extends AbstractST {
     void testDeployKafkaClusterViaHelmChart() {
         testMethodResources().kafkaEphemeral(CLUSTER_NAME, 3).done();
         testMethodResources().topic(CLUSTER_NAME, TOPIC_NAME).done();
-        StUtils.waitForAllStatefulSetPodsReady(zookeeperClusterName(CLUSTER_NAME), 3);
-        StUtils.waitForAllStatefulSetPodsReady(kafkaClusterName(CLUSTER_NAME), 3);
+        StUtils.waitForAllStatefulSetPodsReady(KafkaResources.zookeeperStatefulSetName(CLUSTER_NAME), 3);
+        StUtils.waitForAllStatefulSetPodsReady(KafkaResources.kafkaStatefulSetName(CLUSTER_NAME), 3);
     }
 
     @BeforeEach

File: systemtest/src/test/java/io/strimzi/systemtest/MirrorMakerST.java
Patch:
@@ -90,10 +90,10 @@ void testMirrorMaker() throws Exception {
         verifyLabelsForConfigMaps(kafkaClusterSourceName, null, kafkaClusterTargetName);
         verifyLabelsForServiceAccounts(kafkaClusterSourceName, null);
 
-        String podName = kubeClient().listPods().stream().filter(n -> n.getMetadata().getName().startsWith(kafkaMirrorMakerName(CLUSTER_NAME))).findFirst().get().getMetadata().getName();
+        String podName = kubeClient().listPods().stream().filter(n -> n.getMetadata().getName().startsWith(KafkaMirrorMakerResources.deploymentName(CLUSTER_NAME))).findFirst().get().getMetadata().getName();
         assertResources(NAMESPACE, podName, CLUSTER_NAME.concat("-mirror-maker"),
                 "400M", "2", "300M", "1");
-        assertExpectedJavaOpts(podName, kafkaMirrorMakerName(CLUSTER_NAME),
+        assertExpectedJavaOpts(podName, KafkaMirrorMakerResources.deploymentName(CLUSTER_NAME),
                 "-Xmx200m", "-Xms200m", "-server", "-XX:+UseG1GC");
 
         TimeMeasuringSystem.stopOperation(getOperationID());

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -876,6 +876,7 @@ void testRemoveTopicOperatorFromEntityOperator() {
         //Waiting when EO pod will be recreated without TO
         StUtils.waitForPodDeletion(eoPodName);
         StUtils.waitForDeploymentReady(entityOperatorDeploymentName(CLUSTER_NAME), 1);
+        StUtils.waitUntilPodContainersCount(entityOperatorDeploymentName(CLUSTER_NAME), 2);
 
         //Checking that TO was removed
         kubeClient().listPodsByPrefixInName(entityOperatorDeploymentName(CLUSTER_NAME)).forEach(pod -> {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -52,7 +52,6 @@ public abstract class AbstractAssemblyOperator<C extends KubernetesClient, T ext
     protected static final int LOCK_TIMEOUT_MS = 10000;
 
     protected final PlatformFeaturesAvailability pfa;
-    protected final AbstractWatchableResourceOperator<C, T, L, D, R> resourceOperator;
     protected final SecretOperator secretOperations;
     protected final CertManager certManager;
     protected final NetworkPolicyOperator networkPolicyOperator;
@@ -82,7 +81,6 @@ protected AbstractAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability pfa
                                        ClusterOperatorConfig config) {
         super(vertx, kind, resourceOperator);
         this.pfa = pfa;
-        this.resourceOperator = resourceOperator;
         this.certManager = certManager;
         this.secretOperations = supplier.secretOperations;
         this.networkPolicyOperator = supplier.networkPolicyOperator;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -91,6 +91,7 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
+import java.util.Optional;
 import java.util.Set;
 import java.util.TreeSet;
 import java.util.concurrent.CopyOnWriteArraySet;
@@ -1085,7 +1086,7 @@ public void testReconcile(TestContext context) throws InterruptedException {
 
         Kafka foo = getKafkaAssembly("foo");
         Kafka bar = getKafkaAssembly("bar");
-        when(mockKafkaOps.listAsync(eq(clusterCmNamespace), any())).thenReturn(
+        when(mockKafkaOps.listAsync(eq(clusterCmNamespace), any(Optional.class))).thenReturn(
             Future.succeededFuture(asList(foo, bar))
         );
         // when requested Custom Resource for a specific Kafka cluster
@@ -1175,7 +1176,7 @@ public void testReconcileAllNamespaces(TestContext context) throws InterruptedEx
         foo.getMetadata().setNamespace("namespace1");
         Kafka bar = getKafkaAssembly("bar");
         bar.getMetadata().setNamespace("namespace2");
-        when(mockKafkaOps.listAsync(eq("*"), any())).thenReturn(
+        when(mockKafkaOps.listAsync(eq("*"), any(Optional.class))).thenReturn(
                 Future.succeededFuture(asList(foo, bar))
         );
         // when requested Custom Resource for a specific Kafka cluster

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -14,12 +14,12 @@
 import io.strimzi.api.kafka.model.KafkaBridgeHttpConfig;
 import io.strimzi.api.kafka.model.KafkaBridgeProducerSpec;
 import io.strimzi.api.kafka.model.KafkaBridgeResources;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaBridgeCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
@@ -48,6 +48,7 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
+import java.util.Optional;
 import java.util.Set;
 import java.util.concurrent.CopyOnWriteArraySet;
 
@@ -573,7 +574,7 @@ public void testReconcile(TestContext context) {
         KafkaBridge bar = ResourceUtils.createKafkaBridgeCluster(clusterCmNamespace, "bar", image, 1,
                 BOOTSTRAP_SERVERS, KAFKA_BRIDGE_PRODUCER_SPEC, KAFKA_BRIDGE_CONSUMER_SPEC, KAFKA_BRIDGE_HTTP_SPEC, metricsCm);
 
-        when(mockBridgeOps.listAsync(eq(clusterCmNamespace), any())).thenReturn(Future.succeededFuture(asList(foo, bar)));
+        when(mockBridgeOps.listAsync(eq(clusterCmNamespace), any(Optional.class))).thenReturn(Future.succeededFuture(asList(foo, bar)));
         when(mockBridgeOps.getAsync(anyString(), anyString())).thenReturn(Future.succeededFuture(bar));
         when(mockBridgeOps.updateStatusAsync(any(KafkaBridge.class))).thenReturn(Future.succeededFuture());
         // when requested ConfigMap for a specific Kafka Bridge cluster

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -46,6 +46,7 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
+import java.util.Optional;
 import java.util.Set;
 import java.util.concurrent.CopyOnWriteArraySet;
 
@@ -529,7 +530,7 @@ public void testReconcile(TestContext context) {
 
         KafkaConnect foo = ResourceUtils.createEmptyKafkaConnectCluster(clusterCmNamespace, "foo");
         KafkaConnect bar = ResourceUtils.createEmptyKafkaConnectCluster(clusterCmNamespace, "bar");
-        when(mockConnectOps.listAsync(eq(clusterCmNamespace), any())).thenReturn(Future.succeededFuture(asList(foo, bar)));
+        when(mockConnectOps.listAsync(eq(clusterCmNamespace), any(Optional.class))).thenReturn(Future.succeededFuture(asList(foo, bar)));
         // when requested ConfigMap for a specific Kafka Connect cluster
         when(mockConnectOps.get(eq(clusterCmNamespace), eq("foo"))).thenReturn(foo);
         when(mockConnectOps.get(eq(clusterCmNamespace), eq("bar"))).thenReturn(bar);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperatorTest.java
Patch:
@@ -51,6 +51,7 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
+import java.util.Optional;
 import java.util.Set;
 import java.util.concurrent.CopyOnWriteArraySet;
 
@@ -666,7 +667,7 @@ public void testReconcile(TestContext context) {
 
         KafkaConnectS2I foo = ResourceUtils.createEmptyKafkaConnectS2ICluster(clusterCmNamespace, "foo");
         KafkaConnectS2I bar = ResourceUtils.createEmptyKafkaConnectS2ICluster(clusterCmNamespace, "bar");
-        when(mockConnectOps.listAsync(eq(clusterCmNamespace), any())).thenReturn(Future.succeededFuture(asList(foo, bar)));
+        when(mockConnectOps.listAsync(eq(clusterCmNamespace), any(Optional.class))).thenReturn(Future.succeededFuture(asList(foo, bar)));
         // when requested ConfigMap for a specific Kafka Connect S2I cluster
         when(mockConnectOps.get(eq(clusterCmNamespace), eq("foo"))).thenReturn(foo);
         when(mockConnectOps.get(eq(clusterCmNamespace), eq("bar"))).thenReturn(bar);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -15,12 +15,12 @@
 import io.strimzi.api.kafka.model.KafkaMirrorMakerProducerSpec;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerProducerSpecBuilder;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerResources;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaMirrorMakerCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
@@ -49,6 +49,7 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
+import java.util.Optional;
 import java.util.Set;
 import java.util.concurrent.CopyOnWriteArraySet;
 
@@ -633,7 +634,7 @@ public void testReconcile(TestContext context) {
         KafkaMirrorMaker foo = ResourceUtils.createKafkaMirrorMakerCluster(clusterCmNamespace, "foo", image, producer, consumer, whitelist, metricsCm);
         KafkaMirrorMaker bar = ResourceUtils.createKafkaMirrorMakerCluster(clusterCmNamespace, "bar", image, producer, consumer, whitelist, metricsCm);
 
-        when(mockMirrorOps.listAsync(eq(clusterCmNamespace), any())).thenReturn(Future.succeededFuture(asList(foo, bar)));
+        when(mockMirrorOps.listAsync(eq(clusterCmNamespace), any(Optional.class))).thenReturn(Future.succeededFuture(asList(foo, bar)));
         // when requested ConfigMap for a specific Kafka Mirror Maker cluster
         when(mockMirrorOps.get(eq(clusterCmNamespace), eq("foo"))).thenReturn(foo);
         when(mockMirrorOps.get(eq(clusterCmNamespace), eq("bar"))).thenReturn(bar);

File: user-operator/src/test/java/io/strimzi/operator/user/operator/KafkaUserOperatorTest.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.operator.user.operator;
 
+import io.fabric8.kubernetes.api.model.LabelSelector;
 import io.fabric8.kubernetes.api.model.Secret;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.strimzi.certs.CertManager;
@@ -30,6 +31,7 @@
 import java.util.Base64;
 import java.util.HashSet;
 import java.util.List;
+import java.util.Optional;
 import java.util.Set;
 import java.util.concurrent.CopyOnWriteArraySet;
 
@@ -586,7 +588,7 @@ public void testReconcileAll(TestContext context)    {
         KafkaUser existingScramShaUser = ResourceUtils.createKafkaUserTls();
         existingScramShaUser.getMetadata().setName("existing-scram-sha-user");
 
-        when(mockCrdOps.listAsync(eq(ResourceUtils.NAMESPACE), eq(Labels.userLabels(ResourceUtils.LABELS)))).thenReturn(
+        when(mockCrdOps.listAsync(eq(ResourceUtils.NAMESPACE), eq(Optional.of(new LabelSelector(null, Labels.userLabels(ResourceUtils.LABELS).toMap()))))).thenReturn(
                 Future.succeededFuture(Arrays.asList(newTlsUser, newScramShaUser, existingTlsUser, existingScramShaUser)));
         when(mockSecretOps.list(eq(ResourceUtils.NAMESPACE), eq(Labels.userLabels(ResourceUtils.LABELS).withKind(KafkaUser.RESOURCE_KIND)))).thenReturn(Arrays.asList(existingTlsUserSecret, existingScramShaUserSecret));
         when(aclOps.getUsersWithAcls()).thenReturn(new HashSet<String>(Arrays.asList("existing-tls-user", "second-deleted-user")));

File: systemtest/src/test/java/io/strimzi/systemtest/HelmChartST.java
Patch:
@@ -14,9 +14,9 @@
 
 import java.util.List;
 
-import static io.strimzi.systemtest.Constants.REGRESSION;
+import static io.strimzi.systemtest.Constants.HELM;
 
-@Tag(REGRESSION)
+@Tag(HELM)
 class HelmChartST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(HelmChartST.class);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -413,6 +413,8 @@ public static KafkaCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup vers
 
         if (oldStorage != null) {
             Storage newStorage = kafkaClusterSpec.getStorage();
+            AbstractModel.validatePersistentStorage(newStorage);
+
             StorageDiff diff = new StorageDiff(oldStorage, newStorage);
 
             if (!diff.isEmpty()) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -209,6 +209,8 @@ public static ZookeeperCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup
 
         if (oldStorage != null) {
             Storage newStorage = zookeeperClusterSpec.getStorage();
+            AbstractModel.validatePersistentStorage(newStorage);
+
             StorageDiff diff = new StorageDiff(oldStorage, newStorage);
 
             if (!diff.isEmpty()) {

File: systemtest/src/main/java/io/strimzi/systemtest/clients/api/VerifiableClient.java
Patch:
@@ -153,7 +153,7 @@ private ArrayList<String> prepareCommand() {
      * @return exit status of client
      */
     public boolean run() {
-        return runClient(60000, true);
+        return runClient(120_000, true);
     }
 
     /**

File: api/src/test/java/io/strimzi/api/kafka/model/ExamplesTest.java
Patch:
@@ -86,7 +86,7 @@ private void validate(String content) {
         // This uses a custom deserializer which knows about all the built-in
         // k8s and os kinds, plus the custom kinds registered via Crds
         // But the custom deserializer always allows unknown properties
-        KubernetesResource<?> resource = TestUtils.fromYamlString(content, KubernetesResource.class, false);
+        KubernetesResource resource = TestUtils.fromYamlString(content, KubernetesResource.class, false);
         recurseForAdditionalProperties(new Stack(), resource);
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -53,7 +53,6 @@
 import io.strimzi.api.kafka.model.KafkaConnectBuilder;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaConnectS2IBuilder;
-import io.strimzi.api.kafka.model.KafkaConnectS2IResources;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerBuilder;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerResources;
@@ -662,7 +661,7 @@ private void waitForDeletion(KafkaConnect kafkaConnect) {
     private void waitForDeletion(KafkaConnectS2I kafkaConnectS2I) {
         LOGGER.info("Waiting when all the pods are terminated for Kafka Connect S2I {}", kafkaConnectS2I.getMetadata().getName());
 
-        client().deleteDeploymentConfig(KafkaConnectS2IResources.buildConfigName(kafkaConnectS2I.getMetadata().getName()));
+        // client().deleteDeploymentConfig(KafkaConnectS2IResources.buildConfigName(kafkaConnectS2I.getMetadata().getName()));
 
         client().listPods().stream()
                 .filter(p -> p.getMetadata().getName().contains("-connect-"))

File: systemtest/src/test/java/io/strimzi/systemtest/CustomResourceStatusST.java
Patch:
@@ -184,7 +184,7 @@ void testKafkaConnectStatus() {
     void testKafkaConnectS2IStatus() {
         String connectS2IUrl = "http://my-cluster-s2i-connect-api.status-cluster-test.svc:8083";
         String connectS2IDeploymentConfigName = CONNECTS2I_CLUSTER_NAME + "-connect";
-        testMethodResources().kafkaConnectS2I(CONNECTS2I_CLUSTER_NAME, 1, CLUSTER_NAME).done();
+        testMethodResources().kafkaConnectS2I(CONNECTS2I_CLUSTER_NAME, CLUSTER_NAME, 1).done();
         waitForKafkaConnectS2IStatus("Ready");
         assertKafkaConnectS2IStatus(1, connectS2IUrl, connectS2IDeploymentConfigName);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -21,6 +21,7 @@
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.Probe;
 import io.strimzi.api.kafka.model.ProbeBuilder;
+import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.common.model.Labels;
 
 import java.util.ArrayList;
@@ -208,7 +209,7 @@ public static EntityTopicOperator fromCrd(Kafka kafkaAssembly) {
                 result.setOwnerReference(kafkaAssembly);
                 String image = topicOperatorSpec.getImage();
                 if (image == null) {
-                    image = System.getenv().getOrDefault("STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE", "strimzi/operator:latest");
+                    image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE, "strimzi/operator:latest");
                 }
                 result.setImage(image);
                 result.setWatchedNamespace(topicOperatorSpec.getWatchedNamespace() != null ? topicOperatorSpec.getWatchedNamespace() : namespace);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -22,6 +22,7 @@
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.Probe;
 import io.strimzi.api.kafka.model.ProbeBuilder;
+import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.common.model.Labels;
 
 import java.util.ArrayList;
@@ -195,7 +196,7 @@ public static EntityUserOperator fromCrd(Kafka kafkaAssembly) {
                 result.setOwnerReference(kafkaAssembly);
                 String image = userOperatorSpec.getImage();
                 if (image == null) {
-                    image = System.getenv().getOrDefault("STRIMZI_DEFAULT_USER_OPERATOR_IMAGE", "strimzi/operator:latest");
+                    image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_USER_OPERATOR_IMAGE, "strimzi/operator:latest");
                 }
                 result.setImage(image);
                 result.setWatchedNamespace(userOperatorSpec.getWatchedNamespace() != null ? userOperatorSpec.getWatchedNamespace() : namespace);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -32,6 +32,7 @@
 import io.strimzi.api.kafka.model.ProbeBuilder;
 import io.strimzi.api.kafka.model.authentication.KafkaClientAuthentication;
 import io.strimzi.api.kafka.model.template.KafkaBridgeTemplate;
+import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.common.model.Labels;
 
 import java.util.ArrayList;
@@ -140,7 +141,7 @@ public static KafkaBridgeCluster fromCrd(KafkaBridge kafkaBridge, KafkaVersion.L
         kafkaBridgeCluster.setGcLoggingEnabled(spec.getJvmOptions() == null ? true : spec.getJvmOptions().isGcLoggingEnabled());
         String image = spec.getImage();
         if (image == null) {
-            image = System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE", "strimzi/kafka-bridge:latest");
+            image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE, "strimzi/kafka-bridge:latest");
         }
         kafkaBridgeCluster.setImage(image);
         kafkaBridgeCluster.setReplicas(spec.getReplicas() > 0 ? spec.getReplicas() : DEFAULT_REPLICAS);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -27,6 +27,7 @@
 import io.strimzi.api.kafka.model.Probe;
 import io.strimzi.api.kafka.model.ProbeBuilder;
 import io.strimzi.api.kafka.model.TlsSidecar;
+import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.model.Labels;
 
@@ -228,7 +229,7 @@ public static TopicOperator fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup ver
             result.setOwnerReference(kafkaAssembly);
             String image = tcConfig.getImage();
             if (image == null) {
-                image = System.getenv().getOrDefault("STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE", "strimzi/operator:latest");
+                image = System.getenv().getOrDefault(ClusterOperatorConfig.STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE, "strimzi/operator:latest");
             }
             result.setImage(image);
             result.setWatchedNamespace(tcConfig.getWatchedNamespace() != null ? tcConfig.getWatchedNamespace() : namespace);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaExporterTest.java
Patch:
@@ -106,7 +106,7 @@ private List<EnvVar> getExpectedEnvVars() {
 
     @Test
     public void testFromConfigMapDefaultConfig() {
-        Kafka resource = ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image,
+        Kafka resource = ResourceUtils.createKafkaCluster(namespace, cluster, replicas, null,
                 healthDelay, healthTimeout, metricsCm, kafkaConfig, zooConfig,
                 kafkaStorage, zkStorage, null, kafkaLogJson, zooLogJson, new KafkaExporterSpec());
         KafkaExporter ke = KafkaExporter.fromCrd(resource, VERSIONS);

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -13,7 +13,7 @@ public interface Constants {
     long TIMEOUT_FOR_DEPLOYMENT_CONFIG_READINESS = Duration.ofMinutes(7).toMillis();
     long TIMEOUT_FOR_RESOURCE_CREATION = Duration.ofMinutes(5).toMillis();
     long TIMEOUT_FOR_SECRET_CREATION = Duration.ofMinutes(2).toMillis();
-    long TIMEOUT_FOR_RESOURCE_READINESS = Duration.ofMinutes(12).toMillis();
+    long TIMEOUT_FOR_RESOURCE_READINESS = Duration.ofMinutes(14).toMillis();
     long TIMEOUT_FOR_CR_CREATION = Duration.ofMinutes(3).toMillis();
     long TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS = Duration.ofMinutes(7).toMillis();
     long TIMEOUT_FOR_MIRROR_JOIN_TO_GROUP = Duration.ofMinutes(2).toMillis();

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUserSpec.java
Patch:
@@ -5,7 +5,6 @@
 package io.strimzi.api.kafka.model;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
@@ -23,7 +22,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({ "authentication" })
+@JsonPropertyOrder({ "authentication", "authorization" })
 @EqualsAndHashCode
 public class KafkaUserSpec  implements UnknownPropertyPreserving, Serializable {
 
@@ -34,7 +33,7 @@ public class KafkaUserSpec  implements UnknownPropertyPreserving, Serializable {
     private Map<String, Object> additionalProperties;
 
     @Description("Authentication mechanism enabled for this Kafka user.")
-    @JsonProperty(required = true)
+    @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public KafkaUserAuthentication getAuthentication() {
         return authentication;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthentication.java
Patch:
@@ -25,6 +25,7 @@
 @JsonSubTypes({
         @JsonSubTypes.Type(name = KafkaListenerAuthenticationTls.TYPE_TLS, value = KafkaListenerAuthenticationTls.class),
         @JsonSubTypes.Type(name = KafkaListenerAuthenticationScramSha512.SCRAM_SHA_512, value = KafkaListenerAuthenticationScramSha512.class),
+        @JsonSubTypes.Type(name = KafkaListenerAuthenticationOAuth.TYPE_OAUTH, value = KafkaListenerAuthenticationOAuth.class),
 })
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @Buildable(
@@ -39,6 +40,7 @@ public abstract class KafkaListenerAuthentication implements UnknownPropertyPres
     private Map<String, Object> additionalProperties;
 
     @Description("Authentication type. " +
+            "`oauth` type uses SASL OAUTHBEARER Authentication. " +
             "`scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. " +
             "`tls` type uses TLS Client Authentication. " +
             "`tls` type is supported only on TLS listeners.")

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -262,13 +262,13 @@ void testSecretsWithKafkaConnectWithTlsAuthentication() throws Exception {
                         .endTrustedCertificate()
                     .endTls()
                     .withBootstrapServers(KAFKA_CLUSTER_NAME + "-kafka-bootstrap:9093")
-                    .withNewKafkaConnectAuthenticationTls()
+                    .withNewKafkaClientAuthenticationTls()
                         .withNewCertificateAndKey()
                             .withSecretName("user-example")
                             .withCertificate("user.crt")
                             .withKey("user.key")
                         .endCertificateAndKey()
-                    .endKafkaConnectAuthenticationTls()
+                    .endKafkaClientAuthenticationTls()
                 .endSpec()
                 .done();
 

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -740,8 +740,8 @@ void testSendMessagesPlainScramSha() throws Exception {
                     .editKafka()
                         .withNewListeners()
                             .withNewPlain()
-                                .withNewKafkaListenerAuthenticationScramSha512()
-                                .endKafkaListenerAuthenticationScramSha512()
+                                .withNewKafkaListenerAuthenticationScramSha512Auth()
+                                .endKafkaListenerAuthenticationScramSha512Auth()
                             .endPlain()
                         .endListeners()
                     .endKafka()

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -546,8 +546,8 @@ void testNetworkPoliciesWithPlainListener() throws Exception {
                     .editKafka()
                         .withNewListeners()
                             .withNewPlain()
-                                .withNewKafkaListenerAuthenticationScramSha512()
-                                .endKafkaListenerAuthenticationScramSha512()
+                                .withNewKafkaListenerAuthenticationScramSha512Auth()
+                                .endKafkaListenerAuthenticationScramSha512Auth()
                                 .withNetworkPolicyPeers(
                                     new NetworkPolicyPeerBuilder()
                                         .withNewPodSelector()

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -136,10 +136,10 @@ void createClassResources() throws InterruptedException {
         // Deploy http bridge
         testClassResources().kafkaBridge(CLUSTER_NAME, KafkaResources.tlsBootstrapAddress(CLUSTER_NAME), 1, Constants.HTTP_BRIDGE_DEFAULT_PORT)
             .editSpec()
-            .withNewKafkaBridgeAuthenticationScramSha512()
+            .withNewKafkaClientAuthenticationScramSha512()
                 .withNewUsername(userName)
                 .withPasswordSecret(passwordSecret)
-            .endKafkaBridgeAuthenticationScramSha512()
+            .endKafkaClientAuthenticationScramSha512()
                 .withNewTls()
                 .withTrustedCertificates(certSecret)
                 .endTls()

File: systemtest/src/main/java/io/strimzi/systemtest/MessagingBaseST.java
Patch:
@@ -176,9 +176,9 @@ private boolean allowParameter(String minimalVersion) {
         Matcher current = pattern.matcher(Environment.ST_KAFKA_VERSION);
         Matcher minimal = pattern.matcher(minimalVersion);
         if (current.find() && minimal.find()) {
-            return Integer.valueOf(current.group("major")) >= Integer.valueOf(minimal.group("major"))
-                    && Integer.valueOf(current.group("minor")) >= Integer.valueOf(minimal.group("minor"))
-                    && Integer.valueOf(current.group("micro")) >= Integer.valueOf(minimal.group("micro"));
+            return Integer.parseInt(current.group("major")) >= Integer.parseInt(minimal.group("major"))
+                    && Integer.parseInt(current.group("minor")) >= Integer.parseInt(minimal.group("minor"))
+                    && Integer.parseInt(current.group("micro")) >= Integer.parseInt(minimal.group("micro"));
         }
         return false;
     }

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -776,7 +776,7 @@ public static void waitUntilAddressIsReachable(String address) {
                 try {
                     InetAddress.getByName(kubeClient().getService("my-cluster-kafka-external-bootstrap").getStatus().getLoadBalancer().getIngress().get(0).getHostname());
                     return true;
-                } catch (Exception e) {
+                } catch (IOException e) {
                     return false;
                 }
             });

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -18,6 +18,7 @@ public interface Constants {
     long TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS = Duration.ofMinutes(7).toMillis();
     long TIMEOUT_FOR_MIRROR_JOIN_TO_GROUP = Duration.ofMinutes(2).toMillis();
     long TIMEOUT_FOR_TOPIC_CREATION = Duration.ofMinutes(1).toMillis();
+    long TIMEOUT_FOR_LOG = Duration.ofSeconds(30).toMillis();
     long POLL_INTERVAL_FOR_RESOURCE_CREATION = Duration.ofSeconds(3).toMillis();
     long POLL_INTERVAL_FOR_RESOURCE_READINESS = Duration.ofSeconds(1).toMillis();
     long WAIT_FOR_ROLLING_UPDATE_INTERVAL = Duration.ofSeconds(5).toMillis();

File: api/src/main/java/io/strimzi/api/kafka/model/EntityTopicOperatorSpec.java
Patch:
@@ -103,12 +103,11 @@ public void setTopicMetadataMaxAttempts(int topicMetadataMaxAttempts) {
         this.topicMetadataMaxAttempts = topicMetadataMaxAttempts;
     }
 
-    @Description("Resource constraints (limits and requests).")
+    @Description("CPU and memory resources to reserve (limits and requests).")
     public ResourceRequirements getResources() {
         return resources;
     }
 
-    @Description("Resource constraints (limits and requests).")
     public void setResources(ResourceRequirements resources) {
         this.resources = resources;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/EntityUserOperatorSpec.java
Patch:
@@ -89,12 +89,11 @@ public void setZookeeperSessionTimeoutSeconds(long zookeeperSessionTimeoutSecond
         this.zookeeperSessionTimeoutSeconds = zookeeperSessionTimeoutSeconds;
     }
 
-    @Description("Resource constraints (limits and requests).")
+    @Description("CPU and memory resources to reserve (limits and requests).")
     public ResourceRequirements getResources() {
         return resources;
     }
 
-    @Description("Resource constraints (limits and requests).")
     public void setResources(ResourceRequirements resources) {
         this.resources = resources;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeSpec.java
Patch:
@@ -96,7 +96,7 @@ public void setJvmOptions(JvmOptions jvmOptions) {
 
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    @Description("Resource constraints (limits and requests).")
+    @Description("CPU and memory resources to reserve (limits and requests).")
     public ResourceRequirements getResources() {
         return resources;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -172,7 +172,7 @@ public void setImage(String image) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    @Description("Resource constraints (limits and requests).")
+    @Description("CPU and memory resources to reserve (limits and requests).")
     public ResourceRequirements getResources() {
         return resources;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java
Patch:
@@ -115,7 +115,7 @@ public void setImage(String image) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    @Description("Resource constraints (limits and requests).")
+    @Description("CPU and memory resources to reserve (limits and requests).")
     public ResourceRequirements getResources() {
         return resources;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -191,7 +191,7 @@ public void setTolerations(List<Toleration> tolerations) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    @Description("Resource constraints (limits and requests).")
+    @Description("CPU and memory resources to reserve (limits and requests).")
     public ResourceRequirements getResources() {
         return resources;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/Sidecar.java
Patch:
@@ -43,7 +43,7 @@ public void setImage(String image) {
         this.image = image;
     }
 
-    @Description("Resource constraints (limits and requests).")
+    @Description("CPU and memory resources to reserve (limits and requests).")
     public ResourceRequirements getResources() {
         return resources;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/ZookeeperClusterSpec.java
Patch:
@@ -129,7 +129,7 @@ public void setImage(String image) {
     }
 
     @JsonInclude(JsonInclude.Include.NON_NULL)
-    @Description("Resource constraints (limits and requests).")
+    @Description("CPU and memory resources to reserve (limits and requests).")
     public ResourceRequirements getResources() {
         return resources;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/TopicOperatorTest.java
Patch:
@@ -92,7 +92,7 @@ public class TopicOperatorTest {
             .withTlsSidecar(tlsSidecar)
             .build();
 
-    private final Kafka resource = ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCm, kafkaConfig, zooConfig, kafkaStorage, zkStorage, topicOperator, kafkaLogJson, zooLogJson);
+    private final Kafka resource = ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCm, kafkaConfig, zooConfig, kafkaStorage, zkStorage, topicOperator, kafkaLogJson, zooLogJson, null);
     private final TopicOperator tc = TopicOperator.fromCrd(resource, VERSIONS);
 
     private List<EnvVar> getExpectedEnvVars() {
@@ -122,7 +122,7 @@ public void testFromConfigMapNoConfig() {
     public void testFromConfigMapDefaultConfig() {
         Kafka resource = ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image,
                 healthDelay, healthTimeout, metricsCm, kafkaConfig, zooConfig,
-                kafkaStorage, zkStorage, new TopicOperatorSpec(), kafkaLogJson, zooLogJson);
+                kafkaStorage, zkStorage, new TopicOperatorSpec(), kafkaLogJson, zooLogJson, null);
         TopicOperator tc = TopicOperator.fromCrd(resource, VERSIONS);
         Assert.assertEquals("strimzi/operator:latest", tc.getImage());
         assertEquals(namespace, tc.getWatchedNamespace());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -98,7 +98,7 @@ public class ZookeeperClusterTest {
             .withReadinessProbe(new ProbeBuilder().withInitialDelaySeconds(tlsHealthDelay).withTimeoutSeconds(tlsHealthTimeout).build())
             .build();
 
-    private final Kafka ka = new KafkaBuilder(ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, configurationJson, zooConfigurationJson, null, null, null, kafkaLogConfigJson, zooLogConfigJson))
+    private final Kafka ka = new KafkaBuilder(ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, configurationJson, zooConfigurationJson, null, null, null, kafkaLogConfigJson, zooLogConfigJson, null))
             .editSpec()
                 .editZookeeper()
                     .withTlsSidecar(tlsSidecar)

File: test/src/main/java/io/strimzi/test/k8s/OpenShift.java
Patch:
@@ -25,7 +25,7 @@ public boolean isAvailable() {
     @Override
     public boolean isClusterUp() {
         try {
-            Exec.exec(OC, "status");
+            Exec.exec(OC, "cluster", "status");
             return true;
         } catch (KubeClusterException e) {
             if (e.result.exitStatus() == 1) {

File: topic-operator/src/main/java/io/strimzi/operator/topic/K8sImpl.java
Patch:
@@ -67,9 +67,9 @@ public Future<KafkaTopic> updateResource(KafkaTopic topicResource) {
             try {
                 KafkaTopic kafkaTopic = operation().inNamespace(namespace).withName(topicResource.getMetadata().getName()).patch(topicResource);
                 LOGGER.debug("KafkaTopic {} updated with version {}->{}",
-                        kafkaTopic.getMetadata().getName(),
+                        kafkaTopic != null && kafkaTopic.getMetadata() != null ? kafkaTopic.getMetadata().getName() : null,
                         topicResource.getMetadata() != null ? topicResource.getMetadata().getResourceVersion() : null,
-                        kafkaTopic.getMetadata().getResourceVersion());
+                        kafkaTopic != null && kafkaTopic.getMetadata() != null ? kafkaTopic.getMetadata().getResourceVersion() : null);
                 future.complete(kafkaTopic);
             } catch (Exception e) {
                 future.fail(e);

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -34,7 +34,7 @@ public class Session extends AbstractVerticle {
     private final Config config;
     private final KubernetesClient kubeClient;
 
-    /*test*/ OperatorAssignedKafkaImpl kafka;
+    /*test*/ KafkaImpl kafka;
     private AdminClient adminClient;
     /*test*/ K8sImpl k8s;
     /*test*/ TopicOperator topicOperator;
@@ -140,7 +140,7 @@ public void start(Future<Void> startupFuture) {
 
         this.adminClient = AdminClient.create(adminClientProps);
         LOGGER.debug("Using AdminClient {}", adminClient);
-        this.kafka = new OperatorAssignedKafkaImpl(adminClient, vertx, config);
+        this.kafka = new KafkaImpl(adminClient, vertx);
         LOGGER.debug("Using Kafka {}", kafka);
         Labels labels = config.get(Config.LABELS);
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/K8sTopicWatcher.java
Patch:
@@ -36,8 +36,8 @@ public void eventReceived(Action action, KafkaTopic kafkaTopic) {
             LogContext logContext = LogContext.kubeWatch(action, kafkaTopic).withKubeTopic(kafkaTopic);
             String name = metadata.getName();
             String kind = kafkaTopic.getKind();
-            if (action == Action.ADDED && !initReconcileFuture.isComplete()) {
-                LOGGER.debug("Ignoring initial added event for {} {} during initial reconcile", kind, name);
+            if (!initReconcileFuture.isComplete()) {
+                LOGGER.debug("Ignoring initial event for {} {} during initial reconcile", kind, name);
                 return;
             }
             LOGGER.info("{}: event {} on resource {} generation={}, labels={}", logContext, action, name,

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorTopicDeletionDisabledIT.java
Patch:
@@ -102,7 +102,7 @@ public void testKafkaTopicDeletionDisabled(TestContext context) {
         waitForTopicInKafka(context, topicName, true);
 
         // Delete the k8 KafkaTopic and wait for that to be deleted
-        deleteInKube(topicResource.getMetadata().getName());
+        deleteInKube(context, topicResource.getMetadata().getName());
 
         // trigger an immediate reconcile where, with with delete.topic.enable=false, the K8s KafkaTopic should be recreated
         Future<?> result = session.topicOperator.reconcileAllTopics("periodic");

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -19,6 +19,7 @@
 import java.util.List;
 
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.hasItems;
@@ -90,6 +91,7 @@ void testUOWatchingOtherNamespace() {
     }
 
     @Test
+    @Tag(NODEPORT_SUPPORTED)
     void testUserInDifferentNamespace() throws Exception {
         String startingNamespace = setNamespace(SECOND_NAMESPACE);
         secondNamespaceResources.tlsUser(CLUSTER_NAME, USER_NAME).done();

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -23,6 +23,7 @@
 import java.util.Map;
 
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.Constants.TRAVIS;
 import static io.strimzi.systemtest.k8s.Events.Created;
@@ -238,6 +239,7 @@ void testForUpdateValuesInConnectCM() {
     }
 
     @Test
+    @Tag(NODEPORT_SUPPORTED)
     void testSecretsWithKafkaConnectWithTlsAuthentication() throws Exception {
         final String userName = "user-example";
         final String topicName = "topic-example";

File: systemtest/src/test/java/io/strimzi/systemtest/OpenShiftTemplatesST.java
Patch:
@@ -31,6 +31,7 @@
 import java.util.List;
 
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.test.TestUtils.map;
 import static org.junit.jupiter.api.Assertions.assertEquals;
@@ -65,6 +66,7 @@ public KafkaConnectS2I getKafkaConnectS2I(String clusterName) {
     }
 
     @Test
+    @Tag(NODEPORT_SUPPORTED)
     void testStrimziEphemeral() {
         String clusterName = "foo";
         oc.newApp("strimzi-ephemeral", map("CLUSTER_NAME", clusterName,

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -20,6 +20,7 @@
 import java.util.List;
 
 import static io.strimzi.systemtest.Constants.ACCEPTANCE;
+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.Constants.SCALABILITY;
 import static org.hamcrest.MatcherAssert.assertThat;
@@ -120,12 +121,14 @@ void testUpdateUser() {
     }
 
     @Tag(SCALABILITY)
+    @Tag(NODEPORT_SUPPORTED)
     @Test
     void testBigAmountOfScramShaUsers() {
         createBigAmountOfUsers("SCRAM_SHA");
     }
 
     @Tag(SCALABILITY)
+    @Tag(NODEPORT_SUPPORTED)
     @Test
     void testBigAmountOfTlsUsers() {
         createBigAmountOfUsers("TLS");

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeST.java
Patch:
@@ -21,13 +21,15 @@
 import java.util.Random;
 
 import static io.strimzi.systemtest.Constants.BRIDGE;
+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.junit.jupiter.api.Assertions.assertTrue;
 
 @Tag(BRIDGE)
 @Tag(REGRESSION)
+@Tag(NODEPORT_SUPPORTED)
 @ExtendWith(VertxExtension.class)
 class HttpBridgeST extends HttpBridgeBaseST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -28,13 +28,15 @@
 import java.util.Random;
 
 import static io.strimzi.systemtest.Constants.BRIDGE;
+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.junit.jupiter.api.Assertions.assertTrue;
 
 @Tag(BRIDGE)
 @Tag(REGRESSION)
+@Tag(NODEPORT_SUPPORTED)
 @ExtendWith(VertxExtension.class)
 class HttpBridgeScramShaST extends HttpBridgeBaseST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeScramShaST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -26,13 +26,15 @@
 import java.util.Random;
 
 import static io.strimzi.systemtest.Constants.BRIDGE;
+import static io.strimzi.systemtest.Constants.NODEPORT_SUPPORTED;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.junit.jupiter.api.Assertions.assertTrue;
 
 @Tag(BRIDGE)
 @Tag(REGRESSION)
+@Tag(NODEPORT_SUPPORTED)
 @ExtendWith(VertxExtension.class)
 class HttpBridgeTlsST extends HttpBridgeBaseST {
     private static final Logger LOGGER = LogManager.getLogger(HttpBridgeTlsST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/specific/SpecificST.java
Patch:
@@ -21,6 +21,7 @@
 
 import java.util.List;
 
+import static io.strimzi.systemtest.Constants.LOADBALANCER_SUPPORTED;
 import static io.strimzi.systemtest.Constants.SPECIFIC;
 import static io.strimzi.systemtest.k8s.Events.Created;
 import static io.strimzi.systemtest.k8s.Events.Pulled;
@@ -39,6 +40,7 @@ public class SpecificST extends MessagingBaseST {
     public static final String NAMESPACE = "specific-cluster-test";
 
     @Test
+    @Tag(LOADBALANCER_SUPPORTED)
     void testRackAware() throws Exception {
         testMethodResources().kafkaEphemeral(CLUSTER_NAME, 1, 1)
             .editSpec()
@@ -68,6 +70,7 @@ void testRackAware() throws Exception {
 
 
     @Test
+    @Tag(LOADBALANCER_SUPPORTED)
     void testLoadBalancerIpOverride() throws Exception {
         String bootstrapOverrideIP = "10.0.0.1";
         String brokerOverrideIP = "10.0.0.2";

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerConsumerSpec.java
Patch:
@@ -26,7 +26,7 @@
 public class KafkaMirrorMakerConsumerSpec extends KafkaMirrorMakerClientSpec {
     private static final long serialVersionUID = 1L;
 
-    public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, group.id, sasl., security.";
+    public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, group.id, sasl., security., interceptor.classes";
 
     private Integer numStreams;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerProducerSpec.java
Patch:
@@ -25,7 +25,7 @@ public class KafkaMirrorMakerProducerSpec extends KafkaMirrorMakerClientSpec {
 
     private Boolean abortOnSendFailure;
 
-    public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, sasl., security.";
+    public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, sasl., security., interceptor.classes";
 
     @Description("Flag to set the Mirror Maker to exit on a failed send. Default value is `true`.")
     @JsonInclude(JsonInclude.Include.NON_NULL)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaVersion.java
Patch:
@@ -28,7 +28,8 @@ public class KafkaVersion implements Comparable<KafkaVersion> {
         "(?<default>default)?\\s+" +
         "(?<proto>[0-9.]+)\\s+" +
         "(?<msg>[0-9.]+)\\s+" +
-        "(?<sha>[0-9A-Za-z]+)");
+        "(?<sha>[0-9A-Za-z]+)\\s+" +
+        "(?<thirdpartylibs>[0-9A-Za-z._-]+)");
 
     /**
      * Parse the version information present in the {@code /kafka-versions} classpath resource.

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -50,8 +50,8 @@
 public class EntityOperatorTest {
 
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef\n" +
-            "2.1.0         2.1 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x\n" +
+            "2.1.0         2.1 2.0 1234567890abcdef 2.1.x"),
             map("2.0.0", "strimzi/kafka:latest-kafka-2.0.0",
                     "2.1.0", "strimzi/kafka:latest-kafka-2.1.0"), emptyMap(), emptyMap(), emptyMap()) { };
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -49,7 +49,7 @@
 
 public class KafkaBridgeClusterTest {
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x"),
             emptyMap(), emptyMap(), emptyMap(), emptyMap()) { };
     private final String namespace = "test";
     private final String cluster = "foo";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -99,8 +99,8 @@
 public class KafkaClusterTest {
 
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef\n" +
-                    "2.1.0         2.1 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x\n" +
+                    "2.1.0         2.1 2.0 1234567890abcdef 2.1.x"),
             map("2.0.0", "strimzi/kafka:latest-kafka-2.0.0",
                     "2.1.0", "strimzi/kafka:latest-kafka-2.1.0"), emptyMap(), emptyMap(), emptyMap()) { };
     private final String namespace = "test";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaVersionTest.java
Patch:
@@ -34,8 +34,8 @@ public void load() {
     public void parse() throws Exception {
         Map<String, KafkaVersion> map = new HashMap<>();
         KafkaVersion defaultVersion = KafkaVersion.parseKafkaVersions(new LineNumberReader(new StringReader(
-                "2.0.0 default 2.0 2.0 1234567890abcdef\n" +
-                        "2.0.1  2.0 2.0 1234567890abcdef")), map);
+                "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x\n" +
+                        "2.0.1  2.0 2.0 1234567890abcdef 2.0.x")), map);
         assertEquals("2.0.0", defaultVersion.version());
         assertEquals(2, map.size());
         assertTrue(map.containsKey("2.0.0"));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/TopicOperatorTest.java
Patch:
@@ -44,7 +44,7 @@
 public class TopicOperatorTest {
 
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x"),
             singletonMap("2.0.0", "strimzi/kafka:latest-kafka-2.0.0"),
             emptyMap(), emptyMap(), emptyMap()) { };
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -70,8 +70,8 @@
 public class ZookeeperClusterTest {
 
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef\n" +
-                    "2.1.0         2.1 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x\n" +
+                    "2.1.0         2.1 2.0 1234567890abcdef 2.1.x"),
             map("2.0.0", "strimzi/kafka:latest-kafka-2.0.0",
                     "2.1.0", "strimzi/kafka:latest-kafka-2.1.0"), emptyMap(), emptyMap(), emptyMap()) { };
     private final String namespace = "test";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -53,7 +53,7 @@ public class JbodStorageTest {
     private static final String NAMESPACE = "test-jbod-storage";
     private static final String NAME = "my-kafka";
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x"),
             singletonMap("2.0.0", "strimzi/kafka:latest-kafka-2.0.0"),
             emptyMap(), emptyMap(), emptyMap()) { };
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -89,7 +89,7 @@ public class KafkaAssemblyOperatorMockTest {
     private static final String CLUSTER_NAME = "my-cluster";
 
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x"),
             singletonMap("2.0.0", "strimzi/kafka:latest-kafka-2.0.0"), emptyMap(), emptyMap(), emptyMap()) { };
 
     private final KubernetesVersion kubernetesVersion = KubernetesVersion.V1_9;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -47,7 +47,7 @@ public class KafkaConnectAssemblyOperatorMockTest {
     private static final Logger LOGGER = LogManager.getLogger(KafkaConnectAssemblyOperatorMockTest.class);
 
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x"),
             emptyMap(), singletonMap("2.0.0", "strimzi/kafka-connect:latest-kafka-2.0.0"), emptyMap(), emptyMap()) { };
 
     private static final String NAMESPACE = "my-namespace";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -67,7 +67,7 @@
 public class KafkaConnectAssemblyOperatorTest {
 
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x"),
             emptyMap(), singletonMap("2.0.0", "strimzi/kafka-connect:latest-kafka-2.0.0"), emptyMap(), emptyMap()) { };
     protected static Vertx vertx;
     private static final String METRICS_CONFIG = "{\"foo\":\"bar\"}";

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperatorTest.java
Patch:
@@ -71,7 +71,7 @@
 public class KafkaConnectS2IAssemblyOperatorTest {
 
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x"),
             emptyMap(), emptyMap(), singletonMap("2.0.0", "strimzi/kafka-connect:latest-kafka-2.0.0"),
             emptyMap()) { };
     protected static Vertx vertx;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaStatusTest.java
Patch:
@@ -51,9 +51,9 @@ public class KafkaStatusTest {
     private final ClusterOperatorConfig config = ResourceUtils.dummyClusterOperatorConfig();
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(
             new StringReader(
-                    "2.0.0  default  2.0  2.0  1234567890abcdef\n" +
-                            "2.0.1           2.0  2.0  1234567890abcdef\n" +
-                            "2.1.0           2.1  2.1  1234567890abcdef\n"),
+                    "2.0.0  default  2.0  2.0  1234567890abcdef 2.0.x\n" +
+                            "2.0.1           2.0  2.0  1234567890abcdef 2.0.x\n" +
+                            "2.1.0           2.1  2.1  1234567890abcdef 2.1.x\n"),
             map("2.0.0", "strimzi/kafka:0.8.0-kafka-2.0.0",
                     "2.0.1", "strimzi/kafka:0.8.0-kafka-2.0.1",
                     "2.1.0", "strimzi/kafka:0.8.0-kafka-2.1.0"),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -65,9 +65,9 @@ public class KafkaUpdateTest {
 
     private final KafkaVersion.Lookup lookup = new KafkaVersion.Lookup(
             new StringReader(
-                    "2.0.0  default  2.0  2.0  1234567890abcdef\n" +
-                    "2.0.1           2.0  2.0  1234567890abcdef\n" +
-                    "2.1.0           2.1  2.1  1234567890abcdef\n"),
+                    "2.0.0  default  2.0  2.0  1234567890abcdef 2.0.x\n" +
+                    "2.0.1           2.0  2.0  1234567890abcdef 2.0.x\n" +
+                    "2.1.0           2.1  2.1  1234567890abcdef 2.1.x\n"),
             map("2.0.0", "strimzi/kafka:0.8.0-kafka-2.0.0",
                     "2.0.1", "strimzi/kafka:0.8.0-kafka-2.0.1",
                     "2.1.0", "strimzi/kafka:0.8.0-kafka-2.1.0"),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -56,7 +56,7 @@ public class PartialRollingUpdateTest {
     private static final String NAMESPACE = "my-namespace";
     private static final String CLUSTER_NAME = "my-cluster";
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
-            "2.0.0 default 2.0 2.0 1234567890abcdef"),
+            "2.0.0 default 2.0 2.0 1234567890abcdef 2.0.x"),
             singletonMap("2.0.0", "strimzi/kafka:latest-kafka-2.0.0"),
             emptyMap(), emptyMap(), emptyMap()) { };
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/VolumeResizingTest.java
Patch:
@@ -50,9 +50,9 @@ public class VolumeResizingTest {
     private final ClusterOperatorConfig config = ResourceUtils.dummyClusterOperatorConfig();
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(
             new StringReader(
-                    "2.0.0  default  2.0  2.0  1234567890abcdef\n" +
-                            "2.0.1           2.0  2.0  1234567890abcdef\n" +
-                            "2.1.0           2.1  2.1  1234567890abcdef\n"),
+                    "2.0.0  default  2.0  2.0  1234567890abcdef 2.0.x\n" +
+                            "2.0.1           2.0  2.0  1234567890abcdef 2.0.x\n" +
+                            "2.1.0           2.1  2.1  1234567890abcdef 2.1.x\n"),
             map("2.0.0", "strimzi/kafka:0.8.0-kafka-2.0.0",
                     "2.0.1", "strimzi/kafka:0.8.0-kafka-2.0.1",
                     "2.1.0", "strimzi/kafka:0.8.0-kafka-2.1.0"),

File: mirror-maker-agent/src/main/java/io/strimzi/mirrormaker/agent/MirrorMakerAgent.java
Patch:
@@ -111,7 +111,7 @@ public void run() {
                     } else {
                         LOGGER.debug("Mirror Maker is not ready");
 
-                        if (!readinessFile.delete()) {
+                        if (readinessFile.exists() && !readinessFile.delete()) {
                             LOGGER.error("Could not delete readiness indicator file {}", readinessFile);
                         }
                     }

File: crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java
Patch:
@@ -243,7 +243,9 @@ private ObjectNode buildSpec(Crd.Spec crd, Class<? extends CustomResource> crdCl
                 colNode.put("description", col.description());
                 colNode.put("JSONPath", col.jsonPath());
                 colNode.put("type", col.type());
-                colNode.put("priority", col.priority());
+                if (col.priority() != 0) {
+                    colNode.put("priority", col.priority());
+                }
                 if (!col.format().isEmpty()) {
                     colNode.put("format", col.format());
                 }

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -14,6 +14,7 @@ public interface Constants {
     long TIMEOUT_FOR_RESOURCE_CREATION = Duration.ofMinutes(5).toMillis();
     long TIMEOUT_FOR_SECRET_CREATION = Duration.ofMinutes(2).toMillis();
     long TIMEOUT_FOR_RESOURCE_READINESS = Duration.ofMinutes(7).toMillis();
+    long TIMEOUT_FOR_MIRROR_MAKER_COPY_MESSAGES_BETWEEN_BROKERS = Duration.ofMinutes(7).toMillis();
     long TIMEOUT_FOR_MIRROR_JOIN_TO_GROUP = Duration.ofMinutes(2).toMillis();
     long TIMEOUT_FOR_TOPIC_CREATION = Duration.ofMinutes(1).toMillis();
     long POLL_INTERVAL_FOR_RESOURCE_CREATION = Duration.ofSeconds(3).toMillis();

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -60,7 +60,6 @@ class ConnectST extends AbstractST {
 
     @Test
     void testDeployUndeploy() {
-        String appName = "strimzi-ephemeral";
         testMethodResources().kafkaConnect(KAFKA_CLUSTER_NAME, 1).done();
         LOGGER.info("Looks like the connect cluster my-cluster deployed OK");
 
@@ -241,6 +240,7 @@ void testForUpdateValuesInConnectCM() {
     @Test
     void testSecretsWithKafkaConnectWithTlsAuthentication() throws Exception {
         final String userName = "user-example";
+        final String topicName = "topic-example";
 
         testMethodResources().tlsUser(KAFKA_CLUSTER_NAME, userName).done();
 
@@ -270,7 +270,7 @@ void testSecretsWithKafkaConnectWithTlsAuthentication() throws Exception {
                 .endSpec()
                 .done();
 
-        testMethodResources().topic(KAFKA_CLUSTER_NAME, TEST_TOPIC_NAME).done();
+        testMethodResources().topic(KAFKA_CLUSTER_NAME, topicName).done();
 
         String kafkaConnectPodName = kubeClient().listPods("type", "kafka-connect").get(0).getMetadata().getName();
         String kafkaConnectLogs = kubeClient().logs(kafkaConnectPodName);
@@ -285,7 +285,7 @@ void testSecretsWithKafkaConnectWithTlsAuthentication() throws Exception {
         cmdKubeClient().execInPod(kafkaConnectPodName, "/bin/bash", "-c", "curl -X POST -H \"Content-Type: application/json\" --data "
                 + "'" + connectorConfig + "'" + " http://localhost:8083/connectors");
 
-        sendMessages(kafkaConnectPodName, KAFKA_CLUSTER_NAME, kafkaConnectName(KAFKA_CLUSTER_NAME), TEST_TOPIC_NAME, 2);
+        sendMessages(kafkaConnectPodName, KAFKA_CLUSTER_NAME, kafkaConnectName(KAFKA_CLUSTER_NAME), topicName, 2);
 
         StUtils.waitForMessagesInKafkaConnectFileSink(kafkaConnectPodName);
 

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -215,7 +215,7 @@ void testEODeletion() {
         // Remove EO from Kafka DTO
         kafka.getSpec().setEntityOperator(null);
         // Replace Kafka configuration with removed EO
-        testMethodResources.kafka(kafka).done();
+        testMethodResources().kafka(kafka).done();
 
         // Wait when EO(UO + TO) will be removed
         StUtils.waitForDeploymentDeletion(entityOperatorDeploymentName(CLUSTER_NAME));
@@ -1840,6 +1840,7 @@ void testAppDomainLabels() throws Exception {
                     .editKafka()
                         .editListeners()
                             .withNewKafkaListenerExternalNodePort()
+                                .withTls(false)
                             .endKafkaListenerExternalNodePort()
                         .endListeners()
                     .endKafka()

File: test/src/main/java/io/strimzi/test/BaseITST.java
Patch:
@@ -61,6 +61,7 @@ public static synchronized KubeClusterResource kubeCluster() {
      */
     public static String setNamespace(String futureNamespace) {
         String previousNamespace = namespace;
+        LOGGER.info("Changing to {} namespace", futureNamespace);
         namespace = futureNamespace;
         return previousNamespace;
     }

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -48,7 +48,7 @@
 import static org.junit.jupiter.api.Assertions.assertNotNull;
 
 @Tag(REGRESSION)
-class SecurityST extends AbstractST {
+class SecurityST extends MessagingBaseST {
 
     public static final String NAMESPACE = "security-cluster-test";
     private static final Logger LOGGER = LogManager.getLogger(SecurityST.class);

File: systemtest/src/test/java/io/strimzi/systemtest/TopicST.java
Patch:
@@ -127,7 +127,7 @@ void testBigAmountOfTopicsCreatingViaKafka() {
         for (int i = 0; i < numberOfTopics; i++) {
             currentTopic = topicName + i;
             StUtils.waitForKafkaTopicCreation(currentTopic);
-            KafkaTopic kafkaTopic = testMethodResources().kafkaTopic().withName(currentTopic).get();
+            KafkaTopic kafkaTopic = testMethodResources().kafkaTopic().inNamespace(NAMESPACE).withName(currentTopic).get();
             verifyTopicViaKafkaTopicCRK8s(kafkaTopic, currentTopic, topicPartitions);
         }
 

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -12,6 +12,7 @@
 public interface Constants {
     long TIMEOUT_FOR_DEPLOYMENT_CONFIG_READINESS = Duration.ofMinutes(7).toMillis();
     long TIMEOUT_FOR_RESOURCE_CREATION = Duration.ofMinutes(5).toMillis();
+    long TIMEOUT_FOR_SECRET_CREATION = Duration.ofMinutes(2).toMillis();
     long TIMEOUT_FOR_RESOURCE_READINESS = Duration.ofMinutes(7).toMillis();
     long TIMEOUT_FOR_MIRROR_JOIN_TO_GROUP = Duration.ofMinutes(2).toMillis();
     long TIMEOUT_FOR_TOPIC_CREATION = Duration.ofMinutes(1).toMillis();

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -511,7 +511,7 @@ private Kafka waitFor(Kafka kafka) {
         StUtils.waitForAllStatefulSetPodsReady(KafkaResources.kafkaStatefulSetName(name), kafka.getSpec().getKafka().getReplicas());
         LOGGER.info("Kafka pods are ready");
         // EO should not be deployed if it does not contain UO and TO
-        if (kafka.getSpec().getEntityOperator() != null) {
+        if (kafka.getSpec().getEntityOperator().getTopicOperator() != null || kafka.getSpec().getEntityOperator().getUserOperator() != null) {
             LOGGER.info("Waiting for Entity Operator pods");
             StUtils.waitForDeploymentReady(KafkaResources.entityOperatorDeploymentName(name));
             LOGGER.info("Entity Operator pods are ready");

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -517,7 +517,7 @@ void testCertRegeneratedAfterInternalCAisDeleted() throws Exception {
             assertThat("Certificates has different cert UIDs", !secrets.get(i).getData().get("ca.crt").equals(regeneratedSecrets.get(i).getData().get("ca.crt")));
         }
 
-        waitForClusterAvailabilityTls(userName, NAMESPACE);
+        waitForClusterAvailabilityTls(userName, NAMESPACE, CLUSTER_NAME);
     }
 
     @BeforeEach

File: systemtest/src/test/java/io/strimzi/systemtest/AllNamespaceST.java
Patch:
@@ -111,7 +111,7 @@ void testUserInDifferentNamespace() throws Exception {
                 copySecret(s, THIRD_NAMESPACE, USER_NAME);
             }
         }
-        waitForClusterAvailabilityTls(USER_NAME, THIRD_NAMESPACE);
+        waitForClusterAvailabilityTls(USER_NAME, THIRD_NAMESPACE, CLUSTER_NAME);
 
         setNamespace(startingNamespace);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -1334,7 +1334,7 @@ void testNodePortTls() throws Exception {
             () -> kubeClient().getSecret("alice") != null,
             () -> LOGGER.error("Couldn't find user secret {}", kubeClient().listSecrets()));
 
-        waitForClusterAvailabilityTls(userName, NAMESPACE);
+        waitForClusterAvailabilityTls(userName, NAMESPACE, CLUSTER_NAME);
     }
 
     @Test
@@ -1376,7 +1376,7 @@ void testLoadBalancerTls() throws Exception {
             () -> kubeClient().getSecret("alice") != null,
             () -> LOGGER.error("Couldn't find user secret {}", kubeClient().listSecrets()));
 
-        waitForClusterAvailabilityTls(userName, NAMESPACE);
+        waitForClusterAvailabilityTls(userName, NAMESPACE, CLUSTER_NAME);
     }
 
     private Map<String, String> getAnnotationsForSS(String ssName) {

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -453,6 +453,7 @@ public static void waitForConfigMapRecovery(String name, String configMapUid) {
     }
 
     public static void waitForSecretReady(String secretName) {
+        LOGGER.info("Waiting for secret {}", secretName);
         TestUtils.waitFor("Expected secret " + secretName + " exists", Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> kubeClient().getSecret(secretName) != null);
     }

File: crd-generator/src/main/java/io/strimzi/crdgenerator/DocGenerator.java
Patch:
@@ -168,7 +168,7 @@ private void appendCommonTypeDoc(Crd crd, Class<?> cls) throws IOException {
             KubeLink kubeLink = property.getAnnotation(KubeLink.class);
             String externalUrl = linker != null && kubeLink != null ? linker.link(kubeLink) : null;
             if (externalUrl != null) {
-                out.append("See external documentation of ").append(externalUrl)
+                out.append(" See external documentation of ").append(externalUrl)
                         .append("[").append(kubeLink.group()).append("/").append(kubeLink.version()).append(" ").append(kubeLink.kind()).append("].").append(NL).append(NL);
             } else if (isPolymorphic(propertyClass)) {
                 out.append(" The type depends on the value of the `").append(propertyName).append(".").append(discriminator(propertyClass))

File: systemtest/src/main/java/io/strimzi/systemtest/clients/lib/Producer.java
Patch:
@@ -72,7 +72,7 @@ private void sendNext(KafkaProducer<String, String> producer, String topic) {
                     }
 
                 } else {
-                    LOGGER.warn("Producer cannot connect to topic {}!", topic);
+                    LOGGER.warn("Producer cannot connect to topic {}, because of {}", topic, done.cause());
                     sendNext(producer, topic);
                 }
             });

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -33,6 +33,8 @@ public interface Constants {
     long TIMEOUT_FOR_GET_SECRETS = Duration.ofMinutes(1).toMillis();
     long TIMEOUT_TEARDOWN = Duration.ofSeconds(10).toMillis();
     long GLOBAL_TIMEOUT = Duration.ofMinutes(5).toMillis();
+    long GLOBAL_STATUS_TIMEOUT = Duration.ofMinutes(3).toMillis();
+    long CONNECT_STATUS_TIMEOUT = Duration.ofMinutes(5).toMillis();
     long GLOBAL_POLL_INTERVAL = Duration.ofSeconds(1).toMillis();
 
     long CO_OPERATION_TIMEOUT = Duration.ofMinutes(1).toMillis();

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -398,7 +398,7 @@ public static void waitForDeploymentConfigReady(String name, int expectedPods) {
         LabelSelector deploymentConfigSelector = new LabelSelectorBuilder().addToMatchLabels(kubeClient().getDeploymentConfigSelectors(name)).build();
         waitForPodsReady(deploymentConfigSelector, expectedPods, true);
         String clusterOperatorPodName = kubeClient().listPods("name", "strimzi-cluster-operator").get(0).getMetadata().getName();
-        String log = "BuildConfigOperator:191 - BuildConfig " + name + " in namespace connect-s2i-cluster-test has been created";
+        String log = "BuildConfigOperator:191 - BuildConfig " + name + " in namespace " + kubeClient().getNamespace() + " has been created";
 
         TestUtils.waitFor("build config creation " + name, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> kubeClient().logs(clusterOperatorPodName).contains(log));

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -117,7 +117,9 @@ public static long waitFor(String description, long pollIntervalMs, long timeout
             }
             if (timeLeft <= 0) {
                 onTimeout.run();
-                throw new TimeoutException("Timeout after " + timeoutMs + " ms waiting for " + description);
+                TimeoutException exception = new TimeoutException("Timeout after " + timeoutMs + " ms waiting for " + description);
+                exception.printStackTrace();
+                throw exception;
             }
             long sleepTime = Math.min(pollIntervalMs, timeLeft);
             if (LOGGER.isTraceEnabled()) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1377,7 +1377,6 @@ public ClusterRoleBinding generateClusterRoleBinding(String assemblyNamespace) {
             return new ClusterRoleBindingBuilder()
                     .withNewMetadata()
                         .withName(initContainerClusterRoleBindingName(namespace, cluster))
-                        .withNamespace(assemblyNamespace)
                         .withOwnerReferences(createOwnerReference())
                         .withLabels(labels.toMap())
                     .endMetadata()

File: api/src/main/java/io/strimzi/api/kafka/model/status/KafkaConnectS2Istatus.java
Patch:
@@ -19,7 +19,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({ "conditions", "observedGeneration", "restApiAddress", "buildConfigName" })
+@JsonPropertyOrder({ "conditions", "observedGeneration", "url", "buildConfigName" })
 @EqualsAndHashCode(callSuper = true)
 public class KafkaConnectS2Istatus extends KafkaConnectStatus {
     private static final long serialVersionUID = 1L;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -109,7 +109,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge
                 if (bridge.getHttp() != null) {
                     port = bridge.getHttp().getPort();
                 }
-                kafkaBridgeStatus.setHttpAddress(bridge.getServiceName() + "." + namespace + ".svc:" + port);
+                kafkaBridgeStatus.setUrl(KafkaBridgeResources.url(bridge.getName(), namespace, port));
 
                 updateStatus(assemblyResource, reconciliation, kafkaBridgeStatus).setHandler(statusResult -> {
                     // If both features succeeded, createOrUpdate succeeded as well

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -105,7 +105,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
                 .compose(i -> chainFuture.complete(), chainFuture)
                 .setHandler(reconciliationResult -> {
                     StatusUtils.setStatusConditionAndObservedGeneration(kafkaConnect, kafkaConnectStatus, reconciliationResult);
-                    kafkaConnectStatus.setRestApiAddress(KafkaConnectResources.restApiAddress(connect.getCluster(), namespace, KafkaConnectCluster.REST_API_PORT));
+                    kafkaConnectStatus.setUrl(KafkaConnectResources.url(connect.getCluster(), namespace, KafkaConnectCluster.REST_API_PORT));
 
                     updateStatus(kafkaConnect, reconciliation, kafkaConnectStatus).setHandler(statusResult -> {
                         // If both features succeeded, createOrUpdate succeeded as well

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -116,7 +116,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
                     .compose(i -> chainFuture.complete(), chainFuture)
                     .setHandler(reconciliationResult -> {
                         StatusUtils.setStatusConditionAndObservedGeneration(kafkaConnectS2I, kafkaConnectS2Istatus, reconciliationResult);
-                        kafkaConnectS2Istatus.setRestApiAddress(KafkaConnectS2IResources.restApiAddress(connect.getCluster(), namespace, KafkaConnectS2ICluster.REST_API_PORT));
+                        kafkaConnectS2Istatus.setUrl(KafkaConnectS2IResources.url(connect.getCluster(), namespace, KafkaConnectS2ICluster.REST_API_PORT));
                         kafkaConnectS2Istatus.setBuildConfigName(KafkaConnectS2IResources.buildConfigName(connect.getCluster()));
 
                         updateStatus(kafkaConnectS2I, reconciliation, kafkaConnectS2Istatus).setHandler(statusResult -> {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -171,7 +171,7 @@ public void testCreateCluster(TestContext context) {
 
             // Verify status
             List<KafkaBridge> capturedStatuses = bridgeCaptor.getAllValues();
-            context.assertEquals(capturedStatuses.get(0).getStatus().getHttpAddress(), "foo-bridge-service.test.svc:8080");
+            context.assertEquals(capturedStatuses.get(0).getStatus().getUrl(), "http://foo-bridge-bridge-service.test.svc:8080");
             context.assertEquals(capturedStatuses.get(0).getStatus().getConditions().get(0).getStatus(), "True");
             context.assertEquals(capturedStatuses.get(0).getStatus().getConditions().get(0).getType(), "Ready");
 
@@ -666,7 +666,7 @@ public void testCreateClusterStatusNotReady(TestContext context) {
 
             // Verify status
             List<KafkaBridge> capturedStatuses = bridgeCaptor.getAllValues();
-            context.assertEquals(capturedStatuses.get(0).getStatus().getHttpAddress(), "foo-bridge-service.test.svc:8080");
+            context.assertEquals(capturedStatuses.get(0).getStatus().getUrl(), "http://foo-bridge-bridge-service.test.svc:8080");
             context.assertEquals(capturedStatuses.get(0).getStatus().getConditions().get(0).getStatus(), "True");
             context.assertEquals(capturedStatuses.get(0).getStatus().getConditions().get(0).getType(), "NotReady");
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -160,7 +160,7 @@ public void testCreateCluster(TestContext context) {
 
             // Verify status
             List<KafkaConnect> capturedConnects = connectCaptor.getAllValues();
-            context.assertEquals(capturedConnects.get(0).getStatus().getRestApiAddress(), "foo-connect-api.test.svc:8083");
+            context.assertEquals(capturedConnects.get(0).getStatus().getUrl(), "http://foo-connect-api.test.svc:8083");
             context.assertEquals(capturedConnects.get(0).getStatus().getConditions().get(0).getStatus(), "True");
             context.assertEquals(capturedConnects.get(0).getStatus().getConditions().get(0).getType(), "Ready");
             async.complete();
@@ -612,7 +612,7 @@ public void testCreateClusterStatusNotReady(TestContext context) {
 
             // Verify status
             List<KafkaConnect> capturedConnects = connectCaptor.getAllValues();
-            context.assertEquals(capturedConnects.get(0).getStatus().getRestApiAddress(), "foo-connect-api.test.svc:8083");
+            context.assertEquals(capturedConnects.get(0).getStatus().getUrl(), "http://foo-connect-api.test.svc:8083");
             context.assertEquals(capturedConnects.get(0).getStatus().getConditions().get(0).getStatus(), "True");
             context.assertEquals(capturedConnects.get(0).getStatus().getConditions().get(0).getType(), "NotReady");
             context.assertEquals(capturedConnects.get(0).getStatus().getConditions().get(0).getMessage(), failureMsg);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperatorTest.java
Patch:
@@ -191,7 +191,7 @@ public void testCreateCluster(TestContext context) {
 
             // Verify status
             List<KafkaConnectS2I> capturedConnects = connectCaptor.getAllValues();
-            context.assertEquals(capturedConnects.get(0).getStatus().getRestApiAddress(), "foo-connect-api.test.svc:8083");
+            context.assertEquals(capturedConnects.get(0).getStatus().getUrl(), "http://foo-connect-api.test.svc:8083");
             context.assertEquals(capturedConnects.get(0).getStatus().getConditions().get(0).getStatus(), "True");
             context.assertEquals(capturedConnects.get(0).getStatus().getConditions().get(0).getType(), "Ready");
 
@@ -755,7 +755,7 @@ public void testCreateClusterStatusNotReady(TestContext context) {
 
             // Verify status
             List<KafkaConnectS2I> capturedConnects = connectCaptor.getAllValues();
-            context.assertEquals(capturedConnects.get(0).getStatus().getRestApiAddress(), "foo-connect-api.test.svc:8083");
+            context.assertEquals(capturedConnects.get(0).getStatus().getUrl(), "http://foo-connect-api.test.svc:8083");
             context.assertEquals(capturedConnects.get(0).getStatus().getConditions().get(0).getStatus(), "True");
             context.assertEquals(capturedConnects.get(0).getStatus().getConditions().get(0).getType(), "NotReady");
             context.assertEquals(capturedConnects.get(0).getStatus().getConditions().get(0).getMessage(), failureMessage);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -100,6 +100,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge
             .compose(i -> podDisruptionBudgetOperator.reconcile(namespace, bridge.getName(), bridge.generatePodDisruptionBudget()))
             .compose(i -> deploymentOperations.reconcile(namespace, bridge.getName(), bridge.generateDeployment(annotations, pfa.isOpenshift(), imagePullPolicy, imagePullSecrets)))
             .compose(i -> deploymentOperations.scaleUp(namespace, bridge.getName(), bridge.getReplicas()))
+            .compose(i -> deploymentOperations.waitForObserved(namespace, bridge.getName(), 1_000, operationTimeoutMs))
             .compose(i -> deploymentOperations.readiness(namespace, bridge.getName(), 1_000, operationTimeoutMs))
             .compose(i -> chainFuture.complete(), chainFuture)
             .setHandler(reconciliationResult -> {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -100,6 +100,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
                 .compose(i -> podDisruptionBudgetOperator.reconcile(namespace, connect.getName(), connect.generatePodDisruptionBudget()))
                 .compose(i -> deploymentOperations.reconcile(namespace, connect.getName(), connect.generateDeployment(annotations, pfa.isOpenshift(), imagePullPolicy, imagePullSecrets)))
                 .compose(i -> deploymentOperations.scaleUp(namespace, connect.getName(), connect.getReplicas()))
+                .compose(i -> deploymentOperations.waitForObserved(namespace, connect.getName(), 1_000, operationTimeoutMs))
                 .compose(i -> deploymentOperations.readiness(namespace, connect.getName(), 1_000, operationTimeoutMs))
                 .compose(i -> chainFuture.complete(), chainFuture)
                 .setHandler(reconciliationResult -> {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -111,6 +111,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
                     .compose(i -> podDisruptionBudgetOperator.reconcile(namespace, connect.getName(), connect.generatePodDisruptionBudget()))
                     .compose(i -> buildConfigOperations.reconcile(namespace, KafkaConnectS2IResources.buildConfigName(connect.getCluster()), connect.generateBuildConfig()))
                     .compose(i -> deploymentConfigOperations.scaleUp(namespace, connect.getName(), connect.getReplicas()))
+                    .compose(i -> deploymentConfigOperations.waitForObserved(namespace, connect.getName(), 1_000, operationTimeoutMs))
                     .compose(i -> deploymentConfigOperations.readiness(namespace, connect.getName(), 1_000, operationTimeoutMs))
                     .compose(i -> chainFuture.complete(), chainFuture)
                     .setHandler(reconciliationResult -> {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -103,6 +103,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                 .compose(i -> podDisruptionBudgetOperator.reconcile(namespace, mirror.getName(), mirror.generatePodDisruptionBudget()))
                 .compose(i -> deploymentOperations.reconcile(namespace, mirror.getName(), mirror.generateDeployment(annotations, pfa.isOpenshift(), imagePullPolicy, imagePullSecrets)))
                 .compose(i -> deploymentOperations.scaleUp(namespace, mirror.getName(), mirror.getReplicas()))
+                .compose(i -> deploymentOperations.waitForObserved(namespace, mirror.getName(), 1_000, operationTimeoutMs))
                 .compose(i -> deploymentOperations.readiness(namespace, mirror.getName(), 1_000, operationTimeoutMs))
                 .compose(i -> chainFuture.complete(), chainFuture)
                 .setHandler(reconciliationResult -> {

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -543,7 +543,7 @@ void testSendMessagesTlsAuthenticated() throws Exception {
                 .endSpec().build()).done();
         testMethodResources().topic(CLUSTER_NAME, topicName).done();
         KafkaUser user = testMethodResources().tlsUser(CLUSTER_NAME, kafkaUser).done();
-        waitTillSecretExists(kafkaUser);
+        StUtils.waitForSecretReady(kafkaUser);
 
         testMethodResources().deployKafkaClients(true, CLUSTER_NAME, NAMESPACE, user).done();
         availabilityTest(messagesCount, Constants.TIMEOUT_AVAILABILITY_TEST, CLUSTER_NAME, true, topicName, user);
@@ -574,7 +574,7 @@ void testSendMessagesPlainScramSha() throws Exception {
                 .endSpec().build()).done();
         testMethodResources().topic(CLUSTER_NAME, topicName).done();
         KafkaUser user = testMethodResources().scramShaUser(CLUSTER_NAME, kafkaUser).done();
-        waitTillSecretExists(kafkaUser);
+        StUtils.waitForSecretReady(kafkaUser);
         String brokerPodLog = kubeClient().logs(CLUSTER_NAME + "-kafka-0", "kafka");
         Pattern p = Pattern.compile("^.*" + Pattern.quote(kafkaUser) + ".*$", Pattern.MULTILINE);
         Matcher m = p.matcher(brokerPodLog);
@@ -615,7 +615,7 @@ void testSendMessagesTlsScramSha() throws Exception {
                 .endSpec().build()).done();
         testMethodResources().topic(CLUSTER_NAME, topicName).done();
         KafkaUser user = testMethodResources().scramShaUser(CLUSTER_NAME, kafkaUser).done();
-        waitTillSecretExists(kafkaUser);
+        StUtils.waitForSecretReady(kafkaUser);
 
         testMethodResources().deployKafkaClients(true, CLUSTER_NAME, NAMESPACE, user).done();
         availabilityTest(messagesCount, 180000, CLUSTER_NAME, true, topicName, user);

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -342,7 +342,7 @@ void testAutoRenewCaCertsTriggerByExpiredCertificate() throws Exception {
         String userName = "alice";
         testMethodResources().tlsUser(CLUSTER_NAME, userName).done();
         // Check if user exists
-        waitTillSecretExists(userName);
+        StUtils.waitForSecretReady(userName);
 
         waitForClusterAvailabilityTls(userName, NAMESPACE);
 

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeScramShaST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.api.kafka.model.listener.KafkaListenerTls;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.HttpBridgeBaseST;
+import io.strimzi.systemtest.utils.StUtils;
 import io.vertx.core.json.JsonArray;
 import io.vertx.core.json.JsonObject;
 import io.vertx.junit5.VertxExtension;
@@ -118,7 +119,7 @@ void createClassResources() throws InterruptedException {
 
         // Create Kafka user
         KafkaUser userSource = testClassResources().scramShaUser(CLUSTER_NAME, userName).done();
-        waitTillSecretExists(userName);
+        StUtils.waitForSecretReady(userName);
 
         // Initialize PasswordSecret to set this as PasswordSecret in Mirror Maker spec
         PasswordSecretSource passwordSecret = new PasswordSecretSource();

File: systemtest/src/test/java/io/strimzi/systemtest/bridge/HttpBridgeTlsST.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.api.kafka.model.listener.KafkaListenerTls;
 import io.strimzi.systemtest.Constants;
 import io.strimzi.systemtest.HttpBridgeBaseST;
+import io.strimzi.systemtest.utils.StUtils;
 import io.vertx.core.json.JsonArray;
 import io.vertx.core.json.JsonObject;
 import io.vertx.junit5.VertxExtension;
@@ -116,7 +117,7 @@ void createClassResources() throws InterruptedException {
 
         // Create Kafka user
         KafkaUser userSource = testClassResources().tlsUser(CLUSTER_NAME, userName).done();
-        waitTillSecretExists(userName);
+        StUtils.waitForSecretReady(userName);
 
         // Initialize CertSecretSource with certificate and secret names for consumer
         CertSecretSource certSecret = new CertSecretSource();

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -508,9 +508,9 @@ private Kafka waitFor(Kafka kafka) {
         LOGGER.info("Zookeeper pods are ready");
         LOGGER.info("Waiting for Kafka pods");
         StUtils.waitForAllStatefulSetPodsReady(KafkaResources.kafkaStatefulSetName(name), kafka.getSpec().getKafka().getReplicas());
-        LOGGER.info("Kafka pod are ready");
+        LOGGER.info("Kafka pods are ready");
         // EO should not be deployed if it does not contain UO and TO
-        if (kafka.getSpec().getEntityOperator().getUserOperator() != null || kafka.getSpec().getEntityOperator().getTopicOperator() != null) {
+        if (kafka.getSpec().getEntityOperator() != null) {
             LOGGER.info("Waiting for Entity Operator pods");
             StUtils.waitForDeploymentReady(KafkaResources.entityOperatorDeploymentName(name));
             LOGGER.info("Entity Operator pods are ready");

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -212,6 +212,7 @@ void testEODeletion() {
         // Wait when EO(UO + TO) will be removed
         StUtils.waitForDeploymentDeletion(entityOperatorDeploymentName(CLUSTER_NAME));
         StUtils.waitForPodDeletion(pod.get().getMetadata().getName());
+        LOGGER.info("EO was deleted");
     }
 
     @Test
@@ -1001,7 +1002,7 @@ private void testDockerImagesForKafkaCluster(String clusterName, int kafkaPods,
         //Verifying docker image for zookeeper pods
         for (int i = 0; i < zkPods; i++) {
             String imgFromPod = getContainerImageNameFromPod(zookeeperPodName(clusterName, i), "zookeeper");
-            assertEquals(imgFromDeplConf.get(ZK_IMAGE), imgFromPod);
+            assertThat("Zookeeper image for pod " + i + " uses wrong image", imgFromPod.contains(Environment.ST_KAFKA_VERSION));
             imgFromPod = getContainerImageNameFromPod(zookeeperPodName(clusterName, i), "tls-sidecar");
             assertEquals(imgFromDeplConf.get(TLS_SIDECAR_ZOOKEEPER_IMAGE), imgFromPod);
         }

File: api/src/main/java/io/strimzi/api/kafka/Crds.java
Patch:
@@ -167,6 +167,7 @@ private static CustomResourceDefinition crd(Class<? extends CustomResource> cls,
             group = KafkaMirrorMaker.RESOURCE_GROUP;
             kind = KafkaMirrorMaker.RESOURCE_KIND;
             listKind = KafkaMirrorMaker.RESOURCE_LIST_KIND;
+            status = new CustomResourceSubresourceStatus();
             if (!KafkaMirrorMaker.VERSIONS.contains(version)) {
                 throw new RuntimeException();
             }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -18,6 +18,7 @@
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaBridge;
+import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
@@ -61,6 +62,8 @@ public CrdOperator(Vertx vertx, C client, Class<T> cls, Class<L> listCls, Class<
             this.plural = KafkaConnectS2I.RESOURCE_PLURAL;
         } else if (cls.equals(KafkaBridge.class)) {
             this.plural = KafkaBridge.RESOURCE_PLURAL;
+        } else if (cls.equals(KafkaMirrorMaker.class)) {
+            this.plural = KafkaMirrorMaker.RESOURCE_PLURAL;
         } else {
             this.plural = null;
         }

File: api/src/main/java/io/strimzi/api/kafka/Crds.java
Patch:
@@ -178,6 +178,7 @@ private static CustomResourceDefinition crd(Class<? extends CustomResource> cls,
             group = KafkaBridge.RESOURCE_GROUP;
             kind = KafkaBridge.RESOURCE_KIND;
             listKind = KafkaBridge.RESOURCE_LIST_KIND;
+            status = new CustomResourceSubresourceStatus();
             if (!KafkaBridge.VERSIONS.contains(version)) {
                 throw new RuntimeException();
             }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -17,6 +17,7 @@
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
+import io.strimzi.api.kafka.model.KafkaBridge;
 import io.strimzi.api.kafka.model.KafkaUser;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
@@ -58,6 +59,8 @@ public CrdOperator(Vertx vertx, C client, Class<T> cls, Class<L> listCls, Class<
             this.plural = KafkaConnect.RESOURCE_PLURAL;
         } else if (cls.equals(KafkaConnectS2I.class)) {
             this.plural = KafkaConnectS2I.RESOURCE_PLURAL;
+        } else if (cls.equals(KafkaBridge.class)) {
+            this.plural = KafkaBridge.RESOURCE_PLURAL;
         } else {
             this.plural = null;
         }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -46,7 +46,7 @@ void testDeployS2IWithMongoDBPlugin() throws IOException {
         File dir = StUtils.downloadAndUnzip("https://repo1.maven.org/maven2/io/debezium/debezium-connector-mongodb/0.7.5/debezium-connector-mongodb-0.7.5-plugin.zip");
 
         // Start a new image build using the plugins directory
-        cmdKubeClient().exec("oc", "start-build", CONNECT_DEPLOYMENT_NAME, "--from-dir", dir.getAbsolutePath());
+        cmdKubeClient().exec("oc", "start-build", CONNECT_DEPLOYMENT_NAME, "--from-dir", dir.getAbsolutePath(), "-n", NAMESPACE);
         // Wait for rolling update connect pods
         StUtils.waitTillDepConfigHasRolled(CONNECT_DEPLOYMENT_NAME, 1, connectSnapshot);
         String connectS2IPodName = kubeClient().listPods("type", "kafka-connect-s2i").get(0).getMetadata().getName();

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectCrdOperatorIT.java
Patch:
@@ -77,15 +77,15 @@ public static void before() {
         }
 
         log.info("Creating CRD");
-        client.customResourceDefinitions().create(Crds.kafkaUser());
+        client.customResourceDefinitions().create(Crds.kafkaConnect());
         log.info("Created CRD");
     }
 
     @AfterClass
     public static void after() {
         if (client != null) {
             log.info("Deleting CRD");
-            client.customResourceDefinitions().delete(Crds.kafkaUser());
+            client.customResourceDefinitions().delete(Crds.kafkaConnect());
         }
 
         if (vertx != null) {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/KafkaConnectS2IcrdOperatorIT.java
Patch:
@@ -77,15 +77,15 @@ public static void before() {
         }
 
         log.info("Creating CRD");
-        client.customResourceDefinitions().create(Crds.kafkaUser());
+        client.customResourceDefinitions().create(Crds.kafkaConnectS2I());
         log.info("Created CRD");
     }
 
     @AfterClass
     public static void after() {
         if (client != null) {
             log.info("Deleting CRD");
-            client.customResourceDefinitions().delete(Crds.kafkaUser());
+            client.customResourceDefinitions().delete(Crds.kafkaConnectS2I());
         }
 
         if (vertx != null) {

File: systemtest/src/main/java/io/strimzi/systemtest/HttpBridgeBaseST.java
Patch:
@@ -179,7 +179,7 @@ protected void deployBridgeNodePortService() throws InterruptedException {
                 .withType("NodePort")
                 .withSelector(map)
                 .endSpec().build();
-        getTestClassResources().createServiceResource(service, getBridgeNamespace()).done();
+        testClassResources().createServiceResource(service, getBridgeNamespace()).done();
         StUtils.waitForNodePortService(bridgeExternalService);
     }
 
@@ -220,6 +220,6 @@ void deployClusterOperator() {
         createTestClassResources();
         applyRoleBindings(getBridgeNamespace());
         // 050-Deployment
-        getTestClassResources().clusterOperator(getBridgeNamespace()).done();
+        testClassResources().clusterOperator(getBridgeNamespace()).done();
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -35,7 +35,7 @@ class ConnectS2IST extends AbstractST {
     @OpenShiftOnly
     @Tag(ACCEPTANCE)
     void testDeployS2IWithMongoDBPlugin() throws IOException {
-        getTestClassResources().kafkaConnectS2I(CONNECT_CLUSTER_NAME, 1, CLUSTER_NAME)
+        testClassResources().kafkaConnectS2I(CONNECT_CLUSTER_NAME, 1, CLUSTER_NAME)
             .editMetadata()
                 .addToLabels("type", "kafka-connect-s2i")
             .endMetadata()
@@ -68,12 +68,12 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        getTestClassResources().clusterOperator(NAMESPACE).done();
+        testClassResources().clusterOperator(NAMESPACE).done();
         deployTestSpecificResources();
     }
 
     void deployTestSpecificResources() {
-        getTestClassResources().kafkaEphemeral(CLUSTER_NAME, 3, 1).done();
+        testClassResources().kafkaEphemeral(CLUSTER_NAME, 3, 1).done();
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -257,7 +257,7 @@ void setupEnvironment() {
 
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        getTestClassResources().clusterOperator(NAMESPACE).done();
+        testClassResources().clusterOperator(NAMESPACE).done();
         deployTestSpecificResources();
     }
 
@@ -267,7 +267,7 @@ void deployTestSpecificResources() {
         kafkaConfig.put("transaction.state.log.replication.factor", "3");
         kafkaConfig.put("transaction.state.log.min.isr", "2");
 
-        getTestClassResources().kafkaEphemeral(KAFKA_CLUSTER_NAME, 3)
+        testClassResources().kafkaEphemeral(KAFKA_CLUSTER_NAME, 3)
             .editSpec()
                 .editKafka()
                     .withConfig(kafkaConfig)

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -1427,7 +1427,7 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        getTestClassResources().clusterOperator(NAMESPACE).done();
+        testClassResources().clusterOperator(NAMESPACE).done();
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/MirrorMakerST.java
Patch:
@@ -316,12 +316,12 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        getTestClassResources().clusterOperator(NAMESPACE).done();
+        testClassResources().clusterOperator(NAMESPACE).done();
     }
 
     @AfterAll
     void teardownEnvironment() {
-        getTestClassResources().deleteResources();
+        testClassResources().deleteResources();
         teardownEnvForOperator();
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/MultipleNamespaceST.java
Patch:
@@ -65,13 +65,13 @@ void setupEnvironment() {
         applyRoleBindings(CO_NAMESPACE, SECOND_NAMESPACE);
 
         LOGGER.info("Deploying CO to watch multiple namespaces");
-        getTestClassResources().clusterOperator(String.join(",", CO_NAMESPACE, SECOND_NAMESPACE)).done();
+        testClassResources().clusterOperator(String.join(",", CO_NAMESPACE, SECOND_NAMESPACE)).done();
 
         deployTestSpecificResources();
     }
 
     private void deployTestSpecificResources() {
-        getTestClassResources().kafkaEphemeral(CLUSTER_NAME, 3)
+        testClassResources().kafkaEphemeral(CLUSTER_NAME, 3)
             .editSpec()
                 .editEntityOperator()
                     .editTopicOperator()

File: systemtest/src/test/java/io/strimzi/systemtest/RecoveryST.java
Patch:
@@ -247,14 +247,14 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        getTestClassResources().clusterOperator(NAMESPACE).done();
+        testClassResources().clusterOperator(NAMESPACE).done();
 
         deployTestSpecificResources();
     }
 
     void deployTestSpecificResources() {
-        getTestClassResources().kafkaEphemeral(CLUSTER_NAME, 3, 1).done();
-        getTestClassResources().kafkaBridge(CLUSTER_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), 1, Constants.HTTP_BRIDGE_DEFAULT_PORT).done();
+        testClassResources().kafkaEphemeral(CLUSTER_NAME, 3, 1).done();
+        testClassResources().kafkaBridge(CLUSTER_NAME, KafkaResources.plainBootstrapAddress(CLUSTER_NAME), 1, Constants.HTTP_BRIDGE_DEFAULT_PORT).done();
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/RollingUpdateST.java
Patch:
@@ -173,7 +173,7 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        getTestClassResources().clusterOperator(NAMESPACE, Long.toString(Constants.CO_OPERATION_TIMEOUT)).done();
+        testClassResources().clusterOperator(NAMESPACE, Long.toString(Constants.CO_OPERATION_TIMEOUT)).done();
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -488,7 +488,7 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        getTestClassResources().clusterOperator(NAMESPACE).done();
+        testClassResources().clusterOperator(NAMESPACE).done();
     }
 
     @Override

File: test/src/main/java/io/strimzi/test/k8s/KubeClient.java
Patch:
@@ -122,7 +122,6 @@ public List<ConfigMap> listConfigMaps() {
         return client.configMaps().inNamespace(getNamespace()).list().getItems();
     }
 
-
     public String execInPod(String podName, String container, String... command) {
         ByteArrayOutputStream baos = new ByteArrayOutputStream();
         LOGGER.info("Running command on pod {}: {}", podName, command);

File: api/src/main/java/io/strimzi/api/kafka/Crds.java
Patch:
@@ -120,6 +120,7 @@ private static CustomResourceDefinition crd(Class<? extends CustomResource> cls,
             group = KafkaConnect.RESOURCE_GROUP;
             kind = KafkaConnect.RESOURCE_KIND;
             listKind = KafkaConnect.RESOURCE_LIST_KIND;
+            status = new CustomResourceSubresourceStatus();
             if (!KafkaConnect.VERSIONS.contains(version)) {
                 throw new RuntimeException();
             }
@@ -131,6 +132,7 @@ private static CustomResourceDefinition crd(Class<? extends CustomResource> cls,
             group = KafkaConnectS2I.RESOURCE_GROUP;
             kind = KafkaConnectS2I.RESOURCE_KIND;
             listKind = KafkaConnectS2I.RESOURCE_LIST_KIND;
+            status = new CustomResourceSubresourceStatus();
             if (!KafkaConnectS2I.VERSIONS.contains(version)) {
                 throw new RuntimeException();
             }

File: api/src/main/java/io/strimzi/api/kafka/model/status/Status.java
Patch:
@@ -41,7 +41,7 @@ public void setConditions(List<Condition> conditions) {
         this.conditions = conditions;
     }
 
-    @Description("The generation of the CRD which was last reconciled by the operator.")
+    @Description("The generation of the CRD that was last reconciled by the operator.")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public long getObservedGeneration() {
         return observedGeneration;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -58,7 +58,7 @@
 public class KafkaConnectCluster extends AbstractModel {
 
     // Port configuration
-    protected static final int REST_API_PORT = 8083;
+    public static final int REST_API_PORT = 8083;
     protected static final String REST_API_PORT_NAME = "rest-api";
 
     protected static final String TLS_CERTS_BASE_VOLUME_MOUNT = "/opt/kafka/connect-certs/";

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -87,6 +87,7 @@ public abstract class AbstractAssemblyOperator<C extends KubernetesClient, T ext
     protected final List<LocalObjectReference> imagePullSecrets;
     protected final KafkaVersion.Lookup versions;
     private final String kind;
+    protected long operationTimeoutMs;
 
     /**
      * @param vertx The Vertx instance
@@ -118,6 +119,7 @@ protected AbstractAssemblyOperator(Vertx vertx, PlatformFeaturesAvailability pfa
         this.imagePullPolicy = config.getImagePullPolicy();
         this.imagePullSecrets = config.getImagePullSecrets();
         this.versions = config.versions();
+        this.operationTimeoutMs = config.getOperationTimeoutMs();
     }
 
     /**

File: mockkube/src/main/java/io/strimzi/test/mockkube/MockKube.java
Patch:
@@ -370,6 +370,7 @@ protected void nameScopedMocks(RollableScalableResource<Deployment, DoneableDepl
 
                     return deployment;
                 });
+                when(resource.isReady()).thenReturn(true);
             }
         }.build();
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.operator.cluster;
 
+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.api.model.rbac.ClusterRole;
 import io.fabric8.kubernetes.client.DefaultKubernetesClient;
 import io.fabric8.kubernetes.client.KubernetesClient;
@@ -33,6 +34,7 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
+@SuppressFBWarnings("DM_EXIT")
 public class Main {
     private static final Logger log = LogManager.getLogger(Main.class.getName());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -1152,7 +1152,7 @@ Future<ReconciliationState> zkRollingUpdate() {
          */
         Future<ReconciliationState> zkScaleUpStep() {
             Future<StatefulSet> futss = zkSetOperations.getAsync(namespace, ZookeeperCluster.zookeeperClusterName(name));
-            return withVoid(futss.map(ss -> ss == null ? 0 : ss.getSpec().getReplicas())
+            return withVoid(futss.map(ss -> ss == null ? Integer.valueOf(0) : ss.getSpec().getReplicas())
                     .compose(currentReplicas -> {
                         if (currentReplicas > 0 && zkCluster.getReplicas() > currentReplicas) {
                             zkCluster.setReplicas(currentReplicas + 1);

File: systemtest/src/main/java/io/strimzi/systemtest/HttpBridgeBaseST.java
Patch:
@@ -179,7 +179,7 @@ protected void deployBridgeNodePortService() throws InterruptedException {
                 .withType("NodePort")
                 .withSelector(map)
                 .endSpec().build();
-        testClassResources.createServiceResource(service, getBridgeNamespace()).done();
+        getTestClassResources().createServiceResource(service, getBridgeNamespace()).done();
         StUtils.waitForNodePortService(bridgeExternalService);
     }
 
@@ -220,6 +220,6 @@ void deployClusterOperator() {
         createTestClassResources();
         applyRoleBindings(getBridgeNamespace());
         // 050-Deployment
-        testClassResources.clusterOperator(getBridgeNamespace()).done();
+        getTestClassResources().clusterOperator(getBridgeNamespace()).done();
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -72,6 +72,7 @@
 
 import java.net.MalformedURLException;
 import java.net.URL;
+import java.nio.charset.Charset;
 import java.util.ArrayList;
 import java.util.Base64;
 import java.util.Collections;
@@ -1123,7 +1124,7 @@ String clusterCaCertSecretName(String cluster) {
     String saslConfigs(KafkaUser kafkaUser) {
         Secret secret = client().getSecret(kafkaUser.getMetadata().getName());
 
-        String password = new String(Base64.getDecoder().decode(secret.getData().get("password")));
+        String password = new String(Base64.getDecoder().decode(secret.getData().get("password")), Charset.forName("UTF-8"));
         if (password.isEmpty()) {
             LOGGER.info("Secret {}:\n{}", kafkaUser.getMetadata().getName(), toYamlString(secret));
             throw new RuntimeException("The Secret " + kafkaUser.getMetadata().getName() + " lacks the 'password' key");

File: systemtest/src/main/java/io/strimzi/systemtest/clients/api/VerifiableClient.java
Patch:
@@ -108,6 +108,7 @@ protected void setAllowedArguments(ClientType clientType) {
                 allowedArguments.add(ClientArgument.VALUE_PREFIX);
                 allowedArguments.add(ClientArgument.REPEATING_KEYS);
                 allowedArguments.add(ClientArgument.USER);
+                break;
             case CLI_KAFKA_VERIFIABLE_CONSUMER:
                 allowedArguments.add(ClientArgument.BROKER_LIST);
                 allowedArguments.add(ClientArgument.TOPIC);

File: systemtest/src/main/java/io/strimzi/systemtest/utils/LogCollector.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.systemtest.utils;
 
+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.strimzi.test.k8s.KubeClient;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -22,6 +23,7 @@ public class LogCollector {
     private File configMapDir;
     private File eventsDir;
 
+    @SuppressFBWarnings("RV_RETURN_VALUE_IGNORED_BAD_PRACTICE")
     public LogCollector(KubeClient kubeClient, File logDir) {
         this.kubeClient = kubeClient;
         this.namespace = kubeClient.getNamespace();

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -35,7 +35,7 @@ class ConnectS2IST extends AbstractST {
     @OpenShiftOnly
     @Tag(ACCEPTANCE)
     void testDeployS2IWithMongoDBPlugin() throws IOException {
-        testClassResources.kafkaConnectS2I(CONNECT_CLUSTER_NAME, 1, CLUSTER_NAME)
+        getTestClassResources().kafkaConnectS2I(CONNECT_CLUSTER_NAME, 1, CLUSTER_NAME)
             .editMetadata()
                 .addToLabels("type", "kafka-connect-s2i")
             .endMetadata()
@@ -68,12 +68,12 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        testClassResources.clusterOperator(NAMESPACE).done();
+        getTestClassResources().clusterOperator(NAMESPACE).done();
         deployTestSpecificResources();
     }
 
     void deployTestSpecificResources() {
-        testClassResources.kafkaEphemeral(CLUSTER_NAME, 3, 1).done();
+        getTestClassResources().kafkaEphemeral(CLUSTER_NAME, 3, 1).done();
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -257,7 +257,7 @@ void setupEnvironment() {
 
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        testClassResources.clusterOperator(NAMESPACE).done();
+        getTestClassResources().clusterOperator(NAMESPACE).done();
         deployTestSpecificResources();
     }
 
@@ -267,7 +267,7 @@ void deployTestSpecificResources() {
         kafkaConfig.put("transaction.state.log.replication.factor", "3");
         kafkaConfig.put("transaction.state.log.min.isr", "2");
 
-        testClassResources.kafkaEphemeral(KAFKA_CLUSTER_NAME, 3)
+        getTestClassResources().kafkaEphemeral(KAFKA_CLUSTER_NAME, 3)
             .editSpec()
                 .editKafka()
                     .withConfig(kafkaConfig)

File: systemtest/src/test/java/io/strimzi/systemtest/MultipleNamespaceST.java
Patch:
@@ -65,13 +65,13 @@ void setupEnvironment() {
         applyRoleBindings(CO_NAMESPACE, SECOND_NAMESPACE);
 
         LOGGER.info("Deploying CO to watch multiple namespaces");
-        testClassResources.clusterOperator(String.join(",", CO_NAMESPACE, SECOND_NAMESPACE)).done();
+        getTestClassResources().clusterOperator(String.join(",", CO_NAMESPACE, SECOND_NAMESPACE)).done();
 
         deployTestSpecificResources();
     }
 
     private void deployTestSpecificResources() {
-        testClassResources.kafkaEphemeral(CLUSTER_NAME, 3)
+        getTestClassResources().kafkaEphemeral(CLUSTER_NAME, 3)
             .editSpec()
                 .editEntityOperator()
                     .editTopicOperator()

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -488,7 +488,7 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        testClassResources.clusterOperator(NAMESPACE).done();
+        getTestClassResources().clusterOperator(NAMESPACE).done();
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -159,7 +159,7 @@ void setupEnvironment() {
         createTestClassResources();
         applyRoleBindings(NAMESPACE);
         // 050-Deployment
-        testClassResources.clusterOperator(NAMESPACE).done();
+        getTestClassResources().clusterOperator(NAMESPACE).done();
     }
 
     @Override

File: test-client/src/main/java/io/strimzi/test_client/HttpClientsListener.java
Patch:
@@ -45,6 +45,9 @@ public void start() {
                 case DELETE:
                     deleteHandler(request);
                     break;
+                default:
+                    LOGGER.warn("Unexpected HTTP method ({}).", request.method());
+                    break;
             }
         });
         int port = 4242;

File: user-operator/src/main/java/io/strimzi/operator/user/Main.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.operator.user;
 
+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;
 import io.fabric8.kubernetes.client.DefaultKubernetesClient;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.strimzi.api.kafka.Crds;
@@ -26,6 +27,7 @@
 import java.util.HashMap;
 import java.util.Map;
 
+@SuppressFBWarnings("DM_EXIT")
 public class Main {
     private static final Logger log = LogManager.getLogger(Main.class.getName());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -12,6 +12,7 @@
 import io.strimzi.api.kafka.model.DoneableKafkaBridge;
 import io.strimzi.api.kafka.model.ExternalLogging;
 import io.strimzi.api.kafka.model.KafkaBridge;
+import io.strimzi.api.kafka.model.KafkaBridgeResources;
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.PlatformFeaturesAvailability;
@@ -94,7 +95,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge
 
     Future<ReconcileResult<ServiceAccount>> kafkaBridgeServiceAccount(String namespace, KafkaBridgeCluster bridge) {
         return serviceAccountOperations.reconcile(namespace,
-                KafkaBridgeCluster.containerServiceAccountName(bridge.getCluster()),
+                KafkaBridgeResources.serviceAccountName(bridge.getCluster()),
                 bridge.generateServiceAccount());
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -177,7 +177,7 @@ void testKafkaAndZookeeperScaleUpScaleDown() throws Exception {
         //Test that the new broker has event 'Killing'
         assertThat(getEvents(uid), hasAllOfReasons(Killing));
         //Test that stateful set has event 'SuccessfulDelete'
-        uid = kubeClient().getSsUid(kafkaClusterName(CLUSTER_NAME));
+        uid = kubeClient().getStatefulSetUid(kafkaClusterName(CLUSTER_NAME));
         assertThat(getEvents(uid), hasAllOfReasons(SuccessfulDelete));
         //Test that CO doesn't have any exceptions in log
         TimeMeasuringSystem.stopOperation(operationID);
@@ -255,7 +255,7 @@ void testZookeeperScaleUpScaleDown() {
         //Test that the second pod has event 'Killing'
         assertThat(getEvents(uid), hasAllOfReasons(Killing));
         //Test that stateful set has event 'SuccessfulDelete'
-        uid = kubeClient().getStatefulUid(zookeeperClusterName(CLUSTER_NAME));
+        uid = kubeClient().getStatefulSetUid(zookeeperClusterName(CLUSTER_NAME));
         assertThat(getEvents(uid), hasAllOfReasons(SuccessfulDelete));
         // Stop measuring
         TimeMeasuringSystem.stopOperation(operationID);

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaBridgeSpec.java
Patch:
@@ -115,7 +115,7 @@ public void setAuthentication(KafkaBridgeAuthentication authentication) {
         this.authentication = authentication;
     }
 
-    @Description("TLS configuration for connecting to the cluster.")
+    @Description("TLS configuration for connecting Kafka Bridge to the cluster.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     public KafkaBridgeTls getTls() {
         return tls;
@@ -125,7 +125,7 @@ public void setTls(KafkaBridgeTls tls) {
         this.tls = tls;
     }
 
-    @Description("A list of host:port pairs to use for establishing the initial connection to the Kafka cluster.")
+    @Description("A list of host:port pairs for establishing the initial connection to the Kafka cluster.")
     @JsonProperty(required = true)
     public String getBootstrapServers() {
         return bootstrapServers;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerClientSpec.java
Patch:
@@ -51,7 +51,7 @@ public void setConfig(Map<String, Object> config) {
         this.config = config;
     }
 
-    @Description("TLS configuration for connecting to the cluster.")
+    @Description("TLS configuration for connecting Mirror Maker to the cluster.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     public KafkaMirrorMakerTls getTls() {
         return tls;
@@ -61,7 +61,7 @@ public void setTls(KafkaMirrorMakerTls tls) {
         this.tls = tls;
     }
 
-    @Description("A list of host:port pairs to use for establishing the initial connection to the Kafka cluster.")
+    @Description("A list of host:port pairs for establishing the initial connection to the Kafka cluster.")
     @JsonProperty(required = true)
     public String getBootstrapServers() {
         return bootstrapServers;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerConsumerSpec.java
Patch:
@@ -35,7 +35,7 @@ public class KafkaMirrorMakerConsumerSpec extends KafkaMirrorMakerClientSpec {
     private Integer offsetCommitInterval;
 
     @Override
-    @Description("The mirror maker consumer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
+    @Description("The Mirror Maker consumer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
     public Map<String, Object> getConfig() {
         return config;
     }
@@ -61,7 +61,7 @@ public void setGroupId(String groupId) {
         this.groupId = groupId;
     }
 
-    @Description("Offset commit interval in ms. Default value is 60 000.")
+    @Description("Specifies the offset auto-commit interval in ms. Default value is 60000.")
     @JsonInclude(JsonInclude.Include.NON_DEFAULT)
     public Integer getOffsetCommitInterval() {
         return offsetCommitInterval;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerProducerSpec.java
Patch:
@@ -27,7 +27,7 @@ public class KafkaMirrorMakerProducerSpec extends KafkaMirrorMakerClientSpec {
 
     public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, sasl., security.";
 
-    @Description("Configure the mirror maker to exit on a failed send. Default value is `true`.")
+    @Description("Flag to set the Mirror Maker to exit on a failed send. Default value is `true`.")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     public Boolean getAbortOnSendFailure() {
         return abortOnSendFailure;
@@ -38,7 +38,7 @@ public void setAbortOnSendFailure(Boolean abortOnSendFailure) {
     }
 
     @Override
-    @Description("The mirror maker producer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
+    @Description("The Mirror Maker producer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
     public Map<String, Object> getConfig() {
         return config;
     }

File: user-operator/src/main/java/io/strimzi/operator/user/model/KafkaUserModel.java
Patch:
@@ -99,7 +99,6 @@ public static KafkaUserModel fromCrd(CertManager certManager,
         result.setAuthentication(kafkaUser.getSpec().getAuthentication());
 
         if (kafkaUser.getSpec().getAuthentication() instanceof KafkaUserTlsClientAuthentication) {
-            //if (kafkaUser.getMetadata().getName().length() > 64)    {
             if (kafkaUser.getMetadata().getName().length() > OpenSslCertManager.MAXIMUM_CN_LENGTH)    {
                 throw new InvalidResourceException("Users with TLS client authentication can have a username (name of the KafkaUser custom resource) only up to 64 characters long.");
             }

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/LogHasNoUnexpectedErrors.java
Patch:
@@ -42,7 +42,8 @@ enum LogWhiteList {
         // This is necessary for OCP 3.10 or less because of having exception handling during the patching of NetworkPolicy
         CAUGHT_EXCEPTION_FOR_NETWORK_POLICY("Caught exception while patching NetworkPolicy"
                 + "(?s)(.*?)"
-                + "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: PATCH");
+                + "io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: PATCH"),
+        EXIT_ON_OUT_OF_MEMORY("ExitOnOutOfMemoryError");
 
         final String name;
 

File: test/src/main/java/io/strimzi/test/k8s/BaseCmdKubeClient.java
Patch:
@@ -372,7 +372,7 @@ public String logs(String pod, String container) {
     @Override
     public String searchInLog(String resourceType, String resourceName, long sinceSeconds, String... grepPattern) {
         try {
-            return Exec.exec("bash", "-c", join(" ", namespacedCommand("logs", resourceType + "/" + resourceName, "--since=" + String.valueOf(sinceSeconds) + "s",
+            return Exec.exec("bash", "-c", join(" ", namespacedCommand("logs", resourceType + "/" + resourceName, "--since=" + sinceSeconds + "s",
                     "|", "grep", " -e " + join(" -e ", grepPattern), "-B", "1"))).out();
         } catch (KubeClusterException e) {
             if (e.result != null && e.result.exitStatus() == 1) {

File: api/src/main/java/io/strimzi/api/kafka/Crds.java
Patch:
@@ -8,7 +8,6 @@
 import io.fabric8.kubernetes.api.model.apiextensions.CustomResourceDefinition;
 import io.fabric8.kubernetes.api.model.apiextensions.CustomResourceDefinitionBuilder;
 import io.fabric8.kubernetes.api.model.apiextensions.CustomResourceSubresourceStatus;
-import io.fabric8.kubernetes.api.model.apiextensions.CustomResourceSubresourceStatusBuilder;
 import io.fabric8.kubernetes.client.CustomResource;
 import io.fabric8.kubernetes.client.CustomResourceDoneable;
 import io.fabric8.kubernetes.client.CustomResourceList;
@@ -109,7 +108,7 @@ private static CustomResourceDefinition crd(Class<? extends CustomResource> cls,
             group = Kafka.RESOURCE_GROUP;
             kind = Kafka.RESOURCE_KIND;
             listKind = Kafka.RESOURCE_LIST_KIND;
-            status = new CustomResourceSubresourceStatusBuilder().build();
+            status = new CustomResourceSubresourceStatus();
             if (!Kafka.VERSIONS.contains(version)) {
                 throw new RuntimeException();
             }
@@ -154,6 +153,7 @@ private static CustomResourceDefinition crd(Class<? extends CustomResource> cls,
             group = KafkaUser.RESOURCE_GROUP;
             kind = KafkaUser.RESOURCE_KIND;
             listKind = KafkaUser.RESOURCE_LIST_KIND;
+            status = new CustomResourceSubresourceStatus();
             if (!KafkaUser.VERSIONS.contains(version)) {
                 throw new RuntimeException();
             }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/StorageDiff.java
Patch:
@@ -10,7 +10,7 @@
 import io.strimzi.api.kafka.model.storage.PersistentClaimStorage;
 import io.strimzi.api.kafka.model.storage.SingleVolumeStorage;
 import io.strimzi.api.kafka.model.storage.Storage;
-import io.strimzi.operator.cluster.operator.resource.AbstractResourceDiff;
+import io.strimzi.operator.common.operator.resource.AbstractResourceDiff;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetDiff.java
Patch:
@@ -8,6 +8,7 @@
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.api.model.apps.StatefulSet;
 import io.fabric8.zjsonpatch.JsonDiff;
+import io.strimzi.operator.common.operator.resource.AbstractResourceDiff;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/StatusDiff.java
Patch:
@@ -7,7 +7,7 @@
 import com.fasterxml.jackson.databind.JsonNode;
 import io.fabric8.zjsonpatch.JsonDiff;
 import io.strimzi.api.kafka.model.status.Status;
-import io.strimzi.operator.cluster.operator.resource.AbstractResourceDiff;
+import io.strimzi.operator.common.operator.resource.AbstractResourceDiff;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractResourceDiff.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster.operator.resource;
+package io.strimzi.operator.common.operator.resource;
 
 import com.fasterxml.jackson.databind.JsonNode;
 import com.fasterxml.jackson.databind.node.MissingNode;

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -15,6 +15,7 @@
 import io.fabric8.kubernetes.client.dsl.base.OperationSupport;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.model.Kafka;
+import io.strimzi.api.kafka.model.KafkaUser;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
 import okhttp3.OkHttpClient;
@@ -49,6 +50,8 @@ public CrdOperator(Vertx vertx, C client, Class<T> cls, Class<L> listCls, Class<
 
         if (cls.equals(Kafka.class)) {
             this.plural = Kafka.RESOURCE_PLURAL;
+        } else if (cls.equals(KafkaUser.class)) {
+            this.plural = KafkaUser.RESOURCE_PLURAL;
         } else {
             this.plural = null;
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaVersionTest.java
Patch:
@@ -24,6 +24,7 @@ public void load() {
         assertTrue(loaded.supportedVersions().contains("2.1.1"));
         assertTrue(loaded.supportedVersions().contains("2.2.0"));
         assertTrue(loaded.supportedVersions().contains("2.2.1"));
+        assertTrue(loaded.supportedVersions().contains("2.3.0"));
         assertEquals("2.1.1", loaded.version("2.1.1").version());
         assertEquals("2.1", loaded.version("2.1.1").protocolVersion());
         assertEquals("2.1", loaded.version("2.1.1").messageVersion());

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -57,7 +57,7 @@ public class Environment {
 
     private static final String SKIP_TEARDOWN_ENV = "SKIP_TEARDOWN";
 
-    private static final String ST_KAFKA_VERSION_DEFAULT = "2.2.1";
+    private static final String ST_KAFKA_VERSION_DEFAULT = "2.3.0";
     public static final String STRIMZI_ORG_DEFAULT = "strimzi";
     public static final String STRIMZI_TAG_DEFAULT = "latest";
     public static final String STRIMZI_REGISTRY_DEFAULT = "docker.io";

File: systemtest/src/main/java/io/strimzi/systemtest/MessagingBaseST.java
Patch:
@@ -136,6 +136,7 @@ int receiveMessages(int messageCount, long timeout, String clusterName, boolean
         ClientArgumentMap consumerArguments = new ClientArgumentMap();
         consumerArguments.put(ClientArgument.BROKER_LIST, bootstrapServer);
         consumerArguments.put(ClientArgument.GROUP_ID, "my-group" + rng.nextInt(Integer.MAX_VALUE));
+        consumerArguments.put(ClientArgument.GROUP_INSTANCE_ID, "instance" + rng.nextInt(Integer.MAX_VALUE));
         consumerArguments.put(ClientArgument.VERBOSE, "");
         consumerArguments.put(ClientArgument.TOPIC, topicName);
         consumerArguments.put(ClientArgument.MAX_MESSAGES, Integer.toString(messageCount));

File: systemtest/src/main/java/io/strimzi/systemtest/clients/api/ClientArgument.java
Patch:
@@ -16,6 +16,7 @@ public enum ClientArgument {
     CONSUMER_CONFIG("--consumer.config"),
     MAX_MESSAGES("--max-messages"),
     GROUP_ID("--group-id"),
+    GROUP_INSTANCE_ID("--group-instance-id"),
     SESSION_TIMEOUT("--session-timeout"),
     ENABLE_AUTOCOMMIT("--enable-autocommit"),
     RESET_POLICY("--reset-policy"),

File: systemtest/src/main/java/io/strimzi/systemtest/clients/api/VerifiableClient.java
Patch:
@@ -120,6 +120,7 @@ protected void setAllowedArguments(ClientType clientType) {
                 allowedArguments.add(ClientArgument.ASSIGMENT_STRATEGY);
                 allowedArguments.add(ClientArgument.CONSUMER_CONFIG);
                 allowedArguments.add(ClientArgument.USER);
+                allowedArguments.add(ClientArgument.GROUP_INSTANCE_ID);
                 break;
             default:
                 throw new IllegalArgumentException("Unexpected client type!");

File: test-client/src/main/java/io/strimzi/test_client/HttpClientsListener.java
Patch:
@@ -98,7 +98,7 @@ private void postHandler(HttpServerRequest request) {
         request.bodyHandler(handler -> {
             JsonObject json = handler.toJsonObject();
             LOGGER.info("Incoming POST request: {}", json);
-            Exec executor = new Exec(Paths.get("/opt/logs/"));
+            Exec executor = new Exec(Paths.get("/tmp/"));
             UUID uuid = UUID.randomUUID();
 
             JsonArray command = json.getJsonArray("command");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -1142,7 +1142,7 @@ Future<ReconciliationState> zkRollingUpdate() {
         /**
          * Scale up is divided by scaling up Zookeeper cluster in steps.
          * Scaling up from N to M (N > 0 and M>N) replicas is done in M-N steps.
-         * Each step performs scale up by one replica and full tolling update of Zookeeper cluster.
+         * Each step performs scale up by one replica and full rolling update of Zookeeper cluster.
          * This approach ensures a valid configuration of each Zk pod.
          * Together with modified `maybeRollingUpdate` the quorum is not lost after the scale up operation is performed.
          * There is one special case of scaling from standalone (single one) Zookeeper pod.

File: test/src/main/java/io/strimzi/test/timemeasuring/Operation.java
Patch:
@@ -14,6 +14,7 @@ public enum Operation {
     CO_CREATION,
     CO_DELETION,
     MM_DEPLOYMENT,
+    CLUSTER_DEPLOYMENT,
     CLUSTER_RECOVERY,
     NEXT_RECONCILIATION,
 }
\ No newline at end of file

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -286,10 +286,10 @@ public static void waitForDeploymentDeletion(String name) {
      * @param name The name of the Deployment.
      */
     public static void waitForDeploymentReady(String name) {
-        LOGGER.info("Waiting for Deployment {}", name);
+        LOGGER.debug("Waiting for Deployment {}", name);
         TestUtils.waitFor("deployment " + name, Constants.POLL_INTERVAL_FOR_RESOURCE_READINESS, Constants.TIMEOUT_FOR_RESOURCE_READINESS,
             () -> kubeClient().getDeploymentStatus(name));
-        LOGGER.info("Deployment {} is ready", name);
+        LOGGER.debug("Deployment {} is ready", name);
     }
 
     /**
@@ -404,7 +404,7 @@ public static void waitForKafkaCluster(Kafka kafka) {
         StUtils.waitForAllStatefulSetPodsReady(KafkaResources.zookeeperStatefulSetName(name), kafka.getSpec().getZookeeper().getReplicas());
         StUtils.waitForAllStatefulSetPodsReady(KafkaResources.kafkaStatefulSetName(name), kafka.getSpec().getKafka().getReplicas());
         StUtils.waitForDeploymentReady(KafkaResources.entityOperatorDeploymentName(name));
-        LOGGER.info("Kafka cluster {} in namesapce {} is ready", name, namespace);
+        LOGGER.info("Kafka cluster {} in namespace {} is ready", name, namespace);
     }
 
     public static void waitForKafkaTopicDeletion(String topicName) {

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -33,7 +33,6 @@ class UserST extends AbstractST {
 
     @Test
     void testUserWithNameMoreThan64Chars() {
-        LOGGER.info("Running testUserWithNameMoreThan64Chars in namespace {}", NAMESPACE);
         String userWithLongName = "user" + "abcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdefghijk"; // 65 character username
         String userWithCorrectName = "user-with-correct-name" + "abcdefghijklmnopqrstuvxyzabcdefghijklmnopq"; // 64 character username
         String saslUserWithLongName = "sasl-user" + "abcdefghijklmnopqrstuvxyzabcdefghijklmnopqrstuvxyzabcdef"; // 65 character username
@@ -88,7 +87,6 @@ void testUserWithNameMoreThan64Chars() {
 
     @Test
     void testUpdateUser() {
-        LOGGER.info("Running testUpdateUser in namespace {}", NAMESPACE);
         String kafkaUser = "test-user";
 
         testMethodResources().kafka(testMethodResources().defaultKafka(CLUSTER_NAME, 3)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -251,9 +251,9 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_CLIENTS_CA_KEY_SECRET_NAME, KafkaCluster.clientsCaKeySecretName(cluster)));
         varList.add(buildEnvVar(ENV_VAR_CLIENTS_CA_CERT_SECRET_NAME, KafkaCluster.clientsCaCertSecretName(cluster)));
         varList.add(buildEnvVar(ENV_VAR_CLIENTS_CA_NAMESPACE, namespace));
-        varList.add(buildEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
         varList.add(buildEnvVar(ENV_VAR_CLIENTS_CA_VALIDITY, Integer.toString(clientsCaValidityDays)));
         varList.add(buildEnvVar(ENV_VAR_CLIENTS_CA_RENEWAL, Integer.toString(clientsCaRenewalDays)));
+        varList.add(buildEnvVar(ENV_VAR_STRIMZI_GC_LOG_ENABLED, String.valueOf(gcLoggingEnabled)));
         return varList;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -166,9 +166,6 @@ public static EntityOperator fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup ve
 
             KafkaClusterSpec kafkaClusterSpec = kafkaAssembly.getSpec().getKafka();
             String tlsSidecarImage = versions.kafkaImage(kafkaClusterSpec.getImage(), versions.defaultVersion().version());
-            if (tlsSidecarImage == null) {
-                throw new InvalidResourceException("Version " + kafkaClusterSpec.getVersion() + " is not supported. Supported versions are: " + String.join(", ", versions.supportedVersions()) + ".");
-            }
             result.tlsSidecarImage = tlsSidecarImage;
         }
         return result;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -2331,7 +2331,7 @@ Future<ReconciliationState> entityOperatorTopicOpRoleBinding() {
         }
 
         Future<ReconciliationState> entityOperatorUserOpRoleBinding() {
-            if (eoDeployment != null && entityOperator.getTopicOperator() != null) {
+            if (eoDeployment != null && entityOperator.getUserOperator() != null) {
                 Future<ReconcileResult<RoleBinding>> ownNamespaceFuture;
                 Future<ReconcileResult<RoleBinding>> watchedNamespaceFuture;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -170,6 +170,7 @@ public abstract class AbstractModel {
     protected Map<String, String> templatePodDisruptionBudgetLabels;
     protected Map<String, String> templatePodDisruptionBudgetAnnotations;
     protected int templatePodDisruptionBudgetMaxUnavailable = 1;
+    protected String templatePodPriorityClassName;
 
     // Owner Reference information
     private String ownerApiVersion;
@@ -836,6 +837,7 @@ protected StatefulSet createStatefulSet(
                             .withTerminationGracePeriodSeconds(Long.valueOf(templateTerminationGracePeriodSeconds))
                             .withImagePullSecrets(templateImagePullSecrets != null ? templateImagePullSecrets : imagePullSecrets)
                             .withSecurityContext(securityContext)
+                            .withPriorityClassName(templatePodPriorityClassName)
                         .endSpec()
                     .endTemplate()
                     .withVolumeClaimTemplates(volumeClaims)
@@ -882,6 +884,7 @@ protected Deployment createDeployment(
                             .withTerminationGracePeriodSeconds(Long.valueOf(templateTerminationGracePeriodSeconds))
                             .withImagePullSecrets(templateImagePullSecrets != null ? templateImagePullSecrets : imagePullSecrets)
                             .withSecurityContext(templateSecurityContext)
+                            .withPriorityClassName(templatePodPriorityClassName)
                         .endSpec()
                     .endTemplate()
                 .endSpec()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -160,6 +160,7 @@ public static EntityOperator fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup ve
                     result.templateTerminationGracePeriodSeconds = pod.getTerminationGracePeriodSeconds();
                     result.templateImagePullSecrets = pod.getImagePullSecrets();
                     result.templateSecurityContext = pod.getSecurityContext();
+                    result.templatePodPriorityClassName = pod.getPriorityClassName();
                 }
             }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -137,6 +137,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                             .withTerminationGracePeriodSeconds(Long.valueOf(templateTerminationGracePeriodSeconds))
                             .withImagePullSecrets(templateImagePullSecrets != null ? templateImagePullSecrets : imagePullSecrets)
                             .withSecurityContext(templateSecurityContext)
+                            .withPriorityClassName(templatePodPriorityClassName)
                         .endSpec()
                     .endTemplate()
                     .withTriggers(configChangeTrigger, imageChangeTrigger)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ModelUtils.java
Patch:
@@ -291,6 +291,7 @@ public static void parsePodTemplate(AbstractModel model, PodTemplate pod)   {
             model.templateTerminationGracePeriodSeconds = pod.getTerminationGracePeriodSeconds();
             model.templateImagePullSecrets = pod.getImagePullSecrets();
             model.templateSecurityContext = pod.getSecurityContext();
+            model.templatePodPriorityClassName = pod.getPriorityClassName();
         }
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -182,6 +182,7 @@ public void testTemplate() {
                                             .withLabels(podLabels)
                                             .withAnnotations(podAnots)
                                         .endMetadata()
+                                        .withNewPriorityClassName("top-priority")
                                     .endPod()
                                 .endTemplate()
                             .endEntityOperator()
@@ -193,6 +194,7 @@ public void testTemplate() {
         Deployment dep = entityOperator.generateDeployment(true, Collections.EMPTY_MAP, null, null);
         assertTrue(dep.getMetadata().getLabels().entrySet().containsAll(depLabels.entrySet()));
         assertTrue(dep.getMetadata().getAnnotations().entrySet().containsAll(depAnots.entrySet()));
+        assertEquals("top-priority", dep.getSpec().getTemplate().getSpec().getPriorityClassName());
 
         // Check Pods
         assertTrue(dep.getSpec().getTemplate().getMetadata().getLabels().entrySet().containsAll(podLabels.entrySet()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaBridgeClusterTest.java
Patch:
@@ -366,6 +366,7 @@ public void testTemplate() {
                                 .withLabels(podLabels)
                                 .withAnnotations(podAnots)
                             .endMetadata()
+                            .withNewPriorityClassName("top-priority")
                         .endPod()
                         .withNewApiService()
                             .withNewMetadata()
@@ -388,6 +389,7 @@ public void testTemplate() {
         Deployment dep = kbc.generateDeployment(emptyMap(), true, null, null);
         assertTrue(dep.getMetadata().getLabels().entrySet().containsAll(depLabels.entrySet()));
         assertTrue(dep.getMetadata().getAnnotations().entrySet().containsAll(depAnots.entrySet()));
+        assertEquals("top-priority", dep.getSpec().getTemplate().getSpec().getPriorityClassName());
 
         // Check Pods
         assertTrue(dep.getSpec().getTemplate().getMetadata().getLabels().entrySet().containsAll(podLabels.entrySet()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -1047,6 +1047,7 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
                                     .withLabels(podLabels)
                                     .withAnnotations(podAnots)
                                 .endMetadata()
+                                .withNewPriorityClassName("top-priority")
                             .endPod()
                             .withNewBootstrapService()
                                 .withNewMetadata()
@@ -1100,6 +1101,7 @@ image, healthDelay, healthTimeout, metricsCm, configuration, emptyMap()))
         StatefulSet ss = kc.generateStatefulSet(true, null, null);
         assertTrue(ss.getMetadata().getLabels().entrySet().containsAll(ssLabels.entrySet()));
         assertTrue(ss.getMetadata().getAnnotations().entrySet().containsAll(ssAnots.entrySet()));
+        assertEquals("top-priority", ss.getSpec().getTemplate().getSpec().getPriorityClassName());
 
         // Check Pods
         assertTrue(ss.getSpec().getTemplate().getMetadata().getLabels().entrySet().containsAll(podLabels.entrySet()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -411,6 +411,7 @@ public void testTemplate() {
                                 .withLabels(podLabels)
                                 .withAnnotations(podAnots)
                             .endMetadata()
+                            .withNewPriorityClassName("top-priority")
                         .endPod()
                         .withNewApiService()
                             .withNewMetadata()
@@ -433,6 +434,7 @@ public void testTemplate() {
         Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
         assertTrue(dep.getMetadata().getLabels().entrySet().containsAll(depLabels.entrySet()));
         assertTrue(dep.getMetadata().getAnnotations().entrySet().containsAll(depAnots.entrySet()));
+        assertEquals("top-priority", dep.getSpec().getTemplate().getSpec().getPriorityClassName());
 
         // Check Pods
         assertTrue(dep.getSpec().getTemplate().getMetadata().getLabels().entrySet().containsAll(podLabels.entrySet()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -470,6 +470,7 @@ public void testTemplate() {
                                 .withLabels(podLabels)
                                 .withAnnotations(podAnots)
                             .endMetadata()
+                            .withNewPriorityClassName("top-priority")
                         .endPod()
                         .withNewApiService()
                             .withNewMetadata()
@@ -492,6 +493,7 @@ public void testTemplate() {
         DeploymentConfig dep = kc.generateDeploymentConfig(Collections.EMPTY_MAP, true, null, null);
         assertTrue(dep.getMetadata().getLabels().entrySet().containsAll(depLabels.entrySet()));
         assertTrue(dep.getMetadata().getAnnotations().entrySet().containsAll(depAnots.entrySet()));
+        assertEquals("top-priority", dep.getSpec().getTemplate().getSpec().getPriorityClassName());
 
         // Check Pods
         assertTrue(dep.getSpec().getTemplate().getMetadata().getLabels().entrySet().containsAll(podLabels.entrySet()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -490,6 +490,7 @@ public void testTemplate() {
                                 .withLabels(podLabels)
                                 .withAnnotations(podAnots)
                             .endMetadata()
+                            .withNewPriorityClassName("top-priority")
                         .endPod()
                         .withNewPodDisruptionBudget()
                             .withNewMetadata()
@@ -506,6 +507,7 @@ public void testTemplate() {
         Deployment dep = mmc.generateDeployment(emptyMap(), true, null, null);
         assertTrue(dep.getMetadata().getLabels().entrySet().containsAll(depLabels.entrySet()));
         assertTrue(dep.getMetadata().getAnnotations().entrySet().containsAll(depAnots.entrySet()));
+        assertEquals("top-priority", dep.getSpec().getTemplate().getSpec().getPriorityClassName());
 
         // Check Pods
         assertTrue(dep.getSpec().getTemplate().getMetadata().getLabels().entrySet().containsAll(podLabels.entrySet()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -330,6 +330,7 @@ image, healthDelay, healthTimeout, metricsCmJson, configurationJson, emptyMap())
                                     .withLabels(podLabels)
                                     .withAnnotations(podAnots)
                                 .endMetadata()
+                                .withNewPriorityClassName("top-priority")
                             .endPod()
                             .withNewClientService()
                                 .withNewMetadata()
@@ -359,6 +360,7 @@ image, healthDelay, healthTimeout, metricsCmJson, configurationJson, emptyMap())
         StatefulSet ss = zc.generateStatefulSet(true, null, null);
         assertTrue(ss.getMetadata().getLabels().entrySet().containsAll(ssLabels.entrySet()));
         assertTrue(ss.getMetadata().getAnnotations().entrySet().containsAll(ssAnots.entrySet()));
+        assertEquals("top-priority", ss.getSpec().getTemplate().getSpec().getPriorityClassName());
 
         // Check Pods
         assertTrue(ss.getSpec().getTemplate().getMetadata().getLabels().entrySet().containsAll(podLabels.entrySet()));

File: systemtest/src/main/java/io/strimzi/systemtest/MessagingBaseST.java
Patch:
@@ -158,8 +158,8 @@ int receiveMessages(int messageCount, long timeout, String clusterName, boolean
 
         received = getReceivedMessagesCount(response);
 
-        assertThat(String.format("Received (%s) and expected (%s) message count is not equal", sent, messageCount),
-                sent == messageCount);
+        assertThat(String.format("Received (%s) and expected (%s) message count is not equal", received, messageCount),
+                received == messageCount);
 
         LOGGER.info("Received {} messages", received);
         return received;

File: systemtest/src/main/java/io/strimzi/systemtest/clients/lib/Producer.java
Patch:
@@ -51,7 +51,7 @@ private void sendNext(KafkaProducer<String, String> producer, String topic) {
         if (msgCntPredicate.negate().test(numSent.get())) {
 
             KafkaProducerRecord<String, String> record =
-                    KafkaProducerRecord.create(topic, "message_" + numSent.get());
+                    KafkaProducerRecord.create(topic, String.valueOf(numSent.get()));
 
             producer.send(record, done -> {
                 if (done.succeeded()) {

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -421,14 +421,15 @@ public static <T> T doRequestTillSuccess(int retry, Callable<T> fn, Optional<Run
                     reconnect.get().run();
                 }
             }
-            if (ex.getCause() instanceof UnknownHostException && retry > 0) {
+            if ((ex.getCause() instanceof UnknownHostException || ex.getCause() instanceof IllegalStateException) && retry > 0) {
                 try {
                     LOGGER.info("{} remaining iterations", retry);
                     return doRequestTillSuccess(retry - 1, fn, reconnect);
                 } catch (Exception ex2) {
                     throw ex2;
                 }
             } else {
+                LOGGER.info(ex.getClass().getName());
                 if (ex.getCause() != null) {
                     ex.getCause().printStackTrace();
                 } else {

File: api/src/main/java/io/strimzi/api/kafka/Crds.java
Patch:
@@ -43,6 +43,7 @@ public class Crds {
 
     public static final String CRD_KIND = "CustomResourceDefinition";
 
+    @SuppressWarnings("unchecked")
     private static final Class<? extends CustomResource>[] CRDS = new Class[] {
         Kafka.class,
         KafkaConnect.class,
@@ -281,6 +282,7 @@ public static <T extends CustomResource> String kind(Class<T> cls) {
         }
     }
 
+    @SuppressWarnings("unchecked")
     public static <T extends CustomResource> List<String> apiVersions(Class<T> cls) {
         try {
             String group = (String) cls.getField("RESOURCE_GROUP").get(null);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -103,7 +103,7 @@ private static Set<String> parseNamespaceList(String namespacesList)   {
             if (namespacesList.trim().equals(AbstractWatchableResourceOperator.ANY_NAMESPACE)) {
                 namespaces = Collections.singleton(AbstractWatchableResourceOperator.ANY_NAMESPACE);
             } else if (namespacesList.matches("(\\s*[a-z0-9.-]+\\s*,)*\\s*[a-z0-9.-]+\\s*")) {
-                namespaces = new HashSet(asList(namespacesList.trim().split("\\s*,+\\s*")));
+                namespaces = new HashSet<>(asList(namespacesList.trim().split("\\s*,+\\s*")));
             } else {
                 throw new InvalidConfigurationException(ClusterOperatorConfig.STRIMZI_NAMESPACE
                         + " is not a valid list of namespaces nor the 'any namespace' wildcard "

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -118,7 +118,7 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
                         log.error("Cluster Operator verticle in namespace {} failed to start", namespace, res.cause());
                         System.exit(1);
                     }
-                    fut.completer().handle(res);
+                    fut.handle(res);
                 });
         }
         return CompositeFuture.join(futures);
@@ -156,7 +156,7 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, PlatformFeature
 
             }
 
-            Future returnFuture = Future.future();
+            Future<Void> returnFuture = Future.future();
             CompositeFuture.all(futures).setHandler(res -> {
                 if (res.succeeded())    {
                     returnFuture.complete();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -409,7 +409,7 @@ public ConfigMap generateMetricsAndLogConfigMap(ConfigMap cm) {
         Map<String, String> data = new HashMap<>();
         data.put(getAncillaryConfigMapKeyLogConfig(), parseLogging(getLogging(), cm));
         if (isMetricsEnabled()) {
-            HashMap m = new HashMap();
+            HashMap<String, Object> m = new HashMap<>();
             for (Map.Entry<String, Object> entry : getMetricsConfig()) {
                 m.put(entry.getKey(), entry.getValue());
             }
@@ -1131,6 +1131,7 @@ public static String clusterCaKeySecretName(String cluster)  {
         return KafkaResources.clusterCaKeySecretName(cluster);
     }
 
+    @SafeVarargs
     protected static Map<String, String> mergeAnnotations(Map<String, String> internal, Map<String, String>... templates) {
         Map<String, String> merged = new HashMap<>();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -76,6 +76,7 @@ public String toString() {
         return "cluster-ca";
     }
 
+    @SuppressWarnings("deprecation")
     public void initCaSecrets(List<Secret> secrets) {
         for (Secret secret: secrets) {
             String name = secret.getMetadata().getName();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -173,6 +173,7 @@ public static EntityOperator fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup ve
         return result;
     }
 
+    @SuppressWarnings("deprecation")
     static List<Toleration> tolerations(EntityOperatorSpec entityOperatorSpec) {
         if (entityOperatorSpec.getTemplate() != null
                 && entityOperatorSpec.getTemplate().getPod() != null
@@ -186,6 +187,7 @@ static List<Toleration> tolerations(EntityOperatorSpec entityOperatorSpec) {
         }
     }
 
+    @SuppressWarnings("deprecation")
     static Affinity affinity(EntityOperatorSpec entityOperatorSpec) {
         if (entityOperatorSpec.getTemplate() != null
                 && entityOperatorSpec.getTemplate().getPod() != null

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -481,6 +481,7 @@ public static KafkaCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup vers
         return result;
     }
 
+    @SuppressWarnings("deprecation")
     static List<Toleration> tolerations(KafkaClusterSpec kafkaClusterSpec) {
         if (kafkaClusterSpec.getTemplate() != null
                 && kafkaClusterSpec.getTemplate().getPod() != null
@@ -494,6 +495,7 @@ static List<Toleration> tolerations(KafkaClusterSpec kafkaClusterSpec) {
         }
     }
 
+    @SuppressWarnings("deprecation")
     static Affinity affinity(KafkaClusterSpec kafkaClusterSpec) {
         if (kafkaClusterSpec.getTemplate() != null
                 && kafkaClusterSpec.getTemplate().getPod() != null

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -231,6 +231,7 @@ public static KafkaMirrorMakerCluster fromCrd(KafkaMirrorMaker kafkaMirrorMaker,
         return kafkaMirrorMakerCluster;
     }
 
+    @SuppressWarnings("deprecation")
     static List<Toleration> tolerations(KafkaMirrorMakerSpec spec) {
         if (spec.getTemplate() != null
                 && spec.getTemplate().getPod() != null
@@ -244,6 +245,7 @@ static List<Toleration> tolerations(KafkaMirrorMakerSpec spec) {
         }
     }
 
+    @SuppressWarnings("deprecation")
     static Affinity affinity(KafkaMirrorMakerSpec spec) {
         if (spec.getTemplate() != null
                 && spec.getTemplate().getPod() != null

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -271,6 +271,7 @@ public static ZookeeperCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup
         return zk;
     }
 
+    @SuppressWarnings("deprecation")
     static List<Toleration> tolerations(ZookeeperClusterSpec zookeeperClusterSpec) {
         if (zookeeperClusterSpec.getTemplate() != null
                 && zookeeperClusterSpec.getTemplate().getPod() != null
@@ -284,6 +285,7 @@ static List<Toleration> tolerations(ZookeeperClusterSpec zookeeperClusterSpec) {
         }
     }
 
+    @SuppressWarnings("deprecation")
     static Affinity affinity(ZookeeperClusterSpec zookeeperClusterSpec) {
         if (zookeeperClusterSpec.getTemplate() != null
                 && zookeeperClusterSpec.getTemplate().getPod() != null

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -304,7 +304,7 @@ public void onClose(KubernetesClientException e) {
                     }
                 });
                 future.complete(watch);
-            }, result.completer()
+            }, result
         );
         return result;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -79,7 +79,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaBridge
                 configMapOperations.get(namespace, ((ExternalLogging) bridge.getLogging()).getName()) :
                 null);
 
-        Map<String, String> annotations = new HashMap();
+        Map<String, String> annotations = new HashMap<>();
         annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(bridge.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Bridge cluster", reconciliation, name, namespace);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -79,7 +79,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
                 configMapOperations.get(namespace, ((ExternalLogging) connect.getLogging()).getName()) :
                 null);
 
-        Map<String, String> annotations = new HashMap();
+        Map<String, String> annotations = new HashMap<>();
         annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Connect cluster", reconciliation, name, namespace);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -88,7 +88,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
                     configMapOperations.get(namespace, ((ExternalLogging) connect.getLogging()).getName()) :
                     null);
 
-            HashMap<String, String> annotations = new HashMap();
+            HashMap<String, String> annotations = new HashMap<>();
             annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
 
             return connectServiceAccount(namespace, connect)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -80,7 +80,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                 configMapOperations.get(namespace, ((ExternalLogging) mirror.getLogging()).getName()) :
                 null);
 
-        Map<String, String> annotations = new HashMap();
+        Map<String, String> annotations = new HashMap<>();
         annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(mirror.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Mirror Maker cluster", reconciliation, name, namespace);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperator.java
Patch:
@@ -128,7 +128,7 @@ public Future<Void> maybeRollingUpdate(StatefulSet ss, Predicate<Pod> podRestart
                         return maybeRestartPod(ss, KafkaResources.zookeeperPodName(cluster, leader), podRestart);
                     });
                 }
-            }).setHandler(rollFuture.completer());
+            }).setHandler(rollFuture);
         } else {
             rollFuture = Future.succeededFuture();
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -268,7 +268,7 @@ private KafkaAssemblyOperator createCluster(TestContext context) {
             context.assertEquals("0", zkSs.getSpec().getTemplate().getMetadata().getAnnotations().get(StatefulSetOperator.ANNO_STRIMZI_IO_GENERATION));
             context.assertEquals("0", zkSs.getSpec().getTemplate().getMetadata().getAnnotations().get(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION));
             context.assertNotNull(zkSs);
-            context.assertNotNull(mockClient.extensions().deployments().inNamespace(NAMESPACE).withName(TopicOperator.topicOperatorName(CLUSTER_NAME)).get());
+            context.assertNotNull(mockClient.apps().deployments().inNamespace(NAMESPACE).withName(TopicOperator.topicOperatorName(CLUSTER_NAME)).get());
             context.assertNotNull(mockClient.configMaps().inNamespace(NAMESPACE).withName(KafkaCluster.metricAndLogConfigsName(CLUSTER_NAME)).get());
             context.assertNotNull(mockClient.configMaps().inNamespace(NAMESPACE).withName(ZookeeperCluster.zookeeperMetricAndLogConfigsName(CLUSTER_NAME)).get());
             assertResourceRequirements(context, KafkaCluster.kafkaClusterName(CLUSTER_NAME));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -97,7 +97,7 @@ private KafkaConnectAssemblyOperator createConnectCluster(TestContext context) {
         kco.reconcileAssembly(new Reconciliation("test-trigger", ResourceType.CONNECT, NAMESPACE, CLUSTER_NAME), ar -> {
             if (ar.failed()) ar.cause().printStackTrace();
             context.assertTrue(ar.succeeded());
-            context.assertNotNull(mockClient.extensions().deployments().inNamespace(NAMESPACE).withName(KafkaConnectCluster.kafkaConnectClusterName(CLUSTER_NAME)).get());
+            context.assertNotNull(mockClient.apps().deployments().inNamespace(NAMESPACE).withName(KafkaConnectCluster.kafkaConnectClusterName(CLUSTER_NAME)).get());
             context.assertNotNull(mockClient.configMaps().inNamespace(NAMESPACE).withName(KafkaConnectCluster.logAndMetricsConfigName(CLUSTER_NAME)).get());
             context.assertNotNull(mockClient.services().inNamespace(NAMESPACE).withName(KafkaConnectCluster.serviceName(CLUSTER_NAME)).get());
             context.assertNotNull(mockClient.policy().podDisruptionBudget().inNamespace(NAMESPACE).withName(KafkaConnectCluster.kafkaConnectClusterName(CLUSTER_NAME)).get());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaStatusTest.java
Patch:
@@ -319,6 +319,7 @@ public MockWorkingKafkaAssemblyOperator(Vertx vertx, PlatformFeaturesAvailabilit
             super(vertx, pfa, certManager, supplier, config);
         }
 
+        @Override
         Future<Void> reconcile(ReconciliationState reconcileState)  {
             ListenerStatus ls = new ListenerStatusBuilder()
                     .withNewType("plain")
@@ -355,6 +356,7 @@ public MockFailingKafkaAssemblyOperator(Throwable exception, Vertx vertx, Platfo
             this.exception = exception;
         }
 
+        @Override
         Future<Void> reconcile(ReconciliationState reconcileState)  {
             ListenerStatus ls = new ListenerStatusBuilder()
                     .withNewType("plain")

File: crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java
Patch:
@@ -480,6 +480,7 @@ private ObjectNode buildBasicTypeSchema(AnnotatedElement element, Class type) {
         return result;
     }
 
+    @SuppressWarnings("unchecked")
     private ObjectNode addSimpleTypeConstraints(ObjectNode result, Property property) {
 
         Example example = property.getAnnotation(Example.class);
@@ -559,6 +560,7 @@ ArrayNode stringArray(Iterable<String> list) {
         return arrayNode;
     }
 
+    @SuppressWarnings("unchecked")
     public static void main(String[] args) throws IOException, ClassNotFoundException {
         boolean yaml = false;
         Map<String, String> labels = new LinkedHashMap<>();

File: crd-generator/src/main/java/io/strimzi/crdgenerator/DocGenerator.java
Patch:
@@ -413,6 +413,7 @@ public static void main(String[] args) throws IOException, ClassNotFoundExceptio
         }
     }
 
+    @SuppressWarnings("unchecked")
     static <T> Class<? extends T> classInherits(Class<?> cls, Class<T> test) {
         if (test.isAssignableFrom(cls)) {
             return (Class<? extends T>) cls;

File: operator-common/src/main/java/io/strimzi/operator/PlatformFeaturesAvailability.java
Patch:
@@ -76,7 +76,7 @@ private static Future<VersionInfo> getVersionInfo(Vertx vertx, KubernetesClient
                 log.error("Detection of Kuberetes version failed.", e);
                 request.fail(e);
             }
-        }, fut.completer());
+        }, fut);
 
         return fut;
     }
@@ -103,7 +103,7 @@ private static Future<Boolean> checkApiAvailability(Vertx vertx, OkHttpClient ht
                 log.error("Detection of {}/{} API failed. This API will be disabled.", api, version, e);
                 request.complete(false);
             }
-        }, fut.completer());
+        }, fut);
 
         return fut;
     }

File: operator-common/src/main/java/io/strimzi/operator/common/model/Labels.java
Patch:
@@ -152,7 +152,7 @@ public static Labels fromString(String stringLabels) throws IllegalArgumentExcep
     }
 
     private Labels(Map<String, String> labels) {
-        this.labels = unmodifiableMap(new HashMap(labels));
+        this.labels = unmodifiableMap(new HashMap<>(labels));
     }
 
     private Labels with(String label, String value) {

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractScalableResourceOperator.java
Patch:
@@ -83,7 +83,7 @@ public Future<Integer> scaleUp(String namespace, String name, int scaleTo) {
                 }
             },
             false,
-            fut.completer()
+            fut
         );
         return fut;
     }
@@ -121,7 +121,7 @@ public Future<Integer> scaleDown(String namespace, String name, int scaleTo) {
                 }
             },
             false,
-            fut.completer()
+            fut
         );
         return fut;
     }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -111,7 +111,7 @@ public Future<Void> updateStatusAsync(T resource) {
                 log.debug("Updating status failed", e);
                 future.fail(e);
             }
-        }, true, blockingFuture.completer());
+        }, true, blockingFuture);
 
         return blockingFuture;
     }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/DeploymentOperator.java
Patch:
@@ -39,7 +39,7 @@ public DeploymentOperator(Vertx vertx, KubernetesClient client, PodOperator podO
 
     @Override
     protected MixedOperation<Deployment, DeploymentList, DoneableDeployment, RollableScalableResource<Deployment, DoneableDeployment>> operation() {
-        return client.extensions().deployments();
+        return client.apps().deployments();
     }
 
     @Override

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/NetworkPolicyOperator.java
Patch:
@@ -18,8 +18,9 @@ public NetworkPolicyOperator(Vertx vertx, KubernetesClient client) {
         super(vertx, client, "NetworkPolicy");
 
     }
+
     @Override
     protected MixedOperation<NetworkPolicy, NetworkPolicyList, DoneableNetworkPolicy, Resource<NetworkPolicy, DoneableNetworkPolicy>> operation() {
-        return client.extensions().networkPolicies();
+        return client.network().networkPolicies();
     }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ResourceSupport.java
Patch:
@@ -34,8 +34,8 @@ public class ResourceSupport {
      * @param closeable The closeable
      * @return The Future
      */
-    public Future closeOnWorkerThread(Closeable closeable) {
-        Future result = Future.future();
+    public Future<Void> closeOnWorkerThread(Closeable closeable) {
+        Future<Void> result = Future.future();
         vertx.executeBlocking(
             blockingFuture -> {
                 try {

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/DeploymentOperatorTest.java
Patch:
@@ -9,7 +9,7 @@
 import io.fabric8.kubernetes.api.model.apps.DeploymentList;
 import io.fabric8.kubernetes.api.model.apps.DoneableDeployment;
 import io.fabric8.kubernetes.client.KubernetesClient;
-import io.fabric8.kubernetes.client.dsl.ExtensionsAPIGroupDSL;
+import io.fabric8.kubernetes.client.dsl.AppsAPIGroupDSL;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.RollableScalableResource;
 import io.vertx.core.Vertx;
@@ -38,9 +38,9 @@ protected Deployment resource() {
 
     @Override
     protected void mocker(KubernetesClient mockClient, MixedOperation op) {
-        ExtensionsAPIGroupDSL mockExt = mock(ExtensionsAPIGroupDSL.class);
+        AppsAPIGroupDSL mockExt = mock(AppsAPIGroupDSL.class);
         when(mockExt.deployments()).thenReturn(op);
-        when(mockClient.extensions()).thenReturn(mockExt);
+        when(mockClient.apps()).thenReturn(mockExt);
 
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -249,6 +249,7 @@ void waitForZkMntr(Pattern pattern, int... podIndexes) {
      * @param keyValuePairs Pairs in key=value format; pairs are separated by newlines
      * @return THe map of key/values
      */
+    @SuppressWarnings("unchecked")
     static Map<String, String> loadProperties(String keyValuePairs) {
         try {
             Properties actual = new Properties();

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -99,6 +99,7 @@ public class Resources extends AbstractResources {
         super(client);
     }
 
+    @SuppressWarnings("unchecked")
     private <T extends HasMetadata> T deleteLater(MixedOperation<T, ?, ?, ?> x, T resource) {
         LOGGER.info("Scheduled deletion of {} {}", resource.getKind(), resource.getMetadata().getName());
         switch (resource.getKind()) {

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/HasNoneOfReasons.java
Patch:
@@ -41,6 +41,7 @@ private Stream<Event> filtered(List<Event> actualValue) {
     }
 
     @Override
+    @SuppressWarnings("unchecked")
     public void describeMismatch(Object item, Description description) {
         describeTo(description);
         description.appendValueList(" but actual event reasons were {", ", ", "}.",

File: test-client/src/main/java/io/strimzi/test_client/HttpClientsListener.java
Patch:
@@ -93,6 +93,7 @@ private void getHandler(HttpServerRequest request) {
         });
     }
 
+    @SuppressWarnings("unchecked")
     private void postHandler(HttpServerRequest request) {
         request.bodyHandler(handler -> {
             JsonObject json = handler.toJsonObject();

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -79,6 +79,7 @@ private TestUtils() {
     }
 
     /** Returns a Map of the given sequence of key, value pairs. */
+    @SafeVarargs
     public static <T> Map<T, T> map(T... pairs) {
         if (pairs.length % 2 != 0) {
             throw new IllegalArgumentException();
@@ -217,9 +218,9 @@ public static void assertResourceMatch(Class<?> cls, String resourceName, String
         assertEquals(r, actual);
     }
 
-
+    @SafeVarargs
     public static <T> Set<T> set(T... elements) {
-        return new HashSet(asList(elements));
+        return new HashSet<>(asList(elements));
     }
 
     public static <T> T fromYaml(String resource, Class<T> c) {

File: test/src/main/java/io/strimzi/test/k8s/HelmClient.java
Patch:
@@ -7,9 +7,9 @@
 import java.nio.file.Path;
 import java.util.Map;
 
-public interface HelmClient<H extends HelmClient<H>> {
+public interface HelmClient {
     static HelmClient findClient(KubeCmdClient<?> kubeClient) {
-        HelmClient client = new Helm(kubeClient);
+        HelmClient client = new Helm(kubeClient.namespace());
         if (!client.clientAvailable()) {
             throw new RuntimeException("No helm client found on $PATH. $PATH=" + System.getenv("PATH"));
         }

File: topic-operator/src/main/java/io/strimzi/operator/topic/Labels.java
Patch:
@@ -103,7 +103,7 @@ private static void checkLabelKey(String key) {
      */
     public static Labels fromString(String string) throws IllegalArgumentException {
         if (string == null || string.equals("")) {
-            return new Labels(Collections.EMPTY_MAP);
+            return new Labels(Collections.emptyMap());
         }
         Matcher m = COMMA_SPLITTER.matcher(string);
         int lastEnd = 0;

File: topic-operator/src/main/java/io/strimzi/operator/topic/OperatorAssignedKafkaImpl.java
Patch:
@@ -104,7 +104,7 @@ public void changeReplicationFactor(Topic topic, Handler<AsyncResult<Void>> hand
                 fut.fail(e);
             }
         },
-            generateFuture.completer());
+            generateFuture);
 
         Future<File> executeFuture = Future.future();
 
@@ -120,7 +120,7 @@ public void changeReplicationFactor(Topic topic, Handler<AsyncResult<Void>> hand
                     fut.fail(e);
                 }
             },
-                executeFuture.completer());
+                executeFuture);
         }, executeFuture);
 
         Future<Void> periodicFuture = Future.future();

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -22,8 +22,8 @@
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
+import java.time.Duration;
 import java.util.Properties;
-import java.util.concurrent.TimeUnit;
 
 public class Session extends AbstractVerticle {
 
@@ -77,7 +77,7 @@ public void stop(Future<Void> stopFuture) throws Exception {
             LOGGER.debug("Stopping zk watches");
             topicsWatcher.stop();
 
-            Future f = Future.future();
+            Future<Void> f = Future.future();
             Handler<Long> longHandler = new Handler<Long>() {
                 @Override
                 public void handle(Long inflightTimerId) {
@@ -106,7 +106,7 @@ public void handle(Long inflightTimerId) {
                     long timeoutMs = Math.max(1, deadline - System.currentTimeMillis());
                     LOGGER.debug("Closing AdminClient {} with timeout {}ms", adminClient, timeoutMs);
                     try {
-                        adminClient.close(timeoutMs, TimeUnit.MILLISECONDS);
+                        adminClient.close(Duration.ofMillis(timeoutMs));
                         HttpServer healthServer = this.healthServer;
                         if (healthServer != null) {
                             healthServer.close();

File: user-operator/src/main/java/io/strimzi/operator/user/Main.java
Patch:
@@ -78,15 +78,15 @@ static Future<String> run(Vertx vertx, KubernetesClient client, SimpleAclAuthori
                     log.error("User Operator verticle in namespace {} failed to start", config.getNamespace(), res.cause());
                     System.exit(1);
                 }
-                fut.completer().handle(res);
+                fut.handle(res);
             });
 
         return fut;
     }
 
     private static SimpleAclAuthorizer createSimpleAclAuthorizer(UserOperatorConfig config) {
         log.debug("Creating SimpleAclAuthorizer for Zookeeper {}", config.getZookeperConnect());
-        Map authorizerConfig = new HashMap<String, Object>();
+        Map<String, Object> authorizerConfig = new HashMap<>();
         // The SimpleAclAuthorizer from KAfka requires the Zookeeper URL to be provided twice.
         // See the comments in the SimpleAclAuthorizer.scala class for more details
         authorizerConfig.put(SimpleAclAuthorizer.ZkUrlProp(), config.getZookeperConnect());

File: user-operator/src/main/java/io/strimzi/operator/user/operator/ScramShaCredentialsOperator.java
Patch:
@@ -39,7 +39,7 @@ Future<ReconcileResult<Void>> reconcile(String username, String password) {
                 }
             },
             false,
-            fut.completer());
+            fut);
         return fut;
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -992,7 +992,7 @@ public void testGenerateBrokerSecretExternalWithManyDNS() throws CertificatePars
 
     private Secret generateBrokerSecret(Set<String> externalBootstrapAddress, Map<Integer, Set<String>> externalAddresses) {
         ClusterCa clusterCa = new ClusterCa(new OpenSslCertManager(), cluster, null, null);
-        clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), null);
+        clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), null, true);
 
         kc.generateCertificates(kafkaAssembly, clusterCa, externalBootstrapAddress, externalAddresses);
         return kc.generateBrokersSecret();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -277,7 +277,7 @@ public void checkOwnerReference(OwnerReference ownerRef, HasMetadata resource)
     @Test
     public void testGenerateBrokerSecret() throws CertificateParsingException {
         ClusterCa clusterCa = new ClusterCa(new OpenSslCertManager(), cluster, null, null);
-        clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), null);
+        clusterCa.createRenewOrReplace(namespace, cluster, emptyMap(), null, true);
 
         Secret secret = zc.generateNodesSecret(clusterCa, ka);
         assertEquals(set(

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -906,7 +906,7 @@ private PodSpec createClientSpec(boolean tlsListener, KafkaUser... kafkaUsers) {
         PodSpecBuilder podSpecBuilder = new PodSpecBuilder();
         ContainerBuilder containerBuilder = new ContainerBuilder()
                 .withName(Constants.KAFKA_CLIENTS)
-                .withImage(StUtils.changeTestClientOrgAndTag("strimzi/test-client:latest-kafka-" + KAFKA_VERSION))
+                .withImage(Environment.TEST_CLIENT_IMAGE)
                 .addNewPort()
                     .withContainerPort(4242)
                 .endPort()

File: certificate-manager/src/main/java/io/strimzi/certs/SecretCertProvider.java
Patch:
@@ -40,7 +40,7 @@ public class SecretCertProvider {
      * @param annotations annotations to add to the Secret
      * @param ownerReference owner of the Secret
      * @return the Secret
-     * @throws IOException
+     * @throws IOException If a file could not be read.
      */
     public Secret createSecret(String namespace, String name, File keyFile, File certFile, Map<String, String> labels, Map<String, String> annotations, OwnerReference ownerReference) throws IOException {
         return createSecret(namespace, name, DEFAULT_KEY_KEY, DEFAULT_KEY_CERT, keyFile, certFile, labels, annotations, ownerReference);
@@ -59,7 +59,7 @@ public Secret createSecret(String namespace, String name, File keyFile, File cer
      * @param annotations annotations to add to the Secret
      * @param ownerReference owner of the Secret
      * @return the Secret
-     * @throws IOException
+     * @throws IOException If a file could not be read.
      */
     public Secret createSecret(String namespace, String name, String keyKey, String certKey, File keyFile, File certFile, Map<String, String> labels, Map<String, String> annotations, OwnerReference ownerReference) throws IOException {
         byte[] key = Files.readAllBytes(keyFile.toPath());
@@ -149,7 +149,7 @@ public Secret addSecret(Secret secret, String keyKey, String certKey, byte[] key
      * @param keyFile private key to store
      * @param certFile certificate to store
      * @return the Secret
-     * @throws IOException
+     * @throws IOException If a file could not be read.
      */
     public Secret addSecret(Secret secret, String keyKey, String certKey, File keyFile, File certFile) throws IOException {
         byte[] key = Files.readAllBytes(keyFile.toPath());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -57,6 +57,8 @@ public ClusterCa(CertManager certManager,
      * In Strimzi 0.6.0 the Secrets and keys used a different convention.
      * Here we adapt the keys in the {@code *-cluster-ca} Secret to match what
      * 0.7.0 expects.
+     * @param clusterCaKey The cluster CA key Secret
+     * @return The same Secret.
      */
     public static Secret adapt060ClusterCaSecret(Secret clusterCaKey) {
         if (clusterCaKey != null && clusterCaKey.getData() != null) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -166,6 +166,8 @@ public static String metricAndLogConfigsName(String cluster) {
 
     /**
      * Get the name of the TO role binding given the name of the {@code cluster}.
+     * @param cluster The cluster name.
+     * @return The name of the role binding.
      */
     public static String roleBindingName(String cluster) {
         return "strimzi-" + cluster + "-entity-topic-operator";

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -153,6 +153,8 @@ public static String metricAndLogConfigsName(String cluster) {
 
     /**
      * Get the name of the UO role binding given the name of the {@code cluster}.
+     * @param cluster The cluster name.
+     * @return The name of the role binding.
      */
     public static String roleBindingName(String cluster) {
         return "strimzi-" + cluster + "-entity-user-operator";

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaBridgeCluster.java
Patch:
@@ -474,7 +474,7 @@ protected void setSaslMechanism(String saslMechanism) {
     /**
      * Generates the PodDisruptionBudget
      *
-     * @return
+     * @return The pod disruption budget.
      */
     public PodDisruptionBudget generatePodDisruptionBudget() {
         return createPodDisruptionBudget();
@@ -487,6 +487,8 @@ protected String getServiceAccountName() {
 
     /**
      * Get the name of the bridge service account given the name of the {@code bridgeResourceName}.
+     * @param bridgeResourceName  The name of the bridge resource
+     * @return The name of the service account.
      */
     public static String containerServiceAccountName(String bridgeResourceName) {
         return kafkaBridgeClusterName(bridgeResourceName);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -606,7 +606,7 @@ protected void setSaslMechanism(String saslMechanism) {
     /**
      * Generates the PodDisruptionBudget
      *
-     * @return
+     * @return The PodDisruptionBudget.
      */
     public PodDisruptionBudget generatePodDisruptionBudget() {
         return createPodDisruptionBudget();
@@ -619,6 +619,8 @@ protected String getServiceAccountName() {
 
     /**
      * Get the name of the connect service account given the name of the {@code connectResourceName}.
+     * @param connectResourceName  The resource name.
+     * @return The service account name.
      */
     public static String containerServiceAccountName(String connectResourceName) {
         return kafkaConnectClusterName(connectResourceName);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/OrderedProperties.java
Patch:
@@ -101,6 +101,7 @@ public OrderedProperties addStringPairs(String keyValuePairs) {
      * @param is The UTF-8 input stream containing name=value pairs separated by newlines.
      *
      * @return this instance for chaining
+     * @throws IOException If the input stream could not be read.
      */
     public OrderedProperties addStringPairs(InputStream is) throws IOException {
         new PropertiesReader(pairs).read(is);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/StatusDiff.java
Patch:
@@ -55,6 +55,7 @@ public StatusDiff(Status current, Status desired) {
      *
      * @return true when the storage configurations are the same
      */
+    @Override
     public boolean isEmpty() {
         return isEmpty;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/StorageDiff.java
Patch:
@@ -114,6 +114,7 @@ public StorageDiff(Storage current, Storage desired, String volumeDesc) {
      *
      * @return true when the storage configurations are the same
      */
+    @Override
     public boolean isEmpty() {
         return isEmpty;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/AbstractResourceDiff.java
Patch:
@@ -25,9 +25,9 @@ protected JsonNode lookupPath(JsonNode source, String path) {
     }
 
     /**
-     * Returns whether the Diff is empty or not
+     * Returns whether the Diff is empty or not.
      *
-     * @return
+     * @return whether the Diff is empty or not.
      */
     public abstract boolean isEmpty();
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperator.java
Patch:
@@ -21,6 +21,7 @@ public class KafkaSetOperator extends StatefulSetOperator {
      *
      * @param vertx  The Vertx instance
      * @param client The Kubernetes client
+     * @param operationTimeoutMs The timeout.
      */
     public KafkaSetOperator(Vertx vertx, KubernetesClient client, long operationTimeoutMs) {
         super(vertx, client, operationTimeoutMs);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperator.java
Patch:
@@ -33,6 +33,8 @@ public class ZookeeperSetOperator extends StatefulSetOperator {
      *
      * @param vertx  The Vertx instance
      * @param client The Kubernetes client
+     * @param leaderFinder The Zookeeper leader finder.
+     * @param operationTimeoutMs The timeout.
      */
     public ZookeeperSetOperator(Vertx vertx, KubernetesClient client, ZookeeperLeaderFinder leaderFinder, long operationTimeoutMs) {
         super(vertx, client, operationTimeoutMs);

File: crd-annotations/src/main/java/io/strimzi/api/annotations/DeprecatedProperty.java
Patch:
@@ -13,17 +13,17 @@
 @Retention(RetentionPolicy.RUNTIME)
 public @interface DeprecatedProperty {
 
-    /** The API version in which this property is scheduled to be removed. */
+    /** @return The API version in which this property is scheduled to be removed. */
     String removalVersion() default "";
 
     /**
-     * If this property has moved to a different location in the Custom Resource this is
+     * @return If this property has moved to a different location in the Custom Resource this is
      * the path it has moved to.
      */
     String movedToPath() default "";
 
     /**
-     * If this property has <strong>not</strong> moved to a different location in the Custom Resource this is
+     * @return If this property has <strong>not</strong> moved to a different location in the Custom Resource this is
      * a description of how the functionality can now be configured.
      */
     String description() default "";

File: kafka-agent/src/main/java/io/strimzi/kafka/agent/KafkaAgent.java
Patch:
@@ -150,6 +150,7 @@ private void touch(File file) throws IOException {
 
     /**
      * Agent entry point
+     * @param agentArgs The agent arguments
      */
     public static void premain(String agentArgs) {
         int index = agentArgs.indexOf(':');

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/ClientsCa.java
Patch:
@@ -22,6 +22,8 @@ caSecretKeyName, adapt060ClientsCaSecret(clientsCaKey),
      * In Strimzi 0.6.0 the Secrets and keys used a different convention.
      * Here we adapt the keys in the {@code *-clients-ca} Secret to match what
      * 0.7.0 expects.
+     * @param clientsCaKey The secret to adapt.
+     * @return The same Secret instance.
      */
     public static Secret adapt060ClientsCaSecret(Secret clientsCaKey) {
         if (clientsCaKey != null && clientsCaKey.getData() != null) {

File: operator-common/src/main/java/io/strimzi/operator/common/model/ResourceVisitor.java
Patch:
@@ -55,6 +55,7 @@ default void visitFieldProperty(List<String> path, Object owner,
          * @param member The getter method or field for the property.
          * @param property abstraction for using the method.
          * @param propertyValue The value of the property.
+         * @param <M> The type of member ({@code Field} or {@code Method}).
          */
         <M extends AnnotatedElement & Member> void visitProperty(List<String> path, Object owner,
                                         M member, Property<M> property, Object propertyValue);

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractReadyResourceOperator.java
Patch:
@@ -49,6 +49,7 @@ public Future<Void> readiness(String namespace, String name, long pollIntervalMs
      *
      * @param namespace The namespace.
      * @param name The resource name.
+     * @return Whether the resource in in the Ready state.
      */
     public boolean isReady(String namespace, String name) {
         R resourceOp = operation().inNamespace(namespace).withName(name);

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/CrdOperator.java
Patch:
@@ -37,6 +37,9 @@ public class CrdOperator<C extends KubernetesClient,
      * Constructor
      * @param vertx The Vertx instance
      * @param client The Kubernetes client
+     * @param cls The class of the CR
+     * @param listCls The class of the list.
+     * @param doneableCls The class of the CR's "doneable".
      */
     public CrdOperator(Vertx vertx, C client, Class<T> cls, Class<L> listCls, Class<D> doneableCls) {
         super(vertx, client, Crds.kind(cls));

File: systemtest/src/main/java/io/strimzi/systemtest/clients/api/VerifiableClient.java
Patch:
@@ -40,9 +40,9 @@ public JsonArray getMessages() {
     }
 
     /**
-     * Get all kafka client arguments
+     * Get all kafka client arguments.
      *
-     * @return
+     * @return The kafka client arguments.
      */
     public ArrayList<String> getArguments() {
         return arguments;

File: systemtest/src/main/java/io/strimzi/systemtest/matchers/Matchers.java
Patch:
@@ -18,6 +18,7 @@ private Matchers() {
     /**
      * A matcher checks that examined object has a full match of reasons for actual events.
      * @param eventReasons - expected events for resource
+     * @return The matcher.
      */
     public static Matcher<List<Event>> hasAllOfReasons(Events... eventReasons) {
         return new HasAllOfReasons(eventReasons);
@@ -26,6 +27,7 @@ public static Matcher<List<Event>> hasAllOfReasons(Events... eventReasons) {
     /**
      * A matcher checks that examined object has at least one match of reasons for actual events.
      * @param eventReasons - expected events for resource
+     * @return The matcher.
      */
     public static Matcher<List<Event>> hasAnyOfReasons(Events... eventReasons) {
         return new HasAnyOfReasons(eventReasons);
@@ -42,6 +44,7 @@ public static Matcher<List<Event>> hasNoneOfReasons(Events... eventReasons) {
 
     /**
      * A matcher checks that log doesn't have unexpected errors
+     * @return The matcher.
      */
     public static Matcher<String> logHasNoUnexpectedErrors() {
         return new LogHasNoUnexpectedErrors();

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -408,7 +408,7 @@ public static Map<String, String> parseImageMap(String str) {
      *
      * @param retry count of remaining retries
      * @param fn    request function
-     * @return
+     * @return The result of the successful call to {@code fn}.
      */
     public static <T> T doRequestTillSuccess(int retry, Callable<T> fn, Optional<Runnable> reconnect) throws Exception {
         try {

File: test/src/main/java/io/strimzi/test/k8s/KubeCmdClient.java
Patch:
@@ -97,7 +97,7 @@ default K delete(String... files) {
 
     /**
      * Wait for the deployment with the given {@code name} to
-     * have replicas==readyReplicas && replicas==expected.
+     * have {@code replicas==readyReplicas && replicas==expected}.
      * @param name The deployment name.
      * @param expected Number of expected pods
      * @return This kube client.

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicDiff.java
Patch:
@@ -19,7 +19,7 @@
  *     TopicDiff.diff(topicA, topicB).apply(topicA).equals(topicB)
  * </code></pre>
  */
-public class TopicDiff {
+class TopicDiff {
 
     private final ObjectMeta objectMeta;
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicOperator.java
Patch:
@@ -34,7 +34,7 @@
 import static java.util.Collections.disjoint;
 
 @SuppressWarnings("checkstyle:ClassDataAbstractionCoupling")
-public class TopicOperator {
+class TopicOperator {
 
     private final static Logger LOGGER = LogManager.getLogger(TopicOperator.class);
     private final static Logger EVENT_LOGGER = LogManager.getLogger("Event");

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicSerialization.java
Patch:
@@ -32,7 +32,7 @@
 /**
  * Serialization of a {@link }Topic} to and from various other representations.
  */
-public class TopicSerialization {
+class TopicSerialization {
 
     // These are the keys in the JSON we store in ZK
     public static final String JSON_KEY_TOPIC_NAME = "topic-name";

File: certificate-manager/src/main/java/io/strimzi/certs/CertManager.java
Patch:
@@ -8,7 +8,6 @@
 import java.io.IOException;
 
 public interface CertManager {
-
     /**
      * Generate a self-signed certificate
      *

File: certificate-manager/src/main/java/io/strimzi/certs/OpenSslCertManager.java
Patch:
@@ -28,6 +28,7 @@
  * An OpenSSL based certificates manager
  */
 public class OpenSslCertManager implements CertManager {
+    public static final int MAXIMUM_CN_LENGTH = 64;
 
     private static final Logger log = LogManager.getLogger(OpenSslCertManager.class);
 

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/InvalidResourceException.java
Patch:
@@ -9,7 +9,7 @@ public InvalidResourceException() {
         super();
     }
 
-    protected InvalidResourceException(String s) {
+    public InvalidResourceException(String s) {
         super(s);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/clients/lib/Producer.java
Patch:
@@ -53,7 +53,7 @@ private void sendNext(KafkaProducer<String, String> producer, String topic) {
             KafkaProducerRecord<String, String> record =
                     KafkaProducerRecord.create(topic, "message_" + numSent.get());
 
-            producer.write(record, done -> {
+            producer.send(record, done -> {
                 if (done.succeeded()) {
                     RecordMetadata recordMetadata = done.result();
                     LOGGER.debug("Message " + record.value() + " written on topic=" + recordMetadata.getTopic() +

File: api/src/test/java/io/strimzi/api/kafka/model/AbstractCrdIT.java
Patch:
@@ -18,9 +18,8 @@ public abstract class AbstractCrdIT extends BaseITST {
 
     protected void assumeKube1_11Plus() {
         VersionInfo version = new DefaultKubernetesClient().getVersion();
-        String minor = version.getMinor();
         Assume.assumeTrue("1".equals(version.getMajor())
-                && Integer.parseInt(minor.substring(0, minor.indexOf('+'))) >= 11);
+                && Integer.parseInt(version.getMinor().split("\\D")[0]) >= 11);
     }
 
     protected <T extends CustomResource> void createDelete(Class<T> resourceClass, String resource) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaVersionTest.java
Patch:
@@ -20,8 +20,10 @@ public class KafkaVersionTest {
     @Test
     public void load() {
         KafkaVersion.Lookup loaded = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
-        assertTrue(loaded.supportedVersions().contains("2.0.1"));
+        assertTrue(loaded.supportedVersions().contains("2.1.0"));
         assertTrue(loaded.supportedVersions().contains("2.1.1"));
+        assertTrue(loaded.supportedVersions().contains("2.2.0"));
+        assertTrue(loaded.supportedVersions().contains("2.2.1"));
         assertEquals("2.1.1", loaded.version("2.1.1").version());
         assertEquals("2.1", loaded.version("2.1.1").protocolVersion());
         assertEquals("2.1", loaded.version("2.1.1").messageVersion());

File: systemtest/src/main/java/io/strimzi/systemtest/Environment.java
Patch:
@@ -53,7 +53,7 @@ public class Environment {
     private static final String STRIMZI_TAG_DEFAULT = "latest";
     private static final String STRIMZI_REGISTRY_DEFAULT = "docker.io";
     private static final String TEST_LOG_DIR_DEFAULT = "../systemtest/target/logs/";
-    private static final String ST_KAFKA_VERSION_DEFAULT = "2.2.0";
+    private static final String ST_KAFKA_VERSION_DEFAULT = "2.2.1";
     private static final String STRIMZI_LOG_LEVEL_DEFAULT = "DEBUG";
     static final String KUBERNETES_DOMAIN_DEFAULT = ".nip.io";
     private static final String STRIMZI_FULL_RECONCILIATION_INTERVAL_MS_DEFAULT = "30000";

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -10,6 +10,7 @@
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.certs.OpenSslCertManager;
 import io.strimzi.operator.cluster.operator.assembly.KafkaBridgeAssemblyOperator;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.operator.assembly.KafkaAssemblyOperator;
 import io.strimzi.operator.cluster.operator.assembly.KafkaConnectAssemblyOperator;
 import io.strimzi.operator.cluster.operator.assembly.KafkaConnectS2IAssemblyOperator;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -18,7 +18,7 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.fabric8.zjsonpatch.JsonDiff;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.model.ResourceVisitor;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperator.java
Patch:
@@ -14,7 +14,7 @@
 import io.strimzi.api.kafka.model.KafkaBridge;
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.model.KafkaBridgeCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -14,7 +14,7 @@
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Annotations;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -14,7 +14,7 @@
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
 import io.strimzi.operator.cluster.model.KafkaConnectS2ICluster;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -14,7 +14,7 @@
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.model.KafkaMirrorMakerCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ResourceOperatorSupplier.java
Patch:
@@ -20,7 +20,7 @@
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.common.BackOff;
 import io.strimzi.operator.common.operator.resource.BuildConfigOperator;
 import io.strimzi.operator.common.operator.resource.ClusterRoleBindingOperator;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
Patch:
@@ -17,7 +17,8 @@
 import io.fabric8.openshift.client.OpenShiftClient;
 import io.strimzi.api.kafka.Crds;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.vertx.core.Vertx;
 import io.vertx.ext.unit.Async;
 import io.vertx.ext.unit.TestContext;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -13,13 +13,13 @@
 import io.strimzi.certs.CertAndKey;
 import io.strimzi.certs.OpenSslCertManager;
 import io.strimzi.certs.Subject;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.Ca;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.ModelUtils;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.InvalidConfigurationException;
 import io.strimzi.operator.common.Reconciliation;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -16,13 +16,13 @@
 import io.strimzi.api.kafka.model.storage.PersistentClaimStorage;
 import io.strimzi.api.kafka.model.storage.PersistentClaimStorageBuilder;
 import io.strimzi.api.kafka.model.storage.SingleVolumeStorage;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.model.ModelUtils;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaBridgeAssemblyOperatorTest.java
Patch:
@@ -13,12 +13,12 @@
 import io.strimzi.api.kafka.model.KafkaBridgeConsumerSpec;
 import io.strimzi.api.kafka.model.KafkaBridgeHttpConfig;
 import io.strimzi.api.kafka.model.KafkaBridgeProducerSpec;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaBridgeCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -12,11 +12,11 @@
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectBuilder;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -10,12 +10,12 @@
 import io.fabric8.kubernetes.api.model.apps.Deployment;
 import io.fabric8.kubernetes.api.model.policy.PodDisruptionBudget;
 import io.strimzi.api.kafka.model.KafkaConnect;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperatorTest.java
Patch:
@@ -12,12 +12,12 @@
 import io.fabric8.openshift.api.model.DeploymentConfig;
 import io.fabric8.openshift.api.model.ImageStream;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaConnectS2ICluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -14,12 +14,12 @@
 import io.strimzi.api.kafka.model.KafkaMirrorMakerConsumerSpecBuilder;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerProducerSpec;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerProducerSpecBuilder;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaMirrorMakerCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -12,12 +12,12 @@
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.operator.cluster.KafkaUpgradeException;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaConfiguration;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.KafkaSetOperator;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/MaintenanceTimeWindowsTest.java
Patch:
@@ -23,7 +23,7 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.TopicOperatorSpec;
 import io.strimzi.api.kafka.model.TopicOperatorSpecBuilder;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.Ca;
 import io.strimzi.operator.cluster.model.ClientsCa;
@@ -33,7 +33,7 @@
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.model.TopicOperator;
 import io.strimzi.operator.cluster.model.ZookeeperCluster;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.ResourceType;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -16,13 +16,13 @@
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.api.kafka.model.KafkaResources;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.Ca;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.model.ZookeeperCluster;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.cluster.operator.resource.StatefulSetOperator;
 import io.strimzi.operator.cluster.operator.resource.ZookeeperLeaderFinder;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/VolumeResizingTest.java
Patch:
@@ -14,11 +14,11 @@
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
-import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
+import io.strimzi.operator.PlatformFeaturesAvailability;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
+import io.strimzi.operator.KubernetesVersion;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.ResourceType;

File: mockkube/src/test/java/io/strimzi/test/io/strimzi/test/mockkube/MockKubeTest.java
Patch:
@@ -26,6 +26,7 @@
 import org.junit.runner.RunWith;
 import org.junit.runners.Parameterized;
 
+import java.net.MalformedURLException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -96,7 +97,7 @@ public MockKubeTest(Class<RT> cls,
     }
 
     @Before
-    public void createClient() {
+    public void createClient() throws MalformedURLException {
         MockKube mockKube = new MockKube();
         init.accept(mockKube);
         client = mockKube.build();

File: operator-common/src/main/java/io/strimzi/operator/KubernetesVersion.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster.operator;
+package io.strimzi.operator;
 
 /**
  * Represents Kubernetes version which CO runs on

File: operator-common/src/main/java/io/strimzi/operator/PlatformFeaturesAvailability.java
Patch:
@@ -2,11 +2,10 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster;
+package io.strimzi.operator;
 
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.VersionInfo;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
 import okhttp3.OkHttpClient;

File: operator-common/src/test/java/io/strimzi/operator/KubernetesVersionTest.java
Patch:
@@ -2,11 +2,10 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster.operator;
+package io.strimzi.operator;
 
 import org.junit.Test;
 
-
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertTrue;
 

File: operator-common/src/test/java/io/strimzi/operator/PlatformFeaturesAvailabilityTest.java
Patch:
@@ -2,12 +2,11 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster;
+package io.strimzi.operator;
 
 
 import io.fabric8.kubernetes.client.DefaultKubernetesClient;
 import io.fabric8.kubernetes.client.KubernetesClient;
-import io.strimzi.operator.cluster.operator.KubernetesVersion;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
 import io.vertx.core.http.HttpMethod;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
Patch:
@@ -167,7 +167,7 @@ private void startStop(TestContext context, String namespaces, boolean openShift
             async2.await();
         }
 
-        if (numWatchers.get() > (openShift ? 4 : 3) * namespaceList.size()) {
+        if (numWatchers.get() > (openShift ? 5 : 4) * namespaceList.size()) { // we do not have connectS2I on k8s
             context.fail("Looks like there were more watchers than namespaces");
         }
     }
@@ -245,8 +245,8 @@ private void startStopAllNamespaces(TestContext context, String namespaces, bool
             async2.await();
         }
 
-        if (numWatchers.get() > (openShift ? 4 : 3)) {
-            context.fail("Looks like there were more watchers than we should");
+        if (numWatchers.get() > (openShift ? 5 : 4)) { // we do not have connectS2I on k8s
+            context.fail("Looks like there were more watchers than should be");
         }
     }
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -100,7 +100,7 @@ private ArgumentCaptor<Secret> reconcileCa(TestContext context, CertificateAutho
         KafkaAssemblyOperator op = new KafkaAssemblyOperator(vertx, new PlatformFeaturesAvailability(false, KubernetesVersion.V1_9), certManager,
                 new ResourceOperatorSupplier(null, null, null,
                         null, null, secretOps, null, null, null, null, null, null,
-                        null, null, null, null, null, null, null, null, null, null, null),
+                        null, null, null, null, null, null, null, null, null, null, null, null),
                 ResourceUtils.dummyClusterOperatorConfig(1L));
         Reconciliation reconciliation = new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, NAME);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -155,7 +155,7 @@ private List<StatefulSet> upgrade(TestContext context, Map<String, String> versi
                 new MockCertManager(),
                 new ResourceOperatorSupplier(null, null, null,
                         kso, null, null, null, null, null, null, null,
-                        null, null, null, null, null, null, null, null, null, null, null, null),
+                        null, null, null, null, null, null, null, null, null, null, null, null, null),
                 ResourceUtils.dummyClusterOperatorConfig(lookup, 1L));
         Reconciliation reconciliation = new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, NAME);
 

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -72,6 +72,8 @@ public final class TestUtils {
 
     public static final String CRD_KAFKA_MIRROR_MAKER = "../install/cluster-operator/045-Crd-kafkamirrormaker.yaml";
 
+    public static final String CRD_KAFKA_BRIDGE = "../install/cluster-operator/046-Crd-kafkabridge.yaml";
+
     private TestUtils() {
         // All static methods
     }

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -57,7 +57,7 @@
 import io.strimzi.api.kafka.model.KafkaUserBuilder;
 import io.strimzi.api.kafka.model.KafkaUserScramSha512ClientAuthentication;
 import io.strimzi.api.kafka.model.KafkaUserTlsClientAuthentication;
-import io.strimzi.api.kafka.model.storage.SingleVolumeStorage;
+import io.strimzi.api.kafka.model.storage.JbodStorage;
 import io.strimzi.systemtest.utils.StUtils;
 import io.strimzi.test.TestUtils;
 import io.strimzi.test.k8s.KubeClient;
@@ -225,11 +225,11 @@ DoneableKafka kafkaEphemeral(String name, int kafkaReplicas, int zookeeperReplic
         return kafka(defaultKafka(name, kafkaReplicas, zookeeperReplicas).build());
     }
 
-    DoneableKafka kafkaJBOD(String name, int kafkaReplicas, List<SingleVolumeStorage> volumes) {
+    DoneableKafka kafkaJBOD(String name, int kafkaReplicas, JbodStorage jbodStorage) {
         return kafka(defaultKafka(name, kafkaReplicas).
                 editSpec()
                     .editKafka()
-                        .withNewJbodStorage().withVolumes(volumes).endJbodStorage()
+                        .withStorage(jbodStorage)
                     .endKafka()
                     .editZookeeper().
                         withReplicas(1)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ModelUtilsTest.java
Patch:
@@ -8,10 +8,10 @@
 import io.fabric8.kubernetes.api.model.LocalObjectReference;
 import io.fabric8.kubernetes.api.model.PodSecurityContextBuilder;
 import io.fabric8.kubernetes.api.model.Probe;
-import io.strimzi.api.kafka.model.EphemeralStorageBuilder;
-import io.strimzi.api.kafka.model.JbodStorageBuilder;
-import io.strimzi.api.kafka.model.PersistentClaimStorageBuilder;
 import io.strimzi.api.kafka.model.ProbeBuilder;
+import io.strimzi.api.kafka.model.storage.EphemeralStorageBuilder;
+import io.strimzi.api.kafka.model.storage.JbodStorageBuilder;
+import io.strimzi.api.kafka.model.storage.PersistentClaimStorageBuilder;
 import io.strimzi.api.kafka.model.storage.Storage;
 import io.strimzi.api.kafka.model.template.PodDisruptionBudgetTemplate;
 import io.strimzi.api.kafka.model.template.PodDisruptionBudgetTemplateBuilder;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -338,7 +338,7 @@ public Future<Void> deleteAsync(String namespace, String name, boolean cascading
                         log.debug("{} {} in namespace {} has been deleted", resourceKind, name, namespace);
                         future.complete();
                     } else  {
-                        log.error("{} {} in namespace {} has been not been deleted", resourceKind, name, namespace);
+                        log.debug("{} {} in namespace {} has been not been deleted", resourceKind, name, namespace);
                         future.fail(resourceKind + " " + name + " in namespace " + namespace + " has been not been deleted");
                     }
                 } catch (Exception e) {

File: api/src/main/java/io/strimzi/api/kafka/model/EntityOperatorSpec.java
Patch:
@@ -83,7 +83,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     @DeprecatedProperty(movedToPath = "spec.template.pod.tolerations")
     @Deprecated

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -236,7 +236,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     @DeprecatedProperty(movedToPath = "spec.kafka.template.pod.tolerations")
     @Deprecated

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java
Patch:
@@ -177,7 +177,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     @DeprecatedProperty(movedToPath = "spec.template.pod.tolerations")
     @Deprecated

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -163,7 +163,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     @DeprecatedProperty(movedToPath = "spec.template.pod.tolerations")
     @Deprecated

File: api/src/main/java/io/strimzi/api/kafka/model/ZookeeperClusterSpec.java
Patch:
@@ -193,7 +193,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     @DeprecatedProperty(movedToPath = "spec.zookeeper.template.pod.tolerations")
     @Deprecated

File: api/src/main/java/io/strimzi/api/kafka/model/connect/ExternalConfigurationEnvVarSource.java
Patch:
@@ -38,7 +38,7 @@ public class ExternalConfigurationEnvVarSource implements Serializable, UnknownP
     // TODO: We should make it possible to generate a CRD configuring that exactly one of secretKeyRef and configMapKeyRef has to be defined.
 
     @Description("Reference to a key in a Secret.")
-    @KubeLink(group = "core", version = "v1", kind = "SecretKeySelector")
+    @KubeLink(group = "core", version = "v1", kind = "secretkeyselector")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public SecretKeySelector getSecretKeyRef() {
         return secretKeyRef;
@@ -49,7 +49,7 @@ public void setSecretKeyRef(SecretKeySelector secretKeyRef) {
     }
 
     @Description("Refernce to a key in a ConfigMap.")
-    @KubeLink(group = "core", version = "v1", kind = "ConfigMapKeySelector")
+    @KubeLink(group = "core", version = "v1", kind = "configmapkeyselector")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public ConfigMapKeySelector getConfigMapKeyRef() {
         return configMapKeyRef;

File: api/src/main/java/io/strimzi/api/kafka/model/connect/ExternalConfigurationVolumeSource.java
Patch:
@@ -51,7 +51,7 @@ public void setName(String name) {
 
     @Description("Reference to a key in a Secret. " +
             "Exactly one Secret or ConfigMap has to be specified.")
-    @KubeLink(group = "core", version = "v1", kind = "SecretVolumeSource")
+    @KubeLink(group = "core", version = "v1", kind = "secretvolumesource")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public SecretVolumeSource getSecret() {
         return secret;
@@ -63,7 +63,7 @@ public void setSecret(SecretVolumeSource secret) {
 
     @Description("Reference to a key in a ConfigMap. " +
             "Exactly one Secret or ConfigMap has to be specified.")
-    @KubeLink(group = "core", version = "v1", kind = "ConfigMapVolumeSource")
+    @KubeLink(group = "core", version = "v1", kind = "configmapvolumesource")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public ConfigMapVolumeSource getConfigMap() {
         return configMap;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternal.java
Patch:
@@ -56,7 +56,7 @@ public abstract class KafkaListenerExternal implements UnknownPropertyPreserving
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public abstract List<NetworkPolicyPeer> getNetworkPolicyPeers();
 

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalIngress.java
Patch:
@@ -59,7 +59,7 @@ public void setAuth(KafkaListenerAuthentication auth) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalLoadBalancer.java
Patch:
@@ -72,7 +72,7 @@ public void setTls(boolean tls) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalNodePort.java
Patch:
@@ -72,7 +72,7 @@ public void setTls(boolean tls) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalRoute.java
Patch:
@@ -59,7 +59,7 @@ public void setAuth(KafkaListenerAuthentication auth) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerPlain.java
Patch:
@@ -51,7 +51,7 @@ public void setAuthentication(KafkaListenerAuthentication authentication) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerTls.java
Patch:
@@ -53,7 +53,7 @@ public void setAuth(KafkaListenerAuthentication auth) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/template/PodTemplate.java
Patch:
@@ -106,7 +106,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<Toleration> getTolerations() {
         return tolerations;

File: crd-generator/src/main/java/io/strimzi/crdgenerator/KubeLinker.java
Patch:
@@ -10,13 +10,13 @@ public class KubeLinker implements Linker {
     private final String baseUrl;
 
     public KubeLinker(String baseUrl) {
-        //https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/
+        //https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/
         this.baseUrl = baseUrl;
     }
 
     @Override
     public String link(KubeLink kubeLink) {
-        //https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#ingress-v1beta1-extensions
-        return baseUrl + "#" + kubeLink.kind() + "-" + kubeLink.version() + "-" + kubeLink.group();
+        //https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#networkpolicyingressrule-v1-networking-k8s-io
+        return baseUrl + "#" + kubeLink.kind() + "-" + kubeLink.version() + "-" + kubeLink.group().replace(".", "-");
     }
 }

File: api/src/main/java/io/strimzi/api/kafka/model/EntityOperatorSpec.java
Patch:
@@ -83,7 +83,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     @DeprecatedProperty(movedToPath = "spec.template.pod.tolerations")
     @Deprecated

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -236,7 +236,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     @DeprecatedProperty(movedToPath = "spec.kafka.template.pod.tolerations")
     @Deprecated

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java
Patch:
@@ -177,7 +177,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     @DeprecatedProperty(movedToPath = "spec.template.pod.tolerations")
     @Deprecated

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -163,7 +163,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     @DeprecatedProperty(movedToPath = "spec.template.pod.tolerations")
     @Deprecated

File: api/src/main/java/io/strimzi/api/kafka/model/ZookeeperClusterSpec.java
Patch:
@@ -193,7 +193,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     @DeprecatedProperty(movedToPath = "spec.zookeeper.template.pod.tolerations")
     @Deprecated

File: api/src/main/java/io/strimzi/api/kafka/model/connect/ExternalConfigurationEnvVarSource.java
Patch:
@@ -38,7 +38,7 @@ public class ExternalConfigurationEnvVarSource implements Serializable, UnknownP
     // TODO: We should make it possible to generate a CRD configuring that exactly one of secretKeyRef and configMapKeyRef has to be defined.
 
     @Description("Reference to a key in a Secret.")
-    @KubeLink(group = "core", version = "v1", kind = "SecretKeySelector")
+    @KubeLink(group = "core", version = "v1", kind = "secretkeyselector")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public SecretKeySelector getSecretKeyRef() {
         return secretKeyRef;
@@ -49,7 +49,7 @@ public void setSecretKeyRef(SecretKeySelector secretKeyRef) {
     }
 
     @Description("Refernce to a key in a ConfigMap.")
-    @KubeLink(group = "core", version = "v1", kind = "ConfigMapKeySelector")
+    @KubeLink(group = "core", version = "v1", kind = "configmapkeyselector")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public ConfigMapKeySelector getConfigMapKeyRef() {
         return configMapKeyRef;

File: api/src/main/java/io/strimzi/api/kafka/model/connect/ExternalConfigurationVolumeSource.java
Patch:
@@ -51,7 +51,7 @@ public void setName(String name) {
 
     @Description("Reference to a key in a Secret. " +
             "Exactly one Secret or ConfigMap has to be specified.")
-    @KubeLink(group = "core", version = "v1", kind = "SecretVolumeSource")
+    @KubeLink(group = "core", version = "v1", kind = "secretvolumesource")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public SecretVolumeSource getSecret() {
         return secret;
@@ -63,7 +63,7 @@ public void setSecret(SecretVolumeSource secret) {
 
     @Description("Reference to a key in a ConfigMap. " +
             "Exactly one Secret or ConfigMap has to be specified.")
-    @KubeLink(group = "core", version = "v1", kind = "ConfigMapVolumeSource")
+    @KubeLink(group = "core", version = "v1", kind = "configmapvolumesource")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)
     public ConfigMapVolumeSource getConfigMap() {
         return configMap;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternal.java
Patch:
@@ -56,7 +56,7 @@ public abstract class KafkaListenerExternal implements UnknownPropertyPreserving
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public abstract List<NetworkPolicyPeer> getNetworkPolicyPeers();
 

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalIngress.java
Patch:
@@ -59,7 +59,7 @@ public void setAuth(KafkaListenerAuthentication auth) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalLoadBalancer.java
Patch:
@@ -72,7 +72,7 @@ public void setTls(boolean tls) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalNodePort.java
Patch:
@@ -72,7 +72,7 @@ public void setTls(boolean tls) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternalRoute.java
Patch:
@@ -59,7 +59,7 @@ public void setAuth(KafkaListenerAuthentication auth) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerPlain.java
Patch:
@@ -51,7 +51,7 @@ public void setAuthentication(KafkaListenerAuthentication authentication) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerTls.java
Patch:
@@ -53,7 +53,7 @@ public void setAuth(KafkaListenerAuthentication auth) {
             "Peers in this list are combined using a logical OR operation. " +
             "If this field is empty or missing, all connections will be allowed for this listener. " +
             "If this field is present and contains at least one item, the listener only allows the traffic which matches at least one item in this list.")
-    @KubeLink(group = "networking", version = "v1", kind = "networkpolicypeer")
+    @KubeLink(group = "networking.k8s.io", version = "v1", kind = "networkpolicypeer")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<NetworkPolicyPeer> getNetworkPolicyPeers() {
         return networkPolicyPeers;

File: api/src/main/java/io/strimzi/api/kafka/model/template/PodTemplate.java
Patch:
@@ -106,7 +106,7 @@ public void setAffinity(Affinity affinity) {
     }
 
     @Description("The pod's tolerations.")
-    @KubeLink(group = "core", version = "v1", kind = "tolerations")
+    @KubeLink(group = "core", version = "v1", kind = "toleration")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public List<Toleration> getTolerations() {
         return tolerations;

File: crd-generator/src/main/java/io/strimzi/crdgenerator/KubeLinker.java
Patch:
@@ -10,13 +10,13 @@ public class KubeLinker implements Linker {
     private final String baseUrl;
 
     public KubeLinker(String baseUrl) {
-        //https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/
+        //https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/
         this.baseUrl = baseUrl;
     }
 
     @Override
     public String link(KubeLink kubeLink) {
-        //https://v1-9.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#ingress-v1beta1-extensions
-        return baseUrl + "#" + kubeLink.kind() + "-" + kubeLink.version() + "-" + kubeLink.group();
+        //https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#networkpolicyingressrule-v1-networking-k8s-io
+        return baseUrl + "#" + kubeLink.kind() + "-" + kubeLink.version() + "-" + kubeLink.group().replace(".", "-");
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -354,7 +354,7 @@ public static KafkaCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup vers
             StorageDiff diff = new StorageDiff(oldStorage, newStorage);
 
             if (!diff.isEmpty()) {
-                log.warn("Only following changes to Kafka storage are allowed: changing the deleteClaim flag, adding volumes to Jbod storage or removing volumes from Jbod storage.");
+                log.warn("Only the following changes to Kafka storage are allowed: changing the deleteClaim flag, adding volumes to Jbod storage or removing volumes from Jbod storage and increasing size of persistent claim volumes (depending on the volume type and used storage class).");
                 log.warn("Your desired Kafka storage configuration contains changes which are not allowed. As a result, all storage changes will be ignored. Use DEBUG level logging for more information about the detected changes.");
                 result.setStorage(oldStorage);
             } else {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -212,7 +212,7 @@ public static ZookeeperCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup
             StorageDiff diff = new StorageDiff(oldStorage, newStorage);
 
             if (!diff.isEmpty()) {
-                log.warn("Only following changes to Zookeeper storage are allowed: changing the deleteClaim flag.");
+                log.warn("Only the following changes to Zookeeper storage are allowed: changing the deleteClaim flag and increasing size of persistent claim volumes (depending on the volume type and used storage class).");
                 log.warn("Your desired Zookeeper storage configuration contains changes which are not allowed. As a result, all storage changes will be ignored. Use DEBUG level logging for more information about the detected changes.");
                 zk.setStorage(oldStorage);
             } else {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -257,7 +257,7 @@ protected Future<ReconcileResult<StatefulSet>> internalPatch(String namespace, S
             log.debug("Patching {} {}/{}", resourceKind, namespace, name);
         }
 
-        if (diff.changesVolumeClaimTemplates()) {
+        if (diff.changesVolumeClaimTemplates() || diff.changesVolumeSize()) {
             // When volume claim templates change, we need to delete the STS and re-create it
             return internalReplace(namespace, name, current, desired, false);
         } else {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -67,6 +67,7 @@
 import io.strimzi.operator.common.operator.resource.SecretOperator;
 import io.strimzi.operator.common.operator.resource.ServiceAccountOperator;
 import io.strimzi.operator.common.operator.resource.ServiceOperator;
+import io.strimzi.operator.common.operator.resource.StorageClassOperator;
 import io.strimzi.test.TestUtils;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
@@ -500,7 +501,8 @@ public static ResourceOperatorSupplier supplierWithMocks(boolean openShift) {
                 mock(NetworkPolicyOperator.class), mock(PodDisruptionBudgetOperator.class), mock(PodOperator.class),
                 mock(IngressOperator.class), mock(ImageStreamOperator.class), mock(BuildConfigOperator.class),
                 mock(DeploymentConfigOperator.class), mock(CrdOperator.class), mock(CrdOperator.class), mock(CrdOperator.class),
-                mock(CrdOperator.class));
+                mock(CrdOperator.class),
+                mock(StorageClassOperator.class));
         when(supplier.serviceAccountOperations.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.roleBindingOperations.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.clusterRoleBindingOperator.reconcile(anyString(), any())).thenReturn(Future.succeededFuture());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -100,7 +100,7 @@ private ArgumentCaptor<Secret> reconcileCa(TestContext context, CertificateAutho
         KafkaAssemblyOperator op = new KafkaAssemblyOperator(vertx, new PlatformFeaturesAvailability(false, KubernetesVersion.V1_9), certManager,
                 new ResourceOperatorSupplier(null, null, null,
                         null, null, secretOps, null, null, null, null, null, null,
-                        null, null, null, null, null, null, null, null, null, null),
+                        null, null, null, null, null, null, null, null, null, null, null),
                 ResourceUtils.dummyClusterOperatorConfig(1L));
         Reconciliation reconciliation = new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, NAME);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -155,7 +155,7 @@ private List<StatefulSet> upgrade(TestContext context, Map<String, String> versi
                 new MockCertManager(),
                 new ResourceOperatorSupplier(null, null, null,
                         kso, null, null, null, null, null, null, null,
-                        null, null, null, null, null, null, null, null, null, null, null),
+                        null, null, null, null, null, null, null, null, null, null, null, null),
                 ResourceUtils.dummyClusterOperatorConfig(lookup, 1L));
         Reconciliation reconciliation = new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, NAME);
 

File: api/src/test/java/io/strimzi/api/kafka/model/AbstractCrdIT.java
Patch:
@@ -42,13 +42,13 @@ private void createDelete(String ssStr) {
         RuntimeException thrown2 = null;
         try {
             try {
-                CLUSTER.client().applyContent(ssStr);
+                CLUSTER.cmdClient().applyContent(ssStr);
             } catch (RuntimeException t) {
                 thrown = t;
             }
         } finally {
             try {
-                CLUSTER.client().deleteContent(ssStr);
+                CLUSTER.cmdClient().deleteContent(ssStr);
             } catch (RuntimeException t) {
                 thrown2 = t;
             }

File: systemtest/src/main/java/io/strimzi/systemtest/clients/api/VerifiableClient.java
Patch:
@@ -16,7 +16,6 @@
 public class VerifiableClient {
     private static final Logger LOGGER = LogManager.getLogger(VerifiableClient.class);
     protected ArrayList<ClientArgument> allowedArguments = new ArrayList<>();
-    private ClientType clientType;
     private JsonArray messages = new JsonArray();
     private ArrayList<String> arguments = new ArrayList<>();
     private String executable;
@@ -27,7 +26,6 @@ public class VerifiableClient {
      * @param clientType type of kafka client
      */
     public VerifiableClient(ClientType clientType) {
-        this.clientType = clientType;
         this.setAllowedArguments(clientType);
         this.executable = ClientType.getCommand(clientType);
     }

File: systemtest/src/main/java/io/strimzi/systemtest/clients/lib/Producer.java
Patch:
@@ -4,12 +4,11 @@
  */
 package io.strimzi.systemtest.clients.lib;
 
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
-
 import io.vertx.kafka.client.producer.KafkaProducer;
 import io.vertx.kafka.client.producer.KafkaProducerRecord;
 import io.vertx.kafka.client.producer.RecordMetadata;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
 
 import java.util.Properties;
 import java.util.concurrent.CompletableFuture;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/TestExecutionWatcher.java
Patch:
@@ -15,8 +15,7 @@
 import java.util.Calendar;
 
 import static io.strimzi.systemtest.AbstractST.TEST_LOG_DIR;
-import static io.strimzi.test.BaseITST.CLIENT;
-import static io.strimzi.test.BaseITST.KUBE_CLIENT;
+import static io.strimzi.test.BaseITST.kubeClient;
 
 public class TestExecutionWatcher implements AfterTestExecutionCallback {
     private static final Logger LOGGER = LogManager.getLogger(TestExecutionWatcher.class);
@@ -35,7 +34,7 @@ void collectLogs(String testMethod, String testClass) {
                 TEST_LOG_DIR + testClass + "." + testMethod + "_" + currentDate
                 : TEST_LOG_DIR + currentDate;
 
-        LogCollector logCollector = new LogCollector(CLIENT.inNamespace(KUBE_CLIENT.namespace()), new File(logDir));
+        LogCollector logCollector = new LogCollector(kubeClient(), new File(logDir));
         logCollector.collectEvents();
         logCollector.collectConfigMaps();
         logCollector.collectLogsFromPods();

File: test-client/src/main/java/io/strimzi/test_client/HttpClientsListener.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.test_client;
 
-import io.strimzi.test.k8s.Exec;
+import io.strimzi.test.executor.Exec;
 import io.vertx.core.AbstractVerticle;
 import io.vertx.core.Vertx;
 import io.vertx.core.http.HttpServer;

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -472,5 +472,4 @@ public static <T> T doRequestTillSuccess(int retry, Callable<T> fn, Optional<Run
             }
         }
     }
-    
-}
+}
\ No newline at end of file

File: test/src/main/java/io/strimzi/test/executor/Exec.java
Patch:
@@ -2,8 +2,9 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.test.k8s;
+package io.strimzi.test.executor;
 
+import io.strimzi.test.k8s.KubeClusterException;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
 
@@ -288,7 +289,7 @@ private void storeOutputsToFile() {
      * @param cmd command
      * @return true.false
      */
-    static boolean isExecutableOnPath(String cmd) {
+    public static boolean isExecutableOnPath(String cmd) {
         for (String dir : PATH_SPLITTER.split(System.getenv("PATH"))) {
             if (new File(dir, cmd).canExecute()) {
                 return true;

File: test/src/main/java/io/strimzi/test/executor/ExecResult.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.test.k8s;
+package io.strimzi.test.executor;
 
 import java.io.Serializable;
 

File: test/src/main/java/io/strimzi/test/k8s/KubeCluster.java
Patch:
@@ -29,7 +29,9 @@ public interface KubeCluster {
     /** Attempt to stop a cluster */
     void clusterDown();
 
-    /** Return a default client for this kind of cluster. */
+    /** Return a default CMD cmdClient for this kind of cluster. */
+    KubeCmdClient defaultCmdClient();
+
     KubeClient defaultClient();
 
     /**

File: test/src/main/java/io/strimzi/test/k8s/KubeClusterException.java
Patch:
@@ -4,6 +4,8 @@
  */
 package io.strimzi.test.k8s;
 
+import io.strimzi.test.executor.ExecResult;
+
 public class KubeClusterException extends RuntimeException {
     public final ExecResult result;
 

File: systemtest/src/main/java/io/strimzi/systemtest/MessagingBaseST.java
Patch:
@@ -47,7 +47,7 @@ public void setResponse(JsonObject response) {
     @BeforeAll
     public void setUpClientBase() throws MalformedURLException {
         String clientUrl = ENVIRONMENT.getKubernetesDomain().equals(Environment.KUBERNETES_DOMAIN_DEFAULT) ?  new URL(CONFIG.getMasterUrl()).getHost() + Environment.KUBERNETES_DOMAIN_DEFAULT : ENVIRONMENT.getKubernetesDomain();
-        cliApiClient = new MsgCliApiClient(new URL("http://" + KAFKA_CLIENTS + "." + clientUrl + ":80"));
+        cliApiClient = new MsgCliApiClient(new URL("http://" + Constants.KAFKA_CLIENTS + "." + clientUrl + ":80"));
     }
 
     /**
@@ -180,7 +180,7 @@ private String getClientUUID(JsonObject response) {
      * @param timeout timeout
      */
     private void waitTillProcessFinish(String processUuid, String description, long timeout) {
-        TestUtils.waitFor("Wait till " + description + " finished", GLOBAL_POLL_INTERVAL, timeout, () -> {
+        TestUtils.waitFor("Wait till " + description + " finished", Constants.GLOBAL_POLL_INTERVAL, timeout, () -> {
             JsonObject out;
             try {
                 out = cliApiClient.getClientInfo(processUuid);

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -51,7 +51,7 @@ void deployNewTopic(String topicNamespace, String clusterNamespace, String topic
         LOGGER.info("Creating topic {} in namespace {}", topic, topicNamespace);
         KUBE_CLIENT.namespace(topicNamespace);
         KUBE_CLIENT.create(new File(TOPIC_EXAMPLES_DIR));
-        TestUtils.waitFor("wait for 'my-topic' to be created in Kafka", GLOBAL_POLL_INTERVAL, TIMEOUT_FOR_TOPIC_CREATION, () -> {
+        TestUtils.waitFor("wait for 'my-topic' to be created in Kafka", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_TOPIC_CREATION, () -> {
             KUBE_CLIENT.namespace(clusterNamespace);
             List<String> topics2 = listTopicsUsingPodCLI(CLUSTER_NAME, 0);
             return topics2.contains(topic);
@@ -75,7 +75,7 @@ void createSecondNamespaceResources() {
     @Override
     void tearDownEnvironmentAfterEach() throws Exception {
         secondNamespaceResources.deleteResources();
-        waitForDeletion(TIMEOUT_TEARDOWN, SECOND_NAMESPACE);
+        waitForDeletion(Constants.TIMEOUT_TEARDOWN, SECOND_NAMESPACE);
         KUBE_CLIENT.namespace(CO_NAMESPACE);
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -17,6 +17,7 @@
 import java.io.IOException;
 import java.util.List;
 
+import static io.strimzi.systemtest.Constants.FLAKY;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.containsString;

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -21,6 +21,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.systemtest.Constants.ACCEPTANCE;
 import static io.strimzi.systemtest.Constants.REGRESSION;
 import static io.strimzi.systemtest.k8s.Events.Created;
 import static io.strimzi.systemtest.k8s.Events.Failed;
@@ -89,7 +90,7 @@ void testKafkaConnectWithFileSinkPlugin() {
 
         sendMessages(kafkaConnectPodName, KAFKA_CLUSTER_NAME, TEST_TOPIC_NAME, 2);
 
-        TestUtils.waitFor("messages in file sink", GLOBAL_POLL_INTERVAL, TIMEOUT_FOR_SEND_RECEIVE_MSG,
+        TestUtils.waitFor("messages in file sink", Constants.GLOBAL_POLL_INTERVAL, Constants.TIMEOUT_FOR_SEND_RECEIVE_MSG,
             () -> KUBE_CLIENT.execInPod(kafkaConnectPodName, "/bin/bash", "-c", "cat /tmp/test-file-sink.txt").out().equals("0\n1\n"));
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/HelmChartST.java
Patch:
@@ -47,7 +47,7 @@ void setupEnvironment() {
     @Override
     void tearDownEnvironmentAfterEach() throws Exception {
         deleteTestMethodResources();
-        waitForDeletion(TIMEOUT_TEARDOWN, NAMESPACE);
+        waitForDeletion(Constants.TIMEOUT_TEARDOWN, NAMESPACE);
     }
 
     @Override

File: systemtest/src/test/java/io/strimzi/systemtest/StrimziUpgradeST.java
Patch:
@@ -245,7 +245,7 @@ private void waitTillAllPodsUseImage(Map<String, String> matchLabels, String ima
     }
 
     private void waitTillAllContainersUseImage(Map<String, String> matchLabels, int container, String image) {
-        TestUtils.waitFor("All pods matching " + matchLabels + " to have image " + image, GLOBAL_POLL_INTERVAL, GLOBAL_TIMEOUT, () -> {
+        TestUtils.waitFor("All pods matching " + matchLabels + " to have image " + image, Constants.GLOBAL_POLL_INTERVAL, Constants.GLOBAL_TIMEOUT, () -> {
             List<Pod> pods1 = CLIENT.pods().inNamespace(NAMESPACE).withLabels(matchLabels).list().getItems();
             for (Pod pod : pods1) {
                 if (!image.equals(pod.getSpec().getContainers().get(container).getImage())) {

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -102,6 +102,6 @@ void setupEnvironment() {
     @Override
     void tearDownEnvironmentAfterEach() throws Exception {
         deleteTestMethodResources();
-        waitForDeletion(TIMEOUT_TEARDOWN, NAMESPACE);
+        waitForDeletion(Constants.TIMEOUT_TEARDOWN, NAMESPACE);
     }
 }

File: systemtest/src/main/java/io/strimzi/systemtest/Constants.java
Patch:
@@ -18,7 +18,7 @@ public interface Constants {
     long POLL_INTERVAL_FOR_RESOURCE_CREATION = Duration.ofSeconds(3).toMillis();
     long POLL_INTERVAL_FOR_RESOURCE_READINESS = Duration.ofSeconds(1).toMillis();
     long WAIT_FOR_ROLLING_UPDATE_INTERVAL = Duration.ofSeconds(5).toMillis();
-    long WAIT_FOR_ROLLING_UPDATE_TIMEOUT = Duration.ofMinutes(5).toMillis();
+    long WAIT_FOR_ROLLING_UPDATE_TIMEOUT = Duration.ofMinutes(7).toMillis();
 
     long TIMEOUT_FOR_SEND_RECEIVE_MSG = Duration.ofSeconds(30).toMillis();
     long TIMEOUT_AVAILABILITY_TEST = Duration.ofMinutes(1).toMillis();

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaCrdIT.java
Patch:
@@ -5,12 +5,10 @@
 package io.strimzi.api.kafka.model;
 
 import io.strimzi.test.TestUtils;
-import io.strimzi.test.extensions.StrimziExtension;
 import io.strimzi.test.k8s.KubeClusterException;
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.BeforeAll;
 import org.junit.jupiter.api.Test;
-import org.junit.jupiter.api.extension.ExtendWith;
 
 import static org.junit.Assert.assertTrue;
 
@@ -20,7 +18,6 @@
  * I.e. that such instance resources obtained from POJOs are valid according to the schema
  * validation done by K8S.
  */
-@ExtendWith(StrimziExtension.class)
 public class KafkaCrdIT extends AbstractCrdIT {
     public static final String NAMESPACE = "kafkacrd-it";
 

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractNamespaceST.java
Patch:
@@ -7,7 +7,6 @@
 import io.strimzi.test.TestUtils;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
-import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeEach;
 
 import java.io.File;
@@ -73,8 +72,8 @@ void createSecondNamespaceResources() {
         KUBE_CLIENT.namespace(CO_NAMESPACE);
     }
 
-    @AfterEach
-    void deleteSecondNamespaceResources() throws Exception {
+    @Override
+    void tearDownEnvironmentAfterEach() throws Exception {
         secondNamespaceResources.deleteResources();
         waitForDeletion(TIMEOUT_TEARDOWN, SECOND_NAMESPACE);
         KUBE_CLIENT.namespace(CO_NAMESPACE);

File: test/src/main/java/io/strimzi/test/BaseITST.java
Patch:
@@ -34,7 +34,7 @@ public class BaseITST {
     private static final Logger LOGGER = LogManager.getLogger(BaseITST.class);
     protected static final String CLUSTER_NAME = "my-cluster";
 
-    public static final KubeClusterResource CLUSTER = new KubeClusterResource();
+    public static final KubeClusterResource CLUSTER = KubeClusterResource.getInstance();
 
     public static final Config CONFIG = Config.autoConfigure(System.getenv().getOrDefault("TEST_CLUSTER_CONTEXT", null));
     public static final DefaultKubernetesClient CLIENT = new DefaultKubernetesClient(CONFIG);

File: systemtest/src/main/java/io/strimzi/systemtest/MessagingBaseST.java
Patch:
@@ -46,7 +46,7 @@ public void setResponse(JsonObject response) {
 
     @BeforeAll
     public void setUpClientBase() throws MalformedURLException {
-        String clientUrl = ENVIRONMENT.getKubernetesDomain().equals(Environment.KUBERNETES_DOMAIN_DEFAULT) ?  new URL(ENVIRONMENT.getKubernetesApiUrl()).getHost() + Environment.KUBERNETES_DOMAIN_DEFAULT : ENVIRONMENT.getKubernetesDomain();
+        String clientUrl = ENVIRONMENT.getKubernetesDomain().equals(Environment.KUBERNETES_DOMAIN_DEFAULT) ?  new URL(CONFIG.getMasterUrl()).getHost() + Environment.KUBERNETES_DOMAIN_DEFAULT : ENVIRONMENT.getKubernetesDomain();
         cliApiClient = new MsgCliApiClient(new URL("http://" + KAFKA_CLIENTS + "." + clientUrl + ":80"));
     }
 

File: systemtest/src/main/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -296,10 +296,9 @@ static String globalVariableJsonPathBuilder(String envVar) {
         return "$.spec.containers[*].env[?(@.name=='" + envVar + "')].value";
     }
 
-    List<Event> getEvents(String resourceType, String resourceName) {
+    List<Event> getEvents(String resourceUid) {
         return CLIENT.events().inNamespace(KUBE_CLIENT.namespace()).list().getItems().stream()
-                .filter(event -> event.getInvolvedObject().getKind().equals(resourceType))
-                .filter(event -> event.getInvolvedObject().getName().equals(resourceName))
+                .filter(event -> event.getInvolvedObject().getUid().equals(resourceUid))
                 .collect(Collectors.toList());
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -355,7 +355,7 @@ public void testGenerateDeploymentWithPlainAuth() {
             .endSpec()
             .build();
         KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(resource, VERSIONS);
-        Deployment dep = kc.generateDeployment(emptyMap(), true, null);
+        Deployment dep = kc.generateDeployment(emptyMap(), true, null, null);
 
         assertEquals("user1-secret", dep.getSpec().getTemplate().getSpec().getVolumes().get(1).getName());
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectAuthentication.java
Patch:
@@ -23,7 +23,7 @@
 @JsonSubTypes({
         @JsonSubTypes.Type(name = KafkaConnectAuthenticationTls.TYPE_TLS, value = KafkaConnectAuthenticationTls.class),
         @JsonSubTypes.Type(name = KafkaConnectAuthenticationScramSha512.TYPE_SCRAM_SHA_512, value = KafkaConnectAuthenticationScramSha512.class),
-        @JsonSubTypes.Type(name = KafkaConnectAuthenticationSaslPlain.TYPE_SASL_PLAIN, value = KafkaConnectAuthenticationSaslPlain.class),
+        @JsonSubTypes.Type(name = KafkaConnectAuthenticationPlain.TYPE_PLAIN, value = KafkaConnectAuthenticationPlain.class),
 })
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @EqualsAndHashCode
@@ -33,9 +33,9 @@ public abstract class KafkaConnectAuthentication implements UnknownPropertyPrese
     private Map<String, Object> additionalProperties;
 
     @Description("Authentication type. " +
-            "Currently the only supported types are `tls`, `scram-sha-512` and `sasl-plain`. " +
+            "Currently the only supported types are `tls`, `scram-sha-512` and `plain`. " +
             "`scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. " +
-            "`sasl-plain` type uses SASL PLAIN Authentication. " +
+            "`plain` type uses SASL PLAIN Authentication. " +
             "`tls` type uses TLS Client Authentication. " +
             "`tls` type is supported only over TLS connections.")
     public abstract String getType();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -335,16 +335,16 @@ public void testGenerateDeploymentWithScramSha512Auth() {
     }
 
     @Test
-    public void testGenerateDeploymentWithSaslPlainAuth() {
+    public void testGenerateDeploymentWithPlainAuth() {
         KafkaConnect resource = new KafkaConnectBuilder(this.resource)
                 .editSpec()
-                .withNewKafkaConnectAuthenticationSaslPlain()
+                .withNewKafkaConnectAuthenticationPlain()
                     .withUsername("user1")
                     .withNewPasswordSecret()
                         .withSecretName("user1-secret")
                         .withPassword("password")
                     .endPasswordSecret()
-                .endKafkaConnectAuthenticationSaslPlain()
+                .endKafkaConnectAuthenticationPlain()
             .endSpec()
             .build();
         KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(resource, VERSIONS);

File: systemtest/src/test/java/io/strimzi/systemtest/OpenShiftTemplatesST.java
Patch:
@@ -13,6 +13,7 @@
 import io.strimzi.api.kafka.model.DoneableKafkaConnect;
 import io.strimzi.api.kafka.model.DoneableKafkaConnectS2I;
 import io.strimzi.api.kafka.model.DoneableKafkaTopic;
+import io.strimzi.api.kafka.model.JbodStorage;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
@@ -96,7 +97,7 @@ void testStrimziPersistent() {
         assertNotNull(kafka);
         assertEquals(1, kafka.getSpec().getKafka().getReplicas());
         assertEquals(1, kafka.getSpec().getZookeeper().getReplicas());
-        assertEquals("persistent-claim", kafka.getSpec().getKafka().getStorage().getType());
+        assertEquals("jbod", kafka.getSpec().getKafka().getStorage().getType());
         assertEquals("persistent-claim", kafka.getSpec().getZookeeper().getStorage().getType());
     }
 
@@ -160,7 +161,7 @@ void testStrimziPersistentWithCustomParameters() {
         assertEquals("2", kafka.getSpec().getKafka().getConfig().get("default.replication.factor"));
         assertEquals("5", kafka.getSpec().getKafka().getConfig().get("offsets.topic.replication.factor"));
         assertEquals("5", kafka.getSpec().getKafka().getConfig().get("transaction.state.log.replication.factor"));
-        assertEquals("2Gi", ((PersistentClaimStorage) kafka.getSpec().getKafka().getStorage()).getSize());
+        assertEquals("2Gi", ((PersistentClaimStorage) ((JbodStorage) kafka.getSpec().getKafka().getStorage()).getVolumes().get(0)).getSize());
         assertEquals("2Gi", ((PersistentClaimStorage) kafka.getSpec().getZookeeper().getStorage()).getSize());
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -805,7 +805,7 @@ public void testResources() {
                 .build();
         KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(resource, VERSIONS);
 
-        Deployment dep = kc.generateDeployment(Collections.EMPTY_MAP, true, null);
+        Deployment dep = kc.generateDeployment(Collections.EMPTY_MAP, true, null, null);
         Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
         assertEquals(limits, cont.getResources().getLimits());
         assertEquals(requests, cont.getResources().getRequests());
@@ -829,7 +829,7 @@ public void testJvmOptions() {
                 .build();
         KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(resource, VERSIONS);
 
-        Deployment dep = kc.generateDeployment(Collections.EMPTY_MAP, true, null);
+        Deployment dep = kc.generateDeployment(Collections.EMPTY_MAP, true, null, null);
         Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
         assertTrue(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-server"));
         assertTrue(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:+UseG1GC"));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -48,6 +48,7 @@
 import java.io.StringReader;
 import java.util.ArrayList;
 import java.util.Collections;
+import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.stream.Collectors;
@@ -889,7 +890,7 @@ public void testResources() {
                 .build();
         KafkaConnectS2ICluster kc = KafkaConnectS2ICluster.fromCrd(resource, VERSIONS);
 
-        DeploymentConfig dep = kc.generateDeploymentConfig(Collections.EMPTY_MAP, true, null);
+        DeploymentConfig dep = kc.generateDeploymentConfig(Collections.EMPTY_MAP, true, null, null);
         Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
         assertEquals(limits, cont.getResources().getLimits());
         assertEquals(requests, cont.getResources().getRequests());
@@ -913,7 +914,7 @@ public void testJvmOptions() {
                 .build();
         KafkaConnectS2ICluster kc = KafkaConnectS2ICluster.fromCrd(resource, VERSIONS);
 
-        DeploymentConfig dep = kc.generateDeploymentConfig(Collections.EMPTY_MAP, true, null);
+        DeploymentConfig dep = kc.generateDeploymentConfig(Collections.EMPTY_MAP, true, null, null);
         Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
         assertTrue(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-server"));
         assertTrue(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:+UseG1GC"));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -657,7 +657,7 @@ public void testJvmOptions() {
                 .build();
         KafkaMirrorMakerCluster mmc = KafkaMirrorMakerCluster.fromCrd(resource, VERSIONS);
 
-        Deployment dep = mmc.generateDeployment(Collections.EMPTY_MAP, true, null);
+        Deployment dep = mmc.generateDeployment(Collections.EMPTY_MAP, true, null, null);
         Container cont = dep.getSpec().getTemplate().getSpec().getContainers().get(0);
         assertTrue(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-server"));
         assertTrue(cont.getEnv().stream().filter(env -> "KAFKA_JVM_PERFORMANCE_OPTS".equals(env.getName())).map(EnvVar::getValue).findFirst().orElse("").contains("-XX:+UseG1GC"));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -176,6 +176,7 @@ public static KafkaMirrorMakerCluster fromCrd(KafkaMirrorMaker kafkaMirrorMaker,
 
         kafkaMirrorMakerCluster.setLogging(kafkaMirrorMaker.getSpec().getLogging());
         kafkaMirrorMakerCluster.setGcLoggingEnabled(kafkaMirrorMaker.getSpec().getJvmOptions() == null ? true : kafkaMirrorMaker.getSpec().getJvmOptions().isGcLoggingEnabled());
+        kafkaMirrorMakerCluster.setJvmOptions(kafkaMirrorMaker.getSpec().getJvmOptions());
 
         Map<String, Object> metrics = kafkaMirrorMaker.getSpec().getMetrics();
         if (metrics != null) {

File: systemtest/src/main/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -719,7 +719,7 @@ void deleteClusterOperatorViaHelmChart() {
      */
     void waitForClusterAvailabilityTls(String userName, String namespace) throws Exception {
         int messageCount = 50;
-        String topicName = "test-topic";
+        String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
 
         KafkaClient testClient = new KafkaClient();
         try {
@@ -743,7 +743,7 @@ void waitForClusterAvailabilityTls(String userName, String namespace) throws Exc
      */
     void waitForClusterAvailability(String namespace) throws Exception {
         int messageCount = 50;
-        String topicName = "test-topic";
+        String topicName = "test-topic-" + new Random().nextInt(Integer.MAX_VALUE);
 
         KafkaClient testClient = new KafkaClient();
         try {

File: systemtest/src/main/java/io/strimzi/systemtest/clients/lib/KafkaClientProperties.java
Patch:
@@ -118,7 +118,7 @@ static Properties createConsumerProperties(String namespace, String clusterName,
      */
     private static Properties sharedClientProperties(String namespace, String clusterName, String userName) {
         Properties properties = new Properties();
-        // For turn of hostname verification
+        // For turn off hostname verification
         properties.setProperty("ssl.endpoint.identification.algorithm", "");
 
         try {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -60,6 +60,7 @@
 import static org.junit.Assert.assertNull;
 import static org.junit.Assert.assertTrue;
 
+@SuppressWarnings("checkstyle:ClassDataAbstractionCoupling")
 public class KafkaConnectS2IClusterTest {
     private static final KafkaVersion.Lookup VERSIONS = new KafkaVersion.Lookup(new StringReader(
             "2.0.0 default 2.0 2.0 1234567890abcdef"),

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -176,6 +176,7 @@ public static KafkaMirrorMakerCluster fromCrd(KafkaMirrorMaker kafkaMirrorMaker,
 
         kafkaMirrorMakerCluster.setLogging(kafkaMirrorMaker.getSpec().getLogging());
         kafkaMirrorMakerCluster.setGcLoggingEnabled(kafkaMirrorMaker.getSpec().getJvmOptions() == null ? true : kafkaMirrorMaker.getSpec().getJvmOptions().isGcLoggingEnabled());
+        kafkaMirrorMakerCluster.setJvmOptions(kafkaMirrorMaker.getSpec().getJvmOptions());
 
         Map<String, Object> metrics = kafkaMirrorMaker.getSpec().getMetrics();
         if (metrics != null) {

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -918,7 +918,7 @@ private PodSpec createClientSpec(boolean tlsListener, KafkaUser... kafkaUsers) {
                     .withInitialDelaySeconds(10)
                     .withPeriodSeconds(5)
                 .endLivenessProbe()
-                .withImagePullPolicy(IMAGE_PULL_POLICY);
+                .withImagePullPolicy("IfNotPresent");
 
         if (kafkaUsers == null) {
             String producerConfiguration = "acks=all\n";

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -734,7 +734,7 @@ void testRackAware() {
         KUBE_CLIENT.waitForPod(kafkaPodName);
 
         String rackId = KUBE_CLIENT.execInPodContainer(kafkaPodName, "kafka", "/bin/bash", "-c", "cat /opt/kafka/init/rack.id").out();
-        assertEquals("zone", rackId);
+        assertEquals("zone", rackId.trim());
 
         String brokerRack = KUBE_CLIENT.execInPodContainer(kafkaPodName, "kafka", "/bin/bash", "-c", "cat /tmp/strimzi.properties | grep broker.rack").out();
         assertTrue(brokerRack.contains("broker.rack=zone"));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -238,8 +238,6 @@ public void testUpdateVolumeIdJbod(TestContext context) {
         });
         createAsync.await();
 
-        Set<String> expectedPvcs = expectedPvcs(this.kafka);
-
         // trying to update id for a volume from in the JBOD storage
         volumes.get(0).setId(3);
 
@@ -251,6 +249,8 @@ public void testUpdateVolumeIdJbod(TestContext context) {
                 .endSpec()
                 .build();
 
+        Set<String> expectedPvcs = expectedPvcs(changedKafka);
+
         Crds.kafkaOperation(mockClient).inNamespace(NAMESPACE).withName(NAME).patch(changedKafka);
 
         Async updateAsync = context.async();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/StorageDiff.java
Patch:
@@ -47,10 +47,10 @@ public StorageDiff(Storage current, Storage desired, String volumeDesc) {
 
             for (Integer volumeId : volumeIds)  {
                 SingleVolumeStorage currentVolume = ((JbodStorage) current).getVolumes().stream()
-                        .filter(volume -> volume != null && volume.getId() != null && volume.getId() == volumeId)
+                        .filter(volume -> volume != null && volumeId.equals(volume.getId()))
                         .findAny().orElse(null);
                 SingleVolumeStorage desiredVolume = ((JbodStorage) desired).getVolumes().stream()
-                        .filter(volume -> volume != null && volume.getId() != null && volume.getId() == volumeId)
+                        .filter(volume -> volume != null && volumeId.equals(volume.getId()))
                         .findAny().orElse(null);
 
                 StorageDiff diff = new StorageDiff(currentVolume, desiredVolume, "(volume ID: " + volumeId + ") ");

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -742,7 +742,7 @@ void testRackAware() {
         KUBE_CLIENT.waitForPod(kafkaPodName);
 
         String rackId = KUBE_CLIENT.execInPodContainer(kafkaPodName, "kafka", "/bin/bash", "-c", "cat /opt/kafka/init/rack.id").out();
-        assertEquals("zone", rackId);
+        assertEquals("zone", rackId.trim());
 
         String brokerRack = KUBE_CLIENT.execInPodContainer(kafkaPodName, "kafka", "/bin/bash", "-c", "cat /tmp/strimzi.properties | grep broker.rack").out();
         assertTrue(brokerRack.contains("broker.rack=zone"));

File: topic-operator/src/main/java/io/strimzi/operator/topic/InFlight.java
Patch:
@@ -115,7 +115,7 @@ public void enqueue(T key, Handler<Future<Void>> action, Handler<AsyncResult<Voi
             } else {
                 LOGGER.debug("Queueing {} for deferred execution after {}", action, current);
                 current.setHandler(ar -> {
-                    LOGGER.debug("Queueing {} after deferred execution", action);
+                    LOGGER.debug("Executing {} after now {} has finished", action, current);
                     vertx.runOnContext(ar2 ->
                             action.handle(fut.fut));
                 });

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -190,8 +190,8 @@ private void checkStatefulSet(StatefulSet ss) {
         assertEquals(new Integer(healthTimeout), containers.get(0).getReadinessProbe().getTimeoutSeconds());
         assertEquals(new Integer(healthDelay), containers.get(0).getReadinessProbe().getInitialDelaySeconds());
         OrderedProperties expectedConfig = new OrderedProperties()
-                .addPair("timeTick", "2000")
                 .addPair("autopurge.purgeInterval", "1")
+                .addPair("timeTick", "2000")
                 .addPair("syncLimit", "2")
                 .addPair("initLimit", "5")
                 .addPair("foo", "bar");

File: topic-operator/src/main/java/io/strimzi/operator/topic/InFlight.java
Patch:
@@ -93,6 +93,9 @@ public InFlight(Vertx vertx) {
         this.vertx = vertx;
     }
 
+    public String toString() {
+        return this.map.toString();
+    }
 
     /**
      * Run the given {@code action} on the context thread,

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorMockTest.java
Patch:
@@ -94,7 +94,7 @@ public void createMockKube(TestContext context) throws Exception {
                 context.fail("Failed to deploy session");
             }
         });
-        async.await();
+        async.awaitSuccess();
 
         int timeout = 30_000;
 
@@ -125,6 +125,7 @@ private void createInKube(KafkaTopic topic) {
     }
 
     private void updateInKube(KafkaTopic topic) {
+        LOGGER.info("Updating topic {} in kube", topic.getMetadata().getName());
         Crds.topicOperation(kubeClient).withName(topic.getMetadata().getName()).patch(topic);
     }
 
@@ -169,6 +170,7 @@ void testCreatedInKube(TestContext context, KafkaTopic kt) {
         // Config change + reconcile
         updateInKube(new KafkaTopicBuilder(kt).editSpec().addToConfig("retention.bytes", retention + 1).endSpec().build());
         waitUntilTopicInKafka(kafkaName, config -> Integer.toString(retention + 1).equals(config.get("retention.bytes").value()));
+        // Another reconciliation
         reconcile(context);
 
         // Check things still the same

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -13,7 +13,6 @@
 import io.strimzi.api.kafka.model.KafkaBuilder;
 import io.strimzi.operator.cluster.KafkaUpgradeException;
 import io.strimzi.operator.cluster.PlatformFeaturesAvailability;
-import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaConfiguration;
 import io.strimzi.operator.cluster.model.KafkaVersion;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -105,7 +105,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
             log.error("{} spec cannot be null", kafkaConnectS2I.getMetadata().getName());
             return Future.failedFuture("Spec cannot be null");
         }
-        if (pfa.isOpenshift()) {
+        if (pfa.hasImages() && pfa.hasApps() && pfa.hasBuilds()) {
             KafkaConnectS2ICluster connect;
             try {
                 connect = KafkaConnectS2ICluster.fromCrd(kafkaConnectS2I, versions);
@@ -131,7 +131,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
                     .compose(i -> buildConfigOperations.reconcile(namespace, connect.getName(), connect.generateBuildConfig()))
                     .compose(i -> deploymentConfigOperations.scaleUp(namespace, connect.getName(), connect.getReplicas()).map((Void) null));
         } else {
-            return Future.failedFuture("S2I only available on OpenShift");
+            return Future.failedFuture("The OpenShift build, image or apps APIs are not available in this Kubernetes cluster. Kafka Connect S2I deployment cannot be enabled.");
         }
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ResourceOperatorSupplier.java
Patch:
@@ -53,7 +53,7 @@ public ResourceOperatorSupplier(Vertx vertx, KubernetesClient client, PlatformFe
 
     public ResourceOperatorSupplier(Vertx vertx, KubernetesClient client, ZookeeperLeaderFinder zlf, PlatformFeaturesAvailability pfa, long operationTimeoutMs) {
         this(new ServiceOperator(vertx, client),
-                pfa.isOpenshift() ? new RouteOperator(vertx, client.adapt(OpenShiftClient.class)) : null,
+                pfa.hasRoutes() ? new RouteOperator(vertx, client.adapt(OpenShiftClient.class)) : null,
                 new ZookeeperSetOperator(vertx, client, zlf, operationTimeoutMs),
                 new KafkaSetOperator(vertx, client, operationTimeoutMs),
                 new ConfigMapOperator(vertx, client),

File: systemtest/src/main/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -66,7 +66,7 @@ public class Resources extends AbstractResources {
     private static final long TIMEOUT_FOR_DEPLOYMENT_CONFIG_READINESS = Duration.ofMinutes(7).toMillis();
     private static final long TIMEOUT_FOR_RESOURCE_CREATION = Duration.ofMinutes(5).toMillis();
     public static final long TIMEOUT_FOR_RESOURCE_READINESS = Duration.ofMinutes(7).toMillis();
-    private static final String KAFKA_VERSION = System.getenv().getOrDefault("ST_KAFKA_VERSION", "2.1.1");
+    private static final String KAFKA_VERSION = System.getenv().getOrDefault("ST_KAFKA_VERSION", "2.2.0");
 
     public static final String STRIMZI_PATH_TO_CO_CONFIG = "../install/cluster-operator/050-Deployment-strimzi-cluster-operator.yaml";
     public static final String STRIMZI_DEPLOYMENT_NAME = "strimzi-cluster-operator";

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -232,7 +232,7 @@ private void testDockerImagesForKafkaConnect() {
 
         String connectVersion = Crds.kafkaConnectOperation(CLIENT).inNamespace(NAMESPACE).withName(KAFKA_CLUSTER_NAME).get().getSpec().getVersion();
         if (connectVersion == null) {
-            connectVersion = "2.1.0";
+            connectVersion = "2.2.0";
         }
 
         assertEquals(TestUtils.parseImageMap(imgFromDeplConf.get(KAFKA_CONNECT_IMAGE_MAP)).get(connectVersion), connectImageName);

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -714,7 +714,7 @@ private void testDockerImagesForKafkaCluster(String clusterName, int kafkaPods,
             String imgFromPod = getContainerImageNameFromPod(kafkaPodName(clusterName, i), "kafka");
             String kafkaVersion = Crds.kafkaOperation(CLIENT).inNamespace(NAMESPACE).withName(clusterName).get().getSpec().getKafka().getVersion();
             if (kafkaVersion == null) {
-                kafkaVersion = "2.1.0";
+                kafkaVersion = "2.2.0";
             }
             assertEquals(TestUtils.parseImageMap(imgFromDeplConf.get(KAFKA_IMAGE_MAP)).get(kafkaVersion), imgFromPod);
             imgFromPod = getContainerImageNameFromPod(kafkaPodName(clusterName, i), "tls-sidecar");

File: systemtest/src/test/java/io/strimzi/systemtest/StrimziUpgradeST.java
Patch:
@@ -115,12 +115,12 @@ void upgrade_0_8_2_to_HEAD() throws IOException {
             StUtils.waitTillSsHasRolled(CLIENT, NAMESPACE, zkSsName, zkPods);
             LOGGER.info("Checking ZK pods using new image");
             waitTillAllPodsUseImage(CLIENT.apps().statefulSets().inNamespace(NAMESPACE).withName(zkSsName).get().getSpec().getSelector().getMatchLabels(),
-                    "strimzi/zookeeper:latest-kafka-2.0.0");
+                    "strimzi/kafka:latest-kafka-2.2.0");
             LOGGER.info("Waiting for Kafka SS roll");
             StUtils.waitTillSsHasRolled(CLIENT, NAMESPACE, kafkaSsName, kafkaPods);
             LOGGER.info("Checking Kafka pods using new image");
             waitTillAllPodsUseImage(CLIENT.apps().statefulSets().inNamespace(NAMESPACE).withName(kafkaSsName).get().getSpec().getSelector().getMatchLabels(),
-                    "strimzi/kafka:latest-kafka-2.1.0");
+                    "strimzi/kafka:latest-kafka-2.2.0");
             LOGGER.info("Waiting for EO Dep roll");
             // Check the TO and UO also got upgraded
             StUtils.waitTillDepHasRolled(CLIENT, NAMESPACE, eoDepName, eoPods);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -55,6 +55,7 @@
 import io.strimzi.operator.common.operator.resource.DeploymentOperator;
 import io.strimzi.operator.common.operator.resource.NetworkPolicyOperator;
 import io.strimzi.operator.common.operator.resource.PodDisruptionBudgetOperator;
+import io.strimzi.operator.common.operator.resource.PodOperator;
 import io.strimzi.operator.common.operator.resource.PvcOperator;
 import io.strimzi.operator.common.operator.resource.RoleBindingOperator;
 import io.strimzi.operator.common.operator.resource.RouteOperator;
@@ -490,7 +491,7 @@ public static ResourceOperatorSupplier supplierWithMocks(boolean openShift) {
                 mock(KafkaSetOperator.class), mock(ConfigMapOperator.class), mock(SecretOperator.class),
                 mock(PvcOperator.class), mock(DeploymentOperator.class),
                 mock(ServiceAccountOperator.class), mock(RoleBindingOperator.class), mock(ClusterRoleBindingOperator.class),
-                mock(NetworkPolicyOperator.class), mock(PodDisruptionBudgetOperator.class), mock(CrdOperator.class));
+                mock(NetworkPolicyOperator.class), mock(PodDisruptionBudgetOperator.class), mock(PodOperator.class), mock(CrdOperator.class));
         when(supplier.serviceAccountOperator.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.roleBindingOperator.reconcile(anyString(), anyString(), any())).thenReturn(Future.succeededFuture());
         when(supplier.clusterRoleBindingOperator.reconcile(anyString(), any())).thenReturn(Future.succeededFuture());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -102,7 +102,7 @@ private ArgumentCaptor<Secret> reconcileCa(TestContext context, CertificateAutho
         KafkaAssemblyOperator op = new KafkaAssemblyOperator(vertx, new PlatformFeaturesAvailability(false, KubernetesVersion.V1_9), 1L, certManager,
                 new ResourceOperatorSupplier(null, null, null,
                         null, null, secretOps, null, null,
-                        null, null, null, null, null, null),
+                        null, null, null, null, null, null, null),
                 new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap()), null);
         Reconciliation reconciliation = new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, NAME);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -71,7 +71,6 @@
 
 import static io.strimzi.api.kafka.model.Storage.deleteClaim;
 import static java.util.Collections.emptyMap;
-import static java.util.Collections.emptySet;
 import static java.util.Collections.singletonMap;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
@@ -590,8 +589,6 @@ public void testUpdateKafkaWithChangedDeleteClaim(TestContext context) {
         kco.reconcileAssembly(new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, CLUSTER_NAME), ar -> {
             if (ar.failed()) ar.cause().printStackTrace();
             context.assertTrue(ar.succeeded());
-            assertPvcs(context, !originalKafkaDeleteClaim ? deleteClaim(zkStorage) ? emptySet() : zkPvcs :
-                    deleteClaim(zkStorage) ? kafkaPvcs : allPvcs);
             deleteAsync.complete();
         });
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -154,7 +154,7 @@ private List<StatefulSet> upgrade(TestContext context, Map<String, String> versi
                 new MockCertManager(),
                 new ResourceOperatorSupplier(null, null, null,
                         kso, null, null, null, null,
-                        null, null, null, null, null, null),
+                        null, null, null, null, null, null, null),
                 lookup, null);
         Reconciliation reconciliation = new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, NAME);
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -172,7 +172,7 @@ public void start(Future<Void> startupFuture) {
                 Future<Void> f = Future.future();
                 Thread resourceThread = new Thread(() -> {
                     try {
-                        LOGGER.debug("Watching KafkaTopics matching {}", labels);
+                        LOGGER.debug("Watching KafkaTopics matching {}", labels.labels());
                         Session.this.topicWatch = kubeClient.customResources(Crds.topic(), KafkaTopic.class, KafkaTopicList.class, DoneableKafkaTopic.class)
                                 .inNamespace(namespace).withLabels(labels.labels()).watch(new K8sTopicWatcher(topicOperator));
                         LOGGER.debug("Watching setup");

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorMockTest.java
Patch:
@@ -94,7 +94,7 @@ public void createMockKube(TestContext context) throws Exception {
                 context.fail("Failed to deploy session");
             }
         });
-        async.await();
+        async.awaitSuccess();
 
         int timeout = 30_000;
 
@@ -125,6 +125,7 @@ private void createInKube(KafkaTopic topic) {
     }
 
     private void updateInKube(KafkaTopic topic) {
+        LOGGER.info("Updating topic {} in kube", topic.getMetadata().getName());
         Crds.topicOperation(kubeClient).withName(topic.getMetadata().getName()).patch(topic);
     }
 
@@ -169,6 +170,7 @@ void testCreatedInKube(TestContext context, KafkaTopic kt) {
         // Config change + reconcile
         updateInKube(new KafkaTopicBuilder(kt).editSpec().addToConfig("retention.bytes", retention + 1).endSpec().build());
         waitUntilTopicInKafka(kafkaName, config -> Integer.toString(retention + 1).equals(config.get("retention.bytes").value()));
+        // Another reconciliation
         reconcile(context);
 
         // Check things still the same

File: topic-operator/src/main/java/io/strimzi/operator/topic/InFlight.java
Patch:
@@ -93,6 +93,9 @@ public InFlight(Vertx vertx) {
         this.vertx = vertx;
     }
 
+    public String toString() {
+        return this.map.toString();
+    }
 
     /**
      * Run the given {@code action} on the context thread,

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicOperator.java
Patch:
@@ -887,6 +887,7 @@ public String toString() {
     }
 
     public boolean isWorkInflight() {
+        LOGGER.debug("Inflight: {}", inFlight.toString());
         return inFlight.size() > 0;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -162,6 +162,8 @@ public static KafkaMirrorMakerCluster fromCrd(KafkaMirrorMaker kafkaMirrorMaker,
 
         kafkaMirrorMakerCluster.setReplicas(kafkaMirrorMaker.getSpec() != null && kafkaMirrorMaker.getSpec().getReplicas() > 0 ? kafkaMirrorMaker.getSpec().getReplicas() : DEFAULT_REPLICAS);
 
+        kafkaMirrorMakerCluster.setResources(kafkaMirrorMaker.getSpec().getResources());
+
         kafkaMirrorMakerCluster.setWhitelist(kafkaMirrorMaker.getSpec().getWhitelist());
         kafkaMirrorMakerCluster.setProducer(kafkaMirrorMaker.getSpec().getProducer());
         kafkaMirrorMakerCluster.setConsumer(kafkaMirrorMaker.getSpec().getConsumer());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetDiff.java
Patch:
@@ -24,9 +24,11 @@ public class StatefulSetDiff {
     private static final Pattern IGNORABLE_PATHS = Pattern.compile(
         "^(/spec/revisionHistoryLimit"
         + "|/spec/template/metadata/annotations/strimzi.io~1generation"
+        + "|/spec/template/spec/initContainers/[0-9]+/resources"
         + "|/spec/template/spec/initContainers/[0-9]+/terminationMessagePath"
         + "|/spec/template/spec/initContainers/[0-9]+/terminationMessagePolicy"
         + "|/spec/template/spec/initContainers/[0-9]+/env/[0-9]+/valueFrom/fieldRef/apiVersion"
+        + "|/spec/template/spec/containers/[0-9]+/resources"
         + "|/spec/template/spec/containers/[0-9]+/env/[0-9]+/valueFrom/fieldRef/apiVersion"
         + "|/spec/template/spec/containers/[0-9]+/livenessProbe/failureThreshold"
         + "|/spec/template/spec/containers/[0-9]+/livenessProbe/periodSeconds"

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/QuantitiesTest.java
Patch:
@@ -105,7 +105,7 @@ public void testNormalizeMemory() {
         assertEquals("12345", normalizeMemory("12345"));
         assertEquals("524288000", normalizeMemory("500Mi"));
         assertEquals("1181116006", normalizeMemory("1.1Gi"));
-        assertEquals("1288490189", normalizeMemory("1.2Gi"));
+        assertEquals("1288490188", normalizeMemory("1.2Gi"));
     }
 
     @Test

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -214,9 +214,7 @@ public final void reconcileAssembly(Reconciliation reconciliation, Handler<Async
      */
     protected void validate(T resource) {
         if (resource != null) {
-            String context = kind + " resource " + resource.getMetadata().getName()
-                    + " in namespace " + resource.getMetadata().getNamespace();
-            ResourceVisitor.visit(resource, new ValidationVisitor(context, log));
+            ResourceVisitor.visit(resource, new ValidationVisitor(resource, log));
         }
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -536,7 +536,7 @@ public Service generateExternalService(int pod) {
                 KafkaListenerExternalNodePort externalNodePort = (KafkaListenerExternalNodePort) listeners.getExternal();
                 if (externalNodePort.getOverrides() != null &&  externalNodePort.getOverrides().getBrokers() != null) {
                     nodePort = externalNodePort.getOverrides().getBrokers().stream()
-                        .filter(broker -> broker != null && broker.getBroker() != null && broker.getBroker() == pod)
+                        .filter(broker -> broker != null && broker.getBroker() != null && broker.getBroker() == pod && broker.getNodePort() != null)
                         .map(NodePortListenerBrokerOverride::getNodePort)
                         .findAny().orElse(null);
                 }

File: api/src/main/java/io/strimzi/api/kafka/model/EntityTopicOperatorSpec.java
Patch:
@@ -34,7 +34,7 @@ public class EntityTopicOperatorSpec implements UnknownPropertyPreserving, Seria
     private static final long serialVersionUID = 1L;
 
     public static final String DEFAULT_IMAGE =
-            System.getenv().getOrDefault("STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE", "strimzi/topic-operator:latest");
+            System.getenv().getOrDefault("STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE", "strimzi/operator:latest");
     public static final int DEFAULT_REPLICAS = 1;
     public static final int DEFAULT_HEALTHCHECK_DELAY = 10;
     public static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;

File: api/src/main/java/io/strimzi/api/kafka/model/EntityUserOperatorSpec.java
Patch:
@@ -34,7 +34,7 @@ public class EntityUserOperatorSpec implements UnknownPropertyPreserving, Serial
     private static final long serialVersionUID = 1L;
 
     public static final String DEFAULT_IMAGE =
-            System.getenv().getOrDefault("STRIMZI_DEFAULT_USER_OPERATOR_IMAGE", "strimzi/user-operator:latest");
+            System.getenv().getOrDefault("STRIMZI_DEFAULT_USER_OPERATOR_IMAGE", "strimzi/operator:latest");
     public static final int DEFAULT_HEALTHCHECK_DELAY = 10;
     public static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;
     public static final int DEFAULT_ZOOKEEPER_PORT = 2181;

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractNonNamespacedResourceOperatorTest.java
Patch:
@@ -108,7 +108,7 @@ public void createWhenExistsIsAPatch(TestContext context, boolean cascade) {
             }
             assertTrue(ar.succeeded());
             verify(mockResource).get();
-            verify(mockResource, never()).patch(any()); // for now all non-namespaced resources should not be patched
+            verify(mockResource).patch(any());
             verify(mockResource, never()).create(any());
             verify(mockResource, never()).createNew();
             verify(mockResource, never()).createOrReplace(any());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -217,7 +217,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withCommand("/opt/stunnel/entity_operator_stunnel_run.sh")
                 .withLivenessProbe(ModelUtils.tlsSidecarLivenessProbe(tlsSidecar))
                 .withReadinessProbe(ModelUtils.tlsSidecarReadinessProbe(tlsSidecar))
-                .withResources(ModelUtils.tlsSidecarResources(tlsSidecar))
+                .withResources(tlsSidecar != null ? tlsSidecar.getResources() : null)
                 .withEnv(asList(ModelUtils.tlsSidecarLogEnvVar(tlsSidecar),
                         buildEnvVar(ENV_VAR_ZOOKEEPER_CONNECT, zookeeperConnect)))
                 .withVolumeMounts(createVolumeMount(TLS_SIDECAR_EO_CERTS_VOLUME_NAME, TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT),

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -223,7 +223,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withPorts(singletonList(createContainerPort(HEALTHCHECK_PORT_NAME, HEALTHCHECK_PORT, "TCP")))
                 .withLivenessProbe(createHttpProbe(livenessPath + "healthy", HEALTHCHECK_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath + "ready", HEALTHCHECK_PORT_NAME, readinessInitialDelay, readinessTimeout))
-                .withResources(ModelUtils.resources(getResources()))
+                .withResources(getResources())
                 .withVolumeMounts(getVolumeMounts())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))
                 .build());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -214,7 +214,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withPorts(singletonList(createContainerPort(HEALTHCHECK_PORT_NAME, HEALTHCHECK_PORT, "TCP")))
                 .withLivenessProbe(createHttpProbe(livenessPath + "healthy", HEALTHCHECK_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath + "ready", HEALTHCHECK_PORT_NAME, readinessInitialDelay, readinessTimeout))
-                .withResources(ModelUtils.resources(getResources()))
+                .withResources(getResources())
                 .withVolumeMounts(getVolumeMounts())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))
                 .build());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -864,7 +864,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withPorts(getContainerPortList())
                 .withLivenessProbe(createTcpSocketProbe(REPLICATION_PORT, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createTcpSocketProbe(REPLICATION_PORT, readinessInitialDelay, readinessTimeout))
-                .withResources(ModelUtils.resources(getResources()))
+                .withResources(getResources())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))
                 .withCommand("/opt/kafka/kafka_run.sh")
                 .build();
@@ -880,7 +880,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withCommand("/opt/stunnel/kafka_stunnel_run.sh")
                 .withLivenessProbe(ModelUtils.tlsSidecarLivenessProbe(tlsSidecar))
                 .withReadinessProbe(ModelUtils.tlsSidecarReadinessProbe(tlsSidecar))
-                .withResources(ModelUtils.tlsSidecarResources(tlsSidecar))
+                .withResources(tlsSidecar != null ? tlsSidecar.getResources() : null)
                 .withEnv(asList(buildEnvVar(ENV_VAR_KAFKA_ZOOKEEPER_CONNECT, zookeeperConnect),
                         ModelUtils.tlsSidecarLogEnvVar(tlsSidecar)))
                 .withVolumeMounts(createVolumeMount(BROKER_CERTS_VOLUME, TLS_SIDECAR_KAFKA_CERTS_VOLUME_MOUNT),

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -405,7 +405,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withLivenessProbe(createHttpProbe(livenessPath, REST_API_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath, REST_API_PORT_NAME, readinessInitialDelay, readinessTimeout))
                 .withVolumeMounts(getVolumeMounts())
-                .withResources(ModelUtils.resources(getResources()))
+                .withResources(getResources())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))
                 .build();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -76,7 +76,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                 .withLivenessProbe(createHttpProbe(livenessPath, REST_API_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath, REST_API_PORT_NAME, readinessInitialDelay, readinessTimeout))
                 .withVolumeMounts(getVolumeMounts())
-                .withResources(ModelUtils.resources(getResources()))
+                .withResources(getResources())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, image))
                 .build();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -328,7 +328,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withEnv(getEnvVars())
                 .withPorts(getContainerPortList())
                 .withVolumeMounts(getVolumeMounts())
-                .withResources(ModelUtils.resources(getResources()))
+                .withResources(getResources())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))
                 .build();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -270,7 +270,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withPorts(singletonList(createContainerPort(HEALTHCHECK_PORT_NAME, HEALTHCHECK_PORT, "TCP")))
                 .withLivenessProbe(createHttpProbe(livenessPath + "healthy", HEALTHCHECK_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath + "ready", HEALTHCHECK_PORT_NAME, readinessInitialDelay, readinessTimeout))
-                .withResources(ModelUtils.resources(getResources()))
+                .withResources(getResources())
                 .withVolumeMounts(getVolumeMounts())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))
                 .build();
@@ -280,7 +280,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withImage(tlsSidecarImage)
                 .withLivenessProbe(ModelUtils.tlsSidecarLivenessProbe(tlsSidecar))
                 .withReadinessProbe(ModelUtils.tlsSidecarReadinessProbe(tlsSidecar))
-                .withResources(ModelUtils.tlsSidecarResources(tlsSidecar))
+                .withResources(tlsSidecar != null ? tlsSidecar.getResources() : null)
                 .withEnv(asList(ModelUtils.tlsSidecarLogEnvVar(tlsSidecar),
                         buildEnvVar(ENV_VAR_ZOOKEEPER_CONNECT, zookeeperConnect)))
                 .withVolumeMounts(createVolumeMount(TLS_SIDECAR_EO_CERTS_VOLUME_NAME, TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT),

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -401,7 +401,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withPorts(getContainerPortList())
                 .withLivenessProbe(ModelUtils.createExecProbe(Collections.singletonList(livenessPath), livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(ModelUtils.createExecProbe(Collections.singletonList(readinessPath), readinessInitialDelay, readinessTimeout))
-                .withResources(ModelUtils.resources(getResources()))
+                .withResources(getResources())
                 .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))
                 .build();
 
@@ -416,7 +416,7 @@ protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
                 .withCommand("/opt/stunnel/zookeeper_stunnel_run.sh")
                 .withLivenessProbe(ModelUtils.tlsSidecarLivenessProbe(tlsSidecar))
                 .withReadinessProbe(ModelUtils.tlsSidecarReadinessProbe(tlsSidecar))
-                .withResources(ModelUtils.tlsSidecarResources(tlsSidecar))
+                .withResources(tlsSidecar != null ? tlsSidecar.getResources() : null)
                 .withEnv(asList(ModelUtils.tlsSidecarLogEnvVar(tlsSidecar),
                         buildEnvVar(ENV_VAR_ZOOKEEPER_NODE_COUNT, Integer.toString(replicas))))
                 .withVolumeMounts(createVolumeMount(TLS_SIDECAR_NODES_VOLUME_NAME, TLS_SIDECAR_NODES_VOLUME_MOUNT),

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -99,7 +99,7 @@ public class KafkaCluster extends AbstractModel {
     private static final String ENV_VAR_KAFKA_CLIENTTLS_ENABLED = "KAFKA_CLIENTTLS_ENABLED";
     /** The authentication to configure for the CLIENTTLS listener (TLS transport) . */
     private static final String ENV_VAR_KAFKA_CLIENTTLS_AUTHENTICATION = "KAFKA_CLIENTTLS_AUTHENTICATION";
-    protected static final String ENV_VAR_KAFKA_EXTERNAL_ENABLED = "KAFKA_EXTERNAL_ENABLED";
+    public static final String ENV_VAR_KAFKA_EXTERNAL_ENABLED = "KAFKA_EXTERNAL_ENABLED";
     protected static final String ENV_VAR_KAFKA_EXTERNAL_ADDRESSES = "KAFKA_EXTERNAL_ADDRESSES";
     protected static final String ENV_VAR_KAFKA_EXTERNAL_AUTHENTICATION = "KAFKA_EXTERNAL_AUTHENTICATION";
     protected static final String ENV_VAR_KAFKA_EXTERNAL_TLS = "KAFKA_EXTERNAL_TLS";
@@ -723,7 +723,7 @@ private void setDataVolumesClaimsAndMountPaths(Storage storage) {
                 }
                 return;
             } else {
-                throw new IllegalStateException("The declared storage is not supported");
+                throw new IllegalStateException("The declared storage '" + storage.getType() + "' is not supported");
             }
 
             String name = ModelUtils.getVolumePrefix(id);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -324,7 +324,6 @@ protected Future<ReconcileResult<StatefulSet>> internalPatch(String namespace, S
      */
     protected StatefulSetDiff revertStorageChanges(StatefulSet current, StatefulSet desired) {
         desired.getSpec().setVolumeClaimTemplates(current.getSpec().getVolumeClaimTemplates());
-        desired.getSpec().getTemplate().getSpec().setInitContainers(current.getSpec().getTemplate().getSpec().getInitContainers());
         desired.getSpec().getTemplate().getSpec().setSecurityContext(current.getSpec().getTemplate().getSpec().getSecurityContext());
 
         if (current.getSpec().getVolumeClaimTemplates().isEmpty()) {

File: operator-common/src/main/java/io/strimzi/operator/common/model/ResourceVisitor.java
Patch:
@@ -71,7 +71,7 @@ public static <T extends HasMetadata> void visit(T resource, Visitor visitor) {
         ArrayList<String> path = new ArrayList<>();
         try {
             visit(path, resource, visitor);
-        } catch (RuntimeException | ReflectiveOperationException e) {
+        } catch (RuntimeException | ReflectiveOperationException | StackOverflowError e) {
             LOGGER.error("Error while visiting {}", path, e);
             if (e instanceof RuntimeException) {
                 throw (RuntimeException) e;
@@ -150,7 +150,8 @@ static <M extends AnnotatedElement & Member> void visitProperty(List<String> pat
                 }
                 path.remove(path.size() - 1);
             } else if (!isScalar(returnType)
-                    && !Map.class.isAssignableFrom(returnType)) {
+                    && !Map.class.isAssignableFrom(returnType)
+                    && !returnType.isEnum()) {
                 path.add(propertyName);
                 visit(path, propertyValue, visitor);
                 path.remove(path.size() - 1);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -803,7 +803,7 @@ private void updateCluster(TestContext context, Kafka originalAssembly, Kafka up
 
         // Mock NetworkPolicy get
         when(mockPolicyOps.get(clusterNamespace, KafkaCluster.policyName(clusterName))).thenReturn(originalKafkaCluster.generateNetworkPolicy());
-        when(mockPolicyOps.get(clusterNamespace, ZookeeperCluster.policyName(clusterName))).thenReturn(originalZookeeperCluster.generateNetworkPolicy());
+        when(mockPolicyOps.get(clusterNamespace, ZookeeperCluster.policyName(clusterName))).thenReturn(originalZookeeperCluster.generateNetworkPolicy(true));
 
         // Mock PodDisruptionBudget get
         when(mockPdbOps.get(clusterNamespace, KafkaCluster.kafkaClusterName(clusterName))).thenReturn(originalKafkaCluster.generatePodDisruptionBudget());

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractNonNamespacedResourceOperator.java
Patch:
@@ -120,7 +120,7 @@ protected Future<ReconcileResult<T>> internalDelete(String name) {
             log.debug("{} {} has been deleted", resourceKind, name);
             return Future.succeededFuture(ReconcileResult.deleted());
         } catch (Exception e) {
-            log.error("Caught exception while deleting {} {}", resourceKind, name, e);
+            log.debug("Caught exception while deleting {} {}", resourceKind, name, e);
             return Future.failedFuture(e);
         }
     }
@@ -140,7 +140,7 @@ protected Future<ReconcileResult<T>> internalPatch(String name, T current, T des
             return Future.succeededFuture(wasChanged(current, result) ?
                     ReconcileResult.patched(result) : ReconcileResult.noop(result));
         } catch (Exception e) {
-            log.error("Caught exception while patching {} {}", resourceKind, name, e);
+            log.debug("Caught exception while patching {} {}", resourceKind, name, e);
             return Future.failedFuture(e);
         }
     }
@@ -166,7 +166,7 @@ protected Future<ReconcileResult<T>> internalCreate(String name, T desired) {
             log.debug("{} {} has been created", resourceKind, name);
             return Future.succeededFuture(result);
         } catch (Exception e) {
-            log.error("Caught exception while creating {} {}", resourceKind, name, e);
+            log.debug("Caught exception while creating {} {}", resourceKind, name, e);
             return Future.failedFuture(e);
         }
     }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractResourceOperator.java
Patch:
@@ -121,7 +121,7 @@ protected Future<ReconcileResult<T>> internalDelete(String namespace, String nam
             log.debug("{} {} in namespace {} has been deleted", resourceKind, name, namespace);
             return Future.succeededFuture(ReconcileResult.deleted());
         } catch (Exception e) {
-            log.error("Caught exception while deleting {} {} in namespace {}", resourceKind, name, namespace, e);
+            log.debug("Caught exception while deleting {} {} in namespace {}", resourceKind, name, namespace, e);
             return Future.failedFuture(e);
         }
     }
@@ -140,7 +140,7 @@ protected Future<ReconcileResult<T>> internalPatch(String namespace, String name
             log.debug("{} {} in namespace {} has been patched", resourceKind, name, namespace);
             return Future.succeededFuture(wasChanged(current, result) ? ReconcileResult.patched(result) : ReconcileResult.noop(result));
         } catch (Exception e) {
-            log.error("Caught exception while patching {} {} in namespace {}", resourceKind, name, namespace, e);
+            log.debug("Caught exception while patching {} {} in namespace {}", resourceKind, name, namespace, e);
             return Future.failedFuture(e);
         }
     }
@@ -166,7 +166,7 @@ protected Future<ReconcileResult<T>> internalCreate(String namespace, String nam
             log.debug("{} {} in namespace {} has been created", resourceKind, name, namespace);
             return Future.succeededFuture(result);
         } catch (Exception e) {
-            log.error("Caught exception while creating {} {} in namespace {}", resourceKind, name, namespace, e);
+            log.debug("Caught exception while creating {} {} in namespace {}", resourceKind, name, namespace, e);
             return Future.failedFuture(e);
         }
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -273,6 +273,7 @@ public ServiceAccount generateServiceAccount() {
                     .withName(getServiceAccountName())
                     .withNamespace(namespace)
                     .withOwnerReferences(createOwnerReference())
+                    .withLabels(labels.toMap())
                 .endMetadata()
                 .build();
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -16,7 +16,6 @@
 import io.strimzi.api.kafka.model.PersistentClaimStorage;
 import io.strimzi.api.kafka.model.PersistentClaimStorageBuilder;
 import io.strimzi.api.kafka.model.SingleVolumeStorage;
-import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
@@ -101,7 +100,6 @@ private void init() {
                 .withCustomResourceDefinition(kafkaAssemblyCrd, Kafka.class, KafkaAssemblyList.class, DoneableKafka.class)
                 .end()
                 .build();
-        ResourceUtils.mockHttpClientForWorkaroundRbac(mockClient);
 
         Crds.kafkaOperation(this.mockClient).inNamespace(NAMESPACE).withName(NAME).create(this.kafka);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -231,8 +231,6 @@ public void before() {
 
         mockClient = new MockKube().withCustomResourceDefinition(kafkaAssemblyCrd, Kafka.class, KafkaAssemblyList.class, DoneableKafka.class)
                 .withInitialInstances(Collections.singleton(cluster)).end().build();
-        ResourceUtils.mockHttpClientForWorkaroundRbac(mockClient);
-
     }
 
     @After

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/MaintenanceTimeWindowsTest.java
Patch:
@@ -23,7 +23,6 @@
 import io.strimzi.api.kafka.model.KafkaResources;
 import io.strimzi.api.kafka.model.TopicOperatorSpec;
 import io.strimzi.api.kafka.model.TopicOperatorSpecBuilder;
-import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.Ca;
 import io.strimzi.operator.cluster.model.ClientsCa;
 import io.strimzi.operator.cluster.model.ClusterCa;
@@ -87,7 +86,6 @@ private void initMockClient() {
                 .withInitialInstances(Collections.singleton(this.kafka))
                 .end()
                 .build();
-        ResourceUtils.mockHttpClientForWorkaroundRbac(mockClient);
 
         this.clusterCaSecret = new SecretBuilder()
                 .withNewMetadata()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -116,7 +116,6 @@ public void before(TestContext context) {
                 .withInitialInstances(Collections.singleton(cluster))
                 .end()
                 .build();
-        ResourceUtils.mockHttpClientForWorkaroundRbac(bootstrapClient);
 
         ResourceOperatorSupplier supplier = supplier(bootstrapClient);
         KafkaAssemblyOperator kco = new KafkaAssemblyOperator(vertx, true, 2_000,
@@ -163,7 +162,6 @@ private void startKube() {
                 .withInitialPods(set(zkPod0, zkPod1, zkPod2, kafkaPod0, kafkaPod1, kafkaPod2, kafkaPod3, kafkaPod4))
                 .withInitialSecrets(set(clusterCaCert, clusterCaKey, clientsCaCert, clientsCaKey))
                 .build();
-        ResourceUtils.mockHttpClientForWorkaroundRbac(mockClient);
 
         ResourceOperatorSupplier supplier = supplier(mockClient);
 

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/PodDisruptionBudgetOperator.java
Patch:
@@ -24,6 +24,7 @@ protected MixedOperation<PodDisruptionBudget, PodDisruptionBudgetList, DoneableP
         return client.policy().podDisruptionBudget();
     }
 
+    @Override
     protected Future<ReconcileResult<PodDisruptionBudget>> internalPatch(String namespace, String name, PodDisruptionBudget current, PodDisruptionBudget desired, boolean cascading) {
         Future<ReconcileResult<PodDisruptionBudget>> fut = Future.future();
         internalDelete(namespace, name).setHandler(delRes -> {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -493,7 +493,8 @@ Future<ReconciliationState> kafkaUpgrade() {
                     log.debug("Does SS {} need to be upgraded?", ss.getMetadata().getName());
                     Future<?> result;
                     // Get the current version of the cluster
-                    KafkaVersion currentVersion = versions.version(Annotations.annotations(ss).get(ANNO_STRIMZI_IO_KAFKA_VERSION));
+                    // Strimzi 0.8.x and 0.9.0 didn't set the annotation, so if it's absent we know it must be 2.0.0
+                    KafkaVersion currentVersion = versions.version(Annotations.annotations(ss).getOrDefault(ANNO_STRIMZI_IO_KAFKA_VERSION, "2.0.0"));
                     log.debug("SS {} has current version {}", ss.getMetadata().getName(), currentVersion);
                     String fromVersionAnno = Annotations.annotations(ss).get(ANNO_STRIMZI_IO_FROM_VERSION);
                     KafkaVersion fromVersion;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -1187,19 +1187,19 @@ private List<ExternalListenerBrokerOverride> getExternalListenerBrokerOverride()
         if (isExposedWithNodePort()) {
             NodePortListenerOverride overrides = ((KafkaListenerExternalNodePort) listeners.getExternal()).getOverrides();
 
-            if (overrides != null) {
+            if (overrides != null && overrides.getBrokers() != null) {
                 brokerOverride.addAll(overrides.getBrokers());
             }
         } else if (isExposedWithLoadBalancer()) {
             LoadBalancerListenerOverride overrides = ((KafkaListenerExternalLoadBalancer) listeners.getExternal()).getOverrides();
 
-            if (overrides != null) {
+            if (overrides != null && overrides.getBrokers() != null) {
                 brokerOverride.addAll(overrides.getBrokers());
             }
         } else if (isExposedWithRoute()) {
             RouteListenerOverride overrides = ((KafkaListenerExternalRoute) listeners.getExternal()).getOverrides();
 
-            if (overrides != null) {
+            if (overrides != null && overrides.getBrokers() != null) {
                 brokerOverride.addAll(overrides.getBrokers());
             }
         }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaAuthorizationSimple.java
Patch:
@@ -9,6 +9,7 @@
 import io.strimzi.crdgenerator.annotations.Description;
 import io.strimzi.crdgenerator.annotations.Example;
 import io.sundr.builder.annotations.Buildable;
+import lombok.EqualsAndHashCode;
 
 import java.util.List;
 
@@ -22,6 +23,7 @@
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"type", "superUsers"})
+@EqualsAndHashCode
 public class KafkaAuthorizationSimple extends KafkaAuthorization {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectAuthenticationScramSha512.java
Patch:
@@ -8,6 +8,7 @@
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import io.sundr.builder.annotations.Buildable;
+import lombok.EqualsAndHashCode;
 
 /**
  * Configures the Kafka Connect authentication
@@ -18,6 +19,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@EqualsAndHashCode
 public class KafkaConnectAuthenticationScramSha512 extends KafkaConnectAuthentication {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectAuthenticationTls.java
Patch:
@@ -7,6 +7,7 @@
 import com.fasterxml.jackson.annotation.JsonInclude;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
+import lombok.EqualsAndHashCode;
 
 /**
  * Configures the Kafka Connect authentication
@@ -17,6 +18,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@EqualsAndHashCode
 public class KafkaConnectAuthenticationTls extends KafkaConnectAuthentication {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerAuthenticationScramSha512.java
Patch:
@@ -7,6 +7,7 @@
 import com.fasterxml.jackson.annotation.JsonInclude;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
+import lombok.EqualsAndHashCode;
 
 /**
  * Configures the Kafka Mirror Maker authentication
@@ -17,6 +18,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@EqualsAndHashCode
 public class KafkaMirrorMakerAuthenticationScramSha512 extends KafkaMirrorMakerAuthentication {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerAuthenticationTls.java
Patch:
@@ -7,6 +7,7 @@
 import com.fasterxml.jackson.annotation.JsonInclude;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
+import lombok.EqualsAndHashCode;
 
 /**
  * Configures the Kafka Mirror Maker authentication
@@ -17,6 +18,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@EqualsAndHashCode
 public class KafkaMirrorMakerAuthenticationTls extends KafkaMirrorMakerAuthentication {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerConsumerSpec.java
Patch:
@@ -11,6 +11,8 @@
 import io.strimzi.crdgenerator.annotations.Description;
 import io.strimzi.crdgenerator.annotations.Minimum;
 import io.sundr.builder.annotations.Buildable;
+import lombok.EqualsAndHashCode;
+
 import java.util.Map;
 
 @Buildable(
@@ -20,6 +22,7 @@
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({"numStreams", "groupId", "bootstrapServers", "logging"})
+@EqualsAndHashCode(callSuper = true)
 public class KafkaMirrorMakerConsumerSpec extends KafkaMirrorMakerClientSpec {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerProducerSpec.java
Patch:
@@ -8,6 +8,7 @@
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
+import lombok.EqualsAndHashCode;
 
 import java.util.Map;
 
@@ -18,6 +19,7 @@
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({ "bootstrapServers", "logging"})
+@EqualsAndHashCode(callSuper = true)
 public class KafkaMirrorMakerProducerSpec extends KafkaMirrorMakerClientSpec {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthenticationScramSha512.java
Patch:
@@ -7,6 +7,7 @@
 import com.fasterxml.jackson.annotation.JsonInclude;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
+import lombok.EqualsAndHashCode;
 
 /**
  * Configures a listener to use SASL SCRAM-SHA-512 for authentication.
@@ -17,6 +18,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@EqualsAndHashCode
 public class KafkaListenerAuthenticationScramSha512 extends KafkaListenerAuthentication {
 
     private static final long serialVersionUID = 1L;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthenticationTls.java
Patch:
@@ -8,6 +8,7 @@
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import io.sundr.builder.annotations.Buildable;
+import lombok.EqualsAndHashCode;
 
 /**
  * Configures a listener to use mutual TLS authentication.
@@ -18,6 +19,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@EqualsAndHashCode
 public class KafkaListenerAuthenticationTls extends KafkaListenerAuthentication {
     private static final long serialVersionUID = 1L;
 

File: api/src/test/java/io/strimzi/api/kafka/model/AbstractCrdIT.java
Patch:
@@ -17,7 +17,7 @@ protected <T extends CustomResource> void createDelete(Class<T> resourceClass, S
         String ssStr = TestUtils.readResource(resourceClass, resource);
         assertNotNull("Class path resource " + resource + " was missing", ssStr);
         createDelete(ssStr);
-        T model = TestUtils.fromYaml(resource, resourceClass, true);
+        T model = TestUtils.fromYaml(resource, resourceClass, false);
         ssStr = TestUtils.toYamlString(model);
         try {
             createDelete(ssStr);

File: api/src/test/java/io/strimzi/api/kafka/model/ExamplesTest.java
Patch:
@@ -123,6 +123,7 @@ private void checkForJsonAnyGetter(Stack<String> path, Object resource, Class<?>
             }
         } else {
             if (isGetter(method)) {
+                method.setAccessible(true);
                 Object result = method.invoke(resource);
                 if (result != null
                     && !result.getClass().isPrimitive()

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaConnectTest.java
Patch:
@@ -9,9 +9,9 @@
  *
  * 1. we get a correct tree of POJOs when reading a JSON/YAML `Kafka` resource.
  */
-public class KafkaConnectTest extends AbstractCrdTest<KafkaConnect, KafkaConnectBuilder> {
+public class KafkaConnectTest extends AbstractCrdTest<KafkaConnect> {
 
     public KafkaConnectTest() {
-        super(KafkaConnect.class, KafkaConnectBuilder.class);
+        super(KafkaConnect.class);
     }
 }

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaMirrorMakerTest.java
Patch:
@@ -9,9 +9,9 @@
  *
  * 1. we get a correct tree of POJOs when reading a JSON/YAML `KafkaMirrorMaker` resource.
  */
-public class KafkaMirrorMakerTest extends AbstractCrdTest<KafkaMirrorMaker, KafkaMirrorMakerBuilder> {
+public class KafkaMirrorMakerTest extends AbstractCrdTest<KafkaMirrorMaker> {
 
     public KafkaMirrorMakerTest() {
-        super(KafkaMirrorMaker.class, KafkaMirrorMakerBuilder.class);
+        super(KafkaMirrorMaker.class);
     }
 }

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaTest.java
Patch:
@@ -9,10 +9,10 @@
  *
  * 1. we get a correct tree of POJOs when reading a JSON/YAML `Kafka` resource.
  */
-public class KafkaTest extends AbstractCrdTest<Kafka, KafkaBuilder> {
+public class KafkaTest extends AbstractCrdTest<Kafka> {
 
     public KafkaTest() {
-        super(Kafka.class, KafkaBuilder.class);
+        super(Kafka.class);
     }
 
 }

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaTopicTest.java
Patch:
@@ -9,10 +9,10 @@
  *
  * 1. we get a correct tree of POJOs when reading a JSON/YAML `Kafka` resource.
  */
-public class KafkaTopicTest extends AbstractCrdTest<KafkaTopic, KafkaTopicBuilder> {
+public class KafkaTopicTest extends AbstractCrdTest<KafkaTopic> {
 
     public KafkaTopicTest() {
-        super(KafkaTopic.class, KafkaTopicBuilder.class);
+        super(KafkaTopic.class);
     }
 
 }

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaUserTest.java
Patch:
@@ -9,10 +9,10 @@
  *
  * 1. we get a correct tree of POJOs when reading a JSON/YAML `Kafka` resource.
  */
-public class KafkaUserTest extends AbstractCrdTest<KafkaUser, KafkaUserBuilder> {
+public class KafkaUserTest extends AbstractCrdTest<KafkaUser> {
 
     public KafkaUserTest() {
-        super(KafkaUser.class, KafkaUserBuilder.class);
+        super(KafkaUser.class);
     }
 
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -15,8 +15,8 @@
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.model.ImagePullPolicy;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
-import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.cluster.model.KafkaVersion;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.model.ResourceType;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -15,8 +15,8 @@
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.model.ImagePullPolicy;
 import io.strimzi.operator.cluster.model.KafkaConnectS2ICluster;
-import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.cluster.model.KafkaVersion;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.model.ResourceType;

File: systemtest/src/main/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -147,7 +147,7 @@ public static Map<String, String> waitTillDepHasRolled(KubernetesClient client,
     }
 
     public static File downloadAndUnzip(String url) throws IOException {
-        InputStream bais = (InputStream) URI.create(url).toURL().getContent();
+        InputStream bais = (InputStream) URI.create(url).toURL().openConnection().getContent();
         File dir = Files.createTempDirectory(StUtils.class.getName()).toFile();
         dir.deleteOnExit();
         ZipInputStream zin = new ZipInputStream(bais);

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorAssignedKafkaImplTest.java
Patch:
@@ -4,12 +4,12 @@
  */
 package io.strimzi.operator.topic;
 
-import io.strimzi.test.TestUtils;
 import io.vertx.core.Vertx;
 import io.vertx.ext.unit.Async;
 import io.vertx.ext.unit.TestContext;
 import io.vertx.ext.unit.junit.VertxUnitRunner;
 import org.apache.kafka.clients.admin.AdminClient;
+import org.junit.Assume;
 import org.junit.BeforeClass;
 import org.junit.Test;
 import org.junit.runner.RunWith;
@@ -110,7 +110,7 @@ protected void addJavaArgs(List<String> args) {
 
     @BeforeClass
     public static void setUp() throws Exception {
-        TestUtils.assumeLinux();
+        Assume.assumeTrue(System.getProperty("os.name").contains("nux") || System.getProperty("os.name").contains("Mac OS X"));
     }
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -60,7 +60,7 @@ class ConnectST extends AbstractST {
     private static Resources classResources;
 
     @Test
-    @Tag(ACCEPTANCE)
+    @Tag(REGRESSION)
     void testDeployUndeploy() {
         resources().kafkaConnect(KAFKA_CLUSTER_NAME, 1).done();
         LOGGER.info("Looks like the connect cluster my-cluster deployed OK");
@@ -75,7 +75,7 @@ void testDeployUndeploy() {
     }
 
     @Test
-    @Tag(REGRESSION)
+    @Tag(ACCEPTANCE)
     void testKafkaConnectWithFileSinkPlugin() {
         resources().kafkaConnect(KAFKA_CLUSTER_NAME, 1)
             .editMetadata()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -79,7 +79,7 @@ public static ClusterOperatorConfig fromMap(Map<String, String> map) {
         String namespacesList = map.get(ClusterOperatorConfig.STRIMZI_NAMESPACE);
         Set<String> namespaces;
         if (namespacesList == null || namespacesList.isEmpty()) {
-            throw new InvalidConfigurationException(ClusterOperatorConfig.STRIMZI_NAMESPACE + " cannot be null");
+            namespaces = Collections.singleton(AbstractWatchableResourceOperator.ANY_NAMESPACE);
         } else {
             if (namespacesList.trim().equals(AbstractWatchableResourceOperator.ANY_NAMESPACE)) {
                 namespaces = Collections.singleton(AbstractWatchableResourceOperator.ANY_NAMESPACE);

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -11,6 +11,7 @@
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.fabric8.kubernetes.api.model.Affinity;
 import io.fabric8.kubernetes.api.model.Toleration;
+import io.strimzi.api.kafka.model.listener.KafkaListeners;
 import io.strimzi.api.kafka.model.template.KafkaClusterTemplate;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.strimzi.crdgenerator.annotations.KubeLink;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthentication.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.api.kafka.model;
+package io.strimzi.api.kafka.model.listener;
 
 import com.fasterxml.jackson.annotation.JsonAnyGetter;
 import com.fasterxml.jackson.annotation.JsonAnySetter;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthenticationScramSha512.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.api.kafka.model;
+package io.strimzi.api.kafka.model.listener;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import io.strimzi.crdgenerator.annotations.Description;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerAuthenticationTls.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.api.kafka.model;
+package io.strimzi.api.kafka.model.listener;
 
 import io.strimzi.crdgenerator.annotations.Description;
 

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerExternal.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.api.kafka.model;
+package io.strimzi.api.kafka.model.listener;
 
 import com.fasterxml.jackson.annotation.JsonAnyGetter;
 import com.fasterxml.jackson.annotation.JsonAnySetter;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerPlain.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.api.kafka.model;
+package io.strimzi.api.kafka.model.listener;
 
 import com.fasterxml.jackson.annotation.JsonAnyGetter;
 import com.fasterxml.jackson.annotation.JsonAnySetter;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListenerTls.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.api.kafka.model;
+package io.strimzi.api.kafka.model.listener;
 
 import com.fasterxml.jackson.annotation.JsonAnyGetter;
 import com.fasterxml.jackson.annotation.JsonAnySetter;

File: api/src/main/java/io/strimzi/api/kafka/model/listener/KafkaListeners.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.api.kafka.model;
+package io.strimzi.api.kafka.model.listener;
 
 import io.strimzi.crdgenerator.annotations.Description;
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -18,8 +18,8 @@
 import io.strimzi.api.kafka.model.KafkaConnectBuilder;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaConnectS2IBuilder;
-import io.strimzi.api.kafka.model.KafkaListenerPlain;
-import io.strimzi.api.kafka.model.KafkaListenerTls;
+import io.strimzi.api.kafka.model.listener.KafkaListenerPlain;
+import io.strimzi.api.kafka.model.listener.KafkaListenerTls;
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerBuilder;
 import io.strimzi.api.kafka.model.KafkaMirrorMakerConsumerSpec;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -27,14 +27,14 @@
 import io.strimzi.api.kafka.model.InlineLogging;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
-import io.strimzi.api.kafka.model.KafkaListeners;
-import io.strimzi.api.kafka.model.KafkaListenersBuilder;
+import io.strimzi.api.kafka.model.listener.KafkaListeners;
 import io.strimzi.api.kafka.model.PersistentClaimStorage;
 import io.strimzi.api.kafka.model.PersistentClaimStorageBuilder;
 import io.strimzi.api.kafka.model.SingleVolumeStorage;
 import io.strimzi.api.kafka.model.Storage;
 import io.strimzi.api.kafka.model.TopicOperatorSpec;
 import io.strimzi.api.kafka.model.TopicOperatorSpecBuilder;
+import io.strimzi.api.kafka.model.listener.KafkaListenersBuilder;
 import io.strimzi.operator.cluster.ClusterOperator;
 import io.strimzi.operator.cluster.ClusterOperatorConfig;
 import io.strimzi.operator.cluster.ResourceUtils;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -128,8 +128,6 @@ public static ClusterOperatorConfig fromMap(Map<String, String> map) {
                             + " is not a valid " + ClusterOperatorConfig.STRIMZI_IMAGE_PULL_POLICY + " value. " +
                             ClusterOperatorConfig.STRIMZI_IMAGE_PULL_POLICY + " can have one of the following values: Always, IfNotPresent, Never.");
             }
-
-            createClusterRoles = Boolean.parseBoolean(createClusterRolesEnvVar);
         }
 
         KafkaVersion.Lookup lookup = new KafkaVersion.Lookup(

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -128,8 +128,6 @@ public static ClusterOperatorConfig fromMap(Map<String, String> map) {
                             + " is not a valid " + ClusterOperatorConfig.STRIMZI_IMAGE_PULL_POLICY + " value. " +
                             ClusterOperatorConfig.STRIMZI_IMAGE_PULL_POLICY + " can have one of the following values: Always, IfNotPresent, Never.");
             }
-
-            createClusterRoles = Boolean.parseBoolean(createClusterRolesEnvVar);
         }
 
         KafkaVersion.Lookup lookup = new KafkaVersion.Lookup(

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorIT.java
Patch:
@@ -164,7 +164,7 @@ public void setup(TestContext context) throws Exception {
         });
         async.await();
 
-        waitFor(context, () -> this.topicsWatcher.started(), timeout, "Topics watcher not started");
+        waitFor(context, () -> this.topicWatcher.started(), timeout, "Topic watcher not started");
         waitFor(context, () -> this.topicsConfigWatcher.started(), timeout, "Topic configs watcher not started");
         waitFor(context, () -> this.topicWatcher.started(), timeout, "Topic watcher not started");
 

File: certificate-manager/src/test/java/io/strimzi/certs/OpenSslCertManagerTest.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.certs;
 
-import io.strimzi.test.TestUtils;
+import org.junit.Assume;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -34,14 +34,13 @@ public class OpenSslCertManagerTest {
 
     @BeforeClass
     public static void before() throws CertificateException {
-        TestUtils.assumeLinux();
+        Assume.assumeTrue(System.getProperty("os.name").contains("nux"));
         certFactory = CertificateFactory.getInstance("X.509");
         ssl = new OpenSslCertManager();
     }
 
     @Test
     public void testGenerateSelfSignedCert() throws Exception {
-
         File key = File.createTempFile("key-", ".key");
         File cert = File.createTempFile("crt-", ".crt");
 

File: certificate-manager/src/test/java/io/strimzi/certs/SecretCertProviderTest.java
Patch:
@@ -7,7 +7,7 @@
 import io.fabric8.kubernetes.api.model.OwnerReference;
 import io.fabric8.kubernetes.api.model.OwnerReferenceBuilder;
 import io.fabric8.kubernetes.api.model.Secret;
-import io.strimzi.test.TestUtils;
+import org.junit.Assume;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -29,7 +29,7 @@ public class SecretCertProviderTest {
 
     @BeforeClass
     public static void before() {
-        TestUtils.assumeLinux();
+        Assume.assumeTrue(System.getProperty("os.name").contains("nux"));
         ssl = new OpenSslCertManager();
         secretCertProvider = new SecretCertProvider();
         ownerReference = new OwnerReferenceBuilder()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -209,7 +209,7 @@ public static EntityTopicOperator fromCrd(Kafka kafkaAssembly) {
     }
 
     @Override
-    protected List<Container> getContainers() {
+    protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
 
         return Collections.singletonList(new ContainerBuilder()
                 .withName(TOPIC_OPERATOR_CONTAINER_NAME)
@@ -220,6 +220,7 @@ protected List<Container> getContainers() {
                 .withReadinessProbe(createHttpProbe(readinessPath + "ready", HEALTHCHECK_PORT_NAME, readinessInitialDelay, readinessTimeout))
                 .withResources(ModelUtils.resources(getResources()))
                 .withVolumeMounts(getVolumeMounts())
+                .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))
                 .build());
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -199,7 +199,7 @@ public static EntityUserOperator fromCrd(Kafka kafkaAssembly) {
     }
 
     @Override
-    protected List<Container> getContainers() {
+    protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
 
         return Collections.singletonList(new ContainerBuilder()
                 .withName(USER_OPERATOR_CONTAINER_NAME)
@@ -210,6 +210,7 @@ protected List<Container> getContainers() {
                 .withReadinessProbe(createHttpProbe(readinessPath + "ready", HEALTHCHECK_PORT_NAME, readinessInitialDelay, readinessTimeout))
                 .withResources(ModelUtils.resources(getResources()))
                 .withVolumeMounts(getVolumeMounts())
+                .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, getImage()))
                 .build());
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -66,7 +66,7 @@ public static KafkaConnectS2ICluster fromCrd(KafkaConnectS2I kafkaConnectS2I, Ka
      *
      * @return      Source ImageStream resource definition
      */
-    public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations, boolean isOpenShift) {
+    public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations, boolean isOpenShift, ImagePullPolicy imagePullPolicy) {
         Container container = new ContainerBuilder()
                 .withName(name)
                 .withImage(image)
@@ -76,6 +76,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                 .withReadinessProbe(createHttpProbe(readinessPath, REST_API_PORT_NAME, readinessInitialDelay, readinessTimeout))
                 .withVolumeMounts(getVolumeMounts())
                 .withResources(ModelUtils.resources(getResources()))
+                .withImagePullPolicy(determineImagePullPolicy(imagePullPolicy, image))
                 .build();
 
         DeploymentTriggerPolicy configChangeTrigger = new DeploymentTriggerPolicyBuilder()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetDiff.java
Patch:
@@ -22,13 +22,11 @@ public class StatefulSetDiff {
     private static final Pattern IGNORABLE_PATHS = Pattern.compile(
         "^(/spec/revisionHistoryLimit"
         + "|/spec/template/metadata/annotations"  // Actually it's only the statefulset-generation annotation we care about
-        + "|/spec/template/spec/initContainers/[0-9]+/imagePullPolicy"
         + "|/spec/template/spec/initContainers/[0-9]+/resources"
         + "|/spec/template/spec/initContainers/[0-9]+/terminationMessagePath"
         + "|/spec/template/spec/initContainers/[0-9]+/terminationMessagePolicy"
         + "|/spec/template/spec/initContainers/[0-9]+/env/[0-9]+/valueFrom/fieldRef/apiVersion"
         + "|/spec/template/spec/containers/[0-9]+/env/[0-9]+/valueFrom/fieldRef/apiVersion"
-        + "|/spec/template/spec/containers/[0-9]+/imagePullPolicy"
         + "|/spec/template/spec/containers/[0-9]+/livenessProbe/failureThreshold"
         + "|/spec/template/spec/containers/[0-9]+/livenessProbe/periodSeconds"
         + "|/spec/template/spec/containers/[0-9]+/livenessProbe/successThreshold"

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -155,7 +155,7 @@ public void testFromCrdNoTopicOperatorInEntityOperator() {
 
     @Test
     public void testGetContainers() {
-        List<Container> containers = entityTopicOperator.getContainers();
+        List<Container> containers = entityTopicOperator.getContainers(null);
         assertEquals(1, containers.size());
 
         Container container = containers.get(0);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -150,7 +150,7 @@ public void testFromCrdNoUserOperatorInEntityOperator() {
 
     @Test
     public void testGetContainers() {
-        List<Container> containers = entityUserOperator.getContainers();
+        List<Container> containers = entityUserOperator.getContainers(null);
         assertEquals(1, containers.size());
 
         Container container = containers.get(0);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ModelUtilsTest.java
Patch:
@@ -122,7 +122,7 @@ protected String getDefaultLogConfigFileName() {
         }
 
         @Override
-        protected List<Container> getContainers() {
+        protected List<Container> getContainers(ImagePullPolicy imagePullPolicy) {
             return null;
         }
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -101,7 +101,7 @@ private ArgumentCaptor<Secret> reconcileCa(TestContext context, CertificateAutho
                 new ResourceOperatorSupplier(null, null, null,
                         null, null, secretOps, null, null,
                         null, null, null, null, null, null),
-                new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap()));
+                new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap()), null);
         Reconciliation reconciliation = new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, NAME);
 
         Kafka kafka = new KafkaBuilder()

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/JbodStorageTest.java
Patch:
@@ -108,7 +108,7 @@ private void init() {
         ResourceOperatorSupplier ros =
                 new ResourceOperatorSupplier(this.vertx, this.mockClient, false, 60_000L);
 
-        this.kao = new KafkaAssemblyOperator(this.vertx, false, 2_000, new MockCertManager(), ros, VERSIONS);
+        this.kao = new KafkaAssemblyOperator(this.vertx, false, 2_000, new MockCertManager(), ros, VERSIONS, null);
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -250,7 +250,7 @@ private ResourceOperatorSupplier supplierWithMocks() {
     private KafkaAssemblyOperator createCluster(TestContext context) {
         ResourceOperatorSupplier supplier = supplierWithMocks();
         KafkaAssemblyOperator kco = new KafkaAssemblyOperator(vertx, true, 2_000,
-                new MockCertManager(), supplier, VERSIONS);
+                new MockCertManager(), supplier, VERSIONS, null);
 
         LOGGER.info("Reconciling initially -> create");
         Async createAsync = context.async();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -97,7 +97,7 @@ private KafkaConnectAssemblyOperator createConnectCluster(TestContext context) {
         KafkaConnectAssemblyOperator kco = new KafkaConnectAssemblyOperator(vertx, true,
                 new MockCertManager(),
                 connectOperator,
-                cmops, depops, svcops, secretops, policyops, pdbops, VERSIONS);
+                cmops, depops, svcops, secretops, policyops, pdbops, VERSIONS, null);
 
         LOGGER.info("Reconciling initially -> create");
         Async createAsync = context.async();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -129,7 +129,7 @@ private List<StatefulSet> upgrade(TestContext context, Map<String, String> versi
                                       Consumer<Integer> reconcileExceptions, Consumer<Integer> rollExceptions) {
         KafkaSetOperator kso = mock(KafkaSetOperator.class);
 
-        StatefulSet kafkaSs = initialSs != null ? initialSs : KafkaCluster.fromCrd(initialKafka, lookup).generateStatefulSet(false);
+        StatefulSet kafkaSs = initialSs != null ? initialSs : KafkaCluster.fromCrd(initialKafka, lookup).generateStatefulSet(false, null);
 
         List<StatefulSet> states = new ArrayList<>(2);
         when(kso.reconcile(anyString(), anyString(), any(StatefulSet.class))).thenAnswer(invocation -> {
@@ -151,7 +151,7 @@ private List<StatefulSet> upgrade(TestContext context, Map<String, String> versi
                 new ResourceOperatorSupplier(null, null, null,
                         kso, null, null, null, null,
                         null, null, null, null, null, null),
-                lookup);
+                lookup, null);
         Reconciliation reconciliation = new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, NAME);
 
         Async async = context.async();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -118,7 +118,7 @@ public void before(TestContext context) {
 
         ResourceOperatorSupplier supplier = supplier(bootstrapClient);
         KafkaAssemblyOperator kco = new KafkaAssemblyOperator(vertx, true, 2_000,
-                new MockCertManager(), supplier, VERSIONS);
+                new MockCertManager(), supplier, VERSIONS, null);
 
         LOGGER.info("bootstrap reconciliation");
         Async createAsync = context.async();
@@ -165,7 +165,7 @@ private void startKube() {
         ResourceOperatorSupplier supplier = supplier(mockClient);
 
         this.kco = new KafkaAssemblyOperator(vertx, true, 2_000,
-                new MockCertManager(), supplier, VERSIONS);
+                new MockCertManager(), supplier, VERSIONS, null);
         LOGGER.info("Started test KafkaAssemblyOperator");
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -41,8 +41,8 @@ public class KafkaSetOperatorTest {
     @Before
     public void before() {
         KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
-        a = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true);
-        b = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true);
+        a = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null);
+        b = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null);
     }
 
     private Kafka getResource() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperatorTest.java
Patch:
@@ -31,8 +31,8 @@ public class ZookeeperSetOperatorTest {
     @Before
     public void before() {
         KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
-        a = ZookeeperCluster.fromCrd(getResource(), versions).generateStatefulSet(true);
-        b = ZookeeperCluster.fromCrd(getResource(), versions).generateStatefulSet(true);
+        a = ZookeeperCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null);
+        b = ZookeeperCluster.fromCrd(getResource(), versions).generateStatefulSet(true, null);
     }
 
     private Kafka getResource() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetDiff.java
Patch:
@@ -27,7 +27,6 @@ public class StatefulSetDiff {
         + "|/spec/template/spec/initContainers/[0-9]+/terminationMessagePath"
         + "|/spec/template/spec/initContainers/[0-9]+/terminationMessagePolicy"
         + "|/spec/template/spec/initContainers/[0-9]+/env/[0-9]+/valueFrom/fieldRef/apiVersion"
-        + "|/spec/template/spec/initContainers/[0-9]+/env/[0-9]+/value"
         + "|/spec/template/spec/containers/[0-9]+/env/[0-9]+/valueFrom/fieldRef/apiVersion"
         + "|/spec/template/spec/containers/[0-9]+/imagePullPolicy"
         + "|/spec/template/spec/containers/[0-9]+/livenessProbe/failureThreshold"

File: kafka-init/src/main/java/io/strimzi/kafka/init/Main.java
Patch:
@@ -33,6 +33,7 @@ public static void main(String[] args) {
             if (!writer.writeExternalAddress()) {
                 System.exit(1);
             }
+            writer.writeExternalBrokerAddresses();
         }
 
         client.close();

File: api/src/main/java/io/strimzi/api/kafka/model/CertificateAuthority.java
Patch:
@@ -36,6 +36,8 @@ public class CertificateAuthority implements Serializable {
     private int renewalDays;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
     private CertificateExpirationPolicy certificateExpirationPolicy;
+    public static final int DEFAULT_CERTS_VALIDITY_DAYS = 365;
+    public static final int DEFAULT_CERTS_RENEWAL_DAYS = 30;
 
     @Description("The number of days generated certificates should be valid for. The default is 365.")
     @Minimum(1)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -81,7 +81,6 @@ public abstract class AbstractModel {
 
     protected static final Logger log = LogManager.getLogger(AbstractModel.class.getName());
 
-    protected static final int CERTS_EXPIRATION_DAYS = 365;
     protected static final String DEFAULT_JVM_XMS = "128M";
 
     private static final Long DEFAULT_FS_GROUPID = 0L;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ModelUtils.java
Patch:
@@ -57,7 +57,7 @@ public static Secret findSecretWithName(List<Secret> secrets, String sname) {
     }
 
     public static int getCertificateValidity(CertificateAuthority certificateAuthority) {
-        int validity = AbstractModel.CERTS_EXPIRATION_DAYS;
+        int validity = CertificateAuthority.DEFAULT_CERTS_VALIDITY_DAYS;
         if (certificateAuthority != null
                 && certificateAuthority.getValidityDays() > 0) {
             validity = certificateAuthority.getValidityDays();
@@ -66,7 +66,7 @@ public static int getCertificateValidity(CertificateAuthority certificateAuthori
     }
 
     public static int getRenewalDays(CertificateAuthority certificateAuthority) {
-        return certificateAuthority != null ? certificateAuthority.getRenewalDays() : 30;
+        return certificateAuthority != null ? certificateAuthority.getRenewalDays() : CertificateAuthority.DEFAULT_CERTS_RENEWAL_DAYS;
     }
 
     /**

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaClusterSpec.java
Patch:
@@ -71,7 +71,7 @@ public class KafkaClusterSpec implements Serializable {
     private Probe livenessProbe;
     private Probe readinessProbe;
     private JvmOptions jvmOptions;
-    private Map<String, Object> metrics = new HashMap<>(0);
+    private Map<String, Object> metrics;
     private Affinity affinity;
     private List<Toleration> tolerations;
     private KafkaListeners listeners;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectSpec.java
Patch:
@@ -48,7 +48,7 @@ public class KafkaConnectSpec implements Serializable {
     private Probe livenessProbe;
     private Probe readinessProbe;
     private JvmOptions jvmOptions;
-    private Map<String, Object> metrics = new HashMap<>(0);
+    private Map<String, Object> metrics;
     private Affinity affinity;
     private List<Toleration> tolerations;
     private String bootstrapServers;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -48,7 +48,7 @@ public class KafkaMirrorMakerSpec implements Serializable {
     private List<Toleration> tolerations;
     private JvmOptions jvmOptions;
     private Logging logging;
-    private Map<String, Object> metrics = new HashMap<>(0);
+    private Map<String, Object> metrics;
     private KafkaMirrorMakerTemplate template;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 

File: api/src/main/java/io/strimzi/api/kafka/model/ZookeeperClusterSpec.java
Patch:
@@ -62,7 +62,7 @@ public class ZookeeperClusterSpec implements Serializable {
     private Probe livenessProbe;
     private Probe readinessProbe;
     private JvmOptions jvmOptions;
-    private Map<String, Object> metrics = new HashMap<>(0);
+    private Map<String, Object> metrics;
     private Affinity affinity;
     private List<Toleration> tolerations;
     private ZookeeperClusterTemplate template;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -437,10 +437,10 @@ private List<Volume> getVolumes(boolean isOpenShift) {
         return volumeList;
     }
 
-    private List<PersistentVolumeClaim> getVolumeClaims() {
+    /* test */ List<PersistentVolumeClaim> getVolumeClaims() {
         List<PersistentVolumeClaim> pvcList = new ArrayList<>();
         if (storage instanceof PersistentClaimStorage) {
-            pvcList.add(createPersistentVolumeClaim(VOLUME_NAME));
+            pvcList.add(createPersistentVolumeClaim(VOLUME_NAME, (PersistentClaimStorage) storage));
         }
         return pvcList;
     }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -75,7 +75,7 @@ void deleteTestResources() throws Exception {
     @BeforeAll
     static void createClassResources() {
         LOGGER.info("Creating resources before the test class");
-        applyRoleBindings(NAMESPACE, NAMESPACE);
+        applyRoleBindings(NAMESPACE);
         // 050-Deployment
         testClassResources.clusterOperator(NAMESPACE).done();
 

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -161,7 +161,6 @@ void testKafkaAndZookeeperScaleUpScaleDown() {
         // scale down
         LOGGER.info("Scaling down");
         operationID = startTimeMeasuring(Operation.SCALE_DOWN);
-        //client.apps().statefulSets().inNamespace(DEFAULT_NAMESPACE).withName(kafkaStatefulSetName(CLUSTER_NAME)).scale(initialReplicas, true);
         replaceKafkaResource(CLUSTER_NAME, k -> {
             k.getSpec().getKafka().setReplicas(initialReplicas);
         });
@@ -996,7 +995,7 @@ void deleteTestResources() throws Exception {
 
     @BeforeAll
     static void createClusterOperator() {
-        applyRoleBindings(NAMESPACE, NAMESPACE);
+        applyRoleBindings(NAMESPACE);
         // 050-Deployment
         testClassResources.clusterOperator(NAMESPACE).done();
     }

File: systemtest/src/test/java/io/strimzi/systemtest/RecoveryST.java
Patch:
@@ -188,7 +188,7 @@ void testRecoveryFromZookeeperMetricsConfigDeletion() {
     @BeforeAll
     static void createClassResources(TestInfo testInfo) {
         LOGGER.info("Creating resources before the test class");
-        applyRoleBindings(NAMESPACE, NAMESPACE);
+        applyRoleBindings(NAMESPACE);
         // 050-Deployment
         testClassResources.clusterOperator(NAMESPACE).done();
 

File: systemtest/src/test/java/io/strimzi/systemtest/SecurityST.java
Patch:
@@ -495,7 +495,7 @@ void deleteTestResources() throws Exception {
 
     @BeforeAll
     static void createClusterOperator() {
-        applyRoleBindings(NAMESPACE, NAMESPACE);
+        applyRoleBindings(NAMESPACE);
         // 050-Deployment
         testClassResources.clusterOperator(NAMESPACE).done();
     }

File: systemtest/src/test/java/io/strimzi/systemtest/StrimziUpgradeST.java
Patch:
@@ -166,7 +166,7 @@ void deleteTestResources() throws Exception {
 
     @BeforeAll
     static void createClusterOperator() {
-        applyRoleBindings(NAMESPACE, NAMESPACE);
+        applyRoleBindings(NAMESPACE);
         // 050-Deployment
         testClassResources.clusterOperator(NAMESPACE).done();
     }

File: systemtest/src/test/java/io/strimzi/systemtest/UserST.java
Patch:
@@ -104,7 +104,7 @@ void deleteTestResources() throws Exception {
 
     @BeforeAll
     static void createClusterOperator() {
-        applyRoleBindings(NAMESPACE, NAMESPACE);
+        applyRoleBindings(NAMESPACE);
         // 050-Deployment
         testClassResources.clusterOperator(NAMESPACE).done();
     }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -360,7 +360,7 @@ private List<List<String>> commandLines(String podName, String cmd) {
 
     void assertNoCoErrorsLogged(long sinceSeconds) {
         LOGGER.info("Search in strimzi-cluster-operator log for errors in last {} seconds", sinceSeconds);
-        String clusterOperatorLog = kubeClient.searchInLog("deploy", "strimzi-cluster-operator", sinceSeconds, "Exception", "Error", "Throwable");
+        String clusterOperatorLog = kubeClient.searchInLog("deploy", "strimzi-cluster-operator", sinceSeconds, "Exception", "ERROR", "Throwable");
         assertThat(clusterOperatorLog, logHasNoUnexpectedErrors());
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/Resources.java
Patch:
@@ -245,7 +245,7 @@ public KafkaBuilder defaultKafka(String name, int kafkaReplicas) {
                             .withMetrics(new HashMap<>())
                         .endKafka()
                         .withNewZookeeper()
-                            .withReplicas(1)
+                            .withReplicas(3)
                             .withNewResources()
                                 .withNewRequests()
                                     .withMemory("1G")
@@ -614,6 +614,8 @@ DeploymentBuilder defaultCLusterOperator(String namespace) {
                     envVar.setValue(namespace);
                     envVar.setValueFrom(null);
                     break;
+                case "STRIMZI_FULL_RECONCILIATION_INTERVAL_MS":
+                    envVar.setValue("30000");
                 default:
                     if (envVar.getName().contains("STRIMZI_DEFAULT")) {
                         envVar.setValue(TestUtils.changeOrgAndTag(envVar.getValue()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -235,7 +235,7 @@ public void testDeleteClaim() {
         ka = new KafkaBuilder(ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, configurationJson, zooConfigurationJson))
                 .editSpec()
                     .editZookeeper()
-                        .withNewPersistentClaimStorageStorage().withDeleteClaim(true).endPersistentClaimStorageStorage()
+                        .withNewPersistentClaimStorageStorage().withDeleteClaim(true).withSize("100Gi").endPersistentClaimStorageStorage()
                     .endZookeeper()
                 .endSpec()
             .build();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -464,6 +464,7 @@ public void testUpdateKafkaWithChangedPersistentVolume(TestContext context) {
         Kafka changedClusterCm = new KafkaBuilder(cluster).editSpec().editKafka()
                 .withNewPersistentClaimStorageStorage()
                     .withStorageClass(changedClass)
+                    .withSize("100Gi")
                 .endPersistentClaimStorageStorage().endKafka().endSpec().build();
         kafkaAssembly(NAMESPACE, CLUSTER_NAME).patch(changedClusterCm);
 
@@ -594,6 +595,7 @@ public void testUpdateKafkaWithChangedDeleteClaim(TestContext context) {
         Kafka changedClusterCm = new KafkaBuilder(cluster).editSpec().editKafka()
                 .withNewPersistentClaimStorageStorage()
                 .withDeleteClaim(!originalKafkaDeleteClaim)
+                .withSize("100Gi")
                 .endPersistentClaimStorageStorage().endKafka().endSpec().build();
         kafkaAssembly(NAMESPACE, CLUSTER_NAME).patch(changedClusterCm);
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/K8sImpl.java
Patch:
@@ -55,7 +55,7 @@ public void createResource(KafkaTopic topicResource, Handler<AsyncResult<Void>>
     public void updateResource(KafkaTopic topicResource, Handler<AsyncResult<Void>> handler) {
         vertx.executeBlocking(future -> {
             try {
-                operation().inNamespace(namespace).createOrReplace(topicResource);
+                operation().inNamespace(namespace).withName(topicResource.getMetadata().getName()).patch(topicResource);
                 future.complete();
             } catch (Exception e) {
                 future.fail(e);

File: topic-operator/src/test/java/io/strimzi/operator/topic/MockKafka.java
Patch:
@@ -115,7 +115,8 @@ public void createTopic(Topic t, Handler<AsyncResult<Void>> handler) {
             Topic.Builder topicBuilder = new Topic.Builder()
                     .withTopicName(newTopic.name())
                     .withNumPartitions(newTopic.numPartitions())
-                    .withNumReplicas(newTopic.replicationFactor());
+                    .withNumReplicas(newTopic.replicationFactor())
+                    .withMetadata(t.getMetadata());
             try {
                 Field field = NewTopic.class.getDeclaredField("configs");
                 field.setAccessible(true);

File: api/src/main/java/io/strimzi/api/kafka/model/EphemeralStorage.java
Patch:
@@ -17,7 +17,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
-public class EphemeralStorage extends Storage {
+public class EphemeralStorage extends SingleVolumeStorage {
 
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/PersistentClaimStorage.java
Patch:
@@ -22,7 +22,7 @@
 )
 @JsonPropertyOrder({"type", "size", "storageClass", "selector", "deleteClaim"})
 @JsonInclude(JsonInclude.Include.NON_NULL)
-public class PersistentClaimStorage extends Storage {
+public class PersistentClaimStorage extends SingleVolumeStorage {
 
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/ZookeeperClusterSpec.java
Patch:
@@ -49,7 +49,7 @@ public class ZookeeperClusterSpec implements Serializable {
             System.getenv().getOrDefault("STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE", "strimzi/zookeeper-stunnel:latest");
     public static final int DEFAULT_REPLICAS = 3;
 
-    protected Storage storage;
+    protected SingleVolumeStorage storage;
 
     private Map<String, Object> config = new HashMap<>(0);
 
@@ -80,11 +80,11 @@ public void setConfig(Map<String, Object> config) {
 
     @Description("Storage configuration (disk). Cannot be updated.")
     @JsonProperty(required = true)
-    public Storage getStorage() {
+    public SingleVolumeStorage getStorage() {
         return storage;
     }
 
-    public void setStorage(Storage storage) {
+    public void setStorage(SingleVolumeStorage storage) {
         this.storage = storage;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -477,7 +477,7 @@ public AbstractConfiguration getConfiguration() {
 
     /**
      * Set the configuration object which might be passed to the cluster as EnvVar
-     *
+     *getPersistentVolumeClaimName
      * @param configuration Configuration object with cluster configuration
      */
     protected void setConfiguration(AbstractConfiguration configuration) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -75,7 +75,7 @@ public class ZookeeperClusterTest {
             .withReadinessProbe(new ProbeBuilder().withInitialDelaySeconds(tlsHealthDelay).withTimeoutSeconds(tlsHealthTimeout).build())
             .build();
 
-    private final Kafka ka = new KafkaBuilder(ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, configurationJson, zooConfigurationJson, null, null, kafkaLogConfigJson, zooLogConfigJson))
+    private final Kafka ka = new KafkaBuilder(ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, configurationJson, zooConfigurationJson, null, null, null, kafkaLogConfigJson, zooLogConfigJson))
             .editSpec()
                 .editZookeeper()
                     .withTlsSidecar(tlsSidecar)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -57,7 +57,7 @@ public static KafkaConnectS2ICluster fromCrd(KafkaConnectS2I kafkaConnectS2I, Ka
                 Labels.fromResource(kafkaConnectS2I).withKind(kafkaConnectS2I.getKind())));
 
         cluster.setOwnerReference(kafkaConnectS2I);
-        cluster.setInsecureSourceRepository(spec != null ? spec.isInsecureSourceRepository() : false);
+        cluster.setInsecureSourceRepository(spec.isInsecureSourceRepository());
 
         return cluster;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/CertificateRenewalTest.java
Patch:
@@ -91,7 +91,7 @@ private ArgumentCaptor<Secret> reconcileCa(TestContext context, CertificateAutho
         KafkaAssemblyOperator op = new KafkaAssemblyOperator(vertx, false, 1L, certManager,
                 new ResourceOperatorSupplier(null, null, null,
                         null, null, secretOps, null, null,
-                        null, null, null, null, null),
+                        null, null, null, null, null, null),
                 new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap()));
         Reconciliation reconciliation = new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, NAME);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaUpdateTest.java
Patch:
@@ -150,7 +150,7 @@ private List<StatefulSet> upgrade(TestContext context, Map<String, String> versi
                 new MockCertManager(),
                 new ResourceOperatorSupplier(null, null, null,
                         kso, null, null, null, null,
-                        null, null, null, null, null),
+                        null, null, null, null, null, null),
                 lookup);
         Reconciliation reconciliation = new Reconciliation("test-trigger", ResourceType.KAFKA, NAMESPACE, NAME);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -6,6 +6,7 @@
 
 import io.fabric8.kubernetes.api.model.Container;
 import io.fabric8.kubernetes.api.model.ContainerBuilder;
+import io.fabric8.kubernetes.api.model.LifecycleBuilder;
 import io.fabric8.kubernetes.api.model.Secret;
 import io.fabric8.kubernetes.api.model.ServiceAccount;
 import io.fabric8.kubernetes.api.model.ServiceAccountBuilder;
@@ -218,6 +219,7 @@ protected List<Container> getContainers() {
                         buildEnvVar(ENV_VAR_ZOOKEEPER_CONNECT, zookeeperConnect)))
                 .withVolumeMounts(createVolumeMount(TLS_SIDECAR_EO_CERTS_VOLUME_NAME, TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT),
                         createVolumeMount(TLS_SIDECAR_CA_CERTS_VOLUME_NAME, TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT))
+                .withLifecycle(new LifecycleBuilder().withNewPreStop().withNewExec().withCommand("/opt/stunnel/stunnel_pre_stop.sh", String.valueOf(templateTerminationGracePeriodSeconds)).endExec().endPreStop().build())
                 .build();
 
         containers.add(tlsSidecarContainer);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -12,6 +12,7 @@
 import io.fabric8.kubernetes.api.model.EnvVar;
 import io.fabric8.kubernetes.api.model.IntOrString;
 import io.fabric8.kubernetes.api.model.LabelSelector;
+import io.fabric8.kubernetes.api.model.LifecycleBuilder;
 import io.fabric8.kubernetes.api.model.PersistentVolumeClaim;
 import io.fabric8.kubernetes.api.model.Quantity;
 import io.fabric8.kubernetes.api.model.ResourceRequirements;
@@ -761,6 +762,7 @@ protected List<Container> getContainers() {
                         ModelUtils.tlsSidecarLogEnvVar(tlsSidecar)))
                 .withVolumeMounts(createVolumeMount(BROKER_CERTS_VOLUME, TLS_SIDECAR_KAFKA_CERTS_VOLUME_MOUNT),
                         createVolumeMount(CLUSTER_CA_CERTS_VOLUME, TLS_SIDECAR_CLUSTER_CA_CERTS_VOLUME_MOUNT))
+                .withLifecycle(new LifecycleBuilder().withNewPreStop().withNewExec().withCommand("/opt/stunnel/stunnel_pre_stop.sh", String.valueOf(templateTerminationGracePeriodSeconds)).endExec().endPreStop().build())
                 .build();
 
         containers.add(container);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -10,6 +10,7 @@
 import io.fabric8.kubernetes.api.model.EnvVar;
 import io.fabric8.kubernetes.api.model.IntOrString;
 import io.fabric8.kubernetes.api.model.LabelSelector;
+import io.fabric8.kubernetes.api.model.LifecycleBuilder;
 import io.fabric8.kubernetes.api.model.PersistentVolumeClaim;
 import io.fabric8.kubernetes.api.model.Secret;
 import io.fabric8.kubernetes.api.model.Service;
@@ -388,6 +389,7 @@ protected List<Container> getContainers() {
                 .withPorts(asList(createContainerPort(CLUSTERING_PORT_NAME, CLUSTERING_PORT, "TCP"),
                                 createContainerPort(LEADER_ELECTION_PORT_NAME, LEADER_ELECTION_PORT, "TCP"),
                                 createContainerPort(CLIENT_PORT_NAME, CLIENT_PORT, "TCP")))
+                .withLifecycle(new LifecycleBuilder().withNewPreStop().withNewExec().withCommand("/opt/stunnel/stunnel_pre_stop.sh", String.valueOf(templateTerminationGracePeriodSeconds)).endExec().endPreStop().build())
                 .build();
 
         containers.add(container);

File: api/src/main/java/io/strimzi/api/kafka/model/template/EntityOperatorTemplate.java
Patch:
@@ -30,7 +30,7 @@ public class EntityOperatorTemplate implements Serializable {
     private static final long serialVersionUID = 1L;
 
     private ResourceTemplate deployment;
-    private ResourceTemplate pod;
+    private PodTemplate pod;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Description("Template for Entity Operator `Deployment`.")
@@ -45,11 +45,11 @@ public void setDeployment(ResourceTemplate deployment) {
 
     @Description("Template for Entity Operator `Pods`.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public ResourceTemplate getPod() {
+    public PodTemplate getPod() {
         return pod;
     }
 
-    public void setPod(ResourceTemplate pod) {
+    public void setPod(PodTemplate pod) {
         this.pod = pod;
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/template/KafkaClusterTemplate.java
Patch:
@@ -30,7 +30,7 @@ public class KafkaClusterTemplate implements Serializable {
     private static final long serialVersionUID = 1L;
 
     private ResourceTemplate statefulset;
-    private ResourceTemplate pod;
+    private PodTemplate pod;
     private ResourceTemplate bootstrapService;
     private ResourceTemplate brokersService;
     private ResourceTemplate externalBootstrapService;
@@ -51,11 +51,11 @@ public void setStatefulset(ResourceTemplate statefulset) {
 
     @Description("Template for Kafka `Pods`.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public ResourceTemplate getPod() {
+    public PodTemplate getPod() {
         return pod;
     }
 
-    public void setPod(ResourceTemplate pod) {
+    public void setPod(PodTemplate pod) {
         this.pod = pod;
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/template/KafkaConnectTemplate.java
Patch:
@@ -30,7 +30,7 @@ public class KafkaConnectTemplate implements Serializable {
     private static final long serialVersionUID = 1L;
 
     private ResourceTemplate deployment;
-    private ResourceTemplate pod;
+    private PodTemplate pod;
     private ResourceTemplate apiService;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
@@ -46,11 +46,11 @@ public void setDeployment(ResourceTemplate deployment) {
 
     @Description("Template for Kafka Connect `Pods`.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public ResourceTemplate getPod() {
+    public PodTemplate getPod() {
         return pod;
     }
 
-    public void setPod(ResourceTemplate pod) {
+    public void setPod(PodTemplate pod) {
         this.pod = pod;
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/template/KafkaMirrorMakerTemplate.java
Patch:
@@ -30,7 +30,7 @@ public class KafkaMirrorMakerTemplate implements Serializable {
     private static final long serialVersionUID = 1L;
 
     private ResourceTemplate deployment;
-    private ResourceTemplate pod;
+    private PodTemplate pod;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Description("Template for Kafka Mirror Maker `Deployment`.")
@@ -45,11 +45,11 @@ public void setDeployment(ResourceTemplate deployment) {
 
     @Description("Template for Kafka Mirror Maker `Pods`.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public ResourceTemplate getPod() {
+    public PodTemplate getPod() {
         return pod;
     }
 
-    public void setPod(ResourceTemplate pod) {
+    public void setPod(PodTemplate pod) {
         this.pod = pod;
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/template/ZookeeperClusterTemplate.java
Patch:
@@ -30,7 +30,7 @@ public class ZookeeperClusterTemplate implements Serializable {
     private static final long serialVersionUID = 1L;
 
     private ResourceTemplate statefulset;
-    private ResourceTemplate pod;
+    private PodTemplate pod;
     private ResourceTemplate clientService;
     private ResourceTemplate nodesService;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
@@ -47,11 +47,11 @@ public void setStatefulset(ResourceTemplate statefulset) {
 
     @Description("Template for Zookeeper `Pods`.")
     @JsonInclude(JsonInclude.Include.NON_EMPTY)
-    public ResourceTemplate getPod() {
+    public PodTemplate getPod() {
         return pod;
     }
 
-    public void setPod(ResourceTemplate pod) {
+    public void setPod(PodTemplate pod) {
         this.pod = pod;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -124,6 +124,9 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                             .withVolumes(getVolumes(isOpenShift))
                             .withTolerations(getTolerations())
                             .withAffinity(getMergedAffinity())
+                            .withTerminationGracePeriodSeconds(Long.valueOf(templateTerminationGracePeriodSeconds))
+                            .withImagePullSecrets(templateImagePullSecrets)
+                            .withSecurityContext(templateSecurityContext)
                         .endSpec()
                     .endTemplate()
                     .withTriggers(configChangeTrigger, imageChangeTrigger)

File: crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java
Patch:
@@ -378,7 +378,9 @@ private ObjectNode buildArraySchema(PropertyType propertyType) {
         if (String.class.equals(elementType)) {
             itemResult.put("type", "string");
         } else if (Integer.class.equals(elementType)
-                || int.class.equals(elementType)) {
+                || int.class.equals(elementType)
+                || Long.class.equals(elementType)
+                || long.class.equals(elementType)) {
             itemResult.put("type", "integer");
         } else  {
             buildObjectSchema(itemResult, elementType, true);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -922,7 +922,7 @@ public NetworkPolicy generateNetworkPolicy() {
 
                 NetworkPolicyIngressRule plainRule = new NetworkPolicyIngressRuleBuilder()
                         .withPorts(plainPort)
-                        .withFrom()
+                        .withFrom(listeners.getPlain().getNetworkPolicyPeers())
                         .build();
 
                 rules.add(plainRule);
@@ -934,7 +934,7 @@ public NetworkPolicy generateNetworkPolicy() {
 
                 NetworkPolicyIngressRule tlsRule = new NetworkPolicyIngressRuleBuilder()
                         .withPorts(tlsPort)
-                        .withFrom()
+                        .withFrom(listeners.getTls().getNetworkPolicyPeers())
                         .build();
 
                 rules.add(tlsRule);
@@ -946,7 +946,7 @@ public NetworkPolicy generateNetworkPolicy() {
 
                 NetworkPolicyIngressRule externalRule = new NetworkPolicyIngressRuleBuilder()
                         .withPorts(externalPort)
-                        .withFrom()
+                        .withFrom(listeners.getExternal().getNetworkPolicyPeers())
                         .build();
 
                 rules.add(externalRule);

File: systemtest/src/test/java/io/strimzi/systemtest/timemeasuring/Operation.java
Patch:
@@ -8,4 +8,6 @@
 public enum Operation {
     TEST_EXECUTION,
     CLASS_EXECUTION,
+    SCALE_UP,
+    SCALE_DOWN,
 }
\ No newline at end of file

File: systemtest/src/test/java/io/strimzi/systemtest/utils/AvailabilityVerifier.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest;
+package io.strimzi.systemtest.utils;
 
 import io.fabric8.kubernetes.api.model.LoadBalancerIngress;
 import io.fabric8.kubernetes.api.model.Secret;

File: systemtest/src/test/java/io/strimzi/systemtest/utils/StUtils.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.systemtest;
+package io.strimzi.systemtest.utils;
 
 import io.fabric8.kubernetes.api.model.LabelSelector;
 import io.fabric8.kubernetes.api.model.Pod;

File: topic-operator/src/test/java/io/strimzi/operator/topic/ZkTopicStoreTest.java
Patch:
@@ -13,6 +13,7 @@
 import io.vertx.ext.unit.junit.VertxUnitRunner;
 import org.junit.After;
 import org.junit.Before;
+import org.junit.Ignore;
 import org.junit.Test;
 import org.junit.runner.RunWith;
 
@@ -23,6 +24,7 @@
 
 import static org.junit.Assert.assertEquals;
 
+@Ignore
 @RunWith(VertxUnitRunner.class)
 public class ZkTopicStoreTest {
 

File: crd-generator/src/main/java/io/strimzi/crdgenerator/Property.java
Patch:
@@ -179,6 +179,9 @@ static boolean hasAnyGetterAndAnySetter(Class<?> crdClass) {
 
     private static boolean hasMethod(Class<?> c, Method m) {
         try {
+            if (!c.isAssignableFrom(m.getDeclaringClass()))
+                return false;
+
             c.getDeclaredMethod(m.getName(), m.getParameterTypes());
             return true;
         } catch (NoSuchMethodException e) {

File: api/src/main/java/io/strimzi/api/kafka/model/CertificateAuthority.java
Patch:
@@ -35,7 +35,7 @@ public class CertificateAuthority implements Serializable {
     private int renewalDays;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
-    @Description("The number of days generated certificates should be valid for. Default is 365.")
+    @Description("The number of days generated certificates should be valid for. The default is 365.")
     @Minimum(1)
     public int getValidityDays() {
         return validityDays;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -177,7 +177,7 @@ String getAncillaryConfigMapKeyLogConfig() {
 
     @Override
     public String getGcLoggingOptions() {
-        return gcLoggingDisabled ? " " : DEFAULT_STRIMZI_GC_LOGGING;
+        return gcLoggingEnabled ? DEFAULT_STRIMZI_GC_LOGGING : " ";
     }
 
     /**
@@ -207,7 +207,7 @@ public static EntityTopicOperator fromCrd(Kafka kafkaAssembly) {
                 result.setZookeeperSessionTimeoutMs(topicOperatorSpec.getZookeeperSessionTimeoutSeconds() * 1_000);
                 result.setTopicMetadataMaxAttempts(topicOperatorSpec.getTopicMetadataMaxAttempts());
                 result.setLogging(topicOperatorSpec.getLogging());
-                result.setGcLoggingDisabled(topicOperatorSpec.getJvmOptions() == null ? false : topicOperatorSpec.getJvmOptions().isGcLoggingDisabled());
+                result.setGcLoggingEnabled(topicOperatorSpec.getJvmOptions() == null ? true : topicOperatorSpec.getJvmOptions().isGcLoggingEnabled());
                 result.setResources(topicOperatorSpec.getResources());
             }
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -141,7 +141,7 @@ String getAncillaryConfigMapKeyLogConfig() {
 
     @Override
     public String getGcLoggingOptions() {
-        return gcLoggingDisabled ? " " : DEFAULT_STRIMZI_GC_LOGGING;
+        return gcLoggingEnabled ? DEFAULT_STRIMZI_GC_LOGGING : " ";
     }
 
     /**
@@ -170,7 +170,7 @@ public static EntityUserOperator fromCrd(Kafka kafkaAssembly) {
                 result.setReconciliationIntervalMs(userOperatorSpec.getReconciliationIntervalSeconds() * 1_000);
                 result.setZookeeperSessionTimeoutMs(userOperatorSpec.getZookeeperSessionTimeoutSeconds() * 1_000);
                 result.setLogging(userOperatorSpec.getLogging());
-                result.setGcLoggingDisabled(userOperatorSpec.getJvmOptions() == null ? false : userOperatorSpec.getJvmOptions().isGcLoggingDisabled());
+                result.setGcLoggingEnabled(userOperatorSpec.getJvmOptions() == null ? true : userOperatorSpec.getJvmOptions().isGcLoggingEnabled());
                 result.setResources(userOperatorSpec.getResources());
             }
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -274,7 +274,7 @@ public static KafkaCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup vers
         result.setInitImage(initImage);
         Logging logging = kafkaClusterSpec.getLogging();
         result.setLogging(logging == null ? new InlineLogging() : logging);
-        result.setGcLoggingDisabled(kafkaClusterSpec.getJvmOptions() == null ? false : kafkaClusterSpec.getJvmOptions().isGcLoggingDisabled());
+        result.setGcLoggingEnabled(kafkaClusterSpec.getJvmOptions() == null ? true : kafkaClusterSpec.getJvmOptions().isGcLoggingEnabled());
         result.setJvmOptions(kafkaClusterSpec.getJvmOptions());
         result.setConfiguration(new KafkaConfiguration(kafkaClusterSpec.getConfig().entrySet()));
         Map<String, Object> metrics = kafkaClusterSpec.getMetrics();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -140,7 +140,7 @@ protected static <C extends KafkaConnectCluster> C fromSpec(KafkaConnectSpec spe
 
             kafkaConnect.setResources(spec.getResources());
             kafkaConnect.setLogging(spec.getLogging());
-            kafkaConnect.setGcLoggingDisabled(spec.getJvmOptions() == null ? false : spec.getJvmOptions().isGcLoggingDisabled());
+            kafkaConnect.setGcLoggingEnabled(spec.getJvmOptions() == null ? true : spec.getJvmOptions().isGcLoggingEnabled());
             kafkaConnect.setJvmOptions(spec.getJvmOptions());
             if (spec.getReadinessProbe() != null) {
                 kafkaConnect.setReadinessInitialDelay(spec.getReadinessProbe().getInitialDelaySeconds());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -170,7 +170,7 @@ public static KafkaMirrorMakerCluster fromCrd(KafkaMirrorMaker kafkaMirrorMaker,
                     kafkaMirrorMaker.getSpec().getImage(),
                     kafkaMirrorMaker.getSpec().getVersion()));
             kafkaMirrorMakerCluster.setLogging(kafkaMirrorMaker.getSpec().getLogging());
-            kafkaMirrorMakerCluster.setGcLoggingDisabled(kafkaMirrorMaker.getSpec().getJvmOptions() == null ? false : kafkaMirrorMaker.getSpec().getJvmOptions().isGcLoggingDisabled());
+            kafkaMirrorMakerCluster.setGcLoggingEnabled(kafkaMirrorMaker.getSpec().getJvmOptions() == null ? true : kafkaMirrorMaker.getSpec().getJvmOptions().isGcLoggingEnabled());
 
             Map<String, Object> metrics = kafkaMirrorMaker.getSpec().getMetrics();
             if (metrics != null) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -205,7 +205,7 @@ public static String secretName(String cluster) {
 
     @Override
     public String getGcLoggingOptions() {
-        return gcLoggingDisabled ? " " : DEFAULT_STRIMZI_GC_LOGGING;
+        return gcLoggingEnabled ? DEFAULT_STRIMZI_GC_LOGGING : " ";
     }
 
     /**
@@ -231,7 +231,7 @@ public static TopicOperator fromCrd(Kafka kafkaAssembly) {
             result.setZookeeperSessionTimeoutMs(tcConfig.getZookeeperSessionTimeoutSeconds() * 1_000);
             result.setTopicMetadataMaxAttempts(tcConfig.getTopicMetadataMaxAttempts());
             result.setLogging(tcConfig.getLogging());
-            result.setGcLoggingDisabled(tcConfig.getJvmOptions() == null ? false : tcConfig.getJvmOptions().isGcLoggingDisabled());
+            result.setGcLoggingEnabled(tcConfig.getJvmOptions() == null ? true : tcConfig.getJvmOptions().isGcLoggingEnabled());
             result.setResources(tcConfig.getResources());
             result.setUserAffinity(tcConfig.getAffinity());
             result.setTlsSidecar(tcConfig.getTlsSidecar());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -174,7 +174,7 @@ public static ZookeeperCluster fromCrd(Kafka kafkaAssembly, KafkaVersion.Lookup
         }
         Logging logging = zookeeperClusterSpec.getLogging();
         zk.setLogging(logging == null ? new InlineLogging() : logging);
-        zk.setGcLoggingDisabled(zookeeperClusterSpec.getJvmOptions() == null ? false : zookeeperClusterSpec.getJvmOptions().isGcLoggingDisabled());
+        zk.setGcLoggingEnabled(zookeeperClusterSpec.getJvmOptions() == null ? true : zookeeperClusterSpec.getJvmOptions().isGcLoggingEnabled());
         Map<String, Object> metrics = zookeeperClusterSpec.getMetrics();
         if (metrics != null) {
             zk.setMetricsEnabled(true);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -256,6 +256,7 @@ private void checkStatefulSet(StatefulSet ss, Kafka cm, boolean isOpenShift) {
         assertEquals(new Integer(healthTimeout), containers.get(0).getReadinessProbe().getTimeoutSeconds());
         assertEquals(new Integer(healthDelay), containers.get(0).getReadinessProbe().getInitialDelaySeconds());
         assertEquals("foo=bar" + LINE_SEPARATOR, AbstractModel.containerEnvVars(containers.get(0)).get(KafkaCluster.ENV_VAR_KAFKA_CONFIGURATION));
+        assertEquals(KafkaCluster.DEFAULT_KAFKA_GC_LOGGING, AbstractModel.containerEnvVars(containers.get(0)).get(KafkaCluster.ENV_VAR_KAFKA_GC_LOG_OPTS));
         assertEquals(KafkaCluster.BROKER_CERTS_VOLUME, containers.get(0).getVolumeMounts().get(2).getName());
         assertEquals(KafkaCluster.BROKER_CERTS_VOLUME_MOUNT, containers.get(0).getVolumeMounts().get(2).getMountPath());
         assertEquals(KafkaCluster.CLUSTER_CA_CERTS_VOLUME, containers.get(0).getVolumeMounts().get(1).getName());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerClusterTest.java
Patch:
@@ -125,7 +125,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_WHITELIST).withValue(whitelist).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_GROUPID_CONSUMER).withValue(groupId).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_MIRRORMAKER_NUMSTREAMS).withValue(Integer.toString(numStreams)).build());
-        expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_GC_LOG_OPTS).withValue(KafkaConnectCluster.DEFAULT_KAFKA_GC_LOGGING).build());
+        expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_GC_LOG_OPTS).withValue(KafkaMirrorMakerCluster.DEFAULT_KAFKA_GC_LOGGING).build());
         expected.add(new EnvVarBuilder().withName(KafkaMirrorMakerCluster.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
         return expected;
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -175,6 +175,7 @@ private void checkStatefulSet(StatefulSet ss) {
                         "initLimit=5" + LINE_SEPARATOR +
                         "foo=bar" + LINE_SEPARATOR;
         assertEquals(expectedConfig, AbstractModel.containerEnvVars(containers.get(0)).get(ZookeeperCluster.ENV_VAR_ZOOKEEPER_CONFIGURATION));
+        assertEquals(ZookeeperCluster.DEFAULT_KAFKA_GC_LOGGING, AbstractModel.containerEnvVars(containers.get(0)).get(ZookeeperCluster.ENV_VAR_KAFKA_GC_LOG_OPTS));
         // checks on the TLS sidecar container
         Container tlsSidecarContainer = containers.get(1);
         assertEquals(ZookeeperClusterSpec.DEFAULT_TLS_SIDECAR_IMAGE, tlsSidecarContainer.getImage());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -115,7 +115,6 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, boolean isOpenS
                 config.versions());
 
         KafkaConnectS2IAssemblyOperator kafkaConnectS2IClusterOperations = null;
-        CrdOperator<OpenShiftClient, KafkaConnectS2I, KafkaConnectS2IAssemblyList, DoneableKafkaConnectS2I> kafkaConnectS2iCrdOperator = null;
         if (isOpenShift) {
             kafkaConnectS2IClusterOperations = createS2iOperator(vertx, client, isOpenShift, serviceOperations, configMapOperations, secretOperations, certManager, config.versions());
         } else {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorTest.java
Patch:
@@ -44,7 +44,6 @@
 @RunWith(VertxUnitRunner.class)
 public class ClusterOperatorTest {
 
-    public static final String STRIMZI_IO_KIND_CLUSTER = "strimzi.io/kind=cluster";
     private Vertx vertx;
 
     @Before

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.operator.cluster;
 
-import com.fasterxml.jackson.databind.ObjectMapper;
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.api.model.ObjectMetaBuilder;
 import io.fabric8.kubernetes.api.model.Secret;
@@ -291,7 +290,6 @@ public static Kafka createKafkaCluster(String clusterCmNamespace, String cluster
         livenessProbe.setTimeoutSeconds(healthTimeout);
         kafkaClusterSpec.setLivenessProbe(livenessProbe);
         kafkaClusterSpec.setReadinessProbe(livenessProbe);
-        ObjectMapper om = new ObjectMapper();
         if (metricsCm != null) {
             kafkaClusterSpec.setMetrics(metricsCm);
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -498,7 +498,6 @@ public void testReconcile(TestContext context) {
         when(mockSecretOps.reconcile(eq(clusterCmNamespace), any(), any())).thenReturn(Future.succeededFuture());
 
         Set<String> createdOrUpdated = new CopyOnWriteArraySet<>();
-        Set<String> deleted = new CopyOnWriteArraySet<>();
 
         Async async = context.async(2);
         KafkaConnectAssemblyOperator ops = new KafkaConnectAssemblyOperator(vertx, true,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperatorTest.java
Patch:
@@ -617,7 +617,6 @@ public void testReconcile(TestContext context) {
         when(mockSecretOps.reconcile(eq(clusterCmNamespace), any(), any())).thenReturn(Future.succeededFuture());
 
         Set<String> createdOrUpdated = new CopyOnWriteArraySet<>();
-        Set<String> deleted = new CopyOnWriteArraySet<>();
 
         Async async = context.async(2);
         KafkaConnectS2IAssemblyOperator ops = new KafkaConnectS2IAssemblyOperator(vertx, true,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperatorTest.java
Patch:
@@ -613,7 +613,6 @@ public void testReconcile(TestContext context) {
         when(mockSecretOps.reconcile(eq(clusterCmNamespace), any(), any())).thenReturn(Future.succeededFuture());
 
         Set<String> createdOrUpdated = new CopyOnWriteArraySet<>();
-        Set<String> deleted = new CopyOnWriteArraySet<>();
 
         Async async = context.async(2);
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -12,7 +12,6 @@
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.KafkaVersion;
-import io.strimzi.operator.common.operator.MockCertManager;
 import org.junit.Before;
 import org.junit.Test;
 
@@ -41,7 +40,6 @@ public class KafkaSetOperatorTest {
 
     @Before
     public void before() {
-        MockCertManager certManager = new MockCertManager();
         KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
         a = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true);
         b = KafkaCluster.fromCrd(getResource(), versions).generateStatefulSet(true);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperatorTest.java
Patch:
@@ -11,7 +11,6 @@
 import io.strimzi.operator.cluster.model.ClusterCa;
 import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.cluster.model.ZookeeperCluster;
-import io.strimzi.operator.common.operator.MockCertManager;
 import org.junit.Before;
 import org.junit.Test;
 
@@ -35,7 +34,6 @@ public class ZookeeperSetOperatorTest {
 
     @Before
     public void before() {
-        MockCertManager certManager = new MockCertManager();
         KafkaVersion.Lookup versions = new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap());
         a = ZookeeperCluster.fromCrd(getResource(), versions).generateStatefulSet(true);
         b = ZookeeperCluster.fromCrd(getResource(), versions).generateStatefulSet(true);

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ServiceOperator.java
Patch:
@@ -87,7 +87,7 @@ protected void patchNodePorts(Service current, Service desired) {
     }
 
     public Future<Void> endpointReadiness(String namespace, Service desired, long pollInterval, long operationTimeoutMs) {
-        return endpointOperations.readiness(namespace, desired.getMetadata().getName(), 1_000, operationTimeoutMs);
+        return endpointOperations.readiness(namespace, desired.getMetadata().getName(), pollInterval, operationTimeoutMs);
     }
 
     /**

File: api/src/main/java/io/strimzi/api/kafka/model/TlsSidecar.java
Patch:
@@ -26,6 +26,9 @@
 public class TlsSidecar extends Sidecar {
     private static final long serialVersionUID = 1L;
 
+    public static final int DEFAULT_HEALTHCHECK_DELAY = 15;
+    public static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;
+
     private TlsSidecarLogLevel logLevel = TlsSidecarLogLevel.NOTICE;
     private Probe livenessProbe;
     private Probe readinessProbe;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -224,7 +224,7 @@ protected List<Container> getContainers() {
                 .withPorts(singletonList(createContainerPort(HEALTHCHECK_PORT_NAME, HEALTHCHECK_PORT, "TCP")))
                 .withLivenessProbe(createHttpProbe(livenessPath + "healthy", HEALTHCHECK_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath + "ready", HEALTHCHECK_PORT_NAME, readinessInitialDelay, readinessTimeout))
-                .withResources(resources(getResources()))
+                .withResources(ModelUtils.resources(getResources()))
                 .withVolumeMounts(getVolumeMounts())
                 .build());
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -187,7 +187,7 @@ protected List<Container> getContainers() {
                 .withPorts(singletonList(createContainerPort(HEALTHCHECK_PORT_NAME, HEALTHCHECK_PORT, "TCP")))
                 .withLivenessProbe(createHttpProbe(livenessPath + "healthy", HEALTHCHECK_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath + "ready", HEALTHCHECK_PORT_NAME, readinessInitialDelay, readinessTimeout))
-                .withResources(resources(getResources()))
+                .withResources(ModelUtils.resources(getResources()))
                 .withVolumeMounts(getVolumeMounts())
                 .build());
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -311,7 +311,7 @@ protected List<Container> getContainers() {
                 .withLivenessProbe(createHttpProbe(livenessPath, REST_API_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath, REST_API_PORT_NAME, readinessInitialDelay, readinessTimeout))
                 .withVolumeMounts(getVolumeMounts())
-                .withResources(resources(getResources()))
+                .withResources(ModelUtils.resources(getResources()))
                 .build();
 
         containers.add(container);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -76,7 +76,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                 .withLivenessProbe(createHttpProbe(livenessPath, REST_API_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath, REST_API_PORT_NAME, readinessInitialDelay, readinessTimeout))
                 .withVolumeMounts(getVolumeMounts())
-                .withResources(resources(getResources()))
+                .withResources(ModelUtils.resources(getResources()))
                 .build();
 
         DeploymentTriggerPolicy configChangeTrigger = new DeploymentTriggerPolicyBuilder()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaMirrorMakerCluster.java
Patch:
@@ -327,7 +327,7 @@ protected List<Container> getContainers() {
                 .withEnv(getEnvVars())
                 .withPorts(getContainerPortList())
                 .withVolumeMounts(getVolumeMounts())
-                .withResources(resources(getResources()))
+                .withResources(ModelUtils.resources(getResources()))
                 .build();
 
         containers.add(container);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractModelTest.java
Patch:
@@ -189,7 +189,7 @@ protected List<Container> getContainers() {
             }
         };
         abstractModel.setResources(opts);
-        Assert.assertEquals("1", abstractModel.resources(opts).getLimits().get("cpu").getAmount());
+        Assert.assertEquals("1", ModelUtils.resources(opts).getLimits().get("cpu").getAmount());
     }
 
     @Test

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -89,7 +89,8 @@ public abstract class AbstractModel {
     protected static final int CERTS_EXPIRATION_DAYS = 365;
     protected static final String DEFAULT_JVM_XMS = "128M";
 
-    private static final String VOLUME_MOUNT_HACK_IMAGE = "busybox";
+    private static final String VOLUME_MOUNT_HACK_IMAGE =
+            System.getenv().getOrDefault("STRIMZI_VOLUME_MOUNT_INIT_IMAGE", "busybox");
     protected static final String VOLUME_MOUNT_HACK_NAME = "volume-mount-hack";
     private static final Long VOLUME_MOUNT_HACK_USERID = 1001L;
     private static final Long VOLUME_MOUNT_HACK_GROUPID = 0L;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -156,7 +156,7 @@ public abstract class AbstractModel {
     private List<Toleration> tolerations;
 
     protected Map validLoggerFields;
-    private String[] validLoggerValues = new String[]{"INFO", "ERROR", "WARN", "TRACE", "DEBUG", "FATAL", "OFF" };
+    private final String[] validLoggerValues = new String[]{"INFO", "ERROR", "WARN", "TRACE", "DEBUG", "FATAL", "OFF" };
     private Logging logging;
     protected boolean gcLoggingDisabled;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -164,7 +164,7 @@ protected String getDefaultLogConfigFileName() {
         return null;
     }
 
-    public Deployment generateDeployment(boolean isOpenShift) {
+    public Deployment generateDeployment(boolean isOpenShift, Map<String, String> annotations) {
 
         if (!isDeployed()) {
             log.warn("Topic and/or User Operators not declared: Entity Operator will not be deployed");
@@ -178,7 +178,7 @@ public Deployment generateDeployment(boolean isOpenShift) {
         return createDeployment(
                 updateStrategy,
                 Collections.emptyMap(),
-                Collections.emptyMap(),
+                annotations,
                 getMergedAffinity(),
                 getInitContainers(),
                 getContainers(),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -75,6 +75,7 @@
 import org.mockito.ArgumentCaptor;
 
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -696,7 +697,7 @@ private void updateCluster(TestContext context, Kafka originalAssembly, Kafka up
         }
         if (originalEntityOperator != null) {
             when(mockDepOps.get(clusterNamespace, EntityOperator.entityOperatorName(clusterName))).thenReturn(
-                    originalEntityOperator.generateDeployment(true)
+                    originalEntityOperator.generateDeployment(true, Collections.EMPTY_MAP)
             );
         }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/MaintenanceTimeWindowsTest.java
Patch:
@@ -501,7 +501,7 @@ private void doEntityOperatorRollingUpdate(List<String> maintenanceTimeWindows,
         this.init(maintenanceTimeWindows);
 
         EntityOperator eo = EntityOperator.fromCrd(this.kafka);
-        Deployment eoDep = eo.generateDeployment(false);
+        Deployment eoDep = eo.generateDeployment(false, Collections.EMPTY_MAP);
         eoDep.getSpec().getTemplate().getMetadata().getAnnotations().put(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION, "0");
         this.mockClient.extensions().deployments().inNamespace(NAMESPACE).withName(EntityOperator.entityOperatorName(NAME)).create(eoDep);
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectS2ISpec.java
Patch:
@@ -21,9 +21,6 @@ public class KafkaConnectS2ISpec extends KafkaConnectSpec {
 
     private static final long serialVersionUID = 1L;
 
-    public static final String DEFAULT_IMAGE =
-            System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE", "strimzi/kafka-connect-s2i:latest");
-
     private boolean insecureSourceRepository = false;
 
     @Description("When true this configures the source repository with the 'Local' reference policy " +

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -778,6 +778,7 @@ protected Service createHeadlessService(List<ServicePort> ports, Map<String, Str
     }
 
     protected StatefulSet createStatefulSet(
+            Map<String, String> annotations,
             List<Volume> volumes,
             List<PersistentVolumeClaim> volumeClaims,
             List<VolumeMount> volumeMounts,
@@ -786,7 +787,7 @@ protected StatefulSet createStatefulSet(
             List<Container> containers,
             boolean isOpenShift) {
 
-        Map<String, String> annotations = new HashMap<>();
+        annotations = new HashMap<>(annotations);
 
         annotations.put(ANNO_STRIMZI_IO_DELETE_CLAIM,
                 String.valueOf(storage instanceof PersistentClaimStorage

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/InvalidResourceException.java
Patch:
@@ -10,5 +10,6 @@ public InvalidResourceException() {
     }
 
     protected InvalidResourceException(String s) {
+        super(s);
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -44,7 +44,7 @@ public abstract class StatefulSetOperator extends AbstractScalableResourceOperat
     private static final Logger log = LogManager.getLogger(StatefulSetOperator.class.getName());
     private final PodOperator podOperations;
     private final PvcOperator pvcOperations;
-    private final long operationTimeoutMs;
+    protected final long operationTimeoutMs;
 
     /**
      * Constructor

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
Patch:
@@ -4,9 +4,9 @@
  */
 package io.strimzi.operator.cluster;
 
+import io.strimzi.operator.cluster.model.KafkaVersion;
 import io.strimzi.operator.common.InvalidConfigurationException;
 import io.strimzi.operator.common.model.Labels;
-
 import org.junit.Test;
 
 import java.util.Collections;
@@ -15,6 +15,7 @@
 import java.util.Map;
 
 import static java.util.Arrays.asList;
+import static java.util.Collections.emptyMap;
 import static java.util.Collections.singleton;
 import static org.junit.Assert.assertEquals;
 
@@ -48,7 +49,7 @@ public void testDefaultConfig() {
     @Test
     public void testReconciliationInterval() {
 
-        ClusterOperatorConfig config = new ClusterOperatorConfig(singleton("namespace"), 60_000, 30_000, false);
+        ClusterOperatorConfig config = new ClusterOperatorConfig(singleton("namespace"), 60_000, 30_000, false, new KafkaVersion.Lookup(emptyMap(), emptyMap(), emptyMap(), emptyMap()));
 
         assertEquals(singleton("namespace"), config.getNamespaces());
         assertEquals(60_000, config.getReconciliationIntervalMs());

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/AbstractResourceOperatorTest.java
Patch:
@@ -172,7 +172,7 @@ public void successfulCreation(TestContext context) {
     @Test
     public void creationThrows(TestContext context) {
         T resource = resource();
-        RuntimeException ex = new RuntimeException();
+        RuntimeException ex = new RuntimeException("Testing this exception is handled correctly");
 
         Resource mockResource = mock(resourceType());
         when(mockResource.get()).thenReturn(null);
@@ -277,7 +277,7 @@ public void successfulDeletion(TestContext context) {
     @Test
     public void deletionThrows(TestContext context) {
         T resource = resource();
-        RuntimeException ex = new RuntimeException();
+        RuntimeException ex = new RuntimeException("Testing this exception is handled correctly");
 
         Resource mockResource = mock(resourceType());
         when(mockResource.get()).thenReturn(resource);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java
Patch:
@@ -32,8 +32,6 @@ public class ClusterOperator extends AbstractVerticle {
 
     private static final Logger log = LogManager.getLogger(ClusterOperator.class.getName());
 
-    public static final String STRIMZI_CLUSTER_OPERATOR_DOMAIN = "cluster.operator.strimzi.io";
-
     private static final int HEALTH_SERVER_PORT = 8080;
 
     private final KubernetesClient client;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -22,6 +22,7 @@
 import io.strimzi.api.kafka.model.TlsSidecarLogLevel;
 import io.strimzi.api.kafka.model.TopicOperatorSpec;
 import io.strimzi.certs.CertAndKey;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.operator.resource.RoleBindingOperator;
 
@@ -54,7 +55,7 @@ public class TopicOperator extends AbstractModel {
     protected static final String TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT = "/etc/tls-sidecar/eo-certs/";
     protected static final String TLS_SIDECAR_CA_CERTS_VOLUME_NAME = "cluster-ca-certs";
     protected static final String TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT = "/etc/tls-sidecar/cluster-ca-certs/";
-
+    public static final String ANNO_STRIMZI_IO_LOGGING = Annotations.STRIMZI_DOMAIN + "/logging";
 
     protected static final String METRICS_AND_LOG_CONFIG_SUFFIX = NAME_SUFFIX + "-config";
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -14,6 +14,7 @@
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.model.KafkaConnectCluster;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.model.ResourceType;
@@ -42,6 +43,7 @@
 public class KafkaConnectAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, KafkaConnect, KafkaConnectAssemblyList, DoneableKafkaConnect, Resource<KafkaConnect, DoneableKafkaConnect>> {
 
     private static final Logger log = LogManager.getLogger(KafkaConnectAssemblyOperator.class.getName());
+    public static final String ANNO_STRIMZI_IO_LOGGING = Annotations.STRIMZI_DOMAIN + "/logging";
     private final ServiceOperator serviceOperations;
     private final DeploymentOperator deploymentOperations;
     private final ConfigMapOperator configMapOperations;
@@ -88,7 +90,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
                 null);
 
         Map<String, String> annotations = new HashMap();
-        annotations.put("strimzi.io/logging", logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
+        annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Connect cluster", reconciliation, name, namespace);
         return deploymentOperations.scaleDown(namespace, connect.getName(), connect.getReplicas())

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -14,6 +14,7 @@
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.model.KafkaConnectS2ICluster;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.model.ResourceType;
@@ -45,6 +46,7 @@
 public class KafkaConnectS2IAssemblyOperator extends AbstractAssemblyOperator<OpenShiftClient, KafkaConnectS2I, KafkaConnectS2IAssemblyList, DoneableKafkaConnectS2I, Resource<KafkaConnectS2I, DoneableKafkaConnectS2I>> {
 
     private static final Logger log = LogManager.getLogger(KafkaConnectS2IAssemblyOperator.class.getName());
+    public static final String ANNO_STRIMZI_IO_LOGGING = Annotations.STRIMZI_DOMAIN + "/logging";
     private final ServiceOperator serviceOperations;
     private final DeploymentConfigOperator deploymentConfigOperations;
     private final ImageStreamOperator imagesStreamOperations;
@@ -99,7 +101,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
                     null);
 
             HashMap<String, String> annotations = new HashMap();
-            annotations.put("strimzi.io/logging", logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
+            annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(connect.ANCILLARY_CM_KEY_LOG_CONFIG));
 
             return deploymentConfigOperations.scaleDown(namespace, connect.getName(), connect.getReplicas())
                     .compose(scale -> serviceOperations.reconcile(namespace, connect.getServiceName(), connect.generateService()))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -14,6 +14,7 @@
 import io.strimzi.api.kafka.model.KafkaMirrorMaker;
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.model.KafkaMirrorMakerCluster;
+import io.strimzi.operator.common.Annotations;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.operator.common.model.ResourceType;
@@ -42,6 +43,7 @@
 public class KafkaMirrorMakerAssemblyOperator extends AbstractAssemblyOperator<KubernetesClient, KafkaMirrorMaker, KafkaMirrorMakerList, DoneableKafkaMirrorMaker, Resource<KafkaMirrorMaker, DoneableKafkaMirrorMaker>> {
 
     private static final Logger log = LogManager.getLogger(KafkaMirrorMakerAssemblyOperator.class.getName());
+    public static final String ANNO_STRIMZI_IO_LOGGING = Annotations.STRIMZI_DOMAIN + "/logging";
 
     private final DeploymentOperator deploymentOperations;
     private final ConfigMapOperator configMapOperations;
@@ -89,7 +91,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
                 null);
 
         Map<String, String> annotations = new HashMap();
-        annotations.put("strimzi.io/logging", logAndMetricsConfigMap.getData().get(mirror.ANCILLARY_CM_KEY_LOG_CONFIG));
+        annotations.put(ANNO_STRIMZI_IO_LOGGING, logAndMetricsConfigMap.getData().get(mirror.ANCILLARY_CM_KEY_LOG_CONFIG));
 
         log.debug("{}: Updating Kafka Mirror Maker cluster", reconciliation, name, namespace);
         return deploymentOperations.scaleDown(namespace, mirror.getName(), mirror.getReplicas())

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -232,11 +232,11 @@ private KafkaAssemblyOperator createCluster(TestContext context) {
             context.assertTrue(ar.succeeded());
             StatefulSet kafkaSs = mockClient.apps().statefulSets().inNamespace(NAMESPACE).withName(KafkaCluster.kafkaClusterName(CLUSTER_NAME)).get();
             context.assertNotNull(kafkaSs);
-            context.assertEquals("0", kafkaSs.getSpec().getTemplate().getMetadata().getAnnotations().get(StatefulSetOperator.ANNOTATION_GENERATION));
+            context.assertEquals("0", kafkaSs.getSpec().getTemplate().getMetadata().getAnnotations().get(StatefulSetOperator.ANNO_STRIMZI_IO_GENERATION));
             context.assertEquals("0", kafkaSs.getSpec().getTemplate().getMetadata().getAnnotations().get(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION));
             context.assertEquals("0", kafkaSs.getSpec().getTemplate().getMetadata().getAnnotations().get(Ca.ANNO_STRIMZI_IO_CLIENTS_CA_CERT_GENERATION));
             StatefulSet zkSs = mockClient.apps().statefulSets().inNamespace(NAMESPACE).withName(ZookeeperCluster.zookeeperClusterName(CLUSTER_NAME)).get();
-            context.assertEquals("0", zkSs.getSpec().getTemplate().getMetadata().getAnnotations().get(StatefulSetOperator.ANNOTATION_GENERATION));
+            context.assertEquals("0", zkSs.getSpec().getTemplate().getMetadata().getAnnotations().get(StatefulSetOperator.ANNO_STRIMZI_IO_GENERATION));
             context.assertEquals("0", zkSs.getSpec().getTemplate().getMetadata().getAnnotations().get(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION));
             context.assertNotNull(zkSs);
             context.assertNotNull(mockClient.extensions().deployments().inNamespace(NAMESPACE).withName(TopicOperator.topicOperatorName(CLUSTER_NAME)).get());

File: user-operator/src/main/java/io/strimzi/operator/user/UserOperator.java
Patch:
@@ -28,8 +28,6 @@ public class UserOperator extends AbstractVerticle {
 
     private static final Logger log = LogManager.getLogger(UserOperator.class.getName());
 
-    public static final String STRIMZI_CLUSTER_OPERATOR_DOMAIN = "user.operator.strimzi.io";
-
     private static final int HEALTH_SERVER_PORT = 8081;
 
     private final KubernetesClient client;

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorIT.java
Patch:
@@ -153,6 +153,7 @@ public void setup(TestContext context) throws Exception {
                 topicsWatcher = session.topicsWatcher;
                 async.complete();
             } else {
+                ar.cause().printStackTrace();
                 context.fail("Failed to deploy session");
             }
         });

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetDiff.java
Patch:
@@ -52,6 +52,8 @@ public class StatefulSetDiff {
             "/spec/template/spec/volumes/[0-9]+/configMap/defaultMode",
             "/spec/template/spec/volumes/[0-9]+/secret/defaultMode",
             "/spec/volumeClaimTemplates/[0-9]+/status",
+            "/spec/volumeClaimTemplates/[0-9]+/spec/volumeMode",
+            "/spec/volumeClaimTemplates/[0-9]+/spec/dataSource",
             "/spec/template/spec/serviceAccount",
             "/status").stream().map(Pattern::compile).collect(Collectors.toList());
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -791,7 +791,7 @@ Future<ReconciliationState> kafkaBootstrapRouteReady() {
 
                     address.setHandler(res -> {
                         if (res.succeeded()) {
-                            String bootstrapAddress = routeOperations.get(namespace, routeName).getSpec().getHost();
+                            String bootstrapAddress = routeOperations.get(namespace, routeName).getStatus().getIngress().get(0).getHost();
                             this.kafkaExternalBootstrapDnsName = bootstrapAddress;
 
                             if (log.isTraceEnabled()) {
@@ -835,7 +835,7 @@ Future<ReconciliationState> kafkaReplicaRoutesReady() {
 
                         address.setHandler(res -> {
                             if (res.succeeded()) {
-                                String routeAddress = routeOperations.get(namespace, routeName).getSpec().getHost();
+                                String routeAddress = routeOperations.get(namespace, routeName).getStatus().getIngress().get(0).getHost();
                                 this.kafkaExternalAddresses.put(podNumber, routeAddress);
                                 this.kafkaExternalDnsNames.put(podNumber, routeAddress);
 

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/Ca.java
Patch:
@@ -526,7 +526,7 @@ private CertAndKey renewCa(String commonName) throws IOException {
 
         Base64.Decoder decoder = Base64.getDecoder();
         byte[] bytes = decoder.decode(caKeySecret.getData().get(CA_KEY));
-        File keyFile = File.createTempFile("ererver", "dffbvd");
+        File keyFile = File.createTempFile("tls", commonName + "-key");
         try {
             Files.write(keyFile.toPath(), bytes);
             File certFile = File.createTempFile("tls", commonName + "-cert");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -82,7 +82,7 @@ protected EntityTopicOperator(String namespace, String cluster, Labels labels) {
 
         this.ancillaryConfigName = metricAndLogConfigsName(cluster);
         this.logAndMetricsConfigVolumeName = "entity-topic-operator-metrics-and-logging";
-        this.logAndMetricsConfigMountPath = "/opt/entity-topic-operator/custom-config/";
+        this.logAndMetricsConfigMountPath = "/opt/topic-operator/custom-config/";
         this.validLoggerFields = getDefaultLogConfig();
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -74,7 +74,7 @@ protected EntityUserOperator(String namespace, String cluster, Labels labels) {
 
         this.ancillaryConfigName = metricAndLogConfigsName(cluster);
         this.logAndMetricsConfigVolumeName = "entity-user-operator-metrics-and-logging";
-        this.logAndMetricsConfigMountPath = "/opt/entity-user-operator/custom-config/";
+        this.logAndMetricsConfigMountPath = "/opt/user-operator/custom-config/";
         this.validLoggerFields = getDefaultLogConfig();
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -169,7 +169,7 @@ public void testGetContainers() {
         assertEquals(new Integer(EntityTopicOperator.HEALTHCHECK_PORT), container.getPorts().get(0).getContainerPort());
         assertEquals(EntityTopicOperator.HEALTHCHECK_PORT_NAME, container.getPorts().get(0).getName());
         assertEquals("TCP", container.getPorts().get(0).getProtocol());
-        assertEquals(map("entity-topic-operator-metrics-and-logging", "/opt/entity-topic-operator/custom-config/",
+        assertEquals(map("entity-topic-operator-metrics-and-logging", "/opt/topic-operator/custom-config/",
                 EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT,
                 EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT),
                 EntityOperatorTest.volumeMounts(container.getVolumeMounts()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -159,7 +159,7 @@ public void testGetContainers() {
         assertEquals(new Integer(EntityUserOperator.HEALTHCHECK_PORT), container.getPorts().get(0).getContainerPort());
         assertEquals(EntityUserOperator.HEALTHCHECK_PORT_NAME, container.getPorts().get(0).getName());
         assertEquals("TCP", container.getPorts().get(0).getProtocol());
-        assertEquals("/opt/entity-user-operator/custom-config/", container.getVolumeMounts().get(0).getMountPath());
+        assertEquals("/opt/user-operator/custom-config/", container.getVolumeMounts().get(0).getMountPath());
         assertEquals("entity-user-operator-metrics-and-logging", container.getVolumeMounts().get(0).getName());
     }
 }

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleClusterResource.java
Patch:
@@ -10,7 +10,7 @@
 import io.sundr.builder.annotations.Buildable;
 
 /**
- * A representation of a group resource for ACLs
+ * A representation of a cluster resource for ACLs
  */
 @Buildable(
         editableEnabled = false,

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleResource.java
Patch:
@@ -25,6 +25,7 @@
         @JsonSubTypes.Type(name = AclRuleTopicResource.TYPE_TOPIC, value = AclRuleTopicResource.class),
         @JsonSubTypes.Type(name = AclRuleGroupResource.TYPE_GROUP, value = AclRuleGroupResource.class),
         @JsonSubTypes.Type(name = AclRuleClusterResource.TYPE_CLUSTER, value = AclRuleClusterResource.class),
+        @JsonSubTypes.Type(name = AclRuleTransactionalIdResource.TYPE_TRANSACTIONAL_ID, value = AclRuleTransactionalIdResource.class),
 })
 @JsonInclude(JsonInclude.Include.NON_NULL)
 public abstract class AclRuleResource implements Serializable {
@@ -33,7 +34,7 @@ public abstract class AclRuleResource implements Serializable {
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Description("Resource type. " +
-            "The available resource types are `topic`, `group` and `cluster`.")
+            "The available resource types are `topic`, `group`, `cluster`, and `transactionalId`.")
     public abstract String getType();
 
     @JsonAnyGetter

File: user-operator/src/main/java/io/strimzi/operator/user/model/acl/SimpleAclRuleResourceType.java
Patch:
@@ -13,5 +13,6 @@
 public enum SimpleAclRuleResourceType {
     TOPIC,
     GROUP,
-    CLUSTER;
+    CLUSTER,
+    TRANSACTIONAL_ID;
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -901,6 +901,7 @@ Future<ReconciliationState> kafkaNetPolicy() {
         }
 
         Future<ReconciliationState> kafkaStatefulSet() {
+            kafkaCluster.setExternalAddresses(kafkaExternalAddresses);
             StatefulSet kafkaSs = kafkaCluster.generateStatefulSet(isOpenShift);
             kafkaSs.getSpec().getTemplate().getMetadata().getAnnotations()
                     .put(Ca.ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION, String.valueOf(getCaCertGeneration(this.clusterCa)));

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/Ca.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.certs.CertManager;
 import io.strimzi.certs.SecretCertProvider;
 import io.strimzi.certs.Subject;
+import io.strimzi.operator.common.Util;
 import org.apache.logging.log4j.Level;
 import org.apache.logging.log4j.LogManager;
 import org.apache.logging.log4j.Logger;
@@ -83,7 +84,7 @@ public abstract class Ca {
     public static final String ANNO_STRIMZI_IO_CA_CERT_GENERATION = "strimzi.io/ca-cert-generation";
     public static final String ANNO_STRIMZI_IO_CLUSTER_CA_CERT_GENERATION = "strimzi.io/cluster-ca-cert-generation";
     public static final String ANNO_STRIMZI_IO_CLIENTS_CA_CERT_GENERATION = "strimzi.io/clients-ca-cert-generation";
-    private static final int INIT_GENERATION = 0;
+    public static final int INIT_GENERATION = 0;
 
     /**
      * Set the {@code strimzi.io/force-renew} annotation on the given {@code caCert} if the given {@code caKey} has
@@ -314,7 +315,7 @@ public void createOrRenew(String namespace, String clusterName, Map<String, Stri
         // cluster CA certificate generation annotation handling
         int caCertGeneration = INIT_GENERATION;
         if (caCertSecret != null && caCertSecret.getData().get(CA_CRT) != null) {
-            String caCertGenerationAnnotation = caCertSecret.getMetadata().getAnnotations().get(ANNO_STRIMZI_IO_CA_CERT_GENERATION);
+            String caCertGenerationAnnotation = Util.annotations(caCertSecret).get(ANNO_STRIMZI_IO_CA_CERT_GENERATION);
             if (caCertGenerationAnnotation != null) {
                 caCertGeneration = Integer.parseInt(caCertGenerationAnnotation);
                 if (caRenewed) {

File: api/src/test/java/io/strimzi/test/StrimziExtension.java
Patch:
@@ -230,10 +230,10 @@ private void collectLogsForPods() {
 
         private void collectEvents() {
             LOGGER.info("Collecting events in namespace {}", namespace);
-            String events = kubeClient().exec("oc", "get", "events").out();
+            String events = kubeClient().getEvents();
 
             // Print events to console
-            LOGGER.info("Events for namspace {}{}{}", namespace, System.lineSeparator(), events);
+            LOGGER.info("Events for namespace {}{}{}", namespace, System.lineSeparator(), events);
 
             // Write events to file
             writeFile(logDir + "/" + "events-in-namespace" + kubeClient().namespace() + ".log", events);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -262,6 +262,7 @@ protected Future<ReconcileResult<StatefulSet>> internalPatch(String namespace, S
         } else {
             setGeneration(desired, getSsGeneration(current));
         }
+
         // Don't scale via patch
         desired.getSpec().setReplicas(current.getSpec().getReplicas());
         if (log.isTraceEnabled()) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -25,6 +25,7 @@
 import io.strimzi.api.kafka.model.ResourcesBuilder;
 import io.strimzi.api.kafka.model.Storage;
 import io.strimzi.operator.cluster.ResourceUtils;
+import io.strimzi.operator.cluster.model.Ca;
 import io.strimzi.operator.cluster.model.KafkaCluster;
 import io.strimzi.operator.cluster.model.TopicOperator;
 import io.strimzi.operator.cluster.model.ZookeeperCluster;
@@ -231,8 +232,10 @@ private KafkaAssemblyOperator createCluster(TestContext context) {
             StatefulSet kafkaSs = mockClient.apps().statefulSets().inNamespace(NAMESPACE).withName(KafkaCluster.kafkaClusterName(CLUSTER_NAME)).get();
             context.assertNotNull(kafkaSs);
             context.assertEquals("0", kafkaSs.getSpec().getTemplate().getMetadata().getAnnotations().get(StatefulSetOperator.ANNOTATION_GENERATION));
+            context.assertEquals("0", kafkaSs.getSpec().getTemplate().getMetadata().getAnnotations().get(Ca.ANNO_STRIMZI_IO_CA_CERT_GENERATION));
             StatefulSet zkSs = mockClient.apps().statefulSets().inNamespace(NAMESPACE).withName(ZookeeperCluster.zookeeperClusterName(CLUSTER_NAME)).get();
             context.assertEquals("0", zkSs.getSpec().getTemplate().getMetadata().getAnnotations().get(StatefulSetOperator.ANNOTATION_GENERATION));
+            context.assertEquals("0", zkSs.getSpec().getTemplate().getMetadata().getAnnotations().get(Ca.ANNO_STRIMZI_IO_CA_CERT_GENERATION));
             context.assertNotNull(zkSs);
             context.assertNotNull(mockClient.extensions().deployments().inNamespace(NAMESPACE).withName(TopicOperator.topicOperatorName(CLUSTER_NAME)).get());
             context.assertNotNull(mockClient.configMaps().inNamespace(NAMESPACE).withName(KafkaCluster.metricAndLogConfigsName(CLUSTER_NAME)).get());

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -51,11 +51,10 @@
 import static io.strimzi.systemtest.matchers.Matchers.logHasNoUnexpectedErrors;
 import static io.strimzi.test.TestUtils.indent;
 import static java.util.Arrays.asList;
-
-import static org.junit.jupiter.api.Assertions.fail;
+import static org.hamcrest.MatcherAssert.assertThat;
 import static org.junit.jupiter.api.Assertions.assertEquals;
 import static org.junit.jupiter.api.Assertions.assertNotNull;
-import static org.hamcrest.MatcherAssert.assertThat;
+import static org.junit.jupiter.api.Assertions.fail;
 
 
 public class AbstractST {

File: api/src/test/java/io/strimzi/test/StrimziExtension.java
Patch:
@@ -29,6 +29,7 @@
 
 import java.io.File;
 import java.io.IOException;
+import java.io.InputStream;
 import java.lang.annotation.Annotation;
 import java.lang.reflect.AnnotatedElement;
 import java.lang.reflect.Field;
@@ -43,7 +44,6 @@
 import java.util.Map;
 import java.util.Stack;
 import java.util.LinkedHashMap;
-import java.util.Objects;
 import java.util.function.Consumer;
 import java.util.function.Supplier;
 import java.util.stream.Collectors;
@@ -718,8 +718,8 @@ protected void before() {
                 LOGGER.info("Creating cluster operator with Helm Chart {} before test per @ClusterOperator annotation on {}", cc, name(element));
                 Path pathToChart = new File(HELM_CHART).toPath();
                 String oldNamespace = kubeClient().namespace("kube-system");
-                String pathToHelmServiceAccount = Objects.requireNonNull(getClass().getClassLoader().getResource("helm/helm-service-account.yaml")).getPath();
-                String helmServiceAccount = TestUtils.getFileAsString(pathToHelmServiceAccount);
+                InputStream helmAccountAsStream = getClass().getClassLoader().getResourceAsStream("helm/helm-service-account.yaml");
+                String helmServiceAccount = TestUtils.readResource(helmAccountAsStream);
                 kubeClient().applyContent(helmServiceAccount);
                 helmClient().init();
                 kubeClient().namespace(oldNamespace);

File: systemtest/src/test/java/io/strimzi/systemtest/HelmChartST.java
Patch:
@@ -32,7 +32,7 @@ void testDeployKafkaClusterViaHelmChart() {
         resources().kafkaEphemeral(CLUSTER_NAME, 3).done();
         resources().topic(CLUSTER_NAME, TOPIC_NAME).done();
         LOGGER.info("Running testDeployKafkaClusterViaHelmChart {}", CLUSTER_NAME);
-        kubeClient.waitForStatefulSet(zookeeperClusterName(CLUSTER_NAME), 3);
+        kubeClient.waitForStatefulSet(zookeeperClusterName(CLUSTER_NAME), 1);
         kubeClient.waitForStatefulSet(kafkaClusterName(CLUSTER_NAME), 3);
     }
 }

File: api/src/main/java/io/strimzi/api/kafka/model/AclRule.java
Patch:
@@ -45,8 +45,8 @@ public AclRule(AclRuleType type, AclRuleResource resource, String host, AclOpera
         this.operation = operation;
     }
 
-    @Description("The type of the rule." +
-            "Currently the only supported type is `allow`." +
+    @Description("The type of the rule. " +
+            "Currently the only supported type is `allow`. " +
             "ACL rules with type `allow` are used to allow user to execute the specified operations. " +
             "Default value is `allow`.")
     @DefaultValue("allow")

File: api/src/main/java/io/strimzi/api/kafka/model/CertificateAuthority.java
Patch:
@@ -16,7 +16,7 @@
 import java.util.HashMap;
 import java.util.Map;
 
-@Description("Configuration of how TLS certificates are used within the cluster." +
+@Description("Configuration of how TLS certificates are used within the cluster. " +
         "This applies to certificates used for both internal communication within the cluster and to certificates " +
         "used for client access via `Kafka.spec.kafka.listeners.tls`.")
 @Buildable(
@@ -57,7 +57,7 @@ public void setGenerateCertificateAuthority(boolean generateCertificateAuthority
     }
 
     @Description("The number of days in the certificate renewal period. " +
-            "This is the number of days before the a certificate expires during which renewal actions may be performed." +
+            "This is the number of days before the a certificate expires during which renewal actions may be performed. " +
             "When `generateCertificateAuthority` is true, this will cause the generation of a new certificate. " +
             "When `generateCertificateAuthority` is true, this will cause extra logging at WARN level about the pending certificate expiry. " +
             "Default is 30.")

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -75,7 +75,7 @@ public void setImage(String image) {
         this.image = image;
     }
 
-    @Description("List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions." +
+    @Description("List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions. " +
             "Mirroring two topics named A and B can be achieved by using the whitelist `'A|B'`. Or, as a special case, you can mirror all topics using the whitelist '*'. " +
             "Multiple regular expressions separated by commas can be specified as well.")
     @JsonProperty(required = true)

File: api/src/main/java/io/strimzi/api/kafka/model/TlsSidecar.java
Patch:
@@ -29,7 +29,7 @@ public class TlsSidecar extends Sidecar {
     private TlsSidecarLogLevel logLevel = TlsSidecarLogLevel.NOTICE;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
-    @Description("The log level for the TLS sidecar." +
+    @Description("The log level for the TLS sidecar. " +
             "Default value is `notice`.")
     @DefaultValue("notice")
     @JsonInclude(value = JsonInclude.Include.NON_NULL)

File: api/src/main/java/io/strimzi/api/kafka/model/ZookeeperClusterSpec.java
Patch:
@@ -65,8 +65,8 @@ public class ZookeeperClusterSpec implements Serializable {
     private Map<String, Object> metrics = new HashMap<>(0);
     private Affinity affinity;
     private List<Toleration> tolerations;
-    private Map<String, Object> additionalProperties = new HashMap<>(0);
     private ZookeeperClusterTemplate template;
+    private Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Description("The zookeeper broker config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
     @JsonInclude(JsonInclude.Include.NON_EMPTY)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -509,9 +509,11 @@ public StatefulSet generateStatefulSet(boolean isOpenShift) {
         return createStatefulSet(
                 getVolumes(isOpenShift),
                 getVolumeClaims(),
+                getVolumeMounts(),
                 getMergedAffinity(),
                 getInitContainers(),
-                getContainers());
+                getContainers(),
+                isOpenShift);
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -277,9 +277,11 @@ public StatefulSet generateStatefulSet(boolean isOpenShift) {
         return createStatefulSet(
                 getVolumes(isOpenShift),
                 getVolumeClaims(),
+                getVolumeMounts(),
                 getMergedAffinity(),
                 getInitContainers(),
-                getContainers());
+                getContainers(),
+                isOpenShift);
     }
 
     /**

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ConfigMapOperator.java
Patch:
@@ -45,7 +45,7 @@ && compareObjects(current.getMetadata().getLabels(), desired.getMetadata().getLa
                 // Checking some metadata. We cannot check entire metadata object because it contains
                 // timestamps which would cause restarting loop
                 log.debug("{} {} in namespace {} has not been patched because resources are equal", resourceKind, name, namespace);
-                return Future.succeededFuture(ReconcileResult.noop());
+                return Future.succeededFuture(ReconcileResult.noop(current));
             } else {
                 return super.internalPatch(namespace, name, current, desired);
             }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ServiceAccountOperator.java
Patch:
@@ -32,6 +32,6 @@ protected MixedOperation<ServiceAccount, ServiceAccountList, DoneableServiceAcco
     @Override
     protected Future<ReconcileResult<ServiceAccount>> internalPatch(String namespace, String name, ServiceAccount current, ServiceAccount desired) {
         // Patching a SA causes new tokens to be created, which we should avoid
-        return Future.succeededFuture(ReconcileResult.noop());
+        return Future.succeededFuture(ReconcileResult.noop(current));
     }
 }

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/ServiceOperator.java
Patch:
@@ -50,6 +50,7 @@ protected MixedOperation<Service, ServiceList, DoneableService, Resource<Service
      *
      * @return  Future with reconciliation result
      */
+    @Override
     protected Future<ReconcileResult<Service>> internalPatch(String namespace, String name, Service current, Service desired) {
         try {
             if (current.getSpec() != null && desired.getSpec() != null
@@ -58,9 +59,7 @@ protected Future<ReconcileResult<Service>> internalPatch(String namespace, Strin
                 patchNodePorts(current, desired);
             }
 
-            ReconcileResult.Patched<Service> result = ReconcileResult.patched(operation().inNamespace(namespace).withName(name).cascading(true).patch(desired));
-            log.debug("{} {} in namespace {} has been patched", resourceKind, name, namespace);
-            return Future.succeededFuture(result);
+            return super.internalPatch(namespace, name, current, desired);
         } catch (Exception e) {
             log.error("Caught exception while patching {} {} in namespace {}", resourceKind, name, namespace, e);
             return Future.failedFuture(e);

File: operator-common/src/test/java/io/strimzi/operator/common/operator/resource/ServiceAccountOperatorTest.java
Patch:
@@ -19,7 +19,6 @@
 import org.junit.Test;
 
 import static java.util.Collections.singletonMap;
-import static org.junit.Assert.assertTrue;
 import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.matches;
 import static org.mockito.Mockito.mock;
@@ -91,8 +90,8 @@ public void createWhenExistsIsAPatch(TestContext context, boolean cascade) {
             if (!ar.succeeded()) {
                 ar.cause().printStackTrace();
             }
-            assertTrue(ar.succeeded());
-            assertTrue(ar.result().equals(ReconcileResult.noop()));
+            context.assertTrue(ar.succeeded());
+            context.assertTrue(ar.result() instanceof ReconcileResult.Noop);
             verify(mockResource).get();
             //verify(mockResource).patch(any());
             verify(mockResource, never()).create(any());

File: user-operator/src/main/java/io/strimzi/operator/user/operator/ScramShaCredentialsOperator.java
Patch:
@@ -34,7 +34,7 @@ Future<ReconcileResult<Void>> reconcile(String username, String password) {
                         credsManager.delete(username);
                         future.complete(ReconcileResult.deleted());
                     } else {
-                        future.complete(ReconcileResult.noop());
+                        future.complete(ReconcileResult.noop(null));
                     }
                 }
             },

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectS2ISpec.java
Patch:
@@ -16,7 +16,7 @@
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
 @JsonPropertyOrder({ "replicas", "image",
-        "livenessProbe", "readinessProbe", "jvmOptions", "affinity", "metrics"})
+        "livenessProbe", "readinessProbe", "jvmOptions", "affinity", "metrics", "template"})
 public class KafkaConnectS2ISpec extends KafkaConnectSpec {
 
     private static final long serialVersionUID = 1L;

File: api/src/main/java/io/strimzi/api/kafka/model/PersistentClaimStorage.java
Patch:
@@ -58,8 +58,7 @@ public void setStorageClass(String storageClass) {
     }
 
     @Description("Specifies a specific persistent volume to use. " +
-            "It contains a matchLabels field which defines an inner JSON object with " +
-            "key:value representing labels for selecting such a volume.")
+            "It contains key:value pairs representing labels for selecting such a volume.")
     public Map<String, String> getSelector() {
         return selector;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -1043,11 +1043,11 @@ String getAncillaryConfigMapKeyLogConfig() {
         return ANCILLARY_CM_KEY_LOG_CONFIG;
     }
 
-    public static String getClusterCaName(String cluster)  {
+    public static String clusterCaCertSecretName(String cluster)  {
         return cluster + "-cluster-ca-cert";
     }
 
-    public static String getClusterCaKeyName(String cluster)  {
+    public static String clusterCaKeySecretName(String cluster)  {
         return cluster + "-cluster-ca";
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -44,9 +44,9 @@ public ClusterCa(CertManager certManager,
                      int renewalDays,
                      boolean generateCa) {
         super(certManager, "cluster-ca",
-                AbstractModel.getClusterCaName(clusterName),
+                AbstractModel.clusterCaCertSecretName(clusterName),
                 forceRenewal(clusterCaCert, clusterCaKey, "cluster-ca.key"),
-                AbstractModel.getClusterCaKeyName(clusterName),
+                AbstractModel.clusterCaKeySecretName(clusterName),
                 adapt060ClusterCaSecret(clusterCaKey),
                 validityDays, renewalDays, generateCa);
         this.clusterName = clusterName;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -212,7 +212,7 @@ private List<Volume> getVolumes(boolean isOpenShift) {
             volumeList.addAll(userOperator.getVolumes());
         }
         volumeList.add(createSecretVolume(TLS_SIDECAR_EO_CERTS_VOLUME_NAME, EntityOperator.secretName(cluster), isOpenShift));
-        volumeList.add(createSecretVolume(TLS_SIDECAR_CA_CERTS_VOLUME_NAME, AbstractModel.getClusterCaName(cluster), isOpenShift));
+        volumeList.add(createSecretVolume(TLS_SIDECAR_CA_CERTS_VOLUME_NAME, AbstractModel.clusterCaCertSecretName(cluster), isOpenShift));
         return volumeList;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -190,8 +190,8 @@ protected List<EnvVar> getEnvVars() {
         varList.add(buildEnvVar(ENV_VAR_WATCHED_NAMESPACE, watchedNamespace));
         varList.add(buildEnvVar(ENV_VAR_FULL_RECONCILIATION_INTERVAL_MS, Long.toString(reconciliationIntervalMs)));
         varList.add(buildEnvVar(ENV_VAR_ZOOKEEPER_SESSION_TIMEOUT_MS, Long.toString(zookeeperSessionTimeoutMs)));
-        varList.add(buildEnvVar(ENV_VAR_CLIENTS_CA_KEY_SECRET_NAME, KafkaCluster.clientsCASecretName(cluster)));
-        varList.add(buildEnvVar(ENV_VAR_CLIENTS_CA_CERT_SECRET_NAME, KafkaCluster.clientsPublicKeyName(cluster)));
+        varList.add(buildEnvVar(ENV_VAR_CLIENTS_CA_KEY_SECRET_NAME, KafkaCluster.clientsCaKeySecretName(cluster)));
+        varList.add(buildEnvVar(ENV_VAR_CLIENTS_CA_CERT_SECRET_NAME, KafkaCluster.clientsCaCertSecretName(cluster)));
         return varList;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -344,7 +344,7 @@ private List<Volume> getVolumes(boolean isOpenShift) {
         List<Volume> volumeList = new ArrayList<>();
         volumeList.add(createConfigMapVolume(logAndMetricsConfigVolumeName, ancillaryConfigName));
         volumeList.add(createSecretVolume(TLS_SIDECAR_EO_CERTS_VOLUME_NAME, TopicOperator.secretName(cluster), isOpenShift));
-        volumeList.add(createSecretVolume(TLS_SIDECAR_CA_CERTS_VOLUME_NAME, AbstractModel.getClusterCaName(cluster), isOpenShift));
+        volumeList.add(createSecretVolume(TLS_SIDECAR_CA_CERTS_VOLUME_NAME, AbstractModel.clusterCaCertSecretName(cluster), isOpenShift));
         return volumeList;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -389,7 +389,7 @@ private List<Volume> getVolumes(boolean isOpenShift) {
         }
         volumeList.add(createConfigMapVolume(logAndMetricsConfigVolumeName, ancillaryConfigName));
         volumeList.add(createSecretVolume(TLS_SIDECAR_NODES_VOLUME_NAME, ZookeeperCluster.nodesSecretName(cluster), isOpenShift));
-        volumeList.add(createSecretVolume(TLS_SIDECAR_CLUSTER_CA_VOLUME_NAME, AbstractModel.getClusterCaName(cluster), isOpenShift));
+        volumeList.add(createSecretVolume(TLS_SIDECAR_CLUSTER_CA_VOLUME_NAME, AbstractModel.clusterCaCertSecretName(cluster), isOpenShift));
         return volumeList;
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -70,8 +70,8 @@ private List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_WATCHED_NAMESPACE).withValue(uoWatchedNamespace).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_FULL_RECONCILIATION_INTERVAL_MS).withValue(String.valueOf(uoReconciliationInterval * 1000)).build());
         expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_ZOOKEEPER_SESSION_TIMEOUT_MS).withValue(String.valueOf(uoZookeeperSessionTimeout * 1000)).build());
-        expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_KEY_SECRET_NAME).withValue(KafkaCluster.clientsCASecretName(cluster)).build());
-        expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_CERT_SECRET_NAME).withValue(KafkaCluster.clientsPublicKeyName(cluster)).build());
+        expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_KEY_SECRET_NAME).withValue(KafkaCluster.clientsCaKeySecretName(cluster)).build());
+        expected.add(new EnvVarBuilder().withName(EntityUserOperator.ENV_VAR_CLIENTS_CA_CERT_SECRET_NAME).withValue(KafkaCluster.clientsCaCertSecretName(cluster)).build());
         return expected;
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -666,9 +666,7 @@ private Secret generateBrokerSecret(String externalBootstrapAddress, Map<Integer
         ClusterCa clusterCa = new ClusterCa(new OpenSslCertManager(), cluster, null, null);
         clusterCa.createOrRenew(namespace, cluster, emptyMap(), null);
 
-        ClientsCa clientsCa = new ClientsCa(new OpenSslCertManager(), KafkaCluster.getClusterCaKeyName(cluster), null, KafkaCluster.clientsCASecretName(cluster), null, 365, 30, true);
-
-        kc.generateCertificates(kafkaAssembly, clusterCa, clientsCa, externalBootstrapAddress, externalAddresses);
+        kc.generateCertificates(kafkaAssembly, clusterCa, externalBootstrapAddress, externalAddresses);
         return kc.generateBrokersSecret();
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -516,11 +516,9 @@ public StatefulSet generateStatefulSet(boolean isOpenShift) {
         return createStatefulSet(
                 getVolumes(isOpenShift),
                 getVolumeClaims(),
-                getVolumeMounts(),
                 getMergedAffinity(),
                 getInitContainers(),
-                getContainers(),
-                isOpenShift);
+                getContainers());
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -277,11 +277,9 @@ public StatefulSet generateStatefulSet(boolean isOpenShift) {
         return createStatefulSet(
                 getVolumes(isOpenShift),
                 getVolumeClaims(),
-                getVolumeMounts(),
                 getMergedAffinity(),
                 getInitContainers(),
-                getContainers(),
-                isOpenShift);
+                getContainers());
     }
 
     /**

File: certificate-manager/src/main/java/io/strimzi/certs/SecretCertProvider.java
Patch:
@@ -71,7 +71,6 @@ public Secret createSecret(String namespace, String name, String keyKey, String
      * @param cert certificate to store
      * @param labels Labels to add to the Secret
      * @return the Secret
-     * @throws IOException
      */
     public Secret createSecret(String namespace, String name, String keyKey, String certKey, byte[] key, byte[] cert, Map<String, String> labels, OwnerReference ownerReference) {
         Map<String, String> data = new HashMap<>();
@@ -92,7 +91,6 @@ public Secret createSecret(String namespace, String name, String keyKey, String
      * @param data Map with secret data / files
      * @param labels Labels to add to the Secret
      * @return the Secret
-     * @throws IOException
      */
     public Secret createSecret(String namespace, String name, Map<String, String> data, Map<String, String> labels, OwnerReference ownerReference) {
         Secret secret = new SecretBuilder()
@@ -117,7 +115,6 @@ public Secret createSecret(String namespace, String name, Map<String, String> da
      * @param key private key to store
      * @param cert certificate to store
      * @return the Secret
-     * @throws IOException
      */
     public Secret addSecret(Secret secret, String keyKey, String certKey, byte[] key, byte[] cert) {
         Base64.Encoder encoder = Base64.getEncoder();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -406,7 +406,7 @@ public Service generateExternalBootstrapService() {
     }
 
     /**
-     * Generates service for pod {@pod}. This service is used for exposing it externally.
+     * Generates service for pod. This service is used for exposing it externally.
      *
      * @param pod   Number of the pod for which this service should be generated
      * @return The generated Service
@@ -427,7 +427,7 @@ public Service generateExternalService(int pod) {
     }
 
     /**
-     * Generates route for pod {@pod}. This route is used for exposing it externally using OpenShift Routes.
+     * Generates route for pod. This route is used for exposing it externally using OpenShift Routes.
      *
      * @param pod   Number of the pod for which this route should be generated
      * @return The generated Route

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -131,7 +131,7 @@ protected static String name(HasMetadata resource) {
      * Reconciliation works by getting the assembly resource (e.g. {@code KafkaAssembly}) in the given namespace with the given name and
      * comparing with the corresponding {@linkplain #getResources(String, Labels) resource}.
      * <ul>
-     * <li>An assembly will be {@linkplain #createOrUpdate(Reconciliation, T) created or updated} if ConfigMap is without same-named resources</li>
+     * <li>An assembly will be {@linkplain #createOrUpdate(Reconciliation, HasMetadata) created or updated} if ConfigMap is without same-named resources</li>
      * <li>An assembly will be {@linkplain #delete(Reconciliation) deleted} if resources without same-named ConfigMap</li>
      * </ul>
      */
@@ -193,7 +193,7 @@ public final void reconcileAssembly(Reconciliation reconciliation, Handler<Async
      * Reconciliation works by getting the assembly ConfigMaps in the given namespace with the given selector and
      * comparing with the corresponding {@linkplain #getResources(String, Labels) resource}.
      * <ul>
-     * <li>An assembly will be {@linkplain #createOrUpdate(Reconciliation, T) created} for all ConfigMaps without same-named resources</li>
+     * <li>An assembly will be {@linkplain #createOrUpdate(Reconciliation, HasMetadata) created} for all ConfigMaps without same-named resources</li>
      * <li>An assembly will be {@linkplain #delete(Reconciliation) deleted} for all resources without same-named ConfigMaps</li>
      * </ul>
      *

File: operator-common/src/main/java/io/strimzi/operator/common/model/Labels.java
Patch:
@@ -119,7 +119,7 @@ public static Labels fromMap(Map<String, String> labels) {
      *
      * @param stringLabels  String with labels
      * @return  Labels object with parsed labels
-     * @throws IllegalArgumentException|
+     * @throws IllegalArgumentException
      */
     public static Labels fromString(String stringLabels) throws IllegalArgumentException {
         Map<String, String> labels = new HashMap<>();

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -139,7 +139,6 @@ public static String changeOrgAndTag(String image) {
      * @param cls The class relative to which the resource will be loaded.
      * @param resourceName The name of the resource
      * @return The resource content
-     * @throws IOException
      */
     public static String readResource(Class<?> cls, String resourceName) {
         try {

File: topic-operator/src/main/java/io/strimzi/operator/topic/TopicDiff.java
Patch:
@@ -13,7 +13,7 @@
  * Represents the difference between two topics.
  * {@code TopicDiff}s are {@linkplain #diff(Topic, Topic) computed} from a source topic to a target topic
  * with the invariant that:
- * <pre></pre><code>
+ * <pre><code>
  *     TopicDiff.diff(topicA, topicB).apply(topicA).equals(topicB)
  * </code></pre>
  */

File: user-operator/src/main/java/io/strimzi/operator/user/operator/ScramShaCredentials.java
Patch:
@@ -40,7 +40,7 @@ public ScramShaCredentials(String zookeeper) {
 
     /**
      * Create or update the SCRAM-SHA credentials for the given user.
-     * @param iterations If <= 0 the default number of iterations will be used.
+     * @param iterations If &lt;= 0 the default number of iterations will be used.
      */
     public void createOrUpdate(String username, String password, int iterations) {
         if (0 < iterations && iterations < mechanism.minIterations()) {

File: crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java
Patch:
@@ -506,7 +506,7 @@ public static void main(String[] args) throws IOException, ClassNotFoundExceptio
         }
 
         CrdGenerator generator = new CrdGenerator(yaml ?
-                new YAMLMapper().configure(YAMLGenerator.Feature.MINIMIZE_QUOTES, true) :
+                new YAMLMapper().configure(YAMLGenerator.Feature.MINIMIZE_QUOTES, true).configure(YAMLGenerator.Feature.WRITE_DOC_START_MARKER, false) :
                 new ObjectMapper(), labels);
         for (Map.Entry<String, Class<? extends CustomResource>> entry : classes.entrySet()) {
             File file = new File(entry.getKey());

File: crd-generator/src/test/java/io/strimzi/crdgenerator/CrdGeneratorTest.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.crdgenerator;
 
+import com.fasterxml.jackson.dataformat.yaml.YAMLGenerator;
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
 import org.junit.Test;
 
@@ -18,7 +19,7 @@
 public class CrdGeneratorTest {
     @Test
     public void simpleTest() throws IOException, URISyntaxException {
-        CrdGenerator crdGenerator = new CrdGenerator(new YAMLMapper());
+        CrdGenerator crdGenerator = new CrdGenerator(new YAMLMapper().configure(YAMLGenerator.Feature.WRITE_DOC_START_MARKER, false));
         StringWriter w = new StringWriter();
         crdGenerator.generate(ExampleCrd.class, w);
         String s = w.toString();
@@ -33,7 +34,7 @@ public void generateHelmMetadataLabels() throws IOException {
         labels.put("component", "%plural%.%group%-crd");
         labels.put("release", "{{ .Release.Name }}");
         labels.put("heritage", "{{ .Release.Service }}");
-        CrdGenerator crdGenerator = new CrdGenerator(new YAMLMapper(), labels);
+        CrdGenerator crdGenerator = new CrdGenerator(new YAMLMapper().configure(YAMLGenerator.Feature.WRITE_DOC_START_MARKER, false), labels);
         StringWriter w = new StringWriter();
         crdGenerator.generate(ExampleCrd.class, w);
         String s = w.toString();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -59,7 +59,7 @@
 import java.util.TreeMap;
 import java.util.function.BiFunction;
 
-import static io.strimzi.operator.cluster.ClusterOperator.STRIMZI_CLUSTER_OPERATOR_DOMAIN;
+import static io.strimzi.operator.common.operator.resource.AbstractScalableResourceOperator.STRIMZI_OPERATOR_DOMAIN;
 
 /**
  * <p>Assembly operator for a "Kafka" assembly, which manages:</p>
@@ -85,7 +85,7 @@ public class KafkaAssemblyOperator extends AbstractAssemblyOperator<KubernetesCl
     private final RoleBindingOperator roleBindingOperator;
     private final ClusterRoleBindingOperator clusterRoleBindingOperator;
 
-    public static final String ANNOTATION_MANUAL_RESTART = STRIMZI_CLUSTER_OPERATOR_DOMAIN + "/manual-rolling-update";
+    public static final String ANNOTATION_MANUAL_RESTART = STRIMZI_OPERATOR_DOMAIN + "/manual-rolling-update";
 
     /**
      * @param vertx The Vertx instance

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractScalableResourceOperator.java
Patch:
@@ -30,9 +30,9 @@ public abstract class AbstractScalableResourceOperator<C extends KubernetesClien
             R extends ScalableResource<T, D>>
         extends AbstractReadyResourceOperator<C, T, L, D, R> {
 
-    public static final String STRIMZI_CLUSTER_OPERATOR_DOMAIN = "operator.strimzi.io";
-    public static final String ANNOTATION_GENERATION = STRIMZI_CLUSTER_OPERATOR_DOMAIN + "/generation";
-    public static final String ANNOTATION_MANUAL_DELETE_POD_AND_PVC = STRIMZI_CLUSTER_OPERATOR_DOMAIN + "/delete-pod-and-pvc";
+    public static final String STRIMZI_OPERATOR_DOMAIN = "operator.strimzi.io";
+    public static final String ANNOTATION_GENERATION = STRIMZI_OPERATOR_DOMAIN + "/generation";
+    public static final String ANNOTATION_MANUAL_DELETE_POD_AND_PVC = STRIMZI_OPERATOR_DOMAIN + "/delete-pod-and-pvc";
 
     private final Logger log = LogManager.getLogger(getClass());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -59,7 +59,7 @@
 import java.util.TreeMap;
 import java.util.function.BiFunction;
 
-import static io.strimzi.operator.cluster.ClusterOperator.STRIMZI_CLUSTER_OPERATOR_DOMAIN;
+import static io.strimzi.operator.common.operator.resource.AbstractScalableResourceOperator.STRIMZI_OPERATOR_DOMAIN;
 
 /**
  * <p>Assembly operator for a "Kafka" assembly, which manages:</p>
@@ -85,7 +85,7 @@ public class KafkaAssemblyOperator extends AbstractAssemblyOperator<KubernetesCl
     private final RoleBindingOperator roleBindingOperator;
     private final ClusterRoleBindingOperator clusterRoleBindingOperator;
 
-    public static final String ANNOTATION_MANUAL_RESTART = STRIMZI_CLUSTER_OPERATOR_DOMAIN + "/manual-rolling-update";
+    public static final String ANNOTATION_MANUAL_RESTART = STRIMZI_OPERATOR_DOMAIN + "/manual-rolling-update";
 
     /**
      * @param vertx The Vertx instance

File: operator-common/src/main/java/io/strimzi/operator/common/operator/resource/AbstractScalableResourceOperator.java
Patch:
@@ -30,9 +30,9 @@ public abstract class AbstractScalableResourceOperator<C extends KubernetesClien
             R extends ScalableResource<T, D>>
         extends AbstractReadyResourceOperator<C, T, L, D, R> {
 
-    public static final String STRIMZI_CLUSTER_OPERATOR_DOMAIN = "operator.strimzi.io";
-    public static final String ANNOTATION_GENERATION = STRIMZI_CLUSTER_OPERATOR_DOMAIN + "/generation";
-    public static final String ANNOTATION_MANUAL_DELETE_POD_AND_PVC = STRIMZI_CLUSTER_OPERATOR_DOMAIN + "/delete-pod-and-pvc";
+    public static final String STRIMZI_OPERATOR_DOMAIN = "operator.strimzi.io";
+    public static final String ANNOTATION_GENERATION = STRIMZI_OPERATOR_DOMAIN + "/generation";
+    public static final String ANNOTATION_MANUAL_DELETE_POD_AND_PVC = STRIMZI_OPERATOR_DOMAIN + "/delete-pod-and-pvc";
 
     private final Logger log = LogManager.getLogger(getClass());
 

File: user-operator/src/test/java/io/strimzi/operator/user/model/KafkaUserModelTest.java
Patch:
@@ -176,6 +176,7 @@ public void testDecodeUsername()    {
 
     @Test
     public void testGetUsername()    {
-        assertEquals("CN=my-user", KafkaUserModel.getUserName("my-user"));
+        assertEquals("CN=my-user", KafkaUserModel.getTlsUserName("my-user"));
+        assertEquals("my-user", KafkaUserModel.getScramUserName("my-user"));
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -68,7 +68,7 @@ public static KafkaConnectS2ICluster fromCrd(KafkaConnectS2I kafkaConnectS2I) {
      *
      * @return      Source ImageStream resource definition
      */
-    public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations) {
+    public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations, boolean isOpenShift) {
         Container container = new ContainerBuilder()
                 .withName(name)
                 .withImage(image)
@@ -121,7 +121,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                         .endMetadata()
                         .withNewSpec()
                             .withContainers(container)
-                            .withVolumes(getVolumes())
+                            .withVolumes(getVolumes(isOpenShift))
                             .withTolerations(getTolerations())
                             .withAffinity(getMergedAffinity())
                         .endSpec()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -980,7 +980,7 @@ private final Future<ReconciliationState> getTopicOperatorDescription() {
                                     topicOperator.getLogging() instanceof ExternalLogging ?
                                             configMapOperations.get(kafkaAssembly.getMetadata().getNamespace(), ((ExternalLogging) topicOperator.getLogging()).getName()) :
                                             null);
-                            this.toDeployment = topicOperator.generateDeployment();
+                            this.toDeployment = topicOperator.generateDeployment(isOpenShift);
                             this.toMetricsAndLogsConfigMap = logAndMetricsConfigMap;
                             this.toDeployment.getSpec().getTemplate().getMetadata().getAnnotations().put("strimzi.io/logging", this.toMetricsAndLogsConfigMap.getData().get("log4j2.properties"));
                         } else {
@@ -1065,7 +1065,7 @@ private final Future<ReconciliationState> getEntityOperatorDescription() {
                                             null) : null;
 
                             this.entityOperator = entityOperator;
-                            this.eoDeployment = entityOperator.generateDeployment();
+                            this.eoDeployment = entityOperator.generateDeployment(isOpenShift);
                             this.topicOperatorMetricsAndLogsConfigMap = topicOperatorLogAndMetricsConfigMap;
                             this.userOperatorMetricsAndLogsConfigMap = userOperatorLogAndMetricsConfigMap;
                         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -90,7 +90,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
         return deploymentOperations.scaleDown(namespace, connect.getName(), connect.getReplicas())
                 .compose(scale -> serviceOperations.reconcile(namespace, connect.getServiceName(), connect.generateService()))
                 .compose(i -> configMapOperations.reconcile(namespace, connect.getAncillaryConfigName(), logAndMetricsConfigMap))
-                .compose(i -> deploymentOperations.reconcile(namespace, connect.getName(), connect.generateDeployment(annotations)))
+                .compose(i -> deploymentOperations.reconcile(namespace, connect.getName(), connect.generateDeployment(annotations, isOpenShift)))
                 .compose(i -> deploymentOperations.scaleUp(namespace, connect.getName(), connect.getReplicas()).map((Void) null));
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -100,7 +100,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
             return deploymentConfigOperations.scaleDown(namespace, connect.getName(), connect.getReplicas())
                     .compose(scale -> serviceOperations.reconcile(namespace, connect.getServiceName(), connect.generateService()))
                     .compose(i -> configMapOperations.reconcile(namespace, connect.getAncillaryConfigName(), logAndMetricsConfigMap))
-                    .compose(i -> deploymentConfigOperations.reconcile(namespace, connect.getName(), connect.generateDeploymentConfig(annotations)))
+                    .compose(i -> deploymentConfigOperations.reconcile(namespace, connect.getName(), connect.generateDeploymentConfig(annotations, isOpenShift)))
                     .compose(i -> imagesStreamOperations.reconcile(namespace, connect.getSourceImageStreamName(), connect.generateSourceImageStream()))
                     .compose(i -> imagesStreamOperations.reconcile(namespace, connect.getName(), connect.generateTargetImageStream()))
                     .compose(i -> buildConfigOperations.reconcile(namespace, connect.getName(), connect.generateBuildConfig()))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -91,7 +91,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
         return deploymentOperations.scaleDown(namespace, mirror.getName(), mirror.getReplicas())
                 .compose(scale -> serviceOperations.reconcile(namespace, mirror.getServiceName(), mirror.generateService()))
                 .compose(i -> configMapOperations.reconcile(namespace, mirror.getAncillaryConfigName(), logAndMetricsConfigMap))
-                .compose(i -> deploymentOperations.reconcile(namespace, mirror.getName(), mirror.generateDeployment(annotations)))
+                .compose(i -> deploymentOperations.reconcile(namespace, mirror.getName(), mirror.generateDeployment(annotations, isOpenShift)))
                 .compose(i -> deploymentOperations.scaleUp(namespace, mirror.getName(), mirror.getReplicas()).map((Void) null));
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -65,7 +65,7 @@ static Map<String, String> volumeMounts(List<VolumeMount> mounts) {
     @Test
     public void testGenerateDeployment() {
 
-        Deployment dep = entityOperator.generateDeployment();
+        Deployment dep = entityOperator.generateDeployment(true);
 
         List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();
 
@@ -117,7 +117,7 @@ public void testFromCrdNoTopicAndUserOperatorInEntityOperator() {
 
     @Test
     public void withAffinity() throws IOException {
-        helper.assertDesiredResource("-Deployment.yaml", zc -> zc.generateDeployment().getSpec().getTemplate().getSpec().getAffinity());
+        helper.assertDesiredResource("-Deployment.yaml", zc -> zc.generateDeployment(true).getSpec().getTemplate().getSpec().getAffinity());
     }
 
     @AfterClass

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/TopicOperatorTest.java
Patch:
@@ -142,7 +142,7 @@ public void testFromConfigMap() {
     @Test
     public void testGenerateDeployment() {
 
-        Deployment dep = tc.generateDeployment();
+        Deployment dep = tc.generateDeployment(true);
 
         List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();
 
@@ -187,7 +187,7 @@ public void testEnvVars()   {
 
     @Test
     public void withAffinity() throws IOException {
-        helper.assertDesiredResource("-Deployment.yaml", zc -> zc.generateDeployment().getSpec().getTemplate().getSpec().getAffinity());
+        helper.assertDesiredResource("-Deployment.yaml", zc -> zc.generateDeployment(true).getSpec().getTemplate().getSpec().getAffinity());
     }
 
     private void assertLoggingConfig(Deployment dep) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -677,12 +677,12 @@ private void updateCluster(TestContext context, Kafka originalAssembly, Kafka up
         // Mock Deployment get
         if (originalTopicOperator != null) {
             when(mockDepOps.get(clusterNamespace, TopicOperator.topicOperatorName(clusterName))).thenReturn(
-                    originalTopicOperator.generateDeployment()
+                    originalTopicOperator.generateDeployment(true)
             );
         }
         if (originalEntityOperator != null) {
             when(mockDepOps.get(clusterNamespace, EntityOperator.entityOperatorName(clusterName))).thenReturn(
-                    originalEntityOperator.generateDeployment()
+                    originalEntityOperator.generateDeployment(true)
             );
         }
 

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleClusterResource.java
Patch:
@@ -4,9 +4,9 @@
  */
 package io.strimzi.api.kafka.model;
 
-import io.strimzi.crdgenerator.annotations.Description;
-
 import com.fasterxml.jackson.annotation.JsonInclude;
+import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
 
 /**
@@ -18,6 +18,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonPropertyOrder({"type"})
 public class AclRuleClusterResource extends AclRuleResource {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleGroupResource.java
Patch:
@@ -4,9 +4,9 @@
  */
 package io.strimzi.api.kafka.model;
 
-import io.strimzi.crdgenerator.annotations.Description;
-
 import com.fasterxml.jackson.annotation.JsonInclude;
+import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
 import io.vertx.core.cli.annotations.DefaultValue;
 
@@ -19,6 +19,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonPropertyOrder({"type", "name", "patternType"})
 public class AclRuleGroupResource extends AclRuleResource {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleTopicResource.java
Patch:
@@ -4,9 +4,9 @@
  */
 package io.strimzi.api.kafka.model;
 
-import io.strimzi.crdgenerator.annotations.Description;
-
 import com.fasterxml.jackson.annotation.JsonInclude;
+import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
 import io.vertx.core.cli.annotations.DefaultValue;
 
@@ -19,6 +19,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonPropertyOrder({"type", "name", "patternType"})
 public class AclRuleTopicResource extends AclRuleResource {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/ExternalLogging.java
Patch:
@@ -5,6 +5,7 @@
 package io.strimzi.api.kafka.model;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
+import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
 
@@ -16,6 +17,7 @@
         generateBuilderPackage = false,
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
+@JsonPropertyOrder({"type", "name"})
 @JsonInclude(JsonInclude.Include.NON_NULL)
 public class ExternalLogging extends Logging {
 

File: api/src/main/java/io/strimzi/api/kafka/model/InlineLogging.java
Patch:
@@ -5,6 +5,7 @@
 package io.strimzi.api.kafka.model;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
+import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
 
@@ -19,6 +20,7 @@
         generateBuilderPackage = false,
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
+@JsonPropertyOrder({"type", "loggers"})
 @JsonInclude(JsonInclude.Include.NON_NULL)
 public class InlineLogging extends Logging {
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectAuthentication.java
Patch:
@@ -6,7 +6,6 @@
 
 import com.fasterxml.jackson.annotation.JsonAnyGetter;
 import com.fasterxml.jackson.annotation.JsonAnySetter;
-import com.fasterxml.jackson.annotation.JsonIgnore;
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonSubTypes;
 import com.fasterxml.jackson.annotation.JsonTypeInfo;
@@ -19,7 +18,9 @@
 /**
  * Configures the Kafka Connect authentication
  */
-@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = "type")
+@JsonTypeInfo(use = JsonTypeInfo.Id.NAME,
+        include = JsonTypeInfo.As.EXISTING_PROPERTY,
+        property = "type")
 @JsonSubTypes({
         @JsonSubTypes.Type(name = KafkaConnectAuthenticationTls.TYPE_TLS, value = KafkaConnectAuthenticationTls.class),
         @JsonSubTypes.Type(name = KafkaConnectAuthenticationScramSha512.TYPE_SCRAM_SHA_512, value = KafkaConnectAuthenticationScramSha512.class),
@@ -35,7 +36,6 @@ public abstract class KafkaConnectAuthentication implements Serializable {
             "`scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. " +
             "`tls` type uses TLS Client Authentication. " +
             "`tls` type is supported only over TLS connections.")
-    @JsonIgnore
     public abstract String getType();
 
     @JsonAnyGetter

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaListenerAuthentication.java
Patch:
@@ -6,7 +6,6 @@
 
 import com.fasterxml.jackson.annotation.JsonAnyGetter;
 import com.fasterxml.jackson.annotation.JsonAnySetter;
-import com.fasterxml.jackson.annotation.JsonIgnore;
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonSubTypes;
 import com.fasterxml.jackson.annotation.JsonTypeInfo;
@@ -20,7 +19,9 @@
 /**
  * Configures listener authentication.
  */
-@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = "type")
+@JsonTypeInfo(use = JsonTypeInfo.Id.NAME,
+        include = JsonTypeInfo.As.EXISTING_PROPERTY,
+        property = "type")
 @JsonSubTypes({
         @JsonSubTypes.Type(name = KafkaListenerAuthenticationTls.TYPE_TLS, value = KafkaListenerAuthenticationTls.class),
         @JsonSubTypes.Type(name = KafkaListenerAuthenticationScramSha512.SCRAM_SHA_512, value = KafkaListenerAuthenticationScramSha512.class),
@@ -40,7 +41,6 @@ public abstract class KafkaListenerAuthentication implements Serializable {
             "`scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. " +
             "`tls` type uses TLS Client Authentication. " +
             "`tls` type is supported only on TLS listeners.")
-    @JsonIgnore
     public abstract String getType();
 
     @JsonAnyGetter

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaListenerExternalLoadBalancer.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.api.kafka.model;
 
+import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.strimzi.crdgenerator.annotations.Description;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
@@ -19,6 +20,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonPropertyOrder({"type", "authentication"})
 public class KafkaListenerExternalLoadBalancer extends KafkaListenerExternal {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaListenerExternalNodePort.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.api.kafka.model;
 
+import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.strimzi.crdgenerator.annotations.Description;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
@@ -19,6 +20,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonPropertyOrder({"type", "authentication"})
 public class KafkaListenerExternalNodePort extends KafkaListenerExternal {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaListenerExternalRoute.java
Patch:
@@ -4,10 +4,10 @@
  */
 package io.strimzi.api.kafka.model;
 
-import io.strimzi.crdgenerator.annotations.Description;
-
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.annotation.JsonPropertyOrder;
+import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
 
 /**
@@ -19,6 +19,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonPropertyOrder({"type", "authentication"})
 public class KafkaListenerExternalRoute extends KafkaListenerExternal {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerAuthentication.java
Patch:
@@ -6,7 +6,6 @@
 
 import com.fasterxml.jackson.annotation.JsonAnyGetter;
 import com.fasterxml.jackson.annotation.JsonAnySetter;
-import com.fasterxml.jackson.annotation.JsonIgnore;
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonSubTypes;
 import com.fasterxml.jackson.annotation.JsonTypeInfo;
@@ -19,7 +18,9 @@
 /**
  * Configures the Kafka Mirror Maker authentication
  */
-@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = "type")
+@JsonTypeInfo(use = JsonTypeInfo.Id.NAME,
+        include = JsonTypeInfo.As.EXISTING_PROPERTY,
+        property = "type")
 @JsonSubTypes({
         @JsonSubTypes.Type(name = KafkaMirrorMakerAuthenticationTls.TYPE_TLS, value = KafkaMirrorMakerAuthenticationTls.class),
         @JsonSubTypes.Type(name = KafkaMirrorMakerAuthenticationScramSha512.TYPE_SCRAM_SHA_512, value = KafkaMirrorMakerAuthenticationScramSha512.class),
@@ -35,7 +36,6 @@ public abstract class KafkaMirrorMakerAuthentication implements Serializable {
             "`scram-sha-512` type uses SASL SCRAM-SHA-512 Authentication. " +
             "The `tls` type uses TLS Client Authentication. " +
             "The `tls` type is supported only over TLS connections.")
-    @JsonIgnore
     public abstract String getType();
 
     @JsonAnyGetter

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUserAuthentication.java
Patch:
@@ -6,7 +6,6 @@
 
 import com.fasterxml.jackson.annotation.JsonAnyGetter;
 import com.fasterxml.jackson.annotation.JsonAnySetter;
-import com.fasterxml.jackson.annotation.JsonIgnore;
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonSubTypes;
 import com.fasterxml.jackson.annotation.JsonTypeInfo;
@@ -16,7 +15,9 @@
 import java.util.HashMap;
 import java.util.Map;
 
-@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = "type")
+@JsonTypeInfo(use = JsonTypeInfo.Id.NAME,
+        include = JsonTypeInfo.As.EXISTING_PROPERTY,
+        property = "type")
 @JsonSubTypes({
         @JsonSubTypes.Type(name = KafkaUserTlsClientAuthentication.TYPE_TLS, value = KafkaUserTlsClientAuthentication.class),
         @JsonSubTypes.Type(name = KafkaUserScramSha512ClientAuthentication.TYPE_SCRAM_SHA_512, value = KafkaUserScramSha512ClientAuthentication.class),
@@ -28,7 +29,6 @@ public abstract class KafkaUserAuthentication implements Serializable {
     private Map<String, Object> additionalProperties;
 
     @Description("Authentication type.")
-    @JsonIgnore
     public abstract String getType();
 
     @JsonAnyGetter

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaUserAuthorizationSimple.java
Patch:
@@ -4,10 +4,10 @@
  */
 package io.strimzi.api.kafka.model;
 
+import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.strimzi.crdgenerator.annotations.Description;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
 import io.sundr.builder.annotations.Buildable;
 
 import java.util.List;
@@ -21,6 +21,7 @@
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
 @JsonInclude(JsonInclude.Include.NON_NULL)
+@JsonPropertyOrder({"type", "acls"})
 public class KafkaUserAuthorizationSimple extends KafkaUserAuthorization {
     private static final long serialVersionUID = 1L;
 

File: api/src/main/java/io/strimzi/api/kafka/model/Logging.java
Patch:
@@ -4,7 +4,6 @@
  */
 package io.strimzi.api.kafka.model;
 
-import com.fasterxml.jackson.annotation.JsonIgnore;
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonSubTypes;
 import com.fasterxml.jackson.annotation.JsonTypeInfo;
@@ -15,7 +14,9 @@
 /**
  * Describes the logging configuration
  */
-@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = "type")
+@JsonTypeInfo(use = JsonTypeInfo.Id.NAME,
+        include = JsonTypeInfo.As.EXISTING_PROPERTY,
+        property = "type")
 @JsonSubTypes({
         @JsonSubTypes.Type(name = InlineLogging.TYPE_INLINE, value = InlineLogging.class),
         @JsonSubTypes.Type(name = ExternalLogging.TYPE_EXTERNAL, value = ExternalLogging.class),
@@ -26,7 +27,6 @@ public abstract class Logging implements Serializable {
     private static final long serialVersionUID = 1L;
 
     @Description("Logging type, must be either 'inline' or 'external'.")
-    @JsonIgnore
     public abstract String getType();
 }
 

File: api/src/main/java/io/strimzi/api/kafka/model/PersistentClaimStorage.java
Patch:
@@ -6,6 +6,7 @@
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonProperty;
+import com.fasterxml.jackson.annotation.JsonPropertyOrder;
 import io.strimzi.crdgenerator.annotations.Description;
 import io.sundr.builder.annotations.Buildable;
 
@@ -19,6 +20,7 @@
         generateBuilderPackage = false,
         builderPackage = "io.fabric8.kubernetes.api.builder"
 )
+@JsonPropertyOrder({"type", "size", "storageClass", "selector", "deleteClaim"})
 @JsonInclude(JsonInclude.Include.NON_NULL)
 public class PersistentClaimStorage extends Storage {
 

File: api/src/main/java/io/strimzi/api/kafka/model/Storage.java
Patch:
@@ -6,7 +6,6 @@
 
 import com.fasterxml.jackson.annotation.JsonAnyGetter;
 import com.fasterxml.jackson.annotation.JsonAnySetter;
-import com.fasterxml.jackson.annotation.JsonIgnore;
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.annotation.JsonSubTypes;
 import com.fasterxml.jackson.annotation.JsonTypeInfo;
@@ -21,6 +20,7 @@
  */
 @JsonTypeInfo(
         use = JsonTypeInfo.Id.NAME,
+        include = JsonTypeInfo.As.EXISTING_PROPERTY,
         property = "type"
 )
 @JsonSubTypes({
@@ -37,7 +37,6 @@ public abstract class Storage implements Serializable {
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Description("Storage type, must be either 'ephemeral' or 'persistent-claim'.")
-    @JsonIgnore
     public abstract String getType();
 
     @JsonAnyGetter

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -68,7 +68,7 @@ public static KafkaConnectS2ICluster fromCrd(KafkaConnectS2I kafkaConnectS2I) {
      *
      * @return      Source ImageStream resource definition
      */
-    public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations) {
+    public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations, boolean isOpenShift) {
         Container container = new ContainerBuilder()
                 .withName(name)
                 .withImage(image)
@@ -121,7 +121,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                         .endMetadata()
                         .withNewSpec()
                             .withContainers(container)
-                            .withVolumes(getVolumes())
+                            .withVolumes(getVolumes(isOpenShift))
                             .withTolerations(getTolerations())
                             .withAffinity(getMergedAffinity())
                         .endSpec()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -948,7 +948,7 @@ private final Future<ReconciliationState> getTopicOperatorDescription() {
                                     topicOperator.getLogging() instanceof ExternalLogging ?
                                             configMapOperations.get(kafkaAssembly.getMetadata().getNamespace(), ((ExternalLogging) topicOperator.getLogging()).getName()) :
                                             null);
-                            this.toDeployment = topicOperator.generateDeployment();
+                            this.toDeployment = topicOperator.generateDeployment(isOpenShift);
                             this.toMetricsAndLogsConfigMap = logAndMetricsConfigMap;
                             this.toDeployment.getSpec().getTemplate().getMetadata().getAnnotations().put("strimzi.io/logging", this.toMetricsAndLogsConfigMap.getData().get("log4j2.properties"));
                         } else {
@@ -1033,7 +1033,7 @@ private final Future<ReconciliationState> getEntityOperatorDescription() {
                                             null) : null;
 
                             this.entityOperator = entityOperator;
-                            this.eoDeployment = entityOperator.generateDeployment();
+                            this.eoDeployment = entityOperator.generateDeployment(isOpenShift);
                             this.topicOperatorMetricsAndLogsConfigMap = topicOperatorLogAndMetricsConfigMap;
                             this.userOperatorMetricsAndLogsConfigMap = userOperatorLogAndMetricsConfigMap;
                         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -90,7 +90,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnec
         return deploymentOperations.scaleDown(namespace, connect.getName(), connect.getReplicas())
                 .compose(scale -> serviceOperations.reconcile(namespace, connect.getServiceName(), connect.generateService()))
                 .compose(i -> configMapOperations.reconcile(namespace, connect.getAncillaryConfigName(), logAndMetricsConfigMap))
-                .compose(i -> deploymentOperations.reconcile(namespace, connect.getName(), connect.generateDeployment(annotations)))
+                .compose(i -> deploymentOperations.reconcile(namespace, connect.getName(), connect.generateDeployment(annotations, isOpenShift)))
                 .compose(i -> deploymentOperations.scaleUp(namespace, connect.getName(), connect.getReplicas()).map((Void) null));
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -100,7 +100,7 @@ public Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaConnectS2
             return deploymentConfigOperations.scaleDown(namespace, connect.getName(), connect.getReplicas())
                     .compose(scale -> serviceOperations.reconcile(namespace, connect.getServiceName(), connect.generateService()))
                     .compose(i -> configMapOperations.reconcile(namespace, connect.getAncillaryConfigName(), logAndMetricsConfigMap))
-                    .compose(i -> deploymentConfigOperations.reconcile(namespace, connect.getName(), connect.generateDeploymentConfig(annotations)))
+                    .compose(i -> deploymentConfigOperations.reconcile(namespace, connect.getName(), connect.generateDeploymentConfig(annotations, isOpenShift)))
                     .compose(i -> imagesStreamOperations.reconcile(namespace, connect.getSourceImageStreamName(), connect.generateSourceImageStream()))
                     .compose(i -> imagesStreamOperations.reconcile(namespace, connect.getName(), connect.generateTargetImageStream()))
                     .compose(i -> buildConfigOperations.reconcile(namespace, connect.getName(), connect.generateBuildConfig()))

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaMirrorMakerAssemblyOperator.java
Patch:
@@ -91,7 +91,7 @@ protected Future<Void> createOrUpdate(Reconciliation reconciliation, KafkaMirror
         return deploymentOperations.scaleDown(namespace, mirror.getName(), mirror.getReplicas())
                 .compose(scale -> serviceOperations.reconcile(namespace, mirror.getServiceName(), mirror.generateService()))
                 .compose(i -> configMapOperations.reconcile(namespace, mirror.getAncillaryConfigName(), logAndMetricsConfigMap))
-                .compose(i -> deploymentOperations.reconcile(namespace, mirror.getName(), mirror.generateDeployment(annotations)))
+                .compose(i -> deploymentOperations.reconcile(namespace, mirror.getName(), mirror.generateDeployment(annotations, isOpenShift)))
                 .compose(i -> deploymentOperations.scaleUp(namespace, mirror.getName(), mirror.getReplicas()).map((Void) null));
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -65,7 +65,7 @@ static Map<String, String> volumeMounts(List<VolumeMount> mounts) {
     @Test
     public void testGenerateDeployment() {
 
-        Deployment dep = entityOperator.generateDeployment();
+        Deployment dep = entityOperator.generateDeployment(true);
 
         List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();
 
@@ -117,7 +117,7 @@ public void testFromCrdNoTopicAndUserOperatorInEntityOperator() {
 
     @Test
     public void withAffinity() throws IOException {
-        helper.assertDesiredResource("-Deployment.yaml", zc -> zc.generateDeployment().getSpec().getTemplate().getSpec().getAffinity());
+        helper.assertDesiredResource("-Deployment.yaml", zc -> zc.generateDeployment(true).getSpec().getTemplate().getSpec().getAffinity());
     }
 
     @AfterClass

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/TopicOperatorTest.java
Patch:
@@ -142,7 +142,7 @@ public void testFromConfigMap() {
     @Test
     public void testGenerateDeployment() {
 
-        Deployment dep = tc.generateDeployment();
+        Deployment dep = tc.generateDeployment(true);
 
         List<Container> containers = dep.getSpec().getTemplate().getSpec().getContainers();
 
@@ -187,7 +187,7 @@ public void testEnvVars()   {
 
     @Test
     public void withAffinity() throws IOException {
-        helper.assertDesiredResource("-Deployment.yaml", zc -> zc.generateDeployment().getSpec().getTemplate().getSpec().getAffinity());
+        helper.assertDesiredResource("-Deployment.yaml", zc -> zc.generateDeployment(true).getSpec().getTemplate().getSpec().getAffinity());
     }
 
     private void assertLoggingConfig(Deployment dep) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -677,12 +677,12 @@ private void updateCluster(TestContext context, Kafka originalAssembly, Kafka up
         // Mock Deployment get
         if (originalTopicOperator != null) {
             when(mockDepOps.get(clusterNamespace, TopicOperator.topicOperatorName(clusterName))).thenReturn(
-                    originalTopicOperator.generateDeployment()
+                    originalTopicOperator.generateDeployment(true)
             );
         }
         if (originalEntityOperator != null) {
             when(mockDepOps.get(clusterNamespace, EntityOperator.entityOperatorName(clusterName))).thenReturn(
-                    originalEntityOperator.generateDeployment()
+                    originalEntityOperator.generateDeployment(true)
             );
         }
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -71,7 +71,7 @@ public void setImage(String image) {
     }
 
     @Description("List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions." +
-            "Mirroring two topics named A and B can be achieved by using the whitelist `'A|B'`. Or, as a special case, you can mirror all topics using the whitelist '*'`. " +
+            "Mirroring two topics named A and B can be achieved by using the whitelist `'A|B'`. Or, as a special case, you can mirror all topics using the whitelist '*'. " +
             "Multiple regular expressions separated by commas can be specified as well.")
     @JsonProperty(required = true)
     public String getWhitelist() {

File: crd-generator/src/main/java/io/strimzi/crdgenerator/DocGenerator.java
Patch:
@@ -184,6 +184,7 @@ private String getDescription(Object property, Description description2) {
         if (!doc.trim().matches(".*[.!?]$")) {
             doc = doc + ".";
         }
+        doc = doc.replaceAll("[|]", "\\\\|");
         return doc;
     }
 

File: api/src/test/java/io/strimzi/test/StrimziRunner.java
Patch:
@@ -72,7 +72,7 @@ public class StrimziRunner extends BlockJUnit4ClassRunner {
     public static final String KAFKA_PERSISTENT_YAML = "../examples/kafka/kafka-persistent.yaml";
     public static final String KAFKA_CONNECT_YAML = "../examples/kafka-connect/kafka-connect.yaml";
     public static final String KAFKA_CONNECT_S2I_CM = "../examples/configmaps/cluster-operator/kafka-connect-s2i.yaml";
-    public static final String CO_INSTALL_DIR = "../examples/install/cluster-operator";
+    public static final String CO_INSTALL_DIR = "../install/cluster-operator";
     public static final String CO_DEPLOYMENT_NAME = "strimzi-cluster-operator";
     public static final String TOPIC_CM = "../examples/topic/kafka-topic.yaml";
     public static final String HELM_CHART = "../helm-charts/strimzi-kafka-operator/";

File: topic-operator/src/test/java/io/strimzi/operator/topic/TopicOperatorIT.java
Patch:
@@ -108,7 +108,7 @@ public static void setupKubeCluster() {
                 .createNamespace(NAMESPACE);
         oldNamespace = testCluster.client().namespace(NAMESPACE);
         testCluster.client().clientWithAdmin()
-                .create("../examples/install/topic-operator/02-Role-strimzi-topic-operator.yaml")
+                .create("../install/topic-operator/02-Role-strimzi-topic-operator.yaml")
                 .create(TestUtils.CRD_TOPIC)
                 .create("src/test/resources/TopicOperatorIT-rbac.yaml");
     }
@@ -118,7 +118,7 @@ public static void teardownKubeCluster() {
         testCluster.client().clientWithAdmin()
                 .delete("src/test/resources/TopicOperatorIT-rbac.yaml")
                 .delete(TestUtils.CRD_TOPIC)
-                .delete("../examples/install/topic-operator/02-Role-strimzi-topic-operator.yaml")
+                .delete("../install/topic-operator/02-Role-strimzi-topic-operator.yaml")
                 .deleteNamespace(NAMESPACE);
         testCluster.client().clientWithAdmin().namespace(oldNamespace);
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ClusterOperatorConfigTest.java
Patch:
@@ -48,7 +48,7 @@ public void testDefaultConfig() {
     @Test
     public void testReconciliationInterval() {
 
-        ClusterOperatorConfig config = new ClusterOperatorConfig(singleton("namespace"), 60_000, 30_000);
+        ClusterOperatorConfig config = new ClusterOperatorConfig(singleton("namespace"), 60_000, 30_000, false);
 
         assertEquals(singleton("namespace"), config.getNamespaces());
         assertEquals(60_000, config.getReconciliationIntervalMs());

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerClientSpec.java
Patch:
@@ -28,7 +28,7 @@ public class KafkaMirrorMakerClientSpec implements Serializable {
     private static final long serialVersionUID = 1L;
 
     private String bootstrapServers;
-    protected Map<String, Object> config;
+    protected Map<String, Object> config = new HashMap<>(0);
     private KafkaMirrorMakerTls tls;
     private KafkaMirrorMakerAuthentication authentication;
     private Map<String, Object> additionalProperties;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerConsumerSpec.java
Patch:
@@ -31,7 +31,6 @@ public class KafkaMirrorMakerConsumerSpec extends KafkaMirrorMakerClientSpec {
 
     @Override
     @Description("The mirror maker consumer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public Map<String, Object> getConfig() {
         return config;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerProducerSpec.java
Patch:
@@ -25,7 +25,6 @@ public class KafkaMirrorMakerProducerSpec extends KafkaMirrorMakerClientSpec {
 
     @Override
     @Description("The mirror maker producer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)
-    @JsonInclude(JsonInclude.Include.NON_EMPTY)
     public Map<String, Object> getConfig() {
         return config;
     }

File: api/src/test/java/io/strimzi/test/StrimziRunner.java
Patch:
@@ -575,8 +575,9 @@ private Statement withKafkaClusters(Annotatable element,
                     .getPo(zookeeperStatefulSetName)
                     .logs(zookeeperStatefulSetName + ".*", "zookeeper")
                     .getDep(eoDeploymentName)
-                    .logs(eoDeploymentName + ".*", "entity-operator")) {
-
+                    .logs(eoDeploymentName + ".*", "user-operator")
+                    .logs(eoDeploymentName + ".*", "topic-operator")
+                    .logs(eoDeploymentName + ".*", "tls-sidecar")) {
                     @Override
                     protected void before() {
                         LOGGER.info("Creating kafka cluster '{}' before test per @KafkaCluster annotation on {}", kafkaAssembly.getMetadata().getName(), name(element));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -15,9 +15,8 @@
 import io.strimzi.api.kafka.model.EntityUserOperatorSpecBuilder;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
-import io.strimzi.certs.CertManager;
+import io.strimzi.api.kafka.model.TlsSidecarLogLevel;
 import io.strimzi.operator.cluster.ResourceUtils;
-import io.strimzi.operator.common.operator.MockCertManager;
 import org.junit.AfterClass;
 import org.junit.Rule;
 import org.junit.Test;
@@ -61,7 +60,6 @@ static Map<String, String> volumeMounts(List<VolumeMount> mounts) {
                     .endSpec()
                     .build();
 
-    private final CertManager certManager = new MockCertManager();
     private final EntityOperator entityOperator = EntityOperator.fromCrd(resource);
 
     @Test
@@ -85,6 +83,7 @@ public void testGenerateDeployment() {
         Container tlsSidecarContainer = containers.get(2);
         assertEquals(EntityOperatorSpec.DEFAULT_TLS_SIDECAR_IMAGE, tlsSidecarContainer.getImage());
         assertEquals(EntityOperator.defaultZookeeperConnect(cluster), AbstractModel.containerEnvVars(tlsSidecarContainer).get(EntityOperator.ENV_VAR_ZOOKEEPER_CONNECT));
+        assertEquals(TlsSidecarLogLevel.NOTICE.toValue(), AbstractModel.containerEnvVars(tlsSidecarContainer).get(EntityOperator.ENV_VAR_TLS_SIDECAR_LOG_LEVEL));
         assertEquals(map(
                 EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT,
                 EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_NAME, EntityOperator.TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -26,11 +26,10 @@
 import io.strimzi.api.kafka.model.PersistentClaimStorage;
 import io.strimzi.api.kafka.model.PersistentClaimStorageBuilder;
 import io.strimzi.api.kafka.model.Rack;
-import io.strimzi.certs.CertManager;
+import io.strimzi.api.kafka.model.TlsSidecarLogLevel;
 import io.strimzi.certs.OpenSslCertManager;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.model.Labels;
-import io.strimzi.operator.common.operator.MockCertManager;
 import io.strimzi.test.TestUtils;
 import org.junit.Rule;
 import org.junit.Test;
@@ -72,7 +71,6 @@ public class KafkaClusterTest {
         zooLog.setLoggers(Collections.singletonMap("zookeeper.root.logger", "OFF"));
     }
 
-    private final CertManager certManager = new MockCertManager();
     private final Kafka kafkaAssembly = ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCm, configuration, kafkaLog, zooLog);
     private final KafkaCluster kc = KafkaCluster.fromCrd(kafkaAssembly);
 
@@ -247,6 +245,7 @@ private void checkStatefulSet(StatefulSet ss, Kafka cm, boolean isOpenShift) {
         // checks on the TLS sidecar
         assertEquals(KafkaClusterSpec.DEFAULT_TLS_SIDECAR_IMAGE, containers.get(1).getImage());
         assertEquals(ZookeeperCluster.serviceName(cluster) + ":2181", AbstractModel.containerEnvVars(containers.get(1)).get(KafkaCluster.ENV_VAR_KAFKA_ZOOKEEPER_CONNECT));
+        assertEquals(TlsSidecarLogLevel.NOTICE.toValue(), AbstractModel.containerEnvVars(containers.get(1)).get(KafkaCluster.ENV_VAR_TLS_SIDECAR_LOG_LEVEL));
         assertEquals(KafkaCluster.BROKER_CERTS_VOLUME, containers.get(1).getVolumeMounts().get(0).getName());
         assertEquals(KafkaCluster.TLS_SIDECAR_KAFKA_CERTS_VOLUME_MOUNT, containers.get(1).getVolumeMounts().get(0).getMountPath());
         assertEquals(KafkaCluster.TLS_SIDECAR_CLUSTER_CA_CERTS_VOLUME_MOUNT, containers.get(1).getVolumeMounts().get(1).getMountPath());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -14,12 +14,11 @@
 import io.strimzi.api.kafka.model.InlineLogging;
 import io.strimzi.api.kafka.model.Kafka;
 import io.strimzi.api.kafka.model.KafkaBuilder;
+import io.strimzi.api.kafka.model.TlsSidecarLogLevel;
 import io.strimzi.api.kafka.model.ZookeeperClusterSpec;
-import io.strimzi.certs.CertManager;
 import io.strimzi.certs.OpenSslCertManager;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.model.Labels;
-import io.strimzi.operator.common.operator.MockCertManager;
 import io.strimzi.test.TestUtils;
 import org.junit.Rule;
 import org.junit.Test;
@@ -59,7 +58,6 @@ public class ZookeeperClusterTest {
     }
     private final Map<String, Object> zooConfigurationJson = singletonMap("foo", "bar");
 
-    private final CertManager certManager = new MockCertManager();
     private final Kafka ka = ResourceUtils.createKafkaCluster(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, configurationJson, zooConfigurationJson, null, null, kafkaLogConfigJson, zooLogConfigJson);
     private final ZookeeperCluster zc = ZookeeperCluster.fromCrd(ka);
 
@@ -162,6 +160,7 @@ private void checkStatefulSet(StatefulSet ss) {
         // checks on the TLS sidecar container
         assertEquals(ZookeeperClusterSpec.DEFAULT_TLS_SIDECAR_IMAGE, containers.get(1).getImage());
         assertEquals(new Integer(replicas), Integer.valueOf(AbstractModel.containerEnvVars(containers.get(1)).get(ZookeeperCluster.ENV_VAR_ZOOKEEPER_NODE_COUNT)));
+        assertEquals(TlsSidecarLogLevel.NOTICE.toValue(), AbstractModel.containerEnvVars(containers.get(1)).get(ZookeeperCluster.ENV_VAR_TLS_SIDECAR_LOG_LEVEL));
         assertEquals(ZookeeperCluster.CLUSTERING_PORT_NAME, containers.get(1).getPorts().get(0).getName());
         assertEquals(new Integer(ZookeeperCluster.CLUSTERING_PORT), containers.get(1).getPorts().get(0).getContainerPort());
         assertEquals(ZookeeperCluster.LEADER_ELECTION_PORT_NAME, containers.get(1).getPorts().get(1).getName());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ClusterCa.java
Patch:
@@ -40,7 +40,7 @@ public ClusterCa(CertManager certManager,
                      int validityDays,
                      int renewalDays,
                      boolean generateCa) {
-        super(certManager, AbstractModel.getClusterCaName(clusterName), clusterCaCert,
+        super(certManager, "cluster-ca", AbstractModel.getClusterCaName(clusterName), clusterCaCert,
                 AbstractModel.getClusterCaKeyName(clusterName), clusterCaKey,
                 validityDays, renewalDays, generateCa);
         this.clusterName = clusterName;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -226,7 +226,7 @@ public Secret generateSecret(ClusterCa clusterCa) {
             log.debug("Generating certificates");
             try {
                 Ca.log.debug("Entity Operator certificate to generate");
-                CertAndKey eoCertAndKey = clusterCa.generateSignedCert(name);
+                CertAndKey eoCertAndKey = clusterCa.generateSignedCert(name, Ca.IO_STRIMZI);
                 data.put("entity-operator.key", eoCertAndKey.keyAsBase64String());
                 data.put("entity-operator.crt", eoCertAndKey.certAsBase64String());
             } catch (IOException e) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -368,7 +368,7 @@ public Secret generateSecret(ClusterCa clusterCa) {
             log.debug("Generating certificates");
             try {
                 log.debug("Topic Operator certificate to generate");
-                CertAndKey toCertAndKey = clusterCa.generateSignedCert(name);
+                CertAndKey toCertAndKey = clusterCa.generateSignedCert(name, Ca.IO_STRIMZI);
                 data.put("entity-operator.crt", toCertAndKey.certAsBase64String());
                 data.put("entity-operator.key", toCertAndKey.keyAsBase64String());
             } catch (IOException e) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -249,9 +249,9 @@ Future<ReconciliationState>  reconcileClusterCa() {
                                 clusterCaCertSecret = secret;
                             } else if (secretName.equals(clusterCaKeyName)) {
                                 clusterCaKeySecret = secret;
-                            } else if (secretName.equals(clientsCaKeyName)) {
-                                clientCaCertSecret = secret;
                             } else if (secretName.equals(clientsCaCertName)) {
+                                clientCaCertSecret = secret;
+                            } else if (secretName.equals(clientsCaKeyName)) {
                                 clientCaKeySecret = secret;
                             }
                         }
@@ -274,7 +274,7 @@ Future<ReconciliationState>  reconcileClusterCa() {
 
                         this.clusterCa.initCaSecrets(clusterSecrets);
 
-                        CertificateAuthority clientsCaConfig = kafkaAssembly.getSpec().getClusterCa();
+                        CertificateAuthority clientsCaConfig = kafkaAssembly.getSpec().getClientsCa();
                         this.clientsCa = new ClientsCa(certManager,
                                 clientsCaCertName, clientCaCertSecret,
                                 clientsCaKeyName, clientCaKeySecret,

File: operator-common/src/main/java/io/strimzi/operator/cluster/model/ClientsCa.java
Patch:
@@ -11,7 +11,7 @@ public class ClientsCa extends Ca {
     public ClientsCa(CertManager certManager, String caCertSecretName, Secret clientsCaCert,
                      String caSecretKeyName, Secret clientsCaKey,
                      int validityDays, int renewalDays, boolean generateCa) {
-        super(certManager, caCertSecretName, clientsCaCert,
+        super(certManager, "clients-ca", caCertSecretName, clientsCaCert,
                 caSecretKeyName, clientsCaKey,
                 validityDays, renewalDays, generateCa);
     }

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerSpec.java
Patch:
@@ -71,8 +71,8 @@ public void setImage(String image) {
     }
 
     @Description("List of topics which are included for mirroring. This option allows any regular expression using Java-style regular expressions." +
-            "Mirroring two topics named A and B can be achieved by using `--whitelist 'A|B'`. Or you could mirror all topics using `--whitelist '*'`.")
-    @JsonInclude(JsonInclude.Include.NON_NULL)
+            "Mirroring two topics named A and B can be achieved by using the whitelist `'A|B'`. Or, as a special case, you can mirror all topics using the whitelist '*'`.")
+    @JsonProperty(required = true)
     public String getWhitelist() {
         return whitelist;
     }

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaMirrorMakerCrdIT.java
Patch:
@@ -49,6 +49,7 @@ public void testKafkaMirrorMakerWithMissingRequired() {
         } catch (KubeClusterException.InvalidResource e) {
             assertTrue(e.getMessage(), e.getMessage().contains("spec.consumer.bootstrapServers in body is required"));
             assertTrue(e.getMessage(), e.getMessage().contains("spec.producer in body is required"));
+            assertTrue(e.getMessage(), e.getMessage().contains("spec.whitelist in body is required"));
         }
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -279,7 +279,8 @@ protected List<Container> getContainers() {
                 .withImage(tlsSidecarImage)
                 .withResources(resources(tlsSidecarResources))
                 .withEnv(singletonList(buildEnvVar(ENV_VAR_ZOOKEEPER_CONNECT, zookeeperConnect)))
-                .withVolumeMounts(createVolumeMount(TLS_SIDECAR_EO_CERTS_VOLUME_NAME, TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT))
+                .withVolumeMounts(createVolumeMount(TLS_SIDECAR_EO_CERTS_VOLUME_NAME, TLS_SIDECAR_EO_CERTS_VOLUME_MOUNT),
+                        createVolumeMount(TLS_SIDECAR_CA_CERTS_VOLUME_NAME, TLS_SIDECAR_CA_CERTS_VOLUME_MOUNT))
                 .build();
 
         containers.add(container);

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaTopicCrdIT.java
Patch:
@@ -25,17 +25,17 @@ public class KafkaTopicCrdIT extends AbstractCrdIT {
     public static final String NAMESPACE = "topiccrd-it";
 
     @Test
-    public void testKafka() {
+    public void testKafkaTopic() {
         createDelete(KafkaTopic.class, "KafkaTopic.yaml");
     }
 
     @Test
-    public void testKafkaMinimal() {
+    public void testKafkaTopicMinimal() {
         createDelete(KafkaTopic.class, "KafkaTopic-minimal.yaml");
     }
 
     @Test
-    public void testKafkaWithExtraProperty() {
+    public void testKafkaTopicWithExtraProperty() {
         createDelete(KafkaTopic.class, "KafkaTopic-with-extra-property.yaml");
     }
 }

File: test/src/main/java/io/strimzi/test/TestUtils.java
Patch:
@@ -51,6 +51,8 @@ public final class TestUtils {
 
     public static final String CRD_KAFKA_USER = "../examples/install/cluster-operator/044-Crd-kafkauser.yaml";
 
+    public static final String CRD_KAFKA_MIRROR_MAKER = "../examples/install/cluster-operator/045-Crd-kafkamirrormaker.yaml";
+
     private TestUtils() {
         // All static methods
     }

File: api/src/main/java/io/strimzi/api/kafka/model/Resources.java
Patch:
@@ -15,7 +15,7 @@
 import java.util.Map;
 
 /**
- * Representation for resource containts.
+ * Representation for resource constraints.
  */
 @Buildable(
         editableEnabled = false,

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -44,6 +44,7 @@ public class KafkaConnectClusterTest {
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
     private final String configurationJson = "{\"foo\":\"bar\"}";
     private final String bootstrapServers = "foo-kafka:9092";
+    private final String kafkaHeapOpts = "-Xms" + AbstractModel.DEFAULT_JVM_XMS;
     private final String expectedConfiguration = "group.id=connect-cluster" + LINE_SEPARATOR +
             "key.converter=org.apache.kafka.connect.json.JsonConverter" + LINE_SEPARATOR +
             "internal.key.converter.schemas.enable=false" + LINE_SEPARATOR +
@@ -113,7 +114,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_CONFIGURATION).withValue(expectedConfiguration).build());
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_METRICS_ENABLED).withValue(String.valueOf(true)).build());
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_BOOTSTRAP_SERVERS).withValue(bootstrapServers).build());
-        expected.add(new EnvVarBuilder().withName(AbstractModel.ENV_VAR_DYNAMIC_HEAP_FRACTION).withValue("1.0").build());
+        expected.add(new EnvVarBuilder().withName(AbstractModel.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
         return expected;
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -53,6 +53,7 @@ public class KafkaConnectS2IClusterTest {
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
     private final String configurationJson = "{\"foo\":\"bar\"}";
     private final String bootstrapServers = "foo-kafka:9092";
+    private final String kafkaHeapOpts = "-Xms" + AbstractModel.DEFAULT_JVM_XMS;
     private final String expectedConfiguration = "group.id=connect-cluster" + LINE_SEPARATOR +
             "key.converter=org.apache.kafka.connect.json.JsonConverter" + LINE_SEPARATOR +
             "internal.key.converter.schemas.enable=false" + LINE_SEPARATOR +
@@ -114,7 +115,7 @@ protected List<EnvVar> getExpectedEnvVars() {
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_CONFIGURATION).withValue(expectedConfiguration).build());
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_METRICS_ENABLED).withValue(String.valueOf(true)).build());
         expected.add(new EnvVarBuilder().withName(KafkaConnectCluster.ENV_VAR_KAFKA_CONNECT_BOOTSTRAP_SERVERS).withValue(bootstrapServers).build());
-        expected.add(new EnvVarBuilder().withName(AbstractModel.ENV_VAR_DYNAMIC_HEAP_FRACTION).withValue("1.0").build());
+        expected.add(new EnvVarBuilder().withName(AbstractModel.ENV_VAR_KAFKA_HEAP_OPTS).withValue(kafkaHeapOpts).build());
         return expected;
     }
 

File: crd-generator/src/main/java/io/strimzi/crdgenerator/CrdGenerator.java
Patch:
@@ -56,7 +56,7 @@
  * K8S CRD validation schema support, which is more limited that the full OpenAPI schema
  * supported in the rest of K8S.</p>
  *
- * <p>The tool works be recursing through class properties (in the JavaBeans sense)
+ * <p>The tool works by recursing through class properties (in the JavaBeans sense)
  * and the types of those properties, guided by the annotations.</p>
  *
  * <h3>Annotations</h3>

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerConsumerSpec.java
Patch:
@@ -22,7 +22,7 @@
 public class KafkaMirrorMakerConsumerSpec extends KafkaMirrorMakerClientSpec {
     private static final long serialVersionUID = 1L;
 
-    public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, group.id, sasl.";
+    public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, group.id, sasl., security.";
 
     private int numStreams;
 

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaMirrorMakerProducerSpec.java
Patch:
@@ -21,7 +21,7 @@
 public class KafkaMirrorMakerProducerSpec extends KafkaMirrorMakerClientSpec {
     private static final long serialVersionUID = 1L;
 
-    public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, sasl.";
+    public static final String FORBIDDEN_PREFIXES = "ssl., bootstrap.servers, sasl., security.";
 
     @Override
     @Description("The mirror maker producer config. Properties with the following prefixes cannot be set: " + FORBIDDEN_PREFIXES)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -189,7 +189,7 @@ public final void reconcileAssembly(Reconciliation reconciliation, Handler<Async
      * Reconciliation works by getting the assembly ConfigMaps in the given namespace with the given selector and
      * comparing with the corresponding {@linkplain #getResources(String, Labels) resource}.
      * <ul>
-     * <li>An assembly will be {@linkplain #createOrUpdate(Reconciliation, T, List) created} for all ConfigMaps without same-named resources</li>
+     * <li>An assembly will be {@linkplain #createOrUpdate(Reconciliation, T) created} for all ConfigMaps without same-named resources</li>
      * <li>An assembly will be {@linkplain #delete(Reconciliation) deleted} for all resources without same-named ConfigMaps</li>
      * </ul>
      *

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityOperator.java
Patch:
@@ -141,6 +141,7 @@ public static EntityOperator fromCrd(CertManager certManager, Kafka kafkaAssembl
                     kafkaAssembly.getMetadata().getName(),
                     Labels.fromResource(kafkaAssembly).withKind(kafkaAssembly.getKind()));
 
+            result.setOwnerReference(kafkaAssembly);
             result.setUserAffinity(entityOperatorSpec.getAffinity());
             result.setTolerations(entityOperatorSpec.getTolerations());
             result.setTlsSidecar(entityOperatorSpec.getTlsSidecar());
@@ -312,6 +313,7 @@ public ServiceAccount generateServiceAccount() {
                 .withNewMetadata()
                     .withName(getServiceAccountName())
                     .withNamespace(namespace)
+                    .withOwnerReferences(createOwnerReference())
                 .endMetadata()
                 .build();
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityTopicOperator.java
Patch:
@@ -199,6 +199,7 @@ public static EntityTopicOperator fromCrd(Kafka kafkaAssembly) {
                         kafkaAssembly.getMetadata().getName(),
                         Labels.fromResource(kafkaAssembly).withKind(kafkaAssembly.getKind()));
 
+                result.setOwnerReference(kafkaAssembly);
                 result.setImage(topicOperatorSpec.getImage());
                 result.setWatchedNamespace(topicOperatorSpec.getWatchedNamespace() != null ? topicOperatorSpec.getWatchedNamespace() : namespace);
                 result.setReconciliationIntervalMs(topicOperatorSpec.getReconciliationIntervalSeconds() * 1_000);
@@ -253,6 +254,6 @@ private List<VolumeMount> getVolumeMounts() {
 
     public RoleBindingOperator.RoleBinding generateRoleBinding(String namespace) {
         return new RoleBindingOperator.RoleBinding(roleBindingName(cluster), EntityOperator.EO_CLUSTER_ROLE_NAME,
-                namespace, EntityOperator.entityOperatorServiceAccountName(cluster));
+                namespace, EntityOperator.entityOperatorServiceAccountName(cluster), createOwnerReference());
     }
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/EntityUserOperator.java
Patch:
@@ -155,6 +155,7 @@ public static EntityUserOperator fromCrd(Kafka kafkaAssembly) {
                         kafkaAssembly.getMetadata().getName(),
                         Labels.fromResource(kafkaAssembly).withKind(kafkaAssembly.getKind()));
 
+                result.setOwnerReference(kafkaAssembly);
                 result.setImage(userOperatorSpec.getImage());
                 result.setWatchedNamespace(userOperatorSpec.getWatchedNamespace() != null ? userOperatorSpec.getWatchedNamespace() : namespace);
                 result.setReconciliationIntervalMs(userOperatorSpec.getReconciliationIntervalSeconds() * 1_000);
@@ -202,6 +203,6 @@ private List<VolumeMount> getVolumeMounts() {
 
     public RoleBindingOperator.RoleBinding generateRoleBinding(String namespace) {
         return new RoleBindingOperator.RoleBinding(roleBindingName(cluster), EntityOperator.EO_CLUSTER_ROLE_NAME,
-                namespace, EntityOperator.entityOperatorServiceAccountName(cluster));
+                namespace, EntityOperator.entityOperatorServiceAccountName(cluster), createOwnerReference());
     }
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityOperatorTest.java
Patch:
@@ -66,6 +66,8 @@ public void testGenerateDeployment() {
         assertEquals(entityOperator.entityOperatorName(cluster), dep.getMetadata().getName());
         assertEquals(namespace, dep.getMetadata().getNamespace());
         assertEquals(new Integer(EntityOperatorSpec.DEFAULT_REPLICAS), dep.getSpec().getReplicas());
+        assertEquals(1, dep.getMetadata().getOwnerReferences().size());
+        assertEquals(entityOperator.createOwnerReference(), dep.getMetadata().getOwnerReferences().get(0));
 
         assertEquals(3, containers.size());
         // just check names of topic and user operators (their containers are tested in the related unit test classes)

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/TopicOperatorTest.java
Patch:
@@ -152,6 +152,8 @@ public void testGenerateDeployment() {
         assertEquals(namespace, dep.getMetadata().getNamespace());
         assertEquals(new Integer(TopicOperatorSpec.DEFAULT_REPLICAS), dep.getSpec().getReplicas());
         Assert.assertEquals(TopicOperator.TOPIC_OPERATOR_NAME, containers.get(0).getName());
+        assertEquals(1, dep.getMetadata().getOwnerReferences().size());
+        assertEquals(tc.createOwnerReference(), dep.getMetadata().getOwnerReferences().get(0));
 
         // checks on the main Topic Operator container
         assertEquals(tc.image, containers.get(0).getImage());

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaListenerExternalRoute.java
Patch:
@@ -32,7 +32,7 @@ public String getType() {
         return TYPE_ROUTE;
     }
 
-    @Description("Authorization configuration for Kafka brokers")
+    @Description("Authentication configuration for Kafka brokers")
     @JsonInclude(JsonInclude.Include.NON_NULL)
     @JsonProperty("authentication")
     public KafkaListenerAuthentication getAuth() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperator.java
Patch:
@@ -30,15 +30,15 @@ public KafkaSetOperator(Vertx vertx, KubernetesClient client, long operationTime
 
     @Override
     protected boolean shouldIncrementGeneration(StatefulSet current, StatefulSet desired) {
-        ResourceOperatorSupplier.StatefulSetDiff diff = new ResourceOperatorSupplier.StatefulSetDiff(current, desired);
+        StatefulSetDiff diff = new StatefulSetDiff(current, desired);
         if (diff.changesVolumeClaimTemplates()) {
             log.warn("Changing Kafka storage type or size is not possible. The changes will be ignored.");
             diff = revertStorageChanges(current, desired);
         }
         return !diff.isEmpty() && needsRollingUpdate(diff);
     }
 
-    public static boolean needsRollingUpdate(ResourceOperatorSupplier.StatefulSetDiff diff) {
+    public static boolean needsRollingUpdate(StatefulSetDiff diff) {
         if (diff.changesLabels()) {
             log.debug("Changed labels => needs rolling update");
             return true;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetDiff.java
Patch:
@@ -33,6 +33,7 @@ public class StatefulSetDiff {
             "/spec/template/spec/initContainers/[0-9]+/terminationMessagePolicy",
             "/spec/template/spec/initContainers/[0-9]+/env/[0-9]+/valueFrom/fieldRef/apiVersion",
             "/spec/template/spec/initContainers/[0-9]+/env/[0-9]+/value",
+            "/spec/template/spec/containers/[0-9]+/env/[0-9]+/valueFrom/fieldRef/apiVersion",
             "/spec/template/spec/containers/[0-9]+/imagePullPolicy",
             "/spec/template/spec/containers/[0-9]+/livenessProbe/failureThreshold",
             "/spec/template/spec/containers/[0-9]+/livenessProbe/periodSeconds",

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -254,7 +254,7 @@ protected Future<ReconcileResult<StatefulSet>> internalPatch(String namespace, S
      *
      * @return Updated StatefulSetDiff after the storage patching
      */
-    protected ResourceOperatorSupplier.StatefulSetDiff revertStorageChanges(StatefulSet current, StatefulSet desired) {
+    protected StatefulSetDiff revertStorageChanges(StatefulSet current, StatefulSet desired) {
         desired.getSpec().setVolumeClaimTemplates(current.getSpec().getVolumeClaimTemplates());
         desired.getSpec().getTemplate().getSpec().setInitContainers(current.getSpec().getTemplate().getSpec().getInitContainers());
         desired.getSpec().getTemplate().getSpec().setSecurityContext(current.getSpec().getTemplate().getSpec().getSecurityContext());
@@ -281,7 +281,7 @@ protected ResourceOperatorSupplier.StatefulSetDiff revertStorageChanges(Stateful
             }
         }
 
-        return new ResourceOperatorSupplier.StatefulSetDiff(current, desired);
+        return new StatefulSetDiff(current, desired);
     }
 
     protected Future<String> getUid(String namespace, String podName) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperator.java
Patch:
@@ -30,15 +30,15 @@ public ZookeeperSetOperator(Vertx vertx, KubernetesClient client, long operation
 
     @Override
     protected boolean shouldIncrementGeneration(StatefulSet current, StatefulSet desired) {
-        ResourceOperatorSupplier.StatefulSetDiff diff = new ResourceOperatorSupplier.StatefulSetDiff(current, desired);
+        StatefulSetDiff diff = new StatefulSetDiff(current, desired);
         if (diff.changesVolumeClaimTemplates()) {
             log.warn("Changing Zookeeper storage type or size is not possible. The changes will be ignored.");
             diff = revertStorageChanges(current, desired);
         }
         return !diff.isEmpty() && needsRollingUpdate(diff);
     }
 
-    public static boolean needsRollingUpdate(ResourceOperatorSupplier.StatefulSetDiff diff) {
+    public static boolean needsRollingUpdate(StatefulSetDiff diff) {
         // Because for ZK the brokers know about each other via the config, and rescaling requires a rolling update
         if (diff.changesSpecReplicas()) {
             log.debug("Changed #replicas => needs rolling update");

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -34,6 +34,7 @@
 import io.strimzi.operator.cluster.model.ZookeeperCluster;
 import io.strimzi.operator.cluster.operator.resource.KafkaSetOperator;
 import io.strimzi.operator.cluster.operator.resource.ResourceOperatorSupplier;
+import io.strimzi.operator.cluster.operator.resource.StatefulSetDiff;
 import io.strimzi.operator.cluster.operator.resource.ZookeeperSetOperator;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
@@ -1008,12 +1009,12 @@ private void updateCluster(TestContext context, Kafka originalAssembly, Kafka up
             // rolling restart
             Set<String> expectedRollingRestarts = set();
             if (KafkaSetOperator.needsRollingUpdate(
-                    new ResourceOperatorSupplier.StatefulSetDiff(originalKafkaCluster.generateStatefulSet(openShift),
+                    new StatefulSetDiff(originalKafkaCluster.generateStatefulSet(openShift),
                     updatedKafkaCluster.generateStatefulSet(openShift)))) {
                 expectedRollingRestarts.add(originalKafkaCluster.getName());
             }
             if (ZookeeperSetOperator.needsRollingUpdate(
-                    new ResourceOperatorSupplier.StatefulSetDiff(originalZookeeperCluster.generateStatefulSet(openShift),
+                    new StatefulSetDiff(originalZookeeperCluster.generateStatefulSet(openShift),
                             updatedZookeeperCluster.generateStatefulSet(openShift)))) {
                 expectedRollingRestarts.add(originalZookeeperCluster.getName());
             }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -77,8 +77,8 @@ private List<Secret> getInitialSecrets(String clusterName) {
         return ResourceUtils.createKafkaClusterInitialSecrets(clusterCmNamespace, clusterName);
     }
 
-    private ResourceOperatorSupplier.StatefulSetDiff diff() {
-        return new ResourceOperatorSupplier.StatefulSetDiff(a, b);
+    private StatefulSetDiff diff() {
+        return new StatefulSetDiff(a, b);
     }
 
     @Test

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperatiorTest.java
Patch:
@@ -55,8 +55,8 @@ private List<Secret> getInitialSecrets(String clusterName) {
         return ResourceUtils.createKafkaClusterInitialSecrets(clusterCmNamespace, clusterName);
     }
 
-    private ResourceOperatorSupplier.StatefulSetDiff diff() {
-        return new ResourceOperatorSupplier.StatefulSetDiff(a, b);
+    private StatefulSetDiff diff() {
+        return new StatefulSetDiff(a, b);
     }
 
     @Test

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/Main.java
Patch:
@@ -89,7 +89,7 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, boolean isOpenS
 
         OpenSslCertManager certManager = new OpenSslCertManager();
         KafkaAssemblyOperator kafkaClusterOperations = new KafkaAssemblyOperator(vertx, isOpenShift,
-                config.getOperationTimeoutMs(), certManager, new ResourceOperatorSupplier(vertx, client, config.getOperationTimeoutMs()));
+                config.getOperationTimeoutMs(), certManager, new ResourceOperatorSupplier(vertx, client, isOpenShift, config.getOperationTimeoutMs()));
         KafkaConnectAssemblyOperator kafkaConnectClusterOperations = new KafkaConnectAssemblyOperator(vertx, isOpenShift, certManager, kco, configMapOperations, deploymentOperations, serviceOperations, secretOperations, networkPolicyOperator);
 
         KafkaConnectS2IAssemblyOperator kafkaConnectS2IClusterOperations = null;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -216,7 +216,7 @@ public static void cleanUp() {
     }
 
     private ResourceOperatorSupplier supplierWithMocks() {
-        return new ResourceOperatorSupplier(vertx, mockClient, 2_000);
+        return new ResourceOperatorSupplier(vertx, mockClient, true, 2_000);
     }
 
     private KafkaAssemblyOperator createCluster(TestContext context) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -102,7 +102,7 @@ public void before(TestContext context) {
                 .end()
                 .build();
 
-        ResourceOperatorSupplier supplier = new ResourceOperatorSupplier(vertx, bootstrapClient, 60_000L);
+        ResourceOperatorSupplier supplier = new ResourceOperatorSupplier(vertx, bootstrapClient, true, 60_000L);
         KafkaAssemblyOperator kco = new KafkaAssemblyOperator(vertx, true, 2_000,
                 new MockCertManager(), supplier);
 
@@ -139,7 +139,7 @@ private void startKube() {
                 .withInitialPods(set(zkPod0, zkPod1, zkPod2, kafkaPod0, kafkaPod1, kafkaPod2, kafkaPod3, kafkaPod4))
                 .build();
 
-        ResourceOperatorSupplier supplier = new ResourceOperatorSupplier(vertx, mockClient, 60_000L);
+        ResourceOperatorSupplier supplier = new ResourceOperatorSupplier(vertx, mockClient, true, 60_000L);
 
         this.kco = new KafkaAssemblyOperator(vertx, true, 2_000,
                 new MockCertManager(), supplier);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -43,8 +43,8 @@ public class KafkaSetOperatorTest {
     @Before
     public void before() {
         MockCertManager certManager = new MockCertManager();
-        a = KafkaCluster.fromCrd(certManager, getResource(), getInitialSecrets(getResource().getMetadata().getName())).generateStatefulSet(true);
-        b = KafkaCluster.fromCrd(certManager, getResource(), getInitialSecrets(getResource().getMetadata().getName())).generateStatefulSet(true);
+        a = KafkaCluster.fromCrd(getResource()).generateStatefulSet(true);
+        b = KafkaCluster.fromCrd(getResource()).generateStatefulSet(true);
     }
 
     private Kafka getResource() {

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaUserCrdIT.java
Patch:
@@ -23,7 +23,7 @@
  */
 @RunWith(StrimziRunner.class)
 @Namespace(KafkaUserCrdIT.NAMESPACE)
-@Resources(value = TestUtils.KAFKA_USER_CRD, asAdmin = true)
+@Resources(value = TestUtils.CRD_KAFKA_USER, asAdmin = true)
 public class KafkaUserCrdIT extends AbstractCrdIT {
     public static final String NAMESPACE = "kafkausercrd-it";
 

File: api/src/test/java/io/strimzi/test/StrimziRunner.java
Patch:
@@ -686,7 +686,7 @@ protected void after() {
     private Statement installOperatorFromExamples(Annotatable element, Statement last, ClusterOperator cc) {
         Map<File, String> yamls = Arrays.stream(new File(CO_INSTALL_DIR).listFiles()).sorted().collect(Collectors.toMap(file -> file, f -> getContent(f, node -> {
             // Change the docker org of the images in the 04-deployment.yaml
-            if ("05-Deployment-strimzi-cluster-operator.yaml".equals(f.getName())) {
+            if ("050-Deployment-strimzi-cluster-operator.yaml".equals(f.getName())) {
 
                 ObjectNode containerNode = (ObjectNode) node.get("spec").get("template").get("spec").get("containers").get(0);
                 containerNode.put("imagePullPolicy", IMAGE_PULL_POLICY);
@@ -723,7 +723,7 @@ private Statement installOperatorFromExamples(Annotatable element, Statement las
                 }
             }
 
-            if (f.getName().matches(".*ClusterRoleBinding.*")) {
+            if (f.getName().matches(".*RoleBinding.*")) {
                 String ns = annotations(element, Namespace.class).get(0).value();
                 ArrayNode subjects = (ArrayNode) node.get("subjects");
                 ObjectNode subject = (ObjectNode) subjects.get(0);

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaListenerAuthenticationTls.java
Patch:
@@ -10,7 +10,7 @@
 import io.sundr.builder.annotations.Buildable;
 
 /**
- * Configures the broker authorization
+ * Configures a listener to use mutual TLS authentication.
  */
 @Buildable(
         editableEnabled = false,

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/InvalidConfigParameterException.java
Patch:
@@ -5,7 +5,9 @@
 
 package io.strimzi.operator.cluster;
 
-public class InvalidConfigParameterException extends RuntimeException {
+import io.strimzi.operator.cluster.model.InvalidResourceException;
+
+public class InvalidConfigParameterException extends InvalidResourceException {
 
     private String key;
     public InvalidConfigParameterException(String key, String message) {

File: topic-operator/src/test/java/io/strimzi/operator/topic/ZkTopicStoreTest.java
Patch:
@@ -5,6 +5,7 @@
 package io.strimzi.operator.topic;
 
 import io.strimzi.operator.topic.zk.ZkImpl;
+import io.strimzi.test.EmbeddedZooKeeper;
 import io.vertx.core.Future;
 import io.vertx.core.Vertx;
 import io.vertx.ext.unit.Async;

File: topic-operator/src/test/java/io/strimzi/operator/topic/zk/ZkImplTest.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.operator.topic.zk;
 
-import io.strimzi.operator.topic.EmbeddedZooKeeper;
+import io.strimzi.test.EmbeddedZooKeeper;
 import io.vertx.core.Vertx;
 import io.vertx.ext.unit.Async;
 import io.vertx.ext.unit.TestContext;

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -675,7 +675,7 @@ public void testRackAware() {
      * Test the case where the TO is configured to watch a different namespace that it is deployed in
      */
     @Test
-    //@JUnitGroup(name = "regression")
+    @JUnitGroup(name = "regression")
     @KafkaFromClasspathYaml
     @Namespace(value = "topic-operator-namespace", use = false)
     public void testWatchingOtherNamespace() throws InterruptedException {

File: api/src/test/java/io/strimzi/test/StrimziRunner.java
Patch:
@@ -666,7 +666,7 @@ protected void before() {
                 LOGGER.info("Creating cluster operator with Helm Chart {} before test per @ClusterOperator annotation on {}", cc, name(element));
                 Path pathToChart = new File(HELM_CHART).toPath();
                 String oldNamespace = kubeClient().namespace("kube-system");
-                String pathToHelmServiceAccount = Thread.currentThread().getContextClassLoader().getResource("helm/helm-service-account.yaml").getPath();
+                String pathToHelmServiceAccount = getClass().getClassLoader().getResource("helm/helm-service-account.yaml").getPath();
                 String helmServiceAccount = TestUtils.getFileAsString(pathToHelmServiceAccount);
                 kubeClient().applyContent(helmServiceAccount);
                 helmClient().init();

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -132,8 +132,8 @@ static String zookeeperPVCName(String clusterName, int podId) {
         return "data-" + zookeeperClusterName(clusterName) + "-" + podId;
     }
 
-    static String topicOperatorDeploymentName(String clusterName) {
-        return clusterName + "-topic-operator";
+    static String entityOperatorDeploymentName(String clusterName) {
+        return clusterName + "-entity-operator";
     }
 
     private <T extends CustomResource, L extends CustomResourceList<T>, D extends CustomResourceDoneable<T>>

File: user-operator/src/main/java/io/strimzi/operator/user/operator/SimpleAclOperator.java
Patch:
@@ -122,7 +122,7 @@ protected Future<ReconcileResult<Set<SimpleAclRule>>> internalCreate(String user
 
     /**
      * Update all ACLs for given user.
-     * SimpleAclAuthorizer doesn't support modyfication of existing rules.
+     * SimpleAclAuthorizer doesn't support modification of existing rules.
      * This class is using Sets to decide which rules need to be added and which need to be deleted.
      * It delagates to {@link #internalCreate internalCreate} and {@link #internalDelete internalDelete} methods for the actual addition or deletion.
      */

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaSpec.java
Patch:
@@ -58,11 +58,13 @@ public void setZookeeper(ZookeeperClusterSpec zookeeper) {
         this.zookeeper = zookeeper;
     }
 
+    @Deprecated
     @Description("Configuration of the Topic Operator")
     public TopicOperatorSpec getTopicOperator() {
         return topicOperator;
     }
 
+    @Deprecated
     public void setTopicOperator(TopicOperatorSpec topicOperator) {
         this.topicOperator = topicOperator;
     }

File: api/src/main/java/io/strimzi/api/kafka/model/TopicOperatorSpec.java
Patch:
@@ -14,6 +14,7 @@
 /**
  * Representation of a Strimzi-managed Topic Operator deployment.
  */
+@Deprecated
 @Buildable(
         editableEnabled = false,
         generateBuilderPackage = true,
@@ -27,8 +28,7 @@ public class TopicOperatorSpec extends EntityTopicOperatorSpec {
 
     private static final long serialVersionUID = 1L;
 
-    public static final String DEFAULT_TLS_SIDECAR_IMAGE =
-            System.getenv().getOrDefault("STRIMZI_DEFAULT_TLS_SIDECAR_TOPIC_OPERATOR_IMAGE", "strimzi/topic-operator-stunnel:latest");
+    public static final String DEFAULT_TLS_SIDECAR_IMAGE = EntityOperatorSpec.DEFAULT_TLS_SIDECAR_IMAGE;
 
     private Affinity affinity;
     private Sidecar tlsSidecar;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityTopicOperatorTest.java
Patch:
@@ -168,7 +168,7 @@ public void testGetContainers() {
         assertEquals(new Integer(EntityTopicOperator.HEALTHCHECK_PORT), container.getPorts().get(0).getContainerPort());
         assertEquals(EntityTopicOperator.HEALTHCHECK_PORT_NAME, container.getPorts().get(0).getName());
         assertEquals("TCP", container.getPorts().get(0).getProtocol());
-        assertEquals("/opt/topic-operator/custom-config/", container.getVolumeMounts().get(0).getMountPath());
-        assertEquals("topic-operator-metrics-and-logging", container.getVolumeMounts().get(0).getName());
+        assertEquals("/opt/entity-topic-operator/custom-config/", container.getVolumeMounts().get(0).getMountPath());
+        assertEquals("entity-topic-operator-metrics-and-logging", container.getVolumeMounts().get(0).getName());
     }
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/EntityUserOperatorTest.java
Patch:
@@ -157,7 +157,7 @@ public void testGetContainers() {
         assertEquals(new Integer(EntityUserOperator.HEALTHCHECK_PORT), container.getPorts().get(0).getContainerPort());
         assertEquals(EntityUserOperator.HEALTHCHECK_PORT_NAME, container.getPorts().get(0).getName());
         assertEquals("TCP", container.getPorts().get(0).getProtocol());
-        assertEquals("/opt/user-operator/custom-config/", container.getVolumeMounts().get(0).getMountPath());
-        assertEquals("user-operator-metrics-and-logging", container.getVolumeMounts().get(0).getName());
+        assertEquals("/opt/entity-user-operator/custom-config/", container.getVolumeMounts().get(0).getMountPath());
+        assertEquals("entity-user-operator-metrics-and-logging", container.getVolumeMounts().get(0).getName());
     }
 }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -70,7 +70,7 @@ public class AbstractST {
     protected static final String KAFKA_INIT_IMAGE = "STRIMZI_DEFAULT_KAFKA_INIT_IMAGE";
     protected static final String TLS_SIDECAR_ZOOKEEPER_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE";
     protected static final String TLS_SIDECAR_KAFKA_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE";
-    protected static final String TLS_SIDECAR_TO_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_TOPIC_OPERATOR_IMAGE";
+    protected static final String TLS_SIDECAR_TO_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE";
 
     @Rule
     public Stopwatch stopwatch = new Stopwatch() {

File: user-operator/src/main/java/io/strimzi/operator/user/UserOperator.java
Patch:
@@ -30,7 +30,7 @@ public class UserOperator extends AbstractVerticle {
 
     public static final String STRIMZI_CLUSTER_OPERATOR_DOMAIN = "user.operator.strimzi.io";
 
-    private static final int HEALTH_SERVER_PORT = 8080;
+    private static final int HEALTH_SERVER_PORT = 8081;
 
     private final KubernetesClient client;
     private final String namespace;

File: api/src/main/java/io/strimzi/api/kafka/model/KafkaConnectS2I.java
Patch:
@@ -60,7 +60,7 @@ public class KafkaConnectS2I extends CustomResource {
 
     private String apiVersion;
     private ObjectMeta metadata;
-    private KafkaConnectS2IAssemblySpec spec;
+    private KafkaConnectS2ISpec spec;
     private Map<String, Object> additionalProperties = new HashMap<>(0);
 
     @Override
@@ -91,11 +91,11 @@ public void setMetadata(ObjectMeta metadata) {
     }
 
     @Description("The specification of the Kafka Connect deployment.")
-    public KafkaConnectS2IAssemblySpec getSpec() {
+    public KafkaConnectS2ISpec getSpec() {
         return spec;
     }
 
-    public void setSpec(KafkaConnectS2IAssemblySpec spec) {
+    public void setSpec(KafkaConnectS2ISpec spec) {
         this.spec = spec;
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -44,8 +44,6 @@ public class KafkaConnectCluster extends AbstractModel {
     protected static final String TLS_CERTS_BASE_VOLUME_MOUNT = "/opt/kafka/connect-certs/";
 
     // Configuration defaults
-    protected static final String DEFAULT_IMAGE =
-            System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE", "strimzi/kafka-connect:latest");
     protected static final int DEFAULT_REPLICAS = 3;
     protected static final int DEFAULT_HEALTHCHECK_DELAY = 60;
     protected static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;
@@ -76,7 +74,7 @@ protected KafkaConnectCluster(String namespace, String cluster, Labels labels) {
         this.serviceName = serviceName(cluster);
         this.validLoggerFields = getDefaultLogConfig();
         this.ancillaryConfigName = logAndMetricsConfigName(cluster);
-        this.image = DEFAULT_IMAGE;
+        this.image = KafkaConnectSpec.DEFAULT_IMAGE;
         this.replicas = DEFAULT_REPLICAS;
         this.readinessPath = "/";
         this.readinessTimeout = DEFAULT_HEALTHCHECK_TIMEOUT;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectClusterTest.java
Patch:
@@ -14,6 +14,7 @@
 import io.strimzi.api.kafka.model.KafkaConnect;
 import io.strimzi.api.kafka.model.KafkaConnectAuthenticationTlsBuilder;
 import io.strimzi.api.kafka.model.KafkaConnectBuilder;
+import io.strimzi.api.kafka.model.KafkaConnectSpec;
 import io.strimzi.api.kafka.model.Probe;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.model.Labels;
@@ -118,7 +119,7 @@ protected List<EnvVar> getExpectedEnvVars() {
     public void testDefaultValues() {
         KafkaConnectCluster kc = KafkaConnectCluster.fromCrd(ResourceUtils.createEmptyKafkaConnectCluster(namespace, cluster));
 
-        assertEquals(KafkaConnectCluster.DEFAULT_IMAGE, kc.image);
+        assertEquals(KafkaConnectSpec.DEFAULT_IMAGE, kc.image);
         assertEquals(KafkaConnectCluster.DEFAULT_REPLICAS, kc.replicas);
         assertEquals(KafkaConnectCluster.DEFAULT_HEALTHCHECK_DELAY, kc.readinessInitialDelay);
         assertEquals(KafkaConnectCluster.DEFAULT_HEALTHCHECK_TIMEOUT, kc.readinessTimeout);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -18,6 +18,7 @@
 import io.strimzi.api.kafka.model.KafkaConnectAuthenticationTlsBuilder;
 import io.strimzi.api.kafka.model.KafkaConnectS2I;
 import io.strimzi.api.kafka.model.KafkaConnectS2IBuilder;
+import io.strimzi.api.kafka.model.KafkaConnectS2ISpec;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.common.model.Labels;
 import io.strimzi.test.TestUtils;
@@ -120,7 +121,7 @@ public void testDefaultValues() {
 
         assertEquals(kc.kafkaConnectClusterName(cluster) + ":latest", kc.image);
         assertEquals(KafkaConnectS2ICluster.DEFAULT_REPLICAS, kc.replicas);
-        assertEquals(KafkaConnectS2ICluster.DEFAULT_IMAGE, kc.sourceImageBaseName + ":" + kc.sourceImageTag);
+        assertEquals(KafkaConnectS2ISpec.DEFAULT_IMAGE, kc.sourceImageBaseName + ":" + kc.sourceImageTag);
         assertEquals(KafkaConnectS2ICluster.DEFAULT_HEALTHCHECK_DELAY, kc.readinessInitialDelay);
         assertEquals(KafkaConnectS2ICluster.DEFAULT_HEALTHCHECK_TIMEOUT, kc.readinessTimeout);
         assertEquals(KafkaConnectS2ICluster.DEFAULT_HEALTHCHECK_DELAY, kc.livenessInitialDelay);

File: api/src/main/java/io/strimzi/api/kafka/model/EntityOperatorSpec.java
Patch:
@@ -38,6 +38,7 @@ public class EntityOperatorSpec implements Serializable {
     public static final String DEFAULT_TLS_SIDECAR_IMAGE =
             System.getenv().getOrDefault("STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE", "strimzi/entity-operator-stunnel:latest");
     public static final int DEFAULT_REPLICAS = 1;
+    public static final int DEFAULT_ZOOKEEPER_PORT = 2181;
 
     private EntityTopicOperatorSpec topicOperator;
     private EntityUserOperatorSpec userOperator;

File: api/src/main/java/io/strimzi/api/kafka/model/EntityUserOperatorSpec.java
Patch:
@@ -34,6 +34,9 @@ public class EntityUserOperatorSpec implements Serializable {
 
     public static final String DEFAULT_IMAGE =
             System.getenv().getOrDefault("STRIMZI_DEFAULT_USER_OPERATOR_IMAGE", "strimzi/user-operator:latest");
+    public static final int DEFAULT_HEALTHCHECK_DELAY = 10;
+    public static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;
+    public static final int DEFAULT_ZOOKEEPER_PORT = 2181;
     public static final long DEFAULT_FULL_RECONCILIATION_INTERVAL_SECONDS = 120;
     public static final long DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS = 6;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -115,8 +115,8 @@ protected TopicOperator(String namespace, String cluster, Labels labels) {
         this.kafkaBootstrapServers = defaultBootstrapServers(cluster);
         this.zookeeperConnect = defaultZookeeperConnect(cluster);
         this.watchedNamespace = namespace;
-        this.reconciliationIntervalMs = TopicOperatorSpec.DEFAULT_FULL_RECONCILIATION_INTERVAL_SECONDS;
-        this.zookeeperSessionTimeoutMs = TopicOperatorSpec.DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS;
+        this.reconciliationIntervalMs = TopicOperatorSpec.DEFAULT_FULL_RECONCILIATION_INTERVAL_SECONDS * 1_000;
+        this.zookeeperSessionTimeoutMs = TopicOperatorSpec.DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_SECONDS * 1_000;
         this.topicConfigMapLabels = defaultTopicConfigMapLabels(cluster);
         this.topicMetadataMaxAttempts = TopicOperatorSpec.DEFAULT_TOPIC_METADATA_MAX_ATTEMPTS;
 

File: user-operator/src/main/java/io/strimzi/operator/user/UserOperatorConfig.java
Patch:
@@ -41,7 +41,7 @@ public class UserOperatorConfig {
      * @param reconciliationIntervalMs    specify every how many milliseconds the reconciliation runs
      * @param zookeperConnect Connecton URL for Zookeeper
      * @param zookeeperSessionTimeoutMs Session timeout for Zookeeper connections
-     * @param labels    Map with labels which should be used to find the KAfkaUser resources
+     * @param labels    Map with labels which should be used to find the KafkaUser resources
      * @param caName    Name of the secret containing the Certification Authority
      * @param caNamespace   Namespace with the CA secret
      */

File: api/src/test/java/io/strimzi/test/k8s/Helm.java
Patch:
@@ -34,7 +34,7 @@ public Helm(KubeClient<?> kubeClient) {
     @Override
     public HelmClient init() {
         if (!initialized) {
-            Exec.exec(wait(command("init")));
+            Exec.exec(wait(command("init", "--service-account", "tiller")));
             initialized = true;
         }
         return this;

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractST.java
Patch:
@@ -240,7 +240,7 @@ public String consumeMessages(String clusterName, String topic, int groupID, int
 
     protected void assertResources(String namespace, String podName, String memoryLimit, String cpuLimit, String memoryRequest, String cpuRequest) {
         Pod po = client.pods().inNamespace(namespace).withName(podName).get();
-        assertNotNull("Expected a pod called " + podName + " but found " +
+        assertNotNull("Not found an expected pod  " + podName + " in namespace " + namespace + " but found " +
             client.pods().list().getItems().stream().map(p -> p.getMetadata().getName()).collect(Collectors.toList()),
             po);
         Container container = po.getSpec().getContainers().get(0);

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -24,7 +24,7 @@
 public class ConnectS2IST extends AbstractST {
 
     public static final String NAMESPACE = "connect-s2i-cluster-test";
-    public static final String CONNECT_CLUSTER_NAME = "my-cluster";
+    public static final String CONNECT_CLUSTER_NAME = "connect-s2i-tests";
     public static final String CONNECT_DEPLOYMENT_NAME = CONNECT_CLUSTER_NAME + "-connect";
 
     @Test

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -299,19 +299,19 @@ public void testSendMessages() {
     @Test
     @JUnitGroup(name = "regression")
     public void testJvmAndResources() {
-        assertResources(client.getNamespace(), "jvm-resource-cluster-kafka-0",
+        assertResources(kubeClient.namespace(), "jvm-resource-cluster-kafka-0",
                 "2Gi", "400m", "2Gi", "400m");
         assertExpectedJavaOpts("jvm-resource-cluster-kafka-0",
                 "-Xmx1g", "-Xms1G", "-server", "-XX:+UseG1GC");
 
-        assertResources(client.getNamespace(), "jvm-resource-cluster-zookeeper-0",
+        assertResources(kubeClient.namespace(), "jvm-resource-cluster-zookeeper-0",
                 "1Gi", "300m", "1Gi", "300m");
         assertExpectedJavaOpts("jvm-resource-cluster-zookeeper-0",
                 "-Xmx600m", "-Xms300m", "-server", "-XX:+UseG1GC");
 
         String podName = client.pods().inNamespace(kubeClient.namespace()).list().getItems().stream().filter(p -> p.getMetadata().getName().startsWith("jvm-resource-cluster-topic-operator-")).findFirst().get().getMetadata().getName();
 
-        assertResources(client.getNamespace(), podName,
+        assertResources(kubeClient.namespace(), podName,
                 "500M", "300m", "500M", "300m");
     }
 

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleGroupResource.java
Patch:
@@ -25,7 +25,7 @@ public class AclRuleGroupResource extends AclRuleResource {
     public static final String TYPE_GROUP = "group";
 
     private String name;
-    private AclResourcePatternType patternType;
+    private AclResourcePatternType patternType = AclResourcePatternType.LITERAL;
 
     @Description("Must be `" + TYPE_GROUP + "`")
     @Override

File: api/src/main/java/io/strimzi/api/kafka/model/AclRuleTopicResource.java
Patch:
@@ -25,7 +25,7 @@ public class AclRuleTopicResource extends AclRuleResource {
     public static final String TYPE_TOPIC = "topic";
 
     private String name;
-    private AclResourcePatternType patternType;
+    private AclResourcePatternType patternType = AclResourcePatternType.LITERAL;
 
     @Description("Must be `" + TYPE_TOPIC + "`")
     @Override

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -88,7 +88,8 @@ private void checkMetricsConfigMap(ConfigMap metricsCm) {
     }
 
     private Map<String, String> expectedLabels(String name)    {
-        return TestUtils.map("my-user-label", "cromulent", Labels.STRIMZI_CLUSTER_LABEL, cluster, Labels.STRIMZI_TYPE_LABEL, "kafka-connect-s2i", Labels.STRIMZI_NAME_LABEL, name, Labels.STRIMZI_KIND_LABEL, KafkaConnectS2I.RESOURCE_KIND);
+        return TestUtils.map("my-user-label", "cromulent", Labels.STRIMZI_CLUSTER_LABEL, cluster,
+                Labels.STRIMZI_NAME_LABEL, name, Labels.STRIMZI_KIND_LABEL, KafkaConnectS2I.RESOURCE_KIND);
     }
 
     private Map<String, String> expectedSelectorLabels()    {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -112,6 +112,7 @@ public DeploymentConfig generateDeploymentConfig(Map<String, String> annotations
                 .endMetadata()
                 .withNewSpec()
                     .withReplicas(replicas)
+                    .withSelector(getSelectorLabels())
                     .withNewTemplate()
                         .withNewMetadata()
                             .withAnnotations(annotations)

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaConnectCrdIT.java
Patch:
@@ -46,7 +46,7 @@ public void testKafkaWithMissingRequired() {
         try {
             createDelete(KafkaConnectAssembly.class, "KafkaConnectAssembly-with-missing-required-property.yaml");
         } catch (KubeClusterException.InvalidResource e) {
-            assertTrue(e.getMessage(), e.getMessage().contains("spec.config in body is required"));
+            assertTrue(e.getMessage(), e.getMessage().contains("spec.bootstrapServers in body is required"));
         }
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/InvalidConfigParameterException.java
Patch:
@@ -5,10 +5,10 @@
 
 package io.strimzi.operator.cluster;
 
-public class InvalidConfigMapException extends RuntimeException {
+public class InvalidConfigParameterException extends RuntimeException {
 
     private String key;
-    public InvalidConfigMapException(String key, String message) {
+    public InvalidConfigParameterException(String key, String message) {
         super(key + message);
         this.key = key;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -17,7 +17,7 @@
 import io.strimzi.certs.CertManager;
 import io.strimzi.certs.SecretCertProvider;
 import io.strimzi.certs.Subject;
-import io.strimzi.operator.cluster.InvalidConfigMapException;
+import io.strimzi.operator.cluster.InvalidConfigParameterException;
 import io.strimzi.operator.cluster.model.AbstractModel;
 import io.strimzi.operator.common.Reconciliation;
 import io.strimzi.operator.common.model.Labels;
@@ -235,7 +235,7 @@ public final void reconcileAssembly(Reconciliation reconciliation, Handler<Async
                                     lock.release();
                                     log.debug("{}: Lock {} released", reconciliation, lockName);
                                     if (createResult.failed()) {
-                                        if (createResult.cause() instanceof InvalidConfigMapException) {
+                                        if (createResult.cause() instanceof InvalidConfigParameterException) {
                                             log.error(createResult.cause().getMessage());
                                         } else {
                                             log.error("{}: createOrUpdate failed", reconciliation, createResult.cause());
@@ -380,7 +380,7 @@ private void handleResult(Reconciliation reconciliation, AsyncResult<Void> resul
             log.info("{}: Assembly reconciled", reconciliation);
         } else {
             Throwable cause = result.cause();
-            if (cause instanceof InvalidConfigMapException) {
+            if (cause instanceof InvalidConfigParameterException) {
                 log.warn("{}: Failed to reconcile {}", reconciliation, cause.getMessage());
             } else {
                 log.warn("{}: Failed to reconcile", reconciliation, cause);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -284,12 +284,13 @@ public static KafkaAssembly createKafkaCluster(String clusterCmNamespace, String
      */
     public static KafkaConnectS2IAssembly createKafkaConnectS2ICluster(String clusterCmNamespace, String clusterCmName, int replicas,
                                                                        String image, int healthDelay, int healthTimeout, String metricsCmJson,
-                                                                       String connectConfig, boolean insecureSourceRepo) {
+                                                                       String connectConfig, boolean insecureSourceRepo, String bootstrapServers) {
 
         return new KafkaConnectS2IAssemblyBuilder(createEmptyKafkaConnectS2ICluster(clusterCmNamespace, clusterCmName))
                 .withNewSpec()
                     .withImage(image)
                     .withReplicas(replicas)
+                    .withBootstrapServers(bootstrapServers)
                     .withLivenessProbe(new Probe(healthDelay, healthTimeout))
                     .withReadinessProbe(new Probe(healthDelay, healthTimeout))
                     .withMetrics((Map<String, Object>) TestUtils.fromJson(metricsCmJson, Map.class))

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractConfigurationTest.java
Patch:
@@ -7,7 +7,7 @@
 import java.util.List;
 import java.util.Properties;
 
-import io.strimzi.operator.cluster.InvalidConfigMapException;
+import io.strimzi.operator.cluster.InvalidConfigParameterException;
 import io.vertx.core.json.JsonObject;
 import org.junit.Test;
 
@@ -194,7 +194,7 @@ public void testJsonWithDifferentTypes() {
         try {
             AbstractConfiguration config = new TestConfiguration(configuration);
             fail("Expected it to throw an exception");
-        } catch (InvalidConfigMapException e) {
+        } catch (InvalidConfigParameterException e) {
             assertEquals("var3", e.getKey());
         }
     }

File: systemtest/src/test/java/io/strimzi/systemtest/HelmChartST.java
Patch:
@@ -18,7 +18,7 @@
 @RunWith(StrimziRunner.class)
 @Namespace(HelmChartST.NAMESPACE)
 @ClusterOperator(useHelmChart = true)
-public class HelmChartST extends KafkaST {
+public class HelmChartST extends AbstractST {
 
     private static final Logger LOGGER = LogManager.getLogger(HelmChartST.class);
 
@@ -31,6 +31,7 @@ public class HelmChartST extends KafkaST {
     @KafkaFromClasspathYaml()
     @Topic(name = TOPIC_NAME, clusterName = "my-cluster")
     public void testDeployKafkaClusterViaHelmChart() {
+        LOGGER.info("Running testDeployKafkaClusterViaHelmChart {}", CLUSTER_NAME);
         this.kubeClient.waitForStatefulSet(zookeeperClusterName(CLUSTER_NAME), 3);
         this.kubeClient.waitForStatefulSet(kafkaClusterName(CLUSTER_NAME), 3);
     }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectS2IST.java
Patch:
@@ -18,10 +18,10 @@
 import static org.junit.Assert.assertThat;
 
 @RunWith(StrimziRunner.class)
-@Namespace(ConnectS2IClusterIT.NAMESPACE)
+@Namespace(ConnectS2IST.NAMESPACE)
 @ClusterOperator
 @KafkaFromClasspathYaml
-public class ConnectS2IClusterIT extends AbstractClusterIT {
+public class ConnectS2IST extends AbstractST {
 
     public static final String NAMESPACE = "connect-s2i-cluster-test";
     public static final String CONNECT_CLUSTER_NAME = "my-cluster";

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectST.java
Patch:
@@ -43,12 +43,12 @@
 import static org.valid4j.matchers.jsonpath.JsonPathMatchers.hasJsonPath;
 
 @RunWith(StrimziRunner.class)
-@Namespace(ConnectClusterIT.NAMESPACE)
+@Namespace(ConnectST.NAMESPACE)
 @ClusterOperator
 @KafkaFromClasspathYaml
-public class ConnectClusterIT extends AbstractClusterIT {
+public class ConnectST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(ConnectClusterIT.class);
+    private static final Logger LOGGER = LogManager.getLogger(ConnectST.class);
 
     public static final String NAMESPACE = "connect-cluster-test";
     public static final String KAFKA_CLUSTER_NAME = "connect-tests";

File: systemtest/src/test/java/io/strimzi/systemtest/HelmChartST.java
Patch:
@@ -16,11 +16,11 @@
 import org.junit.runner.RunWith;
 
 @RunWith(StrimziRunner.class)
-@Namespace(HelmChartClusterIT.NAMESPACE)
+@Namespace(HelmChartST.NAMESPACE)
 @ClusterOperator(useHelmChart = true)
-public class HelmChartClusterIT extends KafkaClusterIT {
+public class HelmChartST extends KafkaST {
 
-    private static final Logger LOGGER = LogManager.getLogger(HelmChartClusterIT.class);
+    private static final Logger LOGGER = LogManager.getLogger(HelmChartST.class);
 
     static final String NAMESPACE = "helm-chart-cluster-test";
     private static final String CLUSTER_NAME = "my-cluster";

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaST.java
Patch:
@@ -58,11 +58,11 @@
 import static org.valid4j.matchers.jsonpath.JsonPathMatchers.hasJsonPath;
 
 @RunWith(StrimziRunner.class)
-@Namespace(KafkaClusterIT.NAMESPACE)
+@Namespace(KafkaST.NAMESPACE)
 @ClusterOperator
-public class KafkaClusterIT extends AbstractClusterIT {
+public class KafkaST extends AbstractST {
 
-    private static final Logger LOGGER = LogManager.getLogger(KafkaClusterIT.class);
+    private static final Logger LOGGER = LogManager.getLogger(KafkaST.class);
 
     public static final String NAMESPACE = "kafka-cluster-test";
     private static final String TOPIC_NAME = "test-topic";

File: systemtest/src/test/java/io/strimzi/systemtest/OpenShiftTemplatesST.java
Patch:
@@ -47,15 +47,15 @@
  */
 @RunWith(StrimziRunner.class)
 @OpenShiftOnly
-@Namespace(OpenShiftTemplatesIT.NAMESPACE)
+@Namespace(OpenShiftTemplatesST.NAMESPACE)
 @Resources(value = "../examples/templates/cluster-operator", asAdmin = true)
 @Resources(value = "../examples/templates/topic-operator", asAdmin = true)
 @Resources(value = TestUtils.CRD_KAFKA, asAdmin = true)
 @Resources(value = TestUtils.CRD_KAFKA_CONNECT, asAdmin = true)
 @Resources(value = TestUtils.CRD_KAFKA_CONNECT_S2I, asAdmin = true)
 @Resources(value = TestUtils.CRD_TOPIC, asAdmin = true)
 @Resources(value = "src/rbac/role-edit-kafka.yaml", asAdmin = true)
-public class OpenShiftTemplatesIT {
+public class OpenShiftTemplatesST {
 
     public static final String NAMESPACE = "template-test";
 

File: systemtest/src/test/java/io/strimzi/systemtest/RecoveryST.java
Patch:
@@ -22,15 +22,15 @@
 
 @RunWith(StrimziRunner.class)
 @JUnitGroup(name = "regression")
-@Namespace(RecoveryClusterIT.NAMESPACE)
+@Namespace(RecoveryST.NAMESPACE)
 @ClusterOperator
 @KafkaFromClasspathYaml
-public class RecoveryClusterIT extends AbstractClusterIT {
+public class RecoveryST extends AbstractST {
 
     static final String NAMESPACE = "recovery-cluster-test";
     static final String CLUSTER_NAME = "recovery-cluster";
 
-    private static final Logger LOGGER = LogManager.getLogger(RecoveryClusterIT.class);
+    private static final Logger LOGGER = LogManager.getLogger(RecoveryST.class);
 
     @Test
     public void testRecoveryFromTopicOperatorDeletion() {

File: api/src/test/java/io/strimzi/test/StrimziRunner.java
Patch:
@@ -799,7 +799,7 @@ private Statement withNamespaces(Annotatable element,
                 protected void before() {
                     LOGGER.info("Creating namespace '{}' before test per @Namespace annotation on {}", namespace.value(), name(element));
                     kubeClient().createNamespace(namespace.value());
-                    previousNamespace = kubeClient().namespace(namespace.value());
+                    previousNamespace = namespace.use() ? kubeClient().namespace(namespace.value()) : kubeClient().namespace();
                 }
 
                 @Override

File: api/src/main/java/io/strimzi/api/kafka/model/Logging.java
Patch:
@@ -26,7 +26,7 @@ public abstract class Logging implements Serializable {
 
     private static final long serialVersionUID = 1L;
 
-    @Description("Storage type, must be either 'inline' or 'external'.")
+    @Description("Logging type, must be either 'inline' or 'external'.")
     @JsonIgnore
     public abstract String getType();
 

File: api/src/test/java/io/strimzi/api/kafka/model/ExamplesTest.java
Patch:
@@ -123,7 +123,8 @@ private void checkForJsonAnyGetter(Stack<String> path, Object resource, Class<?>
             if (isGetter(method)) {
                 Object result = method.invoke(resource);
                 if (result != null
-                    && !result.getClass().isPrimitive()) {
+                    && !result.getClass().isPrimitive()
+                    && !result.getClass().isEnum()) {
                     path.push(method.getName());
                     recurseForAdditionalProperties(path, result);
                     path.pop();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -131,8 +131,8 @@ public abstract class AbstractModel {
     protected String headlessServiceName;
     protected String name;
 
-    protected final int metricsPort = 9404;
-    protected final String metricsPortName = "kafkametrics";
+    protected static final int METRICS_PORT = 9404;
+    protected static final String METRICS_PORT_NAME = "metrics";
     protected boolean isMetricsEnabled;
 
     protected Iterable<Map.Entry<String, Object>> metricsConfig;
@@ -1095,7 +1095,7 @@ public static boolean deleteClaim(StatefulSet ss) {
      */
     protected Map<String, String> getPrometheusAnnotations()    {
         Map<String, String> annotations = new HashMap<String, String>(3);
-        annotations.put("prometheus.io/port", String.valueOf(metricsPort));
+        annotations.put("prometheus.io/port", String.valueOf(METRICS_PORT));
         annotations.put("prometheus.io/scrape", "true");
         annotations.put("prometheus.io/path", "/metrics");
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -32,8 +32,6 @@ public class KafkaConnectCluster extends AbstractModel {
     // Port configuration
     protected static final int REST_API_PORT = 8083;
     protected static final String REST_API_PORT_NAME = "rest-api";
-    protected static final int METRICS_PORT = 9404;
-    protected static final String METRICS_PORT_NAME = "metrics";
 
     private static final String NAME_SUFFIX = "-connect";
     private static final String SERVICE_NAME_SUFFIX = NAME_SUFFIX + "-api";
@@ -149,7 +147,7 @@ protected List<ContainerPort> getContainerPortList() {
         List<ContainerPort> portList = new ArrayList<>(2);
         portList.add(createContainerPort(REST_API_PORT_NAME, REST_API_PORT, "TCP"));
         if (isMetricsEnabled) {
-            portList.add(createContainerPort(metricsPortName, metricsPort, "TCP"));
+            portList.add(createContainerPort(METRICS_PORT_NAME, METRICS_PORT, "TCP"));
         }
 
         return portList;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -44,8 +44,6 @@ public class ZookeeperCluster extends AbstractModel {
     protected static final String CLUSTERING_PORT_NAME = "clustering";
     protected static final int LEADER_ELECTION_PORT = 3888;
     protected static final String LEADER_ELECTION_PORT_NAME = "leader-election";
-    protected static final int METRICS_PORT = 9404;
-    protected static final String METRICS_PORT_NAME = "metrics";
 
     protected static final String ZOOKEEPER_NAME = "zookeeper";
     protected static final String TLS_SIDECAR_NAME = "tls-sidecar";
@@ -327,7 +325,7 @@ private List<ServicePort> getServicePortList() {
     private List<ContainerPort> getContainerPortList() {
         List<ContainerPort> portList = new ArrayList<>();
         if (isMetricsEnabled) {
-            portList.add(createContainerPort(metricsPortName, metricsPort, "TCP"));
+            portList.add(createContainerPort(METRICS_PORT_NAME, METRICS_PORT, "TCP"));
         }
 
         return portList;

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -54,7 +54,7 @@ public abstract class AbstractAssemblyOperator<C extends KubernetesClient, T ext
 
     private static final Logger log = LogManager.getLogger(AbstractAssemblyOperator.class.getName());
 
-    protected static final int LOCK_TIMEOUT = 60000;
+    protected static final int LOCK_TIMEOUT_MS = 10000;
     protected static final int CERTS_EXPIRATION_DAYS = 365;
 
     protected final Vertx vertx;
@@ -212,7 +212,7 @@ public final void reconcileAssembly(Reconciliation reconciliation, Handler<Async
         String namespace = reconciliation.namespace();
         String assemblyName = reconciliation.assemblyName();
         final String lockName = getLockName(assemblyType, namespace, assemblyName);
-        vertx.sharedData().getLockWithTimeout(lockName, LOCK_TIMEOUT, res -> {
+        vertx.sharedData().getLockWithTimeout(lockName, LOCK_TIMEOUT_MS, res -> {
             if (res.succeeded()) {
                 log.debug("{}: Lock {} acquired", reconciliation, lockName);
                 Lock lock = res.result();
@@ -273,7 +273,7 @@ public final void reconcileAssembly(Reconciliation reconciliation, Handler<Async
                     handler.handle(Future.failedFuture(ex));
                 }
             } else {
-                log.warn("{}: Failed to acquire lock {}.", reconciliation, lockName);
+                log.debug("{}: Failed to acquire lock {}.", reconciliation, lockName);
             }
         });
     }

File: topic-operator/src/main/java/io/strimzi/operator/topic/Session.java
Patch:
@@ -116,11 +116,12 @@ public void start() {
         adminClientProps.setProperty(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(Config.KAFKA_BOOTSTRAP_SERVERS));
 
         if (Boolean.valueOf(config.get(Config.TLS_ENABLED))) {
-            adminClientProps.setProperty("security.protocol", "SSL");
+            adminClientProps.setProperty(AdminClientConfig.SECURITY_PROTOCOL_CONFIG, "SSL");
             adminClientProps.setProperty("ssl.truststore.location", config.get(Config.TLS_TRUSTSTORE_LOCATION));
             adminClientProps.setProperty("ssl.truststore.password", config.get(Config.TLS_TRUSTSTORE_PASSWORD));
             adminClientProps.setProperty("ssl.keystore.location", config.get(Config.TLS_KEYSTORE_LOCATION));
             adminClientProps.setProperty("ssl.keystore.password", config.get(Config.TLS_KEYSTORE_PASSWORD));
+            adminClientProps.setProperty("ssl.endpoint.identification.algorithm", "HTTPS");
         }
 
         this.adminClient = AdminClient.create(adminClientProps);

File: api/src/test/java/io/strimzi/test/TestUtils.java
Patch:
@@ -50,6 +50,8 @@ private TestUtils() {
         // All static methods
     }
 
+    public static final String KAFKA_USER_CRD = "../examples/install/cluster-operator/04-Crd-kafkauser.yaml";
+
     /** Returns a Map of the given sequence of key, value pairs. */
     public static <T> Map<T, T> map(T... pairs) {
         if (pairs.length % 2 != 0) {

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaConnectCrdIT.java
Patch:
@@ -22,7 +22,7 @@
  */
 @RunWith(StrimziRunner.class)
 @Namespace(KafkaConnectCrdIT.NAMESPACE)
-@Resources(value = TestUtils.KAFKA_CONNECT_CRD, asAdmin = true)
+@Resources(value = TestUtils.CRD_KAFKA_CONNECT, asAdmin = true)
 public class KafkaConnectCrdIT extends AbstractCrdIT {
     public static final String NAMESPACE = "kafkaconnect-crd-it";
 

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaCrdIT.java
Patch:
@@ -22,7 +22,7 @@
  */
 @RunWith(StrimziRunner.class)
 @Namespace(KafkaCrdIT.NAMESPACE)
-@Resources(value = TestUtils.KAFKA_CRD, asAdmin = true)
+@Resources(value = TestUtils.CRD_KAFKA, asAdmin = true)
 public class KafkaCrdIT extends AbstractCrdIT {
     public static final String NAMESPACE = "kafkacrd-it";
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -968,7 +968,7 @@ protected void heapOptions(List<EnvVar> envVars, double dynamicHeapFraction, lon
      */
     protected void jvmPerformanceOptions(List<EnvVar> envVars) {
         StringBuilder jvmPerformanceOpts = new StringBuilder();
-        Boolean server = jvmOptions != null ? jvmOptions.getServer() : null;
+        Boolean server = jvmOptions != null ? jvmOptions.isServer() : null;
 
         if (server != null && server) {
             jvmPerformanceOpts.append("-server");

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/TopicOperatorTest.java
Patch:
@@ -76,7 +76,7 @@ public class TopicOperatorTest {
 
     private List<EnvVar> getExpectedEnvVars() {
         List<EnvVar> expected = new ArrayList<>();
-        expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_CONFIGMAP_LABELS).withValue(TopicOperator.defaultTopicConfigMapLabels(cluster)).build());
+        expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_RESOURCE_LABELS).withValue(TopicOperator.defaultTopicConfigMapLabels(cluster)).build());
         expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_KAFKA_BOOTSTRAP_SERVERS).withValue(TopicOperator.defaultBootstrapServers(cluster)).build());
         expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_ZOOKEEPER_CONNECT).withValue(String.format("%s:%d", "localhost", io.strimzi.api.kafka.model.TopicOperator.DEFAULT_ZOOKEEPER_PORT)).build());
         expected.add(new EnvVarBuilder().withName(TopicOperator.ENV_VAR_WATCHED_NAMESPACE).withValue(tcWatchedNamespace).build());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -196,7 +196,7 @@ public void before() {
                 .endSpec()
                 .build();
 
-        CustomResourceDefinition kafkaAssemblyCrd = TestUtils.fromYamlFile(TestUtils.KAFKA_CRD, CustomResourceDefinition.class);
+        CustomResourceDefinition kafkaAssemblyCrd = TestUtils.fromYamlFile(TestUtils.CRD_KAFKA, CustomResourceDefinition.class);
 
         mockClient = new MockKube().withCustomResourceDefinition(kafkaAssemblyCrd, KafkaAssembly.class, KafkaAssemblyList.class, DoneableKafkaAssembly.class)
                 .withInitialInstances(Collections.singleton(cluster)).end().build();

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -42,7 +42,7 @@ public class PartialRollingUpdateTest {
 
     private static final String NAMESPACE = "my-namespace";
     private static final String CLUSTER_NAME = "my-cluster";
-    public static final String KAFKA_CRD_FILE = TestUtils.KAFKA_CRD;
+    public static final String KAFKA_CRD_FILE = TestUtils.CRD_KAFKA;
 
     private Vertx vertx;
     private KafkaAssembly cluster;

File: crd-generator/src/main/java/io/strimzi/crdgenerator/Property.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.crdgenerator;
 
+import com.fasterxml.jackson.annotation.JsonAnyGetter;
 import com.fasterxml.jackson.annotation.JsonIgnore;
 import com.fasterxml.jackson.annotation.JsonProperty;
 import com.fasterxml.jackson.annotation.JsonPropertyOrder;
@@ -100,7 +101,8 @@ static Map<String, Property> properties(Class<?> crdClass) {
                     && !returnType.equals(void.class);
             boolean isNotInherited = !hasMethod(CustomResource.class, method)
                     && !hasMethod(HasMetadata.class, method);
-            boolean isNotIgnored = !method.isAnnotationPresent(JsonIgnore.class);
+            boolean isNotIgnored = !method.isAnnotationPresent(JsonIgnore.class)
+                    && !method.isAnnotationPresent(JsonAnyGetter.class);
             if (isGetter
                     && isNotInherited
                     && isNotIgnored) {

File: topic-operator/src/main/java/io/strimzi/operator/topic/Config.java
Patch:
@@ -89,7 +89,7 @@ private Value(String key, Type<? extends T> type, boolean required) {
         }
     }
 
-    public static final String TC_CM_LABELS = "STRIMZI_CONFIGMAP_LABELS";
+    public static final String TC_RESOURCE_LABELS = "STRIMZI_RESOURCE_LABELS";
     public static final String TC_KAFKA_BOOTSTRAP_SERVERS = "STRIMZI_KAFKA_BOOTSTRAP_SERVERS";
     public static final String TC_NAMESPACE = "STRIMZI_NAMESPACE";
     public static final String TC_ZK_CONNECT = "STRIMZI_ZOOKEEPER_CONNECT";
@@ -107,8 +107,8 @@ private Value(String key, Type<? extends T> type, boolean required) {
 
     private static final Map<String, Value<?>> CONFIG_VALUES = new HashMap<>();
 
-    /** A comma-separated list of key=value pairs for selecting ConfigMaps that describe topics. */
-    public static final Value<LabelPredicate> LABELS = new Value<>(TC_CM_LABELS, LABEL_PREDICATE, "strimzi.io/kind=topic");
+    /** A comma-separated list of key=value pairs for selecting Resources that describe topics. */
+    public static final Value<LabelPredicate> LABELS = new Value<>(TC_RESOURCE_LABELS, LABEL_PREDICATE, "strimzi.io/kind=topic");
 
     /** A comma-separated list of kafka bootstrap servers. */
     public static final Value<String> KAFKA_BOOTSTRAP_SERVERS = new Value<>(TC_KAFKA_BOOTSTRAP_SERVERS, STRING, true);

File: topic-operator/src/main/java/io/strimzi/operator/topic/InvalidTopicException.java
Patch:
@@ -6,8 +6,8 @@
 
 import io.fabric8.kubernetes.api.model.HasMetadata;
 
-public class InvalidConfigMapException extends OperatorException {
-    public InvalidConfigMapException(HasMetadata involvedObject, String message) {
+public class InvalidTopicException extends OperatorException {
+    public InvalidTopicException(HasMetadata involvedObject, String message) {
         super(involvedObject, message);
     }
 }

File: topic-operator/src/main/java/io/strimzi/operator/topic/LabelPredicate.java
Patch:
@@ -133,8 +133,8 @@ public Map<String, String> labels() {
     }
 
     @Override
-    public boolean test(HasMetadata configMap) {
-        Map<String, String> mapLabels = configMap.getMetadata().getLabels();
+    public boolean test(HasMetadata resource) {
+        Map<String, String> mapLabels = resource.getMetadata().getLabels();
         if (mapLabels == null) {
             return false;
         } else {

File: topic-operator/src/main/java/io/strimzi/operator/topic/OperatorException.java
Patch:
@@ -7,7 +7,7 @@
 import io.fabric8.kubernetes.api.model.HasMetadata;
 
 /**
- * An exception possibly with an attached K8S resource (e.g. a ConfigMap).
+ * An exception possibly with an attached K8S resource (e.g. a KafkaTopic).
  */
 public class OperatorException extends RuntimeException {
 

File: topic-operator/src/main/java/io/strimzi/operator/topic/ZkTopicWatcher.java
Patch:
@@ -11,11 +11,11 @@
  * calling {@link TopicOperator#onTopicPartitionsChanged(TopicName, Handler)}
  * for changed children.
  */
-public class TopicWatcher extends ZkWatcher {
+public class ZkTopicWatcher extends ZkWatcher {
 
     private static final String TOPICS_ZNODE = "/brokers/topics";
 
-    TopicWatcher(TopicOperator topicOperator) {
+    ZkTopicWatcher(TopicOperator topicOperator) {
         super(topicOperator, TOPICS_ZNODE);
     }
 

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectClusterIT.java
Patch:
@@ -104,7 +104,7 @@ public void testDeployUndeploy() {
     public void testKafkaConnectWithFileSinkPlugin() {
 
         String connectorConfig = getFileAsString("../systemtest/src/test/resources/file/sink/connector.json");
-        String kafkaConnectPodName = kubeClient.listResourcesByLabel("pod", "strimzi.io/type=kafka-connect").get(0);
+        String kafkaConnectPodName = kubeClient.listResourcesByLabel("pod", "type=kafka-connect").get(0);
         kubeClient.execInPod(kafkaConnectPodName, "/bin/bash", "-c", "curl -X POST -H \"Content-Type: application/json\" --data "
                 + "'" + connectorConfig + "'" + " http://localhost:8083/connectors");
 

File: certificate-manager/src/test/java/io/strimzi/certs/OpenSslCertManagerTest.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.certs;
 
+import io.strimzi.test.TestUtils;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -31,6 +32,7 @@ public class OpenSslCertManagerTest {
 
     @BeforeClass
     public static void before() throws CertificateException {
+        TestUtils.assumeLinux();
         certFactory = CertificateFactory.getInstance("X.509");
         ssl = new OpenSslCertManager();
     }

File: certificate-manager/src/test/java/io/strimzi/certs/SecretCertProviderTest.java
Patch:
@@ -5,6 +5,7 @@
 package io.strimzi.certs;
 
 import io.fabric8.kubernetes.api.model.Secret;
+import io.strimzi.test.TestUtils;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -25,6 +26,7 @@ public class SecretCertProviderTest {
 
     @BeforeClass
     public static void before() {
+        TestUtils.assumeLinux();
         ssl = new OpenSslCertManager();
         secretCertProvider = new SecretCertProvider();
     }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -30,6 +30,7 @@
 import java.util.List;
 import java.util.Map;
 
+import static io.strimzi.test.TestUtils.LINE_SEPARATOR;
 import static java.util.Collections.emptyMap;
 import static java.util.Collections.singletonMap;
 import static org.junit.Assert.assertEquals;
@@ -198,7 +199,7 @@ private void checkStatefulSet(StatefulSet ss, KafkaAssembly cm, boolean isOpenSh
         assertEquals(new Integer(healthDelay), containers.get(0).getLivenessProbe().getInitialDelaySeconds());
         assertEquals(new Integer(healthTimeout), containers.get(0).getReadinessProbe().getTimeoutSeconds());
         assertEquals(new Integer(healthDelay), containers.get(0).getReadinessProbe().getInitialDelaySeconds());
-        assertEquals("foo=bar\n", AbstractModel.containerEnvVars(containers.get(0)).get(KafkaCluster.ENV_VAR_KAFKA_CONFIGURATION));
+        assertEquals("foo=bar" + LINE_SEPARATOR, AbstractModel.containerEnvVars(containers.get(0)).get(KafkaCluster.ENV_VAR_KAFKA_CONFIGURATION));
         assertEquals(KafkaCluster.BROKER_CERTS_VOLUME, containers.get(0).getVolumeMounts().get(1).getName());
         assertEquals(KafkaCluster.BROKER_CERTS_VOLUME_MOUNT, containers.get(0).getVolumeMounts().get(1).getMountPath());
         assertEquals(KafkaCluster.CLIENT_CA_CERTS_VOLUME, containers.get(0).getVolumeMounts().get(2).getName());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -523,7 +523,9 @@ private final Future<Void> createOrUpdateTopicOperator(Reconciliation reconcilia
                 .compose(desc -> desc.withVoid(roleBindingOperator.reconcile(namespace,
                         TopicOperator.TO_ROLE_BINDING_NAME,
                         desc != TopicOperatorDescription.EMPTY ? desc.topicOperator().generateRoleBinding(namespace) : null)))
-                .compose(desc -> desc.withVoid(configMapOperations.reconcile(namespace, desc != TopicOperatorDescription.EMPTY ? desc.topicOperator().getAncillaryConfigName() : null, desc.metricsAndLogsConfigMap())))
+                .compose(desc -> desc.withVoid(configMapOperations.reconcile(namespace,
+                        desc != TopicOperatorDescription.EMPTY ? desc.topicOperator().getAncillaryConfigName() : TopicOperator.metricAndLogConfigsName(name),
+                        desc.metricsAndLogsConfigMap())))
                 .compose(desc -> desc.withVoid(deploymentOperations.reconcile(namespace, TopicOperator.topicOperatorName(name), desc.deployment())))
                 .compose(desc -> desc.withVoid(secretOperations.reconcile(namespace, TopicOperator.secretName(name), desc.topicOperatorSecret())))
                 .compose(desc -> chainFuture.complete(), chainFuture);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -564,7 +564,7 @@ protected List<EnvVar> getEnvVars() {
         heapOptions(varList, 0.5, 5L * 1024L * 1024L * 1024L);
         jvmPerformanceOptions(varList);
 
-        if (configuration != null) {
+        if (configuration != null && !configuration.getConfiguration().isEmpty()) {
             varList.add(buildEnvVar(ENV_VAR_KAFKA_CONFIGURATION, configuration.getConfiguration()));
         }
         // A hack to force rolling when the logging config changes

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -214,6 +214,7 @@ public static KafkaCluster fromCrd(CertManager certManager, KafkaAssembly kafkaA
         result.setStorage(kafka.getStorage());
         result.setUserAffinity(kafka.getAffinity());
         result.setResources(kafka.getResources());
+        result.setTolerations(kafka.getTolerations());
 
         result.generateCertificates(certManager, secrets);
         result.setTlsSidecar(kafka.getTlsSidecar());

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -130,6 +130,7 @@ protected static <C extends KafkaConnectCluster> C fromSpec(KafkaConnectAssembly
                 kafkaConnect.setMetricsConfig(metrics.entrySet());
             }
             kafkaConnect.setUserAffinity(spec.getAffinity());
+            kafkaConnect.setTolerations(spec.getTolerations());
         }
         return kafkaConnect;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -116,6 +116,8 @@ public DeploymentConfig generateDeploymentConfig() {
                         .withNewSpec()
                             .withContainers(container)
                             .withVolumes(getVolumes())
+                            .withTolerations(getTolerations())
+                            .withAffinity(getMergedAffinity())
                         .endSpec()
                     .endTemplate()
                     .withTriggers(configChangeTrigger, imageChangeTrigger)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -173,6 +173,7 @@ public static ZookeeperCluster fromCrd(CertManager certManager, KafkaAssembly ka
         zk.setResources(zookeeper.getResources());
         zk.setJvmOptions(zookeeper.getJvmOptions());
         zk.setUserAffinity(zookeeper.getAffinity());
+        zk.setTolerations(zookeeper.getTolerations());
         zk.generateCertificates(certManager, secrets);
         zk.setTlsSidecar(zookeeper.getTlsSidecar());
         return zk;

File: api/src/main/java/io/strimzi/api/kafka/model/Kafka.java
Patch:
@@ -28,7 +28,7 @@ public class Kafka extends ReplicatedJvmPods {
     public static final String DEFAULT_IMAGE =
             System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_IMAGE", "strimzi/kafka:latest");
     public static final String DEFAULT_INIT_IMAGE =
-            System.getenv().getOrDefault("STRIMZI_DEFAULT_INIT_KAFKA_IMAGE", "strimzi/init-kafka:latest");
+            System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_INIT_IMAGE", "strimzi/kafka-init:latest");
     public static final String DEFAULT_TLS_SIDECAR_IMAGE =
             System.getenv().getOrDefault("STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE", "strimzi/kafka-stunnel:latest");
     public static final String FORBIDDEN_PREFIXES = "listeners, advertised., broker., listener., host.name, port, "

File: kafka-init/src/main/java/io/strimzi/kafka/init/Main.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.init.kafka;
+package io.strimzi.kafka.init;
 
 import io.fabric8.kubernetes.client.DefaultKubernetesClient;
 import io.fabric8.kubernetes.client.KubernetesClient;

File: kafka-init/src/main/java/io/strimzi/kafka/init/RackWriter.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.init.kafka;
+package io.strimzi.kafka.init;
 
 import io.fabric8.kubernetes.client.KubernetesClient;
 import org.apache.logging.log4j.LogManager;

File: kafka-init/src/main/java/io/strimzi/kafka/init/RackWriterConfig.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.init.kafka;
+package io.strimzi.kafka.init;
 
 import java.util.Map;
 

File: kafka-init/src/test/java/io/strimzi/kafka/init/RackWriterConfigTest.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.init.kafka;
+package io.strimzi.kafka.init;
 
 import org.junit.Test;
 

File: kafka-init/src/test/java/io/strimzi/kafka/init/RackWriterTest.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.init.kafka;
+package io.strimzi.kafka.init;
 
 import io.fabric8.kubernetes.api.model.Node;
 import io.fabric8.kubernetes.api.model.ObjectMeta;

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractClusterIT.java
Patch:
@@ -67,7 +67,7 @@ public class AbstractClusterIT {
     protected static final String CONNECT_IMAGE = "STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE";
     protected static final String S2I_IMAGE = "STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE";
     protected static final String TO_IMAGE = "STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE";
-    protected static final String INIT_KAFKA_IMAGE = "STRIMZI_DEFAULT_INIT_KAFKA_IMAGE";
+    protected static final String KAFKA_INIT_IMAGE = "STRIMZI_DEFAULT_KAFKA_INIT_IMAGE";
     protected static final String TLS_SIDECAR_ZOOKEEPER_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_ZOOKEEPER_IMAGE";
     protected static final String TLS_SIDECAR_KAFKA_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_KAFKA_IMAGE";
     protected static final String TLS_SIDECAR_TO_IMAGE = "STRIMZI_DEFAULT_TLS_SIDECAR_TOPIC_OPERATOR_IMAGE";
@@ -354,7 +354,7 @@ public Map<String, String> getImagesFromConfig(String configJson) {
         images.put(CONNECT_IMAGE, getImageNameFromJSON(configJson, CONNECT_IMAGE));
         images.put(S2I_IMAGE, getImageNameFromJSON(configJson, S2I_IMAGE));
         images.put(TO_IMAGE, getImageNameFromJSON(configJson, TO_IMAGE));
-        images.put(INIT_KAFKA_IMAGE, getImageNameFromJSON(configJson, INIT_KAFKA_IMAGE));
+        images.put(KAFKA_INIT_IMAGE, getImageNameFromJSON(configJson, KAFKA_INIT_IMAGE));
         images.put(TLS_SIDECAR_ZOOKEEPER_IMAGE, getImageNameFromJSON(configJson, TLS_SIDECAR_ZOOKEEPER_IMAGE));
         images.put(TLS_SIDECAR_KAFKA_IMAGE, getImageNameFromJSON(configJson, TLS_SIDECAR_KAFKA_IMAGE));
         images.put(TLS_SIDECAR_TO_IMAGE, getImageNameFromJSON(configJson, TLS_SIDECAR_TO_IMAGE));

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaClusterIT.java
Patch:
@@ -381,7 +381,7 @@ private void testDockerImagesForKafkaCluster(String clusterName, int kafkaPods,
             assertEquals(imgFromDeplConf.get(TLS_SIDECAR_KAFKA_IMAGE), imgFromPod);
             if (rackAwareEnabled) {
                 String initContainerImage = getInitContainerImageName(kafkaPodName(clusterName, i));
-                assertEquals(imgFromDeplConf.get(INIT_KAFKA_IMAGE), initContainerImage);
+                assertEquals(imgFromDeplConf.get(KAFKA_INIT_IMAGE), initContainerImage);
             }
         }
 

File: api/src/main/java/io/strimzi/api/kafka/model/Zookeeper.java
Patch:
@@ -23,7 +23,7 @@
 )
 @JsonPropertyOrder({ "replicas", "image", "storage",
         "livenessProbe", "readinessProbe", "jvmOptions",
-        "affinity", "metrics", "tlsSidecarImage"})
+        "affinity", "metrics", "tlsSidecar"})
 public class Zookeeper extends ReplicatedJvmPods {
     public static final String FORBIDDEN_PREFIXES = "server., dataDir, dataLogDir, clientPort, authProvider, quorum.auth, requireClientAuthScheme";
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -290,7 +290,8 @@ protected List<Container> getContainers() {
                 .withEnv(singletonList(buildEnvVar(ENV_VAR_ZOOKEEPER_NODE_COUNT, Integer.toString(replicas))))
                 .withVolumeMounts(createVolumeMount(TLS_SIDECAR_VOLUME_NAME, TLS_SIDECAR_VOLUME_MOUNT))
                 .withPorts(asList(createContainerPort(CLUSTERING_PORT_NAME, CLUSTERING_PORT, "TCP"),
-                                createContainerPort(LEADER_ELECTION_PORT_NAME, LEADER_ELECTION_PORT, "TCP")))
+                                createContainerPort(LEADER_ELECTION_PORT_NAME, LEADER_ELECTION_PORT, "TCP"),
+                                createContainerPort(CLIENT_PORT_NAME, CLIENT_PORT, "TCP")))
                 .build();
 
         containers.add(container);
@@ -324,7 +325,6 @@ private List<ServicePort> getServicePortList() {
 
     private List<ContainerPort> getContainerPortList() {
         List<ContainerPort> portList = new ArrayList<>();
-        portList.add(createContainerPort(CLIENT_PORT_NAME, CLIENT_PORT, "TCP"));
         if (isMetricsEnabled) {
             portList.add(createContainerPort(metricsPortName, metricsPort, "TCP"));
         }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -134,15 +134,15 @@ private void checkStatefulSet(StatefulSet ss) {
         assertEquals(new Integer(healthTimeout), containers.get(0).getReadinessProbe().getTimeoutSeconds());
         assertEquals(new Integer(healthDelay), containers.get(0).getReadinessProbe().getInitialDelaySeconds());
         assertEquals("timeTick=2000\nautopurge.purgeInterval=1\nsyncLimit=2\ninitLimit=5\nfoo=bar\n", AbstractModel.containerEnvVars(containers.get(0)).get(ZookeeperCluster.ENV_VAR_ZOOKEEPER_CONFIGURATION));
-        assertEquals(ZookeeperCluster.CLIENT_PORT_NAME, containers.get(0).getPorts().get(0).getName());
-        assertEquals(new Integer(ZookeeperCluster.CLIENT_PORT), containers.get(0).getPorts().get(0).getContainerPort());
         // checks on the TLS sidecar container
         assertEquals(Zookeeper.DEFAULT_TLS_SIDECAR_IMAGE, containers.get(1).getImage());
         assertEquals(new Integer(replicas), Integer.valueOf(AbstractModel.containerEnvVars(containers.get(1)).get(ZookeeperCluster.ENV_VAR_ZOOKEEPER_NODE_COUNT)));
         assertEquals(ZookeeperCluster.CLUSTERING_PORT_NAME, containers.get(1).getPorts().get(0).getName());
         assertEquals(new Integer(ZookeeperCluster.CLUSTERING_PORT), containers.get(1).getPorts().get(0).getContainerPort());
         assertEquals(ZookeeperCluster.LEADER_ELECTION_PORT_NAME, containers.get(1).getPorts().get(1).getName());
         assertEquals(new Integer(ZookeeperCluster.LEADER_ELECTION_PORT), containers.get(1).getPorts().get(1).getContainerPort());
+        assertEquals(ZookeeperCluster.CLIENT_PORT_NAME, containers.get(1).getPorts().get(2).getName());
+        assertEquals(new Integer(ZookeeperCluster.CLIENT_PORT), containers.get(1).getPorts().get(2).getContainerPort());
     }
 
     /**

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ResourceTester.java
Patch:
@@ -50,7 +50,7 @@ interface TriFunction<X, Y, Z, R> {
     ResourceTester(Class<R> cls, TriFunction<CertManager, R, List<Secret>, M> fromResource) {
         this.cls = cls;
         this.fromK8sResource = resource -> {
-            return fromResource.apply(new MockCertManager(), resource, ResourceUtils.createKafkaClusterInitialSecrets(resource.getMetadata().getNamespace()));
+            return fromResource.apply(new MockCertManager(), resource, ResourceUtils.createKafkaClusterInitialSecrets(resource.getMetadata().getNamespace(), resource.getMetadata().getName()));
         };
     }
 

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaConnectCrdIT.java
Patch:
@@ -7,6 +7,7 @@
 import io.strimzi.test.Namespace;
 import io.strimzi.test.Resources;
 import io.strimzi.test.StrimziRunner;
+import io.strimzi.test.TestUtils;
 import io.strimzi.test.k8s.KubeClusterException;
 import org.junit.Test;
 import org.junit.runner.RunWith;
@@ -21,7 +22,7 @@
  */
 @RunWith(StrimziRunner.class)
 @Namespace(KafkaConnectCrdIT.NAMESPACE)
-@Resources(value = "../examples/install/cluster-operator/07-crd-kafka-connect.yaml", asAdmin = true)
+@Resources(value = TestUtils.KAFKA_CONNECT_CRD, asAdmin = true)
 public class KafkaConnectCrdIT extends AbstractCrdIT {
     public static final String NAMESPACE = "kafkaconnect-crd-it";
 

File: api/src/test/java/io/strimzi/api/kafka/model/KafkaCrdIT.java
Patch:
@@ -7,6 +7,7 @@
 import io.strimzi.test.Namespace;
 import io.strimzi.test.Resources;
 import io.strimzi.test.StrimziRunner;
+import io.strimzi.test.TestUtils;
 import io.strimzi.test.k8s.KubeClusterException;
 import org.junit.Test;
 import org.junit.runner.RunWith;
@@ -21,7 +22,7 @@
  */
 @RunWith(StrimziRunner.class)
 @Namespace(KafkaCrdIT.NAMESPACE)
-@Resources(value = "../examples/install/cluster-operator/07-crd-kafka.yaml", asAdmin = true)
+@Resources(value = TestUtils.KAFKA_CRD, asAdmin = true)
 public class KafkaCrdIT extends AbstractCrdIT {
     public static final String NAMESPACE = "kafkacrd-it";
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperator.java
Patch:
@@ -32,7 +32,6 @@ public class ClusterOperator extends AbstractVerticle {
     private static final Logger log = LogManager.getLogger(ClusterOperator.class.getName());
 
     public static final String STRIMZI_CLUSTER_OPERATOR_DOMAIN = "cluster.operator.strimzi.io";
-    public static final String STRIMZI_CLUSTER_OPERATOR_SERVICE_ACCOUNT = "strimzi-cluster-operator";
 
     private static final int HEALTH_SERVER_PORT = 8080;
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -70,11 +70,11 @@ public abstract class AbstractAssemblyOperator<C extends KubernetesClient, T ext
      * @param isOpenShift True iff running on OpenShift
      * @param assemblyType Assembly type
      * @param resourceOperator For operating on the desired resource
-     * @param secretOperations For operating on Secrets
      */
     protected AbstractAssemblyOperator(Vertx vertx, boolean isOpenShift, AssemblyType assemblyType,
                                        CertManager certManager,
-                                       AbstractWatchableResourceOperator<C, T, L, D, R> resourceOperator, SecretOperator secretOperations) {
+                                       AbstractWatchableResourceOperator<C, T, L, D, R> resourceOperator,
+                                       SecretOperator secretOperations) {
         this.vertx = vertx;
         this.isOpenShift = isOpenShift;
         this.assemblyType = assemblyType;

File: api/src/main/java/io/strimzi/api/kafka/model/CpuMemory.java
Patch:
@@ -65,7 +65,7 @@ public void setMemory(String mem) {
     /** The CPUs in "millicpus". */
     @JsonIgnore
     public int milliCpuAsInt() {
-        return MilliCpuDeserializer.parse(milliCpu);
+        return milliCpu == null ? 0 : MilliCpuDeserializer.parse(milliCpu);
     }
 
     public void milliCpuAsInt(int milliCpu) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -353,7 +353,7 @@ public String parseLogging(Logging logging, ConfigMap externalCm) {
     }
 
     /**
-     * Generates a metrics ConfigMap according to configured defaults
+     * Generates a metrics and logging ConfigMap according to configured defaults
      * @return The generated ConfigMap
      */
     public ConfigMap generateMetricsAndLogConfigMap(ConfigMap cm) {

File: api/src/test/java/io/strimzi/api/kafka/model/ExamplesTest.java
Patch:
@@ -165,13 +165,14 @@ private void validateTemplate(JsonNode rootNode) {
         }
         for (JsonNode object : rootNode.get("objects")) {
             String s = object.toString();
-            Pattern p = Pattern.compile("\\$\\{(.+?)\\}");
+            Pattern p = Pattern.compile("\\$\\{\\{(.+?)\\}?\\}");
             Matcher matcher = p.matcher(s);
             StringBuilder sb = new StringBuilder();
             int last = 0;
             while (matcher.find()) {
                 sb.append(s, last, matcher.start());
-                sb.append(params.get(matcher.group(1)));
+                String paramName = matcher.group(1);
+                sb.append(params.get(paramName));
                 last = matcher.end();
             }
             sb.append(s.substring(last));

File: api/src/test/java/io/strimzi/api/kafka/model/AbstractCrdIT.java
Patch:
@@ -30,7 +30,7 @@ private void createDelete(String ssStr) {
         RuntimeException thrown2 = null;
         try {
             try {
-                cluster.client().createContent(ssStr);
+                cluster.client().applyContent(ssStr);
             } catch (RuntimeException t) {
                 thrown = t;
             }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectClusterIT.java
Patch:
@@ -81,7 +81,7 @@ public void testDeployConnectClusterViaTemplate() {
         oc.newApp("strimzi-connect", map("CLUSTER_NAME", clusterName,
                 "KAFKA_CONNECT_BOOTSTRAP_SERVERS", KAFKA_CONNECT_BOOTSTRAP_SERVERS));
         String deploymentName = clusterName + "-connect";
-        oc.waitForDeployment(deploymentName);
+        oc.waitForDeployment(deploymentName, 1);
         testDockerImagesForKafkaConnect();
         oc.deleteByName("cm", clusterName);
         oc.waitForResourceDeletion("deployment", deploymentName);
@@ -128,7 +128,7 @@ public void testKafkaConnectScaleUpScaleDown() {
         replaceKafkaConnectResource(CONNECT_CLUSTER_NAME, c -> {
             c.getSpec().setReplicas(initialReplicas + 1);
         });
-        kubeClient.waitForDeployment(kafkaConnectName(CONNECT_CLUSTER_NAME));
+        kubeClient.waitForDeployment(kafkaConnectName(CONNECT_CLUSTER_NAME), 2);
         connectPods = kubeClient.listResourcesByLabel("pod", "strimzi.io/kind=KafkaConnect");
         assertEquals(scaleTo, connectPods.size());
         for (String pod : connectPods) {
@@ -174,7 +174,7 @@ public void testForUpdateValuesInConnectCM() {
             c.getSpec().getReadinessProbe().setTimeoutSeconds(6);
         });
 
-        kubeClient.waitForDeployment(kafkaConnectName(CONNECT_CLUSTER_NAME));
+        kubeClient.waitForDeployment(kafkaConnectName(CONNECT_CLUSTER_NAME), 1);
         for (int i = 0; i < connectPods.size(); i++) {
             kubeClient.waitForResourceDeletion("pod", connectPods.get(i));
         }

File: systemtest/src/test/java/io/strimzi/systemtest/RecoveryClusterIT.java
Patch:
@@ -42,7 +42,7 @@ public void testRecoveryFromTopicOperatorDeletion() {
         kubeClient.waitForResourceDeletion(DEPLOYMENT, topicOperatorDeploymentName);
 
         LOGGER.info("Waiting for recovery {}", topicOperatorDeploymentName);
-        kubeClient.waitForDeployment(topicOperatorDeploymentName);
+        kubeClient.waitForDeployment(topicOperatorDeploymentName, 1);
 
         //Test that CO doesn't have any exceptions in log
         assertNoCoErrorsLogged(stopwatch.runtime(SECONDS));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -145,11 +145,11 @@ public static String topicOperatorName(String cluster) {
     }
 
     protected static String defaultZookeeperConnect(String cluster) {
-        return ZookeeperCluster.zookeeperClusterName(cluster) + ":" + io.strimzi.api.kafka.model.TopicOperator.DEFAULT_ZOOKEEPER_PORT;
+        return ZookeeperCluster.serviceName(cluster) + ":" + io.strimzi.api.kafka.model.TopicOperator.DEFAULT_ZOOKEEPER_PORT;
     }
 
     protected static String defaultBootstrapServers(String cluster) {
-        return KafkaCluster.kafkaClusterName(cluster) + ":" + io.strimzi.api.kafka.model.TopicOperator.DEFAULT_BOOTSTRAP_SERVERS_PORT;
+        return KafkaCluster.serviceName(cluster) + ":" + io.strimzi.api.kafka.model.TopicOperator.DEFAULT_BOOTSTRAP_SERVERS_PORT;
     }
 
     protected static String defaultTopicConfigMapLabels(String cluster) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -86,7 +86,7 @@ protected void createOrUpdate(Reconciliation reconciliation, KafkaConnectAssembl
         log.debug("{}: Updating Kafka Connect cluster", reconciliation, name, namespace);
         Future<Void> chainFuture = Future.future();
         deploymentOperations.scaleDown(namespace, connect.getName(), connect.getReplicas())
-                .compose(scale -> serviceOperations.reconcile(namespace, connect.getName(), connect.generateService()))
+                .compose(scale -> serviceOperations.reconcile(namespace, connect.getServiceName(), connect.generateService()))
                 .compose(i -> configMapOperations.reconcile(namespace, connect.getAncillaryConfigName(), logAndMetricsConfigMap))
                 .compose(i -> deploymentOperations.reconcile(namespace, connect.getName(), connect.generateDeployment()))
                 .compose(i -> deploymentOperations.scaleUp(namespace, connect.getName(), connect.getReplicas()).map((Void) null))
@@ -100,7 +100,7 @@ protected void delete(Reconciliation reconciliation, Handler<AsyncResult<Void>>
         String assemblyName = reconciliation.assemblyName();
         String clusterName = KafkaConnectCluster.kafkaConnectClusterName(assemblyName);
 
-        CompositeFuture.join(serviceOperations.reconcile(namespace, clusterName, null),
+        CompositeFuture.join(serviceOperations.reconcile(namespace, KafkaConnectCluster.serviceName(assemblyName), null),
             configMapOperations.reconcile(namespace, KafkaConnectCluster.logAndMetricsConfigName(assemblyName), null),
             deploymentOperations.reconcile(namespace, clusterName, null))
             .map((Void) null).setHandler(handler);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -98,7 +98,7 @@ public void createOrUpdate(Reconciliation reconciliation, KafkaConnectS2IAssembl
                     null);
 
             deploymentConfigOperations.scaleDown(namespace, connect.getName(), connect.getReplicas())
-                    .compose(scale -> serviceOperations.reconcile(namespace, connect.getName(), connect.generateService()))
+                    .compose(scale -> serviceOperations.reconcile(namespace, connect.getServiceName(), connect.generateService()))
                     .compose(i -> configMapOperations.reconcile(namespace, connect.getAncillaryConfigName(), logAndMetricsConfigMap))
                     .compose(i -> deploymentConfigOperations.reconcile(namespace, connect.getName(), connect.generateDeploymentConfig()))
                     .compose(i -> imagesStreamOperations.reconcile(namespace, connect.getSourceImageStreamName(), connect.generateSourceImageStream()))
@@ -119,7 +119,7 @@ protected void delete(Reconciliation reconciliation, Handler<AsyncResult<Void>>
             String assemblyName = reconciliation.assemblyName();
             String clusterName = KafkaConnectS2ICluster.kafkaConnectClusterName(assemblyName);
 
-            CompositeFuture.join(serviceOperations.reconcile(namespace, clusterName, null),
+            CompositeFuture.join(serviceOperations.reconcile(namespace, KafkaConnectS2ICluster.serviceName(assemblyName), null),
                 configMapOperations.reconcile(namespace, KafkaConnectS2ICluster.logAndMetricsConfigName(assemblyName), null),
                 deploymentConfigOperations.reconcile(namespace, clusterName, null),
                 imagesStreamOperations.reconcile(namespace, KafkaConnectS2ICluster.getSourceImageStreamName(clusterName), null),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -96,7 +96,7 @@ public void testGenerateHeadlessService() {
     }
 
     private void checkHeadlessService(Service headless) {
-        assertEquals(KafkaCluster.headlessName(cluster), headless.getMetadata().getName());
+        assertEquals(KafkaCluster.headlessServiceName(cluster), headless.getMetadata().getName());
         assertEquals("ClusterIP", headless.getSpec().getType());
         assertEquals("None", headless.getSpec().getClusterIP());
         assertEquals(expectedLabels(), headless.getSpec().getSelector());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaConnectS2IClusterTest.java
Patch:
@@ -124,9 +124,8 @@ public void testGenerateService()   {
         Service svc = kc.generateService();
 
         assertEquals("ClusterIP", svc.getSpec().getType());
-        Map<String, String> expectedLabels = expectedLabels(kc.kafkaConnectClusterName(cluster));
-        assertEquals(expectedLabels, svc.getMetadata().getLabels());
-        assertEquals(expectedLabels, svc.getSpec().getSelector());
+        assertEquals(expectedLabels(kc.serviceName(cluster)), svc.getMetadata().getLabels());
+        assertEquals(expectedLabels(kc.kafkaConnectClusterName(cluster)), svc.getSpec().getSelector());
         assertEquals(2, svc.getSpec().getPorts().size());
         assertEquals(new Integer(KafkaConnectCluster.REST_API_PORT), svc.getSpec().getPorts().get(0).getPort());
         assertEquals(KafkaConnectCluster.REST_API_PORT_NAME, svc.getSpec().getPorts().get(0).getName());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -94,7 +94,7 @@ public void testGenerateHeadlessService() {
     }
 
     private void checkHeadlessService(Service headless) {
-        assertEquals(ZookeeperCluster.zookeeperHeadlessName(cluster), headless.getMetadata().getName());
+        assertEquals(ZookeeperCluster.headlessServiceName(cluster), headless.getMetadata().getName());
         assertEquals("ClusterIP", headless.getSpec().getType());
         assertEquals("None", headless.getSpec().getClusterIP());
         assertEquals(expectedLabels(), headless.getSpec().getSelector());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorMockTest.java
Patch:
@@ -94,7 +94,7 @@ private KafkaConnectAssemblyOperator createConnectCluster(TestContext context) {
             context.assertTrue(ar.succeeded());
             context.assertNotNull(mockClient.extensions().deployments().inNamespace(NAMESPACE).withName(KafkaConnectCluster.kafkaConnectClusterName(CLUSTER_NAME)).get());
             context.assertNotNull(mockClient.configMaps().inNamespace(NAMESPACE).withName(KafkaConnectCluster.logAndMetricsConfigName(CLUSTER_NAME)).get());
-            context.assertNotNull(mockClient.services().inNamespace(NAMESPACE).withName(KafkaConnectCluster.kafkaConnectClusterName(CLUSTER_NAME)).get());
+            context.assertNotNull(mockClient.services().inNamespace(NAMESPACE).withName(KafkaConnectCluster.serviceName(CLUSTER_NAME)).get());
             createAsync.complete();
         });
         createAsync.await();
@@ -124,7 +124,7 @@ public void testCreateUpdateDelete(TestContext context) {
             // TODO: Should verify that all resources were removed from MockKube
             context.assertNull(mockClient.extensions().deployments().inNamespace(NAMESPACE).withName(KafkaConnectCluster.kafkaConnectClusterName(CLUSTER_NAME)).get());
             context.assertNull(mockClient.configMaps().inNamespace(NAMESPACE).withName(KafkaConnectCluster.logAndMetricsConfigName(CLUSTER_NAME)).get());
-            context.assertNull(mockClient.services().inNamespace(NAMESPACE).withName(KafkaConnectCluster.kafkaConnectClusterName(CLUSTER_NAME)).get());
+            context.assertNull(mockClient.services().inNamespace(NAMESPACE).withName(KafkaConnectCluster.serviceName(CLUSTER_NAME)).get());
             deleteAsync.complete();
         });
     }
@@ -142,6 +142,6 @@ public void testReconcileAllDeleteCase(TestContext context) throws InterruptedEx
         // TODO: Should verify that all resources were removed from MockKube
         context.assertNull(mockClient.extensions().deployments().inNamespace(NAMESPACE).withName(KafkaConnectCluster.kafkaConnectClusterName(CLUSTER_NAME)).get());
         context.assertNull(mockClient.configMaps().inNamespace(NAMESPACE).withName(KafkaConnectCluster.logAndMetricsConfigName(CLUSTER_NAME)).get());
-        context.assertNull(mockClient.services().inNamespace(NAMESPACE).withName(KafkaConnectCluster.kafkaConnectClusterName(CLUSTER_NAME)).get());
+        context.assertNull(mockClient.services().inNamespace(NAMESPACE).withName(KafkaConnectCluster.serviceName(CLUSTER_NAME)).get());
     }
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -115,7 +115,7 @@ public void testCreateCluster(TestContext context) {
             List<Service> capturedServices = serviceCaptor.getAllValues();
             context.assertEquals(1, capturedServices.size());
             Service service = capturedServices.get(0);
-            context.assertEquals(connect.getName(), service.getMetadata().getName());
+            context.assertEquals(connect.getServiceName(), service.getMetadata().getName());
             context.assertEquals(connect.generateService(), service, "Services are not equal");
 
             // Verify Deployment
@@ -258,7 +258,7 @@ public void testUpdateCluster(TestContext context) {
             List<Service> capturedServices = serviceCaptor.getAllValues();
             context.assertEquals(1, capturedServices.size());
             Service service = capturedServices.get(0);
-            context.assertEquals(compareTo.getName(), service.getMetadata().getName());
+            context.assertEquals(compareTo.getServiceName(), service.getMetadata().getName());
             context.assertEquals(compareTo.generateService(), service, "Services are not equal");
 
             // Verify Deployment
@@ -468,7 +468,7 @@ public void testDeleteCluster(TestContext context) {
             // Vertify service
             context.assertEquals(1, serviceNameCaptor.getAllValues().size());
             context.assertEquals(clusterCmNamespace, serviceNamespaceCaptor.getValue());
-            context.assertEquals(connect.getName(), serviceNameCaptor.getValue());
+            context.assertEquals(connect.getServiceName(), serviceNameCaptor.getValue());
 
             // Vertify Deployment
             context.assertEquals(1, dcNameCaptor.getAllValues().size());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperatorTest.java
Patch:
@@ -121,7 +121,7 @@ public void testCreateCluster(TestContext context) {
             List<Service> capturedServices = serviceCaptor.getAllValues();
             context.assertEquals(1, capturedServices.size());
             Service service = capturedServices.get(0);
-            context.assertEquals(connect.getName(), service.getMetadata().getName());
+            context.assertEquals(connect.getServiceName(), service.getMetadata().getName());
             context.assertEquals(connect.generateService(), service, "Services are not equal");
 
             // Verify Deployment Config
@@ -332,7 +332,7 @@ public void testUpdateCluster(TestContext context) {
             List<Service> capturedServices = serviceCaptor.getAllValues();
             context.assertEquals(1, capturedServices.size());
             Service service = capturedServices.get(0);
-            context.assertEquals(compareTo.getName(), service.getMetadata().getName());
+            context.assertEquals(compareTo.getServiceName(), service.getMetadata().getName());
             context.assertEquals(compareTo.generateService(), service, "Services are not equal");
 
             // Verify Deployment Config
@@ -603,7 +603,7 @@ public void testDeleteCluster(TestContext context) {
             // Verify service
             context.assertEquals(1, serviceNameCaptor.getAllValues().size());
             context.assertEquals(clusterCmNamespace, serviceNamespaceCaptor.getValue());
-            context.assertEquals(connect.getName(), serviceNameCaptor.getValue());
+            context.assertEquals(connect.getServiceName(), serviceNameCaptor.getValue());
 
             // Vertify deployment Config
             context.assertEquals(1, dcNameCaptor.getAllValues().size());

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectClusterIT.java
Patch:
@@ -51,8 +51,8 @@ public class ConnectClusterIT extends AbstractClusterIT {
     public static final String NAMESPACE = "connect-cluster-test";
     public static final String KAFKA_CLUSTER_NAME = "connect-tests";
     public static final String CONNECT_CLUSTER_NAME = "my-cluster";
-    public static final String KAFKA_CONNECT_BOOTSTRAP_SERVERS = KAFKA_CLUSTER_NAME + "-kafka:9092";
-    public static final String KAFKA_CONNECT_BOOTSTRAP_SERVERS_ESCAPED = KAFKA_CLUSTER_NAME + "-kafka\\:9092";
+    public static final String KAFKA_CONNECT_BOOTSTRAP_SERVERS = KAFKA_CLUSTER_NAME + "-kafka-bootstrap:9092";
+    public static final String KAFKA_CONNECT_BOOTSTRAP_SERVERS_ESCAPED = KAFKA_CLUSTER_NAME + "-kafka-bootstrap\\:9092";
     public static final String CONNECT_CONFIG = "{\n" +
             "      \"bootstrap.servers\": \"" + KAFKA_CONNECT_BOOTSTRAP_SERVERS + "\"" +
             "    }";

File: systemtest/src/test/java/io/strimzi/systemtest/RecoveryClusterIT.java
Patch:
@@ -83,7 +83,7 @@ public void testRecoveryFromZookeeperStatefulSetDeletion() {
     @Test
     public void testRecoveryFromKafkaServiceDeletion() {
         // kafka cluster already deployed via annotation
-        String kafkaServiceName = kafkaClusterName(CLUSTER_NAME);
+        String kafkaServiceName = kafkaServiceName(CLUSTER_NAME);
         LOGGER.info("Running deleteKafkaService with cluster {}", CLUSTER_NAME);
 
         kubeClient.deleteByName(SERVICE, kafkaServiceName);
@@ -98,7 +98,7 @@ public void testRecoveryFromKafkaServiceDeletion() {
     @Test
     public void testRecoveryFromZookeeperServiceDeletion() {
         // kafka cluster already deployed via annotation
-        String zookeeperServiceName = zookeeperClusterName(CLUSTER_NAME);
+        String zookeeperServiceName = zookeeperServiceName(CLUSTER_NAME);
 
         LOGGER.info("Running deleteKafkaService with cluster {}", CLUSTER_NAME);
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -552,7 +552,7 @@ protected List<Container> getContainers() {
                 .withPorts(getContainerPortList())
                 .withLivenessProbe(createExecProbe(livenessPath, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createExecProbe(readinessPath, readinessInitialDelay, readinessTimeout))
-                .withResources(resources())
+                .withResources(resources(getResources()))
                 .build());
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -217,7 +217,7 @@ protected List<Container> getContainers() {
                 .withLivenessProbe(createHttpProbe(livenessPath, REST_API_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath, REST_API_PORT_NAME, readinessInitialDelay, readinessTimeout))
                 .withVolumeMounts(getVolumeMounts())
-                .withResources(resources())
+                .withResources(resources(getResources()))
                 .build();
 
         containers.add(container);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -74,7 +74,7 @@ public DeploymentConfig generateDeploymentConfig() {
                 .withLivenessProbe(createHttpProbe(livenessPath, REST_API_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath, REST_API_PORT_NAME, readinessInitialDelay, readinessTimeout))
                 .withVolumeMounts(getVolumeMounts())
-                .withResources(resources())
+                .withResources(resources(getResources()))
                 .build();
 
         DeploymentTriggerPolicy configChangeTrigger = new DeploymentTriggerPolicyBuilder()

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -213,7 +213,7 @@ protected List<Container> getContainers() {
                 .withPorts(Collections.singletonList(createContainerPort(HEALTHCHECK_PORT_NAME, HEALTHCHECK_PORT, "TCP")))
                 .withLivenessProbe(createHttpProbe(livenessPath + "healthy", HEALTHCHECK_PORT_NAME, livenessInitialDelay, livenessTimeout))
                 .withReadinessProbe(createHttpProbe(readinessPath + "ready", HEALTHCHECK_PORT_NAME, readinessInitialDelay, readinessTimeout))
-                .withResources(resources())
+                .withResources(resources(getResources()))
                 .build();
 
         containers.add(container);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/AbstractModelTest.java
Patch:
@@ -158,6 +158,6 @@ protected List<Container> getContainers() {
             }
         };
         abstractModel.setResources(opts);
-        Assert.assertEquals("1", abstractModel.resources().getLimits().get("cpu").getAmount());
+        Assert.assertEquals("1", abstractModel.resources(opts).getLimits().get("cpu").getAmount());
     }
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.api.kafka.model.InlineLogging;
 import io.strimzi.api.kafka.model.KafkaAssembly;
 import io.strimzi.api.kafka.model.KafkaAssemblyBuilder;
+import io.strimzi.api.kafka.model.Zookeeper;
 import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.ResourceUtils;
 import io.strimzi.operator.cluster.operator.assembly.MockCertManager;
@@ -135,6 +136,7 @@ private void checkStatefulSet(StatefulSet ss) {
         assertEquals(ZookeeperCluster.CLIENT_PORT_NAME, containers.get(0).getPorts().get(0).getName());
         assertEquals(new Integer(ZookeeperCluster.CLIENT_PORT), containers.get(0).getPorts().get(0).getContainerPort());
         // checks on the TLS sidecar container
+        assertEquals(Zookeeper.DEFAULT_TLS_SIDECAR_IMAGE, containers.get(1).getImage());
         assertEquals(new Integer(replicas), Integer.valueOf(AbstractModel.containerEnvVars(containers.get(1)).get(ZookeeperCluster.ENV_VAR_ZOOKEEPER_NODE_COUNT)));
         assertEquals(ZookeeperCluster.CLUSTERING_PORT_NAME, containers.get(1).getPorts().get(0).getName());
         assertEquals(new Integer(ZookeeperCluster.CLUSTERING_PORT), containers.get(1).getPorts().get(0).getContainerPort());

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaClusterIT.java
Patch:
@@ -409,9 +409,6 @@ private void testDockerImagesForKafkaCluster(String clusterName, int kafkaPods,
     public void testRackAware() {
         testDockerImagesForKafkaCluster(CLUSTER_NAME, 1, 1, true);
 
-        String cm = kubeClient.get("cm", CLUSTER_NAME);
-        assertThat(cm, valueOfCmEquals("kafka-rack", "{\"topologyKey\": \"rack-key\"}"));
-
         kubeClient.waitForStatefulSet(kafkaClusterName(CLUSTER_NAME), 1);
         String kafkaPodName = kafkaPodName(CLUSTER_NAME, 0);
         kubeClient.waitForPod(kafkaPodName);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -355,8 +355,6 @@ private List<ServicePort> getServicePortList() {
     private List<ContainerPort> getContainerPortList() {
         List<ContainerPort> portList = new ArrayList<>();
         portList.add(createContainerPort(CLIENT_PORT_NAME, CLIENT_PORT, "TCP"));
-        portList.add(createContainerPort(CLUSTERING_PORT_NAME, CLUSTERING_PORT * 10, "TCP"));
-        portList.add(createContainerPort(LEADER_ELECTION_PORT_NAME, LEADER_ELECTION_PORT * 10, "TCP"));
         if (isMetricsEnabled) {
             portList.add(createContainerPort(metricsPortName, metricsPort, "TCP"));
         }

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectClusterIT.java
Patch:
@@ -199,8 +199,9 @@ private void testDockerImagesForKafkaConnect() {
         Map<String, String> imgFromDeplConf = getImagesFromConfig(kubeClient.getResourceAsJson(
                 "deployment", "strimzi-cluster-operator"));
         //Verifying docker image for kafka connect
-        String connectImageName = getImageNameFromPod(kubeClient.listResourcesByLabel("pod",
+        String connectImageName = getContainerImageNameFromPod(kubeClient.listResourcesByLabel("pod",
                 "type=kafka-connect").get(0));
+
         assertEquals(imgFromDeplConf.get(CONNECT_IMAGE), connectImageName);
         LOGGER.info("Docker images verified");
     }

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaClusterIT.java
Patch:
@@ -325,7 +325,7 @@ public void testJvmAndResources() {
                 "-Xmx1g", "-Xms1G", "-server", "-XX:+UseG1GC");
 
         assertResources(NAMESPACE, "jvm-resource-cluster-zookeeper-0",
-                "1G", "300m", "1G", "300m");
+                "1Gi", "300m", "1Gi", "300m");
         assertExpectedJavaOpts("jvm-resource-cluster-zookeeper-0",
                 "-Xmx600m", "-Xms300m", "-server", "-XX:+UseG1GC");
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -157,7 +157,7 @@ public abstract class AbstractModel {
     protected AbstractModel(String namespace, String cluster, Labels labels) {
         this.cluster = cluster;
         this.namespace = namespace;
-        this.labels = labels.withoutKind().withCluster(cluster);
+        this.labels = labels.withCluster(cluster);
     }
 
     public Labels getLabels() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -173,11 +173,10 @@ public static String clientsPublicKeyName(String cluster) {
     public static KafkaCluster fromCrd(CertManager certManager, KafkaAssembly kafkaAssembly, List<Secret> secrets) {
         KafkaCluster result = new KafkaCluster(kafkaAssembly.getMetadata().getNamespace(),
                 kafkaAssembly.getMetadata().getName(),
-                Labels.fromResource(kafkaAssembly));
+                Labels.fromResource(kafkaAssembly).withKind(kafkaAssembly.getKind()));
         Kafka kafka = kafkaAssembly.getSpec().getKafka();
         result.setReplicas(kafka.getReplicas());
         String image = kafka.getImage();
-        log.debug("#### got kafka image from KafkaAssembly" + image);
         if (image == null) {
             image = Kafka.DEFAULT_IMAGE;
         }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -95,7 +95,7 @@ public static KafkaConnectCluster fromCrd(KafkaConnectAssembly crd) {
         return fromSpec(crd.getSpec(),
                 new KafkaConnectCluster(crd.getMetadata().getNamespace(),
                     crd.getMetadata().getName(),
-                    Labels.fromResource(crd)));
+                    Labels.fromResource(crd).withKind(crd.getKind())));
     }
 
     /**

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -55,7 +55,7 @@ public static KafkaConnectS2ICluster fromCrd(KafkaConnectS2IAssembly crd) {
         KafkaConnectS2IAssemblySpec spec = crd.getSpec();
         KafkaConnectS2ICluster cluster = fromSpec(spec, new KafkaConnectS2ICluster(crd.getMetadata().getNamespace(),
                 crd.getMetadata().getName(),
-                Labels.fromResource(crd)));
+                Labels.fromResource(crd).withKind(crd.getKind())));
         cluster.setInsecureSourceRepository(spec != null ? spec.isInsecureSourceRepository() : false);
         return cluster;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -171,7 +171,7 @@ public static TopicOperator fromCrd(KafkaAssembly resource) {
             result = new TopicOperator(
                     namespace,
                     resource.getMetadata().getName(),
-                    Labels.fromResource(resource));
+                    Labels.fromResource(resource).withKind(resource.getKind()));
             io.strimzi.api.kafka.model.TopicOperator tcConfig = resource.getSpec().getTopicOperator();
             result.setImage(tcConfig.getImage());
             result.setWatchedNamespace(tcConfig.getWatchedNamespace() != null ? tcConfig.getWatchedNamespace() : namespace);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -132,7 +132,7 @@ private ZookeeperCluster(String namespace, String cluster, Labels labels) {
 
     public static ZookeeperCluster fromCrd(CertManager certManager, KafkaAssembly kafkaAssembly, List<Secret> secrets) {
         ZookeeperCluster zk = new ZookeeperCluster(kafkaAssembly.getMetadata().getNamespace(), kafkaAssembly.getMetadata().getName(),
-                Labels.fromResource(kafkaAssembly));
+                Labels.fromResource(kafkaAssembly).withKind(kafkaAssembly.getKind()));
         Zookeeper zookeeper = kafkaAssembly.getSpec().getZookeeper();
         int replicas = zookeeper.getReplicas();
         if (replicas <= 0) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -107,9 +107,8 @@ protected void delete(Reconciliation reconciliation, Handler<AsyncResult<Void>>
     }
 
     @Override
-    protected List<HasMetadata> getResources(String namespace) {
+    protected List<HasMetadata> getResources(String namespace, Labels selector) {
         List<HasMetadata> result = new ArrayList<>();
-        Labels selector = Labels.forType(AssemblyType.CONNECT);
         result.addAll(serviceOperations.list(namespace, selector));
         result.addAll(deploymentOperations.list(namespace, selector));
         result.addAll(resourceOperator.list(namespace, selector));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -132,9 +132,8 @@ protected void delete(Reconciliation reconciliation, Handler<AsyncResult<Void>>
     }
 
     @Override
-    protected List<HasMetadata> getResources(String namespace) {
+    protected List<HasMetadata> getResources(String namespace, Labels selector) {
         List<HasMetadata> result = new ArrayList<>();
-        Labels selector = Labels.forType(AssemblyType.CONNECT_S2I);
         result.addAll(serviceOperations.list(namespace, selector));
         result.addAll(deploymentConfigOperations.list(namespace, selector));
         result.addAll(imagesStreamOperations.list(namespace, selector));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -180,7 +180,7 @@ public void before() {
                 .withMetadata(new ObjectMetaBuilder()
                         .withName(CLUSTER_NAME)
                         .withNamespace(NAMESPACE)
-                        .withLabels(Labels.forKind("cluster").withType(AssemblyType.KAFKA).toMap())
+                        .withLabels(Labels.userLabels(TestUtils.map("foo", "bar")).toMap())
                         .build())
                 .withNewSpec()
                     .withNewKafka()
@@ -827,8 +827,9 @@ public void testReconcileAllDeleteCase(TestContext context) throws InterruptedEx
         kafkaAssembly(NAMESPACE, CLUSTER_NAME).delete();
 
         LOGGER.info("reconcileAll after KafkaAssembly deletion -> All resources should be deleted");
-        kco.reconcileAll("test-trigger", NAMESPACE, Labels.forKind("cluster")).await();
+        kco.reconcileAll("test-trigger", NAMESPACE).await();
 
+        // TODO: Should verify that all resources were removed from MockKube
         // Assert no CMs, Services, StatefulSets, Deployments, Secrets are left
         context.assertTrue(mockClient.configMaps().inNamespace(NAMESPACE).list().getItems().isEmpty());
         context.assertTrue(mockClient.services().inNamespace(NAMESPACE).list().getItems().isEmpty());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -847,7 +847,7 @@ public void testReconcile(TestContext context) throws InterruptedException {
                 baz.getSpec().getZookeeper().getReplicas());
 
         // providing the list of ALL StatefulSets for all the Kafka clusters
-        Labels newLabels = Labels.forType(AssemblyType.KAFKA);
+        Labels newLabels = Labels.forKind(KafkaAssembly.RESOURCE_KIND);
         when(mockKsOps.list(eq(clusterCmNamespace), eq(newLabels))).thenReturn(
                 asList(KafkaCluster.fromCrd(certManager, bar, barSecrets).generateStatefulSet(openShift),
                         KafkaCluster.fromCrd(certManager, baz, bazSecrets).generateStatefulSet(openShift))
@@ -901,7 +901,7 @@ public void delete(Reconciliation reconciliation, Handler h) {
         };
 
         // Now try to reconcile all the Kafka clusters
-        ops.reconcileAll("test", clusterCmNamespace, Labels.EMPTY).await();
+        ops.reconcileAll("test", clusterCmNamespace).await();
 
         async.await();
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -499,7 +499,7 @@ public void testReconcile(TestContext context) {
         when(mockConnectOps.get(eq(clusterCmNamespace), eq("bar"))).thenReturn(bar);
 
         // providing the list of ALL Deployments for all the Kafka Connect clusters
-        Labels newLabels = Labels.forType(AssemblyType.CONNECT);
+        Labels newLabels = Labels.forKind(KafkaConnectAssembly.RESOURCE_KIND);
         when(mockDcOps.list(eq(clusterCmNamespace), eq(newLabels))).thenReturn(
                 asList(KafkaConnectCluster.fromCrd(bar).generateDeployment(),
                         KafkaConnectCluster.fromCrd(baz).generateDeployment()));
@@ -541,7 +541,7 @@ public void delete(Reconciliation reconciliation, Handler h) {
         };
 
         // Now try to reconcile all the Kafka Connect clusters
-        ops.reconcileAll("test", clusterCmNamespace, Labels.EMPTY);
+        ops.reconcileAll("test", clusterCmNamespace);
 
         async.await();
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperatorTest.java
Patch:
@@ -651,7 +651,7 @@ public void testReconcile(TestContext context) {
         when(mockConnectOps.get(eq(clusterCmNamespace), eq("bar"))).thenReturn(bar);
 
         // providing the list of ALL DeploymentConfigs for all the Kafka Connect S2I clusters
-        Labels newLabels = Labels.forType(AssemblyType.CONNECT_S2I);
+        Labels newLabels = Labels.forKind(KafkaConnectS2IAssembly.RESOURCE_KIND);
         when(mockDcOps.list(eq(clusterCmNamespace), eq(newLabels))).thenReturn(
                 asList(KafkaConnectS2ICluster.fromCrd(bar).generateDeploymentConfig(),
                         KafkaConnectS2ICluster.fromCrd(baz).generateDeploymentConfig()));
@@ -693,7 +693,7 @@ public void delete(Reconciliation reconciliation, Handler h) {
         };
 
         // Now try to reconcile all the Kafka Connect S2I clusters
-        ops.reconcileAll("test", clusterCmNamespace, Labels.EMPTY);
+        ops.reconcileAll("test", clusterCmNamespace);
 
         async.await();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -37,6 +37,7 @@ public class KafkaConnectS2ICluster extends KafkaConnectCluster {
     protected boolean insecureSourceRepository = false;
 
     // Configuration defaults
+    protected static final String DEFAULT_IMAGE = System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE", "strimzi/kafka-connect-s2i:latest");
 
     // Configuration keys (in ConfigMap)
     public static final String KEY_INSECURE_SOURCE_REPO = "insecure-source-repo";
@@ -254,7 +255,6 @@ protected void setImage(String image) {
         this.sourceImageBaseName = image.substring(0, image.lastIndexOf(":"));
         this.sourceImageTag = image.substring(image.lastIndexOf(":") + 1);
         this.image = name + ":" + tag;
-
     }
 
     /**

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -462,7 +462,7 @@ private KafkaAssembly getKafkaAssembly(String clusterName) {
         int healthDelay = 120;
         int healthTimeout = 30;
         String metricsCmJson = metrics ? METRICS_CONFIG : null;
-        return ResourceUtils.createKafkaCluster(clusterNamespace, clusterName, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaConfig, zooConfig, storage, tcConfig, null, LOG_ZOOKEEPER_CONFIG, LOG_KAFKA_CONFIG);
+        return ResourceUtils.createKafkaCluster(clusterNamespace, clusterName, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaConfig, zooConfig, storage, tcConfig, null, LOG_KAFKA_CONFIG, LOG_ZOOKEEPER_CONFIG);
     }
 
     private List<Secret> getInitialSecrets() {
@@ -593,7 +593,7 @@ public void testUpdateZkClusterMetricsConfig(TestContext context) {
     public void testUpdateZkClusterLogConfig(TestContext context) {
         KafkaAssembly kafkaAssembly = getKafkaAssembly("bar");
         InlineLogging logger = new InlineLogging();
-        logger.setLoggers(singletonMap("kafka.root.logger.level", "DEBUG"));
+        logger.setLoggers(singletonMap("zookeeper.root.logger", "DEBUG"));
         kafkaAssembly.getSpec().getZookeeper().setLogging(logger);
         List<Secret> secrets = getClusterSecrets("bar",
                 kafkaAssembly.getSpec().getKafka().getReplicas(),

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -462,7 +462,7 @@ private KafkaAssembly getKafkaAssembly(String clusterName) {
         int healthDelay = 120;
         int healthTimeout = 30;
         String metricsCmJson = metrics ? METRICS_CONFIG : null;
-        return ResourceUtils.createKafkaCluster(clusterNamespace, clusterName, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaConfig, zooConfig, storage, tcConfig, null, LOG_ZOOKEEPER_CONFIG, LOG_KAFKA_CONFIG);
+        return ResourceUtils.createKafkaCluster(clusterNamespace, clusterName, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaConfig, zooConfig, storage, tcConfig, null, LOG_KAFKA_CONFIG, LOG_ZOOKEEPER_CONFIG);
     }
 
     private List<Secret> getInitialSecrets() {
@@ -593,7 +593,7 @@ public void testUpdateZkClusterMetricsConfig(TestContext context) {
     public void testUpdateZkClusterLogConfig(TestContext context) {
         KafkaAssembly kafkaAssembly = getKafkaAssembly("bar");
         InlineLogging logger = new InlineLogging();
-        logger.setLoggers(singletonMap("kafka.root.logger.level", "DEBUG"));
+        logger.setLoggers(singletonMap("zookeeper.root.logger", "DEBUG"));
         kafkaAssembly.getSpec().getZookeeper().setLogging(logger);
         List<Secret> secrets = getClusterSecrets("bar",
                 kafkaAssembly.getSpec().getKafka().getReplicas(),

File: api/src/main/java/io/strimzi/api/kafka/model/MemoryDeserializer.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster.model;
+package io.strimzi.api.kafka.model;
 
 import com.fasterxml.jackson.core.JsonParser;
 import com.fasterxml.jackson.core.JsonProcessingException;
@@ -127,7 +127,7 @@ private static long factor(String suffix) {
         return factor;
     }
 
-    static String format(long bytes) {
+    public static String format(long bytes) {
         if (bytes == 0) {
             return "0";
         }

File: api/src/main/java/io/strimzi/api/kafka/model/MilliCpuDeserializer.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster.model;
+package io.strimzi.api.kafka.model;
 
 import com.fasterxml.jackson.core.JsonParser;
 import com.fasterxml.jackson.core.JsonProcessingException;

File: api/src/test/java/io/strimzi/api/kafka/model/MemoryDeserializerTest.java
Patch:
@@ -2,12 +2,12 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster.model;
+package io.strimzi.api.kafka.model;
 
 import org.junit.Test;
 
-import static io.strimzi.operator.cluster.model.MemoryDeserializer.format;
-import static io.strimzi.operator.cluster.model.MemoryDeserializer.parse;
+import static io.strimzi.api.kafka.model.MemoryDeserializer.format;
+import static io.strimzi.api.kafka.model.MemoryDeserializer.parse;
 import static org.junit.Assert.assertEquals;
 
 public class MemoryDeserializerTest {

File: api/src/test/java/io/strimzi/api/kafka/model/MilliCpuDeserializerTest.java
Patch:
@@ -2,12 +2,12 @@
  * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.operator.cluster.model;
+package io.strimzi.api.kafka.model;
 
 import org.junit.Test;
 
-import static io.strimzi.operator.cluster.model.MilliCpuDeserializer.format;
-import static io.strimzi.operator.cluster.model.MilliCpuDeserializer.parse;
+import static io.strimzi.api.kafka.model.MilliCpuDeserializer.format;
+import static io.strimzi.api.kafka.model.MilliCpuDeserializer.parse;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.fail;
 

File: api/src/test/java/io/strimzi/test/k8s/KubeClient.java
Patch:
@@ -131,6 +131,8 @@ default K delete(String... files) {
 
     List<String> list(String resourceType);
 
+    String getResourceAsYaml(String resourceType, String resourceName);
+
     String describe(String resourceType, String resourceName);
 
     String logs(String pod);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/AbtractReadyResourceOperatorTest.java
Patch:
@@ -4,6 +4,7 @@
  */
 package io.strimzi.operator.cluster.operator.resource;
 
+import io.fabric8.kubernetes.api.model.Doneable;
 import io.fabric8.kubernetes.api.model.HasMetadata;
 import io.fabric8.kubernetes.api.model.KubernetesResourceList;
 import io.fabric8.kubernetes.client.KubernetesClient;
@@ -31,7 +32,7 @@
 import static org.mockito.Mockito.when;
 
 public abstract class AbtractReadyResourceOperatorTest<C extends KubernetesClient, T extends HasMetadata,
-        L extends KubernetesResourceList, D, R extends Resource<T, D>> extends AbstractResourceOperatorTest<C, T, L, D, R> {
+        L extends KubernetesResourceList, D extends Doneable<T>, R extends Resource<T, D>> extends AbstractResourceOperatorTest<C, T, L, D, R> {
 
     @Override
     protected abstract AbstractReadyResourceOperator<C, T, L, D, R> createResourceOperations(Vertx vertx, C mockClient);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -199,7 +199,7 @@ public final void reconcileAssembly(Reconciliation reconciliation, Handler<Async
                                         if (createResult.cause() instanceof InvalidConfigMapException) {
                                             log.error(createResult.cause().getMessage());
                                         } else {
-                                            log.error(createResult.cause().toString());
+                                            log.error("{}: createOrUpdate failed", reconciliation, createResult.cause());
                                         }
                                     } else {
                                         handler.handle(createResult);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -70,7 +70,7 @@ public Future<Void> maybeRollingUpdate(StatefulSet ss) {
         String namespace = ss.getMetadata().getNamespace();
         String name = ss.getMetadata().getName();
         final int replicas = ss.getSpec().getReplicas();
-        log.info("Starting rolling update of {}/{}", namespace, name);
+        log.debug("Considering rolling update of {}/{}", namespace, name);
         Future<Void> f = Future.succeededFuture();
         // Then for each replica, maybe restart it
         for (int i = 0; i < replicas; i++) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -138,7 +138,7 @@ private KafkaCluster(String namespace, String cluster, Labels labels) {
         this.mountPath = "/var/lib/kafka";
 
         this.logAndMetricsConfigVolumeName = "kafka-metrics-and-logging";
-        this.logAndMetricsConfigMountPath = "/opt/kafka/config/";
+        this.logAndMetricsConfigMountPath = "/opt/kafka/custom-config/";
 
         this.initImage = DEFAULT_INIT_IMAGE;
         this.validLoggerFields = getDefaultLogConfig();

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -83,7 +83,7 @@ protected KafkaConnectCluster(String namespace, String cluster, Labels labels) {
 
         this.mountPath = "/var/lib/kafka";
         this.logAndMetricsConfigVolumeName = "kafka-metrics-and-logging";
-        this.logAndMetricsConfigMountPath = "/opt/kafka/config/";
+        this.logAndMetricsConfigMountPath = "/opt/kafka/custom-config/";
     }
 
     public static String kafkaConnectClusterName(String cluster) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -117,7 +117,7 @@ private ZookeeperCluster(String namespace, String cluster, Labels labels) {
         this.mountPath = "/var/lib/zookeeper";
 
         this.logAndMetricsConfigVolumeName = "zookeeper-metrics-and-logging";
-        this.logAndMetricsConfigMountPath = "/opt/kafka/config/";
+        this.logAndMetricsConfigMountPath = "/opt/kafka/custom-config/";
         this.validLoggerFields = getDefaultLogConfig();
     }
 

File: certificate-manager/src/main/java/io/strimzi/certs/OpenSslCertManager.java
Patch:
@@ -30,6 +30,8 @@ public class OpenSslCertManager implements CertManager {
 
     private static final Logger log = LogManager.getLogger(OpenSslCertManager.class);
 
+    public OpenSslCertManager() {}
+
     @Override
     public void generateSelfSignedCert(File keyFile, File certFile, int days) throws IOException {
         generateSelfSignedCert(keyFile, certFile, null, days);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -9,7 +9,6 @@
 import io.fabric8.kubernetes.api.model.ObjectMeta;
 import io.fabric8.kubernetes.api.model.Secret;
 import io.strimzi.certs.CertManager;
-import io.strimzi.certs.OpenSslCertManager;
 import io.strimzi.certs.SecretCertProvider;
 import io.strimzi.operator.cluster.InvalidConfigMapException;
 import io.strimzi.operator.cluster.Reconciliation;
@@ -55,6 +54,7 @@ public abstract class AbstractAssemblyOperator {
     protected final AssemblyType assemblyType;
     protected final ConfigMapOperator configMapOperations;
     protected final SecretOperator secretOperations;
+    protected final CertManager certManager;
 
     /**
      * @param vertx The Vertx instance
@@ -64,10 +64,12 @@ public abstract class AbstractAssemblyOperator {
      * @param secretOperations For operating on Secrets
      */
     protected AbstractAssemblyOperator(Vertx vertx, boolean isOpenShift, AssemblyType assemblyType,
+                                       CertManager certManager,
                                        ConfigMapOperator configMapOperations, SecretOperator secretOperations) {
         this.vertx = vertx;
         this.isOpenShift = isOpenShift;
         this.assemblyType = assemblyType;
+        this.certManager = certManager;
         this.configMapOperations = configMapOperations;
         this.secretOperations = secretOperations;
     }
@@ -124,7 +126,6 @@ private final void reconcileCertificate(String namespace, Handler<AsyncResult<Vo
                     File internalCAkeyFile = null;
                     File internalCAcertFile = null;
                     try {
-                        CertManager certManager = new OpenSslCertManager();
                         internalCAkeyFile = File.createTempFile("tls", "internal-ca-key");
                         internalCAcertFile = File.createTempFile("tls", "internal-ca-cert");
                         certManager.generateSelfSignedCert(internalCAkeyFile, internalCAcertFile, CERTS_EXPIRATION_DAYS);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperator.java
Patch:
@@ -7,6 +7,7 @@
 import io.fabric8.kubernetes.api.model.ConfigMap;
 import io.fabric8.kubernetes.api.model.HasMetadata;
 import io.fabric8.kubernetes.api.model.Secret;
+import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.Reconciliation;
 import io.strimzi.operator.cluster.model.AssemblyType;
 import io.strimzi.operator.cluster.model.ExternalLogging;
@@ -49,11 +50,12 @@ public class KafkaConnectAssemblyOperator extends AbstractAssemblyOperator {
      * @param secretOperations For operating on Secrets
      */
     public KafkaConnectAssemblyOperator(Vertx vertx, boolean isOpenShift,
+                                        CertManager certManager,
                                         ConfigMapOperator configMapOperations,
                                         DeploymentOperator deploymentOperations,
                                         ServiceOperator serviceOperations,
                                         SecretOperator secretOperations) {
-        super(vertx, isOpenShift, AssemblyType.CONNECT, configMapOperations, secretOperations);
+        super(vertx, isOpenShift, AssemblyType.CONNECT, certManager, configMapOperations, secretOperations);
         this.serviceOperations = serviceOperations;
         this.deploymentOperations = deploymentOperations;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperator.java
Patch:
@@ -7,6 +7,7 @@
 import io.fabric8.kubernetes.api.model.ConfigMap;
 import io.fabric8.kubernetes.api.model.HasMetadata;
 import io.fabric8.kubernetes.api.model.Secret;
+import io.strimzi.certs.CertManager;
 import io.strimzi.operator.cluster.Reconciliation;
 import io.strimzi.operator.cluster.model.AssemblyType;
 import io.strimzi.operator.cluster.model.ExternalLogging;
@@ -57,13 +58,14 @@ public class KafkaConnectS2IAssemblyOperator extends AbstractAssemblyOperator {
      * @param secretOperations           For operating on Secrets
      */
     public KafkaConnectS2IAssemblyOperator(Vertx vertx, boolean isOpenShift,
+                                           CertManager certManager,
                                            ConfigMapOperator configMapOperations,
                                            DeploymentConfigOperator deploymentConfigOperations,
                                            ServiceOperator serviceOperations,
                                            ImageStreamOperator imagesStreamOperations,
                                            BuildConfigOperator buildConfigOperations,
                                            SecretOperator secretOperations) {
-        super(vertx, isOpenShift, AssemblyType.CONNECT_S2I, configMapOperations, secretOperations);
+        super(vertx, isOpenShift, AssemblyType.CONNECT_S2I, certManager, configMapOperations, secretOperations);
         this.serviceOperations = serviceOperations;
         this.deploymentConfigOperations = deploymentConfigOperations;
         this.imagesStreamOperations = imagesStreamOperations;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorMockTest.java
Patch:
@@ -207,6 +207,7 @@ private KafkaAssemblyOperator createCluster(TestContext context) {
         PvcOperator pvcops = new PvcOperator(vertx, mockClient);
         SecretOperator secretops = new SecretOperator(vertx, mockClient);
         KafkaAssemblyOperator kco = new KafkaAssemblyOperator(vertx, true, 2_000,
+                new MockCertManager(),
                 cmops, svcops, zksops, ksops, pvcops, depops, secretops);
 
         LOGGER.info("Reconciling initially -> create");

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/PartialRollingUpdateTest.java
Patch:
@@ -103,6 +103,7 @@ public void before(TestContext context) {
         pvcops = new PvcOperator(vertx, bootstrapClient);
         secretops = new SecretOperator(vertx, bootstrapClient);
         KafkaAssemblyOperator kco = new KafkaAssemblyOperator(vertx, true, 2_000,
+                new MockCertManager(),
                 cmops, svcops, zksops, ksops, pvcops, depops, secretops);
 
         LOGGER.info("bootstrap reconciliation");
@@ -142,6 +143,7 @@ private void startKube() {
         secretops = new SecretOperator(vertx, mockClient);
 
         this.kco = new KafkaAssemblyOperator(vertx, true, 2_000,
+                new MockCertManager(),
                 cmops, svcops, zksops, ksops, pvcops, depops, secretops);
         LOGGER.info("Started test KafkaAssemblyOperator");
     }

File: common-test/src/main/java/io/strimzi/test/k8s/BaseKubeClient.java
Patch:
@@ -357,9 +357,9 @@ public String logs(String pod) {
     }
 
     @Override
-    public String searchInLog(String resourceType, String resourceName, String sinceSeconds, String... grepPattern) {
+    public String searchInLog(String resourceType, String resourceName, long sinceSeconds, String... grepPattern) {
         try {
-            return Exec.exec("bash", "-c", join(" ", namespacedCommand("logs", resourceType + "/" + resourceName, "--since=" + sinceSeconds + "s",
+            return Exec.exec("bash", "-c", join(" ", namespacedCommand("logs", resourceType + "/" + resourceName, "--since=" + String.valueOf(sinceSeconds) + "s",
                     "|", "grep", " -e " + join(" -e ", grepPattern)))).out();
         } catch (KubeClusterException e) {
             if (e.result != null && e.result.exitStatus() == 1) {

File: common-test/src/main/java/io/strimzi/test/k8s/KubeClient.java
Patch:
@@ -142,7 +142,7 @@ default K delete(String... files) {
      * @param grepPattern Grep patterns for search
      * @return Grep result as string
      */
-    String searchInLog(String resourceType, String resourceName, String sinceSeconds, String... grepPattern);
+    String searchInLog(String resourceType, String resourceName, long sinceSeconds, String... grepPattern);
 
     String getResourceAsJson(String resourceType, String resourceName);
 

File: certificate-manager/src/main/java/io/strimzi/certs/OpenSslCertManager.java
Patch:
@@ -184,7 +184,7 @@ private void exec(List<String> cmd) throws IOException {
             ProcessBuilder processBuilder = new ProcessBuilder(cmd)
                     .redirectOutput(out)
                     .redirectErrorStream(true);
-            log.info("Running command {}", processBuilder.command());
+            log.debug("Running command {}", processBuilder.command());
 
             Process proc = processBuilder.start();
 
@@ -196,7 +196,7 @@ private void exec(List<String> cmd) throws IOException {
             String stdout = new String(Files.readAllBytes(out.toPath()), Charset.defaultCharset());
 
             log.debug(stdout);
-            log.info("result {}", result);
+            log.debug("result {}", result);
 
         } catch (InterruptedException ignored) {
         } finally {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ResourceTester.java
Patch:
@@ -10,6 +10,7 @@
 import com.fasterxml.jackson.dataformat.yaml.YAMLMapper;
 import io.fabric8.kubernetes.api.model.ConfigMap;
 import io.fabric8.kubernetes.api.model.Secret;
+import io.strimzi.operator.cluster.ResourceUtils;
 import org.junit.rules.MethodRule;
 import org.junit.runners.model.FrameworkMethod;
 import org.junit.runners.model.Statement;
@@ -19,7 +20,6 @@
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.net.URL;
-import java.util.Collections;
 import java.util.List;
 import java.util.function.BiFunction;
 import java.util.function.Function;
@@ -41,7 +41,7 @@ class ResourceTester<M extends AbstractModel> implements MethodRule {
 
     ResourceTester(BiFunction<ConfigMap, List<Secret>, M> fromConfigMap) {
         this.fromConfigMap = cm -> {
-            return fromConfigMap.apply(cm, Collections.emptyList());
+            return fromConfigMap.apply(cm, ResourceUtils.createKafkaClusterInitialSecrets(cm.getMetadata().getNamespace()));
         };
     }
 

File: certificate-manager/src/main/java/io/strimzi/certs/CertAndKey.java
Patch:
@@ -4,12 +4,12 @@
  */
 package io.strimzi.certs;
 
-public class Cert {
+public class CertAndKey {
 
     private final byte[] key;
     private final byte[] cert;
 
-    public Cert(byte[] key, byte[] cert) {
+    public CertAndKey(byte[] key, byte[] cert) {
         this.key = key;
         this.cert = cert;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -26,7 +26,6 @@
 import org.apache.logging.log4j.Logger;
 
 import java.io.File;
-import java.io.IOException;
 import java.util.Collections;
 import java.util.List;
 import java.util.Set;
@@ -138,7 +137,7 @@ private final void reconcileCertificate(String namespace, Handler<AsyncResult<Vo
                         secretOperations.reconcile(namespace, INTERNAL_CA_NAME, secret)
                                 .compose(future::complete, future);
 
-                    } catch (IOException e) {
+                    } catch (Throwable e) {
                         future.fail(e);
                     } finally {
                         if (internalCAkeyFile != null)

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -196,15 +196,15 @@ private final Future<KafkaClusterDescription> getKafkaClusterDescription(ConfigM
                                     kafka.generateBrokersClientsSecret(), kafka.generateBrokersInternalSecret());
 
                     future.complete(desc);
-                } catch (Exception e) {
+                } catch (Throwable e) {
                     future.fail(e);
                 }
             }, true,
             res -> {
                 if (res.succeeded()) {
                     fut.complete((KafkaClusterDescription) res.result());
                 } else {
-                    fut.fail("");
+                    fut.fail(res.cause());
                 }
             }
         );

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -62,7 +62,7 @@ public abstract class AbstractModel {
 
     protected static final Logger log = LogManager.getLogger(AbstractModel.class.getName());
 
-    protected static final int DEFAULT_CERTS_EXPIRATION_DAYS = 365;
+    protected static final int CERTS_EXPIRATION_DAYS = 365;
 
     private static final String VOLUME_MOUNT_HACK_IMAGE = "busybox";
     protected static final String VOLUME_MOUNT_HACK_NAME = "volume-mount-hack";

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/AbstractAssemblyOperator.java
Patch:
@@ -47,7 +47,7 @@ public abstract class AbstractAssemblyOperator {
     private static final Logger log = LogManager.getLogger(AbstractAssemblyOperator.class.getName());
 
     protected static final int LOCK_TIMEOUT = 60000;
-    protected static final int DEFAULT_CERTS_EXPIRATION_DAYS = 365;
+    protected static final int CERTS_EXPIRATION_DAYS = 365;
 
     public static final String INTERNAL_CA_NAME = "internal-ca";
 
@@ -128,7 +128,7 @@ private final void reconcileCertificate(String namespace, Handler<AsyncResult<Vo
                         CertManager certManager = new OpenSslCertManager();
                         internalCAkeyFile = File.createTempFile("tls", "internal-ca-key");
                         internalCAcertFile = File.createTempFile("tls", "internal-ca-cert");
-                        certManager.generateSelfSignedCert(internalCAkeyFile, internalCAcertFile, DEFAULT_CERTS_EXPIRATION_DAYS);
+                        certManager.generateSelfSignedCert(internalCAkeyFile, internalCAcertFile, CERTS_EXPIRATION_DAYS);
 
                         SecretCertProvider secretCertProvider = new SecretCertProvider();
                         Secret secret = secretCertProvider.createSecret(namespace, INTERNAL_CA_NAME,

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperator.java
Patch:
@@ -245,7 +245,7 @@ private final Future<CompositeFuture> deleteKafka(Reconciliation reconciliation)
         final KafkaCluster kafka = ss == null ? null : KafkaCluster.fromAssembly(ss, namespace, name);
         boolean deleteClaims = kafka != null && kafka.getStorage().type() == Storage.StorageType.PERSISTENT_CLAIM
             && kafka.getStorage().isDeleteClaim();
-        List<Future> result = new ArrayList<>(4 + (deleteClaims ? kafka.getReplicas() : 0));
+        List<Future> result = new ArrayList<>(8 + (deleteClaims ? kafka.getReplicas() : 0));
 
         result.add(configMapOperations.reconcile(namespace, KafkaCluster.metricConfigsName(name), null));
         result.add(serviceOperations.reconcile(namespace, KafkaCluster.kafkaClusterName(name), null));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectAssemblyOperatorTest.java
Patch:
@@ -487,6 +487,8 @@ public void testReconcile(TestContext context) {
                 asList(KafkaConnectCluster.fromConfigMap(baz).generateDeployment())
         );
 
+        when(mockSecretOps.reconcile(eq(clusterCmNamespace), any(), any())).thenReturn(Future.succeededFuture());
+
         Set<String> createdOrUpdated = new HashSet<>();
         Set<String> deleted = new HashSet<>();
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaConnectS2IAssemblyOperatorTest.java
Patch:
@@ -638,6 +638,8 @@ public void testReconcile(TestContext context) {
                 asList(KafkaConnectS2ICluster.fromConfigMap(baz).generateDeploymentConfig())
         );
 
+        when(mockSecretOps.reconcile(eq(clusterCmNamespace), any(), any())).thenReturn(Future.succeededFuture());
+
         Set<String> createdOrUpdated = new CopyOnWriteArraySet<>();
         Set<String> deleted = new CopyOnWriteArraySet<>();
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractModel.java
Patch:
@@ -62,6 +62,8 @@ public abstract class AbstractModel {
 
     protected static final Logger log = LogManager.getLogger(AbstractModel.class.getName());
 
+    protected static final int DEFAULT_CERTS_EXPIRATION_DAYS = 365;
+
     private static final String VOLUME_MOUNT_HACK_IMAGE = "busybox";
     protected static final String VOLUME_MOUNT_HACK_NAME = "volume-mount-hack";
     private static final Long VOLUME_MOUNT_HACK_GROUPID = 1001L;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -30,8 +30,8 @@ public class KafkaSetOperatorTest {
 
     @Before
     public void before() {
-        a = KafkaCluster.fromDescription(getConfigMap(), Collections.emptyList()).generateStatefulSet(true);
-        b = KafkaCluster.fromDescription(getConfigMap(), Collections.emptyList()).generateStatefulSet(true);
+        a = KafkaCluster.fromConfigMap(getConfigMap(), Collections.emptyList()).generateStatefulSet(true);
+        b = KafkaCluster.fromConfigMap(getConfigMap(), Collections.emptyList()).generateStatefulSet(true);
     }
 
     private ConfigMap getConfigMap() {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/StatefulSetDiff.java
Patch:
@@ -50,6 +50,7 @@ public class StatefulSetDiff {
             "/spec/template/spec/securityContext",
             "/spec/template/spec/terminationGracePeriodSeconds",
             "/spec/template/spec/volumes/[0-9]+/configMap/defaultMode",
+            "/spec/template/spec/volumes/[0-9]+/secret/defaultMode",
             "/spec/volumeClaimTemplates/[0-9]+/status",
             "/spec/template/spec/serviceAccount",
             "/status").stream().map(Pattern::compile).collect(Collectors.toList());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -30,8 +30,8 @@ public class KafkaSetOperatorTest {
 
     @Before
     public void before() {
-        a = KafkaCluster.fromDescription(getConfigMap(), Collections.EMPTY_LIST).generateStatefulSet(true);
-        b = KafkaCluster.fromDescription(getConfigMap(), Collections.EMPTY_LIST).generateStatefulSet(true);
+        a = KafkaCluster.fromDescription(getConfigMap(), Collections.emptyList()).generateStatefulSet(true);
+        b = KafkaCluster.fromDescription(getConfigMap(), Collections.emptyList()).generateStatefulSet(true);
     }
 
     private ConfigMap getConfigMap() {

File: certificate-manager/src/main/java/io/strimzi/certs/CertManager.java
Patch:
@@ -10,7 +10,7 @@
 public interface CertManager {
 
     /**
-     * Generate a self signed certificate
+     * Generate a self-signed certificate
      *
      * @param keyFile path to the file which will contain the private key
      * @param certFile path to the file which will contain the self signed certificate
@@ -21,7 +21,7 @@ public interface CertManager {
     void generateSelfSignedCert(File keyFile, File certFile, Subject sbj, int days) throws IOException;
 
     /**
-     * Generate a self signed certificate
+     * Generate a self-signed certificate
      *
      * @param keyFile path to the file which will contain the private key
      * @param certFile path to the file which will contain the self signed certificate

File: common-test/src/main/java/io/strimzi/test/StrimziRunner.java
Patch:
@@ -314,7 +314,7 @@ private void logState(Throwable t) {
         for (String resourceType : asList("pod", "deployment", "statefulset", "cm")) {
             for (String resourceName : ccFirst(kubeClient().list(resourceType))) {
                 LOGGER.info("Description of {} '{}':{}{}", resourceType, resourceName,
-                        System.lineSeparator(), indent(kubeClient().describe(resourceType, resourceName)));
+                        System.lineSeparator(), indent(kubeClient().getResourceAsJson(resourceType, resourceName)));
             }
         }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -42,6 +42,7 @@ public class KafkaConnectCluster extends AbstractModel {
     public static final String KEY_JVM_OPTIONS = "jvmOptions";
     public static final String KEY_RESOURCES = "resources";
     public static final String KEY_CONNECT_CONFIG = "connect-config";
+    public static final String KEY_AFFINITY = "affinity";
 
     // Kafka Connect configuration keys (EnvVariables)
     protected static final String ENV_VAR_KAFKA_CONNECT_CONFIGURATION = "KAFKA_CONNECT_CONFIGURATION";
@@ -86,6 +87,7 @@ public static KafkaConnectCluster fromConfigMap(ConfigMap cm) {
         kafkaConnect.setHealthCheckTimeout(Integer.parseInt(data.getOrDefault(KEY_HEALTHCHECK_TIMEOUT, String.valueOf(DEFAULT_HEALTHCHECK_TIMEOUT))));
 
         kafkaConnect.setConfiguration(Utils.getKafkaConnectConfiguration(data, KEY_CONNECT_CONFIG));
+        kafkaConnect.setUserAffinity(Utils.getAffinity(data.get(KEY_AFFINITY)));
 
         return kafkaConnect;
     }
@@ -142,7 +144,7 @@ public Deployment generateDeployment() {
                 Collections.emptyMap(),
                 Collections.emptyMap(),
                 resources(),
-                getAffinity(),
+                getMergedAffinity(),
                 getInitContainers());
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/TopicOperator.java
Patch:
@@ -189,6 +189,7 @@ public static TopicOperator fromConfigMap(ConfigMap kafkaClusterCm) {
             topicOperator.setZookeeperSessionTimeoutMs(tcConfig.getZookeeperSessionTimeout());
             topicOperator.setTopicMetadataMaxAttempts(tcConfig.getTopicMetadataMaxAttempts());
             topicOperator.setResources(tcConfig.getResources());
+            topicOperator.setUserAffinity(tcConfig.getAffinity());
         }
 
         return topicOperator;
@@ -243,7 +244,7 @@ public Deployment generateDeployment() {
                 Collections.emptyMap(),
                 Collections.emptyMap(),
                 resources(),
-                getAffinity(),
+                getMergedAffinity(),
                 getInitContainers());
     }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -57,6 +57,7 @@ public class ZookeeperCluster extends AbstractModel {
     public static final String KEY_JVM_OPTIONS = "zookeeper-jvmOptions";
     public static final String KEY_RESOURCES = "zookeeper-resources";
     public static final String KEY_ZOOKEEPER_CONFIG = "zookeeper-config";
+    public static final String KEY_AFFINITY = "zookeeper-affinity";
 
     // Zookeeper configuration keys (EnvVariables)
     public static final String ENV_VAR_ZOOKEEPER_NODE_COUNT = "ZOOKEEPER_NODE_COUNT";
@@ -136,6 +137,7 @@ public static ZookeeperCluster fromConfigMap(ConfigMap kafkaClusterCm) {
 
         zk.setResources(Resources.fromJson(data.get(KEY_RESOURCES)));
         zk.setJvmOptions(JvmOptions.fromJson(data.get(KEY_JVM_OPTIONS)));
+        zk.setUserAffinity(Utils.getAffinity(data.get(KEY_AFFINITY)));
 
         return zk;
     }
@@ -205,7 +207,7 @@ public StatefulSet generateStatefulSet(boolean isOpenShift) {
                 createExecProbe(healthCheckPath, healthCheckInitialDelay, healthCheckTimeout),
                 createExecProbe(healthCheckPath, healthCheckInitialDelay, healthCheckTimeout),
                 resources(),
-                getAffinity(),
+                getMergedAffinity(),
                 getInitContainers(),
                 isOpenShift);
     }

File: common-test/src/main/java/io/strimzi/test/k8s/BaseKubeClient.java
Patch:
@@ -296,7 +296,7 @@ public K waitForResourceCreation(String resourceType, String resourceName) {
     @Override
     public K waitForResourceDeletion(String resourceType, String resourceName) {
         TestUtils.waitFor(resourceType + " " + resourceName + " removal",
-            1_000L, 240_000L, () -> {
+            1_000L, 480_000L, () -> {
                 try {
                     get(resourceType, resourceName);
                     return false;

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractClusterIT.java
Patch:
@@ -314,7 +314,7 @@ public String  getImageNameFromPod(String podName) {
 
     public String  getInitContainerImageName(String podName) {
         String clusterOperatorJson = kubeClient.getResourceAsJson("pod", podName);
-        return JsonPath.parse(clusterOperatorJson).read("$.status.initContainerStatuses[0].image").toString();
+        return JsonPath.parse(clusterOperatorJson).read("$.status.initContainerStatuses[-1].image");
     }
 
 }

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractClusterIT.java
Patch:
@@ -314,7 +314,7 @@ public String  getImageNameFromPod(String podName) {
 
     public String  getInitContainerImageName(String podName) {
         String clusterOperatorJson = kubeClient.getResourceAsJson("pod", podName);
-        return JsonPath.parse(clusterOperatorJson).read("$.status.initContainerStatuses[*].image").toString();
+        return JsonPath.parse(clusterOperatorJson).read("$.status.initContainerStatuses[0].image").toString();
     }
 
 }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -422,7 +422,8 @@ protected List<EnvVar> getEnvVars() {
         List<EnvVar> varList = new ArrayList<>();
         varList.add(buildEnvVar(ENV_VAR_KAFKA_ZOOKEEPER_CONNECT, zookeeperConnect));
         varList.add(buildEnvVar(ENV_VAR_KAFKA_METRICS_ENABLED, String.valueOf(isMetricsEnabled)));
-        kafkaHeapOptions(varList, 0.5, 5L * 1024L * 1024L * 1024L);
+        heapOptions(varList, 0.5, 5L * 1024L * 1024L * 1024L);
+        jvmPerformanceOptions(varList);
 
         if (configuration != null) {
             varList.add(buildEnvVar(ENV_VAR_KAFKA_CONFIGURATION, configuration.getConfiguration()));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -150,7 +150,8 @@ public Deployment generateDeployment() {
     protected List<EnvVar> getEnvVars() {
         List<EnvVar> varList = new ArrayList<>();
         varList.add(buildEnvVar(ENV_VAR_KAFKA_CONNECT_CONFIGURATION, configuration.getConfiguration()));
-        kafkaHeapOptions(varList, 1.0, 0L);
+        heapOptions(varList, 1.0, 0L);
+        jvmPerformanceOptions(varList);
 
         return varList;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/ZookeeperCluster.java
Patch:
@@ -225,7 +225,8 @@ protected List<EnvVar> getEnvVars() {
         List<EnvVar> varList = new ArrayList<>();
         varList.add(buildEnvVar(ENV_VAR_ZOOKEEPER_NODE_COUNT, Integer.toString(replicas)));
         varList.add(buildEnvVar(ENV_VAR_ZOOKEEPER_METRICS_ENABLED, String.valueOf(isMetricsEnabled)));
-        kafkaHeapOptions(varList, 0.75, 2L * 1024L * 1024L * 1024L);
+        heapOptions(varList, 0.75, 2L * 1024L * 1024L * 1024L);
+        jvmPerformanceOptions(varList);
         varList.add(buildEnvVar(ENV_VAR_ZOOKEEPER_CONFIGURATION, configuration.getConfiguration()));
 
         return varList;

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractClusterIT.java
Patch:
@@ -217,7 +217,7 @@ protected void assertResources(String namespace, String podName, String memoryLi
         assertEquals(cpuRequest, requests.get("cpu").getAmount());
     }
 
-    protected void assertExpectedJavaOpts(String podName, String expectedXmx, String expectedXms) {
+    protected void assertExpectedJavaOpts(String podName, String expectedXmx, String expectedXms, String expectedServer, String expectedXx) {
         List<List<String>> cmdLines = commandLines(podName, "java");
         assertEquals("Expected exactly 1 java process to be running",
                 1, cmdLines.size());
@@ -231,6 +231,8 @@ protected void assertExpectedJavaOpts(String podName, String expectedXmx, String
         }
         assertCmdOption(cmd, expectedXmx);
         assertCmdOption(cmd, expectedXms);
+        assertCmdOption(cmd, expectedServer);
+        assertCmdOption(cmd, expectedXx);
     }
 
     private void assertCmdOption(List<String> cmd, String expectedXmx) {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -390,7 +390,7 @@ protected List<Container> getInitContainers() {
             ResourceRequirements resources = new ResourceRequirementsBuilder()
                     .addToRequests("cpu", new Quantity("100m"))
                     .addToRequests("memory", new Quantity("128Mi"))
-                    .addToLimits("cpu", new Quantity("1000m"))
+                    .addToLimits("cpu", new Quantity("1"))
                     .addToLimits("memory", new Quantity("256Mi"))
                     .build();
 

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaClusterIT.java
Patch:
@@ -376,11 +376,10 @@ public void testForTopicOperator() {
 
         //Deleting first topic by deletion of CM
         kubeClient.deleteByName("cm", "topic-from-cli");
-        assertThat(listTopicsUsingPodCLI(CLUSTER_NAME, kafkaPodName(CLUSTER_NAME, 1)), not(hasItems("topic-from-cli")));
-
+        
         //Deleting another topic using pod CLI
         deleteTopicUsingPodCLI(CLUSTER_NAME, kafkaPodName(CLUSTER_NAME, 1), "my-topic");
         List<String> topics = listTopicsUsingPodCLI(CLUSTER_NAME, kafkaPodName(CLUSTER_NAME, 1));
         assertThat(topics, not(hasItems("topic-from-cli", "my-topic")));
     }
-}
\ No newline at end of file
+}

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/AbstractReadyResourceOperator.java
Patch:
@@ -22,10 +22,9 @@
  * @param <L> The list variant of the Kubernetes resource type.
  * @param <D> The doneable variant of the Kubernetes resource type.
  * @param <R> The resource operations.
- * @param <P> The type of the {@link #reconcile(String, String, HasMetadata)}result
  */
-public abstract class AbstractReadyResourceOperator<C, T extends HasMetadata, L extends KubernetesResourceList/*<T>*/, D, R extends Resource<T, D>, P>
-        extends AbstractResourceOperator<C, T, L, D, R, P> {
+public abstract class AbstractReadyResourceOperator<C, T extends HasMetadata, L extends KubernetesResourceList/*<T>*/, D, R extends Resource<T, D>>
+        extends AbstractResourceOperator<C, T, L, D, R> {
 
     private final Logger log = LogManager.getLogger(getClass());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/AbstractScalableResourceOperator.java
Patch:
@@ -21,8 +21,8 @@
  * @param <D> The doneable variant of the Kubernetes resource type.
  * @param <R> The resource operations.
  */
-public abstract class AbstractScalableResourceOperator<C, T extends HasMetadata, L extends KubernetesResourceList/*<T>*/, D, R extends ScalableResource<T, D>, P>
-        extends AbstractReadyResourceOperator<C, T, L, D, R, P> {
+public abstract class AbstractScalableResourceOperator<C, T extends HasMetadata, L extends KubernetesResourceList/*<T>*/, D, R extends ScalableResource<T, D>>
+        extends AbstractReadyResourceOperator<C, T, L, D, R> {
 
     private final Logger log = LogManager.getLogger(getClass());
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/BuildConfigOperator.java
Patch:
@@ -17,7 +17,7 @@
 /**
  * Operations for {@code BuildConfig}s.
  */
-public class BuildConfigOperator extends AbstractResourceOperator<OpenShiftClient, BuildConfig, BuildConfigList, DoneableBuildConfig, BuildConfigResource<BuildConfig, DoneableBuildConfig, Void, Build>, Void> {
+public class BuildConfigOperator extends AbstractResourceOperator<OpenShiftClient, BuildConfig, BuildConfigList, DoneableBuildConfig, BuildConfigResource<BuildConfig, DoneableBuildConfig, Void, Build>> {
     /**
      * Constructor
      * @param vertx The Vertx instance
@@ -32,7 +32,8 @@ protected MixedOperation<BuildConfig, BuildConfigList, DoneableBuildConfig, Buil
         return client.buildConfigs();
     }
 
-    protected Future<ReconcileResult<Void>> internalPatch(String namespace, String name, BuildConfig current, BuildConfig desired) {
+    @Override
+    protected Future<ReconcileResult<BuildConfig>> internalPatch(String namespace, String name, BuildConfig current, BuildConfig desired) {
         desired.getSpec().setTriggers(current.getSpec().getTriggers());
         return super.internalPatch(namespace, name, current, desired);
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ConfigMapOperator.java
Patch:
@@ -15,7 +15,7 @@
 /**
  * Operations for {@code ConfigMap}s.
  */
-public class ConfigMapOperator extends AbstractResourceOperator<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>, Void> {
+public class ConfigMapOperator extends AbstractResourceOperator<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>> {
     /**
      * Constructor
      * @param vertx The Vertx instance

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/DeploymentConfigOperator.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * Operations for {@code DeploymentConfigs}s.
  */
-public class DeploymentConfigOperator extends AbstractScalableResourceOperator<OpenShiftClient, DeploymentConfig, DeploymentConfigList, DoneableDeploymentConfig, DeployableScalableResource<DeploymentConfig, DoneableDeploymentConfig>, Void> {
+public class DeploymentConfigOperator extends AbstractScalableResourceOperator<OpenShiftClient, DeploymentConfig, DeploymentConfigList, DoneableDeploymentConfig, DeployableScalableResource<DeploymentConfig, DoneableDeploymentConfig>> {
     /**
      * Constructor
      * @param vertx The Vertx instance
@@ -41,7 +41,8 @@ protected Integer currentScale(String namespace, String name) {
         }
     }
 
-    protected Future<ReconcileResult<Void>> internalPatch(String namespace, String name, DeploymentConfig current, DeploymentConfig desired) {
+    @Override
+    protected Future<ReconcileResult<DeploymentConfig>> internalPatch(String namespace, String name, DeploymentConfig current, DeploymentConfig desired) {
         desired.getSpec().getTemplate().getSpec().getContainers().get(0).setImage(current.getSpec().getTemplate().getSpec().getContainers().get(0).getImage());
         return super.internalPatch(namespace, name, current, desired);
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/DeploymentOperator.java
Patch:
@@ -15,7 +15,7 @@
 /**
  * Operations for {@code Deployment}s.
  */
-public class DeploymentOperator extends AbstractScalableResourceOperator<KubernetesClient, Deployment, DeploymentList, DoneableDeployment, ScalableResource<Deployment, DoneableDeployment>, Void> {
+public class DeploymentOperator extends AbstractScalableResourceOperator<KubernetesClient, Deployment, DeploymentList, DoneableDeployment, ScalableResource<Deployment, DoneableDeployment>> {
     /**
      * Constructor
      * @param vertx The Vertx instance

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/EndpointOperator.java
Patch:
@@ -15,7 +15,7 @@
 /**
  * Operations for {@code Endpoint}s.
  */
-class EndpointOperator extends AbstractReadyResourceOperator<KubernetesClient, Endpoints, EndpointsList, DoneableEndpoints, Resource<Endpoints, DoneableEndpoints>, Void> {
+class EndpointOperator extends AbstractReadyResourceOperator<KubernetesClient, Endpoints, EndpointsList, DoneableEndpoints, Resource<Endpoints, DoneableEndpoints>> {
     /**
      * Constructor
      * @param vertx The Vertx instance

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ImageStreamOperator.java
Patch:
@@ -15,7 +15,7 @@
 /**
  * Operations for {@code ImageStream}s.
  */
-public class ImageStreamOperator extends AbstractResourceOperator<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>, Void> {
+public class ImageStreamOperator extends AbstractResourceOperator<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>> {
     /**
      * Constructor
      * @param vertx The Vertx instance

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/PodOperator.java
Patch:
@@ -18,7 +18,7 @@
  * Operations for {@code Pod}s, which support {@link #isReady(String, String)} and
  * {@link #watch(String, String, Watcher)} in addition to the usual operations.
  */
-class PodOperator extends AbstractReadyResourceOperator<KubernetesClient, Pod, PodList, DoneablePod, PodResource<Pod, DoneablePod>, Void> {
+class PodOperator extends AbstractReadyResourceOperator<KubernetesClient, Pod, PodList, DoneablePod, PodResource<Pod, DoneablePod>> {
     /**
      * Constructor
      * @param vertx The Vertx instance

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/PvcOperator.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * Operations for {@code PersistentVolumeClaim}s.
  */
-public class PvcOperator extends AbstractResourceOperator<KubernetesClient, PersistentVolumeClaim, PersistentVolumeClaimList, DoneablePersistentVolumeClaim, Resource<PersistentVolumeClaim, DoneablePersistentVolumeClaim>, Void> {
+public class PvcOperator extends AbstractResourceOperator<KubernetesClient, PersistentVolumeClaim, PersistentVolumeClaimList, DoneablePersistentVolumeClaim, Resource<PersistentVolumeClaim, DoneablePersistentVolumeClaim>> {
     /**
      * Constructor
      * @param vertx The Vertx instance
@@ -32,7 +32,7 @@ protected MixedOperation<PersistentVolumeClaim, PersistentVolumeClaimList, Donea
     }
 
     @Override
-    public Future<ReconcileResult<Void>> reconcile(String namespace, String name, PersistentVolumeClaim resource) {
+    public Future<ReconcileResult<PersistentVolumeClaim>> reconcile(String namespace, String name, PersistentVolumeClaim resource) {
         if (resource != null) {
             throw new UnsupportedOperationException(); // should never happen
         } else {

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/operator/resource/ServiceOperator.java
Patch:
@@ -16,7 +16,7 @@
 /**
  * Operations for {@code Service}s.
  */
-public class ServiceOperator extends AbstractResourceOperator<KubernetesClient, Service, ServiceList, DoneableService, Resource<Service, DoneableService>, Void> {
+public class ServiceOperator extends AbstractResourceOperator<KubernetesClient, Service, ServiceList, DoneableService, Resource<Service, DoneableService>> {
 
     private final EndpointOperator endpointOperations;
     /**

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/BuildConfigOperatorTest.java
Patch:
@@ -18,7 +18,7 @@
 import static org.mockito.Mockito.when;
 
 public class BuildConfigOperatorTest extends AbstractResourceOperatorTest<OpenShiftClient, BuildConfig,
-        BuildConfigList, DoneableBuildConfig, BuildConfigResource<BuildConfig, DoneableBuildConfig, Void, Build>, Void> {
+        BuildConfigList, DoneableBuildConfig, BuildConfigResource<BuildConfig, DoneableBuildConfig, Void, Build>> {
 
     @Override
     protected void mocker(OpenShiftClient mockClient, MixedOperation mockCms) {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ConfigMapOperatorTest.java
Patch:
@@ -16,15 +16,15 @@
 import static java.util.Collections.singletonMap;
 import static org.mockito.Mockito.when;
 
-public class ConfigMapOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>, Void> {
+public class ConfigMapOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>> {
 
     @Override
     protected void  mocker(KubernetesClient mockClient, MixedOperation mockCms) {
         when(mockClient.configMaps()).thenReturn(mockCms);
     }
 
     @Override
-    protected AbstractResourceOperator<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>, Void> createResourceOperations(Vertx vertx, KubernetesClient mockClient) {
+    protected AbstractResourceOperator<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>> createResourceOperations(Vertx vertx, KubernetesClient mockClient) {
         return new ConfigMapOperator(vertx, mockClient);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/DeploymentConfigOperatorTest.java
Patch:
@@ -19,7 +19,7 @@
 
 public class DeploymentConfigOperatorTest extends ScalableResourceOperatorTest<OpenShiftClient, DeploymentConfig,
         DeploymentConfigList, DoneableDeploymentConfig,
-        DeployableScalableResource<DeploymentConfig, DoneableDeploymentConfig>, Void> {
+        DeployableScalableResource<DeploymentConfig, DoneableDeploymentConfig>> {
 
     @Override
     protected Class<OpenShiftClient> clientType() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/DeploymentOperatorTest.java
Patch:
@@ -19,7 +19,7 @@
 
 public class DeploymentOperatorTest extends
         ScalableResourceOperatorTest<KubernetesClient, Deployment, DeploymentList,
-                                DoneableDeployment, ScalableResource<Deployment, DoneableDeployment>, Void> {
+                                DoneableDeployment, ScalableResource<Deployment, DoneableDeployment>> {
 
     @Override
     protected Class<KubernetesClient> clientType() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/EndpointOperatorTest.java
Patch:
@@ -15,7 +15,7 @@
 
 import static org.mockito.Mockito.when;
 
-public class EndpointOperatorTest extends AbtractReadyResourceOperatorTest<KubernetesClient, Endpoints, EndpointsList, DoneableEndpoints, Resource<Endpoints, DoneableEndpoints>, Void> {
+public class EndpointOperatorTest extends AbtractReadyResourceOperatorTest<KubernetesClient, Endpoints, EndpointsList, DoneableEndpoints, Resource<Endpoints, DoneableEndpoints>> {
 
     @Override
     protected Class<KubernetesClient> clientType() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ImageStreamOperatorTest.java
Patch:
@@ -15,7 +15,7 @@
 
 import static org.mockito.Mockito.when;
 
-public class ImageStreamOperatorTest extends AbstractResourceOperatorTest<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>, Void> {
+public class ImageStreamOperatorTest extends AbstractResourceOperatorTest<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>> {
 
     @Override
     protected Class<OpenShiftClient> clientType() {
@@ -38,7 +38,7 @@ protected void mocker(OpenShiftClient mockClient, MixedOperation op) {
     }
 
     @Override
-    protected AbstractResourceOperator<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>, Void> createResourceOperations(Vertx vertx, OpenShiftClient mockClient) {
+    protected AbstractResourceOperator<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>> createResourceOperations(Vertx vertx, OpenShiftClient mockClient) {
         return new ImageStreamOperator(vertx, mockClient);
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/PodOperatorTest.java
Patch:
@@ -27,7 +27,7 @@
 import static org.mockito.Mockito.when;
 
 public class PodOperatorTest extends
-        AbtractReadyResourceOperatorTest<KubernetesClient, Pod, PodList, DoneablePod, PodResource<Pod, DoneablePod>, Void> {
+        AbtractReadyResourceOperatorTest<KubernetesClient, Pod, PodList, DoneablePod, PodResource<Pod, DoneablePod>> {
 
     @Rule
     public OpenShiftServer server = new OpenShiftServer(false, true);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/PvcOperatorTest.java
Patch:
@@ -17,7 +17,7 @@
 
 import static org.mockito.Mockito.when;
 
-public class PvcOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, PersistentVolumeClaim, PersistentVolumeClaimList, DoneablePersistentVolumeClaim, Resource<PersistentVolumeClaim, DoneablePersistentVolumeClaim>, Void> {
+public class PvcOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, PersistentVolumeClaim, PersistentVolumeClaimList, DoneablePersistentVolumeClaim, Resource<PersistentVolumeClaim, DoneablePersistentVolumeClaim>> {
 
     @Override
     protected Class<KubernetesClient> clientType() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ScalableResourceOperatorTest.java
Patch:
@@ -10,6 +10,6 @@
 import io.fabric8.kubernetes.client.dsl.Resource;
 
 public abstract class ScalableResourceOperatorTest<C extends KubernetesClient, T extends HasMetadata,
-        L extends KubernetesResourceList, D, R extends Resource<T, D>, P> extends AbtractReadyResourceOperatorTest<C, T, L, D, R, P> {
+        L extends KubernetesResourceList, D, R extends Resource<T, D>> extends AbtractReadyResourceOperatorTest<C, T, L, D, R> {
 
 }

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ServiceOperatorTest.java
Patch:
@@ -15,7 +15,7 @@
 
 import static org.mockito.Mockito.when;
 
-public class ServiceOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, Service, ServiceList, DoneableService, Resource<Service, DoneableService>, Void> {
+public class ServiceOperatorTest extends AbstractResourceOperatorTest<KubernetesClient, Service, ServiceList, DoneableService, Resource<Service, DoneableService>> {
 
     @Override
     protected Class<KubernetesClient> clientType() {

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/TopicOperatorTest.java
Patch:
@@ -44,7 +44,7 @@ public class TopicOperatorTest {
             "\"topicMetadataMaxAttempts\":" + tcTopicMetadataMaxAttempts +
             " }";
 
-    private final ConfigMap cm = ResourceUtils.createKafkaClusterConfigMap(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaConfigJson, zooConfigJson, storageJson, topicOperatorJson);
+    private final ConfigMap cm = ResourceUtils.createKafkaClusterConfigMap(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaConfigJson, zooConfigJson, storageJson, topicOperatorJson, null);
     private final TopicOperator tc = TopicOperator.fromConfigMap(cm);
 
     private List<EnvVar> getExpectedEnvVars() {
@@ -72,7 +72,7 @@ public void testFromConfigMapNoConfig() {
     @Test
     public void testFromConfigMapDefaultConfig() {
 
-        ConfigMap cm = ResourceUtils.createKafkaClusterConfigMap(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaConfigJson, zooConfigJson, storageJson, "{ }");
+        ConfigMap cm = ResourceUtils.createKafkaClusterConfigMap(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaConfigJson, zooConfigJson, storageJson, "{ }", null);
         TopicOperator tc = TopicOperator.fromConfigMap(cm);
 
         assertEquals(TopicOperator.DEFAULT_IMAGE, tc.getImage());

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/assembly/KafkaAssemblyOperatorTest.java
Patch:
@@ -63,6 +63,7 @@
 import static org.mockito.Mockito.verifyNoMoreInteractions;
 import static org.mockito.Mockito.when;
 
+
 @RunWith(Parameterized.class)
 @Parameterized.UseParametersRunnerFactory(VertxUnitRunnerWithParametersFactory.class)
 public class KafkaAssemblyOperatorTest {
@@ -395,7 +396,7 @@ private ConfigMap getConfigMap(String clusterCmName) {
         int healthDelay = 120;
         int healthTimeout = 30;
         String metricsCmJson = metrics ? METRICS_CONFIG : null;
-        return ResourceUtils.createKafkaClusterConfigMap(clusterCmNamespace, clusterCmName, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaConfig, zooConfig, storage, tcConfig);
+        return ResourceUtils.createKafkaClusterConfigMap(clusterCmNamespace, clusterCmName, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaConfig, zooConfig, storage, tcConfig, null);
     }
 
     private static <T> Set<T> set(T... elements) {

File: common-test/src/main/java/io/strimzi/test/StrimziRunner.java
Patch:
@@ -425,7 +425,7 @@ private Statement withClusterOperator(Annotatable element,
         for (ClusterOperator cc : annotations(element, ClusterOperator.class)) {
             List<String> yamls = Arrays.stream(new File(CC_INSTALL_DIR).listFiles()).sorted().map(f -> getContent(f, node -> {
                 // Change the docker org of the images in the 04-deployment.yaml
-                if ("04-deployment.yaml".equals(f.getName())) {
+                if ("07-deployment.yaml".equals(f.getName())) {
                     String dockerOrg = System.getenv().getOrDefault("DOCKER_ORG", "strimzi");
                     String dockerTag = System.getenv().getOrDefault("DOCKER_TAG", "latest");
                     ObjectNode containerNode = (ObjectNode) node.get("spec").get("template").get("spec").get("containers").get(0);

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/ClusterOperatorConfig.java
Patch:
@@ -22,7 +22,7 @@ public class ClusterOperatorConfig {
     public static final String STRIMZI_OPERATION_TIMEOUT_MS = "STRIMZI_OPERATION_TIMEOUT_MS";
 
     public static final long DEFAULT_FULL_RECONCILIATION_INTERVAL_MS = 120_000;
-    public static final long DEFAULT_OPERATION_TIMEOUT_MS = 60_000;
+    public static final long DEFAULT_OPERATION_TIMEOUT_MS = 300_000;
 
     private final Set<String> namespaces;
     private final long reconciliationIntervalMs;

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractClusterIT.java
Patch:
@@ -249,7 +249,7 @@ private List<List<String>> commandLines(String podName, String cmd) {
         return result;
     }
 
-    void assertNoCcErrorsLogged() {
+    void assertNoCoErrorsLogged() {
         //TODO add blacklist for unexpected errors
         assertThat(kubeClient.searchInLog("deploy", "strimzi-cluster-operator", "60", "Exception", "Error", "Throwable"), isEmptyString());
     }

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaClusterIT.java
Patch:
@@ -75,7 +75,7 @@ public void testDeployKafkaClusterViaTemplate() {
         Oc oc = (Oc) this.kubeClient;
         String clusterName = "openshift-my-cluster";
         oc.newApp("strimzi-ephemeral", map("CLUSTER_NAME", clusterName));
-        oc.waitForStatefulSet(zookeeperClusterName(clusterName), 1);
+        oc.waitForStatefulSet(zookeeperClusterName(clusterName), 3);
         oc.waitForStatefulSet(kafkaClusterName(clusterName), 3);
         oc.deleteByName("cm", clusterName);
         oc.waitForResourceDeletion("statefulset", kafkaClusterName(clusterName));

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/AbstractConfiguration.java
Patch:
@@ -5,6 +5,7 @@
 
 package io.strimzi.operator.cluster.model;
 
+import io.strimzi.operator.cluster.InvalidConfigMapException;
 import io.vertx.core.json.JsonObject;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -80,6 +81,7 @@ private Map<String, String> convertToStrings(JsonObject json)  {
                 map.put(key, String.valueOf(value));
             } else  {
                 log.error("Unsupported type {} in configuration for key {}", value.getClass(), key);
+                throw new InvalidConfigMapException(key, " - Unsupported type " + value.getClass() + " in configuration for this key");
             }
         }
 

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectCluster.java
Patch:
@@ -13,7 +13,6 @@
 import io.fabric8.kubernetes.api.model.extensions.DeploymentStrategy;
 import io.fabric8.kubernetes.api.model.extensions.DeploymentStrategyBuilder;
 import io.fabric8.kubernetes.api.model.extensions.RollingUpdateDeploymentBuilder;
-import io.vertx.core.json.JsonObject;
 
 import java.util.ArrayList;
 import java.util.Collections;
@@ -86,8 +85,7 @@ public static KafkaConnectCluster fromConfigMap(ConfigMap cm) {
         kafkaConnect.setHealthCheckInitialDelay(Integer.parseInt(data.getOrDefault(KEY_HEALTHCHECK_DELAY, String.valueOf(DEFAULT_HEALTHCHECK_DELAY))));
         kafkaConnect.setHealthCheckTimeout(Integer.parseInt(data.getOrDefault(KEY_HEALTHCHECK_TIMEOUT, String.valueOf(DEFAULT_HEALTHCHECK_TIMEOUT))));
 
-        String connectConfig = data.getOrDefault(KEY_CONNECT_CONFIG, "{}");
-        kafkaConnect.setConfiguration(new KafkaConnectConfiguration(new JsonObject(connectConfig)));
+        kafkaConnect.setConfiguration(Utils.getKafkaConnectConfiguration(data, KEY_CONNECT_CONFIG));
 
         return kafkaConnect;
     }

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/Storage.java
Patch:
@@ -9,6 +9,7 @@
 import io.fabric8.kubernetes.api.model.Quantity;
 import io.vertx.core.json.JsonObject;
 
+import java.util.Arrays;
 import java.util.Map;
 import java.util.stream.Collectors;
 
@@ -177,7 +178,7 @@ public static StorageType from(String type) {
             } else if (type.equals(LOCAL.type)) {
                 return LOCAL;
             } else {
-                throw new IllegalArgumentException("Unknown type: " + type);
+                throw new IllegalArgumentException("Unknown type: " + type + ". Allowed types are: " + Arrays.toString(values()));
             }
         }
     }

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaClusterIT.java
Patch:
@@ -337,7 +337,7 @@ public void testJvmAndResources() {
         assertExpectedJavaOpts("jvm-resource-cluster-zookeeper-0",
                 "-Xmx600m", "-Xms300m");
 
-        String podName = client.pods().list().getItems().stream().filter(p -> p.getMetadata().getName().startsWith("jvm-resource-cluster-topic-operator-")).findFirst().get().getMetadata().getName();
+        String podName = client.pods().inNamespace(NAMESPACE).list().getItems().stream().filter(p -> p.getMetadata().getName().startsWith("jvm-resource-cluster-topic-operator-")).findFirst().get().getMetadata().getName();
 
         assertResources(NAMESPACE, podName,
                 "500M", "300m", "500M", "300m");

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaConnectConfiguration.java
Patch:
@@ -37,6 +37,8 @@ public class KafkaConnectConfiguration extends AbstractConfiguration {
         DEFAULTS.setProperty("value.converter", "org.apache.kafka.connect.json.JsonConverter");
         DEFAULTS.setProperty("internal.key.converter", "org.apache.kafka.connect.json.JsonConverter");
         DEFAULTS.setProperty("internal.value.converter", "org.apache.kafka.connect.json.JsonConverter");
+        DEFAULTS.setProperty("internal.key.converter.schemas.enable", "false");
+        DEFAULTS.setProperty("internal.value.converter.schemas.enable", "false");
     }
 
     /**

File: systemtest/src/test/java/io/strimzi/systemtest/ConnectClusterIT.java
Patch:
@@ -56,12 +56,14 @@ public class ConnectClusterIT extends AbstractClusterIT {
 
     private static final String EXPECTED_CONFIG = "group.id=connect-cluster\\n" +
             "key.converter=org.apache.kafka.connect.json.JsonConverter\\n" +
+            "internal.key.converter.schemas.enable=false\\n" +
             "value.converter=org.apache.kafka.connect.json.JsonConverter\\n" +
             "bootstrap.servers=" + KAFKA_CONNECT_BOOTSTRAP_SERVERS_ESCAPED + "\\n" +
             "config.storage.topic=connect-cluster-configs\\n" +
             "status.storage.topic=connect-cluster-status\\n" +
             "offset.storage.topic=connect-cluster-offsets\\n" +
             "internal.key.converter=org.apache.kafka.connect.json.JsonConverter\\n" +
+            "internal.value.converter.schemas.enable=false\\n" +
             "internal.value.converter=org.apache.kafka.connect.json.JsonConverter\\n";
 
     @Test

File: cluster-operator/src/main/java/io/strimzi/operator/cluster/model/KafkaCluster.java
Patch:
@@ -64,7 +64,7 @@ public class KafkaCluster extends AbstractModel {
     // Kafka configuration keys (EnvVariables)
     public static final String ENV_VAR_KAFKA_ZOOKEEPER_CONNECT = "KAFKA_ZOOKEEPER_CONNECT";
     private static final String ENV_VAR_KAFKA_METRICS_ENABLED = "KAFKA_METRICS_ENABLED";
-    protected static final String ENV_VAR_KAFKA_USER_CONFIGURATION = "KAFKA_USER_CONFIGURATION";
+    protected static final String ENV_VAR_KAFKA_CONFIGURATION = "KAFKA_CONFIGURATION";
 
     /**
      * Constructor
@@ -185,7 +185,7 @@ public static KafkaCluster fromAssembly(StatefulSet ss, String namespace, String
             kafka.setStorage(storage);
         }
 
-        String kafkaConfiguration = containerEnvVars(container).get(ENV_VAR_KAFKA_USER_CONFIGURATION);
+        String kafkaConfiguration = containerEnvVars(container).get(ENV_VAR_KAFKA_CONFIGURATION);
         if (kafkaConfiguration != null) {
             kafka.setConfiguration(new KafkaConfiguration(kafkaConfiguration));
         }
@@ -302,7 +302,7 @@ protected List<EnvVar> getEnvVars() {
         kafkaHeapOptions(varList, 0.5, 5L * 1024L * 1024L * 1024L);
 
         if (configuration != null) {
-            varList.add(buildEnvVar(ENV_VAR_KAFKA_USER_CONFIGURATION, configuration.getConfiguration()));
+            varList.add(buildEnvVar(ENV_VAR_KAFKA_CONFIGURATION, configuration.getConfiguration()));
         }
 
         return varList;

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -102,7 +102,7 @@ private void checkStatefulSet(StatefulSet ss) {
         assertEquals(new Integer(healthDelay), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getLivenessProbe().getInitialDelaySeconds());
         assertEquals(new Integer(healthTimeout), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getTimeoutSeconds());
         assertEquals(new Integer(healthDelay), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getInitialDelaySeconds());
-        assertEquals("foo=bar\n", AbstractModel.containerEnvVars(ss.getSpec().getTemplate().getSpec().getContainers().get(0)).get(KafkaCluster.ENV_VAR_KAFKA_USER_CONFIGURATION));
+        assertEquals("foo=bar\n", AbstractModel.containerEnvVars(ss.getSpec().getTemplate().getSpec().getContainers().get(0)).get(KafkaCluster.ENV_VAR_KAFKA_CONFIGURATION));
     }
 
     /**

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/ZookeeperClusterTest.java
Patch:
@@ -104,7 +104,7 @@ private void checkStatefulSet(StatefulSet ss) {
         assertEquals(new Integer(healthDelay), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getLivenessProbe().getInitialDelaySeconds());
         assertEquals(new Integer(healthTimeout), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getTimeoutSeconds());
         assertEquals(new Integer(healthDelay), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getInitialDelaySeconds());
-        assertEquals("foo=bar\n", AbstractModel.containerEnvVars(ss.getSpec().getTemplate().getSpec().getContainers().get(0)).get(ZookeeperCluster.ENV_VAR_ZOOKEEPER_CONFIGURATION));
+        assertEquals("timeTick=2000\nautopurge.purgeInterval=1\nsyncLimit=2\ninitLimit=5\nfoo=bar\n", AbstractModel.containerEnvVars(ss.getSpec().getTemplate().getSpec().getContainers().get(0)).get(ZookeeperCluster.ENV_VAR_ZOOKEEPER_CONFIGURATION));
     }
 
     /**

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/ResourceUtils.java
Patch:
@@ -119,13 +119,15 @@ public static ConfigMap createKafkaClusterConfigMap(String clusterCmNamespace, S
      * Generate ConfigMap for Kafka Connect S2I cluster
      */
     public static ConfigMap createKafkaConnectS2IClusterConfigMap(String clusterCmNamespace, String clusterCmName, int replicas,
-                                                                  String image, int healthDelay, int healthTimeout, String connectConfig) {
+                                                                  String image, int healthDelay, int healthTimeout, String connectConfig,
+                                                                  boolean insecureSourceRepo) {
         Map<String, String> cmData = new HashMap<>();
         cmData.put(KafkaConnectS2ICluster.KEY_IMAGE, image);
         cmData.put(KafkaConnectS2ICluster.KEY_REPLICAS, Integer.toString(replicas));
         cmData.put(KafkaConnectS2ICluster.KEY_HEALTHCHECK_DELAY, Integer.toString(healthDelay));
         cmData.put(KafkaConnectS2ICluster.KEY_HEALTHCHECK_TIMEOUT, Integer.toString(healthTimeout));
         cmData.put(KafkaConnectS2ICluster.KEY_CONNECT_CONFIG, connectConfig);
+        cmData.put(KafkaConnectS2ICluster.KEY_INSECURE_SOURCE_REPO, String.valueOf(insecureSourceRepo));
 
         ConfigMap cm = createEmptyKafkaConnectS2IClusterConfigMap(clusterCmNamespace, clusterCmName);
         cm.setData(cmData);

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/model/KafkaClusterTest.java
Patch:
@@ -102,7 +102,7 @@ private void checkStatefulSet(StatefulSet ss) {
         assertEquals(new Integer(healthDelay), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getLivenessProbe().getInitialDelaySeconds());
         assertEquals(new Integer(healthTimeout), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getTimeoutSeconds());
         assertEquals(new Integer(healthDelay), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getInitialDelaySeconds());
-        assertEquals("foo=bar\n", AbstractModel.containerEnvVars(ss.getSpec().getTemplate().getSpec().getContainers().get(0)).get(KafkaCluster.KEY_KAFKA_USER_CONFIGURATION));
+        assertEquals("foo=bar\n", AbstractModel.containerEnvVars(ss.getSpec().getTemplate().getSpec().getContainers().get(0)).get(KafkaCluster.ENV_VAR_KAFKA_USER_CONFIGURATION));
     }
 
     /**
@@ -132,7 +132,7 @@ public void testPodNames() {
     public void testPvcNames() {
 
         for (int i = 0; i < replicas; i++) {
-            assertEquals(kc.VOLUME_NAME + "-" + KafkaCluster.kafkaClusterName(cluster) + "-" + i, kc.getPersistentVolumeClaimName(i));
+            assertEquals(kc.VOLUME_NAME + "-" + KafkaCluster.kafkaPodName(cluster, i), kc.getPersistentVolumeClaimName(i));
         }
     }
 

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/KafkaSetOperatorTest.java
Patch:
@@ -16,7 +16,7 @@
 import java.util.Map;
 
 import static io.strimzi.operator.cluster.model.AbstractModel.containerEnvVars;
-import static io.strimzi.operator.cluster.model.KafkaCluster.KEY_KAFKA_ZOOKEEPER_CONNECT;
+import static io.strimzi.operator.cluster.model.KafkaCluster.ENV_VAR_KAFKA_ZOOKEEPER_CONNECT;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
@@ -93,7 +93,7 @@ public void testNeedsRollingUpdateReadinessTimeout() {
 
     @Test
     public void testNeedsRollingUpdateEnvZkConnect() {
-        String envVar = KEY_KAFKA_ZOOKEEPER_CONNECT;
+        String envVar = ENV_VAR_KAFKA_ZOOKEEPER_CONNECT;
         a.getSpec().getTemplate().getSpec().getContainers().get(0).getEnv().add(new EnvVar(envVar,
                 containerEnvVars(a.getSpec().getTemplate().getSpec().getContainers().get(0)).get(envVar) + "-foo", null));
         assertTrue(KafkaSetOperator.needsRollingUpdate(diff()));

File: cluster-operator/src/test/java/io/strimzi/operator/cluster/operator/resource/ZookeeperSetOperatiorTest.java
Patch:
@@ -16,7 +16,7 @@
 import java.util.Map;
 
 import static io.strimzi.operator.cluster.model.AbstractModel.containerEnvVars;
-import static io.strimzi.operator.cluster.model.ZookeeperCluster.KEY_ZOOKEEPER_METRICS_ENABLED;
+import static io.strimzi.operator.cluster.model.ZookeeperCluster.ENV_VAR_ZOOKEEPER_METRICS_ENABLED;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
 
@@ -89,7 +89,7 @@ public void testNeedsRollingUpdateReadinessTimeout() {
 
     @Test
     public void testNeedsRollingUpdateEnvZkMetricsEnabled() {
-        String envVar = KEY_ZOOKEEPER_METRICS_ENABLED;
+        String envVar = ENV_VAR_ZOOKEEPER_METRICS_ENABLED;
         a.getSpec().getTemplate().getSpec().getContainers().get(0).getEnv().add(new EnvVar(envVar,
                 containerEnvVars(a.getSpec().getTemplate().getSpec().getContainers().get(0)).get(envVar) + "-foo", null));
         assertTrue(ZookeeperSetOperator.needsRollingUpdate(diff()));

File: common-test/src/main/java/io/strimzi/test/ConnectCluster.java
Patch:
@@ -20,7 +20,7 @@
 @Repeatable(ConnectCluster.Container.class)
 public @interface ConnectCluster {
     String name();
-    String bootstrapServers();
+    String connectConfig();
     int nodes() default 1;
     CmData[] config() default {};
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/model/KafkaConnectS2ICluster.java
Patch:
@@ -37,7 +37,7 @@ public class KafkaConnectS2ICluster extends KafkaConnectCluster {
 
     // Configuration defaults
     protected static final String DEFAULT_IMAGE =
-            System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_IMAGE", "strimzi/kafka-connect-s2i:latest");
+            System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_CONNECT_S2I_IMAGE", "strimzi/kafka-connect-s2i:latest");
 
     /**
      * Constructor

File: topic-controller/src/main/java/io/strimzi/controller/topic/Session.java
Patch:
@@ -139,7 +139,7 @@ public void start() {
 
         Thread configMapThread = new Thread(() -> {
             LOGGER.debug("Watching configmaps matching {}", cmPredicate);
-            Session.this.topicCmWatch = kubeClient.configMaps().inNamespace(kubeClient.getNamespace()).watch(new ConfigMapWatcher(controller, cmPredicate));
+            Session.this.topicCmWatch = kubeClient.configMaps().inNamespace(namespace).watch(new ConfigMapWatcher(controller, cmPredicate));
             LOGGER.debug("Watching setup");
 
             // start the HTTP server for healthchecks

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/model/KafkaClusterTest.java
Patch:
@@ -22,7 +22,8 @@ public class KafkaClusterTest {
     private final int healthDelay = 120;
     private final int healthTimeout = 30;
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
-    private final ConfigMap cm = ResourceUtils.createKafkaClusterConfigMap(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson);
+    private final String configurationJson = "{\"foo\":\"bar\"}";
+    private final ConfigMap cm = ResourceUtils.createKafkaClusterConfigMap(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, configurationJson);
     private final KafkaCluster kc = KafkaCluster.fromConfigMap(cm);
 
     @Test
@@ -101,6 +102,7 @@ private void checkStatefulSet(StatefulSet ss) {
         assertEquals(new Integer(healthDelay), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getLivenessProbe().getInitialDelaySeconds());
         assertEquals(new Integer(healthTimeout), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getTimeoutSeconds());
         assertEquals(new Integer(healthDelay), ss.getSpec().getTemplate().getSpec().getContainers().get(0).getReadinessProbe().getInitialDelaySeconds());
+        assertEquals("foo=bar\n", AbstractModel.containerEnvVars(ss.getSpec().getTemplate().getSpec().getContainers().get(0)).get(KafkaCluster.KEY_KAFKA_USER_CONFIGURATION));
     }
 
     /**

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/model/TopicControllerTest.java
Patch:
@@ -26,6 +26,7 @@ public class TopicControllerTest {
     private final int healthDelay = 120;
     private final int healthTimeout = 30;
     private final String metricsCmJson = "{\"animal\":\"wombat\"}";
+    private final String kafkaJson = "{\"foo\":\"bar\"}";
     private final String storageJson = "{\"type\": \"ephemeral\"}";
 
     private final String tcWatchedNamespace = "my-topic-namespace";
@@ -42,7 +43,7 @@ public class TopicControllerTest {
             "\"topicMetadataMaxAttempts\":" + tcTopicMetadataMaxAttempts +
             " }";
 
-    private final ConfigMap cm = ResourceUtils.createKafkaClusterConfigMap(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, storageJson, topicControllerJson);
+    private final ConfigMap cm = ResourceUtils.createKafkaClusterConfigMap(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaJson, storageJson, topicControllerJson);
     private final TopicController tc = TopicController.fromConfigMap(cm);
 
     private List<EnvVar> getExpectedEnvVars() {
@@ -70,7 +71,7 @@ public void testFromConfigMapNoConfig() {
     @Test
     public void testFromConfigMapDefaultConfig() {
 
-        ConfigMap cm = ResourceUtils.createKafkaClusterConfigMap(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, storageJson, "{ }");
+        ConfigMap cm = ResourceUtils.createKafkaClusterConfigMap(namespace, cluster, replicas, image, healthDelay, healthTimeout, metricsCmJson, kafkaJson, storageJson, "{ }");
         TopicController tc = TopicController.fromConfigMap(cm);
 
         assertEquals(TopicController.DEFAULT_IMAGE, tc.getImage());

File: systemtest/src/test/java/io/strimzi/systemtest/AbstractClusterIT.java
Patch:
@@ -27,9 +27,9 @@
 
 import static io.strimzi.test.TestUtils.indent;
 
-public class AbstractClusterTest {
+public class AbstractClusterIT {
 
-    private static final Logger LOGGER = LoggerFactory.getLogger(AbstractClusterTest.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(AbstractClusterIT.class);
 
     @ClassRule
     public static KubeClusterResource cluster = new KubeClusterResource();

File: systemtest/src/test/java/io/strimzi/systemtest/KafkaClusterIT.java
Patch:
@@ -49,11 +49,11 @@
 
 
 @RunWith(StrimziRunner.class)
-@Namespace(KafkaClusterTest.NAMESPACE)
+@Namespace(KafkaClusterIT.NAMESPACE)
 @ClusterController
-public class KafkaClusterTest extends AbstractClusterTest {
+public class KafkaClusterIT extends AbstractClusterIT {
 
-    private static final Logger LOGGER = LoggerFactory.getLogger(KafkaClusterTest.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(KafkaClusterIT.class);
 
     public static final String NAMESPACE = "kafka-cluster-test";
     private static final String CLUSTER_NAME = "my-cluster";

File: systemtest/src/test/java/io/strimzi/systemtest/OpenShiftTemplatesIT.java
Patch:
@@ -32,10 +32,10 @@
  */
 @RunWith(StrimziRunner.class)
 @OpenShiftOnly
-@Namespace(OpenShiftTemplatesTest.NAMESPACE)
+@Namespace(OpenShiftTemplatesIT.NAMESPACE)
 @Resources(value = "../examples/templates/cluster-controller", asAdmin = true)
 @Resources(value = "../examples/templates/topic-controller", asAdmin = true)
-public class OpenShiftTemplatesTest {
+public class OpenShiftTemplatesIT {
 
     public static final String NAMESPACE = "template-test";
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/Main.java
Patch:
@@ -57,8 +57,8 @@ public static void main(String[] args) {
 
     static CompositeFuture run(Vertx vertx, KubernetesClient client, boolean isOpenShift, ClusterControllerConfig config) {
         ServiceOperator serviceOperations = new ServiceOperator(vertx, client);
-        ZookeeperSetOperator zookeeperSetOperations = new ZookeeperSetOperator(vertx, client);
-        KafkaSetOperator kafkaSetOperations = new KafkaSetOperator(vertx, client);
+        ZookeeperSetOperator zookeeperSetOperations = new ZookeeperSetOperator(vertx, client, config.getOperationTimeoutMs());
+        KafkaSetOperator kafkaSetOperations = new KafkaSetOperator(vertx, client, config.getOperationTimeoutMs());
         ConfigMapOperator configMapOperations = new ConfigMapOperator(vertx, client);
         PvcOperator pvcOperations = new PvcOperator(vertx, client);
         DeploymentOperator deploymentOperations = new DeploymentOperator(vertx, client);

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/KafkaSetOperator.java
Patch:
@@ -24,8 +24,8 @@ public class KafkaSetOperator extends StatefulSetOperator<Boolean> {
      * @param vertx  The Vertx instance
      * @param client The Kubernetes client
      */
-    public KafkaSetOperator(Vertx vertx, KubernetesClient client) {
-        super(vertx, client);
+    public KafkaSetOperator(Vertx vertx, KubernetesClient client, long operationTimeoutMs) {
+        super(vertx, client, operationTimeoutMs);
     }
 
     @Override

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -34,15 +34,17 @@ public class StatefulSetOperator<P> extends AbstractScalableResourceOperator<Kub
 
     private static final Logger log = LoggerFactory.getLogger(StatefulSetOperator.class.getName());
     private final PodOperator podOperations;
+    private final long operationTimeoutMs;
 
     /**
      * Constructor
      * @param vertx The Vertx instance
      * @param client The Kubernetes client
      */
-    public StatefulSetOperator(Vertx vertx, KubernetesClient client) {
+    public StatefulSetOperator(Vertx vertx, KubernetesClient client, long operationTimeoutMs) {
         super(vertx, client, "StatefulSet");
         this.podOperations = new PodOperator(vertx, client);
+        this.operationTimeoutMs = operationTimeoutMs;
     }
 
     @Override
@@ -212,8 +214,6 @@ protected Future<ReconcileResult<P>> internalCreate(String namespace, String nam
         Future<ReconcileResult<P>> result = Future.future();
         Future<ReconcileResult<P>> crt = super.internalCreate(namespace, name, desired);
 
-        long operationTimeoutMs = 60_000L;
-
         // ... then wait for the SS to be ready...
         crt.compose(res -> readiness(namespace, desired.getMetadata().getName(), 1_000, operationTimeoutMs).map(res))
         // ... then wait for all the pods to be ready

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/ZookeeperSetOperator.java
Patch:
@@ -24,8 +24,8 @@ public class ZookeeperSetOperator extends StatefulSetOperator<Boolean> {
      * @param vertx  The Vertx instance
      * @param client The Kubernetes client
      */
-    public ZookeeperSetOperator(Vertx vertx, KubernetesClient client) {
-        super(vertx, client);
+    public ZookeeperSetOperator(Vertx vertx, KubernetesClient client, long operationTimeoutMs) {
+        super(vertx, client, operationTimeoutMs);
     }
 
     @Override

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/operator/assembly/KafkaAssemblyOperatorMockIT.java
Patch:
@@ -193,8 +193,8 @@ private static <T> Map<T, T> map(T... pairs) {
     private KafkaAssemblyOperator createCluster(TestContext context) {
         ConfigMapOperator cmops = new ConfigMapOperator(vertx, mockClient);
         ServiceOperator svcops = new ServiceOperator(vertx, mockClient);
-        KafkaSetOperator ksops = new KafkaSetOperator(vertx, mockClient);
-        ZookeeperSetOperator zksops = new ZookeeperSetOperator(vertx, mockClient);
+        KafkaSetOperator ksops = new KafkaSetOperator(vertx, mockClient, 60_000L);
+        ZookeeperSetOperator zksops = new ZookeeperSetOperator(vertx, mockClient, 60_000L);
         DeploymentOperator depops = new DeploymentOperator(vertx, mockClient);
         PvcOperator pvcops = new PvcOperator(vertx, mockClient);
         KafkaAssemblyOperator kco = new KafkaAssemblyOperator(vertx, true, 2_000,

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/operator/resource/StatefulSetOperatorTest.java
Patch:
@@ -58,7 +58,7 @@ protected void mocker(KubernetesClient mockClient, MixedOperation op) {
 
     @Override
     protected StatefulSetOperator createResourceOperations(Vertx vertx, KubernetesClient mockClient) {
-        return new StatefulSetOperator(vertx, mockClient) {
+        return new StatefulSetOperator(vertx, mockClient, 60_000L) {
             @Override
             public Future<Void> readiness(String namespace, String name, long pollIntervalMs, long timeoutMs) {
                 return Future.succeededFuture();

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/KafkaSetOperator.java
Patch:
@@ -31,7 +31,7 @@ public KafkaSetOperator(Vertx vertx, KubernetesClient client) {
     @Override
     protected Future<ReconcileResult<Boolean>> internalPatch(String namespace, String name, StatefulSet current, StatefulSet desired) {
         StatefulSetDiff diff = new StatefulSetDiff(current, desired);
-        if (diff.changesVolumeClaimTemplates()) {
+        if (diff.changesVolumeClaimTemplates() || diff.changesSpecTemplateSpecInitContainers()) {
             log.warn("Changing Kafka storage type or size is not possible. The changes will be ignored.");
             diff = revertStorageChanges(current, desired);
         }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/StatefulSetOperator.java
Patch:
@@ -264,6 +264,8 @@ protected Future<ReconcileResult<P>> internalPatch(String namespace, String name
      */
     protected StatefulSetDiff revertStorageChanges(StatefulSet current, StatefulSet desired) {
         desired.getSpec().setVolumeClaimTemplates(current.getSpec().getVolumeClaimTemplates());
+        desired.getSpec().getTemplate().getSpec().setInitContainers(current.getSpec().getTemplate().getSpec().getInitContainers());
+        desired.getSpec().getTemplate().getSpec().setSecurityContext(current.getSpec().getTemplate().getSpec().getSecurityContext());
 
         if (current.getSpec().getVolumeClaimTemplates().isEmpty()) {
             // We are on ephemeral storage and changing to persistent

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/ZookeeperSetOperator.java
Patch:
@@ -31,7 +31,7 @@ public ZookeeperSetOperator(Vertx vertx, KubernetesClient client) {
     @Override
     protected Future<ReconcileResult<Boolean>> internalPatch(String namespace, String name, StatefulSet current, StatefulSet desired) {
         StatefulSetDiff diff = new StatefulSetDiff(current, desired);
-        if (diff.changesVolumeClaimTemplates()) {
+        if (diff.changesVolumeClaimTemplates() || diff.changesSpecTemplateSpecInitContainers()) {
             log.warn("Changing Zookeeper storage type or size is not possible. The changes will be ignored.");
             diff = revertStorageChanges(current, desired);
         }

File: topic-controller/src/test/java/io/strimzi/controller/topic/ControllerIT.java
Patch:
@@ -599,7 +599,7 @@ public void testReconcile(TestContext context) {
         }, timeout, "Expected the configmap to have been created by now");
 
         // trigger an immediate reconcile, while topic controller is dealing with configmap modification
-        session.reconcileTopics("periodic");
+        session.controller.reconcileAllTopics("periodic");
 
         // Wait for the topic to be created
         waitFor(context, () -> {

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/operator/resource/AbstractResourceOperatorTest.java
Patch:
@@ -96,6 +96,9 @@ public void createWhenExistsIsAPatch(TestContext context, boolean cascade) {
         Async async = context.async();
         Future<ReconcileResult<P>> fut = op.createOrUpdate(resource);
         fut.setHandler(ar -> {
+            if (!ar.succeeded()) {
+                ar.cause().printStackTrace();
+            }
             assertTrue(ar.succeeded());
             verify(mockResource).get();
             verify(mockResource).patch(any());

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/model/AbstractModel.java
Patch:
@@ -85,7 +85,7 @@ public abstract class AbstractModel {
     protected Storage storage;
 
     protected String mountPath;
-    protected static final String VOLUME_NAME = "data";
+    public static final String VOLUME_NAME = "data";
     protected String metricsConfigVolumeName;
     protected String metricsConfigMountPath;
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/KafkaSetOperator.java
Patch:
@@ -32,9 +32,8 @@ public KafkaSetOperator(Vertx vertx, KubernetesClient client) {
     protected Future<ReconcileResult<Boolean>> internalPatch(String namespace, String name, StatefulSet current, StatefulSet desired) {
         StatefulSetDiff diff = new StatefulSetDiff(current, desired);
         if (diff.changesVolumeClaimTemplates()) {
-            log.warn("Ignoring change to volumeClaim");
-            desired.getSpec().setVolumeClaimTemplates(current.getSpec().getVolumeClaimTemplates());
-            diff = new StatefulSetDiff(current, desired);
+            log.warn("Changing Kafka storage type or size is not possible. The changes will be ignored.");
+            diff = revertStorageChanges(current, desired);
         }
         if (diff.isEmpty()) {
             return Future.succeededFuture(ReconcileResult.noop());

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/ZookeeperSetOperator.java
Patch:
@@ -32,9 +32,8 @@ public ZookeeperSetOperator(Vertx vertx, KubernetesClient client) {
     protected Future<ReconcileResult<Boolean>> internalPatch(String namespace, String name, StatefulSet current, StatefulSet desired) {
         StatefulSetDiff diff = new StatefulSetDiff(current, desired);
         if (diff.changesVolumeClaimTemplates()) {
-            log.warn("Ignoring change to volumeClaim");
-            desired.getSpec().setVolumeClaimTemplates(current.getSpec().getVolumeClaimTemplates());
-            diff = new StatefulSetDiff(current, desired);
+            log.warn("Changing Zookeeper storage type or size is not possible. The changes will be ignored.");
+            diff = revertStorageChanges(current, desired);
         }
         if (diff.isEmpty()) {
             return Future.succeededFuture(ReconcileResult.noop());

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/AbstractReadyResourceOperator.java
Patch:
@@ -106,7 +106,7 @@ public boolean isReady(String namespace, String name) {
         R resourceOp = operation().inNamespace(namespace).withName(name);
         T resource = resourceOp.get();
         if (resource != null)   {
-            if (Readiness.isReadinessApplicable(resource)) {
+            if (Readiness.isReadinessApplicable(resource.getClass())) {
                 return Boolean.TRUE.equals(resourceOp.isReady());
             } else {
                 return true;

File: topic-controller/src/test/java/io/strimzi/controller/topic/ControllerTest.java
Patch:
@@ -107,7 +107,7 @@ public void testOnConfigMapAdded_invalidCm(TestContext context) {
             assertFailed(context, ar);
             context.assertTrue(ar.cause() instanceof InvalidConfigMapException);
             context.assertEquals("ConfigMap's 'data' section has invalid key 'config': Unexpected character ('n' (code 110)): was expecting double-quote to start field name\n" +
-                    " at [Source: 'config' key of 'data' section of ConfigMap 'invalid' in namespace 'null'; line: 1, column: 3]", ar.cause().getMessage());
+                    " at [Source: UNKNOWN; line: 1, column: 3]", ar.cause().getMessage());
             mockKafka.assertEmpty(context);
             mockTopicStore.assertEmpty(context);
             async.complete();

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/ClusterControllerTest.java
Patch:
@@ -88,7 +88,7 @@ private void startStop(TestContext context, String namespaces) {
         env.put(ClusterControllerConfig.STRIMZI_NAMESPACE, namespaces);
         env.put(ClusterControllerConfig.STRIMZI_CONFIGMAP_LABELS, STRIMZI_IO_KIND_CLUSTER);
         env.put(ClusterControllerConfig.STRIMZI_FULL_RECONCILIATION_INTERVAL_MS, "120000");
-        Main.run(vertx, client, true, env).setHandler(ar -> {
+        Main.run(vertx, client, true, ClusterControllerConfig.fromMap(env)).setHandler(ar -> {
             context.assertNull(ar.cause(), "Expected all verticles to start OK");
             async.complete();
         });

File: topic-controller/src/main/java/io/strimzi/controller/topic/TopicDiff.java
Patch:
@@ -118,7 +118,9 @@ private static class AddedConfigEntry extends Difference {
         private final String configValue;
 
         public AddedConfigEntry(String configKey, String configValue) {
-            assert configKey != null && configValue != null;
+            if (configKey == null || configValue == null) {
+                throw new IllegalArgumentException();
+            }
             this.configKey = configKey;
             this.configValue = configValue;
         }

File: topic-controller/src/main/java/io/strimzi/controller/topic/TopicName.java
Patch:
@@ -19,7 +19,9 @@ class TopicName {
     private final String name;
 
     public TopicName(String name) {
-        assert name != null && !name.isEmpty();
+        if (name == null || name.isEmpty()) {
+            throw new IllegalArgumentException();
+        }
         // TODO Shame we can't validate a topic name without relying on an internal class
         Topic.validate(name);
         this.name = name;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/BuildConfigOperator.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.controller.cluster.operations.resource;
+package io.strimzi.controller.cluster.operator.resource;
 
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.openshift.api.model.Build;
@@ -16,14 +16,14 @@
 /**
  * Operations for {@code BuildConfig}s.
  */
-public class BuildConfigOperations extends AbstractOperations<OpenShiftClient, BuildConfig, BuildConfigList, DoneableBuildConfig, BuildConfigResource<BuildConfig, DoneableBuildConfig, Void, Build>> {
+public class BuildConfigOperator extends AbstractResourceOperator<OpenShiftClient, BuildConfig, BuildConfigList, DoneableBuildConfig, BuildConfigResource<BuildConfig, DoneableBuildConfig, Void, Build>, Void> {
 
     /**
      * Constructor
      * @param vertx The Vertx instance
      * @param client The OpenShift client
      */
-    public BuildConfigOperations(Vertx vertx, OpenShiftClient client) {
+    public BuildConfigOperator(Vertx vertx, OpenShiftClient client) {
         super(vertx, client, "BuildConfig");
     }
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/ConfigMapOperator.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.controller.cluster.operations.resource;
+package io.strimzi.controller.cluster.operator.resource;
 
 import io.fabric8.kubernetes.api.model.ConfigMap;
 import io.fabric8.kubernetes.api.model.ConfigMapList;
@@ -15,13 +15,13 @@
 /**
  * Operations for {@code ConfigMap}s.
  */
-public class ConfigMapOperations extends AbstractOperations<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>> {
+public class ConfigMapOperator extends AbstractResourceOperator<KubernetesClient, ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>, Void> {
     /**
      * Constructor
      * @param vertx The Vertx instance
      * @param client The Kubernetes client
      */
-    public ConfigMapOperations(Vertx vertx, KubernetesClient client) {
+    public ConfigMapOperator(Vertx vertx, KubernetesClient client) {
         super(vertx, client, "ConfigMap");
     }
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/EndpointOperator.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.controller.cluster.operations.resource;
+package io.strimzi.controller.cluster.operator.resource;
 
 import io.fabric8.kubernetes.api.model.DoneableEndpoints;
 import io.fabric8.kubernetes.api.model.Endpoints;
@@ -15,13 +15,13 @@
 /**
  * Operations for {@code Endpoint}s.
  */
-public class EndpointOperations extends AbstractOperations<KubernetesClient, Endpoints, EndpointsList, DoneableEndpoints, Resource<Endpoints, DoneableEndpoints>> {
+class EndpointOperator extends AbstractReadyResourceOperator<KubernetesClient, Endpoints, EndpointsList, DoneableEndpoints, Resource<Endpoints, DoneableEndpoints>, Void> {
     /**
      * Constructor
      * @param vertx The Vertx instance
      * @param client The Kubernetes client
      */
-    public EndpointOperations(Vertx vertx, KubernetesClient client) {
+    EndpointOperator(Vertx vertx, KubernetesClient client) {
         super(vertx, client, "Endpoints");
     }
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/ImageStreamOperator.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.controller.cluster.operations.resource;
+package io.strimzi.controller.cluster.operator.resource;
 
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;
@@ -15,13 +15,13 @@
 /**
  * Operations for {@code ImageStream}s.
  */
-public class ImageStreamOperations extends AbstractOperations<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>> {
+public class ImageStreamOperator extends AbstractResourceOperator<OpenShiftClient, ImageStream, ImageStreamList, DoneableImageStream, Resource<ImageStream, DoneableImageStream>, Void> {
     /**
      * Constructor
      * @param vertx The Vertx instance
      * @param client The OpenShift client
      */
-    public ImageStreamOperations(Vertx vertx, OpenShiftClient client) {
+    public ImageStreamOperator(Vertx vertx, OpenShiftClient client) {
         super(vertx, client, "ImageStream");
     }
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operator/resource/TimeoutException.java
Patch:
@@ -2,7 +2,7 @@
  * Copyright 2017-2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
-package io.strimzi.controller.cluster.operations.resource;
+package io.strimzi.controller.cluster.operator.resource;
 
 /**
  * Thrown to indicate that timeout has been exceeded.

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/ClusterControllerConfigTest.java
Patch:
@@ -4,7 +4,7 @@
  */
 package io.strimzi.controller.cluster;
 
-import io.strimzi.controller.cluster.resources.Labels;
+import io.strimzi.controller.cluster.model.Labels;
 import org.junit.Test;
 
 import java.util.Collections;

File: common-test/src/main/java/io/strimzi/test/k8s/BaseKubeClient.java
Patch:
@@ -37,7 +37,7 @@ public abstract class BaseKubeClient<K extends BaseKubeClient<K>> implements Kub
     protected abstract String cmd();
 
     public K deleteByName(String resourceType, String resourceName) {
-        Exec.exec(cmd(), DELETE, resourceType, resourceName);
+        Exec.exec(namespacedCommand(DELETE, resourceType, resourceName));
         return (K) this;
     }
 

File: common-test/src/main/java/io/strimzi/test/k8s/KubeClient.java
Patch:
@@ -37,6 +37,9 @@ static KubeClient<?> findClient(KubeCluster cluster) {
 
     String namespace(String namespace);
 
+    /** Returns namespace for cluster */
+    String namespace();
+
     boolean clientAvailable();
 
     /** Creates the resources in the given files. */

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaCluster.java
Patch:
@@ -44,7 +44,9 @@ public class KafkaCluster extends AbstractCluster {
     private int transactionStateLogReplicationFactor = DEFAULT_KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR;
 
     // Configuration defaults
-    private static final String DEFAULT_IMAGE = "strimzi/kafka:latest";
+    private static final String DEFAULT_IMAGE =
+            System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_IMAGE", "strimzi/kafka:latest");
+
     private static final int DEFAULT_REPLICAS = 3;
     private static final int DEFAULT_HEALTHCHECK_DELAY = 15;
     private static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaConnectCluster.java
Patch:
@@ -41,7 +41,8 @@ public class KafkaConnectCluster extends AbstractCluster {
     protected int statusStorageReplicationFactor = DEFAULT_STATUS_STORAGE_REPLICATION_FACTOR;
 
     // Configuration defaults
-    protected static final String DEFAULT_IMAGE = "strimzi/kafka-connect:latest";
+    protected static final String DEFAULT_IMAGE =
+            System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_CONNECT_IMAGE", "strimzi/kafka-connect:latest");
     protected static final int DEFAULT_REPLICAS = 3;
     protected static final int DEFAULT_HEALTHCHECK_DELAY = 60;
     protected static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaConnectS2ICluster.java
Patch:
@@ -38,7 +38,8 @@ public class KafkaConnectS2ICluster extends KafkaConnectCluster {
     protected String tag = "latest";
 
     // Configuration defaults
-    protected static final String DEFAULT_IMAGE = "strimzi/kafka-connect-s2i:latest";
+    protected static final String DEFAULT_IMAGE =
+            System.getenv().getOrDefault("STRIMZI_DEFAULT_KAFKA_IMAGE", "strimzi/kafka-connect-s2i:latest");
 
     /**
      * Constructor

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/TopicController.java
Patch:
@@ -42,7 +42,8 @@ public class TopicController extends AbstractCluster {
     protected static final String HEALTHCHECK_PORT_NAME = "healthcheck";
 
     // Configuration defaults
-    protected static final String DEFAULT_IMAGE = "strimzi/topic-controller:latest";
+    protected static final String DEFAULT_IMAGE =
+            System.getenv().getOrDefault("STRIMZI_DEFAULT_TOPIC_CONTROLLER_IMAGE", "strimzi/topic-controller:latest");
     protected static final int DEFAULT_REPLICAS = 1;
     protected static final int DEFAULT_HEALTHCHECK_DELAY = 10;
     protected static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -41,7 +41,8 @@ public class ZookeeperCluster extends AbstractCluster {
     // N/A
 
     // Configuration defaults
-    private static final String DEFAULT_IMAGE = "strimzi/zookeeper:latest";
+    private static final String DEFAULT_IMAGE =
+            System.getenv().getOrDefault("STRIMZI_DEFAULT_ZOOKEEPER_IMAGE", "strimzi/zookeeper:latest");
     private static final int DEFAULT_REPLICAS = 3;
     private static final int DEFAULT_HEALTHCHECK_DELAY = 15;
     private static final int DEFAULT_HEALTHCHECK_TIMEOUT = 5;

File: topic-controller/src/main/java/io/strimzi/controller/topic/TopicsWatcher.java
Patch:
@@ -64,7 +64,7 @@ void start(Zk zk) {
                 return;
             }
             if (childResult.failed()) {
-                LOGGER.error("Error on zone {} children", TOPICS_ZNODE, childResult.cause());
+                LOGGER.error("Error on znode {} children", TOPICS_ZNODE, childResult.cause());
                 return;
             }
             List<String> result = childResult.result();
@@ -107,7 +107,7 @@ void start(Zk zk) {
 
         }).children(TOPICS_ZNODE, childResult -> {
             if (childResult.failed()) {
-                LOGGER.error("Error on zone {} children", TOPICS_ZNODE, childResult.cause());
+                LOGGER.error("Error on znode {} children", TOPICS_ZNODE, childResult.cause());
                 return;
             }
             List<String> result = childResult.result();

File: common-test/src/main/java/io/strimzi/test/ConnectCluster.java
Patch:
@@ -22,6 +22,7 @@
     String name();
     String bootstrapServers();
     int nodes() default 1;
+    CmData[] config() default {};
 
     @Target({ElementType.METHOD, ElementType.TYPE})
     @Retention(RetentionPolicy.RUNTIME)

File: common-test/src/main/java/io/strimzi/test/KafkaCluster.java
Patch:
@@ -23,7 +23,7 @@
     String name();
     int kafkaNodes() default 3;
     int zkNodes() default 1;
-
+    CmData[] config() default {};
 
     @Target({ElementType.METHOD, ElementType.TYPE})
     @Retention(RetentionPolicy.RUNTIME)

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/AbstractCluster.java
Patch:
@@ -574,7 +574,7 @@ protected ConfigMap patchConfigMap(ConfigMap cm, Map<String, String> data) {
      * @param value The value of the environment variable
      * @return The environment variable instance
      */
-    protected EnvVar buildEnvVar(String name, String value) {
+    protected static EnvVar buildEnvVar(String name, String value) {
         return new EnvVarBuilder().withName(name).withValue(value).build();
     }
 }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/TopicController.java
Patch:
@@ -52,7 +52,7 @@ public class TopicController extends AbstractCluster {
     protected static final int DEFAULT_BOOTSTRAP_SERVERS_PORT = 9092;
     protected static final String DEFAULT_FULL_RECONCILIATION_INTERVAL_MS = "900000";
     protected static final String DEFAULT_ZOOKEEPER_SESSION_TIMEOUT_MS = "20000";
-    protected static final int DEFAULT_TOPIC_METADATA_MAX_ATTEMPTS = 4;
+    protected static final int DEFAULT_TOPIC_METADATA_MAX_ATTEMPTS = 6;
 
     // Configuration keys
     public static final String KEY_CONFIG = "topic-controller-config";

File: topic-controller/src/main/java/io/strimzi/controller/topic/BackOff.java
Patch:
@@ -14,7 +14,7 @@ public class BackOff {
     private int attempt = 0;
 
     public BackOff() {
-        this(200L, 2, 4);
+        this(200L, 2, 6);
     }
 
     public BackOff(int maxAttempts) {

File: topic-controller/src/main/java/io/strimzi/controller/topic/Config.java
Patch:
@@ -125,7 +125,7 @@ private Value(String key, Type<? extends T> type, boolean required) {
     public static final Value<Long> REASSIGN_VERIFY_INTERVAL_MS = new Value<>(TC_REASSIGN_VERIFY_INTERVAL_MS, DURATION, "120000");
 
     /** The maximum number of retries for getting topic metadata from the Kafka cluster */
-    public static final Value<Integer> TOPIC_METADATA_MAX_ATTEMPTS = new Value<>(TC_TOPIC_METADATA_MAX_ATTEMPTS, INTEGER, "4");
+    public static final Value<Integer> TOPIC_METADATA_MAX_ATTEMPTS = new Value<>(TC_TOPIC_METADATA_MAX_ATTEMPTS, INTEGER, "6");
 
     static {
         Map<String, Value<?>> configValues = CONFIG_VALUES;

File: topic-controller/src/test/java/io/strimzi/controller/topic/BackOffTest.java
Patch:
@@ -19,13 +19,15 @@ public void testDefaultBackoff() {
         assertEquals(200L, b.delayMs());
         assertEquals(400L, b.delayMs());
         assertEquals(800L, b.delayMs());
+        assertEquals(1600L, b.delayMs());
+        assertEquals(3200L, b.delayMs());
         try {
             b.delayMs();
             fail("Should throw");
         } catch (MaxAttemptsExceededException e) {
 
         }
-        assertEquals(1400L, b.totalDelayMs());
+        assertEquals(6200L, b.totalDelayMs());
     }
 
     @Test

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/Main.java
Patch:
@@ -88,7 +88,6 @@ static CompositeFuture run(Vertx vertx, KubernetesClient client, boolean isOpenS
             Future<String> fut = Future.future();
             futures.add(fut);
             ClusterController controller = new ClusterController(namespace,
-                    config.getLabels(),
                     config.getReconciliationIntervalMs(),
                     client,
                     kafkaClusterOperations,

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/KafkaClusterOperations.java
Patch:
@@ -16,6 +16,7 @@
 import io.strimzi.controller.cluster.operations.resource.StatefulSetOperations;
 import io.strimzi.controller.cluster.resources.ClusterDiffResult;
 import io.strimzi.controller.cluster.resources.KafkaCluster;
+import io.strimzi.controller.cluster.resources.Labels;
 import io.strimzi.controller.cluster.resources.Storage;
 import io.strimzi.controller.cluster.resources.TopicController;
 import io.strimzi.controller.cluster.resources.ZookeeperCluster;
@@ -29,7 +30,6 @@
 
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Map;
 
 /**
  * <p>Cluster operations for a "Kafka" cluster. A KafkaClusterOperations is
@@ -711,8 +711,8 @@ public String clusterType() {
     }
 
     @Override
-    protected List<StatefulSet> getResources(String namespace, Map<String, String> kafkaLabels) {
-        return statefulSetOperations.list(namespace, kafkaLabels);
+    protected List<StatefulSet> getResources(String namespace, Labels selector) {
+        return statefulSetOperations.list(namespace, selector);
     }
 
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/KafkaConnectClusterOperations.java
Patch:
@@ -11,6 +11,7 @@
 import io.strimzi.controller.cluster.operations.resource.ServiceOperations;
 import io.strimzi.controller.cluster.resources.ClusterDiffResult;
 import io.strimzi.controller.cluster.resources.KafkaConnectCluster;
+import io.strimzi.controller.cluster.resources.Labels;
 import io.vertx.core.AsyncResult;
 import io.vertx.core.CompositeFuture;
 import io.vertx.core.Future;
@@ -21,7 +22,6 @@
 
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Map;
 
 /**
  * Cluster operations for a Kafka Connect cluster
@@ -207,7 +207,7 @@ public String clusterType() {
     }
 
     @Override
-    protected List<Deployment> getResources(String namespace, Map<String, String> kafkaLabels) {
-        return deploymentOperations.list(namespace, kafkaLabels);
+    protected List<Deployment> getResources(String namespace, Labels selector) {
+        return deploymentOperations.list(namespace, selector);
     }
 }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/KafkaConnectS2IClusterOperations.java
Patch:
@@ -15,6 +15,7 @@
 import io.strimzi.controller.cluster.operations.resource.ServiceOperations;
 import io.strimzi.controller.cluster.resources.ClusterDiffResult;
 import io.strimzi.controller.cluster.resources.KafkaConnectS2ICluster;
+import io.strimzi.controller.cluster.resources.Labels;
 import io.vertx.core.AsyncResult;
 import io.vertx.core.CompositeFuture;
 import io.vertx.core.Future;
@@ -25,7 +26,6 @@
 
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Map;
 
 /**
  * Cluster operations for a Kafka Connect cluster
@@ -271,8 +271,8 @@ public String clusterType() {
     }
 
     @Override
-    protected List<DeploymentConfig> getResources(String namespace, Map<String, String> kafkaLabels) {
-        return deploymentConfigOperations.list(namespace, kafkaLabels);
+    protected List<DeploymentConfig> getResources(String namespace, Labels selector) {
+        return deploymentConfigOperations.list(namespace, selector);
     }
 
 }

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/operations/resource/PodOperationsMockTest.java
Patch:
@@ -13,6 +13,7 @@
 import io.fabric8.kubernetes.client.dsl.PodResource;
 import io.fabric8.kubernetes.client.dsl.Resource;
 import io.fabric8.openshift.client.server.mock.OpenShiftServer;
+import io.strimzi.controller.cluster.resources.Labels;
 import io.vertx.core.Vertx;
 import io.vertx.ext.unit.Async;
 import io.vertx.ext.unit.TestContext;
@@ -22,7 +23,6 @@
 import java.util.stream.Collectors;
 
 import static java.util.Collections.emptyList;
-import static java.util.Collections.emptyMap;
 import static java.util.Collections.singletonList;
 import static org.mockito.Mockito.when;
 
@@ -37,12 +37,12 @@ public void testCreateReadUpdate(TestContext context) {
         KubernetesClient client = server.getKubernetesClient();
         PodOperations pr = new PodOperations(vertx, client);
 
-        context.assertEquals(emptyList(), pr.list(NAMESPACE, emptyMap()));
+        context.assertEquals(emptyList(), pr.list(NAMESPACE, Labels.EMPTY));
 
         Async async = context.async(1);
         pr.create(resource()).setHandler(createResult -> {
             context.assertTrue(createResult.succeeded());
-            context.assertEquals(singletonList(RESOURCE_NAME), pr.list(NAMESPACE, emptyMap()).stream()
+            context.assertEquals(singletonList(RESOURCE_NAME), pr.list(NAMESPACE, Labels.EMPTY).stream()
                         .map(p -> p.getMetadata().getName())
                         .collect(Collectors.toList()));
             //Pod got = pr.get(NAMESPACE, RESOURCE_NAME);

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/resource/StatefulSetOperations.java
Patch:
@@ -62,7 +62,7 @@ public void rollingUpdate(String namespace, String name, Handler<AsyncResult<Voi
                         Future fut = podOperations.delete(namespace, podName);
 
                         // TODO do this async
-                        while (!fut.isComplete() && !deleted.isComplete()) {
+                        while (!fut.isComplete() || !deleted.isComplete()) {
                             log.info("Waiting for pod {} to be deleted", podName);
                             Thread.sleep(1000);
                         }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/AbstractCluster.java
Patch:
@@ -82,7 +82,7 @@ public abstract class AbstractCluster {
 
     protected Storage storage;
 
-    protected String mounthPath;
+    protected String mountPath;
     protected String volumeName;
     protected String metricsConfigVolumeName;
     protected String metricsConfigMountPath;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaCluster.java
Patch:
@@ -92,8 +92,8 @@ private KafkaCluster(String namespace, String cluster) {
         this.healthCheckInitialDelay = DEFAULT_HEALTHCHECK_DELAY;
         this.isMetricsEnabled = DEFAULT_KAFKA_METRICS_ENABLED;
 
-        this.mounthPath = "/var/lib/kafka";
-        this.volumeName = "kafka-storage";
+        this.mountPath = "/var/lib/kafka";
+        this.volumeName = "data";
         this.metricsConfigVolumeName = "kafka-metrics-config";
         this.metricsConfigMountPath = "/opt/prometheus/config/";
     }
@@ -422,7 +422,7 @@ private List<PersistentVolumeClaim> getVolumeClaims() {
 
     private List<VolumeMount> getVolumeMounts() {
         List<VolumeMount> volumeMountList = new ArrayList<>();
-        volumeMountList.add(createVolumeMount(volumeName, mounthPath));
+        volumeMountList.add(createVolumeMount(volumeName, mountPath));
         if (isMetricsEnabled) {
             volumeMountList.add(createVolumeMount(metricsConfigVolumeName, metricsConfigMountPath));
         }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -95,8 +95,8 @@ private ZookeeperCluster(String namespace, String cluster) {
         this.healthCheckInitialDelay = DEFAULT_HEALTHCHECK_DELAY;
         this.isMetricsEnabled = DEFAULT_ZOOKEEPER_METRICS_ENABLED;
 
-        this.mounthPath = "/var/lib/zookeeper";
-        this.volumeName = "zookeeper-storage";
+        this.mountPath = "/var/lib/zookeeper";
+        this.volumeName = "data";
         this.metricsConfigVolumeName = "zookeeper-metrics-config";
         this.metricsConfigMountPath = "/opt/prometheus/config/";
     }
@@ -372,7 +372,7 @@ private List<PersistentVolumeClaim> getVolumeClaims() {
 
     private List<VolumeMount> getVolumeMounts() {
         List<VolumeMount> volumeMountList = new ArrayList<>();
-        volumeMountList.add(createVolumeMount(volumeName, mounthPath));
+        volumeMountList.add(createVolumeMount(volumeName, mountPath));
         if (isMetricsEnabled) {
             volumeMountList.add(createVolumeMount(metricsConfigVolumeName, metricsConfigMountPath));
         }

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/operations/cluster/KafkaClusterOperationsTest.java
Patch:
@@ -322,10 +322,10 @@ private void deleteCluster(TestContext context, ConfigMap clusterCm) {
             // PvcOperations only used for deletion
             Set<String> expectedPvcDeletions = new HashSet<>();
             for (int i = 0; deleteClaim && i < kafkaCluster.getReplicas(); i++) {
-                expectedPvcDeletions.add("kafka-storage-" + clusterCmName + "-kafka-" + i);
+                expectedPvcDeletions.add("data-" + clusterCmName + "-kafka-" + i);
             }
             for (int i = 0; deleteClaim && i < zookeeperCluster.getReplicas(); i++) {
-                expectedPvcDeletions.add("zookeeper-storage-" + clusterCmName + "-zookeeper-" + i);
+                expectedPvcDeletions.add("data-" + clusterCmName + "-zookeeper-" + i);
             }
             context.assertEquals(expectedPvcDeletions, captured(pvcCaptor));
 

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/resources/KafkaClusterTest.java
Patch:
@@ -208,7 +208,7 @@ public void testPodNames() {
     public void testPvcNames() {
 
         for (int i = 0; i < replicas; i++) {
-            assertEquals("kafka-storage-" + KafkaCluster.kafkaClusterName(cluster) + "-" + i, kc.getPersistentVolumeClaimName(i));
+            assertEquals(kc.volumeName + "-" + KafkaCluster.kafkaClusterName(cluster) + "-" + i, kc.getPersistentVolumeClaimName(i));
         }
     }
 

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/ClusterControllerTest.java
Patch:
@@ -88,7 +88,7 @@ private void startStop(TestContext context, String namespaces) {
         env.put(ClusterControllerConfig.STRIMZI_NAMESPACE, namespaces);
         env.put(ClusterControllerConfig.STRIMZI_CONFIGMAP_LABELS, STRIMZI_IO_KIND_CLUSTER);
         env.put(ClusterControllerConfig.STRIMZI_FULL_RECONCILIATION_INTERVAL_MS, "120000");
-        Main.run(vertx, client, env).setHandler(ar -> {
+        Main.run(vertx, client, true, env).setHandler(ar -> {
             context.assertNull(ar.cause(), "Expected all verticles to start OK");
             async.complete();
         });

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/ClusterControllerTest.java
Patch:
@@ -87,7 +87,7 @@ private void startStop(TestContext context, String namespaces) {
         Map<String, String> env = new HashMap<>();
         env.put(ClusterControllerConfig.STRIMZI_NAMESPACE, namespaces);
         env.put(ClusterControllerConfig.STRIMZI_CONFIGMAP_LABELS, STRIMZI_IO_KIND_CLUSTER);
-        env.put(ClusterControllerConfig.STRIMZI_FULL_RECONCILIATION_INTERVAL, "120000");
+        env.put(ClusterControllerConfig.STRIMZI_FULL_RECONCILIATION_INTERVAL_MS, "120000");
         Main.run(vertx, client, env).setHandler(ar -> {
             context.assertNull(ar.cause(), "Expected all verticles to start OK");
             async.complete();

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/resource/AbstractOperations.java
Patch:
@@ -176,14 +176,15 @@ public List<T> list(String namespace, Map<String, String> labels) {
     }
 
     /**
-     * Waits until resource is in the Ready state
+     * Returns a future that completes when the resource identified by the given {@code namespace} and {@code name}
+     * is ready.
      *
      * @param namespace The namespace.
      * @param name The resource name.
      * @param pollIntervalMs The poll interval in milliseconds.
      * @param timeoutMs The timeout, in milliseconds.
      */
-    public Future<Void> waitUntilReady(String namespace, String name, long pollIntervalMs, long timeoutMs) {
+    public Future<Void> readiness(String namespace, String name, long pollIntervalMs, long timeoutMs) {
         Future<Void> fut = Future.future();
         log.info("Waiting for {} resource {} in namespace {} to get ready", resourceKind, name, namespace);
         long deadline = System.currentTimeMillis() + timeoutMs;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/KafkaClusterOperations.java
Patch:
@@ -614,12 +614,12 @@ public void update(String namespace, String name, Handler<AsyncResult<Void>> han
 
     @Override
     public void reconcileAll(String namespace, Map<String, String> labels) {
-        reconcileAll(namespace, labels, CLUSTER_TYPE_KAFKA);
+        reconcileAll(CLUSTER_TYPE_KAFKA, namespace, labels);
     }
 
     @Override
     public void reconcile(String namespace, String name) {
-        reconcile(namespace, name, CLUSTER_TYPE_KAFKA);
+        reconcile(CLUSTER_TYPE_KAFKA, namespace, name);
     }
 
     @Override

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/KafkaConnectClusterOperations.java
Patch:
@@ -177,12 +177,12 @@ protected void update(String namespace, String name, Handler<AsyncResult<Void>>
 
     @Override
     public void reconcileAll(String namespace, Map<String, String> labels) {
-        reconcileAll(namespace, labels, CLUSTER_TYPE_CONNECT);
+        reconcileAll(CLUSTER_TYPE_CONNECT, namespace, labels);
     }
 
     @Override
     public void reconcile(String namespace, String name) {
-        reconcile(namespace, name, CLUSTER_TYPE_CONNECT);
+        reconcile(CLUSTER_TYPE_CONNECT, namespace, name);
     }
 
     @Override

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/KafkaConnectS2IClusterOperations.java
Patch:
@@ -237,12 +237,12 @@ private Future<Void> scaleUp(KafkaConnectS2ICluster connect, String namespace, C
 
     @Override
     public void reconcileAll(String namespace, Map<String, String> labels) {
-        reconcileAll(namespace, labels, CLUSTER_TYPE_CONNECT_S2I);
+        reconcileAll(CLUSTER_TYPE_CONNECT_S2I, namespace, labels);
     }
 
     @Override
     public void reconcile(String namespace, String name) {
-        reconcile(namespace, name, CLUSTER_TYPE_CONNECT_S2I);
+        reconcile(CLUSTER_TYPE_CONNECT_S2I, namespace, name);
     }
 
     @Override

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaConnectS2ICluster.java
Patch:
@@ -426,6 +426,7 @@ public static String getSourceImageStreamName(String baseName) {
         return baseName + "-source";
     }
 
+    @Override
     protected void setImage(String image) {
         this.sourceImageBaseName = image.substring(0, image.lastIndexOf(":"));
         this.sourceImageTag = image.substring(image.lastIndexOf(":") + 1);

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -320,6 +320,7 @@ public StatefulSet patchStatefulSet(StatefulSet statefulSet) {
                 annotations);
     }
 
+    @Override
     protected List<EnvVar> getEnvVars() {
         List<EnvVar> varList = new ArrayList<>();
         varList.add(new EnvVarBuilder().withName(KEY_ZOOKEEPER_NODE_COUNT).withValue(Integer.toString(replicas)).build());
@@ -379,6 +380,7 @@ private List<VolumeMount> getVolumeMounts() {
         return volumeMountList;
     }
 
+    @Override
     protected void setLabels(Map<String, String> labels) {
         Map<String, String> newLabels = new HashMap<>(labels);
 

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/operations/resource/ResourceOperationsMockTest.java
Patch:
@@ -370,7 +370,7 @@ public void waitUntilReadySuccessful(TestContext context) {
         AbstractOperations<C, T, L, D, R> op = createResourceOperations(vertx, mockClient);
 
         Async async = context.async();
-        op.waitUntilReady(NAMESPACE, RESOURCE_NAME, 20, 100).setHandler(ar -> {
+        op.waitUntilReady(NAMESPACE, RESOURCE_NAME, 20, 5_000).setHandler(ar -> {
             assertTrue(ar.succeeded());
             verify(mockResource).get();
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/TopicController.java
Patch:
@@ -150,9 +150,9 @@ protected static String defaultBootstrapServers(String cluster) {
     }
 
     protected static String defaultTopicConfigMapLabels(String cluster) {
-        String clusterLabel = String.format("%s=%s", ClusterController.STRIMZI_CLUSTER_LABEL, cluster);
-        String topicLabel = String.format("%s=%s", ClusterController.STRIMZI_KIND_LABEL, TopicController.KIND);
-        return clusterLabel + "," + topicLabel;
+        return String.format("%s=%s,%s=%s",
+                ClusterController.STRIMZI_CLUSTER_LABEL, cluster,
+                ClusterController.STRIMZI_KIND_LABEL, TopicController.KIND);
     }
 
     /**

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaCluster.java
Patch:
@@ -34,7 +34,7 @@ public class KafkaCluster extends AbstractCluster {
     protected static final int REPLICATION_PORT = 9091;
     protected static final String REPLICATION_PORT_NAME = "replication";
 
-    protected static final String NAME_SUFFIX = "-kafka";
+    private static final String NAME_SUFFIX = "-kafka";
     private static final String HEADLESS_NAME_SUFFIX = NAME_SUFFIX + "-headless";
     private static final String METRICS_CONFIG_SUFFIX = NAME_SUFFIX + "-metrics-config";
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/TopicController.java
Patch:
@@ -84,11 +84,11 @@ public static String topicControllerName(String cluster) {
     }
 
     protected static String defaultZookeeperConnect(String cluster) {
-        return cluster + ZookeeperCluster.NAME_SUFFIX + ":" + DEFAULT_ZOOKEEPER_PORT;
+        return ZookeeperCluster.zookeeperClusterName(cluster) + ":" + DEFAULT_ZOOKEEPER_PORT;
     }
 
     protected static String defaultBootstrapServers(String cluster) {
-        return cluster + KafkaCluster.NAME_SUFFIX + ":" + DEFAULT_BOOTSTRAP_SERVERS_PORT;
+        return KafkaCluster.kafkaClusterName(cluster) + ":" + DEFAULT_BOOTSTRAP_SERVERS_PORT;
     }
 
     public void setConfig(TopicControllerConfig config) {

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -35,7 +35,7 @@ public class ZookeeperCluster extends AbstractCluster {
     private static final int LEADER_ELECTION_PORT = 3888;
     private static final String LEADER_ELECTION_PORT_NAME = "leader-election";
 
-    protected static final String NAME_SUFFIX = "-zookeeper";
+    private static final String NAME_SUFFIX = "-zookeeper";
     private static final String HEADLESS_NAME_SUFFIX = NAME_SUFFIX + "-headless";
     private static final String METRICS_CONFIG_SUFFIX = NAME_SUFFIX + "-metrics-config";
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/ClusterController.java
Patch:
@@ -37,7 +37,7 @@ public class ClusterController extends AbstractVerticle {
     public static final String STRIMZI_TYPE_LABEL = STRIMZI_DOMAIN + "/type";
     public static final String STRIMZI_CLUSTER_LABEL = STRIMZI_DOMAIN + "/cluster";
     public static final String STRIMZI_NAME_LABEL = STRIMZI_DOMAIN + "/name";
-    public static final String STRMIZI_CONTROLLER_SERVICE_ACCOUNT = "strimzi-cluster-controller";
+    public static final String STRIMZI_CLUSTER_CONTROLLER_SERVICE_ACCOUNT = "strimzi-cluster-controller";
 
     private static final int HEALTH_SERVER_PORT = 8080;
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/AbstractCluster.java
Patch:
@@ -217,6 +217,9 @@ public String getImage() {
         return this.image;
     }
 
+    /**
+     * @return the service account used by the deployed cluster for Kubernetes/OpenShift API operations
+     */
     protected String getServiceAccountName() {
         return null;
     }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/ClusterController.java
Patch:
@@ -37,6 +37,7 @@ public class ClusterController extends AbstractVerticle {
     public static final String STRIMZI_TYPE_LABEL = STRIMZI_DOMAIN + "/type";
     public static final String STRIMZI_CLUSTER_LABEL = STRIMZI_DOMAIN + "/cluster";
     public static final String STRIMZI_NAME_LABEL = STRIMZI_DOMAIN + "/name";
+    public static final String STRMIZI_CONTROLLER_SERVICE_ACCOUNT = "strimzi-cluster-controller";
 
     private static final int HEALTH_SERVER_PORT = 8080;
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaCluster.java
Patch:
@@ -34,7 +34,7 @@ public class KafkaCluster extends AbstractCluster {
     protected static final int REPLICATION_PORT = 9091;
     protected static final String REPLICATION_PORT_NAME = "replication";
 
-    private static final String NAME_SUFFIX = "-kafka";
+    protected static final String NAME_SUFFIX = "-kafka";
     private static final String HEADLESS_NAME_SUFFIX = NAME_SUFFIX + "-headless";
     private static final String METRICS_CONFIG_SUFFIX = NAME_SUFFIX + "-metrics-config";
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -35,7 +35,7 @@ public class ZookeeperCluster extends AbstractCluster {
     private static final int LEADER_ELECTION_PORT = 3888;
     private static final String LEADER_ELECTION_PORT_NAME = "leader-election";
 
-    private static final String NAME_SUFFIX = "-zookeeper";
+    protected static final String NAME_SUFFIX = "-zookeeper";
     private static final String HEADLESS_NAME_SUFFIX = NAME_SUFFIX + "-headless";
     private static final String METRICS_CONFIG_SUFFIX = NAME_SUFFIX + "-metrics-config";
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/KafkaClusterOperations.java
Patch:
@@ -599,6 +599,8 @@ public void update(String namespace, String name, Handler<AsyncResult<Void>> han
                         ClusterOperation<TopicController> clusterOp = updateTopicController.getCluster(namespace, name);
                         if (clusterOp.cluster() != null) {
                             execute(CLUSTER_TYPE_TOPIC_CONTROLLER, OP_UPDATE, namespace, name, updateTopicController, handler);
+                        } else {
+                            handler.handle(kafkaDone);
                         }
                     }
                 });

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/AbstractClusterOperations.java
Patch:
@@ -25,14 +25,14 @@
 import java.util.stream.Collectors;
 
 /**
- * <p>Abstract cluster creation, update, read, delection, etc, for a generic cluster type {@code C}.
+ * <p>Abstract cluster creation, update, read, deletion, etc, for a generic cluster type {@code C}.
  * This class applies the "template method" pattern, first obtaining the desired cluster configuration
  * ({@link CompositeOperation#getCluster(String, String)}),
  * then creating resources to match ({@link CompositeOperation#composite(String, ClusterOperation)}.</p>
  *
  * <p>This class manages a per-cluster-type and per-cluster locking strategy so only one operation per cluster
  * can proceed at once.</p>
- * @param <C> The type of Kubernetes client
+ * @param <C> The type of cluster.
  * @param <R> The type of resource from which the cluster state can be recovered
  */
 public abstract class AbstractClusterOperations<C extends AbstractCluster,

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/AbstractClusterOperations.java
Patch:
@@ -279,7 +279,7 @@ protected String nameFromLabels(R resource) {
     protected void reconcile(String namespace, Map<String, String> labels, String type) {
         log.info("Reconciling {} clusters ...", clusterDescription);
 
-        Map<String, String> kafkaLabels = new HashMap(labels);
+        Map<String, String> kafkaLabels = new HashMap<>(labels);
         kafkaLabels.put(ClusterController.STRIMZI_TYPE_LABEL, type);
 
         List<ConfigMap> cms = configMapOperations.list(namespace, kafkaLabels);

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/resource/AbstractOperations.java
Patch:
@@ -54,6 +54,7 @@ public AbstractOperations(Vertx vertx, C client, String resourceKind) {
      * If the resource with that name already exists the future completes successfully.
      * @param resource The resource to create.
      */
+    @SuppressWarnings("unchecked")
     public Future<Void> create(T resource) {
         Future<Void> fut = Future.future();
         vertx.createSharedWorkerExecutor("kubernetes-ops-pool").executeBlocking(
@@ -89,7 +90,7 @@ public Future<Void> create(T resource) {
      * @param name The name of the resource to delete.
      */
     public Future<Void> delete(String namespace, String name) {
-        Future fut = Future.future();
+        Future<Void> fut = Future.future();
         vertx.createSharedWorkerExecutor("kubernetes-ops-pool").executeBlocking(
             future -> {
                 if (operation().inNamespace(namespace).withName(name).get() != null) {
@@ -168,6 +169,7 @@ public T get(String namespace, String name) {
      * @param labels The labels.
      * @return A list of matching resources.
      */
+    @SuppressWarnings("unchecked")
     public List<T> list(String namespace, Map<String, String> labels) {
         return operation().inNamespace(namespace).withLabels(labels).list().getItems();
     }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/AbstractCluster.java
Patch:
@@ -347,7 +347,7 @@ protected Service createService(String type, List<ServicePort> ports) {
     }
 
     protected Service createHeadlessService(String name, List<ServicePort> ports) {
-        return createHeadlessService(name, ports, Collections.EMPTY_MAP);
+        return createHeadlessService(name, ports, Collections.emptyMap());
     }
 
     protected Service createHeadlessService(String name, List<ServicePort> ports, Map<String, String> annotations) {

File: topic-controller/src/main/java/io/strimzi/controller/topic/Session.java
Patch:
@@ -47,7 +47,7 @@ public Session(KubernetesClient kubeClient, Config config) {
         this.kubeClient = kubeClient;
         this.config = config;
         StringBuilder sb = new StringBuilder(System.lineSeparator());
-        for (Config.Value v: config.keys()) {
+        for (Config.Value<?> v: Config.keys()) {
             sb.append("\t").append(v.key).append(": ").append(config.get(v)).append(System.lineSeparator());
         }
         LOGGER.info("Using config:{}", sb.toString());
@@ -56,6 +56,7 @@ public Session(KubernetesClient kubeClient, Config config) {
     /**
      * Stop the controller.
      */
+    @Override
     public void stop(Future<Void> stopFuture) throws Exception {
         this.stopped = true;
         vertx.executeBlocking(blockingResult -> {

File: topic-controller/src/main/java/io/strimzi/controller/topic/TopicDiff.java
Patch:
@@ -325,11 +325,11 @@ public Topic apply(Topic topic) {
      * Return true if this TopicDiff conflicts with the given other TopicDiff
      */
     public String conflict(TopicDiff other) {
-        Set<String> intersection = new HashSet(this.differences.keySet());
+        Set<String> intersection = new HashSet<>(this.differences.keySet());
         intersection.retainAll(other.differences.keySet());
         // they could still be OK if they're applying the _same_ differences
         StringBuilder sb = new StringBuilder();
-        for (Object address : intersection) {
+        for (String address : intersection) {
             Difference difference = this.differences.get(address);
             Difference otherDifference = other.differences.get(address);
             if (!difference.equals(otherDifference)) {
@@ -355,7 +355,7 @@ public TopicDiff merge(TopicDiff other) {
         if (confict != null) {
             throw new IllegalArgumentException("Conflict: " + confict);
         }
-        Map<String, Difference> union = new HashMap(this.differences);
+        Map<String, Difference> union = new HashMap<>(this.differences);
         union.putAll(other.differences);
         return new TopicDiff(union);
     }

File: topic-controller/src/main/java/io/strimzi/controller/topic/TopicsWatcher.java
Patch:
@@ -68,9 +68,9 @@ void start(Zk zk) {
             }
             List<String> result = childResult.result();
             LOGGER.debug("znode {} now has children {}, previous children {}", TOPICS_ZNODE, result, this.children);
-            Set<String> deleted = new HashSet(this.children);
+            Set<String> deleted = new HashSet<>(this.children);
             deleted.removeAll(result);
-            Set<String> created = new HashSet(result);
+            Set<String> created = new HashSet<>(result);
             created.removeAll(this.children);
             this.children = result;
 

File: topic-controller/src/main/java/io/strimzi/controller/topic/zk/AclBuilder.java
Patch:
@@ -180,7 +180,7 @@ public List<ACL> build() {
         if (auth != null) {
             result.add(auth);
         }
-        for (Map<String, ACL> m : new Map[]{digests, hosts, ips}) {
+        for (Map<String, ACL> m : asList(digests, hosts, ips)) {
             if (m != null) {
                 result.addAll(m.values());
             }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/resource/EndpointOperations.java
Patch:
@@ -5,11 +5,8 @@
 package io.strimzi.controller.cluster.operations.resource;
 
 import io.fabric8.kubernetes.api.model.DoneableEndpoints;
-import io.fabric8.kubernetes.api.model.DoneableService;
 import io.fabric8.kubernetes.api.model.Endpoints;
 import io.fabric8.kubernetes.api.model.EndpointsList;
-import io.fabric8.kubernetes.api.model.Service;
-import io.fabric8.kubernetes.api.model.ServiceList;
 import io.fabric8.kubernetes.client.KubernetesClient;
 import io.fabric8.kubernetes.client.dsl.MixedOperation;
 import io.fabric8.kubernetes.client.dsl.Resource;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/resource/PvcOperations.java
Patch:
@@ -33,11 +33,11 @@ protected MixedOperation<PersistentVolumeClaim, PersistentVolumeClaimList, Donea
 
     @Override
     public Future<Void> create(PersistentVolumeClaim resource) {
-        throw new UnsupportedOperationException();// should never happen
+        throw new UnsupportedOperationException(); // should never happen
     }
 
     @Override
     public Future<Void> patch(String namespace, String name, PersistentVolumeClaim patch) {
-        throw new UnsupportedOperationException();// should never happen
+        throw new UnsupportedOperationException(); // should never happen
     }
 }

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/operations/resource/DeploymentConfigOperationsMockTest.java
Patch:
@@ -16,7 +16,9 @@
 
 import static org.mockito.Mockito.when;
 
-public class DeploymentConfigOperationsMockTest extends ResourceOperationsMockTest<OpenShiftClient,DeploymentConfig,DeploymentConfigList,DoneableDeploymentConfig,DeployableScalableResource<DeploymentConfig,DoneableDeploymentConfig>> {
+public class DeploymentConfigOperationsMockTest extends ResourceOperationsMockTest<OpenShiftClient, DeploymentConfig,
+        DeploymentConfigList, DoneableDeploymentConfig,
+        DeployableScalableResource<DeploymentConfig, DoneableDeploymentConfig>> {
 
     @Override
     protected Class<OpenShiftClient> clientType() {

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/resources/KafkaClusterTest.java
Patch:
@@ -127,7 +127,7 @@ public void testDiffNoDiffs() {
     @Test
     public void testDiffMetrics() {
         KafkaCluster other = KafkaCluster.fromConfigMap(ResourceUtils.createKafkaClusterConfigMap(namespace, cluster,
-                replicas, image, healthDelay, healthTimeout,"{\"something\":\"different\"}"));
+                replicas, image, healthDelay, healthTimeout, "{\"something\":\"different\"}"));
         ClusterDiffResult diff = kc.diff(other.generateMetricsConfigMap(), other.generateStatefulSet(true));
         assertFalse(diff.isDifferent());
         assertFalse(diff.isScaleDown());
@@ -175,7 +175,7 @@ public void testDiffImage() {
     @Test
     public void testDiffHealthDelay() {
         KafkaCluster other = KafkaCluster.fromConfigMap(ResourceUtils.createKafkaClusterConfigMap(namespace, cluster,
-                replicas, image, healthDelay+1, healthTimeout, metricsCmJson));
+                replicas, image, healthDelay + 1, healthTimeout, metricsCmJson));
         ClusterDiffResult diff = kc.diff(other.generateMetricsConfigMap(), other.generateStatefulSet(true));
         assertTrue(diff.isDifferent());
         assertFalse(diff.isScaleDown());
@@ -187,7 +187,7 @@ public void testDiffHealthDelay() {
     @Test
     public void testDiffHealthTimeout() {
         KafkaCluster other = KafkaCluster.fromConfigMap(ResourceUtils.createKafkaClusterConfigMap(namespace, cluster,
-                replicas, image, healthDelay, healthTimeout+1, metricsCmJson));
+                replicas, image, healthDelay, healthTimeout + 1, metricsCmJson));
         ClusterDiffResult diff = kc.diff(other.generateMetricsConfigMap(), other.generateStatefulSet(true));
         assertTrue(diff.isDifferent());
         assertFalse(diff.isScaleDown());

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/resources/KafkaConnectClusterTest.java
Patch:
@@ -148,7 +148,7 @@ public void testDiffNoDiffs() {
     @Test
     public void testDiffScaleUp() {
         Deployment dep = kc.generateDeployment();
-        dep.getSpec().setReplicas(dep.getSpec().getReplicas()-1);
+        dep.getSpec().setReplicas(dep.getSpec().getReplicas() - 1);
         ClusterDiffResult diff = kc.diff(dep);
 
         assertFalse(diff.isDifferent());
@@ -161,7 +161,7 @@ public void testDiffScaleUp() {
     @Test
     public void testDiffScaleDown() {
         Deployment dep = kc.generateDeployment();
-        dep.getSpec().setReplicas(dep.getSpec().getReplicas()+1);
+        dep.getSpec().setReplicas(dep.getSpec().getReplicas() + 1);
         ClusterDiffResult diff = kc.diff(dep);
 
         assertFalse(diff.isDifferent());

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/resources/KafkaConnectS2IClusterTest.java
Patch:
@@ -162,7 +162,7 @@ public void testDiffNoDiffs() {
     @Test
     public void testDiffScaleUp() {
         DeploymentConfig dep = kc.generateDeploymentConfig();
-        dep.getSpec().setReplicas(dep.getSpec().getReplicas()-1);
+        dep.getSpec().setReplicas(dep.getSpec().getReplicas() - 1);
         ClusterDiffResult diff = kc.diff(dep, kc.generateSourceImageStream(), kc.generateTargetImageStream(), kc.generateBuildConfig());
 
         assertFalse(diff.isDifferent());
@@ -175,7 +175,7 @@ public void testDiffScaleUp() {
     @Test
     public void testDiffScaleDown() {
         DeploymentConfig dep = kc.generateDeploymentConfig();
-        dep.getSpec().setReplicas(dep.getSpec().getReplicas()+1);
+        dep.getSpec().setReplicas(dep.getSpec().getReplicas() + 1);
         ClusterDiffResult diff = kc.diff(dep, kc.generateSourceImageStream(), kc.generateTargetImageStream(), kc.generateBuildConfig());
 
         assertFalse(diff.isDifferent());

File: topic-controller/src/main/java/io/strimzi/controller/topic/Main.java
Patch:
@@ -19,7 +19,7 @@
  */
 public class Main {
 
-    private final static Logger logger = LoggerFactory.getLogger(Main.class);
+    private final static Logger LOGGER = LoggerFactory.getLogger(Main.class);
 
     public static void main(String[] args) {
         Main main = new Main();
@@ -39,9 +39,9 @@ private void deploy(Config config) {
         Session session = new Session(kubeClient, config);
         vertx.deployVerticle(session, ar -> {
             if (ar.succeeded()) {
-                logger.info("Session deployed");
+                LOGGER.info("Session deployed");
             } else {
-                logger.error("Error deploying Session", ar.cause());
+                LOGGER.error("Error deploying Session", ar.cause());
             }
         });
     }

File: topic-controller/src/main/java/io/strimzi/controller/topic/TopicMetadataHandler.java
Patch:
@@ -73,7 +73,7 @@ protected void retry() {
             vertx.runOnContext(timerId -> kafka.topicMetadata(topicName, this));
         } else {
             vertx.setTimer(TimeUnit.MILLISECONDS.convert(delay, TimeUnit.MILLISECONDS),
-                    timerId -> kafka.topicMetadata(topicName, this));
+                timerId -> kafka.topicMetadata(topicName, this));
         }
     }
 

File: topic-controller/src/main/java/io/strimzi/controller/topic/ZkWatcher.java
Patch:
@@ -23,7 +23,7 @@ public abstract class ZkWatcher {
     private volatile ZkWatcherState state = ZkWatcherState.NOT_STARTED;
     private volatile Zk zk;
 
-    private final ConcurrentHashMap<String,Boolean> children = new ConcurrentHashMap<>();
+    private final ConcurrentHashMap<String, Boolean> children = new ConcurrentHashMap<>();
     private final String rootZNode;
 
     /**

File: topic-controller/src/main/java/io/strimzi/controller/topic/zk/AclBuilder.java
Patch:
@@ -117,7 +117,7 @@ public AclBuilder addDigest(String username, String password, Permission... perm
             a = new ACL();
             digests.put(username, a);
         }
-        a.setId(new Id("digest", username+":"+password));
+        a.setId(new Id("digest", username + ":" + password));
         a.setPerms(Permission.encode(permissions));
         return this;
     }
@@ -151,7 +151,7 @@ private Map<String, ACL> getHosts() {
      */
     public AclBuilder addIp(String address, int bits, Permission... permissions) {
         Map<String, ACL> ips = getIps();
-        String cidr = address+"/"+bits;
+        String cidr = address + "/" + bits;
         ACL a = ips.get(cidr);
         if (a == null) {
             a = new ACL();

File: topic-controller/src/test/java/io/strimzi/controller/topic/ControllerAssignedKafkaImplTest.java
Patch:
@@ -19,7 +19,6 @@
 
 import static java.util.Arrays.asList;
 import static java.util.Collections.emptyMap;
-import static java.util.Collections.singletonMap;
 
 @RunWith(VertxUnitRunner.class)
 public class ControllerAssignedKafkaImplTest {
@@ -56,7 +55,7 @@ static List<String> executeStarted() {
         }
 
         static List<String> verifyInProgress(String... partitions) {
-            List<String> result = new ArrayList(2*partitions.length);
+            List<String> result = new ArrayList(2 * partitions.length);
             for (String partition: partitions) {
                 result.add("--verify-in-progress");
                 result.add(partition);
@@ -65,7 +64,7 @@ static List<String> verifyInProgress(String... partitions) {
         }
 
         static List<String> verifySuccess(String... partitions) {
-            List<String> result = new ArrayList(2*partitions.length);
+            List<String> result = new ArrayList(2 * partitions.length);
             for (String partition: partitions) {
                 result.add("--verify-success");
                 result.add(partition);

File: topic-controller/src/test/java/io/strimzi/controller/topic/EmbeddedZooKeeper.java
Patch:
@@ -69,7 +69,7 @@ public int getZkPort() {
 
     public String getZkConnectString() {
         InetSocketAddress addr = factory.getLocalAddress();
-        return addr.getAddress().getHostAddress()+":"+addr.getPort();
+        return addr.getAddress().getHostAddress() + ":" + addr.getPort();
     }
 
 }

File: topic-controller/src/test/java/io/strimzi/controller/topic/LabelPredicateTest.java
Patch:
@@ -23,14 +23,14 @@ public void testCtorError() {
         try {
             new LabelPredicate("foo");
             fail();
-        } catch(IllegalArgumentException e) {
+        } catch (IllegalArgumentException e) {
 
         }
 
         try {
             new LabelPredicate("foo", "1", "bar");
             fail();
-        } catch(IllegalArgumentException e) {
+        } catch (IllegalArgumentException e) {
 
         }
     }

File: topic-controller/src/test/java/io/strimzi/controller/topic/TopicBuilderTest.java
Patch:
@@ -49,7 +49,7 @@ public void testConstructorWithConfig() {
         topic = builder.build();
         assertEquals(new TopicName("my_topic"), topic.getTopicName());
         assertEquals(1, topic.getNumPartitions());
-        assertEquals(-1, topic.getNumReplicas());;
+        assertEquals(-1, topic.getNumReplicas());
         assertEquals(singletonMap("foo", "bar"), topic.getConfig());
     }
 
@@ -75,7 +75,7 @@ public void testWithConfig() {
         topic = builder.build();
         assertEquals(new TopicName("my_topic"), topic.getTopicName());
         assertEquals(1, topic.getNumPartitions());
-        assertEquals(-1, topic.getNumReplicas());;
+        assertEquals(-1, topic.getNumReplicas());
         assertEquals(singletonMap("foo", "bar"), topic.getConfig());
     }
 

File: topic-controller/src/test/java/io/strimzi/test/Exec.java
Patch:
@@ -17,7 +17,7 @@
 import static java.lang.String.join;
 
 class Exec {
-    private static final Logger logger = LoggerFactory.getLogger(Exec.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(Exec.class);
 
     /**
      * Executes the given command in a subprocess.
@@ -55,7 +55,7 @@ static String execOutput(String... cmd) throws KubeClusterException {
 
     private static String execOutput(File out, List<String> cmd) throws KubeClusterException {
         try {
-            logger.info("{}", join(" ", cmd));
+            LOGGER.info("{}", join(" ", cmd));
             ProcessBuilder pb = new ProcessBuilder(cmd);
             if (out == null) {
                 pb.redirectOutput(ProcessBuilder.Redirect.INHERIT);
@@ -66,7 +66,7 @@ private static String execOutput(File out, List<String> cmd) throws KubeClusterE
             Process p = pb.start();
             int sc = p.waitFor();
             if (sc != 0) {
-                throw new KubeClusterException(sc, "`"+ join(" ", cmd) + "` got status code " + sc);
+                throw new KubeClusterException(sc, "`" + join(" ", cmd) + "` got status code " + sc);
             }
             return out == null ? null : new String(Files.readAllBytes(out.toPath()));
         } catch (IOException e) {

File: topic-controller/src/test/java/io/strimzi/test/OpenShift.java
Patch:
@@ -4,7 +4,8 @@
  */
 package io.strimzi.test;
 
-import static io.strimzi.test.Exec.*;
+import static io.strimzi.test.Exec.isExecutableOnPath;
+import static io.strimzi.test.Exec.exec;
 
 public class OpenShift implements KubeCluster {
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaCluster.java
Patch:
@@ -314,9 +314,8 @@ public Service generateService() {
      * @return The generated Service
      */
     public Service generateHeadlessService() {
-
-        return createHeadlessService(headlessName,
-                getServicePorts());
+        Map<String, String> annotations = Collections.singletonMap("service.alpha.kubernetes.io/tolerate-unready-endpoints", "true");
+        return createHeadlessService(headlessName, getServicePorts(), annotations);
     }
 
     /**

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/ClusterController.java
Patch:
@@ -72,7 +72,7 @@ public void start(Future<Void> start) {
         log.info("Starting ClusterController");
 
         // Configure the executor here, but it is used only in other places
-        getVertx().createSharedWorkerExecutor("kubernetes-ops-pool", 5, TimeUnit.SECONDS.toNanos(120));
+        getVertx().createSharedWorkerExecutor("kubernetes-ops-pool", 10, TimeUnit.SECONDS.toNanos(120));
 
         createConfigMapWatch(res -> {
             if (res.succeeded())    {

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -266,8 +266,8 @@ public Service generateService() {
     }
 
     public Service generateHeadlessService() {
-
-        return createHeadlessService(headlessName, getServicePortList());
+        Map<String, String> annotations = Collections.singletonMap("service.alpha.kubernetes.io/tolerate-unready-endpoints", "true");
+        return createHeadlessService(headlessName, getServicePortList(), annotations);
     }
 
     public Service patchHeadlessService(Service svc) {

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/AbstractCluster.java
Patch:
@@ -31,7 +31,7 @@ public abstract class AbstractCluster {
     private static final String VOLUME_MOUNT_HACK_NAME = "volume-mount-hack";
     private static final Long VOLUME_MOUNT_HACK_GROUPID = 1001L;
 
-    protected static final String METRICS_CONFIG_FILE = "config.yml";
+    public static final String METRICS_CONFIG_FILE = "config.yml";
 
     protected final String cluster;
     protected final String namespace;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/Storage.java
Patch:
@@ -177,7 +177,7 @@ public StorageDiffResult diff(Storage other) {
     private boolean compareSize(Quantity other) {
 
         return this.size == null ?
-                other == null : this.size.getAmount().equals(other.getAmount());
+                other == null : other != null && this.size.getAmount().equals(other.getAmount());
     }
 
     /**

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/ClusterControllerConfigTest.java
Patch:
@@ -1,5 +1,5 @@
 /*
- * Copyright 2017-2018, Strimzi authors.
+ * Copyright 2018, Strimzi authors.
  * License: Apache License 2.0 (see the file LICENSE or http://apache.org/licenses/LICENSE-2.0.html).
  */
 package io.strimzi.controller.cluster;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/AbstractClusterOperations.java
Patch:
@@ -114,7 +114,7 @@ private final void execute(String namespace, String name, CompositeOperation<C>
                         lock.release();
                     } else {
                         log.error("{} cluster {} in namespace {}: failed to {}", clusterType, clusterOp.cluster().getName(), namespace, operationType);
-                        handler.handle(Future.failedFuture("Failed to create Kafka cluster"));
+                        handler.handle(Future.failedFuture("Failed to execute cluster operation"));
                         lock.release();
                     }
                 });

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/AbstractCluster.java
Patch:
@@ -444,7 +444,7 @@ protected Deployment createDeployment(
                 .withReplicas(replicas)
                 .withNewTemplate()
                 .withNewMetadata()
-                .withLabels(getLabels())
+                .withLabels(getLabelsWithName())
                 .withAnnotations(podAnnotations)
                 .endMetadata()
                 .withNewSpec()

File: cluster-controller/src/test/java/io/strimzi/controller/cluster/operations/cluster/KafkaClusterOperationsTest.java
Patch:
@@ -80,7 +80,7 @@ private void createCluster(TestContext context, boolean isOpenShift) {
         int healthDelay = 120;
         int healthTimeout = 30;
         String metricsCmJson = null;
-        ConfigMap clusterCm = ResourceUtils.createConfigMap(clusterCmNamespace, clusterCmName, replicas, image, healthDelay, healthTimeout, metricsCmJson);
+        ConfigMap clusterCm = ResourceUtils.createKafkaClusterConfigMap(clusterCmNamespace, clusterCmName, replicas, image, healthDelay, healthTimeout, metricsCmJson);
         when(mockCmOps.get(clusterCmNamespace, clusterCmName)).thenReturn(clusterCm);
         ArgumentCaptor<Service> serviceCaptor = ArgumentCaptor.forClass(Service.class);
         when(mockServiceOps.create(serviceCaptor.capture())).thenReturn(Future.succeededFuture());

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/cluster/AbstractClusterOperations.java
Patch:
@@ -46,11 +46,11 @@ public abstract class AbstractClusterOperations<C extends AbstractCluster> {
     protected final Vertx vertx;
     private final String clusterType;
     private final String operationType;
-    protected final KubernetesClient client;
+    protected final boolean isOpenShift;
 
-    protected AbstractClusterOperations(Vertx vertx, KubernetesClient client, String clusterType, String operationType) {
+    protected AbstractClusterOperations(Vertx vertx, boolean isOpenShift, String clusterType, String operationType) {
         this.vertx = vertx;
-        this.client = client;
+        this.isOpenShift = isOpenShift;
         this.clusterType = clusterType;
         this.operationType = operationType;
     }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/resource/AbstractOperations.java
Patch:
@@ -166,7 +166,7 @@ public Future<Void> patch(String namespace, String name, boolean cascading, T pa
      * @param name The name.
      * @return The resource, or null if it doesn't exist.
      */
-    public final T get(String namespace, String name) {
+    public T get(String namespace, String name) {
         return operation().inNamespace(namespace).withName(name).get();
     }
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/resource/StatefulSetOperations.java
Patch:
@@ -113,7 +113,7 @@ public void rollingUpdate(String namespace, String name, Handler<AsyncResult<Voi
         );
     }
 
-    class RollingUpdateWatcher implements Watcher<Pod> {
+    static class RollingUpdateWatcher implements Watcher<Pod> {
         //private static final Logger log = LoggerFactory.getLogger(RollingUpdateWatcher.class.getName());
         private final Future deleted;
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/Storage.java
Patch:
@@ -220,7 +220,7 @@ private boolean compareSelector(LabelSelector other) {
     /**
      * Result after comparing two Storage instances
      */
-    public class StorageDiffResult {
+    public static class StorageDiffResult {
 
         private boolean isType;
         private boolean isSize;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -23,7 +23,7 @@ public class ZookeeperCluster extends AbstractCluster {
     private static final int CLUSTERING_PORT = 2888;
     private static final String CLUSTERING_PORT_NAME = "clustering";
     private static final int LEADER_ELECTION_PORT = 3888;
-    private final String leaderElectionPortName = "leader-election";
+    private static final String LEADER_ELECTION_PORT_NAME = "leader-election";
 
     private static String NAME_SUFFIX = "-zookeeper";
     private static String HEADLESS_NAME_SUFFIX = NAME_SUFFIX + "-headless";
@@ -313,7 +313,7 @@ private List<ServicePort> getServicePortList() {
         List<ServicePort> portList = new ArrayList<>();
         portList.add(createServicePort(CLIENT_PORT_NAME, CLIENT_PORT, CLIENT_PORT, "TCP"));
         portList.add(createServicePort(CLUSTERING_PORT_NAME, CLUSTERING_PORT, CLUSTERING_PORT, "TCP"));
-        portList.add(createServicePort(leaderElectionPortName, LEADER_ELECTION_PORT, LEADER_ELECTION_PORT, "TCP"));
+        portList.add(createServicePort(LEADER_ELECTION_PORT_NAME, LEADER_ELECTION_PORT, LEADER_ELECTION_PORT, "TCP"));
 
         return portList;
     }
@@ -322,7 +322,7 @@ private List<ContainerPort> getContainerPortList() {
         List<ContainerPort> portList = new ArrayList<>();
         portList.add(createContainerPort(CLIENT_PORT_NAME, CLIENT_PORT, "TCP"));
         portList.add(createContainerPort(CLUSTERING_PORT_NAME, CLUSTERING_PORT, "TCP"));
-        portList.add(createContainerPort(leaderElectionPortName, LEADER_ELECTION_PORT,"TCP"));
+        portList.add(createContainerPort(LEADER_ELECTION_PORT_NAME, LEADER_ELECTION_PORT,"TCP"));
         if (isMetricsEnabled) {
             portList.add(createContainerPort(metricsPortName, metricsPort, "TCP"));
         }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -22,7 +22,7 @@ public class ZookeeperCluster extends AbstractCluster {
     private static final String CLIENT_PORT_NAME = "clients";
     private static final int CLUSTERING_PORT = 2888;
     private static final String CLUSTERING_PORT_NAME = "clustering";
-    private final int leaderElectionPort = 3888;
+    private static final int LEADER_ELECTION_PORT = 3888;
     private final String leaderElectionPortName = "leader-election";
 
     private static String NAME_SUFFIX = "-zookeeper";
@@ -313,7 +313,7 @@ private List<ServicePort> getServicePortList() {
         List<ServicePort> portList = new ArrayList<>();
         portList.add(createServicePort(CLIENT_PORT_NAME, CLIENT_PORT, CLIENT_PORT, "TCP"));
         portList.add(createServicePort(CLUSTERING_PORT_NAME, CLUSTERING_PORT, CLUSTERING_PORT, "TCP"));
-        portList.add(createServicePort(leaderElectionPortName, leaderElectionPort, leaderElectionPort, "TCP"));
+        portList.add(createServicePort(leaderElectionPortName, LEADER_ELECTION_PORT, LEADER_ELECTION_PORT, "TCP"));
 
         return portList;
     }
@@ -322,7 +322,7 @@ private List<ContainerPort> getContainerPortList() {
         List<ContainerPort> portList = new ArrayList<>();
         portList.add(createContainerPort(CLIENT_PORT_NAME, CLIENT_PORT, "TCP"));
         portList.add(createContainerPort(CLUSTERING_PORT_NAME, CLUSTERING_PORT, "TCP"));
-        portList.add(createContainerPort(leaderElectionPortName, leaderElectionPort,"TCP"));
+        portList.add(createContainerPort(leaderElectionPortName, LEADER_ELECTION_PORT,"TCP"));
         if (isMetricsEnabled) {
             portList.add(createContainerPort(metricsPortName, metricsPort, "TCP"));
         }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -21,7 +21,7 @@ public class ZookeeperCluster extends AbstractCluster {
     private static final int CLIENT_PORT = 2181;
     private static final String CLIENT_PORT_NAME = "clients";
     private static final int CLUSTERING_PORT = 2888;
-    private final String clusteringPortName = "clustering";
+    private static final String CLUSTERING_PORT_NAME = "clustering";
     private final int leaderElectionPort = 3888;
     private final String leaderElectionPortName = "leader-election";
 
@@ -312,7 +312,7 @@ protected List<EnvVar> getEnvVars() {
     private List<ServicePort> getServicePortList() {
         List<ServicePort> portList = new ArrayList<>();
         portList.add(createServicePort(CLIENT_PORT_NAME, CLIENT_PORT, CLIENT_PORT, "TCP"));
-        portList.add(createServicePort(clusteringPortName, CLUSTERING_PORT, CLUSTERING_PORT, "TCP"));
+        portList.add(createServicePort(CLUSTERING_PORT_NAME, CLUSTERING_PORT, CLUSTERING_PORT, "TCP"));
         portList.add(createServicePort(leaderElectionPortName, leaderElectionPort, leaderElectionPort, "TCP"));
 
         return portList;
@@ -321,7 +321,7 @@ private List<ServicePort> getServicePortList() {
     private List<ContainerPort> getContainerPortList() {
         List<ContainerPort> portList = new ArrayList<>();
         portList.add(createContainerPort(CLIENT_PORT_NAME, CLIENT_PORT, "TCP"));
-        portList.add(createContainerPort(clusteringPortName, CLUSTERING_PORT, "TCP"));
+        portList.add(createContainerPort(CLUSTERING_PORT_NAME, CLUSTERING_PORT, "TCP"));
         portList.add(createContainerPort(leaderElectionPortName, leaderElectionPort,"TCP"));
         if (isMetricsEnabled) {
             portList.add(createContainerPort(metricsPortName, metricsPort, "TCP"));

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -20,7 +20,7 @@ public class ZookeeperCluster extends AbstractCluster {
 
     private static final int CLIENT_PORT = 2181;
     private static final String CLIENT_PORT_NAME = "clients";
-    private final int clusteringPort = 2888;
+    private static final int CLUSTERING_PORT = 2888;
     private final String clusteringPortName = "clustering";
     private final int leaderElectionPort = 3888;
     private final String leaderElectionPortName = "leader-election";
@@ -312,7 +312,7 @@ protected List<EnvVar> getEnvVars() {
     private List<ServicePort> getServicePortList() {
         List<ServicePort> portList = new ArrayList<>();
         portList.add(createServicePort(CLIENT_PORT_NAME, CLIENT_PORT, CLIENT_PORT, "TCP"));
-        portList.add(createServicePort(clusteringPortName, clusteringPort, clusteringPort, "TCP"));
+        portList.add(createServicePort(clusteringPortName, CLUSTERING_PORT, CLUSTERING_PORT, "TCP"));
         portList.add(createServicePort(leaderElectionPortName, leaderElectionPort, leaderElectionPort, "TCP"));
 
         return portList;
@@ -321,7 +321,7 @@ private List<ServicePort> getServicePortList() {
     private List<ContainerPort> getContainerPortList() {
         List<ContainerPort> portList = new ArrayList<>();
         portList.add(createContainerPort(CLIENT_PORT_NAME, CLIENT_PORT, "TCP"));
-        portList.add(createContainerPort(clusteringPortName, clusteringPort, "TCP"));
+        portList.add(createContainerPort(clusteringPortName, CLUSTERING_PORT, "TCP"));
         portList.add(createContainerPort(leaderElectionPortName, leaderElectionPort,"TCP"));
         if (isMetricsEnabled) {
             portList.add(createContainerPort(metricsPortName, metricsPort, "TCP"));

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaConnectCluster.java
Patch:
@@ -22,7 +22,7 @@ public class KafkaConnectCluster extends AbstractCluster {
     public static final String TYPE = "kafka-connect";
 
     // Port configuration
-    private final int restApiPort = 8083;
+    private static final int REST_API_PORT = 8083;
     private final String restApiPortName = "rest-api";
 
     private static String NAME_SUFFIX = "-connect";
@@ -277,13 +277,13 @@ else if (replicas < dep.getSpec().getReplicas()) {
     public Service generateService() {
 
         return createService("ClusterIP",
-                Collections.singletonList(createServicePort(restApiPortName, restApiPort, restApiPort, "TCP")));
+                Collections.singletonList(createServicePort(restApiPortName, REST_API_PORT, REST_API_PORT, "TCP")));
     }
 
     public Deployment generateDeployment() {
 
         return createDeployment(
-                Collections.singletonList(createContainerPort(restApiPortName, restApiPort, "TCP")),
+                Collections.singletonList(createContainerPort(restApiPortName, REST_API_PORT, "TCP")),
                 createHttpProbe(healthCheckPath, restApiPortName, healthCheckInitialDelay, healthCheckTimeout),
                 createHttpProbe(healthCheckPath, restApiPortName, healthCheckInitialDelay, healthCheckTimeout),
                 getDeploymentAnnotations(),

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/Storage.java
Patch:
@@ -172,8 +172,8 @@ public StorageDiffResult diff(Storage other) {
      */
     private boolean compareSize(Quantity other) {
 
-        return Objects.isNull(this.size) ?
-                Objects.isNull(other) : this.size.getAmount().equals(other.getAmount());
+        return this.size == null ?
+                other == null : this.size.getAmount().equals(other.getAmount());
     }
 
     /**

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/ClusterController.java
Patch:
@@ -200,7 +200,7 @@ public void onClose(KubernetesClientException e) {
                                 log.error("Watcher closed with exception", e);
                             }
                             else {
-                                log.error("Watcher closed with exception", e);
+                                log.error("Watcher closed");
                             }
 
                             recreateConfigMapWatch();

File: topic-controller/src/main/java/io/strimzi/controller/topic/TopicDiff.java
Patch:
@@ -338,7 +338,7 @@ public Topic apply(Topic topic) {
      * Return true if this TopicDiff conflicts with the given other TopicDiff
      */
     public String conflict(TopicDiff other) {
-        Set<Difference> intersection = new HashSet(this.differences.keySet());
+        Set<String> intersection = new HashSet(this.differences.keySet());
         intersection.retainAll(other.differences.keySet());
         // they could still be OK if they're applying the _same_ differences
         StringBuilder sb = new StringBuilder();

File: topic-controller/src/main/java/io/strimzi/controller/topic/Config.java
Patch:
@@ -125,7 +125,7 @@ private Value(String key, Type<? extends T> type, boolean required, String doc)
             "A comma-separated list of key=value pairs for selecting ConfigMaps that describe topics.");
     public static final Value<String> KAFKA_BOOTSTRAP_SERVERS = new Value(TC_KAFKA_BOOTSTRAP_SERVERS, STRING, true,
             "A comma-separated list of kafka bootstrap servers.");
-    public static final Value<String> NAMESPACE = new Value(TC_NAMESPACE, STRING,true,
+    public static final Value<String> NAMESPACE = new Value(TC_NAMESPACE, STRING, true,
             "The kubernetes namespace in which to operate.");
     public static final Value<String> ZOOKEEPER_CONNECT = new Value(TC_ZK_CONNECT, STRING, true,
             "The zookeeper connection string.");

File: topic-controller/src/test/java/io/strimzi/controller/topic/ConfigTest.java
Patch:
@@ -33,6 +33,7 @@ public class ConfigTest {
     static {
         mandatory.put(Config.ZOOKEEPER_CONNECT.key, "localhost:2181");
         mandatory.put(Config.KAFKA_BOOTSTRAP_SERVERS.key, "localhost:9092");
+        mandatory.put(Config.NAMESPACE.key, "default");
     }
 
     @Test(expected = IllegalArgumentException.class)

File: topic-controller/src/test/java/io/strimzi/controller/topic/ControllerAssignedKafkaImplTest.java
Patch:
@@ -44,6 +44,7 @@ public class ControllerAssignedKafkaImplTest {
         Map<String, String> map = new HashMap<>();
         map.put(Config.ZOOKEEPER_CONNECT.key, "localhost:2181");
         map.put(Config.KAFKA_BOOTSTRAP_SERVERS.key, "localhost:9092");
+        map.put(Config.NAMESPACE.key, "default");
         map.put(Config.REASSIGN_VERIFY_INTERVAL_MS.key, "1 seconds");
         config = new Config(map);
     }

File: topic-controller/src/test/java/io/strimzi/controller/topic/ControllerTest.java
Patch:
@@ -69,7 +69,7 @@ public void setup() {
         mockKafka = new MockKafka();
         mockTopicStore = new MockTopicStore();
         mockK8s = new MockK8s();
-        controller = new Controller(vertx, mockKafka, mockK8s, mockTopicStore, cmPredicate);
+        controller = new Controller(vertx, mockKafka, mockK8s, mockTopicStore, cmPredicate, "default-namespace");
     }
 
     @After

File: topic-controller/src/test/java/io/strimzi/controller/topic/K8sImplTest.java
Patch:
@@ -52,6 +52,7 @@ public void testList(TestContext context) {
         MixedOperation<ConfigMap, ConfigMapList, DoneableConfigMap, Resource<ConfigMap, DoneableConfigMap>> mockConfigMaps = mock(MixedOperation.class);
         when(mockClient.configMaps()).thenReturn(mockConfigMaps);
         when(mockConfigMaps.withLabels(any())).thenReturn(mockConfigMaps);
+        when(mockConfigMaps.inNamespace(any())).thenReturn(mockConfigMaps);
         when(mockConfigMaps.list()).thenReturn(new ConfigMapListBuilder()
                 .addNewItem().withKind("ConfigMap")
                 .withNewMetadata()
@@ -61,7 +62,7 @@ public void testList(TestContext context) {
                 .addNewItem().endItem()
                 .build());
 
-        K8sImpl k8s = new K8sImpl(vertx, mockClient, new LabelPredicate("foo", "bar"));
+        K8sImpl k8s = new K8sImpl(vertx, mockClient, new LabelPredicate("foo", "bar"), "default");
 
         k8s.listMaps(ar -> {
             List<ConfigMap> list = ar.result();

File: topic-controller/src/test/java/io/strimzi/controller/topic/MockController.java
Patch:
@@ -28,7 +28,7 @@
 class MockController extends Controller {
 
     public MockController() {
-        super(null, null, null, null, null);
+        super(null, null, null, null, null, null);
     }
 
     static class MockControllerEvent {

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/ClusterControllerConfig.java
Patch:
@@ -17,7 +17,6 @@ public ClusterControllerConfig(String namespace, Map<String, String> labels) {
     }
 
     public static ClusterControllerConfig fromEnv() {
-
         String namespace = System.getenv(ClusterControllerConfig.STRIMZI_NAMESPACE);
         String stringLabels = System.getenv(ClusterControllerConfig.STRIMZI_CONFIGMAP_LABELS);
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/ClusterController.java
Patch:
@@ -435,7 +435,7 @@ private void startHealthServer() {
         this.vertx.createHttpServer()
                 .requestHandler(request -> {
 
-                    if (request.path().equals("/health")) {
+                    if (request.path().equals("/healthy")) {
                         request.response().setStatusCode(HttpResponseStatus.OK.code()).end();
                     } else if (request.path().equals("/ready")) {
                         request.response().setStatusCode(HttpResponseStatus.OK.code()).end();

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/ClusterController.java
Patch:
@@ -398,7 +398,7 @@ private void updateKafkaConnectCluster(ConfigMap cm)   {
     }
 
     private void deleteKafkaConnectCluster(Deployment dep)   {
-        String name = dep.getMetadata().getName();
+        String name = dep.getMetadata().getLabels().get(ClusterController.STRIMZI_CLUSTER_LABEL);
         log.info("Deleting cluster {}", name);
         deleteKafkaConnectCluster(namespace, name);
     }

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/ClusterController.java
Patch:
@@ -336,7 +336,7 @@ private void updateKafkaCluster(ConfigMap cm)   {
     }
 
     private void deleteKafkaCluster(StatefulSet ss)   {
-        String name = ss.getMetadata().getName();
+        String name = ss.getMetadata().getLabels().get(ClusterController.STRIMZI_CLUSTER_LABEL);
         log.info("Deleting cluster {}", name);
         deleteKafkaCluster(namespace, name);
     }

File: topic-controller/src/main/java/io/strimzi/controller/topic/K8sImpl.java
Patch:
@@ -70,11 +70,11 @@ public void updateConfigMap(ConfigMap cm, Handler<AsyncResult<Void>> handler) {
     }
 
     @Override
-    public void deleteConfigMap(TopicName topicName, Handler<AsyncResult<Void>> handler) {
+    public void deleteConfigMap(MapName mapName, Handler<AsyncResult<Void>> handler) {
         vertx.executeBlocking(future -> {
             try {
                 // Delete the CM by the topic name, because neither ZK nor Kafka know the CM name
-                client.configMaps().withName(topicName.toString()).delete();
+                client.configMaps().withName(mapName.toString()).delete();
                 future.complete();
             } catch (Exception e) {
                 future.fail(e);

File: topic-controller/src/test/java/io/strimzi/controller/topic/ControllerTest.java
Patch:
@@ -437,7 +437,7 @@ public void testReconcile_withCm_noKafka_withPrivate(TestContext context) {
         Async async0 = context.async(2);
         mockK8s.setCreateResponse(mapName, null)
                 .createConfigMap(TopicSerialization.toConfigMap(kubeTopic, cmPredicate), ar -> async0.countDown());
-        mockK8s.setDeleteResponse(topicName, null);
+        mockK8s.setDeleteResponse(mapName, null);
         mockTopicStore.setCreateTopicResponse(topicName, null)
                 .create(privateTopic, ar-> async0.countDown());
         mockTopicStore.setDeleteTopicResponse(topicName, null);
@@ -790,13 +790,13 @@ public void testOnConfigMapRemoved_NoSuchEntityExistsException(TestContext conte
     }
 
     private void topicDeleted(TestContext context, Exception storeException, Exception k8sException) {
-        Topic kubeTopic = new Topic.Builder(topicName.toString(), 10, (short)2, map("cleanup.policy", "bar")).build();
+        Topic kubeTopic = new Topic.Builder(topicName.toString(), 10, (short)2, map("cleanup.policy", "bar")).withMapName(mapName).build();
         Topic kafkaTopic = kubeTopic;
         Topic privateTopic = kubeTopic;
 
         mockK8s.setCreateResponse(mapName, null)
                 .createConfigMap(TopicSerialization.toConfigMap(kubeTopic, cmPredicate), ar -> {});
-        mockK8s.setDeleteResponse(topicName, k8sException);
+        mockK8s.setDeleteResponse(mapName, k8sException);
 
         mockTopicStore.setCreateTopicResponse(topicName, null)
                 .create(privateTopic, ar -> {});

File: topic-controller/src/main/java/io/strimzi/controller/topic/ControllerAssignedKafkaImpl.java
Patch:
@@ -70,7 +70,7 @@ public void increasePartitions(Topic topic, Handler<AsyncResult<Void>> handler)
         final NewPartitions newPartitions = NewPartitions.increaseTo(topic.getNumPartitions());
         final Map<String, NewPartitions> request = Collections.singletonMap(topic.getTopicName().toString(), newPartitions);
         KafkaFuture<Void> future = adminClient.createPartitions(request).values().get(topic.getTopicName());
-        queueWork(new UniWork<>(future, handler));
+        queueWork(new UniWork<>("increasePartitions", future, handler));
     }
 
     /**
@@ -84,7 +84,7 @@ public void createTopic(Topic topic, Handler<AsyncResult<Void>> handler) {
         logger.debug("Creating topic {}", newTopic);
         KafkaFuture<Void> future = adminClient.createTopics(
                 Collections.singleton(newTopic)).values().get(newTopic.name());
-        queueWork(new UniWork<>(future, handler));
+        queueWork(new UniWork<>("createTopic", future, handler));
     }
 
     @Override

File: topic-controller/src/main/java/io/strimzi/controller/topic/K8sImpl.java
Patch:
@@ -74,7 +74,7 @@ public void deleteConfigMap(TopicName topicName, Handler<AsyncResult<Void>> hand
         vertx.executeBlocking(future -> {
             try {
                 // Delete the CM by the topic name, because neither ZK nor Kafka know the CM name
-                client.configMaps().withField("name", topicName.toString()).delete();
+                client.configMaps().withName(topicName.toString()).delete();
                 future.complete();
             } catch (Exception e) {
                 future.fail(e);

File: topic-controller/src/main/java/io/strimzi/controller/topic/Kafka.java
Patch:
@@ -73,6 +73,7 @@ public interface Kafka {
      * handler with the result. If the operation fails the given handler
      * will be called with a failed AsyncResult whose {@code cause()} is the
      * KafkaException (not an ExecutionException).
+     * If the topic does not exist the {@link AsyncResult#result()} will be null.
      */
     void topicMetadata(TopicName topicName, Handler<AsyncResult<TopicMetadata>> handler);
 

File: topic-controller/src/main/java/io/strimzi/controller/topic/Topic.java
Patch:
@@ -66,6 +66,7 @@ public Builder(TopicName topicName, int numPartitions, short numReplicas, Map<St
         public Builder(Topic topic) {
             this.topicName = topic.topicName;
             this.numPartitions = topic.numPartitions;
+            this.numReplicas = topic.numReplicas;
             this.config.putAll(topic.config);
         }
 

File: topic-controller/src/test/java/io/strimzi/controller/topic/BackOffTest.java
Patch:
@@ -38,6 +38,7 @@ public void testDefaultBackoff() {
         } catch (MaxAttemptsExceededException e) {
 
         }
+        assertEquals(1400L, b.totalDelayMs());
     }
 
     @Test
@@ -54,5 +55,7 @@ public void testAnotherBackoff() {
         } catch (MaxAttemptsExceededException e) {
 
         }
+
+        assertEquals(1111L, b.totalDelayMs());
     }
 }
\ No newline at end of file

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/UpdateKafkaClusterOperation.java
Patch:
@@ -43,7 +43,7 @@ public void execute(Vertx vertx, K8SUtils k8s, Handler<AsyncResult<Void>> handle
 
                         kafka = KafkaCluster.fromConfigMap(kafkaConfigMap);
                         log.info("Updating Kafka cluster {} in namespace {}", kafka.getName(), namespace);
-                        diff = kafka.diff(k8s, namespace, name);
+                        diff = kafka.diff(k8s, namespace);
 
                     } catch (Exception ex) {
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/UpdateKafkaConnectClusterOperation.java
Patch:
@@ -40,7 +40,7 @@ public void execute(Vertx vertx, K8SUtils k8s, Handler<AsyncResult<Void>> handle
 
                     connect = KafkaConnectCluster.fromConfigMap(connectConfigMap);
                     log.info("Updating Kafka Connect cluster {} in namespace {}", connect.getName(), namespace);
-                    diff = connect.diff(k8s, namespace, name);
+                    diff = connect.diff(k8s, namespace);
 
                 } else  {
                     log.error("ConfigMap {} doesn't exist anymore in namespace {}", name, namespace);

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/operations/UpdateZookeeperClusterOperation.java
Patch:
@@ -40,7 +40,7 @@ public void execute(Vertx vertx, K8SUtils k8s, Handler<AsyncResult<Void>> handle
 
                         zk = ZookeeperCluster.fromConfigMap(zkConfigMap);
                         log.info("Updating Zookeeper cluster {} in namespace {}", zk.getName(), namespace);
-                        diff = zk.diff(k8s, namespace, name);
+                        diff = zk.diff(k8s, namespace);
 
                     } catch (Exception ex) {
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaConnectCluster.java
Patch:
@@ -153,12 +153,11 @@ public static KafkaConnectCluster fromDeployment(K8SUtils k8s, String namespace,
      *
      * @param k8s   K8SUtils client instance for accessing Kubernetes/OpenShift cluster
      * @param namespace Kubernetes/OpenShift namespace where cluster resources belong to
-     * @param cluster   overall cluster name
      * @return  ClusterDiffResult instance with differences
      */
-    public ClusterDiffResult diff(K8SUtils k8s, String namespace, String cluster) {
+    public ClusterDiffResult diff(K8SUtils k8s, String namespace) {
 
-        Deployment dep = k8s.getDeployment(namespace, cluster + KafkaConnectCluster.NAME_SUFFIX);
+        Deployment dep = k8s.getDeployment(namespace, getName());
 
         ClusterDiffResult diff = new ClusterDiffResult();
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/ClusterController.java
Patch:
@@ -213,7 +213,7 @@ private void reconcileKafka() {
         List<StatefulSet> sss = k8s.getStatefulSets(namespace, kafkaLabels);
 
         List<String> cmsNames = cms.stream().map(cm -> cm.getMetadata().getName()).collect(Collectors.toList());
-        List<String> sssNames = sss.stream().map(cm -> cm.getMetadata().getName()).collect(Collectors.toList());
+        List<String> sssNames = sss.stream().map(cm -> cm.getMetadata().getLabels().get(ClusterController.STRIMZI_CLUSTER_LABEL)).collect(Collectors.toList());
 
         List<ConfigMap> addList = cms.stream().filter(cm -> !sssNames.contains(cm.getMetadata().getName())).collect(Collectors.toList());
         List<ConfigMap> updateList = cms.stream().filter(cm -> sssNames.contains(cm.getMetadata().getName())).collect(Collectors.toList());
@@ -255,7 +255,7 @@ private void reconcileKafkaConnect() {
         List<Deployment> deps = k8s.getDeployments(namespace, kafkaLabels);
 
         List<String> cmsNames = cms.stream().map(cm -> cm.getMetadata().getName()).collect(Collectors.toList());
-        List<String> sssNames = deps.stream().map(cm -> cm.getMetadata().getName()).collect(Collectors.toList());
+        List<String> sssNames = deps.stream().map(cm -> cm.getMetadata().getLabels().get(ClusterController.STRIMZI_CLUSTER_LABEL)).collect(Collectors.toList());
 
         List<ConfigMap> addList = cms.stream().filter(cm -> !sssNames.contains(cm.getMetadata().getName())).collect(Collectors.toList());
         List<ConfigMap> updateList = cms.stream().filter(cm -> sssNames.contains(cm.getMetadata().getName())).collect(Collectors.toList());
@@ -269,7 +269,7 @@ private void reconcileKafkaConnect() {
     private void addKafkaConnectClusters(List<ConfigMap> add)   {
         for (ConfigMap cm : add) {
             log.info("Reconciliation: Kafka Connect cluster {} should be added", cm.getMetadata().getName());
-            addKafkaCluster(cm);
+            addKafkaConnectCluster(cm);
         }
     }
 

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/KafkaCluster.java
Patch:
@@ -29,7 +29,7 @@ public class KafkaCluster extends AbstractCluster {
     private int transactionStateLogReplicationFactor = DEFAULT_KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR;
 
     // Configuration defaults
-    private static String DEFAULT_IMAGE = "strimzi/kafka-statefulsets:latest";
+    private static String DEFAULT_IMAGE = "strimzi/kafka:latest";
     private static int DEFAULT_REPLICAS = 3;
     private static int DEFAULT_HEALTHCHECK_DELAY = 15;
     private static int DEFAULT_HEALTHCHECK_TIMEOUT = 5;

File: cluster-controller/src/main/java/io/strimzi/controller/cluster/resources/AbstractCluster.java
Patch:
@@ -21,7 +21,7 @@ public abstract class AbstractCluster {
 
     protected final Logger log = LoggerFactory.getLogger(getClass());
 
-    public static final String STRIMZI_CLUSTER_CONTROLLER_DOMAIN = "cluster-contorller.strimzi,io";
+    public static final String STRIMZI_CLUSTER_CONTROLLER_DOMAIN = "cluster.controller.strimzi.io";
 
     private static final String VOLUME_MOUNT_HACK_IMAGE = "busybox";
     private static final String VOLUME_MOUNT_HACK_NAME = "volume-mount-hack";

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/KafkaCluster.java
Patch:
@@ -125,7 +125,7 @@ public static KafkaCluster fromStatefulSet(StatefulSet ss) {
             Storage storage = Storage.fromPersistentVolumeClaim(ss.getSpec().getVolumeClaimTemplates().get(0));
             kafka.setStorage(storage);
         } else {
-            Storage storage = new Storage(Storage.StorageType.TEMPORARY);
+            Storage storage = new Storage(Storage.StorageType.EPHEMERAL);
             kafka.setStorage(storage);
         }
 
@@ -258,7 +258,7 @@ private List<ContainerPort> getContainerPortList() {
 
     private List<Volume> getVolumes() {
         List<Volume> volumeList = new ArrayList<>();
-        if (storage.type() == Storage.StorageType.TEMPORARY) {
+        if (storage.type() == Storage.StorageType.EPHEMERAL) {
             volumeList.add(createEmptyDirVolume(volumeName));
         }
         if (isMetricsEnabled) {

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -112,7 +112,7 @@ public static ZookeeperCluster fromStatefulSet(StatefulSet ss) {
             Storage storage = Storage.fromPersistentVolumeClaim(ss.getSpec().getVolumeClaimTemplates().get(0));
             zk.setStorage(storage);
         } else {
-            Storage storage = new Storage(Storage.StorageType.TEMPORARY);
+            Storage storage = new Storage(Storage.StorageType.EPHEMERAL);
             zk.setStorage(storage);
         }
 
@@ -255,7 +255,7 @@ private List<ContainerPort> getContainerPortList() {
 
     private List<Volume> getVolumes() {
         List<Volume> volumeList = new ArrayList<>();
-        if (storage.type() == Storage.StorageType.TEMPORARY) {
+        if (storage.type() == Storage.StorageType.EPHEMERAL) {
             volumeList.add(createEmptyDirVolume(volumeName));
         }
         if (isMetricsEnabled) {

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/operations/CreateKafkaConnectClusterOperation.java
Patch:
@@ -39,7 +39,7 @@ public void execute(Vertx vertx, K8SUtils k8s, Handler<AsyncResult<Void>> handle
                         lock.release();
                     } else {
                         log.error("Kafka Connect cluster {} failed to create in namespace {}", name, namespace);
-                        handler.handle(Future.failedFuture("Failed to create Zookeeper cluster"));
+                        handler.handle(Future.failedFuture("Failed to create Kafka Connect cluster"));
                         lock.release();
                     }
                 });

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/KafkaCluster.java
Patch:
@@ -29,7 +29,7 @@ public class KafkaCluster extends AbstractCluster {
     private int transactionStateLogReplicationFactor = DEFAULT_KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR;
 
     // Configuration defaults
-    private static String DEFAULT_IMAGE = "enmasseproject/kafka-statefulsets:latest";
+    private static String DEFAULT_IMAGE = "strimzi/kafka-statefulsets:latest";
     private static int DEFAULT_REPLICAS = 3;
     private static int DEFAULT_HEALTHCHECK_DELAY = 15;
     private static int DEFAULT_HEALTHCHECK_TIMEOUT = 5;

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/KafkaConnectCluster.java
Patch:
@@ -29,7 +29,7 @@ public class KafkaConnectCluster extends AbstractCluster {
     private int statusStorageReplicationFactor = DEFAULT_STATUS_STORAGE_REPLICATION_FACTOR;
 
     // Configuration defaults
-    private static String DEFAULT_IMAGE = "enmasseproject/kafka-connect:latest";
+    private static String DEFAULT_IMAGE = "strimzi/kafka-connect:latest";
     private static int DEFAULT_REPLICAS = 3;
     private static int DEFAULT_HEALTHCHECK_DELAY = 60;
     private static int DEFAULT_HEALTHCHECK_TIMEOUT = 5;

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -30,7 +30,7 @@ public class ZookeeperCluster extends AbstractCluster {
     // N/A
 
     // Configuration defaults
-    private static String DEFAULT_IMAGE = "enmasseproject/zookeeper:latest";
+    private static String DEFAULT_IMAGE = "strimzi/zookeeper:latest";
     private static int DEFAULT_REPLICAS = 3;
     private static int DEFAULT_HEALTHCHECK_DELAY = 15;
     private static int DEFAULT_HEALTHCHECK_TIMEOUT = 5;

File: topic-operator/src/test/java/io/enmasse/barnabas/operator/topic/OperatorTest.java
Patch:
@@ -50,7 +50,7 @@
 @RunWith(VertxUnitRunner.class)
 public class OperatorTest {
 
-    private final LabelPredicate cmPredicate = new LabelPredicate("type", "runtime",
+    private final LabelPredicate cmPredicate = new LabelPredicate(
             "kind", "topic",
             "app", "barnabas");
 

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/KafkaCluster.java
Patch:
@@ -11,6 +11,8 @@
 
 public class KafkaCluster extends AbstractCluster {
 
+    public static final String TYPE = "kafka";
+
     private final int clientPort = 9092;
     private final String clientPortName = "clients";
     private final String mounthPath = "/var/lib/kafka";

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/KafkaConnectCluster.java
Patch:
@@ -11,6 +11,8 @@
 
 public class KafkaConnectCluster extends AbstractCluster {
 
+    public static final String TYPE = "kafka-connect";
+
     // Port configuration
     private final int restApiPort = 8083;
     private final String restApiPortName = "rest-api";

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/Main.java
Patch:
@@ -14,7 +14,7 @@ public static void main(String args[]) {
         String namespace = "myproject";
         Map<String, String> labels = new HashMap<>();
         labels.put("app", "barnabas");
-        labels.put("type", "cluster");
+        labels.put("kind", "cluster");
 
         try {
             Vertx vertx = Vertx.vertx();

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/ZookeeperCluster.java
Patch:
@@ -178,8 +178,8 @@ private List<ContainerPort> getContainerPortList() {
     protected void setLabels(Map<String, String> labels) {
         Map<String, String> newLabels = new HashMap<>(labels);
 
-        if (newLabels.containsKey("kind") && newLabels.get("kind").equals("kafka")) {
-            newLabels.put("kind", "zookeeper");
+        if (newLabels.containsKey("type") && newLabels.get("type").equals("kafka")) {
+            newLabels.put("type", "zookeeper");
         }
 
         super.setLabels(newLabels);

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/Main.java
Patch:
@@ -14,8 +14,7 @@ public static void main(String args[]) {
         String namespace = "myproject";
         Map<String, String> labels = new HashMap<>();
         labels.put("app", "barnabas");
-        labels.put("type", "deployment");
-        //labels.put("kind", "kafka");
+        labels.put("type", "cluster");
 
         try {
             Vertx vertx = Vertx.vertx();

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/operations/cluster/UpdateKafkaClusterOperation.java
Patch:
@@ -95,7 +95,7 @@ private Future<Void> patchService(KafkaResource kafka, ResourceDiffResult diff)
     private Future<Void> patchHeadlessService(KafkaResource kafka, ResourceDiffResult diff) {
         if (diff.getDifferent()) {
             Future<Void> patchService = Future.future();
-            OperationExecutor.getInstance().execute(new PatchOperation(k8s.getServiceResource(namespace, kafka.getHeadlessName()), kafka.patchService(k8s.getService(namespace, kafka.getHeadlessName()))), patchService.completer());
+            OperationExecutor.getInstance().execute(new PatchOperation(k8s.getServiceResource(namespace, kafka.getHeadlessName()), kafka.patchHeadlessService(k8s.getService(namespace, kafka.getHeadlessName()))), patchService.completer());
             return patchService;
         }
             else

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/operations/cluster/UpdateZookeeperClusterOperation.java
Patch:
@@ -92,7 +92,7 @@ private Future<Void> patchService(ZookeeperResource zk, ResourceDiffResult diff)
     private Future<Void> patchHeadlessService(ZookeeperResource zk, ResourceDiffResult diff) {
         if (diff.getDifferent()) {
             Future<Void> patchService = Future.future();
-            OperationExecutor.getInstance().execute(new PatchOperation(k8s.getServiceResource(namespace, zk.getHeadlessName()), zk.patchService(k8s.getService(namespace, zk.getHeadlessName()))), patchService.completer());
+            OperationExecutor.getInstance().execute(new PatchOperation(k8s.getServiceResource(namespace, zk.getHeadlessName()), zk.patchHeadlessService(k8s.getService(namespace, zk.getHeadlessName()))), patchService.completer());
             return patchService;
         }
             else

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/ZookeeperResource.java
Patch:
@@ -89,7 +89,7 @@ public static ZookeeperResource fromConfigMap(ConfigMap cm) {
     // and name. Do we need this as it is? Or would it be enough to create just and empty shell from name and namespace
     // which would generate the headless name?
     public static ZookeeperResource fromStatefulSet(StatefulSet ss) {
-        String name = ss.getMetadata().getName() + "-zookeeper";
+        String name = ss.getMetadata().getName();
         ZookeeperResource zk =  new ZookeeperResource(name, ss.getMetadata().getNamespace());
 
         zk.setLabels(ss.getMetadata().getLabels());

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/K8SUtils.java
Patch:
@@ -129,7 +129,7 @@ public ScalableResource<Deployment, DoneableDeployment> getDeploymentResource(St
         return client.extensions().deployments().inNamespace(namespace).withName(name);
     }
 
-    public List<Deployment> getDeployment(String namespace, Map<String, String> labels) {
+    public List<Deployment> getDeployments(String namespace, Map<String, String> labels) {
         return client.extensions().deployments().inNamespace(namespace).withLabels(labels).list().getItems();
     }
 

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/KafkaResource.java
Patch:
@@ -275,7 +275,7 @@ public void update(Handler<AsyncResult<Void>> handler) {
 
                                     if (diff.getRollingUpdate()) {
                                         log.info("Doing rolling update");
-                                        for (int i = 0; i < replicas; i++) {
+                                        for (int i = 0; i < k8s.getStatefulSet(namespace, name).getSpec().getReplicas(); i++) {
                                             String podName = name + "-" + i;
                                             log.info("Rolling pod {}", podName);
                                             Future deleted = Future.future();

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/resources/ZookeeperResource.java
Patch:
@@ -251,7 +251,7 @@ public void update(Handler<AsyncResult<Void>> handler) {
 
                                     if (diff.getRollingUpdate()) {
                                         log.info("Doing rolling update");
-                                        for (int i = 0; i < replicas; i++) {
+                                        for (int i = 0; i < k8s.getStatefulSet(namespace, name).getSpec().getReplicas(); i++) {
                                             String podName = name + "-" + i;
                                             log.info("Rolling pod {}", podName);
                                             Future deleted = Future.future();

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/ClusterController.java
Patch:
@@ -14,7 +14,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.stream.Collectors;
@@ -28,7 +27,7 @@ public class ClusterController extends AbstractVerticle {
 
     private WorkerExecutor executor;
 
-    public ClusterController(ClusterControlerConfig config) throws Exception {
+    public ClusterController(ClusterControllerConfig config) throws Exception {
         log.info("Creating ClusterController");
 
         this.namespace = config.getNamespace();

File: cluster-controller/src/main/java/io/enmasse/barnabas/controller/cluster/Main.java
Patch:
@@ -19,7 +19,7 @@ public static void main(String args[]) {
 
         try {
             Vertx vertx = Vertx.vertx();
-            vertx.deployVerticle(new ClusterController(new ClusterControlerConfig(namespace, labels)));
+            vertx.deployVerticle(new ClusterController(new ClusterControllerConfig(namespace, labels)));
         } catch (IllegalArgumentException e) {
             log.error("Unable to parse arguments", e);
             System.exit(1);

File: topic-operator/src/main/java/io/enmasse/barnabas/operator/topic/TopicName.java
Patch:
@@ -26,6 +26,7 @@ class TopicName {
     private final String name;
 
     public TopicName(String name) {
+        assert(name != null && !name.isEmpty());
         this.name = name;
     }
 

