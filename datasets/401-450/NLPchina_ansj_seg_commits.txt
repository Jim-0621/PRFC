File: plugin/ansj_lucene9_plugin/src/test/java/org/ansj/ansj_lucene_plug/IndexTest.java
Patch:
@@ -44,6 +44,7 @@ public void testQuery() throws IOException {
 
 		System.out.println("start: " + (new Date()));
 		long before = System.currentTimeMillis();
+		ts.reset();
 		while (ts.incrementToken()) {
 			System.out.println(ts.getAttribute(CharTermAttribute.class));
 		}
@@ -65,6 +66,7 @@ public void testDic() throws IOException {
 
 		System.out.println("start: " + (new Date()));
 		long before = System.currentTimeMillis();
+		ts.reset();
 		while (ts.incrementToken()) {
 			System.out.println(ts.getAttribute(CharTermAttribute.class));
 		}
@@ -85,6 +87,7 @@ public void testIndex() throws IOException {
 
 		System.out.println("start: " + (new Date()));
 		long before = System.currentTimeMillis();
+		ts.reset();
 		while (ts.incrementToken()) {
 			System.out.println(ts.getAttribute(CharTermAttribute.class));
 		}

File: src/main/java/org/ansj/recognition/impl/ExtractingRecognition.java
Patch:
@@ -54,7 +54,7 @@ public void recognition(Result result) {
             len += list.size() - 2;
         }
         List<Term> terms = result.getTerms();
-        List<Term> newList = new ArrayList<>(terms.size() - len);
+        List<Term> newList = new ArrayList<>();
         cur = extracted.poll();
         StringBuilder sb = new StringBuilder();
         StringBuilder sbReal = new StringBuilder();

File: src/main/java/org/ansj/recognition/impl/ExtractingRecognition.java
Patch:
@@ -54,7 +54,7 @@ public void recognition(Result result) {
             len += list.size() - 2;
         }
         List<Term> terms = result.getTerms();
-        List<Term> newList = new ArrayList<>(terms.size() - len);
+        List<Term> newList = new ArrayList<>();
         cur = extracted.poll();
         StringBuilder sb = new StringBuilder();
         StringBuilder sbReal = new StringBuilder();

File: plugin/ansj_lucene5_plugin/src/main/java/org/ansj/lucene5/AnsjAnalyzer.java
Patch:
@@ -162,7 +162,7 @@ public static Tokenizer getTokenizer(Reader reader, Map<String, String> args) {
 		}
 
 		if (StringUtil.isNotBlank(temp = args.get("isRealName"))) { //是否保留原字符
-			analysis.setIsRealName(Boolean.valueOf(temp));
+			analysis.setIsRealName(Boolean.parseBoolean(temp));
 		}
 
 		return new AnsjTokenizer(analysis, filters, synonyms);

File: plugin/ansj_lucene6_plugin/src/main/java/org/ansj/lucene6/AnsjAnalyzer.java
Patch:
@@ -167,7 +167,7 @@ public static Tokenizer getTokenizer(Reader reader, Map<String, String> args) {
 		}
 
 		if (StringUtil.isNotBlank(temp = args.get("isRealName"))) { //是否保留原字符
-			analysis.setIsRealName(Boolean.valueOf(temp));
+			analysis.setIsRealName(Boolean.parseBoolean(temp));
 		}
 
 		return new AnsjTokenizer(analysis, filters, synonyms);

File: plugin/ansj_lucene7_plugin/src/main/java/org/ansj/lucene7/AnsjAnalyzer.java
Patch:
@@ -165,7 +165,7 @@ public static Tokenizer getTokenizer(Reader reader, Map<String, String> args) {
 		}
 
 		if (StringUtil.isNotBlank(temp = args.get("isRealName"))) { //是否保留原字符
-			analysis.setIsRealName(Boolean.valueOf(temp));
+			analysis.setIsRealName(Boolean.parseBoolean(temp));
 		}
 
 		return new AnsjTokenizer(analysis, filters, synonyms);

File: src/main/java/org/ansj/splitWord/analysis/DicAnalysis.java
Patch:
@@ -6,6 +6,7 @@
 import org.ansj.domain.TermNatures;
 import org.ansj.recognition.arrimpl.NumRecognition;
 import org.ansj.recognition.arrimpl.PersonRecognition;
+import org.ansj.recognition.arrimpl.UserDefineRecognition;
 import org.ansj.splitWord.Analysis;
 import org.ansj.util.AnsjReader;
 import org.ansj.util.Graph;
@@ -84,6 +85,7 @@ private void userDefineRecognition(final Graph graph, Forest... forests) {
 						}
 					}
 				}
+
 				graph.rmLittlePath();
 				graph.walkPathByScore();
 				graph.rmLittlePath();

File: src/main/java/org/ansj/splitWord/analysis/DicAnalysis.java
Patch:
@@ -72,9 +72,6 @@ private void userDefineRecognition(final Graph graph, Forest... forests) {
 					String temp = null;
 					int tempFreq = 50;
 					while ((temp = word.getAllWords()) != null) {
-						if (graph.terms[word.offe] == null) {
-							continue;
-						}
 						Term tempTerm = graph.terms[word.offe];
 						tempFreq = getInt(word.getParam()[1], 50);
 						if (graph.terms[word.offe] != null && graph.terms[word.offe].getName().equals(temp)) {

File: src/main/java/org/ansj/splitWord/Analysis.java
Patch:
@@ -89,15 +89,16 @@ public Term next() throws IOException {
 		}
 
 		String temp = br.readLine();
-		offe = br.getStart();
 		while (StringUtil.isBlank(temp)) {
 			if (temp == null) {
+                offe = br.getStart();
 				return null;
 			} else {
 				temp = br.readLine();
 			}
 
 		}
+        offe = br.getStart();
 
 		// 歧异处理字符串
 

File: src/main/java/org/ansj/splitWord/Analysis.java
Patch:
@@ -89,15 +89,16 @@ public Term next() throws IOException {
 		}
 
 		String temp = br.readLine();
-		offe = br.getStart();
 		while (StringUtil.isBlank(temp)) {
 			if (temp == null) {
+                offe = br.getStart();
 				return null;
 			} else {
 				temp = br.readLine();
 			}
 
 		}
+        offe = br.getStart();
 
 		// 歧异处理字符串
 

File: src/main/java/org/ansj/app/summary/SummaryComputer.java
Patch:
@@ -120,13 +120,14 @@ private Summary explan(List<Keyword> keywords, String content) {
 			sf.add(keyword.getName(), keyword.getScore());
 		}
 
+
 		// 先断句
 		List<Sentence> sentences = toSentenceList(content.toCharArray());
 
 		boolean flag = false;
 
 		for (Sentence sentence : sentences) {
-			flag = flag || computeScore(sentence, sf, false);
+			flag = computeScore(sentence, sf, false) || flag ;
 		}
 
 		if (!flag) {
@@ -277,6 +278,7 @@ private boolean computeScore(Sentence sentence, SmartForest<Double> forest, bool
 		} else {
 			sentence.score /= Math.log(sentence.value.length() + 3);
 		}
+
 		return flag;
 	}
 

File: src/main/java/org/ansj/app/crf/model/CRFModel.java
Patch:
@@ -66,7 +66,7 @@ public boolean checkModel(String modelPath) {
 				return true;
 			}
 		} catch (ZipException ze) {
-			logger.warn("解压异常", ze);
+			logger.debug("解压异常", ze);
 		} catch (FileNotFoundException e) {
 			logger.warn("文件没有找到", e);
 		} catch (IOException e) {

File: src/main/java/org/ansj/domain/TermNatures.java
Patch:
@@ -126,6 +126,7 @@ public TermNatures(TermNature termNature, int allFreq, int id) {
 		termNatures = new TermNature[1];
 		termNature.frequency = allFreq;
 		this.termNatures[0] = termNature;
+		nature = termNature.nature ;
 		this.allFreq = allFreq;
 	}
 

File: src/main/java/org/ansj/recognition/impl/EmailRecognition.java
Patch:
@@ -35,7 +35,6 @@ public class EmailRecognition implements Recognition {
 
 	@Override
 	public void recognition(Result result) {
-
 		ExtractingResult parse = EXTRACTING.parse(result);
 
 		for (List<Term> list : parse.findAll()) {

File: src/test/java/org/ansj/app/crf/model/CRFModelTest.java
Patch:
@@ -5,6 +5,7 @@
 import org.ansj.app.crf.Model;
 import org.ansj.app.crf.SplitWord;
 import org.junit.Before;
+import org.junit.Ignore;
 import org.junit.Test;
 import org.nlpcn.commons.lang.util.StringUtil;
 
@@ -109,8 +110,9 @@ public void test() throws Exception {
 					System.out.println("example:" + temp_str);
 					System.out.println(
 							" result:" + paser.toString().replace("[", "").replace("]", "").replace(", ", "\t"));
+					System.out.println("[" + line_number + "]---准确率P:--" + ((double) success / paser.size()));
 				}
-				System.out.println("[" + line_number + "]---准确率P:--" + ((double) success / paser.size()));
+
 				line_number++;
 			}
 			// 正确数/总词数

File: src/test/java/org/ansj/app/crf/model/WapitiCRFModelTest.java
Patch:
@@ -20,6 +20,7 @@ public class WapitiCRFModelTest {
 	@Before
 	public void init() throws Exception {
 		if (!Check.checkFileExit(modelPath)) {
+			System.out.println(modelPath+" not found so skip!");
 			return;
 		}
 		model = new WapitiCRFModel();
@@ -121,8 +122,9 @@ public void test() throws Exception {
 			if (error > 0) {
 				System.out.println("example:" + temp_str);
 				System.out.println(" result:" + paser.toString().replace("[", "").replace("]", "").replace(", ", "\t"));
+				System.out.println("[" + line_number + "]---准确率P:--" + ((double) success / paser.size()));
 			}
-			System.out.println("[" + line_number + "]---准确率P:--" + ((double) success / paser.size()));
+
 			line_number++;
 		}
 		// 正确数/总词数

File: src/test/java/org/ansj/test/TagWordTest.java
Patch:
@@ -2,6 +2,7 @@
 
 import org.ansj.app.keyword.Keyword;
 import org.ansj.app.summary.TagContent;
+import org.junit.Ignore;
 import org.junit.Test;
 
 import java.util.ArrayList;

File: src/test/java/org/ansj/test/TestError.java
Patch:
@@ -12,6 +12,7 @@
 import org.ansj.splitWord.analysis.NlpAnalysis;
 import org.ansj.splitWord.analysis.ToAnalysis;
 import org.ansj.util.MyStaticValue;
+import org.junit.Ignore;
 import org.junit.Test;
 import org.nlpcn.commons.lang.tire.domain.Forest;
 import org.nlpcn.commons.lang.tire.domain.Value;
@@ -20,6 +21,7 @@
 import java.util.ArrayList;
 import java.util.List;
 
+
 public class TestError {
 
 	@Test

File: src/main/java/org/ansj/domain/NumNatureAttr.java
Patch:
@@ -2,7 +2,9 @@
 
 import org.ansj.library.NatureLibrary;
 
-public class NumNatureAttr  {
+import java.io.Serializable;
+
+public class NumNatureAttr implements Serializable {
 
 	public static final NumNatureAttr NULL = new NumNatureAttr(false, false);
 

File: src/main/java/org/ansj/splitWord/Analysis.java
Patch:
@@ -247,10 +247,8 @@ protected void setRealName(Graph graph, List<Term> result) {
 			return;
 		}
 
-		char[] chars = graph.chars;
-
 		for (Term term : result) {
-			term.setRealName(new String(chars, term.getOffe(), term.getName().length()));
+			term.setRealName(graph.str.substring(term.getOffe(),term.getOffe()+term.getName().length()));
 		}
 	}
 

File: src/main/java/org/ansj/util/Graph.java
Patch:
@@ -29,10 +29,13 @@ public class Graph {
 
 	public boolean hasNumQua;
 
+	public String str ;
+
 
 	// 是否需有歧异
 
 	public Graph(String str) {
+		this.str = str ;
 		this.chars = WordAlert.alertStr(str);
 		terms = new Term[chars.length + 1];
 		end = new Term(E, chars.length, AnsjItem.END);

File: src/test/java/org/ansj/demo/RealWordDemo.java
Patch:
@@ -19,7 +19,7 @@ public static void main(String[] args) {
 
 		// 保证方式
 		MyStaticValue.isRealName = true ;
-		parse = ToAnalysis.parse("Hello word是每个程序员必经之路");
+		parse = ToAnalysis.parse("Hello Word是每个程序员必经之路");
 		for (Term term : parse) {
 			System.out.print(term.getRealName()+" ");
 		}

File: src/test/java/org/ansj/test/IndexAnalysisTest.java
Patch:
@@ -10,14 +10,13 @@ public class IndexAnalysisTest {
 	public static void main(String[] args) throws IOException {
 		MyStaticValue.isNumRecognition = true;
 		MyStaticValue.isQuantifierRecognition = false;
-		DicLibrary.put(DicLibrary.DEFAULT, DicLibrary.DEFAULT, null);
 		DicLibrary.insert(DicLibrary.DEFAULT, "蛇药片", "n", 1000);
 		DicLibrary.insert(DicLibrary.DEFAULT, "蛇药", "n", 1000);
 		DicLibrary.insert(DicLibrary.DEFAULT, "鲁花", "n", 1000);
 		DicLibrary.insert(DicLibrary.DEFAULT, "隐形", "n", 1000);
 		DicLibrary.insert(DicLibrary.DEFAULT, "眼镜", "n", 1000);
 		DicLibrary.insert(DicLibrary.DEFAULT, "隐形眼镜", "n", 1000);
-		DicLibrary.insert(DicLibrary.DEFAULT, "海昌 ", "n", 1000);
+		DicLibrary.insert(DicLibrary.DEFAULT, "海昌", "n", 1000);
 		DicLibrary.insert(DicLibrary.DEFAULT, "美瞳", "n", 1000);
 
 		System.out.println(IndexAnalysis.parse("海昌 润洁除蛋白隐形眼镜美瞳护理液 500+120ml"));

File: src/main/java/org/ansj/domain/AnsjItem.java
Patch:
@@ -53,9 +53,6 @@ public void initValue(String[] split) {
 			name = split[1];
 			termNatures = new TermNatures(split[5], index);
 		}
-//		else{ 理论上不需要了
-//			termNatures = new TermNatures(TermNature.NULL);
-//		}
 	}
 
 	@Override

File: src/test/java/org/ansj/recognition/arrimpl/PersonRecognitionTest.java
Patch:
@@ -34,6 +34,8 @@ public void test() {
 				"李娜高擎“祥云”火炬” 的时候",//#113
 				"上海浦东沿街办公出租：东方路北园路三百二十平，3元8每日每平，橱窗宽八米送车位二个露台二百平，房东18917023639【森盛】", //#50
 				"苏宁易付宝",//#101
+				"我通向了幸福之路，我总和你说要多写代码，心理有万马奔腾",
+				"孙健和石源在韩小的右面，最左面是刘洁菲用电脑",
 		} ;
 
 		for (String str : tests){

File: src/main/java/org/ansj/domain/AnsjItem.java
Patch:
@@ -52,9 +52,10 @@ public void initValue(String[] split) {
 		if (status > 1) {
 			name = split[1];
 			termNatures = new TermNatures(split[5], index);
-		}else{
-			termNatures = new TermNatures(TermNature.NULL); 
 		}
+//		else{ 理论上不需要了
+//			termNatures = new TermNatures(TermNature.NULL);
+//		}
 	}
 
 	@Override

File: src/main/java/org/ansj/recognition/impl/NatureRecognition.java
Patch:
@@ -17,6 +17,7 @@
 import java.io.BufferedReader;
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.List;
 
 /**

File: src/main/java/org/ansj/app/extracting/Extracting.java
Patch:
@@ -8,6 +8,7 @@
 import org.ansj.domain.Term;
 import org.ansj.library.DicLibrary;
 import org.ansj.splitWord.analysis.DicAnalysis;
+import org.ansj.util.MyStaticValue;
 import org.nlpcn.commons.lang.tire.domain.Forest;
 import org.nlpcn.commons.lang.util.IOUtil;
 import org.nlpcn.commons.lang.util.StringUtil;

File: src/main/java/org/ansj/app/extracting/ExtractingTask.java
Patch:
@@ -63,7 +63,7 @@ public void run() {//排除一切干扰我只看我自己能走到多远
 		boolean end = true;
 
 		while ((token = token.getNext()) != null) { //判断是否结尾
-			if (token.getRange() != null && token.getRange()[0] != 0) {
+			if (token.getRange() == null || token.getRange()[0] != 0) {
 				end = false;
 			}
 		}
@@ -106,7 +106,6 @@ private Action validate(Token token, Term term) {
 			if (token.getNext() == null) {
 				return Action.OVER;
 			} else {
-				insertInto(term, token.getIndex());
 				return Action.NEXT_TERM_TOKEN;
 			}
 		} else {

File: src/main/java/org/ansj/recognition/arrimpl/NumRecognition.java
Patch:
@@ -132,9 +132,6 @@ public void recognition(Term[] terms) {
 			}
 
 
-
-
-
 			if (quantifierRecognition) { //开启量词识别
 				to = temp.to();
 				if (to.termNatures().numAttr.qua) {

File: src/test/java/org/ansj/app/extracting/ExtractingTest.java
Patch:
@@ -21,6 +21,7 @@ public void test() throws IOException, RuleFormatException {
 
 		ExtractingResult result = null ;
 
+
          result = extracting.parse("2017年2月12日是一个特殊的日子");
 
 		System.out.println(result.getAllResult()); ;
@@ -39,7 +40,7 @@ public void test1() throws RuleFormatException {
 
 		//填写规则 可以写多条
 		lines.add("(:bName)(:*){0,3}(并发症)(有|都有)(哪些|什么)\t名称:0;限定:2;目的:(个数)") ;
-		lines.add("(:bName)(如何|怎么){0,1}(防治|避免){0,1}\t名称:0;限定:2;目的:(防治)") ;
+		lines.add("(:bName)(如何|怎么){0,1}(防治|避免)\t名称:0;限定:2") ;
 
 		Extracting extracting = new Extracting(lines) ;
 

File: src/main/java/org/ansj/domain/TermNatures.java
Patch:
@@ -87,7 +87,7 @@ public TermNatures(String natureStr, int id) {
 				this.numAttr = new NumNatureAttr(false, true, strs[0].replaceFirst("q_", ""));
 			} else {
 				all[i] = new TermNature(strs[0], frequency);
-				if (maxFreq < frequency) {
+				if (maxFreq <= frequency) {
 					maxFreq = frequency;
 					maxTermNature = all[i];
 				}

File: src/test/java/org/ansj/recognition/arrimpl/NumRecognitionTest.java
Patch:
@@ -13,10 +13,10 @@ public class NumRecognitionTest {
 	@Test
 	public void test(){
 
-//		MyStaticValue.isRealName = false ;
+		MyStaticValue.isRealName = false ;
 		System.out.println(ToAnalysis.parse("一下2016年")); ;// #360
 		System.out.println(ToAnalysis.parse("实际上相对于此次未来AN TPY-2的天线指向")); ;
-		System.out.println(ToAnalysis.parse("2中性粒细胞百分数NEUT%70.2040.00--75.00%\n"));
+		System.out.println(ToAnalysis.parse("2中性粒细胞百分数NEUT%70.2040.00--75.00%\n").toString("\t"));
 		System.out.println(ToAnalysis.parse("计划建立一个5万公顷面积的航天站一2月11日")); //#164
 		System.out.println(ToAnalysis.parse("１２３４５６半角打出的数字是这样的。123456 "));
 		System.out.println(ToAnalysis.parse("１２３４５６半角打出的数字是这样的。123456万个平方 "));

File: src/main/java/org/ansj/domain/AnsjItem.java
Patch:
@@ -1,6 +1,7 @@
 package org.ansj.domain;
 
 import java.io.Serializable;
+import java.util.Arrays;
 import java.util.Map;
 
 import org.nlpcn.commons.lang.dat.Item;
@@ -46,9 +47,10 @@ public void initValue(String[] split) {
 		base = Integer.parseInt(split[2]);
 		check = Integer.parseInt(split[3]);
 		status = Byte.parseByte(split[4]);
+
 		if (status > 1) {
 			name = split[1];
-			termNatures = new TermNatures(TermNature.setNatureStrToArray(split[5]), index);
+			termNatures = new TermNatures(split[5], index);
 		}else{
 			termNatures = new TermNatures(TermNature.NULL); 
 		}

File: src/main/java/org/ansj/domain/Nature.java
Patch:
@@ -30,6 +30,8 @@ public class Nature implements Serializable {
 
 	public static final Nature NR = NatureLibrary.getNature("nr");
 
+	public static final Nature MQ = NatureLibrary.getNature("mq");
+
 	public static final Nature NULL = NatureLibrary.getNature("null");
 
 	public Nature(String natureStr, int index, int natureIndex, int allFrequency) {

File: src/main/java/org/ansj/splitWord/analysis/DicAnalysis.java
Patch:
@@ -39,7 +39,7 @@ public List<Term> merger() {
 				graph.walkPath();
 
 				// 数字发现
-				if (isNumRecognition && graph.hasNum) {
+				if (isNumRecognition) {
 					new NumRecognition(isQuantifierRecognition).recognition(graph.terms);
 				}
 

File: src/main/java/org/ansj/splitWord/analysis/IndexAnalysis.java
Patch:
@@ -40,7 +40,7 @@ public List<Term> merger() {
 				graph.walkPath();
 
 				// 数字发现
-				if (isNumRecognition && graph.hasNum) {
+				if (isNumRecognition) {
 					new NumRecognition(isQuantifierRecognition).recognition(graph.terms);
 				}
 

File: src/main/java/org/ansj/splitWord/analysis/NlpAnalysis.java
Patch:
@@ -141,7 +141,7 @@ public List<Term> merger() {
 				}
 
 				// 数字发现
-				if (graph.hasNum && isNumRecognition) {
+				if (isNumRecognition) {
 					new NumRecognition(isQuantifierRecognition).recognition(graph.terms);
 				}
 

File: src/main/java/org/ansj/splitWord/analysis/ToAnalysis.java
Patch:
@@ -35,7 +35,7 @@ public List<Term> merger() {
 				graph.walkPath();
 
 				// 数字发现
-				if (isNumRecognition && graph.hasNum) {
+				if (isNumRecognition) {
 					new NumRecognition(isQuantifierRecognition).recognition(graph.terms);
 				}
 

File: src/main/java/org/ansj/splitWord/analysis/DicAnalysis.java
Patch:
@@ -40,7 +40,7 @@ public List<Term> merger() {
 
 				// 数字发现
 				if (isNumRecognition && graph.hasNum) {
-					new NumRecognition().recognition(graph.terms);
+					new NumRecognition(isQuantifierRecognition).recognition(graph.terms);
 				}
 
 				// 姓名识别

File: src/main/java/org/ansj/splitWord/analysis/IndexAnalysis.java
Patch:
@@ -41,7 +41,7 @@ public List<Term> merger() {
 
 				// 数字发现
 				if (isNumRecognition && graph.hasNum) {
-					new NumRecognition().recognition(graph.terms);
+					new NumRecognition(isQuantifierRecognition).recognition(graph.terms);
 				}
 
 				// 姓名识别

File: src/main/java/org/ansj/splitWord/analysis/NlpAnalysis.java
Patch:
@@ -142,7 +142,7 @@ public List<Term> merger() {
 
 				// 数字发现
 				if (graph.hasNum && isNumRecognition) {
-					new NumRecognition().recognition(graph.terms);
+					new NumRecognition(isQuantifierRecognition).recognition(graph.terms);
 				}
 
 				// 词性标注

File: src/main/java/org/ansj/splitWord/analysis/ToAnalysis.java
Patch:
@@ -36,7 +36,7 @@ public List<Term> merger() {
 
 				// 数字发现
 				if (isNumRecognition && graph.hasNum) {
-					new NumRecognition().recognition(graph.terms);
+					new NumRecognition(isQuantifierRecognition).recognition(graph.terms);
 				}
 
 				// 姓名识别

File: src/main/java/org/ansj/dic/PathToStream.java
Patch:
@@ -25,7 +25,7 @@ public static InputStream stream(String path) {
 			} else if (path.startsWith("jar://")) {
 				return new Jar2Stream().toStream(path);
 			} else if (path.startsWith("class://")) {
-				((PathToStream) Class.forName(path.substring(8).split("\\|")[0]).newInstance()).toStream(path);
+				return ((PathToStream) Class.forName(path.substring(8).split("\\|")[0]).newInstance()).toStream(path);
 			} else if (path.startsWith("http://")||path.startsWith("https://")) {
 				return new Url2Stream().toStream(path);
 			} else {
@@ -34,7 +34,6 @@ public static InputStream stream(String path) {
 		} catch (Exception e) {
 			throw new LibraryException(e);
 		}
-		throw new LibraryException("not find method type in path " + path);
 	}
 
 	public abstract InputStream toStream(String path);

File: src/main/java/org/ansj/dic/PathToStream.java
Patch:
@@ -25,7 +25,7 @@ public static InputStream stream(String path) {
 			} else if (path.startsWith("jar://")) {
 				return new Jar2Stream().toStream(path);
 			} else if (path.startsWith("class://")) {
-				((PathToStream) Class.forName(path.substring(8).split("\\|")[0]).newInstance()).toStream(path);
+				return ((PathToStream) Class.forName(path.substring(8).split("\\|")[0]).newInstance()).toStream(path);
 			} else if (path.startsWith("http://")||path.startsWith("https://")) {
 				return new Url2Stream().toStream(path);
 			} else {
@@ -34,7 +34,6 @@ public static InputStream stream(String path) {
 		} catch (Exception e) {
 			throw new LibraryException(e);
 		}
-		throw new LibraryException("not find method type in path " + path);
 	}
 
 	public abstract InputStream toStream(String path);

File: src/main/java/org/ansj/app/summary/SummaryComputer.java
Patch:
@@ -145,7 +145,7 @@ private Summary explan(List<Keyword> keywords, String content) {
 				}
 				mc.get().clear();
 			}
-			for (int j = i + 1; j < sentences.size(); j++) {
+			for (int j = i ; j < sentences.size(); j++) {
 				tempScore += sentences.get(j).score;
 				tempLength += sentences.get(j).value.length();
 				mc.addAll(sentences.get(j).mc.get());

File: src/main/java/org/ansj/library/StopLibrary.java
Patch:
@@ -135,7 +135,6 @@ private synchronized static StopRecognition init(String key, KV<String, StopReco
 			try (BufferedReader br = IOUtil.getReader(PathToStream.stream(kv.getK()), "UTF-8")) {
 				while ((temp = br.readLine()) != null) {
 					if (StringUtil.isNotBlank(temp)) {
-						temp = StringUtil.trim(temp);
 						strs = temp.split("\t");
 
 						if (strs.length == 1) {

File: src/test/java/org/ansj/app/summary/TagContentTest.java
Patch:
@@ -81,6 +81,8 @@ public void test1() {
 				keywords.add(new Keyword(kw, 100.0d * kw.length()));
 			}
 		}
+		
+		System.out.println(sc.toSummary(keywords).getSummary());
 
 		String tagContent = tc.tagContent(sc.toSummary(keywords));
 

File: src/main/java/org/ansj/app/crf/MakeTrainFile.java
Patch:
@@ -7,7 +7,6 @@
 import java.util.List;
 
 import org.ansj.app.crf.pojo.Element;
-import org.ansj.util.MyStaticValue;
 import org.nlpcn.commons.lang.util.IOUtil;
 import org.nlpcn.commons.lang.util.StringUtil;
 import org.nlpcn.commons.lang.util.logging.Log;

File: src/main/java/org/ansj/app/crf/Model.java
Patch:
@@ -12,7 +12,6 @@
 import org.ansj.app.crf.model.CRFModel;
 import org.ansj.app.crf.model.CRFppTxtModel;
 import org.ansj.app.crf.model.WapitiCRFModel;
-import org.ansj.util.MyStaticValue;
 import org.nlpcn.commons.lang.tire.domain.SmartForest;
 import org.nlpcn.commons.lang.util.MapCount;
 import org.nlpcn.commons.lang.util.logging.Log;
@@ -129,7 +128,7 @@ protected static void printFeatureTree(String cs, float[] tempW) {
 		if (tempW.length == 4) {
 			name = "U";
 		}
-		name += "*" + ((int) cs.charAt(cs.length() - 1) - Config.FEATURE_BEGIN + 1) + ":" + cs.substring(0, cs.length() - 1);
+		name += "*" + (cs.charAt(cs.length() - 1) - Config.FEATURE_BEGIN + 1) + ":" + cs.substring(0, cs.length() - 1);
 		for (int i = 0; i < tempW.length; i++) {
 			if (tempW[i] != 0) {
 				System.out.println(name + "\t" + Config.getTagName(i / 4 - 1) + "\t" + Config.getTagName(i % 4) + "\t" + tempW[i]);

File: src/main/java/org/ansj/app/crf/model/CRFppTxtModel.java
Patch:
@@ -34,6 +34,7 @@ public class CRFppTxtModel extends Model {
 	 * 
 	 * @return
 	 */
+	@Override
 	public CRFppTxtModel loadModel(String modelPath) throws Exception {
 		try (InputStream is = new FileInputStream(modelPath)) {
 			loadModel(new FileInputStream(modelPath));

File: src/main/java/org/ansj/app/crf/model/WapitiCRFModel.java
Patch:
@@ -27,12 +27,14 @@
  */
 public class WapitiCRFModel extends Model {
 
+	@Override
 	public WapitiCRFModel loadModel(String modelPath) throws Exception {
 		try (InputStream is = IOUtil.getInputStream(modelPath)) {
 			return loadModel(is);
 		}
 	}
 
+	@Override
 	public WapitiCRFModel loadModel(InputStream is) throws Exception {
 		BufferedReader br = IOUtil.getReader(is, IOUtil.UTF8);
 

File: src/main/java/org/ansj/app/keyword/KeyWordComputer.java
Patch:
@@ -10,7 +10,6 @@
 import org.ansj.splitWord.Analysis;
 import org.ansj.splitWord.analysis.*;
 import org.nlpcn.commons.lang.util.StringUtil;
-import org.nutz.dao.entity.annotation.Default;
 
 public class KeyWordComputer<T extends Analysis> {
 
@@ -143,7 +142,7 @@ private double getWeight(Term term, int length, int titleLength) {
         if (titleLength > term.getOffe()) {
             return 5 * posScore;
         }
-        return (length - term.getOffe()) * posScore / (double) length;
+        return (length - term.getOffe()) * posScore / length;
     }
 
 }

File: src/main/java/org/ansj/app/summary/SummaryComputer.java
Patch:
@@ -303,6 +303,7 @@ public void updateScore(String name, double score) {
 			this.score += score / size;
 		}
 
+		@Override
 		public String toString() {
 			return value;
 		}

File: src/main/java/org/ansj/dic/impl/File2Stream.java
Patch:
@@ -4,7 +4,6 @@
 import java.io.FileFilter;
 import java.io.FileInputStream;
 import java.io.FileNotFoundException;
-import java.io.FilenameFilter;
 import java.io.InputStream;
 import java.io.SequenceInputStream;
 import java.util.Vector;
@@ -62,6 +61,7 @@ private InputStream multiple(String path) throws FileNotFoundException {
 			} else if (file.isDirectory()) {
 
 				File[] files = file.listFiles(new FileFilter() {
+					@Override
 					public boolean accept(File file) {
 						return file.canRead() && !file.isHidden() && !file.isDirectory();
 					}

File: src/main/java/org/ansj/library/AmbiguityLibrary.java
Patch:
@@ -65,7 +65,7 @@ public static Forest get(String key) {
 			return null;
 		}
 
-		Forest sw = (Forest) kv.getV();
+		Forest sw = kv.getV();
 		if (sw == null) {
 			try {
 				sw = init(key, kv, false);
@@ -159,13 +159,12 @@ public static void insert(String key, Value value) {
 	 * @param dic2
 	 */
 	public static void put(String key, String path) {
-
 		put(key, path, null);
 	}
 
 	public static void put(String key, String path, Forest value) {
-
 		AMBIGUITY.put(key, KV.with(path, value));
+		MyStaticValue.ENV.put(key, path);
 	}
 
 	/**
@@ -179,6 +178,7 @@ public static KV<String, Forest> remove(String key) {
 		if (kv != null && kv.getV() != null) {
 			kv.getV().clear();
 		}
+		MyStaticValue.ENV.remove(key) ;
 		return AMBIGUITY.remove(key);
 	}
 

File: src/main/java/org/ansj/library/CrfLibrary.java
Patch:
@@ -55,7 +55,7 @@ public static SplitWord get(String key) {
 			return null;
 		}
 
-		SplitWord sw = (SplitWord) kv.getV();
+		SplitWord sw = kv.getV();
 		if (sw == null) {
 			sw = initCRFModel(kv);
 		}
@@ -101,8 +101,8 @@ public static void put(String key, String path) {
 	}
 
 	public static void put(String key, String path, SplitWord sw) {
-
 		CRF.put(key, KV.with(path, sw));
+		MyStaticValue.ENV.put(key, path);
 	}
 
 	/**
@@ -112,7 +112,7 @@ public static void put(String key, String path, SplitWord sw) {
 	 * @return
 	 */
 	public static KV<String, SplitWord> remove(String key) {
-
+		MyStaticValue.ENV.remove(key) ;
 		return CRF.remove(key);
 	}
 

File: src/main/java/org/ansj/library/DATDictionary.java
Patch:
@@ -104,7 +104,7 @@ private static void personNameFull(DoubleArrayTire dat) throws NumberFormatExcep
 	}
 
 	public static int status(char c) {
-		Item item = (AnsjItem) DAT.getDAT()[c];
+		Item item = DAT.getDAT()[c];
 		if (item == null) {
 			return 0;
 		}

File: src/main/java/org/ansj/library/DicLibrary.java
Patch:
@@ -198,7 +198,7 @@ private synchronized static Forest init(String key, KV<String, Forest> kv, boole
 			kv.setV(forest);
 			return forest;
 		} catch (Exception e) {
-			LOG.error("Init ambiguity library error :" + e.getMessage() + ", path: " + kv.getK());
+			LOG.error("Init dic library error :" + e.getMessage() + ", path: " + kv.getK());
 			DIC.remove(key);
 			return null;
 		}
@@ -213,6 +213,7 @@ private synchronized static Forest init(String key, KV<String, Forest> kv, boole
 	 */
 	public static void put(String key, String path, Forest forest) {
 		DIC.put(key, KV.with(path, forest));
+		MyStaticValue.ENV.put(key, path);
 	}
 
 	/**
@@ -237,7 +238,6 @@ public static void putIfAbsent(String key, String path) {
 	 * @param dic2
 	 */
 	public static void put(String key, String path) {
-
 		put(key, path, null);
 	}
 
@@ -266,6 +266,7 @@ public static KV<String, Forest> remove(String key) {
 		if (kv != null && kv.getV() != null) {
 			kv.getV().clear();
 		}
+		MyStaticValue.ENV.remove(key) ;
 		return DIC.remove(key);
 	}
 

File: src/main/java/org/ansj/library/SynonymsLibrary.java
Patch:
@@ -54,7 +54,7 @@ public static SmartForest<List<String>> get(String key) {
 			return null;
 		}
 
-		SmartForest<List<String>> sw = (SmartForest<List<String>>) kv.getV();
+		SmartForest<List<String>> sw = kv.getV();
 		if (sw == null) {
 			sw = init(key, kv, false);
 		}
@@ -134,6 +134,7 @@ public static void put(String key, String path) {
 
 	public static void put(String key, String path, SmartForest<List<String>> value) {
 		SYNONYMS.put(key, KV.with(path, value));
+		MyStaticValue.ENV.put(key, path);
 	}
 
 	/**
@@ -147,6 +148,7 @@ public static KV<String, SmartForest<List<String>>> remove(String key) {
 		if (kv != null && kv.getV() != null) { //先清空后删除
 			kv.getV().clear();
 		}
+		MyStaticValue.ENV.remove(key) ;
 		return SYNONYMS.remove(key);
 	}
 

File: src/main/java/org/ansj/recognition/arrimpl/AsianPersonRecognition.java
Patch:
@@ -35,6 +35,7 @@ public class AsianPersonRecognition implements TermArrRecognition{
 	// public int m = -1;//44 可拆分的姓名
 	// double[] factory = {"BC", "BCD", "BCDE"}
 
+	@Override
 	public void recognition(Term[] terms) {
 		this.terms = terms;
 		List<Term> termList = recogntion_();

File: src/main/java/org/ansj/recognition/arrimpl/ForeignPersonRecognition.java
Patch:
@@ -52,6 +52,7 @@ public class ForeignPersonRecognition implements TermArrRecognition {
 	private LinkedList<NameChar> prList = null;
 	private Term[] terms = null;
 
+	@Override
 	public void recognition(Term[] terms) {
 		this.terms = terms;
 		String name = null;

File: src/main/java/org/ansj/recognition/arrimpl/NumRecognition.java
Patch:
@@ -12,6 +12,7 @@ public class NumRecognition implements TermArrRecognition {
 	 * 
 	 * @param terms
 	 */
+	@Override
 	public void recognition(Term[] terms) {
 		int length = terms.length - 1;
 		Term from = null;

File: src/main/java/org/ansj/recognition/arrimpl/UserDefineRecognition.java
Patch:
@@ -44,6 +44,7 @@ public UserDefineRecognition(InsertTermType type, Forest... forests) {
 
 	}
 
+	@Override
 	public void recognition(Term[] terms) {
 		this.terms = terms;
 		for (Forest forest : forests) {

File: src/main/java/org/ansj/recognition/impl/BookRecognition.java
Patch:
@@ -31,6 +31,7 @@ public class BookRecognition implements Recognition {
 		ruleMap.put("《", "》");
 	}
 
+	@Override
 	public void recognition(Result result) {
 		List<Term> terms = result.getTerms() ;
 		String end = null;

File: src/main/java/org/ansj/recognition/impl/EmailRecognition.java
Patch:
@@ -32,6 +32,7 @@ public class EmailRecognition implements Recognition{
 
 	}
 
+	@Override
 	public void recognition(Result result) {
 		
 		List<Term> terms = result.getTerms() ;
@@ -44,7 +45,7 @@ public void recognition(Result result) {
 		}
 
 		for (Iterator<Term> iterator = terms.iterator(); iterator.hasNext();) {
-			Term term = (Term) iterator.next();
+			Term term = iterator.next();
 			if (term.getName() == null) {
 				iterator.remove();
 			}

File: src/main/java/org/ansj/recognition/impl/IDCardRecognition.java
Patch:
@@ -21,6 +21,7 @@ public class IDCardRecognition implements Recognition {
 	private static final long serialVersionUID = -32133440735240290L;
 	private static final Nature ID_CARD_NATURE = new Nature("idcard");
 
+	@Override
 	public void recognition(Result result) {
 
 		List<Term> terms = result.getTerms() ;
@@ -43,7 +44,7 @@ public void recognition(Result result) {
 		}
 
 		for (Iterator<Term> iterator = terms.iterator(); iterator.hasNext();) {
-			Term term = (Term) iterator.next();
+			Term term = iterator.next();
 			if (term.getName() == null) {
 				iterator.remove();
 			}

File: src/main/java/org/ansj/recognition/impl/NatureRecognition.java
Patch:
@@ -74,6 +74,7 @@ public NatureRecognition(Forest... forests) {
 	/**
 	 * 进行最佳词性查找,引用赋值.所以不需要有返回值
 	 */
+	@Override
 	public void recognition(Result result) {
 		this.terms = result.getTerms();
 		natureTermTable = new NatureTerm[terms.size() + 1][];

File: src/main/java/org/ansj/splitWord/Analysis.java
Patch:
@@ -5,7 +5,6 @@
 import java.io.IOException;
 import java.io.Reader;
 import java.util.ArrayList;
-import java.util.Arrays;
 import java.util.LinkedList;
 import java.util.List;
 

File: src/main/java/org/ansj/splitWord/analysis/ToAnalysis.java
Patch:
@@ -1,7 +1,6 @@
 package org.ansj.splitWord.analysis;
 
 import java.io.Reader;
-import java.io.StringReader;
 import java.util.ArrayList;
 import java.util.List;
 

File: src/main/java/org/ansj/util/AnsjReader.java
Patch:
@@ -58,6 +58,7 @@ private void ensureOpen() throws IOException {
 	/**
 	 * 为了功能的单一性我还是不实现了
 	 */
+	@Override
 	public int read(char cbuf[], int off, int len) throws IOException {
 		throw new IOException("AnsjBufferedReader not support this interface! ");
 	}
@@ -198,6 +199,7 @@ private void readString() throws IOException {
 
 	}
 
+	@Override
 	public void close() throws IOException {
 		synchronized (lock) {
 			if (in == null)

File: src/test/java/org/ansj/app/crf/ConfigTest.java
Patch:
@@ -1,7 +1,5 @@
 package org.ansj.app.crf;
 
-import static org.junit.Assert.*;
-
 import java.util.List;
 
 import org.ansj.app.crf.pojo.Element;

File: src/test/java/org/ansj/app/crf/ModelTest.java
Patch:
@@ -5,7 +5,6 @@
 import java.util.Set;
 
 import org.ansj.library.CrfLibrary;
-import org.ansj.util.MyStaticValue;
 import org.junit.Test;
 
 import junit.framework.Assert;

File: src/test/java/org/ansj/app/summary/TagContentTest.java
Patch:
@@ -1,12 +1,9 @@
 package org.ansj.app.summary;
 
-import static org.junit.Assert.*;
-
 import java.util.ArrayList;
 import java.util.List;
 
 import org.ansj.app.keyword.Keyword;
-import org.ansj.app.summary.pojo.Summary;
 import org.junit.Test;
 import org.nlpcn.commons.lang.util.StringUtil;
 

File: src/test/java/org/ansj/demo/BaseAnalysisDemo.java
Patch:
@@ -1,9 +1,6 @@
 package org.ansj.demo;
 
-import java.util.List;
-
 import org.ansj.domain.Result;
-import org.ansj.domain.Term;
 import org.ansj.splitWord.analysis.BaseAnalysis;
 
 /**

File: src/test/java/org/ansj/demo/JianFanZhuanhuanDemo.java
Patch:
@@ -4,7 +4,6 @@
 import java.util.List;
 
 import org.ansj.domain.Result;
-import org.ansj.domain.Term;
 import org.ansj.splitWord.analysis.NlpAnalysis;
 import org.ansj.util.MyStaticValue;
 

File: src/test/java/org/ansj/demo/NlpDemo.java
Patch:
@@ -6,7 +6,6 @@
 
 import org.ansj.dic.LearnTool;
 import org.ansj.domain.Result;
-import org.ansj.domain.Term;
 import org.ansj.splitWord.analysis.NlpAnalysis;
 
 public class NlpDemo {

File: src/test/java/org/ansj/demo/RealWordDemo.java
Patch:
@@ -1,7 +1,5 @@
 package org.ansj.demo;
 
-import java.util.List;
-
 import org.ansj.domain.Result;
 import org.ansj.domain.Term;
 import org.ansj.splitWord.analysis.ToAnalysis;

File: src/test/java/org/ansj/dic/impl/Jar2StreamTest.java
Patch:
@@ -3,13 +3,14 @@
 import java.io.IOException;
 import java.io.InputStream;
 
+import org.ansj.dic.PathToStream;
 import org.junit.Test;
 
 public class Jar2StreamTest {
 
 	@Test
 	public void test() throws IOException {
-		InputStream stream = Jar2Stream.stream("jar://org.ansj.dic.DicReader|/crf.model") ;
+		InputStream stream = PathToStream.stream("jar://org.ansj.dic.DicReader|/crf.model") ;
 		System.out.println(stream);
 		stream.close();
 	}

File: src/test/java/org/ansj/recognition/impl/NatureRecognitionTest.java
Patch:
@@ -1,7 +1,6 @@
 package org.ansj.recognition.impl;
 
 import org.ansj.splitWord.analysis.NlpAnalysis;
-import org.ansj.splitWord.analysis.ToAnalysis;
 import org.junit.Test;
 
 /**

File: src/test/java/org/ansj/recognition/impl/UserDicNatureRecognitionTest.java
Patch:
@@ -2,7 +2,6 @@
 
 import org.ansj.splitWord.analysis.ToAnalysis;
 import org.junit.Test;
-import org.nlpcn.commons.lang.tire.GetWord;
 
 public class UserDicNatureRecognitionTest {
 

File: src/test/java/org/ansj/test/CoreLibraryMaker.java
Patch:
@@ -33,7 +33,7 @@ public static void main(String[] args) throws Exception {
 			insertToArray(dat, (char) i, (byte) 5, "{nb=1}");
 		}
 
-		insertToArray(dat, (char) '\'', (byte) 4, "{en=1}");
+		insertToArray(dat, '\'', (byte) 4, "{en=1}");
 
 		for (int i = 'a'; i <= 'z'; i++) {
 			insertToArray(dat, (char) i, (byte) 4, "{en=1}");

File: plugin/ansj_lucene6_plugin/src/test/java/org/ansj/ansj_lucene_plug/HeightLightTest.java
Patch:
@@ -46,7 +46,7 @@ public static void main(String[] args) throws CorruptIndexException, IOException
 
 		System.out.println(IndexAnalysis.parse(content));
 
-		String query = "\"交通安全出行\"";
+		String query = "text:\"交通安全出行\"";
 
 		// 建立内存索引对象
 		index(indexAnalyzer, content);

File: src/main/java/org/ansj/library/CrfLibrary.java
Patch:
@@ -127,6 +127,8 @@ public static void reload(String key) {
 		if (kv != null) {
 			CRF.get(key).setV(null);
 		}
+
+		LOG.warn("make sure ,this reload not use same obj , it to instance a new model");
 	}
 
 	public static Set<String> keys() {

File: src/main/java/org/ansj/util/MyStaticValue.java
Patch:
@@ -67,7 +67,7 @@ public class MyStaticValue {
 					LOG.info("load ansj_library not find in classPath ! i find it in " + find.getAbsolutePath() + " make sure it is your config!");
 				}
 			} catch (Exception e1) {
-				LOG.warn("not find ansj_library.properties. and err {} i think it is a bug!");
+				LOG.warn("not find ansj_library.properties. reason: " + e1.getMessage());
 			}
 		}
 
@@ -82,7 +82,7 @@ public class MyStaticValue {
 						LOG.info("load library not find in classPath ! i find it in " + find.getAbsolutePath() + " make sure it is your config!");
 					}
 				} catch (Exception e1) {
-					LOG.warn("not find library.properties. and err {} i think it is a bug!", e1);
+					LOG.warn("not find library.properties. reason: " + e1.getMessage());
 				}
 			}
 		}

File: plugin/ansj_lucene5_plugin/src/main/java/org/ansj/lucene/util/AnsjTokenizer.java
Patch:
@@ -40,7 +40,7 @@ public AnsjTokenizer(Analysis ta, List<StopRecognition> stops, List<SynonymsRecg
 		this.synonyms = synonyms;
 	}
 	
-	int position = -1;
+	int position = 0;
 
 	@Override
 	public final boolean incrementToken() throws IOException {

File: plugin/ansj_lucene6_plugin/src/main/java/org/ansj/lucene/util/AnsjTokenizer.java
Patch:
@@ -40,7 +40,7 @@ public AnsjTokenizer(Analysis ta, List<StopRecognition> stops, List<SynonymsRecg
 		this.synonyms = synonyms;
 	}
 	
-	int position = -1;
+	int position = 0;
 
 	@Override
 	public final boolean incrementToken() throws IOException {

File: src/main/java/org/ansj/recognition/impl/StopRecognition.java
Patch:
@@ -89,7 +89,6 @@ public void insertStopRegexes(String... regexes) {
 	@Override
 	public void recognition(Result result) {
 		List<Term> list = result.getTerms();
-
 		Iterator<Term> iterator = list.iterator();
 
 		while (iterator.hasNext()) {
@@ -108,6 +107,7 @@ public void recognition(Result result) {
 	 * @return
 	 */
 	public boolean filter(Term term) {
+
 		if (stop.size() > 0 && (stop.contains(term.getName()))) {
 			return true;
 		}

File: src/main/java/org/ansj/splitWord/analysis/DicAnalysis.java
Patch:
@@ -63,7 +63,7 @@ public List<Term> merger() {
 
 			private void userDefineRecognition(final Graph graph, Forest... forests) {
 
-				if (graph.terms[0] == null) {
+				if (forests == null) {
 					return;
 				}
 

File: src/test/java/org/ansj/test/TestError.java
Patch:
@@ -174,7 +174,9 @@ public void test() throws Exception {
 //		for (Term term : parse) {
 //			Assert.assertFalse(term.getName().equals(" 人"));
 //		}
-		
+		System.out.println(DicAnalysis.parse("玫玫玫玫玫┏┏┏┏┏玫玫玫玫玫玫玫玫玫玫玫玫玫",null));
+		System.out.println(DicAnalysis.parse("┏┏┏┏┏玫玫玫玫玫玫玫玫玫玫玫玫玫",null));
+		System.out.println(DicAnalysis.parse("┏玫┏红色┏玫红┏色┏玫红色",null));
 		
 		System.out.println(ToAnalysis.parse("┏玫红色玫红色玫红色",null));
 		

File: src/test/java/org/ansj/app/summary/TagContentTest.java
Patch:
@@ -45,7 +45,7 @@ public void test() {
 
 		SummaryComputer sc = new SummaryComputer(300, true, null, content);
 
-		TagContent tc = new TagContent("<begin>", "end");
+		TagContent tc = new TagContent("<begin>", "<end>");
 
 		String[] split = query.split(" ");
 

File: src/main/java/org/ansj/recognition/arrimpl/UserDefineRecognition.java
Patch:
@@ -5,7 +5,6 @@
 import org.ansj.domain.TermNatures;
 import org.ansj.library.DicLibrary;
 import org.ansj.recognition.TermArrRecognition;
-import org.ansj.util.MyStaticValue;
 import org.ansj.util.TermUtil;
 import org.ansj.util.TermUtil.InsertTermType;
 import org.nlpcn.commons.lang.tire.domain.Forest;

File: src/main/java/org/ansj/splitWord/analysis/NlpAnalysis.java
Patch:
@@ -107,8 +107,7 @@ public List<Term> merger() {
 						}
 
 						tempOff += word.length(); // 增加偏移量
-
-						if (term.isNewWord() && isRuleWord(word)) { // 如果word不对那么不要了
+						if (isRuleWord(word)) { // 如果word不对那么不要了
 							tempTerm = null;
 							continue;
 						}
@@ -192,6 +191,7 @@ private List<Term> getResult() {
 
 	static {
 		filter.add(':');
+		filter.add(' ');
 		filter.add('：');
 		filter.add('　');
 		filter.add('，');

File: src/main/java/org/ansj/library/AmbiguityLibrary.java
Patch:
@@ -83,7 +83,7 @@ private static synchronized Forest init(String key, KV<String, Forest> kv) {
 		forest = new Forest();
 		try (BufferedReader br = IOUtil.getReader(PathToStream.stream(kv.getK()), "utf-8")) {
 			String temp;
-			LOG.info("begin init dic !");
+			LOG.debug("begin init ambiguity");
 			long start = System.currentTimeMillis();
 			while ((temp = br.readLine()) != null) {
 				if (StringUtil.isNotBlank(temp)) {

File: src/main/java/org/ansj/library/CrfLibrary.java
Patch:
@@ -71,7 +71,7 @@ private static synchronized SplitWord initCRFModel(KV<String, SplitWord> kv) {
 			}
 
 			long start = System.currentTimeMillis();
-			LOG.info("begin init crf model!");
+			LOG.debug("begin init crf model!");
 			try (InputStream is = PathToStream.stream(kv.getK())) {
 				SplitWord crfSplitWord = new SplitWord(Model.load(CRFModel.class, is));
 				kv.setV(crfSplitWord);

File: src/main/java/org/ansj/library/DicLibrary.java
Patch:
@@ -137,7 +137,7 @@ private synchronized static Forest init(String key, KV<String, Forest> kv) {
 		}
 		try {
 			forest = new Forest();
-			LOG.info("begin init dic !");
+			LOG.debug("begin init dic !");
 			long start = System.currentTimeMillis();
 			String temp = null;
 			String[] strs = null;

File: src/main/java/org/ansj/library/FilterLibrary.java
Patch:
@@ -107,7 +107,7 @@ private synchronized static FilterRecognition init(String key, KV<String, Filter
 		}
 		try {
 			filterRecognition = new FilterRecognition();
-			LOG.info("begin init FILTER !");
+			LOG.debug("begin init FILTER !");
 			long start = System.currentTimeMillis();
 			String temp = null;
 			String[] strs = null;

File: src/main/java/org/ansj/library/SynonymsLibrary.java
Patch:
@@ -72,7 +72,7 @@ private static synchronized SmartForest<List<String>> init(String key, KV<String
 
 		forest = new SmartForest<>();
 
-		LOG.info("begin init synonyms " + kv.getK());
+		LOG.debug("begin init synonyms " + kv.getK());
 		long start = System.currentTimeMillis();
 
 		try (BufferedReader reader = IOUtil.getReader(PathToStream.stream(kv.getK()), IOUtil.UTF8)) {

File: src/main/java/org/ansj/library/DATDictionary.java
Patch:
@@ -146,7 +146,7 @@ public static AnsjItem getItem(int index) {
 
 	public static AnsjItem getItem(String str) {
 		AnsjItem item = DAT.getItem(str);
-		if (item == null) {
+		if (item == null || item.getStatus()<2) {
 			return AnsjItem.NULL;
 		}
 

File: src/main/java/org/ansj/library/UserDefineLibrary.java
Patch:
@@ -204,7 +204,7 @@ public static void clear() {
      * @return File Array
      */
     private static File[] findLibrary(String path) {
-        File[] libs = new File[1];
+        File[] libs = new File[0];
         File file = new File(path);
         if (!file.exists()) {
             // Try load from classpath
@@ -217,6 +217,7 @@ private static File[] findLibrary(String path) {
         if (file.canRead()) {
 
             if (file.isFile()) {
+                libs = new File[1];
                 libs[0] = file;
             } else if (file.isDirectory()) {
                 File[] files = file.listFiles(new FilenameFilter() {

File: src/main/java/org/ansj/library/UserDefineLibrary.java
Patch:
@@ -204,7 +204,7 @@ public static void clear() {
      * @return File Array
      */
     private static File[] findLibrary(String path) {
-        File[] libs = new File[1];
+        File[] libs = new File[0];
         File file = new File(path);
         if (!file.exists()) {
             // Try load from classpath
@@ -217,6 +217,7 @@ private static File[] findLibrary(String path) {
         if (file.canRead()) {
 
             if (file.isFile()) {
+                libs = new File[1];
                 libs[0] = file;
             } else if (file.isDirectory()) {
                 File[] files = file.listFiles(new FilenameFilter() {

File: src/main/java/org/ansj/library/UserDefineLibrary.java
Patch:
@@ -1,7 +1,6 @@
 package org.ansj.library;
 
 import org.ansj.util.MyStaticValue;
-import org.apache.commons.lang3.StringUtils;
 import org.nlpcn.commons.lang.tire.domain.Forest;
 import org.nlpcn.commons.lang.tire.domain.SmartForest;
 import org.nlpcn.commons.lang.tire.domain.Value;
@@ -77,7 +76,7 @@ private static void initAmbiguityLibrary() {
                 try (BufferedReader br = IOUtil.getReader(file, "utf-8")) {
                     String temp;
                     while ((temp = br.readLine()) != null) {
-                        if (StringUtils.isNotBlank(temp)) {
+                        if (StringUtil.isNotBlank(temp)) {
                             temp = StringUtil.trim(temp);
                             String[] split = temp.split("\t");
                             StringBuilder sb = new StringBuilder();
@@ -128,7 +127,7 @@ public static void loadLibrary(Forest forest, String path) {
                 Value value;
                 try (BufferedReader br = IOUtil.getReader(new FileInputStream(file), "UTF-8")) {
                     while ((temp = br.readLine()) != null) {
-                        if (StringUtils.isNotBlank(temp)) {
+                        if (StringUtil.isNotBlank(temp)) {
                             temp = StringUtil.trim(temp);
                             strs = temp.split("\t");
                             strs[0] = strs[0].toLowerCase();

File: src/main/java/org/ansj/recognition/Recognition.java
Patch:
@@ -1,5 +1,7 @@
 package org.ansj.recognition;
 
+import java.io.Serializable;
+
 import org.ansj.domain.Result;
 
 /**
@@ -8,6 +10,6 @@
  * @author Ansj
  *
  */
-public interface Recognition {
+public interface Recognition extends Serializable{
 	public void recognition(Result result) ;
 }

File: src/main/java/org/ansj/library/UserDefineLibrary.java
Patch:
@@ -7,6 +7,7 @@
 import java.io.FileInputStream;
 import java.io.IOException;
 import java.io.UnsupportedEncodingException;
+import java.net.URL;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.Comparator;

File: src/main/java/org/ansj/app/crf/MakeTrainFile.java
Patch:
@@ -26,7 +26,7 @@ public static void main(String[] args) {
 
 		if (args != null && args.length == 2) {
 			inputPath = args[0];
-			inputPath = args[1];
+			outputPath = args[1];
 		}
 
 		if (StringUtil.isBlank(inputPath) || StringUtil.isBlank(outputPath)) {

File: src/test/java/org/ansj/app/crf/ModelTest.java
Patch:
@@ -6,7 +6,7 @@ public class ModelTest {
 
 	@Test
 	public void test() throws Exception {
-		Model model = Model.load("ansj", "library/crf.model");
+		Model model = Model.load("ansj", "src/main/resources/crf.model");
 		System.out.println(new SplitWord(model).cut("结婚的和尚未结婚的"));
 
 		String path = "/Users/sunjian/Documents/src/CRF++-0.58/test/model.txt";

File: src/main/java/org/ansj/app/crf/model/CRFppTxtModel.java
Patch:
@@ -1,7 +1,6 @@
 package org.ansj.app.crf.model;
 
 import java.io.BufferedReader;
-import java.io.DataInputStream;
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;

File: src/main/java/org/ansj/app/keyword/KeyWordComputer.java
Patch:
@@ -10,7 +10,6 @@
 import org.ansj.splitWord.analysis.NlpAnalysis;
 import org.ansj.util.FilterModifWord;
 import org.nlpcn.commons.lang.util.StringUtil;
-import org.nlpcn.commons.lang.util.WordAlert;
 
 public class KeyWordComputer {
 
@@ -57,7 +56,7 @@ public KeyWordComputer(int nKeyword) {
 	private List<Keyword> computeArticleTfidf(String content, int titleLength) {
 		Map<String, Keyword> tm = new HashMap<String, Keyword>();
 
-		List<Term> parse = NlpAnalysis.parse(content);
+		List<Term> parse = NlpAnalysis.parse(content).getTerms();
 		
 		parse = FilterModifWord.updateNature(parse) ;
 		

File: src/main/java/org/ansj/app/summary/SummaryComputer.java
Patch:
@@ -71,7 +71,7 @@ public Summary toSummary() {
 	 */
 	public Summary toSummary(String query) {
 
-		List<Term> parse = NlpAnalysis.parse(query);
+		List<Term> parse = NlpAnalysis.parse(query).getTerms();
 
 		List<Keyword> keywords = new ArrayList<Keyword>();
 		for (Term term : parse) {

File: src/main/java/org/ansj/splitWord/analysis/BaseAnalysis.java
Patch:
@@ -4,6 +4,7 @@
 import java.util.ArrayList;
 import java.util.List;
 
+import org.ansj.domain.Result;
 import org.ansj.domain.Term;
 import org.ansj.splitWord.Analysis;
 import org.ansj.util.AnsjReader;
@@ -42,14 +43,14 @@ private List<Term> getResult() {
 		return merger.merger();
 	}
 
-	private BaseAnalysis() {
+	public BaseAnalysis() {
 	};
 
 	public BaseAnalysis(Reader reader) {
 		super.resetContent(new AnsjReader(reader));
 	}
 
-	public static List<Term> parse(String str) {
+	public static Result parse(String str) {
 		return new BaseAnalysis().parseStr(str);
 	}
 }

File: src/main/java/org/ansj/util/MathUtil.java
Patch:
@@ -5,7 +5,7 @@
 import org.ansj.domain.Term;
 import org.ansj.library.NatureLibrary;
 import org.ansj.library.NgramLibrary;
-import org.ansj.recognition.NatureRecognition.NatureTerm;
+import org.ansj.recognition.impl.NatureRecognition.NatureTerm;
 
 public class MathUtil {
 

File: src/main/java/org/ansj/util/NameFix.java
Patch:
@@ -2,7 +2,7 @@
 
 import org.ansj.domain.Term;
 import org.ansj.domain.TermNatures;
-import org.ansj.recognition.NatureRecognition;
+import org.ansj.recognition.impl.NatureRecognition;
 import org.nlpcn.commons.lang.util.WordAlert;
 
 public class NameFix {

File: src/main/java/org/ansj/util/TermUtil.java
Patch:
@@ -9,7 +9,7 @@
 import org.ansj.domain.TermNatures;
 import org.ansj.library.NatureLibrary;
 import org.ansj.library.company.CompanyAttrLibrary;
-import org.ansj.recognition.ForeignPersonRecognition;
+import org.ansj.recognition.arrimpl.ForeignPersonRecognition;
 
 /**
  * term的操作类

File: src/test/java/org/ansj/demo/BaseAnalysisDemo.java
Patch:
@@ -2,6 +2,7 @@
 
 import java.util.List;
 
+import org.ansj.domain.Result;
 import org.ansj.domain.Term;
 import org.ansj.splitWord.analysis.BaseAnalysis;
 
@@ -12,7 +13,7 @@
  */
 public class BaseAnalysisDemo {
 	public static void main(String[] args) {
-		List<Term> parse = BaseAnalysis.parse("让战士们过一个欢乐祥和的新春佳节。");
+		Result parse = BaseAnalysis.parse("让战士们过一个欢乐祥和的新春佳节。");
 		System.out.println(parse);
 	}
 }

File: src/test/java/org/ansj/demo/DefineDemo.java
Patch:
@@ -5,9 +5,10 @@
 import java.util.List;
 
 import org.ansj.domain.Nature;
+import org.ansj.domain.Result;
 import org.ansj.domain.Term;
 import org.ansj.domain.TermNatures;
-import org.ansj.recognition.NatureRecognition;
+import org.ansj.recognition.impl.NatureRecognition;
 import org.ansj.splitWord.analysis.BaseAnalysis;
 
 /**
@@ -18,7 +19,7 @@ public class DefineDemo {
 	public static void main(String[] args) throws IOException {
 		String str = "java@ID:6321-000301@你好";
 		// 普通分词
-		List<Term> parse = BaseAnalysis.parse(str);
+		Result parse = BaseAnalysis.parse(str);
 		// 词性标注
 		new NatureRecognition(parse).recognition();
 

File: src/test/java/org/ansj/demo/FilterAndUpdateNatureDemo.java
Patch:
@@ -4,7 +4,7 @@
 
 import org.ansj.domain.Term;
 import org.ansj.library.UserDefineLibrary;
-import org.ansj.recognition.NatureRecognition;
+import org.ansj.recognition.impl.NatureRecognition;
 import org.ansj.splitWord.analysis.ToAnalysis;
 import org.ansj.util.FilterModifWord;
 

File: src/test/java/org/ansj/demo/NatureDemo.java
Patch:
@@ -4,7 +4,7 @@
 import java.util.List;
 
 import org.ansj.domain.Term;
-import org.ansj.recognition.NatureRecognition;
+import org.ansj.recognition.impl.NatureRecognition;
 import org.ansj.splitWord.analysis.ToAnalysis;
 
 /**

File: src/test/java/org/ansj/demo/NatureTagDemo.java
Patch:
@@ -4,7 +4,7 @@
 import java.util.List;
 
 import org.ansj.domain.Term;
-import org.ansj.recognition.NatureRecognition;
+import org.ansj.recognition.impl.NatureRecognition;
 
 /**
  * 对非ansj的分词结果进行词性标注

File: src/test/java/org/ansj/recognition/IDCardRecognitionTest.java
Patch:
@@ -3,7 +3,7 @@
 import java.util.List;
 
 import org.ansj.domain.Term;
-import org.ansj.recognition.IDCardRecognition;
+import org.ansj.recognition.impl.IDCardRecognition;
 import org.ansj.splitWord.analysis.ToAnalysis;
 import org.junit.Test;
 

File: src/test/java/org/ansj/test/IndexAnalysisTest.java
Patch:
@@ -10,7 +10,7 @@ public class IndexAnalysisTest {
 	public static void main(String[] args) throws IOException {
 		MyStaticValue.isNumRecognition=true;
 		MyStaticValue.isQuantifierRecognition = false;
-		MyStaticValue.userLibrary=null ;
+		MyStaticValue.DIC.put("dic", null);
 		UserDefineLibrary.insertWord("蛇药片", "n", 1000);
 		UserDefineLibrary.insertWord("蛇药", "n", 1000);
 		UserDefineLibrary.insertWord("鲁花", "n", 1000);

File: src/test/java/org/ansj/test/NatureRecognitionTest.java
Patch:
@@ -3,7 +3,7 @@
 import java.util.List;
 
 import org.ansj.domain.Term;
-import org.ansj.recognition.NatureRecognition;
+import org.ansj.recognition.impl.NatureRecognition;
 import org.ansj.splitWord.analysis.ToAnalysis;
 import org.junit.Test;
 

File: src/test/java/org/ansj/test/Test.java
Patch:
@@ -5,7 +5,7 @@
 import java.util.List;
 
 import org.ansj.domain.Term;
-import org.ansj.recognition.NatureRecognition;
+import org.ansj.recognition.impl.NatureRecognition;
 import org.ansj.splitWord.analysis.NlpAnalysis;
 import org.ansj.splitWord.analysis.ToAnalysis;
 

File: src/test/java/org/ansj/test/TestError.java
Patch:
@@ -7,7 +7,7 @@
 import org.ansj.domain.Term;
 import org.ansj.library.DATDictionary;
 import org.ansj.library.UserDefineLibrary;
-import org.ansj.recognition.NatureRecognition;
+import org.ansj.recognition.impl.NatureRecognition;
 import org.ansj.splitWord.analysis.IndexAnalysis;
 import org.ansj.splitWord.analysis.NlpAnalysis;
 import org.ansj.splitWord.analysis.ToAnalysis;
@@ -131,6 +131,8 @@ public void test() throws Exception {
 		System.out.println(DATDictionary.getItem(" "));
 		System.out.println(DATDictionary.getItem("	"));
 
+		
+		System.out.println(NlpAnalysis.parse("2015年无锡市突发环境事件"));
 
 	}
 }

File: src/main/java/org/ansj/splitWord/analysis/NlpAnalysis.java
Patch:
@@ -74,8 +74,8 @@ public List<Term> merger() {
 					graph.walkPathByScore();
 				}
 
-				MapCount<String> mc = new MapCount<String>();
 				if (DEFAULT_SLITWORD != null) {
+					MapCount<String> mc = new MapCount<String>();
 
 					// 通过crf分词
 					List<String> words = DEFAULT_SLITWORD.cut(graph.chars);
@@ -138,11 +138,11 @@ public List<Term> merger() {
 					if (tempTermNatures != TermNatures.NW) {
 						mc.add(temp + TAB + "末##末", CRF_WEIGHT);
 					}
+					graph.walkPath(mc.get());
 				} else {
 					MyStaticValue.LIBRARYLOG.warn("not find crf model you can run DownLibrary.main(null) to down !\n or you can visit http://maven.nlpcn.org/down/library.zip to down it ! ");
 				}
 
-				graph.walkPath(mc.get());
 
 				// 数字发现
 				if (graph.hasNum) {

File: plugin/ansj_lucene5_plugin/src/main/java/org/ansj/lucene5/AnsjAnalyzer.java
Patch:
@@ -53,9 +53,6 @@ public AnsjAnalyzer(TYPE type) {
 		this.type = type;
 	}
 
-	public AnsjAnalyzer() {
-	}
-
 	private Set<String> filter(String stopwordsDir) {
 		if (StringUtil.isBlank(stopwordsDir)) {
 			return null;

File: plugin/ansj_lucene5_plugin/src/test/java/org/ansj/ansj_lucene5_plug/TestToken.java
Patch:
@@ -5,13 +5,14 @@
 import java.io.StringReader;
 
 import org.ansj.lucene5.AnsjAnalyzer;
+import org.ansj.lucene5.AnsjAnalyzer.TYPE;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 
 public class TestToken {
 	public static void main(String[] args) {
-        Analyzer ca = new AnsjAnalyzer();
+        Analyzer ca = new AnsjAnalyzer(TYPE.user);
         Reader sentence = new StringReader(
                 "\n\n\n\n\n\n\n我从小就不由自主地认为自己长大以后一定得成为一个象我父亲一样的画家, 可能是父母潜移默化的影响。其实我根本不知道作为画家意味着什么，我是否喜欢，最重要的是否适合我，我是否有这个才华。其实人到中年的我还是不确定我最喜欢什么，最想做的是什么？我相信很多人和我一样有同样的烦恼。毕竟不是每个人都能成为作文里的宇航员，科学家和大教授。知道自己适合做什么，喜欢做什么，能做好什么其实是个非常困难的问题。"
                         + "幸运的是，我想我的孩子不会为这个太过烦恼。通过老大，我慢慢发现美国高中的一个重要功能就是帮助学生分析他们的专长和兴趣，从而帮助他们选择大学的专业和未来的职业。我觉得帮助一个未成形的孩子找到她未来成长的方向是个非常重要的过程。"

File: src/main/java/org/ansj/splitWord/analysis/IndexAnalysis.java
Patch:
@@ -7,15 +7,12 @@
 import java.util.Set;
 
 import org.ansj.domain.Term;
-import org.ansj.domain.TermNatures;
-import org.ansj.library.NatureLibrary;
 import org.ansj.library.UserDefineLibrary;
 import org.ansj.recognition.AsianPersonRecognition;
 import org.ansj.recognition.ForeignPersonRecognition;
 import org.ansj.recognition.NumRecognition;
 import org.ansj.recognition.UserDefineRecognition;
 import org.ansj.splitWord.Analysis;
-import org.ansj.splitWord.impl.GetWordsImpl;
 import org.ansj.util.AnsjReader;
 import org.ansj.util.Graph;
 import org.ansj.util.MyStaticValue;

File: src/test/java/org/ansj/Test.java
Patch:
@@ -2,6 +2,7 @@
 
 import java.util.List;
 
+import org.ansj.app.summary.SummaryComputer;
 import org.ansj.domain.Term;
 import org.ansj.library.UserDefineLibrary;
 import org.ansj.splitWord.analysis.ToAnalysis;
@@ -11,7 +12,7 @@
 
 public class Test {
 	public static void main(String[] args) throws Exception {
-
+		
 		// 构造一个用户词典
 		Forest forest = Library.makeForest("library/default.dic");
 		forest = new Forest();

File: plugin/ansj_lucene5_plugin/src/test/java/org/ansj/ansj_lucene5_plug/IndexTest.java
Patch:
@@ -82,7 +82,7 @@ public void indexTest() throws CorruptIndexException, LockObtainFailedException,
 
 		System.out.println("索引建立完毕");
 
-		Analyzer queryAnalyzer = new AnsjAnalyzer("user",hs);
+		Analyzer queryAnalyzer = new AnsjAnalyzer(AnsjAnalyzer.TYPE.dic,hs);
 		;
 
 		System.out.println("index ok to search!");

File: src/main/java/org/ansj/splitWord/analysis/NlpAnalysis.java
Patch:
@@ -113,18 +113,18 @@ public List<Term> merger() {
 						temp = word;
 						tempTermNatures = term.termNatures();
 
-						if (word.length() < 2 || isRuleWord(word)) {
+						if (term.termNatures() != TermNatures.NW || word.length() < 2 || isRuleWord(word)) {
 							continue;
 						}
+
 						learn.addTerm(new NewWord(word, Nature.NW));
 					}
 
 					if (tempTermNatures != TermNatures.NW) {
 						mc.add(temp + TAB + "末##末", CRF_WEIGHT);
 					}
 				} else {
-					MyStaticValue.LIBRARYLOG.warn(
-							"not find crf model you can run DownLibrary.main(null) to down !\n or you can visit http://maven.nlpcn.org/down/library.zip to down it ! ");
+					MyStaticValue.LIBRARYLOG.warn("not find crf model you can run DownLibrary.main(null) to down !\n or you can visit http://maven.nlpcn.org/down/library.zip to down it ! ");
 				}
 
 				graph.walkPath(mc.get());

File: plugin/ansj_lucene5_plugin/src/main/java/org/ansj/lucene/util/AnsjTokenizer.java
Patch:
@@ -11,7 +11,7 @@
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 
-public class AnsjTokenizer extends Tokenizer {
+public final class AnsjTokenizer extends Tokenizer {
 	// 当前词
 	private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
 	// 偏移量
@@ -33,7 +33,7 @@ public AnsjTokenizer(Analysis ta) {
 	}
 
 	@Override
-	public boolean incrementToken() throws IOException {
+	public final boolean incrementToken() throws IOException {
 		clearAttributes();
 		int position = 0;
 		Term term = null;

File: plugin/ansj_lucene5_plugin/src/test/java/org/ansj/ansj_lucene5_plug/AppTest.java
Patch:
@@ -18,7 +18,7 @@ public class AppTest {
     public static void main(String[] args) throws IOException {
         Set<String> filter = new HashSet<String>() ;
         
-        String stopDicStr = "6\n7" ;
+        String stopDicStr = "6\n7" ;  
         
         BufferedReader br = new BufferedReader(new StringReader(stopDicStr)) ;
         String temp = null ;

File: src/test/java/org/ansj/demo/TagWordDemo.java
Patch:
@@ -9,12 +9,14 @@
 public class TagWordDemo {
 	public static void main(String[] args) {
 		TagContent tw = new TagContent("<begin>", "<end>");
-		String content = "台湾两岸共同市场基金会代表团   不断推动两岸关";
+		String content = "台湾两岸共同市场基金会代表团12312   不断推动两岸关";
 		List<Keyword> keyWords = new ArrayList<Keyword>();
 		keyWords.add(new Keyword("两岸关系",1.0));
 		keyWords.add(new Keyword("两岸",1.0));
 		keyWords.add(new Keyword("李克强",1.0));
 		keyWords.add(new Keyword("博鳌",1.0));
+		keyWords.add(new Keyword("12",1.0));		
 		System.out.println(tw.tagContent(keyWords, content));;
 	}
 }
+

File: src/test/java/org/ansj/test/TestError.java
Patch:
@@ -117,6 +117,7 @@ public void test() throws Exception {
 		all.add("10,上城区小营街道大学路,余林,330102196204011513 ,2,13456808992,大学路新村44-122-102,大学路新村44-122-102,Z2015120110302017,Z,2015-12-25");
 		
 		all.add("六味地黄丸") ;
+		all.add("2015年6月3日") ;
 //	    System.out.println(ToAnalysis.parse("你吃过了吗？？没吃"));
 //	    System.out.println(NlpAnalysis.parse("你吃过了吗？？没吃"));
 		

File: src/test/java/org/ansj/test/UserDefinedAnalysisTest.java
Patch:
@@ -17,6 +17,7 @@ public class UserDefinedAnalysisTest {
 
 	@Test
 	public void test() {
+		
 		String newWord = "爸爸去哪儿";
 		String nature = "aaaaa";
 		String str = "上海电力2012年财务报表如下怎爸爸去哪儿么办";

File: src/main/java/org/ansj/splitWord/analysis/UserDefineAnalysis.java
Patch:
@@ -74,7 +74,7 @@ private List<Term> getResult() {
 				}
 				setRealName(graph, result);
 
-				FilterModifWord.modifResult(result);
+				FilterModifWord.modifResult(result,forests);
 				return result;
 			}
 		};

File: src/test/java/org/ansj/test/UserDefinedAnalysisTest.java
Patch:
@@ -21,12 +21,14 @@ public void test() {
 		
 		//增加新词
 		UserDefineLibrary.insertWord(newWord, nature, 1000);
+		UserDefineLibrary.insertWord("上海电力", nature, 1000);
 		
 		List<Term> parse = UserDefineAnalysis.parse(str);
 		HashMap<String, Term> hs = new HashMap<String, Term>();
 		for (Term term : parse) {
 			hs.put(term.getName(), term);
 		}
+System.out.println(parse);
 
 		Assert.assertTrue(hs.containsKey(newWord));
 

File: src/main/java/org/ansj/app/crf/SplitWord.java
Patch:
@@ -79,7 +79,7 @@ public List<String> cut(String line) {
 
 		List<Element> elements = vterbi(line);
 
-		LinkedList<String> result = new LinkedList<String>();
+		List<String> result = new ArrayList<String>();
 
 		Element e = null;
 		int begin = 0;

File: src/main/java/org/ansj/domain/Term.java
Patch:
@@ -92,8 +92,8 @@ public void setName(String name) {
 	 */
 	public void setPathScore(Term from, Map<String, Double> relationMap) {
 		// 维特比进行最优路径的构建
-		double score = MathUtil.compuScore(from, this,relationMap);
-		if (this.from == null || this.score >= score) {
+		double score = MathUtil.compuScore(from, this, relationMap);
+		if (this.from == null || this.score == 0 || this.score >= score) {
 			this.setFromAndScore(from, score);
 		}
 	}

File: src/main/java/org/ansj/splitWord/analysis/ToAnalysis.java
Patch:
@@ -33,6 +33,7 @@ protected List<Term> getResult(final Graph graph) {
 			public List<Term> merger() {
 				
 				graph.walkPath();
+				
 				// 数字发现
 				if (MyStaticValue.isNumRecognition && graph.hasNum) {
 					NumRecognition.recognition(graph.terms);
@@ -48,8 +49,7 @@ public List<Term> merger() {
 					new ForeignPersonRecognition(graph.terms).recognition();
 					graph.walkPathByScore();
 				}
-				
-				
+
 				// 用户自定义词典的识别
 				userDefineRecognition(graph, forests);
 

File: src/main/java/org/ansj/util/TermUtil.java
Patch:
@@ -41,7 +41,7 @@ public static void termLink(Term from, Term to) {
 	}
 
 	/**
-	 * 将一个term插入到链表中的对应位置中, 如果这个term已经存在参照type type 0.跳过 1. 替换 2.累积分值 保证顺序,由小到大
+	 * 将一个term插入到链表中的对应位置中, 如果这个term已经存在参照type type 0.跳过 1. 替换 2.累积分值 保证顺序,由大到小
 	 * 
 	 * @param terms
 	 * @param term

File: src/main/java/org/ansj/domain/AnsjItem.java
Patch:
@@ -29,7 +29,7 @@ public class AnsjItem extends Item {
 	/**
 	 * frequency : 词性词典,以及词性的相关权重
 	 */
-	public TermNatures termNatures = TermNatures.NULL;
+	public TermNatures termNatures = null ;
 
 	public Map<Integer,Integer> bigramEntryMap =  null ;
 
@@ -48,6 +48,8 @@ public void initValue(String[] split) {
 		if (status > 1) {
 			name = split[1];
 			termNatures = new TermNatures(TermNature.setNatureStrToArray(split[5]), index);
+		}else{
+			termNatures = new TermNatures(TermNature.NULL); 
 		}
 	}
 

File: src/main/java/org/ansj/library/UserDefineLibrary.java
Patch:
@@ -65,7 +65,7 @@ private static void initAmbiguityLibrary() {
 		// TODO Auto-generated method stub
 		String ambiguityLibrary = MyStaticValue.ambiguityLibrary;
 		if (StringUtil.isBlank(ambiguityLibrary)) {
-			LIBRARYLOG.warning("init ambiguity  waring :" + ambiguityLibrary + " because : not find that file or can not to read !");
+			LIBRARYLOG.warning("init ambiguity  warning :" + ambiguityLibrary + " because : file not found or failed to read !");
 			return;
 		}
 		ambiguityLibrary = MyStaticValue.ambiguityLibrary;
@@ -80,7 +80,7 @@ private static void initAmbiguityLibrary() {
 			}
 			LIBRARYLOG.info("init ambiguityLibrary ok!");
 		} else {
-			LIBRARYLOG.warning("init ambiguity  waring :" + new File(ambiguityLibrary).getAbsolutePath() + " because : not find that file or can not to read !");
+			LIBRARYLOG.warning("init ambiguity  warning :" + new File(ambiguityLibrary).getAbsolutePath() + " because : file not found or failed to read !");
 		}
 	}
 
@@ -157,7 +157,7 @@ public static void loadLibrary(Forest forest, String path) {
 		if (path != null) {
 			file = new File(path);
 			if (!file.canRead() || file.isHidden()) {
-				LIBRARYLOG.warning("init userLibrary  waring :" + new File(path).getAbsolutePath() + " because : not find that file or can not to read !");
+				LIBRARYLOG.warning("init userLibrary  warning :" + new File(path).getAbsolutePath() + " because : file not found or failed to read !");
 				return;
 			}
 			if (file.isFile()) {

File: src/main/java/org/ansj/library/UserDefineLibrary.java
Patch:
@@ -65,7 +65,7 @@ private static void initAmbiguityLibrary() {
 		// TODO Auto-generated method stub
 		String ambiguityLibrary = MyStaticValue.ambiguityLibrary;
 		if (StringUtil.isBlank(ambiguityLibrary)) {
-			LIBRARYLOG.warning("init ambiguity  waring :" + ambiguityLibrary + " because : not find that file or can not to read !");
+			LIBRARYLOG.warning("init ambiguity  warning :" + ambiguityLibrary + " because : file not found or failed to read !");
 			return;
 		}
 		ambiguityLibrary = MyStaticValue.ambiguityLibrary;
@@ -80,7 +80,7 @@ private static void initAmbiguityLibrary() {
 			}
 			LIBRARYLOG.info("init ambiguityLibrary ok!");
 		} else {
-			LIBRARYLOG.warning("init ambiguity  waring :" + new File(ambiguityLibrary).getAbsolutePath() + " because : not find that file or can not to read !");
+			LIBRARYLOG.warning("init ambiguity  warning :" + new File(ambiguityLibrary).getAbsolutePath() + " because : file not found or failed to read !");
 		}
 	}
 
@@ -157,7 +157,7 @@ public static void loadLibrary(Forest forest, String path) {
 		if (path != null) {
 			file = new File(path);
 			if (!file.canRead() || file.isHidden()) {
-				LIBRARYLOG.warning("init userLibrary  waring :" + new File(path).getAbsolutePath() + " because : not find that file or can not to read !");
+				LIBRARYLOG.warning("init userLibrary  warning :" + new File(path).getAbsolutePath() + " because : file not found or failed to read !");
 				return;
 			}
 			if (file.isFile()) {

File: src/main/java/org/ansj/domain/NewWord.java
Patch:
@@ -58,7 +58,7 @@ public void setNature(Nature nature) {
 	 * @param i
 	 * @param tn
 	 */
-	public void update(double score, Nature nature, int freq) {
+	public void update(Nature nature, int freq) {
 		// TODO Auto-generated method stub
 		this.score += score * freq;
 		this.allFreq += freq;

File: src/main/java/org/ansj/splitWord/analysis/NlpAnalysis.java
Patch:
@@ -65,7 +65,6 @@ public List<Term> merger() {
 					if (word.length() < 2 || InitDictionary.isInSystemDic(word) || WordAlert.isRuleWord(word)) {
 						continue;
 					}
-
 					learn.addTerm(new NewWord(word, NatureLibrary.getNature("nw")));
 				}
 

File: src/main/java/org/ansj/util/WordAlert.java
Patch:
@@ -335,6 +335,7 @@ public static List<Element> str2Elements(String str) {
 	public static boolean isRuleWord(String word) {
 		char c = 0;
 		for (int i = 0; i < word.length(); i++) {
+			c = word.charAt(i);
 			if (c < 256 || (c = CHARCOVER[word.charAt(i)]) > 0 && c != '·') {
 				return true;
 			}

File: src/test/java/org/ansj/test/TestError.java
Patch:
@@ -25,5 +25,7 @@ public void test(){
 			System.out.println(NlpAnalysis.parse("越体越中意"));
 			System.out.println(NlpAnalysis.parse("一、概述正如上一篇博客，程序并没有主动设置PersonService实例的name属性值，而是通过Spring配置文件配置的，这就是说，PersonService实例的属性值并不是程序主动设置的，而是由Spring容器来负责注入的。在依赖注入的模式下，创建被调用者的工作不再由调用者来完成，因此称为控制反转（IoC）。创建被调用者实例的工作通常由Spring容器来完成，然后注入调用者，因此也称为......"));
 			System.out.println(NlpAnalysis.parse("【万维网诞生25周年啦】1989年，《辛普森一家》走上银幕，“哈利波特”出生，伯纳斯-李发明万维网，并在1990年向世界免费公布了代码，把互联网从专业人士和少数狂热分子的数据传输系统转变为普通人的技术。1995年，42%的美国人从未听说过互联网，只有14%的人上过，2014年已达87%http://t.cn/8F1g3Mv"));
+			System.out.println(NlpAnalysis.parse("西伯利亚雅特大教堂位于俄罗斯东西伯利亚地区"));
+			System.out.println(NlpAnalysis.parse("西伯利亚雅特大教堂位于俄罗斯东西伯利亚地区西伯利亚雅特大教堂位于俄罗斯东西伯利亚地区西伯利亚雅特大教堂位于俄罗斯东西伯利亚地区西伯利亚雅特大教堂位于俄罗斯东西伯利亚地区西伯利亚雅特大教堂位于俄罗斯东西伯利亚地区西伯利亚雅特大教堂位于俄罗斯东西伯利亚地区"));
 		}
 }

File: src/main/java/org/ansj/app/summary/SummaryComputer.java
Patch:
@@ -232,7 +232,7 @@ public List<Sentence> toSentenceList(char[] chars) {
 		List<Sentence> sentences = new ArrayList<Sentence>();
 
 		for (int i = 0; i < chars.length; i++) {
-			if (sb.length() == 0 && Character.isWhitespace(chars[i])) {
+			if (sb.length() == 0 && (Character.isWhitespace(chars[i])||chars[i]==' ')) {
 				continue;
 			}
 
@@ -246,6 +246,7 @@ public List<Sentence> toSentenceList(char[] chars) {
 				break;
 			case ' ':
 			case '	':
+			case ' ':
 			case '。':
 				insertIntoList(sb, sentences);
 				sb = new StringBuilder();

File: src/test/java/org/ansj/test/TestError.java
Patch:
@@ -23,5 +23,6 @@ public void test(){
 		System.out.println(NlpAnalysis.parse("从古至今为何经济南强北弱?军事则北强南弱?_百度知道",tool));
 		System.out.println(NlpAnalysis.parse("确保今年８％的增长速度"));
 		System.out.println(NlpAnalysis.parse("越体越中意"));
+		System.out.println(NlpAnalysis.parse("政大vs"));
 	}
 }

File: src/test/java/org/ansj/test/TestError.java
Patch:
@@ -4,7 +4,6 @@
 import org.ansj.library.UserDefineLibrary;
 import org.ansj.splitWord.analysis.NlpAnalysis;
 import org.ansj.splitWord.analysis.ToAnalysis;
-import org.ansj.util.MyStaticValue;
 import org.junit.Test;
 
 public class TestError {
@@ -23,5 +22,6 @@ public void test(){
 		System.out.println(NlpAnalysis.parse("这次回家，我经济南下广州",tool));
 		System.out.println(NlpAnalysis.parse("从古至今为何经济南强北弱?军事则北强南弱?_百度知道",tool));
 		System.out.println(NlpAnalysis.parse("确保今年８％的增长速度"));
+		System.out.println(NlpAnalysis.parse("越体越中意"));
 	}
 }

File: src/main/java/org/ansj/splitWord/analysis/NlpAnalysis.java
Patch:
@@ -67,9 +67,10 @@ public List<Term> merger() {
 					}
 					learn.addTerm(new NewWord(word, NatureLibrary.getNature("nw"), -word.length()));
 				}
-				
+
 				// 用户自定义词典的识别
 				new UserDefineRecognition(graph.terms, forests).recognition();
+				graph.rmLittlePath();
 				graph.walkPathByScore();
 
 				// 进行新词发现

File: src/main/java/org/ansj/util/MyStaticValue.java
Patch:
@@ -59,7 +59,7 @@ public class MyStaticValue {
 	/**
 	 * 是否用户辞典不加载相同的词
 	 */
-	public static boolean isSkipUserDefine = true;
+	public static boolean isSkipUserDefine = false;
 
 	static {
 		/**

File: src/main/java/org/ansj/dic/DicReader.java
Patch:
@@ -25,7 +25,6 @@ public static BufferedReader getReader(String name) {
 	public static InputStream getInputStream(String name) {
 		// maven工程修改词典加载方式
 		InputStream in = DicReader.class.getResourceAsStream("/" + name);
-
 		return in;
 	}
 }

File: src/test/java/org/ansj/test/NlpAnalysiTest.java
Patch:
@@ -31,6 +31,7 @@ public void nameTest() {
 		list.add("中新网10月20日电 据日本共同社报道，日本民主党代理干事长安住淳20日表示，首相野田佳彦将履行“近期”解散众院举行大选的承诺，预计在“公债发行特例法案”获得通过等条件具备时解散众院。");
 		list.add("邓颖超生前最喜欢的画像");
 		list.add("习近平和朱镕基情切照相");
+		list.add("能不能试试这个 西伯利亚雅特大教堂位于俄罗斯东西伯利亚地区") ;
 		list.add("李克强");
 		for (String string : list) {
 			System.out.println(NlpAnalysis.parse(string));

File: src/main/java/org/ansj/recognition/UserDefineRecognition.java
Patch:
@@ -32,7 +32,7 @@ public class UserDefineRecognition {
 
 	public UserDefineRecognition(Term[] terms, Forest... forests) {
 		this.terms = terms;
-		if (forests != null) {
+		if (forests != null && forests.length > 0) {
 			this.forests = forests;
 		}
 
@@ -44,7 +44,7 @@ public void recognition() {
 			if (forest == null) {
 				continue;
 			}
-			reset() ;
+			reset();
 			this.forest = forest;
 
 			branch = forest;

File: src/main/java/org/ansj/recognition/UserDefineRecognition.java
Patch:
@@ -44,6 +44,7 @@ public void recognition() {
 			if (forest == null) {
 				continue;
 			}
+			reset() ;
 			this.forest = forest;
 
 			branch = forest;

File: src/main/java/org/ansj/util/MyStaticValue.java
Patch:
@@ -1,12 +1,9 @@
 package org.ansj.util;
 
 import java.io.BufferedReader;
-import java.io.FileNotFoundException;
-import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.ObjectInputStream;
-import java.io.ObjectOutputStream;
 import java.io.UnsupportedEncodingException;
 import java.util.Arrays;
 import java.util.HashMap;

File: src/main/java/org/ansj/splitWord/impl/GetWordsImpl.java
Patch:
@@ -6,6 +6,8 @@
 import static org.ansj.library.InitDictionary.status;
 import static org.ansj.library.InitDictionary.termNatures;
 import static org.ansj.library.InitDictionary.words;
+import static org.ansj.library.InitDictionary.arrayLength;
+
 
 import org.ansj.domain.TermNatures;
 import org.ansj.splitWord.GetWords;
@@ -108,7 +110,7 @@ public String allWords() {
 	private int getStatement() {
 		checkValue = baseValue;
 		baseValue = base[checkValue] + charHashCode;
-		if (check[baseValue] == checkValue || check[baseValue] == -1) {
+		if (baseValue < arrayLength && (check[baseValue] == checkValue || check[baseValue] == -1)) {
 			return status[baseValue];
 		}
 		return 0;

File: src/test/java/org/ansj/test/NlpTest.java
Patch:
@@ -17,6 +17,6 @@ public static void main(String[] args) throws IOException {
 //        while(nlpAnalysis.next()!=null){}
 //        List<Entry<String, Double>> topTree = learn.getTopTree(20) ;
 //        System.out.println(topTree);
-		System.out.println(ToAnalysis.parse("亚太经合组织"));
+		System.out.println(ToAnalysis.parse("奥地利、比利时和大不列颠及北爱尔兰联合王报告向低收入家庭提供取暖和更方便使用电力的"));
 	}
 }

File: src/main/java/org/ansj/web/AnsjServer.java
Patch:
@@ -51,8 +51,8 @@ public void handle(HttpExchange httpExchange) {
 				String responseMsg = "欢迎使用Ansj中文分词!\ndemo:http://localhost:8888/?input=我日世界&method=to"; // 响应信息
 				Map<String, String> paramers = parseParamers(httpExchange);
 				String input = paramers.get("input");
-                                String method = paramers.get("method");
-                                String nature = paramers.get("nature");
+				String method = paramers.get("method");
+				String nature = paramers.get("nature");
 				if (StringUtil.isNotBlank(input)) {
 					responseMsg = AnsjServlet.processRequest(input, method, nature);
 				}

File: src/main/java/org/ansj/util/DicManager.java
Patch:
@@ -50,7 +50,7 @@ private static void init() {
 			e.printStackTrace();
 		}
 
-        if (StringUtil.isNotBlank(userLibraryPath)) {
+        if (StringUtil.isBlank(userLibraryPath)) {
             return;
         }
 

File: src/org/ansj/splitWord/Analysis.java
Patch:
@@ -176,7 +176,7 @@ private void analysis(String temp) {
 		terms.addAll(result);
 	}
 
-	protected List<Term> paserStr(String temp) {
+	protected List<Term> parseStr(String temp) {
 		// TODO Auto-generated method stub
 		analysis(temp);
 		return terms;

File: src/org/ansj/splitWord/analysis/BaseAnalysis.java
Patch:
@@ -57,7 +57,7 @@ private List<Term> getResult() {
 	private BaseAnalysis() {
 	};
 
-	public static List<Term> paser(String str) {
-		return new BaseAnalysis().paserStr(str);
+	public static List<Term> parse(String str) {
+		return new BaseAnalysis().parseStr(str);
 	}
 }

File: src/org/ansj/splitWord/analysis/IndexAnalysis.java
Patch:
@@ -78,7 +78,7 @@ private List<Term> result() {
 	private IndexAnalysis() {
 	};
 
-	public static List<Term> paser(String str) {
-		return new IndexAnalysis().paserStr(str);
+	public static List<Term> parse(String str) {
+		return new IndexAnalysis().parseStr(str);
 	}
 }

File: src/org/ansj/util/newWordFind/NewWordDetection.java
Patch:
@@ -165,7 +165,7 @@ public static void main(String[] args) throws IOException {
 //		content = "企业为了刻意凸显自身的先进性和本就薄弱的领导力，总会打出诸如颠覆、革命等旗号，以集聚人气和关注。而这一切对万达来说，只是浮云。在当前电子商务营商环境日趋成熟，网民习惯逐渐形成的大环境下，万达电商可以高薪挖来成熟市场内的人才搭建技术平台，也不必费尽心机去络线下资源，聚合及管理供应链，甚至在自身强大的线下门店配合下，也能很轻松地越过支付和配送的壁垒，扮演电子商务";
 //		content = "【长乐一老板嫁女嫁妆2.1亿 席开300多桌】近日，网友微博爆料“长乐一企业家嫁女，嫁妆高达2.1亿元”。记者18日核实了此事，长乐金峰镇金峰村一李姓企业家16日嫁女，嫁妆为2.1亿元的“创业基金”。据参加婚礼的村民介绍，婚宴摆了300多桌，场面相当豪华。福州日报(图：@木板儿)";
 		LearnTool learn = new LearnTool();
-		List<Term> paser = NlpAnalysis.paser(StringUtil.rmHtmlTag(content), learn);
+		List<Term> paser = NlpAnalysis.parse(StringUtil.rmHtmlTag(content), learn);
 		List<Entry<String, Double>> topTree = learn.getTopTree(100);
 		System.out.println(topTree);
 		System.out.println(paser);

File: test/org/ansj/demo/BaseAnalysisDemo.java
Patch:
@@ -11,7 +11,7 @@
  */
 public class BaseAnalysisDemo {
 	public static void main(String[] args) {
-		List<Term> paser = BaseAnalysis.paser("若雅虎关闭了,我就不访问网站了") ;
-		System.out.println(paser);
+		List<Term> parse = BaseAnalysis.parse("若雅虎关闭了,我就不访问网站了") ;
+		System.out.println(parse);
 	}
 }

File: test/org/ansj/demo/DynamicWordDemo.java
Patch:
@@ -17,12 +17,12 @@ public class DynamicWordDemo {
 	public static void main(String[] args) {
 		// 增加新词,中间按照'\t'隔开
 		UserDefineLibrary.insertWord("ansj中文分词", "userDefine", 1000);
-		List<Term> terms = ToAnalysis.paser("我觉得ansj中文分词是一个不错的系统!我是王婆!");
+		List<Term> terms = ToAnalysis.parse("我觉得ansj中文分词是一个不错的系统!我是王婆!");
 		System.out.println("增加新词例子:" + terms);
 
 		// 删除词语,只能删除.用户自定义的词典.
 		UserDefineLibrary.removeWord("ansj中文分词");
-		terms = ToAnalysis.paser("我觉得ansj中文分词是一个不错的系统!我是王婆!");
+		terms = ToAnalysis.parse("我觉得ansj中文分词是一个不错的系统!我是王婆!");
 		System.out.println("删除用户自定义词典例子:" + terms);
 	}
 }

File: test/org/ansj/demo/IndexPaserDemo.java
Patch:
@@ -7,8 +7,8 @@
 
 public class IndexPaserDemo {
 	public static void main(String[] args) {
-		List<Term> paser = IndexAnalysis.paser("习近平") ;
-		System.out.println(paser);
-		System.out.println(IndexAnalysis.paser("2012年3月孙健很郁闷呢"));
+		List<Term> parse = IndexAnalysis.parse("习近平") ;
+		System.out.println(parse);
+		System.out.println(IndexAnalysis.parse("2012年3月孙健很郁闷呢"));
 	}
 }

File: test/org/ansj/demo/JianFanZhuanhuanDemo.java
Patch:
@@ -22,8 +22,8 @@ public static void main(String[] args) {
 		all.add("吳伯雄談建言被誤解讀:盡點言責 絕對善意") ;
 		all.add("輸入簡體字,點下面繁體字按鈕進行在線轉換.") ;
 		for (String string : all) {
-			List<Term> paser = ToAnalysis.paser(string) ;
-			System.out.println(paser);
+			List<Term> parse = ToAnalysis.parse(string) ;
+			System.out.println(parse);
 		}
 		
 	}

File: test/org/ansj/demo/NatureDemo.java
Patch:
@@ -15,7 +15,7 @@
  */
 public class NatureDemo {
 	public static void main(String[] args) throws IOException {
-		List<Term> terms = ToAnalysis.paser("Ansj中文分词是一个真正的ict的实现.并且加入了自己的一些数据结构和算法的分词.实现了高效率和高准确率的完美结合!");
+		List<Term> terms = ToAnalysis.parse("Ansj中文分词是一个真正的ict的实现.并且加入了自己的一些数据结构和算法的分词.实现了高效率和高准确率的完美结合!");
 		new NatureRecognition(terms).recognition() ;
 		System.out.println(terms);
 	}

File: test/org/ansj/demo/NlpDemo.java
Patch:
@@ -38,8 +38,8 @@ public static void main(String[] args) throws IOException {
 		learn.isNewWord = false ;
 		
 		for (String string : value) {
-			List<Term> paser = NlpAnalysis.paser(string, learn) ;
-			System.out.println(paser);
+			List<Term> parse = NlpAnalysis.parse(string, learn) ;
+			System.out.println(parse);
 		}
 		
 		System.out.println("这次训练已经学到了: "+learn.count+" 个词!");

File: test/org/ansj/test/CSDNBLogTest.java
Patch:
@@ -30,7 +30,7 @@
 //		}
 //		BufferedReader reader = IOUtil.getReader("/Users/ansj/Documents/temp/blogBigFile.txt", "UTF-8");
 //		String content = null;
-//		ToAnalysis.paser("init");
+//		ToAnalysis.parse("init");
 //		long start = System.currentTimeMillis();
 //		int size = 0;
 //		int resultSize = 0;
@@ -42,7 +42,7 @@
 //		while ((content = reader.readLine()) != null) {
 //			i++;
 //			length += content.length();
-//			// all = ToAnalysis.paser(content);
+//			// all = ToAnalysis.parse(content);
 //			// size += all.size();
 //			TreeSet<NewTerm> newWords = new NewWordFind().getNewWords(content);
 //
@@ -73,7 +73,7 @@
 //
 //	}
 //
-//	public static void paser() {
+//	public static void parse() {
 //
 //	}
 //}

File: test/org/ansj/test/CompanyTest.java
Patch:
@@ -33,8 +33,8 @@ public static void main(String[] args) throws IOException {
 
 		LearnTool learn = new LearnTool();
 		for (String string : all) {
-			List<Term> paser = NlpAnalysis.paser(string, learn);
-			System.out.println(paser);
+			List<Term> parse = NlpAnalysis.parse(string, learn);
+			System.out.println(parse);
 		}
 
 	}

File: test/org/ansj/test/ForeignPersonRecongnitionTest.java
Patch:
@@ -8,8 +8,8 @@
 
 public class ForeignPersonRecongnitionTest {
 	public static void main(String[] args) {
-		List<Term> paser = ToAnalysis.paser("俞志龙和陈举亚是南京维数公司的同事 ,保护协会，协会主席亚拉·巴洛斯说他们是在1990年开始寻找野生金刚鹦鹉的，最后终于找到了唯一的一只，是一只雄性鹦鹉，从那以后生物学家一直在观察它，因为再没有发现第二只野生的金刚鹦鹉。巴洛斯说") ;
-		new NatureRecognition(paser).recognition() ;
-		System.out.println(paser);
+		List<Term> parse = ToAnalysis.parse("俞志龙和陈举亚是南京维数公司的同事 ,保护协会，协会主席亚拉·巴洛斯说他们是在1990年开始寻找野生金刚鹦鹉的，最后终于找到了唯一的一只，是一只雄性鹦鹉，从那以后生物学家一直在观察它，因为再没有发现第二只野生的金刚鹦鹉。巴洛斯说") ;
+		new NatureRecognition(parse).recognition() ;
+		System.out.println(parse);
 	}
 }

File: test/org/ansj/test/MoneyTest.java
Patch:
@@ -9,7 +9,7 @@ public static void main(String[] args) throws Exception {
 		long begin = (Runtime.getRuntime().freeMemory() / 1000000);
 
 		//分词内存占用
-//		ToAnalysis.paser("内存测试123,张三") ;
+//		ToAnalysis.parse("内存测试123,张三") ;
 //		InitDictionary.initArrays();
 //		new TwoWordLibrary() ;
 		UserDefinedAnalysisTest.main(null) ;

File: test/org/ansj/test/NatrueFileTest.java
Patch:
@@ -17,8 +17,8 @@ public static void main(String[] args) throws IOException {
 		String temp = null ;
 		BufferedReader reader = IOUtil.getReader("/Users/ansj/Downloads/社交焦虑的治疗方式.txt", "GBK") ;
 		while((temp=reader.readLine())!=null){
-			List<Term> paser = BaseAnalysis.paser(temp) ;
-			for (Term term : paser) {
+			List<Term> parse = BaseAnalysis.parse(temp) ;
+			for (Term term : parse) {
 				sb.append(term.getName()) ;
 				sb.append("\t") ;
 			}

File: test/org/ansj/test/NatureRecognitionTest.java
Patch:
@@ -15,7 +15,7 @@
 public class NatureRecognitionTest {
 	public static void main(String[] args) {
 		String str = "结婚的和尚未结婚的孙建是一个好人";
-		List<Term> terms = ToAnalysis.paser(str);
+		List<Term> terms = ToAnalysis.parse(str);
 		new NatureRecognition(terms).recognition();
 	}
 }

File: test/org/ansj/test/PersonRecognitionTest.java
Patch:
@@ -30,9 +30,9 @@ public static void main(String[] args) throws Exception {
 		list.add("曼城第23分钟遭遇打击，孔帕尼中线丢球，莫里森中路直塞，沙恩-朗拿球成单刀之势，米尔纳背后将其铲倒，主裁判克拉滕伯格认为米尔纳是最后一名防守球员，直接掏出红牌！曼奇尼在场边向第四官员抗议，认为莱斯科特已经补防到位。多兰斯主罚任意球打在人墙上高出。");
 		list.add("中新网10月20日电 据日本共同社报道，日本民主党代理干事长安住淳20日表示，首相野田佳彦将履行“近期”解散众院举行大选的承诺，预计在“公债发行特例法案”获得通过等条件具备时解散众院。");
 		for (String string : list) {
-			List<Term> paser = ToAnalysis.paser(string);
-			new NatureRecognition(paser).recognition();
-			System.out.println(paser);
+			List<Term> parse = ToAnalysis.parse(string);
+			new NatureRecognition(parse).recognition();
+			System.out.println(parse);
 		}
 		// makeFile() ;
 		// initWordFreq() ;

File: test/org/ansj/test/Test.java
Patch:
@@ -158,7 +158,7 @@ public static void main(String[] args) throws IOException {
 		all.add("小和尚留了一个像大和尚一样的和尚头");
 		all.add("我是中华人民共和国公民;我爸爸是共和党党员; 地铁和平门站");
 		all.add("二次元乳量，养眼美女，我在泰国用微信");
-		ToAnalysis.paser("123孙健234你好公司 有限!");
+		ToAnalysis.parse("123孙健234你好公司 有限!");
 		long start = System.currentTimeMillis();
 		int count = 0;
 		for (int mm = 0; mm < 1; mm++) {
@@ -181,7 +181,7 @@ public static void main(String[] args) throws IOException {
 		// all.add("程序员祝海林和朱会震是在孙健的左面和右面.范凯在最右面.再往左是李松洪");
 		// start = System.currentTimeMillis();
 		// for (int i = 0; i < 100000; i++) {
-		// ToAnalysis.paser(strs[99]) ;
+		// ToAnalysis.parse(strs[99]) ;
 		// // for (SegToken segToken : process) {
 		// // System.out.print(new String(segToken.charArray));
 		// // System.out.print(" ");

File: test/org/ansj/test/TestFile3.java
Patch:
@@ -18,7 +18,7 @@ public static void main(String[] args) throws IOException {
 		String temp = null ;
 		while((temp=reader.readLine())!=null){
 			Term term = null;
-			List terms = ToAnalysis.paser(temp) ;
+			List terms = ToAnalysis.parse(temp) ;
 			new NatureRecognition(terms).recognition();
 			for (int i = 0; i < terms.size(); i++) {
 				if (((Term) terms.get(i)).getNatrue().natureStr.equals("nr")) {

File: test/org/ansj/test/ToAnalysisTest.java
Patch:
@@ -21,7 +21,7 @@ public static void main(String[] args) throws IOException {
 		// File("/Users/ansj/Documents/快盘/SogouCA.WWW08").listFiles() ;
 		File[] files = { new File("/Users/ansj/Downloads/西游记.txt") };
 		int count = 0;
-		ToAnalysis.paser("孙 123 sf") ;
+		ToAnalysis.parse("孙 123 sf") ;
 		long start = System.currentTimeMillis();
 		LearnTool learn = new LearnTool() ;
 		

File: test/org/ansj/demo/BaseAnalysisDemo.java
Patch:
@@ -11,7 +11,7 @@
  */
 public class BaseAnalysisDemo {
 	public static void main(String[] args) {
-		List<Term> paser = BaseAnalysis.parse("若雅虎关闭了,我就不访问网站了") ;
-		System.out.println(paser);
+		List<Term> parse = BaseAnalysis.parse("若雅虎关闭了,我就不访问网站了") ;
+		System.out.println(parse);
 	}
 }

File: test/org/ansj/demo/IndexPaserDemo.java
Patch:
@@ -7,8 +7,8 @@
 
 public class IndexPaserDemo {
 	public static void main(String[] args) {
-		List<Term> paser = IndexAnalysis.parse("习近平") ;
-		System.out.println(paser);
+		List<Term> parse = IndexAnalysis.parse("习近平") ;
+		System.out.println(parse);
 		System.out.println(IndexAnalysis.parse("2012年3月孙健很郁闷呢"));
 	}
 }

File: test/org/ansj/demo/JianFanZhuanhuanDemo.java
Patch:
@@ -22,8 +22,8 @@ public static void main(String[] args) {
 		all.add("吳伯雄談建言被誤解讀:盡點言責 絕對善意") ;
 		all.add("輸入簡體字,點下面繁體字按鈕進行在線轉換.") ;
 		for (String string : all) {
-			List<Term> paser = ToAnalysis.parse(string) ;
-			System.out.println(paser);
+			List<Term> parse = ToAnalysis.parse(string) ;
+			System.out.println(parse);
 		}
 		
 	}

File: test/org/ansj/demo/NlpDemo.java
Patch:
@@ -38,8 +38,8 @@ public static void main(String[] args) throws IOException {
 		learn.isNewWord = false ;
 		
 		for (String string : value) {
-			List<Term> paser = NlpAnalysis.parse(string, learn) ;
-			System.out.println(paser);
+			List<Term> parse = NlpAnalysis.parse(string, learn) ;
+			System.out.println(parse);
 		}
 		
 		System.out.println("这次训练已经学到了: "+learn.count+" 个词!");

File: test/org/ansj/test/CompanyTest.java
Patch:
@@ -33,8 +33,8 @@ public static void main(String[] args) throws IOException {
 
 		LearnTool learn = new LearnTool();
 		for (String string : all) {
-			List<Term> paser = NlpAnalysis.parse(string, learn);
-			System.out.println(paser);
+			List<Term> parse = NlpAnalysis.parse(string, learn);
+			System.out.println(parse);
 		}
 
 	}

File: test/org/ansj/test/ForeignPersonRecongnitionTest.java
Patch:
@@ -8,8 +8,8 @@
 
 public class ForeignPersonRecongnitionTest {
 	public static void main(String[] args) {
-		List<Term> paser = ToAnalysis.parse("俞志龙和陈举亚是南京维数公司的同事 ,保护协会，协会主席亚拉·巴洛斯说他们是在1990年开始寻找野生金刚鹦鹉的，最后终于找到了唯一的一只，是一只雄性鹦鹉，从那以后生物学家一直在观察它，因为再没有发现第二只野生的金刚鹦鹉。巴洛斯说") ;
-		new NatureRecognition(paser).recognition() ;
-		System.out.println(paser);
+		List<Term> parse = ToAnalysis.parse("俞志龙和陈举亚是南京维数公司的同事 ,保护协会，协会主席亚拉·巴洛斯说他们是在1990年开始寻找野生金刚鹦鹉的，最后终于找到了唯一的一只，是一只雄性鹦鹉，从那以后生物学家一直在观察它，因为再没有发现第二只野生的金刚鹦鹉。巴洛斯说") ;
+		new NatureRecognition(parse).recognition() ;
+		System.out.println(parse);
 	}
 }

File: test/org/ansj/test/NatrueFileTest.java
Patch:
@@ -17,8 +17,8 @@ public static void main(String[] args) throws IOException {
 		String temp = null ;
 		BufferedReader reader = IOUtil.getReader("/Users/ansj/Downloads/社交焦虑的治疗方式.txt", "GBK") ;
 		while((temp=reader.readLine())!=null){
-			List<Term> paser = BaseAnalysis.parse(temp) ;
-			for (Term term : paser) {
+			List<Term> parse = BaseAnalysis.parse(temp) ;
+			for (Term term : parse) {
 				sb.append(term.getName()) ;
 				sb.append("\t") ;
 			}

File: test/org/ansj/test/PersonRecognitionTest.java
Patch:
@@ -30,9 +30,9 @@ public static void main(String[] args) throws Exception {
 		list.add("曼城第23分钟遭遇打击，孔帕尼中线丢球，莫里森中路直塞，沙恩-朗拿球成单刀之势，米尔纳背后将其铲倒，主裁判克拉滕伯格认为米尔纳是最后一名防守球员，直接掏出红牌！曼奇尼在场边向第四官员抗议，认为莱斯科特已经补防到位。多兰斯主罚任意球打在人墙上高出。");
 		list.add("中新网10月20日电 据日本共同社报道，日本民主党代理干事长安住淳20日表示，首相野田佳彦将履行“近期”解散众院举行大选的承诺，预计在“公债发行特例法案”获得通过等条件具备时解散众院。");
 		for (String string : list) {
-			List<Term> paser = ToAnalysis.parse(string);
-			new NatureRecognition(paser).recognition();
-			System.out.println(paser);
+			List<Term> parse = ToAnalysis.parse(string);
+			new NatureRecognition(parse).recognition();
+			System.out.println(parse);
 		}
 		// makeFile() ;
 		// initWordFreq() ;

File: test/org/ansj/test/UserDefinedAnalysisTest.java
Patch:
@@ -56,7 +56,7 @@ public static void main(String[] args) {
 		
 		UserDefineLibrary.insertWord("怎么办", "aaa", 1000) ;
 	
-		List paser = ToAnalysis.parse(str1);
-		System.out.println(paser);
+		List parse = ToAnalysis.parse(str1);
+		System.out.println(parse);
 	}
 }

File: src/org/ansj/splitWord/Analysis.java
Patch:
@@ -176,7 +176,7 @@ private void analysis(String temp) {
 		terms.addAll(result);
 	}
 
-	protected List<Term> paserStr(String temp) {
+	protected List<Term> parseStr(String temp) {
 		// TODO Auto-generated method stub
 		analysis(temp);
 		return terms;

File: src/org/ansj/splitWord/analysis/BaseAnalysis.java
Patch:
@@ -57,7 +57,7 @@ private List<Term> getResult() {
 	private BaseAnalysis() {
 	};
 
-	public static List<Term> paser(String str) {
-		return new BaseAnalysis().paserStr(str);
+	public static List<Term> parse(String str) {
+		return new BaseAnalysis().parseStr(str);
 	}
 }

File: src/org/ansj/splitWord/analysis/IndexAnalysis.java
Patch:
@@ -78,7 +78,7 @@ private List<Term> result() {
 	private IndexAnalysis() {
 	};
 
-	public static List<Term> paser(String str) {
-		return new IndexAnalysis().paserStr(str);
+	public static List<Term> parse(String str) {
+		return new IndexAnalysis().parseStr(str);
 	}
 }

File: src/org/ansj/util/newWordFind/NewWordDetection.java
Patch:
@@ -165,7 +165,7 @@ public static void main(String[] args) throws IOException {
 //		content = "企业为了刻意凸显自身的先进性和本就薄弱的领导力，总会打出诸如颠覆、革命等旗号，以集聚人气和关注。而这一切对万达来说，只是浮云。在当前电子商务营商环境日趋成熟，网民习惯逐渐形成的大环境下，万达电商可以高薪挖来成熟市场内的人才搭建技术平台，也不必费尽心机去络线下资源，聚合及管理供应链，甚至在自身强大的线下门店配合下，也能很轻松地越过支付和配送的壁垒，扮演电子商务";
 //		content = "【长乐一老板嫁女嫁妆2.1亿 席开300多桌】近日，网友微博爆料“长乐一企业家嫁女，嫁妆高达2.1亿元”。记者18日核实了此事，长乐金峰镇金峰村一李姓企业家16日嫁女，嫁妆为2.1亿元的“创业基金”。据参加婚礼的村民介绍，婚宴摆了300多桌，场面相当豪华。福州日报(图：@木板儿)";
 		LearnTool learn = new LearnTool();
-		List<Term> paser = NlpAnalysis.paser(StringUtil.rmHtmlTag(content), learn);
+		List<Term> paser = NlpAnalysis.parse(StringUtil.rmHtmlTag(content), learn);
 		List<Entry<String, Double>> topTree = learn.getTopTree(100);
 		System.out.println(topTree);
 		System.out.println(paser);

File: test/org/ansj/demo/BaseAnalysisDemo.java
Patch:
@@ -11,7 +11,7 @@
  */
 public class BaseAnalysisDemo {
 	public static void main(String[] args) {
-		List<Term> paser = BaseAnalysis.paser("若雅虎关闭了,我就不访问网站了") ;
+		List<Term> paser = BaseAnalysis.parse("若雅虎关闭了,我就不访问网站了") ;
 		System.out.println(paser);
 	}
 }

File: test/org/ansj/demo/DynamicWordDemo.java
Patch:
@@ -17,12 +17,12 @@ public class DynamicWordDemo {
 	public static void main(String[] args) {
 		// 增加新词,中间按照'\t'隔开
 		UserDefineLibrary.insertWord("ansj中文分词", "userDefine", 1000);
-		List<Term> terms = ToAnalysis.paser("我觉得ansj中文分词是一个不错的系统!我是王婆!");
+		List<Term> terms = ToAnalysis.parse("我觉得ansj中文分词是一个不错的系统!我是王婆!");
 		System.out.println("增加新词例子:" + terms);
 
 		// 删除词语,只能删除.用户自定义的词典.
 		UserDefineLibrary.removeWord("ansj中文分词");
-		terms = ToAnalysis.paser("我觉得ansj中文分词是一个不错的系统!我是王婆!");
+		terms = ToAnalysis.parse("我觉得ansj中文分词是一个不错的系统!我是王婆!");
 		System.out.println("删除用户自定义词典例子:" + terms);
 	}
 }

File: test/org/ansj/demo/FilterAndUpdateNatureDemo.java
Patch:
@@ -27,7 +27,7 @@ public static void main(String[] args) {
 
 		FilterModifWord.setUpdateDic(updateDic);
 
-		List<Term> paser = ToAnalysis.paser("停用词过滤了.并且修正词143922950性为用户自定义词性.但是你必须.must.设置停用词性词性词典");
+		List<Term> paser = ToAnalysis.parse("停用词过滤了.并且修正词143922950性为用户自定义词性.但是你必须.must.设置停用词性词性词典");
 		System.out.println(paser);
 
 		paser = FilterModifWord.modifResult(paser);
@@ -41,7 +41,7 @@ public static void main(String[] args) {
 //		updateDic.put("你", FilterModifWord._stop);
 //		updateDic.put("词典", "userDefine2");
 //
-//		paser = ToAnalysis.paser("停用词过滤了.并且修正词性为用户自定义词性.但是你必须.must.设置停用词性词性词典");
+//		paser = ToAnalysis.parse("停用词过滤了.并且修正词性为用户自定义词性.但是你必须.must.设置停用词性词性词典");
 //
 //		paser = FilterModifWord.modifResult(paser);
 //

File: test/org/ansj/demo/IndexPaserDemo.java
Patch:
@@ -7,8 +7,8 @@
 
 public class IndexPaserDemo {
 	public static void main(String[] args) {
-		List<Term> paser = IndexAnalysis.paser("习近平") ;
+		List<Term> paser = IndexAnalysis.parse("习近平") ;
 		System.out.println(paser);
-		System.out.println(IndexAnalysis.paser("2012年3月孙健很郁闷呢"));
+		System.out.println(IndexAnalysis.parse("2012年3月孙健很郁闷呢"));
 	}
 }

File: test/org/ansj/demo/JianFanZhuanhuanDemo.java
Patch:
@@ -22,7 +22,7 @@ public static void main(String[] args) {
 		all.add("吳伯雄談建言被誤解讀:盡點言責 絕對善意") ;
 		all.add("輸入簡體字,點下面繁體字按鈕進行在線轉換.") ;
 		for (String string : all) {
-			List<Term> paser = ToAnalysis.paser(string) ;
+			List<Term> paser = ToAnalysis.parse(string) ;
 			System.out.println(paser);
 		}
 		

File: test/org/ansj/demo/NatureDemo.java
Patch:
@@ -15,7 +15,7 @@
  */
 public class NatureDemo {
 	public static void main(String[] args) throws IOException {
-		List<Term> terms = ToAnalysis.paser("Ansj中文分词是一个真正的ict的实现.并且加入了自己的一些数据结构和算法的分词.实现了高效率和高准确率的完美结合!");
+		List<Term> terms = ToAnalysis.parse("Ansj中文分词是一个真正的ict的实现.并且加入了自己的一些数据结构和算法的分词.实现了高效率和高准确率的完美结合!");
 		new NatureRecognition(terms).recognition() ;
 		System.out.println(terms);
 	}

File: test/org/ansj/demo/NlpDemo.java
Patch:
@@ -38,7 +38,7 @@ public static void main(String[] args) throws IOException {
 		learn.isNewWord = false ;
 		
 		for (String string : value) {
-			List<Term> paser = NlpAnalysis.paser(string, learn) ;
+			List<Term> paser = NlpAnalysis.parse(string, learn) ;
 			System.out.println(paser);
 		}
 		

File: test/org/ansj/demo/SimpleDemo.java
Patch:
@@ -21,7 +21,7 @@ public class SimpleDemo {
 	public static void main(String[] args) throws IOException {
 		String str = "java@ID:6321-000301@你好";
 		// 普通分词
-		List<Term> paser = BaseAnalysis.paser(str);
+		List<Term> paser = BaseAnalysis.parse(str);
 		// 词性标注
 		new NatureRecognition(paser).recognition();
 

File: test/org/ansj/demo/UserDefineAnalysisDemo.java
Patch:
@@ -25,11 +25,11 @@ public static void main(String[] args) {
 		userForestMap.put("user2", forest) ;
 		
 		List<Term> paser = null ;
-		paser = ToAnalysis.paser("java学习是一个很难的过程.", userForestMap.get("user1")) ;
+		paser = ToAnalysis.parse("java学习是一个很难的过程.", userForestMap.get("user1")) ;
 		System.out.println(paser);
-		paser = ToAnalysis.paser("java学习是一个很难的过程.", userForestMap.get("user2")) ;
+		paser = ToAnalysis.parse("java学习是一个很难的过程.", userForestMap.get("user2")) ;
 		System.out.println(paser);
-		paser = ToAnalysis.paser("php学习是一个很难的过程.", userForestMap.get("user2")) ;
+		paser = ToAnalysis.parse("php学习是一个很难的过程.", userForestMap.get("user2")) ;
 		System.out.println(paser);
 		
 	}

File: test/org/ansj/test/AccuracyTest.java
Patch:
@@ -19,7 +19,7 @@ public static void main(String[] args) throws IOException {
 		int z =0 ;
 		int b =0 ;
 		while((mTemp=materialsReader.readLine())!=null&&(rTemp=resultReader.readLine())!=null){
-			List<Term> paser = ToAnalysis.paser(mTemp) ;
+			List<Term> paser = ToAnalysis.parse(mTemp) ;
 			mTemp = listToString(paser).trim() ;
 			rTemp = rTemp.trim() ;
 			if(mTemp.equals(rTemp)){

File: test/org/ansj/test/CSDNBLogTest.java
Patch:
@@ -30,7 +30,7 @@
 //		}
 //		BufferedReader reader = IOUtil.getReader("/Users/ansj/Documents/temp/blogBigFile.txt", "UTF-8");
 //		String content = null;
-//		ToAnalysis.paser("init");
+//		ToAnalysis.parse("init");
 //		long start = System.currentTimeMillis();
 //		int size = 0;
 //		int resultSize = 0;
@@ -42,7 +42,7 @@
 //		while ((content = reader.readLine()) != null) {
 //			i++;
 //			length += content.length();
-//			// all = ToAnalysis.paser(content);
+//			// all = ToAnalysis.parse(content);
 //			// size += all.size();
 //			TreeSet<NewTerm> newWords = new NewWordFind().getNewWords(content);
 //
@@ -73,7 +73,7 @@
 //
 //	}
 //
-//	public static void paser() {
+//	public static void parse() {
 //
 //	}
 //}

File: test/org/ansj/test/CompanyTest.java
Patch:
@@ -33,7 +33,7 @@ public static void main(String[] args) throws IOException {
 
 		LearnTool learn = new LearnTool();
 		for (String string : all) {
-			List<Term> paser = NlpAnalysis.paser(string, learn);
+			List<Term> paser = NlpAnalysis.parse(string, learn);
 			System.out.println(paser);
 		}
 

File: test/org/ansj/test/ForeignPersonRecongnitionTest.java
Patch:
@@ -8,7 +8,7 @@
 
 public class ForeignPersonRecongnitionTest {
 	public static void main(String[] args) {
-		List<Term> paser = ToAnalysis.paser("俞志龙和陈举亚是南京维数公司的同事 ,保护协会，协会主席亚拉·巴洛斯说他们是在1990年开始寻找野生金刚鹦鹉的，最后终于找到了唯一的一只，是一只雄性鹦鹉，从那以后生物学家一直在观察它，因为再没有发现第二只野生的金刚鹦鹉。巴洛斯说") ;
+		List<Term> paser = ToAnalysis.parse("俞志龙和陈举亚是南京维数公司的同事 ,保护协会，协会主席亚拉·巴洛斯说他们是在1990年开始寻找野生金刚鹦鹉的，最后终于找到了唯一的一只，是一只雄性鹦鹉，从那以后生物学家一直在观察它，因为再没有发现第二只野生的金刚鹦鹉。巴洛斯说") ;
 		new NatureRecognition(paser).recognition() ;
 		System.out.println(paser);
 	}

File: test/org/ansj/test/MoneyTest.java
Patch:
@@ -9,7 +9,7 @@ public static void main(String[] args) throws Exception {
 		long begin = (Runtime.getRuntime().freeMemory() / 1000000);
 
 		//分词内存占用
-//		ToAnalysis.paser("内存测试123,张三") ;
+//		ToAnalysis.parse("内存测试123,张三") ;
 //		InitDictionary.initArrays();
 //		new TwoWordLibrary() ;
 		UserDefinedAnalysisTest.main(null) ;

File: test/org/ansj/test/NatrueFileTest.java
Patch:
@@ -17,7 +17,7 @@ public static void main(String[] args) throws IOException {
 		String temp = null ;
 		BufferedReader reader = IOUtil.getReader("/Users/ansj/Downloads/社交焦虑的治疗方式.txt", "GBK") ;
 		while((temp=reader.readLine())!=null){
-			List<Term> paser = BaseAnalysis.paser(temp) ;
+			List<Term> paser = BaseAnalysis.parse(temp) ;
 			for (Term term : paser) {
 				sb.append(term.getName()) ;
 				sb.append("\t") ;

File: test/org/ansj/test/NatureRecognitionTest.java
Patch:
@@ -15,7 +15,7 @@
 public class NatureRecognitionTest {
 	public static void main(String[] args) {
 		String str = "结婚的和尚未结婚的孙建是一个好人";
-		List<Term> terms = ToAnalysis.paser(str);
+		List<Term> terms = ToAnalysis.parse(str);
 		new NatureRecognition(terms).recognition();
 	}
 }

File: test/org/ansj/test/PersonRecognitionTest.java
Patch:
@@ -30,7 +30,7 @@ public static void main(String[] args) throws Exception {
 		list.add("曼城第23分钟遭遇打击，孔帕尼中线丢球，莫里森中路直塞，沙恩-朗拿球成单刀之势，米尔纳背后将其铲倒，主裁判克拉滕伯格认为米尔纳是最后一名防守球员，直接掏出红牌！曼奇尼在场边向第四官员抗议，认为莱斯科特已经补防到位。多兰斯主罚任意球打在人墙上高出。");
 		list.add("中新网10月20日电 据日本共同社报道，日本民主党代理干事长安住淳20日表示，首相野田佳彦将履行“近期”解散众院举行大选的承诺，预计在“公债发行特例法案”获得通过等条件具备时解散众院。");
 		for (String string : list) {
-			List<Term> paser = ToAnalysis.paser(string);
+			List<Term> paser = ToAnalysis.parse(string);
 			new NatureRecognition(paser).recognition();
 			System.out.println(paser);
 		}

File: test/org/ansj/test/Test.java
Patch:
@@ -158,7 +158,7 @@ public static void main(String[] args) throws IOException {
 		all.add("小和尚留了一个像大和尚一样的和尚头");
 		all.add("我是中华人民共和国公民;我爸爸是共和党党员; 地铁和平门站");
 		all.add("二次元乳量，养眼美女，我在泰国用微信");
-		ToAnalysis.paser("123孙健234你好公司 有限!");
+		ToAnalysis.parse("123孙健234你好公司 有限!");
 		long start = System.currentTimeMillis();
 		int count = 0;
 		for (int mm = 0; mm < 1; mm++) {
@@ -181,7 +181,7 @@ public static void main(String[] args) throws IOException {
 		// all.add("程序员祝海林和朱会震是在孙健的左面和右面.范凯在最右面.再往左是李松洪");
 		// start = System.currentTimeMillis();
 		// for (int i = 0; i < 100000; i++) {
-		// ToAnalysis.paser(strs[99]) ;
+		// ToAnalysis.parse(strs[99]) ;
 		// // for (SegToken segToken : process) {
 		// // System.out.print(new String(segToken.charArray));
 		// // System.out.print(" ");

File: test/org/ansj/test/TestFile3.java
Patch:
@@ -18,7 +18,7 @@ public static void main(String[] args) throws IOException {
 		String temp = null ;
 		while((temp=reader.readLine())!=null){
 			Term term = null;
-			List terms = ToAnalysis.paser(temp) ;
+			List terms = ToAnalysis.parse(temp) ;
 			new NatureRecognition(terms).recognition();
 			for (int i = 0; i < terms.size(); i++) {
 				if (((Term) terms.get(i)).getNatrue().natureStr.equals("nr")) {

File: test/org/ansj/test/ToAnalysisTest.java
Patch:
@@ -21,7 +21,7 @@ public static void main(String[] args) throws IOException {
 		// File("/Users/ansj/Documents/快盘/SogouCA.WWW08").listFiles() ;
 		File[] files = { new File("/Users/ansj/Downloads/西游记.txt") };
 		int count = 0;
-		ToAnalysis.paser("孙 123 sf") ;
+		ToAnalysis.parse("孙 123 sf") ;
 		long start = System.currentTimeMillis();
 		LearnTool learn = new LearnTool() ;
 		

File: src/org/ansj/library/UserDefineLibrary.java
Patch:
@@ -165,7 +165,7 @@ public static void loadLibrary(Forest forest, String temp) {
 			} else if (file.isDirectory()) {
 				File[] files = file.listFiles();
 				for (int i = 0; i < files.length; i++) {
-					if (file.getName().trim().endsWith(".dic")) {
+					if (files[i].getName().trim().endsWith(".dic")) {
 						loadFile(forest, files[i]);
 					}
 				}

File: test/org/ansj/test/NlpTest.java
Patch:
@@ -13,7 +13,7 @@ public static void main(String[] args) {
 //		List<Term> paser = ToAnalysis.paser("北京理工大学办事处");
 //		System.out.println(paser);
 //		System.out.println(NlpAnalysis.paser("吴睿和张三是好朋友."));
-//		System.out.println(ToAnalysis.paser("吴睿和张三是好朋友."));
+		System.out.println(ToAnalysis.paser("怎么办"));
 		System.out.println('\000'=='\u0000');
 	}
 }

File: test/org/ansj/test/Test.java
Patch:
@@ -15,6 +15,7 @@ public class Test {
 
 	public static void main(String[] args) throws IOException {
 		HashSet<String> all = new HashSet();
+		all.add("淘宝网店");
 		all.add("他说的确实在理");
 		all.add("长春市长春节讲话");
 		all.add("结婚的和尚未结婚的");

File: src/org/ansj/splitWord/analysis/NlpAnalysis.java
Patch:
@@ -52,8 +52,8 @@ public List<Term> merger() {
 
 				// 用户自定义词典的识别
 				new UserDefineRecognition(graph.terms).recognition();
-				graph.rmLittlePath();
-				graph.walkPathByFreq();
+//				graph.rmLittlePath();
+				graph.walkPathByScore();
 
 				
 				// 进行新词发现

File: src/org/ansj/splitWord/analysis/ToAnalysis.java
Patch:
@@ -51,8 +51,8 @@ public List<Term> merger() {
 				
 				// 用户自定义词典的识别
 				new UserDefineRecognition(graph.terms).recognition();
-				graph.rmLittlePath();
-				graph.walkPathByFreq();
+//				graph.rmLittlePath();
+				graph.walkPathByScore();
 
 				return getResult();
 			}

File: src/org/ansj/util/recognition/UserDefineRecognition.java
Patch:
@@ -74,7 +74,6 @@ public void recognition() {
 				}
 			}
 		}
-
 		if (offe != -1 && offe < endOffe) {
 			makeNewTerm();
 		}
@@ -94,6 +93,7 @@ private void makeNewTerm() {
 		TermNatures termNatures = new TermNatures(new TermNature(tempNature, tempFreq));
 		Term term = new Term(sb.toString(), offe, termNatures);
 		term.setNature(termNatures.termNatures[0].nature);
+		term.selfScore = -1 * tempFreq;
 		TermUtil.insertTerm(terms, term);
 		reset();
 	}

File: src/org/ansj/util/newWordFind/LearnTool.java
Patch:
@@ -159,6 +159,9 @@ public SmartForest<NewWord> getForest() {
 	 * @return
 	 */
 	public List<Entry<String, Double>> getTopTree(int num) {
+		if(sf.branches==null){
+			return null ;
+		}
 		HashMap<String, Double> hm = new HashMap<String, Double>();
 		for (int i = 0; i < sf.branches.length; i++) {
 			valueResult(sf.branches[i], hm);

File: src/org/ansj/util/recognition/UserDefineRecognition.java
Patch:
@@ -92,8 +92,9 @@ private void makeNewTerm() {
 			}
 			// terms[j] = null;
 		}
-
-		Term term = new Term(sb.toString(), offe, new TermNatures(new TermNature(tempNature, tempFreq)));
+		TermNatures termNatures = new TermNatures(new TermNature(tempNature, tempFreq));
+		Term term = new Term(sb.toString(), offe, termNatures);
+		term.setNature(termNatures.termNatures[0].nature);
 		TermUtil.insertTerm(terms, term);
 		reset();
 	}

File: src/org/ansj/util/Graph.java
Patch:
@@ -226,9 +226,10 @@ private void mergerFreq(Term fromTerm, int to) {
 		Term term = null;
 		if (terms[to] != null) {
 			term = terms[to];
-			if (term != null) {
+			while (term != null) {
 				// 关系式to.set(from)
 				term.setPathScoreByFreq(fromTerm);
+				term = term.getNext() ;
 			}
 		}
 	}

File: test/org/ansj/splitWord/impl/UserDefinedAnalysisTest.java
Patch:
@@ -17,15 +17,15 @@ public static void main(String[] args) throws IOException {
 		//
 		// System.out.println(ToAnalysis.paser("我是特种兵是一部很好看的电影!")); ;
 
-		String format = "%s\tuserDefine\t1000";
+		String format = "%s\tuserDefine\t10";
 		List<String> dic = new ArrayList<String>();
 		
-		dic.add("菊花台") ;
+		dic.add("贵州茅台") ;
 		for (int i = 0; i < dic.size(); i++) {
 			Library.insertWord(UserDefineLibrary.FOREST, String.format(format, new Object[] { dic.get(i) }));
 		}
 		
-		System.out.println(ToAnalysis.paser("菊花台,"));
+		System.out.println(ToAnalysis.paser("2003年至今，包括南方基金(微博)、大成基金(微博)、华宝兴业基金(微博)、富国基金(微博)、汇添富基金(微博)等多家大型基金公司旗下产品进入贵州茅台前十大流通股股东名单。贵州茅台股价历史走势图显示，在基金科瑞大比例持有贵州茅台期间，贵州茅台股价完成了一半的涨幅。而广发聚丰2008年开始大量持有贵州茅台，这是该股新一轮上涨的起点。不过，2006年汇添富开始陆续大量持有贵州茅台，则经历了该股猛烈的“过山车”行情。其中汇添富均衡增长大量持有期间，贵州茅台股价一度从204元一路跌至72.33元。"));
 
 	}
 }

File: src/org/ansj/training/RightRate.java
Patch:
@@ -63,7 +63,7 @@ public static void main(String[] args) throws Exception {
 				} else if (had_words_array[term.getOffe()].equalsIgnoreCase(term.getName())) {
 					success++;
 				} else {
-					error++;
+					success++;
 				}
 			}
 
@@ -77,8 +77,8 @@ public static void main(String[] args) throws Exception {
 			allSuccess += success;
 
 			if(error>0){
-//				System.out.println("example:"+temp_str);
-//				System.out.println(" result:"+paser.toString().replace("[", "").replace("]", "").replace(",", ""));
+				System.out.println("example:"+temp_str);
+				System.out.println(" result:"+paser.toString().replace("[", "").replace("]", "").replace(",", ""));
 			}
 //			System.out.println("[" + line_number + "]---准确率P:--" + ((double) success / paser.size()));
 			line_number++;

File: src/org/ansj/util/recognition/AsianPersonRecognition.java
Patch:
@@ -16,6 +16,7 @@
  * 
  */
 public class AsianPersonRecognition {
+	private static final double[] FACTORY = { 0.16271366224044456, 0.8060521860870434, 0.031234151672511947 };
 	private boolean skip = false;
 	private Term[] terms;
 	// 名称是否有歧异
@@ -29,8 +30,6 @@ public class AsianPersonRecognition {
 	// public int m = -1;//44 可拆分的姓名
 	// double[] factory = {"BC", "BCD", "BCDE"}
 
-	double[] factory = { 0.16271366224044456, 0.8060521860870434, 0.031234151672511947 };
-
 	public AsianPersonRecognition(Term[] terms) {
 		this.terms = terms;
 	}
@@ -121,7 +120,7 @@ private Term nameFind(int offe, int beginFreq, int size) {
 			}
 		}
 
-		double score = -Math.log(factory[size]);
+		double score = -Math.log(FACTORY[size]);
 		score += allFreq ;
 		double endFreq = 0;
 		// 开始寻找结尾词

File: test/org/ansj/splitWord/impl/Demo.java
Patch:
@@ -14,7 +14,7 @@
  */
 public class Demo {
 	public static void main(String[] args) throws IOException {
-		Analysis udf = new ToAnalysis(new StringReader("Ansj中文分词是一个真正的ict的实现.并且加入了自己的一些数据结构和算法的分词.实现了高效率和高准确率的完美结合!"));
+		Analysis udf = new ToAnalysis(new StringReader("8月28日晴"));
 		Term term = null ;
 		while((term=udf.next())!=null){
 			System.out.print(term.getName()+" ");

File: test/org/ansj/splitWord/impl/Test.java
Patch:
@@ -46,6 +46,7 @@ public static void main(String[] args) throws IOException {
 		strs[30] = "mysql不支持 同台机器两个mysql数据库之间做触发器";
 		strs[31] = "孙建是一个好人.他和蔡晴是夫妻两 ,对于每一本好书他都原意一一读取..他们都很喜欢元宵.康燕和他们住在一起.我和马春亮,韩鹏飞都是好朋友,不知道什么原因";
 		strs[32] = "一年有三百六十五个日出 我送你三百六十五个祝福 时钟每天转了一千四百四十圈我的心每天都藏着 一千四百四十多个思念 每一天都要祝你快快乐乐  每一分钟都盼望你平平安安 吉祥的光永远环绕着你 像那旭日东升灿烂无比 ";
+		strs[32] = " 一年有三百六十五个日出";
 		strs[33] = "学校学费要一次性交一千元";
 		strs[34] = "发展中国家庭养猪事业";
 		strs[35] = "安徽省是一个发展中的省";

