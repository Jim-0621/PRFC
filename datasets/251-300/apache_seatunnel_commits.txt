File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/util/ClickhouseCatalogUtil.java
Patch:
@@ -38,7 +38,9 @@ public String columnToConnectorType(Column column) {
                 ClickhouseTypeConverter.INSTANCE.reconvert(column).getColumnType(),
                 StringUtils.isEmpty(column.getComment())
                         ? ""
-                        : "COMMENT '" + column.getComment() + "'");
+                        : "COMMENT '"
+                                + column.getComment().replace("'", "''").replace("\\", "\\\\")
+                                + "'");
     }
 
     public String getDropTableSql(TablePath tablePath, boolean ignoreIfNotExists) {

File: seatunnel-connectors-v2/connector-clickhouse/src/test/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/ClickhouseCreateTableTest.java
Patch:
@@ -53,7 +53,8 @@ public void test() {
         columns.add(
                 PhysicalColumn.of(
                         "age", BasicType.INT_TYPE, (Long) null, true, null, "test comment"));
-        columns.add(PhysicalColumn.of("score", BasicType.INT_TYPE, (Long) null, true, null, ""));
+        columns.add(
+                PhysicalColumn.of("score", BasicType.INT_TYPE, (Long) null, true, null, "'N'-N"));
         columns.add(PhysicalColumn.of("gender", BasicType.BYTE_TYPE, (Long) null, true, null, ""));
         columns.add(
                 PhysicalColumn.of("create_time", BasicType.LONG_TYPE, (Long) null, true, null, ""));
@@ -103,7 +104,7 @@ public void test() {
                 "CREATE TABLE IF NOT EXISTS  `test1`.`test2` (\n"
                         + "    `id` Int64 ,`age` Int32 COMMENT 'test comment',\n"
                         + "    `name` String ,\n"
-                        + "`score` Int32 ,\n"
+                        + "`score` Int32 COMMENT '''N''-N',\n"
                         + "`gender` Int8 ,\n"
                         + "`create_time` Int64 \n"
                         + ") ENGINE = MergeTree()\n"

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/util/CatalogUtil.java
Patch:
@@ -106,7 +106,9 @@ public String getCreateTableSql(
                         SaveModePlaceHolder.ROWTYPE_FIELDS.getReplacePlaceHolder(), rowTypeFields)
                 .replaceAll(
                         SaveModePlaceHolder.COMMENT.getReplacePlaceHolder(),
-                        Objects.isNull(comment) ? "" : comment);
+                        Objects.isNull(comment)
+                                ? ""
+                                : comment.replace("'", "''").replace("\\", "\\\\"));
     }
 
     private String mergeColumnInTemplate(

File: seatunnel-connectors-v2/connector-doris/src/test/java/org/apache/seatunnel/connectors/doris/catalog/DorisCreateTableTest.java
Patch:
@@ -60,7 +60,8 @@ public void test() {
         columns.add(
                 PhysicalColumn.of(
                         "age", BasicType.INT_TYPE, (Long) null, true, null, "test comment"));
-        columns.add(PhysicalColumn.of("score", BasicType.INT_TYPE, (Long) null, true, null, ""));
+        columns.add(
+                PhysicalColumn.of("score", BasicType.INT_TYPE, (Long) null, true, null, "'N'-N"));
         columns.add(PhysicalColumn.of("gender", BasicType.BYTE_TYPE, (Long) null, true, null, ""));
         columns.add(
                 PhysicalColumn.of("create_time", BasicType.LONG_TYPE, (Long) null, true, null, ""));
@@ -125,7 +126,7 @@ public void test() {
                 result,
                 "CREATE TABLE IF NOT EXISTS `test1`.`test2` (                                                                                                                                                   \n"
                         + "`id` BIGINT NULL ,`age` INT NULL COMMENT 'test comment'  ,       \n"
-                        + "`name` STRING NULL ,`score` INT NULL  , \n"
+                        + "`name` STRING NULL ,`score` INT NULL COMMENT '''N''-N' , \n"
                         + "`create_time` DATETIME NOT NULL ,  \n"
                         + "`gender` TINYINT NULL   \n"
                         + ") ENGINE=OLAP  \n"

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/sink/StarRocksSaveModeUtil.java
Patch:
@@ -45,7 +45,9 @@ public String columnToConnectorType(Column column) {
                 column.isNullable() ? "NULL" : "NOT NULL",
                 StringUtils.isEmpty(column.getComment())
                         ? ""
-                        : "COMMENT '" + column.getComment() + "'");
+                        : "COMMENT '"
+                                + column.getComment().replace("'", "''").replace("\\", "\\\\")
+                                + "'");
     }
 
     private static String dataTypeToStarrocksType(SeaTunnelDataType<?> dataType, long length) {

File: seatunnel-connectors-v2/connector-starrocks/src/test/java/org/apache/seatunnel/connectors/seatunnel/starrocks/catalog/StarRocksCreateTableTest.java
Patch:
@@ -58,7 +58,7 @@ public void test() {
         columns.add(
                 PhysicalColumn.of(
                         "name", BasicType.STRING_TYPE, (Long) null, true, null, "test comment"));
-        columns.add(PhysicalColumn.of("age", BasicType.INT_TYPE, (Long) null, true, null, ""));
+        columns.add(PhysicalColumn.of("age", BasicType.INT_TYPE, (Long) null, true, null, "'N'-N"));
         columns.add(PhysicalColumn.of("score", BasicType.INT_TYPE, (Long) null, true, null, ""));
         columns.add(PhysicalColumn.of("gender", BasicType.BYTE_TYPE, (Long) null, true, null, ""));
         columns.add(
@@ -115,7 +115,7 @@ public void test() {
                         StarRocksSinkOptions.SAVE_MODE_CREATE_TEMPLATE.key());
         Assertions.assertEquals(
                 "CREATE TABLE IF NOT EXISTS `test1`.`test2` (                                                                                                                                                   \n"
-                        + "`id` BIGINT NULL ,`age` INT NULL   ,       \n"
+                        + "`id` BIGINT NULL ,`age` INT NULL COMMENT '''N''-N'  ,       \n"
                         + "`name` STRING NULL COMMENT 'test comment',`score` INT NULL  , \n"
                         + "`create_time` DATETIME NOT NULL ,  \n"
                         + "`gender` TINYINT NULL   \n"

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-doris-e2e/src/test/java/org/apache/seatunnel/e2e/connector/doris/DorisCatalogIT.java
Patch:
@@ -66,7 +66,7 @@ public class DorisCatalogIT extends AbstractDorisIT {
         TableSchema.Builder builder = TableSchema.builder();
         builder.column(PhysicalColumn.of("k1", BasicType.INT_TYPE, 10, false, 0, "k1"));
         builder.column(PhysicalColumn.of("k2", BasicType.STRING_TYPE, 64, false, "", "k2"));
-        builder.column(PhysicalColumn.of("v1", BasicType.DOUBLE_TYPE, 10, true, null, "v1"));
+        builder.column(PhysicalColumn.of("v1", BasicType.DOUBLE_TYPE, 10, true, null, "v1-'v1'"));
         builder.column(PhysicalColumn.of("v2", new DecimalType(10, 2), 0, false, 0.1, "v2"));
         builder.primaryKey(PrimaryKey.of("pk", Arrays.asList("k1", "k2")));
         catalogTable =
@@ -75,7 +75,7 @@ public class DorisCatalogIT extends AbstractDorisIT {
                         builder.build(),
                         Collections.emptyMap(),
                         Collections.emptyList(),
-                        "test");
+                        "test - \\ 'test'");
     }
 
     private DorisCatalogFactory factory;

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-file-local-e2e/src/test/java/org/apache/seatunnel/e2e/connector/file/local/LocalFileIT.java
Patch:
@@ -298,6 +298,8 @@ public class LocalFileIT extends TestSuiteBase {
     public void testLocalFileReadAndWrite(TestContainer container)
             throws IOException, InterruptedException {
         TestHelper helper = new TestHelper(container);
+        helper.execute("/csv/fake_to_local_csv.conf");
+        helper.execute("/csv/local_csv_to_assert.conf");
         helper.execute("/excel/fake_to_local_excel.conf");
         helper.execute("/excel/local_excel_to_assert.conf");
         helper.execute("/excel/local_excel_projection_to_assert.conf");

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/ArrayType.java
Patch:
@@ -56,7 +56,7 @@ public class ArrayType<T, E> implements SeaTunnelDataType<T> {
     private final Class<T> arrayClass;
     private final SeaTunnelDataType<E> elementType;
 
-    protected ArrayType(Class<T> arrayClass, SeaTunnelDataType<E> elementType) {
+    public ArrayType(Class<T> arrayClass, SeaTunnelDataType<E> elementType) {
         this.arrayClass = arrayClass;
         this.elementType = elementType;
     }

File: seatunnel-connectors-v2/connector-jdbc/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/psql/PostgresCreateTableSqlBuilderTest.java
Patch:
@@ -52,9 +52,10 @@ void build() {
                                             catalogTable.getTableId().toTablePath());
                             String pattern =
                                     "CREATE TABLE \"test\" \\(\n"
-                                            + "\"id\" int4 NOT NULL PRIMARY KEY,\n"
+                                            + "\"id\" int4 NOT NULL,\n"
                                             + "\"name\" text NOT NULL,\n"
                                             + "\"age\" int4 NOT NULL,\n"
+                                            + "\tCONSTRAINT \"([a-zA-Z0-9]+)\" PRIMARY KEY \\(\"id\",\"name\"\\),\n"
                                             + "\tCONSTRAINT \"([a-zA-Z0-9]+)\" UNIQUE \\(\"name\"\\)\n"
                                             + "\\);";
                             Assertions.assertTrue(
@@ -142,7 +143,7 @@ private CatalogTable catalogTable(boolean otherDB) {
         TableSchema tableSchema =
                 TableSchema.builder()
                         .columns(columns)
-                        .primaryKey(PrimaryKey.of("pk_id", Lists.newArrayList("id")))
+                        .primaryKey(PrimaryKey.of("pk_id_name", Lists.newArrayList("id", "name")))
                         .constraintKey(
                                 Lists.newArrayList(
                                         ConstraintKey.of(

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/BinaryReadStrategy.java
Patch:
@@ -77,6 +77,7 @@ public void read(String path, String tableId, Collector<SeaTunnelRow> output)
                 }
                 SeaTunnelRow row = new SeaTunnelRow(new Object[] {buffer, relativePath, partIndex});
                 buffer = new byte[1024];
+                row.setTableId(tableId);
                 output.collect(row);
                 partIndex++;
             }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SaveModePlaceHolder.java
Patch:
@@ -27,6 +27,7 @@ public enum SaveModePlaceHolder {
     ROWTYPE_FIELDS("rowtype_fields", "fields"),
     TABLE("table", "table"),
     DATABASE("database", "database"),
+    COMMENT("comment", "comment"),
     /** @deprecated instead by {@link #TABLE} todo remove this enum */
     @Deprecated
     TABLE_NAME("table_name", "table name");

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/catalog/ClickhouseCatalog.java
Patch:
@@ -144,6 +144,7 @@ public void createTable(TablePath tablePath, CatalogTable table, boolean ignoreI
                 tablePath.getDatabaseName(),
                 tablePath.getTableName(),
                 template,
+                table.getComment(),
                 table.getTableSchema());
     }
 
@@ -252,6 +253,7 @@ public PreviewResult previewAction(
                             tablePath.getDatabaseName(),
                             tablePath.getTableName(),
                             catalogTable.get().getTableSchema(),
+                            catalogTable.get().getComment(),
                             ClickhouseConfig.SAVE_MODE_CREATE_TEMPLATE.key()));
         } else if (actionType == ActionType.DROP_TABLE) {
             return new SQLPreviewResult(

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/config/DorisSinkOptions.java
Patch:
@@ -134,6 +134,9 @@ public interface DorisSinkOptions {
                                     + " UNIQUE KEY ("
                                     + SaveModePlaceHolder.ROWTYPE_PRIMARY_KEY.getPlaceHolder()
                                     + ")\n"
+                                    + "COMMENT '"
+                                    + SaveModePlaceHolder.COMMENT.getPlaceHolder()
+                                    + "'\n"
                                     + "DISTRIBUTED BY HASH ("
                                     + SaveModePlaceHolder.ROWTYPE_PRIMARY_KEY.getPlaceHolder()
                                     + ")\n "

File: seatunnel-connectors-v2/connector-doris/src/test/java/org/apache/seatunnel/connectors/doris/catalog/PreviewActionTest.java
Patch:
@@ -108,6 +108,7 @@ public void testDorisPreviewAction() {
                         + "`test` STRING NULL \n"
                         + ") ENGINE=OLAP\n"
                         + " UNIQUE KEY (`id`)\n"
+                        + "COMMENT 'comment'\n"
                         + "DISTRIBUTED BY HASH (`id`)\n"
                         + " PROPERTIES (\n"
                         + "\"replication_allocation\" = \"tag.location.default: 1\",\n"

File: seatunnel-connectors-v2/connector-maxcompute/src/main/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/config/MaxcomputeConfig.java
Patch:
@@ -98,7 +98,9 @@ public class MaxcomputeConfig implements Serializable {
                                     + "` (\n"
                                     + SaveModePlaceHolder.ROWTYPE_FIELDS.getPlaceHolder()
                                     + "\n"
-                                    + ");")
+                                    + ") COMMENT '"
+                                    + SaveModePlaceHolder.COMMENT.getPlaceHolder()
+                                    + "' ;")
                     .withDescription(
                             "Create table statement template, used to create MaxCompute table");
 }

File: seatunnel-connectors-v2/connector-maxcompute/src/test/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/catalog/MaxComputeCreateTableTest.java
Patch:
@@ -73,7 +73,7 @@ public void test() {
                                 + "\"in_memory\" = \"false\",\n"
                                 + "\"storage_format\" = \"V2\",\n"
                                 + "\"disable_auto_compaction\" = \"false\"\n"
-                                + ");",
+                                + ") COMMENT '${comment}';",
                         TablePath.of("test1.test2"),
                         CatalogTable.of(
                                 TableIdentifier.of("test", "test1", "test2"),
@@ -109,7 +109,7 @@ public void test() {
                                         .build(),
                                 Collections.emptyMap(),
                                 Collections.emptyList(),
-                                ""));
+                                "comment"));
         Assertions.assertEquals(
                 result,
                 "CREATE TABLE IF NOT EXISTS `test1`.`test2` (                                                                                                                                                   \n"
@@ -128,6 +128,6 @@ public void test() {
                         + "\"in_memory\" = \"false\",\n"
                         + "\"storage_format\" = \"V2\",\n"
                         + "\"disable_auto_compaction\" = \"false\"\n"
-                        + ");");
+                        + ") COMMENT 'comment';");
     }
 }

File: seatunnel-connectors-v2/connector-maxcompute/src/test/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/catalog/PreviewActionTest.java
Patch:
@@ -90,7 +90,7 @@ public void testDorisPreviewAction() {
                 "CREATE TABLE IF NOT EXISTS `testtable` (\n"
                         + "`id` BIGINT NOT NULL ,\n"
                         + "`test` STRING NULL \n"
-                        + ");",
+                        + ") COMMENT 'comment' ;",
                 Optional.of(CATALOG_TABLE));
     }
 

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/catalog/StarRocksCatalog.java
Patch:
@@ -209,6 +209,7 @@ public void createTable(TablePath tablePath, CatalogTable table, boolean ignoreI
                         tablePath.getDatabaseName(),
                         tablePath.getTableName(),
                         table.getTableSchema(),
+                        table.getComment(),
                         StarRocksSinkOptions.SAVE_MODE_CREATE_TEMPLATE.key()));
     }
 
@@ -504,6 +505,7 @@ public PreviewResult previewAction(
                             tablePath.getDatabaseName(),
                             tablePath.getTableName(),
                             catalogTable.get().getTableSchema(),
+                            catalogTable.get().getComment(),
                             StarRocksSinkOptions.SAVE_MODE_CREATE_TEMPLATE.key()));
         } else if (actionType == ActionType.DROP_TABLE) {
             return new SQLPreviewResult(

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/config/StarRocksSinkOptions.java
Patch:
@@ -71,6 +71,9 @@ public interface StarRocksSinkOptions {
                                     + " PRIMARY KEY ("
                                     + SaveModePlaceHolder.ROWTYPE_PRIMARY_KEY.getPlaceHolder()
                                     + ")\n"
+                                    + "COMMENT '"
+                                    + SaveModePlaceHolder.COMMENT.getPlaceHolder()
+                                    + "'\n"
                                     + "DISTRIBUTED BY HASH ("
                                     + SaveModePlaceHolder.ROWTYPE_PRIMARY_KEY.getPlaceHolder()
                                     + ")"

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/sink/StarRocksSinkFactory.java
Patch:
@@ -100,7 +100,7 @@ public TableSink createSink(TableSinkFactoryContext context) {
                         catalogTable.getTableSchema(),
                         catalogTable.getOptions(),
                         catalogTable.getPartitionKeys(),
-                        catalogTable.getCatalogName());
+                        catalogTable.getComment());
 
         return () -> new StarRocksSink(sinkConfig, finalCatalogTable);
     }

File: seatunnel-connectors-v2/connector-starrocks/src/test/java/org/apache/seatunnel/connectors/seatunnel/starrocks/catalog/PreviewActionTest.java
Patch:
@@ -106,6 +106,7 @@ public void testDorisPreviewAction() {
                         + "`test2` STRING NULL \n"
                         + ") ENGINE=OLAP\n"
                         + " PRIMARY KEY (`test`)\n"
+                        + "COMMENT 'comment'\n"
                         + "DISTRIBUTED BY HASH (`test`)PROPERTIES (\n"
                         + "    \"replication_num\" = \"1\" \n"
                         + ")",

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/FactoryUtil.java
Patch:
@@ -32,6 +32,7 @@
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.catalog.TableIdentifier;
+import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.connector.TableSource;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.transform.SeaTunnelTransform;
@@ -178,7 +179,7 @@ SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT> createAndPrepareSi
 
     public static <IN, StateT, CommitInfoT, AggregatedCommitInfoT>
             SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT> createMultiTableSink(
-                    Map<String, SeaTunnelSink> sinks,
+                    Map<TablePath, SeaTunnelSink> sinks,
                     ReadonlyConfig options,
                     ClassLoader classLoader) {
         try {

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/MultiTableFactoryContext.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
+import org.apache.seatunnel.api.table.catalog.TablePath;
 
 import lombok.Getter;
 
@@ -27,10 +28,10 @@
 @Getter
 public class MultiTableFactoryContext extends TableSinkFactoryContext {
 
-    private final Map<String, SeaTunnelSink> sinks;
+    private final Map<TablePath, SeaTunnelSink> sinks;
 
     public MultiTableFactoryContext(
-            ReadonlyConfig options, ClassLoader classLoader, Map<String, SeaTunnelSink> sinks) {
+            ReadonlyConfig options, ClassLoader classLoader, Map<TablePath, SeaTunnelSink> sinks) {
         super(null, options, classLoader);
         this.sinks = sinks;
     }

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceConfig.java
Patch:
@@ -137,7 +137,7 @@ private Map<TablePath, ConsumerMetadata> createMapConsumerMetadata(
         return consumerMetadataList.stream()
                 .collect(
                         Collectors.toMap(
-                                consumerMetadata -> TablePath.of(consumerMetadata.getTopic()),
+                                consumerMetadata -> TablePath.of(null, consumerMetadata.getTopic()),
                                 consumerMetadata -> consumerMetadata));
     }
 
@@ -208,7 +208,7 @@ private ConsumerMetadata createConsumerMetadata(ReadonlyConfig readonlyConfig) {
     private CatalogTable createCatalogTable(ReadonlyConfig readonlyConfig) {
         Optional<Map<String, Object>> schemaOptions =
                 readonlyConfig.getOptional(TableSchemaOptions.SCHEMA);
-        TablePath tablePath = TablePath.of(readonlyConfig.get(TOPIC));
+        TablePath tablePath = TablePath.of(null, readonlyConfig.get(TOPIC));
         TableSchema tableSchema;
         if (schemaOptions.isPresent()) {
             tableSchema = new ReadonlyConfigParser().parse(readonlyConfig);

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/execution/PluginUtil.java
Patch:
@@ -28,6 +28,7 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
+import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.connector.TableSource;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.FactoryException;
@@ -184,7 +185,7 @@ public static SeaTunnelSink createSink(
             return sink;
         } else {
             if (catalogTables.size() > 1) {
-                Map<String, SeaTunnelSink> sinks = new HashMap<>();
+                Map<TablePath, SeaTunnelSink> sinks = new HashMap<>();
                 ReadonlyConfig readonlyConfig = ReadonlyConfig.fromConfig(sinkConfig);
                 catalogTables.forEach(
                         catalogTable -> {
@@ -202,7 +203,7 @@ public static SeaTunnelSink createSink(
                                             .createSink(context)
                                             .createSink();
                             action.setJobContext(jobContext);
-                            sinks.put(catalogTable.getTablePath().toString(), action);
+                            sinks.put(catalogTable.getTablePath(), action);
                         });
                 return FactoryUtil.createMultiTableSink(sinks, readonlyConfig, classLoader);
             }

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-2-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.seatunnel.api.sink.SupportSaveMode;
 import org.apache.seatunnel.api.sink.multitablesink.MultiTableSink;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
+import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSinkFactory;
 import org.apache.seatunnel.common.exception.SeaTunnelRuntimeException;
@@ -168,7 +169,7 @@ public void handleSaveMode(SeaTunnelSink sink) {
                 }
             }
         } else if (sink instanceof MultiTableSink) {
-            Map<String, SeaTunnelSink> sinks = ((MultiTableSink) sink).getSinks();
+            Map<TablePath, SeaTunnelSink> sinks = ((MultiTableSink) sink).getSinks();
             for (SeaTunnelSink seaTunnelSink : sinks.values()) {
                 handleSaveMode(seaTunnelSink);
             }

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-starter-common/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.seatunnel.api.sink.SupportSaveMode;
 import org.apache.seatunnel.api.sink.multitablesink.MultiTableSink;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
+import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSinkFactory;
 import org.apache.seatunnel.common.exception.SeaTunnelRuntimeException;
@@ -169,7 +170,7 @@ public void handleSaveMode(SeaTunnelSink sink) {
                 }
             }
         } else if (sink instanceof MultiTableSink) {
-            Map<String, SeaTunnelSink> sinks = ((MultiTableSink) sink).getSinks();
+            Map<TablePath, SeaTunnelSink> sinks = ((MultiTableSink) sink).getSinks();
             for (SeaTunnelSink seaTunnelSink : sinks.values()) {
                 handleSaveMode(seaTunnelSink);
             }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/SinkConfig.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.engine.core.dag.actions;
 
+import org.apache.seatunnel.api.table.catalog.TablePath;
+
 import lombok.AllArgsConstructor;
 import lombok.Getter;
 import lombok.NoArgsConstructor;
@@ -25,5 +27,5 @@
 @NoArgsConstructor
 @AllArgsConstructor
 public class SinkConfig implements Config {
-    private String multipleRowTableId;
+    private TablePath tablePath;
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlanGenerator.java
Patch:
@@ -330,7 +330,7 @@ private List<PhysicalVertex> getShuffleTask(
                                             (PhysicalExecutionFlow) nextFlow;
                                     SinkAction sinkAction = (SinkAction) sinkFlow.getAction();
                                     String sinkTableId =
-                                            sinkAction.getConfig().getMultipleRowTableId();
+                                            sinkAction.getConfig().getTablePath().toString();
 
                                     long taskIDPrefix = idGenerator.getNextId();
                                     long taskGroupIDPrefix = idGenerator.getNextId();

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
 import org.apache.seatunnel.api.sink.SupportSaveMode;
 import org.apache.seatunnel.api.sink.multitablesink.MultiTableSink;
+import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.common.exception.SeaTunnelRuntimeException;
 import org.apache.seatunnel.common.utils.ExceptionUtils;
 import org.apache.seatunnel.common.utils.RetryUtils;
@@ -527,7 +528,7 @@ public static void handleSaveMode(SeaTunnelSink sink) {
                 }
             }
         } else if (sink instanceof MultiTableSink) {
-            Map<String, SeaTunnelSink> sinks = ((MultiTableSink) sink).getSinks();
+            Map<TablePath, SeaTunnelSink> sinks = ((MultiTableSink) sink).getSinks();
             for (SeaTunnelSink seaTunnelSink : sinks.values()) {
                 handleSaveMode(seaTunnelSink);
             }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/SinkFlowLifeCycle.java
Patch:
@@ -123,13 +123,13 @@ public SinkFlowLifeCycle(
         boolean isMulti = sinkAction.getSink() instanceof MultiTableSink;
         if (isMulti) {
             sinkTables = ((MultiTableSink) sinkAction.getSink()).getSinkTables();
-            String[] upstreamTablePaths =
+            TablePath[] upstreamTablePaths =
                     ((MultiTableSink) sinkAction.getSink())
                             .getSinks()
                             .keySet()
-                            .toArray(new String[0]);
+                            .toArray(new TablePath[0]);
             for (int i = 0; i < ((MultiTableSink) sinkAction.getSink()).getSinks().size(); i++) {
-                tablesMaps.put(TablePath.of(upstreamTablePaths[i]), sinkTables.get(i));
+                tablesMaps.put(upstreamTablePaths[i], sinkTables.get(i));
             }
         } else {
             Optional<CatalogTable> catalogTable = sinkAction.getSink().getWriteCatalogTable();

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/HiveSinkFactory.java
Patch:
@@ -50,6 +50,7 @@ public OptionRule optionRule() {
                 .optional(BaseSinkConfig.REMOTE_USER)
                 .optional(HiveConfig.HADOOP_CONF)
                 .optional(HiveConfig.HADOOP_CONF_PATH)
+                .optional(BaseSinkConfig.PARQUET_AVRO_WRITE_TIMESTAMP_AS_INT96)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceFactory.java
Patch:
@@ -56,6 +56,7 @@ public OptionRule optionRule() {
                         Config.SCHEMA,
                         Config.FORMAT,
                         Config.DEBEZIUM_RECORD_INCLUDE_SCHEMA,
+                        Config.DEBEZIUM_RECORD_TABLE_FILTER,
                         Config.KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS)
                 .conditional(Config.START_MODE, StartMode.TIMESTAMP, Config.START_MODE_TIMESTAMP)
                 .conditional(

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/ArrayType.java
Patch:
@@ -56,7 +56,7 @@ public class ArrayType<T, E> implements SeaTunnelDataType<T> {
     private final Class<T> arrayClass;
     private final SeaTunnelDataType<E> elementType;
 
-    public ArrayType(Class<T> arrayClass, SeaTunnelDataType<E> elementType) {
+    protected ArrayType(Class<T> arrayClass, SeaTunnelDataType<E> elementType) {
         this.arrayClass = arrayClass;
         this.elementType = elementType;
     }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/psql/PostgresTypeConverter.java
Patch:
@@ -75,7 +75,8 @@ public class PostgresTypeConverter implements TypeConverter<BasicTypeDefine> {
     public static final String PG_MONEY = "money";
 
     // char <=> character <=> bpchar
-    public static final String PG_CHAR = "bpchar";
+    public static final String PG_CHAR = "char";
+    public static final String PG_BPCHAR = "bpchar";
     public static final String PG_CHARACTER = "character";
     // char[] <=> _character <=> _bpchar
     public static final String PG_CHAR_ARRAY = "_bpchar";
@@ -189,6 +190,7 @@ public Column convert(BasicTypeDefine typeDefine) {
                 builder.scale(2);
                 break;
             case PG_CHAR:
+            case PG_BPCHAR:
             case PG_CHARACTER:
                 builder.dataType(BasicType.STRING_TYPE);
                 if (typeDefine.getLength() == null || typeDefine.getLength() <= 0) {

File: seatunnel-ci-tools/src/test/java/org/apache/seatunnel/api/ChineseCharacterCheckTest.java
Patch:
@@ -38,7 +38,7 @@
 import java.util.regex.Pattern;
 import java.util.stream.Stream;
 
-import static org.apache.seatunnel.api.ImportShadeClassCheckTest.isWindows;
+import static org.apache.seatunnel.api.ImportClassCheckTest.isWindows;
 
 @Slf4j
 public class ChineseCharacterCheckTest {

File: seatunnel-ci-tools/src/test/java/org/apache/seatunnel/api/UTClassNameCheckTest.java
Patch:
@@ -37,7 +37,7 @@
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
-import static org.apache.seatunnel.api.ImportShadeClassCheckTest.isWindows;
+import static org.apache.seatunnel.api.ImportClassCheckTest.isWindows;
 
 @Slf4j
 public class UTClassNameCheckTest {

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/seatunnel/SeaTunnelContainer.java
Patch:
@@ -393,6 +393,7 @@ private static boolean isSystemThread(String s) {
                 || s.startsWith("seatunnel-coordinator-service")
                 || s.startsWith("GC task thread")
                 || s.contains("CompilerThread")
+                || s.startsWith("SeaTunnel-CompletableFuture-Thread-")
                 || s.contains("NioNetworking-closeListenerExecutor")
                 || s.contains("ForkJoinPool.commonPool")
                 || s.contains("DestroyJavaVM")

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/ConnectorPackageClientTest.java
Patch:
@@ -35,6 +35,7 @@
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.config.SeaTunnelConfig;
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.job.ConnectorJarIdentifier;
 import org.apache.seatunnel.engine.core.job.ConnectorJarType;
 import org.apache.seatunnel.engine.core.job.JobStatus;
@@ -68,7 +69,6 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/SeaTunnelClientTest.java
Patch:
@@ -31,6 +31,7 @@
 import org.apache.seatunnel.engine.common.config.ConfigProvider;
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.config.SeaTunnelConfig;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.dag.logical.LogicalDag;
 import org.apache.seatunnel.engine.core.job.JobDAGInfo;
 import org.apache.seatunnel.engine.core.job.JobStatus;
@@ -57,7 +58,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Spliterators;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.TimeUnit;
 import java.util.stream.Collectors;

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/checkpoint/CheckpointIDCounter.java
Patch:
@@ -18,10 +18,9 @@
 
 package org.apache.seatunnel.engine.core.checkpoint;
 
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.job.PipelineStatus;
 
-import java.util.concurrent.CompletableFuture;
-
 /** A checkpoint ID counter. */
 public interface CheckpointIDCounter {
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/CoordinatorService.java
Patch:
@@ -37,6 +37,7 @@
 import org.apache.seatunnel.engine.common.exception.SavePointFailedException;
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.job.JobDAGInfo;
 import org.apache.seatunnel.engine.core.job.JobInfo;
 import org.apache.seatunnel.engine.core.job.JobResult;
@@ -88,7 +89,6 @@
 import java.util.Objects;
 import java.util.Optional;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/TaskExecutionService.java
Patch:
@@ -31,6 +31,7 @@
 import org.apache.seatunnel.engine.common.config.server.ThreadShareMode;
 import org.apache.seatunnel.engine.common.exception.JobNotFoundException;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.classloader.ClassLoaderService;
 import org.apache.seatunnel.engine.core.job.ConnectorJarIdentifier;
 import org.apache.seatunnel.engine.server.exception.TaskGroupContextNotFoundException;
@@ -82,7 +83,6 @@
 import java.util.UUID;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.CancellationException;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -29,6 +29,7 @@
 import org.apache.seatunnel.engine.common.config.server.CheckpointConfig;
 import org.apache.seatunnel.engine.common.utils.ExceptionUtil;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.checkpoint.Checkpoint;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointIDCounter;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointType;
@@ -61,7 +62,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CompletionException;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.CopyOnWriteArraySet;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManager.java
Patch:
@@ -28,6 +28,7 @@
 import org.apache.seatunnel.engine.common.utils.ExceptionUtil;
 import org.apache.seatunnel.engine.common.utils.FactoryUtil;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointIDCounter;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
 import org.apache.seatunnel.engine.core.job.Job;
@@ -55,7 +56,6 @@
 
 import java.util.Arrays;
 import java.util.Map;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutorService;
 import java.util.function.Function;
 import java.util.stream.Collectors;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/IMapCheckpointIDCounter.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.common.utils.RetryUtils;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.common.utils.ExceptionUtil;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointIDCounter;
 import org.apache.seatunnel.engine.core.job.PipelineStatus;
 
@@ -28,7 +29,6 @@
 
 import java.nio.ByteBuffer;
 import java.util.Base64;
-import java.util.concurrent.CompletableFuture;
 
 import static org.apache.seatunnel.engine.common.Constant.IMAP_CHECKPOINT_ID;
 import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkNotNull;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/PendingCheckpoint.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.checkpoint;
 
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.checkpoint.Checkpoint;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointType;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
@@ -34,7 +35,6 @@
 import java.util.Map;
 import java.util.Objects;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ScheduledFuture;
 
 public class PendingCheckpoint implements Checkpoint {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/StandaloneCheckpointIDCounter.java
Patch:
@@ -17,10 +17,10 @@
 
 package org.apache.seatunnel.engine.server.checkpoint;
 
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointIDCounter;
 import org.apache.seatunnel.engine.core.job.PipelineStatus;
 
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.atomic.AtomicLong;
 
 public class StandaloneCheckpointIDCounter implements CheckpointIDCounter {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlan.java
Patch:
@@ -23,6 +23,7 @@
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
 import org.apache.seatunnel.engine.common.utils.ExceptionUtil;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.job.JobImmutableInformation;
 import org.apache.seatunnel.engine.core.job.JobResult;
 import org.apache.seatunnel.engine.core.job.JobStatus;
@@ -39,7 +40,6 @@
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicReference;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlanGenerator.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.engine.common.config.server.QueueType;
 import org.apache.seatunnel.engine.common.utils.IdGenerator;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
 import org.apache.seatunnel.engine.core.dag.actions.ShuffleAction;
 import org.apache.seatunnel.engine.core.dag.actions.ShuffleConfig;
@@ -77,7 +78,6 @@
 import java.util.Objects;
 import java.util.Optional;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.atomic.AtomicInteger;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalVertex.java
Patch:
@@ -26,6 +26,7 @@
 import org.apache.seatunnel.engine.common.exception.TaskGroupDeployException;
 import org.apache.seatunnel.engine.common.utils.ExceptionUtil;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.job.ConnectorJarIdentifier;
 import org.apache.seatunnel.engine.core.job.JobImmutableInformation;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
@@ -58,7 +59,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.function.Function;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/ResourceUtils.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.dag.physical;
 
 import org.apache.seatunnel.common.utils.ExceptionUtils;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.execution.TaskGroupLocation;
 import org.apache.seatunnel.engine.server.master.JobMaster;
 import org.apache.seatunnel.engine.server.resourcemanager.NoEnoughResourceException;
@@ -31,7 +32,6 @@
 
 import java.util.HashMap;
 import java.util.Map;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CompletionException;
 
 public class ResourceUtils {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -23,6 +23,7 @@
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.common.utils.ExceptionUtil;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.job.JobImmutableInformation;
 import org.apache.seatunnel.engine.core.job.PipelineExecutionState;
 import org.apache.seatunnel.engine.core.job.PipelineStatus;
@@ -41,7 +42,6 @@
 
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -40,6 +40,7 @@
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
 import org.apache.seatunnel.engine.common.utils.ExceptionUtil;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.dag.actions.SinkAction;
 import org.apache.seatunnel.engine.core.dag.logical.LogicalDag;
 import org.apache.seatunnel.engine.core.dag.logical.LogicalVertex;
@@ -96,7 +97,6 @@
 import java.util.Objects;
 import java.util.Optional;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CompletionException;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.CopyOnWriteArrayList;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/GetJobCheckpointOperation.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.operation;
 
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
@@ -29,7 +30,6 @@
 import com.hazelcast.spi.impl.operationservice.Operation;
 
 import java.io.IOException;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 
 public class GetJobCheckpointOperation extends Operation

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/GetJobDetailStatusOperation.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.operation;
 
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
@@ -28,7 +29,6 @@
 import com.hazelcast.spi.impl.operationservice.Operation;
 
 import java.io.IOException;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 
 public class GetJobDetailStatusOperation extends Operation

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/GetJobInfoOperation.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.operation;
 
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
@@ -29,7 +30,6 @@
 import com.hazelcast.spi.impl.operationservice.Operation;
 
 import java.io.IOException;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 
 public class GetJobInfoOperation extends Operation

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/GetJobMetricsOperation.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.engine.server.operation;
 
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
@@ -27,7 +28,6 @@
 import com.hazelcast.spi.impl.operationservice.Operation;
 
 import java.io.IOException;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 
 import static org.apache.seatunnel.engine.server.metrics.JobMetricsUtil.toJsonString;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/GetJobStatusOperation.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.engine.server.operation;
 
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.job.JobStatus;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
@@ -28,7 +29,6 @@
 import com.hazelcast.spi.impl.operationservice.Operation;
 
 import java.io.IOException;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 
 public class GetJobStatusOperation extends Operation

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/GetRunningJobMetricsOperation.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.engine.server.operation;
 
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
@@ -27,7 +28,6 @@
 import com.hazelcast.spi.impl.operationservice.Operation;
 
 import java.io.IOException;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 
 import static org.apache.seatunnel.engine.server.metrics.JobMetricsUtil.toJsonString;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/ListJobStatusOperation.java
Patch:
@@ -18,12 +18,12 @@
 package org.apache.seatunnel.engine.server.operation;
 
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 
 import com.hazelcast.spi.impl.AllowedDuringPassiveState;
 import com.hazelcast.spi.impl.operationservice.Operation;
 
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 
 public class ListJobStatusOperation extends Operation implements AllowedDuringPassiveState {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/UploadConnectorJarOperation.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.operation;
 
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.job.ConnectorJarIdentifier;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
@@ -30,7 +31,6 @@
 import com.hazelcast.spi.impl.operationservice.Operation;
 
 import java.io.IOException;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 
 public class UploadConnectorJarOperation extends Operation implements IdentifiedDataSerializable {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/AbstractResourceManager.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.engine.common.config.EngineConfig;
 import org.apache.seatunnel.engine.common.runtime.ExecutionMode;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.resourcemanager.opeartion.ReleaseSlotOperation;
 import org.apache.seatunnel.engine.server.resourcemanager.opeartion.ResetResourceOperation;
 import org.apache.seatunnel.engine.server.resourcemanager.opeartion.SyncWorkerProfileOperation;
@@ -39,7 +40,6 @@
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.stream.Collectors;
@@ -176,7 +176,8 @@ public void close() {
     }
 
     protected <E> CompletableFuture<E> sendToMember(Operation operation, Address address) {
-        return NodeEngineUtil.sendOperationToMemberNode(nodeEngine, operation, address);
+        return new CompletableFuture<>(
+                NodeEngineUtil.sendOperationToMemberNode(nodeEngine, operation, address));
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/ResourceManager.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.engine.server.resourcemanager;
 
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.ResourceProfile;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.SlotProfile;
 import org.apache.seatunnel.engine.server.resourcemanager.worker.WorkerProfile;
@@ -25,7 +26,6 @@
 
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.CompletableFuture;
 
 public interface ResourceManager {
     void init();

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/ResourceRequestHandler.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.shade.com.google.common.annotations.VisibleForTesting;
 
 import org.apache.seatunnel.engine.common.runtime.DeployType;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.resourcemanager.opeartion.RequestSlotOperation;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.ResourceProfile;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.SlotProfile;
@@ -36,7 +37,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Optional;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/thirdparty/ThirdPartyResourceManager.java
Patch:
@@ -17,10 +17,9 @@
 
 package org.apache.seatunnel.engine.server.resourcemanager.thirdparty;
 
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.ResourceProfile;
 
-import java.util.concurrent.CompletableFuture;
-
 public interface ThirdPartyResourceManager {
 
     CompletableFuture<CreateWorkerResult> createNewWorker(ResourceProfile resourceProfile);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/thirdparty/kubernetes/KubernetesResourceManager.java
Patch:
@@ -18,15 +18,14 @@
 package org.apache.seatunnel.engine.server.resourcemanager.thirdparty.kubernetes;
 
 import org.apache.seatunnel.engine.common.config.EngineConfig;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.resourcemanager.AbstractResourceManager;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.ResourceProfile;
 import org.apache.seatunnel.engine.server.resourcemanager.thirdparty.CreateWorkerResult;
 import org.apache.seatunnel.engine.server.resourcemanager.thirdparty.ThirdPartyResourceManager;
 
 import com.hazelcast.spi.impl.NodeEngine;
 
-import java.util.concurrent.CompletableFuture;
-
 public class KubernetesResourceManager extends AbstractResourceManager
         implements ThirdPartyResourceManager {
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/thirdparty/yarn/YarnResourceManager.java
Patch:
@@ -18,15 +18,14 @@
 package org.apache.seatunnel.engine.server.resourcemanager.thirdparty.yarn;
 
 import org.apache.seatunnel.engine.common.config.EngineConfig;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.resourcemanager.AbstractResourceManager;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.ResourceProfile;
 import org.apache.seatunnel.engine.server.resourcemanager.thirdparty.CreateWorkerResult;
 import org.apache.seatunnel.engine.server.resourcemanager.thirdparty.ThirdPartyResourceManager;
 
 import com.hazelcast.spi.impl.NodeEngine;
 
-import java.util.concurrent.CompletableFuture;
-
 public class YarnResourceManager extends AbstractResourceManager
         implements ThirdPartyResourceManager {
     public YarnResourceManager(NodeEngine nodeEngine, EngineConfig engineConfig) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/AbstractTask.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.task;
 
 import org.apache.seatunnel.api.serialization.Serializer;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.job.ConnectorJarIdentifier;
 import org.apache.seatunnel.engine.server.checkpoint.operation.TaskReportStatusOperation;
 import org.apache.seatunnel.engine.server.execution.ProgressState;
@@ -32,7 +33,6 @@
 import java.net.URL;
 import java.util.List;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.stream.Collectors;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -23,6 +23,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.tracing.MDCTracer;
 import org.apache.seatunnel.common.utils.function.ConsumerWithException;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.checkpoint.InternalCheckpointListener;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
 import org.apache.seatunnel.engine.core.dag.actions.ShuffleAction;
@@ -75,7 +76,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.function.BiConsumer;
 import java.util.stream.Collectors;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SinkAggregatedCommitterTask.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.serialization.Serializer;
 import org.apache.seatunnel.api.sink.SinkAggregatedCommitter;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.dag.actions.SinkAction;
 import org.apache.seatunnel.engine.core.job.ConnectorJarIdentifier;
 import org.apache.seatunnel.engine.server.checkpoint.ActionStateKey;
@@ -49,7 +50,6 @@
 import java.util.Map;
 import java.util.Objects;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CopyOnWriteArrayList;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSeaTunnelTask.java
Patch:
@@ -26,6 +26,7 @@
 import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.core.starter.flowcontrol.FlowControlStrategy;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.dag.actions.SourceAction;
 import org.apache.seatunnel.engine.server.dag.physical.config.SourceConfig;
 import org.apache.seatunnel.engine.server.dag.physical.flow.PhysicalExecutionFlow;
@@ -42,7 +43,6 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.CompletableFuture;
 import java.util.stream.Collectors;
 
 public class SourceSeaTunnelTask<T, SplitT extends SourceSplit> extends SeaTunnelTask {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/TransformSeaTunnelTask.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.api.common.metrics.MetricsContext;
 import org.apache.seatunnel.api.table.type.Record;
 import org.apache.seatunnel.api.transform.Collector;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.dag.actions.SourceAction;
 import org.apache.seatunnel.engine.server.dag.physical.config.SourceConfig;
 import org.apache.seatunnel.engine.server.dag.physical.flow.Flow;
@@ -33,8 +34,6 @@
 import com.hazelcast.logging.Logger;
 import lombok.NonNull;
 
-import java.util.concurrent.CompletableFuture;
-
 public class TransformSeaTunnelTask extends SeaTunnelTask {
 
     private static final ILogger LOGGER = Logger.getLogger(TransformSeaTunnelTask.class);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/AbstractFlowLifeCycle.java
Patch:
@@ -17,13 +17,13 @@
 
 package org.apache.seatunnel.engine.server.task.flow;
 
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.task.SeaTunnelTask;
 
 import lombok.Getter;
 import lombok.Setter;
 
 import java.io.IOException;
-import java.util.concurrent.CompletableFuture;
 
 public class AbstractFlowLifeCycle implements FlowLifeCycle {
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/ActionFlowLifeCycle.java
Patch:
@@ -17,12 +17,11 @@
 
 package org.apache.seatunnel.engine.server.task.flow;
 
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
 import org.apache.seatunnel.engine.server.checkpoint.Stateful;
 import org.apache.seatunnel.engine.server.task.SeaTunnelTask;
 
-import java.util.concurrent.CompletableFuture;
-
 public abstract class ActionFlowLifeCycle extends AbstractFlowLifeCycle implements Stateful {
 
     protected Action action;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/IntermediateQueueFlowLifeCycle.java
Patch:
@@ -19,11 +19,11 @@
 
 import org.apache.seatunnel.api.table.type.Record;
 import org.apache.seatunnel.api.transform.Collector;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.task.SeaTunnelTask;
 import org.apache.seatunnel.engine.server.task.group.queue.AbstractIntermediateQueue;
 
 import java.io.IOException;
-import java.util.concurrent.CompletableFuture;
 
 public class IntermediateQueueFlowLifeCycle<T extends AbstractIntermediateQueue<?>>
         extends AbstractFlowLifeCycle

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/ShuffleSinkFlowLifeCycle.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.table.schema.event.SchemaChangeEvent;
 import org.apache.seatunnel.api.table.type.Record;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.dag.actions.ShuffleAction;
 import org.apache.seatunnel.engine.core.dag.actions.ShuffleStrategy;
 import org.apache.seatunnel.engine.server.checkpoint.ActionStateKey;
@@ -35,7 +36,6 @@
 import java.util.LinkedList;
 import java.util.Map;
 import java.util.Queue;
-import java.util.concurrent.CompletableFuture;
 
 @SuppressWarnings("MagicNumber")
 @Slf4j

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/ShuffleSourceFlowLifeCycle.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.table.type.Record;
 import org.apache.seatunnel.api.transform.Collector;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.dag.actions.ShuffleAction;
 import org.apache.seatunnel.engine.server.checkpoint.ActionStateKey;
 import org.apache.seatunnel.engine.server.task.SeaTunnelTask;
@@ -34,7 +35,6 @@
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.CompletableFuture;
 
 @Slf4j
 @SuppressWarnings("MagicNumber")

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/SinkFlowLifeCycle.java
Patch:
@@ -32,6 +32,7 @@
 import org.apache.seatunnel.api.table.type.Record;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.common.constants.PluginType;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.checkpoint.InternalCheckpointListener;
 import org.apache.seatunnel.engine.core.dag.actions.SinkAction;
 import org.apache.seatunnel.engine.server.checkpoint.ActionStateKey;
@@ -60,7 +61,6 @@
 import java.util.Map;
 import java.util.Objects;
 import java.util.Optional;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 import java.util.stream.Collectors;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/SourceFlowLifeCycle.java
Patch:
@@ -26,6 +26,7 @@
 import org.apache.seatunnel.api.source.event.ReaderCloseEvent;
 import org.apache.seatunnel.api.source.event.ReaderOpenEvent;
 import org.apache.seatunnel.api.table.type.Record;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointType;
 import org.apache.seatunnel.engine.core.checkpoint.InternalCheckpointListener;
 import org.apache.seatunnel.engine.core.dag.actions.SourceAction;
@@ -57,7 +58,6 @@
 import java.util.Collection;
 import java.util.List;
 import java.util.Objects;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.stream.Collectors;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/TransformFlowLifeCycle.java
Patch:
@@ -23,6 +23,7 @@
 import org.apache.seatunnel.api.transform.SeaTunnelFlatMapTransform;
 import org.apache.seatunnel.api.transform.SeaTunnelMapTransform;
 import org.apache.seatunnel.api.transform.SeaTunnelTransform;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.dag.actions.TransformChainAction;
 import org.apache.seatunnel.engine.server.checkpoint.ActionStateKey;
 import org.apache.seatunnel.engine.server.checkpoint.ActionSubtaskState;
@@ -38,7 +39,6 @@
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
-import java.util.concurrent.CompletableFuture;
 
 @Slf4j
 public class TransformFlowLifeCycle<T> extends ActionFlowLifeCycle

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/TaskExecutionServiceTest.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.shade.com.google.common.collect.Lists;
 
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.execution.BlockTask;
 import org.apache.seatunnel.engine.server.execution.ExceptionTestTask;
 import org.apache.seatunnel.engine.server.execution.FixedCallTestTimeTask;
@@ -52,7 +53,6 @@
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.TimeUnit;

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointStorageTest.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.engine.common.config.SeaTunnelConfig;
 import org.apache.seatunnel.engine.common.config.server.CheckpointConfig;
 import org.apache.seatunnel.engine.common.utils.FactoryUtil;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.core.job.JobStatus;
 import org.apache.seatunnel.engine.server.AbstractSeaTunnelServerTest;
 
@@ -33,7 +34,6 @@
 import org.junit.jupiter.api.condition.OS;
 
 import java.util.List;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.TimeUnit;
 
 import static org.awaitility.Awaitility.await;

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/resourcemanager/FakeResourceManager.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.resourcemanager;
 
 import org.apache.seatunnel.engine.common.config.EngineConfig;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.resourcemanager.opeartion.RequestSlotOperation;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.ResourceProfile;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.SlotProfile;
@@ -30,7 +31,6 @@
 
 import java.net.UnknownHostException;
 import java.util.Collections;
-import java.util.concurrent.CompletableFuture;
 
 /** Used to test ResourceManager, override init method to register more workers. */
 public class FakeResourceManager extends AbstractResourceManager {

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/resourcemanager/FakeResourceManagerForRequestSlotRetryTest.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.resourcemanager;
 
 import org.apache.seatunnel.engine.common.config.EngineConfig;
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
 import org.apache.seatunnel.engine.server.resourcemanager.opeartion.RequestSlotOperation;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.ResourceProfile;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.SlotProfile;
@@ -32,7 +33,6 @@
 import java.util.Collections;
 import java.util.HashSet;
 import java.util.Set;
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.atomic.AtomicInteger;
 
 /** Used to test ResourceManager, override init method to register more workers. */

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/utils/PeekBlockingQueueTest.java
Patch:
@@ -17,11 +17,12 @@
 
 package org.apache.seatunnel.engine.server.utils;
 
+import org.apache.seatunnel.engine.common.utils.concurrent.CompletableFuture;
+
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
 
-import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.TimeUnit;
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/ArrayType.java
Patch:
@@ -56,7 +56,7 @@ public class ArrayType<T, E> implements SeaTunnelDataType<T> {
     private final Class<T> arrayClass;
     private final SeaTunnelDataType<E> elementType;
 
-    protected ArrayType(Class<T> arrayClass, SeaTunnelDataType<E> elementType) {
+    public ArrayType(Class<T> arrayClass, SeaTunnelDataType<E> elementType) {
         this.arrayClass = arrayClass;
         this.elementType = elementType;
     }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/tracing/MDCExecutor.java
Patch:
@@ -31,6 +31,6 @@ public MDCExecutor(MDCContext context, Executor delegate) {
 
     @Override
     public void execute(Runnable command) {
-        delegate.execute(new MDCRunnable(context, command));
+        delegate.execute(new MDCRunnable(MDCContext.of(context), command));
     }
 }

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaRecordEmitter.java
Patch:
@@ -67,9 +67,6 @@ public void emitRecord(
             } else {
                 deserializationSchema.deserialize(consumerRecord.value(), outputCollector);
             }
-            // consumerRecord.offset + 1 is the offset commit to Kafka and also the start offset
-            // for the next run
-            splitState.setCurrentOffset(consumerRecord.offset() + 1);
         } catch (Exception e) {
             if (this.messageFormatErrorHandleWay == MessageFormatErrorHandleWay.SKIP) {
                 logger.warn(
@@ -79,6 +76,9 @@ public void emitRecord(
                 throw e;
             }
         }
+        // consumerRecord.offset + 1 is the offset commit to Kafka and also the start offset
+        // for the next run
+        splitState.setCurrentOffset(consumerRecord.offset() + 1);
     }
 
     private static class OutputCollector<T> implements Collector<T> {

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/config/FileSinkConfig.java
Patch:
@@ -187,6 +187,7 @@ public FileSinkConfig(@NonNull Config config, @NonNull SeaTunnelRowType seaTunne
         this.sinkColumnsIndexInRow =
                 this.sinkColumnList.stream()
                         .map(column -> columnsMap.get(column.toLowerCase()))
+                        .filter(e -> e != null)
                         .collect(Collectors.toList());
 
         if (!CollectionUtils.isEmpty(this.partitionFieldList)) {

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/sink/ElasticsearchSinkWriter.java
Patch:
@@ -70,7 +70,8 @@ public ElasticsearchSinkWriter(
         this.context = context;
         this.maxBatchSize = maxBatchSize;
 
-        IndexInfo indexInfo = new IndexInfo(catalogTable.getTableId().getTableName(), config);
+        IndexInfo indexInfo =
+                new IndexInfo(catalogTable.getTableId().getTableName().toLowerCase(), config);
         esRestClient = EsRestClient.createInstance(config);
         this.seaTunnelRowSerializer =
                 new ElasticsearchRowSerializer(

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/nlpmodel/embedding/EmbeddingMultiCatalogTransform.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.nlpmodel.embadding;
+package org.apache.seatunnel.transform.nlpmodel.embedding;
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/nlpmodel/embedding/EmbeddingTransformConfig.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.nlpmodel.embadding;
+package org.apache.seatunnel.transform.nlpmodel.embedding;
 
 import org.apache.seatunnel.api.configuration.Option;
 import org.apache.seatunnel.api.configuration.Options;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/nlpmodel/embedding/EmbeddingTransformFactory.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.nlpmodel.embadding;
+package org.apache.seatunnel.transform.nlpmodel.embedding;
 
 import org.apache.seatunnel.shade.com.google.common.collect.Lists;
 

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/nlpmodel/embedding/remote/AbstractModel.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.nlpmodel.embadding.remote;
+package org.apache.seatunnel.transform.nlpmodel.embedding.remote;
 
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
 

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/nlpmodel/embedding/remote/Model.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.nlpmodel.embadding.remote;
+package org.apache.seatunnel.transform.nlpmodel.embedding.remote;
 
 import java.io.Closeable;
 import java.io.IOException;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/nlpmodel/embedding/remote/custom/CustomModel.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.nlpmodel.embadding.remote.custom;
+package org.apache.seatunnel.transform.nlpmodel.embedding.remote.custom;
 
 import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.JsonNode;
@@ -24,7 +24,7 @@
 import org.apache.seatunnel.shade.com.google.common.annotations.VisibleForTesting;
 
 import org.apache.seatunnel.transform.nlpmodel.CustomConfigPlaceholder;
-import org.apache.seatunnel.transform.nlpmodel.embadding.remote.AbstractModel;
+import org.apache.seatunnel.transform.nlpmodel.embedding.remote.AbstractModel;
 
 import org.apache.http.client.methods.CloseableHttpResponse;
 import org.apache.http.client.methods.HttpPost;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/nlpmodel/embedding/remote/doubao/DoubaoModel.java
Patch:
@@ -15,15 +15,15 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.nlpmodel.embadding.remote.doubao;
+package org.apache.seatunnel.transform.nlpmodel.embedding.remote.doubao;
 
 import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.JsonNode;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ArrayNode;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ObjectNode;
 import org.apache.seatunnel.shade.com.google.common.annotations.VisibleForTesting;
 
-import org.apache.seatunnel.transform.nlpmodel.embadding.remote.AbstractModel;
+import org.apache.seatunnel.transform.nlpmodel.embedding.remote.AbstractModel;
 
 import org.apache.http.client.config.RequestConfig;
 import org.apache.http.client.methods.CloseableHttpResponse;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/nlpmodel/embedding/remote/openai/OpenAIModel.java
Patch:
@@ -15,15 +15,15 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.nlpmodel.embadding.remote.openai;
+package org.apache.seatunnel.transform.nlpmodel.embedding.remote.openai;
 
 import org.apache.seatunnel.shade.com.fasterxml.jackson.core.JsonProcessingException;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.JsonNode;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ObjectNode;
 import org.apache.seatunnel.shade.com.google.common.annotations.VisibleForTesting;
 
-import org.apache.seatunnel.transform.nlpmodel.embadding.remote.AbstractModel;
+import org.apache.seatunnel.transform.nlpmodel.embedding.remote.AbstractModel;
 
 import org.apache.http.client.config.RequestConfig;
 import org.apache.http.client.methods.CloseableHttpResponse;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/nlpmodel/embedding/remote/qianfan/QianfanModel.java
Patch:
@@ -15,15 +15,15 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.nlpmodel.embadding.remote.qianfan;
+package org.apache.seatunnel.transform.nlpmodel.embedding.remote.qianfan;
 
 import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.JsonNode;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ArrayNode;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ObjectNode;
 import org.apache.seatunnel.shade.com.google.common.annotations.VisibleForTesting;
 
-import org.apache.seatunnel.transform.nlpmodel.embadding.remote.AbstractModel;
+import org.apache.seatunnel.transform.nlpmodel.embedding.remote.AbstractModel;
 
 import org.apache.http.client.config.RequestConfig;
 import org.apache.http.client.methods.CloseableHttpResponse;

File: seatunnel-transforms-v2/src/test/java/org/apache/seatunnel/transform/EmbeddingTransformFactoryTest.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.transform;
 
-import org.apache.seatunnel.transform.nlpmodel.embadding.EmbeddingTransformFactory;
+import org.apache.seatunnel.transform.nlpmodel.embedding.EmbeddingTransformFactory;
 
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;

File: seatunnel-connectors-v2/connector-tdengine/src/main/java/org/apache/seatunnel/connectors/seatunnel/tdengine/typemapper/TDengineTypeMapper.java
Patch:
@@ -58,6 +58,7 @@ public class TDengineTypeMapper {
 
     // -------------------------string----------------------------
     private static final String TDENGINE_CHAR = "CHAR";
+    private static final String TDENGINE_NCHAR = "NCHAR";
     private static final String TDENGINE_VARCHAR = "VARCHAR";
     private static final String TDENGINE_TINYTEXT = "TINYTEXT";
     private static final String TDENGINE_MEDIUMTEXT = "MEDIUMTEXT";
@@ -118,6 +119,7 @@ public static SeaTunnelDataType<?> mapping(String tdengineType) {
                 log.warn("{} will probably cause value overflow.", TDENGINE_DOUBLE_UNSIGNED);
                 return BasicType.DOUBLE_TYPE;
             case TDENGINE_CHAR:
+            case TDENGINE_NCHAR:
             case TDENGINE_TINYTEXT:
             case TDENGINE_MEDIUMTEXT:
             case TDENGINE_TEXT:

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-oracle/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/oracle/utils/OracleConnectionUtils.java
Patch:
@@ -92,7 +92,8 @@ public static List<TableId> listTables(
         Set<TableId> tableIdSet = new HashSet<>();
         String queryTablesSql =
                 "SELECT OWNER ,TABLE_NAME,TABLESPACE_NAME FROM ALL_TABLES \n"
-                        + "WHERE TABLESPACE_NAME IS NOT NULL AND TABLESPACE_NAME NOT IN ('SYSAUX')";
+                        + "WHERE PARTITIONED = 'YES' OR (TABLESPACE_NAME IS NOT NULL AND TABLESPACE_NAME NOT IN ('SYSAUX'))";
+
         try {
             jdbcConnection.query(
                     queryTablesSql,

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/rest/servlet/AllNodeLogServlet.java
Patch:
@@ -66,7 +66,7 @@ protected void doGet(HttpServletRequest req, HttpServletResponse resp)
             FormatType formatType = FormatType.fromString(req.getParameter("format"));
             switch (formatType) {
                 case JSON:
-                    writeJson(resp, logService.allNodeLogFormatHtml(jobId));
+                    writeJson(resp, logService.allNodeLogFormatJson(jobId));
                     return;
                 case HTML:
                 default:

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/ZetaSQLType.java
Patch:
@@ -28,6 +28,7 @@
 import org.apache.seatunnel.api.table.type.SqlType;
 import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.transform.exception.TransformException;
+import org.apache.seatunnel.transform.sql.zeta.functions.ArrayFunction;
 
 import org.apache.commons.collections4.CollectionUtils;
 
@@ -448,6 +449,7 @@ private SeaTunnelDataType<?> getFunctionType(Function function) {
             case ZetaSQLFunction.TRUNCATE:
                 return BasicType.DOUBLE_TYPE;
             case ZetaSQLFunction.ARRAY:
+                return ArrayFunction.castArrayTypeMapping(function, inputRowType);
             case ZetaSQLFunction.SPLIT:
                 return ArrayType.STRING_ARRAY_TYPE;
             case ZetaSQLFunction.NOW:

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/HiveSink.java
Patch:
@@ -219,6 +219,7 @@ private HadoopConf createHadoopConf(ReadonlyConfig readonlyConfig) {
                 .getOptional(HiveOptions.HDFS_SITE_PATH)
                 .ifPresent(hadoopConf::setHdfsSitePath);
         readonlyConfig.getOptional(HiveOptions.REMOTE_USER).ifPresent(hadoopConf::setRemoteUser);
+        readonlyConfig.getOptional(HiveOptions.KRB5_PATH).ifPresent(hadoopConf::setKrb5Path);
         readonlyConfig
                 .getOptional(HiveOptions.KERBEROS_PRINCIPAL)
                 .ifPresent(hadoopConf::setKerberosPrincipal);

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/source/config/HiveSourceConfig.java
Patch:
@@ -182,6 +182,9 @@ private HadoopConf parseHiveHadoopConfig(ReadonlyConfig readonlyConfig, Table ta
         readonlyConfig
                 .getOptional(HdfsSourceConfigOptions.HDFS_SITE_PATH)
                 .ifPresent(hadoopConf::setHdfsSitePath);
+        readonlyConfig
+                .getOptional(HdfsSourceConfigOptions.KRB5_PATH)
+                .ifPresent(hadoopConf::setKrb5Path);
         readonlyConfig
                 .getOptional(HdfsSourceConfigOptions.KERBEROS_PRINCIPAL)
                 .ifPresent(hadoopConf::setKerberosPrincipal);

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-starrocks-e2e/src/test/java/org/apache/seatunnel/e2e/connector/starrocks/StarRocksSchemaChangeIT.java
Patch:
@@ -314,7 +314,7 @@ private void assertSchemaEvolutionForDropColumns(
             Connection sinkConnection) {
 
         // case1 add columns with cdc data at same time
-        shopDatabase.setTemplateName("drop_columns_validate_schema.sql").createAndInitialize();
+        shopDatabase.setTemplateName("drop_columns_validate_schema").createAndInitialize();
         await().atMost(60000, TimeUnit.MILLISECONDS)
                 .untilAsserted(
                         () ->

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/util/SchemaUtils.java
Patch:
@@ -236,7 +236,7 @@ public static boolean columnExists(Connection connection, TablePath tablePath, S
         String selectColumnSQL =
                 String.format(
                         "SELECT %s FROM %s WHERE 1 != 1",
-                        quoteIdentifier(column), tablePath.getTableName());
+                        quoteIdentifier(column), tablePath.getFullName());
         try (Statement statement = connection.createStatement()) {
             return statement.execute(selectColumnSQL);
         } catch (SQLException e) {

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaSinkCommitter.java
Patch:
@@ -48,7 +48,7 @@ public List<KafkaCommitInfo> commit(List<KafkaCommitInfo> commitInfos) {
         for (KafkaCommitInfo commitInfo : commitInfos) {
             String transactionId = commitInfo.getTransactionId();
             if (log.isDebugEnabled()) {
-                log.debug("Committing transaction {}", transactionId);
+                log.debug("Committing transaction {}, commitInfo {}", transactionId, commitInfo);
             }
             KafkaProducer<?, ?> producer = getProducer(commitInfo);
             producer.commitTransaction();
@@ -87,7 +87,8 @@ public void abort(List<KafkaCommitInfo> commitInfos) {
                     new KafkaInternalProducer<>(
                             commitInfo.getKafkaProperties(), commitInfo.getTransactionId());
         }
-        kafkaProducer.resumeTransaction(commitInfo.getProducerId(), commitInfo.getEpoch());
+        kafkaProducer.resumeTransaction(
+                commitInfo.getProducerId(), commitInfo.getEpoch(), commitInfo.isTxnStarted());
         return kafkaProducer;
     }
 }

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/state/KafkaCommitInfo.java
Patch:
@@ -31,4 +31,5 @@ public class KafkaCommitInfo implements Serializable {
     private final Properties kafkaProperties;
     private final long producerId;
     private final short epoch;
+    private final boolean txnStarted;
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -21,6 +21,7 @@
 import org.apache.seatunnel.api.common.metrics.MetricsContext;
 import org.apache.seatunnel.api.table.type.Record;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
+import org.apache.seatunnel.api.tracing.MDCTracer;
 import org.apache.seatunnel.common.utils.function.ConsumerWithException;
 import org.apache.seatunnel.engine.core.checkpoint.InternalCheckpointListener;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
@@ -322,8 +323,7 @@ private <T> Set<T> getFlowInfo(BiConsumer<Action, Set<T>> function) {
     @Override
     public void close() throws IOException {
         super.close();
-        allCycles
-                .parallelStream()
+        MDCTracer.tracing(allCycles.parallelStream())
                 .forEach(
                         flowLifeCycle -> {
                             try {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/executor/FieldNamedPreparedStatement.java
Patch:
@@ -336,7 +336,9 @@ public void setAsciiStream(int parameterIndex, InputStream x) throws SQLExceptio
 
     @Override
     public void setBinaryStream(int parameterIndex, InputStream x) throws SQLException {
-        throw new UnsupportedOperationException();
+        for (int index : indexMapping[parameterIndex - 1]) {
+            statement.setBinaryStream(index, x);
+        }
     }
 
     @Override

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/JobClientJobProxyIT.java
Patch:
@@ -77,6 +77,7 @@ public void testMultiTableSinkFailedWithThrowable() throws IOException, Interrup
         Container.ExecResult execResult =
                 executeJob(server, "/stream_fake_to_inmemory_with_throwable_error.conf");
         Assertions.assertNotEquals(0, execResult.getExitCode());
+        Assertions.assertTrue(execResult.getStderr().contains("table fake sink throw error"));
     }
 
     @Test

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobHistoryService.java
Patch:
@@ -183,7 +183,7 @@ public JobState getJobDetailState(Long jobId) {
     }
 
     public JobMetrics getJobMetrics(Long jobId) {
-        return finishedJobMetricsImap.getOrDefault(jobId, null);
+        return finishedJobMetricsImap.getOrDefault(jobId, JobMetrics.empty());
     }
 
     public JobDAGInfo getJobDAGInfo(Long jobId) {

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/converter/BasicTypeDefine.java
Patch:
@@ -31,6 +31,8 @@ public class BasicTypeDefine<T> implements Serializable {
     protected String columnType;
     // e.g. `varchar` for MySQL
     protected String dataType;
+    // It's jdbc sql type(java.sql.Types) not SeaTunnel SqlType
+    protected int sqlType;
     protected T nativeType;
     // e.g. `varchar` length is 10
     protected Long length;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/DatabaseIdentifier.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect;
 
 public class DatabaseIdentifier {
+    public static final String GENERIC = "Generic";
     public static final String DB_2 = "DB2";
     public static final String DAMENG = "Dameng";
     public static final String GBASE_8A = "Gbase8a";

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/JdbcDialectTypeMapper.java
Patch:
@@ -68,6 +68,7 @@ default SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex)
                         .name(columnName)
                         .columnType(nativeType)
                         .dataType(nativeType)
+                        .sqlType(metadata.getColumnType(colIndex))
                         .nullable(isNullable == ResultSetMetaData.columnNullable)
                         .length((long) precision)
                         .precision((long) precision)
@@ -93,6 +94,7 @@ default List<Column> mappingColumn(
             while (rs.next()) {
                 String columnName = rs.getString("COLUMN_NAME");
                 String nativeType = rs.getString("TYPE_NAME");
+                int sqlType = rs.getInt("DATA_TYPE");
                 int columnSize = rs.getInt("COLUMN_SIZE");
                 int decimalDigits = rs.getInt("DECIMAL_DIGITS");
                 int nullable = rs.getInt("NULLABLE");
@@ -102,6 +104,7 @@ default List<Column> mappingColumn(
                                 .name(columnName)
                                 .columnType(nativeType)
                                 .dataType(nativeType)
+                                .sqlType(sqlType)
                                 .length((long) columnSize)
                                 .precision((long) columnSize)
                                 .scale(decimalDigits)

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/catalog/CatalogTableUtil.java
Patch:
@@ -255,7 +255,7 @@ public static CatalogTable newCatalogTable(
                 finalColumns.add(column);
             } else {
                 finalColumns.add(
-                        PhysicalColumn.of(fieldNames[i], fieldTypes[i], 0, false, null, null));
+                        PhysicalColumn.of(fieldNames[i], fieldTypes[i], 0, true, null, null));
             }
         }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-5/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcGBase8aIT.java
Patch:
@@ -23,7 +23,6 @@
 
 import org.apache.commons.lang3.tuple.Pair;
 
-import org.junit.jupiter.api.Disabled;
 import org.testcontainers.containers.GenericContainer;
 import org.testcontainers.containers.output.Slf4jLogConsumer;
 import org.testcontainers.utility.DockerLoggerFactory;
@@ -40,7 +39,6 @@
 import java.util.List;
 import java.util.Map;
 
-@Disabled("due to the driver cannot be downloaded")
 public class JdbcGBase8aIT extends AbstractJdbcIT {
 
     private static final String GBASE_IMAGE = "shihd/gbase8a:1.0";
@@ -113,7 +111,7 @@ JdbcCase getJdbcCase() {
 
     @Override
     String driverUrl() {
-        return "https://cdn.gbase.cn/products/30/p5CiVwXBKQYIUGN8ecHvk/gbase-connector-java-9.5.0.7-build1-bin.jar";
+        return "https://linux.hadoop.wiki/lib/gbase-connector-java-9.5.0.7-build1-bin.jar";
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/telemetry/log/TaskLogManagerService.java
Patch:
@@ -37,7 +37,7 @@ public void initClean() {
         try {
             path = LogUtil.getLogPath();
         } catch (Exception e) {
-            log.warn(
+            log.debug(
                     "The corresponding log file path is not properly configured, please check the log configuration file.",
                     e);
         }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/catalog/schema/TableSchemaOptions.java
Patch:
@@ -92,10 +92,10 @@ public static class ColumnOptions {
                         .noDefaultValue()
                         .withDescription("SeaTunnel Schema Column scale");
 
-        public static final Option<Integer> COLUMN_LENGTH =
+        public static final Option<Long> COLUMN_LENGTH =
                 Options.key("columnLength")
-                        .intType()
-                        .defaultValue(0)
+                        .longType()
+                        .defaultValue(0L)
                         .withDescription("SeaTunnel Schema Column Length");
 
         public static final Option<Boolean> NULLABLE =

File: seatunnel-api/src/test/java/org/apache/seatunnel/api/table/catalog/schema/ReadonlyConfigParserTest.java
Patch:
@@ -77,7 +77,7 @@ private void assertConstraintKey(TableSchema tableSchema) {
                 constraintKey.getColumnNames().get(0).getSortType());
     }
 
-    private void assertColumn(TableSchema tableSchema, boolean checkDefaultValue) {
+    private void assertColumn(TableSchema tableSchema, boolean comeFromColumnConfig) {
         List<Column> columns = tableSchema.getColumns();
         Assertions.assertEquals(19, columns.size());
 
@@ -109,12 +109,13 @@ private void assertColumn(TableSchema tableSchema, boolean checkDefaultValue) {
         SeaTunnelRowType seatunnalRowType1 = (SeaTunnelRowType) seaTunnelRowType.getFieldType(17);
         Assertions.assertEquals(17, seatunnalRowType1.getTotalFields());
 
-        if (checkDefaultValue) {
+        if (comeFromColumnConfig) {
             Assertions.assertEquals(0, columns.get(0).getDefaultValue());
             Assertions.assertEquals("I'm default value", columns.get(4).getDefaultValue());
             Assertions.assertEquals(false, columns.get(5).getDefaultValue());
             Assertions.assertEquals(1.1, columns.get(10).getDefaultValue());
             Assertions.assertEquals("2020-01-01", columns.get(15).getDefaultValue());
+            Assertions.assertEquals(4294967295L, columns.get(4).getColumnLength());
         }
     }
 }

File: seatunnel-connectors-v2/connector-assert/src/main/java/org/apache/seatunnel/connectors/seatunnel/assertion/rule/AssertCatalogTableRuleParser.java
Patch:
@@ -87,7 +87,7 @@ private Optional<AssertCatalogTableRule.AssertColumnRule> parseColumnRule(
                                 config -> {
                                     String name = config.getString(COLUMN_NAME);
                                     String type = config.getString(COLUMN_TYPE);
-                                    Integer columnLength =
+                                    Long columnLength =
                                             TypesafeConfigUtils.getConfig(
                                                     config,
                                                     COLUMN_LENGTH,

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/JobStatusRunner.java
Patch:
@@ -41,8 +41,9 @@ public void run() {
             while (isPrint(jobClient.getJobStatus(jobId))) {
                 Thread.sleep(5000);
             }
+        } catch (InterruptedException ignore) {
         } catch (Exception e) {
-            log.error("Failed to get job runner status. {}", ExceptionUtils.getMessage(e));
+            log.info("Failed to get job runner status. {}", ExceptionUtils.getMessage(e));
         }
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -673,7 +673,7 @@ private synchronized void stateProcess() {
             case CANCELED:
                 if (checkNeedRestore(state) && prepareRestorePipeline()) {
                     jobMaster.releasePipelineResource(this);
-                    jobMaster.preApplyResources();
+                    jobMaster.preApplyResources(this);
                     restorePipeline();
                     return;
                 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/BinaryReadStrategy.java
Patch:
@@ -55,7 +55,7 @@ public void read(String path, String tableId, Collector<SeaTunnelRow> output)
             throws IOException, FileConnectorException {
         try (InputStream inputStream = hadoopFileSystemProxy.getInputStream(path)) {
             String relativePath;
-            if (basePath.isFile()) {
+            if (hadoopFileSystemProxy.isFile(basePath.getAbsolutePath())) {
                 relativePath = basePath.getName();
             } else {
                 relativePath =

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/debezium/row/SeaTunnelRowDebeziumDeserializationConverters.java
Patch:
@@ -85,7 +85,7 @@ public SeaTunnelRow convert(SourceRecord record, Struct struct, Schema schema)
             if (field == null) {
                 row.setField(i, null);
             } else {
-                Object fieldValue = struct.get(fieldName);
+                Object fieldValue = struct.getWithoutDefault(fieldName);
                 Schema fieldSchema = field.schema();
                 Object convertedField =
                         SeaTunnelRowDebeziumDeserializationConverters.convertField(
@@ -494,11 +494,11 @@ public Object convert(Object dbzObj, Schema schema) throws Exception {
                 SeaTunnelRow row = new SeaTunnelRow(arity);
                 for (int i = 0; i < arity; i++) {
                     String fieldName = fieldNames[i];
-                    Object fieldValue = struct.get(fieldName);
                     Field field = schema.field(fieldName);
                     if (field == null) {
                         row.setField(i, null);
                     } else {
+                        Object fieldValue = struct.getWithoutDefault(fieldName);
                         Schema fieldSchema = field.schema();
                         Object convertedField =
                                 SeaTunnelRowDebeziumDeserializationConverters.convertField(

File: seatunnel-connectors-v2/connector-prometheus/src/main/java/org/apache/seatunnel/connectors/seatunnel/prometheus/sink/PrometheusSinkFactory.java
Patch:
@@ -39,7 +39,7 @@ public TableSink createSink(TableSinkFactoryContext context) {
 
         ReadonlyConfig readonlyConfig = context.getOptions();
         CatalogTable catalogTable = context.getCatalogTable();
-        return () -> new PrometheusSink(readonlyConfig, catalogTable.getSeaTunnelRowType());
+        return () -> new PrometheusSink(readonlyConfig, catalogTable);
     }
 
     @Override

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/utils/JdbcCatalogUtils.java
Patch:
@@ -232,10 +232,12 @@ static CatalogTable mergeCatalogTable(CatalogTable tableOfPath, CatalogTable tab
                                                 && columnsOfPath
                                                         .get(column.getName())
                                                         .getDataType()
+                                                        .getSqlType()
                                                         .equals(
                                                                 columnsOfQuery
                                                                         .get(column.getName())
-                                                                        .getDataType()))
+                                                                        .getDataType()
+                                                                        .getSqlType()))
                         .map(column -> columnsOfPath.get(column.getName()))
                         .collect(Collectors.toList());
         boolean schemaIncludeAllColumns = columnsOfMerge.size() == columnKeysOfQuery.size();

File: seatunnel-connectors-v2/connector-jdbc/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/saphana/SapHanaTypeConverterTest.java
Patch:
@@ -126,7 +126,7 @@ public void testConvertSmallDecimal() {
                         .build();
         Column column = SapHanaTypeConverter.INSTANCE.convert(typeDefine);
         Assertions.assertEquals(typeDefine.getName(), column.getName());
-        Assertions.assertEquals(new DecimalType(38, 368), column.getDataType());
+        Assertions.assertEquals(new DecimalType(38, 0), column.getDataType());
         Assertions.assertEquals(typeDefine.getColumnType(), column.getSourceType());
 
         typeDefine =
@@ -139,7 +139,7 @@ public void testConvertSmallDecimal() {
                         .build();
         column = SapHanaTypeConverter.INSTANCE.convert(typeDefine);
         Assertions.assertEquals(typeDefine.getName(), column.getName());
-        Assertions.assertEquals(new DecimalType(10, 368), column.getDataType());
+        Assertions.assertEquals(new DecimalType(10, 5), column.getDataType());
         Assertions.assertEquals(typeDefine.getColumnType(), column.getSourceType());
     }
 
@@ -153,7 +153,7 @@ public void testConvertDecimal() {
                         .build();
         Column column = SapHanaTypeConverter.INSTANCE.convert(typeDefine);
         Assertions.assertEquals(typeDefine.getName(), column.getName());
-        Assertions.assertEquals(new DecimalType(34, 6176), column.getDataType());
+        Assertions.assertEquals(new DecimalType(34, 0), column.getDataType());
         Assertions.assertEquals(typeDefine.getColumnType(), column.getSourceType());
 
         BasicTypeDefine<Object> typeDefine2 =

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/source/ClickhouseSourceSplitEnumerator.java
Patch:
@@ -78,6 +78,7 @@ public void registerReader(int subtaskId) {
             assigned = subtaskId;
             context.assignSplit(subtaskId, new ClickhouseSourceSplit());
         }
+        context.signalNoMoreSplits(subtaskId);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/server/ServerConfigOptions.java
Patch:
@@ -207,7 +207,7 @@ public class ServerConfigOptions {
     public static final Option<Boolean> CLASSLOADER_CACHE_MODE =
             Options.key("classloader-cache-mode")
                     .booleanType()
-                    .defaultValue(false)
+                    .defaultValue(true)
                     .withDescription(
                             "Whether to use classloader cache mode. With cache mode, all jobs share the same classloader if the jars are the same");
 

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -98,7 +98,7 @@ public List<DataStreamTableInfo> execute(List<DataStreamTableInfo> upstreamDataS
             throws TaskExecuteException {
         SeaTunnelSinkPluginDiscovery sinkPluginDiscovery =
                 new SeaTunnelSinkPluginDiscovery(ADD_URL_TO_CLASSLOADER);
-        DataStreamTableInfo input = upstreamDataStreams.get(0);
+        DataStreamTableInfo input = upstreamDataStreams.get(upstreamDataStreams.size() - 1);
         ClassLoader classLoader = Thread.currentThread().getContextClassLoader();
         for (int i = 0; i < plugins.size(); i++) {
             Config sinkConfig = pluginConfigs.get(i);

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-starter-common/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -99,7 +99,7 @@ public List<DataStreamTableInfo> execute(List<DataStreamTableInfo> upstreamDataS
             throws TaskExecuteException {
         SeaTunnelSinkPluginDiscovery sinkPluginDiscovery =
                 new SeaTunnelSinkPluginDiscovery(ADD_URL_TO_CLASSLOADER);
-        DataStreamTableInfo input = upstreamDataStreams.get(0);
+        DataStreamTableInfo input = upstreamDataStreams.get(upstreamDataStreams.size() - 1);
         ClassLoader classLoader = Thread.currentThread().getContextClassLoader();
         for (int i = 0; i < plugins.size(); i++) {
             Config sinkConfig = pluginConfigs.get(i);

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-2-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -89,7 +89,7 @@ public List<DatasetTableInfo> execute(List<DatasetTableInfo> upstreamDataStreams
             throws TaskExecuteException {
         SeaTunnelSinkPluginDiscovery sinkPluginDiscovery = new SeaTunnelSinkPluginDiscovery();
         ClassLoader classLoader = Thread.currentThread().getContextClassLoader();
-        DatasetTableInfo input = upstreamDataStreams.get(0);
+        DatasetTableInfo input = upstreamDataStreams.get(upstreamDataStreams.size() - 1);
         for (int i = 0; i < plugins.size(); i++) {
             Config sinkConfig = pluginConfigs.get(i);
             DatasetTableInfo datasetTableInfo =

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-starter-common/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -90,7 +90,7 @@ public List<DatasetTableInfo> execute(List<DatasetTableInfo> upstreamDataStreams
             throws TaskExecuteException {
         SeaTunnelSinkPluginDiscovery sinkPluginDiscovery = new SeaTunnelSinkPluginDiscovery();
         ClassLoader classLoader = Thread.currentThread().getContextClassLoader();
-        DatasetTableInfo input = upstreamDataStreams.get(0);
+        DatasetTableInfo input = upstreamDataStreams.get(upstreamDataStreams.size() - 1);
         for (int i = 0; i < plugins.size(); i++) {
             Config sinkConfig = pluginConfigs.get(i);
             DatasetTableInfo datasetTableInfo =

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/saphana/SapHanaTypeConverter.java
Patch:
@@ -297,6 +297,7 @@ public Column convert(BasicTypeDefine typeDefine) {
                 break;
             case HANA_ST_POINT:
             case HANA_ST_GEOMETRY:
+                builder.columnLength(typeDefine.getLength());
                 builder.dataType(PrimitiveByteArrayType.INSTANCE);
                 break;
             default:

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/utils/ConfigBuilder.java
Patch:
@@ -38,7 +38,7 @@
 import java.nio.file.Paths;
 import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.HashMap;
+import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.Objects;
@@ -123,7 +123,7 @@ public static Config of(
     public static Map<String, Object> configDesensitization(Map<String, Object> configMap) {
         return configMap.entrySet().stream()
                 .collect(
-                        HashMap::new,
+                        LinkedHashMap::new,
                         (m, p) -> {
                             String key = p.getKey();
                             Object value = p.getValue();
@@ -154,7 +154,7 @@ public static Map<String, Object> configDesensitization(Map<String, Object> conf
                                 }
                             }
                         },
-                        HashMap::putAll);
+                        LinkedHashMap::putAll);
     }
 
     public static Config of(

File: seatunnel-connectors-v2/connector-file/connector-file-ftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/ftp/config/FtpConfigOptions.java
Patch:
@@ -22,7 +22,7 @@
 import org.apache.seatunnel.connectors.seatunnel.file.config.BaseSourceConfigOptions;
 import org.apache.seatunnel.connectors.seatunnel.file.ftp.system.FtpConnectionMode;
 
-import static org.apache.seatunnel.connectors.seatunnel.file.ftp.system.FtpConnectionMode.ACTIVE_LOCAL_DATA_CONNECTION_MODE;
+import static org.apache.seatunnel.connectors.seatunnel.file.ftp.system.FtpConnectionMode.ACTIVE_LOCAL;
 
 public class FtpConfigOptions extends BaseSourceConfigOptions {
     public static final Option<String> FTP_PASSWORD =
@@ -42,6 +42,6 @@ public class FtpConfigOptions extends BaseSourceConfigOptions {
     public static final Option<FtpConnectionMode> FTP_CONNECTION_MODE =
             Options.key("connection_mode")
                     .enumType(FtpConnectionMode.class)
-                    .defaultValue(ACTIVE_LOCAL_DATA_CONNECTION_MODE)
+                    .defaultValue(ACTIVE_LOCAL)
                     .withDescription("FTP server connection mode ");
 }

File: seatunnel-connectors-v2/connector-file/connector-file-ftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/ftp/system/FtpConnectionMode.java
Patch:
@@ -21,10 +21,10 @@
 public enum FtpConnectionMode {
 
     /** ACTIVE_LOCAL_DATA_CONNECTION_MODE */
-    ACTIVE_LOCAL_DATA_CONNECTION_MODE("active_local"),
+    ACTIVE_LOCAL("active_local"),
 
     /** PASSIVE_LOCAL_DATA_CONNECTION_MODE */
-    PASSIVE_LOCAL_DATA_CONNECTION_MODE("passive_local");
+    PASSIVE_LOCAL("passive_local");
 
     private final String mode;
 
@@ -38,7 +38,7 @@ public String getMode() {
 
     public static FtpConnectionMode fromMode(String mode) {
         for (FtpConnectionMode ftpConnectionModeEnum : FtpConnectionMode.values()) {
-            if (ftpConnectionModeEnum.getMode().equals(mode)) {
+            if (ftpConnectionModeEnum.getMode().equals(mode.toLowerCase())) {
                 return ftpConnectionModeEnum;
             }
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/psql/PostgresTypeConverter.java
Patch:
@@ -81,6 +81,7 @@ public class PostgresTypeConverter implements TypeConverter<BasicTypeDefine> {
     public static final String PG_CHAR_ARRAY = "_bpchar";
     // character varying <=> varchar
     public static final String PG_VARCHAR = "varchar";
+    public static final String PG_INET = "inet";
     public static final String PG_CHARACTER_VARYING = "character varying";
     // character varying[] <=> varchar[] <=> _varchar
     public static final String PG_VARCHAR_ARRAY = "_varchar";
@@ -221,7 +222,9 @@ public Column convert(BasicTypeDefine typeDefine) {
             case PG_XML:
             case PG_GEOMETRY:
             case PG_GEOGRAPHY:
+            case PG_INET:
                 builder.dataType(BasicType.STRING_TYPE);
+                builder.sourceType(pgDataType);
                 break;
             case PG_CHAR_ARRAY:
             case PG_VARCHAR_ARRAY:

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cdc-postgres-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/cdc/postgres/PostgresCDCIT.java
Patch:
@@ -662,7 +662,7 @@ private void upsertDeleteSourceTable(String database, String tableName) {
                         + tableName
                         + " VALUES (2, '2', 32767, 65535, 2147483647, 5.5, 6.6, 123.12345, 404.4443, true,\n"
                         + "        'Hello World', 'a', 'abc', 'abcd..xyz', '2020-07-17 18:00:22.123', '2020-07-17 18:00:22.123456',\n"
-                        + "        '2020-07-17', '18:00:22', 500);");
+                        + "        '2020-07-17', '18:00:22', 500,'192.168.1.1');");
 
         executeSql(
                 "INSERT INTO "
@@ -671,7 +671,7 @@ private void upsertDeleteSourceTable(String database, String tableName) {
                         + tableName
                         + " VALUES (3, '2', 32767, 65535, 2147483647, 5.5, 6.6, 123.12345, 404.4443, true,\n"
                         + "        'Hello World', 'a', 'abc', 'abcd..xyz', '2020-07-17 18:00:22.123', '2020-07-17 18:00:22.123456',\n"
-                        + "        '2020-07-17', '18:00:22', 500);");
+                        + "        '2020-07-17', '18:00:22', 500,'192.168.1.1');");
 
         executeSql("DELETE FROM " + database + "." + tableName + " where id = 2;");
 

File: seatunnel-connectors-v2/connector-paimon/src/main/java/org/apache/seatunnel/connectors/seatunnel/paimon/sink/PaimonSinkWriter.java
Patch:
@@ -193,7 +193,7 @@ public Optional<PaimonCommitInfo> prepareCommit(long checkpointId) throws IOExce
         } catch (Exception e) {
             throw new PaimonConnectorException(
                     PaimonConnectorErrorCode.TABLE_PRE_COMMIT_FAILED,
-                    "Flink table store failed to prepare commit",
+                    "Paimon pre-commit failed.",
                     e);
         }
     }

File: seatunnel-connectors-v2/connector-paimon/src/main/java/org/apache/seatunnel/connectors/seatunnel/paimon/sink/commit/PaimonAggregatedCommitter.java
Patch:
@@ -103,7 +103,7 @@ public List<PaimonAggregatedCommitInfo> commit(
         } catch (Exception e) {
             throw new PaimonConnectorException(
                     PaimonConnectorErrorCode.TABLE_WRITE_COMMIT_FAILED,
-                    "Flink table store commit operation failed",
+                    "Paimon table storage write-commit Failed.",
                     e);
         }
         return Collections.emptyList();

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaRecordEmitter.java
Patch:
@@ -31,7 +31,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.io.IOException;
 import java.util.Map;
 
 public class KafkaRecordEmitter
@@ -71,13 +70,14 @@ public void emitRecord(
             // consumerRecord.offset + 1 is the offset commit to Kafka and also the start offset
             // for the next run
             splitState.setCurrentOffset(consumerRecord.offset() + 1);
-        } catch (IOException e) {
+        } catch (Exception e) {
             if (this.messageFormatErrorHandleWay == MessageFormatErrorHandleWay.SKIP) {
                 logger.warn(
                         "Deserialize message failed, skip this message, message: {}",
                         new String(consumerRecord.value()));
+            } else {
+                throw e;
             }
-            throw e;
         }
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-kafka-e2e/src/test/java/org/apache/seatunnel/e2e/connector/kafka/KafkaIT.java
Patch:
@@ -291,7 +291,7 @@ public void testSourceKafkaJsonFormatErrorHandleWaySkipToConsole(TestContainer c
                         DEFAULT_FORMAT,
                         DEFAULT_FIELD_DELIMITER,
                         null);
-        generateTestData(row -> serializer.serializeRow(row), 0, 100);
+        generateTestData(serializer::serializeRow, 0, 100);
         Container.ExecResult execResult =
                 container.executeJob(
                         "/kafka/kafkasource_format_error_handle_way_skip_to_console.conf");
@@ -308,11 +308,11 @@ public void testSourceKafkaJsonFormatErrorHandleWayFailToConsole(TestContainer c
                         DEFAULT_FORMAT,
                         DEFAULT_FIELD_DELIMITER,
                         null);
-        generateTestData(row -> serializer.serializeRow(row), 0, 100);
+        generateTestData(serializer::serializeRow, 0, 100);
         Container.ExecResult execResult =
                 container.executeJob(
                         "/kafka/kafkasource_format_error_handle_way_fail_to_console.conf");
-        Assertions.assertEquals(0, execResult.getExitCode(), execResult.getStderr());
+        Assertions.assertEquals(1, execResult.getExitCode(), execResult.getStderr());
     }
 
     @TestTemplate

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/source/reader/batch/ParallelBatchPartitionReader.java
Patch:
@@ -84,7 +84,7 @@ protected String getEnumeratorThreadName() {
         return String.format("parallel-split-enumerator-executor-%s", subtaskId);
     }
 
-    public boolean next() throws IOException {
+    public boolean next() throws Exception {
         prepare();
         while (running && handover.isEmpty()) {
             try {

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-3.3/src/main/java/org/apache/seatunnel/translation/spark/source/partition/batch/ParallelBatchPartitionReader.java
Patch:
@@ -84,7 +84,7 @@ protected String getEnumeratorThreadName() {
         return String.format("parallel-split-enumerator-executor-%s", subtaskId);
     }
 
-    public boolean next() throws IOException {
+    public boolean next() throws Exception {
         prepare();
         while (running && handover.isEmpty()) {
             try {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-2/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcOceanBaseITBase.java
Patch:
@@ -87,6 +87,6 @@ void checkResult(String executeKey, TestContainer container, Container.ExecResul
 
     @Override
     String driverUrl() {
-        return "https://repo1.maven.org/maven2/com/oceanbase/oceanbase-client/2.4.11/oceanbase-client-2.4.11.jar";
+        return "https://repo1.maven.org/maven2/com/oceanbase/oceanbase-client/2.4.12/oceanbase-client-2.4.12.jar";
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseFileSourceConfig.java
Patch:
@@ -95,7 +95,7 @@ private CatalogTable parseCatalogTable(ReadonlyConfig readonlyConfig) {
             case JSON:
             case EXCEL:
             case XML:
-                readStrategy.setSeaTunnelRowTypeInfo(catalogTable.getSeaTunnelRowType());
+                readStrategy.setCatalogTable(catalogTable);
                 return newCatalogTable(catalogTable, readStrategy.getActualSeaTunnelRowTypeInfo());
             case ORC:
             case PARQUET:

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/BaseMultipleTableFileSink.java
Patch:
@@ -112,7 +112,7 @@ public Optional<Serializer<FileSinkState>> getWriterStateSerializer() {
     protected WriteStrategy createWriteStrategy() {
         WriteStrategy writeStrategy =
                 WriteStrategyFactory.of(fileSinkConfig.getFileFormat(), fileSinkConfig);
-        writeStrategy.setSeaTunnelRowTypeInfo(catalogTable.getSeaTunnelRowType());
+        writeStrategy.setCatalogTable(catalogTable);
         return writeStrategy;
     }
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/JsonReadStrategy.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.serialization.DeserializationSchema;
 import org.apache.seatunnel.api.source.Collector;
+import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
@@ -62,8 +63,8 @@ public void init(HadoopConf conf) {
     }
 
     @Override
-    public void setSeaTunnelRowTypeInfo(SeaTunnelRowType seaTunnelRowType) {
-        super.setSeaTunnelRowTypeInfo(seaTunnelRowType);
+    public void setCatalogTable(CatalogTable catalogTable) {
+        super.setCatalogTable(catalogTable);
         if (isMergePartition) {
             deserializationSchema =
                     new JsonDeserializationSchema(false, false, this.seaTunnelRowTypeWithPartition);

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/ReadStrategy.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
 import org.apache.seatunnel.api.source.Collector;
+import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
@@ -56,8 +57,7 @@ default SeaTunnelRowType getSeaTunnelRowTypeInfoWithUserConfigRowType(
         return getSeaTunnelRowTypeInfo(path);
     }
 
-    // todo: use CatalogTable
-    void setSeaTunnelRowTypeInfo(SeaTunnelRowType seaTunnelRowType);
+    void setCatalogTable(CatalogTable catalogTable);
 
     List<String> getFileNamesByPath(String path) throws IOException;
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/test/java/org/apache/seatunnel/connectors/seatunnel/file/writer/ParquetWriteStrategyTest.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;
 
 import org.apache.seatunnel.api.source.Collector;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.LocalTimeType;
 import org.apache.seatunnel.api.table.type.PrimitiveByteArrayType;
@@ -82,7 +83,8 @@ public void testParquetWriteInt96() throws Exception {
         ParquetWriteStrategy writeStrategy = new ParquetWriteStrategy(writeSinkConfig);
         ParquetReadStrategyTest.LocalConf hadoopConf =
                 new ParquetReadStrategyTest.LocalConf(FS_DEFAULT_NAME_DEFAULT);
-        writeStrategy.setSeaTunnelRowTypeInfo(writeRowType);
+        writeStrategy.setCatalogTable(
+                CatalogTableUtil.getCatalogTable("test", null, null, "test", writeRowType));
         writeStrategy.init(hadoopConf, "test1", "test1", 0);
         writeStrategy.beginTransaction(1L);
         writeStrategy.write(

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/HiveSink.java
Patch:
@@ -240,7 +240,7 @@ private Table getTableInformation() {
     private WriteStrategy getWriteStrategy() {
         if (writeStrategy == null) {
             writeStrategy = WriteStrategyFactory.of(fileSinkConfig.getFileFormat(), fileSinkConfig);
-            writeStrategy.setSeaTunnelRowTypeInfo(catalogTable.getSeaTunnelRowType());
+            writeStrategy.setCatalogTable(catalogTable);
         }
         return writeStrategy;
     }

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/source/config/HiveSourceConfig.java
Patch:
@@ -279,7 +279,9 @@ private CatalogTable parseCatalogTableFromTable(
         }
 
         SeaTunnelRowType seaTunnelRowType = new SeaTunnelRowType(fieldNames, fieldTypes);
-        readStrategy.setSeaTunnelRowTypeInfo(seaTunnelRowType);
+        readStrategy.setCatalogTable(
+                CatalogTableUtil.getCatalogTable(
+                        "hive", table.getDbName(), null, table.getTableName(), seaTunnelRowType));
         final SeaTunnelRowType finalSeatunnelRowType = readStrategy.getActualSeaTunnelRowTypeInfo();
 
         CatalogTable catalogTable = buildEmptyCatalogTable(readonlyConfig, table);

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/source/AbstractSingleSplitReader.java
Patch:
@@ -26,13 +26,11 @@
 
 public abstract class AbstractSingleSplitReader<T> implements SourceReader<T, SingleSplit> {
 
-    protected final Object lock = new Object();
-
     protected volatile boolean noMoreSplits = false;
 
     @Override
     public void pollNext(Collector<T> output) throws Exception {
-        synchronized (lock) {
+        synchronized (output.getCheckpointLock()) {
             if (noMoreSplits) {
                 return;
             }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/metrics/TaskMetricsCalcContext.java
Patch:
@@ -122,14 +122,13 @@ private void initializeMetrics(
         }
     }
 
-    public void updateMetrics(Object data) {
+    public void updateMetrics(Object data, String tableId) {
         count.inc();
         QPS.markEvent();
         if (data instanceof SeaTunnelRow) {
             SeaTunnelRow row = (SeaTunnelRow) data;
             bytes.inc(row.getBytesSize());
             bytesPerSeconds.markEvent(row.getBytesSize());
-            String tableId = row.getTableId();
 
             if (StringUtils.isNotBlank(tableId)) {
                 String tableName = TablePath.of(tableId).getFullName();

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelSourceCollector.java
Patch:
@@ -107,7 +107,7 @@ public void collect(T row) {
                             "Unsupported row type: " + rowType.getClass().getName());
                 }
                 flowControlGate.audit((SeaTunnelRow) row);
-                taskMetricsCalcContext.updateMetrics(row);
+                taskMetricsCalcContext.updateMetrics(row, tableId);
             }
             sendRecordToNext(new Record<>(row));
             emptyThisPollNext = false;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-postgres/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/postgres/source/PostgresSourceOptions.java
Patch:
@@ -38,7 +38,7 @@ public class PostgresSourceOptions {
                             .defaultValue(StartupMode.INITIAL)
                             .withDescription(
                                     "Optional startup mode for CDC source, valid enumerations are "
-                                            + "\"initial\", \"earliest\", \"latest\", \"timestamp\"\n or \"specific\"");
+                                            + "\"initial\", \"earliest\", \"latest\"");
 
     public static final SingleChoiceOption<StopMode> STOP_MODE =
             (SingleChoiceOption)
@@ -47,5 +47,5 @@ public class PostgresSourceOptions {
                             .defaultValue(StopMode.NEVER)
                             .withDescription(
                                     "Optional stop mode for CDC source, valid enumerations are "
-                                            + "\"never\", \"latest\", \"timestamp\"\n or \"specific\"");
+                                            + "\"never\"");
 }

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterSeaTunnelContainer.java
Patch:
@@ -107,7 +107,7 @@ public void startUp() throws Exception {
         tasks.add(
                 new Tuple3<>(
                         server.getMappedPort(5801), RestConstant.CONTEXT_PATH, CUSTOM_JOB_ID_1));
-        tasks.add(new Tuple3<>(server.getMappedPort(8080), "/seatunnel", CUSTOM_JOB_ID_2));
+        tasks.add(new Tuple3<>(server.getMappedPort(8080), "", CUSTOM_JOB_ID_2));
     }
 
     @Override

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerCatalog.java
Patch:
@@ -40,7 +40,7 @@
 @Slf4j
 public class SqlServerCatalog extends AbstractJdbcCatalog {
 
-    private static final String SELECT_COLUMNS_SQL_TEMPLATE =
+    public static final String SELECT_COLUMNS_SQL_TEMPLATE =
             "SELECT tbl.name AS table_name,\n"
                     + "       col.name AS column_name,\n"
                     + "       ext.value AS comment,\n"
@@ -53,7 +53,7 @@ public class SqlServerCatalog extends AbstractJdbcCatalog {
                     + "       def.definition AS default_value\n"
                     + "FROM sys.tables tbl\n"
                     + "    INNER JOIN sys.columns col ON tbl.object_id = col.object_id\n"
-                    + "    LEFT JOIN sys.types types ON col.user_type_id = types.user_type_id\n"
+                    + "    LEFT JOIN sys.types types ON col.system_type_id = types.user_type_id\n"
                     + "    LEFT JOIN sys.extended_properties ext ON ext.major_id = col.object_id AND ext.minor_id = col.column_id\n"
                     + "    LEFT JOIN sys.default_constraints def ON col.default_object_id = def.object_id AND ext.minor_id = col.column_id AND ext.name = 'MS_Description'\n"
                     + "WHERE schema_name(tbl.schema_id) = '%s' %s\n"

File: seatunnel-connectors-v2/connector-paimon/src/main/java/org/apache/seatunnel/connectors/seatunnel/paimon/exception/PaimonConnectorErrorCode.java
Patch:
@@ -27,7 +27,9 @@ public enum PaimonConnectorErrorCode implements SeaTunnelErrorCode {
     GET_TABLE_FAILED("PAIMON-04", "Get table from database failed"),
     AUTHENTICATE_KERBEROS_FAILED("PAIMON-05", "Authenticate kerberos failed"),
     LOAD_CATALOG("PAIMON-06", "Load catalog failed"),
-    GET_FILED_FAILED("PAIMON-07", "Get field failed");
+    GET_FILED_FAILED("PAIMON-07", "Get field failed"),
+    UNSUPPORTED_PRIMARY_DATATYPE("PAIMON-08", "Paimon primary key datatype is unsupported"),
+    WRITE_PROPS_BUCKET_KEY_ERROR("PAIMON-09", "Cannot define 'bucket-key' in dynamic bucket mode");
 
     private final String code;
     private final String description;

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/IcebergCatalogLoader.java
Patch:
@@ -33,7 +33,6 @@
 import org.apache.iceberg.common.DynMethods;
 
 import lombok.extern.slf4j.Slf4j;
-import sun.security.krb5.KrbException;
 
 import java.io.IOException;
 import java.io.Serializable;
@@ -170,11 +169,10 @@ public static void doKerberosAuthentication(
                         "Start Kerberos authentication using principal {} and keytab {}",
                         principal,
                         keytabPath);
-                sun.security.krb5.Config.refresh();
                 UserGroupInformation.loginUserFromKeytab(principal, keytabPath);
                 UserGroupInformation loginUser = UserGroupInformation.getLoginUser();
                 log.info("Kerberos authentication successful,UGI {}", loginUser);
-            } catch (IOException | KrbException e) {
+            } catch (IOException e) {
                 throw new SeaTunnelException("check connectivity failed, " + e.getMessage(), e);
             }
         }

File: seatunnel-connectors-v2/connector-hbase/src/main/java/org/apache/seatunnel/connectors/seatunnel/hbase/client/HbaseClient.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.seatunnel.connectors.seatunnel.hbase.exception.HbaseConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.hbase.source.HbaseSourceSplit;
 
+import org.apache.commons.lang3.StringUtils;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.hbase.HBaseConfiguration;
 import org.apache.hadoop.hbase.NamespaceDescriptor;
@@ -202,7 +203,7 @@ public void createTable(
             List<String> columnFamilies,
             boolean ignoreIfExists) {
         try {
-            if (!databaseExists(databaseName)) {
+            if (!databaseExists(databaseName) && !StringUtils.isBlank(databaseName)) {
                 admin.createNamespace(NamespaceDescriptor.create(databaseName).build());
             }
             TableName table = TableName.valueOf(databaseName, tableName);

File: seatunnel-connectors-v2/connector-typesense/src/main/java/org/apache/seatunnel/connectors/seatunnel/typesense/client/TypesenseClient.java
Patch:
@@ -68,7 +68,7 @@ public class TypesenseClient {
 
     public static TypesenseClient createInstance(ReadonlyConfig config) {
         List<String> hosts = config.get(TypesenseConnectionConfig.HOSTS);
-        String protocol = config.get(TypesenseConnectionConfig.protocol);
+        String protocol = config.get(TypesenseConnectionConfig.PROTOCOL);
         String apiKey = config.get(TypesenseConnectionConfig.APIKEY);
         return createInstance(hosts, apiKey, protocol);
     }

File: seatunnel-connectors-v2/connector-typesense/src/main/java/org/apache/seatunnel/connectors/seatunnel/typesense/config/TypesenseConnectionConfig.java
Patch:
@@ -37,7 +37,7 @@ public class TypesenseConnectionConfig {
                     .noDefaultValue()
                     .withDescription("Typesense api key");
 
-    public static final Option<String> protocol =
+    public static final Option<String> PROTOCOL =
             Options.key("protocol")
                     .stringType()
                     .defaultValue("http")

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-iceberg-e2e/src/test/java/org/apache/seatunnel/e2e/connector/iceberg/IcebergSinkCDCIT.java
Patch:
@@ -325,10 +325,10 @@ private List<Record> loadIcebergTable() {
                     results.add(record);
                 }
             } catch (IOException e) {
-                e.printStackTrace();
+                log.error(e.getMessage());
             }
         } catch (Exception ex) {
-            ex.printStackTrace();
+            log.error(ex.getMessage());
         }
         return results;
     }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/multitablesink/MultiTableCommitInfo.java
Patch:
@@ -21,10 +21,10 @@
 import lombok.Getter;
 
 import java.io.Serializable;
-import java.util.Map;
+import java.util.concurrent.ConcurrentMap;
 
 @Getter
 @AllArgsConstructor
 public class MultiTableCommitInfo implements Serializable {
-    private Map<SinkIdentifier, Object> commitInfo;
+    private ConcurrentMap<SinkIdentifier, Object> commitInfo;
 }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlSchemaChangeResolver.java
Patch:
@@ -64,6 +64,7 @@ public SchemaChangeEvent resolve(SourceRecord record, SeaTunnelDataType dataType
         customMySqlAntlrDdlParser.parse(ddl, tables);
         List<AlterTableColumnEvent> parsedEvents =
                 customMySqlAntlrDdlParser.getAndClearParsedEvents();
+        parsedEvents.forEach(e -> e.setSourceDialectName(DatabaseIdentifier.MYSQL));
         AlterTableColumnsEvent alterTableColumnsEvent =
                 new AlterTableColumnsEvent(
                         TableIdentifier.of(

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/sink/writer/IcebergRecordWriter.java
Patch:
@@ -91,6 +91,8 @@ record = recordConverter.convert(seaTunnelRow, rowType);
     public void applySchemaChange(SeaTunnelRowType afterRowType, SchemaChangeEvent event) {
         log.info("Apply schema change start.");
         SchemaChangeWrapper updates = new SchemaChangeWrapper();
+        // get the latest schema in case another process updated it
+        table.refresh();
         Schema schema = table.schema();
         if (event instanceof AlterTableDropColumnEvent) {
             AlterTableDropColumnEvent dropColumnEvent = (AlterTableDropColumnEvent) event;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/external/IncrementalSourceScanFetcher.java
Patch:
@@ -93,7 +93,7 @@ public void submitTask(FetchTask<SourceSplitBase> fetchTask) {
                                 currentSnapshotSplit,
                                 taskContext.isExactlyOnce());
                         snapshotSplitReadTask.execute(taskContext);
-                    } catch (Exception e) {
+                    } catch (Throwable e) {
                         log.error(
                                 String.format(
                                         "Execute snapshot read task for snapshot split %s fail",

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/external/IncrementalSourceStreamFetcher.java
Patch:
@@ -104,7 +104,7 @@ public void submitTask(FetchTask<SourceSplitBase> fetchTask) {
                                 currentIncrementalSplit,
                                 taskContext.isExactlyOnce());
                         streamFetchTask.execute(taskContext);
-                    } catch (Exception e) {
+                    } catch (Throwable e) {
                         log.error(
                                 String.format(
                                         "Execute stream read task for incremental split %s fail",

File: seatunnel-connectors-v2/connector-rocketmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rocketmq/source/RocketMqSourceReader.java
Patch:
@@ -98,7 +98,7 @@ public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
             Thread.sleep(THREAD_WAIT_TIME);
             return;
         }
-        while (pendingPartitionsQueue.size() != 0) {
+        while (!pendingPartitionsQueue.isEmpty()) {
             sourceSplits.add(pendingPartitionsQueue.poll());
         }
         sourceSplits.forEach(
@@ -166,7 +166,7 @@ record ->
                                                     // just for bounded mode
                                                     sourceSplit.setEndOffset(lastOffset);
                                                 }
-                                            } catch (Exception e) {
+                                            } catch (Throwable e) {
                                                 completableFuture.completeExceptionally(e);
                                             }
                                             completableFuture.complete(null);

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-api/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/api/AbstractCheckpointStorage.java
Patch:
@@ -195,7 +195,7 @@ public void asyncStoreCheckPoint(PipelineState state) {
                 () -> {
                     try {
                         storeCheckPoint(state);
-                    } catch (Exception e) {
+                    } catch (Throwable e) {
                         log.error(
                                 String.format(
                                         "store checkpoint failed, job id : %s, pipeline id : %d",

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/config/JdbcSourceTableConfig.java
Patch:
@@ -101,7 +101,9 @@ public static List<JdbcSourceTableConfig> of(ReadonlyConfig connectorConfig) {
 
         if (tableList.size() > 1) {
             List<String> tableIds =
-                    tableList.stream().map(e -> e.getTablePath()).collect(Collectors.toList());
+                    tableList.stream()
+                            .map(JdbcSourceTableConfig::getTablePath)
+                            .collect(Collectors.toList());
             Set<String> tableIdSet = new HashSet<>(tableIds);
             if (tableIdSet.size() < tableList.size() - 1) {
                 throw new IllegalArgumentException(

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/config/FakeConfig.java
Patch:
@@ -27,6 +27,7 @@
 import lombok.AllArgsConstructor;
 import lombok.Builder;
 import lombok.Getter;
+import lombok.Setter;
 
 import java.io.Serializable;
 import java.util.ArrayList;
@@ -451,6 +452,7 @@ public static FakeConfig buildWithConfig(ReadonlyConfig readonlyConfig) {
     }
 
     @Getter
+    @Setter
     @AllArgsConstructor
     public static class RowData implements Serializable {
         static final String KEY_KIND = "kind";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-1/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcDb2IT.java
Patch:
@@ -117,9 +117,6 @@ JdbcCase getJdbcCase() {
                 .build();
     }
 
-    @Override
-    void compareResult(String executeKey) {}
-
     @Override
     String driverUrl() {
         return "https://repo1.maven.org/maven2/com/ibm/db2/jcc/db2jcc/db2jcc4/db2jcc-db2jcc4.jar";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-1/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcOracleIT.java
Patch:
@@ -211,7 +211,7 @@ JdbcCase getJdbcCase() {
     }
 
     @Override
-    void compareResult(String executeKey) {
+    void checkResult(String executeKey, TestContainer container, Container.ExecResult execResult) {
         defaultCompare(executeKey, fieldNames, "INTEGER_COL");
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-2/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcPhoenixIT.java
Patch:
@@ -121,9 +121,6 @@ public void clearTable(String schema, String table) {
         }
     }
 
-    @Override
-    void compareResult(String executeKey) {}
-
     @Override
     String driverUrl() {
         return "https://repo1.maven.org/maven2/com/aliyun/phoenix/ali-phoenix-shaded-thin-client/5.2.5-HBase-2.x/ali-phoenix-shaded-thin-client-5.2.5-HBase-2.x.jar";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-3/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcHiveIT.java
Patch:
@@ -142,9 +142,6 @@ protected void insertTestData() {
         }
     }
 
-    @Override
-    void compareResult(String executeKey) {}
-
     @Override
     String driverUrl() {
         return "https://repo1.maven.org/maven2/org/apache/hive/hive-jdbc/3.1.3/hive-jdbc-3.1.3-standalone.jar";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-3/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcVerticaIT.java
Patch:
@@ -90,9 +90,6 @@ JdbcCase getJdbcCase() {
                 .build();
     }
 
-    @Override
-    void compareResult(String executeKey) {}
-
     @Override
     String driverUrl() {
         return "https://repo1.maven.org/maven2/com/vertica/jdbc/vertica-jdbc/12.0.3-0/vertica-jdbc-12.0.3-0.jar";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-5/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcDmIT.java
Patch:
@@ -131,9 +131,6 @@ JdbcCase getJdbcCase() {
                 .build();
     }
 
-    @Override
-    void compareResult(String executeKey) {}
-
     @Override
     String driverUrl() {
         return "https://repo1.maven.org/maven2/com/dameng/DmJdbcDriver18/8.1.1.193/DmJdbcDriver18-8.1.1.193.jar";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-5/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcDmUpsetIT.java
Patch:
@@ -155,9 +155,6 @@ JdbcCase getJdbcCase() {
                 .build();
     }
 
-    @Override
-    void compareResult(String executeKey) {}
-
     @Override
     protected void createNeededTables() {
         try (Statement statement = connection.createStatement()) {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-5/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcGBase8aIT.java
Patch:
@@ -109,9 +109,6 @@ JdbcCase getJdbcCase() {
                 .build();
     }
 
-    @Override
-    void compareResult(String executeKey) {}
-
     @Override
     String driverUrl() {
         return "https://cdn.gbase.cn/products/30/p5CiVwXBKQYIUGN8ecHvk/gbase-connector-java-9.5.0.7-build1-bin.jar";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-5/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcGreenplumIT.java
Patch:
@@ -88,9 +88,6 @@ JdbcCase getJdbcCase() {
                 .build();
     }
 
-    @Override
-    void compareResult(String executeKey) {}
-
     @Override
     String driverUrl() {
         return "https://repo1.maven.org/maven2/org/postgresql/postgresql/42.3.3/postgresql-42.3.3.jar";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-6/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcHanaIT.java
Patch:
@@ -127,9 +127,6 @@ JdbcCase getJdbcCase() {
                 .build();
     }
 
-    @Override
-    void compareResult(String executeKey) {}
-
     @Override
     String driverUrl() {
         return "https://repo1.maven.org/maven2/com/sap/cloud/db/jdbc/ngdbc/2.21.11/ngdbc-2.21.11.jar";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-6/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcOracleLowercaseTableIT.java
Patch:
@@ -140,9 +140,6 @@ JdbcCase getJdbcCase() {
                 .build();
     }
 
-    @Override
-    void compareResult(String executeKey) {}
-
     @Override
     String driverUrl() {
         return "https://repo1.maven.org/maven2/com/oracle/database/jdbc/ojdbc8/12.2.0.1/ojdbc8-12.2.0.1.jar";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-7/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcIrisIT.java
Patch:
@@ -424,7 +424,7 @@ public String insertTable(String schema, String table, String... fields) {
     }
 
     @Override
-    void compareResult(String executeKey) throws SQLException, IOException {
+    void checkResult(String executeKey, TestContainer container, Container.ExecResult execResult) {
         defaultCompare(executeKey, fieldNames, "BIGINT_COL");
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-7/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcMysqlSaveModeHandlerIT.java
Patch:
@@ -24,11 +24,13 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.common.utils.JdbcUrlUtil;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.mysql.MySqlCatalog;
+import org.apache.seatunnel.e2e.common.container.TestContainer;
 
 import org.apache.commons.lang3.tuple.Pair;
 
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.Assertions;
+import org.testcontainers.containers.Container;
 import org.testcontainers.containers.GenericContainer;
 import org.testcontainers.containers.MySQLContainer;
 import org.testcontainers.containers.output.Slf4jLogConsumer;
@@ -157,7 +159,7 @@ JdbcCase getJdbcCase() {
     }
 
     @Override
-    void compareResult(String executeKey) {
+    void checkResult(String executeKey, TestContainer container, Container.ExecResult execResult) {
         final TablePath tablePathSource = TablePath.of("seatunnel", "source");
         final CatalogTable tableSource = catalog.getTable(tablePathSource);
         final List<Column> columnsSource = tableSource.getTableSchema().getColumns();

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-7/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcXuguIT.java
Patch:
@@ -20,9 +20,11 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.common.utils.JdbcUrlUtil;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.xugu.XuguCatalog;
+import org.apache.seatunnel.e2e.common.container.TestContainer;
 
 import org.apache.commons.lang3.tuple.Pair;
 
+import org.testcontainers.containers.Container;
 import org.testcontainers.containers.GenericContainer;
 import org.testcontainers.containers.output.Slf4jLogConsumer;
 import org.testcontainers.utility.DockerLoggerFactory;
@@ -157,7 +159,7 @@ JdbcCase getJdbcCase() {
     }
 
     @Override
-    void compareResult(String executeKey) {
+    void checkResult(String executeKey, TestContainer container, Container.ExecResult execResult) {
         defaultCompare(executeKey, fieldNames, "XUGU_INT");
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/oracle/OracleTypeConverter.java
Patch:
@@ -173,7 +173,7 @@ public Column convert(BasicTypeDefine typeDefine) {
             case ORACLE_VARCHAR:
             case ORACLE_VARCHAR2:
                 builder.dataType(BasicType.STRING_TYPE);
-                builder.columnLength(typeDefine.getLength());
+                builder.columnLength(TypeDefineUtils.charTo4ByteLength(typeDefine.getLength()));
                 break;
             case ORACLE_NCHAR:
             case ORACLE_NVARCHAR2:

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/oracle/OracleTypeMapper.java
Patch:
@@ -59,9 +59,6 @@ public Column mappingColumn(ResultSetMetaData metadata, int colIndex) throws SQL
         } else if (Arrays.asList("NVARCHAR2", "NCHAR").contains(nativeType)) {
             long doubleByteLength = TypeDefineUtils.charToDoubleByteLength(precision);
             precision = doubleByteLength;
-        } else if (Arrays.asList("CHAR", "VARCHAR", "VARCHAR2").contains(nativeType)) {
-            long octetByteLength = TypeDefineUtils.charTo4ByteLength(precision);
-            precision = octetByteLength;
         }
 
         BasicTypeDefine typeDefine =

File: seatunnel-connectors-v2/connector-jdbc/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/oracle/OracleTypeConverterTest.java
Patch:
@@ -355,7 +355,7 @@ public void testConvertChar() {
 
         Assertions.assertEquals(typeDefine.getName(), column.getName());
         Assertions.assertEquals(BasicType.STRING_TYPE, column.getDataType());
-        Assertions.assertEquals(typeDefine.getLength(), column.getColumnLength());
+        Assertions.assertEquals(typeDefine.getLength() * 4, column.getColumnLength());
         Assertions.assertEquals(typeDefine.getColumnType(), column.getSourceType());
 
         typeDefine =
@@ -383,7 +383,7 @@ public void testConvertChar() {
 
         Assertions.assertEquals(typeDefine.getName(), column.getName());
         Assertions.assertEquals(BasicType.STRING_TYPE, column.getDataType());
-        Assertions.assertEquals(typeDefine.getLength(), column.getColumnLength());
+        Assertions.assertEquals(typeDefine.getLength() * 4, column.getColumnLength());
         Assertions.assertEquals(typeDefine.getColumnType(), column.getSourceType());
 
         typeDefine =
@@ -397,7 +397,7 @@ public void testConvertChar() {
 
         Assertions.assertEquals(typeDefine.getName(), column.getName());
         Assertions.assertEquals(BasicType.STRING_TYPE, column.getDataType());
-        Assertions.assertEquals(typeDefine.getLength(), column.getColumnLength());
+        Assertions.assertEquals(typeDefine.getLength() * 4, column.getColumnLength());
         Assertions.assertEquals(typeDefine.getColumnType(), column.getSourceType());
 
         typeDefine =

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/nlpmodel/llm/remote/openai/OpenAIModel.java
Patch:
@@ -82,7 +82,8 @@ protected List<String> chatWithModel(String prompt, String data) throws IOExcept
 
         JsonNode result = OBJECT_MAPPER.readTree(responseStr);
         String resultData = result.get("choices").get(0).get("message").get("content").asText();
-        return OBJECT_MAPPER.readValue(resultData, new TypeReference<List<String>>() {});
+        return OBJECT_MAPPER.readValue(
+                convertData(resultData), new TypeReference<List<String>>() {});
     }
 
     @VisibleForTesting

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/TableSinkFactoryContext.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.api.table.factory;
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
-import org.apache.seatunnel.api.sink.TablePlaceholder;
+import org.apache.seatunnel.api.sink.TablePlaceholderProcessor;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 
 import com.google.common.annotations.VisibleForTesting;
@@ -48,7 +48,7 @@ public static TableSinkFactoryContext replacePlaceholderAndCreate(
             ClassLoader classLoader,
             Collection<String> excludeTablePlaceholderReplaceKeys) {
         ReadonlyConfig rewriteConfig =
-                TablePlaceholder.replaceTablePlaceholder(
+                TablePlaceholderProcessor.replaceTablePlaceholder(
                         options, catalogTable, excludeTablePlaceholderReplaceKeys);
         return new TableSinkFactoryContext(catalogTable, rewriteConfig, classLoader);
     }

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/data/IcebergTypeMapper.java
Patch:
@@ -115,7 +115,7 @@ public static Type toIcebergType(SeaTunnelDataType dataType) {
         return toIcebergType(dataType, new AtomicInteger(1));
     }
 
-    private static Type toIcebergType(SeaTunnelDataType dataType, AtomicInteger nextId) {
+    public static Type toIcebergType(SeaTunnelDataType dataType, AtomicInteger nextId) {
         switch (dataType.getSqlType()) {
             case BOOLEAN:
                 return Types.BooleanType.get();

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/sink/writer/IcebergWriterFactory.java
Patch:
@@ -23,7 +23,7 @@
 import org.apache.seatunnel.shade.com.google.common.collect.Sets;
 import org.apache.seatunnel.shade.com.google.common.primitives.Ints;
 
-import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
+import org.apache.seatunnel.api.table.catalog.TableSchema;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.IcebergTableLoader;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.config.SinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.utils.SchemaUtils;
@@ -63,7 +63,7 @@ public IcebergWriterFactory(IcebergTableLoader tableLoader, SinkConfig config) {
         this.config = config;
     }
 
-    public RecordWriter createWriter(SeaTunnelRowType rowType) {
+    public RecordWriter createWriter(TableSchema tableSchema) {
         Table table;
         try {
             table = tableLoader.loadTable();
@@ -76,7 +76,7 @@ public RecordWriter createWriter(SeaTunnelRowType rowType) {
                                     tableLoader.getCatalog(),
                                     tableLoader.getTableIdentifier(),
                                     config,
-                                    rowType);
+                                    tableSchema);
                     // Create an empty snapshot for the branch
                     if (config.getCommitBranch() != null) {
                         table.manageSnapshots().createBranch(config.getCommitBranch()).commit();

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/exception/CommonError.java
Patch:
@@ -266,8 +266,8 @@ public static SeaTunnelRuntimeException writeRowErrorWithFiledsCountNotMatch(
             String connector, int sourceFieldsNum, int sinkFieldsNum) {
         Map<String, String> params = new HashMap<>();
         params.put("connector", connector);
-        params.put("sourceFiledName", String.valueOf(sourceFieldsNum));
-        params.put("sourceFiledType", String.valueOf(sinkFieldsNum));
+        params.put("sourceFieldsNum", String.valueOf(sourceFieldsNum));
+        params.put("sinkFieldsNum", String.valueOf(sinkFieldsNum));
         return new SeaTunnelRuntimeException(
                 WRITE_SEATUNNEL_ROW_ERROR_WITH_FILEDS_NOT_MATCH, params);
     }

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/catalog/ElasticSearchCatalog.java
Patch:
@@ -110,8 +110,7 @@ public String getDefaultDatabase() throws CatalogException {
     public boolean databaseExists(String databaseName) throws CatalogException {
         // check if the index exist
         try {
-            List<IndexDocsCount> indexDocsCount = esRestClient.getIndexDocsCount(databaseName);
-            return true;
+            return esRestClient.checkIndexExist(databaseName);
         } catch (Exception e) {
             log.error(
                     String.format(

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/source/DefaultSeaTunnelRowDeserializer.java
Patch:
@@ -137,7 +137,9 @@ SeaTunnelRow convert(ElasticsearchRecord rowRecord) {
                             fieldName, value, seaTunnelDataType, JsonUtils.toJsonString(rowRecord)),
                     ex);
         }
-        return new SeaTunnelRow(seaTunnelFields);
+        SeaTunnelRow seaTunnelRow = new SeaTunnelRow(seaTunnelFields);
+        seaTunnelRow.setTableId(rowRecord.getTableId());
+        return seaTunnelRow;
     }
 
     Object convertValue(SeaTunnelDataType<?> fieldType, String fieldValue)

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/source/ElasticsearchRecord.java
Patch:
@@ -30,4 +30,6 @@
 public class ElasticsearchRecord {
     private Map<String, Object> doc;
     private List<String> source;
+
+    private String tableId;
 }

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/serde/BsonToRowDataConverters.java
Patch:
@@ -401,7 +401,7 @@ private static byte[] convertToBinary(BsonValue bsonValue) {
     }
 
     private static long convertToLong(BsonValue bsonValue) {
-        if (bsonValue.isInt64()) {
+        if (bsonValue.isInt64() || bsonValue.isInt32()) {
             return bsonValue.asNumber().longValue();
         }
         throw new MongodbConnectorException(

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/config/JdbcSourceTableConfig.java
Patch:
@@ -85,8 +85,6 @@ public static List<JdbcSourceTableConfig> of(ReadonlyConfig connectorConfig) {
                             .partitionNumber(connectorConfig.get(JdbcOptions.PARTITION_NUM))
                             .partitionStart(connectorConfig.get(JdbcOptions.PARTITION_LOWER_BOUND))
                             .partitionEnd(connectorConfig.get(JdbcOptions.PARTITION_UPPER_BOUND))
-                            .useSelectCount(connectorConfig.get(JdbcSourceOptions.USE_SELECT_COUNT))
-                            .skipAnalyze(connectorConfig.get(JdbcSourceOptions.SKIP_ANALYZE))
                             .build();
             tableList = Collections.singletonList(tableProperty);
         }
@@ -96,6 +94,9 @@ public static List<JdbcSourceTableConfig> of(ReadonlyConfig connectorConfig) {
                     if (tableConfig.getPartitionNumber() == null) {
                         tableConfig.setPartitionNumber(DEFAULT_PARTITION_NUMBER);
                     }
+                    tableConfig.setUseSelectCount(
+                            connectorConfig.get(JdbcSourceOptions.USE_SELECT_COUNT));
+                    tableConfig.setSkipAnalyze(connectorConfig.get(JdbcSourceOptions.SKIP_ANALYZE));
                 });
 
         if (tableList.size() > 1) {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/utils/JdbcCatalogUtils.java
Patch:
@@ -140,6 +140,8 @@ public static Map<TablePath, JdbcSourceTable> getTables(
                                 .partitionNumber(tableConfig.getPartitionNumber())
                                 .partitionStart(tableConfig.getPartitionStart())
                                 .partitionEnd(tableConfig.getPartitionEnd())
+                                .useSelectCount(tableConfig.getUseSelectCount())
+                                .skipAnalyze(tableConfig.getSkipAnalyze())
                                 .catalogTable(catalogTable)
                                 .build();
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-common/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/AbstractJdbcIT.java
Patch:
@@ -123,7 +123,7 @@ public abstract class AbstractJdbcIT extends TestSuiteBase implements TestResour
     protected URLClassLoader getUrlClassLoader() throws MalformedURLException {
         if (urlClassLoader == null) {
             urlClassLoader =
-                    new URLClassLoader(
+                    new InsecureURLClassLoader(
                             new URL[] {new URL(driverUrl())},
                             AbstractJdbcIT.class.getClassLoader());
             Thread.currentThread().setContextClassLoader(urlClassLoader);

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/Constant.java
Patch:
@@ -24,6 +24,8 @@ public class Constant {
 
     public static final String DEFAULT_SEATUNNEL_CLUSTER_NAME = "seatunnel";
 
+    public static final String REST_SUBMIT_JOBS_PARAMS = "params";
+
     /**
      * The default port number for the cluster auto-discovery mechanism's multicast communication.
      */

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/rest/RestConstant.java
Patch:
@@ -50,7 +50,6 @@ public class RestConstant {
     @Deprecated public static final String RUNNING_JOB_URL = "/hazelcast/rest/maps/running-job";
     public static final String JOB_INFO_URL = "/hazelcast/rest/maps/job-info";
     public static final String FINISHED_JOBS_INFO = "/hazelcast/rest/maps/finished-jobs";
-    public static final String SUBMIT_JOB_URL = "/hazelcast/rest/maps/submit-job";
     public static final String ENCRYPT_CONFIG = "/hazelcast/rest/maps/encrypt-config";
 
     // only for test use
@@ -59,5 +58,8 @@ public class RestConstant {
     public static final String SYSTEM_MONITORING_INFORMATION =
             "/hazelcast/rest/maps/system-monitoring-information";
 
+    public static final String SUBMIT_JOB_URL = "/hazelcast/rest/maps/submit-job";
+    public static final String SUBMIT_JOBS_URL = "/hazelcast/rest/maps/submit-jobs";
     public static final String STOP_JOB_URL = "/hazelcast/rest/maps/stop-job";
+    public static final String STOP_JOBS_URL = "/hazelcast/rest/maps/stop-jobs";
 }

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-common/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/AbstractJdbcIT.java
Patch:
@@ -99,7 +99,8 @@ public abstract class AbstractJdbcIT extends TestSuiteBase implements TestResour
                                 "bash",
                                 "-c",
                                 "mkdir -p /tmp/seatunnel/plugins/Jdbc/lib && cd /tmp/seatunnel/plugins/Jdbc/lib && wget "
-                                        + driverUrl());
+                                        + driverUrl()
+                                        + " --no-check-certificate");
                 Assertions.assertEquals(0, extraCommands.getExitCode(), extraCommands.getStderr());
             };
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-5/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcGBase8aIT.java
Patch:
@@ -114,7 +114,7 @@ void compareResult(String executeKey) {}
 
     @Override
     String driverUrl() {
-        return "https://www.gbase8.cn/wp-content/uploads/2020/10/gbase-connector-java-8.3.81.53-build55.5.7-bin_min_mix.jar";
+        return "https://cdn.gbase.cn/products/30/p5CiVwXBKQYIUGN8ecHvk/gbase-connector-java-9.5.0.7-build1-bin.jar";
     }
 
     @Override

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-1/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcMysqlIT.java
Patch:
@@ -180,6 +180,7 @@ JdbcCase getJdbcCase() {
                 .testData(testDataSet)
                 .catalogDatabase(CATALOG_DATABASE)
                 .catalogTable(MYSQL_SINK)
+                .tablePathFullName(MYSQL_DATABASE + "." + MYSQL_SOURCE)
                 .build();
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-1/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcOracleIT.java
Patch:
@@ -205,6 +205,8 @@ JdbcCase getJdbcCase() {
                 .configFile(CONFIG_FILE)
                 .insertSql(insertSql)
                 .testData(testDataSet)
+                // oracle jdbc not support getTables/getCatalog/getSchema , is empty
+                .tablePathFullName(TablePath.DEFAULT.getFullName())
                 .build();
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-2/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcStarRocksdbIT.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc;
 
+import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 
 import org.apache.commons.lang3.tuple.Pair;
@@ -105,6 +106,7 @@ JdbcCase getJdbcCase() {
                 .configFile(CONFIG_FILE)
                 .insertSql(insertSql)
                 .testData(testDataSet)
+                .tablePathFullName(TablePath.DEFAULT.getFullName())
                 .build();
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-3/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcHiveIT.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc;
 
+import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.common.exception.SeaTunnelRuntimeException;
 import org.apache.seatunnel.common.utils.ExceptionUtils;
@@ -43,7 +44,7 @@ public class JdbcHiveIT extends AbstractJdbcIT {
 
     private static final String HIVE_DATABASE = "default";
 
-    private static final String HIVE_SOURCE = "e2e_table_source";
+    private static final String HIVE_SOURCE = "hive_e2e_source_table";
     private static final String HIVE_USERNAME = "root";
     private static final String HIVE_PASSWORD = null;
     private static final int HIVE_PORT = 10000;
@@ -94,6 +95,7 @@ JdbcCase getJdbcCase() {
                 .sourceTable(HIVE_SOURCE)
                 .createSql(CREATE_SQL)
                 .configFile(CONFIG_FILE)
+                .tablePathFullName(TablePath.DEFAULT.getFullName())
                 .build();
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-3/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcSqlServerIT.java
Patch:
@@ -180,6 +180,7 @@ JdbcCase getJdbcCase() {
                 .configFile(CONFIG_FILE)
                 .insertSql(insertSql)
                 .testData(testDataSet)
+                .tablePathFullName(TablePath.DEFAULT.getFullName())
                 .build();
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-5/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcDmIT.java
Patch:
@@ -127,6 +127,7 @@ JdbcCase getJdbcCase() {
                 .configFile(CONFIG_FILE)
                 .insertSql(insertSql)
                 .testData(testDataSet)
+                .tablePathFullName(String.format("%s.%s", DM_DATABASE, DM_SOURCE))
                 .build();
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-5/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcGreenplumIT.java
Patch:
@@ -84,6 +84,7 @@ JdbcCase getJdbcCase() {
                 .configFile(CONFIG_FILE)
                 .insertSql(insertSql)
                 .testData(testDataSet)
+                .tablePathFullName(GREENPLUM_SOURCE)
                 .build();
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-7/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcXuguIT.java
Patch:
@@ -152,6 +152,7 @@ JdbcCase getJdbcCase() {
                 .configFile(CONFIG_FILE)
                 .insertSql(insertSql)
                 .testData(testDataSet)
+                .tablePathFullName(XUGU_DATABASE + "." + XUGU_SCHEMA + "." + XUGU_SOURCE)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/oracle/OracleCatalogFactory.java
Patch:
@@ -25,6 +25,7 @@
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.common.utils.JdbcUrlUtil;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.JdbcCatalogOptions;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcOptions;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.DatabaseIdentifier;
 
 import com.google.auto.service.AutoService;
@@ -52,7 +53,8 @@ public Catalog createCatalog(String catalogName, ReadonlyConfig options) {
                 options.get(JdbcCatalogOptions.USERNAME),
                 options.get(JdbcCatalogOptions.PASSWORD),
                 urlInfo,
-                options.get(JdbcCatalogOptions.SCHEMA));
+                options.get(JdbcCatalogOptions.SCHEMA),
+                options.get(JdbcOptions.DECIMAL_TYPE_NARROWING));
     }
 
     @Override

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/utils/JdbcCatalogUtils.java
Patch:
@@ -34,6 +34,7 @@
 import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.JdbcCatalogOptions;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.utils.CatalogUtils;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcConnectionConfig;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcOptions;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcSourceTableConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.connection.JdbcConnectionProvider;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.JdbcDialect;
@@ -395,6 +396,8 @@ private static ReadonlyConfig extractCatalogConfig(JdbcConnectionConfig config)
                 .ifPresent(val -> catalogConfig.put(JdbcCatalogOptions.PASSWORD.key(), val));
         Optional.ofNullable(config.getCompatibleMode())
                 .ifPresent(val -> catalogConfig.put(JdbcCatalogOptions.COMPATIBLE_MODE.key(), val));
+        catalogConfig.put(
+                JdbcOptions.DECIMAL_TYPE_NARROWING.key(), config.isDecimalTypeNarrowing());
         return ReadonlyConfig.fromMap(catalogConfig);
     }
 }

File: seatunnel-e2e/seatunnel-engine-e2e/connector-console-seatunnel-e2e/src/test/java/org/apache/seatunnel/engine/e2e/console/FakeSourceToConsoleWithEventReportIT.java
Patch:
@@ -109,7 +109,7 @@ public void testEventReport() throws IOException, InterruptedException {
                 arrayNode.elements().forEachRemaining(jsonNode -> events.add(jsonNode));
             }
         }
-        Assertions.assertEquals(8, events.size());
+        Assertions.assertEquals(10, events.size());
         Set<String> eventTypes =
                 events.stream().map(e -> e.get("eventType").asText()).collect(Collectors.toSet());
         Assertions.assertTrue(

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/sink/writer/SparkDataWriterFactory.java
Patch:
@@ -63,6 +63,6 @@ public DataWriter<InternalRow> createDataWriter(int partitionId, long taskId, lo
             throw new RuntimeException("Failed to create SinkCommitter.", e);
         }
         return new SparkDataWriter<>(
-                writer, committer, new MultiTableManager(catalogTables), epochId);
+                writer, committer, new MultiTableManager(catalogTables), epochId, context);
     }
 }

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-3.3/src/main/java/org/apache/seatunnel/translation/spark/sink/write/SeaTunnelSparkDataWriterFactory.java
Patch:
@@ -64,7 +64,7 @@ public DataWriter<InternalRow> createWriter(int partitionId, long taskId) {
             throw new RuntimeException("Failed to create SinkCommitter.", e);
         }
         return new SeaTunnelSparkDataWriter<>(
-                writer, committer, new MultiTableManager(catalogTables), 0);
+                writer, committer, new MultiTableManager(catalogTables), 0, context);
     }
 
     @Override

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/config/MessageFormat.java
Patch:
@@ -26,5 +26,6 @@ public enum MessageFormat {
     COMPATIBLE_KAFKA_CONNECT_JSON,
     OGG_JSON,
     AVRO,
-    MAXWELL_JSON
+    MAXWELL_JSON,
+    PROTOBUF
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/worker/WorkerProfile.java
Patch:
@@ -85,6 +85,7 @@ public void writeData(ObjectDataOutput out) throws IOException {
             out.writeObject(unassignedSlot);
         }
         out.writeBoolean(dynamicSlot);
+        out.writeObject(attributes);
     }
 
     @Override
@@ -103,5 +104,6 @@ public void readData(ObjectDataInput in) throws IOException {
             unassignedSlots[i] = in.readObject();
         }
         dynamicSlot = in.readBoolean();
+        attributes = in.readObject();
     }
 }

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceIT.java
Patch:
@@ -992,7 +992,6 @@ public void testStreamJobRestoreFromOssInAllNodeDown() throws Exception {
                             + "          fs.oss.endpoint: "
                             + OSS_ENDPOINT
                             + "\n"
-                            + "          fs.oss.credentials.provider: org.apache.hadoop.fs.aliyun.oss.AliyunCredentialsProvider\n"
                             + "  properties:\n"
                             + "    hazelcast.invocation.max.retry.count: 200\n"
                             + "    hazelcast.tcp.join.port.try.count: 30\n"

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-hdfs/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/hdfs/HdfsStorageFactory.java
Patch:
@@ -58,7 +58,6 @@
  *      fs.oss.accessKeySecret = "your script key"
  *      fs.oss.endpoint = "such as: oss-cn-hangzhou.aliyuncs.com"
  *      oss.bucket= "oss://your bucket"
- *      fs.oss.credentials.provider = "org.apache.hadoop.fs.aliyun.oss.AliyunCredentialsProvider"
  *  </pre>
  */
 @AutoService(CheckpointStorageFactory.class)

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-hdfs/src/test/java/org/apache/seatunnel/engine/checkpoint/storage/hdfs/OssFileCheckpointTest.java
Patch:
@@ -40,9 +40,6 @@ public static void setup() throws CheckpointStorageException {
         config.put("fs.oss.accessKeySecret", "your access key secret");
         config.put("fs.oss.endpoint", "oss-cn-hangzhou.aliyuncs.com");
         config.put("oss.bucket", "oss://seatunnel-test/");
-        config.put(
-                "fs.oss.credentials.provider",
-                "org.apache.hadoop.fs.aliyun.oss.AliyunCredentialsProvider");
         STORAGE = new HdfsStorage(config);
         initStorageData();
     }

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/ElasticsearchRowSerializer.java
Patch:
@@ -169,6 +169,7 @@ private Map<String, Object> toDocumentMap(SeaTunnelRow row, SeaTunnelRowType row
         for (int i = 0; i < fieldNames.length; i++) {
             Object value = fields[i];
             if (value == null) {
+                doc.put(fieldNames[i], null);
             } else if (value instanceof SeaTunnelRow) {
                 doc.put(
                         fieldNames[i],

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelRow.java
Patch:
@@ -143,7 +143,6 @@ private int getBytesForValue(Object v, SeaTunnelDataType<?> dataType) {
             case TIMESTAMP:
                 return 48;
             case FLOAT_VECTOR:
-                return getArrayNotNullSize((Object[]) v) * 4;
             case FLOAT16_VECTOR:
             case BFLOAT16_VECTOR:
             case BINARY_VECTOR:

File: seatunnel-connectors-v2/connector-milvus/src/main/java/org/apache/seatunnel/connectors/seatunnel/milvus/source/MilvusSourceReader.java
Patch:
@@ -29,6 +29,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.utils.BufferUtils;
 import org.apache.seatunnel.connectors.seatunnel.milvus.config.MilvusSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.milvus.exception.MilvusConnectionErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.milvus.exception.MilvusConnectorException;
@@ -220,7 +221,7 @@ public SeaTunnelRow convertToSeaTunnelRow(
                         for (int i = 0; i < list.size(); i++) {
                             arrays[i] = Float.parseFloat(list.get(i).toString());
                         }
-                        fields[fieldIndex] = arrays;
+                        fields[fieldIndex] = BufferUtils.toByteBuffer(arrays);
                         break;
                     } else {
                         throw new MilvusConnectorException(

File: seatunnel-connectors-v2/connector-cassandra/src/main/java/org/apache/seatunnel/connectors/seatunnel/cassandra/sink/CassandraSink.java
Patch:
@@ -28,6 +28,7 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
+import org.apache.seatunnel.common.utils.ExceptionUtils;
 import org.apache.seatunnel.connectors.seatunnel.cassandra.client.CassandraClient;
 import org.apache.seatunnel.connectors.seatunnel.cassandra.config.CassandraParameters;
 import org.apache.seatunnel.connectors.seatunnel.cassandra.exception.CassandraConnectorErrorCode;
@@ -107,7 +108,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                     SeaTunnelAPIErrorCode.CONFIG_VALIDATION_FAILED,
                     String.format(
                             "PluginName: %s, PluginType: %s, Message: %s",
-                            getPluginName(), PluginType.SINK, checkResult.getMsg()));
+                            getPluginName(), PluginType.SINK, ExceptionUtils.getMessage(e)));
         }
     }
 

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/source/ClickhouseSource.java
Patch:
@@ -34,6 +34,7 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
+import org.apache.seatunnel.common.utils.ExceptionUtils;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.state.ClickhouseSourceState;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.util.ClickhouseUtil;
@@ -146,7 +147,7 @@ public void prepare(Config config) throws PrepareFailException {
                     SeaTunnelAPIErrorCode.CONFIG_VALIDATION_FAILED,
                     String.format(
                             "PluginName: %s, PluginType: %s, Message: %s",
-                            getPluginName(), PluginType.SOURCE, e.getMessage()));
+                            getPluginName(), PluginType.SOURCE, ExceptionUtils.getMessage(e)));
         }
     }
 

File: seatunnel-connectors-v2/connector-influxdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/influxdb/source/InfluxDBSource.java
Patch:
@@ -35,6 +35,7 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
+import org.apache.seatunnel.common.utils.ExceptionUtils;
 import org.apache.seatunnel.connectors.seatunnel.influxdb.client.InfluxDBClient;
 import org.apache.seatunnel.connectors.seatunnel.influxdb.config.SourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.influxdb.exception.InfluxdbConnectorErrorCode;
@@ -95,7 +96,7 @@ public void prepare(Config config) throws PrepareFailException {
                     SeaTunnelAPIErrorCode.CONFIG_VALIDATION_FAILED,
                     String.format(
                             "PluginName: %s, PluginType: %s, Message: %s",
-                            getPluginName(), PluginType.SOURCE, e));
+                            getPluginName(), PluginType.SOURCE, ExceptionUtils.getMessage(e)));
         }
     }
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/DefaultSaveModeHandler.java
Patch:
@@ -76,6 +76,8 @@ public void handleSchemaSaveMode() {
             case ERROR_WHEN_SCHEMA_NOT_EXIST:
                 errorWhenSchemaNotExist();
                 break;
+            case IGNORE:
+                break;
             default:
                 throw new UnsupportedOperationException("Unsupported save mode: " + schemaSaveMode);
         }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SchemaSaveMode.java
Patch:
@@ -27,4 +27,7 @@ public enum SchemaSaveMode {
 
     // Error will be reported when the table does not exist
     ERROR_WHEN_SCHEMA_NOT_EXIST,
+
+    // Ignore creation
+    IGNORE
 }

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-2/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcOceanBaseITBase.java
Patch:
@@ -84,6 +84,6 @@ void compareResult(String executeKey) {
 
     @Override
     String driverUrl() {
-        return "https://repo1.maven.org/maven2/com/oceanbase/oceanbase-client/2.4.3/oceanbase-client-2.4.3.jar";
+        return "https://repo1.maven.org/maven2/com/oceanbase/oceanbase-client/2.4.11/oceanbase-client-2.4.11.jar";
     }
 }

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/seatunnel/SeaTunnelContainer.java
Patch:
@@ -433,7 +433,9 @@ private boolean isIssueWeAlreadyKnow(String threadName) {
                 || threadName.contains("Timer for 's3a-file-system' metrics system")
                 || threadName.startsWith("MutableQuantiles-")
                 // JDBC Hana driver
-                || threadName.startsWith("Thread-");
+                || threadName.startsWith("Thread-")
+                // JNA Cleaner
+                || threadName.startsWith("JNA Cleaner");
     }
 
     @Override

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlDialect.java
Patch:
@@ -29,7 +29,7 @@
 import org.apache.seatunnel.connectors.cdc.base.utils.CatalogTableUtils;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.config.MySqlSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.config.MySqlSourceConfigFactory;
-import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.eumerator.MySqlChunkSplitter;
+import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.enumerator.MySqlChunkSplitter;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.reader.fetch.MySqlSourceFetchTaskContext;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.reader.fetch.binlog.MySqlBinlogFetchTask;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.reader.fetch.scan.MySqlSnapshotFetchTask;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/enumerator/MySqlChunkSplitter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.eumerator;
+package org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.enumerator;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-oracle/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/oracle/source/OracleDialect.java
Patch:
@@ -29,7 +29,7 @@
 import org.apache.seatunnel.connectors.cdc.base.utils.CatalogTableUtils;
 import org.apache.seatunnel.connectors.seatunnel.cdc.oracle.config.OracleSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.cdc.oracle.config.OracleSourceConfigFactory;
-import org.apache.seatunnel.connectors.seatunnel.cdc.oracle.source.eumerator.OracleChunkSplitter;
+import org.apache.seatunnel.connectors.seatunnel.cdc.oracle.source.enumerator.OracleChunkSplitter;
 import org.apache.seatunnel.connectors.seatunnel.cdc.oracle.source.reader.fetch.OracleSourceFetchTaskContext;
 import org.apache.seatunnel.connectors.seatunnel.cdc.oracle.source.reader.fetch.logminer.OracleRedoLogFetchTask;
 import org.apache.seatunnel.connectors.seatunnel.cdc.oracle.source.reader.fetch.scan.OracleSnapshotFetchTask;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-oracle/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/oracle/source/enumerator/OracleChunkSplitter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.cdc.oracle.source.eumerator;
+package org.apache.seatunnel.connectors.seatunnel.cdc.oracle.source.enumerator;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/SqlServerDialect.java
Patch:
@@ -29,7 +29,7 @@
 import org.apache.seatunnel.connectors.cdc.base.utils.CatalogTableUtils;
 import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.config.SqlServerSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.config.SqlServerSourceConfigFactory;
-import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.source.eumerator.SqlServerChunkSplitter;
+import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.source.enumerator.SqlServerChunkSplitter;
 import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.source.reader.fetch.SqlServerSourceFetchTaskContext;
 import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.source.reader.fetch.scan.SqlServerSnapshotFetchTask;
 import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.source.reader.fetch.transactionlog.SqlServerTransactionLogFetchTask;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/enumerator/SqlServerChunkSplitter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.source.eumerator;
+package org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.source.enumerator;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/serialize/SeaTunnelRowSerializer.java
Patch:
@@ -70,7 +70,7 @@ public SeaTunnelRowSerializer(
 
         if (JSON.equals(type)) {
             JsonSerializationSchema jsonSerializationSchema =
-                    new JsonSerializationSchema(this.seaTunnelRowType, NULL_VALUE);
+                    new JsonSerializationSchema(this.seaTunnelRowType);
             ObjectMapper mapper = jsonSerializationSchema.getMapper();
             mapper.configure(JsonGenerator.Feature.WRITE_BIGDECIMAL_AS_PLAIN, true);
             this.serialize = jsonSerializationSchema;

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SinkCommonOptions.java
Patch:
@@ -28,5 +28,5 @@ public class SinkCommonOptions {
             Options.key("multi_table_sink_replica")
                     .intType()
                     .defaultValue(1)
-                    .withDescription("The replica number of multi table sink");
+                    .withDescription("The replica number of multi table sink writer");
 }

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/sink/ElasticsearchSinkFactory.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.TableIdentifier;
 import org.apache.seatunnel.api.table.connector.TableSink;
@@ -69,7 +70,8 @@ public OptionRule optionRule() {
                         TLS_KEY_STORE_PATH,
                         TLS_KEY_STORE_PASSWORD,
                         TLS_TRUST_STORE_PATH,
-                        TLS_TRUST_STORE_PASSWORD)
+                        TLS_TRUST_STORE_PASSWORD,
+                        SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/LocalFileSinkFactory.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.connector.TableSink;
 import org.apache.seatunnel.api.table.factory.Factory;
@@ -48,6 +49,7 @@ public OptionRule optionRule() {
                 .optional(BaseSinkConfig.FILE_FORMAT_TYPE)
                 .optional(BaseSinkConfig.SCHEMA_SAVE_MODE)
                 .optional(BaseSinkConfig.DATA_SAVE_MODE)
+                .optional(SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.TEXT,

File: seatunnel-connectors-v2/connector-file/connector-file-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/sink/OssFileSinkFactory.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.connector.TableSink;
 import org.apache.seatunnel.api.table.factory.Factory;
@@ -102,6 +103,7 @@ public OptionRule optionRule() {
                 .optional(BaseSinkConfig.DATE_FORMAT)
                 .optional(BaseSinkConfig.DATETIME_FORMAT)
                 .optional(BaseSinkConfig.TIME_FORMAT)
+                .optional(SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .build();
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/sink/S3FileSinkFactory.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.connector.TableSink;
 import org.apache.seatunnel.api.table.factory.Factory;
@@ -103,6 +104,7 @@ public OptionRule optionRule() {
                 .optional(BaseSinkConfig.DATETIME_FORMAT)
                 .optional(BaseSinkConfig.TIME_FORMAT)
                 .optional(BaseSinkConfig.TMP_PATH)
+                .optional(SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/sink/HttpSinkFactory.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.http.sink;
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.connector.TableSink;
 import org.apache.seatunnel.api.table.factory.Factory;
@@ -49,6 +50,7 @@ public OptionRule optionRule() {
                 .optional(HttpConfig.RETRY)
                 .optional(HttpConfig.RETRY_BACKOFF_MULTIPLIER_MS)
                 .optional(HttpConfig.RETRY_BACKOFF_MAX_MS)
+                .optional(SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .build();
     }
 }

File: seatunnel-connectors-v2/connector-hudi/src/main/java/org/apache/seatunnel/connectors/seatunnel/hudi/sink/HudiSinkFactory.java
Patch:
@@ -19,6 +19,7 @@
 package org.apache.seatunnel.connectors.seatunnel.hudi.sink;
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.connector.TableSink;
 import org.apache.seatunnel.api.table.factory.Factory;
@@ -61,7 +62,8 @@ public OptionRule optionRule() {
                         INSERT_SHUFFLE_PARALLELISM,
                         UPSERT_SHUFFLE_PARALLELISM,
                         MIN_COMMITS_TO_KEEP,
-                        MAX_COMMITS_TO_KEEP)
+                        MAX_COMMITS_TO_KEEP,
+                        SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/sink/IcebergSinkFactory.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.TableIdentifier;
 import org.apache.seatunnel.api.table.connector.TableSink;
@@ -57,7 +58,8 @@ public OptionRule optionRule() {
                         SinkConfig.TABLE_DEFAULT_PARTITION_KEYS,
                         SinkConfig.TABLE_UPSERT_MODE_ENABLED_PROP,
                         SinkConfig.TABLE_SCHEMA_EVOLUTION_ENABLED_PROP,
-                        SinkConfig.TABLES_DEFAULT_COMMIT_BRANCH)
+                        SinkConfig.TABLES_DEFAULT_COMMIT_BRANCH,
+                        SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-influxdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/influxdb/sink/InfluxDBSinkFactory.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.connector.TableSink;
 import org.apache.seatunnel.api.table.factory.Factory;
@@ -65,7 +66,8 @@ public OptionRule optionRule() {
                         KEY_TIME,
                         BATCH_SIZE,
                         MAX_RETRIES,
-                        RETRY_BACKOFF_MULTIPLIER_MS)
+                        RETRY_BACKOFF_MULTIPLIER_MS,
+                        SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/sink/KuduSinkFactory.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.connector.TableSink;
 import org.apache.seatunnel.api.table.factory.Factory;
@@ -56,6 +57,7 @@ public OptionRule optionRule() {
                 .optional(KuduSinkConfig.IGNORE_DUPLICATE)
                 .optional(KuduSinkConfig.ENABLE_KERBEROS)
                 .optional(KuduSinkConfig.KERBEROS_KRB5_CONF)
+                .optional(SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .conditional(
                         KuduSinkConfig.FLUSH_MODE,
                         Arrays.asList(AUTO_FLUSH_BACKGROUND.name(), MANUAL_FLUSH.name()),

File: seatunnel-connectors-v2/connector-paimon/src/main/java/org/apache/seatunnel/connectors/seatunnel/paimon/sink/PaimonSinkFactory.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.TableIdentifier;
 import org.apache.seatunnel.api.table.connector.TableSink;
@@ -54,7 +55,8 @@ public OptionRule optionRule() {
                         PaimonSinkConfig.DATA_SAVE_MODE,
                         PaimonSinkConfig.PRIMARY_KEYS,
                         PaimonSinkConfig.PARTITION_KEYS,
-                        PaimonSinkConfig.WRITE_PROPS)
+                        PaimonSinkConfig.WRITE_PROPS,
+                        SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .conditional(
                         PaimonConfig.CATALOG_TYPE, PaimonCatalogEnum.HIVE, PaimonConfig.CATALOG_URI)
                 .build();

File: seatunnel-connectors-v2/connector-redis/src/main/java/org/apache/seatunnel/connectors/seatunnel/redis/sink/RedisSinkFactory.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.redis.sink;
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.sink.SinkCommonOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.connector.TableSink;
 import org.apache.seatunnel.api.table.factory.Factory;
@@ -51,7 +52,8 @@ public OptionRule optionRule() {
                         RedisConfig.USER,
                         RedisConfig.KEY_PATTERN,
                         RedisConfig.FORMAT,
-                        RedisConfig.EXPIRE)
+                        RedisConfig.EXPIRE,
+                        SinkCommonOptions.MULTI_TABLE_SINK_REPLICA)
                 .conditional(RedisConfig.MODE, RedisConfig.RedisMode.CLUSTER, RedisConfig.NODES)
                 .build();
     }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/oceanbase/OceanBaseDialectFactory.java
Patch:
@@ -19,7 +19,6 @@
 
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.JdbcDialect;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.JdbcDialectFactory;
-import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.mysql.MysqlDialect;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.oracle.OracleDialect;
 
 import com.google.auto.service.AutoService;
@@ -44,6 +43,6 @@ public JdbcDialect create(@Nonnull String compatibleMode, String fieldIde) {
         if ("oracle".equalsIgnoreCase(compatibleMode)) {
             return new OracleDialect();
         }
-        return new MysqlDialect();
+        return new OceanBaseMysqlDialect();
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/utils/JdbcCatalogUtils.java
Patch:
@@ -393,6 +393,8 @@ private static ReadonlyConfig extractCatalogConfig(JdbcConnectionConfig config)
                 .ifPresent(val -> catalogConfig.put(JdbcCatalogOptions.USERNAME.key(), val));
         config.getPassword()
                 .ifPresent(val -> catalogConfig.put(JdbcCatalogOptions.PASSWORD.key(), val));
+        Optional.ofNullable(config.getCompatibleMode())
+                .ifPresent(val -> catalogConfig.put(JdbcCatalogOptions.COMPATIBLE_MODE.key(), val));
         return ReadonlyConfig.fromMap(catalogConfig);
     }
 }

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/sink/writer/DorisStreamLoad.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
 
 import org.apache.seatunnel.api.table.catalog.TablePath;
+import org.apache.seatunnel.common.utils.ExceptionUtils;
 import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.connectors.doris.config.DorisConfig;
 import org.apache.seatunnel.connectors.doris.exception.DorisConnectorErrorCode;
@@ -196,7 +197,7 @@ public String getLoadFailedMsg() {
             try {
                 errorMessage = handlePreCommitResponse(pendingLoadFuture.get()).getMessage();
             } catch (Exception e) {
-                errorMessage = e.getMessage();
+                errorMessage = ExceptionUtils.getMessage(e);
             }
             recordStream.setErrorMessageByStreamLoad(errorMessage);
             return errorMessage;

File: seatunnel-connectors-v2/connector-hbase/src/main/java/org/apache/seatunnel/connectors/seatunnel/hbase/sink/HbaseSink.java
Patch:
@@ -79,7 +79,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                             "PluginName: %s, PluginType: %s, Message: %s",
                             getPluginName(), PluginType.SINK, result.getMsg()));
         }
-        this.hbaseParameters = HbaseParameters.buildWithConfig(pluginConfig);
+        this.hbaseParameters = HbaseParameters.buildWithSinkConfig(pluginConfig);
         if (hbaseParameters.getFamilyNames().size() == 0) {
             throw new HbaseConnectorException(
                     SeaTunnelAPIErrorCode.CONFIG_VALIDATION_FAILED,

File: seatunnel-connectors-v2/connector-hbase/src/main/java/org/apache/seatunnel/connectors/seatunnel/hbase/source/HbaseSourceFactory.java
Patch:
@@ -45,7 +45,6 @@ public OptionRule optionRule() {
         return OptionRule.builder()
                 .required(HbaseConfig.ZOOKEEPER_QUORUM)
                 .required(HbaseConfig.TABLE)
-                .required(HbaseConfig.QUERY_COLUMNS)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/util/HttpUtil.java
Patch:
@@ -21,6 +21,7 @@
 import org.apache.http.impl.client.DefaultRedirectStrategy;
 import org.apache.http.impl.client.HttpClientBuilder;
 import org.apache.http.impl.client.HttpClients;
+import org.apache.http.protocol.RequestContent;
 
 /** util to build http client. */
 public class HttpUtil {
@@ -32,7 +33,8 @@ public class HttpUtil {
                                 protected boolean isRedirectable(String method) {
                                     return true;
                                 }
-                            });
+                            })
+                    .addInterceptorLast(new RequestContent(true));;
 
     public CloseableHttpClient getHttpClient() {
         return httpClientBuilder.build();

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalVertex.java
Patch:
@@ -214,7 +214,7 @@ public PassiveCompletableFuture<TaskExecutionState> initStateFuture() {
             }
         } else if (ExecutionState.DEPLOYING.equals(currExecutionState)) {
             if (!checkTaskGroupIsExecuting(taskGroupLocation)) {
-                updateTaskState(ExecutionState.RUNNING);
+                updateTaskState(ExecutionState.FAILING);
             }
         }
         return new PassiveCompletableFuture<>(this.taskFuture);
@@ -485,6 +485,8 @@ private void resetExecutionState() {
                         () -> {
                             updateStateTimestamps(ExecutionState.CREATED);
                             runningJobStateIMap.set(taskGroupLocation, ExecutionState.CREATED);
+                            // reset the errorByPhysicalVertex
+                            errorByPhysicalVertex = new AtomicReference<>();
                             return null;
                         },
                         new RetryUtils.RetryMaterial(

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/CheckTaskGroupIsExecutingOperation.java
Patch:
@@ -46,7 +46,8 @@ public void run() {
         SeaTunnelServer server = getService();
         try {
             response =
-                    server.getTaskExecutionService().getExecutionContext(taskGroupLocation) != null;
+                    server.getTaskExecutionService().getActiveExecutionContext(taskGroupLocation)
+                            != null;
         } catch (TaskGroupContextNotFoundException e) {
             response = false;
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/saphana/SapHanaTypeConverter.java
Patch:
@@ -255,7 +255,7 @@ public Column convert(BasicTypeDefine typeDefine) {
                     builder.dataType(new DecimalType((int) precision, MAX_SCALE));
                     builder.columnLength(precision);
                     builder.scale(MAX_SCALE);
-                } else if (scale <= 0) {
+                } else if (scale < 0) {
                     int newPrecision = (int) (precision - scale);
                     if (newPrecision == 1) {
                         builder.dataType(BasicType.SHORT_TYPE);

File: seatunnel-connectors-v2/connector-maxcompute/src/main/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/sink/MaxcomputeSink.java
Patch:
@@ -59,6 +59,6 @@ public void setTypeInfo(SeaTunnelRowType seaTunnelRowType) {
 
     @Override
     public AbstractSinkWriter<SeaTunnelRow, Void> createWriter(SinkWriter.Context context) {
-        return new MaxcomputeWriter(this.pluginConfig);
+        return new MaxcomputeWriter(this.pluginConfig, this.typeInfo);
     }
 }

File: seatunnel-connectors-v2/connector-maxcompute/src/test/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/BasicTypeToOdpsTypeTest.java
Patch:
@@ -53,7 +53,8 @@ private static void testType(
         }
 
         SeaTunnelRow seaTunnelRow = MaxcomputeTypeMapper.getSeaTunnelRowData(record, typeInfo);
-        Record tRecord = MaxcomputeTypeMapper.getMaxcomputeRowData(seaTunnelRow, tableSchema);
+        Record tRecord =
+                MaxcomputeTypeMapper.getMaxcomputeRowData(seaTunnelRow, tableSchema, typeInfo);
 
         for (int i = 0; i < tRecord.getColumns().length; i++) {
             Assertions.assertEquals(record.get(i), tRecord.get(i));

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/classloader/ClassLoaderITBase.java
Patch:
@@ -68,7 +68,7 @@ public void testFakeSourceToInMemorySink() throws IOException, InterruptedExcept
             if (cacheMode()) {
                 Assertions.assertTrue(3 >= getClassLoaderCount());
             } else {
-                Assertions.assertTrue(2 + i >= getClassLoaderCount());
+                Assertions.assertTrue(3 + 2 * i >= getClassLoaderCount());
             }
         }
     }

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-iceberg-s3-e2e/src/test/java/org/apache/seatunnel/e2e/connector/iceberg/s3/IcebergSourceIT.java
Patch:
@@ -112,7 +112,7 @@ public class IcebergSourceIT extends TestSuiteBase implements TestResource {
                 Assertions.assertEquals(0, extraCommands.getExitCode());
             };
 
-    private static final String MINIO_DOCKER_IMAGE = "minio/minio";
+    private static final String MINIO_DOCKER_IMAGE = "minio/minio:RELEASE.2024-06-13T22-53-53Z";
     private static final String HOST = "minio";
     private static final int MINIO_PORT = 9000;
 

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/sink/inmemory/InMemorySink.java
Patch:
@@ -68,7 +68,7 @@ public Optional<Serializer<InMemoryCommitInfo>> getCommitInfoSerializer() {
     @Override
     public Optional<SinkAggregatedCommitter<InMemoryCommitInfo, InMemoryAggregatedCommitInfo>>
             createAggregatedCommitter() throws IOException {
-        return Optional.of(new InMemoryAggregatedCommitter());
+        return Optional.of(new InMemoryAggregatedCommitter(config));
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -293,6 +293,9 @@ private void handleCoordinatorError(CheckpointCloseReason reason, Throwable e) {
     private void restoreTaskState(TaskLocation taskLocation) {
         List<ActionSubtaskState> states = new ArrayList<>();
         if (latestCompletedCheckpoint != null) {
+            if (!latestCompletedCheckpoint.isRestored()) {
+                latestCompletedCheckpoint.setRestored(true);
+            }
             final Integer currentParallelism = pipelineTasks.get(taskLocation.getTaskVertexId());
             plan.getSubtaskActions()
                     .get(taskLocation)

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CompletedCheckpoint.java
Patch:
@@ -46,7 +46,7 @@ public class CompletedCheckpoint implements Checkpoint, Serializable {
 
     private final Map<Long, TaskStatistics> taskStatistics;
 
-    @Getter @Setter private boolean isRestored = false;
+    @Getter @Setter private volatile boolean isRestored = false;
 
     public CompletedCheckpoint(
             long jobId,

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/catalog/ElasticSearchCatalog.java
Patch:
@@ -217,8 +217,7 @@ public void dropDatabase(TablePath tablePath, boolean ignoreIfNotExists)
 
     @Override
     public void truncateTable(TablePath tablePath, boolean ignoreIfNotExists) {
-        dropTable(tablePath, ignoreIfNotExists);
-        createTable(tablePath, null, ignoreIfNotExists);
+        esRestClient.clearIndexData(tablePath.getTableName());
     }
 
     @Override

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/exception/ElasticsearchConnectorErrorCode.java
Patch:
@@ -28,7 +28,8 @@ public enum ElasticsearchConnectorErrorCode implements SeaTunnelErrorCode {
     LIST_INDEX_FAILED("ELASTICSEARCH-05", "List elasticsearch index failed"),
     DROP_INDEX_FAILED("ELASTICSEARCH-06", "Drop elasticsearch index failed"),
     CREATE_INDEX_FAILED("ELASTICSEARCH-07", "Create elasticsearch index failed"),
-    ES_FIELD_TYPE_NOT_SUPPORT("ELASTICSEARCH-08", "Not support the elasticsearch field type");
+    ES_FIELD_TYPE_NOT_SUPPORT("ELASTICSEARCH-08", "Not support the elasticsearch field type"),
+    CLEAR_INDEX_DATA_FAILED("ELASTICSEARCH-09", "Clear elasticsearch index data failed");
     ;
 
     private final String code;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/dialect/JdbcDataSourceDialect.java
Patch:
@@ -99,6 +99,7 @@ default Optional<PrimaryKey> getPrimaryKey(JdbcConnection jdbcConnection, TableI
                 primaryKeyColumns.stream()
                         .sorted(Comparator.comparingInt(Pair::getKey))
                         .map(Pair::getValue)
+                        .distinct()
                         .collect(Collectors.toList());
         if (CollectionUtils.isEmpty(pkFields)) {
             return Optional.empty();

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/utils/CatalogUtils.java
Patch:
@@ -128,6 +128,7 @@ public static Optional<PrimaryKey> getPrimaryKey(DatabaseMetaData metaData, Tabl
                 primaryKeyColumns.stream()
                         .sorted(Comparator.comparingInt(Pair::getKey))
                         .map(Pair::getValue)
+                        .distinct()
                         .collect(Collectors.toList());
         if (CollectionUtils.isEmpty(pkFields)) {
             return Optional.empty();

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-common/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcCase.java
Patch:
@@ -52,6 +52,7 @@ public class JdbcCase {
     private List<String> configFile;
     private Pair<String[], List<SeaTunnelRow>> testData;
     private Map<String, String> containerEnv;
+    private boolean useSaveModeCreateTable;
 
     private String catalogDatabase;
     private String catalogSchema;

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/seatunnel/SeaTunnelContainer.java
Patch:
@@ -431,7 +431,9 @@ private boolean isIssueWeAlreadyKnow(String threadName) {
                 // Iceberg S3 Hadoop catalog
                 || threadName.contains("java-sdk-http-connection-reaper")
                 || threadName.contains("Timer for 's3a-file-system' metrics system")
-                || threadName.startsWith("MutableQuantiles-");
+                || threadName.startsWith("MutableQuantiles-")
+                // JDBC Hana driver
+                || threadName.startsWith("Thread-");
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManager.java
Patch:
@@ -166,9 +166,9 @@ public PassiveCompletableFuture<CompletedCheckpoint>[] triggerSavePoints() {
     }
 
     public void reportedPipelineRunning(int pipelineId, boolean alreadyStarted) {
-        log.info(
-                "reported pipeline running stack: "
-                        + Arrays.toString(Thread.currentThread().getStackTrace()));
+        log.debug(
+                "reported pipeline running stack: {}",
+                Arrays.toString(Thread.currentThread().getStackTrace()));
         getCheckpointCoordinator(pipelineId).restoreCoordinator(alreadyStarted);
     }
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/env/EnvCommonOptions.java
Patch:
@@ -77,6 +77,7 @@ public interface EnvCommonOptions {
                     .noDefaultValue()
                     .withDescription(
                             "The each parallelism bytes limit per second for read data from source.");
+
     Option<Long> CHECKPOINT_TIMEOUT =
             Options.key("checkpoint.timeout")
                     .longType()

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/rest/RestJobExecutionEnvironment.java
Patch:
@@ -31,6 +31,7 @@
 
 import org.apache.commons.lang3.tuple.ImmutablePair;
 
+import com.google.common.annotations.VisibleForTesting;
 import com.hazelcast.instance.impl.Node;
 import com.hazelcast.spi.impl.NodeEngineImpl;
 
@@ -77,8 +78,9 @@ public Long getJobId() {
         return jobId;
     }
 
+    @VisibleForTesting
     @Override
-    protected LogicalDag getLogicalDag() {
+    public LogicalDag getLogicalDag() {
         ImmutablePair<List<Action>, Set<URL>> immutablePair =
                 getJobConfigParser().parse(seaTunnelServer.getClassLoaderService());
         actions.addAll(immutablePair.getLeft());

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/debezium/row/SeaTunnelRowDebeziumDeserializeSchema.java
Patch:
@@ -184,7 +184,7 @@ private void deserializeDataChangeRecord(SourceRecord record, Collector<SeaTunne
             delete.setRowKind(RowKind.DELETE);
             delete.setTableId(tableId);
             collector.collect(delete);
-        } else {
+        } else if (operation == Envelope.Operation.UPDATE) {
             SeaTunnelRow before = extractBeforeRow(converters, record, messageStruct, valueSchema);
             before.setRowKind(RowKind.UPDATE_BEFORE);
             before.setTableId(tableId);
@@ -194,6 +194,8 @@ private void deserializeDataChangeRecord(SourceRecord record, Collector<SeaTunne
             after.setRowKind(RowKind.UPDATE_AFTER);
             after.setTableId(tableId);
             collector.collect(after);
+        } else {
+            log.warn("Received {} operation, skip", operation);
         }
     }
 

File: seatunnel-connectors-v2/connector-rabbitmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rabbitmq/source/RabbitmqSplitEnumerator.java
Patch:
@@ -60,8 +60,8 @@ public void registerReader(int subtaskId) {
     }
 
     @Override
-    public Object snapshotState(long checkpointId) throws Exception {
-        return null;
+    public RabbitmqSourceState snapshotState(long checkpointId) throws Exception {
+        return new RabbitmqSourceState();
     }
 
     @Override

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceIT.java
Patch:
@@ -839,6 +839,7 @@ public void testStreamJobRestoreInAllNodeDown() throws Exception {
             // shutdown all node
             node1.shutdown();
             node2.shutdown();
+            engineClient.close();
 
             log.warn(
                     "==========================================All node is done========================================");

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/HadoopConf.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.config;
 
+import org.apache.commons.lang3.StringUtils;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.CommonConfigurationKeys;
 import org.apache.hadoop.fs.Path;
@@ -62,7 +63,7 @@ public void setExtraOptionsForConfiguration(Configuration configuration) {
             removeUnwantedOverwritingProps(extraOptions);
             extraOptions.forEach(configuration::set);
         }
-        if (hdfsSitePath != null) {
+        if (StringUtils.isNotBlank(hdfsSitePath)) {
             Configuration hdfsSiteConfiguration = new Configuration();
             hdfsSiteConfiguration.addResource(new Path(hdfsSitePath));
             unsetUnwantedOverwritingProps(hdfsSiteConfiguration);

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/exception/HiveConnectorErrorCode.java
Patch:
@@ -25,6 +25,7 @@ public enum HiveConnectorErrorCode implements SeaTunnelErrorCode {
     GET_HIVE_TABLE_INFORMATION_FAILED(
             "HIVE-03", "Get hive table information from hive metastore service failed"),
     HIVE_TABLE_NAME_ERROR("HIVE-04", "Hive table name is invalid"),
+    LOAD_HIVE_BASE_HADOOP_CONFIG_FAILED("HIVE-05", "Load hive base hadoop config failed"),
     ;
 
     private final String code;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/reader/fetch/MySqlSourceFetchTaskContext.java
Patch:
@@ -30,6 +30,7 @@
 import org.apache.seatunnel.connectors.cdc.debezium.EmbeddedDatabaseHistory;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.config.MySqlSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.offset.BinlogOffset;
+import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.utils.MySqlConnectionUtils;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.utils.MySqlUtils;
 
 import org.apache.kafka.connect.data.Struct;
@@ -120,7 +121,8 @@ public void configure(SourceSplitBase sourceSplitBase) {
         this.topicSelector = MySqlTopicSelector.defaultSelector(connectorConfig);
 
         this.databaseSchema =
-                MySqlUtils.createMySqlDatabaseSchema(connectorConfig, tableIdCaseInsensitive);
+                MySqlConnectionUtils.createMySqlDatabaseSchema(
+                        connectorConfig, tableIdCaseInsensitive);
         this.offsetContext =
                 loadStartingOffsetState(
                         new MySqlOffsetContext.Loader(connectorConfig), sourceSplitBase);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/utils/MySqlConnectionUtils.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.cdc.mysql.utils;
 
 import org.apache.seatunnel.common.utils.SeaTunnelException;
+import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.config.CustomMySqlConnectionConfiguration;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.offset.BinlogOffset;
 
 import com.github.shyiko.mysql.binlog.BinaryLogClient;
@@ -44,8 +45,7 @@ public class MySqlConnectionUtils {
 
     /** Creates a new {@link MySqlConnection}, but not open the connection. */
     public static MySqlConnection createMySqlConnection(Configuration dbzConfiguration) {
-        return new MySqlConnection(
-                new MySqlConnection.MySqlConnectionConfiguration(dbzConfiguration));
+        return new MySqlConnection(new CustomMySqlConnectionConfiguration(dbzConfiguration));
     }
 
     /** Creates a new {@link BinaryLogClient} for consuming mysql binlog. */

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobHistoryService.java
Patch:
@@ -249,7 +249,7 @@ public static final class JobState implements Serializable {
         private Long jobId;
         private String jobName;
         private JobStatus jobStatus;
-        private Long submitTime;
+        private long submitTime;
         private Long finishTime;
         private Map<PipelineLocation, PipelineStateData> pipelineStateMapperMap;
         private String errorMessage;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerCreateTableSqlBuilder.java
Patch:
@@ -207,7 +207,7 @@ private String buildColumnIdentifySql(
 
         // comment
         if (column.getComment() != null) {
-            columnComments.put(column.getName(), column.getComment());
+            columnComments.put(column.getName(), column.getComment().replace("'", "''"));
         }
 
         return String.join(" ", columnSqls);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/psql/PostgresCreateTableSqlBuilder.java
Patch:
@@ -151,7 +151,7 @@ private String buildColumnCommentSql(Column column, String tableName) {
         columnCommentSql
                 .append(CatalogUtils.quoteIdentifier(column.getName(), fieldIde, "\""))
                 .append(CatalogUtils.quoteIdentifier(" IS '", fieldIde))
-                .append(column.getComment())
+                .append(column.getComment().replace("'", "''"))
                 .append("'");
         return columnCommentSql.toString();
     }

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/serde/BsonToRowDataConverters.java
Patch:
@@ -353,7 +353,7 @@ private static boolean convertToBoolean(BsonValue bsonValue) {
     }
 
     private static double convertToDouble(BsonValue bsonValue) {
-        if (bsonValue.isDouble()) {
+        if (bsonValue.isNumber()) {
             return bsonValue.asNumber().doubleValue();
         }
         throw new MongodbConnectorException(

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/TaskExecutionService.java
Patch:
@@ -627,7 +627,7 @@ private void updateMetricsContextInImap() {
             try {
                 if (!metricsImap.tryLock(
                         Constant.IMAP_RUNNING_JOB_METRICS_KEY, 2, TimeUnit.SECONDS)) {
-                    logger.info("try lock failed in update metrics");
+                    logger.warning("try lock failed in update metrics");
                     return;
                 }
                 HashMap<TaskLocation, SeaTunnelMetricsContext> centralMap =
@@ -953,6 +953,7 @@ void taskDone(Task task) {
                         taskGroupLocation, executionContexts.remove(taskGroupLocation));
                 cancellationFutures.remove(taskGroupLocation);
                 cancelAsyncFunction(taskGroupLocation);
+                updateMetricsContextInImap();
                 if (ex == null) {
                     future.complete(
                             new TaskExecutionState(taskGroupLocation, ExecutionState.FINISHED));

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -609,7 +609,8 @@ public void savePipelineMetricsToHistory(PipelineLocation pipelineLocation) {
 
     public void removeMetricsContext(
             PipelineLocation pipelineLocation, PipelineStatus pipelineStatus) {
-        if (pipelineStatus.equals(PipelineStatus.FINISHED) && !checkpointManager.isSavePointEnd()
+        if ((pipelineStatus.equals(PipelineStatus.FINISHED)
+                        && !checkpointManager.isPipelineSavePointEnd(pipelineLocation))
                 || pipelineStatus.equals(PipelineStatus.CANCELED)) {
             try {
                 metricsImap.lock(Constant.IMAP_RUNNING_JOB_METRICS_KEY);

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/HadoopConf.java
Patch:
@@ -29,7 +29,6 @@
 
 import static org.apache.parquet.avro.AvroReadSupport.READ_INT96_AS_FIXED;
 import static org.apache.parquet.avro.AvroSchemaConverter.ADD_LIST_ELEMENT_RECORDS;
-import static org.apache.parquet.avro.AvroWriteSupport.WRITE_FIXED_AS_INT96;
 import static org.apache.parquet.avro.AvroWriteSupport.WRITE_OLD_LIST_STRUCTURE;
 
 @Data
@@ -86,7 +85,6 @@ public void unsetUnwantedOverwritingProps(Configuration hdfsSiteConfiguration) {
     public Configuration toConfiguration() {
         Configuration configuration = new Configuration();
         configuration.setBoolean(READ_INT96_AS_FIXED, true);
-        configuration.setBoolean(WRITE_FIXED_AS_INT96, true);
         configuration.setBoolean(ADD_LIST_ELEMENT_RECORDS, false);
         configuration.setBoolean(WRITE_OLD_LIST_STRUCTURE, true);
         configuration.setBoolean(getHdfsImplDisableCacheKey(), true);

File: seatunnel-connectors-v2/connector-file/connector-file-cos/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/cos/sink/CosFileSinkFactory.java
Patch:
@@ -66,7 +66,9 @@ public OptionRule optionRule() {
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.PARQUET,
-                        BaseSinkConfig.PARQUET_COMPRESS)
+                        BaseSinkConfig.PARQUET_COMPRESS,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_FIXED_AS_INT96,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_TIMESTAMP_AS_INT96)
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.XML,

File: seatunnel-connectors-v2/connector-file/connector-file-ftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/ftp/sink/FtpFileSinkFactory.java
Patch:
@@ -66,7 +66,9 @@ public OptionRule optionRule() {
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.PARQUET,
-                        BaseSinkConfig.PARQUET_COMPRESS)
+                        BaseSinkConfig.PARQUET_COMPRESS,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_FIXED_AS_INT96,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_TIMESTAMP_AS_INT96)
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.XML,

File: seatunnel-connectors-v2/connector-file/connector-file-hadoop/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/hdfs/sink/HdfsFileSinkFactory.java
Patch:
@@ -63,7 +63,9 @@ public OptionRule optionRule() {
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.PARQUET,
-                        BaseSinkConfig.PARQUET_COMPRESS)
+                        BaseSinkConfig.PARQUET_COMPRESS,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_FIXED_AS_INT96,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_TIMESTAMP_AS_INT96)
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.XML,

File: seatunnel-connectors-v2/connector-file/connector-file-jindo-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/jindo/sink/OssFileSinkFactory.java
Patch:
@@ -66,7 +66,9 @@ public OptionRule optionRule() {
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.PARQUET,
-                        BaseSinkConfig.PARQUET_COMPRESS)
+                        BaseSinkConfig.PARQUET_COMPRESS,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_FIXED_AS_INT96,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_TIMESTAMP_AS_INT96)
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.XML,

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/LocalFileSinkFactory.java
Patch:
@@ -69,7 +69,9 @@ public OptionRule optionRule() {
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.PARQUET,
-                        BaseSinkConfig.PARQUET_COMPRESS)
+                        BaseSinkConfig.PARQUET_COMPRESS,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_FIXED_AS_INT96,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_TIMESTAMP_AS_INT96)
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.XML,

File: seatunnel-connectors-v2/connector-file/connector-file-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/sink/OssFileSinkFactory.java
Patch:
@@ -80,7 +80,9 @@ public OptionRule optionRule() {
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.PARQUET,
-                        BaseSinkConfig.PARQUET_COMPRESS)
+                        BaseSinkConfig.PARQUET_COMPRESS,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_FIXED_AS_INT96,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_TIMESTAMP_AS_INT96)
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.XML,

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/sink/S3FileSinkFactory.java
Patch:
@@ -85,7 +85,9 @@ public OptionRule optionRule() {
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.PARQUET,
-                        BaseSinkConfig.PARQUET_COMPRESS)
+                        BaseSinkConfig.PARQUET_COMPRESS,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_FIXED_AS_INT96,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_TIMESTAMP_AS_INT96)
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.XML,

File: seatunnel-connectors-v2/connector-file/connector-file-sftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sftp/sink/SftpFileSinkFactory.java
Patch:
@@ -66,7 +66,9 @@ public OptionRule optionRule() {
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.PARQUET,
-                        BaseSinkConfig.PARQUET_COMPRESS)
+                        BaseSinkConfig.PARQUET_COMPRESS,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_FIXED_AS_INT96,
+                        BaseSinkConfig.PARQUET_AVRO_WRITE_TIMESTAMP_AS_INT96)
                 .conditional(
                         BaseSinkConfig.FILE_FORMAT_TYPE,
                         FileFormat.XML,

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaConsumerThread.java
Patch:
@@ -45,7 +45,7 @@ public KafkaConsumerThread(KafkaSourceConfig kafkaSourceConfig, ConsumerMetadata
                         kafkaSourceConfig.getBootstrap(),
                         metadata.getConsumerGroup(),
                         kafkaSourceConfig.getProperties(),
-                        kafkaSourceConfig.isCommitOnCheckpoint());
+                        !kafkaSourceConfig.isCommitOnCheckpoint());
     }
 
     @Override

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/utils/HiveMetaStoreProxy.java
Patch:
@@ -56,9 +56,11 @@ private HiveMetaStoreProxy(ReadonlyConfig readonlyConfig) {
                 hiveConf.addResource(new File(hiveSitePath).toURI().toURL());
             }
             if (HiveMetaStoreProxyUtils.enableKerberos(readonlyConfig)) {
+                Configuration hadoopConfig = new Configuration();
+                hadoopConfig.set("hadoop.security.authentication", "kerberos");
                 this.hiveMetaStoreClient =
                         HadoopLoginFactory.loginWithKerberos(
-                                new Configuration(),
+                                hadoopConfig,
                                 readonlyConfig.get(BaseSourceConfigOptions.KRB5_PATH),
                                 readonlyConfig.get(BaseSourceConfigOptions.KERBEROS_PRINCIPAL),
                                 readonlyConfig.get(BaseSourceConfigOptions.KERBEROS_KEYTAB_PATH),

File: seatunnel-connectors-v2/connector-paimon/src/main/java/org/apache/seatunnel/connectors/seatunnel/paimon/config/PaimonConfig.java
Patch:
@@ -48,6 +48,8 @@
 @Getter
 public class PaimonConfig implements Serializable {
 
+    public static final String CONNECTOR_IDENTITY = "Paimon";
+
     public static final Option<String> WAREHOUSE =
             Options.key("warehouse")
                     .stringType()

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -180,7 +180,7 @@ public JobMaster(
         this.seaTunnelServer = seaTunnelServer;
     }
 
-    public void init(long initializationTimestamp, boolean restart) throws Exception {
+    public synchronized void init(long initializationTimestamp, boolean restart) throws Exception {
         jobImmutableInformation =
                 nodeEngine.getSerializationService().toObject(jobImmutableInformationData);
         jobCheckpointConfig =
@@ -490,7 +490,7 @@ public Address queryTaskGroupAddress(TaskGroupLocation taskGroupLocation) {
                 "can't find task group address from taskGroupLocation: " + taskGroupLocation);
     }
 
-    public void cancelJob() {
+    public synchronized void cancelJob() {
         physicalPlan.cancelJob();
     }
 

File: seatunnel-connectors-v2/connector-paimon/src/main/java/org/apache/seatunnel/connectors/seatunnel/paimon/sink/PaimonSinkWriter.java
Patch:
@@ -89,7 +89,7 @@ public PaimonSinkWriter(
         this.table = table;
         this.tableWriteBuilder =
                 JobContextUtil.isBatchJob(jobContext)
-                        ? this.table.newBatchWriteBuilder().withOverwrite()
+                        ? this.table.newBatchWriteBuilder()
                         : this.table.newStreamWriteBuilder();
         this.tableWrite = tableWriteBuilder.newWrite();
         this.seaTunnelRowType = seaTunnelRowType;

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointStorageTest.java
Patch:
@@ -77,7 +77,7 @@ public void testGenerateFileWhenSavepoint()
                                                 .getJobStatus(jobId)
                                                 .equals(JobStatus.RUNNING)));
         Thread.sleep(1000);
-        CompletableFuture<Void> future1 =
+        CompletableFuture<Boolean> future1 =
                 server.getCoordinatorService().getJobMaster(jobId).savePoint();
         future1.join();
         await().atMost(120000, TimeUnit.MILLISECONDS)

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/SavePointTest.java
Patch:
@@ -82,8 +82,7 @@ public void testSavePointButJobGoingToFail() throws InterruptedException {
         } catch (Exception e) {
             errorCount++;
         }
-        // we should make sure only one savepoint success in the same time
-        Assertions.assertEquals(2, errorCount);
+        Assertions.assertEquals(3, errorCount);
         await().atMost(120, TimeUnit.SECONDS)
                 .untilAsserted(
                         () ->

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/splitter/AbstractJdbcSourceChunkSplitter.java
Patch:
@@ -114,7 +114,7 @@ public Collection<SnapshotSplit> generateSplits(TableId tableId) {
     }
 
     private List<ChunkRange> splitTableIntoChunks(
-            JdbcConnection jdbc, TableId tableId, Column splitColumn) throws SQLException {
+            JdbcConnection jdbc, TableId tableId, Column splitColumn) throws Exception {
         final String splitColumnName = splitColumn.name();
         final Object[] minMax = queryMinMax(jdbc, tableId, splitColumn);
         final Object min = minMax[0];

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/splitter/JdbcSourceChunkSplitter.java
Patch:
@@ -81,7 +81,7 @@ default Object queryMin(
     @Deprecated
     Object[] sampleDataFromColumn(
             JdbcConnection jdbc, TableId tableId, String columnName, int samplingRate)
-            throws SQLException;
+            throws Exception;
 
     /**
      * Performs a sampling operation on the specified column of a table in a JDBC-connected
@@ -97,7 +97,7 @@ Object[] sampleDataFromColumn(
      */
     default Object[] sampleDataFromColumn(
             JdbcConnection jdbc, TableId tableId, Column column, int samplingRate)
-            throws SQLException {
+            throws Exception {
         return sampleDataFromColumn(jdbc, tableId, column.name(), samplingRate);
     }
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/test/java/jdbc/source/JdbcSourceChunkSplitterTest.java
Patch:
@@ -83,7 +83,7 @@ public Object queryMin(
         @Override
         public Object[] sampleDataFromColumn(
                 JdbcConnection jdbc, TableId tableId, String columnName, int samplingRate)
-                throws SQLException {
+                throws Exception {
             return new Object[0];
         }
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/test/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/splitter/AbstractJdbcSourceChunkSplitterTest.java
Patch:
@@ -195,7 +195,7 @@ public Object queryMin(
         @Override
         public Object[] sampleDataFromColumn(
                 JdbcConnection jdbc, TableId tableId, String columnName, int samplingRate)
-                throws SQLException {
+                throws Exception {
             return new Object[0];
         }
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/eumerator/MySqlChunkSplitter.java
Patch:
@@ -57,7 +57,7 @@ public Object queryMin(
     @Override
     public Object[] sampleDataFromColumn(
             JdbcConnection jdbc, TableId tableId, String columnName, int inverseSamplingRate)
-            throws SQLException {
+            throws Exception {
         return MySqlUtils.skipReadAndSortSampleData(jdbc, tableId, columnName, inverseSamplingRate);
     }
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-oracle/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/oracle/source/eumerator/OracleChunkSplitter.java
Patch:
@@ -61,7 +61,7 @@ public Object queryMin(
     @Override
     public Object[] sampleDataFromColumn(
             JdbcConnection jdbc, TableId tableId, String columnName, int inverseSamplingRate)
-            throws SQLException {
+            throws Exception {
         return OracleUtils.skipReadAndSortSampleData(
                 jdbc, tableId, columnName, inverseSamplingRate);
     }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-postgres/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/postgres/source/enumerator/PostgresChunkSplitter.java
Patch:
@@ -70,15 +70,15 @@ public Object queryMin(
     @Override
     public Object[] sampleDataFromColumn(
             JdbcConnection jdbc, TableId tableId, String columnName, int inverseSamplingRate)
-            throws SQLException {
+            throws Exception {
         return PostgresUtils.skipReadAndSortSampleData(
                 jdbc, tableId, columnName, null, inverseSamplingRate);
     }
 
     @Override
     public Object[] sampleDataFromColumn(
             JdbcConnection jdbc, TableId tableId, Column column, int inverseSamplingRate)
-            throws SQLException {
+            throws Exception {
         return PostgresUtils.skipReadAndSortSampleData(
                 jdbc, tableId, column.name(), column, inverseSamplingRate);
     }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/eumerator/SqlServerChunkSplitter.java
Patch:
@@ -57,7 +57,7 @@ public Object queryMin(
     @Override
     public Object[] sampleDataFromColumn(
             JdbcConnection jdbc, TableId tableId, String columnName, int inverseSamplingRate)
-            throws SQLException {
+            throws Exception {
         return SqlServerUtils.skipReadAndSortSampleData(
                 jdbc, tableId, columnName, inverseSamplingRate);
     }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/ChunkSplitter.java
Patch:
@@ -85,7 +85,7 @@ public synchronized void close() {
         }
     }
 
-    public Collection<JdbcSourceSplit> generateSplits(JdbcSourceTable table) throws SQLException {
+    public Collection<JdbcSourceSplit> generateSplits(JdbcSourceTable table) throws Exception {
         log.info("Start splitting table {} into chunks...", table.getTablePath());
         long start = System.currentTimeMillis();
 
@@ -111,7 +111,7 @@ public Collection<JdbcSourceSplit> generateSplits(JdbcSourceTable table) throws
     }
 
     protected abstract Collection<JdbcSourceSplit> createSplits(
-            JdbcSourceTable table, SeaTunnelRowType splitKeyType) throws SQLException;
+            JdbcSourceTable table, SeaTunnelRowType splitKeyType) throws SQLException, Exception;
 
     public PreparedStatement generateSplitStatement(JdbcSourceSplit split, TableSchema schema)
             throws SQLException {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-1/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcOracleIT.java
Patch:
@@ -40,7 +40,6 @@
 
 import java.math.BigDecimal;
 import java.sql.Date;
-import java.sql.SQLException;
 import java.sql.Timestamp;
 import java.time.LocalDate;
 import java.time.LocalDateTime;
@@ -104,7 +103,7 @@ public class JdbcOracleIT extends AbstractJdbcIT {
             };
 
     @Test
-    public void testSampleDataFromColumnSuccess() throws SQLException {
+    public void testSampleDataFromColumnSuccess() throws Exception {
         JdbcDialect dialect = new OracleDialect();
         JdbcSourceTable table =
                 JdbcSourceTable.builder()

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-7/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcIrisIT.java
Patch:
@@ -288,7 +288,7 @@ public class JdbcIrisIT extends AbstractJdbcIT {
             };
 
     @Test
-    public void testSampleDataFromColumnSuccess() throws SQLException {
+    public void testSampleDataFromColumnSuccess() throws Exception {
         JdbcDialect dialect = new IrisDialect();
         JdbcSourceTable table =
                 JdbcSourceTable.builder()

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-7/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcMysqlSplitIT.java
Patch:
@@ -468,7 +468,7 @@ public void testSplit() throws Exception {
 
     private JdbcSourceSplit[] getCheckedSplitArray(
             Map<String, Object> configMap, CatalogTable table, String splitKey, int splitNum)
-            throws SQLException {
+            throws Exception {
         configMap.put("partition_column", splitKey);
         DynamicChunkSplitter splitter = getDynamicChunkSplitter(configMap);
 

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/rest/RestService.java
Patch:
@@ -237,7 +237,8 @@ static String[] parseIdentifier(String tableIdentifier, Logger logger)
     }
 
     @VisibleForTesting
-    static String randomEndpoint(String feNodes, Logger logger) throws DorisConnectorException {
+    public static String randomEndpoint(String feNodes, Logger logger)
+            throws DorisConnectorException {
         logger.trace("Parse fenodes '{}'.", feNodes);
         if (StringUtils.isEmpty(feNodes)) {
             String errMsg =

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/sink/writer/DorisSinkWriter.java
Patch:
@@ -25,6 +25,7 @@
 import org.apache.seatunnel.connectors.doris.config.DorisConfig;
 import org.apache.seatunnel.connectors.doris.exception.DorisConnectorErrorCode;
 import org.apache.seatunnel.connectors.doris.exception.DorisConnectorException;
+import org.apache.seatunnel.connectors.doris.rest.RestService;
 import org.apache.seatunnel.connectors.doris.rest.models.RespContent;
 import org.apache.seatunnel.connectors.doris.serialize.DorisSerializer;
 import org.apache.seatunnel.connectors.doris.serialize.SeaTunnelRowSerializer;
@@ -96,7 +97,7 @@ public DorisSinkWriter(
     }
 
     private void initializeLoad() {
-        String backend = dorisConfig.getFrontends();
+        String backend = RestService.randomEndpoint(dorisConfig.getFrontends(), log);
         try {
             this.dorisStreamLoad =
                     new DorisStreamLoad(

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-15-starter/src/test/java/org/apache/seatunnel/core/starter/flink/multitable/MultiTableSinkTest.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.e2e.sink.inmemory.InMemorySinkWriter;
 
 import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Order;
 import org.junit.jupiter.api.Test;
 
 import java.io.FileNotFoundException;
@@ -34,6 +35,7 @@
 import java.util.Collections;
 import java.util.List;
 
+@Order(1)
 public class MultiTableSinkTest {
 
     @Test

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-3-starter/src/test/java/org/apache/seatunnel/core/starter/spark/multitable/MultiTableSinkTest.java
Patch:
@@ -25,6 +25,7 @@
 import org.apache.seatunnel.e2e.sink.inmemory.InMemorySinkWriter;
 
 import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Order;
 import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.condition.DisabledOnJre;
 import org.junit.jupiter.api.condition.JRE;
@@ -40,6 +41,7 @@
 import java.util.List;
 
 @Slf4j
+@Order(1)
 public class MultiTableSinkTest {
 
     @Test

File: seatunnel-core/seatunnel-starter/src/test/java/org/apache/seatunnel/core/starter/seatunnel/multitable/MultiTableSinkTest.java
Patch:
@@ -25,6 +25,7 @@
 import org.apache.seatunnel.e2e.sink.inmemory.InMemorySinkWriter;
 
 import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Order;
 import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.condition.DisabledOnOs;
 import org.junit.jupiter.api.condition.OS;
@@ -37,6 +38,7 @@
 import java.util.Collections;
 import java.util.List;
 
+@Order(1)
 public class MultiTableSinkTest {
 
     @Test

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/ClientJobProxy.java
Patch:
@@ -101,14 +101,13 @@ public JobResult waitForJobCompleteV2() {
                             new RetryUtils.RetryMaterial(
                                     100000,
                                     true,
-                                    exception ->
-                                            ExceptionUtil.isOperationNeedRetryException(exception),
+                                    ExceptionUtil::isOperationNeedRetryException,
                                     Constant.OPERATION_RETRY_SLEEP));
             if (jobResult == null) {
                 throw new SeaTunnelEngineException("failed to fetch job result");
             }
         } catch (Exception e) {
-            LOGGER.info(
+            LOGGER.severe(
                     String.format(
                             "Job (%s) end with unknown state, and throw Exception: %s",
                             jobId, ExceptionUtils.getMessage(e)));

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/PendingCheckpoint.java
Patch:
@@ -153,7 +153,7 @@ public void acknowledgeTask(
     }
 
     protected boolean isFullyAcknowledged() {
-        return notYetAcknowledgedTasks.size() == 0;
+        return notYetAcknowledgedTasks.isEmpty();
     }
 
     private CompletedCheckpoint toCompletedCheckpoint() {

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SaveModePlaceHolder.java
Patch:
@@ -23,6 +23,7 @@
 public enum SaveModePlaceHolder {
     ROWTYPE_PRIMARY_KEY("rowtype_primary_key", "primary keys"),
     ROWTYPE_UNIQUE_KEY("rowtype_unique_key", "unique keys"),
+    ROWTYPE_DUPLICATE_KEY("rowtype_duplicate_key", "duplicate keys"),
     ROWTYPE_FIELDS("rowtype_fields", "fields"),
     TABLE_NAME("table_name", "table name"),
     DATABASE("database", "database");

File: seatunnel-connectors-v2/connector-amazondynamodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/amazondynamodb/serialize/DefaultSeaTunnelRowSerializer.java
Patch:
@@ -18,7 +18,6 @@
 package org.apache.seatunnel.connectors.seatunnel.amazondynamodb.serialize;
 
 import org.apache.seatunnel.api.table.type.ArrayType;
-import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.MapType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
@@ -171,7 +170,7 @@ private AttributeValue convertItem(
                 return AttributeValue.builder().m(resultMap).build();
             case L:
                 ArrayType<?, ?> arrayType = (ArrayType<?, ?>) seaTunnelDataType;
-                BasicType<?> elementType = arrayType.getElementType();
+                SeaTunnelDataType<?> elementType = arrayType.getElementType();
                 Object[] l = (Object[]) value;
                 return AttributeValue.builder()
                         .l(

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/catalog/DorisCatalogFactory.java
Patch:
@@ -44,7 +44,7 @@ public Catalog createCatalog(String catalogName, ReadonlyConfig options) {
 
     @Override
     public String factoryIdentifier() {
-        return "Doris";
+        return DorisConfig.IDENTIFIER;
     }
 
     @Override

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/config/DorisConfig.java
Patch:
@@ -62,6 +62,8 @@
 @ToString
 public class DorisConfig implements Serializable {
 
+    public static final String IDENTIFIER = "Doris";
+
     // common option
     private String frontends;
     private String database;

File: seatunnel-connectors-v2/connector-doris/src/test/java/org/apache/seatunnel/connectors/doris/catalog/PreviewActionTest.java
Patch:
@@ -104,7 +104,7 @@ public void testDorisPreviewAction() {
                 catalog,
                 Catalog.ActionType.CREATE_TABLE,
                 "CREATE TABLE IF NOT EXISTS `testddatabase`.`testtable` (\n"
-                        + "`id` BIGINT(1) NOT NULL ,\n"
+                        + "`id` BIGINT NOT NULL ,\n"
                         + "`test` STRING NULL \n"
                         + ") ENGINE=OLAP\n"
                         + " UNIQUE KEY (`id`)\n"

File: seatunnel-connectors-v2/connector-easysearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/easysearch/serialize/source/DefaultSeaTunnelRowDeserializer.java
Patch:
@@ -25,7 +25,6 @@
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.TextNode;
 
 import org.apache.seatunnel.api.table.type.ArrayType;
-import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.DecimalType;
 import org.apache.seatunnel.api.table.type.LocalTimeType;
 import org.apache.seatunnel.api.table.type.MapType;
@@ -167,7 +166,7 @@ Object convertValue(SeaTunnelDataType<?> fieldType, String fieldValue)
             return new BigDecimal(fieldValue);
         } else if (fieldType instanceof ArrayType) {
             ArrayType<?, ?> arrayType = (ArrayType<?, ?>) fieldType;
-            BasicType<?> elementType = arrayType.getElementType();
+            SeaTunnelDataType<?> elementType = arrayType.getElementType();
             List<String> stringList = JsonUtils.toList(fieldValue, String.class);
             Object arr = Array.newInstance(elementType.getTypeClass(), stringList.size());
             for (int i = 0; i < stringList.size(); i++) {

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/catalog/ElasticSearchTypeConverter.java
Patch:
@@ -297,7 +297,7 @@ public BasicTypeDefine<EsType> reconvert(Column column) {
                 builder.nativeType(new EsType(FLATTENED, new HashMap<>()));
                 break;
             case ARRAY:
-                BasicType type = ((ArrayType) column.getDataType()).getElementType();
+                SeaTunnelDataType type = ((ArrayType) column.getDataType()).getElementType();
                 if (type.equals(BasicType.BYTE_TYPE)) {
                     builder.columnType(BINARY);
                     builder.dataType(BINARY);

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeDataGenerator.java
Patch:
@@ -19,7 +19,6 @@
 
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.type.ArrayType;
-import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.DecimalType;
 import org.apache.seatunnel.api.table.type.MapType;
 import org.apache.seatunnel.api.table.type.RowKind;
@@ -109,7 +108,7 @@ private Object randomColumnValue(SeaTunnelDataType<?> fieldType) {
         switch (fieldType.getSqlType()) {
             case ARRAY:
                 ArrayType<?, ?> arrayType = (ArrayType<?, ?>) fieldType;
-                BasicType<?> elementType = arrayType.getElementType();
+                SeaTunnelDataType<?> elementType = arrayType.getElementType();
                 int length = fakeConfig.getArraySize();
                 Object array = Array.newInstance(elementType.getTypeClass(), length);
                 for (int i = 0; i < length; i++) {

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/OrcWriteStrategy.java
Patch:
@@ -18,7 +18,6 @@
 package org.apache.seatunnel.connectors.seatunnel.file.sink.writer;
 
 import org.apache.seatunnel.api.table.type.ArrayType;
-import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.DecimalType;
 import org.apache.seatunnel.api.table.type.MapType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
@@ -139,7 +138,7 @@ private Writer getOrCreateWriter(@NonNull String filePath) {
     public static TypeDescription buildFieldWithRowType(SeaTunnelDataType<?> type) {
         switch (type.getSqlType()) {
             case ARRAY:
-                BasicType<?> elementType = ((ArrayType<?, ?>) type).getElementType();
+                SeaTunnelDataType<?> elementType = ((ArrayType<?, ?>) type).getElementType();
                 return TypeDescription.createList(buildFieldWithRowType(elementType));
             case MAP:
                 SeaTunnelDataType<?> keyType = ((MapType<?, ?>) type).getKeyType();

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/exception/JdbcConnectorErrorCode.java
Patch:
@@ -30,7 +30,8 @@ public enum JdbcConnectorErrorCode implements SeaTunnelErrorCode {
     NO_SUITABLE_DIALECT_FACTORY("JDBC-06", "No suitable dialect factory found"),
     DONT_SUPPORT_SINK("JDBC-07", "The jdbc type don't support sink"),
     KERBEROS_AUTHENTICATION_FAILED("JDBC-08", "Kerberos authentication failed"),
-    NO_SUPPORT_OPERATION_FAILED("JDBC-09", "The jdbc driver not support operation.");
+    NO_SUPPORT_OPERATION_FAILED("JDBC-09", "The jdbc driver not support operation."),
+    DATA_TYPE_CAST_FAILED("JDBC-10", "Data type cast failed");
     private final String code;
 
     private final String description;

File: seatunnel-connectors-v2/connector-neo4j/src/main/java/org/apache/seatunnel/connectors/seatunnel/neo4j/source/Neo4jSourceReader.java
Patch:
@@ -139,7 +139,8 @@ public static Object convertType(SeaTunnelDataType<?> dataType, Value value)
                 final SeaTunnelDataType<?> valueType = ((MapType<?, ?>) dataType).getValueType();
                 return value.asMap(v -> valueType.getTypeClass().cast(convertType(valueType, v)));
             case ARRAY:
-                final BasicType<?> elementType = ((ArrayType<?, ?>) dataType).getElementType();
+                final SeaTunnelDataType<?> elementType =
+                        ((ArrayType<?, ?>) dataType).getElementType();
                 final List<?> list =
                         value.asList(
                                 v -> elementType.getTypeClass().cast(convertType(elementType, v)));

File: seatunnel-connectors-v2/connector-paimon/src/main/java/org/apache/seatunnel/connectors/seatunnel/paimon/utils/RowTypeConverter.java
Patch:
@@ -290,7 +290,7 @@ public DataType visit(SeaTunnelDataType<?> dataType) {
                                     .getValueType();
                     return DataTypes.MAP(visit(keyType), visit(valueType));
                 case ARRAY:
-                    BasicType<?> elementType =
+                    SeaTunnelDataType<?> elementType =
                             ((org.apache.seatunnel.api.table.type.ArrayType<?, ?>) dataType)
                                     .getElementType();
                     return DataTypes.ARRAY(visit(elementType));

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-amazondynamodb-e2e/src/test/java/org/apache/seatunnel/e2e/connector/amazondynamodb/AmazondynamodbIT.java
Patch:
@@ -369,7 +369,7 @@ private AttributeValue convertItem(
                 return AttributeValue.builder().m(resultMap).build();
             case L:
                 ArrayType<?, ?> arrayType = (ArrayType<?, ?>) seaTunnelDataType;
-                BasicType<?> elementType = arrayType.getElementType();
+                SeaTunnelDataType<?> elementType = arrayType.getElementType();
                 Object[] l = (Object[]) value;
                 return AttributeValue.builder()
                         .l(

File: seatunnel-formats/seatunnel-format-avro/src/main/java/org/apache/seatunnel/format/avro/AvroToRowConverter.java
Patch:
@@ -18,7 +18,6 @@
 package org.apache.seatunnel.format.avro;
 
 import org.apache.seatunnel.api.table.type.ArrayType;
-import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.MapType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
@@ -118,7 +117,7 @@ private Object convertField(SeaTunnelDataType<?> dataType, Object val) {
                 }
                 return res;
             case ARRAY:
-                BasicType<?> basicType = ((ArrayType<?, ?>) dataType).getElementType();
+                SeaTunnelDataType<?> basicType = ((ArrayType<?, ?>) dataType).getElementType();
                 List<Object> list = (List<Object>) val;
                 return convertArray(list, basicType);
             case ROW:

File: seatunnel-formats/seatunnel-format-avro/src/main/java/org/apache/seatunnel/format/avro/RowToAvroConverter.java
Patch:
@@ -19,7 +19,6 @@
 package org.apache.seatunnel.format.avro;
 
 import org.apache.seatunnel.api.table.type.ArrayType;
-import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
@@ -111,7 +110,8 @@ private Object resolveObject(Object data, SeaTunnelDataType<?> seaTunnelDataType
             case BYTES:
                 return ByteBuffer.wrap((byte[]) data);
             case ARRAY:
-                BasicType<?> basicType = ((ArrayType<?, ?>) seaTunnelDataType).getElementType();
+                SeaTunnelDataType<?> basicType =
+                        ((ArrayType<?, ?>) seaTunnelDataType).getElementType();
                 int length = Array.getLength(data);
                 ArrayList<Object> records = new ArrayList<>(length);
                 for (int i = 0; i < length; i++) {

File: seatunnel-formats/seatunnel-format-avro/src/main/java/org/apache/seatunnel/format/avro/SeaTunnelRowTypeToAvroSchemaConverter.java
Patch:
@@ -19,7 +19,6 @@
 package org.apache.seatunnel.format.avro;
 
 import org.apache.seatunnel.api.table.type.ArrayType;
-import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.DecimalType;
 import org.apache.seatunnel.api.table.type.MapType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
@@ -78,7 +77,8 @@ private static Schema seaTunnelDataType2AvroDataType(
                 SeaTunnelDataType<?> valueType = ((MapType<?, ?>) seaTunnelDataType).getValueType();
                 return Schema.createMap(seaTunnelDataType2AvroDataType(fieldName, valueType));
             case ARRAY:
-                BasicType<?> elementType = ((ArrayType<?, ?>) seaTunnelDataType).getElementType();
+                SeaTunnelDataType<?> elementType =
+                        ((ArrayType<?, ?>) seaTunnelDataType).getElementType();
                 return Schema.createArray(seaTunnelDataType2AvroDataType(fieldName, elementType));
             case ROW:
                 SeaTunnelDataType<?>[] fieldTypes =

File: seatunnel-formats/seatunnel-format-text/src/main/java/org/apache/seatunnel/format/text/TextSerializationSchema.java
Patch:
@@ -19,7 +19,6 @@
 
 import org.apache.seatunnel.api.serialization.SerializationSchema;
 import org.apache.seatunnel.api.table.type.ArrayType;
-import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.MapType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
@@ -168,7 +167,7 @@ private String convert(Object field, SeaTunnelDataType<?> fieldType, int level)
             case BYTES:
                 return new String((byte[]) field, StandardCharsets.UTF_8);
             case ARRAY:
-                BasicType<?> elementType = ((ArrayType<?, ?>) fieldType).getElementType();
+                SeaTunnelDataType<?> elementType = ((ArrayType<?, ?>) fieldType).getElementType();
                 return Arrays.stream((Object[]) field)
                         .map(f -> convert(f, elementType, level + 1))
                         .collect(Collectors.joining(separators[level + 1]));

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/source/HttpSourceReader.java
Patch:
@@ -116,7 +116,7 @@ public void pollAndCollectData(Collector<SeaTunnelRow> output) throws Exception
                         this.httpParameter.getHeaders(),
                         this.httpParameter.getParams(),
                         this.httpParameter.getBody());
-        if (HttpResponse.STATUS_OK == response.getCode()) {
+        if (response.getCode() >= 200 && response.getCode() <= 207) {
             String content = response.getContent();
             if (!Strings.isNullOrEmpty(content)) {
                 if (this.httpParameter.isEnableMultilines()) {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/test/java/jdbc/source/JdbcSourceChunkSplitterTest.java
Patch:
@@ -106,7 +106,7 @@ public Long queryApproximateRowCnt(JdbcConnection jdbc, TableId tableId)
 
         @Override
         public String buildSplitScanQuery(
-                TableId tableId,
+                Table table,
                 SeaTunnelRowType splitKeyType,
                 boolean isFirstSplit,
                 boolean isLastSplit) {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/test/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/splitter/AbstractJdbcSourceChunkSplitterTest.java
Patch:
@@ -24,6 +24,7 @@
 
 import io.debezium.jdbc.JdbcConnection;
 import io.debezium.relational.Column;
+import io.debezium.relational.Table;
 import io.debezium.relational.TableId;
 
 import java.sql.SQLException;
@@ -217,7 +218,7 @@ public Long queryApproximateRowCnt(JdbcConnection jdbc, TableId tableId)
 
         @Override
         public String buildSplitScanQuery(
-                TableId tableId,
+                Table table,
                 SeaTunnelRowType splitKeyType,
                 boolean isFirstSplit,
                 boolean isLastSplit) {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-postgres/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/postgres/source/reader/snapshot/PostgresSnapshotSplitReadTask.java
Patch:
@@ -179,7 +179,7 @@ private void createDataEventsForTable(
 
         final String selectSql =
                 PostgresUtils.buildSplitScanQuery(
-                        snapshotSplit.getTableId(),
+                        table,
                         snapshotSplit.getSplitKeyType(),
                         snapshotSplit.getSplitStart() == null,
                         snapshotSplit.getSplitEnd() == null);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/JdbcInputFormat.java
Patch:
@@ -95,7 +95,7 @@ public void open(JdbcSourceSplit inputSplit) throws IOException {
             splitTableSchema = tables.get(inputSplit.getTablePath()).getTableSchema();
             splitTableId = inputSplit.getTablePath().toString();
 
-            statement = chunkSplitter.generateSplitStatement(inputSplit);
+            statement = chunkSplitter.generateSplitStatement(inputSplit, splitTableSchema);
             resultSet = statement.executeQuery();
             hasNext = resultSet.next();
         } catch (SQLException se) {

File: seatunnel-connectors-v2/connector-jdbc/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerCatalogTest.java
Patch:
@@ -75,7 +75,7 @@ static void before() {
 
     @Test
     void listDatabases() {
-        List<String> list = sqlServerCatalog.listDatabases();
+        sqlServerCatalog.listDatabases();
     }
 
     @Test

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/ResourceManager.java
Patch:
@@ -58,4 +58,6 @@ CompletableFuture<List<SlotProfile>> applyResources(
     void memberRemoved(MembershipServiceEvent event);
 
     void close();
+
+    List<SlotProfile> getUnassignedSlots();
 }

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/multitablesink/MultiTableWriterRunnable.java
Patch:
@@ -66,7 +66,7 @@ public void run() {
                 // exception.
                 throwable = e;
                 break;
-            } catch (Exception e) {
+            } catch (Throwable e) {
                 log.error("MultiTableWriterRunnable error", e);
                 throwable = e;
                 break;

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cdc-mysql-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/MysqlCDCIT.java
Patch:
@@ -360,7 +360,8 @@ public void testMultiTableWithRestore(TestContainer container)
 
         Pattern jobIdPattern =
                 Pattern.compile(
-                        ".*Init JobMaster for Job SeaTunnel_Job \\(([0-9]*)\\).*", Pattern.DOTALL);
+                        ".*Init JobMaster for Job mysqlcdc_to_mysql_with_multi_table_mode_one_table.conf \\(([0-9]*)\\).*",
+                        Pattern.DOTALL);
         Matcher matcher = jobIdPattern.matcher(container.getServerLogs());
         String jobId;
         if (matcher.matches()) {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cdc-oracle-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/cdc/oracle/OracleCDCIT.java
Patch:
@@ -405,7 +405,8 @@ public void testMultiTableWithRestore(TestContainer container)
 
         Pattern jobIdPattern =
                 Pattern.compile(
-                        ".*Init JobMaster for Job SeaTunnel_Job \\(([0-9]*)\\).*", Pattern.DOTALL);
+                        ".*Init JobMaster for Job oraclecdc_to_oracle_with_multi_table_mode_one_table.conf \\(([0-9]*)\\).*",
+                        Pattern.DOTALL);
         Matcher matcher = jobIdPattern.matcher(container.getServerLogs());
         String jobId;
         if (matcher.matches()) {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cdc-postgres-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/cdc/postgres/PostgresCDCIT.java
Patch:
@@ -307,7 +307,7 @@ public void testMultiTableWithRestore(TestContainer container)
 
             Pattern jobIdPattern =
                     Pattern.compile(
-                            ".*Init JobMaster for Job SeaTunnel_Job \\(([0-9]*)\\).*",
+                            ".*Init JobMaster for Job pgcdc_to_pg_with_multi_table_mode_one_table.conf \\(([0-9]*)\\).*",
                             Pattern.DOTALL);
             Matcher matcher = jobIdPattern.matcher(container.getServerLogs());
             String jobId;
@@ -412,7 +412,7 @@ public void testAddFiledWithRestore(TestContainer container)
 
             Pattern jobIdPattern =
                     Pattern.compile(
-                            ".*Init JobMaster for Job SeaTunnel_Job \\(([0-9]*)\\).*",
+                            ".*Init JobMaster for Job postgrescdc_to_postgres_test_add_Filed.conf \\(([0-9]*)\\).*",
                             Pattern.DOTALL);
             Matcher matcher = jobIdPattern.matcher(container.getServerLogs());
             String jobId;

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/AbstractTestContainer.java
Patch:
@@ -116,6 +116,8 @@ protected Container.ExecResult executeJob(
         command.add(adaptPathForWin(binPath));
         command.add("--config");
         command.add(adaptPathForWin(confInContainerPath));
+        command.add("--name");
+        command.add(new File(confInContainerPath).getName());
         List<String> extraStartShellCommands = new ArrayList<>(getExtraStartShellCommands());
         if (variables != null && !variables.isEmpty()) {
             variables.forEach(

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/CheckpointEnableIT.java
Patch:
@@ -114,7 +114,7 @@ public void testZetaStreamingCheckpointInterval(TestContainer container)
                         () -> {
                             Pattern jobIdPattern =
                                     Pattern.compile(
-                                            ".*Init JobMaster for Job SeaTunnel_Job \\(([0-9]*)\\).*",
+                                            ".*Init JobMaster for Job stream_fakesource_to_localfile_interval.conf \\(([0-9]*)\\).*",
                                             Pattern.DOTALL);
                             Matcher matcher = jobIdPattern.matcher(container.getServerLogs());
                             if (matcher.matches()) {
@@ -181,7 +181,7 @@ public void testZetaStreamingCheckpointNoInterval(TestContainer container)
                         () -> {
                             Pattern jobIdPattern =
                                     Pattern.compile(
-                                            ".*Init JobMaster for Job SeaTunnel_Job \\(([0-9]*)\\).*",
+                                            ".*Init JobMaster for Job stream_fakesource_to_localfile.conf \\(([0-9]*)\\).*",
                                             Pattern.DOTALL);
                             Matcher matcher = jobIdPattern.matcher(container.getServerLogs());
                             if (matcher.matches()) {

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/config/DorisOptions.java
Patch:
@@ -233,6 +233,8 @@ public interface DorisOptions {
                                     + "`.`"
                                     + SaveModePlaceHolder.TABLE_NAME.getPlaceHolder()
                                     + "` (\n"
+                                    + SaveModePlaceHolder.ROWTYPE_PRIMARY_KEY.getPlaceHolder()
+                                    + ",\n"
                                     + SaveModePlaceHolder.ROWTYPE_FIELDS.getPlaceHolder()
                                     + "\n"
                                     + ") ENGINE=OLAP\n"

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/catalog/KuduCatalogFactory.java
Patch:
@@ -60,6 +60,7 @@ public OptionRule optionRule() {
                 .optional(OPERATION_TIMEOUT)
                 .optional(ADMIN_OPERATION_TIMEOUT)
                 .optional(KERBEROS_KRB5_CONF)
+                .optional(ENABLE_KERBEROS)
                 .conditional(ENABLE_KERBEROS, true, KERBEROS_PRINCIPAL, KERBEROS_KEYTAB)
                 .build();
     }

File: seatunnel-connectors-v2/connector-kudu/src/test/java/org/apache/seatunnel/connectors/seatunnel/kudu/KuduFactoryTest.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.kudu;
 
+import org.apache.seatunnel.connectors.seatunnel.kudu.catalog.KuduCatalogFactory;
 import org.apache.seatunnel.connectors.seatunnel.kudu.sink.KuduSinkFactory;
 import org.apache.seatunnel.connectors.seatunnel.kudu.source.KuduSourceFactory;
 
@@ -29,5 +30,6 @@ class KuduFactoryTest {
     void optionRule() {
         Assertions.assertNotNull((new KuduSourceFactory()).optionRule());
         Assertions.assertNotNull((new KuduSinkFactory()).optionRule());
+        Assertions.assertNotNull((new KuduCatalogFactory()).optionRule());
     }
 }

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/JobClientJobProxyIT.java
Patch:
@@ -63,6 +63,6 @@ public void testJobFailedWillThrowException() throws IOException, InterruptedExc
                         && execResult
                                 .getStderr()
                                 .contains(
-                                        "org.apache.seatunnel.engine.server.resourcemanager.NoEnoughResourceException: can't apply resource request"));
+                                        "org.apache.seatunnel.engine.server.resourcemanager.NoEnoughResourceException"));
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/AbstractSeaTunnelServerTest.java
Patch:
@@ -81,7 +81,7 @@ public void before() {
         Config hazelcastConfig = Config.loadFromString(yaml);
         hazelcastConfig.setClusterName(
                 TestUtils.getClusterName("AbstractSeaTunnelServerTest_" + name));
-        SeaTunnelConfig seaTunnelConfig = ConfigProvider.locateAndGetSeaTunnelConfig();
+        SeaTunnelConfig seaTunnelConfig = loadSeaTunnelConfig();
         seaTunnelConfig.setHazelcastConfig(hazelcastConfig);
         instance = SeaTunnelServerStarter.createHazelcastInstance(seaTunnelConfig);
         nodeEngine = instance.node.nodeEngine;

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointStorageTest.java
Patch:
@@ -48,7 +48,7 @@ public class CheckpointStorageTest extends AbstractSeaTunnelServerTest {
     public SeaTunnelConfig loadSeaTunnelConfig() {
         SeaTunnelConfig seaTunnelConfig = super.loadSeaTunnelConfig();
         CheckpointConfig checkpointConfig = seaTunnelConfig.getEngineConfig().getCheckpointConfig();
-        // set a bigger interval in here and config file to avoid auto trigger checkpoint affect
+        // set a big interval in here and config file to avoid auto trigger checkpoint affect
         // test result
         checkpointConfig.setCheckpointInterval(Integer.MAX_VALUE);
         seaTunnelConfig.getEngineConfig().setCheckpointConfig(checkpointConfig);
@@ -61,7 +61,6 @@ public void testGenerateFileWhenSavepoint()
         long jobId = System.currentTimeMillis();
         CheckpointConfig checkpointConfig =
                 server.getSeaTunnelConfig().getEngineConfig().getCheckpointConfig();
-        server.getSeaTunnelConfig().getEngineConfig().setCheckpointConfig(checkpointConfig);
 
         CheckpointStorage checkpointStorage =
                 FactoryUtil.discoverFactory(
@@ -96,7 +95,6 @@ public void testBatchJob() throws CheckpointStorageException {
         long jobId = System.currentTimeMillis();
         CheckpointConfig checkpointConfig =
                 server.getSeaTunnelConfig().getEngineConfig().getCheckpointConfig();
-        server.getSeaTunnelConfig().getEngineConfig().setCheckpointConfig(checkpointConfig);
 
         CheckpointStorage checkpointStorage =
                 FactoryUtil.discoverFactory(

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-1/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcOracleIT.java
Patch:
@@ -73,6 +73,7 @@ public class JdbcOracleIT extends AbstractJdbcIT {
                     + "    CHAR_10_COL                   char(10),\n"
                     + "    CLOB_COL                      clob,\n"
                     + "    NUMBER_3_SF_2_DP              number(3, 2),\n"
+                    + "    NUMBER_7_SF_N2_DP             number(7, -2),\n"
                     + "    INTEGER_COL                   integer,\n"
                     + "    FLOAT_COL                     float(10),\n"
                     + "    REAL_COL                      real,\n"
@@ -90,6 +91,7 @@ public class JdbcOracleIT extends AbstractJdbcIT {
                 "CHAR_10_COL",
                 "CLOB_COL",
                 "NUMBER_3_SF_2_DP",
+                "NUMBER_7_SF_N2_DP",
                 "INTEGER_COL",
                 "FLOAT_COL",
                 "REAL_COL",
@@ -170,6 +172,7 @@ Pair<String[], List<SeaTunnelRow>> initTestData() {
                                 String.format("f%s", i),
                                 String.format("f%s", i),
                                 BigDecimal.valueOf(1.1),
+                                BigDecimal.valueOf(2400),
                                 i,
                                 Float.parseFloat("2.2"),
                                 Float.parseFloat("2.2"),

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/exception/HttpConnectorErrorCode.java
Patch:
@@ -20,7 +20,8 @@
 import org.apache.seatunnel.common.exception.SeaTunnelErrorCode;
 
 public enum HttpConnectorErrorCode implements SeaTunnelErrorCode {
-    FIELD_DATA_IS_INCONSISTENT("HTTP-01", "The field data is inconsistent");
+    FIELD_DATA_IS_INCONSISTENT("HTTP-01", "The field data is inconsistent"),
+    REQUEST_FAILED("HTTP-02", "The request is failed");
 
     private final String code;
     private final String description;

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/source/HttpSource.java
Patch:
@@ -73,6 +73,7 @@ public HttpSource(Config pluginConfig) {
                             "PluginName: %s, PluginType: %s, Message: %s",
                             getPluginName(), PluginType.SOURCE, result.getMsg()));
         }
+
         this.httpParameter.buildWithConfig(pluginConfig);
         buildSchemaWithConfig(pluginConfig);
         buildPagingWithConfig(pluginConfig);
@@ -94,9 +95,6 @@ private void buildPagingWithConfig(Config pluginConfig) {
         if (pluginConfig.hasPath(HttpConfig.PAGEING.key())) {
             pageInfo = new PageInfo();
             Config pageConfig = pluginConfig.getConfig(HttpConfig.PAGEING.key());
-            if (pageConfig.hasPath(HttpConfig.TOTAL_PAGE_SIZE.key())) {
-                pageInfo.setTotalPageSize(pageConfig.getLong(HttpConfig.TOTAL_PAGE_SIZE.key()));
-            }
             if (pageConfig.hasPath(HttpConfig.TOTAL_PAGE_SIZE.key())) {
                 pageInfo.setTotalPageSize(pageConfig.getLong(HttpConfig.TOTAL_PAGE_SIZE.key()));
             } else {

File: seatunnel-formats/seatunnel-format-compatible-connect-json/src/main/java/org/apache/seatunnel/format/compatible/kafka/connect/json/CompatibleKafkaConnectDeserializationSchema.java
Patch:
@@ -63,7 +63,7 @@ public class CompatibleKafkaConnectDeserializationSchema
     private transient Method keyConverterMethod;
     private transient Method valueConverterMethod;
     private final SeaTunnelRowType seaTunnelRowType;
-    private final JsonToRowConverters.JsonToRowConverter runtimeConverter;
+    private final JsonToRowConverters.JsonToObjectConverter runtimeConverter;
     private final boolean keySchemaEnable;
     private final boolean valueSchemaEnable;
     /** Object mapper for parsing the JSON. */
@@ -83,7 +83,7 @@ public CompatibleKafkaConnectDeserializationSchema(
         // Runtime converter
         this.runtimeConverter =
                 new JsonToRowConverters(failOnMissingField, ignoreParseErrors)
-                        .createConverter(checkNotNull(seaTunnelRowType));
+                        .createRowConverter(checkNotNull(seaTunnelRowType));
     }
 
     @Override
@@ -130,7 +130,7 @@ private SeaTunnelRow convertJsonNode(JsonNode jsonNode) {
         try {
             org.apache.seatunnel.shade.com.fasterxml.jackson.databind.JsonNode jsonData =
                     objectMapper.readTree(jsonNode.toString());
-            return (SeaTunnelRow) runtimeConverter.convert(jsonData);
+            return (SeaTunnelRow) runtimeConverter.convert(jsonData, null);
         } catch (Throwable t) {
             throw CommonError.jsonOperationError(FORMAT, jsonNode.toString(), t);
         }

File: seatunnel-connectors-v2/connector-file/connector-file-cos/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/cos/source/CosFileSourceFactory.java
Patch:
@@ -35,7 +35,7 @@
 public class CosFileSourceFactory implements TableSourceFactory {
     @Override
     public String factoryIdentifier() {
-        return FileSystemType.OSS.getFileSystemPluginName();
+        return FileSystemType.COS.getFileSystemPluginName();
     }
 
     @Override

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/OrcWriteStrategy.java
Patch:
@@ -122,6 +122,7 @@ private Writer getOrCreateWriter(@NonNull String filePath) {
                                 .compress(compressFormat.getOrcCompression())
                                 // use orc version 0.12
                                 .version(OrcFile.Version.V_0_12)
+                                .fileSystem(hadoopFileSystemProxy.getFileSystem())
                                 .overwrite(true);
                 Writer newWriter = OrcFile.createWriter(path, options);
                 this.beingWrittenWriter.put(filePath, newWriter);

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-amazondynamodb-e2e/src/test/java/org/apache/seatunnel/e2e/connector/amazondynamodb/AmazondynamodbIT.java
Patch:
@@ -171,7 +171,9 @@ private void clearSinkTable() {
     }
 
     private void assertHasData(String tableName) {
-        ScanResponse scan = dynamoDbClient.scan(ScanRequest.builder().tableName(tableName).build());
+        ScanResponse scan =
+                dynamoDbClient.scan(
+                        ScanRequest.builder().tableName(tableName).consistentRead(true).build());
         Assertions.assertTrue(
                 !scan.items().isEmpty(), String.format("table %s is empty.", tableName));
     }

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/commit/HiveSinkAggregatedCommitter.java
Patch:
@@ -24,7 +24,6 @@
 import org.apache.seatunnel.connectors.seatunnel.file.sink.commit.FileSinkAggregatedCommitter;
 import org.apache.seatunnel.connectors.seatunnel.hive.utils.HiveMetaStoreProxy;
 
-import org.apache.hadoop.hive.metastore.api.AlreadyExistsException;
 import org.apache.thrift.TException;
 
 import lombok.extern.slf4j.Slf4j;
@@ -71,8 +70,6 @@ public List<FileAggregatedCommitInfo> commit(
                 try {
                     hiveMetaStore.addPartitions(dbName, tableName, partitions);
                     log.info("Add these partitions {}", partitions);
-                } catch (AlreadyExistsException e) {
-                    log.warn("These partitions {} are already exists", partitions);
                 } catch (TException e) {
                     log.error("Failed to add these partitions {}", partitions, e);
                     errorCommitInfos.add(aggregatedCommitInfo);

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/catalog/CatalogTableUtil.java
Patch:
@@ -115,14 +115,14 @@ public static List<CatalogTable> getCatalogTables(
         return optionalCatalog
                 .map(
                         c -> {
-                            long startTime = System.currentTimeMillis();
                             try (Catalog catalog = c) {
+                                long startTime = System.currentTimeMillis();
                                 catalog.open();
                                 List<CatalogTable> catalogTables =
                                         catalog.getTables(readonlyConfig);
                                 log.info(
                                         String.format(
-                                                "Get catalog tables, cost time: %d",
+                                                "Get catalog tables, cost time: %d ms",
                                                 System.currentTimeMillis() - startTime));
                                 if (catalogTables.isEmpty()) {
                                     throw new SeaTunnelException(

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/seatunnel/SeaTunnelContainer.java
Patch:
@@ -248,6 +248,8 @@ private static boolean isSystemThread(String s) {
                 || s.startsWith("Timer-")
                 || s.contains("InterruptTimer")
                 || s.contains("Java2D Disposer")
+                || s.contains("OkHttp ConnectionPool")
+                || s.startsWith("http-report-event-scheduler")
                 || s.contains(
                         "org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner")
                 || s.startsWith("Log4j2-TF-")

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/dto/IndexInfo.java
Patch:
@@ -31,8 +31,8 @@ public class IndexInfo {
     private String[] primaryKeys;
     private String keyDelimiter;
 
-    public IndexInfo(ReadonlyConfig config) {
-        index = config.get(SinkConfig.INDEX);
+    public IndexInfo(String index, ReadonlyConfig config) {
+        this.index = index;
         type = config.get(SinkConfig.INDEX_TYPE);
         if (config.getOptional(SinkConfig.PRIMARY_KEYS).isPresent()) {
             primaryKeys = config.get(SinkConfig.PRIMARY_KEYS).toArray(new String[0]);

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/sink/ElasticsearchSink.java
Patch:
@@ -72,7 +72,7 @@ public String getPluginName() {
     public SinkWriter<SeaTunnelRow, ElasticsearchCommitInfo, ElasticsearchSinkState> createWriter(
             SinkWriter.Context context) {
         return new ElasticsearchSinkWriter(
-                context, catalogTable.getSeaTunnelRowType(), config, maxBatchSize, maxRetryCount);
+                context, catalogTable, config, maxBatchSize, maxRetryCount);
     }
 
     @Override
@@ -89,7 +89,7 @@ public Optional<SaveModeHandler> getSaveModeHandler() {
         SchemaSaveMode schemaSaveMode = config.get(SinkConfig.SCHEMA_SAVE_MODE);
         DataSaveMode dataSaveMode = config.get(SinkConfig.DATA_SAVE_MODE);
 
-        TablePath tablePath = TablePath.of("", config.get(SinkConfig.INDEX));
+        TablePath tablePath = TablePath.of("", catalogTable.getTableId().getTableName());
         catalog.open();
         return Optional.of(
                 new DefaultSaveModeHandler(

File: seatunnel-connectors-v2/connector-tdengine/src/main/java/org/apache/seatunnel/connectors/seatunnel/tdengine/source/TDengineSource.java
Patch:
@@ -56,6 +56,7 @@
 import static org.apache.seatunnel.connectors.seatunnel.tdengine.config.TDengineSourceConfig.ConfigNames.URL;
 import static org.apache.seatunnel.connectors.seatunnel.tdengine.config.TDengineSourceConfig.ConfigNames.USERNAME;
 import static org.apache.seatunnel.connectors.seatunnel.tdengine.config.TDengineSourceConfig.buildSourceConfig;
+import static org.apache.seatunnel.connectors.seatunnel.tdengine.utils.TDengineUtil.checkDriverExist;
 
 /**
  * TDengine source each split corresponds one subtable
@@ -135,6 +136,8 @@ private StableMetadata getStableMetadata(TDengineSourceConfig config) throws SQL
                         config.getUsername(),
                         "&password=",
                         config.getPassword());
+        // check td driver whether exist and if not, try to register
+        checkDriverExist(jdbcUrl);
         try (Connection conn = DriverManager.getConnection(jdbcUrl)) {
             try (Statement statement = conn.createStatement()) {
                 ResultSet metaResultSet =

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/factory/BaseMultipleTableFileSinkFactory.java
Patch:
@@ -31,7 +31,7 @@
 import org.apache.seatunnel.connectors.seatunnel.file.sink.commit.FileCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.state.FileSinkState;
 
-public abstract class BaseMultipleTableFinkSinkFactory
+public abstract class BaseMultipleTableFileSinkFactory
         implements TableSinkFactory<
                 SeaTunnelRow, FileSinkState, FileCommitInfo, FileAggregatedCommitInfo> {
 

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/LocalFileSinkFactory.java
Patch:
@@ -27,15 +27,15 @@
 import org.apache.seatunnel.connectors.seatunnel.file.config.BaseSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileSystemType;
-import org.apache.seatunnel.connectors.seatunnel.file.factory.BaseMultipleTableFinkSinkFactory;
+import org.apache.seatunnel.connectors.seatunnel.file.factory.BaseMultipleTableFileSinkFactory;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.commit.FileAggregatedCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.commit.FileCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.state.FileSinkState;
 
 import com.google.auto.service.AutoService;
 
 @AutoService(Factory.class)
-public class LocalFileSinkFactory extends BaseMultipleTableFinkSinkFactory {
+public class LocalFileSinkFactory extends BaseMultipleTableFileSinkFactory {
     @Override
     public String factoryIdentifier() {
         return FileSystemType.LOCAL.getFileSystemPluginName();

File: seatunnel-connectors-v2/connector-file/connector-file-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/sink/OssFileSinkFactory.java
Patch:
@@ -26,13 +26,13 @@
 import org.apache.seatunnel.connectors.seatunnel.file.config.BaseSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileSystemType;
-import org.apache.seatunnel.connectors.seatunnel.file.factory.BaseMultipleTableFinkSinkFactory;
+import org.apache.seatunnel.connectors.seatunnel.file.factory.BaseMultipleTableFileSinkFactory;
 import org.apache.seatunnel.connectors.seatunnel.file.oss.config.OssConfigOptions;
 
 import com.google.auto.service.AutoService;
 
 @AutoService(Factory.class)
-public class OssFileSinkFactory extends BaseMultipleTableFinkSinkFactory {
+public class OssFileSinkFactory extends BaseMultipleTableFileSinkFactory {
     @Override
     public String factoryIdentifier() {
         return FileSystemType.OSS.getFileSystemPluginName();

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/flowcontrol/FlowControlGate.java
Patch:
@@ -32,15 +32,15 @@ public class FlowControlGate {
 
     private FlowControlGate(FlowControlStrategy flowControlStrategy) {
         final int bytesPerSecond = flowControlStrategy.getBytesPerSecond();
-        final int countPreSecond = flowControlStrategy.getCountPreSecond();
+        final int countPerSecond = flowControlStrategy.getCountPerSecond();
         this.bytesRateLimiter =
                 bytesPerSecond == DEFAULT_VALUE
                         ? Optional.empty()
                         : Optional.of(RateLimiter.create(bytesPerSecond));
         this.countRateLimiter =
-                countPreSecond == DEFAULT_VALUE
+                countPerSecond == DEFAULT_VALUE
                         ? Optional.empty()
-                        : Optional.of(RateLimiter.create(countPreSecond));
+                        : Optional.of(RateLimiter.create(countPerSecond));
     }
 
     public void audit(SeaTunnelRow row) {

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/util/CreateTableParser.java
Patch:
@@ -43,6 +43,9 @@ public static Map<String, ColumnInfo> getColumnList(String createTableSql) {
             } else if ((c == ',' || c == ')') && !insideParentheses) {
                 parseColumn(columnBuilder.toString(), columns, startIndex + i + 1);
                 columnBuilder.setLength(0);
+                if (c == ')') {
+                    break;
+                }
             } else if (c == ')') {
                 insideParentheses = false;
                 columnBuilder.append(c);

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/util/CreateTableParser.java
Patch:
@@ -43,6 +43,9 @@ public static Map<String, ColumnInfo> getColumnList(String createTableSql) {
             } else if ((c == ',' || c == ')') && !insideParentheses) {
                 parseColumn(columnBuilder.toString(), columns, startIndex + i + 1);
                 columnBuilder.setLength(0);
+                if (c == ')') {
+                    break;
+                }
             } else if (c == ')') {
                 insideParentheses = false;
                 columnBuilder.append(c);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/sqlserver/SqlserverJdbcRowConverter.java
Patch:
@@ -25,7 +25,7 @@
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.converter.AbstractJdbcRowConverter;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.DatabaseIdentifier;
-import org.apache.seatunnel.connectors.seatunnel.jdbc.utils.JdbcUtils;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.utils.JdbcFieldTypeUtils;
 
 import java.math.BigDecimal;
 import java.sql.PreparedStatement;
@@ -46,7 +46,7 @@ public String converterName() {
 
     @Override
     protected LocalTime readTime(ResultSet rs, int resultSetIndex) throws SQLException {
-        Timestamp sqlTime = JdbcUtils.getTimestamp(rs, resultSetIndex);
+        Timestamp sqlTime = JdbcFieldTypeUtils.getTimestamp(rs, resultSetIndex);
         return Optional.ofNullable(sqlTime)
                 .map(e -> e.toLocalDateTime().toLocalTime())
                 .orElse(null);

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/SQLTransform.java
Patch:
@@ -167,6 +167,7 @@ protected TableSchema transformTableSchema() {
                                 fieldNames[i],
                                 fieldTypes[i],
                                 simpleColumn.getColumnLength(),
+                                simpleColumn.getScale(),
                                 simpleColumn.isNullable(),
                                 simpleColumn.getDefaultValue(),
                                 simpleColumn.getComment());

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/source/DorisSource.java
Patch:
@@ -29,14 +29,12 @@
 import org.apache.seatunnel.connectors.doris.source.split.DorisSourceSplit;
 import org.apache.seatunnel.connectors.doris.source.split.DorisSourceSplitEnumerator;
 
-import com.google.auto.service.AutoService;
 import lombok.extern.slf4j.Slf4j;
 
 import java.util.Collections;
 import java.util.List;
 
 @Slf4j
-@AutoService(SeaTunnelSource.class)
 public class DorisSource
         implements SeaTunnelSource<SeaTunnelRow, DorisSourceSplit, DorisSourceState> {
 

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/sink/ElasticsearchSink.java
Patch:
@@ -35,15 +35,12 @@
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.state.ElasticsearchCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.state.ElasticsearchSinkState;
 
-import com.google.auto.service.AutoService;
-
 import java.util.Optional;
 
 import static org.apache.seatunnel.api.table.factory.FactoryUtil.discoverFactory;
 import static org.apache.seatunnel.connectors.seatunnel.elasticsearch.config.SinkConfig.MAX_BATCH_SIZE;
 import static org.apache.seatunnel.connectors.seatunnel.elasticsearch.config.SinkConfig.MAX_RETRY_COUNT;
 
-@AutoService(SeaTunnelSink.class)
 public class ElasticsearchSink
         implements SeaTunnelSink<
                         SeaTunnelRow,

File: seatunnel-connectors-v2/connector-file/connector-file-jindo-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/jindo/config/OssConf.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.oss.config;
+package org.apache.seatunnel.connectors.seatunnel.file.oss.jindo.config;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-connectors-v2/connector-file/connector-file-jindo-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/jindo/config/OssConfigOptions.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.oss.config;
+package org.apache.seatunnel.connectors.seatunnel.file.oss.jindo.config;
 
 import org.apache.seatunnel.api.configuration.Option;
 import org.apache.seatunnel.api.configuration.Options;

File: seatunnel-connectors-v2/connector-file/connector-file-jindo-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/jindo/exception/OssJindoConnectorException.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.oss.exception;
+package org.apache.seatunnel.connectors.seatunnel.file.oss.jindo.exception;
 
 import org.apache.seatunnel.common.exception.SeaTunnelErrorCode;
 import org.apache.seatunnel.common.exception.SeaTunnelRuntimeException;

File: seatunnel-connectors-v2/connector-file/connector-file-jindo-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/jindo/sink/OssFileSinkFactory.java
Patch:
@@ -15,15 +15,15 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.oss.sink;
+package org.apache.seatunnel.connectors.seatunnel.file.oss.jindo.sink;
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSinkFactory;
 import org.apache.seatunnel.connectors.seatunnel.file.config.BaseSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileSystemType;
-import org.apache.seatunnel.connectors.seatunnel.file.oss.config.OssConfigOptions;
+import org.apache.seatunnel.connectors.seatunnel.file.oss.jindo.config.OssConfigOptions;
 
 import com.google.auto.service.AutoService;
 

File: seatunnel-connectors-v2/connector-file/connector-file-jindo-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/jindo/source/OssFileSourceFactory.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.oss.source;
+package org.apache.seatunnel.connectors.seatunnel.file.oss.jindo.source;
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
@@ -25,7 +25,7 @@
 import org.apache.seatunnel.connectors.seatunnel.file.config.BaseSourceConfigOptions;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileSystemType;
-import org.apache.seatunnel.connectors.seatunnel.file.oss.config.OssConfigOptions;
+import org.apache.seatunnel.connectors.seatunnel.file.oss.jindo.config.OssConfigOptions;
 
 import com.google.auto.service.AutoService;
 

File: seatunnel-connectors-v2/connector-file/connector-file-jindo-oss/src/test/java/org/apache/seatunnel/connectors/test/OssJindoFactoryTest.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.seatunnel.connectors.test;
 
-import org.apache.seatunnel.connectors.seatunnel.file.oss.sink.OssFileSinkFactory;
-import org.apache.seatunnel.connectors.seatunnel.file.oss.source.OssFileSourceFactory;
+import org.apache.seatunnel.connectors.seatunnel.file.oss.jindo.sink.OssFileSinkFactory;
+import org.apache.seatunnel.connectors.seatunnel.file.oss.jindo.source.OssFileSourceFactory;
 
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;

File: seatunnel-connectors-v2/connector-hudi/src/main/java/org/apache/seatunnel/connectors/seatunnel/hudi/source/HudiSourceFactory.java
Patch:
@@ -19,12 +19,13 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
 import org.apache.seatunnel.connectors.seatunnel.hudi.config.HudiSourceConfig;
 
 import com.google.auto.service.AutoService;
 
-@AutoService(SeaTunnelSource.class)
+@AutoService(Factory.class)
 public class HudiSourceFactory implements TableSourceFactory {
 
     @Override

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/sink/IcebergSink.java
Patch:
@@ -44,8 +44,6 @@
 import org.apache.seatunnel.connectors.seatunnel.iceberg.sink.commit.IcebergCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.sink.state.IcebergSinkState;
 
-import com.google.auto.service.AutoService;
-
 import java.io.IOException;
 import java.util.List;
 import java.util.Objects;
@@ -54,7 +52,6 @@
 
 import static org.apache.seatunnel.api.table.factory.FactoryUtil.discoverFactory;
 
-@AutoService(SeaTunnelSink.class)
 public class IcebergSink
         implements SeaTunnelSink<
                         SeaTunnelRow,

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/IcebergSource.java
Patch:
@@ -49,7 +49,6 @@
 import org.apache.iceberg.Schema;
 import org.apache.iceberg.types.Types;
 
-import com.google.auto.service.AutoService;
 import lombok.SneakyThrows;
 
 import java.util.ArrayList;
@@ -58,7 +57,6 @@
 
 import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
-@AutoService(SeaTunnelSource.class)
 public class IcebergSource
         implements SeaTunnelSource<
                         SeaTunnelRow, IcebergFileScanTaskSplit, IcebergSplitEnumeratorState>,

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/source/StarRocksSource.java
Patch:
@@ -26,12 +26,9 @@
 import org.apache.seatunnel.connectors.seatunnel.starrocks.config.CommonConfig;
 import org.apache.seatunnel.connectors.seatunnel.starrocks.config.SourceConfig;
 
-import com.google.auto.service.AutoService;
-
 import java.util.Collections;
 import java.util.List;
 
-@AutoService(SeaTunnelSource.class)
 public class StarRocksSource
         implements SeaTunnelSource<SeaTunnelRow, StarRocksSourceSplit, StarRocksSourceState> {
 

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/MultipleTableJobConfigParser.java
Patch:
@@ -46,7 +46,6 @@
 import org.apache.seatunnel.core.starter.utils.ConfigBuilder;
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.exception.JobDefineCheckException;
-import org.apache.seatunnel.engine.common.loader.ClassLoaderUtil;
 import org.apache.seatunnel.engine.common.loader.SeaTunnelChildFirstClassLoader;
 import org.apache.seatunnel.engine.common.utils.IdGenerator;
 import org.apache.seatunnel.engine.core.classloader.ClassLoaderService;
@@ -209,7 +208,6 @@ public ImmutablePair<List<Action>, Set<URL>> parse(ClassLoaderService classLoade
                 classLoaderService.releaseClassLoader(
                         Long.parseLong(jobConfig.getJobContext().getJobId()), connectorJars);
             }
-            ClassLoaderUtil.recycleClassLoaderFromThread(classLoader);
         }
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/TaskExecutionService.java
Patch:
@@ -25,7 +25,6 @@
 import org.apache.seatunnel.engine.common.config.SeaTunnelConfig;
 import org.apache.seatunnel.engine.common.config.server.ThreadShareMode;
 import org.apache.seatunnel.engine.common.exception.JobNotFoundException;
-import org.apache.seatunnel.engine.common.loader.ClassLoaderUtil;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.core.classloader.ClassLoaderService;
 import org.apache.seatunnel.engine.core.job.ConnectorJarIdentifier;
@@ -919,9 +918,7 @@ void taskDone(Task task) {
 
         private void recycleClassLoader(TaskGroupLocation taskGroupLocation) {
             TaskGroupContext context = executionContexts.get(taskGroupLocation);
-            ClassLoader classLoader = context.getClassLoader();
             executionContexts.get(taskGroupLocation).setClassLoader(null);
-            ClassLoaderUtil.recycleClassLoaderFromThread(classLoader);
             classLoaderService.releaseClassLoader(taskGroupLocation.getJobId(), context.getJars());
         }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -30,7 +30,6 @@
 import org.apache.seatunnel.engine.common.config.server.CheckpointConfig;
 import org.apache.seatunnel.engine.common.config.server.CheckpointStorageConfig;
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
-import org.apache.seatunnel.engine.common.loader.ClassLoaderUtil;
 import org.apache.seatunnel.engine.common.utils.ExceptionUtil;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.core.dag.logical.LogicalDag;
@@ -217,8 +216,6 @@ public void init(long initializationTimestamp, boolean restart) throws Exception
                         jobImmutableInformation.getJobId(),
                         jobImmutableInformation.getPluginJarsUrls());
 
-        ClassLoaderUtil.recycleClassLoaderFromThread(classLoader);
-
         final Tuple2<PhysicalPlan, Map<Integer, CheckpointPlan>> planTuple =
                 PlanUtils.fromLogicalDAG(
                         logicalDag,

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/ClientJobExecutionEnvironment.java
Patch:
@@ -85,7 +85,7 @@ protected MultipleTableJobConfigParser getJobConfigParser() {
 
     @Override
     protected LogicalDag getLogicalDag() {
-        ImmutablePair<List<Action>, Set<URL>> immutablePair = getJobConfigParser().parse();
+        ImmutablePair<List<Action>, Set<URL>> immutablePair = getJobConfigParser().parse(null);
         actions.addAll(immutablePair.getLeft());
         // Enable upload connector jar package to engine server, automatically upload connector Jar
         // packages and dependent third-party Jar packages to the server before job execution.

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/LogicalDagGeneratorTest.java
Patch:
@@ -49,7 +49,7 @@ public void testLogicalGenerator() {
 
         IdGenerator idGenerator = new IdGenerator();
         ImmutablePair<List<Action>, Set<URL>> immutablePair =
-                new MultipleTableJobConfigParser(filePath, idGenerator, jobConfig).parse();
+                new MultipleTableJobConfigParser(filePath, idGenerator, jobConfig).parse(null);
 
         LogicalDagGenerator logicalDagGenerator =
                 new LogicalDagGenerator(immutablePair.getLeft(), jobConfig, idGenerator);

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/classloader/ClassLoaderService.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.server.service.classloader;
+package org.apache.seatunnel.engine.core.classloader;
 
 import java.net.URL;
 import java.util.Collection;

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/classloader/DefaultClassLoaderService.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.server.service.classloader;
+package org.apache.seatunnel.engine.core.classloader;
 
 import org.apache.seatunnel.engine.common.loader.SeaTunnelChildFirstClassLoader;
 

File: seatunnel-engine/seatunnel-engine-core/src/test/java/org/apache/seatunnel/engine/core/classloader/AbstractClassLoaderServiceTest.java
Patch:
@@ -15,17 +15,17 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.server.service.classloader;
+package org.apache.seatunnel.engine.core.classloader;
 
 import org.apache.seatunnel.engine.common.loader.SeaTunnelChildFirstClassLoader;
 
-import org.apache.curator.shaded.com.google.common.collect.Lists;
-
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
 
+import com.google.common.collect.Lists;
+
 import java.net.MalformedURLException;
 import java.net.URL;
 import java.util.Collections;

File: seatunnel-engine/seatunnel-engine-core/src/test/java/org/apache/seatunnel/engine/core/classloader/ClassLoaderServiceCacheModeTest.java
Patch:
@@ -15,13 +15,13 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.server.service.classloader;
-
-import org.apache.curator.shaded.com.google.common.collect.Lists;
+package org.apache.seatunnel.engine.core.classloader;
 
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
 
+import com.google.common.collect.Lists;
+
 import java.net.MalformedURLException;
 import java.net.URL;
 

File: seatunnel-engine/seatunnel-engine-core/src/test/java/org/apache/seatunnel/engine/core/classloader/ClassLoaderServiceTest.java
Patch:
@@ -15,13 +15,13 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.server.service.classloader;
-
-import org.apache.curator.shaded.com.google.common.collect.Lists;
+package org.apache.seatunnel.engine.core.classloader;
 
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
 
+import com.google.common.collect.Lists;
+
 import java.net.MalformedURLException;
 import java.net.URL;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/SeaTunnelServer.java
Patch:
@@ -21,10 +21,10 @@
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.common.config.SeaTunnelConfig;
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
+import org.apache.seatunnel.engine.core.classloader.ClassLoaderService;
+import org.apache.seatunnel.engine.core.classloader.DefaultClassLoaderService;
 import org.apache.seatunnel.engine.server.execution.ExecutionState;
 import org.apache.seatunnel.engine.server.execution.TaskGroupLocation;
-import org.apache.seatunnel.engine.server.service.classloader.ClassLoaderService;
-import org.apache.seatunnel.engine.server.service.classloader.DefaultClassLoaderService;
 import org.apache.seatunnel.engine.server.service.jar.ConnectorPackageService;
 import org.apache.seatunnel.engine.server.service.slot.DefaultSlotService;
 import org.apache.seatunnel.engine.server.service.slot.SlotService;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/TaskExecutionService.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.seatunnel.engine.common.exception.JobNotFoundException;
 import org.apache.seatunnel.engine.common.loader.ClassLoaderUtil;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
+import org.apache.seatunnel.engine.core.classloader.ClassLoaderService;
 import org.apache.seatunnel.engine.core.job.ConnectorJarIdentifier;
 import org.apache.seatunnel.engine.server.exception.TaskGroupContextNotFoundException;
 import org.apache.seatunnel.engine.server.execution.ExecutionState;
@@ -42,7 +43,6 @@
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.execution.TaskTracker;
 import org.apache.seatunnel.engine.server.metrics.SeaTunnelMetricsContext;
-import org.apache.seatunnel.engine.server.service.classloader.ClassLoaderService;
 import org.apache.seatunnel.engine.server.service.jar.ServerConnectorPackageClient;
 import org.apache.seatunnel.engine.server.task.SeaTunnelTask;
 import org.apache.seatunnel.engine.server.task.TaskGroupImmutableInformation;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/rest/RestHttpGetCommandProcessor.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.api.common.metrics.JobMetrics;
 import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.engine.common.Constant;
+import org.apache.seatunnel.engine.core.classloader.ClassLoaderService;
 import org.apache.seatunnel.engine.core.dag.logical.LogicalDag;
 import org.apache.seatunnel.engine.core.job.JobDAGInfo;
 import org.apache.seatunnel.engine.core.job.JobImmutableInformation;
@@ -35,7 +36,6 @@
 import org.apache.seatunnel.engine.server.operation.GetClusterHealthMetricsOperation;
 import org.apache.seatunnel.engine.server.operation.GetJobMetricsOperation;
 import org.apache.seatunnel.engine.server.operation.GetJobStatusOperation;
-import org.apache.seatunnel.engine.server.service.classloader.ClassLoaderService;
 import org.apache.seatunnel.engine.server.utils.NodeEngineUtil;
 
 import com.hazelcast.cluster.Address;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/rest/RestHttpPostCommandProcessor.java
Patch:
@@ -124,8 +124,10 @@ private void handleSubmitJob(HttpPostCommand httpPostCommand, String uri)
 
         boolean startWithSavePoint =
                 Boolean.parseBoolean(requestParams.get(RestConstant.IS_START_WITH_SAVE_POINT));
+        SeaTunnelServer seaTunnelServer = getSeaTunnelServer();
         RestJobExecutionEnvironment restJobExecutionEnvironment =
                 new RestJobExecutionEnvironment(
+                        seaTunnelServer,
                         jobConfig,
                         config,
                         textCommandService.getNode(),
@@ -135,7 +137,6 @@ private void handleSubmitJob(HttpPostCommand httpPostCommand, String uri)
                                 : null);
         JobImmutableInformation jobImmutableInformation = restJobExecutionEnvironment.build();
         Long jobId = jobImmutableInformation.getJobId();
-        SeaTunnelServer seaTunnelServer = getSeaTunnelServer();
         if (seaTunnelServer == null) {
 
             NodeEngineUtil.sendOperationToMasterNode(

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/ConnectorPackageServiceTest.java
Patch:
@@ -199,7 +199,7 @@ public void testRestoreWhenMasterNodeSwitch() throws InterruptedException, IOExc
         fillJobConfig(jobConfig, envOptions);
         List<URL> commonPluginJars = new ArrayList<>(searchPluginJars());
         commonPluginJars.addAll(
-                new ArrayList<URL>(
+                new ArrayList<>(
                         Common.getThirdPartyJars(
                                         jobConfig
                                                 .getEnvOptions()
@@ -220,7 +220,8 @@ public void testRestoreWhenMasterNodeSwitch() throws InterruptedException, IOExc
         MultipleTableJobConfigParser multipleTableJobConfigParser =
                 new MultipleTableJobConfigParser(
                         filePath, new IdGenerator(), jobConfig, commonPluginJars, false);
-        ImmutablePair<List<Action>, Set<URL>> immutablePair = multipleTableJobConfigParser.parse();
+        ImmutablePair<List<Action>, Set<URL>> immutablePair =
+                multipleTableJobConfigParser.parse(null);
         Set<ConnectorJarIdentifier> commonJarIdentifiers = new HashSet<>();
 
         // Upload commonPluginJar

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/TestUtils.java
Patch:
@@ -119,7 +119,7 @@ public static LogicalDag createTestLogicalPlan(
 
         IdGenerator idGenerator = new IdGenerator();
         ImmutablePair<List<Action>, Set<URL>> immutablePair =
-                new MultipleTableJobConfigParser(filePath, idGenerator, jobConfig).parse();
+                new MultipleTableJobConfigParser(filePath, idGenerator, jobConfig).parse(null);
 
         LogicalDagGenerator logicalDagGenerator =
                 new LogicalDagGenerator(immutablePair.getLeft(), jobConfig, idGenerator);

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/ClientJobExecutionEnvironment.java
Patch:
@@ -153,12 +153,13 @@ private void uploadActionPluginJar(List<Action> actions, Set<ConnectorJarIdentif
     }
 
     public ClientJobProxy execute() throws ExecutionException, InterruptedException {
+        LogicalDag logicalDag = getLogicalDag();
         JobImmutableInformation jobImmutableInformation =
                 new JobImmutableInformation(
                         Long.parseLong(jobConfig.getJobContext().getJobId()),
                         jobConfig.getName(),
                         isStartWithSavePoint,
-                        seaTunnelHazelcastClient.getSerializationService().toData(getLogicalDag()),
+                        seaTunnelHazelcastClient.getSerializationService().toData(logicalDag),
                         jobConfig,
                         new ArrayList<>(jarUrls),
                         new ArrayList<>(connectorJarIdentifiers));

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/MultipleTableJobConfigParser.java
Patch:
@@ -251,7 +251,8 @@ void addCommonPluginJarsToAction(Action action) {
     private void fillJobConfig() {
         jobConfig.getJobContext().setJobMode(envOptions.get(EnvCommonOptions.JOB_MODE));
         if (StringUtils.isEmpty(jobConfig.getName())
-                || jobConfig.getName().equals(Constants.LOGO)) {
+                || jobConfig.getName().equals(Constants.LOGO)
+                || jobConfig.getName().equals(EnvCommonOptions.JOB_NAME.defaultValue())) {
             jobConfig.setName(envOptions.get(EnvCommonOptions.JOB_NAME));
         }
         envOptions

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlIncrementalSourceFactory.java
Patch:
@@ -57,8 +57,8 @@ public OptionRule optionRule() {
                 .required(
                         JdbcSourceOptions.USERNAME,
                         JdbcSourceOptions.PASSWORD,
-                        CatalogOptions.TABLE_NAMES,
                         JdbcCatalogOptions.BASE_URL)
+                .exclusive(CatalogOptions.TABLE_NAMES, CatalogOptions.TABLE_PATTERN)
                 .optional(
                         JdbcSourceOptions.DATABASE_NAMES,
                         JdbcSourceOptions.SERVER_ID,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-postgres/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/postgres/source/PostgresIncrementalSourceFactory.java
Patch:
@@ -56,8 +56,8 @@ public OptionRule optionRule() {
                 .required(
                         JdbcSourceOptions.USERNAME,
                         JdbcSourceOptions.PASSWORD,
-                        CatalogOptions.TABLE_NAMES,
                         JdbcCatalogOptions.BASE_URL)
+                .exclusive(CatalogOptions.TABLE_NAMES, CatalogOptions.TABLE_PATTERN)
                 .optional(
                         JdbcSourceOptions.DATABASE_NAMES,
                         JdbcSourceOptions.SERVER_TIME_ZONE,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/SqlServerIncrementalSourceFactory.java
Patch:
@@ -58,8 +58,8 @@ public OptionRule optionRule() {
                 .required(
                         JdbcSourceOptions.USERNAME,
                         JdbcSourceOptions.PASSWORD,
-                        CatalogOptions.TABLE_NAMES,
                         JdbcCatalogOptions.BASE_URL)
+                .exclusive(CatalogOptions.TABLE_NAMES, CatalogOptions.TABLE_PATTERN)
                 .optional(
                         JdbcSourceOptions.DATABASE_NAMES,
                         JdbcSourceOptions.SERVER_TIME_ZONE,

File: seatunnel-connectors-v2/connector-easysearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/easysearch/catalog/EasysearchCatalog.java
Patch:
@@ -153,7 +153,7 @@ public CatalogTable getTable(TablePath tablePath)
                                     fieldName,
                                     easySearchDataTypeConvertor.toSeaTunnelType(
                                             fieldName, fieldType),
-                                    null,
+                                    (Long) null,
                                     true,
                                     null,
                                     null);

File: seatunnel-connectors-v2/connector-file/connector-file-base-hadoop/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/hdfs/source/BaseHdfsFileSource.java
Patch:
@@ -102,6 +102,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 case TEXT:
                 case JSON:
                 case EXCEL:
+                case XML:
                     SeaTunnelRowType userDefinedSchema =
                             CatalogTableUtil.buildWithConfig(pluginConfig).getSeaTunnelRowType();
                     readStrategy.setSeaTunnelRowTypeInfo(userDefinedSchema);

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseFileSourceConfig.java
Patch:
@@ -93,6 +93,7 @@ private CatalogTable parseCatalogTable(ReadonlyConfig readonlyConfig) {
             case TEXT:
             case JSON:
             case EXCEL:
+            case XML:
                 readStrategy.setSeaTunnelRowTypeInfo(catalogTable.getSeaTunnelRowType());
                 return newCatalogTable(catalogTable, readStrategy.getActualSeaTunnelRowTypeInfo());
             case ORC:

File: seatunnel-connectors-v2/connector-file/connector-file-cos/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/cos/source/CosFileSource.java
Patch:
@@ -94,6 +94,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 case TEXT:
                 case JSON:
                 case EXCEL:
+                case XML:
                     SeaTunnelRowType userDefinedSchema =
                             CatalogTableUtil.buildWithConfig(pluginConfig).getSeaTunnelRowType();
                     readStrategy.setSeaTunnelRowTypeInfo(userDefinedSchema);

File: seatunnel-connectors-v2/connector-file/connector-file-ftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/ftp/source/FtpFileSource.java
Patch:
@@ -99,6 +99,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 case TEXT:
                 case JSON:
                 case EXCEL:
+                case XML:
                     SeaTunnelRowType userDefinedSchema =
                             CatalogTableUtil.buildWithConfig(pluginConfig).getSeaTunnelRowType();
                     readStrategy.setSeaTunnelRowTypeInfo(userDefinedSchema);

File: seatunnel-connectors-v2/connector-file/connector-file-jindo-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/source/OssFileSource.java
Patch:
@@ -95,6 +95,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 case TEXT:
                 case JSON:
                 case EXCEL:
+                case XML:
                     SeaTunnelRowType userDefinedSchema =
                             CatalogTableUtil.buildWithConfig(pluginConfig).getSeaTunnelRowType();
                     readStrategy.setSeaTunnelRowTypeInfo(userDefinedSchema);

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/source/S3FileSource.java
Patch:
@@ -91,6 +91,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 case TEXT:
                 case JSON:
                 case EXCEL:
+                case XML:
                     SeaTunnelRowType userDefinedSchema =
                             CatalogTableUtil.buildWithConfig(pluginConfig).getSeaTunnelRowType();
                     readStrategy.setSeaTunnelRowTypeInfo(userDefinedSchema);

File: seatunnel-connectors-v2/connector-file/connector-file-sftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sftp/source/SftpFileSource.java
Patch:
@@ -75,7 +75,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
         if (fileFormat == FileFormat.ORC || fileFormat == FileFormat.PARQUET) {
             throw new FileConnectorException(
                     CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
-                    "Sftp file source connector only support read [text, csv, json] files");
+                    "Sftp file source connector only support read [text, csv, json, xml] files");
         }
         String path = pluginConfig.getString(SftpConfigOptions.FILE_PATH.key());
         hadoopConf = SftpConf.buildWithConfig(pluginConfig);
@@ -99,6 +99,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 case TEXT:
                 case JSON:
                 case EXCEL:
+                case XML:
                     SeaTunnelRowType userDefinedSchema =
                             CatalogTableUtil.buildWithConfig(pluginConfig).getSeaTunnelRowType();
                     readStrategy.setSeaTunnelRowTypeInfo(userDefinedSchema);

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-2/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcOceanBaseMysqlIT.java
Patch:
@@ -27,6 +27,7 @@
 import org.testcontainers.containers.GenericContainer;
 import org.testcontainers.containers.output.Slf4jLogConsumer;
 import org.testcontainers.containers.wait.strategy.Wait;
+import org.testcontainers.images.PullPolicy;
 import org.testcontainers.utility.DockerLoggerFactory;
 
 import com.google.common.collect.Lists;
@@ -283,6 +284,7 @@ GenericContainer<?> initContainer() {
                 .withNetwork(NETWORK)
                 .withNetworkAliases(HOSTNAME)
                 .withExposedPorts(PORT)
+                .withImagePullPolicy(PullPolicy.alwaysPull())
                 .waitingFor(Wait.forLogMessage(".*boot success!.*", 1))
                 .withStartupTimeout(Duration.ofMinutes(5))
                 .withLogConsumer(new Slf4jLogConsumer(DockerLoggerFactory.getLogger(IMAGE)));

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/serialize/SeaTunnelRowConverter.java
Patch:
@@ -35,7 +35,8 @@ public class SeaTunnelRowConverter {
     @Builder.Default private DateUtils.Formatter dateFormatter = DateUtils.Formatter.YYYY_MM_DD;
 
     @Builder.Default
-    private DateTimeUtils.Formatter dateTimeFormatter = DateTimeUtils.Formatter.YYYY_MM_DD_HH_MM_SS;
+    private DateTimeUtils.Formatter dateTimeFormatter =
+            DateTimeUtils.Formatter.YYYY_MM_DD_HH_MM_SS_SSSSSS;
 
     @Builder.Default private TimeUtils.Formatter timeFormatter = TimeUtils.Formatter.HH_MM_SS;
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-doris-e2e/src/test/java/org/apache/seatunnel/e2e/connector/doris/DorisIT.java
Patch:
@@ -126,7 +126,7 @@ private void checkSinkData() {
             String sinkSql = String.format("select * from %s.%s order by F_ID", sinkDB, TABLE);
             List<String> columnList =
                     Arrays.stream(COLUMN_STRING.split(","))
-                            .map(x -> x.trim())
+                            .map(String::trim)
                             .collect(Collectors.toList());
             Statement sourceStatement =
                     conn.createStatement(
@@ -284,8 +284,8 @@ private List<SeaTunnelRow> genDorisTestData(Long nums) {
                                 GenerateTestData.genString(1),
                                 GenerateTestData.genString(11),
                                 GenerateTestData.genString(12),
-                                GenerateTestData.genDatetimeString(false),
                                 GenerateTestData.genDatetimeString(true),
+                                GenerateTestData.genDatetimeString(false),
                                 GenerateTestData.genDateString()
                             }));
         }

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/utils/FakeDataRandomUtils.java
Patch:
@@ -37,7 +37,7 @@ public FakeDataRandomUtils(FakeConfig fakeConfig) {
     }
 
     private static <T> T randomFromList(List<T> list) {
-        int index = RandomUtils.nextInt(0, list.size() - 1);
+        int index = RandomUtils.nextInt(0, list.size());
         return list.get(index);
     }
 

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/enumerator/AbstractSplitEnumerator.java
Patch:
@@ -24,7 +24,6 @@
 import org.apache.seatunnel.connectors.seatunnel.iceberg.source.split.IcebergFileScanTaskSplit;
 
 import org.apache.iceberg.Table;
-import org.apache.iceberg.util.ThreadPools;
 
 import lombok.Getter;
 import lombok.NonNull;
@@ -79,8 +78,6 @@ public void run() {
     public void close() throws IOException {
         icebergTableLoader.close();
         isOpen = false;
-        // TODO we should remove shutdown logic when supported closed part task
-        ThreadPools.getWorkerPool().shutdownNow();
     }
 
     @Override

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/reader/IcebergSourceReader.java
Patch:
@@ -31,7 +31,6 @@
 
 import org.apache.iceberg.Schema;
 import org.apache.iceberg.io.CloseableIterator;
-import org.apache.iceberg.util.ThreadPools;
 
 import lombok.NonNull;
 import lombok.extern.slf4j.Slf4j;
@@ -101,8 +100,6 @@ public void close() throws IOException {
             icebergFileScanTaskSplitReader.close();
         }
         icebergTableLoader.close();
-        // TODO we should remove shutdown logic when supported closed part task
-        ThreadPools.getWorkerPool().shutdownNow();
     }
 
     @Override

File: seatunnel-connectors-v2/connector-influxdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/influxdb/sink/InfluxDBSinkWriter.java
Patch:
@@ -36,7 +36,6 @@
 
 import lombok.SneakyThrows;
 import lombok.extern.slf4j.Slf4j;
-import okhttp3.internal.concurrent.TaskRunner;
 
 import java.io.IOException;
 import java.net.ConnectException;
@@ -89,8 +88,6 @@ public void close() throws IOException {
         if (influxdb != null) {
             influxdb.close();
             influxdb = null;
-            // TODO we should remove shutdown logic when supported closed part task
-            ((TaskRunner.RealBackend) TaskRunner.INSTANCE.getBackend()).shutdown();
         }
     }
 

File: seatunnel-connectors-v2/connector-influxdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/influxdb/source/InfluxdbSourceReader.java
Patch:
@@ -35,7 +35,6 @@
 import org.influxdb.dto.QueryResult;
 
 import lombok.extern.slf4j.Slf4j;
-import okhttp3.internal.concurrent.TaskRunner;
 
 import java.net.ConnectException;
 import java.util.ArrayList;
@@ -94,8 +93,6 @@ public void close() {
         if (influxdb != null) {
             influxdb.close();
             influxdb = null;
-            // TODO we should remove shutdown logic when supported closed part task
-            ((TaskRunner.RealBackend) TaskRunner.INSTANCE.getBackend()).shutdown();
         }
     }
 

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/util/ContainerUtil.java
Patch:
@@ -166,7 +166,7 @@ public static String adaptPathForWin(String path) {
         return path == null ? "" : path.replaceAll("\\\\", "/");
     }
 
-    private static List<File> getConnectorFiles(
+    public static List<File> getConnectorFiles(
             File currentModule, Set<String> connectorNames, String connectorPrefix) {
         List<File> connectorFiles = new ArrayList<>();
         for (File file : Objects.requireNonNull(currentModule.listFiles())) {

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterSeaTunnelContainer.java
Patch:
@@ -47,8 +47,6 @@
 import static org.hamcrest.Matchers.equalTo;
 
 public class ClusterSeaTunnelContainer extends SeaTunnelContainer {
-    private static final String JDK_DOCKER_IMAGE = "openjdk:8";
-    private static final String SERVER_SHELL = "seatunnel-cluster.sh";
 
     private GenericContainer<?> secondServer;
 

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/EngineConfig.java
Patch:
@@ -53,6 +53,9 @@ public class EngineConfig {
     private ConnectorJarStorageConfig connectorJarStorageConfig =
             ServerConfigOptions.CONNECTOR_JAR_STORAGE_CONFIG.defaultValue();
 
+    private boolean classloaderCacheMode =
+            ServerConfigOptions.CLASSLOADER_CACHE_MODE.defaultValue();
+
     private QueueType queueType = ServerConfigOptions.QUEUE_TYPE.defaultValue();
     private int historyJobExpireMinutes =
             ServerConfigOptions.HISTORY_JOB_EXPIRE_MINUTES.defaultValue();

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/YamlSeaTunnelDomConfigProcessor.java
Patch:
@@ -143,6 +143,8 @@ private void parseEngineConfig(Node engineNode, SeaTunnelConfig config) {
                                 getTextContent(node)));
             } else if (ServerConfigOptions.CONNECTOR_JAR_STORAGE_CONFIG.key().equals(name)) {
                 engineConfig.setConnectorJarStorageConfig(parseConnectorJarStorageConfig(node));
+            } else if (ServerConfigOptions.CLASSLOADER_CACHE_MODE.key().equals(name)) {
+                engineConfig.setClassloaderCacheMode(getBooleanValue(getTextContent(node)));
             } else {
                 LOGGER.warning("Unrecognized element: " + name);
             }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalVertex.java
Patch:
@@ -343,6 +343,7 @@ private TaskDeployState deployInternal(
 
     private TaskGroupImmutableInformation getTaskGroupImmutableInformation() {
         return new TaskGroupImmutableInformation(
+                this.taskGroup.getTaskGroupLocation().getJobId(),
                 flakeIdGenerator.newId(),
                 nodeEngine.getSerializationService().toData(this.taskGroup),
                 this.pluginJarsUrls,

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/TaskGroupImmutableInformation.java
Patch:
@@ -34,6 +34,7 @@
 @lombok.Data
 @AllArgsConstructor
 public class TaskGroupImmutableInformation implements IdentifiedDataSerializable {
+    private long jobId;
     // Each deployment generates a new executionId
     private long executionId;
 
@@ -67,6 +68,7 @@ public int getClassId() {
 
     @Override
     public void writeData(ObjectDataOutput out) throws IOException {
+        out.writeLong(jobId);
         out.writeLong(executionId);
         out.writeObject(jars);
         out.writeObject(connectorJarIdentifiers);
@@ -75,6 +77,7 @@ public void writeData(ObjectDataOutput out) throws IOException {
 
     @Override
     public void readData(ObjectDataInput in) throws IOException {
+        jobId = in.readLong();
         executionId = in.readLong();
         jars = in.readObject();
         connectorJarIdentifiers = in.readObject();

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/config/MongodbSourceOptions.java
Patch:
@@ -241,8 +241,7 @@ public class MongodbSourceOptions extends SourceOptions {
             Options.key(SourceOptions.STARTUP_MODE_KEY)
                     .singleChoice(
                             StartupMode.class,
-                            Arrays.asList(
-                                    StartupMode.INITIAL, StartupMode.EARLIEST, StartupMode.LATEST))
+                            Arrays.asList(StartupMode.INITIAL, StartupMode.TIMESTAMP))
                     .defaultValue(StartupMode.INITIAL)
                     .withDescription(
                             "Optional startup mode for CDC source, valid enumerations are "

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/catalog/MetadataColumn.java
Patch:
@@ -34,7 +34,7 @@ public class MetadataColumn extends Column {
     protected MetadataColumn(
             String name,
             SeaTunnelDataType<?> dataType,
-            Integer columnLength,
+            Long columnLength,
             String metadataKey,
             boolean nullable,
             Object defaultValue,
@@ -46,7 +46,7 @@ protected MetadataColumn(
     public static MetadataColumn of(
             String name,
             SeaTunnelDataType<?> dataType,
-            Integer columnLength,
+            Long columnLength,
             String metadataKey,
             boolean nullable,
             Object defaultValue,

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/event/AlterTableColumnEvent.java
Patch:
@@ -17,13 +17,13 @@
 
 package org.apache.seatunnel.api.table.event;
 
-import org.apache.seatunnel.api.table.catalog.TablePath;
+import org.apache.seatunnel.api.table.catalog.TableIdentifier;
 
 import lombok.ToString;
 
 @ToString(callSuper = true)
 public abstract class AlterTableColumnEvent extends AlterTableEvent {
-    public AlterTableColumnEvent(TablePath tablePath) {
-        super(tablePath);
+    public AlterTableColumnEvent(TableIdentifier tableIdentifier) {
+        super(tableIdentifier);
     }
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/event/AlterTableDropColumnEvent.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.api.table.event;
 
-import org.apache.seatunnel.api.table.catalog.TablePath;
+import org.apache.seatunnel.api.table.catalog.TableIdentifier;
 
 import lombok.Getter;
 import lombok.ToString;
@@ -27,8 +27,8 @@
 public class AlterTableDropColumnEvent extends AlterTableColumnEvent {
     private final String column;
 
-    public AlterTableDropColumnEvent(TablePath tablePath, String column) {
-        super(tablePath);
+    public AlterTableDropColumnEvent(TableIdentifier tableIdentifier, String column) {
+        super(tableIdentifier);
         this.column = column;
     }
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/event/AlterTableEvent.java
Patch:
@@ -17,13 +17,13 @@
 
 package org.apache.seatunnel.api.table.event;
 
-import org.apache.seatunnel.api.table.catalog.TablePath;
+import org.apache.seatunnel.api.table.catalog.TableIdentifier;
 
 import lombok.ToString;
 
 @ToString(callSuper = true)
 public abstract class AlterTableEvent extends TableEvent {
-    public AlterTableEvent(TablePath tablePath) {
-        super(tablePath);
+    public AlterTableEvent(TableIdentifier tableIdentifier) {
+        super(tableIdentifier);
     }
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/event/handler/AlterTableEventHandler.java
Patch:
@@ -94,7 +94,7 @@ private SeaTunnelRowType applyAddColumn(
             return applyModifyColumn(
                     dataType,
                     new AlterTableModifyColumnEvent(
-                            addColumnEvent.tablePath(),
+                            addColumnEvent.tableIdentifier(),
                             addColumnEvent.getColumn(),
                             addColumnEvent.isFirst(),
                             addColumnEvent.getAfterColumn()));

File: seatunnel-api/src/test/java/org/apache/seatunnel/api/table/catalog/InMemoryCatalog.java
Patch:
@@ -69,7 +69,7 @@ private void addDefaultTable() {
                                         "name", BasicType.STRING_TYPE, 128, false, null, "name"))
                         .column(
                                 PhysicalColumn.of(
-                                        "age", BasicType.INT_TYPE, null, true, null, "age"))
+                                        "age", BasicType.INT_TYPE, (Long) null, true, null, "age"))
                         .column(
                                 PhysicalColumn.of(
                                         "createTime",

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-postgres/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/postgres/source/reader/PostgresSourceFetchTaskContext.java
Patch:
@@ -113,7 +113,8 @@ public PostgresSourceFetchTaskContext(
         this.metadataProvider = new PostgresEventMetadataProvider();
         this.engineHistory = engineHistory;
         this.postgresValueConverterBuilder =
-                newPostgresValueConverterBuilder(getDbzConnectorConfig());
+                newPostgresValueConverterBuilder(
+                        getDbzConnectorConfig(), sourceConfig.getServerTimeZone());
     }
 
     @Override

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/catalog/ElasticSearchCatalog.java
Patch:
@@ -158,7 +158,7 @@ public CatalogTable getTable(TablePath tablePath)
                             nameAndType.getKey(),
                             elasticSearchDataTypeConvertor.toSeaTunnelType(
                                     nameAndType.getKey(), nameAndType.getValue()),
-                            null,
+                            (Long) null,
                             true,
                             null,
                             null);

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/catalog/IcebergCatalog.java
Patch:
@@ -232,7 +232,7 @@ public CatalogTable toCatalogTable(Table icebergTable, TablePath tablePath) {
                                     PhysicalColumn.of(
                                             name,
                                             seaTunnelType,
-                                            null,
+                                            (Long) null,
                                             true,
                                             null,
                                             nestedField.doc());

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerType.java
Patch:
@@ -28,6 +28,7 @@
 import java.util.Map;
 import java.util.Objects;
 
+@Deprecated
 public enum SqlServerType implements SQLType {
     UNKNOWN("unknown", 999, Object.class),
     TINYINT("tinyint", java.sql.Types.TINYINT, Short.class),

File: seatunnel-connectors-v2/connector-jdbc/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sql/MysqlCreateTableSqlBuilderTest.java
Patch:
@@ -56,7 +56,7 @@ public void testBuild() {
                                         "name", BasicType.STRING_TYPE, 128, false, null, "name"))
                         .column(
                                 PhysicalColumn.of(
-                                        "age", BasicType.INT_TYPE, null, true, null, "age"))
+                                        "age", BasicType.INT_TYPE, (Long) null, true, null, "age"))
                         .column(
                                 PhysicalColumn.of(
                                         "createTime",

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -200,7 +200,7 @@ public void init(long initializationTimestamp, boolean restart) throws Exception
                         jobImmutableInformation.getJobConfig().getName(),
                         jobImmutableInformation.getJobId(),
                         jobImmutableInformation.getPluginJarsUrls()));
-
+        ClassLoader appClassLoader = Thread.currentThread().getContextClassLoader();
         ClassLoader classLoader =
                 new SeaTunnelChildFirstClassLoader(jobImmutableInformation.getPluginJarsUrls());
         logicalDag =
@@ -222,6 +222,8 @@ public void init(long initializationTimestamp, boolean restart) throws Exception
                         runningJobStateTimestampsIMap,
                         engineConfig.getQueueType(),
                         engineConfig);
+        // revert to app class loader, it may be changed by PlanUtils.fromLogicalDAG
+        Thread.currentThread().setContextClassLoader(appClassLoader);
         this.physicalPlan = planTuple.f0();
         this.physicalPlan.setJobMaster(this);
         this.checkpointPlanMap = planTuple.f1();

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/serialize/SeaTunnelRowConverter.java
Patch:
@@ -35,7 +35,8 @@ public class SeaTunnelRowConverter {
     @Builder.Default private DateUtils.Formatter dateFormatter = DateUtils.Formatter.YYYY_MM_DD;
 
     @Builder.Default
-    private DateTimeUtils.Formatter dateTimeFormatter = DateTimeUtils.Formatter.YYYY_MM_DD_HH_MM_SS;
+    private DateTimeUtils.Formatter dateTimeFormatter =
+            DateTimeUtils.Formatter.YYYY_MM_DD_HH_MM_SS_SSSSSS;
 
     @Builder.Default private TimeUtils.Formatter timeFormatter = TimeUtils.Formatter.HH_MM_SS;
 

File: seatunnel-connectors-v2/connector-file/connector-file-sftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sftp/system/SFTPInputStream.java
Patch:
@@ -110,6 +110,7 @@ public synchronized void close() throws IOException {
         if (closed) {
             return;
         }
+        wrappedStream.close();
         super.close();
         closed = true;
         if (!channel.isConnected()) {

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/config/DorisOptions.java
Patch:
@@ -152,7 +152,7 @@ public interface DorisOptions {
     Option<Boolean> SINK_ENABLE_2PC =
             Options.key("sink.enable-2pc")
                     .booleanType()
-                    .defaultValue(true)
+                    .defaultValue(false)
                     .withDescription("enable 2PC while loading");
 
     Option<Integer> SINK_CHECK_INTERVAL =

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/sink/writer/DorisSinkWriter.java
Patch:
@@ -116,7 +116,7 @@ private void initializeLoad() {
         }
         // get main work thread.
         executorThread = Thread.currentThread();
-        dorisStreamLoad.startLoad(labelGenerator.generateLabel(lastCheckpointId + 1));
+        startLoad(labelGenerator.generateLabel(lastCheckpointId + 1));
         // when uploading data in streaming mode, we need to regularly detect whether there are
         // exceptions.
         scheduledExecutorService.scheduleWithFixedDelay(

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-doris-e2e/src/test/java/org/apache/seatunnel/e2e/connector/doris/AbstractDorisIT.java
Patch:
@@ -85,7 +85,7 @@ public void startUp() {
                 .untilAsserted(this::initializeJdbcConnection);
     }
 
-    private void initializeJdbcConnection() throws SQLException {
+    protected void initializeJdbcConnection() throws SQLException {
         Properties props = new Properties();
         props.put("user", USERNAME);
         props.put("password", PASSWORD);

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/flink/AbstractTestFlinkContainer.java
Patch:
@@ -155,7 +155,7 @@ public Container.ExecResult executeJob(String confFile)
 
     @Override
     public String getServerLogs() {
-        return jobManager.getLogs();
+        return jobManager.getLogs() + "\n" + taskManager.getLogs();
     }
 
     public String executeJobManagerInnerCommand(String command)

File: seatunnel-connectors-v2/connector-assert/src/main/java/org/apache/seatunnel/connectors/seatunnel/assertion/rule/AssertFieldRule.java
Patch:
@@ -34,14 +34,16 @@ public class AssertFieldRule implements Serializable {
     public static class AssertRule implements Serializable {
         private AssertRuleType ruleType;
         private Double ruleValue;
-        private String equalTo;
+        private Object equalTo;
     }
 
     /**
      * Here is all supported value assert rule type, An exception will be thrown if a field value
      * break the rule
      */
     public enum AssertRuleType {
+        /** value can be null */
+        NULL,
         /** value can't be null */
         NOT_NULL,
         /** minimum value of the data */

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-1/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcMysqlMultipleTablesIT.java
Patch:
@@ -38,6 +38,7 @@
 import org.testcontainers.containers.MySQLContainer;
 import org.testcontainers.containers.output.Slf4jLogConsumer;
 import org.testcontainers.containers.wait.strategy.Wait;
+import org.testcontainers.images.PullPolicy;
 import org.testcontainers.lifecycle.Startables;
 import org.testcontainers.utility.DockerLoggerFactory;
 
@@ -223,6 +224,7 @@ private MySQLContainer startMySqlContainer() {
                         .withNetworkAliases(MYSQL_CONTAINER_HOST)
                         .withExposedPorts(MYSQL_PORT)
                         .waitingFor(Wait.forHealthcheck())
+                        .withImagePullPolicy(PullPolicy.alwaysPull())
                         .withLogConsumer(
                                 new Slf4jLogConsumer(DockerLoggerFactory.getLogger(MYSQL_IMAGE)));
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/catalog/CatalogTableUtil.java
Patch:
@@ -215,7 +215,7 @@ public static CatalogTable buildWithConfig(String catalogName, ReadonlyConfig re
         } else {
             Optional<String> resultTableNameOptional =
                     readonlyConfig.getOptional(CommonOptions.RESULT_TABLE_NAME);
-            tablePath = resultTableNameOptional.map(TablePath::of).orElse(TablePath.EMPTY);
+            tablePath = resultTableNameOptional.map(TablePath::of).orElse(TablePath.DEFAULT);
         }
 
         return CatalogTable.of(

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/catalog/TablePath.java
Patch:
@@ -34,7 +34,7 @@ public final class TablePath implements Serializable {
     private final String schemaName;
     private final String tableName;
 
-    public static final TablePath EMPTY = TablePath.of(null, null, null);
+    public static final TablePath DEFAULT = TablePath.of("default", "default", "default");
 
     public static TablePath of(String fullName) {
         return of(fullName, false);

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cdc-sqlserver-e2e/src/test/java/org/apache/seatunnel/e2e/connector/cdc/sqlserver/SqlServerCDCIT.java
Patch:
@@ -65,7 +65,7 @@
 @Slf4j
 @DisabledOnContainer(
         value = {},
-        type = {EngineType.SPARK, EngineType.FLINK},
+        type = {EngineType.SPARK},
         disabledReason = "Currently SPARK do not support cdc")
 public class SqlServerCDCIT extends TestSuiteBase implements TestResource {
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cdc-sqlserver-e2e/src/test/java/org/apache/seatunnel/e2e/connector/cdc/sqlserver/SqlServerCDCIT.java
Patch:
@@ -65,7 +65,7 @@
 @Slf4j
 @DisabledOnContainer(
         value = {},
-        type = {EngineType.SPARK},
+        type = {EngineType.SPARK, EngineType.FLINK},
         disabledReason = "Currently SPARK do not support cdc")
 public class SqlServerCDCIT extends TestSuiteBase implements TestResource {
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cdc-oracle-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/cdc/oracle/OracleCDCIT.java
Patch:
@@ -272,7 +272,7 @@ public void testOracleCdcCheckDataWithCustomPrimaryKey(TestContainer container)
             value = {},
             type = {EngineType.SPARK, EngineType.FLINK},
             disabledReason = "Currently SPARK and FLINK do not support multi table")
-    public void testMysqlCdcMultiTableE2e(TestContainer container)
+    public void testOracleCdcMultiTableE2e(TestContainer container)
             throws IOException, InterruptedException {
 
         clearTable(DATABASE, SOURCE_TABLE1);

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-1/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcMysqlIT.java
Patch:
@@ -74,7 +74,7 @@
 
 public class JdbcMysqlIT extends AbstractJdbcIT {
 
-    private static final String MYSQL_IMAGE = "mysql:latest";
+    private static final String MYSQL_IMAGE = "mysql:8.0";
     private static final String MYSQL_CONTAINER_HOST = "mysql-e2e";
     private static final String MYSQL_DATABASE = "seatunnel";
     private static final String MYSQL_SOURCE = "source";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-4/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcMySqlCreateTableIT.java
Patch:
@@ -72,7 +72,7 @@ public class JdbcMySqlCreateTableIT extends TestSuiteBase implements TestResourc
     private static final String PG_GEOMETRY_JAR =
             "https://repo1.maven.org/maven2/net/postgis/postgis-geometry/2.5.1/postgis-geometry-2.5.1.jar";
 
-    private static final String MYSQL_IMAGE = "mysql:latest";
+    private static final String MYSQL_IMAGE = "mysql:8.0";
     private static final String MYSQL_CONTAINER_HOST = "mysql-e2e";
     private static final String MYSQL_DATABASE = "auto";
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-4/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcSqlServerCreateTableIT.java
Patch:
@@ -128,7 +128,7 @@ public class JdbcSqlServerCreateTableIT extends TestSuiteBase implements TestRes
     private static final String PG_GEOMETRY_JAR =
             "https://repo1.maven.org/maven2/net/postgis/postgis-geometry/2.5.1/postgis-geometry-2.5.1.jar";
 
-    private static final String MYSQL_IMAGE = "mysql:latest";
+    private static final String MYSQL_IMAGE = "mysql:8.0";
     private static final String MYSQL_CONTAINER_HOST = "mysql-e2e";
     private static final String MYSQL_DATABASE = "auto";
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-7/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcMySqlSaveModeCatalogIT.java
Patch:
@@ -52,7 +52,7 @@ public class JdbcMySqlSaveModeCatalogIT extends TestSuiteBase implements TestRes
     private static final String MYSQL_DRIVER_JAR =
             "https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.0.32/mysql-connector-j-8.0.32.jar";
 
-    private static final String MYSQL_IMAGE = "mysql:latest";
+    private static final String MYSQL_IMAGE = "mysql:8.0";
     private static final String MYSQL_CONTAINER_HOST = "mysql-e2e";
     private static final String MYSQL_DATABASE = "auto";
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-7/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcMysqlSaveModeHandlerIT.java
Patch:
@@ -55,7 +55,7 @@
 @Slf4j
 public class JdbcMysqlSaveModeHandlerIT extends AbstractJdbcIT {
 
-    private static final String MYSQL_IMAGE = "mysql:latest";
+    private static final String MYSQL_IMAGE = "mysql:8.0";
     private static final String MYSQL_CONTAINER_HOST = "mysql-e2e-2";
     private static final String MYSQL_DATABASE = "seatunnel";
     private static final String MYSQL_SOURCE = "source";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-7/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcMysqlSplitIT.java
Patch:
@@ -74,7 +74,7 @@
 public class JdbcMysqlSplitIT extends TestSuiteBase implements TestResource {
     private static final Logger LOG = LoggerFactory.getLogger(JdbcMysqlSplitIT.class);
 
-    private static final String MYSQL_IMAGE = "mysql:latest";
+    private static final String MYSQL_IMAGE = "mysql:8.0";
     private static final String MYSQL_CONTAINER_HOST = "mysql-e2e";
     private static final String MYSQL_DATABASE = "auto";
     private static final String MYSQL_TABLE = "split_test";

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/configuration/util/ConfigUtil.java
Patch:
@@ -111,6 +111,8 @@ static <T> T convertValue(Object rawValue, Class<T> clazz) {
             return (T) convertToFloat(rawValue);
         } else if (Double.class.equals(clazz)) {
             return (T) convertToDouble(rawValue);
+        } else if (Object.class.equals(clazz)) {
+            return (T) rawValue;
         }
         throw new IllegalArgumentException("Unsupported type: " + clazz);
     }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/option/SourceOptions.java
Patch:
@@ -105,7 +105,7 @@ public class SourceOptions {
     public static final Option<Boolean> EXACTLY_ONCE =
             Options.key("exactly_once")
                     .booleanType()
-                    .defaultValue(true)
+                    .defaultValue(false)
                     .withDescription("Enable exactly once semantic.");
 
     public static OptionRule.Builder getBaseRule() {

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterIT.java
Patch:
@@ -77,7 +77,7 @@ public void getClusterHealthMetrics() {
 
         } finally {
             if (engineClient != null) {
-                engineClient.shutdown();
+                engineClient.close();
             }
 
             if (node1 != null) {

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/SeaTunnelSlotIT.java
Patch:
@@ -82,7 +82,7 @@ public void testSlotNotEnough() throws Exception {
 
         } finally {
             if (engineClient != null) {
-                engineClient.shutdown();
+                engineClient.close();
             }
 
             if (node1 != null) {
@@ -134,7 +134,7 @@ public void testSlotEnough() throws Exception {
 
         } finally {
             if (engineClient != null) {
-                engineClient.shutdown();
+                engineClient.close();
             }
 
             if (node1 != null) {

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/TextHeaderIT.java
Patch:
@@ -161,7 +161,7 @@ public void enableWriteHeader(String file_format_type, String headerWrite, Strin
             log.info("========================clean test resource====================");
         } finally {
             if (engineClient != null) {
-                engineClient.shutdown();
+                engineClient.close();
             }
             if (node1 != null) {
                 node1.shutdown();

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/utils/SqlServerTypeUtils.java
Patch:
@@ -49,6 +49,7 @@ public class SqlServerTypeUtils {
 
     // ------------------------------number-------------------------
     private static final String SQLSERVER_INTEGER = "INT";
+    private static final String SQLSERVER_INT_IDENTITY = "INT IDENTITY";
     private static final String SQLSERVER_SMALLINT = "SMALLINT";
     private static final String SQLSERVER_TINYINT = "TINYINT";
     private static final String SQLSERVER_BIGINT = "BIGINT";
@@ -91,6 +92,7 @@ public static SeaTunnelDataType<?> convertFromColumn(Column column) {
             case SQLSERVER_VARBINARY:
                 return PrimitiveByteArrayType.INSTANCE;
             case SQLSERVER_INTEGER:
+            case SQLSERVER_INT_IDENTITY:
                 return BasicType.INT_TYPE;
             case SQLSERVER_SMALLINT:
             case SQLSERVER_TINYINT:

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerDataTypeConvertor.java
Patch:
@@ -60,6 +60,7 @@ public SeaTunnelDataType<?> toSeaTunnelType(
             case SMALLINT:
                 return BasicType.SHORT_TYPE;
             case INTEGER:
+            case INT_IDENTITY:
                 return BasicType.INT_TYPE;
             case BIGINT:
                 return BasicType.LONG_TYPE;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerType.java
Patch:
@@ -34,6 +34,7 @@ public enum SqlServerType implements SQLType {
     BIT("bit", java.sql.Types.BIT, Boolean.class),
     SMALLINT("smallint", java.sql.Types.SMALLINT, Short.class),
     INTEGER("int", java.sql.Types.INTEGER, Integer.class),
+    INT_IDENTITY("int identity", java.sql.Types.INTEGER, Integer.class),
     BIGINT("bigint", java.sql.Types.BIGINT, Long.class),
     FLOAT("float", java.sql.Types.DOUBLE, Double.class),
     REAL("real", java.sql.Types.REAL, Float.class),

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-common/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/AbstractJdbcIT.java
Patch:
@@ -193,6 +193,9 @@ protected void createNeededTables() {
                                     jdbcCase.getDatabase(),
                                     jdbcCase.getSchema(),
                                     jdbcCase.getSourceTable()));
+            if (jdbcCase.getSinkCreateSql() != null) {
+                createTemplate = jdbcCase.getSinkCreateSql();
+            }
             String createSink =
                     String.format(
                             createTemplate,

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-common/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcCase.java
Patch:
@@ -47,6 +47,7 @@ public class JdbcCase {
     private String jdbcTemplate;
     private String jdbcUrl;
     private String createSql;
+    private String sinkCreateSql;
     private String insertSql;
     private List<String> configFile;
     private Pair<String[], List<SeaTunnelRow>> testData;

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/master/JobMetricsTest.java
Patch:
@@ -141,7 +141,6 @@ public void testMetricsOnJobRestart() throws InterruptedException {
                 .untilAsserted(
                         () -> {
                             JobMetrics jobMetrics = coordinatorService.getJobMetrics(jobId3);
-                            log.info(jobMetrics.toJsonString());
                             assertTrue(40 < (Long) jobMetrics.get(SINK_WRITE_COUNT).get(0).value());
                             assertTrue(40 < (Long) jobMetrics.get(SINK_WRITE_COUNT).get(1).value());
                             assertTrue(

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-fake-e2e/src/test/java/org/apache/seatunnel/e2e/connector/fake/FakeIT.java
Patch:
@@ -38,5 +38,8 @@ public void testFakeConnector(TestContainer container)
         Container.ExecResult fakeWithTemplate =
                 container.executeJob("/fake_to_assert_with_template.conf");
         Assertions.assertEquals(0, fakeWithTemplate.getExitCode());
+        Container.ExecResult fakeComplex =
+                container.executeJob("/fake_generic_row_type_to_assert.conf");
+        Assertions.assertEquals(0, fakeWithTemplate.getExitCode());
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -560,7 +560,9 @@ public void handleCheckpointError() {
         log.warn(
                 String.format(
                         "%s checkpoint have error, cancel the pipeline", getPipelineFullName()));
-        this.cancelPipeline();
+        if (!getPipelineState().isEndState()) {
+            updatePipelineState(PipelineStatus.CANCELING);
+        }
     }
 
     public void startSubPlanStateProcess() {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-oracle/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/oracle/source/OracleIncrementalSourceFactory.java
Patch:
@@ -103,7 +103,7 @@ TableSource<T, SplitT, StateT> createSource(TableSourceFactoryContext context) {
                     CatalogTableUtil.getCatalogTables(
                             context.getOptions(), context.getClassLoader());
             SeaTunnelDataType<SeaTunnelRow> dataType =
-                    CatalogTableUtil.convertToDataType(catalogTables);
+                    CatalogTableUtil.convertToMultipleRowType(catalogTables);
             return new OracleIncrementalSource(context.getOptions(), dataType, catalogTables);
         };
     }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-oracle/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/oracle/utils/OracleUtils.java
Patch:
@@ -56,6 +56,8 @@
 @Slf4j
 public class OracleUtils {
 
+    private static final int DEFAULT_FETCH_SIZE = 1024;
+
     private OracleUtils() {}
 
     public static Object[] queryMinMax(JdbcConnection jdbc, TableId tableId, String columnName)
@@ -162,7 +164,7 @@ public static Object[] skipReadAndSortSampleData(
                             .createStatement(
                                     ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);
 
-            stmt.setFetchSize(Integer.MIN_VALUE);
+            stmt.setFetchSize(DEFAULT_FETCH_SIZE);
             rs = stmt.executeQuery(sampleQuery);
 
             int count = 0;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/dm/DamengCatalog.java
Patch:
@@ -61,8 +61,8 @@ public class DamengCatalog extends AbstractJdbcCatalog {
                     + "ON COLUMNS.OWNER = COMMENTS.SCHEMA_NAME "
                     + "AND COLUMNS.TABLE_NAME = COMMENTS.TABLE_NAME "
                     + "AND COLUMNS.COLUMN_NAME = COMMENTS.COLUMN_NAME "
-                    + "WHERE COLUMNS.OWNER = ? "
-                    + "AND COLUMNS.TABLE_NAME = ? "
+                    + "WHERE COLUMNS.OWNER = '%s' "
+                    + "AND COLUMNS.TABLE_NAME = '%s' "
                     + "ORDER BY COLUMNS.COLUMN_ID ASC";
 
     public DamengCatalog(

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/ExcelReadStrategy.java
Patch:
@@ -91,7 +91,6 @@ public void read(String path, String tableId, Collector<SeaTunnelRow> output) {
                         : workbook.getSheetAt(0);
         cellCount = seaTunnelRowType.getTotalFields();
         cellCount = partitionsMap.isEmpty() ? cellCount : cellCount + partitionsMap.size();
-        SeaTunnelRow seaTunnelRow = new SeaTunnelRow(cellCount);
         SeaTunnelDataType<?>[] fieldTypes = seaTunnelRowType.getFieldTypes();
         int rowCount = sheet.getPhysicalNumberOfRows();
         if (skipHeaderNumber > Integer.MAX_VALUE
@@ -111,6 +110,7 @@ public void read(String path, String tableId, Collector<SeaTunnelRow> output) {
                                             ? IntStream.range(0, cellCount).toArray()
                                             : indexes;
                             int z = 0;
+                            SeaTunnelRow seaTunnelRow = new SeaTunnelRow(cellCount);
                             for (int j : cellIndexes) {
                                 Cell cell = rowData.getCell(j);
                                 seaTunnelRow.setField(

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-3/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcSqlServerIT.java
Patch:
@@ -312,7 +312,7 @@ public void testCatalog(TestContainer container) throws IOException, Interrupted
         Assertions.assertFalse(existsDataBefore);
         // insert one data
         sqlServerCatalog.executeSql(
-                tablePathSqlserver_Sink, "insert into sink_lw(age, name) values(12,'laowang')");
+                tablePathSqlserver_Sink, "insert into sink_lw(BIGINT_TEST) values(12)");
         boolean existsDataAfter = sqlServerCatalog.isExistsData(tablePathSqlserver_Sink);
         Assertions.assertTrue(existsDataAfter);
         // truncateTable

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerDataTypeConvertor.java
Patch:
@@ -81,6 +81,8 @@ public SeaTunnelDataType<?> toSeaTunnelType(
             case NVARCHAR:
             case TEXT:
             case XML:
+            case GUID:
+            case SQL_VARIANT:
                 return BasicType.STRING_TYPE;
             case DATE:
                 return LocalTimeType.LOCAL_DATE_TYPE;

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-3/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcHiveIT.java
Patch:
@@ -131,7 +131,7 @@ protected void insertTestData() {
                                 + "        TRUE,"
                                 + "        '2023-09-04',"
                                 + "        '2023-09-04 10:30:00',"
-                                + "        42.12,"
+                                + "        42.10,"
                                 + "        42.12)");
             }
         } catch (Exception exception) {

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/exception/CommonErrorCodeDeprecated.java
Patch:
@@ -24,8 +24,6 @@
  */
 @Deprecated
 public enum CommonErrorCodeDeprecated implements SeaTunnelErrorCode {
-    FILE_OPERATION_FAILED(
-            "COMMON-01", "File operation failed, such as (read,list,write,move,copy,sync) etc..."),
     REFLECT_CLASS_OPERATION_FAILED("COMMON-03", "Reflect class operation failed"),
     SERIALIZE_OPERATION_FAILED("COMMON-04", "Serialize class operation failed"),
     UNSUPPORTED_OPERATION("COMMON-05", "Unsupported operation"),

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/AbstractWriteStrategy.java
Patch:
@@ -286,7 +286,7 @@ public void abortPrepare(String transactionId) {
             hadoopFileSystemProxy.deleteFile(getTransactionDir(transactionId));
         } catch (IOException e) {
             throw new FileConnectorException(
-                    CommonErrorCodeDeprecated.FILE_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.WRITER_OPERATION_FAILED,
                     "Abort transaction "
                             + transactionId
                             + " error, delete transaction directory failed",

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/OrcWriteStrategy.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
+import org.apache.seatunnel.common.exception.CommonError;
 import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.config.FileSinkConfig;
@@ -86,9 +87,7 @@ public void write(@NonNull SeaTunnelRow seaTunnelRow) {
             writer.addRowBatch(rowBatch);
             rowBatch.reset();
         } catch (IOException e) {
-            String errorMsg = String.format("Write data to orc file [%s] error", filePath);
-            throw new FileConnectorException(
-                    CommonErrorCodeDeprecated.FILE_OPERATION_FAILED, errorMsg, e);
+            throw CommonError.fileOperationFailed("OrcFile", "write", filePath, e);
         }
     }
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/ParquetWriteStrategy.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
+import org.apache.seatunnel.common.exception.CommonError;
 import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.file.config.HadoopConf;
 import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
@@ -104,9 +105,7 @@ public void write(@NonNull SeaTunnelRow seaTunnelRow) {
         try {
             writer.write(record);
         } catch (IOException e) {
-            String errorMsg = String.format("Write data to file [%s] error", filePath);
-            throw new FileConnectorException(
-                    CommonErrorCodeDeprecated.FILE_OPERATION_FAILED, errorMsg, e);
+            throw CommonError.fileOperationFailed("ParquetFile", "write", filePath, e);
         }
     }
 

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/seatunnel/SeaTunnelContainer.java
Patch:
@@ -49,7 +49,7 @@ public class SeaTunnelContainer extends AbstractTestContainer {
     private static final String JDK_DOCKER_IMAGE = "openjdk:8";
     private static final String CLIENT_SHELL = "seatunnel.sh";
     private static final String SERVER_SHELL = "seatunnel-cluster.sh";
-    private GenericContainer<?> server;
+    protected GenericContainer<?> server;
 
     @Override
     public void startUp() throws Exception {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/job/Job.java
Patch:
@@ -29,6 +29,7 @@ public interface Job {
 
     JobStatus getJobStatus();
 
+    @Deprecated
     default JobStatus waitForJobComplete() {
         return waitForJobCompleteV2().getStatus();
     }

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/JsonToRowConverters.java
Patch:
@@ -394,9 +394,9 @@ public Object convert(JsonNode jsonNode) {
                 }
                 try {
                     return converter.convert(jsonNode);
-                } catch (Throwable t) {
+                } catch (RuntimeException e) {
                     if (!ignoreParseErrors) {
-                        throw t;
+                        throw e;
                     }
                     return null;
                 }

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/canal/CanalJsonDeserializationSchema.java
Patch:
@@ -169,9 +169,9 @@ public void deserialize(ObjectNode jsonNode, Collector<SeaTunnelRow> out) throws
             } else {
                 throw new IllegalStateException(format("Unknown operation type '%s'.", type));
             }
-        } catch (Throwable t) {
+        } catch (RuntimeException e) {
             if (!ignoreParseErrors) {
-                throw CommonError.jsonOperationError(FORMAT, jsonNode.toString(), t);
+                throw CommonError.jsonOperationError(FORMAT, jsonNode.toString(), e);
             }
         }
     }

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/debezium/DebeziumJsonDeserializationSchema.java
Patch:
@@ -120,10 +120,10 @@ public void deserialize(byte[] message, Collector<SeaTunnelRow> out) throws IOEx
             } else {
                 throw new IllegalStateException(format("Unknown operation type '%s'.", op));
             }
-        } catch (Throwable t) {
+        } catch (RuntimeException e) {
             // a big try catch to protect the processing.
             if (!ignoreParseErrors) {
-                throw CommonError.jsonOperationError(FORMAT, new String(message), t);
+                throw CommonError.jsonOperationError(FORMAT, new String(message), e);
             }
         }
     }

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/exception/CommonErrorCode.java
Patch:
@@ -19,7 +19,8 @@
 
 /** SeaTunnel connector error code interface */
 public enum CommonErrorCode implements SeaTunnelErrorCode {
-    JSON_OPERATION_FAILED("COMMON-02", "<format> JSON convert/parse '<payload>' operation failed."),
+    JSON_OPERATION_FAILED(
+            "COMMON-02", "<identifier> JSON convert/parse '<payload>' operation failed."),
 
     UNSUPPORTED_DATA_TYPE(
             "COMMON-07", "'<identifier>' unsupported data type '<dataType>' of '<field>'"),

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/exception/CommonErrorCodeDeprecated.java
Patch:
@@ -26,7 +26,6 @@
 public enum CommonErrorCodeDeprecated implements SeaTunnelErrorCode {
     FILE_OPERATION_FAILED(
             "COMMON-01", "File operation failed, such as (read,list,write,move,copy,sync) etc..."),
-    JSON_OPERATION_FAILED("COMMON-02", "Json covert/parse operation failed"),
     REFLECT_CLASS_OPERATION_FAILED("COMMON-03", "Reflect class operation failed"),
     SERIALIZE_OPERATION_FAILED("COMMON-04", "Serialize class operation failed"),
     UNSUPPORTED_OPERATION("COMMON-05", "Unsupported operation"),

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeDataGenerator.java
Patch:
@@ -26,6 +26,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
+import org.apache.seatunnel.common.exception.CommonError;
 import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.fake.config.FakeConfig;
 import org.apache.seatunnel.connectors.seatunnel.fake.exception.FakeConnectorException;
@@ -67,7 +68,7 @@ private SeaTunnelRow convertRow(FakeConfig.RowData rowData) {
             seaTunnelRow.setTableId(tableId);
             return seaTunnelRow;
         } catch (IOException e) {
-            throw new FakeConnectorException(CommonErrorCodeDeprecated.JSON_OPERATION_FAILED, e);
+            throw CommonError.jsonOperationError("Fake", rowData.getFieldsJson(), e);
         }
     }
 

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/RestApiIT.java
Patch:
@@ -238,7 +238,9 @@ public void testSubmitJob() {
                                                     + RestConstant.FINISHED_JOBS_INFO)
                                     .then()
                                     .statusCode(200)
-                                    .body("[" + i.get() + "].jobName", equalTo("test测试"))
+                                    .body(
+                                            "[" + i.get() + "].jobName",
+                                            equalTo(i.get() == 0 ? paramJobName : jobName))
                                     .body("[" + i.get() + "].errorMsg", equalTo(null))
                                     .body(
                                             "[" + i.get() + "].jobDag.jobId",

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/utils/RestUtil.java
Patch:
@@ -21,7 +21,6 @@
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
-import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.core.starter.utils.ConfigBuilder;
 import org.apache.seatunnel.engine.server.rest.RestConstant;
@@ -44,7 +43,6 @@ public static JsonNode convertByteToJsonNode(byte[] byteData) throws IOException
 
     public static void buildRequestParams(Map<String, String> requestParams, String uri) {
         requestParams.put(RestConstant.JOB_ID, null);
-        requestParams.put(RestConstant.JOB_NAME, Constants.LOGO);
         requestParams.put(RestConstant.IS_START_WITH_SAVE_POINT, String.valueOf(false));
         uri = StringUtil.stripTrailingSlash(uri);
         if (!uri.contains("?")) {

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/command/AbstractCommandArgs.java
Patch:
@@ -42,7 +42,9 @@ public abstract class AbstractCommandArgs extends CommandArgs {
     @Parameter(
             names = {"-i", "--variable"},
             splitter = ParameterSplitter.class,
-            description = "Variable substitution, such as -i city=beijing, or -i date=20190318")
+            description =
+                    "Variable substitution, such as -i city=beijing, or -i date=20190318."
+                            + "We use ',' as separator, when inside \"\", ',' are treated as normal characters instead of delimiters.")
     protected List<String> variables = Collections.emptyList();
 
     /** check config flag */

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/utils/SqlServerUtils.java
Patch:
@@ -165,7 +165,7 @@ public static Object[] skipReadAndSortSampleData(
                             .createStatement(
                                     ResultSet.TYPE_FORWARD_ONLY, ResultSet.CONCUR_READ_ONLY);
 
-            stmt.setFetchSize(Integer.MIN_VALUE);
+            stmt.setFetchSize(1024);
             rs = stmt.executeQuery(sampleQuery);
 
             int count = 0;

File: seatunnel-formats/seatunnel-format-compatible-debezium-json/src/main/java/org/apache/seatunnel/format/compatible/debezium/json/CompatibleDebeziumJsonDeserializationSchema.java
Patch:
@@ -60,8 +60,7 @@ public SeaTunnelRow deserialize(SourceRecord record)
         String key = debeziumJsonConverter.serializeKey(record);
         String value = debeziumJsonConverter.serializeValue(record);
         Object[] fields = new Object[] {record.topic(), key, value};
-        SeaTunnelRow row = new SeaTunnelRow(fields);
-        return row;
+        return new SeaTunnelRow(fields);
     }
 
     @Override

File: seatunnel-formats/seatunnel-format-compatible-debezium-json/src/main/java/org/apache/seatunnel/format/compatible/debezium/json/CompatibleDebeziumJsonSerializationSchema.java
Patch:
@@ -29,7 +29,6 @@
 
 @RequiredArgsConstructor
 public class CompatibleDebeziumJsonSerializationSchema implements SerializationSchema {
-    public static final String IDENTIFIER = CompatibleDebeziumJsonDeserializationSchema.IDENTIFIER;
 
     private final int index;
 

File: seatunnel-formats/seatunnel-format-compatible-debezium-json/src/main/java/org/apache/seatunnel/format/compatible/debezium/json/DebeziumJsonConverter.java
Patch:
@@ -41,8 +41,8 @@ public class DebeziumJsonConverter implements Serializable {
 
     private final boolean keySchemaEnable;
     private final boolean valueSchemaEnable;
-    private transient JsonConverter keyConverter;
-    private transient JsonConverter valueConverter;
+    private transient volatile JsonConverter keyConverter;
+    private transient volatile JsonConverter valueConverter;
     private transient Method keyConverterMethod;
     private transient Method valueConverterMethod;
 

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/FileUtils.java
Patch:
@@ -101,7 +101,7 @@ public static void createParentFile(File file) {
      *
      * @param filePath filePath
      */
-    public static void createNewFile(String filePath) {
+    public static void createNewFile(String filePath) throws IOException {
         File file = new File(filePath);
         if (file.exists()) {
             file.delete();
@@ -110,6 +110,7 @@ public static void createNewFile(String filePath) {
         if (!file.getParentFile().exists()) {
             createParentFile(file);
         }
+        file.createNewFile();
     }
 
     /**

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/TestUtils.java
Patch:
@@ -24,6 +24,7 @@
 import lombok.extern.slf4j.Slf4j;
 
 import java.io.File;
+import java.io.IOException;
 import java.nio.file.Paths;
 import java.util.Map;
 
@@ -54,7 +55,8 @@ public static String getResource(String confFile) {
     public static void createTestConfigFileFromTemplate(
             @NonNull String templateFile,
             @NonNull Map<String, String> valueMap,
-            @NonNull String targetFilePath) {
+            @NonNull String targetFilePath)
+            throws IOException {
         String templateFilePath = getResource(templateFile);
         String confContent = FileUtils.readFileToStr(Paths.get(templateFilePath));
         String targetConfContent = VariablesSubstitute.substitute(confContent, valueMap);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/utils/JdbcCatalogUtils.java
Patch:
@@ -76,7 +76,7 @@ public static Map<TablePath, JdbcSourceTable> getTables(
                 log.info("Loading catalog tables for catalog : {}", jdbcCatalog.getClass());
 
                 jdbcCatalog.open();
-                Map<String, Map<String, String>> unsupportedTable = new HashMap<>();
+                Map<String, Map<String, String>> unsupportedTable = new LinkedHashMap<>();
                 for (JdbcSourceTableConfig tableConfig : tablesConfig) {
                     try {
                         CatalogTable catalogTable =

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/kuduclient/KuduTypeMapper.java
Patch:
@@ -32,15 +32,13 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.sql.SQLException;
 import java.util.List;
 
 public class KuduTypeMapper {
 
     private static final Logger log = LoggerFactory.getLogger(KuduTypeMapper.class);
 
-    public static SeaTunnelDataType<?> mapping(List<ColumnSchema> columnSchemaList, int colIndex)
-            throws SQLException {
+    public static SeaTunnelDataType<?> mapping(List<ColumnSchema> columnSchemaList, int colIndex) {
         Type kuduType = columnSchemaList.get(colIndex).getType();
         switch (kuduType) {
             case BOOL:

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/FixedChunkSplitter.java
Patch:
@@ -33,6 +33,7 @@
 
 import java.io.Serializable;
 import java.math.BigDecimal;
+import java.math.BigInteger;
 import java.sql.Array;
 import java.sql.Date;
 import java.sql.PreparedStatement;
@@ -250,6 +251,8 @@ private BigDecimal convertToBigDecimal(Object o) {
             return (BigDecimal) o;
         } else if (o instanceof Long) {
             return BigDecimal.valueOf((Long) o);
+        } else if (o instanceof BigInteger) {
+            return new BigDecimal((BigInteger) o);
         } else if (o instanceof Integer) {
             return BigDecimal.valueOf((Integer) o);
         } else if (o instanceof Double) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -442,7 +442,7 @@ protected void tryTriggerPendingCheckpoint(CheckpointType checkpointType) {
 
             if (pendingCounter.get() > 0) {
                 scheduleTriggerPendingCheckpoint(checkpointType, 500L);
-                LOG.info("skip trigger checkpoint because there is already a pending checkpoint.");
+                LOG.debug("skip trigger checkpoint because there is already a pending checkpoint.");
                 return;
             }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/converter/JdbcRowConverter.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.converter;
 
+import org.apache.seatunnel.api.table.catalog.TableSchema;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 
 import java.io.Serializable;
 import java.sql.PreparedStatement;
@@ -36,9 +36,9 @@ public interface JdbcRowConverter extends Serializable {
      *
      * @param rs ResultSet from JDBC
      */
-    SeaTunnelRow toInternal(ResultSet rs, SeaTunnelRowType typeInfo) throws SQLException;
+    SeaTunnelRow toInternal(ResultSet rs, TableSchema tableSchema) throws SQLException;
 
     PreparedStatement toExternal(
-            SeaTunnelRowType rowType, SeaTunnelRow row, PreparedStatement statement)
+            TableSchema tableSchema, SeaTunnelRow row, PreparedStatement statement)
             throws SQLException;
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/hive/HiveJdbcRowConverter.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.hive;
 
+import org.apache.seatunnel.api.table.catalog.TableSchema;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.converter.AbstractJdbcRowConverter;
@@ -35,7 +35,7 @@ public String converterName() {
 
     @Override
     public PreparedStatement toExternal(
-            SeaTunnelRowType rowType, SeaTunnelRow row, PreparedStatement statement) {
+            TableSchema tableSchema, SeaTunnelRow row, PreparedStatement statement) {
         throw new JdbcConnectorException(
                 JdbcConnectorErrorCode.DONT_SUPPORT_SINK,
                 "The Hive jdbc connector don't support sink");

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/psql/PostgresJdbcRowConverter.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.psql;
 
+import org.apache.seatunnel.api.table.catalog.TableSchema;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
@@ -45,7 +46,8 @@ public String converterName() {
     }
 
     @Override
-    public SeaTunnelRow toInternal(ResultSet rs, SeaTunnelRowType typeInfo) throws SQLException {
+    public SeaTunnelRow toInternal(ResultSet rs, TableSchema tableSchema) throws SQLException {
+        SeaTunnelRowType typeInfo = tableSchema.toPhysicalRowDataType();
         Object[] fields = new Object[typeInfo.getTotalFields()];
         for (int fieldIndex = 0; fieldIndex < typeInfo.getTotalFields(); fieldIndex++) {
             SeaTunnelDataType<?> seaTunnelDataType = typeInfo.getFieldType(fieldIndex);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/executor/SimpleBatchStatementExecutor.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.executor;
 
+import org.apache.seatunnel.api.table.catalog.TableSchema;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.converter.JdbcRowConverter;
 
 import lombok.NonNull;
@@ -31,7 +31,7 @@
 @RequiredArgsConstructor
 public class SimpleBatchStatementExecutor implements JdbcBatchStatementExecutor<SeaTunnelRow> {
     @NonNull private final StatementFactory statementFactory;
-    @NonNull private final SeaTunnelRowType rowType;
+    @NonNull private final TableSchema tableSchema;
     @NonNull private final JdbcRowConverter converter;
     private transient PreparedStatement statement;
 
@@ -42,7 +42,7 @@ public void prepareStatements(Connection connection) throws SQLException {
 
     @Override
     public void addToBatch(SeaTunnelRow record) throws SQLException {
-        converter.toExternal(rowType, record, statement);
+        converter.toExternal(tableSchema, record, statement);
         statement.addBatch();
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcExactlyOnceSinkWriter.java
Patch:
@@ -20,8 +20,8 @@
 import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.sink.SinkWriter;
 import org.apache.seatunnel.api.sink.SupportMultiTableSinkWriter;
+import org.apache.seatunnel.api.table.catalog.TableSchema;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorErrorCode;
@@ -84,7 +84,7 @@ public JdbcExactlyOnceSinkWriter(
             JobContext context,
             JdbcDialect dialect,
             JdbcSinkConfig jdbcSinkConfig,
-            SeaTunnelRowType rowType,
+            TableSchema tableSchema,
             List<JdbcSinkState> states) {
         checkArgument(
                 jdbcSinkConfig.getJdbcConnectionConfig().getMaxRetries() == 0,
@@ -99,7 +99,7 @@ public JdbcExactlyOnceSinkWriter(
         this.xaFacade =
                 XaFacade.fromJdbcConnectionOptions(jdbcSinkConfig.getJdbcConnectionConfig());
         this.outputFormat =
-                new JdbcOutputFormatBuilder(dialect, xaFacade, jdbcSinkConfig, rowType).build();
+                new JdbcOutputFormatBuilder(dialect, xaFacade, jdbcSinkConfig, tableSchema).build();
         this.xaGroupOps = new XaGroupOpsImpl(xaFacade);
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/JdbcSourceReader.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.source.Collector;
 import org.apache.seatunnel.api.source.SourceReader;
+import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.JdbcInputFormat;
 
@@ -42,7 +42,7 @@ public class JdbcSourceReader implements SourceReader<SeaTunnelRow, JdbcSourceSp
     private volatile boolean noMoreSplit;
 
     public JdbcSourceReader(
-            Context context, JdbcSourceConfig config, Map<TablePath, SeaTunnelRowType> tables) {
+            Context context, JdbcSourceConfig config, Map<TablePath, CatalogTable> tables) {
         this.inputFormat = new JdbcInputFormat(config, tables);
         this.context = context;
     }

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/config/HttpConfig.java
Patch:
@@ -67,7 +67,7 @@ public class HttpConfig {
     public static final Option<ResponseFormat> FORMAT =
             Options.key("format")
                     .enumType(ResponseFormat.class)
-                    .defaultValue(ResponseFormat.JSON)
+                    .defaultValue(ResponseFormat.TEXT)
                     .withDescription("Http response format");
     public static final Option<Integer> POLL_INTERVAL_MILLS =
             Options.key("poll_interval_millis")
@@ -113,7 +113,8 @@ public class HttpConfig {
                             "SeaTunnel enableMultiLines.This parameter can support http splitting response text by line.");
 
     public enum ResponseFormat {
-        JSON("json");
+        JSON("json"),
+        TEXT("text");
 
         private String format;
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-http-e2e/src/test/java/org/apache/seatunnel/e2e/connector/http/HttpIT.java
Patch:
@@ -157,6 +157,9 @@ public void testSourceToAssertSink(TestContainer container)
         Container.ExecResult execResult17 =
                 container.executeJob("/http_jsonrequestbody_to_feishu.conf");
         Assertions.assertEquals(0, execResult17.getExitCode());
+
+        Container.ExecResult execResult18 = container.executeJob("/httpnoschema_to_http.conf");
+        Assertions.assertEquals(0, execResult18.getExitCode());
     }
 
     public String getMockServerConfig() {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/JdbcOutputFormatBuilder.java
Patch:
@@ -283,15 +283,14 @@ private static JdbcBatchStatementExecutor<SeaTunnelRow> createSimpleExecutor(
                 rowConverter);
     }
 
-    private static Function<SeaTunnelRow, SeaTunnelRow> createKeyExtractor(int[] pkFields) {
+    static Function<SeaTunnelRow, SeaTunnelRow> createKeyExtractor(int[] pkFields) {
         return row -> {
             Object[] fields = new Object[pkFields.length];
             for (int i = 0; i < pkFields.length; i++) {
                 fields[i] = row.getField(pkFields[i]);
             }
             SeaTunnelRow newRow = new SeaTunnelRow(fields);
             newRow.setTableId(row.getTableId());
-            newRow.setRowKind(row.getRowKind());
             return newRow;
         };
     }

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/multitablesink/MultiTableSinkWriter.java
Patch:
@@ -55,11 +55,11 @@ public class MultiTableSinkWriter
     public MultiTableSinkWriter(
             Map<SinkIdentifier, SinkWriter<SeaTunnelRow, ?, ?>> sinkWriters, int queueSize) {
         this.sinkWriters = sinkWriters;
+        AtomicInteger cnt = new AtomicInteger(0);
         executorService =
                 Executors.newFixedThreadPool(
                         queueSize,
                         runnable -> {
-                            AtomicInteger cnt = new AtomicInteger(0);
                             Thread thread = new Thread(runnable);
                             thread.setDaemon(true);
                             thread.setName(

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/config/JdbcConnectionConfig.java
Patch:
@@ -76,7 +76,7 @@ public static JdbcConnectionConfig of(ReadonlyConfig config) {
             builder.useKerberos(config.get(JdbcOptions.USE_KERBEROS));
             builder.kerberosPrincipal(config.get(JdbcOptions.KERBEROS_PRINCIPAL));
             builder.kerberosKeytabPath(config.get(JdbcOptions.KERBEROS_KEYTAB_PATH));
-            builder.kerberosKeytabPath(config.get(JdbcOptions.KRB5_PATH));
+            builder.krb5Path(config.get(JdbcOptions.KRB5_PATH));
         }
         config.getOptional(JdbcOptions.USER).ifPresent(builder::username);
         config.getOptional(JdbcOptions.PASSWORD).ifPresent(builder::password);

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/RestApiIT.java
Patch:
@@ -134,7 +134,7 @@ public void testSystemMonitoringInformation() {
     @Test
     public void testSubmitJob() {
         Response response = submitJob("BATCH");
-        response.then().statusCode(200).body("jobName", equalTo("test"));
+        response.then().statusCode(200).body("jobName", equalTo("test测试"));
         String jobId = response.getBody().jsonPath().getString("jobId");
         SeaTunnelServer seaTunnelServer =
                 (SeaTunnelServer)
@@ -349,7 +349,7 @@ private Response submitJob(String jobMode, boolean isStartWithSavePoint) {
                         + "        }\n"
                         + "    ]\n"
                         + "}";
-        String parameters = "jobName=test";
+        String parameters = "jobName=test测试";
         if (isStartWithSavePoint) {
             parameters = parameters + "&isStartWithSavePoint=true";
         }

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/config/PulsarConfigUtil.java
Patch:
@@ -34,7 +34,7 @@
 
 public class PulsarConfigUtil {
 
-    public static final String IDENTIFIER = "pulsar";
+    public static final String IDENTIFIER = "Pulsar";
 
     private PulsarConfigUtil() {}
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/oracle/OracleDataTypeConvertor.java
Patch:
@@ -125,7 +125,6 @@ public SeaTunnelDataType<?> toSeaTunnelType(
             case ORACLE_XML:
                 return BasicType.STRING_TYPE;
             case ORACLE_DATE:
-                return LocalTimeType.LOCAL_DATE_TYPE;
             case ORACLE_TIMESTAMP:
             case ORACLE_TIMESTAMP_WITH_LOCAL_TIME_ZONE:
                 return LocalTimeType.LOCAL_DATE_TIME_TYPE;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/oracle/OracleTypeMapper.java
Patch:
@@ -73,7 +73,6 @@ public class OracleTypeMapper implements JdbcDialectTypeMapper {
     public SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex)
             throws SQLException {
         String oracleType = metadata.getColumnTypeName(colIndex).toUpperCase();
-        String columnName = metadata.getColumnName(colIndex);
         int precision = metadata.getPrecision(colIndex);
         int scale = metadata.getScale(colIndex);
         switch (oracleType) {
@@ -110,7 +109,6 @@ public SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex)
             case ORACLE_XML:
                 return BasicType.STRING_TYPE;
             case ORACLE_DATE:
-                return LocalTimeType.LOCAL_DATE_TYPE;
             case ORACLE_TIMESTAMP:
             case ORACLE_TIMESTAMP_WITH_LOCAL_TIME_ZONE:
                 return LocalTimeType.LOCAL_DATE_TIME_TYPE;

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/source/DefaultSeaTunnelRowDeserializer.java
Patch:
@@ -168,7 +168,7 @@ Object convertValue(SeaTunnelDataType<?> fieldType, String fieldValue)
             Object arr = Array.newInstance(elementType.getTypeClass(), stringList.size());
             for (int i = 0; i < stringList.size(); i++) {
                 Object convertValue = convertValue(elementType, stringList.get(i));
-                Array.set(arr, 0, convertValue);
+                Array.set(arr, i, convertValue);
             }
             return arr;
         } else if (fieldType instanceof MapType) {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-elasticsearch-e2e/src/test/java/org/apache/seatunnel/e2e/connector/elasticsearch/ElasticsearchIT.java
Patch:
@@ -157,7 +157,7 @@ private List<String> generateTestDataSet() throws JsonProcessingException {
             Object[] values =
                     new Object[] {
                         Collections.singletonMap("key", Short.parseShort(String.valueOf(i))),
-                        new Byte[] {Byte.parseByte("1")},
+                        new Byte[] {Byte.parseByte("1"), Byte.parseByte("2"), Byte.parseByte("3")},
                         "string",
                         Boolean.FALSE,
                         Byte.parseByte("1"),

File: seatunnel-common/src/test/java/org/apache/seatunnel/common/utils/ExceptionUtilsTest.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.common.utils;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.exception.SeaTunnelRuntimeException;
 
 import org.junit.jupiter.api.Assertions;
@@ -30,7 +30,8 @@ public void testGetRootException() {
                 new UnsupportedOperationException(
                         new SeaTunnelException(
                                 new SeaTunnelRuntimeException(
-                                        CommonErrorCode.CLASS_NOT_FOUND, "class not fount")));
+                                        CommonErrorCodeDeprecated.CLASS_NOT_FOUND,
+                                        "class not fount")));
         Throwable throwable = ExceptionUtils.getRootException(exception);
         Assertions.assertTrue(throwable instanceof SeaTunnelRuntimeException);
     }

File: seatunnel-connectors-v2/connector-amazonsqs/src/main/java/org/apache/seatunnel/connectors/seatunnel/amazonsqs/sink/AmazonSqsSinkWriter.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.serialization.SerializationSchema;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.amazonsqs.config.MessageFormat;
 import org.apache.seatunnel.connectors.seatunnel.common.sink.AbstractSinkWriter;
 import org.apache.seatunnel.format.json.JsonSerializationSchema;
@@ -123,7 +123,8 @@ private static SerializationSchema createSerializationSchema(
                 return new DebeziumJsonSerializationSchema(rowType);
             default:
                 throw new SeaTunnelJsonFormatException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE, "Unsupported format: " + format);
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
+                        "Unsupported format: " + format);
         }
     }
 }

File: seatunnel-connectors-v2/connector-amazonsqs/src/main/java/org/apache/seatunnel/connectors/seatunnel/amazonsqs/source/AmazonSqsSource.java
Patch:
@@ -34,7 +34,7 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.amazonsqs.config.AmazonSqsSourceOptions;
 import org.apache.seatunnel.connectors.seatunnel.amazonsqs.config.MessageFormat;
 import org.apache.seatunnel.connectors.seatunnel.amazonsqs.exception.AmazonSqsConnectorException;
@@ -142,7 +142,8 @@ private void setDeserialization(Config config) {
                     break;
                 default:
                     throw new SeaTunnelJsonFormatException(
-                            CommonErrorCode.UNSUPPORTED_DATA_TYPE, "Unsupported format: " + format);
+                            CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
+                            "Unsupported format: " + format);
             }
         } else {
             typeInfo = CatalogTableUtil.buildSimpleTextSchema();

File: seatunnel-connectors-v2/connector-assert/src/main/java/org/apache/seatunnel/connectors/seatunnel/assertion/rule/AssertCatalogTableRuleParser.java
Patch:
@@ -114,7 +114,7 @@ private Optional<AssertCatalogTableRule.AssertColumnRule> parseColumnRule(
                                     return PhysicalColumn.of(
                                             name,
                                             SeaTunnelDataTypeConvertorUtil
-                                                    .deserializeSeaTunnelDataType(type),
+                                                    .deserializeSeaTunnelDataType(name, type),
                                             columnLength,
                                             nullable,
                                             object,

File: seatunnel-connectors-v2/connector-cassandra/src/main/java/org/apache/seatunnel/connectors/seatunnel/cassandra/client/CassandraClient.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.cassandra.client;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.cassandra.exception.CassandraConnectorException;
 
 import org.apache.commons.lang3.StringUtils;
@@ -81,7 +81,7 @@ public static ColumnDefinitions getTableSchema(CqlSession session, String table)
                     .getColumnDefinitions();
         } catch (Exception e) {
             throw new CassandraConnectorException(
-                    CommonErrorCode.TABLE_SCHEMA_GET_FAILED,
+                    CommonErrorCodeDeprecated.TABLE_SCHEMA_GET_FAILED,
                     "Cannot get table schema from cassandra",
                     e);
         }

File: seatunnel-connectors-v2/connector-cassandra/src/main/java/org/apache/seatunnel/connectors/seatunnel/cassandra/source/CassandraSource.java
Patch:
@@ -30,7 +30,7 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.cassandra.client.CassandraClient;
 import org.apache.seatunnel.connectors.seatunnel.cassandra.config.CassandraParameters;
 import org.apache.seatunnel.connectors.seatunnel.cassandra.exception.CassandraConnectorErrorCode;
@@ -103,7 +103,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
             this.rowTypeInfo = new SeaTunnelRowType(fieldNames, seaTunnelDataTypes);
         } catch (Exception e) {
             throw new CassandraConnectorException(
-                    CommonErrorCode.TABLE_SCHEMA_GET_FAILED,
+                    CommonErrorCodeDeprecated.TABLE_SCHEMA_GET_FAILED,
                     "Get table schema from cassandra source data failed",
                     e);
         }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/config/MongodbSourceConfigProvider.java
Patch:
@@ -27,7 +27,7 @@
 import java.util.List;
 import java.util.Objects;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.BATCH_SIZE;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.HEARTBEAT_INTERVAL_MILLIS;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.INCREMENTAL_SNAPSHOT_CHUNK_SIZE_MB;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/sender/MongoDBConnectorDeserializationSchema.java
Patch:
@@ -59,9 +59,9 @@
 import java.util.Map;
 import java.util.Objects;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
-import static org.apache.seatunnel.common.exception.CommonErrorCode.UNSUPPORTED_DATA_TYPE;
-import static org.apache.seatunnel.common.exception.CommonErrorCode.UNSUPPORTED_OPERATION;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.DEFAULT_JSON_WRITER_SETTINGS;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.DOCUMENT_KEY;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.ENCODE_VALUE_FIELD;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/source/fetch/MongodbFetchTaskContext.java
Patch:
@@ -52,7 +52,7 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.COLL_FIELD;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.DB_FIELD;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.DOCUMENT_KEY;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/source/fetch/MongodbScanFetchTask.java
Patch:
@@ -49,7 +49,7 @@
 import java.util.ArrayList;
 import java.util.Collections;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.COLL_FIELD;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.DB_FIELD;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.DOCUMENT_KEY;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/source/fetch/MongodbStreamFetchTask.java
Patch:
@@ -57,8 +57,8 @@
 import java.time.Instant;
 import java.util.Optional;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
-import static org.apache.seatunnel.common.exception.CommonErrorCode.UNSUPPORTED_OPERATION;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.CLUSTER_TIME_FIELD;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.COLL_FIELD;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.DB_FIELD;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/source/offset/ChangeStreamOffsetFactory.java
Patch:
@@ -23,7 +23,7 @@
 
 import java.util.Map;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.UNSUPPORTED_OPERATION;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.utils.MongodbRecordUtils.bsonTimestampFromEpochMillis;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.utils.MongodbRecordUtils.currentBsonTimestamp;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/utils/BsonUtils.java
Patch:
@@ -39,7 +39,7 @@
 import java.util.Map;
 import java.util.Objects;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
 
 public class BsonUtils {
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/utils/MongodbUtils.java
Patch:
@@ -61,7 +61,7 @@
 import static com.mongodb.client.model.Filters.regex;
 import static com.mongodb.client.model.Projections.include;
 import static com.mongodb.client.model.Sorts.ascending;
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.ADD_NS_FIELD_NAME;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.COMMAND_SUCCEED_FLAG;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mongodb.config.MongodbSourceOptions.DOCUMENT_KEY;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/utils/ResumeToken.java
Patch:
@@ -29,7 +29,7 @@
 import java.nio.ByteOrder;
 import java.util.Objects;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
 
 public class ResumeToken {
 

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/config/ClickhouseFileCopyMethod.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.clickhouse.config;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorException;
 
 public enum ClickhouseFileCopyMethod {
@@ -42,6 +42,7 @@ public static ClickhouseFileCopyMethod from(String name) {
             }
         }
         throw new ClickhouseConnectorException(
-                CommonErrorCode.ILLEGAL_ARGUMENT, "Unknown ClickhouseFileCopyMethod: " + name);
+                CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
+                "Unknown ClickhouseFileCopyMethod: " + name);
     }
 }

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/ClickhouseProxy.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.clickhouse.sink.client;
 
 import org.apache.seatunnel.api.common.SeaTunnelAPIErrorCode;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.shard.Shard;
@@ -142,7 +142,7 @@ public Map<String, String> getClickhouseTableSchema(
                     .forEach(r -> schema.put(r.getValue(0).asString(), r.getValue(1).asString()));
         } catch (ClickHouseException e) {
             throw new ClickhouseConnectorException(
-                    CommonErrorCode.TABLE_SCHEMA_GET_FAILED,
+                    CommonErrorCodeDeprecated.TABLE_SCHEMA_GET_FAILED,
                     "Cannot get table schema from clickhouse",
                     e);
         }

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/ClickhouseSink.java
Patch:
@@ -31,7 +31,7 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ReaderOption;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.shard.Shard;
@@ -149,7 +149,7 @@ public void prepare(Config config) throws PrepareFailException {
         if (config.getBoolean(SPLIT_MODE.key())) {
             if (!"Distributed".equals(table.getEngine())) {
                 throw new ClickhouseConnectorException(
-                        CommonErrorCode.ILLEGAL_ARGUMENT,
+                        CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
                         "split mode only support table which engine is "
                                 + "'Distributed' engine at now");
             }
@@ -193,7 +193,7 @@ public void prepare(Config config) throws PrepareFailException {
             String primaryKey = config.getString(PRIMARY_KEY.key());
             if (shardKey != null && !Objects.equals(primaryKey, shardKey)) {
                 throw new ClickhouseConnectorException(
-                        CommonErrorCode.ILLEGAL_ARGUMENT,
+                        CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
                         "sharding_key and primary_key must be consistent to ensure correct processing of cdc events");
             }
             primaryKeys = new String[] {primaryKey};

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/file/FileTransferFactory.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.clickhouse.sink.file;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseFileCopyMethod;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorException;
 
@@ -31,7 +31,7 @@ public static FileTransfer createFileTransfer(
                 return new RsyncFileTransfer(host, user, password);
             default:
                 throw new ClickhouseConnectorException(
-                        CommonErrorCode.ILLEGAL_ARGUMENT,
+                        CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
                         "unsupported clickhouse file copy method:" + type);
         }
     }

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/file/RsyncFileTransfer.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.clickhouse.sink.file;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorException;
 
@@ -113,7 +113,7 @@ public void transferAndChown(String sourcePath, String targetPath) {
             start.waitFor();
         } catch (IOException | InterruptedException ex) {
             throw new ClickhouseConnectorException(
-                    CommonErrorCode.FILE_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.FILE_OPERATION_FAILED,
                     "Rsync failed to transfer file: " + sourcePath + " to: " + targetPath,
                     ex);
         }
@@ -140,7 +140,7 @@ public void transferAndChown(String sourcePath, String targetPath) {
     public void transferAndChown(List<String> sourcePaths, String targetPath) {
         if (sourcePaths == null) {
             throw new ClickhouseConnectorException(
-                    CommonErrorCode.ILLEGAL_ARGUMENT, "sourcePath is null");
+                    CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT, "sourcePath is null");
         }
         sourcePaths.forEach(sourcePath -> transferAndChown(sourcePath, targetPath));
     }

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/file/ScpFileTransfer.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.clickhouse.sink.file;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorException;
 
@@ -87,7 +87,7 @@ public void transferAndChown(String sourcePath, String targetPath) {
                     ScpClient.Option.PreserveAttributes);
         } catch (IOException e) {
             throw new ClickhouseConnectorException(
-                    CommonErrorCode.FILE_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.FILE_OPERATION_FAILED,
                     "Scp failed to transfer file: " + sourcePath + " to: " + targetPath,
                     e);
         }
@@ -114,7 +114,7 @@ public void transferAndChown(String sourcePath, String targetPath) {
     public void transferAndChown(List<String> sourcePaths, String targetPath) {
         if (sourcePaths == null) {
             throw new ClickhouseConnectorException(
-                    CommonErrorCode.ILLEGAL_ARGUMENT, "sourcePath is null");
+                    CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT, "sourcePath is null");
         }
         sourcePaths.forEach(sourcePath -> transferAndChown(sourcePath, targetPath));
     }

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/inject/ArrayInjectFunction.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.clickhouse.sink.inject;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorException;
 
 import java.sql.PreparedStatement;
@@ -79,7 +79,7 @@ public void injectFields(PreparedStatement statement, int index, Object value)
                 break;
             default:
                 throw new ClickhouseConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                         "array inject error, unsupported data type: " + type);
         }
         statement.setArray(index, statement.getConnection().createArrayOf(sqlType, elements));

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/inject/StringInjectFunction.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.shade.com.fasterxml.jackson.core.JsonProcessingException;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorException;
 
 import java.sql.PreparedStatement;
@@ -52,7 +52,7 @@ public void injectFields(PreparedStatement statement, int index, Object value)
             }
         } catch (JsonProcessingException e) {
             throw new ClickhouseConnectorException(
-                    CommonErrorCode.JSON_OPERATION_FAILED, e.getMessage());
+                    CommonErrorCodeDeprecated.JSON_OPERATION_FAILED, e.getMessage());
         }
     }
 

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/serialize/SeaTunnelRowConverter.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.doris.serialize;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.DateTimeUtils;
 import org.apache.seatunnel.common.utils.DateUtils;
 import org.apache.seatunnel.common.utils.JsonUtils;
@@ -67,7 +67,8 @@ protected Object convert(SeaTunnelDataType dataType, Object val) {
                 return new String((byte[]) val);
             default:
                 throw new DorisConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE, dataType + " is not supported ");
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
+                        dataType + " is not supported ");
         }
     }
 }

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/KeyExtractor.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.exception.ElasticsearchConnectorException;
 
 import lombok.AllArgsConstructor;
@@ -75,7 +75,7 @@ private static FieldFormatter createFieldFormatter(
                 case ARRAY:
                 case MAP:
                     throw new ElasticsearchConnectorException(
-                            CommonErrorCode.UNSUPPORTED_OPERATION,
+                            CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                             "Unsupported type: " + fieldType);
                 case DATE:
                     LocalDate localDate = (LocalDate) row.getField(fieldIndex);

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/sink/ElasticsearchSinkWriter.java
Patch:
@@ -23,7 +23,7 @@
 import org.apache.seatunnel.api.table.type.RowKind;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.RetryUtils;
 import org.apache.seatunnel.common.utils.RetryUtils.RetryMaterial;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.client.EsRestClient;
@@ -123,7 +123,7 @@ public synchronized void bulkEsWithRetry(
             requestEsList.clear();
         } catch (Exception e) {
             throw new ElasticsearchConnectorException(
-                    CommonErrorCode.SQL_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.SQL_OPERATION_FAILED,
                     "ElasticSearch execute batch statement error",
                     e);
         }

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/source/ElasticsearchSourceSplitEnumerator.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.client.EsRestClient;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.config.SourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.dto.source.IndexDocsCount;
@@ -196,7 +196,7 @@ public int currentUnassignedSplitSize() {
     @Override
     public void handleSplitRequest(int subtaskId) {
         throw new ElasticsearchConnectorException(
-                CommonErrorCode.UNSUPPORTED_OPERATION,
+                CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                 "Unsupported handleSplitRequest: " + subtaskId);
     }
 

File: seatunnel-connectors-v2/connector-email/src/main/java/org/apache/seatunnel/connectors/seatunnel/email/sink/EmailSinkWriter.java
Patch:
@@ -21,7 +21,7 @@
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.common.sink.AbstractSinkWriter;
 import org.apache.seatunnel.connectors.seatunnel.email.config.EmailSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.email.exception.EmailConnectorErrorCode;
@@ -156,7 +156,7 @@ public void createFile() {
             log.info("Create File successfully....");
         } catch (IOException e) {
             throw new EmailConnectorException(
-                    CommonErrorCode.FILE_OPERATION_FAILED, "Create file failed", e);
+                    CommonErrorCodeDeprecated.FILE_OPERATION_FAILED, "Create file failed", e);
         }
     }
 }

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeDataGenerator.java
Patch:
@@ -26,7 +26,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.fake.config.FakeConfig;
 import org.apache.seatunnel.connectors.seatunnel.fake.exception.FakeConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.fake.utils.FakeDataRandomUtils;
@@ -65,7 +65,7 @@ private SeaTunnelRow convertRow(FakeConfig.RowData rowData) {
             }
             return seaTunnelRow;
         } catch (IOException e) {
-            throw new FakeConnectorException(CommonErrorCode.JSON_OPERATION_FAILED, e);
+            throw new FakeConnectorException(CommonErrorCodeDeprecated.JSON_OPERATION_FAILED, e);
         }
     }
 
@@ -171,7 +171,7 @@ private Object randomColumnValue(SeaTunnelDataType<?> fieldType) {
             default:
                 // never got in there
                 throw new FakeConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                         "SeaTunnel Fake source connector not support this data type");
         }
     }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/AbstractWriteStrategy.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.Constants;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.VariablesSubstitute;
 import org.apache.seatunnel.connectors.seatunnel.file.config.BaseSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.file.config.CompressFormat;
@@ -292,7 +292,7 @@ public void abortPrepare(String transactionId) {
             fileSystemUtils.deleteFile(getTransactionDir(transactionId));
         } catch (IOException e) {
             throw new FileConnectorException(
-                    CommonErrorCode.FILE_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.FILE_OPERATION_FAILED,
                     "Abort transaction "
                             + transactionId
                             + " error, delete transaction directory failed",

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/ExcelWriteStrategy.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.file.sink.writer;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.config.FileSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.util.ExcelGenerator;
@@ -57,7 +57,7 @@ public void finishAndCloseFile() {
                         fileOutputStream.close();
                     } catch (IOException e) {
                         throw new FileConnectorException(
-                                CommonErrorCode.FILE_OPERATION_FAILED,
+                                CommonErrorCodeDeprecated.FILE_OPERATION_FAILED,
                                 "can not get output file stream");
                     }
                     needMoveFiles.put(k, getTargetLocation(k));

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/WriteStrategyFactory.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.sink.writer;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
 import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.config.FileSinkConfig;
@@ -38,7 +38,7 @@ public static WriteStrategy of(String fileType, FileSinkConfig fileSinkConfig) {
                     String.format(
                             "File sink connector not support this file type [%s], please check your config",
                             fileType);
-            throw new FileConnectorException(CommonErrorCode.ILLEGAL_ARGUMENT, errorMsg);
+            throw new FileConnectorException(CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT, errorMsg);
         }
     }
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/BaseFileSourceReader.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.source.Collector;
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.file.config.HadoopConf;
 import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.file.source.reader.ReadStrategy;
@@ -68,7 +68,7 @@ public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
                     String errorMsg =
                             String.format("Read data from this file [%s] failed", split.splitId());
                     throw new FileConnectorException(
-                            CommonErrorCode.FILE_OPERATION_FAILED, errorMsg, e);
+                            CommonErrorCodeDeprecated.FILE_OPERATION_FAILED, errorMsg, e);
                 }
             } else if (noMoreSplit && sourceSplits.isEmpty()) {
                 // signal to the source that we have reached the end of the data.

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/ReadStrategyFactory.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.source.reader;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
 import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
 
@@ -37,7 +37,7 @@ public static ReadStrategy of(String fileType) {
                     String.format(
                             "File source connector not support this file type [%s], please check your config",
                             fileType);
-            throw new FileConnectorException(CommonErrorCode.ILLEGAL_ARGUMENT, errorMsg);
+            throw new FileConnectorException(CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT, errorMsg);
         }
     }
 }

File: seatunnel-connectors-v2/connector-google-sheets/src/main/java/org/apache/seatunnel/connectors/seatunnel/google/sheets/deserialize/GoogleSheetsDeserializer.java
Patch:
@@ -21,7 +21,7 @@
 
 import org.apache.seatunnel.api.serialization.DeserializationSchema;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.google.sheets.exception.GoogleSheetsConnectorException;
 
 import java.io.IOException;
@@ -54,7 +54,7 @@ public SeaTunnelRow deserializeRow(List<Object> row) {
             return deserializationSchema.deserialize(rowStr.getBytes());
         } catch (IOException e) {
             throw new GoogleSheetsConnectorException(
-                    CommonErrorCode.JSON_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.JSON_OPERATION_FAILED,
                     "Object json deserialization failed.",
                     e);
         }

File: seatunnel-connectors-v2/connector-hbase/src/main/java/org/apache/seatunnel/connectors/seatunnel/hbase/sink/HbaseSinkWriter.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.common.sink.AbstractSinkWriter;
 import org.apache.seatunnel.connectors.seatunnel.hbase.config.HbaseParameters;
 import org.apache.seatunnel.connectors.seatunnel.hbase.exception.HbaseConnectorException;
@@ -187,7 +187,8 @@ private byte[] convertColumnToBytes(SeaTunnelRow row, int index) {
                         String.format(
                                 "Hbase connector does not support this column type [%s]",
                                 fieldType.getSqlType());
-                throw new HbaseConnectorException(CommonErrorCode.UNSUPPORTED_DATA_TYPE, errorMsg);
+                throw new HbaseConnectorException(
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE, errorMsg);
         }
     }
 }

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/HiveSink.java
Patch:
@@ -27,7 +27,7 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
 import org.apache.seatunnel.connectors.seatunnel.file.config.HadoopConf;
 import org.apache.seatunnel.connectors.seatunnel.file.hdfs.sink.BaseHdfsFileSink;
@@ -160,7 +160,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                             ConfigValueFactory.fromAnyRef(FileFormat.ORC.toString()));
         } else {
             throw new HiveConnectorException(
-                    CommonErrorCode.ILLEGAL_ARGUMENT,
+                    CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
                     "Hive connector only support [text parquet orc] table now");
         }
         pluginConfig =

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/source/HttpSource.java
Patch:
@@ -35,7 +35,7 @@
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.common.constants.PluginType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.connectors.seatunnel.common.source.AbstractSingleSplitReader;
 import org.apache.seatunnel.connectors.seatunnel.common.source.AbstractSingleSplitSource;
@@ -139,7 +139,7 @@ protected void buildSchemaWithConfig(Config pluginConfig) {
                 default:
                     // TODO: use format SPI
                     throw new HttpConnectorException(
-                            CommonErrorCode.ILLEGAL_ARGUMENT,
+                            CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
                             String.format(
                                     "Unsupported data format [%s], http connector only support json format now",
                                     format));

File: seatunnel-connectors-v2/connector-hudi/src/main/java/org/apache/seatunnel/connectors/seatunnel/hudi/source/HudiSource.java
Patch:
@@ -31,7 +31,7 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.hudi.exception.HudiConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.hudi.util.HudiUtil;
 
@@ -116,7 +116,7 @@ public void prepare(Config pluginConfig) {
             this.filePath = HudiUtil.getParquetFileByPath(this.confFiles, tablePath);
             if (this.filePath == null) {
                 throw new HudiConnectorException(
-                        CommonErrorCode.FILE_OPERATION_FAILED,
+                        CommonErrorCodeDeprecated.FILE_OPERATION_FAILED,
                         String.format("%s has no parquet file, please check!", tablePath));
             }
             // should read from config or read from hudi metadata( wait catalog done)

File: seatunnel-connectors-v2/connector-hudi/src/main/java/org/apache/seatunnel/connectors/seatunnel/hudi/source/HudiSourceReader.java
Patch:
@@ -22,7 +22,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.hudi.exception.HudiConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.hudi.util.HudiUtil;
 
@@ -117,7 +117,7 @@ public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
                         reader.close();
                     } catch (Exception e) {
                         throw new HudiConnectorException(
-                                CommonErrorCode.READER_OPERATION_FAILED, e);
+                                CommonErrorCodeDeprecated.READER_OPERATION_FAILED, e);
                     }
                 });
         context.signalNoMoreElement();

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/IcebergCatalogFactory.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.iceberg;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.config.IcebergCatalogType;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.exception.IcebergConnectorException;
 
@@ -69,7 +69,7 @@ public Catalog create() {
                 return hive(catalogName, serializableConf, properties);
             default:
                 throw new IcebergConnectorException(
-                        CommonErrorCode.UNSUPPORTED_OPERATION,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                         String.format("Unsupported catalogType: %s", catalogType));
         }
     }

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/data/DefaultDeserializer.java
Patch:
@@ -22,7 +22,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.exception.IcebergConnectorException;
 
 import org.apache.iceberg.Schema;
@@ -148,7 +148,7 @@ private Object convert(
                 return seatunnelMap;
             default:
                 throw new IcebergConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                         String.format("Unsupported iceberg type: %s", icebergType));
         }
     }

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/IcebergSource.java
Patch:
@@ -97,7 +97,7 @@ private SeaTunnelRowType loadSeaTunnelRowType(Schema tableSchema, Config pluginC
         List<SeaTunnelDataType<?>> columnDataTypes = new ArrayList<>(tableSchema.columns().size());
         for (Types.NestedField column : tableSchema.columns()) {
             columnNames.add(column.name());
-            columnDataTypes.add(IcebergTypeMapper.mapping(column.type()));
+            columnDataTypes.add(IcebergTypeMapper.mapping(column.name(), column.type()));
         }
         SeaTunnelRowType originalRowType =
                 new SeaTunnelRowType(

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/enumerator/scan/IcebergScanSplitPlanner.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.iceberg.source.enumerator.scan;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.exception.IcebergConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.exception.IcebergConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.source.enumerator.IcebergEnumerationResult;
@@ -162,7 +162,7 @@ private static Optional<Snapshot> getStreamStartSnapshot(
                 }
             default:
                 throw new IcebergConnectorException(
-                        CommonErrorCode.UNSUPPORTED_OPERATION,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                         "Unsupported stream scan strategy: "
                                 + icebergScanContext.getStreamScanStrategy());
         }

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/reader/IcebergFileScanTaskReader.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.iceberg.source.reader;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.data.IcebergRecordProjection;
 import org.apache.seatunnel.connectors.seatunnel.iceberg.exception.IcebergConnectorException;
 
@@ -103,7 +103,7 @@ private CloseableIterable<Record> applyResidual(
     private CloseableIterable<Record> openFile(FileScanTask task, Schema fileProjection) {
         if (task.isDataTask()) {
             throw new IcebergConnectorException(
-                    CommonErrorCode.UNSUPPORTED_OPERATION, "Cannot read data task.");
+                    CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION, "Cannot read data task.");
         }
         InputFile input = fileIO.newInputFile(task.file().path().toString());
         Map<Integer, ?> partition =
@@ -156,7 +156,7 @@ private CloseableIterable<Record> openFile(FileScanTask task, Schema fileProject
                 return orc.build();
             default:
                 throw new IcebergConnectorException(
-                        CommonErrorCode.UNSUPPORTED_OPERATION,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                         String.format(
                                 "Cannot read %s file: %s",
                                 task.file().format().name(), task.file().path()));

File: seatunnel-connectors-v2/connector-influxdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/influxdb/converter/InfluxDBRowConverter.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.api.table.type.SqlType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.influxdb.exception.InfluxdbConnectorException;
 
 import java.util.ArrayList;
@@ -58,7 +58,7 @@ public static SeaTunnelRow convert(
                 seaTunnelField = values.get(columnIndex);
             } else {
                 throw new InfluxdbConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                         "Unsupported data type: " + seaTunnelDataType);
             }
 

File: seatunnel-connectors-v2/connector-influxdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/influxdb/serialize/DefaultSerializer.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.influxdb.exception.InfluxdbConnectorException;
 
 import org.apache.commons.collections4.CollectionUtils;
@@ -104,7 +104,7 @@ private BiConsumer<SeaTunnelRow, Point.Builder> createFieldExtractor(
                         break;
                     default:
                         throw new InfluxdbConnectorException(
-                                CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                                CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                                 "Unsupported data type: " + dataType);
                 }
             }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/connection/DataSourceUtils.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.connection;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcConnectionConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 
@@ -117,7 +117,7 @@ private static Object loadDataSource(final String xaDataSourceClassName) {
                 xaDataSourceClass = Class.forName(xaDataSourceClassName);
             } catch (final ClassNotFoundException ex) {
                 throw new JdbcConnectorException(
-                        CommonErrorCode.CLASS_NOT_FOUND,
+                        CommonErrorCodeDeprecated.CLASS_NOT_FOUND,
                         "Failed to load [" + xaDataSourceClassName + "]",
                         ex);
             }
@@ -126,7 +126,7 @@ private static Object loadDataSource(final String xaDataSourceClassName) {
             return xaDataSourceClass.getDeclaredConstructor().newInstance();
         } catch (final ReflectiveOperationException ex) {
             throw new JdbcConnectorException(
-                    CommonErrorCode.REFLECT_CLASS_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.REFLECT_CLASS_OPERATION_FAILED,
                     "Failed to instance [" + xaDataSourceClassName + "]",
                     ex);
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/converter/AbstractJdbcRowConverter.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.utils.JdbcUtils;
 
@@ -108,7 +108,7 @@ public SeaTunnelRow toInternal(ResultSet rs, SeaTunnelRowType typeInfo) throws S
                 case ROW:
                 default:
                     throw new JdbcConnectorException(
-                            CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                            CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                             "Unexpected value: " + seaTunnelDataType);
             }
         }
@@ -180,7 +180,7 @@ public PreparedStatement toExternal(
                 case ROW:
                 default:
                     throw new JdbcConnectorException(
-                            CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                            CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                             "Unexpected value: " + seaTunnelDataType);
             }
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/kingbase/KingbaseJdbcRowConverter.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.converter.AbstractJdbcRowConverter;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.DatabaseIdentifier;
@@ -108,7 +108,7 @@ public SeaTunnelRow toInternal(ResultSet rs, SeaTunnelRowType typeInfo) throws S
                 case ARRAY:
                 default:
                     throw new JdbcConnectorException(
-                            CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                            CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                             "Unexpected value: " + seaTunnelDataType);
             }
         }
@@ -180,7 +180,7 @@ public PreparedStatement toExternal(
                 case ARRAY:
                 default:
                     throw new JdbcConnectorException(
-                            CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                            CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                             "Unexpected value: " + seaTunnelDataType);
             }
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/psql/PostgresJdbcRowConverter.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.converter.AbstractJdbcRowConverter;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.DatabaseIdentifier;
@@ -116,7 +116,7 @@ public SeaTunnelRow toInternal(ResultSet rs, SeaTunnelRowType typeInfo) throws S
                 case ROW:
                 default:
                     throw new JdbcConnectorException(
-                            CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                            CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                             "Unexpected value: " + seaTunnelDataType);
             }
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/sqlserver/SqlserverJdbcRowConverter.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.api.table.type.SqlType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.converter.AbstractJdbcRowConverter;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.DatabaseIdentifier;
@@ -108,7 +108,7 @@ public PreparedStatement toExternal(
                 case ROW:
                 default:
                     throw new JdbcConnectorException(
-                            CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                            CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                             "Unexpected value: " + seaTunnelDataType);
             }
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/executor/BufferReducedBatchStatementExecutor.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.api.table.type.RowKind;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 
 import org.apache.commons.lang3.tuple.Pair;
@@ -113,7 +113,8 @@ private boolean changeFlag(RowKind rowKind) {
                 return false;
             default:
                 throw new JdbcConnectorException(
-                        CommonErrorCode.UNSUPPORTED_OPERATION, "Unsupported rowKind: " + rowKind);
+                        CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
+                        "Unsupported rowKind: " + rowKind);
         }
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/executor/InsertOrUpdateBatchStatementExecutor.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.converter.JdbcRowConverter;
 
@@ -131,7 +131,7 @@ private boolean existRow(SeaTunnelRow record) throws SQLException {
                 return true;
             default:
                 throw new JdbcConnectorException(
-                        CommonErrorCode.UNSUPPORTED_OPERATION,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                         "unsupported row kind: " + record.getRowKind());
         }
     }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/XaFacadeImplAutoLoad.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.xa;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcConnectionConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
@@ -170,7 +170,7 @@ public void closeConnection() {
     @Override
     public Connection reestablishConnection() {
         throw new JdbcConnectorException(
-                CommonErrorCode.UNSUPPORTED_OPERATION,
+                CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                 "The instance failed to implement this method");
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/XidImpl.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.xa;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 
 import javax.transaction.xa.Xid;
@@ -112,7 +112,8 @@ public static String byteToHexString(final byte[] bytes, final int start, final
         final int number0x0f = 0x0F;
         final int number4 = 4;
         if (bytes == null) {
-            throw new JdbcConnectorException(CommonErrorCode.ILLEGAL_ARGUMENT, "bytes == null");
+            throw new JdbcConnectorException(
+                    CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT, "bytes == null");
         }
 
         int length = end - start;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcExactlyOnceSinkWriter.java
Patch:
@@ -22,7 +22,7 @@
 import org.apache.seatunnel.api.sink.SupportMultiTableSinkWriter;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
@@ -118,7 +118,7 @@ private void tryOpen() {
                 beginTx();
             } catch (Exception e) {
                 throw new JdbcConnectorException(
-                        CommonErrorCode.WRITER_OPERATION_FAILED,
+                        CommonErrorCodeDeprecated.WRITER_OPERATION_FAILED,
                         "unable to open JDBC exactly one writer",
                         e);
             }
@@ -177,7 +177,7 @@ public void close() throws IOException {
             xaFacade.close();
         } catch (Exception e) {
             throw new JdbcConnectorException(
-                    CommonErrorCode.WRITER_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.WRITER_OPERATION_FAILED,
                     "unable to close JDBC exactly one writer",
                     e);
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkAggregatedCommitter.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.jdbc.sink;
 
 import org.apache.seatunnel.api.sink.SinkAggregatedCommitter;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.xa.GroupXaOperationResult;
@@ -56,7 +56,7 @@ private void tryOpen() throws IOException {
                 xaFacade.open();
             } catch (Exception e) {
                 throw new JdbcConnectorException(
-                        CommonErrorCode.WRITER_OPERATION_FAILED,
+                        CommonErrorCodeDeprecated.WRITER_OPERATION_FAILED,
                         "unable to open JDBC sink aggregated committer",
                         e);
             }
@@ -105,7 +105,7 @@ public void close() throws IOException {
             }
         } catch (Exception e) {
             throw new JdbcConnectorException(
-                    CommonErrorCode.WRITER_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.WRITER_OPERATION_FAILED,
                     "unable to close JDBC sink aggregated committer",
                     e);
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkCommitter.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.jdbc.sink;
 
 import org.apache.seatunnel.api.sink.SinkCommitter;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcConnectionConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorErrorCode;
@@ -45,7 +45,7 @@ public JdbcSinkCommitter(JdbcSinkConfig jdbcSinkConfig) throws IOException {
             xaFacade.open();
         } catch (Exception e) {
             throw new JdbcConnectorException(
-                    CommonErrorCode.WRITER_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.WRITER_OPERATION_FAILED,
                     "unable to open JDBC sink committer",
                     e);
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/JdbcSourceSplitEnumerator.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
 import org.apache.seatunnel.api.table.catalog.TablePath;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.exception.JdbcConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.state.JdbcSourceState;
@@ -126,7 +126,7 @@ public int currentUnassignedSplitSize() {
     @Override
     public void handleSplitRequest(int subtaskId) {
         throw new JdbcConnectorException(
-                CommonErrorCode.UNSUPPORTED_OPERATION,
+                CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                 String.format("Unsupported handleSplitRequest: %d", subtaskId));
     }
 

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceConfig.java
Patch:
@@ -29,7 +29,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.kafka.config.MessageFormat;
 import org.apache.seatunnel.connectors.seatunnel.kafka.config.MessageFormatErrorHandleWay;
 import org.apache.seatunnel.connectors.seatunnel.kafka.config.StartMode;
@@ -237,7 +237,8 @@ private DeserializationSchema<SeaTunnelRow> createDeserializationSchema(
                 return new DebeziumJsonDeserializationSchema(seaTunnelRowType, true, includeSchema);
             default:
                 throw new SeaTunnelJsonFormatException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE, "Unsupported format: " + format);
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
+                        "Unsupported format: " + format);
         }
     }
 }

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/kuduclient/KuduTypeMapper.java
Patch:
@@ -22,7 +22,7 @@
 import org.apache.seatunnel.api.table.type.LocalTimeType;
 import org.apache.seatunnel.api.table.type.PrimitiveByteArrayType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.kudu.exception.KuduConnectorException;
 
 import org.apache.kudu.ColumnSchema;
@@ -70,7 +70,7 @@ public static SeaTunnelDataType<?> mapping(List<ColumnSchema> columnSchemaList,
                 return PrimitiveByteArrayType.INSTANCE;
             default:
                 throw new KuduConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                         String.format("Doesn't support KUDU type '%s' .", kuduType));
         }
     }

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/serialize/KuduRowSerializer.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.kudu.config.KuduSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.kudu.exception.KuduConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.kudu.exception.KuduConnectorException;
@@ -66,7 +66,7 @@ public Operation serializeRow(SeaTunnelRow row) {
                 break;
             default:
                 throw new KuduConnectorException(
-                        CommonErrorCode.UNSUPPORTED_OPERATION,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                         "Unsupported write row kind: " + row.getRowKind());
         }
         transform(operation, row);
@@ -106,7 +106,7 @@ private void transform(Operation operation, SeaTunnelRow element) {
                         break;
                     default:
                         throw new KuduConnectorException(
-                                CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                                CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                                 "Unsupported column type: " + type.getSqlType());
                 }
             } catch (ClassCastException e) {

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/source/KuduSourceFactory.java
Patch:
@@ -30,7 +30,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.constants.PluginType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.ExceptionUtils;
 import org.apache.seatunnel.connectors.seatunnel.kudu.config.KuduSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.kudu.config.KuduSourceConfig;
@@ -125,7 +125,7 @@ public static SeaTunnelRowType getSeaTunnelRowType(List<ColumnSchema> columnSche
 
         } catch (Exception e) {
             throw new KuduConnectorException(
-                    CommonErrorCode.TABLE_SCHEMA_GET_FAILED,
+                    CommonErrorCodeDeprecated.TABLE_SCHEMA_GET_FAILED,
                     String.format(
                             "PluginName: %s, PluginType: %s, Message: %s",
                             "Kudu", PluginType.SOURCE, ExceptionUtils.getMessage(e)));

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/source/KuduSourceSplitEnumerator.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.kudu.source;
 
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.kudu.config.KuduSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.kudu.exception.KuduConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.kudu.kuduclient.KuduInputFormat;
@@ -159,7 +159,7 @@ public int currentUnassignedSplitSize() {
     @Override
     public void handleSplitRequest(int subtaskId) {
         throw new KuduConnectorException(
-                CommonErrorCode.UNSUPPORTED_OPERATION,
+                CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                 String.format("Unsupported handleSplitRequest: %d", subtaskId));
     }
 

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/util/KuduUtil.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.kudu.util;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.kudu.config.CommonConfig;
 import org.apache.seatunnel.connectors.seatunnel.kudu.config.KuduSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.kudu.exception.KuduConnectorErrorCode;
@@ -74,7 +74,7 @@ public static KuduClient getKuduClient(CommonConfig config) {
     private static UserGroupInformation loginAndReturnUgi(CommonConfig config) throws IOException {
         if (StringUtils.isBlank(config.getPrincipal()) || StringUtils.isBlank(config.getKeytab())) {
             throw new KuduConnectorException(
-                    CommonErrorCode.ILLEGAL_ARGUMENT,
+                    CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
                     String.format(ERROR_MESSAGE, config.getPrincipal(), config.getKeytab()));
         }
         if (StringUtils.isNotBlank(config.getKrb5conf())) {

File: seatunnel-connectors-v2/connector-maxcompute/src/main/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/source/MaxcomputeSourceReader.java
Patch:
@@ -24,7 +24,7 @@
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.maxcompute.exception.MaxcomputeConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.maxcompute.util.MaxcomputeTypeMapper;
 import org.apache.seatunnel.connectors.seatunnel.maxcompute.util.MaxcomputeUtil;
@@ -81,7 +81,7 @@ public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
                         recordReader.close();
                     } catch (Exception e) {
                         throw new MaxcomputeConnectorException(
-                                CommonErrorCode.READER_OPERATION_FAILED, e);
+                                CommonErrorCodeDeprecated.READER_OPERATION_FAILED, e);
                     }
                 });
         if (this.noMoreSplit && Boundedness.BOUNDED.equals(context.getBoundedness())) {

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/serde/BsonToRowDataConverters.java
Patch:
@@ -45,9 +45,9 @@
 import java.util.List;
 import java.util.Map;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
-import static org.apache.seatunnel.common.exception.CommonErrorCode.UNSUPPORTED_DATA_TYPE;
-import static org.apache.seatunnel.common.exception.CommonErrorCode.UNSUPPORTED_OPERATION;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION;
 import static org.apache.seatunnel.connectors.seatunnel.mongodb.config.MongodbConfig.DEFAULT_JSON_WRITER_SETTINGS;
 import static org.apache.seatunnel.connectors.seatunnel.mongodb.config.MongodbConfig.ENCODE_VALUE_FIELD;
 

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/serde/DocumentRowDataDeserializer.java
Patch:
@@ -26,8 +26,8 @@
 import org.bson.BsonValue;
 
 import static org.apache.seatunnel.api.table.type.SqlType.STRING;
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
-import static org.apache.seatunnel.common.exception.CommonErrorCode.UNSUPPORTED_OPERATION;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION;
 
 public class DocumentRowDataDeserializer implements DocumentDeserializer<SeaTunnelRow> {
 

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/serde/RowDataDocumentSerializer.java
Patch:
@@ -38,7 +38,7 @@
 import java.util.function.Function;
 import java.util.stream.Collectors;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.ILLEGAL_ARGUMENT;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT;
 
 public class RowDataDocumentSerializer implements DocumentSerializer<SeaTunnelRow> {
 

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/serde/RowDataToBsonConverters.java
Patch:
@@ -24,7 +24,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.api.table.type.SqlType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.mongodb.exception.MongodbConnectorException;
 
 import org.bson.BsonArray;
@@ -53,7 +53,7 @@
 import java.util.Objects;
 
 import static org.apache.seatunnel.api.table.type.SqlType.NULL;
-import static org.apache.seatunnel.common.exception.CommonErrorCode.UNSUPPORTED_DATA_TYPE;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE;
 import static org.apache.seatunnel.connectors.seatunnel.mongodb.config.MongodbConfig.ENCODE_VALUE_FIELD;
 import static org.apache.seatunnel.connectors.seatunnel.mongodb.serde.BsonToRowDataConverters.fromBigDecimal;
 
@@ -281,7 +281,7 @@ private static SerializableFunction<Object, BsonValue> createMapConverter(
             String typeSummary, SeaTunnelDataType<?> keyType, SeaTunnelDataType<?> valueType) {
         if (!SqlType.STRING.equals(keyType.getSqlType())) {
             throw new MongodbConnectorException(
-                    CommonErrorCode.UNSUPPORTED_OPERATION,
+                    CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                     "JSON format doesn't support non-string as key type of map. The type is: "
                             + typeSummary);
         }

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/sink/MongodbWriter.java
Patch:
@@ -44,7 +44,7 @@
 import java.util.stream.Collectors;
 import java.util.stream.IntStream;
 
-import static org.apache.seatunnel.common.exception.CommonErrorCode.WRITER_OPERATION_FAILED;
+import static org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated.WRITER_OPERATION_FAILED;
 
 @Slf4j
 public class MongodbWriter implements SinkWriter<SeaTunnelRow, MongodbCommitInfo, DocumentBulk> {

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/source/enumerator/MongodbSplitEnumerator.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.shade.com.google.common.collect.Lists;
 
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.mongodb.exception.MongodbConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.mongodb.internal.MongodbClientProvider;
 import org.apache.seatunnel.connectors.seatunnel.mongodb.source.split.MongoSplit;
@@ -107,7 +107,7 @@ public int currentUnassignedSplitSize() {
     @Override
     public void handleSplitRequest(int subtaskId) {
         throw new MongodbConnectorException(
-                CommonErrorCode.UNSUPPORTED_OPERATION,
+                CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                 String.format("Unsupported handleSplitRequest: %d", subtaskId));
     }
 

File: seatunnel-connectors-v2/connector-neo4j/src/main/java/org/apache/seatunnel/connectors/seatunnel/neo4j/source/Neo4jSourceReader.java
Patch:
@@ -24,7 +24,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.common.source.AbstractSingleSplitReader;
 import org.apache.seatunnel.connectors.seatunnel.common.source.SingleSplitReaderContext;
 import org.apache.seatunnel.connectors.seatunnel.neo4j.config.Neo4jSourceQueryInfo;
@@ -133,7 +133,7 @@ public static Object convertType(SeaTunnelDataType<?> dataType, Value value)
             case MAP:
                 if (!((MapType<?, ?>) dataType).getKeyType().equals(BasicType.STRING_TYPE)) {
                     throw new Neo4jConnectorException(
-                            CommonErrorCode.ILLEGAL_ARGUMENT,
+                            CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
                             "Key Type of MapType must String type");
                 }
                 final SeaTunnelDataType<?> valueType = ((MapType<?, ?>) dataType).getValueType();
@@ -154,7 +154,7 @@ public static Object convertType(SeaTunnelDataType<?> dataType, Value value)
                 return value.asFloat();
             default:
                 throw new Neo4jConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                         "not supported data type: " + dataType);
         }
     }

File: seatunnel-connectors-v2/connector-openmldb/src/main/java/org/apache/seatunnel/connectors/seatunnel/openmldb/source/OpenMldbSourceReader.java
Patch:
@@ -22,7 +22,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.common.source.AbstractSingleSplitReader;
 import org.apache.seatunnel.connectors.seatunnel.common.source.SingleSplitReaderContext;
 import org.apache.seatunnel.connectors.seatunnel.openmldb.config.OpenMldbParameters;
@@ -112,7 +112,8 @@ private Object getObject(ResultSet resultSet, int index, SeaTunnelDataType<?> da
                 return timestamp.toLocalDateTime();
             default:
                 throw new OpenMldbConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE, "Unsupported this data type");
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
+                        "Unsupported this data type");
         }
     }
 }

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/PulsarSource.java
Patch:
@@ -33,7 +33,7 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.pulsar.config.PulsarAdminConfig;
 import org.apache.seatunnel.connectors.seatunnel.pulsar.config.PulsarClientConfig;
 import org.apache.seatunnel.connectors.seatunnel.pulsar.config.PulsarConfigUtil;
@@ -320,7 +320,8 @@ private void setDeserialization(Config config) {
                     break;
                 default:
                     throw new SeaTunnelJsonFormatException(
-                            CommonErrorCode.UNSUPPORTED_DATA_TYPE, "Unsupported format: " + format);
+                            CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
+                            "Unsupported format: " + format);
             }
         } else {
             typeInfo = CatalogTableUtil.buildSimpleTextSchema();

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/enumerator/PulsarSplitEnumerator.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.api.source.Boundedness;
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.pulsar.config.PulsarAdminConfig;
 import org.apache.seatunnel.connectors.seatunnel.pulsar.config.PulsarConfigUtil;
 import org.apache.seatunnel.connectors.seatunnel.pulsar.exception.PulsarConnectorException;
@@ -113,7 +113,7 @@ public PulsarSplitEnumerator(
                 && partitionDiscoveryIntervalMs > 0
                 && Boundedness.BOUNDED == stopCursor.getBoundedness()) {
             throw new PulsarConnectorException(
-                    CommonErrorCode.UNSUPPORTED_OPERATION,
+                    CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                     "Bounded streams do not support dynamic partition discovery.");
         }
         this.context = context;

File: seatunnel-connectors-v2/connector-rocketmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rocketmq/common/SchemaFormat.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.rocketmq.common;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
 
 /** schema format type */
@@ -39,7 +39,7 @@ public static SchemaFormat find(String name) {
             }
         }
         throw new SeaTunnelJsonFormatException(
-                CommonErrorCode.UNSUPPORTED_DATA_TYPE, "Unsupported format: " + name);
+                CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE, "Unsupported format: " + name);
     }
 
     public String getName() {

File: seatunnel-connectors-v2/connector-rocketmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rocketmq/serialize/DefaultSeaTunnelRowSerializer.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.rocketmq.common.SchemaFormat;
 import org.apache.seatunnel.format.json.JsonSerializationSchema;
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
@@ -84,7 +84,8 @@ private static SerializationSchema createSerializationSchema(
                 return new JsonSerializationSchema(rowType);
             default:
                 throw new SeaTunnelJsonFormatException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE, "Unsupported format: " + format);
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
+                        "Unsupported format: " + format);
         }
     }
 

File: seatunnel-connectors-v2/connector-rocketmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rocketmq/sink/RocketMqSinkWriter.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.common.sink.AbstractSinkWriter;
 import org.apache.seatunnel.connectors.seatunnel.rocketmq.exception.RocketMqConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.rocketmq.serialize.DefaultSeaTunnelRowSerializer;
@@ -64,7 +64,7 @@ public void close() throws IOException {
                 this.rocketMqProducerSender.close();
             } catch (Exception e) {
                 throw new RocketMqConnectorException(
-                        CommonErrorCode.WRITER_OPERATION_FAILED,
+                        CommonErrorCodeDeprecated.WRITER_OPERATION_FAILED,
                         "Close RocketMq sink writer error",
                         e);
             }
@@ -91,7 +91,7 @@ private List<String> getPartitionKeyFields(SeaTunnelRowType seaTunnelRowType) {
         for (String partitionKeyField : partitionKeyFields) {
             if (!rowTypeFieldNames.contains(partitionKeyField)) {
                 throw new RocketMqConnectorException(
-                        CommonErrorCode.ILLEGAL_ARGUMENT,
+                        CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
                         String.format(
                                 "Partition key field not found: %s, rowType: %s",
                                 partitionKeyField, rowTypeFieldNames));

File: seatunnel-connectors-v2/connector-rocketmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rocketmq/source/RocketMqSource.java
Patch:
@@ -38,7 +38,7 @@
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.common.constants.PluginType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.connectors.seatunnel.rocketmq.common.RocketMqBaseConfiguration;
 import org.apache.seatunnel.connectors.seatunnel.rocketmq.common.SchemaFormat;
@@ -274,7 +274,8 @@ private void setDeserialization(Config config) {
                     break;
                 default:
                     throw new SeaTunnelJsonFormatException(
-                            CommonErrorCode.UNSUPPORTED_DATA_TYPE, "Unsupported format: " + format);
+                            CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
+                            "Unsupported format: " + format);
             }
         } else {
             typeInfo = CatalogTableUtil.buildSimpleTextSchema();

File: seatunnel-connectors-v2/connector-s3-redshift/src/main/java/org/apache/seatunnel/connectors/seatunnel/redshift/RedshiftJdbcClient.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.redshift.config.S3RedshiftConfig;
 import org.apache.seatunnel.connectors.seatunnel.redshift.exception.S3RedshiftJdbcConnectorException;
 
@@ -50,7 +50,7 @@ public static RedshiftJdbcClient getInstance(Config config)
                                         config.getString(S3RedshiftConfig.JDBC_PASSWORD.key()));
                     } catch (SQLException | ClassNotFoundException e) {
                         throw new S3RedshiftJdbcConnectorException(
-                                CommonErrorCode.SQL_OPERATION_FAILED,
+                                CommonErrorCodeDeprecated.SQL_OPERATION_FAILED,
                                 "RedshiftJdbcClient init error",
                                 e);
                     }
@@ -75,7 +75,7 @@ public boolean checkTableExists(String tableName) {
             flag = rs.next();
         } catch (SQLException e) {
             throw new S3RedshiftJdbcConnectorException(
-                    CommonErrorCode.TABLE_SCHEMA_GET_FAILED,
+                    CommonErrorCodeDeprecated.TABLE_SCHEMA_GET_FAILED,
                     String.format(
                             "Check table is or not existed failed, table name is %s ", tableName),
                     e);

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/serialize/SeaTunnelRowConverter.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.selectdb.serialize;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.DateTimeUtils;
 import org.apache.seatunnel.common.utils.DateUtils;
 import org.apache.seatunnel.common.utils.JsonUtils;
@@ -67,7 +67,8 @@ protected Object convert(SeaTunnelDataType dataType, Object val) {
                 return new String((byte[]) val);
             default:
                 throw new SelectDBConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE, dataType + " is not supported ");
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
+                        dataType + " is not supported ");
         }
     }
 }

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/catalog/StarRocksCatalog.java
Patch:
@@ -34,7 +34,7 @@
 import org.apache.seatunnel.api.table.type.LocalTimeType;
 import org.apache.seatunnel.api.table.type.PrimitiveByteArrayType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.JdbcUrlUtil;
 import org.apache.seatunnel.connectors.seatunnel.starrocks.exception.StarRocksConnectorException;
 
@@ -307,7 +307,7 @@ private SeaTunnelDataType<?> fromJdbcType(ResultSetMetaData metadata, int colInd
                 return new DecimalType(precision, scale);
             default:
                 throw new StarRocksConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                         String.format(
                                 "Doesn't support Starrocks type '%s' yet",
                                 starrocksType.getName()));

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/client/StarRocksStreamLoadVisitor.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.starrocks.client;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.connectors.seatunnel.starrocks.config.SinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.starrocks.exception.StarRocksConnectorErrorCode;
@@ -67,7 +67,7 @@ public Boolean doStreamLoad(StarRocksFlushTuple flushData) throws IOException {
         String host = getAvailableHost();
         if (null == host) {
             throw new StarRocksConnectorException(
-                    CommonErrorCode.ILLEGAL_ARGUMENT,
+                    CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
                     "None of the host in `load_url` could be connected.");
         }
         String loadUrl =

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/serialize/StarRocksBaseSerializer.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.starrocks.serialize;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.DateTimeUtils;
 import org.apache.seatunnel.common.utils.DateUtils;
 import org.apache.seatunnel.common.utils.JsonUtils;
@@ -67,7 +67,8 @@ protected Object convert(SeaTunnelDataType dataType, Object val) {
                 return new String((byte[]) val);
             default:
                 throw new StarRocksConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE, dataType + " is not supported ");
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
+                        dataType + " is not supported ");
         }
     }
 }

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/source/StartRocksSourceSplitEnumerator.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.starrocks.client.source.StarRocksQueryPlanReadClient;
 import org.apache.seatunnel.connectors.seatunnel.starrocks.client.source.model.QueryPartition;
 import org.apache.seatunnel.connectors.seatunnel.starrocks.config.SourceConfig;
@@ -138,7 +138,7 @@ public void close() {
     @Override
     public void handleSplitRequest(int subtaskId) {
         throw new StarRocksConnectorException(
-                CommonErrorCode.UNSUPPORTED_OPERATION,
+                CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                 String.format("Unsupported handleSplitRequest: %d", subtaskId));
     }
 

File: seatunnel-connectors-v2/connector-tablestore/src/main/java/org/apache/seatunnel/connectors/seatunnel/tablestore/sink/TablestoreSinkClient.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.tablestore.sink;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.tablestore.config.TablestoreOptions;
 import org.apache.seatunnel.connectors.seatunnel.tablestore.exception.TablestoreConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.tablestore.exception.TablestoreConnectorException;
@@ -99,7 +99,7 @@ synchronized void flush() {
     private void checkFlushException() {
         if (flushException != null) {
             throw new TablestoreConnectorException(
-                    CommonErrorCode.FLUSH_DATA_FAILED,
+                    CommonErrorCodeDeprecated.FLUSH_DATA_FAILED,
                     "Writing items to Tablestore failed.",
                     flushException);
         }

File: seatunnel-connectors-v2/connector-tdengine/src/main/java/org/apache/seatunnel/connectors/seatunnel/tdengine/typemapper/TDengineTypeMapper.java
Patch:
@@ -22,7 +22,7 @@
 import org.apache.seatunnel.api.table.type.LocalTimeType;
 import org.apache.seatunnel.api.table.type.PrimitiveByteArrayType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.connectors.seatunnel.tdengine.exception.TDengineConnectorException;
 
 import lombok.extern.slf4j.Slf4j;
@@ -144,7 +144,7 @@ public static SeaTunnelDataType<?> mapping(String tdengineType) {
             case TDENGINE_UNKNOWN:
             default:
                 throw new TDengineConnectorException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                         String.format(
                                 "Doesn't support TDENGINE type '%s' on column '%s'  yet.",
                                 tdengineType));

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/utils/FileUtils.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.core.starter.utils;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.exception.SeaTunnelRuntimeException;
 import org.apache.seatunnel.core.starter.command.AbstractCommandArgs;
 
@@ -65,7 +65,8 @@ public static Path getConfigPath(@NonNull AbstractCommandArgs args) {
     public static void checkConfigExist(Path configFile) {
         if (!configFile.toFile().exists()) {
             String message = "Can't find config file: " + configFile;
-            throw new SeaTunnelRuntimeException(CommonErrorCode.FILE_OPERATION_FAILED, message);
+            throw new SeaTunnelRuntimeException(
+                    CommonErrorCodeDeprecated.FILE_OPERATION_FAILED, message);
         }
     }
 

File: seatunnel-formats/seatunnel-format-compatible-connect-json/src/main/java/org/apache/seatunnel/format/compatible/kafka/connect/json/CompatibleKafkaConnectDeserializationSchema.java
Patch:
@@ -25,7 +25,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.ReflectionUtils;
 import org.apache.seatunnel.format.json.JsonToRowConverters;
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
@@ -132,7 +132,7 @@ private SeaTunnelRow convertJsonNode(JsonNode jsonNode) {
             return (SeaTunnelRow) runtimeConverter.convert(jsonData);
         } catch (Throwable t) {
             throw new SeaTunnelJsonFormatException(
-                    CommonErrorCode.JSON_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.JSON_OPERATION_FAILED,
                     String.format("Failed to deserialize JSON '%s'.", jsonNode),
                     t);
         }

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/JsonSerializationSchema.java
Patch:
@@ -24,7 +24,7 @@
 import org.apache.seatunnel.api.serialization.SerializationSchema;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
 
 import lombok.Getter;
@@ -60,7 +60,7 @@ public byte[] serialize(SeaTunnelRow row) {
             return mapper.writeValueAsBytes(node);
         } catch (Throwable e) {
             throw new SeaTunnelJsonFormatException(
-                    CommonErrorCode.JSON_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.JSON_OPERATION_FAILED,
                     String.format("Failed to deserialize JSON '%s'.", row),
                     e);
         }

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/canal/CanalJsonSerializationSchema.java
Patch:
@@ -23,7 +23,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.format.json.JsonSerializationSchema;
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
 
@@ -54,7 +54,7 @@ public byte[] serialize(SeaTunnelRow row) {
             return jsonSerializer.serialize(reuse);
         } catch (Throwable t) {
             throw new SeaTunnelJsonFormatException(
-                    CommonErrorCode.JSON_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.JSON_OPERATION_FAILED,
                     String.format("Could not serialize row %s.", row),
                     t);
         }
@@ -70,7 +70,7 @@ private String rowKind2String(RowKind rowKind) {
                 return OP_DELETE;
             default:
                 throw new SeaTunnelJsonFormatException(
-                        CommonErrorCode.UNSUPPORTED_OPERATION,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                         String.format("Unsupported operation %s for row kind.", rowKind));
         }
     }

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/debezium/DebeziumJsonSerializationSchema.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.format.json.JsonSerializationSchema;
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
 
@@ -66,7 +66,7 @@ public byte[] serialize(SeaTunnelRow row) {
             }
         } catch (Throwable t) {
             throw new SeaTunnelJsonFormatException(
-                    CommonErrorCode.JSON_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.JSON_OPERATION_FAILED,
                     String.format("Could not serialize row %s.", row),
                     t);
         }

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/ogg/OggJsonSerializationSchema.java
Patch:
@@ -23,7 +23,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.format.json.JsonSerializationSchema;
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
 
@@ -54,7 +54,7 @@ public byte[] serialize(SeaTunnelRow row) {
             return jsonSerializer.serialize(reuse);
         } catch (Throwable t) {
             throw new SeaTunnelJsonFormatException(
-                    CommonErrorCode.JSON_OPERATION_FAILED,
+                    CommonErrorCodeDeprecated.JSON_OPERATION_FAILED,
                     String.format("Could not serialize row %s.", row),
                     t);
         }
@@ -70,7 +70,7 @@ private String rowKind2String(RowKind rowKind) {
                 return OP_DELETE;
             default:
                 throw new SeaTunnelJsonFormatException(
-                        CommonErrorCode.UNSUPPORTED_OPERATION,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                         String.format("Unsupported operation %s for row kind.", rowKind));
         }
     }

File: seatunnel-formats/seatunnel-format-text/src/main/java/org/apache/seatunnel/format/text/TextDeserializationSchema.java
Patch:
@@ -24,7 +24,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.DateTimeUtils;
 import org.apache.seatunnel.common.utils.DateUtils;
 import org.apache.seatunnel.common.utils.TimeUtils;
@@ -175,7 +175,7 @@ private Object convert(String field, SeaTunnelDataType<?> fieldType, int level)
                         return objectArrayList.toArray(new Double[0]);
                     default:
                         throw new SeaTunnelTextFormatException(
-                                CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                                CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                                 String.format(
                                         "SeaTunnel array not support this data type [%s]",
                                         elementType.getSqlType()));
@@ -238,7 +238,7 @@ private Object convert(String field, SeaTunnelDataType<?> fieldType, int level)
                 return new SeaTunnelRow(objects);
             default:
                 throw new SeaTunnelTextFormatException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                         String.format(
                                 "SeaTunnel not support this data type [%s]",
                                 fieldType.getSqlType()));

File: seatunnel-formats/seatunnel-format-text/src/main/java/org/apache/seatunnel/format/text/TextSerializationSchema.java
Patch:
@@ -24,14 +24,13 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.utils.DateTimeUtils;
 import org.apache.seatunnel.common.utils.DateUtils;
 import org.apache.seatunnel.common.utils.TimeUtils;
 import org.apache.seatunnel.format.text.constant.TextFormatConstant;
 import org.apache.seatunnel.format.text.exception.SeaTunnelTextFormatException;
 
-import lombok.Builder;
 import lombok.NonNull;
 
 import java.time.LocalDate;
@@ -183,7 +182,7 @@ private String convert(Object field, SeaTunnelDataType<?> fieldType, int level)
                 return String.join(separators[level + 1], strings);
             default:
                 throw new SeaTunnelTextFormatException(
-                        CommonErrorCode.UNSUPPORTED_DATA_TYPE,
+                        CommonErrorCodeDeprecated.UNSUPPORTED_DATA_TYPE,
                         String.format(
                                 "SeaTunnel format text not supported for parsing this type [%s]",
                                 fieldType.getSqlType()));

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/filterrowkind/FilterRowKindTransform.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.type.RowKind;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.common.exception.SeaTunnelRuntimeException;
 import org.apache.seatunnel.transform.common.FilterRowTransform;
 
@@ -61,7 +61,7 @@ private void initConfig(ReadonlyConfig config) {
         if ((includeKinds.isEmpty() && excludeKinds.isEmpty())
                 || (!includeKinds.isEmpty() && !excludeKinds.isEmpty())) {
             throw new SeaTunnelRuntimeException(
-                    CommonErrorCode.ILLEGAL_ARGUMENT,
+                    CommonErrorCodeDeprecated.ILLEGAL_ARGUMENT,
                     String.format(
                             "These options(%s,%s) are mutually exclusive, allowing only one set of options to be configured.",
                             FilterRowKinkTransformConfig.INCLUDE_KINDS.key(),
@@ -79,7 +79,7 @@ protected SeaTunnelRow transformRow(SeaTunnelRow inputRow) {
             return includeKinds.contains(inputRow.getRowKind()) ? inputRow : null;
         }
         throw new SeaTunnelRuntimeException(
-                CommonErrorCode.UNSUPPORTED_OPERATION,
+                CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                 "Transform config error! Either excludeKinds or includeKinds must be configured");
     }
 }

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/jsonpath/JsonPathTransformConfig.java
Patch:
@@ -93,7 +93,7 @@ public static JsonPathTransformConfig of(ReadonlyConfig config) {
             String destField = map.get(DEST_FIELD.key());
             String type = map.getOrDefault(DEST_TYPE.key(), DEST_TYPE.defaultValue());
             SeaTunnelDataType<?> dataType =
-                    SeaTunnelDataTypeConvertorUtil.deserializeSeaTunnelDataType(type);
+                    SeaTunnelDataTypeConvertorUtil.deserializeSeaTunnelDataType(srcField, type);
             ColumnConfig columnConfig = new ColumnConfig(path, srcField, destField, dataType);
             configs.add(columnConfig);
         }

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/SQLEngineFactory.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.transform.sql;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.transform.exception.TransformException;
 import org.apache.seatunnel.transform.sql.zeta.ZetaSQLEngine;
 
@@ -29,7 +29,7 @@ public static SQLEngine getSQLEngine(EngineType engineType) {
                 return new ZetaSQLEngine();
         }
         throw new TransformException(
-                CommonErrorCode.UNSUPPORTED_OPERATION,
+                CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                 String.format("Unsupported SQL engine type: %s", engineType));
     }
 

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/ZetaSQLEngine.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.transform.exception.TransformException;
 import org.apache.seatunnel.transform.sql.SQLEngine;
 
@@ -91,7 +91,7 @@ private void parseSQL() {
             this.selectBody = (PlainSelect) ((Select) statement).getSelectBody();
         } catch (JSQLParserException e) {
             throw new TransformException(
-                    CommonErrorCode.UNSUPPORTED_OPERATION,
+                    CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                     String.format("SQL parse failed: %s, cause: %s", sql, e.getMessage()));
         }
     }
@@ -149,7 +149,7 @@ private void validateSQL(Statement statement) {
             // }
         } catch (Exception e) {
             throw new TransformException(
-                    CommonErrorCode.UNSUPPORTED_OPERATION,
+                    CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                     String.format("SQL validate failed: %s, cause: %s", sql, e.getMessage()));
         }
     }

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/functions/StringFunction.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.transform.sql.zeta.functions;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.transform.exception.TransformException;
 import org.apache.seatunnel.transform.sql.zeta.ZetaSQLFunction;
 
@@ -116,7 +116,7 @@ public static String hextoraw(List<Object> args) {
         int len = arg.length();
         if (len % 4 != 0) {
             throw new TransformException(
-                    CommonErrorCode.UNSUPPORTED_OPERATION,
+                    CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                     String.format("Unsupported arg for function: %s", ZetaSQLFunction.HEXTORAW));
         }
         StringBuilder builder = new StringBuilder(len / 4);
@@ -428,7 +428,7 @@ private static int makeRegexpFlags(String stringFlags, boolean ignoreGlobalFlag)
                         // $FALL-THROUGH$
                     default:
                         throw new TransformException(
-                                CommonErrorCode.UNSUPPORTED_OPERATION,
+                                CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                                 String.format(
                                         "Unsupported regexpMode arg: %s for function: %s",
                                         flags, ZetaSQLFunction.HEXTORAW));

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/functions/SystemFunction.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.transform.sql.zeta.functions;
 
-import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.exception.CommonErrorCodeDeprecated;
 import org.apache.seatunnel.transform.exception.TransformException;
 
 import java.math.BigDecimal;
@@ -42,7 +42,7 @@ public static Object coalesce(List<Object> args) {
     public static Object ifnull(List<Object> args) {
         if (args.size() != 2) {
             throw new TransformException(
-                    CommonErrorCode.UNSUPPORTED_OPERATION,
+                    CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                     String.format("Unsupported function IFNULL() arguments: %s", args));
         }
         return coalesce(args);
@@ -119,7 +119,7 @@ public static Object castAs(List<Object> args) {
                 return bigDecimal.setScale(scale, RoundingMode.CEILING);
         }
         throw new TransformException(
-                CommonErrorCode.UNSUPPORTED_OPERATION,
+                CommonErrorCodeDeprecated.UNSUPPORTED_OPERATION,
                 String.format("Unsupported CAST AS type: %s", v2));
     }
 }

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-3/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcHiveIT.java
Patch:
@@ -141,7 +141,7 @@ protected void insertTestData() {
     }
 
     @Override
-    void compareResult() {}
+    void compareResult(String executeKey) {}
 
     @Override
     String driverUrl() {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/MongodbIncrementalSourceFactory.java
Patch:
@@ -77,7 +77,7 @@ TableSource<T, SplitT, StateT> createSource(TableSourceFactoryContext context) {
                     CatalogTableUtil.getCatalogTables(
                             context.getOptions(), context.getClassLoader());
             SeaTunnelDataType<SeaTunnelRow> dataType =
-                    CatalogTableUtil.convertToDataType(catalogTables);
+                    CatalogTableUtil.convertToMultipleRowType(catalogTables);
             return (SeaTunnelSource<T, SplitT, StateT>)
                     new MongodbIncrementalSource<>(context.getOptions(), dataType, catalogTables);
         };

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlIncrementalSourceFactory.java
Patch:
@@ -97,7 +97,7 @@ TableSource<T, SplitT, StateT> createSource(TableSourceFactoryContext context) {
                     CatalogTableUtil.getCatalogTables(
                             context.getOptions(), context.getClassLoader());
             SeaTunnelDataType<SeaTunnelRow> dataType =
-                    CatalogTableUtil.convertToDataType(catalogTables);
+                    CatalogTableUtil.convertToMultipleRowType(catalogTables);
             return (SeaTunnelSource<T, SplitT, StateT>)
                     new MySqlIncrementalSource<>(context.getOptions(), dataType, catalogTables);
         };

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/SqlServerIncrementalSourceFactory.java
Patch:
@@ -102,7 +102,7 @@ TableSource<T, SplitT, StateT> createSource(TableSourceFactoryContext context) {
                     CatalogTableUtil.getCatalogTables(
                             context.getOptions(), context.getClassLoader());
             SeaTunnelDataType<SeaTunnelRow> dataType =
-                    CatalogTableUtil.convertToDataType(catalogTables);
+                    CatalogTableUtil.convertToMultipleRowType(catalogTables);
             return new SqlServerIncrementalSource(context.getOptions(), dataType, catalogTables);
         };
     }

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/config/Common.java
Patch:
@@ -50,7 +50,7 @@ private Common() {
 
     private static final int PLUGIN_LIB_DIR_DEPTH = 3;
 
-    private static DeployMode MODE;
+    private static DeployMode MODE = DeployMode.CLIENT;
 
     private static String SEATUNNEL_HOME;
 

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/RestApiIT.java
Patch:
@@ -17,8 +17,6 @@
 
 package org.apache.seatunnel.engine.e2e;
 
-import org.apache.seatunnel.common.config.Common;
-import org.apache.seatunnel.common.config.DeployMode;
 import org.apache.seatunnel.engine.client.SeaTunnelClient;
 import org.apache.seatunnel.engine.client.job.ClientJobExecutionEnvironment;
 import org.apache.seatunnel.engine.client.job.ClientJobProxy;
@@ -63,7 +61,6 @@ void beforeClass() throws Exception {
         SeaTunnelConfig seaTunnelConfig = ConfigProvider.locateAndGetSeaTunnelConfig();
         seaTunnelConfig.getHazelcastConfig().setClusterName(testClusterName);
         hazelcastInstance = SeaTunnelServerStarter.createHazelcastInstance(seaTunnelConfig);
-        Common.setDeployMode(DeployMode.CLIENT);
         String filePath = TestUtils.getResource("stream_fakesource_to_file.conf");
         JobConfig jobConfig = new JobConfig();
         jobConfig.setName("fake_to_file");

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -119,7 +119,9 @@ public List<DataStreamTableInfo> execute(List<DataStreamTableInfo> upstreamDataS
                 saveModeHandler.ifPresent(SaveModeHandler::handleSaveMode);
             }
             DataStreamSink<Row> dataStreamSink =
-                    stream.getDataStream().sinkTo(new FlinkSink<>(sink)).name(sink.getPluginName());
+                    stream.getDataStream()
+                            .sinkTo(new FlinkSink<>(sink, stream.getCatalogTable()))
+                            .name(sink.getPluginName());
             if (sinkConfig.hasPath(CommonOptions.PARALLELISM.key())) {
                 int parallelism = sinkConfig.getInt(CommonOptions.PARALLELISM.key());
                 dataStreamSink.setParallelism(parallelism);

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-starter-common/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -121,7 +121,9 @@ public List<DataStreamTableInfo> execute(List<DataStreamTableInfo> upstreamDataS
             }
             DataStreamSink<Row> dataStreamSink =
                     stream.getDataStream()
-                            .sinkTo(SinkV1Adapter.wrap(new FlinkSink<>(sink)))
+                            .sinkTo(
+                                    SinkV1Adapter.wrap(
+                                            new FlinkSink<>(sink, stream.getCatalogTable())))
                             .name(sink.getPluginName());
             if (sinkConfig.hasPath(CommonOptions.PARALLELISM.key())) {
                 int parallelism = sinkConfig.getInt(CommonOptions.PARALLELISM.key());

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-2-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -140,7 +140,7 @@ public List<DatasetTableInfo> execute(List<DatasetTableInfo> upstreamDataStreams
                 Optional<SaveModeHandler> saveModeHandler = saveModeSink.getSaveModeHandler();
                 saveModeHandler.ifPresent(SaveModeHandler::handleSaveMode);
             }
-            SparkSinkInjector.inject(dataset.write(), sink)
+            SparkSinkInjector.inject(dataset.write(), sink, datasetTableInfo.getCatalogTable())
                     .option("checkpointLocation", "/tmp")
                     .save();
         }

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-starter-common/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -141,7 +141,7 @@ public List<DatasetTableInfo> execute(List<DatasetTableInfo> upstreamDataStreams
                 Optional<SaveModeHandler> saveModeHandler = saveModeSink.getSaveModeHandler();
                 saveModeHandler.ifPresent(SaveModeHandler::handleSaveMode);
             }
-            SparkSinkInjector.inject(dataset.write(), sink)
+            SparkSinkInjector.inject(dataset.write(), sink, datasetTableInfo.getCatalogTable())
                     .option("checkpointLocation", "/tmp")
                     .mode(SaveMode.Append)
                     .save();

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/catalog/ElasticSearchCatalog.java
Patch:
@@ -148,7 +148,8 @@ public CatalogTable getTable(TablePath tablePath)
                     PhysicalColumn physicalColumn =
                             PhysicalColumn.of(
                                     fieldName,
-                                    elasticSearchDataTypeConvertor.toSeaTunnelType(fieldType),
+                                    elasticSearchDataTypeConvertor.toSeaTunnelType(
+                                            fieldName, fieldType),
                                     null,
                                     true,
                                     null,

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/source/ElasticsearchSource.java
Patch:
@@ -79,7 +79,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
             for (int i = 0; i < source.size(); i++) {
                 String esType = esFieldType.get(source.get(i));
                 SeaTunnelDataType seaTunnelDataType =
-                        elasticSearchDataTypeConvertor.toSeaTunnelType(esType);
+                        elasticSearchDataTypeConvertor.toSeaTunnelType(source.get(i), esType);
                 fieldTypes[i] = seaTunnelDataType;
             }
             rowTypeInfo = new SeaTunnelRowType(source.toArray(new String[0]), fieldTypes);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/oracle/OracleCreateTableSqlBuilder.java
Patch:
@@ -122,7 +122,9 @@ private String buildColumnType(Column column) {
                     return "CLOB";
                 }
             default:
-                String type = oracleDataTypeConvertor.toConnectorType(column.getDataType(), null);
+                String type =
+                        oracleDataTypeConvertor.toConnectorType(
+                                column.getName(), column.getDataType(), null);
                 if (type.equals("NUMBER")) {
                     if (column.getDataType() instanceof DecimalType) {
                         DecimalType decimalType = (DecimalType) column.getDataType();

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/psql/PostgresCreateTableSqlBuilder.java
Patch:
@@ -157,7 +157,9 @@ private String buildColumnType(Column column) {
                     return "text";
                 }
             default:
-                String type = postgresDataTypeConvertor.toConnectorType(column.getDataType(), null);
+                String type =
+                        postgresDataTypeConvertor.toConnectorType(
+                                column.getName(), column.getDataType(), null);
                 if (type.equals(PG_NUMERIC)) {
                     DecimalType decimalType = (DecimalType) column.getDataType();
                     return "numeric("

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerCreateTableSqlBuilder.java
Patch:
@@ -218,7 +218,8 @@ private String buildColumnIdentifySql(
             } else {
                 // Add column type
                 SqlServerType sqlServerType =
-                        sqlServerDataTypeConvertor.toConnectorType(column.getDataType(), null);
+                        sqlServerDataTypeConvertor.toConnectorType(
+                                column.getName(), column.getDataType(), null);
                 String typeName = sqlServerType.getName();
                 String fieldSuffixSql = null;
                 tyNameDef = typeName;

File: seatunnel-connectors-v2/connector-jdbc/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/SnowflakeDataTypeConvertorTest.java
Patch:
@@ -37,16 +37,16 @@ public void toSeaTunnelType() {
         Assertions.assertEquals(
                 BasicType.STRING_TYPE,
                 snowflakeDataTypeConvertor.toSeaTunnelType(
-                        SnowflakeType.TEXT.name(), Collections.emptyMap()));
+                        "", SnowflakeType.TEXT.name(), Collections.emptyMap()));
 
         Assertions.assertEquals(
                 BasicType.STRING_TYPE,
                 snowflakeDataTypeConvertor.toSeaTunnelType(
-                        SnowflakeType.VARIANT.name(), Collections.emptyMap()));
+                        "", SnowflakeType.VARIANT.name(), Collections.emptyMap()));
 
         Assertions.assertEquals(
                 BasicType.STRING_TYPE,
                 snowflakeDataTypeConvertor.toSeaTunnelType(
-                        SnowflakeType.OBJECT.name(), Collections.emptyMap()));
+                        "", SnowflakeType.OBJECT.name(), Collections.emptyMap()));
     }
 }

File: seatunnel-connectors-v2/connector-maxcompute/src/main/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/util/MaxcomputeTypeMapper.java
Patch:
@@ -87,10 +87,11 @@ public static SeaTunnelRowType getSeaTunnelRowType(Config pluginConfig) {
         try {
             MaxComputeDataTypeConvertor typeConvertor = new MaxComputeDataTypeConvertor();
             for (int i = 0; i < tableSchema.getColumns().size(); i++) {
-                fieldNames.add(tableSchema.getColumns().get(i).getName());
+                String fieldName = tableSchema.getColumns().get(i).getName();
+                fieldNames.add(fieldName);
                 TypeInfo maxcomputeTypeInfo = tableSchema.getColumns().get(i).getTypeInfo();
                 SeaTunnelDataType<?> seaTunnelDataType =
-                        typeConvertor.toSeaTunnelType(maxcomputeTypeInfo, null);
+                        typeConvertor.toSeaTunnelType(fieldName, maxcomputeTypeInfo, null);
                 seaTunnelDataTypes.add(seaTunnelDataType);
             }
         } catch (Exception e) {

File: seatunnel-connectors-v2/connector-starrocks/src/test/java/org/apache/seatunnel/connectors/seatunnel/starrocks/catalog/StarRocksCatalogTest.java
Patch:
@@ -15,11 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.starrocks;
+package org.apache.seatunnel.connectors.seatunnel.starrocks.catalog;
 
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.TablePath;
-import org.apache.seatunnel.connectors.seatunnel.starrocks.catalog.StarRocksCatalog;
 
 import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;

File: seatunnel-connectors-v2/connector-starrocks/src/test/java/org/apache/seatunnel/connectors/seatunnel/starrocks/catalog/StarRocksCreateTableTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.starrocks;
+package org.apache.seatunnel.connectors.seatunnel.starrocks.catalog;
 
 import org.apache.seatunnel.api.table.catalog.Column;
 import org.apache.seatunnel.api.table.catalog.PhysicalColumn;

File: seatunnel-e2e/seatunnel-engine-e2e/seatunnel-engine-k8s-e2e/src/test/java/org/apache/seatunnel/engine/e2e/k8s/KubernetesIT.java
Patch:
@@ -110,7 +110,7 @@ public void test()
             appsV1Api.createNamespacedStatefulSet(
                     namespace, yamlStatefulSet, null, null, null, null);
             Awaitility.await()
-                    .atMost(30, TimeUnit.SECONDS)
+                    .atMost(60, TimeUnit.SECONDS)
                     .untilAsserted(
                             () -> {
                                 V1StatefulSet v1StatefulSet =

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/RestApiIT.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.engine.e2e;
 
+import org.apache.seatunnel.common.config.Common;
+import org.apache.seatunnel.common.config.DeployMode;
 import org.apache.seatunnel.engine.client.SeaTunnelClient;
 import org.apache.seatunnel.engine.client.job.ClientJobExecutionEnvironment;
 import org.apache.seatunnel.engine.client.job.ClientJobProxy;
@@ -61,6 +63,7 @@ void beforeClass() throws Exception {
         SeaTunnelConfig seaTunnelConfig = ConfigProvider.locateAndGetSeaTunnelConfig();
         seaTunnelConfig.getHazelcastConfig().setClusterName(testClusterName);
         hazelcastInstance = SeaTunnelServerStarter.createHazelcastInstance(seaTunnelConfig);
+        Common.setDeployMode(DeployMode.CLIENT);
         String filePath = TestUtils.getResource("stream_fakesource_to_file.conf");
         JobConfig jobConfig = new JobConfig();
         jobConfig.setName("fake_to_file");

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/oracle/OracleDataTypeConvertor.java
Patch:
@@ -66,6 +66,7 @@ public class OracleDataTypeConvertor implements DataTypeConvertor<String> {
     public static final String ORACLE_ROWID = "ROWID";
     public static final String ORACLE_CLOB = "CLOB";
     public static final String ORACLE_NCLOB = "NCLOB";
+    private static final String ORACLE_XML = "XMLTYPE";
     // ------------------------------time-------------------------
     public static final String ORACLE_DATE = "DATE";
     public static final String ORACLE_TIMESTAMP = "TIMESTAMP";
@@ -124,6 +125,7 @@ public SeaTunnelDataType<?> toSeaTunnelType(
             case ORACLE_ROWID:
             case ORACLE_NCLOB:
             case ORACLE_CLOB:
+            case ORACLE_XML:
                 return BasicType.STRING_TYPE;
             case ORACLE_DATE:
                 return LocalTimeType.LOCAL_DATE_TYPE;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/oracle/OracleTypeMapper.java
Patch:
@@ -55,6 +55,7 @@ public class OracleTypeMapper implements JdbcDialectTypeMapper {
     private static final String ORACLE_ROWID = "ROWID";
     private static final String ORACLE_CLOB = "CLOB";
     private static final String ORACLE_NCLOB = "NCLOB";
+    private static final String ORACLE_XML = "SYS.XMLTYPE";
 
     // ------------------------------time-------------------------
     private static final String ORACLE_DATE = "DATE";
@@ -106,6 +107,7 @@ public SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex)
             case ORACLE_ROWID:
             case ORACLE_NCLOB:
             case ORACLE_CLOB:
+            case ORACLE_XML:
                 return BasicType.STRING_TYPE;
             case ORACLE_DATE:
                 return LocalTimeType.LOCAL_DATE_TYPE;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/SnapshotSplitAssigner.java
Patch:
@@ -217,13 +217,13 @@ public SnapshotPhaseState snapshotState(long checkpointId) {
                 new SnapshotPhaseState(
                         alreadyProcessedTables,
                         remainingSplits.isEmpty()
-                                ? Collections.emptyList()
+                                ? new ArrayList<>()
                                 : new ArrayList<>(remainingSplits),
                         assignedSplits,
                         splitCompletedOffsets,
                         assignerCompleted,
                         remainingTables.isEmpty()
-                                ? Collections.emptyList()
+                                ? new ArrayList<>()
                                 : new ArrayList<>(remainingTables),
                         isTableIdCaseSensitive,
                         true);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlDialect.java
Patch:
@@ -32,6 +32,7 @@
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.reader.fetch.scan.MySqlSnapshotFetchTask;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.utils.MySqlSchema;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.utils.TableDiscoveryUtils;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.DatabaseIdentifier;
 
 import io.debezium.jdbc.JdbcConnection;
 import io.debezium.relational.TableId;
@@ -55,7 +56,7 @@ public MySqlDialect(MySqlSourceConfigFactory configFactory) {
 
     @Override
     public String getName() {
-        return "MySQL";
+        return DatabaseIdentifier.MYSQL;
     }
 
     @Override

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlIncrementalSource.java
Patch:
@@ -45,6 +45,7 @@
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.offset.BinlogOffsetFactory;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.JdbcCatalogOptions;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.mysql.MySqlCatalogFactory;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.DatabaseIdentifier;
 
 import com.google.auto.service.AutoService;
 import lombok.NoArgsConstructor;
@@ -109,7 +110,8 @@ public DebeziumDeserializationSchema<T> createDebeziumDeserializationSchema(
         SeaTunnelDataType<SeaTunnelRow> physicalRowType;
         if (dataType == null) {
             // TODO: support metadata keys
-            try (Catalog catalog = new MySqlCatalogFactory().createCatalog("mysql", config)) {
+            try (Catalog catalog =
+                    new MySqlCatalogFactory().createCatalog(DatabaseIdentifier.MYSQL, config)) {
                 catalog.open();
                 CatalogTable table =
                         catalog.getTable(

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/SqlServerDialect.java
Patch:
@@ -32,6 +32,7 @@
 import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.source.reader.fetch.transactionlog.SqlServerTransactionLogFetchTask;
 import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.utils.SqlServerSchema;
 import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.utils.TableDiscoveryUtils;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.dialect.DatabaseIdentifier;
 
 import io.debezium.jdbc.JdbcConnection;
 import io.debezium.relational.TableId;
@@ -56,7 +57,7 @@ public SqlServerDialect(SqlServerSourceConfigFactory configFactory) {
 
     @Override
     public String getName() {
-        return "SqlServer";
+        return DatabaseIdentifier.SQLSERVER;
     }
 
     @Override

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/DatabaseIdentifier.java
Patch:
@@ -27,12 +27,12 @@ public class DatabaseIdentifier {
     public static final String MYSQL = "MySQL";
     public static final String ORACLE = "Oracle";
     public static final String PHOENIX = "Phoenix";
-    public static final String POSTGRESQL = "PostgreSQL";
+    public static final String POSTGRESQL = "Postgres";
     public static final String REDSHIFT = "Redshift";
     public static final String SAP_HANA = "SapHana";
     public static final String SNOWFLAKE = "Snowflake";
     public static final String SQLITE = "Sqlite";
-    public static final String SQLSERVER = "Sqlserver";
+    public static final String SQLSERVER = "SqlServer";
     public static final String TABLE_STORE = "Tablestore";
     public static final String TERADATA = "Teradata";
     public static final String VERTICA = "Vertica";

File: seatunnel-core/seatunnel-starter/src/main/java/org/apache/seatunnel/core/starter/seatunnel/command/ClientExecuteCommand.java
Patch:
@@ -130,10 +130,12 @@ public void execute() throws CommandExecuteException {
                             engineClient.restoreExecutionContext(
                                     configFile.toString(),
                                     jobConfig,
+                                    seaTunnelConfig,
                                     Long.parseLong(clientCommandArgs.getRestoreJobId()));
                 } else {
                     jobExecutionEnv =
-                            engineClient.createExecutionContext(configFile.toString(), jobConfig);
+                            engineClient.createExecutionContext(
+                                    configFile.toString(), jobConfig, seaTunnelConfig);
                 }
 
                 // get job start time

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/RestApiIT.java
Patch:
@@ -69,7 +69,7 @@ void beforeClass() throws Exception {
         clientConfig.setClusterName(testClusterName);
         SeaTunnelClient engineClient = new SeaTunnelClient(clientConfig);
         ClientJobExecutionEnvironment jobExecutionEnv =
-                engineClient.createExecutionContext(filePath, jobConfig);
+                engineClient.createExecutionContext(filePath, jobConfig, seaTunnelConfig);
 
         clientJobProxy = jobExecutionEnv.execute();
 

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/TextHeaderIT.java
Patch:
@@ -131,7 +131,8 @@ public void enableWriteHeader(String file_format_type, String headerWrite, Strin
             clientConfig.setClusterName(TestUtils.getClusterName(testClusterName));
             engineClient = new SeaTunnelClient(clientConfig);
             ClientJobExecutionEnvironment jobExecutionEnv =
-                    engineClient.createExecutionContext(testResources.getRight(), jobConfig);
+                    engineClient.createExecutionContext(
+                            testResources.getRight(), jobConfig, seaTunnelConfig);
             ClientJobProxy clientJobProxy = jobExecutionEnv.execute();
 
             CompletableFuture<JobStatus> objectCompletableFuture =

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/Constant.java
Patch:
@@ -58,4 +58,6 @@ public class Constant {
     public static final String IMAP_RUNNING_JOB_METRICS = "engine_runningJobMetrics";
 
     public static final Long IMAP_RUNNING_JOB_METRICS_KEY = 1L;
+
+    public static final String IMAP_CONNECTOR_JAR_REF_COUNTERS = "engine_connectorJarRefCounters";
 }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/ShuffleAction.java
Patch:
@@ -25,7 +25,7 @@
 public class ShuffleAction extends AbstractAction {
 
     public ShuffleAction(long id, @NonNull String name, @NonNull ShuffleConfig shuffleConfig) {
-        super(id, name, new ArrayList<>(), new HashSet<>(), shuffleConfig);
+        super(id, name, new ArrayList<>(), new HashSet<>(), new HashSet<>(), shuffleConfig);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/AbstractTask.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.task;
 
 import org.apache.seatunnel.api.serialization.Serializer;
+import org.apache.seatunnel.engine.core.job.ConnectorJarIdentifier;
 import org.apache.seatunnel.engine.server.checkpoint.operation.TaskReportStatusOperation;
 import org.apache.seatunnel.engine.server.execution.ProgressState;
 import org.apache.seatunnel.engine.server.execution.Task;
@@ -64,6 +65,8 @@ public AbstractTask(long jobID, TaskLocation taskLocation) {
 
     public abstract Set<URL> getJarsUrl();
 
+    public abstract Set<ConnectorJarIdentifier> getConnectorPluginJars();
+
     @Override
     public void setTaskExecutionContext(TaskExecutionContext taskExecutionContext) {
         this.executionContext = taskExecutionContext;

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/CoordinatorServiceTest.java
Patch:
@@ -107,6 +107,7 @@ public void testClearCoordinatorService() {
                         "Test",
                         coordinatorServiceTest.getSerializationService().toData(testLogicalDag),
                         testLogicalDag.getJobConfig(),
+                        Collections.emptyList(),
                         Collections.emptyList());
 
         Data data =
@@ -168,6 +169,7 @@ public void testJobRestoreWhenMasterNodeSwitch() throws InterruptedException {
                         "Test",
                         instance1.getSerializationService().toData(testLogicalDag),
                         testLogicalDag.getJobConfig(),
+                        Collections.emptyList(),
                         Collections.emptyList());
 
         Data data = instance1.getSerializationService().toData(jobImmutableInformation);

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointTimeOutTest.java
Patch:
@@ -71,6 +71,7 @@ private void startJob(Long jobid, String path) {
                         false,
                         nodeEngine.getSerializationService().toData(testLogicalDag),
                         testLogicalDag.getJobConfig(),
+                        Collections.emptyList(),
                         Collections.emptyList());
 
         Data data = nodeEngine.getSerializationService().toData(jobImmutableInformation);

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/SavePointTest.java
Patch:
@@ -134,6 +134,7 @@ private void startJob(Long jobid, String path, boolean isStartWithSavePoint) {
                         isStartWithSavePoint,
                         nodeEngine.getSerializationService().toData(testLogicalDag),
                         testLogicalDag.getJobConfig(),
+                        Collections.emptyList(),
                         Collections.emptyList());
 
         Data data = nodeEngine.getSerializationService().toData(jobImmutableInformation);

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/master/JobHistoryServiceTest.java
Patch:
@@ -137,6 +137,7 @@ private void startJob(Long jobid, String path) {
                         "Test",
                         nodeEngine.getSerializationService().toData(testLogicalDag),
                         testLogicalDag.getJobConfig(),
+                        Collections.emptyList(),
                         Collections.emptyList());
 
         Data data = nodeEngine.getSerializationService().toData(jobImmutableInformation);

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/master/JobMasterTest.java
Patch:
@@ -118,6 +118,7 @@ public void testHandleCheckpointTimeout() throws Exception {
                         "Test",
                         nodeEngine.getSerializationService().toData(testLogicalDag),
                         testLogicalDag.getJobConfig(),
+                        Collections.emptyList(),
                         Collections.emptyList());
 
         Data data = nodeEngine.getSerializationService().toData(jobImmutableInformation);

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/master/JobMetricsTest.java
Patch:
@@ -156,6 +156,7 @@ private void startJob(Long jobid, String path, boolean isStartWithSavePoint) {
                         isStartWithSavePoint,
                         nodeEngine.getSerializationService().toData(testLogicalDag),
                         testLogicalDag.getJobConfig(),
+                        Collections.emptyList(),
                         Collections.emptyList());
 
         Data data = nodeEngine.getSerializationService().toData(jobImmutableInformation);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/AbstractJdbcCatalog.java
Patch:
@@ -494,7 +494,7 @@ protected List<String> queryString(String url, String sql, ResultSetConsumer<Str
     // If sql is DDL, the execute() method always returns false, so the return value
     // should not be used to determine whether changes were made in database.
     protected boolean executeInternal(String url, String sql) throws SQLException {
-        LOG.info("create table sql is: {}", sql);
+        LOG.info("Execute sql : {}", sql);
         try (PreparedStatement ps = getConnection(url).prepareStatement(sql)) {
             return ps.execute();
         }

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/enumerator/AbstractSplitEnumerator.java
Patch:
@@ -108,7 +108,7 @@ protected void refreshPendingSplits() {
     private void addPendingSplits(Collection<IcebergFileScanTaskSplit> newSplits) {
         int numReaders = context.currentParallelism();
         for (IcebergFileScanTaskSplit newSplit : newSplits) {
-            int ownerReader = newSplit.splitId().hashCode() % numReaders;
+            int ownerReader = (newSplit.splitId().hashCode() & Integer.MAX_VALUE) % numReaders;
             pendingSplits.computeIfAbsent(ownerReader, r -> new ArrayList<>()).add(newSplit);
             log.info("Assigning {} to {} reader.", newSplit, ownerReader);
         }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SeaTunnelSink.java
Patch:
@@ -57,7 +57,9 @@ public interface SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT>
      * @param seaTunnelRowType The row type info of sink.
      */
     @Deprecated
-    void setTypeInfo(SeaTunnelRowType seaTunnelRowType);
+    default void setTypeInfo(SeaTunnelRowType seaTunnelRowType) {
+        throw new UnsupportedOperationException("setTypeInfo method is not supported");
+    }
 
     /**
      * Get the data type of the records consumed by this sink.

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/TableSinkFactory.java
Patch:
@@ -34,7 +34,7 @@ public interface TableSinkFactory<IN, StateT, CommitInfoT, AggregatedCommitInfoT
      * We will never use this method now. So gave a default implement and return null.
      *
      * @param context TableFactoryContext
-     * @return
+     * @return return the sink created by this factory
      */
     default TableSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT> createSink(
             TableSinkFactoryContext context) {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/psql/PostgresDataTypeConvertor.java
Patch:
@@ -108,6 +108,7 @@ public class PostgresDataTypeConvertor implements DataTypeConvertor<String> {
     public static final String PG_GEOGRAPHY = "geography";
     public static final String PG_JSON = "json";
     public static final String PG_JSONB = "jsonb";
+    public static final String PG_XML = "xml";
 
     @Override
     public SeaTunnelDataType<?> toSeaTunnelType(String connectorDataType) {
@@ -165,6 +166,7 @@ public SeaTunnelDataType<?> toSeaTunnelType(
             case PG_GEOGRAPHY:
             case PG_JSON:
             case PG_JSONB:
+            case PG_XML:
                 return BasicType.STRING_TYPE;
             case PG_CHAR_ARRAY:
             case PG_CHARACTER_ARRAY:

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/psql/PostgresTypeMapper.java
Patch:
@@ -88,6 +88,7 @@ public class PostgresTypeMapper implements JdbcDialectTypeMapper {
     private static final String PG_GEOGRAPHY = "geography";
     private static final String PG_JSON = "json";
     private static final String PG_JSONB = "jsonb";
+    private static final String PG_XML = "xml";
 
     @Override
     public SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex)
@@ -142,6 +143,7 @@ public SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex)
             case PG_GEOGRAPHY:
             case PG_JSON:
             case PG_JSONB:
+            case PG_XML:
                 return BasicType.STRING_TYPE;
             case PG_CHAR_ARRAY:
             case PG_CHARACTER_ARRAY:

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/job/RestJobExecutionEnvironment.java
Patch:
@@ -55,7 +55,7 @@ public RestJobExecutionEnvironment(
                                         .getHazelcastInstance()
                                         .getFlakeIdGenerator(Constant.SEATUNNEL_ID_GENERATOR_NAME)
                                         .newId()));
-        this.jobId = Long.valueOf(jobConfig.getJobContext().getJobId());
+        this.jobId = Long.valueOf(this.jobConfig.getJobContext().getJobId());
     }
 
     public Long getJobId() {

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/executor/JdbcBatchStatementExecutorBuilder.java
Patch:
@@ -57,8 +57,8 @@ private boolean supportReplacingMergeTreeTableUpsert() {
 
     private String[] getDefaultProjectionFields() {
         List<String> fieldNames = Arrays.asList(rowType.getFieldNames());
-        return clickhouseTableSchema.keySet().stream()
-                .filter(fieldNames::contains)
+        return fieldNames.stream()
+                .filter(clickhouseTableSchema::containsKey)
                 .toArray(String[]::new);
     }
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/option/JdbcSourceOptions.java
Patch:
@@ -77,7 +77,7 @@ public class JdbcSourceOptions extends SourceOptions {
                                     + "currently-running database processes in the MySQL cluster. This connector"
                                     + " joins the MySQL  cluster as another server (with this unique ID) "
                                     + "so it can read the binlog. By default, a random number is generated between"
-                                    + " 5400 and 6400, though we recommend setting an explicit value.");
+                                    + " 6500 and 2,148,492,146, though we recommend setting an explicit value.");
 
     public static final Option<Long> CONNECT_TIMEOUT_MS =
             Options.key("connect.timeout.ms")

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/MySqlSourceConfigFactory.java
Patch:
@@ -39,8 +39,8 @@ public class MySqlSourceConfigFactory extends JdbcSourceConfigFactory {
      * required when 'scan.incremental.snapshot.enabled' enabled. Every ID must be unique across all
      * currently-running database processes in the MySQL cluster. This connector joins the MySQL
      * cluster as another server (with this unique ID) so it can read the binlog. By default, a
-     * random number is generated between 5400 and 6400, though we recommend setting an explicit
-     * value."
+     * random number is generated between 6500 and 2,148,492,146, though we recommend setting an
+     * explicit value."
      */
     public MySqlSourceConfigFactory serverId(String serverId) {
         this.serverIdRange = ServerIdRange.from(serverId);

File: seatunnel-connectors-v2/connector-maxcompute/src/main/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/catalog/MaxComputeCatalogFactory.java
Patch:
@@ -25,7 +25,7 @@
 
 import com.google.auto.service.AutoService;
 
-import static org.apache.seatunnel.api.table.catalog.CatalogTableUtil.SCHEMA;
+import static org.apache.seatunnel.api.table.catalog.schema.TableSchemaOptions.SCHEMA;
 import static org.apache.seatunnel.connectors.seatunnel.maxcompute.config.MaxcomputeConfig.ACCESS_ID;
 import static org.apache.seatunnel.connectors.seatunnel.maxcompute.config.MaxcomputeConfig.ACCESS_KEY;
 import static org.apache.seatunnel.connectors.seatunnel.maxcompute.config.MaxcomputeConfig.ENDPOINT;

File: seatunnel-connectors-v2/connector-maxcompute/src/main/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/source/MaxcomputeSource.java
Patch:
@@ -33,7 +33,7 @@
 import com.google.auto.service.AutoService;
 import lombok.extern.slf4j.Slf4j;
 
-import static org.apache.seatunnel.api.table.catalog.CatalogTableUtil.SCHEMA;
+import static org.apache.seatunnel.api.table.catalog.schema.TableSchemaOptions.SCHEMA;
 import static org.apache.seatunnel.connectors.seatunnel.maxcompute.config.MaxcomputeConfig.PLUGIN_NAME;
 
 @Slf4j

File: seatunnel-connectors-v2/connector-maxcompute/src/main/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/source/MaxcomputeSourceFactory.java
Patch:
@@ -24,7 +24,7 @@
 
 import com.google.auto.service.AutoService;
 
-import static org.apache.seatunnel.api.table.catalog.CatalogTableUtil.SCHEMA;
+import static org.apache.seatunnel.api.table.catalog.schema.TableSchemaOptions.SCHEMA;
 import static org.apache.seatunnel.connectors.seatunnel.maxcompute.config.MaxcomputeConfig.ACCESS_ID;
 import static org.apache.seatunnel.connectors.seatunnel.maxcompute.config.MaxcomputeConfig.ACCESS_KEY;
 import static org.apache.seatunnel.connectors.seatunnel.maxcompute.config.MaxcomputeConfig.ENDPOINT;

File: seatunnel-connectors-v2/connector-assert/src/main/java/org/apache/seatunnel/connectors/seatunnel/assertion/sink/AssertSink.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
 import org.apache.seatunnel.api.sink.SinkWriter;
+import org.apache.seatunnel.api.sink.SupportMultiTableSink;
 import org.apache.seatunnel.api.table.catalog.CatalogOptions;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
@@ -50,7 +51,8 @@
 import static org.apache.seatunnel.connectors.seatunnel.assertion.sink.AssertConfig.RULES;
 
 @AutoService(SeaTunnelSink.class)
-public class AssertSink extends AbstractSimpleSink<SeaTunnelRow, Void> {
+public class AssertSink extends AbstractSimpleSink<SeaTunnelRow, Void>
+        implements SupportMultiTableSink {
     private SeaTunnelRowType seaTunnelRowType;
     private CatalogTable catalogTable;
     private List<AssertFieldRule> assertFieldRules;

File: seatunnel-connectors-v2/connector-assert/src/main/java/org/apache/seatunnel/connectors/seatunnel/assertion/sink/AssertSinkWriter.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.assertion.sink;
 
+import org.apache.seatunnel.api.sink.SupportMultiTableSinkWriter;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.assertion.excecutor.AssertExecutor;
@@ -33,7 +34,8 @@
 import java.util.concurrent.CopyOnWriteArraySet;
 import java.util.concurrent.atomic.LongAccumulator;
 
-public class AssertSinkWriter extends AbstractSinkWriter<SeaTunnelRow, Void> {
+public class AssertSinkWriter extends AbstractSinkWriter<SeaTunnelRow, Void>
+        implements SupportMultiTableSinkWriter<Void> {
 
     private final SeaTunnelRowType seaTunnelRowType;
     private final List<AssertFieldRule> assertFieldRules;

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/TestContainer.java
Patch:
@@ -34,4 +34,6 @@ void executeExtraCommands(ContainerExtendedFactory extendedFactory)
             throws IOException, InterruptedException;
 
     Container.ExecResult executeJob(String confFile) throws IOException, InterruptedException;
+
+    String getServerLogs();
 }

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/TestUtils.java
Patch:
@@ -43,7 +43,7 @@ public void testContentFormatUtil() throws InterruptedException {
                     new JobStatusData(
                             4352352414135L + i,
                             "Testfdsafew" + i,
-                            JobStatus.CANCELLING,
+                            JobStatus.CANCELING,
                             System.currentTimeMillis(),
                             System.currentTimeMillis()));
             Thread.sleep(2L);
@@ -53,7 +53,7 @@ public void testContentFormatUtil() throws InterruptedException {
                     new JobStatusData(
                             4352352414135L + i,
                             "fdsafsddfasfsdafasdf" + i,
-                            JobStatus.RECONCILING,
+                            JobStatus.UNKNOWABLE,
                             System.currentTimeMillis(),
                             null));
             Thread.sleep(2L);

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/job/PipelineStatus.java
Patch:
@@ -66,9 +66,9 @@ public enum PipelineStatus {
 
     CANCELED,
 
-    FAILED,
+    FAILING,
 
-    RECONCILING,
+    FAILED,
 
     /** Restoring last possible valid state of the pipeline if it has it. */
     INITIALIZING;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobHistoryService.java
Patch:
@@ -36,6 +36,7 @@
 import com.hazelcast.map.IMap;
 import lombok.AllArgsConstructor;
 import lombok.Data;
+import lombok.Getter;
 
 import java.io.Serializable;
 import java.util.ArrayList;
@@ -76,7 +77,7 @@ public class JobHistoryService {
      * finishedJobStateImap key is jobId and value is jobState(json) JobStateData Indicates the
      * status of the job, pipeline, and task
      */
-    private final IMap<Long, JobState> finishedJobStateImap;
+    @Getter private final IMap<Long, JobState> finishedJobStateImap;
 
     private final IMap<Long, JobMetrics> finishedJobMetricsImap;
 

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/rest/RestService.java
Patch:
@@ -230,7 +230,9 @@ private static String parseResponse(HttpURLConnection connection, Logger logger)
         } catch (IOException e) {
             throw new IOException(e);
         } finally {
-            in.close();
+            if (in != null) {
+                in.close();
+            }
         }
         return result.toString();
     }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SeaTunnelSource.java
Patch:
@@ -56,7 +56,7 @@ public interface SeaTunnelSource<T, SplitT extends SourceSplit, StateT extends S
      */
     @Deprecated
     default SeaTunnelDataType<T> getProducedType() {
-        throw new UnsupportedOperationException("getProducedType method has not been implemented.");
+        return (SeaTunnelDataType) getProducedCatalogTables().get(0).getSeaTunnelRowType();
     }
 
     /**

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/execution/PluginUtil.java
Patch:
@@ -117,7 +117,6 @@ private static boolean isFallback(Optional<Factory> factory) {
                             .equals(e.getMessage())) {
                 return true;
             }
-            return true;
         }
         return false;
     }

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -138,7 +138,6 @@ public boolean isFallback(Factory factory) {
                             .equals(e.getMessage())) {
                 return true;
             }
-            return true;
         }
         return false;
     }

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-starter-common/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -141,7 +141,6 @@ public boolean isFallback(Factory factory) {
                             .equals(e.getMessage())) {
                 return true;
             }
-            return true;
         }
         return false;
     }

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-2-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -157,7 +157,6 @@ public boolean isFallback(Factory factory) {
                             .equals(e.getMessage())) {
                 return true;
             }
-            return true;
         }
         return false;
     }

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-starter-common/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -159,7 +159,6 @@ public boolean isFallback(Factory factory) {
                             .equals(e.getMessage())) {
                 return true;
             }
-            return true;
         }
         return false;
     }

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/TestUtils.java
Patch:
@@ -63,7 +63,6 @@ public static LogicalDag getTestLogicalDag(JobContext jobContext) throws Malform
                                         "fields", ImmutableMap.of("id", "int", "name", "string"))));
         FakeSource fakeSource = new FakeSource(ReadonlyConfig.fromConfig(fakeSourceConfig));
         fakeSource.setJobContext(jobContext);
-        fakeSource.prepare(fakeSourceConfig);
 
         Action fake =
                 new SourceAction<>(

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointPlanTest.java
Patch:
@@ -115,7 +115,6 @@ private static void fillVirtualVertex(
                                 Collections.singletonMap(
                                         "fields", ImmutableMap.of("id", "int", "name", "string"))));
         FakeSource fakeSource = new FakeSource(ReadonlyConfig.fromConfig(fakeSourceConfig));
-        fakeSource.prepare(fakeSourceConfig);
         fakeSource.setJobContext(jobContext);
 
         Action fake =

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/dag/TaskTest.java
Patch:
@@ -165,8 +165,6 @@ private static FakeSource createFakeSource() {
                                 "schema",
                                 Collections.singletonMap(
                                         "fields", ImmutableMap.of("id", "int", "name", "string"))));
-        FakeSource fakeSource = new FakeSource(ReadonlyConfig.fromConfig(fakeSourceConfig));
-        fakeSource.prepare(fakeSourceConfig);
-        return fakeSource;
+        return new FakeSource(ReadonlyConfig.fromConfig(fakeSourceConfig));
     }
 }

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -101,7 +101,7 @@ public List<DataStreamTableInfo> execute(List<DataStreamTableInfo> upstreamDataS
                                         sinkConfig.getString(PLUGIN_NAME.key())),
                                 sinkConfig);
                 sink.setJobContext(jobContext);
-                SeaTunnelRowType sourceType = initSourceType(sinkConfig, stream.getDataStream());
+                SeaTunnelRowType sourceType = stream.getCatalogTable().getSeaTunnelRowType();
                 sink.setTypeInfo(sourceType);
             } else {
                 TableSinkFactoryContext context =

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-starter-common/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -102,7 +102,7 @@ public List<DataStreamTableInfo> execute(List<DataStreamTableInfo> upstreamDataS
                                         sinkConfig.getString(PLUGIN_NAME.key())),
                                 sinkConfig);
                 sink.setJobContext(jobContext);
-                SeaTunnelRowType sourceType = initSourceType(sinkConfig, stream.getDataStream());
+                SeaTunnelRowType sourceType = stream.getCatalogTable().getSeaTunnelRowType();
                 sink.setTypeInfo(sourceType);
             } else {
                 TableSinkFactoryContext context =

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-starter-common/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SourceExecuteProcessor.java
Patch:
@@ -24,7 +24,6 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SupportCoordinate;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.core.starter.enums.PluginType;
 import org.apache.seatunnel.core.starter.execution.PluginUtil;
@@ -95,7 +94,6 @@ public List<DataStreamTableInfo> execute(List<DataStreamTableInfo> upstreamDataS
                             sourceFunction,
                             "SeaTunnel " + internalSource.getClass().getSimpleName(),
                             bounded);
-            stageType(pluginConfig, (SeaTunnelRowType) internalSource.getProducedType());
 
             if (pluginConfig.hasPath(CommonOptions.PARALLELISM.key())) {
                 int parallelism = pluginConfig.getInt(CommonOptions.PARALLELISM.key());

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-starter-common/src/main/java/org/apache/seatunnel/core/starter/flink/execution/TransformExecuteProcessor.java
Patch:
@@ -91,11 +91,10 @@ public List<DataStreamTableInfo> execute(List<DataStreamTableInfo> upstreamDataS
                 ConfigValidator.of(context.getOptions()).validate(factory.optionRule());
                 SeaTunnelTransform transform = factory.createTransform(context).createTransform();
 
-                SeaTunnelRowType sourceType = initSourceType(pluginConfig, stream.getDataStream());
+                SeaTunnelRowType sourceType = stream.getCatalogTable().getSeaTunnelRowType();
                 transform.setJobContext(jobContext);
                 DataStream<Row> inputStream =
                         flinkTransform(sourceType, transform, stream.getDataStream());
-                stageType(pluginConfig, transform.getProducedCatalogTable().getSeaTunnelRowType());
                 registerResultTable(pluginConfig, inputStream);
                 upstreamDataStreams.add(
                         new DataStreamTableInfo(

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/common/SeaTunnelPluginLifeCycle.java
Patch:
@@ -39,5 +39,7 @@ public interface SeaTunnelPluginLifeCycle {
      *     org.apache.seatunnel.api.table.factory.Factory}
      */
     @Deprecated
-    void prepare(Config pluginConfig) throws PrepareFailException;
+    default void prepare(Config pluginConfig) throws PrepareFailException {
+        throw new UnsupportedOperationException("prepare method is not supported");
+    }
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/transform/SeaTunnelTransform.java
Patch:
@@ -41,7 +41,9 @@ default void open() {}
      * @param inputDataType The data type info of upstream input.
      */
     @Deprecated
-    void setTypeInfo(SeaTunnelDataType<T> inputDataType);
+    default void setTypeInfo(SeaTunnelDataType<T> inputDataType) {
+        throw new UnsupportedOperationException("setTypeInfo method is not supported");
+    }
 
     /**
      * Get the data type of the records produced by this transform.

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/serde/BsonToRowDataConverters.java
Patch:
@@ -86,9 +86,7 @@ private static SerializableFunction<BsonValue, Object> wrapIntoNullSafeInternalC
             @Override
             public Object apply(BsonValue bsonValue) {
                 if (isBsonValueNull(bsonValue) || isBsonDecimalNaN(bsonValue)) {
-                    throw new MongodbConnectorException(
-                            UNSUPPORTED_OPERATION,
-                            "Unable to convert to <" + type + "> from nullable value " + bsonValue);
+                    return null;
                 }
                 return internalConverter.apply(bsonValue);
             }

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-starter-common/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SourceExecuteProcessor.java
Patch:
@@ -76,6 +76,7 @@ public List<DatasetTableInfo> execute(List<DatasetTableInfo> upstreamDataStreams
                                         CommonOptions.PARALLELISM.key(),
                                         CommonOptions.PARALLELISM.defaultValue());
             }
+            StructType schema = (StructType) TypeConverterUtils.convert(source.getProducedType());
             Dataset<Row> dataset =
                     sparkRuntimeEnvironment
                             .getSparkSession()
@@ -85,9 +86,7 @@ public List<DatasetTableInfo> execute(List<DatasetTableInfo> upstreamDataStreams
                             .option(
                                     Constants.SOURCE_SERIALIZATION,
                                     SerializationUtils.objectToString(source))
-                            .schema(
-                                    (StructType)
-                                            TypeConverterUtils.convert(source.getProducedType()))
+                            .schema(schema)
                             .load();
             sources.add(
                     new DatasetTableInfo(

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelRow.java
Patch:
@@ -255,6 +255,7 @@ private int getBytesForValue(Object v) {
             case "Double[]":
                 return ((Double[]) v).length * 8;
             case "HashMap":
+            case "LinkedHashMap":
                 int size = 0;
                 for (Map.Entry<?, ?> entry : ((Map<?, ?>) v).entrySet()) {
                     size += getBytesForValue(entry.getKey()) + getBytesForValue(entry.getValue());

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/AbstractJdbcCatalog.java
Patch:
@@ -539,6 +539,7 @@ protected List<String> queryString(String url, String sql, ResultSetConsumer<Str
     // If sql is DDL, the execute() method always returns false, so the return value
     // should not be used to determine whether changes were made in database.
     protected boolean executeInternal(String url, String sql) throws SQLException {
+        LOG.info("create table sql is: {}", sql);
         try (PreparedStatement ps = getConnection(url).prepareStatement(sql)) {
             return ps.execute();
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/oracle/OracleCreateTableSqlBuilder.java
Patch:
@@ -91,7 +91,7 @@ private String buildColumnSql(Column column) {
         columnSql.append("\"").append(column.getName()).append("\" ");
 
         String columnType =
-                sourceCatalogName.equals("oracle")
+                StringUtils.equalsIgnoreCase("oracle", sourceCatalogName)
                         ? column.getSourceType()
                         : buildColumnType(column);
         columnSql.append(columnType);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/psql/PostgresCreateTableSqlBuilder.java
Patch:
@@ -89,7 +89,7 @@ private String buildColumnSql(Column column) {
 
         // For simplicity, assume the column type in SeaTunnelDataType is the same as in PostgreSQL
         String columnType =
-                sourceCatalogName.equals("postgres")
+                StringUtils.equalsIgnoreCase("postgres", sourceCatalogName)
                         ? column.getSourceType()
                         : buildColumnType(column);
         columnSql.append(columnType);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkFactory.java
Patch:
@@ -102,6 +102,7 @@ public TableSink createSink(TableSinkFactoryContext context) {
                                 catalogTable.getTableSchema(),
                                 catalogTable.getOptions(),
                                 catalogTable.getPartitionKeys(),
+                                catalogTable.getComment(),
                                 catalogTable.getCatalogName());
             }
             Map<String, String> map = config.toMap();

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/debezium/row/SeaTunnelRowDebeziumDeserializationConverters.java
Patch:
@@ -81,11 +81,11 @@ public SeaTunnelRow convert(SourceRecord record, Struct struct, Schema schema)
         // physical column
         for (int i = 0; i < physicalConverters.length; i++) {
             String fieldName = fieldNames[i];
-            Object fieldValue = struct.get(fieldName);
             Field field = schema.field(fieldName);
             if (field == null) {
                 row.setField(i, null);
             } else {
+                Object fieldValue = struct.get(fieldName);
                 Schema fieldSchema = field.schema();
                 Object convertedField =
                         SeaTunnelRowDebeziumDeserializationConverters.convertField(

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -31,7 +31,6 @@
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
 import org.apache.seatunnel.plugin.discovery.seatunnel.SeaTunnelSinkPluginDiscovery;
 import org.apache.seatunnel.translation.flink.sink.FlinkSink;
-import org.apache.seatunnel.translation.flink.utils.TypeConverterUtils;
 
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.datastream.DataStreamSink;
@@ -101,8 +100,8 @@ public List<DataStream<Row>> execute(List<DataStream<Row>> upstreamDataStreams)
             SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializable> seaTunnelSink =
                     plugins.get(i);
             DataStream<Row> stream = fromSourceTable(sinkConfig).orElse(input);
-            seaTunnelSink.setTypeInfo(
-                    (SeaTunnelRowType) TypeConverterUtils.convert(stream.getType()));
+            SeaTunnelRowType sourceType = initSourceType(sinkConfig, stream);
+            seaTunnelSink.setTypeInfo(sourceType);
             if (SupportDataSaveMode.class.isAssignableFrom(seaTunnelSink.getClass())) {
                 SupportDataSaveMode saveModeSink = (SupportDataSaveMode) seaTunnelSink;
                 DataSaveMode dataSaveMode = saveModeSink.getUserConfigSaveMode();

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-starter-common/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -31,7 +31,6 @@
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
 import org.apache.seatunnel.plugin.discovery.seatunnel.SeaTunnelSinkPluginDiscovery;
 import org.apache.seatunnel.translation.flink.sink.FlinkSink;
-import org.apache.seatunnel.translation.flink.utils.TypeConverterUtils;
 
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.datastream.DataStreamSink;
@@ -102,8 +101,8 @@ public List<DataStream<Row>> execute(List<DataStream<Row>> upstreamDataStreams)
             SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializable> seaTunnelSink =
                     plugins.get(i);
             DataStream<Row> stream = fromSourceTable(sinkConfig).orElse(input);
-            seaTunnelSink.setTypeInfo(
-                    (SeaTunnelRowType) TypeConverterUtils.convert(stream.getType()));
+            SeaTunnelRowType sourceType = initSourceType(sinkConfig, stream);
+            seaTunnelSink.setTypeInfo(sourceType);
             if (SupportDataSaveMode.class.isAssignableFrom(seaTunnelSink.getClass())) {
                 SupportDataSaveMode saveModeSink = (SupportDataSaveMode) seaTunnelSink;
                 DataSaveMode dataSaveMode = saveModeSink.getUserConfigSaveMode();

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-2/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcPhoenixIT.java
Patch:
@@ -120,7 +120,7 @@ void compareResult() {}
 
     @Override
     String driverUrl() {
-        return "https://maven.aliyun.com/repository/public/com/aliyun/phoenix/ali-phoenix-shaded-thin-client/5.2.5-HBase-2.x/ali-phoenix-shaded-thin-client-5.2.5-HBase-2.x.jar";
+        return "https://repo1.maven.org/maven2/com/aliyun/phoenix/ali-phoenix-shaded-thin-client/5.2.5-HBase-2.x/ali-phoenix-shaded-thin-client-5.2.5-HBase-2.x.jar";
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/MultipleTableJobConfigParser.java
Patch:
@@ -531,7 +531,7 @@ private static <T> T findLast(LinkedHashMap<?, T> map) {
                         factoryId,
                         (factory) -> factory.createSink(null));
         if (fallback) {
-            return fallbackParser.parseSinks(inputVertices, sinkConfig, jobConfig);
+            return fallbackParser.parseSinks(configIndex, inputVertices, sinkConfig, jobConfig);
         }
 
         Map<TablePath, CatalogTable> tableMap =

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/ExcelReadStrategy.java
Patch:
@@ -136,8 +136,7 @@ public void setSeaTunnelRowTypeInfo(SeaTunnelRowType seaTunnelRowType) {
                     "Schmea information is not set or incorrect schmea settings");
         }
         SeaTunnelRowType userDefinedRowTypeWithPartition =
-                mergePartitionTypes(
-                        fileNames.size() > 0 ? fileNames.get(0) : null, seaTunnelRowType);
+                mergePartitionTypes(fileNames.get(0), seaTunnelRowType);
         // column projection
         if (pluginConfig.hasPath(BaseSourceConfig.READ_COLUMNS.key())) {
             // get the read column index from user-defined row type

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/TextReadStrategy.java
Patch:
@@ -138,8 +138,7 @@ public SeaTunnelRowType getSeaTunnelRowTypeInfo(HadoopConf hadoopConf, String pa
     @Override
     public void setSeaTunnelRowTypeInfo(SeaTunnelRowType seaTunnelRowType) {
         SeaTunnelRowType userDefinedRowTypeWithPartition =
-                mergePartitionTypes(
-                        fileNames.size() > 0 ? fileNames.get(0) : null, seaTunnelRowType);
+                mergePartitionTypes(fileNames.get(0), seaTunnelRowType);
         if (pluginConfig.hasPath(BaseSourceConfig.DELIMITER.key())) {
             fieldDelimiter = pluginConfig.getString(BaseSourceConfig.DELIMITER.key());
         } else {

File: seatunnel-connectors-v2/connector-assert/src/main/java/org/apache/seatunnel/connectors/seatunnel/assertion/exception/AssertConnectorErrorCode.java
Patch:
@@ -20,7 +20,8 @@
 import org.apache.seatunnel.common.exception.SeaTunnelErrorCode;
 
 public enum AssertConnectorErrorCode implements SeaTunnelErrorCode {
-    RULE_VALIDATION_FAILED("ASSERT-01", "Rule validate failed");
+    RULE_VALIDATION_FAILED("ASSERT-01", "Rule validate failed"),
+    TYPES_NOT_SUPPORTED_FAILED("ASSERT-02", "Types not supported");
 
     private final String code;
     private final String description;

File: seatunnel-connectors-v2/connector-assert/src/main/java/org/apache/seatunnel/connectors/seatunnel/assertion/rule/AssertRuleParser.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
 import org.apache.seatunnel.api.table.type.BasicType;
+import org.apache.seatunnel.api.table.type.DecimalType;
 import org.apache.seatunnel.api.table.type.LocalTimeType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 
@@ -105,5 +106,6 @@ private SeaTunnelDataType<?> getFieldType(String fieldTypeStr) {
         TYPES.put("datetime", LocalTimeType.LOCAL_DATE_TIME_TYPE);
         TYPES.put("date", LocalTimeType.LOCAL_DATE_TYPE);
         TYPES.put("time", LocalTimeType.LOCAL_TIME_TYPE);
+        TYPES.put("decimal", new DecimalType(38, 18));
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/ExcelReadStrategy.java
Patch:
@@ -136,7 +136,8 @@ public void setSeaTunnelRowTypeInfo(SeaTunnelRowType seaTunnelRowType) {
                     "Schmea information is not set or incorrect schmea settings");
         }
         SeaTunnelRowType userDefinedRowTypeWithPartition =
-                mergePartitionTypes(fileNames.get(0), seaTunnelRowType);
+                mergePartitionTypes(
+                        fileNames.size() > 0 ? fileNames.get(0) : null, seaTunnelRowType);
         // column projection
         if (pluginConfig.hasPath(BaseSourceConfig.READ_COLUMNS.key())) {
             // get the read column index from user-defined row type

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/TextReadStrategy.java
Patch:
@@ -138,7 +138,8 @@ public SeaTunnelRowType getSeaTunnelRowTypeInfo(HadoopConf hadoopConf, String pa
     @Override
     public void setSeaTunnelRowTypeInfo(SeaTunnelRowType seaTunnelRowType) {
         SeaTunnelRowType userDefinedRowTypeWithPartition =
-                mergePartitionTypes(fileNames.get(0), seaTunnelRowType);
+                mergePartitionTypes(
+                        fileNames.size() > 0 ? fileNames.get(0) : null, seaTunnelRowType);
         if (pluginConfig.hasPath(BaseSourceConfig.DELIMITER.key())) {
             fieldDelimiter = pluginConfig.getString(BaseSourceConfig.DELIMITER.key());
         } else {

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/config/StarRocksSinkOptions.java
Patch:
@@ -60,6 +60,7 @@ public interface StarRocksSinkOptions {
                     .stringType()
                     .defaultValue(
                             "CREATE TABLE IF NOT EXISTS `${database}`.`${table_name}` (\n"
+                                    + "${rowtype_primary_key},\n"
                                     + "${rowtype_fields}\n"
                                     + ") ENGINE=OLAP\n"
                                     + " PRIMARY KEY (${rowtype_primary_key})\n"

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointTimeOutTest.java
Patch:
@@ -25,6 +25,7 @@
 import org.apache.seatunnel.engine.server.TestUtils;
 
 import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 
 import com.hazelcast.internal.serialization.Data;
@@ -42,6 +43,7 @@ public class CheckpointTimeOutTest extends AbstractSeaTunnelServerTest {
     public static long JOB_ID = System.currentTimeMillis();
 
     @Test
+    @Disabled("Currently unstable tests, waiting for @EricJoy2048 to refactor state handling logic")
     public void testJobLevelCheckpointTimeOut() {
         startJob(JOB_ID, CONF_PATH);
 

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/command/AbstractCommandArgs.java
Patch:
@@ -41,6 +41,7 @@ public abstract class AbstractCommandArgs extends CommandArgs {
     /** user-defined parameters */
     @Parameter(
             names = {"-i", "--variable"},
+            splitter = ParameterSplitter.class,
             description = "Variable substitution, such as -i city=beijing, or -i date=20190318")
     protected List<String> variables = Collections.emptyList();
 

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/ClickhouseSinkWriter.java
Patch:
@@ -208,7 +208,8 @@ private static boolean clickhouseServerEnableExperimentalLightweightDelete(
             }
             return false;
         } catch (SQLException e) {
-            throw new ClickhouseConnectorException(CommonErrorCode.SQL_OPERATION_FAILED, e);
+            log.warn("Failed to get clickhouse server config: {}", configKey, e);
+            return false;
         }
     }
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/configuration/Options.java
Patch:
@@ -30,7 +30,7 @@
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 public class Options {
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelRowType.java
Patch:
@@ -20,7 +20,7 @@
 import java.util.Arrays;
 import java.util.List;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 public class SeaTunnelRowType implements CompositeType<SeaTunnelRow> {
     private static final long serialVersionUID = 2L;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/splitter/ChunkRange.java
Patch:
@@ -22,7 +22,7 @@
 
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 /**
  * An internal structure describes a chunk range with a chunk start (inclusive) and chunk end

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/ServerIdRange.java
Patch:
@@ -21,7 +21,7 @@
 
 import java.io.Serializable;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 /**
  * This class defines a range of server id. The boundaries of the range are inclusive.

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/executor/FieldNamedPreparedStatement.java
Patch:
@@ -46,8 +46,8 @@
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkNotNull;
 
 @RequiredArgsConstructor
 public class FieldNamedPreparedStatement implements PreparedStatement {

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/source/AbstractSingleSplitSource.java
Patch:
@@ -23,7 +23,7 @@
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 public abstract class AbstractSingleSplitSource<T>
         implements SeaTunnelSource<T, SingleSplit, SingleSplitEnumeratorState> {

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/config/FileSinkConfig.java
Patch:
@@ -40,7 +40,7 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 @Data
 public class FileSinkConfig extends BaseFileSinkConfig implements PartitionConfig {

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/IcebergTableLoader.java
Patch:
@@ -31,7 +31,7 @@
 import java.io.IOException;
 import java.io.Serializable;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 public class IcebergTableLoader implements Closeable, Serializable {
 

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/config/CommonConfig.java
Patch:
@@ -28,10 +28,10 @@
 import java.io.Serializable;
 import java.util.List;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
 import static org.apache.seatunnel.connectors.seatunnel.iceberg.config.IcebergCatalogType.HADOOP;
 import static org.apache.seatunnel.connectors.seatunnel.iceberg.config.IcebergCatalogType.HIVE;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkNotNull;
 
 @Getter
 @ToString

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/IcebergSource.java
Patch:
@@ -53,7 +53,7 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 @AutoService(SeaTunnelSource.class)
 public class IcebergSource

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/enumerator/scan/IcebergScanSplitPlanner.java
Patch:
@@ -43,7 +43,7 @@
 import java.util.List;
 import java.util.Optional;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 @Slf4j
 public class IcebergScanSplitPlanner {

File: seatunnel-connectors-v2/connector-iotdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/iotdb/config/SinkConfig.java
Patch:
@@ -30,8 +30,8 @@
 import java.time.ZoneId;
 import java.util.List;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkNotNull;
 
 @Setter
 @Getter

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/AbstractJdbcCatalog.java
Patch:
@@ -50,8 +50,8 @@
 import java.util.Optional;
 import java.util.stream.Collectors;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkNotNull;
 
 public abstract class AbstractJdbcCatalog implements Catalog {
     private static final Logger LOG = LoggerFactory.getLogger(AbstractJdbcCatalog.class);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/mysql/MysqlCreateTableSqlBuilder.java
Patch:
@@ -35,8 +35,8 @@
 import java.util.List;
 import java.util.stream.Collectors;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkNotNull;
 
 public class MysqlCreateTableSqlBuilder {
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerCreateTableSqlBuilder.java
Patch:
@@ -35,8 +35,8 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkNotNull;
 
 public class SqlServerCreateTableSqlBuilder {
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/executor/FieldNamedPreparedStatement.java
Patch:
@@ -47,8 +47,8 @@
 import java.util.List;
 import java.util.Map;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkNotNull;
 
 @RequiredArgsConstructor
 @Slf4j

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/split/JdbcNumericBetweenParametersProvider.java
Patch:
@@ -21,8 +21,8 @@
 import java.math.BigDecimal;
 import java.math.RoundingMode;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkState;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkState;
 
 /**
  * This query parameters generator is an helper class to parameterize from/to queries on a numeric

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/SemanticXidGenerator.java
Patch:
@@ -25,7 +25,7 @@
 import java.security.SecureRandom;
 import java.util.Arrays;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 /**
  * Generates {@link Xid} from:

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/XidImpl.java
Patch:
@@ -26,7 +26,7 @@
 import java.util.Arrays;
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 /**
  * A simple {@link Xid} implementation that stores branch and global transaction identifiers as byte

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcExactlyOnceSinkWriter.java
Patch:
@@ -50,8 +50,8 @@
 import java.util.List;
 import java.util.Optional;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkState;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkState;
 
 public class JdbcExactlyOnceSinkWriter implements SinkWriter<SeaTunnelRow, XidInfo, JdbcSinkState> {
     private static final Logger LOG = LoggerFactory.getLogger(JdbcExactlyOnceSinkWriter.class);

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/source/config/MongodbReadOptions.java
Patch:
@@ -22,10 +22,10 @@
 
 import java.io.Serializable;
 
-import static com.google.common.base.Preconditions.checkArgument;
 import static org.apache.seatunnel.connectors.seatunnel.mongodb.config.MongodbConfig.CURSOR_NO_TIMEOUT;
 import static org.apache.seatunnel.connectors.seatunnel.mongodb.config.MongodbConfig.FETCH_SIZE;
 import static org.apache.seatunnel.connectors.seatunnel.mongodb.config.MongodbConfig.MAX_TIME_MIN;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 /** The configuration class for MongoDB source. */
 @EqualsAndHashCode

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/enumerator/cursor/start/MessageIdStartCursor.java
Patch:
@@ -24,7 +24,7 @@
 import org.apache.pulsar.client.api.PulsarClientException;
 import org.apache.pulsar.client.impl.MessageIdImpl;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 /** This cursor would left pulsar start consuming from a specific message id. */
 public class MessageIdStartCursor implements StartCursor {

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/catalog/StarRocksCatalog.java
Patch:
@@ -60,7 +60,7 @@
 import java.util.Optional;
 import java.util.Set;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 public class StarRocksCatalog implements Catalog {
 

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/client/source/StarRocksRowBatchReader.java
Patch:
@@ -50,7 +50,7 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 @Slf4j
 public class StarRocksRowBatchReader {

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceIT.java
Patch:
@@ -50,7 +50,7 @@
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.TimeUnit;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 /**
  * Cluster fault tolerance test. Test the job recovery capability and data consistency assurance

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceTwoPipelineIT.java
Patch:
@@ -48,7 +48,7 @@
 import java.util.concurrent.ExecutionException;
 import java.util.concurrent.TimeUnit;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 /**
  * Cluster fault tolerance test. Test the job which have two pipelines can recovery capability and

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/server/CheckpointConfig.java
Patch:
@@ -21,7 +21,7 @@
 
 import java.io.Serializable;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 @Data
 @SuppressWarnings("checkstyle:MagicNumber")

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/ShufflePartitionStrategy.java
Patch:
@@ -35,7 +35,7 @@
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 @Slf4j
 @SuperBuilder

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/TaskStatistics.java
Patch:
@@ -21,8 +21,8 @@
 import java.util.Arrays;
 import java.util.List;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkNotNull;
 
 public class TaskStatistics implements Serializable {
     /** ID of the task the statistics belong to. */

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/ExecutionPlanGenerator.java
Patch:
@@ -54,7 +54,7 @@
 import java.util.Optional;
 import java.util.Set;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 @Slf4j
 public class ExecutionPlanGenerator {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/PipelineGenerator.java
Patch:
@@ -29,7 +29,7 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 public class PipelineGenerator {
     /** The action & vertex ID needs to be regenerated because of split pipeline. */

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/resource/ResourceProfile.java
Patch:
@@ -19,7 +19,7 @@
 
 import java.io.Serializable;
 
-import static com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
 
 public class ResourceProfile implements Serializable {
 

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/source/HiveSourceFactory.java
Patch:
@@ -21,6 +21,7 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
+import org.apache.seatunnel.connectors.seatunnel.file.config.BaseSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.hive.config.HiveConfig;
 
 import com.google.auto.service.AutoService;
@@ -37,6 +38,8 @@ public OptionRule optionRule() {
         return OptionRule.builder()
                 .required(HiveConfig.TABLE_NAME)
                 .required(HiveConfig.METASTORE_URI)
+                .optional(BaseSourceConfig.READ_PARTITIONS)
+                .optional(BaseSourceConfig.READ_COLUMNS)
                 .build();
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/rest/RestHttpGetCommandProcessor.java
Patch:
@@ -243,7 +243,7 @@ private JsonObject convertToJson(JobInfo jobInfo, long jobId) {
         JobStatus jobStatus = getSeaTunnelServer().getCoordinatorService().getJobStatus(jobId);
 
         jobInfoJson
-                .add("jobId", jobId)
+                .add("jobId", String.valueOf(jobId))
                 .add("jobName", logicalDag.getJobConfig().getName())
                 .add("jobStatus", jobStatus.toString())
                 .add("envOptions", JsonUtil.toJsonObject(logicalDag.getJobConfig().getEnvOptions()))

File: seatunnel-connectors-v2/connector-redis/src/main/java/org/apache/seatunnel/connectors/seatunnel/redis/sink/RedisSinkFactory.java
Patch:
@@ -41,7 +41,8 @@ public OptionRule optionRule() {
                         RedisConfig.AUTH,
                         RedisConfig.USER,
                         RedisConfig.KEY_PATTERN,
-                        RedisConfig.FORMAT)
+                        RedisConfig.FORMAT,
+                        RedisConfig.EXPIRE)
                 .conditional(RedisConfig.MODE, RedisConfig.RedisMode.CLUSTER, RedisConfig.NODES)
                 .build();
     }

File: seatunnel-connectors-v2/connector-redis/src/main/java/org/apache/seatunnel/connectors/seatunnel/redis/sink/RedisSinkWriter.java
Patch:
@@ -59,7 +59,8 @@ public void write(SeaTunnelRow element) throws IOException {
         } else {
             key = keyField;
         }
-        redisDataType.set(jedis, key, data);
+        long expire = redisParameters.getExpire();
+        redisDataType.set(jedis, key, data, expire);
     }
 
     @Override

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/serialization/DefaultSerializer.java
Patch:
@@ -35,6 +35,9 @@ public byte[] serialize(T obj) throws IOException {
 
     @Override
     public T deserialize(byte[] serialized) throws IOException {
+        if (serialized == null) {
+            return null;
+        }
         return SerializationUtils.deserialize(serialized);
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSplitEnumeratorTask.java
Patch:
@@ -37,6 +37,7 @@
 import com.hazelcast.cluster.Address;
 import com.hazelcast.spi.impl.operationservice.Operation;
 import com.hazelcast.spi.impl.operationservice.impl.InvocationFuture;
+import lombok.Getter;
 import lombok.NonNull;
 import lombok.extern.slf4j.Slf4j;
 
@@ -77,6 +78,7 @@ public class SourceSplitEnumeratorTask<SplitT extends SourceSplit> extends Coord
     private SeaTunnelSplitEnumeratorContext<SplitT> enumeratorContext;
 
     private Serializer<Serializable> enumeratorStateSerializer;
+    @Getter private Serializer<SplitT> splitSerializer;
 
     private int maxReaderSize;
     private Set<Long> unfinishedReaders;
@@ -102,6 +104,7 @@ public void init() throws Exception {
                 new SeaTunnelSplitEnumeratorContext<>(
                         this.source.getParallelism(), this, getMetricsContext());
         enumeratorStateSerializer = this.source.getSource().getEnumeratorStateSerializer();
+        splitSerializer = this.source.getSource().getSplitSerializer();
         taskMemberMapping = new ConcurrentHashMap<>();
         taskIDToTaskLocationMapping = new ConcurrentHashMap<>();
         taskIndexToTaskLocationMapping = new ConcurrentHashMap<>();

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/JobExecutionIT.java
Patch:
@@ -32,7 +32,6 @@
 import org.apache.seatunnel.engine.core.job.JobStatus;
 import org.apache.seatunnel.engine.server.SeaTunnelServerStarter;
 
-import org.awaitility.Awaitility;
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/JobExecutionIT.java
Patch:
@@ -199,8 +199,7 @@ public void testExpiredJobWasDeleted() throws Exception {
 
         JobResult result = clientJobProxy.doWaitForJobComplete().get();
         Assertions.assertEquals(result.getStatus(), JobStatus.FINISHED);
-        Awaitility.await()
-                .atMost(65, TimeUnit.SECONDS)
+        await().atMost(65, TimeUnit.SECONDS)
                 .untilAsserted(
                         () ->
                                 Assertions.assertThrowsExactly(

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/CoordinatorService.java
Patch:
@@ -219,7 +219,8 @@ private void initCoordinatorService() {
                                 .getMap(Constant.IMAP_FINISHED_JOB_METRICS),
                         nodeEngine
                                 .getHazelcastInstance()
-                                .getMap(Constant.IMAP_FINISHED_JOB_VERTEX_INFO));
+                                .getMap(Constant.IMAP_FINISHED_JOB_VERTEX_INFO),
+                        engineConfig.getHistoryJobExpireMinutes());
 
         List<CompletableFuture<Void>> collect =
                 runningJobInfoIMap.entrySet().stream()

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlIncrementalSourceFactory.java
Patch:
@@ -68,7 +68,8 @@ public OptionRule optionRule() {
                         JdbcSourceOptions.CONNECTION_POOL_SIZE,
                         JdbcSourceOptions.CHUNK_KEY_EVEN_DISTRIBUTION_FACTOR_LOWER_BOUND,
                         JdbcSourceOptions.CHUNK_KEY_EVEN_DISTRIBUTION_FACTOR_UPPER_BOUND,
-                        JdbcSourceOptions.SAMPLE_SHARDING_THRESHOLD)
+                        JdbcSourceOptions.SAMPLE_SHARDING_THRESHOLD,
+                        JdbcSourceOptions.INVERSE_SAMPLING_RATE)
                 .optional(MySqlSourceOptions.STARTUP_MODE, MySqlSourceOptions.STOP_MODE)
                 .conditional(
                         MySqlSourceOptions.STARTUP_MODE,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/eumerator/MySqlChunkSplitter.java
Patch:
@@ -28,10 +28,12 @@
 import io.debezium.jdbc.JdbcConnection;
 import io.debezium.relational.Column;
 import io.debezium.relational.TableId;
+import lombok.extern.slf4j.Slf4j;
 
 import java.sql.SQLException;
 
 /** The {@code ChunkSplitter} used to split table into a set of chunks for JDBC data source. */
+@Slf4j
 public class MySqlChunkSplitter extends AbstractJdbcSourceChunkSplitter {
 
     public MySqlChunkSplitter(JdbcSourceConfig sourceConfig, JdbcDataSourceDialect dialect) {
@@ -55,7 +57,7 @@ public Object queryMin(
     public Object[] sampleDataFromColumn(
             JdbcConnection jdbc, TableId tableId, String columnName, int inverseSamplingRate)
             throws SQLException {
-        return MySqlUtils.sampleDataFromColumn(jdbc, tableId, columnName, inverseSamplingRate);
+        return MySqlUtils.skipReadAndSortSampleData(jdbc, tableId, columnName, inverseSamplingRate);
     }
 
     @Override

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/eumerator/SqlServerChunkSplitter.java
Patch:
@@ -57,7 +57,8 @@ public Object queryMin(
     public Object[] sampleDataFromColumn(
             JdbcConnection jdbc, TableId tableId, String columnName, int inverseSamplingRate)
             throws SQLException {
-        return SqlServerUtils.sampleDataFromColumn(jdbc, tableId, columnName, inverseSamplingRate);
+        return SqlServerUtils.skipReadAndSortSampleData(
+                jdbc, tableId, columnName, inverseSamplingRate);
     }
 
     @Override

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/oracle/OracleTypeMapper.java
Patch:
@@ -87,9 +87,10 @@ public SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex)
                 if (scale == 0) {
                     if (precision <= 9) {
                         return BasicType.INT_TYPE;
-                    }
-                    if (precision <= 18) {
+                    } else if (precision <= 18) {
                         return BasicType.LONG_TYPE;
+                    } else if (precision <= 38) {
+                        return new DecimalType(38, 0);
                     }
                 }
                 return new DecimalType(38, 18);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/debezium/row/SeaTunnelRowDebeziumDeserializationConverters.java
Patch:
@@ -210,6 +210,8 @@ public Object convert(Object dbzObj, Schema schema) {
                     return dbzObj;
                 } else if (dbzObj instanceof BigDecimal) {
                     return ((BigDecimal) dbzObj).byteValue();
+                } else if (dbzObj instanceof Boolean) {
+                    return Boolean.TRUE.equals(dbzObj) ? Byte.valueOf("1") : Byte.valueOf("0");
                 } else {
                     return Byte.parseByte(dbzObj.toString());
                 }

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/SavePointTest.java
Patch:
@@ -45,7 +45,6 @@ public class SavePointTest extends AbstractSeaTunnelServerTest {
     public static long JOB_ID = 823342L;
 
     @Test
-    @Disabled()
     public void testSavePoint() throws InterruptedException {
         savePointAndRestore(false);
     }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/source/fetch/MongodbFetchTaskContext.java
Patch:
@@ -139,11 +139,11 @@ public boolean isDataChangeRecord(SourceRecord record) {
     public boolean isRecordBetween(
             SourceRecord record, @Nonnull Object[] splitStart, @Nonnull Object[] splitEnd) {
         BsonDocument documentKey = getDocumentKey(record);
-        BsonDocument splitKeys = (BsonDocument) ((Object[]) splitStart[0])[0];
+        BsonDocument splitKeys = (BsonDocument) splitStart[0];
         String firstKey = splitKeys.getFirstKey();
         BsonValue keyValue = documentKey.get(firstKey);
-        BsonValue lowerBound = ((BsonDocument) ((Object[]) splitEnd[0])[1]).get(firstKey);
-        BsonValue upperBound = ((BsonDocument) ((Object[]) splitEnd[0])[1]).get(firstKey);
+        BsonValue lowerBound = ((BsonDocument) splitStart[1]).get(firstKey);
+        BsonValue upperBound = ((BsonDocument) splitEnd[1]).get(firstKey);
 
         if (isFullRange(lowerBound, upperBound)) {
             return true;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PipelineLocation.java
Patch:
@@ -25,6 +25,7 @@
 @AllArgsConstructor
 @Data
 public class PipelineLocation implements Serializable {
+    private static final long serialVersionUID = 2510281765212372549L;
     private long jobId;
     private int pipelineId;
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/TaskGroupLocation.java
Patch:
@@ -30,6 +30,7 @@
 @Data
 @AllArgsConstructor
 public class TaskGroupLocation implements Serializable {
+    private static final long serialVersionUID = -8321526709920799751L;
     private final long jobId;
 
     private final int pipelineId;

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-starter-common/src/main/java/org/apache/seatunnel/core/starter/spark/execution/TransformExecuteProcessor.java
Patch:
@@ -185,7 +185,6 @@ public Row next() {
                     return null;
                 }
                 seaTunnelRow = outputRowConverter.convert(seaTunnelRow);
-
                 return new GenericRowWithSchema(seaTunnelRow.getFields(), structType);
             } catch (Exception e) {
                 throw new TaskExecuteException("Row convert failed, caused: " + e.getMessage(), e);

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/AbstractReadStrategy.java
Patch:
@@ -72,7 +72,7 @@ public abstract class AbstractReadStrategy implements ReadStrategy {
     protected List<String> readColumns = new ArrayList<>();
     protected boolean isMergePartition = true;
     protected long skipHeaderNumber = BaseSourceConfig.SKIP_HEADER_ROW_NUMBER.defaultValue();
-    protected boolean isKerberosAuthorization = false;
+    protected transient boolean isKerberosAuthorization = false;
 
     @Override
     public void init(HadoopConf conf) {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/config/MongodbSourceOptions.java
Patch:
@@ -108,6 +108,8 @@ public class MongodbSourceOptions extends SourceOptions {
                     + "    { \"name\": \"source\","
                     + "      \"type\": [{\"name\": \"source\", \"type\": \"record\", \"fields\": ["
                     + "                {\"name\": \"ts_ms\", \"type\": \"long\"},"
+                    + "                {\"name\": \"table\", \"type\": [\"string\", \"null\"]},"
+                    + "                {\"name\": \"db\", \"type\": [\"string\", \"null\"]},"
                     + "                {\"name\": \"snapshot\", \"type\": [\"string\", \"null\"] } ]"
                     + "               }, \"null\" ] },"
                     + "    { \"name\": \"ts_ms\", \"type\": [\"long\", \"null\"]},"

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/SinkFlowLifeCycle.java
Patch:
@@ -109,6 +109,7 @@ public SinkFlowLifeCycle(
     public void init() throws Exception {
         this.writerStateSerializer = sinkAction.getSink().getWriterStateSerializer();
         this.committer = sinkAction.getSink().createCommitter();
+        this.lastCommitInfo = Optional.empty();
     }
 
     @Override

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/utils/ObjectUtils.java
Patch:
@@ -63,6 +63,8 @@ public static BigDecimal minus(Object minuend, Object subtrahend) {
                     ((BigInteger) minuend).subtract((BigInteger) subtrahend).toString());
         } else if (minuend instanceof BigDecimal) {
             return ((BigDecimal) minuend).subtract((BigDecimal) subtrahend);
+        } else if (minuend instanceof String) {
+            return BigDecimal.valueOf(Long.MAX_VALUE);
         } else {
             throw new UnsupportedOperationException(
                     String.format(

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cdc-mongodb-e2e/src/test/java/mongodb/MongoDBContainer.java
Patch:
@@ -84,6 +84,7 @@ public MongoDBContainer(Network network, ShardingClusterRole clusterRole) {
         withExposedPorts(MONGODB_PORT);
         withCommand(ShardingClusterRole.startupCommand(clusterRole));
         waitingFor(clusterRole.waitStrategy);
+        withEnv("TZ", "Asia/Shanghai");
     }
 
     public void executeCommand(String command) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -273,7 +273,8 @@ private CheckpointConfig createJobCheckpointConfig(
 
         if (jobEnv.containsKey(EnvCommonOptions.CHECKPOINT_INTERVAL.key())) {
             jobCheckpointConfig.setCheckpointInterval(
-                    (Long) jobEnv.get(EnvCommonOptions.CHECKPOINT_INTERVAL.key()));
+                    Long.parseLong(
+                            jobEnv.get(EnvCommonOptions.CHECKPOINT_INTERVAL.key()).toString()));
         }
         return jobCheckpointConfig;
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -346,7 +346,9 @@ public InvocationFuture<?>[] notifyTaskStart() {
 
     public void reportCheckpointErrorFromTask(String errorMsg) {
         handleCoordinatorError(
-                CheckpointCloseReason.CHECKPOINT_INSIDE_ERROR, new SeaTunnelException(errorMsg));
+                "report error from task",
+                new SeaTunnelException(errorMsg),
+                CheckpointCloseReason.CHECKPOINT_INSIDE_ERROR);
     }
 
     private void scheduleTriggerPendingCheckpoint(long delayMills) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -341,7 +341,7 @@ public void ack(Barrier barrier) {
                                 new TaskAcknowledgeOperation(
                                         this.taskLocation,
                                         (CheckpointBarrier) barrier,
-                                        checkpointStates.get(barrier.getId())))
+                                        checkpointStates.remove(barrier.getId())))
                         .join();
             }
         }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mongodb/config/MongodbSourceOptions.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.Option;
 import org.apache.seatunnel.api.configuration.Options;
+import org.apache.seatunnel.api.configuration.SingleChoiceOption;
 import org.apache.seatunnel.connectors.cdc.base.option.SourceOptions;
 import org.apache.seatunnel.connectors.cdc.base.option.StartupMode;
 import org.apache.seatunnel.connectors.cdc.base.option.StopMode;
@@ -234,7 +235,7 @@ public class MongodbSourceOptions extends SourceOptions {
                     .withDescription(
                             "Decides if the table options contains Debezium client properties that start with prefix 'debezium'.");
 
-    public static final Option<StartupMode> STARTUP_MODE =
+    public static final SingleChoiceOption<StartupMode> STARTUP_MODE =
             Options.key(SourceOptions.STARTUP_MODE_KEY)
                     .singleChoice(
                             StartupMode.class,
@@ -245,7 +246,7 @@ public class MongodbSourceOptions extends SourceOptions {
                             "Optional startup mode for CDC source, valid enumerations are "
                                     + "\"initial\", \"earliest\", \"latest\", \"timestamp\"\n or \"specific\"");
 
-    public static final Option<StopMode> STOP_MODE =
+    public static final SingleChoiceOption<StopMode> STOP_MODE =
             Options.key(SourceOptions.STOP_MODE_KEY)
                     .singleChoice(StopMode.class, Collections.singletonList(StopMode.NEVER))
                     .defaultValue(StopMode.NEVER)

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalVertex.java
Patch:
@@ -394,7 +394,7 @@ private boolean turnToEndState(@NonNull ExecutionState endState) {
     public boolean updateTaskState(
             @NonNull ExecutionState current, @NonNull ExecutionState targetState) {
         synchronized (this) {
-            LOGGER.fine(
+            LOGGER.info(
                     String.format(
                             "Try to update the task %s state from %s to %s",
                             taskFullName, current, targetState));

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/PartitionParameter.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.source;
 
+import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
+
 import lombok.AllArgsConstructor;
 import lombok.Data;
 
@@ -28,6 +30,7 @@
 public class PartitionParameter implements Serializable {
 
     String partitionColumnName;
+    SeaTunnelDataType<?> dataType;
     BigDecimal minValue;
     BigDecimal maxValue;
     Integer partitionNumber;

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/file/ClickhouseFileSink.java
Patch:
@@ -66,6 +66,7 @@
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.NODE_FREE_PASSWORD;
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.NODE_PASS;
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.PASSWORD;
+import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.SERVER_TIME_ZONE;
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.SHARDING_KEY;
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.TABLE;
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.USERNAME;
@@ -114,6 +115,7 @@ public void prepare(Config config) throws PrepareFailException {
                 ClickhouseUtil.createNodes(
                         config.getString(HOST.key()),
                         config.getString(DATABASE.key()),
+                        config.getString(SERVER_TIME_ZONE.key()),
                         config.getString(USERNAME.key()),
                         config.getString(PASSWORD.key()));
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/debezium/row/SeaTunnelRowDebeziumDeserializeSchema.java
Patch:
@@ -211,7 +211,7 @@ public static class Builder {
         private SeaTunnelDataType<SeaTunnelRow> resultTypeInfo;
         private MetadataConverter[] metadataConverters = new MetadataConverter[0];
         private ValueValidator validator = (rowData, rowKind) -> {};
-        private ZoneId serverTimeZone = ZoneId.of("UTC");
+        private ZoneId serverTimeZone = ZoneId.systemDefault();
         private DebeziumDeserializationConverterFactory userDefinedConverterFactory =
                 DebeziumDeserializationConverterFactory.DEFAULT;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/MySqlSourceConfigFactory.java
Patch:
@@ -89,7 +89,7 @@ public MySqlSourceConfig create(int subtaskId) {
 
         if (serverIdRange != null) {
             props.setProperty("database.server.id.range", String.valueOf(serverIdRange));
-            int serverId = serverIdRange.getServerId(subtaskId);
+            long serverId = serverIdRange.getServerId(subtaskId);
             props.setProperty("database.server.id", String.valueOf(serverId));
         }
         if (databaseList != null) {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/config/JdbcConnectionConfig.java
Patch:
@@ -58,6 +58,7 @@ public static JdbcConnectionConfig of(ReadonlyConfig config) {
             builder.xaDataSourceClassName(config.get(JdbcOptions.XA_DATA_SOURCE_CLASS_NAME));
             builder.maxCommitAttempts(config.get(JdbcOptions.MAX_COMMIT_ATTEMPTS));
             builder.transactionTimeoutSec(config.get(JdbcOptions.TRANSACTION_TIMEOUT_SEC));
+            builder.maxRetries(0);
         }
 
         config.getOptional(JdbcOptions.USER).ifPresent(builder::username);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/IncrementalSourceSplitReader.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.connectors.cdc.base.source.reader;
 
+import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.connectors.cdc.base.config.SourceConfig;
 import org.apache.seatunnel.connectors.cdc.base.dialect.DataSourceDialect;
 import org.apache.seatunnel.connectors.cdc.base.source.reader.external.FetchTask;
@@ -66,7 +67,7 @@ public RecordsWithSplitIds<SourceRecords> fetch() throws IOException {
         Iterator<SourceRecords> dataIt = null;
         try {
             dataIt = currentFetcher.pollSplitRecords();
-        } catch (InterruptedException e) {
+        } catch (InterruptedException | SeaTunnelException e) {
             log.warn("fetch data failed.", e);
             throw new IOException(e);
         }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/external/Fetcher.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.connectors.cdc.base.source.reader.external;
 
+import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.connectors.cdc.base.source.split.IncrementalSplit;
 import org.apache.seatunnel.connectors.cdc.base.source.split.SnapshotSplit;
 
@@ -35,7 +36,7 @@ public interface Fetcher<T, Split> {
      * Fetched records from data source. The method should return null when reaching the end of the
      * split, the empty {@link Iterator} will be returned if the data of split is on pulling.
      */
-    Iterator<T> pollSplitRecords() throws InterruptedException;
+    Iterator<T> pollSplitRecords() throws InterruptedException, SeaTunnelException;
 
     /** Return the current fetch task is finished or not. */
     boolean isFinished();

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/external/IncrementalSourceScanFetcher.java
Patch:
@@ -107,7 +107,8 @@ public boolean isFinished() {
     }
 
     @Override
-    public Iterator<SourceRecords> pollSplitRecords() throws InterruptedException {
+    public Iterator<SourceRecords> pollSplitRecords()
+            throws InterruptedException, SeaTunnelException {
         checkReadException();
 
         if (hasNextElement.get()) {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/external/IncrementalSourceStreamFetcher.java
Patch:
@@ -95,7 +95,8 @@ public boolean isFinished() {
     }
 
     @Override
-    public Iterator<SourceRecords> pollSplitRecords() throws InterruptedException {
+    public Iterator<SourceRecords> pollSplitRecords()
+            throws InterruptedException, SeaTunnelException {
         checkReadException();
         final List<SourceRecord> sourceRecords = new ArrayList<>();
         if (streamFetchTask.isRunning()) {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/reader/fetch/scan/SqlServerSnapshotFetchTask.java
Patch:
@@ -38,8 +38,6 @@
 import java.util.Collections;
 import java.util.Map;
 
-import static org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.utils.SqlServerConnectionUtils.createSqlServerConnection;
-
 @Slf4j
 public class SqlServerSnapshotFetchTask implements FetchTask<SourceSplitBase> {
 
@@ -148,7 +146,7 @@ private IncrementalSplit createBackFillLsnSplit(
         // task to read binlog and backfill for current split
         return new SqlServerTransactionLogFetchTask.TransactionLogSplitReadTask(
                 new SqlServerConnectorConfig(dezConf),
-                createSqlServerConnection(context.getSourceConfig().getDbzConfiguration()),
+                context.getDataConnection(),
                 context.getMetadataConnection(),
                 context.getDispatcher(),
                 context.getErrorHandler(),

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/source/reader/SourceReaderOptions.java
Patch:
@@ -31,7 +31,7 @@ public class SourceReaderOptions {
     public static final Option<Long> SOURCE_READER_CLOSE_TIMEOUT =
             Options.key("source.reader.close.timeout")
                     .longType()
-                    .defaultValue(30000L)
+                    .defaultValue(60000L)
                     .withDescription("The timeout when closing the source reader");
 
     public static final Option<Integer> ELEMENT_QUEUE_CAPACITY =

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/source/reader/fetcher/FetchTask.java
Patch:
@@ -68,9 +68,9 @@ public void run() throws IOException {
                             fetcherIndex);
                 }
             }
-        } catch (InterruptedException e) {
+        } catch (IOException | InterruptedException e) {
             // this should only happen on shutdown
-            throw new IOException("Source fetch execution was interrupted", e);
+            throw new IOException("Source fetch execution was fail", e);
         } finally {
             // clean up the potential wakeup effect.
             if (isWakeup()) {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/reader/fetch/scan/MySqlSnapshotFetchTask.java
Patch:
@@ -38,8 +38,6 @@
 import java.util.Collections;
 import java.util.Map;
 
-import static org.apache.seatunnel.connectors.seatunnel.cdc.mysql.utils.MySqlConnectionUtils.createMySqlConnection;
-
 @Slf4j
 public class MySqlSnapshotFetchTask implements FetchTask<SourceSplitBase> {
 
@@ -158,7 +156,7 @@ private MySqlBinlogFetchTask.MySqlBinlogSplitReadTask createBackfillBinlogReadTa
         return new MySqlBinlogFetchTask.MySqlBinlogSplitReadTask(
                 new MySqlConnectorConfig(dezConf),
                 mySqlOffsetContext,
-                createMySqlConnection(context.getSourceConfig().getDbzConfiguration()),
+                context.getConnection(),
                 context.getDispatcher(),
                 context.getErrorHandler(),
                 context.getTaskContext(),

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/config/MongodbConfig.java
Patch:
@@ -56,7 +56,8 @@ public class MongodbConfig {
             Options.key("match.query")
                     .stringType()
                     .noDefaultValue()
-                    .withDescription("Mongodb's query syntax.");
+                    .withDescription("Mongodb's query syntax.")
+                    .withFallbackKeys("matchQuery");
 
     public static final Option<String> PROJECTION =
             Options.key("match.projection")

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/utils/HiveMetaStoreProxy.java
Patch:
@@ -54,6 +54,9 @@ private HiveMetaStoreProxy(Config config) {
             Configuration configuration = new Configuration();
             FileSystemUtils.doKerberosAuthentication(configuration, principal, keytabPath);
         }
+        if (config.hasPath(HiveConfig.HIVE_SITE_PATH.key())) {
+            hiveConf.addResource(config.getString(HiveConfig.HIVE_SITE_PATH.key()));
+        }
         try {
             hiveMetaStoreClient = new HiveMetaStoreClient(hiveConf);
         } catch (MetaException e) {

File: seatunnel-plugin-discovery/src/main/java/org/apache/seatunnel/plugin/discovery/AbstractPluginDiscovery.java
Patch:
@@ -238,7 +238,7 @@ public Map<PluginType, LinkedHashMap<PluginIdentifier, OptionRule>> getAllPlugin
             factories =
                     FactoryUtil.discoverFactories(new URLClassLoader(files.toArray(new URL[0])));
         } else {
-            log.info("plugin dir: {} not exists, load plugin from classpath", this.pluginDir);
+            log.warn("plugin dir: {} not exists, load plugin from classpath", this.pluginDir);
             factories =
                     FactoryUtil.discoverFactories(Thread.currentThread().getContextClassLoader());
         }

File: seatunnel-connectors-v2/connector-file/connector-file-jindo-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/config/OssConf.java
Patch:
@@ -49,6 +49,8 @@ public static HadoopConf buildWithConfig(Config config) {
         ossOptions.put("fs.oss.accessKeyId", config.getString(OssConfig.ACCESS_KEY.key()));
         ossOptions.put("fs.oss.accessKeySecret", config.getString(OssConfig.ACCESS_SECRET.key()));
         ossOptions.put("fs.oss.endpoint", config.getString(OssConfig.ENDPOINT.key()));
+        ossOptions.put("fs.oss.upload.thread.concurrency", "20");
+        ossOptions.put("fs.oss.upload.queue.size", "100");
         hadoopConf.setExtraOptions(ossOptions);
         return hadoopConf;
     }

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/config/MongodbConfig.java
Patch:
@@ -118,16 +118,16 @@ public class MongodbConfig {
     public static final Option<Long> BUFFER_FLUSH_INTERVAL =
             Options.key("buffer-flush.interval")
                     .longType()
-                    .defaultValue(30_000L)
+                    .defaultValue(30000L)
                     .withDescription(
-                            "Specifies the retry time interval if writing records to database failed.");
+                            "Specifies the maximum interval of buffered rows per batch request, the unit is millisecond.");
 
     public static final Option<Integer> RETRY_MAX =
             Options.key("retry.max")
                     .intType()
                     .defaultValue(3)
                     .withDescription(
-                            "Specifies the max retry times if writing records to database failed.");
+                            "Specifies the max number of retry if writing records to database failed.");
 
     public static final Option<Long> RETRY_INTERVAL =
             Options.key("retry.interval")

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/serde/DocumentRowDataDeserializer.java
Patch:
@@ -37,10 +37,10 @@ public class DocumentRowDataDeserializer implements DocumentDeserializer<SeaTunn
 
     private final BsonToRowDataConverters bsonConverters;
 
-    private final Boolean flatSyncString;
+    private final boolean flatSyncString;
 
     public DocumentRowDataDeserializer(
-            String[] fieldNames, SeaTunnelDataType<?> dataTypes, Boolean flatSyncString) {
+            String[] fieldNames, SeaTunnelDataType<?> dataTypes, boolean flatSyncString) {
         if (fieldNames == null || fieldNames.length < 1) {
             throw new MongodbConnectorException(ILLEGAL_ARGUMENT, "fieldName is empty");
         }

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/serde/RowDataDocumentSerializer.java
Patch:
@@ -43,7 +43,7 @@
 public class RowDataDocumentSerializer implements DocumentSerializer<SeaTunnelRow> {
 
     private final RowDataToBsonConverters.RowDataToBsonConverter rowDataToBsonConverter;
-    private final Boolean isUpsertEnable;
+    private final boolean isUpsertEnable;
     private final Function<BsonDocument, BsonDocument> filterConditions;
 
     private final Map<RowKind, WriteModelSupplier> writeModelSuppliers;

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/sink/MongodbSink.java
Patch:
@@ -33,7 +33,6 @@
 
 import com.google.auto.service.AutoService;
 
-import java.io.IOException;
 import java.util.List;
 
 import static org.apache.seatunnel.connectors.seatunnel.mongodb.config.MongodbConfig.CONNECTOR_IDENTITY;
@@ -110,8 +109,7 @@ public SeaTunnelDataType<SeaTunnelRow> getConsumedType() {
     }
 
     @Override
-    public AbstractSinkWriter<SeaTunnelRow, Void> createWriter(SinkWriter.Context context)
-            throws IOException {
+    public AbstractSinkWriter<SeaTunnelRow, Void> createWriter(SinkWriter.Context context) {
         return new MongodbWriter(
                 new RowDataDocumentSerializer(
                         RowDataToBsonConverters.createConverter(seaTunnelRowType),

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/sink/MongodbWriter.java
Patch:
@@ -33,7 +33,6 @@
 import com.mongodb.client.model.WriteModel;
 import lombok.extern.slf4j.Slf4j;
 
-import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Optional;
@@ -61,6 +60,7 @@ public class MongodbWriter extends AbstractSinkWriter<SeaTunnelRow, Void> {
 
     private volatile long lastSendTime = 0L;
 
+    // TODO：Reserve parameters.
     private final SinkWriter.Context context;
 
     public MongodbWriter(
@@ -103,7 +103,7 @@ public Optional<Void> prepareCommit() {
     }
 
     @Override
-    public void close() throws IOException {
+    public void close() {
         doBulkWrite();
         if (collectionProvider != null) {
             collectionProvider.close();

File: seatunnel-connectors-v2/connector-hbase/src/main/java/org/apache/seatunnel/connectors/seatunnel/hbase/sink/HbaseSinkWriter.java
Patch:
@@ -112,7 +112,7 @@ public void close() throws IOException {
 
     private Put convertRowToPut(SeaTunnelRow row) {
         byte[] rowkey = getRowkeyFromRow(row);
-        long timestamp = HConstants.LATEST_TIMESTAMP;
+        long timestamp = System.currentTimeMillis();
         if (versionColumnIndex != -1) {
             timestamp = (Long) row.getField(versionColumnIndex);
         }

File: seatunnel-config/seatunnel-config-shade/src/main/java/org/apache/seatunnel/shade/com/typesafe/config/impl/ConfigParser.java
Patch:
@@ -128,7 +128,7 @@ private AbstractConfigValue parseValue(AbstractConfigNodeValue n, List<String> c
                         && ("source".equals(path.first())
                                 || "transform".equals(path.first())
                                 || "sink".equals(path.first()))) {
-                    v = parseObjectForSeatunnel((ConfigNodeObject) n);
+                    v = parseObjectForSeaTunnel((ConfigNodeObject) n);
                 } else {
                     v = parseObject((ConfigNodeObject) n);
                 }
@@ -250,7 +250,7 @@ private void parseInclude(Map<String, AbstractConfigValue> values, ConfigNodeInc
             }
         }
 
-        private SimpleConfigList parseObjectForSeatunnel(ConfigNodeObject n) {
+        private SimpleConfigList parseObjectForSeaTunnel(ConfigNodeObject n) {
 
             Map<String, AbstractConfigValue> values = new LinkedHashMap<>();
             List<AbstractConfigValue> valuesList = new ArrayList<>();

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/JdbcConnectionPoolFactory.java
Patch:
@@ -39,6 +39,7 @@ public HikariDataSource createPooledDataSource(JdbcSourceConfig sourceConfig) {
         config.setJdbcUrl(sourceConfig.getOriginUrl());
         config.setUsername(sourceConfig.getUsername());
         config.setPassword(sourceConfig.getPassword());
+        config.setDriverClassName(sourceConfig.getDriverClassName());
         config.setMinimumIdle(MINIMUM_POOL_SIZE);
         config.setMaximumPoolSize(sourceConfig.getConnectionPoolSize());
         config.setConnectionTimeout(sourceConfig.getConnectTimeoutMillis());

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/converter/AbstractJdbcRowConverter.java
Patch:
@@ -35,7 +35,7 @@
 import java.time.LocalTime;
 import java.util.Optional;
 
-/** Base class for all converters that convert between JDBC object and Seatunnel internal object. */
+/** Base class for all converters that convert between JDBC object and SeaTunnel internal object. */
 public abstract class AbstractJdbcRowConverter implements JdbcRowConverter {
 
     public abstract String converterName();

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/converter/JdbcRowConverter.java
Patch:
@@ -26,7 +26,7 @@
 import java.sql.SQLException;
 
 /**
- * Converter that is responsible to convert between JDBC object and Seatunnel data structure {@link
+ * Converter that is responsible to convert between JDBC object and SeaTunnel data structure {@link
  * SeaTunnelRow}.
  */
 public interface JdbcRowConverter extends Serializable {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/JdbcDialectTypeMapper.java
Patch:
@@ -26,6 +26,6 @@
 /** Separate the jdbc meta-information type to SeaTunnelDataType into the interface. */
 public interface JdbcDialectTypeMapper extends Serializable {
 
-    /** Convert ResultSetMetaData to Seatunnel data type {@link SeaTunnelDataType}. */
+    /** Convert ResultSetMetaData to SeaTunnel data type {@link SeaTunnelDataType}. */
     SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex) throws SQLException;
 }

File: seatunnel-connectors-v2/connector-neo4j/src/main/java/org/apache/seatunnel/connectors/seatunnel/neo4j/internal/SeaTunnelRowNeo4jValue.java
Patch:
@@ -31,11 +31,11 @@
  * This class includes the seatunnelRow and implements the neo4j.driver.internal.AsValue interface.
  * This class will be able to convert to neo4j.driver.Value quickly without any extra effort.
  */
-public class SeatunnelRowNeo4jValue implements AsValue {
+public class SeaTunnelRowNeo4jValue implements AsValue {
     private final SeaTunnelRowType seaTunnelRowType;
     private final SeaTunnelRow seaTunnelRow;
 
-    public SeatunnelRowNeo4jValue(SeaTunnelRowType seaTunnelRowType, SeaTunnelRow seaTunnelRow) {
+    public SeaTunnelRowNeo4jValue(SeaTunnelRowType seaTunnelRowType, SeaTunnelRow seaTunnelRow) {
         this.seaTunnelRowType = seaTunnelRowType;
         this.seaTunnelRow = seaTunnelRow;
     }

File: seatunnel-connectors-v2/connector-neo4j/src/main/java/org/apache/seatunnel/connectors/seatunnel/neo4j/sink/Neo4jSinkWriter.java
Patch:
@@ -26,7 +26,7 @@
 import org.apache.seatunnel.connectors.seatunnel.neo4j.constants.CypherEnum;
 import org.apache.seatunnel.connectors.seatunnel.neo4j.exception.Neo4jConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.neo4j.exception.Neo4jConnectorException;
-import org.apache.seatunnel.connectors.seatunnel.neo4j.internal.SeatunnelRowNeo4jValue;
+import org.apache.seatunnel.connectors.seatunnel.neo4j.internal.SeaTunnelRowNeo4jValue;
 
 import org.neo4j.driver.Driver;
 import org.neo4j.driver.Query;
@@ -56,7 +56,7 @@ public class Neo4jSinkWriter implements SinkWriter<SeaTunnelRow, Void, Void> {
     private final transient Session session;
 
     private final SeaTunnelRowType seaTunnelRowType;
-    private final List<SeatunnelRowNeo4jValue> writeBuffer;
+    private final List<SeaTunnelRowNeo4jValue> writeBuffer;
     private final Integer maxBatchSize;
 
     public Neo4jSinkWriter(
@@ -93,7 +93,7 @@ private void writeOneByOne(SeaTunnelRow element) {
     }
 
     private void writeByBatchSize(SeaTunnelRow element) {
-        writeBuffer.add(new SeatunnelRowNeo4jValue(seaTunnelRowType, element));
+        writeBuffer.add(new SeaTunnelRowNeo4jValue(seaTunnelRowType, element));
         tryWriteByBatchSize();
     }
 

File: seatunnel-connectors-v2/connector-paimon/src/main/java/org/apache/seatunnel/connectors/seatunnel/paimon/utils/RowConverter.java
Patch:
@@ -124,7 +124,7 @@ public static Object convert(InternalArray array, SeaTunnelDataType<?> dataType)
     /**
      * Convert SeaTunnel array to Paimon array {@link InternalArray}
      *
-     * @param array Seatunnel array object
+     * @param array SeaTunnel array object
      * @param dataType SeaTunnel array data type
      * @return Paimon array object {@link BinaryArray}
      */
@@ -324,7 +324,7 @@ public static SeaTunnelRow convert(InternalRow rowData, SeaTunnelRowType seaTunn
      * Convert SeaTunnel row {@link SeaTunnelRow} to Paimon row {@link InternalRow}
      *
      * @param seaTunnelRow SeaTunnel row object
-     * @param seaTunnelRowType Seatunnel row type
+     * @param seaTunnelRowType SeaTunnel row type
      * @return Paimon row object
      */
     public static InternalRow convert(

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/rest/RestHttpGetCommandProcessor.java
Patch:
@@ -207,7 +207,7 @@ private Map<String, Long> getJobMetrics(String jobMetrics) {
         return metricsMap;
     }
 
-    private SeaTunnelServer getSeatunnelServer() {
+    private SeaTunnelServer getSeaTunnelServer() {
         Map<String, Object> extensionServices =
                 this.textCommandService.getNode().getNodeExtension().createExtensionServices();
         return (SeaTunnelServer) extensionServices.get(Constant.SEATUNNEL_SERVICE_NAME);
@@ -235,8 +235,8 @@ private JsonObject convertToJson(JobInfo jobInfo, long jobId) {
                         .toObject(jobImmutableInformation.getLogicalDag());
 
         String jobMetrics =
-                getSeatunnelServer().getCoordinatorService().getJobMetrics(jobId).toJsonString();
-        JobStatus jobStatus = getSeatunnelServer().getCoordinatorService().getJobStatus(jobId);
+                getSeaTunnelServer().getCoordinatorService().getJobMetrics(jobId).toJsonString();
+        JobStatus jobStatus = getSeaTunnelServer().getCoordinatorService().getJobStatus(jobId);
 
         jobInfoJson
                 .add("jobId", jobId)

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/NotifyTaskRestoreOperation.java
Patch:
@@ -107,7 +107,7 @@ public void run() throws Exception {
                                                 log.debug(
                                                         "NotifyTaskRestoreOperation.finished "
                                                                 + restoredState);
-                                            } catch (Exception e) {
+                                            } catch (Throwable e) {
                                                 task.getExecutionContext()
                                                         .sendToMaster(
                                                                 new CheckpointErrorReportOperation(

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/sink/HttpPutBuilder.java
Patch:
@@ -49,6 +49,7 @@ public HttpPutBuilder setUrl(String url) {
 
     public HttpPutBuilder addCommonHeader() {
         header.put(HttpHeaders.EXPECT, "100-continue");
+        header.put("Content-Type", "text/plain");
         return this;
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/PartitionParameter.java
Patch:
@@ -21,13 +21,14 @@
 import lombok.Data;
 
 import java.io.Serializable;
+import java.math.BigDecimal;
 
 @Data
 @AllArgsConstructor
 public class PartitionParameter implements Serializable {
 
     String partitionColumnName;
-    long minValue;
-    long maxValue;
+    BigDecimal minValue;
+    BigDecimal maxValue;
     Integer partitionNumber;
 }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/JdbcConnectionPoolFactory.java
Patch:
@@ -43,7 +43,6 @@ public HikariDataSource createPooledDataSource(JdbcSourceConfig sourceConfig) {
         config.setMaximumPoolSize(sourceConfig.getConnectionPoolSize());
         config.setConnectionTimeout(sourceConfig.getConnectTimeoutMillis());
         config.addDataSourceProperty(SERVER_TIMEZONE_KEY, sourceConfig.getServerTimeZone());
-        config.setDriverClassName(sourceConfig.getDriverClassName());
 
         // optional optimization configurations for pooled DataSource
         config.addDataSourceProperty("cachePrepStmts", "true");

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/AbstractReadStrategy.java
Patch:
@@ -128,7 +128,8 @@ public List<String> getFileNamesByPath(HadoopConf hadoopConf, String path) throw
             }
             if (fileStatus.isFile()) {
                 // filter '_SUCCESS' file
-                if (!fileStatus.getPath().getName().equals("_SUCCESS")) {
+                if (!fileStatus.getPath().getName().equals("_SUCCESS")
+                        && !fileStatus.getPath().getName().startsWith(".")) {
                     String filePath = fileStatus.getPath().toString();
                     if (!readPartitions.isEmpty()) {
                         for (String readPartition : readPartitions) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -615,6 +615,8 @@ protected void cleanPendingCheckpoint(CheckpointCloseReason closedReason) {
                 // TODO: clear related future & scheduler task
                 pendingCheckpoints.clear();
             }
+            pipelineTaskStatus.clear();
+            readyToCloseStartingTask.clear();
             pendingCounter.set(0);
             scheduler.shutdownNow();
             scheduler =

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/offset/LsnOffset.java
Patch:
@@ -61,8 +61,8 @@ public Lsn getCommitLsn() {
         return Lsn.valueOf(offset.get(SourceInfo.COMMIT_LSN_KEY));
     }
 
-    public Long getEventSerialNo() {
-        return Long.valueOf(offset.get(SourceInfo.EVENT_SERIAL_NO_KEY));
+    public Object getEventSerialNo() {
+        return offset.get(SourceInfo.EVENT_SERIAL_NO_KEY);
     }
 
     public int compareTo(Offset o) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSplitEnumeratorTask.java
Patch:
@@ -142,6 +142,7 @@ public void triggerBarrier(Barrier barrier) throws Exception {
         final long barrierId = barrier.getId();
         Serializable snapshotState = null;
         byte[] serialize = null;
+        // Do not modify this lock object, as it is also used in the SourceSplitEnumerator.
         synchronized (enumeratorContext) {
             if (barrier.snapshot()) {
                 snapshotState = enumerator.snapshotState(barrierId);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -242,7 +242,8 @@ public void initCheckPointManager() throws CheckpointStorageException {
                         this,
                         checkpointPlanMap,
                         jobCheckpointConfig,
-                        executorService);
+                        executorService,
+                        runningJobStateIMap);
     }
 
     // TODO replace it after ReadableConfig Support parse yaml format, then use only one config to

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -341,7 +341,8 @@ public void ack(Barrier barrier) {
                                 new TaskAcknowledgeOperation(
                                         this.taskLocation,
                                         (CheckpointBarrier) barrier,
-                                        checkpointStates.get(barrier.getId())));
+                                        checkpointStates.get(barrier.getId())))
+                        .join();
             }
         }
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SinkAggregatedCommitterTask.java
Patch:
@@ -224,7 +224,8 @@ public void triggerBarrier(Barrier barrier) throws Exception {
                                     (CheckpointBarrier) barrier,
                                     Collections.singletonList(
                                             new ActionSubtaskState(
-                                                    ActionStateKey.of(sink), -1, states))));
+                                                    ActionStateKey.of(sink), -1, states))))
+                    .join();
         }
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSplitEnumeratorTask.java
Patch:
@@ -160,7 +160,8 @@ public void triggerBarrier(Barrier barrier) throws Exception {
                                             new ActionSubtaskState(
                                                     ActionStateKey.of(source),
                                                     -1,
-                                                    Collections.singletonList(serialize)))));
+                                                    Collections.singletonList(serialize)))))
+                    .join();
         }
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManagerTest.java
Patch:
@@ -44,6 +44,7 @@
 import java.util.concurrent.CompletableFuture;
 
 import static org.apache.seatunnel.engine.common.Constant.IMAP_CHECKPOINT_ID;
+import static org.apache.seatunnel.engine.common.Constant.IMAP_RUNNING_JOB_STATE;
 
 @DisabledOnOs(OS.WINDOWS)
 @Disabled
@@ -88,7 +89,8 @@ public void testHAByIMapCheckpointIDCounter() throws CheckpointStorageException
                         null,
                         planMap,
                         new CheckpointConfig(),
-                        instance.getExecutorService("test"));
+                        instance.getExecutorService("test"),
+                        nodeEngine.getHazelcastInstance().getMap(IMAP_RUNNING_JOB_STATE));
         Assertions.assertTrue(checkpointManager.isCompletedPipeline(1));
         checkpointManager.listenPipeline(1, PipelineStatus.FINISHED);
         Assertions.assertNull(checkpointIdMap.get(1));

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/sink/writer/DorisSinkWriter.java
Patch:
@@ -59,7 +59,7 @@ public class DorisSinkWriter implements SinkWriter<SeaTunnelRow, DorisCommitInfo
     private static final int CONNECT_TIMEOUT = 1000;
     private static final List<String> DORIS_SUCCESS_STATUS =
             new ArrayList<>(Arrays.asList(LoadStatus.SUCCESS, LoadStatus.PUBLISH_TIMEOUT));
-    private final long lastCheckpointId;
+    private long lastCheckpointId;
     private DorisStreamLoad dorisStreamLoad;
     volatile boolean loading;
     private final DorisConfig dorisConfig;
@@ -156,7 +156,8 @@ public List<DorisSinkState> snapshotState(long checkpointId) throws IOException
         this.dorisStreamLoad.setHostPort(getAvailableBackend());
         this.dorisStreamLoad.startLoad(labelGenerator.generateLabel(checkpointId + 1));
         this.loading = true;
-        return Collections.singletonList(dorisSinkState);
+        this.lastCheckpointId = checkpointId;
+        return Collections.singletonList(new DorisSinkState(labelPrefix, lastCheckpointId));
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -313,6 +313,7 @@ private <T> Set<T> getFlowInfo(BiConsumer<Action, Set<T>> function) {
 
     @Override
     public void close() throws IOException {
+        super.close();
         allCycles
                 .parallelStream()
                 .forEach(

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SinkAggregatedCommitterTask.java
Patch:
@@ -179,6 +179,7 @@ protected void stateProcess() throws Exception {
 
     @Override
     public void close() throws IOException {
+        super.close();
         aggregatedCommitter.close();
         progress.done();
         completableFuture.complete(null);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSplitEnumeratorTask.java
Patch:
@@ -111,6 +111,7 @@ public void init() throws Exception {
 
     @Override
     public void close() throws IOException {
+        super.close();
         if (enumerator != null) {
             enumerator.close();
         }

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/ClientJobProxy.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.seatunnel.engine.client.SeaTunnelHazelcastClient;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
+import org.apache.seatunnel.engine.common.utils.ExceptionUtil;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.core.job.Job;
 import org.apache.seatunnel.engine.core.job.JobImmutableInformation;
@@ -35,7 +36,6 @@
 import org.apache.commons.lang3.StringUtils;
 
 import com.hazelcast.client.impl.protocol.ClientMessage;
-import com.hazelcast.core.OperationTimeoutException;
 import com.hazelcast.logging.ILogger;
 import com.hazelcast.logging.Logger;
 import lombok.NonNull;
@@ -104,8 +104,7 @@ public JobStatus waitForJobComplete() {
                                     100000,
                                     true,
                                     exception ->
-                                            exception.getCause()
-                                                    instanceof OperationTimeoutException,
+                                            ExceptionUtil.isOperationNeedRetryException(exception),
                                     Constant.OPERATION_RETRY_SLEEP));
             if (jobResult == null) {
                 throw new SeaTunnelEngineException("failed to fetch job result");

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/IMapCheckpointIDCounter.java
Patch:
@@ -19,10 +19,10 @@
 
 import org.apache.seatunnel.common.utils.RetryUtils;
 import org.apache.seatunnel.engine.common.Constant;
+import org.apache.seatunnel.engine.common.utils.ExceptionUtil;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointIDCounter;
 import org.apache.seatunnel.engine.core.job.PipelineStatus;
 
-import com.hazelcast.core.HazelcastInstanceNotActiveException;
 import com.hazelcast.map.IMap;
 import com.hazelcast.spi.impl.NodeEngine;
 
@@ -56,7 +56,7 @@ public void start() throws Exception {
                 new RetryUtils.RetryMaterial(
                         Constant.OPERATION_RETRY_TIME,
                         true,
-                        exception -> exception instanceof HazelcastInstanceNotActiveException,
+                        exception -> ExceptionUtil.isOperationNeedRetryException(exception),
                         Constant.OPERATION_RETRY_SLEEP));
     }
 

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/sink/writer/DorisSinkStateSerializer.java
Patch:
@@ -32,6 +32,7 @@ public byte[] serialize(DorisSinkState dorisSinkState) throws IOException {
         try (final ByteArrayOutputStream baos = new ByteArrayOutputStream();
                 final DataOutputStream out = new DataOutputStream(baos)) {
             out.writeUTF(dorisSinkState.getLabelPrefix());
+            out.writeLong(dorisSinkState.getCheckpointId());
             out.flush();
             return baos.toByteArray();
         }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/MultipleTableJobConfigParser.java
Patch:
@@ -409,9 +409,9 @@ private void parseTransform(
         SeaTunnelDataType<?> expectedType = getProducedType(inputs.get(0)._2());
         checkProducedTypeEquals(inputActions);
         int spareParallelism = inputs.get(0)._2().getParallelism();
+        int parallelism =
+                readonlyConfig.getOptional(CommonOptions.PARALLELISM).orElse(spareParallelism);
         if (fallback) {
-            int parallelism =
-                    readonlyConfig.getOptional(CommonOptions.PARALLELISM).orElse(spareParallelism);
             Tuple2<CatalogTable, Action> tuple =
                     fallbackParser.parseTransform(
                             config,
@@ -437,6 +437,7 @@ private void parseTransform(
         TransformAction transformAction =
                 new TransformAction(
                         id, actionName, new ArrayList<>(inputActions), transform, factoryUrls);
+        transformAction.setParallelism(parallelism);
         tableWithActionMap.put(
                 tableId,
                 Collections.singletonList(

File: seatunnel-engine/seatunnel-engine-common/src/test/java/org/apache/seatunnel/engine/common/config/YamlSeaTunnelConfigParserTest.java
Patch:
@@ -54,7 +54,7 @@ public void testSeaTunnelConfig() {
                 7000, config.getEngineConfig().getCheckpointConfig().getCheckpointTimeout());
 
         Assertions.assertEquals(
-                5, config.getEngineConfig().getCheckpointConfig().getMaxConcurrentCheckpoints());
+                1, config.getEngineConfig().getCheckpointConfig().getMaxConcurrentCheckpoints());
 
         Assertions.assertEquals(
                 2, config.getEngineConfig().getCheckpointConfig().getTolerableFailureCheckpoints());

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -614,7 +614,7 @@ protected void acknowledgeTask(TaskAcknowledgeOperation ackOperation) {
                         : SubtaskStatus.RUNNING);
     }
 
-    public void completePendingCheckpoint(CompletedCheckpoint completedCheckpoint) {
+    public synchronized void completePendingCheckpoint(CompletedCheckpoint completedCheckpoint) {
         LOG.debug(
                 "pending checkpoint({}/{}@{}) completed! cost: {}, trigger: {}, completed: {}",
                 completedCheckpoint.getCheckpointId(),

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalVertex.java
Patch:
@@ -418,6 +418,8 @@ public void cancel() {
                     new TaskExecutionState(this.taskGroupLocation, ExecutionState.CANCELED));
         } else if (updateTaskState(ExecutionState.RUNNING, ExecutionState.CANCELING)) {
             noticeTaskExecutionServiceCancel();
+        } else if (ExecutionState.CANCELING.equals(runningJobStateIMap.get(taskGroupLocation))) {
+            noticeTaskExecutionServiceCancel();
         }
 
         LOGGER.info(

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/TaskExecutionService.java
Patch:
@@ -836,6 +836,8 @@ void taskDone(Task task) {
                             task.getTaskID(), taskGroupLocation));
             Throwable ex = executionException.get();
             if (completionLatch.decrementAndGet() == 0) {
+                // recycle classloader
+                executionContexts.get(taskGroupLocation).setClassLoader(null);
                 finishedExecutionContexts.put(
                         taskGroupLocation, executionContexts.remove(taskGroupLocation));
                 cancellationFutures.remove(taskGroupLocation);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/CoordinatorService.java
Patch:
@@ -23,6 +23,7 @@
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.common.config.EngineConfig;
 import org.apache.seatunnel.engine.common.exception.JobException;
+import org.apache.seatunnel.engine.common.exception.JobNotFoundException;
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.core.job.JobDAGInfo;
@@ -525,7 +526,7 @@ public void updateTaskExecutionState(TaskExecutionState taskExecutionState) {
         TaskGroupLocation taskGroupLocation = taskExecutionState.getTaskGroupLocation();
         JobMaster runningJobMaster = runningJobMasterMap.get(taskGroupLocation.getJobId());
         if (runningJobMaster == null) {
-            throw new JobException(
+            throw new JobNotFoundException(
                     String.format("Job %s not running", taskGroupLocation.getJobId()));
         }
         runningJobMaster.updateTaskExecutionState(taskExecutionState);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCloseReason.java
Patch:
@@ -19,7 +19,8 @@
 
 public enum CheckpointCloseReason {
     PIPELINE_END("Pipeline turn to end state."),
-    CHECKPOINT_EXPIRED("Checkpoint expired before completing."),
+    CHECKPOINT_EXPIRED(
+            "Checkpoint expired before completing. Please increase checkpoint timeout in the seatunnel.yaml"),
     CHECKPOINT_COORDINATOR_COMPLETED("CheckpointCoordinator completed."),
     CHECKPOINT_COORDINATOR_SHUTDOWN("CheckpointCoordinator shutdown."),
     CHECKPOINT_COORDINATOR_RESET("CheckpointCoordinator reset."),

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlan.java
Patch:
@@ -174,7 +174,7 @@ public void addPipelineEndCallback(SubPlan subPlan) {
                         }
 
                         if (finishedPipelineNum.incrementAndGet() == this.pipelineList.size()) {
-                            JobStatus jobStatus = JobStatus.FAILING;
+                            JobStatus jobStatus;
                             if (failedPipelineNum.get() > 0) {
                                 jobStatus = JobStatus.FAILING;
                                 updateJobState(jobStatus);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/AbstractTask.java
Patch:
@@ -68,6 +68,7 @@ public void setTaskExecutionContext(TaskExecutionContext taskExecutionContext) {
         this.executionContext = taskExecutionContext;
     }
 
+    @Override
     public TaskExecutionContext getExecutionContext() {
         return executionContext;
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/SinkFlowLifeCycle.java
Patch:
@@ -190,7 +190,8 @@ public void received(Record<?> record) {
                                 .getExecutionContext()
                                 .sendToMember(
                                         new BarrierFlowOperation(barrier, committerTaskLocation),
-                                        committerTaskAddress);
+                                        committerTaskAddress)
+                                .join();
                     }
                 }
                 runningTask.ack(barrier);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/group/queue/IntermediateBlockingQueue.java
Patch:
@@ -57,7 +57,7 @@ public void collect(Collector<Record<?>> collector) throws Exception {
 
     @Override
     public void close() throws IOException {
-        // nothing
+        getIntermediateQueue().clear();
     }
 
     private void handleRecord(Record<?> record, ConsumerWithException<Record<?>> consumer)

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/JdbcOutputFormatBuilder.java
Patch:
@@ -244,7 +244,7 @@ private static Function<SeaTunnelRow, SeaTunnelRow> createKeyExtractor(int[] pkF
             SeaTunnelRow newRow = new SeaTunnelRow(fields);
             newRow.setTableId(row.getTableId());
             newRow.setRowKind(row.getRowKind());
-            return row;
+            return newRow;
         };
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerCatalog.java
Patch:
@@ -69,7 +69,7 @@ public SqlServerCatalog(
     @Override
     public List<String> listDatabases() throws CatalogException {
         try (Connection conn = DriverManager.getConnection(defaultUrl, username, pwd);
-                PreparedStatement ps = conn.prepareStatement("SELECT NAME FROM SYS.DATABASES")) {
+                PreparedStatement ps = conn.prepareStatement("SELECT NAME FROM sys.databases")) {
 
             List<String> databases = new ArrayList<>();
             ResultSet rs = ps.executeQuery();

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-plugins/imap-storage-file/src/test/java/org/apache/seatunnel/engine/imap/storage/file/IMapFileStorageTest.java
Patch:
@@ -56,11 +56,13 @@ public class IMapFileStorageTest {
         CONF.set("fs.defaultFS", "file:///");
         CONF.set("fs.file.impl", "org.apache.hadoop.fs.LocalFileSystem");
         STORAGE = new IMapFileStorage();
+
         Map<String, Object> properties = new HashMap<>();
+        properties.put("fs.defaultFS", "file:///");
+        properties.put("fs.file.impl", "org.apache.hadoop.fs.LocalFileSystem");
         properties.put(FileConstants.FileInitProperties.BUSINESS_KEY, "random");
         properties.put(FileConstants.FileInitProperties.NAMESPACE_KEY, "/tmp/imap-kris-test/2");
         properties.put(FileConstants.FileInitProperties.CLUSTER_NAME, "test-one");
-        properties.put(FileConstants.FileInitProperties.HDFS_CONFIG_KEY, CONF);
         properties.put(WRITE_DATA_TIMEOUT_MILLISECONDS_KEY, 60L);
 
         STORAGE.initialize(properties);

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-plugins/imap-storage-file/src/test/java/org/apache/seatunnel/engine/imap/storage/file/common/WALReaderAndWriterTest.java
Patch:
@@ -21,6 +21,7 @@
 package org.apache.seatunnel.engine.imap.storage.file.common;
 
 import org.apache.seatunnel.engine.imap.storage.file.bean.IMapFileData;
+import org.apache.seatunnel.engine.imap.storage.file.config.FileConfiguration;
 import org.apache.seatunnel.engine.serializer.api.Serializer;
 import org.apache.seatunnel.engine.serializer.protobuf.ProtoStuffSerializer;
 
@@ -59,7 +60,7 @@ public static void init() throws IOException {
 
     @Test
     public void testWriterAndReader() throws Exception {
-        WALWriter writer = new WALWriter(FS, PARENT_PATH, SERIALIZER);
+        WALWriter writer = new WALWriter(FS, FileConfiguration.HDFS, PARENT_PATH, SERIALIZER);
         IMapFileData data;
         boolean isDelete;
         for (int i = 0; i < 1024; i++) {
@@ -106,7 +107,7 @@ public void testWriterAndReader() throws Exception {
         writer.close();
         await().atMost(10, java.util.concurrent.TimeUnit.SECONDS).await();
 
-        WALReader reader = new WALReader(FS, new ProtoStuffSerializer());
+        WALReader reader = new WALReader(FS, FileConfiguration.HDFS, new ProtoStuffSerializer());
         Map<Object, Object> result = reader.loadAllData(PARENT_PATH, new HashSet<>());
         Assertions.assertEquals("Kristen", result.get("key511"));
         Assertions.assertEquals(511, result.size());

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-plugins/imap-storage-file/src/test/java/org/apache/seatunnel/engine/imap/storage/file/disruptor/WALDisruptorTest.java
Patch:
@@ -21,6 +21,7 @@
 package org.apache.seatunnel.engine.imap.storage.file.disruptor;
 
 import org.apache.seatunnel.engine.imap.storage.file.bean.IMapFileData;
+import org.apache.seatunnel.engine.imap.storage.file.config.FileConfiguration;
 import org.apache.seatunnel.engine.imap.storage.file.future.RequestFuture;
 import org.apache.seatunnel.engine.imap.storage.file.future.RequestFutureCache;
 import org.apache.seatunnel.engine.serializer.protobuf.ProtoStuffSerializer;
@@ -59,7 +60,8 @@ public class WALDisruptorTest {
     @Test
     void testProducerAndConsumer() throws IOException {
         FS = FileSystem.get(CONF);
-        DISRUPTOR = new WALDisruptor(FS, FILEPATH, new ProtoStuffSerializer());
+        DISRUPTOR =
+                new WALDisruptor(FS, FileConfiguration.HDFS, FILEPATH, new ProtoStuffSerializer());
         IMapFileData data;
         for (int i = 0; i < 100; i++) {
             data =

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/eumerator/MySqlChunkSplitter.java
Patch:
@@ -295,8 +295,10 @@ private SnapshotSplit createSnapshotSplit(
             Object chunkStart,
             Object chunkEnd) {
         // currently, we only support single split column
+        Object[] splitStart = chunkStart == null ? null : new Object[] {chunkStart};
+        Object[] splitEnd = chunkEnd == null ? null : new Object[] {chunkEnd};
         return new SnapshotSplit(
-                splitId(tableId, chunkId), tableId, splitKeyType, chunkStart, chunkEnd, null);
+                splitId(tableId, chunkId), tableId, splitKeyType, splitStart, splitEnd, null);
     }
 
     // ------------------------------------------------------------------------------------------

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/reader/fetch/scan/MySqlSnapshotSplitReadTask.java
Patch:
@@ -205,8 +205,8 @@ private void createDataEventsForTable(
                                 selectSql,
                                 snapshotSplit.getSplitStart() == null,
                                 snapshotSplit.getSplitEnd() == null,
-                                new Object[] {snapshotSplit.getSplitStart()},
-                                new Object[] {snapshotSplit.getSplitEnd()},
+                                snapshotSplit.getSplitStart(),
+                                snapshotSplit.getSplitEnd(),
                                 snapshotSplit.getSplitKeyType().getTotalFields(),
                                 connectorConfig.getSnapshotFetchSize());
                 ResultSet rs = selectStatement.executeQuery()) {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/eumerator/SqlServerChunkSplitter.java
Patch:
@@ -292,8 +292,10 @@ private SnapshotSplit createSnapshotSplit(
             Object chunkStart,
             Object chunkEnd) {
         // currently, we only support single split column
+        Object[] splitStart = chunkStart == null ? null : new Object[] {chunkStart};
+        Object[] splitEnd = chunkEnd == null ? null : new Object[] {chunkEnd};
         return new SnapshotSplit(
-                splitId(tableId, chunkId), tableId, splitKeyType, chunkStart, chunkEnd, null);
+                splitId(tableId, chunkId), tableId, splitKeyType, splitStart, splitEnd, null);
     }
 
     // ------------------------------------------------------------------------------------------

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/reader/fetch/scan/SqlServerSnapshotSplitReadTask.java
Patch:
@@ -195,8 +195,8 @@ private void createDataEventsForTable(
                                 selectSql,
                                 snapshotSplit.getSplitStart() == null,
                                 snapshotSplit.getSplitEnd() == null,
-                                new Object[] {snapshotSplit.getSplitStart()},
-                                new Object[] {snapshotSplit.getSplitEnd()},
+                                snapshotSplit.getSplitStart(),
+                                snapshotSplit.getSplitEnd(),
                                 snapshotSplit.getSplitKeyType().getTotalFields(),
                                 connectorConfig.getSnapshotFetchSize());
                 ResultSet rs = selectStatement.executeQuery()) {

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/ElasticsearchRowSerializer.java
Patch:
@@ -38,7 +38,7 @@
 import java.util.Map;
 import java.util.function.Function;
 
-/** use in elasticsearch version >= 7.* */
+/** use in elasticsearch version >= 2.x and <= 8.x */
 public class ElasticsearchRowSerializer implements SeaTunnelRowSerializer {
     private final SeaTunnelRowType seaTunnelRowType;
     private final ObjectMapper objectMapper = new ObjectMapper();

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/SQLEngine.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine;
+package org.apache.seatunnel.transform.sql;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/SQLEngineFactory.java
Patch:
@@ -15,11 +15,11 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine;
+package org.apache.seatunnel.transform.sql;
 
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.transform.exception.TransformException;
-import org.apache.seatunnel.transform.sqlengine.zeta.ZetaSQLEngine;
+import org.apache.seatunnel.transform.sql.zeta.ZetaSQLEngine;
 
 public class SQLEngineFactory {
     public static SQLEngine getSQLEngine(EngineType engineType) {

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/SQLTransformFactory.java
Patch:
@@ -15,15 +15,15 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform;
+package org.apache.seatunnel.transform.sql;
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableTransformFactory;
 
 import com.google.auto.service.AutoService;
 
-import static org.apache.seatunnel.transform.SQLTransform.KEY_QUERY;
+import static org.apache.seatunnel.transform.sql.SQLTransform.KEY_QUERY;
 
 @AutoService(Factory.class)
 public class SQLTransformFactory implements TableTransformFactory {

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/ZetaSQLEngine.java
Patch:
@@ -15,14 +15,14 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta;
+package org.apache.seatunnel.transform.sql.zeta;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.transform.exception.TransformException;
-import org.apache.seatunnel.transform.sqlengine.SQLEngine;
+import org.apache.seatunnel.transform.sql.SQLEngine;
 
 import net.sf.jsqlparser.JSQLParserException;
 import net.sf.jsqlparser.expression.Expression;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/ZetaSQLFilter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta;
+package org.apache.seatunnel.transform.sql.zeta;
 
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.transform.exception.TransformException;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/ZetaSQLType.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta;
+package org.apache.seatunnel.transform.sql.zeta;
 
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.DecimalType;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/ZetaUDF.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta;
+package org.apache.seatunnel.transform.sql.zeta;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/functions/DateTimeFunction.java
Patch:
@@ -15,11 +15,11 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta.functions;
+package org.apache.seatunnel.transform.sql.zeta.functions;
 
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.transform.exception.TransformException;
-import org.apache.seatunnel.transform.sqlengine.zeta.ZetaSQLFunction;
+import org.apache.seatunnel.transform.sql.zeta.ZetaSQLFunction;
 
 import java.text.DateFormatSymbols;
 import java.time.Duration;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/functions/NumericFunction.java
Patch:
@@ -15,11 +15,11 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta.functions;
+package org.apache.seatunnel.transform.sql.zeta.functions;
 
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.transform.exception.TransformException;
-import org.apache.seatunnel.transform.sqlengine.zeta.ZetaSQLFunction;
+import org.apache.seatunnel.transform.sql.zeta.ZetaSQLFunction;
 
 import java.math.BigDecimal;
 import java.math.RoundingMode;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/functions/StringFunction.java
Patch:
@@ -15,11 +15,11 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta.functions;
+package org.apache.seatunnel.transform.sql.zeta.functions;
 
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.transform.exception.TransformException;
-import org.apache.seatunnel.transform.sqlengine.zeta.ZetaSQLFunction;
+import org.apache.seatunnel.transform.sql.zeta.ZetaSQLFunction;
 
 import java.nio.charset.StandardCharsets;
 import java.time.temporal.Temporal;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/functions/SystemFunction.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta.functions;
+package org.apache.seatunnel.transform.sql.zeta.functions;
 
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.transform.exception.TransformException;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/functions/udf/DESUtil.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta.functions.udf;
+package org.apache.seatunnel.transform.sql.zeta.functions.udf;
 
 import javax.crypto.Cipher;
 import javax.crypto.SecretKeyFactory;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/functions/udf/DesDecrypt.java
Patch:
@@ -15,11 +15,11 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta.functions.udf;
+package org.apache.seatunnel.transform.sql.zeta.functions.udf;
 
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
-import org.apache.seatunnel.transform.sqlengine.zeta.ZetaUDF;
+import org.apache.seatunnel.transform.sql.zeta.ZetaUDF;
 
 import com.google.auto.service.AutoService;
 

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/sql/zeta/functions/udf/DesEncrypt.java
Patch:
@@ -15,11 +15,11 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.transform.sqlengine.zeta.functions.udf;
+package org.apache.seatunnel.transform.sql.zeta.functions.udf;
 
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
-import org.apache.seatunnel.transform.sqlengine.zeta.ZetaUDF;
+import org.apache.seatunnel.transform.sql.zeta.ZetaUDF;
 
 import com.google.auto.service.AutoService;
 

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/ClickhouseProxy.java
Patch:
@@ -86,7 +86,7 @@ public DistributedEngine getClickhouseDistributedTable(
 
                 String clusterName = infos.get(0);
                 String localDatabase = infos.get(1);
-                String localTable = infos.get(2).replace("\\)", "").trim();
+                String localTable = infos.get(2).replace(")", "").trim();
 
                 String localTableSQL =
                         String.format(

File: seatunnel-core/seatunnel-starter/src/main/java/org/apache/seatunnel/core/starter/seatunnel/command/ClientExecuteCommand.java
Patch:
@@ -230,6 +230,7 @@ private void closeClient() {
     private HazelcastInstance createServerInLocal(
             String clusterName, SeaTunnelConfig seaTunnelConfig) {
         seaTunnelConfig.getHazelcastConfig().setClusterName(clusterName);
+        seaTunnelConfig.getHazelcastConfig().getNetworkConfig().setPortAutoIncrement(true);
         return HazelcastInstanceFactory.newHazelcastInstance(
                 seaTunnelConfig.getHazelcastConfig(),
                 Thread.currentThread().getName(),

File: seatunnel-connectors-v2/connector-file/connector-file-sftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sftp/system/SFTPFileSystem.java
Patch:
@@ -593,7 +593,6 @@ public Path getHomeDirectory() {
             try {
                 disconnect(channel);
             } catch (IOException ioe) {
-                return null;
             }
         }
     }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/common/SeaTunnelAPIErrorCode.java
Patch:
@@ -28,6 +28,7 @@ public enum SeaTunnelAPIErrorCode implements SeaTunnelErrorCode {
     FACTORY_INITIALIZE_FAILED("API-06", "Factory initialize failed"),
     DATABASE_ALREADY_EXISTED("API-07", "Database already existed"),
     TABLE_ALREADY_EXISTED("API-08", "Table already existed"),
+    HANDLE_SAVE_MODE_FAILED("API-09", "Handle save mode failed"),
     ;
 
     private final String code;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkFactory.java
Patch:
@@ -107,7 +107,6 @@ public OptionRule optionRule() {
                         TRANSACTION_TIMEOUT_SEC)
                 .conditional(IS_EXACTLY_ONCE, false, MAX_RETRIES)
                 .conditional(GENERATE_SINK_SQL, true, DATABASE)
-                .conditional(GENERATE_SINK_SQL, true, TABLE)
                 .conditional(GENERATE_SINK_SQL, false, QUERY)
                 .build();
     }

File: seatunnel-translation/seatunnel-translation-flink/seatunnel-translation-flink-common/src/main/java/org/apache/seatunnel/translation/flink/sink/FlinkSink.java
Patch:
@@ -66,7 +66,7 @@ public SinkWriter<InputT, CommitWrapper<CommT>, FlinkWriterState<WriterStateT>>
                     states.stream().map(FlinkWriterState::getState).collect(Collectors.toList());
             return new FlinkSinkWriter<>(
                     sink.restoreWriter(stContext, restoredState),
-                    states.get(0).getCheckpointId(),
+                    states.get(0).getCheckpointId() + 1,
                     sink.getConsumedType());
         }
     }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkWriter.java
Patch:
@@ -84,6 +84,7 @@ public void write(SeaTunnelRow element) throws IOException {
     @Override
     public Optional<XidInfo> prepareCommit() throws IOException {
         tryOpen();
+        outputFormat.checkFlushException();
         outputFormat.flush();
         try {
             if (!connectionProvider.getConnection().getAutoCommit()) {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sqlserver/SqlServerURLParser.java
Patch:
@@ -45,7 +45,7 @@ public static JdbcUrlUtil.UrlInfo parse(String url) {
         if (split.length > 1) {
             props = parseQueryParams(split[1], ";");
             serverName = props.get("serverName");
-            dbInstance = props.get("databaseName");
+            dbInstance = props.getOrDefault("databaseName", props.get("database"));
             if (props.containsKey("portNumber")) {
                 String portNumber = props.get("portNumber");
                 try {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-amazondynamodb-e2e/src/test/java/org/apache/seatunnel/e2e/connector/amazondynamodb/AmazondynamodbIT.java
Patch:
@@ -81,7 +81,7 @@
 
 @Slf4j
 public class AmazondynamodbIT extends TestSuiteBase implements TestResource {
-    private static final String AMAZONDYNAMODB_DOCKER_IMAGE = "amazon/dynamodb-local";
+    private static final String AMAZONDYNAMODB_DOCKER_IMAGE = "amazon/dynamodb-local:1.21.0";
     private static final String AMAZONDYNAMODB_CONTAINER_HOST = "dynamodb-host";
     private static final int AMAZONDYNAMODB_CONTAINER_PORT = 8000;
     private static final String AMAZONDYNAMODB_JOB_CONFIG = "/amazondynamodbIT_source_to_sink.conf";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cassandra-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/cassandra/CassandraIT.java
Patch:
@@ -86,7 +86,7 @@
 
 @Slf4j
 public class CassandraIT extends TestSuiteBase implements TestResource {
-    private static final String CASSANDRA_DOCKER_IMAGE = "cassandra";
+    private static final String CASSANDRA_DOCKER_IMAGE = "cassandra:4.1.1";
     private static final String HOST = "cassandra";
     private static final Integer PORT = 9042;
     private static final String INIT_CASSANDRA_PATH = "/init/cassandra_init.conf";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-clickhouse-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/ClickhouseIT.java
Patch:
@@ -76,7 +76,7 @@
 
 public class ClickhouseIT extends TestSuiteBase implements TestResource {
     private static final Logger LOG = LoggerFactory.getLogger(ClickhouseIT.class);
-    private static final String CLICKHOUSE_DOCKER_IMAGE = "yandex/clickhouse-server:latest";
+    private static final String CLICKHOUSE_DOCKER_IMAGE = "yandex/clickhouse-server:22.1.3.7";
     private static final String HOST = "clickhouse";
     private static final String DRIVER_CLASS = "com.clickhouse.jdbc.ClickHouseDriver";
     private static final String INIT_CLICKHOUSE_PATH = "/init/clickhouse_init.conf";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-kafka-e2e/src/test/java/org/apache/seatunnel/e2e/connector/kafka/CanalToKafkaIT.java
Patch:
@@ -84,7 +84,7 @@ public class CanalToKafkaIT extends TestSuiteBase implements TestResource {
 
     // ----------------------------------------------------------------------------
     // kafka
-    private static final String KAFKA_IMAGE_NAME = "confluentinc/cp-kafka:latest";
+    private static final String KAFKA_IMAGE_NAME = "confluentinc/cp-kafka:7.0.9";
 
     private static final String KAFKA_TOPIC = "test-canal-sink";
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-mongodb-e2e/src/test/java/org/apache/seatunnel/e2e/connector/v2/mongodb/MongodbIT.java
Patch:
@@ -67,7 +67,7 @@
 @Slf4j
 public class MongodbIT extends TestSuiteBase implements TestResource {
 
-    private static final String MONGODB_IMAGE = "mongo:latest";
+    private static final String MONGODB_IMAGE = "mongo:6.0.5";
     private static final String MONGODB_CONTAINER_HOST = "e2e_mongodb";
     private static final int MONGODB_PORT = 27017;
     private static final String MONGODB_DATABASE = "test_db";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-neo4j-e2e/src/test/java/org/apache/seatunnel/e2e/connector/neo4j/Neo4jIT.java
Patch:
@@ -60,7 +60,7 @@
 @Slf4j
 public class Neo4jIT extends TestSuiteBase implements TestResource {
 
-    private static final String CONTAINER_IMAGE = "neo4j:latest";
+    private static final String CONTAINER_IMAGE = "neo4j:5.6.0";
     private static final String CONTAINER_HOST = "neo4j-host";
     private static final int HTTP_PORT = 7474;
     private static final int BOLT_PORT = 7687;

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceReader.java
Patch:
@@ -152,13 +152,13 @@ public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
                                                         try {
                                                             deserializationSchema.deserialize(
                                                                     record.value(), output);
-                                                        } catch (IOException e) {
+                                                        } catch (Exception e) {
                                                             if (this.messageFormatErrorHandleWay
                                                                     == MessageFormatErrorHandleWay
                                                                             .SKIP) {
                                                                 log.warn(
                                                                         "Deserialize message failed, skip this message, message: {}",
-                                                                        record.value());
+                                                                        new String(record.value()));
                                                                 continue;
                                                             }
                                                             throw e;

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-file-local-e2e/src/test/java/org/apache/seatunnel/e2e/connector/file/local/LocalFileIT.java
Patch:
@@ -77,7 +77,7 @@ public void testLocalFileReadAndWrite(TestContainer container)
         Container.ExecResult excelProjectionReadResult =
                 container.executeJob("/excel/local_excel_projection_to_assert.conf");
         Assertions.assertEquals(
-                0, excelReadResult.getExitCode(), excelProjectionReadResult.getStderr());
+                0, excelProjectionReadResult.getExitCode(), excelProjectionReadResult.getStderr());
         // test write local text file
         Container.ExecResult textWriteResult =
                 container.executeJob("/text/fake_to_local_file_text.conf");

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/env/EnvCommonOptions.java
Patch:
@@ -41,7 +41,7 @@ public interface EnvCommonOptions {
     Option<JobMode> JOB_MODE =
             Options.key("job.mode")
                     .enumType(JobMode.class)
-                    .noDefaultValue()
+                    .defaultValue(JobMode.BATCH)
                     .withDescription("The job mode of this job, support Batch and Stream");
 
     Option<Long> CHECKPOINT_INTERVAL =

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-clickhouse-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/ClickhouseSinkCDCChangelogIT.java
Patch:
@@ -52,7 +52,7 @@
 
 @DisabledOnContainer(
         value = {},
-        type = {EngineType.SPARK, EngineType.SEATUNNEL},
+        type = {EngineType.SPARK},
         disabledReason = "Spark engine will lose the row kind of record")
 @Slf4j
 public class ClickhouseSinkCDCChangelogIT extends TestSuiteBase implements TestResource {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-file-local-e2e/src/test/java/org/apache/seatunnel/e2e/connector/file/local/LocalFileIT.java
Patch:
@@ -19,7 +19,6 @@
 
 import org.apache.seatunnel.e2e.common.TestSuiteBase;
 import org.apache.seatunnel.e2e.common.container.ContainerExtendedFactory;
-import org.apache.seatunnel.e2e.common.container.EngineType;
 import org.apache.seatunnel.e2e.common.container.TestContainer;
 import org.apache.seatunnel.e2e.common.container.TestContainerId;
 import org.apache.seatunnel.e2e.common.junit.DisabledOnContainer;
@@ -36,7 +35,7 @@
 
 @DisabledOnContainer(
         value = {TestContainerId.SPARK_2_4},
-        type = {EngineType.SEATUNNEL},
+        type = {},
         disabledReason = "The apache-compress version is not compatible with apache-poi")
 public class LocalFileIT extends TestSuiteBase {
 
@@ -70,7 +69,7 @@ public class LocalFileIT extends TestSuiteBase {
     public void testLocalFileReadAndWrite(TestContainer container)
             throws IOException, InterruptedException {
         Container.ExecResult excelWriteResult =
-                container.executeJob("/excel/fakesource_to_local_excel.conf");
+                container.executeJob("/excel/fake_to_local_excel.conf");
         Assertions.assertEquals(0, excelWriteResult.getExitCode(), excelWriteResult.getStderr());
         Container.ExecResult excelReadResult =
                 container.executeJob("/excel/local_excel_to_assert.conf");

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-iotdb-e2e/src/test/java/org/apache/seatunnel/e2e/connector/iotdb/IoTDBIT.java
Patch:
@@ -61,7 +61,7 @@
 @Slf4j
 @DisabledOnContainer(
         value = {},
-        type = {EngineType.SEATUNNEL, EngineType.SPARK},
+        type = {EngineType.SPARK},
         disabledReason =
                 "There is a conflict of thrift version between IoTDB and Spark.Therefore. Refactor starter module, so disabled in flink")
 public class IoTDBIT extends TestSuiteBase implements TestResource {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/connector-jdbc-e2e-part-3/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcSinkCDCChangelogIT.java
Patch:
@@ -56,7 +56,7 @@
 
 @DisabledOnContainer(
         value = {},
-        type = {EngineType.SPARK, EngineType.SEATUNNEL},
+        type = {EngineType.SPARK},
         disabledReason = "Spark engine will lose the row kind of record")
 @Slf4j
 public class JdbcSinkCDCChangelogIT extends TestSuiteBase implements TestResource {

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/TestContainerId.java
Patch:
@@ -32,7 +32,7 @@ public enum TestContainerId {
     FLINK_1_16(FLINK, "1.16.0"),
     SPARK_2_4(SPARK, "2.4.6"),
     SPARK_3_3(SPARK, "3.3.0"),
-    SEATUNNEL(EngineType.SEATUNNEL, "2.2.0");
+    SEATUNNEL(EngineType.SEATUNNEL, "2.3.1");
 
     private final EngineType engineType;
     private final String version;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/opeartion/SyncWorkerProfileOperation.java
Patch:
@@ -23,7 +23,9 @@
 
 import com.hazelcast.nio.serialization.IdentifiedDataSerializable;
 import com.hazelcast.spi.impl.operationservice.Operation;
+import lombok.extern.slf4j.Slf4j;
 
+@Slf4j
 public class SyncWorkerProfileOperation extends Operation implements IdentifiedDataSerializable {
 
     private WorkerProfile result;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/checkpoint/BarrierFlowOperation.java
Patch:
@@ -81,7 +81,7 @@ public void run() throws Exception {
                                     .getTaskGroup()
                                     .getTask(taskLocation.getTaskID());
                     try {
-                        log.debug("BarrierFlowOperation [{}]" + taskLocation);
+                        log.debug("BarrierFlowOperation [{}]", taskLocation);
                         task.triggerBarrier(barrier);
                     } catch (Exception e) {
                         log.warn(ExceptionUtils.getMessage(e));

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/source/StarRocksSource.java
Patch:
@@ -78,8 +78,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                             getPluginName(), PluginType.SOURCE, mergedConfigCheck.getMsg()));
         }
 
-        Config schemaConfig = pluginConfig.getConfig(CatalogTableUtil.SCHEMA.key());
-        this.typeInfo = CatalogTableUtil.buildWithConfig(schemaConfig).getSeaTunnelRowType();
+        this.typeInfo = CatalogTableUtil.buildWithConfig(pluginConfig).getSeaTunnelRowType();
         this.sourceConfig = SourceConfig.loadConfig(pluginConfig);
     }
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-rocketmq-e2e/src/test/java/org/apache/seatunnel/e2e/connector/rocketmq/RocketMqContainer.java
Patch:
@@ -42,6 +42,7 @@ public class RocketMqContainer extends GenericContainer<RocketMqContainer> {
     public RocketMqContainer(DockerImageName image) {
         super(image);
         withExposedPorts(NAMESRV_PORT, BROKER_PORT, BROKER_PORT - 2);
+        this.withEnv("JAVA_OPT_EXT", "-Xms512m -Xmx512m");
     }
 
     @Override

File: seatunnel-connectors-v2/connector-rocketmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rocketmq/common/RocketMqAdminUtil.java
Patch:
@@ -17,6 +17,9 @@
 
 package org.apache.seatunnel.connectors.seatunnel.rocketmq.common;
 
+import org.apache.seatunnel.shade.com.google.common.collect.Lists;
+import org.apache.seatunnel.shade.com.google.common.collect.Maps;
+
 import org.apache.seatunnel.connectors.seatunnel.rocketmq.exception.RocketMqConnectorErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.rocketmq.exception.RocketMqConnectorException;
 
@@ -44,9 +47,6 @@
 import org.apache.rocketmq.tools.admin.DefaultMQAdminExt;
 import org.apache.rocketmq.tools.command.CommandUtil;
 
-import com.google.common.collect.Lists;
-import com.google.common.collect.Maps;
-
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;

File: seatunnel-connectors-v2/connector-rocketmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rocketmq/source/RocketMqSourceReader.java
Patch:
@@ -17,6 +17,9 @@
 
 package org.apache.seatunnel.connectors.seatunnel.rocketmq.source;
 
+import org.apache.seatunnel.shade.com.google.common.collect.Maps;
+import org.apache.seatunnel.shade.com.google.common.collect.Sets;
+
 import org.apache.seatunnel.api.serialization.DeserializationSchema;
 import org.apache.seatunnel.api.source.Boundedness;
 import org.apache.seatunnel.api.source.Collector;
@@ -28,8 +31,6 @@
 import org.apache.rocketmq.common.message.MessageExt;
 import org.apache.rocketmq.common.message.MessageQueue;
 
-import com.google.common.collect.Maps;
-import com.google.common.collect.Sets;
 import lombok.extern.slf4j.Slf4j;
 
 import java.io.IOException;

File: seatunnel-connectors-v2/connector-rocketmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rocketmq/source/RocketMqSourceSplitEnumerator.java
Patch:
@@ -17,6 +17,9 @@
 
 package org.apache.seatunnel.connectors.seatunnel.rocketmq.source;
 
+import org.apache.seatunnel.shade.com.google.common.collect.Maps;
+import org.apache.seatunnel.shade.com.google.common.collect.Sets;
+
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
 import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.connectors.seatunnel.rocketmq.common.RocketMqAdminUtil;
@@ -28,8 +31,6 @@
 import org.apache.rocketmq.common.consumer.ConsumeFromWhere;
 import org.apache.rocketmq.common.message.MessageQueue;
 
-import com.google.common.collect.Maps;
-import com.google.common.collect.Sets;
 import lombok.extern.slf4j.Slf4j;
 
 import java.io.IOException;

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-rocketmq-e2e/src/test/java/org/apache/seatunnel/e2e/connector/rocketmq/RocketMqIT.java
Patch:
@@ -185,7 +185,6 @@ public void testSinkRocketMq(TestContainer container) throws IOException, Interr
         ObjectNode objectNode = objectMapper.readValue(key, ObjectNode.class);
         Assertions.assertTrue(objectNode.has("c_map"));
         Assertions.assertTrue(objectNode.has("c_string"));
-        Assertions.assertEquals(10, data.size());
     }
 
     @TestTemplate

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/JdbcSourceFactory.java
Patch:
@@ -155,11 +155,11 @@ static PartitionParameter createPartitionParameter(
                 max =
                         config.getPartitionUpperBound().isPresent()
                                 ? config.getPartitionUpperBound().get()
-                                : Long.parseLong(rs.getString(1));
+                                : rs.getLong(1);
                 min =
                         config.getPartitionLowerBound().isPresent()
                                 ? config.getPartitionLowerBound().get()
-                                : Long.parseLong(rs.getString(2));
+                                : rs.getLong(2);
             }
         } catch (SQLException e) {
             throw new PrepareFailException("jdbc", PluginType.SOURCE, e.toString());

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/JdbcSourceSplitEnumerator.java
Patch:
@@ -108,7 +108,8 @@ private Set<JdbcSourceSplit> discoverySplits() {
                             : enumeratorContext.currentParallelism();
             JdbcNumericBetweenParametersProvider jdbcNumericBetweenParametersProvider =
                     new JdbcNumericBetweenParametersProvider(
-                                    partitionParameter.minValue, partitionParameter.maxValue)
+                                    partitionParameter.getMinValue(),
+                                    partitionParameter.getMaxValue())
                             .ofBatchNum(partitionNumber);
             Serializable[][] parameterValues =
                     jdbcNumericBetweenParametersProvider.getParameterValues();

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/PartitionParameter.java
Patch:
@@ -27,7 +27,7 @@
 public class PartitionParameter implements Serializable {
 
     String partitionColumnName;
-    Long minValue;
-    Long maxValue;
+    long minValue;
+    long maxValue;
     Integer partitionNumber;
 }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/MultipleTableJobConfigParser.java
Patch:
@@ -428,6 +428,7 @@ private void parseTransform(
         SeaTunnelTransform<?> transform =
                 FactoryUtil.createAndPrepareTransform(
                         catalogTable, readonlyConfig, classLoader, factoryId);
+        transform.setJobContext(jobConfig.getJobContext());
         long id = idGenerator.getNextId();
         String actionName =
                 JobConfigParser.createTransformActionName(
@@ -440,7 +441,6 @@ private void parseTransform(
                 tableId,
                 Collections.singletonList(
                         new Tuple2<>(transform.getProducedCatalogTable(), transformAction)));
-        return;
     }
 
     public static SeaTunnelDataType<?> getProducedType(Action action) {
@@ -592,6 +592,7 @@ private static <T> T findLast(LinkedHashMap<?, T> map) {
         SeaTunnelSink<?, ?, ?, ?> sink =
                 FactoryUtil.createAndPrepareSink(
                         catalogTable, readonlyConfig, classLoader, factoryId);
+        sink.setJobContext(jobConfig.getJobContext());
         SinkConfig actionConfig =
                 new SinkConfig(catalogTable.getTableId().toTablePath().toString());
         long id = idGenerator.getNextId();

File: seatunnel-connectors-v2/connector-rabbitmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rabbitmq/client/QueueingConsumer.java
Patch:
@@ -84,7 +84,6 @@ public void handleDelivery(
             String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body)
             throws IOException {
         checkShutdown();
-        log.info(new String(body));
         handover.produce(new Delivery(envelope, properties, body));
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-oss-jindo/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/sink/OssFileSink.java
Patch:
@@ -47,7 +47,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 CheckConfigUtil.checkAllExists(
                         pluginConfig,
                         OssConfig.FILE_PATH.key(),
-                        OssConfig.BUCKET.key(),
+                        OssConfig.ENDPOINT.key(),
                         OssConfig.ACCESS_KEY.key(),
                         OssConfig.ACCESS_SECRET.key(),
                         OssConfig.BUCKET.key());

File: seatunnel-connectors-v2/connector-file/connector-file-oss-jindo/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/sink/OssFileSinkFactory.java
Patch:
@@ -31,7 +31,7 @@
 public class OssFileSinkFactory implements TableSinkFactory {
     @Override
     public String factoryIdentifier() {
-        return FileSystemType.OSS.getFileSystemPluginName();
+        return FileSystemType.OSS_JINDO.getFileSystemPluginName();
     }
 
     @Override

File: seatunnel-connectors-v2/connector-file/connector-file-oss-jindo/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/source/OssFileSource.java
Patch:
@@ -56,7 +56,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                         pluginConfig,
                         OssConfig.FILE_PATH.key(),
                         OssConfig.FILE_FORMAT_TYPE.key(),
-                        OssConfig.BUCKET.key(),
+                        OssConfig.ENDPOINT.key(),
                         OssConfig.ACCESS_KEY.key(),
                         OssConfig.ACCESS_SECRET.key(),
                         OssConfig.BUCKET.key());

File: seatunnel-connectors-v2/connector-file/connector-file-oss-jindo/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/source/OssFileSourceFactory.java
Patch:
@@ -35,7 +35,7 @@
 public class OssFileSourceFactory implements TableSourceFactory {
     @Override
     public String factoryIdentifier() {
-        return FileSystemType.OSS.getFileSystemPluginName();
+        return FileSystemType.OSS_JINDO.getFileSystemPluginName();
     }
 
     @Override

File: seatunnel-connectors-v2/connector-file/connector-file-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/sink/OssFileSink.java
Patch:
@@ -47,7 +47,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 CheckConfigUtil.checkAllExists(
                         pluginConfig,
                         OssConfig.FILE_PATH.key(),
-                        OssConfig.BUCKET.key(),
+                        OssConfig.ENDPOINT.key(),
                         OssConfig.ACCESS_KEY.key(),
                         OssConfig.ACCESS_SECRET.key(),
                         OssConfig.BUCKET.key());

File: seatunnel-connectors-v2/connector-file/connector-file-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/source/OssFileSource.java
Patch:
@@ -55,7 +55,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                         pluginConfig,
                         OssConfig.FILE_PATH.key(),
                         OssConfig.FILE_FORMAT_TYPE.key(),
-                        OssConfig.BUCKET.key(),
+                        OssConfig.ENDPOINT.key(),
                         OssConfig.ACCESS_KEY.key(),
                         OssConfig.ACCESS_SECRET.key(),
                         OssConfig.BUCKET.key());

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCloseReason.java
Patch:
@@ -24,7 +24,8 @@ public enum CheckpointCloseReason {
     CHECKPOINT_COORDINATOR_SHUTDOWN("CheckpointCoordinator shutdown."),
     CHECKPOINT_COORDINATOR_RESET("CheckpointCoordinator reset."),
     CHECKPOINT_INSIDE_ERROR("CheckpointCoordinator inside have error."),
-    AGGREGATE_COMMIT_ERROR("Aggregate commit error.");
+    AGGREGATE_COMMIT_ERROR("Aggregate commit error."),
+    TASK_NOT_ALL_READY_WHEN_SAVEPOINT("Task not all ready, savepoint error");
 
     private final String message;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/CheckpointBarrierTriggerOperation.java
Patch:
@@ -80,7 +80,7 @@ public void run() throws Exception {
                                     .getTaskGroup()
                                     .getTask(taskLocation.getTaskID());
                     try {
-                        log.debug("CheckpointBarrierTriggerOperation [{}]" + taskLocation);
+                        log.debug("CheckpointBarrierTriggerOperation [{}]", taskLocation);
                         task.triggerBarrier(barrier);
                     } catch (Exception e) {
                         sneakyThrow(e);

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaSinkFactory.java
Patch:
@@ -49,8 +49,9 @@ public OptionRule optionRule() {
                         Config.KAFKA_CONFIG,
                         Config.ASSIGN_PARTITIONS,
                         Config.TRANSACTION_PREFIX,
-                        Config.SEMANTICS)
-                .exclusive(Config.PARTITION, Config.PARTITION_KEY_FIELDS)
+                        Config.SEMANTICS,
+                        Config.PARTITION,
+                        Config.PARTITION_KEY_FIELDS)
                 .build();
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlanGenerator.java
Patch:
@@ -224,6 +224,7 @@ public Tuple2<PhysicalPlan, Map<Integer, CheckpointPlan>> generate() {
         return edges.stream()
                 .filter(s -> s.getLeftVertex().getAction() instanceof SourceAction)
                 .map(s -> (SourceAction<?, ?, ?>) s.getLeftVertex().getAction())
+                .distinct()
                 .collect(Collectors.toList());
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/JdbcOutputFormatBuilder.java
Patch:
@@ -31,7 +31,8 @@
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.executor.JdbcBatchStatementExecutor;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.executor.SimpleBatchStatementExecutor;
 
-import com.google.common.base.Strings;
+import org.apache.commons.lang3.StringUtils;
+
 import lombok.NonNull;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
@@ -56,7 +57,7 @@ public JdbcOutputFormat build() {
         final String database = jdbcSinkConfig.getDatabase();
         final String table = jdbcSinkConfig.getTable();
         final List<String> primaryKeys = jdbcSinkConfig.getPrimaryKeys();
-        if (Strings.isNullOrEmpty(table) && Strings.isNullOrEmpty(database)) {
+        if (StringUtils.isNotBlank(jdbcSinkConfig.getSimpleSql())) {
             statementExecutorFactory =
                     () ->
                             createSimpleBufferedExecutor(

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/MapType.java
Patch:
@@ -17,15 +17,15 @@
 
 package org.apache.seatunnel.api.table.type;
 
-import com.google.common.collect.Lists;
+import org.apache.seatunnel.shade.com.google.common.collect.Lists;
 
 import java.util.Arrays;
 import java.util.List;
 import java.util.Map;
 import java.util.Objects;
 
-import static com.google.common.base.Preconditions.checkArgument;
-import static com.google.common.base.Preconditions.checkNotNull;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkArgument;
+import static org.apache.seatunnel.shade.com.google.common.base.Preconditions.checkNotNull;
 
 public class MapType<K, V> implements CompositeType<Map<K, V>> {
 

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/TestSuiteBase.java
Patch:
@@ -39,7 +39,7 @@
 @TestInstance(TestInstance.Lifecycle.PER_CLASS)
 @DisabledOnContainer(
         value = {},
-        type = {EngineType.SEATUNNEL, EngineType.SPARK},
+        type = {EngineType.SEATUNNEL},
         disabledReason = "TODO: SeaTunnel engine e2e test isn't completed")
 public abstract class TestSuiteBase {
 

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/spark/Spark2Container.java
Patch:
@@ -46,7 +46,7 @@ protected String getStartModuleName() {
 
     @Override
     protected String getDockerImage() {
-        return "bitnami/spark:2.4.6";
+        return "tyrantlucifer/spark:2.4.6";
     }
 
     @Override

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/spark/Spark3Container.java
Patch:
@@ -46,7 +46,7 @@ protected String getStartModuleName() {
 
     @Override
     protected String getDockerImage() {
-        return "bitnami/spark:3.3.0";
+        return "tyrantlucifer/spark:3.3.0";
     }
 
     @Override

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/config/JdbcOptions.java
Patch:
@@ -79,7 +79,7 @@ public interface JdbcOptions {
     Option<Boolean> GENERATE_SINK_SQL =
             Options.key("generate_sink_sql")
                     .booleanType()
-                    .defaultValue(true)
+                    .defaultValue(false)
                     .withDescription("generate sql using the database table");
 
     Option<String> XA_DATA_SOURCE_CLASS_NAME =

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/server/ServerConfigOptions.java
Patch:
@@ -49,7 +49,7 @@ public class ServerConfigOptions {
     public static final Option<Integer> JOB_METRICS_BACKUP_INTERVAL =
             Options.key("job-metrics-backup-interval")
                     .intType()
-                    .defaultValue(60)
+                    .defaultValue(10)
                     .withDescription("The interval (in seconds) of job metrics backups");
 
     public static final Option<ThreadShareMode> TASK_EXECUTION_THREAD_SHARE_MODE =

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -82,7 +82,7 @@ public class SubPlan {
     private final PipelineLocation pipelineLocation;
 
     /** The error throw by physicalVertex, should be set when physicalVertex throw error. */
-    private final AtomicReference<String> errorByPhysicalVertex = new AtomicReference<>();
+    private AtomicReference<String> errorByPhysicalVertex = new AtomicReference<>();
 
     private final ExecutorService executorService;
 
@@ -140,6 +140,8 @@ public SubPlan(
     }
 
     public synchronized PassiveCompletableFuture<PipelineExecutionState> initStateFuture() {
+        // reset errorByPhysicalVertex when restore pipeline
+        errorByPhysicalVertex = new AtomicReference<>();
         physicalVertexList.forEach(
                 physicalVertex -> {
                     addPhysicalVertexCallBack(physicalVertex.initStateFuture());

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -212,6 +212,9 @@ private void handleCoordinatorError(String message, Throwable e, CheckpointClose
     }
 
     private void handleCoordinatorError(CheckpointCloseReason reason, Throwable e) {
+        if (checkpointCoordinatorFuture.isDone()) {
+            return;
+        }
         CheckpointException checkpointException = new CheckpointException(reason, e);
         cleanPendingCheckpoint(reason);
         checkpointCoordinatorFuture.complete(

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/MultipleTableJobConfigParser.java
Patch:
@@ -132,6 +132,9 @@ public ImmutablePair<List<Action>, Set<URL>> parse() {
         } catch (IOException e) {
             LOGGER.info(e);
         }
+        if (!commonPluginJars.isEmpty()) {
+            connectorJars.addAll(commonPluginJars);
+        }
         ClassLoader classLoader = new SeaTunnelChildFirstClassLoader(connectorJars);
         Thread.currentThread().setContextClassLoader(classLoader);
         List<? extends Config> sourceConfigs =

File: seatunnel-transforms-v2/src/test/java/org/apache/seatunnel/transform/ReplaceTransformFactoryTest.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.transform;
 
+import org.apache.seatunnel.transform.replace.ReplaceTransformFactory;
+
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
 

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/MultipleTableJobConfigParser.java
Patch:
@@ -316,7 +316,9 @@ public void parseTransforms(
             return;
         }
         Queue<Config> configList = new LinkedList<>(transformConfigs);
-        parseTransform(configList, classLoader, tableWithActionMap);
+        while (!configList.isEmpty()) {
+            parseTransform(configList, classLoader, tableWithActionMap);
+        }
     }
 
     private void parseTransform(

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaConsumerThread.java
Patch:
@@ -57,7 +57,7 @@ public void run() {
                     if (task != null) {
                         task.accept(consumer);
                     }
-                } catch (InterruptedException e) {
+                } catch (Exception e) {
                     throw new KafkaConnectorException(
                             KafkaConnectorErrorCode.CONSUME_THREAD_RUN_ERROR, e);
                 }

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaSinkCommitter.java
Patch:
@@ -22,7 +22,6 @@
 import org.apache.seatunnel.api.sink.SinkCommitter;
 import org.apache.seatunnel.connectors.seatunnel.kafka.state.KafkaCommitInfo;
 
-import org.apache.kafka.clients.consumer.ConsumerConfig;
 import org.apache.kafka.clients.producer.KafkaProducer;
 import org.apache.kafka.clients.producer.ProducerConfig;
 
@@ -83,8 +82,6 @@ public void abort(List<KafkaCommitInfo> commitInfos) {
             this.kafkaProducer.setTransactionalId(commitInfo.getTransactionId());
         } else {
             Properties kafkaProperties = commitInfo.getKafkaProperties();
-            kafkaProperties.setProperty(
-                    ConsumerConfig.CLIENT_ID_CONFIG, "sink-committer-" + this.hashCode());
             kafkaProperties.setProperty(
                     ProducerConfig.TRANSACTIONAL_ID_CONFIG, commitInfo.getTransactionId());
             kafkaProducer =

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaTransactionSender.java
Patch:
@@ -122,6 +122,7 @@ public void close() {
 
     private KafkaInternalProducer<K, V> getTransactionProducer(
             Properties properties, String transactionId) {
+        close();
         Properties transactionProperties = (Properties) properties.clone();
         transactionProperties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, transactionId);
         KafkaInternalProducer<K, V> transactionProducer =

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/JobConfigParser.java
Patch:
@@ -49,6 +49,7 @@
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
+import java.util.LinkedHashSet;
 import java.util.List;
 import java.util.Set;
 import java.util.stream.Collectors;
@@ -136,7 +137,7 @@ public Tuple2<CatalogTable, Action> parseTransform(
                     inputVertices.stream()
                             .flatMap(Collection::stream)
                             .map(Tuple2::_2)
-                            .collect(Collectors.toSet());
+                            .collect(Collectors.toCollection(LinkedHashSet::new));
             checkProducedTypeEquals(inputActions);
             SinkAction<?, ?, ?, ?> sinkAction =
                     parseSink(

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/reader/PulsarSplitReaderThread.java
Patch:
@@ -81,6 +81,7 @@ public void open() throws PulsarClientException {
         if (split.getLatestConsumedId() == null) {
             startCursor.seekPosition(consumer);
         }
+        this.running = true;
     }
 
     @Override

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/TableSinkFactory.java
Patch:
@@ -38,6 +38,7 @@ public interface TableSinkFactory<IN, StateT, CommitInfoT, AggregatedCommitInfoT
      */
     default TableSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT> createSink(
             TableFactoryContext context) {
-        throw new UnsupportedOperationException("unsupported now");
+        throw new UnsupportedOperationException(
+                "The Factory has not been implemented and the deprecated Plugin will be used.");
     }
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/TableSourceFactory.java
Patch:
@@ -36,7 +36,8 @@ public interface TableSourceFactory extends Factory {
      */
     default <T, SplitT extends SourceSplit, StateT extends Serializable>
             TableSource<T, SplitT, StateT> createSource(TableFactoryContext context) {
-        throw new UnsupportedOperationException("unsupported now");
+        throw new UnsupportedOperationException(
+                "The Factory has not been implemented and the deprecated Plugin will be used.");
     }
 
     /**

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/TableTransformFactory.java
Patch:
@@ -33,6 +33,7 @@ public interface TableTransformFactory extends Factory {
      * @return
      */
     default <T> TableTransform<T> createTransform(TableFactoryContext context) {
-        throw new UnsupportedOperationException("unsupported now");
+        throw new UnsupportedOperationException(
+                "The Factory has not been implemented and the deprecated Plugin will be used.");
     }
 }

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/LogicalDagGeneratorTest.java
Patch:
@@ -25,7 +25,7 @@
 import org.apache.seatunnel.engine.core.dag.actions.Action;
 import org.apache.seatunnel.engine.core.dag.logical.LogicalDag;
 import org.apache.seatunnel.engine.core.dag.logical.LogicalDagGenerator;
-import org.apache.seatunnel.engine.core.parse.JobConfigParser;
+import org.apache.seatunnel.engine.core.parse.MultipleTableJobConfigParser;
 
 import org.apache.commons.lang3.tuple.ImmutablePair;
 
@@ -49,14 +49,14 @@ public void testLogicalGenerator() {
 
         IdGenerator idGenerator = new IdGenerator();
         ImmutablePair<List<Action>, Set<URL>> immutablePair =
-                new JobConfigParser(filePath, idGenerator, jobConfig).parse();
+                new MultipleTableJobConfigParser(filePath, idGenerator, jobConfig).parse();
 
         LogicalDagGenerator logicalDagGenerator =
                 new LogicalDagGenerator(immutablePair.getLeft(), jobConfig, idGenerator);
         LogicalDag logicalDag = logicalDagGenerator.generate();
         JsonObject logicalDagJson = logicalDag.getLogicalDagAsJson();
         String result =
-                "{\"vertices\":[{\"id\":2,\"name\":\"Source[0]-FakeSource-fake(id=2)\",\"parallelism\":3},{\"id\":3,\"name\":\"Source[1]-FakeSource-fake(id=3)\",\"parallelism\":3},{\"id\":1,\"name\":\"Sink[0]-LocalFile-fake(id=1)\",\"parallelism\":6}],\"edges\":[{\"inputVertex\":\"Source[0]-FakeSource-fake\",\"targetVertex\":\"Sink[0]-LocalFile-fake\"},{\"inputVertex\":\"Source[1]-FakeSource-fake\",\"targetVertex\":\"Sink[0]-LocalFile-fake\"}]}";
+                "{\"vertices\":[{\"id\":1,\"name\":\"Source[0]-FakeSource-fake(id=1)\",\"parallelism\":3},{\"id\":2,\"name\":\"Source[0]-FakeSource-fake2(id=2)\",\"parallelism\":3},{\"id\":3,\"name\":\"Sink[0]-LocalFile-default-identifier(id=3)\",\"parallelism\":3}],\"edges\":[{\"inputVertex\":\"Source[0]-FakeSource-fake\",\"targetVertex\":\"Sink[0]-LocalFile-default-identifier\"},{\"inputVertex\":\"Source[0]-FakeSource-fake2\",\"targetVertex\":\"Sink[0]-LocalFile-default-identifier\"}]}";
         Assertions.assertEquals(result, logicalDagJson.toString());
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/TestUtils.java
Patch:
@@ -34,7 +34,7 @@
 import org.apache.seatunnel.engine.core.dag.logical.LogicalDagGenerator;
 import org.apache.seatunnel.engine.core.dag.logical.LogicalEdge;
 import org.apache.seatunnel.engine.core.dag.logical.LogicalVertex;
-import org.apache.seatunnel.engine.core.parse.JobConfigParser;
+import org.apache.seatunnel.engine.core.parse.MultipleTableJobConfigParser;
 
 import org.apache.commons.lang3.tuple.ImmutablePair;
 
@@ -109,7 +109,7 @@ public static LogicalDag createTestLogicalPlan(
 
         IdGenerator idGenerator = new IdGenerator();
         ImmutablePair<List<Action>, Set<URL>> immutablePair =
-                new JobConfigParser(filePath, idGenerator, jobConfig).parse();
+                new MultipleTableJobConfigParser(filePath, idGenerator, jobConfig).parse();
 
         LogicalDagGenerator logicalDagGenerator =
                 new LogicalDagGenerator(immutablePair.getLeft(), jobConfig, idGenerator);

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/master/JobHistoryServiceTest.java
Patch:
@@ -40,9 +40,9 @@
 @TestInstance(TestInstance.Lifecycle.PER_CLASS)
 class JobHistoryServiceTest extends AbstractSeaTunnelServerTest {
 
-    private static final Long JOB_1 = 1L;
-    private static final Long JOB_2 = 2L;
-    private static final Long JOB_3 = 3L;
+    private static final Long JOB_1 = System.currentTimeMillis() + 1L;
+    private static final Long JOB_2 = System.currentTimeMillis() + 2L;
+    private static final Long JOB_3 = System.currentTimeMillis() + 3L;
 
     @Test
     public void testlistJobState() throws Exception {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/JdbcSource.java
Patch:
@@ -151,7 +151,8 @@ private SeaTunnelRowType initTableField(Connection conn) {
             ResultSetMetaData resultSetMetaData =
                     jdbcDialect.getResultSetMetaData(conn, jdbcSourceConfig);
             for (int i = 1; i <= resultSetMetaData.getColumnCount(); i++) {
-                fieldNames.add(resultSetMetaData.getColumnName(i));
+                // Support AS syntax
+                fieldNames.add(resultSetMetaData.getColumnLabel(i));
                 seaTunnelDataTypes.add(jdbcDialectTypeMapper.mapping(resultSetMetaData, i));
             }
         } catch (Exception e) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/PendingCheckpoint.java
Patch:
@@ -165,7 +165,8 @@ private CompletedCheckpoint toCompletedCheckpoint() {
     }
 
     public void abortCheckpoint(CheckpointCloseReason closedReason, @Nullable Throwable cause) {
-        if (closedReason.equals(CheckpointCloseReason.CHECKPOINT_COORDINATOR_RESET)) {
+        if (closedReason.equals(CheckpointCloseReason.CHECKPOINT_COORDINATOR_RESET)
+                || closedReason.equals(CheckpointCloseReason.PIPELINE_END)) {
             completableFuture.complete(null);
         } else {
             this.failureCause = new CheckpointException(closedReason, cause);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/utils/MySqlUtils.java
Patch:
@@ -339,6 +339,7 @@ public static String quote(TableId tableId) {
     private static PreparedStatement initStatement(JdbcConnection jdbc, String sql, int fetchSize)
             throws SQLException {
         final Connection connection = jdbc.connection();
+        // Add MySQL metadata locks to prevent modification of table structure.
         connection.setAutoCommit(false);
         final PreparedStatement statement =
                 connection.prepareStatement(

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/FactoryUtil.java
Patch:
@@ -156,8 +156,7 @@ public static Optional<Catalog> createOptionalCatalog(
     }
 
     public static <T extends Factory> URL getFactoryUrl(T factory) {
-        URL jarUrl = factory.getClass().getProtectionDomain().getCodeSource().getLocation();
-        return jarUrl;
+        return factory.getClass().getProtectionDomain().getCodeSource().getLocation();
     }
 
     public static <T extends Factory> Optional<T> discoverOptionalFactory(

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/ExceptionUtils.java
Patch:
@@ -24,6 +24,9 @@ public class ExceptionUtils {
     private ExceptionUtils() {}
 
     public static String getMessage(Throwable e) {
+        if (e == null) {
+            return "";
+        }
         try (StringWriter sw = new StringWriter();
                 PrintWriter pw = new PrintWriter(sw)) {
             // Output the error stack information to the printWriter

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/server/ServerConfigOptions.java
Patch:
@@ -49,7 +49,7 @@ public class ServerConfigOptions {
     public static final Option<Integer> JOB_METRICS_BACKUP_INTERVAL =
             Options.key("job-metrics-backup-interval")
                     .intType()
-                    .defaultValue(3)
+                    .defaultValue(60)
                     .withDescription("The interval (in seconds) of job metrics backups");
 
     public static final Option<ThreadShareMode> TASK_EXECUTION_THREAD_SHARE_MODE =

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/service/slot/DefaultSlotService.java
Patch:
@@ -47,7 +47,7 @@
 public class DefaultSlotService implements SlotService {
 
     private static final ILogger LOGGER = Logger.getLogger(DefaultSlotService.class);
-    private static final long DEFAULT_HEARTBEAT_TIMEOUT = 2000;
+    private static final long DEFAULT_HEARTBEAT_TIMEOUT = 5000;
     private final NodeEngineImpl nodeEngine;
 
     private AtomicReference<ResourceProfile> unassignedResource;

File: seatunnel-core/seatunnel-starter/src/main/java/org/apache/seatunnel/core/starter/seatunnel/args/ClientCommandArgs.java
Patch:
@@ -61,7 +61,7 @@ public class ClientCommandArgs extends AbstractCommandArgs {
     @Parameter(
             names = {"-cn", "--cluster"},
             description = "The name of cluster")
-    private String clusterName = "seatunnel_default_cluster";
+    private String clusterName;
 
     @Parameter(
             names = {"-j", "--job-id"},

File: seatunnel-core/seatunnel-starter/src/main/java/org/apache/seatunnel/core/starter/seatunnel/args/ServerCommandArgs.java
Patch:
@@ -31,7 +31,7 @@ public class ServerCommandArgs extends CommandArgs {
     @Parameter(
             names = {"-cn", "--cluster"},
             description = "The name of cluster")
-    private String clusterName = "seatunnel_default_cluster";
+    private String clusterName;
 
     @Override
     public Command<?> buildCommand() {

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/SeaTunnelConfig.java
Patch:
@@ -46,7 +46,6 @@ public SeaTunnelConfig() {
                 .getJoin()
                 .getMulticastConfig()
                 .setMulticastPort(Constant.DEFAULT_SEATUNNEL_MULTICAST_PORT);
-        hazelcastConfig.setClusterName(Constant.DEFAULT_SEATUNNEL_CLUSTER_NAME);
         hazelcastConfig
                 .getHotRestartPersistenceConfig()
                 .setBaseDir(new File(seatunnelHome(), "recovery").getAbsoluteFile());

File: seatunnel-e2e/seatunnel-transforms-v2-e2e/seatunnel-transforms-v2-e2e-part-2/src/test/java/org/apache/seatunnel/e2e/transform/TestSparkDateTimeTransformIT.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.e2e.transform;
 
+import org.apache.seatunnel.e2e.common.TestSuiteBase;
 import org.apache.seatunnel.e2e.common.container.EngineType;
 import org.apache.seatunnel.e2e.common.container.TestContainer;
 import org.apache.seatunnel.e2e.common.junit.DisabledOnContainer;

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/exception/ElasticsearchConnectorErrorCode.java
Patch:
@@ -28,6 +28,7 @@ public enum ElasticsearchConnectorErrorCode implements SeaTunnelErrorCode {
     LIST_INDEX_FAILED("ELASTICSEARCH-05", "List elasticsearch index failed"),
     DROP_INDEX_FAILED("ELASTICSEARCH-06", "Drop elasticsearch index failed"),
     CREATE_INDEX_FAILED("ELASTICSEARCH-07", "Create elasticsearch index failed"),
+    ES_FIELD_TYPE_NOT_SUPPORT("ELASTICSEARCH-08", "Not support the elasticsearch field type");
     ;
 
     private final String code;

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/Constants.java
Patch:
@@ -23,6 +23,8 @@ public final class Constants {
 
     public static final String LOGO = "SeaTunnel";
 
+    public static final String ENV = "env";
+
     public static final String SOURCE = "source";
 
     public static final String TRANSFORM = "transform";

File: seatunnel-config/seatunnel-config-shade/src/test/java/org/apache/seatunnel/config/utils/FileUtils.java
Patch:
@@ -24,8 +24,7 @@
 
 public final class FileUtils {
 
-    private FileUtils() {
-    }
+    private FileUtils() {}
 
     // get file from classpath, resources folder
     public static File getFileFromResources(String fileName) throws URISyntaxException {
@@ -35,5 +34,4 @@ public static File getFileFromResources(String fileName) throws URISyntaxExcepti
         }
         return Paths.get(resource.toURI()).toFile();
     }
-
 }

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/exception/SelectDBConnectorException.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.exception;
+package org.apache.seatunnel.connectors.selectdb.exception;
 
 import org.apache.seatunnel.common.exception.SeaTunnelErrorCode;
 import org.apache.seatunnel.common.exception.SeaTunnelRuntimeException;

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/rest/BaseResponse.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.rest;
+package org.apache.seatunnel.connectors.selectdb.rest;
 
 import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
 

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/rest/CopyIntoResp.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.rest;
+package org.apache.seatunnel.connectors.selectdb.rest;
 
 import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
 

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/serialize/SelectDBSerializer.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.serialize;
+package org.apache.seatunnel.connectors.selectdb.serialize;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/sink/committer/SelectDBCommitInfo.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.sink.committer;
+package org.apache.seatunnel.connectors.selectdb.sink.committer;
 
 import lombok.EqualsAndHashCode;
 import lombok.Getter;

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/sink/committer/SelectDBCommitInfoSerializer.java
Patch:
@@ -15,7 +15,7 @@
 // specific language governing permissions and limitations
 // under the License.
 
-package org.apache.seatunnel.connector.selectdb.sink.committer;
+package org.apache.seatunnel.connectors.selectdb.sink.committer;
 
 import org.apache.seatunnel.api.serialization.Serializer;
 

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/sink/writer/CopySQLBuilder.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.sink.writer;
+package org.apache.seatunnel.connectors.selectdb.sink.writer;
 
-import org.apache.seatunnel.connector.selectdb.config.SelectDBConfig;
+import org.apache.seatunnel.connectors.selectdb.config.SelectDBConfig;
 
 import java.util.List;
 import java.util.Map;
@@ -34,7 +34,7 @@ public class CopySQLBuilder {
     public CopySQLBuilder(SelectDBConfig selectdbConfig, List<String> fileList) {
         this.selectdbConfig = selectdbConfig;
         this.fileList = fileList;
-        this.properties = selectdbConfig.getStreamLoadProps();
+        this.properties = selectdbConfig.getStageLoadProps();
     }
 
     public String buildCopySQL() {

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/sink/writer/LoadConstants.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.sink.writer;
+package org.apache.seatunnel.connectors.selectdb.sink.writer;
 
 /** Constants for load. */
 public class LoadConstants {

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/sink/writer/LoadStatus.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.sink.writer;
+package org.apache.seatunnel.connectors.selectdb.sink.writer;
 
 /** enum of LoadStatus. */
 public class LoadStatus {

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/sink/writer/SelectDBSinkStateSerializer.java
Patch:
@@ -15,7 +15,7 @@
 // specific language governing permissions and limitations
 // under the License.
 
-package org.apache.seatunnel.connector.selectdb.sink.writer;
+package org.apache.seatunnel.connectors.selectdb.sink.writer;
 
 import org.apache.seatunnel.api.serialization.Serializer;
 
@@ -43,7 +43,8 @@ public SelectDBSinkState deserialize(byte[] serialized) throws IOException {
         try (final ByteArrayInputStream bais = new ByteArrayInputStream(serialized);
                 final DataInputStream in = new DataInputStream(bais)) {
             final String labelPrefix = in.readUTF();
-            return new SelectDBSinkState(labelPrefix);
+            final long checkpointId = in.readLong();
+            return new SelectDBSinkState(labelPrefix, checkpointId);
         }
     }
 }

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/util/HttpPostBuilder.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.util;
+package org.apache.seatunnel.connectors.selectdb.util;
 
 import org.apache.commons.codec.binary.Base64;
 import org.apache.http.HttpEntity;

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/util/HttpPutBuilder.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.util;
+package org.apache.seatunnel.connectors.selectdb.util;
 
 import org.apache.commons.codec.binary.Base64;
 import org.apache.http.HttpEntity;

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/util/HttpUtil.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.util;
+package org.apache.seatunnel.connectors.selectdb.util;
 
 import org.apache.http.impl.client.CloseableHttpClient;
 import org.apache.http.impl.client.HttpClientBuilder;

File: seatunnel-connectors-v2/connector-selectdb-cloud/src/main/java/org/apache/seatunnel/connectors/selectdb/util/ResponseUtil.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connector.selectdb.util;
+package org.apache.seatunnel.connectors.selectdb.util;
 
 import java.util.regex.Pattern;
 

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/exception/DorisConnectorErrorCode.java
Patch:
@@ -20,7 +20,9 @@
 import org.apache.seatunnel.common.exception.SeaTunnelErrorCode;
 
 public enum DorisConnectorErrorCode implements SeaTunnelErrorCode {
-    WRITE_RECORDS_FAILED("DORIS-01", "Writing records to Doris failed.");
+    STREAM_LOAD_FAILED("Doris-01", "stream load error"),
+    COMMIT_FAILED("Doris-02", "commit error"),
+    REST_SERVICE_FAILED("Doris-03", "rest service error");
 
     private final String code;
     private final String description;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCloseReason.java
Patch:
@@ -23,7 +23,8 @@ public enum CheckpointCloseReason {
     CHECKPOINT_COORDINATOR_COMPLETED("CheckpointCoordinator completed."),
     CHECKPOINT_COORDINATOR_SHUTDOWN("CheckpointCoordinator shutdown."),
     CHECKPOINT_COORDINATOR_RESET("CheckpointCoordinator reset."),
-    CHECKPOINT_INSIDE_ERROR("CheckpointCoordinator inside have error.");
+    CHECKPOINT_INSIDE_ERROR("CheckpointCoordinator inside have error."),
+    AGGREGATE_COMMIT_ERROR("Aggregate commit error.");
 
     private final String message;
 

File: seatunnel-connectors-v2/connector-s3-redshift/src/main/java/org/apache/seatunnel/connectors/seatunnel/redshift/sink/S3RedshiftSink.java
Patch:
@@ -53,6 +53,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 CheckConfigUtil.checkAllExists(
                         pluginConfig,
                         S3Config.S3_BUCKET.key(),
+                        S3Config.S3A_AWS_CREDENTIALS_PROVIDER.key(),
                         S3RedshiftConfig.JDBC_URL.key(),
                         S3RedshiftConfig.JDBC_USER.key(),
                         S3RedshiftConfig.JDBC_PASSWORD.key(),

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/NotifyTaskStartOperation.java
Patch:
@@ -59,7 +59,9 @@ public void run() throws Exception {
                         true,
                         exception ->
                                 exception instanceof TaskGroupContextNotFoundException
-                                        && !server.taskIsEnded(taskLocation.getTaskGroupLocation()),
+                                        || exception instanceof NullPointerException
+                                                && !server.taskIsEnded(
+                                                        taskLocation.getTaskGroupLocation()),
                         Constant.OPERATION_RETRY_SLEEP));
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -319,13 +319,13 @@ public void run() {
         }
     }
 
-    public void handleCheckpointError(long pipelineId, Throwable e) {
+    public void handleCheckpointError(long pipelineId) {
         this.physicalPlan
                 .getPipelineList()
                 .forEach(
                         pipeline -> {
                             if (pipeline.getPipelineLocation().getPipelineId() == pipelineId) {
-                                pipeline.handleCheckpointError(e);
+                                pipeline.handleCheckpointError();
                             }
                         });
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManager.java
Patch:
@@ -151,7 +151,7 @@ public CheckpointManager(
      * After the savepoint is triggered, it will cause the job to stop automatically.
      */
     @SuppressWarnings("unchecked")
-    public PassiveCompletableFuture<CompletedCheckpoint>[] triggerSavepoints() {
+    public PassiveCompletableFuture<CompletedCheckpoint>[] triggerSavePoints() {
         return coordinatorMap
                 .values()
                 .parallelStream()

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -596,7 +596,7 @@ public void updateTaskExecutionState(TaskExecutionState taskExecutionState) {
     /** Execute savePoint, which will cause the job to end. */
     public CompletableFuture<Void> savePoint() {
         PassiveCompletableFuture<CompletedCheckpoint>[] passiveCompletableFutures =
-                checkpointManager.triggerSavepoints();
+                checkpointManager.triggerSavePoints();
         return CompletableFuture.allOf(passiveCompletableFutures);
     }
 

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-api/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/api/AbstractCheckpointStorage.java
Patch:
@@ -115,6 +115,9 @@ public PipelineState deserializeCheckPointData(byte[] data) throws IOException {
 
     public void setStorageNameSpace(String storageNameSpace) {
         if (storageNameSpace != null) {
+            if (!storageNameSpace.endsWith(DEFAULT_CHECKPOINT_FILE_PATH_SPLIT)) {
+                storageNameSpace = storageNameSpace + DEFAULT_CHECKPOINT_FILE_PATH_SPLIT;
+            }
             this.storageNameSpace = storageNameSpace;
         }
     }

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/config/Config.java
Patch:
@@ -71,7 +71,7 @@ public class Config {
     public static final Option<String> CONSUMER_GROUP =
             Options.key("consumer.group")
                     .stringType()
-                    .noDefaultValue()
+                    .defaultValue("SeaTunnel-Consumer-Group")
                     .withDescription(
                             "Kafka consumer group id, used to distinguish different consumer groups.");
 

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSource.java
Patch:
@@ -79,8 +79,6 @@ public class KafkaSource
         implements SeaTunnelSource<SeaTunnelRow, KafkaSourceSplit, KafkaSourceState>,
                 SupportParallelism {
 
-    private static final String DEFAULT_CONSUMER_GROUP = "SeaTunnel-Consumer-Group";
-
     private final ConsumerMetadata metadata = new ConsumerMetadata();
     private DeserializationSchema<SeaTunnelRow> deserializationSchema;
     private SeaTunnelRowType typeInfo;
@@ -113,14 +111,16 @@ public void prepare(Config config) throws PrepareFailException {
         this.metadata.setTopic(config.getString(TOPIC.key()));
         if (config.hasPath(PATTERN.key())) {
             this.metadata.setPattern(config.getBoolean(PATTERN.key()));
+        } else {
+            this.metadata.setPattern(PATTERN.defaultValue());
         }
         this.metadata.setBootstrapServers(config.getString(BOOTSTRAP_SERVERS.key()));
         this.metadata.setProperties(new Properties());
 
         if (config.hasPath(CONSUMER_GROUP.key())) {
             this.metadata.setConsumerGroup(config.getString(CONSUMER_GROUP.key()));
         } else {
-            this.metadata.setConsumerGroup(DEFAULT_CONSUMER_GROUP);
+            this.metadata.setConsumerGroup(CONSUMER_GROUP.defaultValue());
         }
 
         if (config.hasPath(COMMIT_ON_CHECKPOINT.key())) {

File: seatunnel-connectors-v2/connector-maxcompute/src/main/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/sink/MaxcomputeSink.java
Patch:
@@ -63,6 +63,6 @@ public SeaTunnelDataType<SeaTunnelRow> getConsumedType() {
 
     @Override
     public AbstractSinkWriter<SeaTunnelRow, Void> createWriter(SinkWriter.Context context) {
-        return new MaxcomputeWriter(this.typeInfo, this.pluginConfig);
+        return new MaxcomputeWriter(this.pluginConfig);
     }
 }

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/config/Config.java
Patch:
@@ -33,7 +33,7 @@ public class Config {
 
     public static final String TEXT_FORMAT = "text";
 
-    public static final String CANNAL_FORMAT = "canal-json";
+    public static final String CANAL_FORMAT = "canal-json";
 
     /** The default field delimiter is “,” */
     public static final String DEFAULT_FIELD_DELIMITER = ",";

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/serialize/DefaultSeaTunnelRowSerializer.java
Patch:
@@ -32,7 +32,7 @@
 import java.util.List;
 import java.util.function.Function;
 
-import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.CANNAL_FORMAT;
+import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.CANAL_FORMAT;
 import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.DEFAULT_FORMAT;
 import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.TEXT_FORMAT;
 
@@ -88,7 +88,7 @@ private static SerializationSchema createSerializationSchema(
                         .seaTunnelRowType(rowType)
                         .delimiter(delimiter)
                         .build();
-            case CANNAL_FORMAT:
+            case CANAL_FORMAT:
                 return new CanalJsonSerializationSchema(rowType);
             default:
                 throw new SeaTunnelJsonFormatException(

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSource.java
Patch:
@@ -57,7 +57,7 @@
 import java.util.Properties;
 
 import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.BOOTSTRAP_SERVERS;
-import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.CANNAL_FORMAT;
+import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.CANAL_FORMAT;
 import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.COMMIT_ON_CHECKPOINT;
 import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.CONSUMER_GROUP;
 import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.DEFAULT_FIELD_DELIMITER;
@@ -246,7 +246,7 @@ private void setDeserialization(Config config) {
                                     .delimiter(delimiter)
                                     .build();
                     break;
-                case CANNAL_FORMAT:
+                case CANAL_FORMAT:
                     deserializationSchema =
                             CanalJsonDeserializationSchema.builder(typeInfo)
                                     .setIgnoreParseErrors(true)

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/common/SeaTunnelAPIErrorCode.java
Patch:
@@ -26,6 +26,8 @@ public enum SeaTunnelAPIErrorCode implements SeaTunnelErrorCode {
     DATABASE_NOT_EXISTED("API-04", "Database not existed"),
     TABLE_NOT_EXISTED("API-05", "Table not existed"),
     FACTORY_INITIALIZE_FAILED("API-06", "Factory initialize failed"),
+    DATABASE_ALREADY_EXISTED("API-07", "Database already existed"),
+    TABLE_ALREADY_EXISTED("API-08", "Table already existed"),
     ;
 
     private final String code;

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/env/EnvOptionRule.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.api.env;
 
+import org.apache.seatunnel.api.common.CommonOptions;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 
 public class EnvOptionRule {
@@ -26,7 +27,7 @@ public static OptionRule getEnvOptionRules() {
                 .required(EnvCommonOptions.JOB_MODE)
                 .optional(
                         EnvCommonOptions.JOB_NAME,
-                        EnvCommonOptions.PARALLELISM,
+                        CommonOptions.PARALLELISM,
                         EnvCommonOptions.JARS,
                         EnvCommonOptions.CHECKPOINT_INTERVAL,
                         EnvCommonOptions.CUSTOM_PARAMETERS)

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/catalog/TableIdentifier.java
Patch:
@@ -47,7 +47,7 @@ public String getDatabaseName() {
         return databaseName;
     }
 
-    public String gettableName() {
+    public String getTableName() {
         return tableName;
     }
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/connector/TableSource.java
Patch:
@@ -22,6 +22,7 @@
 
 import java.io.Serializable;
 
+/** Used to support authentication and processing of {@link SupportReadingMetadata} */
 public interface TableSource<T, SplitT extends SourceSplit, StateT extends Serializable> {
 
     SeaTunnelSource<T, SplitT, StateT> createSource();

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelRow.java
Patch:
@@ -27,7 +27,7 @@
 public final class SeaTunnelRow implements Serializable {
     private static final long serialVersionUID = -1L;
     /** Table identifier, used for the source connector that {@link SupportMultipleTable}. */
-    private int tableId = -1;
+    private String tableId = "";
     /** The kind of change that a row describes in a changelog. */
     private RowKind kind = RowKind.INSERT;
     /** The array to store the actual internal format values. */
@@ -45,7 +45,7 @@ public void setField(int pos, Object value) {
         this.fields[pos] = value;
     }
 
-    public void setTableId(int tableId) {
+    public void setTableId(String tableId) {
         this.tableId = tableId;
     }
 
@@ -57,7 +57,7 @@ public int getArity() {
         return fields.length;
     }
 
-    public int getTableId() {
+    public String getTableId() {
         return tableId;
     }
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SqlType.java
Patch:
@@ -35,5 +35,6 @@ public enum SqlType {
     DATE,
     TIME,
     TIMESTAMP,
-    ROW;
+    ROW,
+    MULTIPLE_ROW;
 }

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/FileUtils.java
Patch:
@@ -115,8 +115,8 @@ public static void createNewFile(String filePath) {
      * @return The file line number
      */
     public static Long getFileLineNumber(@NonNull String filePath) {
-        try {
-            return Files.lines(Paths.get(filePath)).count();
+        try (Stream<String> lines = Files.lines(Paths.get(filePath))) {
+            return lines.count();
         } catch (IOException e) {
             throw new SeaTunnelRuntimeException(
                     CommonErrorCode.FILE_OPERATION_FAILED,

File: seatunnel-connectors-v2/connector-amazondynamodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/amazondynamodb/config/AmazonDynamoDBSourceOptions.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 
 import lombok.AllArgsConstructor;
 import lombok.Data;
@@ -51,8 +51,8 @@ public AmazonDynamoDBSourceOptions(Config config) {
         this.accessKeyId = config.getString(AmazonDynamoDBConfig.ACCESS_KEY_ID.key());
         this.secretAccessKey = config.getString(AmazonDynamoDBConfig.SECRET_ACCESS_KEY.key());
         this.table = config.getString(AmazonDynamoDBConfig.TABLE.key());
-        if (config.hasPath(SeaTunnelSchema.SCHEMA.key())) {
-            this.schema = config.getConfig(SeaTunnelSchema.SCHEMA.key());
+        if (config.hasPath(CatalogTableUtil.SCHEMA.key())) {
+            this.schema = config.getConfig(CatalogTableUtil.SCHEMA.key());
         }
         if (config.hasPath(AmazonDynamoDBConfig.BATCH_SIZE.key())) {
             this.batchSize = config.getInt(AmazonDynamoDBConfig.BATCH_SIZE.key());

File: seatunnel-connectors-v2/connector-amazondynamodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/amazondynamodb/source/AmazonDynamoDBSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 
 import com.google.auto.service.AutoService;
 
@@ -47,7 +47,7 @@ public OptionRule optionRule() {
                         ACCESS_KEY_ID,
                         SECRET_ACCESS_KEY,
                         TABLE,
-                        SeaTunnelSchema.SCHEMA)
+                        CatalogTableUtil.SCHEMA)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/JdbcConnectionPoolFactory.java
Patch:
@@ -36,7 +36,7 @@ public HikariDataSource createPooledDataSource(JdbcSourceConfig sourceConfig) {
         int port = sourceConfig.getPort();
 
         config.setPoolName(CONNECTION_POOL_PREFIX + hostName + ":" + port);
-        config.setJdbcUrl(getJdbcUrl(sourceConfig));
+        config.setJdbcUrl(sourceConfig.getOriginUrl());
         config.setUsername(sourceConfig.getUsername());
         config.setPassword(sourceConfig.getPassword());
         config.setMinimumIdle(MINIMUM_POOL_SIZE);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/JdbcConnectionPools.java
Patch:
@@ -52,7 +52,7 @@ public HikariDataSource getOrCreateConnectionPool(
             ConnectionPoolId poolId, JdbcSourceConfig sourceConfig) {
         synchronized (pools) {
             if (!pools.containsKey(poolId)) {
-                LOG.info("Create and register connection pool {}", poolId);
+                LOG.debug("Create and register connection pool {}", poolId);
                 pools.put(poolId, JDBCCONNECTIONPOOLFACTORY.createPooledDataSource(sourceConfig));
             }
             return pools.get(poolId);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/IncrementalSourceEnumerator.java
Patch:
@@ -101,7 +101,7 @@ public void registerReader(int subtaskId) {
     @Override
     public void handleSourceEvent(int subtaskId, SourceEvent sourceEvent) {
         if (sourceEvent instanceof CompletedSnapshotSplitsReportEvent) {
-            LOG.info(
+            LOG.debug(
                     "The enumerator receives completed split watermarks(log offset) {} from subtask {}.",
                     sourceEvent,
                     subtaskId);
@@ -158,7 +158,7 @@ private void assignSplits() {
                 final SourceSplitBase sourceSplit = split.get();
                 context.assignSplit(nextAwaiting, sourceSplit);
                 awaitingReader.remove();
-                LOG.info("Assign split {} to subtask {}", sourceSplit, nextAwaiting);
+                LOG.debug("Assign split {} to subtask {}", sourceSplit, nextAwaiting);
             } else {
                 // there is no available splits by now, skip assigning
                 break;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/external/IncrementalSourceScanFetcher.java
Patch:
@@ -31,8 +31,8 @@
 import lombok.extern.slf4j.Slf4j;
 
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.Iterator;
+import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ExecutorService;
@@ -119,7 +119,7 @@ public Iterator<SourceRecords> pollSplitRecords() throws InterruptedException {
             boolean reachChangeLogEnd = false;
             SourceRecord lowWatermark = null;
             SourceRecord highWatermark = null;
-            Map<Struct, SourceRecord> outputBuffer = new HashMap<>();
+            Map<Struct, SourceRecord> outputBuffer = new LinkedHashMap<>();
             while (!reachChangeLogEnd) {
                 checkReadException();
                 List<DataChangeEvent> batch = queue.poll();

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/MySqlSourceConfig.java
Patch:
@@ -49,6 +49,7 @@ public MySqlSourceConfig(
             int port,
             String username,
             String password,
+            String originUrl,
             int fetchSize,
             String serverTimeZone,
             long connectTimeoutMillis,
@@ -68,6 +69,7 @@ public MySqlSourceConfig(
                 port,
                 username,
                 password,
+                originUrl,
                 fetchSize,
                 serverTimeZone,
                 connectTimeoutMillis,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/MySqlSourceConfigFactory.java
Patch:
@@ -123,6 +123,7 @@ public MySqlSourceConfig create(int subtaskId) {
                 port,
                 username,
                 password,
+                originUrl,
                 fetchSize,
                 serverTimeZone,
                 connectTimeoutMillis,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/utils/TableDiscoveryUtils.java
Patch:
@@ -70,9 +70,9 @@ public static List<TableId> listTables(JdbcConnection jdbc, RelationalTableFilte
                                 TableId tableId = new TableId(dbName, null, rs.getString(1));
                                 if (tableFilters.dataCollectionFilter().isIncluded(tableId)) {
                                     capturedTableIds.add(tableId);
-                                    LOG.info("\t including '{}' for further processing", tableId);
+                                    LOG.debug("\t including '{}' for further processing", tableId);
                                 } else {
-                                    LOG.info("\t '{}' is filtered out of capturing", tableId);
+                                    LOG.debug("\t '{}' is filtered out of capturing", tableId);
                                 }
                             }
                         });

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/config/SqlServerSourceConfig.java
Patch:
@@ -49,6 +49,7 @@ public SqlServerSourceConfig(
             int port,
             String username,
             String password,
+            String originUrl,
             int fetchSize,
             String serverTimeZone,
             long connectTimeoutMillis,
@@ -68,6 +69,7 @@ public SqlServerSourceConfig(
                 port,
                 username,
                 password,
+                originUrl,
                 fetchSize,
                 serverTimeZone,
                 connectTimeoutMillis,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/config/SqlServerSourceConfigFactory.java
Patch:
@@ -94,6 +94,7 @@ public SqlServerSourceConfig create(int subtask) {
                 port,
                 username,
                 password,
+                originUrl,
                 fetchSize,
                 serverTimeZone,
                 connectTimeoutMillis,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/SqlServerIncrementalSourceFactory.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogOptions;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
 import org.apache.seatunnel.connectors.cdc.base.option.JdbcSourceOptions;
 
@@ -36,9 +37,9 @@ public OptionRule optionRule() {
                         JdbcSourceOptions.HOSTNAME,
                         JdbcSourceOptions.USERNAME,
                         JdbcSourceOptions.PASSWORD,
-                        JdbcSourceOptions.DATABASE_NAME,
-                        JdbcSourceOptions.TABLE_NAME)
+                        CatalogOptions.TABLE_NAMES)
                 .optional(
+                        JdbcSourceOptions.DATABASE_NAMES,
                         JdbcSourceOptions.PORT,
                         JdbcSourceOptions.SERVER_TIME_ZONE,
                         JdbcSourceOptions.CONNECT_TIMEOUT_MS,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/utils/TableDiscoveryUtils.java
Patch:
@@ -75,7 +75,7 @@ public static List<TableId> listTables(JdbcConnection jdbc, RelationalTableFilte
                                     capturedTableIds.add(tableId);
                                     LOG.info("\t including '{}' for further processing", tableId);
                                 } else {
-                                    LOG.info("\t '{}' is filtered out of capturing", tableId);
+                                    LOG.debug("\t '{}' is filtered out of capturing", tableId);
                                 }
                             }
                         });

File: seatunnel-connectors-v2/connector-console/src/main/java/org/apache/seatunnel/connectors/seatunnel/console/sink/ConsoleSinkWriter.java
Patch:
@@ -37,7 +37,7 @@
 public class ConsoleSinkWriter extends AbstractSinkWriter<SeaTunnelRow, Void> {
 
     private final SeaTunnelRowType seaTunnelRowType;
-    public static final AtomicLong CNT = new AtomicLong(0);
+    public final AtomicLong rowCounter = new AtomicLong(0);
     public SinkWriter.Context context;
 
     public ConsoleSinkWriter(SeaTunnelRowType seaTunnelRowType, SinkWriter.Context context) {
@@ -58,7 +58,7 @@ public void write(SeaTunnelRow element) {
         log.info(
                 "subtaskIndex={}  rowIndex={}:  SeaTunnelRow#tableId={} SeaTunnelRow#kind={} : {}",
                 context.getIndexOfSubtask(),
-                CNT.incrementAndGet(),
+                rowCounter.incrementAndGet(),
                 element.getTableId(),
                 element.getRowKind(),
                 StringUtils.join(arr, ", "));

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/source/ElasticsearchSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 
 import com.google.auto.service.AutoService;
 
@@ -61,7 +61,7 @@ public OptionRule optionRule() {
                         TLS_KEY_STORE_PASSWORD,
                         TLS_TRUST_STORE_PATH,
                         TLS_TRUST_STORE_PASSWORD)
-                .exclusive(SOURCE, SeaTunnelSchema.SCHEMA)
+                .exclusive(SOURCE, CatalogTableUtil.SCHEMA)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 import org.apache.seatunnel.connectors.seatunnel.fake.config.FakeOption;
 
 import com.google.auto.service.AutoService;
@@ -64,7 +64,7 @@ public String factoryIdentifier() {
     @Override
     public OptionRule optionRule() {
         return OptionRule.builder()
-                .required(SeaTunnelSchema.SCHEMA)
+                .required(CatalogTableUtil.SCHEMA)
                 .optional(STRING_FAKE_MODE)
                 .conditional(STRING_FAKE_MODE, FakeOption.FakeMode.TEMPLATE, STRING_TEMPLATE)
                 .optional(TINYINT_FAKE_MODE)

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseFileSinkConfig.java
Patch:
@@ -76,11 +76,11 @@ public BaseFileSinkConfig(@NonNull Config config) {
             this.fileNameExpression = config.getString(BaseSinkConfig.FILE_NAME_EXPRESSION.key());
         }
 
-        if (config.hasPath(BaseSinkConfig.FILE_FORMAT.key())
-                && !StringUtils.isBlank(config.getString(BaseSinkConfig.FILE_FORMAT.key()))) {
+        if (config.hasPath(BaseSinkConfig.FILE_FORMAT_TYPE.key())
+                && !StringUtils.isBlank(config.getString(BaseSinkConfig.FILE_FORMAT_TYPE.key()))) {
             this.fileFormat =
                     FileFormat.valueOf(
-                            config.getString(BaseSinkConfig.FILE_FORMAT.key())
+                            config.getString(BaseSinkConfig.FILE_FORMAT_TYPE.key())
                                     .toUpperCase(Locale.ROOT));
         }
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseSinkConfig.java
Patch:
@@ -179,11 +179,11 @@ public class BaseSinkConfig {
                     .withDescription(
                             "Only used when `custom_filename` is true. The time format of the path");
 
-    public static final Option<FileFormat> FILE_FORMAT =
-            Options.key("file_format")
+    public static final Option<FileFormat> FILE_FORMAT_TYPE =
+            Options.key("file_format_type")
                     .enumType(FileFormat.class)
                     .defaultValue(FileFormat.CSV)
-                    .withDescription("File format type");
+                    .withDescription("File format type, e.g. csv, orc, parquet, text");
 
     public static final Option<List<String>> SINK_COLUMNS =
             Options.key("sink_columns")

File: seatunnel-connectors-v2/connector-google-sheets/src/main/java/org/apache/seatunnel/connectors/seatunnel/google/sheets/source/SheetsSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 import org.apache.seatunnel.connectors.seatunnel.google.sheets.config.SheetsConfig;
 
 import com.google.auto.service.AutoService;
@@ -40,7 +40,7 @@ public OptionRule optionRule() {
                 .required(SheetsConfig.SHEET_ID)
                 .required(SheetsConfig.SHEET_NAME)
                 .required(SheetsConfig.RANGE)
-                .optional(SeaTunnelSchema.SCHEMA)
+                .optional(CatalogTableUtil.SCHEMA)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/source/HttpSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 import org.apache.seatunnel.connectors.seatunnel.http.config.HttpConfig;
 import org.apache.seatunnel.connectors.seatunnel.http.config.HttpRequestMethod;
 
@@ -51,7 +51,7 @@ public OptionRule.Builder getHttpBuilder() {
                 .optional(HttpConfig.CONTENT_FIELD)
                 .conditional(HttpConfig.METHOD, HttpRequestMethod.POST, HttpConfig.BODY)
                 .conditional(
-                        HttpConfig.FORMAT, HttpConfig.ResponseFormat.JSON, SeaTunnelSchema.SCHEMA)
+                        HttpConfig.FORMAT, HttpConfig.ResponseFormat.JSON, CatalogTableUtil.SCHEMA)
                 .optional(HttpConfig.POLL_INTERVAL_MILLS)
                 .optional(HttpConfig.RETRY)
                 .optional(HttpConfig.RETRY_BACKOFF_MULTIPLIER_MS)

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/IcebergSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 
 import com.google.auto.service.AutoService;
 
@@ -55,7 +55,7 @@ public OptionRule optionRule() {
                         KEY_CATALOG_NAME, KEY_CATALOG_TYPE, KEY_WAREHOUSE, KEY_NAMESPACE, KEY_TABLE)
                 .conditional(KEY_CATALOG_TYPE, HIVE, KEY_URI)
                 .optional(
-                        SeaTunnelSchema.SCHEMA,
+                        CatalogTableUtil.SCHEMA,
                         KEY_CASE_SENSITIVE,
                         KEY_START_SNAPSHOT_TIMESTAMP,
                         KEY_START_SNAPSHOT_ID,

File: seatunnel-connectors-v2/connector-influxdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/influxdb/source/InfluxDBSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 
 import com.google.auto.service.AutoService;
 
@@ -48,7 +48,7 @@ public String factoryIdentifier() {
     @Override
     public OptionRule optionRule() {
         return OptionRule.builder()
-                .required(URL, SQL, DATABASES, SeaTunnelSchema.SCHEMA)
+                .required(URL, SQL, DATABASES, CatalogTableUtil.SCHEMA)
                 .bundled(USERNAME, PASSWORD)
                 .bundled(LOWER_BOUND, UPPER_BOUND, PARTITION_NUM, SPLIT_COLUMN)
                 .optional(EPOCH, CONNECT_TIMEOUT_MS, QUERY_TIMEOUT_SEC)

File: seatunnel-connectors-v2/connector-iotdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/iotdb/source/IoTDBSourceFactory.java
Patch:
@@ -24,7 +24,7 @@
 
 import com.google.auto.service.AutoService;
 
-import static org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema.SCHEMA;
+import static org.apache.seatunnel.api.table.catalog.CatalogTableUtil.SCHEMA;
 import static org.apache.seatunnel.connectors.seatunnel.iotdb.config.CommonConfig.NODE_URLS;
 import static org.apache.seatunnel.connectors.seatunnel.iotdb.config.CommonConfig.PASSWORD;
 import static org.apache.seatunnel.connectors.seatunnel.iotdb.config.CommonConfig.USERNAME;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/db2/DB2Dialect.java
Patch:
@@ -42,7 +42,7 @@ public JdbcDialectTypeMapper getJdbcDialectTypeMapper() {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         return Optional.empty();
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/dm/DmdbDialect.java
Patch:
@@ -42,7 +42,7 @@ public JdbcDialectTypeMapper getJdbcDialectTypeMapper() {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         return Optional.empty();
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/gbase8a/Gbase8aDialect.java
Patch:
@@ -41,7 +41,7 @@ public JdbcDialectTypeMapper getJdbcDialectTypeMapper() {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         return Optional.empty();
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/mysql/MysqlDialect.java
Patch:
@@ -52,7 +52,7 @@ public String quoteIdentifier(String identifier) {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         String updateClause =
                 Arrays.stream(fieldNames)
                         .map(
@@ -63,7 +63,7 @@ public Optional<String> getUpsertStatement(
                                                 + ")")
                         .collect(Collectors.joining(", "));
         String upsertSQL =
-                getInsertIntoStatement(tableName, fieldNames)
+                getInsertIntoStatement(database, tableName, fieldNames)
                         + " ON DUPLICATE KEY UPDATE "
                         + updateClause;
         return Optional.of(upsertSQL);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/oracle/OracleDialect.java
Patch:
@@ -51,7 +51,7 @@ public JdbcDialectTypeMapper getJdbcDialectTypeMapper() {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         List<String> nonUniqueKeyFields =
                 Arrays.stream(fieldNames)
                         .filter(fieldName -> !Arrays.asList(uniqueKeyFields).contains(fieldName))
@@ -91,13 +91,14 @@ public Optional<String> getUpsertStatement(
 
         String upsertSQL =
                 String.format(
-                        " MERGE INTO %s TARGET"
+                        " MERGE INTO %s.%s TARGET"
                                 + " USING (%s) SOURCE"
                                 + " ON (%s) "
                                 + " WHEN MATCHED THEN"
                                 + " UPDATE SET %s"
                                 + " WHEN NOT MATCHED THEN"
                                 + " INSERT (%s) VALUES (%s)",
+                        database,
                         tableName,
                         usingClause,
                         onConditions,

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/phoenix/PhoenixDialect.java
Patch:
@@ -41,7 +41,7 @@ public JdbcDialectTypeMapper getJdbcDialectTypeMapper() {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         return Optional.empty();
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/redshift/RedshiftDialect.java
Patch:
@@ -41,7 +41,7 @@ public JdbcDialectTypeMapper getJdbcDialectTypeMapper() {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         return Optional.empty();
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/saphana/SapHanaDialect.java
Patch:
@@ -42,7 +42,7 @@ public JdbcDialectTypeMapper getJdbcDialectTypeMapper() {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         return Optional.empty();
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/sqlite/SqliteDialect.java
Patch:
@@ -48,7 +48,7 @@ public String quoteIdentifier(String identifier) {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         String updateClause =
                 Arrays.stream(fieldNames)
                         .map(
@@ -65,7 +65,7 @@ public Optional<String> getUpsertStatement(
                         .collect(Collectors.joining(","));
 
         String upsertSQL =
-                getInsertIntoStatement(tableName, fieldNames)
+                getInsertIntoStatement(database, tableName, fieldNames)
                         + " ON CONFLICT("
                         + conflictFields
                         + ") DO UPDATE SET "

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/sqlserver/SqlServerDialect.java
Patch:
@@ -44,7 +44,7 @@ public JdbcDialectTypeMapper getJdbcDialectTypeMapper() {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         List<String> nonUniqueKeyFields =
                 Arrays.stream(fieldNames)
                         .filter(fieldName -> !Arrays.asList(uniqueKeyFields).contains(fieldName))
@@ -83,13 +83,14 @@ public Optional<String> getUpsertStatement(
                         .collect(Collectors.joining(", "));
         String upsertSQL =
                 String.format(
-                        "MERGE INTO %s AS [TARGET]"
+                        "MERGE INTO %s.%s AS [TARGET]"
                                 + " USING (%s) AS [SOURCE]"
                                 + " ON (%s)"
                                 + " WHEN MATCHED THEN"
                                 + " UPDATE SET %s"
                                 + " WHEN NOT MATCHED THEN"
                                 + " INSERT (%s) VALUES (%s);",
+                        database,
                         tableName,
                         usingClause,
                         onConditions,

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/teradata/TeradataDialect.java
Patch:
@@ -42,7 +42,7 @@ public JdbcDialectTypeMapper getJdbcDialectTypeMapper() {
 
     @Override
     public Optional<String> getUpsertStatement(
-            String tableName, String[] fieldNames, String[] uniqueKeyFields) {
+            String database, String tableName, String[] fieldNames, String[] uniqueKeyFields) {
         return Optional.empty();
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/XaFacade.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.xa;
 
+import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcConnectionConfig;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.connection.JdbcConnectionProvider;
-import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.options.JdbcConnectionOptions;
 
 import javax.transaction.xa.XAException;
 import javax.transaction.xa.Xid;
@@ -42,8 +42,8 @@
  */
 public interface XaFacade extends JdbcConnectionProvider, Serializable, AutoCloseable {
 
-    static XaFacade fromJdbcConnectionOptions(JdbcConnectionOptions jdbcConnectionOptions) {
-        return new XaFacadeImplAutoLoad(jdbcConnectionOptions);
+    static XaFacade fromJdbcConnectionOptions(JdbcConnectionConfig jdbcConnectionConfig) {
+        return new XaFacadeImplAutoLoad(jdbcConnectionConfig);
     }
 
     void open() throws Exception;

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/config/Config.java
Patch:
@@ -25,6 +25,9 @@
 
 public class Config {
 
+    public static final String CONNECTOR_IDENTITY = "Kafka";
+    public static final String REPLICATION_FACTOR = "replication.factor";
+
     /** The default data format is JSON */
     public static final String DEFAULT_FORMAT = "json";
 

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaSink.java
Patch:
@@ -112,6 +112,6 @@ public Optional<Serializer<KafkaCommitInfo>> getCommitInfoSerializer() {
 
     @Override
     public String getPluginName() {
-        return "Kafka";
+        return org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.CONNECTOR_IDENTITY;
     }
 }

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/sink/MongodbSink.java
Patch:
@@ -23,13 +23,13 @@
 import org.apache.seatunnel.api.common.SeaTunnelAPIErrorCode;
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
 import org.apache.seatunnel.api.sink.SinkWriter;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 import org.apache.seatunnel.connectors.seatunnel.common.sink.AbstractSimpleSink;
 import org.apache.seatunnel.connectors.seatunnel.common.sink.AbstractSinkWriter;
 import org.apache.seatunnel.connectors.seatunnel.mongodb.config.MongodbConfig;
@@ -83,7 +83,7 @@ public SeaTunnelDataType<SeaTunnelRow> getConsumedType() {
     @Override
     public AbstractSinkWriter<SeaTunnelRow, Void> createWriter(SinkWriter.Context context)
             throws IOException {
-        boolean useSimpleTextSchema = SeaTunnelSchema.buildSimpleTextSchema().equals(rowType);
+        boolean useSimpleTextSchema = CatalogTableUtil.buildSimpleTextSchema().equals(rowType);
         return new MongodbSinkWriter(rowType, useSimpleTextSchema, params);
     }
 }

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/source/MongodbSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 
 import com.google.auto.service.AutoService;
 
@@ -40,7 +40,7 @@ public String factoryIdentifier() {
     @Override
     public OptionRule optionRule() {
         return OptionRule.builder()
-                .required(URI, DATABASE, COLLECTION, SeaTunnelSchema.SCHEMA)
+                .required(URI, DATABASE, COLLECTION, CatalogTableUtil.SCHEMA)
                 .optional(MATCHQUERY)
                 .build();
     }

File: seatunnel-connectors-v2/connector-neo4j/src/main/java/org/apache/seatunnel/connectors/seatunnel/neo4j/source/Neo4jSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 
 import com.google.auto.service.AutoService;
 
@@ -46,7 +46,7 @@ public String factoryIdentifier() {
     @Override
     public OptionRule optionRule() {
         return OptionRule.builder()
-                .required(KEY_NEO4J_URI, KEY_DATABASE, KEY_QUERY, SeaTunnelSchema.SCHEMA)
+                .required(KEY_NEO4J_URI, KEY_DATABASE, KEY_QUERY, CatalogTableUtil.SCHEMA)
                 .optional(
                         KEY_USERNAME,
                         KEY_PASSWORD,

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/PulsarSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 import org.apache.seatunnel.connectors.seatunnel.pulsar.config.PulsarConfigUtil;
 import org.apache.seatunnel.connectors.seatunnel.pulsar.config.SourceProperties;
 
@@ -62,7 +62,7 @@ public OptionRule optionRule() {
                         POLL_TIMEOUT,
                         POLL_INTERVAL,
                         POLL_BATCH_SIZE,
-                        SeaTunnelSchema.SCHEMA)
+                        CatalogTableUtil.SCHEMA)
                 .exclusive(TOPIC, TOPIC_PATTERN)
                 .conditional(
                         CURSOR_STARTUP_MODE,

File: seatunnel-connectors-v2/connector-rabbitmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rabbitmq/source/RabbitmqSourceFactory.java
Patch:
@@ -24,7 +24,7 @@
 
 import com.google.auto.service.AutoService;
 
-import static org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema.SCHEMA;
+import static org.apache.seatunnel.api.table.catalog.CatalogTableUtil.SCHEMA;
 import static org.apache.seatunnel.connectors.seatunnel.rabbitmq.config.RabbitmqConfig.AUTOMATIC_RECOVERY_ENABLED;
 import static org.apache.seatunnel.connectors.seatunnel.rabbitmq.config.RabbitmqConfig.CONNECTION_TIMEOUT;
 import static org.apache.seatunnel.connectors.seatunnel.rabbitmq.config.RabbitmqConfig.DELIVERY_TIMEOUT;

File: seatunnel-connectors-v2/connector-redis/src/main/java/org/apache/seatunnel/connectors/seatunnel/redis/source/RedisSourceFactory.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 import org.apache.seatunnel.connectors.seatunnel.redis.config.RedisConfig;
 
 import com.google.auto.service.AutoService;
@@ -45,7 +45,7 @@ public OptionRule optionRule() {
                         RedisConfig.USER,
                         RedisConfig.KEY_PATTERN)
                 .conditional(RedisConfig.MODE, RedisConfig.RedisMode.CLUSTER, RedisConfig.NODES)
-                .bundled(RedisConfig.FORMAT, SeaTunnelSchema.SCHEMA)
+                .bundled(RedisConfig.FORMAT, CatalogTableUtil.SCHEMA)
                 .build();
     }
 

File: seatunnel-connectors-v2/connector-s3-redshift/src/main/java/org/apache/seatunnel/connectors/seatunnel/redshift/sink/S3RedshiftFactory.java
Patch:
@@ -46,7 +46,7 @@ public OptionRule optionRule() {
                         S3RedshiftConfig.EXECUTE_SQL,
                         BaseSourceConfig.FILE_PATH)
                 .optional(S3Config.S3_ACCESS_KEY, S3Config.S3_SECRET_KEY)
-                .optional(BaseSinkConfig.FILE_FORMAT)
+                .optional(BaseSinkConfig.FILE_FORMAT_TYPE)
                 .optional(BaseSinkConfig.FILENAME_TIME_FORMAT)
                 .optional(BaseSinkConfig.FIELD_DELIMITER)
                 .optional(BaseSinkConfig.ROW_DELIMITER)

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/source/StarRocksSourceFactory.java
Patch:
@@ -25,7 +25,7 @@
 
 import com.google.auto.service.AutoService;
 
-import static org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema.SCHEMA;
+import static org.apache.seatunnel.api.table.catalog.CatalogTableUtil.SCHEMA;
 
 @AutoService(Factory.class)
 public class StarRocksSourceFactory implements TableSourceFactory {

File: seatunnel-connectors-v2/connector-tablestore/src/main/java/org/apache/seatunnel/connectors/seatunnel/tablestore/sink/TablestoreSinkFactory.java
Patch:
@@ -18,9 +18,9 @@
 package org.apache.seatunnel.connectors.seatunnel.tablestore.sink;
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
+import org.apache.seatunnel.api.table.catalog.CatalogTableUtil;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSinkFactory;
-import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 
 import com.google.auto.service.AutoService;
 
@@ -50,7 +50,7 @@ public OptionRule optionRule() {
                         ACCESS_KEY_ID,
                         ACCESS_KEY_SECRET,
                         PRIMARY_KEYS,
-                        SeaTunnelSchema.SCHEMA)
+                        CatalogTableUtil.SCHEMA)
                 .optional(BATCH_INTERVAL_MS, BATCH_SIZE)
                 .build();
     }

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -19,11 +19,11 @@
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
+import org.apache.seatunnel.api.common.CommonOptions;
 import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.sink.DataSaveMode;
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
 import org.apache.seatunnel.api.sink.SupportDataSaveMode;
-import org.apache.seatunnel.api.source.SourceCommonOptions;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.core.starter.enums.PluginType;
@@ -117,8 +117,8 @@ public List<DataStream<Row>> execute(List<DataStream<Row>> upstreamDataStreams)
             DataStreamSink<Row> dataStreamSink =
                     stream.sinkTo(new FlinkSink<>(seaTunnelSink))
                             .name(seaTunnelSink.getPluginName());
-            if (sinkConfig.hasPath(SourceCommonOptions.PARALLELISM.key())) {
-                int parallelism = sinkConfig.getInt(SourceCommonOptions.PARALLELISM.key());
+            if (sinkConfig.hasPath(CommonOptions.PARALLELISM.key())) {
+                int parallelism = sinkConfig.getInt(CommonOptions.PARALLELISM.key());
                 dataStreamSink.setParallelism(parallelism);
             }
         }

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SourceExecuteProcessor.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
+import org.apache.seatunnel.api.common.CommonOptions;
 import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
-import org.apache.seatunnel.api.source.SourceCommonOptions;
 import org.apache.seatunnel.api.source.SupportCoordinate;
 import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.core.starter.enums.PluginType;
@@ -79,8 +79,8 @@ public List<DataStream<Row>> execute(List<DataStream<Row>> upstreamDataStreams)
                             internalSource.getBoundedness()
                                     == org.apache.seatunnel.api.source.Boundedness.BOUNDED);
             Config pluginConfig = pluginConfigs.get(i);
-            if (pluginConfig.hasPath(SourceCommonOptions.PARALLELISM.key())) {
-                int parallelism = pluginConfig.getInt(SourceCommonOptions.PARALLELISM.key());
+            if (pluginConfig.hasPath(CommonOptions.PARALLELISM.key())) {
+                int parallelism = pluginConfig.getInt(CommonOptions.PARALLELISM.key());
                 sourceStream.setParallelism(parallelism);
             }
             registerResultTable(pluginConfig, sourceStream);

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-15-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -19,11 +19,11 @@
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
+import org.apache.seatunnel.api.common.CommonOptions;
 import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.sink.DataSaveMode;
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
 import org.apache.seatunnel.api.sink.SupportDataSaveMode;
-import org.apache.seatunnel.api.source.SourceCommonOptions;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.core.starter.enums.PluginType;
@@ -118,8 +118,8 @@ public List<DataStream<Row>> execute(List<DataStream<Row>> upstreamDataStreams)
             DataStreamSink<Row> dataStreamSink =
                     stream.sinkTo(SinkV1Adapter.wrap(new FlinkSink<>(seaTunnelSink)))
                             .name(seaTunnelSink.getPluginName());
-            if (sinkConfig.hasPath(SourceCommonOptions.PARALLELISM.key())) {
-                int parallelism = sinkConfig.getInt(SourceCommonOptions.PARALLELISM.key());
+            if (sinkConfig.hasPath(CommonOptions.PARALLELISM.key())) {
+                int parallelism = sinkConfig.getInt(CommonOptions.PARALLELISM.key());
                 dataStreamSink.setParallelism(parallelism);
             }
         }

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-15-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SourceExecuteProcessor.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
+import org.apache.seatunnel.api.common.CommonOptions;
 import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
-import org.apache.seatunnel.api.source.SourceCommonOptions;
 import org.apache.seatunnel.api.source.SupportCoordinate;
 import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.core.starter.enums.PluginType;
@@ -79,8 +79,8 @@ public List<DataStream<Row>> execute(List<DataStream<Row>> upstreamDataStreams)
                             internalSource.getBoundedness()
                                     == org.apache.seatunnel.api.source.Boundedness.BOUNDED);
             Config pluginConfig = pluginConfigs.get(i);
-            if (pluginConfig.hasPath(SourceCommonOptions.PARALLELISM.key())) {
-                int parallelism = pluginConfig.getInt(SourceCommonOptions.PARALLELISM.key());
+            if (pluginConfig.hasPath(CommonOptions.PARALLELISM.key())) {
+                int parallelism = pluginConfig.getInt(CommonOptions.PARALLELISM.key());
                 sourceStream.setParallelism(parallelism);
             }
             registerResultTable(pluginConfig, sourceStream);

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-starrocks-e2e/src/test/java/org/apache/seatunnel/e2e/connector/starrocks/StarRocksCDCSinkIT.java
Patch:
@@ -24,6 +24,7 @@
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.TestTemplate;
 import org.testcontainers.containers.Container;
 import org.testcontainers.containers.GenericContainer;
@@ -52,6 +53,7 @@
 import static org.awaitility.Awaitility.given;
 
 @Slf4j
+@Disabled("There are still errors unfixed @Hisoka-X")
 public class StarRocksCDCSinkIT extends TestSuiteBase implements TestResource {
     private static final String DOCKER_IMAGE = "d87904488/starrocks-starter:2.2.1";
     private static final String DRIVER_CLASS = "com.mysql.cj.jdbc.Driver";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-starrocks-e2e/src/test/java/org/apache/seatunnel/e2e/connector/starrocks/StarRocksIT.java
Patch:
@@ -28,6 +28,7 @@
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.TestTemplate;
 import org.testcontainers.containers.Container;
 import org.testcontainers.containers.GenericContainer;
@@ -63,6 +64,7 @@
 import static org.awaitility.Awaitility.given;
 
 @Slf4j
+@Disabled("There are still errors unfixed @Hisoka-X")
 public class StarRocksIT extends TestSuiteBase implements TestResource {
     private static final String DOCKER_IMAGE = "d87904488/starrocks-starter:2.2.1";
     private static final String DRIVER_CLASS = "com.mysql.cj.jdbc.Driver";

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/AbstractTestContainer.java
Patch:
@@ -40,7 +40,7 @@ public abstract class AbstractTestContainer implements TestContainer {
     protected static final Logger LOG = LoggerFactory.getLogger(AbstractTestContainer.class);
     protected static final String START_ROOT_MODULE_NAME = "seatunnel-core";
 
-    public static final String SEATUNNEL_HOME = "/tmp/seatunnel";
+    public static final String SEATUNNEL_HOME = "/tmp/seatunnel/";
     protected final String startModuleName;
 
     protected final String startModuleFullPath;

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/flink/AbstractTestFlinkContainer.java
Patch:
@@ -29,6 +29,7 @@
 import org.testcontainers.utility.DockerLoggerFactory;
 
 import lombok.NoArgsConstructor;
+import lombok.extern.slf4j.Slf4j;
 
 import java.io.IOException;
 import java.time.Duration;
@@ -43,6 +44,7 @@
  * TestContainer#executeJob} to submit a seatunnel config and run a seatunnel job.
  */
 @NoArgsConstructor
+@Slf4j
 public abstract class AbstractTestFlinkContainer extends AbstractTestContainer {
 
     protected static final List<String> DEFAULT_FLINK_PROPERTIES =
@@ -134,6 +136,7 @@ public void executeExtraCommands(ContainerExtendedFactory extendedFactory)
     @Override
     public Container.ExecResult executeJob(String confFile)
             throws IOException, InterruptedException {
+        log.info("test in container: {}", identifier());
         return executeJob(jobManager, confFile);
     }
 }

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/JobExecutionIT.java
Patch:
@@ -78,7 +78,7 @@ public void testExecuteJob() throws Exception {
                         });
 
         Awaitility.await()
-                .atMost(20000, TimeUnit.MILLISECONDS)
+                .atMost(600000, TimeUnit.MILLISECONDS)
                 .untilAsserted(
                         () ->
                                 Assertions.assertTrue(

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/SeaTunnelClient.java
Patch:
@@ -99,7 +99,7 @@ public String getJobDetailStatus(Long jobId) {
     /** list all jobId and job status */
     @Deprecated
     public String listJobStatus() {
-        return jobClient.listJobStatus();
+        return jobClient.listJobStatus(false);
     }
 
     /**

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/Constant.java
Patch:
@@ -55,8 +55,5 @@ public class Constant {
 
     public static final String IMAP_CHECKPOINT_ID = "engine_checkpoint-id-%d";
 
-    public static final String IMAP_RESOURCE_MANAGER_REGISTER_WORKER =
-            "ResourceManager_RegisterWorker";
-
     public static final String IMAP_RUNNING_JOB_METRICS = "engine_runningJobMetrics";
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseFileSinkConfig.java
Patch:
@@ -76,11 +76,11 @@ public BaseFileSinkConfig(@NonNull Config config) {
             this.fileNameExpression = config.getString(BaseSinkConfig.FILE_NAME_EXPRESSION.key());
         }
 
-        if (config.hasPath(BaseSinkConfig.FILE_FORMAT.key())
-                && !StringUtils.isBlank(config.getString(BaseSinkConfig.FILE_FORMAT.key()))) {
+        if (config.hasPath(BaseSinkConfig.FILE_FORMAT_TYPE.key())
+                && !StringUtils.isBlank(config.getString(BaseSinkConfig.FILE_FORMAT_TYPE.key()))) {
             this.fileFormat =
                     FileFormat.valueOf(
-                            config.getString(BaseSinkConfig.FILE_FORMAT.key())
+                            config.getString(BaseSinkConfig.FILE_FORMAT_TYPE.key())
                                     .toUpperCase(Locale.ROOT));
         }
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseSinkConfig.java
Patch:
@@ -179,11 +179,11 @@ public class BaseSinkConfig {
                     .withDescription(
                             "Only used when `custom_filename` is true. The time format of the path");
 
-    public static final Option<FileFormat> FILE_FORMAT =
-            Options.key("file_format")
+    public static final Option<FileFormat> FILE_FORMAT_TYPE =
+            Options.key("file_format_type")
                     .enumType(FileFormat.class)
                     .defaultValue(FileFormat.CSV)
-                    .withDescription("File format type");
+                    .withDescription("File format type, e.g. csv, orc, parquet, text");
 
     public static final Option<List<String>> SINK_COLUMNS =
             Options.key("sink_columns")

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/TextReadStrategy.java
Patch:
@@ -144,7 +144,9 @@ public void setSeaTunnelRowTypeInfo(SeaTunnelRowType seaTunnelRowType) {
         } else {
             FileFormat fileFormat =
                     FileFormat.valueOf(
-                            pluginConfig.getString(BaseSourceConfig.FILE_TYPE.key()).toUpperCase());
+                            pluginConfig
+                                    .getString(BaseSourceConfig.FILE_FORMAT_TYPE.key())
+                                    .toUpperCase());
             if (fileFormat == FileFormat.CSV) {
                 fieldDelimiter = ",";
             }

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/catalog/S3Catalog.java
Patch:
@@ -73,10 +73,10 @@ public S3Catalog(String catalogName, Config s3Config) {
     @Override
     public void open() throws CatalogException {
         ReadStrategy readStrategy =
-                ReadStrategyFactory.of(s3Config.getString(S3Config.FILE_TYPE.key()));
+                ReadStrategyFactory.of(s3Config.getString(S3Config.FILE_FORMAT_TYPE.key()));
         readStrategy.setPluginConfig(s3Config);
         this.defaultDatabase = s3Config.getString(S3Config.FILE_PATH.key());
-        readStrategy = ReadStrategyFactory.of(s3Config.getString(S3Config.FILE_TYPE.key()));
+        readStrategy = ReadStrategyFactory.of(s3Config.getString(S3Config.FILE_FORMAT_TYPE.key()));
         readStrategy.setPluginConfig(s3Config);
         try {
             fileSystem =

File: seatunnel-connectors-v2/connector-s3-redshift/src/main/java/org/apache/seatunnel/connectors/seatunnel/redshift/sink/S3RedshiftFactory.java
Patch:
@@ -46,7 +46,7 @@ public OptionRule optionRule() {
                         S3RedshiftConfig.EXECUTE_SQL,
                         BaseSourceConfig.FILE_PATH)
                 .optional(S3Config.S3_ACCESS_KEY, S3Config.S3_SECRET_KEY)
-                .optional(BaseSinkConfig.FILE_FORMAT)
+                .optional(BaseSinkConfig.FILE_FORMAT_TYPE)
                 .optional(BaseSinkConfig.FILENAME_TIME_FORMAT)
                 .optional(BaseSinkConfig.FIELD_DELIMITER)
                 .optional(BaseSinkConfig.ROW_DELIMITER)

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlIncrementalSource.java
Patch:
@@ -39,7 +39,7 @@
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.config.MySqlSourceConfigFactory;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.offset.BinlogOffsetFactory;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.JdbcCatalogOptions;
-import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.MySqlCatalogFactory;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.mysql.MySqlCatalogFactory;
 
 import com.google.auto.service.AutoService;
 import lombok.NoArgsConstructor;

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/catalog/S3DataTypeConvertor.java
Patch:
@@ -23,7 +23,6 @@
 import org.apache.seatunnel.api.table.catalog.DataTypeConvertor;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
-import org.apache.seatunnel.connectors.seatunnel.file.config.FileSystemType;
 
 import com.google.auto.service.AutoService;
 
@@ -59,6 +58,6 @@ public SeaTunnelRowType toConnectorType(
 
     @Override
     public String getIdentity() {
-        return FileSystemType.S3.getFileSystemPluginName();
+        return "S3";
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/mysql/MySqlCatalog.java
Patch:
@@ -16,7 +16,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.jdbc.catalog;
+package org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.mysql;
 
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.ConstraintKey;
@@ -30,7 +30,7 @@
 import org.apache.seatunnel.api.table.catalog.exception.TableNotExistException;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.common.utils.JdbcUrlUtil;
-import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.sql.MysqlCreateTableSqlBuilder;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.AbstractJdbcCatalog;
 
 import com.mysql.cj.MysqlType;
 import com.mysql.cj.jdbc.result.ResultSetImpl;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/mysql/MySqlCatalogFactory.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.jdbc.catalog;
+package org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.mysql;
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.api.table.factory.CatalogFactory;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.common.utils.JdbcUrlUtil;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.JdbcCatalogOptions;
 
 import com.google.auto.service.AutoService;
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/mysql/MysqlCreateTableSqlBuilder.java
Patch:
@@ -15,15 +15,14 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.sql;
+package org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.mysql;
 
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.Column;
 import org.apache.seatunnel.api.table.catalog.ConstraintKey;
 import org.apache.seatunnel.api.table.catalog.PrimaryKey;
 import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.catalog.TableSchema;
-import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.MysqlDataTypeConvertor;
 
 import org.apache.commons.collections4.CollectionUtils;
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/mysql/MysqlDataTypeConvertor.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.jdbc.catalog;
+package org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.mysql;
 
 import org.apache.seatunnel.api.table.catalog.DataTypeConvertException;
 import org.apache.seatunnel.api.table.catalog.DataTypeConvertor;

File: seatunnel-connectors-v2/connector-jdbc/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/MysqlDataTypeConvertorTest.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.DecimalType;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.mysql.MysqlDataTypeConvertor;
 
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;

File: seatunnel-connectors-v2/connector-jdbc/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sql/MysqlCreateTableSqlBuilderTest.java
Patch:
@@ -26,6 +26,7 @@
 import org.apache.seatunnel.api.table.catalog.TableSchema;
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.LocalTimeType;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.mysql.MysqlCreateTableSqlBuilder;
 
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/FileUtils.java
Patch:
@@ -115,8 +115,8 @@ public static void createNewFile(String filePath) {
      * @return The file line number
      */
     public static Long getFileLineNumber(@NonNull String filePath) {
-        try {
-            return Files.lines(Paths.get(filePath)).count();
+        try (Stream<String> lines = Files.lines(Paths.get(filePath))) {
+            return lines.count();
         } catch (IOException e) {
             throw new SeaTunnelRuntimeException(
                     CommonErrorCode.FILE_OPERATION_FAILED,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/JdbcConnectionPools.java
Patch:
@@ -52,7 +52,7 @@ public HikariDataSource getOrCreateConnectionPool(
             ConnectionPoolId poolId, JdbcSourceConfig sourceConfig) {
         synchronized (pools) {
             if (!pools.containsKey(poolId)) {
-                LOG.info("Create and register connection pool {}", poolId);
+                LOG.debug("Create and register connection pool {}", poolId);
                 pools.put(poolId, JDBCCONNECTIONPOOLFACTORY.createPooledDataSource(sourceConfig));
             }
             return pools.get(poolId);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/IncrementalSource.java
Patch:
@@ -152,7 +152,7 @@ public SourceReader<T, SourceSplitBase> createReader(SourceReader.Context reader
         // create source config for the given subtask (e.g. unique server id)
         C sourceConfig = configFactory.create(readerContext.getIndexOfSubtask());
         BlockingQueue<RecordsWithSplitIds<SourceRecords>> elementsQueue =
-                new LinkedBlockingQueue<>(1024);
+                new LinkedBlockingQueue<>(2);
 
         Supplier<IncrementalSourceSplitReader<C>> splitReaderSupplier =
                 () ->

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/IncrementalSourceEnumerator.java
Patch:
@@ -101,7 +101,7 @@ public void registerReader(int subtaskId) {
     @Override
     public void handleSourceEvent(int subtaskId, SourceEvent sourceEvent) {
         if (sourceEvent instanceof CompletedSnapshotSplitsReportEvent) {
-            LOG.info(
+            LOG.debug(
                     "The enumerator receives completed split watermarks(log offset) {} from subtask {}.",
                     sourceEvent,
                     subtaskId);
@@ -158,7 +158,7 @@ private void assignSplits() {
                 final SourceSplitBase sourceSplit = split.get();
                 context.assignSplit(nextAwaiting, sourceSplit);
                 awaitingReader.remove();
-                LOG.info("Assign split {} to subtask {}", sourceSplit, nextAwaiting);
+                LOG.debug("Assign split {} to subtask {}", sourceSplit, nextAwaiting);
             } else {
                 // there is no available splits by now, skip assigning
                 break;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/utils/TableDiscoveryUtils.java
Patch:
@@ -70,9 +70,9 @@ public static List<TableId> listTables(JdbcConnection jdbc, RelationalTableFilte
                                 TableId tableId = new TableId(dbName, null, rs.getString(1));
                                 if (tableFilters.dataCollectionFilter().isIncluded(tableId)) {
                                     capturedTableIds.add(tableId);
-                                    LOG.info("\t including '{}' for further processing", tableId);
+                                    LOG.debug("\t including '{}' for further processing", tableId);
                                 } else {
-                                    LOG.info("\t '{}' is filtered out of capturing", tableId);
+                                    LOG.debug("\t '{}' is filtered out of capturing", tableId);
                                 }
                             }
                         });

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/utils/TableDiscoveryUtils.java
Patch:
@@ -75,7 +75,7 @@ public static List<TableId> listTables(JdbcConnection jdbc, RelationalTableFilte
                                     capturedTableIds.add(tableId);
                                     LOG.info("\t including '{}' for further processing", tableId);
                                 } else {
-                                    LOG.info("\t '{}' is filtered out of capturing", tableId);
+                                    LOG.debug("\t '{}' is filtered out of capturing", tableId);
                                 }
                             }
                         });

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/AbstractTestContainer.java
Patch:
@@ -40,7 +40,7 @@ public abstract class AbstractTestContainer implements TestContainer {
     protected static final Logger LOG = LoggerFactory.getLogger(AbstractTestContainer.class);
     protected static final String START_ROOT_MODULE_NAME = "seatunnel-core";
 
-    public static final String SEATUNNEL_HOME = "/tmp/seatunnel";
+    public static final String SEATUNNEL_HOME = "/tmp/seatunnel/";
     protected final String startModuleName;
 
     protected final String startModuleFullPath;

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/flink/AbstractTestFlinkContainer.java
Patch:
@@ -29,6 +29,7 @@
 import org.testcontainers.utility.DockerLoggerFactory;
 
 import lombok.NoArgsConstructor;
+import lombok.extern.slf4j.Slf4j;
 
 import java.io.IOException;
 import java.time.Duration;
@@ -43,6 +44,7 @@
  * TestContainer#executeJob} to submit a seatunnel config and run a seatunnel job.
  */
 @NoArgsConstructor
+@Slf4j
 public abstract class AbstractTestFlinkContainer extends AbstractTestContainer {
 
     protected static final List<String> DEFAULT_FLINK_PROPERTIES =
@@ -134,6 +136,7 @@ public void executeExtraCommands(ContainerExtendedFactory extendedFactory)
     @Override
     public Container.ExecResult executeJob(String confFile)
             throws IOException, InterruptedException {
+        log.info("test in container: {}", identifier());
         return executeJob(jobManager, confFile);
     }
 }

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/JobExecutionIT.java
Patch:
@@ -78,7 +78,7 @@ public void testExecuteJob() throws Exception {
                         });
 
         Awaitility.await()
-                .atMost(20000, TimeUnit.MILLISECONDS)
+                .atMost(600000, TimeUnit.MILLISECONDS)
                 .untilAsserted(
                         () ->
                                 Assertions.assertTrue(

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/Constant.java
Patch:
@@ -55,8 +55,5 @@ public class Constant {
 
     public static final String IMAP_CHECKPOINT_ID = "engine_checkpoint-id-%d";
 
-    public static final String IMAP_RESOURCE_MANAGER_REGISTER_WORKER =
-            "ResourceManager_RegisterWorker";
-
     public static final String IMAP_RUNNING_JOB_METRICS = "engine_runningJobMetrics";
 }

File: seatunnel-engine/seatunnel-engine-common/src/test/java/org/apache/seatunnel/engine/common/config/YamlSeaTunnelConfigParserTest.java
Patch:
@@ -69,12 +69,12 @@ public void testSeaTunnelConfig() {
                         .getStorage()
                         .getMaxRetainedCheckpoints());
         Assertions.assertEquals(
-                "secret-key",
+                "file:///",
                 config.getEngineConfig()
                         .getCheckpointConfig()
                         .getStorage()
                         .getStoragePluginConfig()
-                        .get("s3.secret-key"));
+                        .get("fs.defaultFS"));
     }
 
     @Test

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/PendingCheckpoint.java
Patch:
@@ -118,6 +118,7 @@ public void acknowledgeTask(
             TaskLocation taskLocation,
             List<ActionSubtaskState> states,
             SubtaskStatus subtaskStatus) {
+        LOG.debug("acknowledgeTask states [{}]", states);
         boolean exist = notYetAcknowledgedTasks.remove(taskLocation.getTaskID());
         if (!exist) {
             return;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/CheckpointFinishedOperation.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.common.utils.RetryUtils;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
+import org.apache.seatunnel.engine.server.exception.TaskGroupContextNotFoundException;
 import org.apache.seatunnel.engine.server.execution.Task;
 import org.apache.seatunnel.engine.server.execution.TaskGroupContext;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
@@ -101,7 +102,7 @@ public void run() throws Exception {
                         Constant.OPERATION_RETRY_TIME,
                         false,
                         exception ->
-                                exception instanceof NullPointerException
+                                exception instanceof TaskGroupContextNotFoundException
                                         && !server.taskIsEnded(taskLocation.getTaskGroupLocation()),
                         Constant.OPERATION_RETRY_SLEEP));
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/NotifyTaskStartOperation.java
Patch:
@@ -18,9 +18,9 @@
 package org.apache.seatunnel.engine.server.checkpoint.operation;
 
 import org.apache.seatunnel.common.utils.RetryUtils;
-import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
+import org.apache.seatunnel.engine.server.exception.TaskGroupContextNotFoundException;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.serializable.CheckpointDataSerializerHook;
 import org.apache.seatunnel.engine.server.task.AbstractTask;
@@ -58,7 +58,7 @@ public void run() throws Exception {
                         Constant.OPERATION_RETRY_TIME,
                         true,
                         exception ->
-                                exception instanceof SeaTunnelException
+                                exception instanceof TaskGroupContextNotFoundException
                                         && !server.taskIsEnded(taskLocation.getTaskGroupLocation()),
                         Constant.OPERATION_RETRY_SLEEP));
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/TaskCallTimer.java
Patch:
@@ -91,6 +91,7 @@ public void timerStart(TaskTracker taskTracker) {
     }
 
     public void timerStop() {
+        // Wait until the next time the timer is enabled to wake up
         wait0.set(true);
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/service/slot/DefaultSlotService.java
Patch:
@@ -142,7 +142,7 @@ public synchronized SlotAndWorkerProfile requestSlot(
                     profile.getSlotID(),
                     p -> new SlotContext(profile.getSlotID(), taskExecutionService));
         }
-        LOGGER.info(
+        LOGGER.fine(
                 String.format(
                         "received slot request, jobID: %d, resource profile: %s, return: %s",
                         jobId, resourceProfile, profile));

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -321,6 +321,7 @@ public void close() throws IOException {
     }
 
     public void ack(Barrier barrier) {
+        log.debug("seatunnel task ack barrier[{}]", this.taskLocation);
         Integer ackSize =
                 cycleAcks.compute(barrier.getId(), (id, count) -> count == null ? 1 : ++count);
         if (ackSize == allCycles.size()) {
@@ -366,6 +367,7 @@ public void notifyAllAction(ConsumerWithException<InternalCheckpointListener> co
 
     @Override
     public void restoreState(List<ActionSubtaskState> actionStateList) throws Exception {
+        log.debug("restoreState for SeaTunnelTask[{}]", actionStateList);
         Map<Long, List<ActionSubtaskState>> stateMap =
                 actionStateList.stream()
                         .collect(
@@ -386,6 +388,7 @@ public void restoreState(List<ActionSubtaskState> actionStateList) throws Except
                             }
                         });
         restoreComplete.complete(null);
+        log.debug("restoreState for SeaTunnelTask finished, actionStateList: {}", actionStateList);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/group/TaskGroupWithIntermediateBlockingQueue.java
Patch:
@@ -32,7 +32,7 @@
 
 public class TaskGroupWithIntermediateBlockingQueue extends AbstractTaskGroupWithIntermediateQueue {
 
-    public static final int QUEUE_SIZE = 100000;
+    public static final int QUEUE_SIZE = 2048;
 
     public TaskGroupWithIntermediateBlockingQueue(
             TaskGroupLocation taskGroupLocation, String taskGroupName, Collection<Task> tasks) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/checkpoint/CloseRequestOperation.java
Patch:
@@ -18,9 +18,9 @@
 package org.apache.seatunnel.engine.server.task.operation.checkpoint;
 
 import org.apache.seatunnel.common.utils.RetryUtils;
-import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
+import org.apache.seatunnel.engine.server.exception.TaskGroupContextNotFoundException;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.serializable.TaskDataSerializerHook;
 import org.apache.seatunnel.engine.server.task.SourceSeaTunnelTask;
@@ -56,7 +56,7 @@ public void run() throws Exception {
                         Constant.OPERATION_RETRY_TIME,
                         true,
                         exception ->
-                                exception instanceof SeaTunnelException
+                                exception instanceof TaskGroupContextNotFoundException
                                         && !server.taskIsEnded(
                                                 readerLocation.getTaskGroupLocation()),
                         Constant.OPERATION_RETRY_SLEEP));

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/AssignSplitOperation.java
Patch:
@@ -19,10 +19,10 @@
 
 import org.apache.seatunnel.api.source.SourceSplit;
 import org.apache.seatunnel.common.utils.RetryUtils;
-import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.common.utils.SerializationUtils;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
+import org.apache.seatunnel.engine.server.exception.TaskGroupContextNotFoundException;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.serializable.TaskDataSerializerHook;
 import org.apache.seatunnel.engine.server.task.SourceSeaTunnelTask;
@@ -69,7 +69,7 @@ public void run() throws Exception {
                         Constant.OPERATION_RETRY_TIME,
                         true,
                         exception ->
-                                exception instanceof SeaTunnelException
+                                exception instanceof TaskGroupContextNotFoundException
                                         && !server.taskIsEnded(taskID.getTaskGroupLocation()),
                         Constant.OPERATION_RETRY_SLEEP));
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/RequestSplitOperation.java
Patch:
@@ -18,9 +18,9 @@
 package org.apache.seatunnel.engine.server.task.operation.source;
 
 import org.apache.seatunnel.common.utils.RetryUtils;
-import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
+import org.apache.seatunnel.engine.server.exception.TaskGroupContextNotFoundException;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.serializable.TaskDataSerializerHook;
 import org.apache.seatunnel.engine.server.task.SourceSplitEnumeratorTask;
@@ -60,7 +60,7 @@ public void run() throws Exception {
                         Constant.OPERATION_RETRY_TIME,
                         true,
                         exception ->
-                                exception instanceof SeaTunnelException
+                                exception instanceof TaskGroupContextNotFoundException
                                         && !server.taskIsEnded(
                                                 enumeratorTaskID.getTaskGroupLocation()),
                         Constant.OPERATION_RETRY_SLEEP));

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceNoMoreElementOperation.java
Patch:
@@ -18,9 +18,9 @@
 package org.apache.seatunnel.engine.server.task.operation.source;
 
 import org.apache.seatunnel.common.utils.RetryUtils;
-import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
+import org.apache.seatunnel.engine.server.exception.TaskGroupContextNotFoundException;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.serializable.TaskDataSerializerHook;
 import org.apache.seatunnel.engine.server.task.SourceSplitEnumeratorTask;
@@ -58,7 +58,7 @@ public void run() throws Exception {
                         Constant.OPERATION_RETRY_TIME,
                         true,
                         exception ->
-                                exception instanceof SeaTunnelException
+                                exception instanceof TaskGroupContextNotFoundException
                                         && !server.taskIsEnded(
                                                 enumeratorTaskID.getTaskGroupLocation()),
                         Constant.OPERATION_RETRY_SLEEP));

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceReaderEventOperation.java
Patch:
@@ -19,10 +19,10 @@
 
 import org.apache.seatunnel.api.source.SourceEvent;
 import org.apache.seatunnel.common.utils.RetryUtils;
-import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.common.utils.SerializationUtils;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
+import org.apache.seatunnel.engine.server.exception.TaskGroupContextNotFoundException;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.serializable.TaskDataSerializerHook;
 import org.apache.seatunnel.engine.server.task.SourceSplitEnumeratorTask;
@@ -64,7 +64,7 @@ public void run() throws Exception {
                         Constant.OPERATION_RETRY_TIME,
                         true,
                         exception ->
-                                exception instanceof SeaTunnelException
+                                exception instanceof TaskGroupContextNotFoundException
                                         && !server.taskIsEnded(taskLocation.getTaskGroupLocation()),
                         Constant.OPERATION_RETRY_SLEEP));
     }

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-api/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/api/CheckpointStorage.java
Patch:
@@ -115,4 +115,7 @@ PipelineState getCheckpoint(String jobId, String pipelineId, String checkpointId
      */
     void deleteCheckpoint(String jobId, String pipelineId, String checkpointId)
             throws CheckpointStorageException;
+
+    void deleteCheckpoint(String jobId, String pipelineId, List<String> checkpointIdList)
+            throws CheckpointStorageException;
 }

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-hdfs/src/test/java/org/apache/seatunnel/engine/checkpoint/storage/hdfs/S3FileCheckpointTest.java
Patch:
@@ -36,8 +36,8 @@ public class S3FileCheckpointTest extends AbstractFileCheckPointTest {
     public static void setup() throws CheckpointStorageException {
         Map<String, String> config = new HashMap<>();
         config.put("storage.type", "s3");
-        config.put("access.key", "your access key");
-        config.put("secret.key", "your secret key");
+        config.put("fs.s3a.access.key", "your access key");
+        config.put("fs.s3a.secret.key", "your secret key");
         config.put("s3.bucket", "s3a://calvin.test.cn");
         config.put(
                 "fs.s3a.aws.credentials.provider",

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-local-file/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/localfile/LocalFileStorageFactory.java
Patch:
@@ -34,7 +34,6 @@
  * <p>deprecated: use @see org.apache.seatunnel.engine.checkpoint.storage.hdfs.HdfsStorageFactory
  * instead
  */
-@Deprecated
 @AutoService(CheckpointStorageFactory.class)
 public class LocalFileStorageFactory implements CheckpointStorageFactory {
 

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/master/JobMetricsTest.java
Patch:
@@ -85,7 +85,7 @@ public void testGetJobMetrics() throws Exception {
                                                 .listAllJob()
                                                 .contains(
                                                         String.format(
-                                                                "{\"jobId\":%s,\"jobStatus\":\"FINISHED\"}",
+                                                                "\"jobId\":%s,\"jobName\":\"Test\",\"jobStatus\":\"FINISHED\"",
                                                                 JOB_1))));
 
         JobMetrics jobMetrics = server.getCoordinatorService().getJobMetrics(JOB_1);

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/client/StarRocksSinkManager.java
Patch:
@@ -169,6 +169,6 @@ public String createBatchLabel() {
         if (!Strings.isNullOrEmpty(sinkConfig.getLabelPrefix())) {
             sb.append(sinkConfig.getLabelPrefix());
         }
-        return sb.append(UUID.randomUUID().toString()).toString();
+        return sb.append(UUID.randomUUID()).toString();
     }
 }

File: seatunnel-common/src/test/java/org/apache/seatunnel/common/utils/JdbcUrlUtilTest.java
Patch:
@@ -33,7 +33,8 @@ public void testMySQLUrlWithDatabase() {
         Assertions.assertTrue(urlInfo.getDefaultDatabase().isPresent());
         Assertions.assertEquals("seatunnel", urlInfo.getDefaultDatabase().get());
         Assertions.assertEquals(
-                "jdbc:mysql://192.168.1.1:5310/seatunnel", urlInfo.getUrlWithDatabase().get());
+                "jdbc:mysql://192.168.1.1:5310/seatunnel?useSSL=true",
+                urlInfo.getUrlWithDatabase().get());
         Assertions.assertEquals("jdbc:mysql://192.168.1.1:5310", urlInfo.getUrlWithoutDatabase());
         Assertions.assertEquals("192.168.1.1", urlInfo.getHost());
         Assertions.assertEquals(5310, urlInfo.getPort());
@@ -50,6 +51,6 @@ public void testMySQLUrlWithoutDatabase() {
         Assertions.assertEquals("jdbc:mysql://192.168.1.1:5310", urlInfo.getUrlWithoutDatabase());
         Assertions.assertEquals("192.168.1.1", urlInfo.getHost());
         Assertions.assertEquals(5310, urlInfo.getPort());
-        Assertions.assertEquals(urlInfo, JdbcUrlUtil.getUrlInfo("jdbc:mysql://192.168.1.1:5310"));
+        Assertions.assertEquals(urlInfo, JdbcUrlUtil.getUrlInfo("jdbc:mysql://192.168.1.1:5310/"));
     }
 }

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/JdbcUrlUtil.java
Patch:
@@ -71,13 +71,13 @@ public UrlInfo(
             this.host = host;
             this.port = port;
             this.defaultDatabase = defaultDatabase;
-            this.suffix = suffix;
+            this.suffix = suffix == null ? "" : suffix;
         }
 
         public Optional<String> getUrlWithDatabase() {
             return StringUtils.isBlank(defaultDatabase)
                     ? Optional.empty()
-                    : Optional.of(urlWithoutDatabase + "/" + defaultDatabase);
+                    : Optional.of(urlWithoutDatabase + "/" + defaultDatabase + suffix);
         }
 
         public Optional<String> getDefaultDatabase() {

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/sink/StarRocksSink.java
Patch:
@@ -84,7 +84,6 @@ private void autoCreateTable(String template) {
         StarRocksCatalog starRocksCatalog =
                 new StarRocksCatalog(
                         "StarRocks",
-                        sinkConfig.getDatabase(),
                         sinkConfig.getUsername(),
                         sinkConfig.getPassword(),
                         sinkConfig.getJdbcUrl());

File: seatunnel-connectors-v2/connector-starrocks/src/test/java/org/apache/seatunnel/connectors/seatunnel/starrocks/StarRocksCatalogTest.java
Patch:
@@ -37,7 +37,7 @@ public class StarRocksCatalogTest {
     public void testCatalog() {
         StarRocksCatalog catalog =
                 new StarRocksCatalog(
-                        "starrocks", "", "root", "123456", "jdbc:mysql://47.108.65.163:9030/");
+                        "starrocks", "root", "123456", "jdbc:mysql://47.108.65.163:9030/");
         List<String> databases = catalog.listDatabases();
         LOGGER.info("find databases: " + databases);
 

File: seatunnel-common/src/test/java/org/apache/seatunnel/common/utils/JdbcUrlUtilTest.java
Patch:
@@ -38,7 +38,8 @@ public void testMySQLUrlWithDatabase() {
         Assertions.assertEquals("192.168.1.1", urlInfo.getHost());
         Assertions.assertEquals(5310, urlInfo.getPort());
         Assertions.assertEquals(
-                urlInfo, JdbcUrlUtil.getUrlInfo("jdbc:mysql://192.168.1.1:5310/seatunnel"));
+                urlInfo,
+                JdbcUrlUtil.getUrlInfo("jdbc:mysql://192.168.1.1:5310/seatunnel?useSSL=true"));
     }
 
     @Test

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/JdbcConnectionPoolFactory.java
Patch:
@@ -36,7 +36,7 @@ public HikariDataSource createPooledDataSource(JdbcSourceConfig sourceConfig) {
         int port = sourceConfig.getPort();
 
         config.setPoolName(CONNECTION_POOL_PREFIX + hostName + ":" + port);
-        config.setJdbcUrl(getJdbcUrl(sourceConfig));
+        config.setJdbcUrl(sourceConfig.getOriginUrl());
         config.setUsername(sourceConfig.getUsername());
         config.setPassword(sourceConfig.getPassword());
         config.setMinimumIdle(MINIMUM_POOL_SIZE);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/MySqlSourceConfig.java
Patch:
@@ -49,6 +49,7 @@ public MySqlSourceConfig(
             int port,
             String username,
             String password,
+            String originUrl,
             int fetchSize,
             String serverTimeZone,
             long connectTimeoutMillis,
@@ -68,6 +69,7 @@ public MySqlSourceConfig(
                 port,
                 username,
                 password,
+                originUrl,
                 fetchSize,
                 serverTimeZone,
                 connectTimeoutMillis,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/MySqlSourceConfigFactory.java
Patch:
@@ -123,6 +123,7 @@ public MySqlSourceConfig create(int subtaskId) {
                 port,
                 username,
                 password,
+                originUrl,
                 fetchSize,
                 serverTimeZone,
                 connectTimeoutMillis,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlIncrementalSource.java
Patch:
@@ -69,6 +69,7 @@ public SourceConfig.Factory<JdbcSourceConfig> createSourceConfigFactory(Readonly
         configFactory.fromReadonlyConfig(readonlyConfig);
         JdbcUrlUtil.UrlInfo urlInfo =
                 JdbcUrlUtil.getUrlInfo(config.get(JdbcCatalogOptions.BASE_URL));
+        configFactory.originUrl(urlInfo.getOrigin());
         configFactory.hostname(urlInfo.getHost());
         configFactory.port(urlInfo.getPort());
         configFactory.startupOptions(startupConfig);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/config/SqlServerSourceConfig.java
Patch:
@@ -49,6 +49,7 @@ public SqlServerSourceConfig(
             int port,
             String username,
             String password,
+            String originUrl,
             int fetchSize,
             String serverTimeZone,
             long connectTimeoutMillis,
@@ -68,6 +69,7 @@ public SqlServerSourceConfig(
                 port,
                 username,
                 password,
+                originUrl,
                 fetchSize,
                 serverTimeZone,
                 connectTimeoutMillis,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/config/SqlServerSourceConfigFactory.java
Patch:
@@ -94,6 +94,7 @@ public SqlServerSourceConfig create(int subtask) {
                 port,
                 username,
                 password,
+                originUrl,
                 fetchSize,
                 serverTimeZone,
                 connectTimeoutMillis,

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/MySqlCatalogFactory.java
Patch:
@@ -49,9 +49,7 @@ public Catalog createCatalog(String catalogName, ReadonlyConfig options) {
                 catalogName,
                 options.get(JdbcCatalogOptions.USERNAME),
                 options.get(JdbcCatalogOptions.PASSWORD),
-                defaultDatabase.get(),
-                urlInfo.getUrlWithoutDatabase(),
-                urlInfo.getUrlWithDatabase().get());
+                urlInfo);
     }
 
     @Override

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/catalog/StarRocksCatalog.java
Patch:
@@ -35,6 +35,7 @@
 import org.apache.seatunnel.api.table.type.PrimitiveByteArrayType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.common.utils.JdbcUrlUtil;
 import org.apache.seatunnel.connectors.seatunnel.starrocks.exception.StarRocksConnectorException;
 
 import org.apache.commons.lang3.StringUtils;
@@ -83,6 +84,7 @@ public StarRocksCatalog(String catalogName, String username, String pwd, String
         checkArgument(StringUtils.isNotBlank(username));
         checkArgument(StringUtils.isNotBlank(pwd));
         checkArgument(StringUtils.isNotBlank(defaultUrl));
+        JdbcUrlUtil.getUrlInfo(defaultUrl);
 
         defaultUrl = defaultUrl.trim();
         if (validateJdbcUrlWithDatabase(defaultUrl)) {

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/exception/PulsarConnectorErrorCode.java
Patch:
@@ -25,7 +25,8 @@ public enum PulsarConnectorErrorCode implements SeaTunnelErrorCode {
     PULSAR_AUTHENTICATION_FAILED("PULSAR-03", "Pulsar authentication failed"),
     SUBSCRIBE_TOPIC_FAILED("PULSAR-04", "Subscribe topic from pulsar failed"),
     GET_LAST_CURSOR_FAILED("PULSAR-05", "Get last cursor of pulsar topic failed"),
-    GET_TOPIC_PARTITION_FAILED("PULSAR-06", "Get partition information of pulsar topic failed");
+    GET_TOPIC_PARTITION_FAILED("PULSAR-06", "Get partition information of pulsar topic failed"),
+    ACK_CUMULATE_FAILED("PULSAR-07", "Pulsar consumer acknowledgeCumulative failed");
 
     private final String code;
     private final String description;

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/reader/PulsarSplitReaderThread.java
Patch:
@@ -118,11 +118,11 @@ public void close() throws IOException {
         }
     }
 
-    public void committingCursor(MessageId offsetsToCommit) {
+    public void committingCursor(MessageId offsetsToCommit) throws PulsarClientException {
         if (consumer == null) {
             consumer = createPulsarConsumer(split);
         }
-        consumer.acknowledgeAsync(offsetsToCommit);
+        consumer.acknowledgeCumulative(offsetsToCommit);
     }
 
     /** Create a specified {@link Consumer} by the given split information. */

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/config/StarRocksOptions.java
Patch:
@@ -26,8 +26,8 @@ public interface StarRocksOptions {
                     .stringType()
                     .noDefaultValue()
                     .withDescription(
-                            "URL has to be without database, like \"jdbc:mysql://localhost:5432/\" or"
-                                    + "\"jdbc:mysql://localhost:5432\" rather than \"jdbc:mysql://localhost:5432/db\"");
+                            "The JDBC URL like \"jdbc:mysql://localhost:9030/\" or"
+                                    + "\"jdbc:mysql://localhost:9030/\" or \"jdbc:mysql://localhost:9030/db\"");
 
     Option<String> USERNAME =
             Options.key("username")

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/config/StarRocksSinkOptions.java
Patch:
@@ -131,6 +131,6 @@ public interface StarRocksSinkOptions {
     Option<StreamLoadFormat> LOAD_FORMAT =
             Options.key("starrocks.config.format")
                     .enumType(StreamLoadFormat.class)
-                    .defaultValue(StreamLoadFormat.CSV)
+                    .defaultValue(StreamLoadFormat.JSON)
                     .withDescription("");
 }

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/catalog/StarRocksCatalog.java
Patch:
@@ -89,13 +89,14 @@ public StarRocksCatalog(String catalogName, String username, String pwd, String
             String[] strings = splitDefaultUrl(defaultUrl);
             this.baseUrl = strings[0];
             this.defaultDatabase = strings[1];
+            this.defaultUrl = defaultUrl;
         } else {
             this.baseUrl = defaultUrl;
+            this.defaultUrl = this.baseUrl + defaultDatabase;
         }
         this.catalogName = catalogName;
         this.username = username;
         this.pwd = pwd;
-        this.defaultUrl = defaultUrl;
     }
 
     public StarRocksCatalog(
@@ -116,6 +117,7 @@ public StarRocksCatalog(
         } else {
             String[] strings = splitDefaultUrl(baseUrl);
             this.baseUrl = strings[0];
+            this.defaultUrl = baseUrl;
         }
         this.catalogName = catalogName;
         this.defaultDatabase = defaultDatabase;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/config/JdbcOptions.java
Patch:
@@ -73,7 +73,7 @@ public interface JdbcOptions {
     Option<Boolean> IS_EXACTLY_ONCE =
             Options.key("is_exactly_once")
                     .booleanType()
-                    .defaultValue(true)
+                    .defaultValue(false)
                     .withDescription("exactly once");
 
     Option<Boolean> GENERATE_SINK_SQL =

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-starrocks-e2e/src/test/java/org/apache/seatunnel/e2e/connector/starrocks/StarRocksCDCSinkIT.java
Patch:
@@ -24,6 +24,7 @@
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.TestTemplate;
 import org.testcontainers.containers.Container;
 import org.testcontainers.containers.GenericContainer;
@@ -52,6 +53,7 @@
 import static org.awaitility.Awaitility.given;
 
 @Slf4j
+@Disabled("There are still errors unfixed @Hisoka-X")
 public class StarRocksCDCSinkIT extends TestSuiteBase implements TestResource {
     private static final String DOCKER_IMAGE = "d87904488/starrocks-starter:2.2.1";
     private static final String DRIVER_CLASS = "com.mysql.cj.jdbc.Driver";

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-starrocks-e2e/src/test/java/org/apache/seatunnel/e2e/connector/starrocks/StarRocksIT.java
Patch:
@@ -28,6 +28,7 @@
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.TestTemplate;
 import org.testcontainers.containers.Container;
 import org.testcontainers.containers.GenericContainer;
@@ -63,6 +64,7 @@
 import static org.awaitility.Awaitility.given;
 
 @Slf4j
+@Disabled("There are still errors unfixed @Hisoka-X")
 public class StarRocksIT extends TestSuiteBase implements TestResource {
     private static final String DOCKER_IMAGE = "d87904488/starrocks-starter:2.2.1";
     private static final String DRIVER_CLASS = "com.mysql.cj.jdbc.Driver";

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/source/HiveSource.java
Patch:
@@ -52,7 +52,7 @@
 import java.util.Map;
 
 import static org.apache.hadoop.fs.CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY;
-import static org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema.SCHEMA;
+import static org.apache.seatunnel.api.table.catalog.CatalogTableUtil.SCHEMA;
 import static org.apache.seatunnel.connectors.seatunnel.file.config.BaseSourceConfig.FILE_PATH;
 import static org.apache.seatunnel.connectors.seatunnel.file.config.BaseSourceConfig.FILE_TYPE;
 import static org.apache.seatunnel.connectors.seatunnel.hive.config.HiveConfig.ORC_INPUT_FORMAT_CLASSNAME;

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/source/StarRocksSourceFactory.java
Patch:
@@ -25,7 +25,7 @@
 
 import com.google.auto.service.AutoService;
 
-import static org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema.SCHEMA;
+import static org.apache.seatunnel.api.table.catalog.CatalogTableUtil.SCHEMA;
 
 @AutoService(Factory.class)
 public class StarRocksSourceFactory implements TableSourceFactory {

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelRow.java
Patch:
@@ -27,7 +27,7 @@
 public final class SeaTunnelRow implements Serializable {
     private static final long serialVersionUID = -1L;
     /** Table identifier, used for the source connector that {@link SupportMultipleTable}. */
-    private String tableId;
+    private String tableId = "";
     /** The kind of change that a row describes in a changelog. */
     private RowKind kind = RowKind.INSERT;
     /** The array to store the actual internal format values. */

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/common/metrics/JobMetrics.java
Patch:
@@ -22,6 +22,8 @@
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.SerializationFeature;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ObjectNode;
 
+import lombok.Getter;
+
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
@@ -45,7 +47,7 @@ public final class JobMetrics implements Serializable {
     private static final Collector<Measurement, ?, Map<String, List<Measurement>>> COLLECTOR =
             Collectors.groupingBy(Measurement::metric);
 
-    private Map<String, List<Measurement>> metrics; // metric name -> set of measurements
+    @Getter private Map<String, List<Measurement>> metrics; // metric name -> set of measurements
 
     JobMetrics() { // needed for deserialization
     }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/common/metrics/Metric.java
Patch:
@@ -17,7 +17,9 @@
 
 package org.apache.seatunnel.api.common.metrics;
 
-public interface Metric {
+import java.io.Serializable;
+
+public interface Metric extends Serializable {
 
     /** Returns the name of the associated metric. */
     String name();

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/exception/CommonErrorCode.java
Patch:
@@ -37,7 +37,8 @@ public enum CommonErrorCode implements SeaTunnelErrorCode {
     HTTP_OPERATION_FAILED(
             "COMMON-13", "Http operation failed, such as (open, close, response) etc..."),
     KERBEROS_AUTHORIZED_FAILED("COMMON-14", "Kerberos authorized failed"),
-    CLASS_NOT_FOUND("COMMON-15", "Class load operation failed");
+    CLASS_NOT_FOUND("COMMON-15", "Class load operation failed"),
+    IMPROPERLY_FORMATTED_JVM_OPTION("COMMON-16", "Encountered improperly formatted JVM option");
 
     private final String code;
     private final String description;

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseSinkConfig.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.seatunnel.common.utils.DateTimeUtils;
 import org.apache.seatunnel.common.utils.DateUtils;
 import org.apache.seatunnel.common.utils.TimeUtils;
+import org.apache.seatunnel.format.text.constant.TextFormatConstant;
 
 import java.util.Arrays;
 import java.util.List;
@@ -31,7 +32,7 @@ public class BaseSinkConfig {
     public static final String NON_PARTITION = "NON_PARTITION";
     public static final String TRANSACTION_ID_SPLIT = "_";
     public static final String TRANSACTION_EXPRESSION = "transactionId";
-    public static final String DEFAULT_FIELD_DELIMITER = String.valueOf('\001');
+    public static final String DEFAULT_FIELD_DELIMITER = TextFormatConstant.SEPARATOR[0];
     public static final String DEFAULT_ROW_DELIMITER = "\n";
     public static final String DEFAULT_PARTITION_DIR_EXPRESSION =
             "${k0}=${v0}/${k1}=${v1}/.../${kn}=${vn}/";

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/exception/FileConnectorErrorCode.java
Patch:
@@ -22,7 +22,8 @@
 public enum FileConnectorErrorCode implements SeaTunnelErrorCode {
     FILE_TYPE_INVALID("FILE-01", "File type is invalid"),
     DATA_DESERIALIZE_FAILED("FILE-02", "Data deserialization failed"),
-    FILE_LIST_GET_FAILED("FILE-03", "Get file list failed");
+    FILE_LIST_GET_FAILED("FILE-03", "Get file list failed"),
+    FILE_LIST_EMPTY("FILE-04", "File list is empty");
 
     private final String code;
     private final String description;

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/OrcWriteStrategy.java
Patch:
@@ -135,7 +135,7 @@ private Writer getOrCreateWriter(@NonNull String filePath) {
         return writer;
     }
 
-    private TypeDescription buildFieldWithRowType(SeaTunnelDataType<?> type) {
+    public static TypeDescription buildFieldWithRowType(SeaTunnelDataType<?> type) {
         switch (type.getSqlType()) {
             case ARRAY:
                 BasicType<?> elementType = ((ArrayType<?, ?>) type).getElementType();

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/ParquetWriteStrategy.java
Patch:
@@ -224,7 +224,7 @@ private Object resolveObject(Object data, SeaTunnelDataType<?> seaTunnelDataType
     }
 
     @SuppressWarnings("checkstyle:MagicNumber")
-    private Type seaTunnelDataType2ParquetDataType(
+    public static Type seaTunnelDataType2ParquetDataType(
             String fieldName, SeaTunnelDataType<?> seaTunnelDataType) {
         switch (seaTunnelDataType.getSqlType()) {
             case ARRAY:

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/BaseFileSource.java
Patch:
@@ -21,6 +21,7 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
+import org.apache.seatunnel.api.source.SupportColumnProjection;
 import org.apache.seatunnel.api.source.SupportParallelism;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
@@ -35,7 +36,8 @@
 
 public abstract class BaseFileSource
         implements SeaTunnelSource<SeaTunnelRow, FileSourceSplit, FileSourceState>,
-                SupportParallelism {
+                SupportParallelism,
+                SupportColumnProjection {
     protected SeaTunnelRowType rowType;
     protected ReadStrategy readStrategy;
     protected HadoopConf hadoopConf;

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/commit/HiveSinkAggregatedCommitter.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.connectors.seatunnel.file.sink.util.FileSystemUtils;
 import org.apache.seatunnel.connectors.seatunnel.hive.utils.HiveMetaStoreProxy;
 
+import org.apache.hadoop.hive.metastore.api.AlreadyExistsException;
 import org.apache.thrift.TException;
 
 import lombok.extern.slf4j.Slf4j;
@@ -63,6 +64,8 @@ public List<FileAggregatedCommitInfo> commit(
                 try {
                     hiveMetaStore.addPartitions(dbName, tableName, partitions);
                     log.info("Add these partitions {}", partitions);
+                } catch (AlreadyExistsException e) {
+                    log.warn("These partitions {} are already exists", partitions);
                 } catch (TException e) {
                     log.error("Failed to add these partitions {}", partitions, e);
                     errorCommitInfos.add(aggregatedCommitInfo);

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/config/Config.java
Patch:
@@ -33,6 +33,8 @@ public class Config {
 
     public static final String TEXT_FORMAT = "text";
 
+    public static final String CANNAL_FORMAT = "canal-json";
+
     /** The default field delimiter is “,” */
     public static final String DEFAULT_FIELD_DELIMITER = ",";
 

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/reader/PulsarSourceReader.java
Patch:
@@ -172,6 +172,9 @@ public void addSplits(List<PulsarPartitionSplit> splits) {
                     PulsarSplitReaderThread splitReaderThread =
                             createPulsarSplitReaderThread(split);
                     try {
+                        splitReaderThread.setName(
+                                "Pulsar Source Data Consumer "
+                                        + split.getPartition().getPartition());
                         splitReaderThread.open();
                         splitReaders.put(split.splitId(), splitReaderThread);
                         splitReaderThread.start();

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/sink/StarRocksSinkWriter.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.connectors.seatunnel.starrocks.sink;
 
+import org.apache.seatunnel.shade.com.typesafe.config.Config;
+
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.exception.CommonErrorCode;

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-starrocks-e2e/src/test/java/org/apache/seatunnel/e2e/connector/starrocks/StarRocksIT.java
Patch:
@@ -241,7 +241,8 @@ public void tearDown() throws Exception {
     @TestTemplate
     public void testStarRocksSink(TestContainer container)
             throws IOException, InterruptedException {
-        Container.ExecResult execResult = container.executeJob("/starrocks-jdbc-to-starrocks.conf");
+        Container.ExecResult execResult =
+                container.executeJob("/starrocks-thrift-to-starrocks-streamload.conf");
         Assertions.assertEquals(0, execResult.getExitCode());
         try {
             assertHasData(SINK_TABLE);

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/util/ContainerUtil.java
Patch:
@@ -25,6 +25,8 @@
 import org.apache.seatunnel.api.table.factory.FactoryException;
 import org.apache.seatunnel.e2e.common.container.TestContainer;
 
+import org.apache.commons.lang3.StringUtils;
+
 import org.junit.jupiter.api.Assertions;
 import org.testcontainers.containers.GenericContainer;
 import org.testcontainers.utility.MountableFile;
@@ -123,7 +125,7 @@ public static void copySeaTunnelStarterToContainer(
             String seatunnelHomeInContainer) {
         // solve the problem of multi modules such as
         // seatunnel-flink-starter/seatunnel-flink-13-starter
-        final String[] splits = startModuleName.split(File.separator);
+        final String[] splits = StringUtils.split(startModuleName, File.separator);
         final String startJarName = splits[splits.length - 1] + ".jar";
         // copy starter
         final String startJarPath =

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceIT.java
Patch:
@@ -56,6 +56,7 @@
  * capability in case of cluster node failure
  */
 @Slf4j
+@Disabled
 public class ClusterFaultToleranceIT {
 
     public static final String DYNAMIC_TEST_CASE_NAME = "dynamic_test_case_name";
@@ -69,7 +70,6 @@ public class ClusterFaultToleranceIT {
 
     @SuppressWarnings("checkstyle:RegexpSingleline")
     @Test
-    @Disabled
     public void testBatchJobRunOkIn2Node() throws ExecutionException, InterruptedException {
         String testCaseName = "testBatchJobRunOkIn2Node";
         String testClusterName = "ClusterFaultToleranceIT_testBatchJobRunOkIn2Node";
@@ -192,7 +192,6 @@ private ImmutablePair<String, String> createTestResources(
 
     @SuppressWarnings("checkstyle:RegexpSingleline")
     @Test
-    @Disabled
     public void testStreamJobRunOkIn2Node() throws ExecutionException, InterruptedException {
         String testCaseName = "testStreamJobRunOkIn2Node";
         String testClusterName = "ClusterFaultToleranceIT_testStreamJobRunOkIn2Node";

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceTwoPipelineIT.java
Patch:
@@ -55,6 +55,7 @@
  * data consistency assurance capability in case of cluster node failure
  */
 @Slf4j
+@Disabled
 public class ClusterFaultToleranceTwoPipelineIT {
 
     public static final String TEST_TEMPLATE_FILE_NAME =

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/JobExecutionEnvironment.java
Patch:
@@ -33,6 +33,8 @@
 
 import org.apache.commons.lang3.tuple.ImmutablePair;
 
+import org.apache.commons.lang3.tuple.ImmutablePair;
+
 import com.hazelcast.logging.ILogger;
 import com.hazelcast.logging.Logger;
 

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/JobMetricsRunner.java
Patch:
@@ -53,6 +53,8 @@ public void run() {
             log.info(
                     StringFormatUtils.formatTable(
                             "Job Progress Information",
+                            "Job Id",
+                            jobId,
                             "Read Count So Far",
                             jobMetricsSummary.getSourceReadCount(),
                             "Write Count So Far",

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/Constant.java
Patch:
@@ -35,7 +35,7 @@ public class Constant {
 
     public static final String HAZELCAST_SEATUNNEL_DEFAULT_YAML = "seatunnel.yaml";
 
-    public static final int OPERATION_RETRY_TIME = 10;
+    public static final int OPERATION_RETRY_TIME = 30;
 
     public static final int OPERATION_RETRY_SLEEP = 2000;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/NodeExtension.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.engine.common.config.SeaTunnelConfig;
 import org.apache.seatunnel.engine.server.log.Log4j2HttpGetCommandProcessor;
 import org.apache.seatunnel.engine.server.log.Log4j2HttpPostCommandProcessor;
+import org.apache.seatunnel.engine.server.rest.RestHttpGetCommandProcessor;
 
 import com.hazelcast.cluster.ClusterState;
 import com.hazelcast.instance.impl.DefaultNodeExtension;
@@ -77,6 +78,7 @@ public TextCommandService createTextCommandService() {
             {
                 register(HTTP_GET, new Log4j2HttpGetCommandProcessor(this));
                 register(HTTP_POST, new Log4j2HttpPostCommandProcessor(this));
+                register(HTTP_GET, new RestHttpGetCommandProcessor(this));
             }
         };
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlan.java
Patch:
@@ -225,6 +225,9 @@ private void subPlanDone(SubPlan subPlan, PipelineStatus pipelineStatus) {
      * @param subPlan subPlan
      */
     private void notifyCheckpointManagerPipelineEnd(@NonNull SubPlan subPlan) {
+        if (jobMaster.getCheckpointManager() == null) {
+            return;
+        }
         jobMaster
                 .getCheckpointManager()
                 .listenPipeline(

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -411,6 +411,8 @@ public void restorePipeline() {
                         String.format(
                                 "Restore pipeline %s error with exception: %s",
                                 pipelineFullName, ExceptionUtils.getMessage(e)));
+                                "Restore pipeline %s error with exception: ", pipelineFullName),
+                        e);
                 cancelPipeline();
             }
         }

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/catalog/StarRocksCatalog.java
Patch:
@@ -62,7 +62,7 @@
 public class StarRocksCatalog implements Catalog {
 
     protected final String catalogName;
-    protected String defaultDatabase = "default";
+    protected String defaultDatabase = "information_schema";
     protected final String username;
     protected final String pwd;
     protected final String baseUrl;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/PendingCheckpoint.java
Patch:
@@ -124,7 +124,7 @@ public void acknowledgeTask(TaskLocation taskLocation, List<ActionSubtaskState>
         for (ActionSubtaskState state : states) {
             ActionState actionState = actionStates.get(state.getActionId());
             if (actionState == null) {
-                return;
+                continue;
             }
             stateSize += state.getState().stream().filter(Objects::nonNull).map(s -> s.length).count();
             actionState.reportState(state.getIndex(), state);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/ExecutionPlanGenerator.java
Patch:
@@ -201,13 +201,14 @@ private Set<ExecutionEdge> generateShuffleEdges(Set<ExecutionEdge> executionEdge
         String shuffleActionName = String.format("Shuffle [%s -> table[0~%s]]",
             sourceAction.getName(), ((MultipleRowType) sourceProducedType).getTableIds().length - 1);
         ShuffleAction shuffleAction = new ShuffleAction(shuffleVertexId, shuffleActionName, shuffleConfig);
-        // multiple-row shuffle default parallelism is 1
-        shuffleAction.setParallelism(1);
+        shuffleAction.setParallelism(sourceAction.getParallelism());
         ExecutionVertex shuffleVertex = new ExecutionVertex(shuffleVertexId, shuffleAction, shuffleAction.getParallelism());
         ExecutionEdge sourceToShuffleEdge = new ExecutionEdge(sourceExecutionVertex, shuffleVertex);
         newExecutionEdges.add(sourceToShuffleEdge);
 
         for (ExecutionVertex sinkVertex : sinkVertices) {
+            sinkVertex.setParallelism(1);
+            sinkVertex.getAction().setParallelism(1);
             ExecutionEdge shuffleToSinkEdge = new ExecutionEdge(shuffleVertex, sinkVertex);
             newExecutionEdges.add(shuffleToSinkEdge);
         }

File: seatunnel-core/seatunnel-starter/src/main/java/org/apache/seatunnel/core/starter/seatunnel/command/ClientExecuteCommand.java
Patch:
@@ -45,7 +45,6 @@
 import java.time.Duration;
 import java.time.LocalDateTime;
 import java.util.Random;
-import java.util.concurrent.ExecutionException;
 import java.util.concurrent.Executors;
 import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.TimeUnit;
@@ -137,7 +136,7 @@ public void execute() throws CommandExecuteException {
                 // get job statistic information when job finished
                 jobMetricsSummary = engineClient.getJobMetricsSummary(jobId);
             }
-        } catch (ExecutionException | InterruptedException e) {
+        } catch (Exception e) {
             throw new CommandExecuteException("SeaTunnel job executed failed", e);
         } finally {
             if (engineClient != null) {

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/catalog/ConstraintKey.java
Patch:
@@ -53,7 +53,7 @@ public static ConstraintKey of(ConstraintType constraintType,
 
     @Data
     @AllArgsConstructor
-    public static class ConstraintKeyColumn {
+    public static class ConstraintKeyColumn implements Serializable{
         private final String columnName;
         private final ColumnSortType sortType;
 

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-hdfs/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/hdfs/HdfsStorage.java
Patch:
@@ -226,7 +226,7 @@ public PipelineState getCheckpoint(String jobId, String pipelineId, String check
     }
 
     @Override
-    public void deleteCheckpoint(String jobId, String pipelineId, String checkpointId) throws CheckpointStorageException {
+    public synchronized void deleteCheckpoint(String jobId, String pipelineId, String checkpointId) throws CheckpointStorageException {
         String path = getStorageParentDirectory() + jobId;
         List<String> fileNames = getFileNames(path);
         if (fileNames.isEmpty()) {

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-local-file/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/localfile/LocalFileStorage.java
Patch:
@@ -242,7 +242,7 @@ public PipelineState getCheckpoint(String jobId, String pipelineId, String check
     }
 
     @Override
-    public void deleteCheckpoint(String jobId, String pipelineId, String checkpointId) throws CheckpointStorageException {
+    public synchronized void deleteCheckpoint(String jobId, String pipelineId, String checkpointId) throws CheckpointStorageException {
         Collection<File> fileList = FileUtils.listFiles(new File(getStorageParentDirectory() + jobId), FILE_EXTENSIONS, false);
         if (fileList.isEmpty()) {
             throw new CheckpointStorageException("No checkpoint found for job " + jobId);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/external/IncrementalSourceScanFetcher.java
Patch:
@@ -35,8 +35,8 @@
 import org.apache.kafka.connect.source.SourceRecord;
 
 import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.Iterator;
+import java.util.LinkedHashMap;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ExecutorService;
@@ -118,7 +118,7 @@ public Iterator<SourceRecords> pollSplitRecords() throws InterruptedException {
             boolean reachChangeLogEnd = false;
             SourceRecord lowWatermark = null;
             SourceRecord highWatermark = null;
-            Map<Struct, SourceRecord> outputBuffer = new HashMap<>();
+            Map<Struct, SourceRecord> outputBuffer = new LinkedHashMap<>();
             while (!reachChangeLogEnd) {
                 checkReadException();
                 List<DataChangeEvent> batch = queue.poll();

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/MultipleTableJobConfigParser.java
Patch:
@@ -171,6 +171,9 @@ private void fillJobConfig() {
 
     public void parserSource(Config sourceConfig, ClassLoader classLoader) {
         List<CatalogTable> catalogTables = CatalogTableUtil.getCatalogTables(sourceConfig, classLoader);
+        if (catalogTables.isEmpty()) {
+            throw new JobDefineCheckException("The source needs catalog table, please configure `catalog` or `schema` options.");
+        }
         ReadonlyConfig readonlyConfig = ReadonlyConfig.fromConfig(sourceConfig);
         String factoryId = getFactoryId(readonlyConfig);
         String tableId = readonlyConfig.getOptional(CommonOptions.RESULT_TABLE_NAME).orElse("default");

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/AbstractJdbcCatalog.java
Patch:
@@ -230,7 +230,7 @@ protected List<ConstraintKey> getConstraintKeys(DatabaseMetaData metaData, Strin
     }
 
     protected Optional<String> getColumnDefaultValue(DatabaseMetaData metaData, String table, String column) throws SQLException {
-        try (ResultSet resultSet = metaData.getColumns(null, null, table, "MyColumn")) {
+        try (ResultSet resultSet = metaData.getColumns(null, null, table, column)) {
             while (resultSet.next()) {
                 String defaultValue = resultSet.getString("COLUMN_DEF");
                 return Optional.ofNullable(defaultValue);

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/FactoryUtil.java
Patch:
@@ -271,7 +271,7 @@ public static OptionRule sinkFullOptionRule(@NonNull TableSinkFactory factory) {
                     OptionRule.builder().required(saveMode).build();
                 sinkOptionRule.getOptionalOptions().addAll(sinkCommonOptionRule.getOptionalOptions());
             }
-        } catch (UnsupportedOperationException e) {
+        } catch (Exception e) {
             LOG.warn("Add save mode option need sink connector support create sink by TableSinkFactory");
         }
 

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/reader/PulsarSourceReader.java
Patch:
@@ -172,6 +172,9 @@ public void addSplits(List<PulsarPartitionSplit> splits) {
                     PulsarSplitReaderThread splitReaderThread =
                             createPulsarSplitReaderThread(split);
                     try {
+                        splitReaderThread.setName(
+                                "Pulsar Source Data Consumer "
+                                        + split.getPartition().getPartition());
                         splitReaderThread.open();
                         splitReaders.put(split.splitId(), splitReaderThread);
                         splitReaderThread.start();

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/config/JdbcSourceConfigFactory.java
Patch:
@@ -192,7 +192,7 @@ public JdbcSourceConfigFactory fromReadonlyConfig(ReadonlyConfig config) {
         // TODO: support multi-table
         this.databaseList = Collections.singletonList(config.get(JdbcSourceOptions.DATABASE_NAME));
         this.tableList = Collections.singletonList(config.get(JdbcSourceOptions.DATABASE_NAME)
-            + "." + config.get(JdbcSourceOptions.TABLE_NAME));
+            + "\\." + config.get(JdbcSourceOptions.TABLE_NAME));
         this.distributionFactorUpper = config.get(JdbcSourceOptions.CHUNK_KEY_EVEN_DISTRIBUTION_FACTOR_UPPER_BOUND);
         this.distributionFactorLower = config.get(JdbcSourceOptions.CHUNK_KEY_EVEN_DISTRIBUTION_FACTOR_LOWER_BOUND);
         this.splitSize = config.get(SourceOptions.SNAPSHOT_SPLIT_SIZE);

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/sink/StarRocksSink.java
Patch:
@@ -38,11 +38,13 @@
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
 import com.google.auto.service.AutoService;
+import lombok.NoArgsConstructor;
 import org.apache.commons.lang3.StringUtils;
 
 import java.util.Collections;
 import java.util.List;
 
+@NoArgsConstructor
 @AutoService(SeaTunnelSink.class)
 public class StarRocksSink extends AbstractSimpleSink<SeaTunnelRow, Void> implements SupportDataSaveMode {
 

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/JobConfigParser.java
Patch:
@@ -158,7 +158,7 @@ void jobConfigAnalyze(@NonNull Config envConfigs) {
         if (envConfigs.hasPath(EnvCommonOptions.CHECKPOINT_INTERVAL.key())) {
             jobConfig.getEnvOptions()
                 .put(EnvCommonOptions.CHECKPOINT_INTERVAL.key(),
-                    envConfigs.getInt(EnvCommonOptions.CHECKPOINT_INTERVAL.key()));
+                    envConfigs.getLong(EnvCommonOptions.CHECKPOINT_INTERVAL.key()));
         }
     }
 

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/MultipleTableJobConfigParser.java
Patch:
@@ -109,11 +109,11 @@ public ImmutablePair<List<Action>, Set<URL>> parse() {
         if (!envOptions.get(EnvCommonOptions.MULTIPLE_TABLE_ENABLE)) {
             return fallbackParser.parse();
         }
-        List<URL> connectorJars = null;
+        List<URL> connectorJars = new ArrayList<>();
         try {
             connectorJars = FileUtils.searchJarFiles(Common.connectorJarDir("seatunnel"));
         } catch (IOException e) {
-            throw new RuntimeException(e);
+            LOGGER.info(e);
         }
         ClassLoader classLoader = new SeaTunnelChildFirstClassLoader(connectorJars);
         Thread.currentThread().setContextClassLoader(classLoader);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -212,7 +212,7 @@ private CheckpointConfig createJobCheckpointConfig(CheckpointConfig defaultCheck
         jobCheckpointConfig.setStorage(jobCheckpointStorageConfig);
 
         if (jobEnv.containsKey(EnvCommonOptions.CHECKPOINT_INTERVAL.key())) {
-            jobCheckpointConfig.setCheckpointInterval((Integer) jobEnv.get(EnvCommonOptions.CHECKPOINT_INTERVAL.key()));
+            jobCheckpointConfig.setCheckpointInterval((Long) jobEnv.get(EnvCommonOptions.CHECKPOINT_INTERVAL.key()));
         }
         return jobCheckpointConfig;
     }

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/catalog/ElasticSearchDataTypeConvertor.java
Patch:
@@ -80,7 +80,7 @@ public SeaTunnelDataType<?> toSeaTunnelType(String connectorDataType, Map<String
             case DATE:
                 return LocalTimeType.LOCAL_DATE_TIME_TYPE;
             default:
-                throw new DataTypeConvertException("unsupported connectorDataType: " + connectorDataType);
+                return BasicType.STRING_TYPE;
         }
     }
 

File: seatunnel-connectors-v2/connector-iceberg/src/main/java/org/apache/seatunnel/connectors/seatunnel/iceberg/source/IcebergSourceFactory.java
Patch:
@@ -21,13 +21,13 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
+import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 
 import com.google.auto.service.AutoService;
 
 import static org.apache.seatunnel.connectors.seatunnel.iceberg.config.CommonConfig.KEY_CASE_SENSITIVE;
 import static org.apache.seatunnel.connectors.seatunnel.iceberg.config.CommonConfig.KEY_CATALOG_NAME;
 import static org.apache.seatunnel.connectors.seatunnel.iceberg.config.CommonConfig.KEY_CATALOG_TYPE;
-import static org.apache.seatunnel.connectors.seatunnel.iceberg.config.CommonConfig.KEY_FIELDS;
 import static org.apache.seatunnel.connectors.seatunnel.iceberg.config.CommonConfig.KEY_NAMESPACE;
 import static org.apache.seatunnel.connectors.seatunnel.iceberg.config.CommonConfig.KEY_TABLE;
 import static org.apache.seatunnel.connectors.seatunnel.iceberg.config.CommonConfig.KEY_URI;
@@ -55,7 +55,7 @@ public OptionRule optionRule() {
                         KEY_CATALOG_NAME, KEY_CATALOG_TYPE, KEY_WAREHOUSE, KEY_NAMESPACE, KEY_TABLE)
                 .conditional(KEY_CATALOG_TYPE, HIVE, KEY_URI)
                 .optional(
-                        KEY_FIELDS,
+                        SeaTunnelSchema.SCHEMA,
                         KEY_CASE_SENSITIVE,
                         KEY_START_SNAPSHOT_TIMESTAMP,
                         KEY_START_SNAPSHOT_ID,

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/schema/SeaTunnelSchema.java
Patch:
@@ -152,7 +152,7 @@ private static SeaTunnelDataType<?> parseTypeByString(String type) {
         } catch (IllegalArgumentException e) {
             String errorMsg =
                     String.format(
-                            "Field type not support [%s], currently only support [array, map, string, boolean, tinyint, smallint, int, bigint, float, double, decimal, null, bytes, date, time, timestamp]",
+                            "Field type not support [%s], currently only support [array, map, string, boolean, tinyint, smallint, int, bigint, float, double, decimal, null, bytes, date, time, timestamp, row]",
                             type.toUpperCase());
             throw new RuntimeException(errorMsg);
         }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseSinkConfig.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.seatunnel.common.utils.DateTimeUtils;
 import org.apache.seatunnel.common.utils.DateUtils;
 import org.apache.seatunnel.common.utils.TimeUtils;
+import org.apache.seatunnel.format.text.constant.TextFormatConstant;
 
 import java.util.Arrays;
 import java.util.List;
@@ -31,7 +32,7 @@ public class BaseSinkConfig {
     public static final String NON_PARTITION = "NON_PARTITION";
     public static final String TRANSACTION_ID_SPLIT = "_";
     public static final String TRANSACTION_EXPRESSION = "transactionId";
-    public static final String DEFAULT_FIELD_DELIMITER = String.valueOf('\001');
+    public static final String DEFAULT_FIELD_DELIMITER = TextFormatConstant.SEPARATOR[0];
     public static final String DEFAULT_ROW_DELIMITER = "\n";
     public static final String DEFAULT_PARTITION_DIR_EXPRESSION =
             "${k0}=${v0}/${k1}=${v1}/.../${kn}=${vn}/";

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/exception/FileConnectorErrorCode.java
Patch:
@@ -22,7 +22,8 @@
 public enum FileConnectorErrorCode implements SeaTunnelErrorCode {
     FILE_TYPE_INVALID("FILE-01", "File type is invalid"),
     DATA_DESERIALIZE_FAILED("FILE-02", "Data deserialization failed"),
-    FILE_LIST_GET_FAILED("FILE-03", "Get file list failed");
+    FILE_LIST_GET_FAILED("FILE-03", "Get file list failed"),
+    FILE_LIST_EMPTY("FILE-04", "File list is empty");
 
     private final String code;
     private final String description;

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/OrcWriteStrategy.java
Patch:
@@ -135,7 +135,7 @@ private Writer getOrCreateWriter(@NonNull String filePath) {
         return writer;
     }
 
-    private TypeDescription buildFieldWithRowType(SeaTunnelDataType<?> type) {
+    public static TypeDescription buildFieldWithRowType(SeaTunnelDataType<?> type) {
         switch (type.getSqlType()) {
             case ARRAY:
                 BasicType<?> elementType = ((ArrayType<?, ?>) type).getElementType();

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/ParquetWriteStrategy.java
Patch:
@@ -224,7 +224,7 @@ private Object resolveObject(Object data, SeaTunnelDataType<?> seaTunnelDataType
     }
 
     @SuppressWarnings("checkstyle:MagicNumber")
-    private Type seaTunnelDataType2ParquetDataType(
+    public static Type seaTunnelDataType2ParquetDataType(
             String fieldName, SeaTunnelDataType<?> seaTunnelDataType) {
         switch (seaTunnelDataType.getSqlType()) {
             case ARRAY:

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/BaseFileSource.java
Patch:
@@ -21,6 +21,7 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
+import org.apache.seatunnel.api.source.SupportColumnProjection;
 import org.apache.seatunnel.api.source.SupportParallelism;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
@@ -35,7 +36,8 @@
 
 public abstract class BaseFileSource
         implements SeaTunnelSource<SeaTunnelRow, FileSourceSplit, FileSourceState>,
-                SupportParallelism {
+                SupportParallelism,
+                SupportColumnProjection {
     protected SeaTunnelRowType rowType;
     protected ReadStrategy readStrategy;
     protected HadoopConf hadoopConf;

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/commit/HiveSinkAggregatedCommitter.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.connectors.seatunnel.file.sink.util.FileSystemUtils;
 import org.apache.seatunnel.connectors.seatunnel.hive.utils.HiveMetaStoreProxy;
 
+import org.apache.hadoop.hive.metastore.api.AlreadyExistsException;
 import org.apache.thrift.TException;
 
 import lombok.extern.slf4j.Slf4j;
@@ -63,6 +64,8 @@ public List<FileAggregatedCommitInfo> commit(
                 try {
                     hiveMetaStore.addPartitions(dbName, tableName, partitions);
                     log.info("Add these partitions {}", partitions);
+                } catch (AlreadyExistsException e) {
+                    log.warn("These partitions {} are already exists", partitions);
                 } catch (TException e) {
                     log.error("Failed to add these partitions {}", partitions, e);
                     errorCommitInfos.add(aggregatedCommitInfo);

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSource.java
Patch:
@@ -46,6 +46,7 @@
 import org.apache.seatunnel.format.json.canal.CanalJsonDeserializationSchema;
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
 import org.apache.seatunnel.format.text.TextDeserializationSchema;
+import org.apache.seatunnel.format.text.constant.TextFormatConstant;
 
 import org.apache.kafka.common.TopicPartition;
 
@@ -259,7 +260,7 @@ private void setDeserialization(Config config) {
             this.deserializationSchema =
                     TextDeserializationSchema.builder()
                             .seaTunnelRowType(typeInfo)
-                            .delimiter(String.valueOf('\002'))
+                            .delimiter(TextFormatConstant.PLACEHOLDER)
                             .build();
         }
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/TaskExecutionService.java
Patch:
@@ -36,7 +36,7 @@
 import org.apache.seatunnel.engine.server.execution.TaskGroupLocation;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.execution.TaskTracker;
-import org.apache.seatunnel.engine.server.metrics.MetricsContext;
+import org.apache.seatunnel.engine.server.metrics.SeaTunnelMetricsContext;
 import org.apache.seatunnel.engine.server.task.SeaTunnelTask;
 import org.apache.seatunnel.engine.server.task.TaskGroupImmutableInformation;
 import org.apache.seatunnel.engine.server.task.operation.NotifyTaskStatusOperation;
@@ -432,7 +432,7 @@ private synchronized void updateMetricsContextInImap() {
         contextMap.putAll(executionContexts);
         contextMap.putAll(finishedExecutionContexts);
         try {
-            IMap<TaskLocation, MetricsContext> map =
+            IMap<TaskLocation, SeaTunnelMetricsContext> map =
                     nodeEngine.getHazelcastInstance().getMap(Constant.IMAP_RUNNING_JOB_METRICS);
             contextMap.forEach(
                     (taskGroupLocation, taskGroupContext) -> {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/Task.java
Patch:
@@ -17,10 +17,10 @@
 
 package org.apache.seatunnel.engine.server.execution;
 
+import org.apache.seatunnel.api.common.metrics.MetricsContext;
 import org.apache.seatunnel.engine.core.checkpoint.InternalCheckpointListener;
 import org.apache.seatunnel.engine.server.checkpoint.ActionSubtaskState;
 import org.apache.seatunnel.engine.server.checkpoint.Stateful;
-import org.apache.seatunnel.engine.server.metrics.MetricsContext;
 import org.apache.seatunnel.engine.server.task.record.Barrier;
 
 import com.hazelcast.internal.metrics.DynamicMetricsProvider;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -50,7 +50,7 @@
 import org.apache.seatunnel.engine.server.execution.TaskGroupLocation;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.metrics.JobMetricsUtil;
-import org.apache.seatunnel.engine.server.metrics.MetricsContext;
+import org.apache.seatunnel.engine.server.metrics.SeaTunnelMetricsContext;
 import org.apache.seatunnel.engine.server.resourcemanager.ResourceManager;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.SlotProfile;
 import org.apache.seatunnel.engine.server.scheduler.JobScheduler;
@@ -488,7 +488,7 @@ public void removeMetricsContext(
             PipelineLocation pipelineLocation, PipelineStatus pipelineStatus) {
         if (pipelineStatus.equals(PipelineStatus.FINISHED) && !checkpointManager.isSavePointEnd()
                 || pipelineStatus.equals(PipelineStatus.CANCELED)) {
-            IMap<TaskLocation, MetricsContext> map =
+            IMap<TaskLocation, SeaTunnelMetricsContext> map =
                     nodeEngine.getHazelcastInstance().getMap(Constant.IMAP_RUNNING_JOB_METRICS);
             map.keySet().stream()
                     .filter(

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSplitEnumeratorTask.java
Patch:
@@ -96,7 +96,8 @@ public void init() throws Exception {
                 "starting seatunnel source split enumerator task, source name: "
                         + source.getName());
         enumeratorContext =
-                new SeaTunnelSplitEnumeratorContext<>(this.source.getParallelism(), this);
+                new SeaTunnelSplitEnumeratorContext<>(
+                        this.source.getParallelism(), this, getMetricsContext());
         enumeratorStateSerializer = this.source.getSource().getEnumeratorStateSerializer();
         taskMemberMapping = new ConcurrentHashMap<>();
         taskIDToTaskLocationMapping = new ConcurrentHashMap<>();

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/TransformSeaTunnelTask.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.engine.server.task;
 
+import org.apache.seatunnel.api.common.metrics.MetricsContext;
 import org.apache.seatunnel.api.table.type.Record;
 import org.apache.seatunnel.api.transform.Collector;
 import org.apache.seatunnel.engine.core.dag.actions.SourceAction;
@@ -61,7 +62,8 @@ public void init() throws Exception {
     protected SourceFlowLifeCycle<?, ?> createSourceFlowLifeCycle(
             SourceAction<?, ?, ?> sourceAction,
             SourceConfig config,
-            CompletableFuture<Void> completableFuture) {
+            CompletableFuture<Void> completableFuture,
+            MetricsContext metricsContext) {
         throw new UnsupportedOperationException(
                 "TransformSeaTunnelTask can't create SourceFlowLifeCycle");
     }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/common/metrics/JobMetrics.java
Patch:
@@ -22,6 +22,8 @@
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.SerializationFeature;
 import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ObjectNode;
 
+import lombok.Getter;
+
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
@@ -45,7 +47,7 @@ public final class JobMetrics implements Serializable {
     private static final Collector<Measurement, ?, Map<String, List<Measurement>>> COLLECTOR =
             Collectors.groupingBy(Measurement::metric);
 
-    private Map<String, List<Measurement>> metrics; // metric name -> set of measurements
+    @Getter private Map<String, List<Measurement>> metrics; // metric name -> set of measurements
 
     JobMetrics() { // needed for deserialization
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/NodeExtension.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.engine.common.config.SeaTunnelConfig;
 import org.apache.seatunnel.engine.server.log.Log4j2HttpGetCommandProcessor;
 import org.apache.seatunnel.engine.server.log.Log4j2HttpPostCommandProcessor;
+import org.apache.seatunnel.engine.server.rest.RestHttpGetCommandProcessor;
 
 import com.hazelcast.cluster.ClusterState;
 import com.hazelcast.instance.impl.DefaultNodeExtension;
@@ -77,6 +78,7 @@ public TextCommandService createTextCommandService() {
             {
                 register(HTTP_GET, new Log4j2HttpGetCommandProcessor(this));
                 register(HTTP_POST, new Log4j2HttpPostCommandProcessor(this));
+                register(HTTP_GET, new RestHttpGetCommandProcessor(this));
             }
         };
     }

File: seatunnel-core/seatunnel-starter/src/main/java/org/apache/seatunnel/core/starter/seatunnel/command/ClientExecuteCommand.java
Patch:
@@ -211,7 +211,8 @@ private String creatRandomClusterName(String namePrefix) {
 
     private void shutdownHook(ClientJobProxy clientJobProxy) {
         if (clientCommandArgs.isCloseJob()) {
-            if (jobStatus == null || !jobStatus.isEndState()) {
+            if (clientJobProxy.getJobResultCache() == null
+                    && (jobStatus == null || !jobStatus.isEndState())) {
                 log.warn("Task will be closed due to client shutdown.");
                 clientJobProxy.cancelJob();
             }

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/util/ContainerUtil.java
Patch:
@@ -25,6 +25,8 @@
 import org.apache.seatunnel.api.table.factory.FactoryException;
 import org.apache.seatunnel.e2e.common.container.TestContainer;
 
+import org.apache.commons.lang3.StringUtils;
+
 import org.junit.jupiter.api.Assertions;
 import org.testcontainers.containers.GenericContainer;
 import org.testcontainers.utility.MountableFile;
@@ -123,7 +125,7 @@ public static void copySeaTunnelStarterToContainer(
             String seatunnelHomeInContainer) {
         // solve the problem of multi modules such as
         // seatunnel-flink-starter/seatunnel-flink-13-starter
-        final String[] splits = startModuleName.split(File.separator);
+        final String[] splits = StringUtils.split(startModuleName, File.separator);
         final String startJarName = splits[splits.length - 1] + ".jar";
         // copy starter
         final String startJarPath =

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/sql/MysqlCreateTableSqlBuilder.java
Patch:
@@ -26,7 +26,7 @@
 import org.apache.seatunnel.api.table.catalog.PrimaryKey;
 import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.catalog.TableSchema;
-import org.apache.seatunnel.connectors.seatunnel.jdbc.utils.DataTypeUtils;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.catalog.MysqlDataTypeConvertor;
 
 import org.apache.commons.collections4.CollectionUtils;
 
@@ -147,7 +147,7 @@ private String buildColumnIdentifySql(Column column) {
         // Column name
         columnSqls.add(column.getName());
         // Column type
-        columnSqls.add(DataTypeUtils.toMysqlType(column.getDataType()).getName());
+        columnSqls.add(MysqlDataTypeConvertor.getInstance().toConnectorType(column.getDataType(), null).getName());
         // Column length
         if (column.getColumnLength() != null) {
             columnSqls.add("(" + column.getColumnLength() + ")");

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/resourcemanager/AbstractResourceManager.java
Patch:
@@ -179,7 +179,7 @@ public boolean slotActiveCheck(SlotProfile profile) {
         boolean active = false;
         if (registerWorker.containsKey(profile.getWorker())) {
             active = Arrays.stream(registerWorker.get(profile.getWorker()).getAssignedSlots())
-                .allMatch(s -> s.getSlotID() == profile.getSlotID());
+                .allMatch(s -> s.getSlotID() == profile.getSlotID() && s.getSequence().equals(profile.getSequence()));
         }
 
         if (!active) {

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/SeaTunnelHazelcastClient.java
Patch:
@@ -40,8 +40,11 @@ public class SeaTunnelHazelcastClient {
     private final HazelcastClientInstanceImpl hazelcastClient;
     private final SerializationService serializationService;
 
+    private static final int CONNECT_TIMEOUT = 3000;
+
     public SeaTunnelHazelcastClient(@NonNull ClientConfig clientConfig) {
         Preconditions.checkNotNull(clientConfig, "config");
+        clientConfig.getConnectionStrategyConfig().getConnectionRetryConfig().setClusterConnectTimeoutMillis(CONNECT_TIMEOUT);
         this.hazelcastClient =
             ((HazelcastClientProxy) com.hazelcast.client.HazelcastClient.newHazelcastClient(
                 clientConfig)).client;

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/JobConfigParser.java
Patch:
@@ -144,7 +144,8 @@ private void addCommonPluginJarsToAction(Action action) {
 
     private void jobConfigAnalyze(@NonNull Config envConfigs) {
         if (envConfigs.hasPath(EnvCommonOptions.JOB_MODE.key())) {
-            jobConfig.getJobContext().setJobMode(envConfigs.getEnum(JobMode.class, EnvCommonOptions.JOB_MODE.key()));
+            String jobMode = envConfigs.getString(EnvCommonOptions.JOB_MODE.key());
+            jobConfig.getJobContext().setJobMode(JobMode.valueOf(jobMode.toUpperCase()));
         } else {
             jobConfig.getJobContext().setJobMode(EnvCommonOptions.JOB_MODE.defaultValue());
         }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/TaskExecutionService.java
Patch:
@@ -375,7 +375,7 @@ private synchronized void updateMetricsContextInImap() {
                     }
                 });
             });
-        } catch (Exception e){
+        } catch (Exception e) {
             logger.warning("The Imap acquisition failed due to the hazelcast node being offline or restarted, and will be retried next time", e);
         }
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlan.java
Patch:
@@ -205,6 +205,9 @@ private void subPlanDone(SubPlan subPlan, PipelineStatus pipelineStatus) {
      * @param subPlan subPlan
      */
     private void notifyCheckpointManagerPipelineEnd(@NonNull SubPlan subPlan) {
+        if (jobMaster.getCheckpointManager() == null) {
+            return;
+        }
         jobMaster.getCheckpointManager()
             .listenPipeline(subPlan.getPipelineLocation().getPipelineId(), subPlan.getPipelineState()).join();
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -361,9 +361,7 @@ public void restorePipeline() {
                     reSchedulerPipelineFuture.join();
                 }
             } catch (Throwable e) {
-                LOGGER.severe(
-                    String.format("Restore pipeline %s error with exception: %s", pipelineFullName,
-                        ExceptionUtils.getMessage(e)));
+                LOGGER.severe(String.format("Restore pipeline %s error with exception: ", pipelineFullName), e);
                 cancelPipeline();
             }
         }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/service/slot/SlotService.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.engine.server.resourcemanager.resource.ResourceProfile;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.SlotProfile;
+import org.apache.seatunnel.engine.server.resourcemanager.worker.WorkerProfile;
 
 public interface SlotService {
 
@@ -34,4 +35,5 @@ public interface SlotService {
 
     void close();
 
+    WorkerProfile getWorkerProfile();
 }

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/Constant.java
Patch:
@@ -36,7 +36,7 @@ public class Constant {
 
     public static final String HAZELCAST_SEATUNNEL_DEFAULT_YAML = "seatunnel.yaml";
 
-    public static final int OPERATION_RETRY_TIME = 10;
+    public static final int OPERATION_RETRY_TIME = 30;
 
     public static final int OPERATION_RETRY_SLEEP = 2000;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/AbstractTask.java
Patch:
@@ -32,6 +32,7 @@
 import java.net.URL;
 import java.util.List;
 import java.util.Set;
+import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.stream.Collectors;
 
@@ -41,7 +42,7 @@ public abstract class AbstractTask implements Task {
     protected TaskExecutionContext executionContext;
     protected final long jobID;
     protected final TaskLocation taskLocation;
-    protected volatile boolean restoreComplete;
+    protected volatile CompletableFuture<Void> restoreComplete;
     protected volatile boolean startCalled;
     protected volatile boolean closeCalled;
     protected volatile boolean prepareCloseStatus;
@@ -54,7 +55,6 @@ public AbstractTask(long jobID, TaskLocation taskLocation) {
         this.taskLocation = taskLocation;
         this.jobID = jobID;
         this.progress = new Progress();
-        this.restoreComplete = false;
         this.startCalled = false;
         this.closeCalled = false;
         this.prepareCloseStatus = false;
@@ -74,6 +74,7 @@ public TaskExecutionContext getExecutionContext() {
 
     @Override
     public void init() throws Exception {
+        this.restoreComplete = new CompletableFuture<>();
         progress.start();
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -137,7 +137,7 @@ protected void stateProcess() throws Exception {
                 reportTaskStatus(WAITING_RESTORE);
                 break;
             case WAITING_RESTORE:
-                if (restoreComplete) {
+                if (restoreComplete.isDone()) {
                     for (FlowLifeCycle cycle : allCycles) {
                         cycle.open();
                     }
@@ -325,7 +325,7 @@ public void restoreState(List<ActionSubtaskState> actionStateList) throws Except
                     sneakyThrow(e);
                 }
             });
-        restoreComplete = true;
+        restoreComplete.complete(null);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SinkAggregatedCommitterTask.java
Patch:
@@ -125,7 +125,7 @@ protected void stateProcess() throws Exception {
                 reportTaskStatus(WAITING_RESTORE);
                 break;
             case WAITING_RESTORE:
-                if (restoreComplete) {
+                if (restoreComplete.isDone()) {
                     currState = READY_START;
                     reportTaskStatus(READY_START);
                 }
@@ -203,7 +203,7 @@ public void restoreState(List<ActionSubtaskState> actionStateList) throws Except
             .map(bytes -> sneaky(() -> aggregatedCommitInfoSerializer.deserialize(bytes)))
             .collect(Collectors.toList());
         aggregatedCommitter.commit(aggregatedCommitInfos);
-        restoreComplete = true;
+        restoreComplete.complete(null);
     }
 
     public void receivedWriterCommitInfo(long checkpointID,

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/checkpoint/CloseRequestOperation.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.task.operation.checkpoint;
 
 import org.apache.seatunnel.common.utils.RetryUtils;
+import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
@@ -50,7 +51,7 @@ public void run() throws Exception {
             task.close();
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException &&
+            exception -> exception instanceof SeaTunnelException &&
                 !server.taskIsEnded(readerLocation.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/AssignSplitOperation.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.source.SourceSplit;
 import org.apache.seatunnel.common.utils.RetryUtils;
+import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.common.utils.SerializationUtils;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
@@ -58,7 +59,7 @@ public void run() throws Exception {
             task.receivedSourceSplit(Arrays.stream(o).map(i -> (SplitT) i).collect(Collectors.toList()));
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException &&
+            exception -> exception instanceof SeaTunnelException &&
                 !server.taskIsEnded(taskID.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/RequestSplitOperation.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.task.operation.source;
 
 import org.apache.seatunnel.common.utils.RetryUtils;
+import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
@@ -54,7 +55,7 @@ public void run() throws Exception {
             task.requestSplit(taskID.getTaskIndex());
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException &&
+            exception -> exception instanceof SeaTunnelException &&
                 !server.taskIsEnded(enumeratorTaskID.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/RestoredSplitOperation.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.source.SourceSplit;
 import org.apache.seatunnel.common.utils.RetryUtils;
+import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.common.utils.SerializationUtils;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
@@ -88,7 +89,7 @@ public void run() throws Exception {
             task.addSplitsBack(deserialize, subtaskIndex);
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException &&
+            exception -> exception instanceof SeaTunnelException &&
                 !server.taskIsEnded(taskLocation.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceNoMoreElementOperation.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.task.operation.source;
 
 import org.apache.seatunnel.common.utils.RetryUtils;
+import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
@@ -53,7 +54,7 @@ public void run() throws Exception {
             task.readerFinished(currentTaskID.getTaskID());
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException &&
+            exception -> exception instanceof SeaTunnelException &&
                 !server.taskIsEnded(enumeratorTaskID.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceReaderEventOperation.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.source.SourceEvent;
 import org.apache.seatunnel.common.utils.RetryUtils;
+import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.common.utils.SerializationUtils;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
@@ -57,7 +58,7 @@ public void run() throws Exception {
             task.handleSourceEvent(currentTaskLocation.getTaskIndex(), SerializationUtils.deserialize(sourceEvent, classLoader));
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException &&
+            exception -> exception instanceof SeaTunnelException &&
                 !server.taskIsEnded(taskLocation.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceRegisterOperation.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.task.operation.source;
 
 import org.apache.seatunnel.common.utils.RetryUtils;
+import org.apache.seatunnel.common.utils.SeaTunnelException;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.serializable.TaskDataSerializerHook;
@@ -36,7 +37,7 @@
  * the {@link org.apache.seatunnel.api.source.SourceSplitEnumerator}
  */
 public class SourceRegisterOperation extends Operation implements IdentifiedDataSerializable {
-    private static final int RETRY_TIME = 5;
+    private static final int RETRY_TIME = 20;
 
     private static final int RETRY_TIME_OUT = 2000;
 
@@ -61,7 +62,7 @@ public void run() throws Exception {
             task.receivedReader(readerTaskID, readerAddress);
             return null;
         }, new RetryUtils.RetryMaterial(RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException &&
+            exception -> exception instanceof SeaTunnelException &&
                 !server.taskIsEnded(enumeratorTaskID.getTaskGroupLocation()), RETRY_TIME_OUT));
     }
 

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/canal/CanalJsonFormatFactory.java
Patch:
@@ -62,7 +62,7 @@ public SerializationSchema createSerializationSchema() {
 
     @Override
     public DeserializationFormat createDeserializationFormat(TableFactoryContext context) {
-        Map<String, String> options = context.getOptions();
+        Map<String, String> options = context.getOptions().toMap();
         boolean ignoreParseErrors = CanalJsonFormatOptions.getIgnoreParseErrors(options);
         String  databaseInclude = CanalJsonFormatOptions.getDatabaseInclude(options);
         String  tableInclude = CanalJsonFormatOptions.getTableInclude(options);

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/config/Config.java
Patch:
@@ -32,6 +32,8 @@ public class Config {
 
     public static final String TEXT_FORMAT = "text";
 
+    public static final String CANNAL_FORMAT = "canal-json";
+
     /**
      * The default field delimiter is “,”
      */

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-plugins/imap-storage-file/src/test/java/org/apache/seatunnel/engine/imap/storage/file/IMapFileStorageTest.java
Patch:
@@ -20,6 +20,7 @@
 
 package org.apache.seatunnel.engine.imap.storage.file;
 
+import static org.apache.seatunnel.engine.imap.storage.file.common.FileConstants.FileInitProperties.WRITE_DATA_TIMEOUT_MILLISECONDS_KEY;
 import static org.awaitility.Awaitility.await;
 import static org.junit.jupiter.api.condition.OS.LINUX;
 import static org.junit.jupiter.api.condition.OS.MAC;
@@ -59,6 +60,7 @@ public class IMapFileStorageTest {
         properties.put(FileConstants.FileInitProperties.NAMESPACE_KEY, "/tmp/imap-kris-test/2");
         properties.put(FileConstants.FileInitProperties.CLUSTER_NAME, "test-one");
         properties.put(FileConstants.FileInitProperties.HDFS_CONFIG_KEY, CONF);
+        properties.put(WRITE_DATA_TIMEOUT_MILLISECONDS_KEY, 60L);
 
         STORAGE.initialize(properties);
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -262,7 +262,9 @@ public void cancelPipeline() {
     }
 
     private void cancelCheckpointCoordinator() {
-        jobMaster.getCheckpointManager().listenPipelineRetry(pipelineId, PipelineStatus.CANCELING).join();
+        if (jobMaster.getCheckpointManager() != null) {
+            jobMaster.getCheckpointManager().listenPipelineRetry(pipelineId, PipelineStatus.CANCELING).join();
+        }
     }
 
     private void cancelPipelineTasks() {

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/shard/Shard.java
Patch:
@@ -19,9 +19,9 @@
 
 import com.clickhouse.client.ClickHouseCredentials;
 import com.clickhouse.client.ClickHouseNode;
+import com.clickhouse.client.ClickHouseProtocol;
 
 import java.io.Serializable;
-import java.net.InetSocketAddress;
 import java.util.Objects;
 
 public class Shard implements Serializable {
@@ -46,8 +46,8 @@ public Shard(int shardNum,
                  String password) {
         this.shardNum = shardNum;
         this.replicaNum = replicaNum;
-        this.node = ClickHouseNode.builder().host(hostname).address(InetSocketAddress.createUnresolved(hostAddress,
-                port)).database(database).weight(shardWeight).credentials(ClickHouseCredentials.fromUserAndPassword(username, password)).build();
+        this.node = ClickHouseNode.builder().host(hostname).port(ClickHouseProtocol.HTTP,
+            port).database(database).weight(shardWeight).credentials(ClickHouseCredentials.fromUserAndPassword(username, password)).build();
     }
 
     public Shard(int shardNum, int replicaNum, ClickHouseNode node) {

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/ClickhouseProxy.java
Patch:
@@ -141,7 +141,7 @@ public Map<String, String> getClickhouseTableSchema(ClickHouseRequest<?> request
      */
     public List<Shard> getClusterShardList(ClickHouseRequest<?> connection, String clusterName,
                                            String database, int port, String username, String password) {
-        String sql = "select shard_num,shard_weight,replica_num,host_name,host_address,port from system.clusters where cluster = '" + clusterName + "'";
+        String sql = "select shard_num,shard_weight,replica_num,host_name,host_address,port from system.clusters where cluster = '" + clusterName + "'" + " and replica_num=1";
         List<Shard> shardList = new ArrayList<>();
         try (ClickHouseResponse response = connection.query(sql).executeAndWait()) {
             response.records().forEach(r -> {

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/ShardRouter.java
Patch:
@@ -98,7 +98,7 @@ public Shard getShard(Object shardValue) {
             return shards.firstEntry().getValue();
         }
         if (StringUtils.isEmpty(shardKey) || shardValue == null) {
-            return shards.lowerEntry(threadLocalRandom.nextInt(shardWeightCount + 1)).getValue();
+            return shards.lowerEntry(threadLocalRandom.nextInt(shardWeightCount) + 1).getValue();
         }
         int offset = (int) (HASH_INSTANCE.hash(ByteBuffer.wrap(shardValue.toString().getBytes(StandardCharsets.UTF_8)),
             0) & Long.MAX_VALUE % shardWeightCount);

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/file/ClickhouseFileSink.java
Patch:
@@ -116,7 +116,7 @@ public void prepare(Config config) throws PrepareFailException {
             config.getString(DATABASE.key()),
             config.getString(TABLE.key()),
             table.getEngine(),
-            false, // we don't need to set splitMode in clickhouse file mode.
+            true,
             new Shard(1, 1, nodes.get(0)), config.getString(USERNAME.key()), config.getString(PASSWORD.key()));
         List<String> fields = new ArrayList<>(tableSchema.keySet());
         Map<String, String> nodeUser = config.getObjectList(NODE_PASS.key()).stream()

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/file/ClickhouseFileSinkWriter.java
Patch:
@@ -258,7 +258,7 @@ private List<String> generateClickhouseLocalFiles(String clickhouseLocalFileTmpF
     }
 
     private void moveClickhouseLocalFileToServer(Shard shard, List<String> clickhouseLocalFiles) {
-        String hostAddress = shard.getNode().getAddress().getHostName();
+        String hostAddress = shard.getNode().getHost();
         String user = readerOption.getNodeUser().getOrDefault(hostAddress, "root");
         String password = readerOption.getNodePassword().getOrDefault(hostAddress, null);
         FileTransfer fileTransfer = FileTransferFactory.createFileTransfer(this.readerOption.getCopyMethod(), hostAddress, user, password);

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/Constant.java
Patch:
@@ -57,4 +57,6 @@ public class Constant {
     public static final String IMAP_CHECKPOINT_ID = "engine_checkpoint-id-%d";
 
     public static final String IMAP_RESOURCE_MANAGER_REGISTER_WORKER = "ResourceManager_RegisterWorker";
+
+    public static final String IMAP_RUNNING_JOB_METRICS = "engine_runningJobMetrics";
 }

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/YamlSeaTunnelDomConfigProcessor.java
Patch:
@@ -105,6 +105,9 @@ private void parseEngineConfig(Node engineNode, SeaTunnelConfig config) {
             } else if (ServerConfigOptions.PRINT_JOB_METRICS_INFO_INTERVAL.key().equals(name)) {
                 engineConfig.setPrintJobMetricsInfoInterval(getIntegerValue(ServerConfigOptions.PRINT_JOB_METRICS_INFO_INTERVAL.key(),
                     getTextContent(node)));
+            } else if (ServerConfigOptions.JOB_METRICS_BACKUP_INTERVAL.key().equals(name)) {
+                engineConfig.setJobMetricsBackupInterval(getIntegerValue(ServerConfigOptions.JOB_METRICS_BACKUP_INTERVAL.key(),
+                    getTextContent(node)));
             } else if (ServerConfigOptions.SLOT_SERVICE.key().equals(name)) {
                 engineConfig.setSlotServiceConfig(parseSlotServiceConfig(node));
             } else if (ServerConfigOptions.CHECKPOINT.key().equals(name)) {

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/server/ServerConfigOptions.java
Patch:
@@ -33,6 +33,8 @@ public class ServerConfigOptions {
 
     public static final Option<Integer> PRINT_JOB_METRICS_INFO_INTERVAL = Options.key("print-job-metrics-info-interval").intType().defaultValue(60).withDescription("The interval (in seconds) of job print metrics info");
 
+    public static final Option<Integer> JOB_METRICS_BACKUP_INTERVAL = Options.key("job-metrics-backup-interval").intType().defaultValue(3).withDescription("The interval (in seconds) of job metrics backups");
+
     public static final Option<Boolean> DYNAMIC_SLOT = Options.key("dynamic-slot").booleanType().defaultValue(true).withDescription("Whether to use dynamic slot.");
 
     public static final Option<Integer> SLOT_NUM = Options.key("slot-num").intType().defaultValue(2).withDescription("The number of slots. Only valid when dynamic slot is disabled.");

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/CoordinatorService.java
Patch:
@@ -430,7 +430,8 @@ public PassiveCompletableFuture<Void> cancelJob(long jodId) {
     public JobStatus getJobStatus(long jobId) {
         JobMaster runningJobMaster = runningJobMasterMap.get(jobId);
         if (runningJobMaster == null) {
-            return jobHistoryService.getJobDetailState(jobId).getJobStatus();
+            JobHistoryService.JobStateData jobDetailState = jobHistoryService.getJobDetailState(jobId);
+            return null == jobDetailState ? null : jobDetailState.getJobStatus();
         }
         return runningJobMaster.getJobStatus();
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManager.java
Patch:
@@ -232,7 +232,7 @@ public void acknowledgeTask(TaskAcknowledgeOperation ackOperation) {
         coordinator.acknowledgeTask(ackOperation);
     }
 
-    private boolean isSavePointEnd() {
+    public boolean isSavePointEnd() {
         return coordinatorMap.values().stream().map(CheckpointCoordinator::isEndOfSavePoint)
             .reduce((v1, v2) -> v1 && v2).orElse(false);
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlan.java
Patch:
@@ -170,7 +170,7 @@ public void addPipelineEndCallback(SubPlan subPlan) {
                     }
                     LOGGER.severe("Pipeline Failed, Begin to cancel other pipelines in this job.");
                 }
-                subPlanDone(subPlan);
+                subPlanDone(subPlan, pipelineState.getPipelineStatus());
 
                 if (finishedPipelineNum.incrementAndGet() == this.pipelineList.size()) {
                     if (failedPipelineNum.get() > 0) {
@@ -189,8 +189,9 @@ public void addPipelineEndCallback(SubPlan subPlan) {
         });
     }
 
-    private void subPlanDone(SubPlan subPlan) {
+    private void subPlanDone(SubPlan subPlan, PipelineStatus pipelineStatus) {
         jobMaster.savePipelineMetricsToHistory(subPlan.getPipelineLocation());
+        jobMaster.removeMetricsContext(subPlan.getPipelineLocation(), pipelineStatus);
         jobMaster.releasePipelineResource(subPlan);
         notifyCheckpointManagerPipelineEnd(subPlan);
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/metrics/MetricsContext.java
Patch:
@@ -27,12 +27,13 @@
 import com.hazelcast.internal.metrics.ProbeLevel;
 import com.hazelcast.internal.metrics.ProbeUnit;
 
+import java.io.Serializable;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.atomic.AtomicLongFieldUpdater;
 import java.util.function.BiFunction;
 
-public class MetricsContext implements DynamicMetricsProvider {
+public class MetricsContext implements DynamicMetricsProvider, Serializable {
 
     private static final BiFunction<String, Unit, AbstractMetric> CREATE_SINGLE_WRITER_METRIC = SingleWriterMetric::new;
     private static final BiFunction<String, Unit, AbstractMetric> CREATE_THREAD_SAFE_METRICS = ThreadSafeMetric::new;
@@ -94,7 +95,7 @@ private ProbeUnit toProbeUnit(Unit unit) {
         return ProbeUnit.valueOf(unit.name());
     }
 
-    private abstract static class AbstractMetric implements Metric {
+    private abstract static class AbstractMetric implements Metric, Serializable {
 
         private final String name;
         private final Unit unit;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -118,7 +118,7 @@ public SeaTunnelTask(long jobID, TaskLocation taskID, int indexID, Flow executio
     @Override
     public void init() throws Exception {
         super.init();
-        metricsContext = new MetricsContext();
+        metricsContext = getExecutionContext().getOrCreateMetricsContext(taskLocation);
         this.currState = SeaTunnelTaskState.INIT;
         flowFutures = new ArrayList<>();
         allCycles = new ArrayList<>();

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlan.java
Patch:
@@ -159,6 +159,7 @@ public void addPipelineEndCallback(SubPlan subPlan) {
                     LOGGER.info(String.format("release the pipeline %s resource", subPlan.getPipelineFullName()));
                 } else if (PipelineStatus.FAILED.equals(pipelineState.getPipelineStatus())) {
                     if (canRestorePipeline(subPlan)) {
+                        LOGGER.info(String.format("Can restore pipeline %s", subPlan.getPipelineFullName()));
                         subPlan.restorePipeline();
                         return;
                     }

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-plugins/imap-storage-file/src/main/java/org/apache/seatunnel/engine/imap/storage/file/disruptor/WALDisruptor.java
Patch:
@@ -43,7 +43,7 @@ public class WALDisruptor implements Closeable {
 
     private volatile Disruptor<FileWALEvent> disruptor;
 
-    private static final int DEFAULT_RING_BUFFER_SIZE = 256 * 1024;
+    private static final int DEFAULT_RING_BUFFER_SIZE = 1024;
 
     private static final int DEFAULT_CLOSE_WAIT_TIME_SECONDS = 5;
 

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/source/ClickhouseSourceReader.java
Patch:
@@ -31,6 +31,7 @@
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.List;
 import java.util.Random;
 
@@ -88,7 +89,7 @@ public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
 
     @Override
     public List<ClickhouseSourceSplit> snapshotState(long checkpointId) throws Exception {
-        return null;
+        return Collections.emptyList();
     }
 
     @Override

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/source/KuduSourceReader.java
Patch:
@@ -29,6 +29,7 @@
 import org.apache.kudu.client.RowResult;
 import org.apache.kudu.client.RowResultIterator;
 
+import java.util.Collections;
 import java.util.Deque;
 import java.util.LinkedList;
 import java.util.List;
@@ -85,7 +86,7 @@ public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
 
     @Override
     public List<KuduSourceSplit> snapshotState(long checkpointId) {
-        return null;
+        return Collections.emptyList();
     }
 
     @Override

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/Constants.java
Patch:
@@ -31,6 +31,8 @@ public final class Constants {
 
     public static final String SOURCE_SERIALIZATION = "source.serialization";
 
+    public static final String SINK_SERIALIZATION = "sink.serialization";
+
     public static final String HDFS_ROOT = "hdfs.root";
 
     public static final String HDFS_USER = "hdfs.user";

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/enums/EngineType.java
Patch:
@@ -21,7 +21,8 @@
  * Engine type enum
  */
 public enum EngineType {
-    SPARK("spark", "seatunnel-spark-starter.jar", "start-seatunnel-spark-connector-v2.sh"),
+    SPARK2("spark", "seatunnel-spark-2-starter.jar", "start-seatunnel-spark-2-connector-v2.sh"),
+    SPARK3("spark", "seatunnel-spark-3-starter.jar", "start-seatunnel-spark-3-connector-v2.sh"),
     FLINK13("flink", "seatunnel-flink-13-starter.jar", "start-seatunnel-flink-13-connector-v2.sh"),
     FLINK15("flink", "seatunnel-flink-15-starter.jar", "start-seatunnel-flink-15-connector-v2.sh"),
     SEATUNNEL("seatunnel", "seatunnel-starter.jar", "seatunnel.sh");

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-2-starter/src/main/java/org/apache/seatunnel/core/starter/spark/SeaTunnelSpark.java
Patch:
@@ -27,7 +27,7 @@ public class SeaTunnelSpark {
 
     public static void main(String[] args) throws CommandException {
         SparkCommandArgs sparkCommandArgs = CommandLineUtils.parse(args, new SparkCommandArgs(),
-                EngineType.SPARK.getStarterShellName(), true);
+                EngineType.SPARK2.getStarterShellName(), true);
         SeaTunnel.run(sparkCommandArgs.buildCommand());
     }
 }

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-2-starter/src/main/java/org/apache/seatunnel/core/starter/spark/SparkStarter.java
Patch:
@@ -106,7 +106,7 @@ public static void main(String[] args) throws IOException {
      */
     static SparkStarter getInstance(String[] args) {
         SparkCommandArgs commandArgs = CommandLineUtils.parse(args, new SparkCommandArgs(),
-                EngineType.SPARK.getStarterShellName(), true);
+                EngineType.SPARK2.getStarterShellName(), true);
         DeployMode deployMode = commandArgs.getDeployMode();
         switch (deployMode) {
             case CLUSTER:
@@ -265,7 +265,7 @@ protected void appendSparkConf(List<String> commands, Map<String, String> sparkC
      * append appJar to StringBuilder
      */
     protected void appendAppJar(List<String> commands) {
-        commands.add(Common.appStarterDir().resolve(EngineType.SPARK.getStarterJarName()).toString());
+        commands.add(Common.appStarterDir().resolve(EngineType.SPARK2.getStarterJarName()).toString());
     }
 
     @SuppressWarnings("checkstyle:Indentation")

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-2-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -28,8 +28,8 @@
 import org.apache.seatunnel.core.starter.exception.TaskExecuteException;
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
 import org.apache.seatunnel.plugin.discovery.seatunnel.SeaTunnelSinkPluginDiscovery;
-import org.apache.seatunnel.translation.spark.common.utils.TypeConverterUtils;
 import org.apache.seatunnel.translation.spark.sink.SparkSinkInjector;
+import org.apache.seatunnel.translation.spark.utils.TypeConverterUtils;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-2-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SourceExecuteProcessor.java
Patch:
@@ -25,7 +25,7 @@
 import org.apache.seatunnel.common.utils.SerializationUtils;
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
 import org.apache.seatunnel.plugin.discovery.seatunnel.SeaTunnelSourcePluginDiscovery;
-import org.apache.seatunnel.translation.spark.common.utils.TypeConverterUtils;
+import org.apache.seatunnel.translation.spark.utils.TypeConverterUtils;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-core/seatunnel-spark-starter/seatunnel-spark-2-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/TransformExecuteProcessor.java
Patch:
@@ -24,8 +24,8 @@
 import org.apache.seatunnel.core.starter.exception.TaskExecuteException;
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
 import org.apache.seatunnel.plugin.discovery.seatunnel.SeaTunnelTransformPluginDiscovery;
-import org.apache.seatunnel.translation.spark.common.serialization.InternalRowConverter;
-import org.apache.seatunnel.translation.spark.common.utils.TypeConverterUtils;
+import org.apache.seatunnel.translation.spark.serialization.InternalRowConverter;
+import org.apache.seatunnel.translation.spark.utils.TypeConverterUtils;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/TestContainerId.java
Patch:
@@ -31,6 +31,7 @@ public enum TestContainerId {
     FLINK_1_15(FLINK, "1.15.3"),
     FLINK_1_16(FLINK, "1.16.0"),
     SPARK_2_4(SPARK, "2.4.6"),
+    SPARK_3_3(SPARK, "3.3.0"),
     SEATUNNEL(EngineType.SEATUNNEL, "2.2.0");
 
     private final EngineType engineType;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/serialization/InternalRowCollector.java
Patch:
@@ -15,13 +15,12 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.common;
+package org.apache.seatunnel.translation.spark.serialization;
 
 import org.apache.seatunnel.api.source.Collector;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.common.Handover;
-import org.apache.seatunnel.translation.spark.common.serialization.InternalRowConverter;
 
 import org.apache.spark.sql.catalyst.InternalRow;
 

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/serialization/InternalRowConverter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.common.serialization;
+package org.apache.seatunnel.translation.spark.serialization;
 
 import org.apache.seatunnel.api.table.type.ArrayType;
 import org.apache.seatunnel.api.table.type.BasicType;
@@ -24,8 +24,8 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.translation.serialization.RowConverter;
-import org.apache.seatunnel.translation.spark.common.utils.InstantConverterUtils;
-import org.apache.seatunnel.translation.spark.common.utils.TypeConverterUtils;
+import org.apache.seatunnel.translation.spark.utils.InstantConverterUtils;
+import org.apache.seatunnel.translation.spark.utils.TypeConverterUtils;
 
 import org.apache.spark.sql.catalyst.InternalRow;
 import org.apache.spark.sql.catalyst.expressions.MutableAny;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/sink/SparkSink.java
Patch:
@@ -21,6 +21,8 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.common.utils.SerializationUtils;
+import org.apache.seatunnel.translation.spark.sink.writer.SparkDataSourceWriter;
+import org.apache.seatunnel.translation.spark.sink.writer.SparkStreamWriter;
 
 import org.apache.spark.sql.SaveMode;
 import org.apache.spark.sql.sources.v2.DataSourceOptions;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/sink/writer/SparkDataSourceWriter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.sink;
+package org.apache.seatunnel.translation.spark.sink.writer;
 
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
 import org.apache.seatunnel.api.sink.SinkAggregatedCommitter;
@@ -42,7 +42,7 @@ public class SparkDataSourceWriter<StateT, CommitInfoT, AggregatedCommitInfoT> i
     @Nullable
     protected final SinkAggregatedCommitter<CommitInfoT, AggregatedCommitInfoT> sinkAggregatedCommitter;
 
-    SparkDataSourceWriter(SeaTunnelSink<SeaTunnelRow, StateT, CommitInfoT, AggregatedCommitInfoT> sink)
+    public SparkDataSourceWriter(SeaTunnelSink<SeaTunnelRow, StateT, CommitInfoT, AggregatedCommitInfoT> sink)
             throws IOException {
         this.sink = sink;
         this.sinkAggregatedCommitter = sink.createAggregatedCommitter().orElse(null);

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/sink/writer/SparkDataWriter.java
Patch:
@@ -15,14 +15,14 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.sink;
+package org.apache.seatunnel.translation.spark.sink.writer;
 
 import org.apache.seatunnel.api.sink.SinkCommitter;
 import org.apache.seatunnel.api.sink.SinkWriter;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.translation.serialization.RowConverter;
-import org.apache.seatunnel.translation.spark.common.serialization.InternalRowConverter;
+import org.apache.seatunnel.translation.spark.serialization.InternalRowConverter;
 
 import org.apache.spark.sql.catalyst.InternalRow;
 import org.apache.spark.sql.sources.v2.writer.DataWriter;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/sink/writer/SparkDataWriterFactory.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.sink;
+package org.apache.seatunnel.translation.spark.sink.writer;
 
 import org.apache.seatunnel.api.sink.DefaultSinkWriterContext;
 import org.apache.seatunnel.api.sink.SeaTunnelSink;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/sink/writer/SparkStreamWriter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.sink;
+package org.apache.seatunnel.translation.spark.sink.writer;
 
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
@@ -30,7 +30,7 @@
 public class SparkStreamWriter<StateT, CommitInfoT, AggregatedCommitInfoT> extends SparkDataSourceWriter<StateT, CommitInfoT, AggregatedCommitInfoT>
         implements StreamWriter {
 
-    SparkStreamWriter(SeaTunnelSink<SeaTunnelRow, StateT, CommitInfoT, AggregatedCommitInfoT> sink) throws IOException {
+    public SparkStreamWriter(SeaTunnelSink<SeaTunnelRow, StateT, CommitInfoT, AggregatedCommitInfoT> sink) throws IOException {
         super(sink);
     }
 

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/sink/writer/SparkWriterCommitMessage.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.sink;
+package org.apache.seatunnel.translation.spark.sink.writer;
 
 import org.apache.spark.sql.sources.v2.writer.WriterCommitMessage;
 

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/source/SeaTunnelSourceSupport.java
Patch:
@@ -22,8 +22,8 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.common.utils.SerializationUtils;
-import org.apache.seatunnel.translation.spark.source.batch.BatchSourceReader;
-import org.apache.seatunnel.translation.spark.source.micro.MicroBatchSourceReader;
+import org.apache.seatunnel.translation.spark.source.reader.batch.BatchSourceReader;
+import org.apache.seatunnel.translation.spark.source.reader.micro.MicroBatchSourceReader;
 
 import org.apache.commons.lang3.StringUtils;
 import org.apache.hadoop.conf.Configuration;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/source/reader/SeaTunnelInputPartitionReader.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.source;
+package org.apache.seatunnel.translation.spark.source.reader;
 
-import org.apache.seatunnel.translation.spark.common.source.batch.ParallelBatchPartitionReader;
+import org.apache.seatunnel.translation.spark.source.reader.batch.ParallelBatchPartitionReader;
 
 import org.apache.spark.sql.catalyst.InternalRow;
 import org.apache.spark.sql.sources.v2.reader.InputPartitionReader;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/source/reader/batch/BatchSourceReader.java
Patch:
@@ -15,12 +15,13 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.source.batch;
+package org.apache.seatunnel.translation.spark.source.reader.batch;
 
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SupportCoordinate;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.translation.spark.common.utils.TypeConverterUtils;
+import org.apache.seatunnel.translation.spark.source.partition.batch.BatchPartition;
+import org.apache.seatunnel.translation.spark.utils.TypeConverterUtils;
 
 import org.apache.spark.sql.catalyst.InternalRow;
 import org.apache.spark.sql.sources.v2.reader.DataSourceReader;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/source/reader/batch/CoordinatedBatchPartitionReader.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.common.source.batch;
+package org.apache.seatunnel.translation.spark.source.reader.batch;
 
 import org.apache.seatunnel.api.source.Collector;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
@@ -24,7 +24,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.translation.source.BaseSourceFunction;
 import org.apache.seatunnel.translation.source.CoordinatedSource;
-import org.apache.seatunnel.translation.spark.common.InternalRowCollector;
+import org.apache.seatunnel.translation.spark.serialization.InternalRowCollector;
 
 import java.io.Serializable;
 import java.util.HashMap;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/source/reader/batch/ParallelBatchPartitionReader.java
Patch:
@@ -15,15 +15,15 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.common.source.batch;
+package org.apache.seatunnel.translation.spark.source.reader.batch;
 
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceSplit;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.common.Handover;
 import org.apache.seatunnel.translation.source.BaseSourceFunction;
 import org.apache.seatunnel.translation.source.ParallelSource;
-import org.apache.seatunnel.translation.spark.common.InternalRowCollector;
+import org.apache.seatunnel.translation.spark.serialization.InternalRowCollector;
 import org.apache.seatunnel.translation.util.ThreadPoolExecutorFactory;
 
 import lombok.extern.slf4j.Slf4j;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/source/reader/micro/ParallelMicroBatchPartitionReader.java
Patch:
@@ -15,14 +15,14 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.common.source.micro;
+package org.apache.seatunnel.translation.spark.source.reader.micro;
 
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.common.utils.SerializationUtils;
 import org.apache.seatunnel.translation.source.BaseSourceFunction;
-import org.apache.seatunnel.translation.spark.common.ReaderState;
-import org.apache.seatunnel.translation.spark.common.source.batch.ParallelBatchPartitionReader;
+import org.apache.seatunnel.translation.spark.source.reader.batch.ParallelBatchPartitionReader;
+import org.apache.seatunnel.translation.spark.source.state.ReaderState;
 import org.apache.seatunnel.translation.util.ThreadPoolExecutorFactory;
 
 import org.apache.commons.lang3.StringUtils;

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/source/state/MicroBatchState.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.common.source.micro;
+package org.apache.seatunnel.translation.spark.source.state;
 
 import org.apache.seatunnel.common.utils.SerializationUtils;
 

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/source/state/ReaderState.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.common;
+package org.apache.seatunnel.translation.spark.source.state;
 
 import org.apache.spark.sql.sources.v2.reader.streaming.PartitionOffset;
 

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/utils/InstantConverterUtils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.common.utils;
+package org.apache.seatunnel.translation.spark.utils;
 
 import java.time.Instant;
 

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/utils/TypeConverterUtils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.common.utils;
+package org.apache.seatunnel.translation.spark.utils;
 
 import static com.google.common.base.Preconditions.checkNotNull;
 

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-3.3/src/main/java/org/apache/seatunnel/translation/spark/source/partition/micro/CoordinatedMicroBatchPartitionReader.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.translation.spark.common.source.micro;
+package org.apache.seatunnel.translation.spark.source.partition.micro;
 
 import org.apache.seatunnel.api.source.Collector;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
@@ -24,8 +24,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.translation.source.BaseSourceFunction;
 import org.apache.seatunnel.translation.source.CoordinatedSource;
-import org.apache.seatunnel.translation.spark.common.InternalRowCollector;
-import org.apache.seatunnel.translation.spark.common.ReaderState;
+import org.apache.seatunnel.translation.spark.serialization.InternalRowCollector;
 
 import java.io.Serializable;
 import java.util.HashMap;

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/enums/EngineType.java
Patch:
@@ -22,7 +22,8 @@
  */
 public enum EngineType {
     SPARK("spark", "seatunnel-spark-starter.jar", "start-seatunnel-spark-connector-v2.sh"),
-    FLINK("flink", "seatunnel-flink-starter.jar", "start-seatunnel-flink-connector-v2.sh"),
+    FLINK13("flink", "seatunnel-flink-13-starter.jar", "start-seatunnel-flink-13-connector-v2.sh"),
+    FLINK15("flink", "seatunnel-flink-15-starter.jar", "start-seatunnel-flink-15-connector-v2.sh"),
     SEATUNNEL("seatunnel", "seatunnel-starter.jar", "seatunnel.sh");
 
     private final String engine;

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/FlinkStarter.java
Patch:
@@ -32,8 +32,8 @@
  */
 public class FlinkStarter implements Starter {
     private static final String APP_NAME = SeaTunnelFlink.class.getName();
-    public static final String APP_JAR_NAME = EngineType.FLINK.getStarterJarName();
-    public static final String SHELL_NAME = EngineType.FLINK.getStarterShellName();
+    public static final String APP_JAR_NAME = EngineType.FLINK13.getStarterJarName();
+    public static final String SHELL_NAME = EngineType.FLINK13.getStarterShellName();
     private final FlinkCommandArgs flinkCommandArgs;
     private final String appJar;
 

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/SeaTunnelFlink.java
Patch:
@@ -26,7 +26,7 @@
 public class SeaTunnelFlink {
     public static void main(String[] args) throws CommandException {
         FlinkCommandArgs flinkCommandArgs = CommandLineUtils.parse(args, new FlinkCommandArgs(),
-                EngineType.FLINK.getStarterShellName(), true);
+                EngineType.FLINK13.getStarterShellName(), true);
         SeaTunnel.run(flinkCommandArgs.buildCommand());
     }
 }

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/FlinkAbstractPluginExecuteProcessor.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.common.utils.ReflectionUtils;
 import org.apache.seatunnel.core.starter.execution.PluginExecuteProcessor;
-import org.apache.seatunnel.core.starter.flink.util.TableUtil;
+import org.apache.seatunnel.core.starter.flink.utils.TableUtil;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/FlinkRuntimeEnvironment.java
Patch:
@@ -22,9 +22,9 @@
 import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.common.utils.ReflectionUtils;
 import org.apache.seatunnel.core.starter.execution.RuntimeEnvironment;
-import org.apache.seatunnel.core.starter.flink.util.ConfigKeyName;
-import org.apache.seatunnel.core.starter.flink.util.EnvironmentUtil;
-import org.apache.seatunnel.core.starter.flink.util.TableUtil;
+import org.apache.seatunnel.core.starter.flink.utils.ConfigKeyName;
+import org.apache.seatunnel.core.starter.flink.utils.EnvironmentUtil;
+import org.apache.seatunnel.core.starter.flink.utils.TableUtil;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -38,13 +38,12 @@
 import org.apache.flink.streaming.api.datastream.DataStreamSink;
 import org.apache.flink.types.Row;
 
+import java.io.Serializable;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.stream.Collectors;
 
-import scala.Serializable;
-
 public class SinkExecuteProcessor extends FlinkAbstractPluginExecuteProcessor
         <SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializable>> {
 

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/utils/ConfigKeyName.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.core.starter.flink.util;
+package org.apache.seatunnel.core.starter.flink.utils;
 
 public class ConfigKeyName {
 

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/utils/EnvironmentUtil.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.core.starter.flink.util;
+package org.apache.seatunnel.core.starter.flink.utils;
 
 import org.apache.seatunnel.common.config.CheckResult;
 

File: seatunnel-core/seatunnel-flink-starter/seatunnel-flink-13-starter/src/main/java/org/apache/seatunnel/core/starter/flink/utils/TableUtil.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.core.starter.flink.util;
+package org.apache.seatunnel.core.starter.flink.utils;
 
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.streaming.api.datastream.DataStream;

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/TestContainerId.java
Patch:
@@ -28,6 +28,8 @@
 public enum TestContainerId {
     FLINK_1_13(FLINK, "1.13.6"),
     FLINK_1_14(FLINK, "1.14.6"),
+    FLINK_1_15(FLINK, "1.15.3"),
+    FLINK_1_16(FLINK, "1.16.0"),
     SPARK_2_4(SPARK, "2.4.6"),
     SEATUNNEL(EngineType.SEATUNNEL, "2.2.0");
 

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/util/ContainerUtil.java
Patch:
@@ -106,7 +106,9 @@ public static void copySeaTunnelStarterToContainer(GenericContainer<?> container
                                                        String startModuleName,
                                                        String startModulePath,
                                                        String seatunnelHomeInContainer) {
-        final String startJarName = startModuleName + ".jar";
+        // solve the problem of multi modules such as seatunnel-flink-starter/seatunnel-flink-13-starter
+        final String[] splits = startModuleName.split(File.separator);
+        final String startJarName = splits[splits.length - 1] + ".jar";
         // copy starter
         final String startJarPath = startModulePath + File.separator + "target" + File.separator + startJarName;
         checkPathExist(startJarPath);

File: seatunnel-translation/seatunnel-translation-flink/seatunnel-translation-flink-13/src/main/java/org/apache/seatunnel/translation/flink/source/BaseSeaTunnelSourceFunction.java
Patch:
@@ -46,6 +46,9 @@
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
 
+/**
+ * The abstract implementation of {@link RichSourceFunction}, the entrypoint of flink source translation
+ */
 public abstract class BaseSeaTunnelSourceFunction extends RichSourceFunction<Row>
     implements CheckpointListener, ResultTypeQueryable<Row>, CheckpointedFunction {
     private static final Logger LOG = LoggerFactory.getLogger(BaseSeaTunnelSourceFunction.class);

File: seatunnel-translation/seatunnel-translation-flink/seatunnel-translation-flink-13/src/main/java/org/apache/seatunnel/translation/flink/source/SeaTunnelCoordinatedSource.java
Patch:
@@ -22,6 +22,9 @@
 import org.apache.seatunnel.translation.source.BaseSourceFunction;
 import org.apache.seatunnel.translation.source.CoordinatedSource;
 
+/**
+ * The coordinated source function implementation of {@link BaseSeaTunnelSourceFunction}
+ */
 public class SeaTunnelCoordinatedSource extends BaseSeaTunnelSourceFunction {
 
     protected static final String COORDINATED_SOURCE_STATE_NAME = "coordinated-source-states";

File: seatunnel-translation/seatunnel-translation-flink/seatunnel-translation-flink-13/src/main/java/org/apache/seatunnel/translation/flink/source/SeaTunnelParallelSource.java
Patch:
@@ -25,6 +25,9 @@
 import org.apache.flink.streaming.api.functions.source.ParallelSourceFunction;
 import org.apache.flink.types.Row;
 
+/**
+ * The parallel source function implementation of {@link BaseSeaTunnelSourceFunction}
+ */
 public class SeaTunnelParallelSource extends BaseSeaTunnelSourceFunction implements ParallelSourceFunction<Row> {
 
     protected static final String PARALLEL_SOURCE_STATE_NAME = "parallel-source-states";

File: seatunnel-translation/seatunnel-translation-flink/seatunnel-translation-flink-13/src/main/java/org/apache/seatunnel/translation/flink/utils/TypeConverterUtils.java
Patch:
@@ -59,6 +59,7 @@ public class TypeConverterUtils {
         BRIDGED_TYPES.put(Float.class, BridgedType.of(BasicType.FLOAT_TYPE, BasicTypeInfo.FLOAT_TYPE_INFO));
         BRIDGED_TYPES.put(Double.class, BridgedType.of(BasicType.DOUBLE_TYPE, BasicTypeInfo.DOUBLE_TYPE_INFO));
         BRIDGED_TYPES.put(Void.class, BridgedType.of(BasicType.VOID_TYPE, BasicTypeInfo.VOID_TYPE_INFO));
+        // TODO: there is a still an unresolved issue that the BigDecimal type will lose the precision and scale
         BRIDGED_TYPES.put(BigDecimal.class, BridgedType.of(new DecimalType(38, 18), BasicTypeInfo.BIG_DEC_TYPE_INFO));
         // data time types
         BRIDGED_TYPES.put(LocalDate.class, BridgedType.of(LocalTimeType.LOCAL_DATE_TYPE, LocalTimeTypeInfo.LOCAL_DATE));

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlIncrementalSourceFactory.java
Patch:
@@ -35,7 +35,7 @@ public String factoryIdentifier() {
 
     @Override
     public OptionRule optionRule() {
-        return JdbcSourceOptions.BASE_RULE
+        return JdbcSourceOptions.getBaseRule()
             .required(
                 JdbcSourceOptions.HOSTNAME,
                 JdbcSourceOptions.USERNAME,

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceTwoPipelineIT.java
Patch:
@@ -38,7 +38,6 @@
 import lombok.extern.slf4j.Slf4j;
 import org.awaitility.Awaitility;
 import org.junit.jupiter.api.Assertions;
-import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.testcontainers.shaded.org.apache.commons.lang3.tuple.ImmutablePair;
 
@@ -53,7 +52,6 @@
  * Cluster fault tolerance test. Test the job which have two pipelines can recovery capability and data consistency assurance capability in case of cluster node failure
  */
 @Slf4j
-@Disabled
 public class ClusterFaultToleranceTwoPipelineIT {
 
     public static final String TEST_TEMPLATE_FILE_NAME = "cluster_batch_fake_to_localfile_two_pipeline_template.conf";

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -258,11 +258,12 @@ protected void readyToClose(TaskLocation taskLocation) {
     }
 
     protected void restoreCoordinator(boolean alreadyStarted) {
+        LOG.info("received restore CheckpointCoordinator with alreadyStarted= " + alreadyStarted);
         cleanPendingCheckpoint(CheckpointCloseReason.CHECKPOINT_COORDINATOR_RESET);
         shutdown = false;
         if (alreadyStarted) {
-            tryTriggerPendingCheckpoint();
             isAllTaskReady = true;
+            tryTriggerPendingCheckpoint();
         } else {
             isAllTaskReady = false;
         }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/DeployTaskOperation.java
Patch:
@@ -47,7 +47,7 @@ public DeployTaskOperation(@NonNull SlotProfile slotProfile, @NonNull Data taskI
     public void run() throws Exception {
         SeaTunnelServer server = getService();
         server.getSlotService().getSlotContext(slotProfile)
-            .getTaskExecutionService().deployTask(taskImmutableInformation).get();
+            .getTaskExecutionService().deployTask(taskImmutableInformation);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-plugins/imap-storage-file/src/main/java/org/apache/seatunnel/engine/imap/storage/file/IMapFileStorageFactory.java
Patch:
@@ -26,10 +26,12 @@
 import org.apache.seatunnel.engine.imap.storage.api.IMapStorageFactory;
 import org.apache.seatunnel.engine.imap.storage.api.exception.IMapStorageException;
 
+import com.google.auto.service.AutoService;
 import org.apache.hadoop.conf.Configuration;
 
 import java.util.Map;
 
+@AutoService(IMapStorageFactory.class)
 public class IMapFileStorageFactory implements IMapStorageFactory {
     @Override
     public String factoryIdentifier() {

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/Handover.java
Patch:
@@ -24,9 +24,10 @@
 import java.util.concurrent.LinkedBlockingQueue;
 
 public final class Handover<T> implements Closeable {
+    private static final int DEFAULT_QUEUE_SIZE = 10000;
     private final Object lock = new Object();
     private final LinkedBlockingQueue<T> blockingQueue =
-        new LinkedBlockingQueue<>();
+        new LinkedBlockingQueue<>(DEFAULT_QUEUE_SIZE);
     private Throwable error;
 
     public boolean isEmpty() {

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/ClickhouseProxy.java
Patch:
@@ -167,7 +167,7 @@ public List<Shard> getClusterShardList(ClickHouseRequest<?> connection, String c
      * @return clickhouse table info.
      */
     public ClickhouseTable getClickhouseTable(String database, String table) {
-        String sql = String.format("select engine,create_table_query,engine_full,data_paths from system.tables where database = '%s' and name = '%s'", database, table);
+        String sql = String.format("select engine,create_table_query,engine_full,data_paths,sorting_key from system.tables where database = '%s' and name = '%s'", database, table);
         try (ClickHouseResponse response = clickhouseRequest.query(sql).executeAndWait()) {
             List<ClickHouseRecord> records = response.stream().collect(Collectors.toList());
             if (records.isEmpty()) {
@@ -178,6 +178,7 @@ public ClickhouseTable getClickhouseTable(String database, String table) {
             String createTableDDL = record.getValue(1).asString();
             String engineFull = record.getValue(2).asString();
             List<String> dataPaths = record.getValue(3).asTuple().stream().map(Object::toString).collect(Collectors.toList());
+            String sortingKey = record.getValue(4).asString();
             DistributedEngine distributedEngine = null;
             if ("Distributed".equals(engine)) {
                 distributedEngine = getClickhouseDistributedTable(clickhouseRequest, database, table);
@@ -191,6 +192,7 @@ public ClickhouseTable getClickhouseTable(String database, String table) {
                 createTableDDL,
                 engineFull,
                 dataPaths,
+                sortingKey,
                 getClickhouseTableSchema(clickhouseRequest, table));
         } catch (ClickHouseException e) {
             throw new ClickhouseConnectorException(SeaTunnelAPIErrorCode.TABLE_NOT_EXISTED, "Cannot get clickhouse table", e);

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/ClickhouseSink.java
Patch:
@@ -142,6 +142,7 @@ public void prepare(Config config) throws PrepareFailException {
             metadata = new ShardMetadata(
                 shardKey,
                 shardKeyType,
+                table.getSortingKey(),
                 config.getString(DATABASE.key()),
                 config.getString(TABLE.key()),
                 table.getEngine(),
@@ -151,6 +152,7 @@ public void prepare(Config config) throws PrepareFailException {
             metadata = new ShardMetadata(
                 shardKey,
                 shardKeyType,
+                table.getSortingKey(),
                 config.getString(DATABASE.key()),
                 config.getString(TABLE.key()),
                 table.getEngine(),

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/source/BaseSeaTunnelSourceFunction.java
Patch:
@@ -54,7 +54,7 @@ public abstract class BaseSeaTunnelSourceFunction extends RichSourceFunction<Row
     protected transient volatile BaseSourceFunction<SeaTunnelRow> internalSource;
 
     protected transient ListState<Map<Integer, List<byte[]>>> sourceState;
-    protected transient volatile Map<Integer, List<byte[]>> restoredState = new HashMap<>();
+    protected transient volatile Map<Integer, List<byte[]>> restoredState;
 
     protected final AtomicLong latestCompletedCheckpointId = new AtomicLong(0);
     protected final AtomicLong latestTriggerCheckpointId = new AtomicLong(0);
@@ -142,6 +142,7 @@ public void snapshotState(FunctionSnapshotContext snapshotContext) throws Except
 
     @Override
     public void initializeState(FunctionInitializationContext initializeContext) throws Exception {
+        this.restoredState = new HashMap<>();
         this.sourceState = initializeContext.getOperatorStateStore()
             .getListState(
                 new ListStateDescriptor<>(

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/configuration/Option.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.api.configuration;
 
-import com.fasterxml.jackson.core.type.TypeReference;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
 
 import java.util.Objects;
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/configuration/Options.java
Patch:
@@ -19,7 +19,8 @@
 
 import static com.google.common.base.Preconditions.checkArgument;
 
-import com.fasterxml.jackson.core.type.TypeReference;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
+
 import lombok.NonNull;
 import org.apache.commons.lang3.StringUtils;
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/configuration/SingleChoiceOption.java
Patch:
@@ -17,7 +17,8 @@
 
 package org.apache.seatunnel.api.configuration;
 
-import com.fasterxml.jackson.core.type.TypeReference;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
+
 import lombok.Getter;
 
 import java.util.List;

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/configuration/util/OptionUtil.java
Patch:
@@ -19,7 +19,8 @@
 
 import org.apache.seatunnel.api.configuration.Option;
 
-import com.fasterxml.jackson.core.type.TypeReference;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
+
 import org.apache.commons.lang3.StringUtils;
 
 import java.lang.reflect.Field;

File: seatunnel-api/src/test/java/org/apache/seatunnel/api/configuration/ReadableConfigTest.java
Patch:
@@ -17,11 +17,11 @@
 
 package org.apache.seatunnel.api.configuration;
 
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigResolveOptions;
 
-import com.fasterxml.jackson.core.type.TypeReference;
 import org.apache.commons.lang3.StringUtils;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;

File: seatunnel-api/src/test/java/org/apache/seatunnel/api/configuration/util/OptionRuleTest.java
Patch:
@@ -26,7 +26,8 @@
 import org.apache.seatunnel.api.configuration.OptionTest;
 import org.apache.seatunnel.api.configuration.Options;
 
-import com.fasterxml.jackson.core.type.TypeReference;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
+
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.function.Executable;

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/inject/StringInjectFunction.java
Patch:
@@ -20,8 +20,8 @@
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.exception.ClickhouseConnectorException;
 
-import com.fasterxml.jackson.core.JsonProcessingException;
-import com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.JsonProcessingException;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
 
 import java.sql.PreparedStatement;
 import java.sql.SQLException;

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/ElasticsearchRowSerializer.java
Patch:
@@ -28,8 +28,9 @@
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.serialize.type.IndexTypeSerializer;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.serialize.type.IndexTypeSerializerFactory;
 
-import com.fasterxml.jackson.core.JsonProcessingException;
-import com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.JsonProcessingException;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
+
 import lombok.NonNull;
 
 import java.time.temporal.Temporal;

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/source/DefaultSeaTunnelRowDeserializer.java
Patch:
@@ -40,9 +40,9 @@
 import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.exception.ElasticsearchConnectorException;
 
-import com.fasterxml.jackson.core.JsonProcessingException;
-import com.fasterxml.jackson.core.type.TypeReference;
-import com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.JsonProcessingException;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
 
 import java.lang.reflect.Array;
 import java.math.BigDecimal;

File: seatunnel-connectors-v2/connector-google-sheets/src/main/java/org/apache/seatunnel/connectors/seatunnel/google/sheets/deserialize/GoogleSheetsDeserializer.java
Patch:
@@ -22,7 +22,7 @@
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.google.sheets.exception.GoogleSheetsConnectorException;
 
-import com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
 
 import java.io.IOException;
 import java.util.HashMap;

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSource.java
Patch:
@@ -59,10 +59,10 @@
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
 import org.apache.seatunnel.format.text.TextDeserializationSchema;
 
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ObjectNode;
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigRenderOptions;
 
-import com.fasterxml.jackson.databind.node.ObjectNode;
 import com.google.auto.service.AutoService;
 import org.apache.kafka.common.TopicPartition;
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-elasticsearch-e2e/src/test/java/org/apache/seatunnel/e2e/connector/elasticsearch/ElasticsearchIT.java
Patch:
@@ -24,8 +24,9 @@
 import org.apache.seatunnel.e2e.common.TestSuiteBase;
 import org.apache.seatunnel.e2e.common.container.TestContainer;
 
-import com.fasterxml.jackson.core.JsonProcessingException;
-import com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.JsonProcessingException;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
+
 import com.google.common.collect.Lists;
 import lombok.extern.slf4j.Slf4j;
 import org.junit.jupiter.api.AfterEach;

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-kafka-e2e/src/test/java/org/apache/seatunnel/e2e/connector/kafka/KafkaIT.java
Patch:
@@ -32,8 +32,9 @@
 import org.apache.seatunnel.e2e.common.container.TestContainer;
 import org.apache.seatunnel.format.text.TextSerializationSchema;
 
-import com.fasterxml.jackson.databind.ObjectMapper;
-import com.fasterxml.jackson.databind.node.ObjectNode;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ObjectNode;
+
 import lombok.extern.slf4j.Slf4j;
 import org.apache.kafka.clients.consumer.ConsumerConfig;
 import org.apache.kafka.clients.consumer.ConsumerRecord;

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/SeaTunnelClientTest.java
Patch:
@@ -34,7 +34,8 @@
 import org.apache.seatunnel.engine.core.job.JobStatus;
 import org.apache.seatunnel.engine.server.SeaTunnelNodeContext;
 
-import com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
+
 import com.hazelcast.client.config.ClientConfig;
 import com.hazelcast.core.HazelcastInstance;
 import com.hazelcast.instance.impl.HazelcastInstanceFactory;

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/server/ServerConfigOptions.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.configuration.Option;
 import org.apache.seatunnel.api.configuration.Options;
 
-import com.fasterxml.jackson.core.type.TypeReference;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.core.type.TypeReference;
 
 import java.util.Map;
 

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/JsonSerializationSchema.java
Patch:
@@ -26,8 +26,9 @@
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
 
-import com.fasterxml.jackson.databind.ObjectMapper;
-import com.fasterxml.jackson.databind.node.ObjectNode;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ObjectNode;
+
 import lombok.Getter;
 
 public class JsonSerializationSchema implements SerializationSchema {

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/JsonToRowConverters.java
Patch:
@@ -29,7 +29,7 @@
 import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.format.json.exception.SeaTunnelJsonFormatException;
 
-import com.fasterxml.jackson.databind.JsonNode;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.JsonNode;
 
 import java.io.IOException;
 import java.io.Serializable;

File: seatunnel-formats/seatunnel-format-text/src/main/java/org/apache/seatunnel/format/text/TextDeserializationSchema.java
Patch:
@@ -32,7 +32,8 @@
 import org.apache.seatunnel.common.utils.TimeUtils;
 import org.apache.seatunnel.format.text.exception.SeaTunnelTextFormatException;
 
-import com.fasterxml.jackson.databind.node.ArrayNode;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ArrayNode;
+
 import lombok.Builder;
 import lombok.NonNull;
 import org.apache.commons.lang3.StringUtils;

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/FieldMapperTransform.java
Patch:
@@ -30,11 +30,11 @@
 import org.apache.seatunnel.transform.exception.FieldMapperTransformErrorCode;
 import org.apache.seatunnel.transform.exception.FieldMapperTransformException;
 
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.JsonNode;
+import org.apache.seatunnel.shade.com.fasterxml.jackson.databind.node.ObjectNode;
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigRenderOptions;
 
-import com.fasterxml.jackson.databind.JsonNode;
-import com.fasterxml.jackson.databind.node.ObjectNode;
 import com.google.auto.service.AutoService;
 import com.google.common.collect.Lists;
 import lombok.extern.slf4j.Slf4j;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -29,6 +29,7 @@
 import com.hazelcast.logging.ILogger;
 import com.hazelcast.logging.Logger;
 import com.hazelcast.map.IMap;
+import lombok.Data;
 import lombok.NonNull;
 
 import java.util.List;
@@ -39,6 +40,7 @@
 import java.util.concurrent.atomic.AtomicReference;
 import java.util.stream.Collectors;
 
+@Data
 public class SubPlan {
     private static final ILogger LOGGER = Logger.getLogger(SubPlan.class);
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/CheckpointFinishedOperation.java
Patch:
@@ -92,7 +92,7 @@ public void run() throws Exception {
                 sneakyThrow(e);
             }
             return null;
-        }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
+        }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, false,
             exception -> exception instanceof NullPointerException &&
                 !server.taskIsEnded(taskLocation.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceIT.java
Patch:
@@ -736,7 +736,7 @@ public void testStreamJobRestoreInAllNodeDown() throws ExecutionException, Inter
             Thread.sleep(10000);
             clientJobProxy.cancelJob();
 
-            Awaitility.await().atMost(200000, TimeUnit.MILLISECONDS)
+            Awaitility.await().atMost(360000, TimeUnit.MILLISECONDS)
                 .untilAsserted(() -> Assertions.assertTrue(
                     objectCompletableFuture.isDone() && JobStatus.CANCELED.equals(objectCompletableFuture.get())));
 

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/exception/KafkaConnectorErrorCode.java
Patch:
@@ -25,7 +25,8 @@ public enum KafkaConnectorErrorCode implements SeaTunnelErrorCode {
     ADD_SPLIT_CHECKPOINT_FAILED("KAFKA-03", "Add the split checkpoint state to reader failed"),
     ADD_SPLIT_BACK_TO_ENUMERATOR_FAILED("KAFKA-04", "Add a split back to the split enumerator failed,it will only happen when a SourceReader failed"),
     CONSUME_THREAD_RUN_ERROR("KAFKA-05", "Error occurred when the kafka consumer thread was running"),
-    CONSUME_DATA_FAILED("KAFKA-06", "Kafka failed to consume data");
+    CONSUME_DATA_FAILED("KAFKA-06", "Kafka failed to consume data"),
+    CONSUMER_CLOSE_FAILED("KAFKA-07", "Kafka failed to close consumer");
 
     private final String code;
     private final String description;

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/configuration/util/OptionRule.java
Patch:
@@ -195,8 +195,9 @@ public <T> Builder conditional(@NonNull Option<T> conditionalOption, @NonNull Li
 
         public <T> Builder conditional(@NonNull Option<T> conditionalOption, @NonNull T expectValue, @NonNull Option<?>... requiredOptions) {
             for (Option<?> o : requiredOptions) {
-                verifyDuplicate(o, "ConditionalOption");
-                //verifyRequiredOptionDefaultValue(o);
+                // temporarily cancel this logic, need to find a way to verify that the options is duplicated
+                // verifyDuplicate(o, "ConditionalOption");
+                // verifyRequiredOptionDefaultValue(o);
             }
 
             verifyConditionalExists(conditionalOption);

File: seatunnel-connectors-v2/connector-fake/src/test/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeFactoryTest.java
Patch:
@@ -15,9 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.fake;
-
-import org.apache.seatunnel.connectors.seatunnel.fake.source.FakeSourceFactory;
+package org.apache.seatunnel.connectors.seatunnel.fake.source;
 
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceReader.java
Patch:
@@ -160,7 +160,7 @@ public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
     @Override
     public List<KafkaSourceSplit> snapshotState(long checkpointId) {
         checkpointOffsetMap.put(checkpointId, sourceSplits.stream()
-            .collect(Collectors.toMap(KafkaSourceSplit::getTopicPartition, KafkaSourceSplit::getEndOffset)));
+            .collect(Collectors.toMap(KafkaSourceSplit::getTopicPartition, KafkaSourceSplit::getStartOffset)));
         return sourceSplits.stream().map(KafkaSourceSplit::copy).collect(Collectors.toList());
     }
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SinkCommonOptions.java
Patch:
@@ -22,6 +22,8 @@
 
 public class SinkCommonOptions {
 
+    public static final String DATA_SAVE_MODE = "save_mode";
+
     public static final Option<String> SOURCE_TABLE_NAME =
         Options.key("source_table_name")
             .stringType()

File: seatunnel-plugin-discovery/src/main/java/org/apache/seatunnel/plugin/discovery/AbstractPluginDiscovery.java
Patch:
@@ -236,7 +236,7 @@ public Map<PluginType, LinkedHashMap<PluginIdentifier, OptionRule>> getAllPlugin
                         PluginType.SINK.getType(),
                         plugin.factoryIdentifier()
                     ),
-                    plugin.optionRule());
+                    FactoryUtil.sinkFullOptionRule((TableSinkFactory) plugin));
                 return;
             }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/JdbcOutputFormat.java
Patch:
@@ -244,6 +244,4 @@ public Connection getConnection() {
     public interface StatementExecutorFactory<T extends JdbcBatchStatementExecutor<?>>
         extends Supplier<T>, Serializable {
     }
-
-    ;
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/executor/BufferedBatchStatementExecutor.java
Patch:
@@ -63,8 +63,6 @@ public void closeStatements() throws SQLException {
         if (!buffer.isEmpty()) {
             executeBatch();
         }
-        if (statementExecutor != null) {
-            statementExecutor.closeStatements();
-        }
+        statementExecutor.closeStatements();
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkAggregatedCommitter.java
Patch:
@@ -54,7 +54,7 @@ private void tryOpen() throws IOException {
             try {
                 xaFacade.open();
             } catch (Exception e) {
-                new JdbcConnectorException(CommonErrorCode.WRITER_OPERATION_FAILED, "unable to open JDBC sink aggregated committer", e);
+                throw new JdbcConnectorException(CommonErrorCode.WRITER_OPERATION_FAILED, "unable to open JDBC sink aggregated committer", e);
             }
         }
     }
@@ -89,7 +89,7 @@ public void close()
                 xaFacade.close();
             }
         } catch (Exception e) {
-            new JdbcConnectorException(CommonErrorCode.WRITER_OPERATION_FAILED, "unable to close JDBC sink aggregated committer", e);
+            throw new JdbcConnectorException(CommonErrorCode.WRITER_OPERATION_FAILED, "unable to close JDBC sink aggregated committer", e);
         }
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkCommitter.java
Patch:
@@ -49,7 +49,7 @@ public JdbcSinkCommitter(
         try {
             xaFacade.open();
         } catch (Exception e) {
-            new JdbcConnectorException(CommonErrorCode.WRITER_OPERATION_FAILED, "unable to open JDBC sink committer", e);
+            throw new JdbcConnectorException(CommonErrorCode.WRITER_OPERATION_FAILED, "unable to open JDBC sink committer", e);
         }
     }
 
@@ -65,7 +65,7 @@ public void abort(List<XidInfo> commitInfos) {
         try {
             xaGroupOps.rollback(commitInfos);
         } catch (Exception e) {
-            new JdbcConnectorException(JdbcConnectorErrorCode.XA_OPERATION_FAILED, "rollback failed", e);
+            throw new JdbcConnectorException(JdbcConnectorErrorCode.XA_OPERATION_FAILED, "rollback failed", e);
         }
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/oracle/OracleDialect.java
Patch:
@@ -55,7 +55,7 @@ public Optional<String> getUpsertStatement(String tableName, String[] fieldNames
             .filter(fieldName -> !Arrays.asList(uniqueKeyFields).contains(fieldName))
             .collect(Collectors.toList());
         String valuesBinding = Arrays.stream(fieldNames)
-            .map(fieldName -> "? " + quoteIdentifier(fieldName))
+            .map(fieldName -> ":" + fieldName + " " + quoteIdentifier(fieldName))
             .collect(Collectors.joining(", "));
 
         String usingClause = String.format("SELECT %s FROM DUAL", valuesBinding);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/sqlserver/SqlServerDialect.java
Patch:
@@ -48,7 +48,7 @@ public Optional<String> getUpsertStatement(String tableName, String[] fieldNames
             .filter(fieldName -> !Arrays.asList(uniqueKeyFields).contains(fieldName))
             .collect(Collectors.toList());
         String valuesBinding = Arrays.stream(fieldNames)
-            .map(fieldName -> "? " + quoteIdentifier(fieldName))
+            .map(fieldName -> ":" + fieldName + " " + quoteIdentifier(fieldName))
             .collect(Collectors.joining(", "));
 
         String usingClause = String.format("SELECT %s", valuesBinding);

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/IncrementalSourceEnumerator.java
Patch:
@@ -67,13 +67,13 @@ public void open() {
     }
 
     @Override
-    public void run() throws Exception {
+    public synchronized void run() throws Exception {
         this.running = true;
         assignSplits();
     }
 
     @Override
-    public void handleSplitRequest(int subtaskId) {
+    public synchronized void handleSplitRequest(int subtaskId) {
         if (!context.registeredReaders().contains(subtaskId)) {
             // reader failed between sending the request and now. skip this request.
             return;
@@ -128,7 +128,7 @@ public PendingSplitsState snapshotState(long checkpointId) {
     }
 
     @Override
-    public void notifyCheckpointComplete(long checkpointId) {
+    public synchronized void notifyCheckpointComplete(long checkpointId) {
         splitAssigner.notifyCheckpointComplete(checkpointId);
         // incremental split may be available after checkpoint complete
         assignSplits();

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/job/Job.java
Patch:
@@ -25,7 +25,7 @@
 public interface Job {
     long getJobId();
 
-    PassiveCompletableFuture<JobStatus> doWaitForJobComplete();
+    PassiveCompletableFuture<JobResult> doWaitForJobComplete();
 
     void cancelJob();
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/WaitForJobCompleteOperation.java
Patch:
@@ -34,7 +34,8 @@ public WaitForJobCompleteOperation(long jobId) {
     @Override
     protected PassiveCompletableFuture<?> doRun() throws Exception {
         SeaTunnelServer service = getService();
-        return service.getCoordinatorService().waitForJobComplete(jobId);
+        return new PassiveCompletableFuture<>(service.getCoordinatorService().waitForJobComplete(jobId)
+            .thenApply(jobResult -> this.getNodeEngine().getSerializationService().toData(jobResult)));
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/protocol/task/WaitForJobCompleteTask.java
Patch:
@@ -17,20 +17,20 @@
 
 package org.apache.seatunnel.engine.server.protocol.task;
 
-import org.apache.seatunnel.engine.core.job.JobStatus;
 import org.apache.seatunnel.engine.core.protocol.codec.SeaTunnelWaitForJobCompleteCodec;
 import org.apache.seatunnel.engine.server.operation.WaitForJobCompleteOperation;
 
 import com.hazelcast.client.impl.protocol.ClientMessage;
 import com.hazelcast.instance.impl.Node;
 import com.hazelcast.internal.nio.Connection;
+import com.hazelcast.internal.serialization.Data;
 import com.hazelcast.spi.impl.operationservice.Operation;
 
-public class WaitForJobCompleteTask extends AbstractSeaTunnelMessageTask<Long, JobStatus> {
+public class WaitForJobCompleteTask extends AbstractSeaTunnelMessageTask<Long, Data> {
     protected WaitForJobCompleteTask(ClientMessage clientMessage, Node node, Connection connection) {
         super(clientMessage, node, connection,
             SeaTunnelWaitForJobCompleteCodec::decodeRequest,
-            x -> SeaTunnelWaitForJobCompleteCodec.encodeResponse(x.ordinal()));
+            SeaTunnelWaitForJobCompleteCodec::encodeResponse);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/DeployTaskOperation.java
Patch:
@@ -47,7 +47,7 @@ public DeployTaskOperation(@NonNull SlotProfile slotProfile, @NonNull Data taskI
     public void run() throws Exception {
         SeaTunnelServer server = getService();
         server.getSlotService().getSlotContext(slotProfile)
-            .getTaskExecutionService().deployTask(taskImmutableInformation);
+            .getTaskExecutionService().deployTask(taskImmutableInformation).get();
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/master/JobMasterTest.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.engine.core.dag.logical.LogicalDag;
 import org.apache.seatunnel.engine.core.job.JobImmutableInformation;
 import org.apache.seatunnel.engine.core.job.JobInfo;
+import org.apache.seatunnel.engine.core.job.JobResult;
 import org.apache.seatunnel.engine.core.job.JobStatus;
 import org.apache.seatunnel.engine.core.job.PipelineStatus;
 import org.apache.seatunnel.engine.server.AbstractSeaTunnelServerTest;
@@ -132,14 +133,14 @@ public void testHandleCheckpointTimeout() throws Exception {
         await().atMost(120000, TimeUnit.MILLISECONDS)
             .untilAsserted(() -> Assertions.assertEquals(JobStatus.RUNNING, jobMaster.getJobStatus()));
 
-        PassiveCompletableFuture<JobStatus> jobMasterCompleteFuture = jobMaster.getJobMasterCompleteFuture();
+        PassiveCompletableFuture<JobResult> jobMasterCompleteFuture = jobMaster.getJobMasterCompleteFuture();
         // cancel job
         jobMaster.cancelJob();
 
         // test job turn to complete
         await().atMost(120000, TimeUnit.MILLISECONDS)
             .untilAsserted(() -> Assertions.assertTrue(
-                jobMasterCompleteFuture.isDone() && JobStatus.CANCELED.equals(jobMasterCompleteFuture.get())));
+                jobMasterCompleteFuture.isDone() && JobStatus.CANCELED.equals(jobMasterCompleteFuture.get().getStatus())));
 
         testIMapRemovedAfterJobComplete(jobMaster);
     }

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceIT.java
Patch:
@@ -39,6 +39,7 @@
 import lombok.extern.slf4j.Slf4j;
 import org.awaitility.Awaitility;
 import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.testcontainers.shaded.org.apache.commons.lang3.tuple.ImmutablePair;
 
@@ -53,6 +54,7 @@
  * Cluster fault tolerance test. Test the job recovery capability and data consistency assurance capability in case of cluster node failure
  */
 @Slf4j
+@Disabled
 public class ClusterFaultToleranceIT {
 
     public static final String DYNAMIC_TEST_CASE_NAME = "dynamic_test_case_name";

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceTwoPipelineIT.java
Patch:
@@ -38,6 +38,7 @@
 import lombok.extern.slf4j.Slf4j;
 import org.awaitility.Awaitility;
 import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.testcontainers.shaded.org.apache.commons.lang3.tuple.ImmutablePair;
 
@@ -52,6 +53,7 @@
  * Cluster fault tolerance test. Test the job which have two pipelines can recovery capability and data consistency assurance capability in case of cluster node failure
  */
 @Slf4j
+@Disabled
 public class ClusterFaultToleranceTwoPipelineIT {
 
     public static final String TEST_TEMPLATE_FILE_NAME = "cluster_batch_fake_to_localfile_two_pipeline_template.conf";

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/command/AbstractCommandArgs.java
Patch:
@@ -34,8 +34,7 @@ public abstract class AbstractCommandArgs extends CommandArgs {
      * config file path
      */
     @Parameter(names = {"-c", "--config"},
-            description = "Config file",
-            required = true)
+            description = "Config file")
     protected String configFile;
 
     /**

File: seatunnel-core/seatunnel-starter/src/main/java/org/apache/seatunnel/core/starter/seatunnel/args/ClientCommandArgs.java
Patch:
@@ -33,9 +33,9 @@
 
 public class ClientCommandArgs extends AbstractCommandArgs {
     @Parameter(names = {"-m", "--master"},
-        description = "SeaTunnel job submit master, support [client, cluster]",
+        description = "SeaTunnel job submit master, support [local, cluster]",
         converter = SeaTunnelMasterTargetConverter.class)
-    private MasterType masterType = MasterType.LOCAL;
+    private MasterType masterType = MasterType.CLUSTER;
 
     @Parameter(names = {"-cn", "--cluster"},
         description = "The name of cluster")

File: seatunnel-formats/seatunnel-format-json/src/test/java/org/apache/seatunnel/format/json/JsonRowDataSerDeSchemaTest.java
Patch:
@@ -235,8 +235,8 @@ public void testDeserializationNullRow() throws Exception {
         SeaTunnelRowType schema = new SeaTunnelRowType(new String[]{"name"}, new SeaTunnelDataType[]{STRING_TYPE});
         JsonDeserializationSchema deserializationSchema =
                 new JsonDeserializationSchema(true, false, schema);
-
-        assertNull(deserializationSchema.deserialize(null));
+        String s = null;
+        assertNull(deserializationSchema.deserialize(s));
     }
 
     @Test

File: seatunnel-engine/seatunnel-engine-serializer/serializer-protobuf/src/main/java/org/apache/seatunnel/engine/serializer/protobuf/ProtoStuffSerializer.java
Patch:
@@ -18,7 +18,9 @@
  *
  */
 
-package org.apache.seatunnel.engine.imap.storage.api.common;
+package org.apache.seatunnel.engine.serializer.protobuf;
+
+import org.apache.seatunnel.engine.serializer.api.Serializer;
 
 import io.protostuff.LinkedBuffer;
 import io.protostuff.ProtostuffIOUtil;

File: seatunnel-engine/seatunnel-engine-serializer/serializer-protobuf/src/test/java/org/apache/seatunnel/engine/serializer/protobuf/ProtoStuffSerializerTest.java
Patch:
@@ -18,9 +18,7 @@
  *
  */
 
-package org.apache.seatunnel.engine.imap.storage.api;
-
-import org.apache.seatunnel.engine.imap.storage.api.common.ProtoStuffSerializer;
+package org.apache.seatunnel.engine.serializer.protobuf;
 
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -26,14 +26,14 @@
 import org.apache.seatunnel.common.utils.ExceptionUtils;
 import org.apache.seatunnel.engine.checkpoint.storage.PipelineState;
 import org.apache.seatunnel.engine.checkpoint.storage.api.CheckpointStorage;
-import org.apache.seatunnel.engine.checkpoint.storage.common.ProtoStuffSerializer;
-import org.apache.seatunnel.engine.checkpoint.storage.common.Serializer;
 import org.apache.seatunnel.engine.common.config.server.CheckpointConfig;
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.core.checkpoint.Checkpoint;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointIDCounter;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointType;
+import org.apache.seatunnel.engine.serializer.api.Serializer;
+import org.apache.seatunnel.engine.serializer.protobuf.ProtoStuffSerializer;
 import org.apache.seatunnel.engine.server.checkpoint.operation.CheckpointBarrierTriggerOperation;
 import org.apache.seatunnel.engine.server.checkpoint.operation.CheckpointFinishedOperation;
 import org.apache.seatunnel.engine.server.checkpoint.operation.NotifyTaskRestoreOperation;

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManagerTest.java
Patch:
@@ -22,14 +22,14 @@
 import org.apache.seatunnel.engine.checkpoint.storage.PipelineState;
 import org.apache.seatunnel.engine.checkpoint.storage.api.CheckpointStorage;
 import org.apache.seatunnel.engine.checkpoint.storage.api.CheckpointStorageFactory;
-import org.apache.seatunnel.engine.checkpoint.storage.common.ProtoStuffSerializer;
 import org.apache.seatunnel.engine.checkpoint.storage.exception.CheckpointStorageException;
 import org.apache.seatunnel.engine.common.config.server.CheckpointConfig;
 import org.apache.seatunnel.engine.common.config.server.CheckpointStorageConfig;
 import org.apache.seatunnel.engine.common.utils.FactoryUtil;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointType;
 import org.apache.seatunnel.engine.core.job.JobStatus;
 import org.apache.seatunnel.engine.core.job.PipelineStatus;
+import org.apache.seatunnel.engine.serializer.protobuf.ProtoStuffSerializer;
 import org.apache.seatunnel.engine.server.AbstractSeaTunnelServerTest;
 
 import com.hazelcast.map.IMap;

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/StorageTest.java
Patch:
@@ -18,8 +18,8 @@
 package org.apache.seatunnel.engine.server.checkpoint;
 
 import org.apache.seatunnel.engine.checkpoint.storage.PipelineState;
-import org.apache.seatunnel.engine.checkpoint.storage.common.ProtoStuffSerializer;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointType;
+import org.apache.seatunnel.engine.serializer.protobuf.ProtoStuffSerializer;
 
 import org.apache.commons.io.FileUtils;
 import org.junit.jupiter.api.Assertions;

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-api/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/api/AbstractCheckpointStorage.java
Patch:
@@ -21,10 +21,10 @@
 package org.apache.seatunnel.engine.checkpoint.storage.api;
 
 import org.apache.seatunnel.engine.checkpoint.storage.PipelineState;
-import org.apache.seatunnel.engine.checkpoint.storage.common.ProtoStuffSerializer;
-import org.apache.seatunnel.engine.checkpoint.storage.common.Serializer;
 import org.apache.seatunnel.engine.checkpoint.storage.common.StorageThreadFactory;
 import org.apache.seatunnel.engine.checkpoint.storage.exception.CheckpointStorageException;
+import org.apache.seatunnel.engine.serializer.api.Serializer;
+import org.apache.seatunnel.engine.serializer.protobuf.ProtoStuffSerializer;
 
 import lombok.extern.slf4j.Slf4j;
 

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-file/src/main/java/org/apache/seatunnel/engine/imap/storage/file/IMapFileStorage.java
Patch:
@@ -28,8 +28,6 @@
 import static org.apache.seatunnel.engine.imap.storage.file.common.FileConstants.FileInitProperties.NAMESPACE_KEY;
 
 import org.apache.seatunnel.engine.imap.storage.api.IMapStorage;
-import org.apache.seatunnel.engine.imap.storage.api.common.ProtoStuffSerializer;
-import org.apache.seatunnel.engine.imap.storage.api.common.Serializer;
 import org.apache.seatunnel.engine.imap.storage.api.exception.IMapStorageException;
 import org.apache.seatunnel.engine.imap.storage.file.bean.IMapFileData;
 import org.apache.seatunnel.engine.imap.storage.file.common.FileConstants;
@@ -38,6 +36,8 @@
 import org.apache.seatunnel.engine.imap.storage.file.disruptor.WALEventType;
 import org.apache.seatunnel.engine.imap.storage.file.future.RequestFuture;
 import org.apache.seatunnel.engine.imap.storage.file.future.RequestFutureCache;
+import org.apache.seatunnel.engine.serializer.api.Serializer;
+import org.apache.seatunnel.engine.serializer.protobuf.ProtoStuffSerializer;
 
 import lombok.extern.slf4j.Slf4j;
 import org.apache.hadoop.conf.Configuration;

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-file/src/main/java/org/apache/seatunnel/engine/imap/storage/file/common/WALReader.java
Patch:
@@ -22,9 +22,9 @@
 
 import static org.apache.seatunnel.engine.imap.storage.file.common.WALDataUtils.WAL_DATA_METADATA_LENGTH;
 
-import org.apache.seatunnel.engine.imap.storage.api.common.Serializer;
 import org.apache.seatunnel.engine.imap.storage.api.exception.IMapStorageException;
 import org.apache.seatunnel.engine.imap.storage.file.bean.IMapFileData;
+import org.apache.seatunnel.engine.serializer.api.Serializer;
 
 import org.apache.commons.collections.CollectionUtils;
 import org.apache.commons.lang3.ClassUtils;

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-file/src/main/java/org/apache/seatunnel/engine/imap/storage/file/common/WALWriter.java
Patch:
@@ -20,8 +20,8 @@
 
 package org.apache.seatunnel.engine.imap.storage.file.common;
 
-import org.apache.seatunnel.engine.imap.storage.api.common.Serializer;
 import org.apache.seatunnel.engine.imap.storage.file.bean.IMapFileData;
+import org.apache.seatunnel.engine.serializer.api.Serializer;
 
 import org.apache.hadoop.fs.FSDataOutputStream;
 import org.apache.hadoop.fs.FileSystem;

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-file/src/main/java/org/apache/seatunnel/engine/imap/storage/file/disruptor/WALDisruptor.java
Patch:
@@ -20,9 +20,9 @@
 
 package org.apache.seatunnel.engine.imap.storage.file.disruptor;
 
-import org.apache.seatunnel.engine.imap.storage.api.common.Serializer;
 import org.apache.seatunnel.engine.imap.storage.api.exception.IMapStorageException;
 import org.apache.seatunnel.engine.imap.storage.file.bean.IMapFileData;
+import org.apache.seatunnel.engine.serializer.api.Serializer;
 
 import com.lmax.disruptor.BlockingWaitStrategy;
 import com.lmax.disruptor.EventTranslatorThreeArg;

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-file/src/main/java/org/apache/seatunnel/engine/imap/storage/file/disruptor/WALWorkHandler.java
Patch:
@@ -20,11 +20,11 @@
 
 package org.apache.seatunnel.engine.imap.storage.file.disruptor;
 
-import org.apache.seatunnel.engine.imap.storage.api.common.Serializer;
 import org.apache.seatunnel.engine.imap.storage.api.exception.IMapStorageException;
 import org.apache.seatunnel.engine.imap.storage.file.bean.IMapFileData;
 import org.apache.seatunnel.engine.imap.storage.file.common.WALWriter;
 import org.apache.seatunnel.engine.imap.storage.file.future.RequestFutureCache;
+import org.apache.seatunnel.engine.serializer.api.Serializer;
 
 import com.lmax.disruptor.WorkHandler;
 import lombok.extern.slf4j.Slf4j;

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-file/src/test/java/org/apache/seatunnel/engine/imap/storage/file/common/WALReaderAndWriterTest.java
Patch:
@@ -24,9 +24,9 @@
 import static org.junit.jupiter.api.condition.OS.LINUX;
 import static org.junit.jupiter.api.condition.OS.MAC;
 
-import org.apache.seatunnel.engine.imap.storage.api.common.ProtoStuffSerializer;
-import org.apache.seatunnel.engine.imap.storage.api.common.Serializer;
 import org.apache.seatunnel.engine.imap.storage.file.bean.IMapFileData;
+import org.apache.seatunnel.engine.serializer.api.Serializer;
+import org.apache.seatunnel.engine.serializer.protobuf.ProtoStuffSerializer;
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;

File: seatunnel-engine/seatunnel-engine-storage/imap-storage-file/src/test/java/org/apache/seatunnel/engine/imap/storage/file/disruptor/WALDisruptorTest.java
Patch:
@@ -23,10 +23,10 @@
 import static org.junit.jupiter.api.condition.OS.LINUX;
 import static org.junit.jupiter.api.condition.OS.MAC;
 
-import org.apache.seatunnel.engine.imap.storage.api.common.ProtoStuffSerializer;
 import org.apache.seatunnel.engine.imap.storage.file.bean.IMapFileData;
 import org.apache.seatunnel.engine.imap.storage.file.future.RequestFuture;
 import org.apache.seatunnel.engine.imap.storage.file.future.RequestFutureCache;
+import org.apache.seatunnel.engine.serializer.protobuf.ProtoStuffSerializer;
 
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.fs.FileSystem;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/SourceFlowLifeCycle.java
Patch:
@@ -48,6 +48,7 @@
 import java.io.IOException;
 import java.util.Collection;
 import java.util.List;
+import java.util.Objects;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutionException;
 import java.util.stream.Collectors;
@@ -200,7 +201,7 @@ public void restoreState(List<ActionSubtaskState> actionStateList) throws Except
         }
         List<SplitT> splits = actionStateList.stream()
             .map(ActionSubtaskState::getState)
-            .flatMap(Collection::stream)
+            .flatMap(Collection::stream).filter(Objects::nonNull)
             .map(bytes -> sneaky(() -> splitSerializer.deserialize(bytes)))
             .collect(Collectors.toList());
         try {

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/config/Common.java
Patch:
@@ -77,15 +77,15 @@ public static DeployMode getDeployMode() {
      * When running seatunnel in --master yarn or --master mesos, you can put plugins related files in plugins dir.
      */
     public static Path appRootDir() {
-        if (DeployMode.CLIENT == MODE || STARTER) {
+        if (DeployMode.CLIENT == MODE || DeployMode.RUN == MODE || STARTER) {
             try {
                 String path = Common.class.getProtectionDomain().getCodeSource().getLocation().toURI().getPath();
                 path = new File(path).getPath();
                 return Paths.get(path).getParent().getParent();
             } catch (URISyntaxException e) {
                 throw new RuntimeException(e);
             }
-        } else if (DeployMode.CLUSTER == MODE) {
+        } else if (DeployMode.CLUSTER == MODE || DeployMode.RUN_APPLICATION == MODE) {
             return Paths.get("");
         } else {
             throw new IllegalStateException("deploy mode not support : " + MODE);

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/SeaTunnel.java
Patch:
@@ -26,7 +26,7 @@
 import org.apache.commons.lang3.exception.ExceptionUtils;
 
 @Slf4j
-public class Seatunnel {
+public class SeaTunnel {
 
     /**
      * This method is the entrypoint of SeaTunnel.

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/Starter.java
Patch:
@@ -20,13 +20,12 @@
 import java.util.List;
 
 /**
- * a Starter is for building a commandline start command
- * based on different engine for SeaTunnel job.
+ * A starter for building a commandline start command based on different engine for SeaTunnel job.
  */
 public interface Starter {
 
     /**
-     * return the SeaTunnel job commandline start commands
+     * Return the SeaTunnel job commandline start commands
      */
     List<String> buildCommands() throws Exception;
 

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/constants/SeaTunnelStarterConstants.java
Patch:
@@ -17,6 +17,6 @@
 
 package org.apache.seatunnel.core.starter.constants;
 
-public class Constants {
+public class SeaTunnelStarterConstants {
     public static final int USAGE_EXIT_CODE = 234;
 }

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/exception/CommandException.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.core.starter.exception;
 
-public class CommandException extends Exception {
+public class CommandException extends RuntimeException {
     public CommandException(String message) {
         super(message);
     }

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/exception/TaskExecuteException.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.core.starter.exception;
 
-public class TaskExecuteException extends Exception {
+public class TaskExecuteException extends RuntimeException {
 
     public TaskExecuteException(String message) {
         super(message);

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/execution/TaskExecution.java
Patch:
@@ -19,6 +19,9 @@
 
 import org.apache.seatunnel.core.starter.exception.TaskExecuteException;
 
+/**
+ * Executes a SeaTunnel task of the specified engine, contained in the {@link org.apache.seatunnel.core.starter.command.Command}
+ */
 public interface TaskExecution {
 
     void execute() throws TaskExecuteException;

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/TransformExecuteProcessor.java
Patch:
@@ -23,7 +23,7 @@
 import org.apache.seatunnel.api.transform.SeaTunnelTransform;
 import org.apache.seatunnel.core.starter.exception.TaskExecuteException;
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
-import org.apache.seatunnel.plugin.discovery.seatunnel.SeaTunnelFlinkTransformPluginDiscovery;
+import org.apache.seatunnel.plugin.discovery.seatunnel.SeaTunnelTransformPluginDiscovery;
 import org.apache.seatunnel.translation.flink.serialization.FlinkRowConverter;
 import org.apache.seatunnel.translation.flink.utils.TypeConverterUtils;
 
@@ -41,7 +41,7 @@
 import java.util.List;
 import java.util.stream.Collectors;
 
-public class TransformExecuteProcessor extends AbstractPluginExecuteProcessor<SeaTunnelTransform> {
+public class TransformExecuteProcessor extends FlinkAbstractPluginExecuteProcessor<SeaTunnelTransform> {
 
     private static final String PLUGIN_TYPE = "transform";
 
@@ -51,7 +51,7 @@ protected TransformExecuteProcessor(List<URL> jarPaths, List<? extends Config> p
 
     @Override
     protected List<SeaTunnelTransform> initializePlugins(List<URL> jarPaths, List<? extends Config> pluginConfigs) {
-        SeaTunnelFlinkTransformPluginDiscovery transformPluginDiscovery = new SeaTunnelFlinkTransformPluginDiscovery();
+        SeaTunnelTransformPluginDiscovery transformPluginDiscovery = new SeaTunnelTransformPluginDiscovery();
         List<URL> pluginJars = new ArrayList<>();
         List<SeaTunnelTransform> transforms = pluginConfigs.stream()
             .map(transformConfig -> {

File: seatunnel-core/seatunnel-flink-starter/src/test/java/org/apache/seatunnel/core/starter/flink/args/FlinkCommandArgsTest.java
Patch:
@@ -28,11 +28,10 @@ public class FlinkCommandArgsTest {
 
     @Test
     public void testParseFlinkArgs() {
-        String[] args = {"-c", "app.conf", "-t", "-i", "city=shenyang", "-i", "date=20200202"};
+        String[] args = {"-c", "app.conf", "--check", "-i", "city=shenyang", "-i", "date=20200202"};
         FlinkCommandArgs flinkArgs = CommandLineUtils.parse(args, new FlinkCommandArgs(), "seatunnel-flink", true);
         Assertions.assertEquals("app.conf", flinkArgs.getConfigFile());
         Assertions.assertTrue(flinkArgs.isCheckConfig());
         Assertions.assertEquals(Arrays.asList("city=shenyang", "date=20200202"), flinkArgs.getVariables());
     }
-
 }

File: seatunnel-core/seatunnel-spark-starter/src/test/java/org/apache/seatunnel/core/starter/spark/utils/CommandLineUtilsTest.java
Patch:
@@ -33,13 +33,12 @@ public void testParseSparkArgs() {
         SparkCommandArgs commandLineArgs = CommandLineUtils.parse(args, new SparkCommandArgs());
 
         Assertions.assertEquals("app.conf", commandLineArgs.getConfigFile());
-        Assertions.assertEquals("cluster", commandLineArgs.getDeployMode().getName());
+        Assertions.assertEquals("cluster", commandLineArgs.getDeployMode().getDeployMode());
 
         args = new String[]{"-c", "app.conf", "-e", "cluster", "-m", "local[*]", "--queue", "test"};
         commandLineArgs = CommandLineUtils.parse(args, new SparkCommandArgs(), "seatunnel-spark", true);
 
         Assertions.assertEquals(Arrays.asList("--queue", "test"), commandLineArgs.getOriginalParameters());
 
     }
-
 }

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cdc-sqlserver-e2e/src/test/java/org/apache/seatunnel/e2e/connector/cdc/sqlserver/SqlServerCDCIT.java
Patch:
@@ -32,7 +32,6 @@
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.TestTemplate;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.testcontainers.containers.MSSQLServerContainer;
@@ -108,7 +107,8 @@ public void tearDown() throws Exception {
         LOG.info("Containers are stopped.");
     }
 
-    @TestTemplate
+    // Temporary disabled because the test can not be executed successfully
+    // https://github.com/apache/incubator-seatunnel/issues/3827
     public void test(TestContainer container) throws IOException, InterruptedException {
         initializeSqlServerTable("column_type_test");
 

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-doris-e2e/src/test/java/org/apache/seatunnel/e2e/connector/doris/DorisIT.java
Patch:
@@ -168,7 +168,7 @@ public void startUp() throws Exception {
         // wait for doris fully start
         given().ignoreExceptions()
                 .await()
-                .atMost(1000, TimeUnit.SECONDS)
+                .atMost(10000, TimeUnit.SECONDS)
                 .untilAsserted(this::initializeJdbcConnection);
         initializeJdbcTable();
         batchInsertData();

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-iotdb-e2e/src/test/java/org/apache/seatunnel/e2e/connector/iotdb/IoTDBIT.java
Patch:
@@ -58,7 +58,7 @@
 
 @Slf4j
 @DisabledOnContainer(value = {}, type = {EngineType.SEATUNNEL, EngineType.SPARK},
-    disabledReason = "There is a conflict of thrift version between IoTDB and Spark.Therefore.")
+    disabledReason = "There is a conflict of thrift version between IoTDB and Spark.Therefore. Refactor starter module, so disabled in flink")
 public class IoTDBIT extends TestSuiteBase implements TestResource {
 
     private static final String IOTDB_DOCKER_IMAGE = "apache/iotdb:0.13.1-node";

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/connector-jdbc-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/jdbc/JdbcMysqlIT.java
Patch:
@@ -20,7 +20,7 @@
 import static org.awaitility.Awaitility.given;
 
 import org.apache.seatunnel.common.config.CheckConfigUtil;
-import org.apache.seatunnel.core.starter.config.ConfigBuilder;
+import org.apache.seatunnel.core.starter.utils.ConfigBuilder;
 import org.apache.seatunnel.e2e.flink.FlinkContainer;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
@@ -88,7 +88,7 @@ public void startMySqlContainer() throws Exception {
     private void initializeJdbcTable() throws URISyntaxException {
         URI resource = Objects.requireNonNull(FlinkContainer.class.getResource("/jdbc/init_sql/mysql_init.conf")).toURI();
 
-        config = new ConfigBuilder(Paths.get(resource)).getConfig();
+        config = ConfigBuilder.of(Paths.get(resource));
 
         CheckConfigUtil.checkAllExists(this.config, "source_table", "sink_table", "type_source_table",
             "type_sink_table", "insert_type_source_table_sql", "check_type_sink_table_sql");

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/connector-jdbc-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/jdbc/JdbcSqliteIT.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.e2e.flink.v2.jdbc;
 
 import org.apache.seatunnel.common.config.CheckConfigUtil;
-import org.apache.seatunnel.core.starter.config.ConfigBuilder;
+import org.apache.seatunnel.core.starter.utils.ConfigBuilder;
 import org.apache.seatunnel.e2e.flink.FlinkContainer;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
@@ -56,7 +56,7 @@ public class JdbcSqliteIT extends FlinkContainer {
 
     private void initTestDb() throws Exception {
         URI resource = Objects.requireNonNull(JdbcSqliteIT.class.getResource("/jdbc/init_sql/sqlite_init.conf")).toURI();
-        config = new ConfigBuilder(Paths.get(resource)).getConfig();
+        config = ConfigBuilder.of(Paths.get(resource));
         CheckConfigUtil.checkAllExists(this.config, "source_table", "sink_table", "type_source_table",
                 "type_sink_table", "insert_type_source_table_sql", "check_type_sink_table_sql");
         tmpdir = Paths.get(System.getProperty("java.io.tmpdir")).toString();
@@ -116,7 +116,7 @@ public void testJdbcSqliteSourceAndSinkDataType() throws Exception {
 
     private void checkSinkDataTypeTable() throws Exception {
         URI resource = Objects.requireNonNull(JdbcSqliteIT.class.getResource("/jdbc/init_sql/sqlite_init.conf")).toURI();
-        config = new ConfigBuilder(Paths.get(resource)).getConfig();
+        config = ConfigBuilder.of(Paths.get(resource));
         CheckConfigUtil.checkAllExists(this.config, "source_table", "sink_table", "type_source_table",
                 "type_sink_table", "insert_type_source_table_sql", "check_type_sink_table_sql");
 

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/connector-jdbc-spark-e2e/src/test/java/org/apache/seatunnel/e2e/spark/v2/jdbc/JdbcMysqlIT.java
Patch:
@@ -20,7 +20,7 @@
 import static org.awaitility.Awaitility.given;
 
 import org.apache.seatunnel.common.config.CheckConfigUtil;
-import org.apache.seatunnel.core.starter.config.ConfigBuilder;
+import org.apache.seatunnel.core.starter.utils.ConfigBuilder;
 import org.apache.seatunnel.e2e.spark.SparkContainer;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
@@ -88,7 +88,7 @@ public void startMySqlContainer() throws Exception {
     private void initializeJdbcTable() throws URISyntaxException {
 
         URI resource = Objects.requireNonNull(JdbcMysqlIT.class.getResource("/jdbc/init_sql/mysql_init.conf")).toURI();
-        config = new ConfigBuilder(Paths.get(resource)).getConfig();
+        config = ConfigBuilder.of(Paths.get(resource));
         CheckConfigUtil.checkAllExists(this.config, "source_table", "sink_table", "type_source_table",
             "type_sink_table", "insert_type_source_table_sql", "check_type_sink_table_sql");
 

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/connector-jdbc-spark-e2e/src/test/java/org/apache/seatunnel/e2e/spark/v2/jdbc/JdbcSqliteIT.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.e2e.spark.v2.jdbc;
 
 import org.apache.seatunnel.common.config.CheckConfigUtil;
-import org.apache.seatunnel.core.starter.config.ConfigBuilder;
+import org.apache.seatunnel.core.starter.utils.ConfigBuilder;
 import org.apache.seatunnel.e2e.spark.SparkContainer;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
@@ -56,7 +56,7 @@ public class JdbcSqliteIT extends SparkContainer {
 
     private void initTestDb() throws Exception {
         URI resource = Objects.requireNonNull(JdbcSqliteIT.class.getResource("/jdbc/init_sql/sqlite_init.conf")).toURI();
-        config = new ConfigBuilder(Paths.get(resource)).getConfig();
+        config = ConfigBuilder.of(Paths.get(resource));
         CheckConfigUtil.checkAllExists(this.config, "source_table", "sink_table", "type_source_table",
                 "type_sink_table", "insert_type_source_table_sql", "check_type_sink_table_sql");
         tmpdir = Paths.get(System.getProperty("java.io.tmpdir")).toString();
@@ -116,7 +116,7 @@ public void testJdbcSqliteSourceAndSinkDataType() throws Exception {
 
     private void checkSinkDataTypeTable() throws Exception {
         URI resource = Objects.requireNonNull(JdbcSqliteIT.class.getResource("/jdbc/init_sql/sqlite_init.conf")).toURI();
-        config = new ConfigBuilder(Paths.get(resource)).getConfig();
+        config = ConfigBuilder.of(Paths.get(resource));
         CheckConfigUtil.checkAllExists(this.config, "source_table", "sink_table", "type_source_table",
                 "type_sink_table", "insert_type_source_table_sql", "check_type_sink_table_sql");
 

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/JobConfigParser.java
Patch:
@@ -31,7 +31,7 @@
 import org.apache.seatunnel.common.config.TypesafeConfigUtils;
 import org.apache.seatunnel.common.constants.CollectionConstants;
 import org.apache.seatunnel.common.constants.JobMode;
-import org.apache.seatunnel.core.starter.config.ConfigBuilder;
+import org.apache.seatunnel.core.starter.utils.ConfigBuilder;
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.exception.JobDefineCheckException;
 import org.apache.seatunnel.engine.common.loader.SeatunnelChildFirstClassLoader;
@@ -103,7 +103,7 @@ public JobConfigParser(@NonNull String jobDefineFilePath,
         this.jobDefineFilePath = jobDefineFilePath;
         this.idGenerator = idGenerator;
         this.jobConfig = jobConfig;
-        this.seaTunnelJobConfig = new ConfigBuilder(Paths.get(jobDefineFilePath)).getConfig();
+        this.seaTunnelJobConfig = ConfigBuilder.of(Paths.get(jobDefineFilePath));
         this.envConfigs = seaTunnelJobConfig.getConfig("env");
         this.commonPluginJars = commonPluginJars;
     }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/IncrementalSourceRecordEmitter.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.cdc.base.source.reader;
 
-import static org.apache.seatunnel.connectors.cdc.base.source.split.wartermark.WatermarkEvent.isLowWatermarkEvent;
+import static org.apache.seatunnel.connectors.cdc.base.source.split.wartermark.WatermarkEvent.isHighWatermarkEvent;
 import static org.apache.seatunnel.connectors.cdc.base.source.split.wartermark.WatermarkEvent.isWatermarkEvent;
 import static org.apache.seatunnel.connectors.cdc.base.utils.SourceRecordUtils.isDataChangeRecord;
 import static org.apache.seatunnel.connectors.cdc.base.utils.SourceRecordUtils.isSchemaChangeEvent;
@@ -75,7 +75,7 @@ protected void processElement(
         throws Exception {
         if (isWatermarkEvent(element)) {
             Offset watermark = getWatermark(element);
-            if (isLowWatermarkEvent(element) && splitState.isSnapshotSplitState()) {
+            if (isHighWatermarkEvent(element) && splitState.isSnapshotSplitState()) {
                 splitState.asSnapshotSplitState().setHighWatermark(watermark);
             }
         } else if (isSchemaChangeEvent(element) && splitState.isIncrementalSplitState()) {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/external/IncrementalSourceStreamFetcher.java
Patch:
@@ -139,7 +139,7 @@ public void close() {
     private boolean shouldEmit(SourceRecord sourceRecord) {
         if (taskContext.isDataChangeRecord(sourceRecord)) {
             Offset position = taskContext.getStreamOffset(sourceRecord);
-            return position.isAtOrAfter(splitStartWatermark);
+            return position.isAfter(splitStartWatermark);
             // TODO only the table who captured snapshot splits need to filter( Used to support Exactly-Once )
         }
         return true;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/external/JdbcSourceFetchTaskContext.java
Patch:
@@ -66,7 +66,7 @@ public TableId getTableId(SourceRecord record) {
 
     @Override
     public boolean isDataChangeRecord(SourceRecord record) {
-        return false;
+        return SourceRecordUtils.isDataChangeRecord(record);
     }
 
     @Override
@@ -161,7 +161,7 @@ public CommonConnectorConfig getDbzConnectorConfig() {
     }
 
     public SchemaNameAdjuster getSchemaNameAdjuster() {
-        return null;
+        return schemaNameAdjuster;
     }
 
     public abstract RelationalDatabaseSchema getDatabaseSchema();

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/config/SqlServerSourceConfigFactory.java
Patch:
@@ -72,7 +72,7 @@ public SqlServerSourceConfig create(int subtask) {
         }
 
         if (dbzProperties != null) {
-            props.putAll(dbzProperties);
+            dbzProperties.forEach(props::put);
         }
 
         return new SqlServerSourceConfig(

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/SqlServerDialect.java
Patch:
@@ -73,7 +73,7 @@ public boolean isDataCollectionIdCaseSensitive(JdbcSourceConfig sourceConfig) {
 
     @Override
     public JdbcConnection openJdbcConnection(JdbcSourceConfig sourceConfig) {
-        return createSqlServerConnection(sourceConfig.getDbzConnectorConfig().getJdbcConfig());
+        return createSqlServerConnection(sourceConfig.getDbzConfiguration());
     }
 
     @Override
@@ -109,9 +109,9 @@ public TableChanges.TableChange queryTableSchema(JdbcConnection jdbc, TableId ta
     public SqlServerSourceFetchTaskContext createFetchTaskContext(
         SourceSplitBase sourceSplitBase, JdbcSourceConfig taskSourceConfig) {
         final SqlServerConnection jdbcConnection =
-            createSqlServerConnection(taskSourceConfig.getDbzConnectorConfig().getJdbcConfig());
+            createSqlServerConnection(taskSourceConfig.getDbzConfiguration());
         final SqlServerConnection metaDataConnection =
-            createSqlServerConnection(taskSourceConfig.getDbzConnectorConfig().getJdbcConfig());
+            createSqlServerConnection(taskSourceConfig.getDbzConfiguration());
 
         List<TableChanges.TableChange> tableChangeList = new ArrayList<>();
         // TODO: support save table schema

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/offset/LsnOffsetFactory.java
Patch:
@@ -24,7 +24,6 @@
 import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.source.SqlServerDialect;
 import org.apache.seatunnel.connectors.seatunnel.cdc.sqlserver.source.utils.SqlServerUtils;
 
-import io.debezium.connector.sqlserver.Lsn;
 import io.debezium.connector.sqlserver.SourceInfo;
 import io.debezium.connector.sqlserver.SqlServerConnection;
 import io.debezium.jdbc.JdbcConnection;
@@ -64,7 +63,7 @@ public Offset latest() {
 
     @Override
     public Offset specific(Map<String, String> offset) {
-        return new LsnOffset(Lsn.valueOf(offset.get(SourceInfo.CHANGE_LSN_KEY)));
+        return LsnOffset.valueOf(offset.get(SourceInfo.COMMIT_LSN_KEY));
     }
 
     @Override

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/utils/SqlServerConnectionUtils.java
Patch:
@@ -35,7 +35,7 @@ public static SqlServerConnection createSqlServerConnection(Configuration dbzCon
                         connectorConfig.getTemporalPrecisionMode(),
                         connectorConfig.binaryHandlingMode());
         return new SqlServerConnection(
-                dbzConfiguration,
+                connectorConfig.jdbcConfig(),
                 Clock.system(),
                 connectorConfig.getSourceTimestampMode(),
                 valueConverters,

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/utils/SqlServerUtils.java
Patch:
@@ -188,16 +188,16 @@ public static LsnOffset getLsnPosition(Map<String, ?> offset) {
             offsetStrMap.put(
                 entry.getKey(), entry.getValue() == null ? null : entry.getValue().toString());
         }
-        return new LsnOffset(Lsn.valueOf(offsetStrMap.get(SourceInfo.CHANGE_LSN_KEY)));
+        return LsnOffset.valueOf(offsetStrMap.get(SourceInfo.COMMIT_LSN_KEY));
     }
 
     /**
      * Fetch current largest log sequence number (LSN) of the database.
      */
     public static LsnOffset currentLsn(SqlServerConnection connection) {
         try {
-            Lsn maxLsn = connection.getMaxLsn();
-            return new LsnOffset(maxLsn);
+            Lsn commitLsn = connection.getMaxTransactionLsn();
+            return LsnOffset.valueOf(commitLsn.toString());
         } catch (SQLException e) {
             throw new SeaTunnelException(e.getMessage(), e);
         }

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/source/reader/SourceReaderBase.java
Patch:
@@ -155,7 +155,7 @@ private RecordsWithSplitIds<E> getNextFetch(Collector<T> output) {
         splitFetcherManager.checkErrors();
         RecordsWithSplitIds<E> recordsWithSplitId = elementsQueue.poll();
         if (recordsWithSplitId == null || !moveToNextSplit(recordsWithSplitId, output)) {
-            log.debug("Current fetch is finished.");
+            log.trace("Current fetch is finished.");
             return null;
         }
 

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-common/src/main/java/org/apache/seatunnel/translation/spark/common/source/batch/ParallelBatchPartitionReader.java
Patch:
@@ -123,7 +123,9 @@ public InternalRow get() {
     public void close() throws IOException {
         running = false;
         try {
-            internalSource.close();
+            if (internalSource != null) {
+                internalSource.close();
+            }
         } catch (Exception e) {
             throw new RuntimeException(e);
         }

File: seatunnel-connectors-v2/connector-doris/src/main/java/org/apache/seatunnel/connectors/doris/sink/DorisSinkFactory.java
Patch:
@@ -37,7 +37,7 @@ public OptionRule optionRule() {
                 .required(SinkConfig.NODE_URLS, SinkConfig.USERNAME, SinkConfig.PASSWORD, SinkConfig.DATABASE, SinkConfig.TABLE)
                 .optional(SinkConfig.LABEL_PREFIX, SinkConfig.BATCH_MAX_SIZE, SinkConfig.BATCH_MAX_BYTES,
                         SinkConfig.BATCH_INTERVAL_MS, SinkConfig.MAX_RETRIES, SinkConfig.MAX_RETRY_BACKOFF_MS,
-                        SinkConfig.RETRY_BACKOFF_MULTIPLIER_MS, SinkConfig.DORIS_SINK_CONFIG_PREFIX)
+                        SinkConfig.RETRY_BACKOFF_MULTIPLIER_MS, SinkConfig.DORIS_CONFIG)
                 .build();
     }
 }

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/loader/SeatunnelChildFirstClassLoader.java
Patch:
@@ -39,7 +39,8 @@ public class SeatunnelChildFirstClassLoader extends SeatunnelBaseClassLoader {
         "org.slf4j",
         "org.apache.log4j",
         "org.apache.logging",
-        "org.apache.commons.logging"
+        "org.apache.commons.logging",
+        "com.fasterxml.jackson"
     };
 
     public SeatunnelChildFirstClassLoader(List<URL> urls) {

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/JsonDeserializationSchema.java
Patch:
@@ -135,7 +135,7 @@ private SeaTunnelRow convertJsonNode(JsonNode jsonNode) throws IOException {
                 return null;
             }
             throw new SeaTunnelJsonFormatException(CommonErrorCode.JSON_OPERATION_FAILED,
-                    String.format("Failed to deserialize JSON '%s'.", jsonNode.asText()), t);
+                    String.format("Failed to deserialize JSON '%s'.", jsonNode), t);
         }
     }
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/FactoryUtil.java
Patch:
@@ -171,7 +171,7 @@ public static OptionRule sourceFullOptionRule(@NonNull TableSourceFactory factor
         }
 
         Class<? extends SeaTunnelSource> sourceClass = factory.getSourceClass();
-        if (sourceClass.isAssignableFrom(SupportParallelism.class)) {
+        if (SupportParallelism.class.isAssignableFrom(sourceClass)) {
             OptionRule sourceCommonOptionRule =
                 OptionRule.builder().optional(SourceCommonOptions.PARALLELISM).build();
             sourceOptionRule.getOptionalOptions().addAll(sourceCommonOptionRule.getOptionalOptions());

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/TableSourceFactory.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.api.table.factory;
 
+import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceSplit;
 import org.apache.seatunnel.api.table.connector.TableSource;
 
@@ -36,4 +37,6 @@ default <T, SplitT extends SourceSplit, StateT extends Serializable> TableSource
         TableFactoryContext context) {
         throw new UnsupportedOperationException("unsupported now");
     }
+
+    Class<? extends SeaTunnelSource> getSourceClass();
 }

File: seatunnel-connectors-v2/connector-influxdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/influxdb/sink/InfluxDBSinkFactory.java
Patch:
@@ -32,12 +32,12 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
-import org.apache.seatunnel.api.table.factory.TableSourceFactory;
+import org.apache.seatunnel.api.table.factory.TableSinkFactory;
 
 import com.google.auto.service.AutoService;
 
 @AutoService(Factory.class)
-public class InfluxDBSinkFactory implements TableSourceFactory {
+public class InfluxDBSinkFactory implements TableSinkFactory {
 
     @Override
     public String factoryIdentifier() {

File: seatunnel-connectors-v2/connector-rabbitmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rabbitmq/sink/RabbitmqSinkFactory.java
Patch:
@@ -34,12 +34,12 @@
 
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
-import org.apache.seatunnel.api.table.factory.TableSourceFactory;
+import org.apache.seatunnel.api.table.factory.TableSinkFactory;
 
 import com.google.auto.service.AutoService;
 
 @AutoService(Factory.class)
-public class RabbitmqSinkFactory implements TableSourceFactory {
+public class RabbitmqSinkFactory implements TableSinkFactory {
 
     @Override
     public String factoryIdentifier() {

File: seatunnel-plugin-discovery/src/main/java/org/apache/seatunnel/plugin/discovery/AbstractPluginDiscovery.java
Patch:
@@ -220,14 +220,15 @@ public Map<PluginType, LinkedHashMap<PluginIdentifier, OptionRule>> getAllPlugin
 
         factories.forEach(plugin -> {
             if (TableSourceFactory.class.isAssignableFrom(plugin.getClass())) {
+                TableSourceFactory tableSourceFactory = (TableSourceFactory) plugin;
                 plugins.computeIfAbsent(PluginType.SOURCE, k -> new LinkedHashMap<>());
 
                 plugins.get(PluginType.SOURCE).put(PluginIdentifier.of(
                         "seatunnel",
                         PluginType.SOURCE.getType(),
                         plugin.factoryIdentifier()
                     ),
-                    FactoryUtil.sourceFullOptionRule(plugin));
+                    FactoryUtil.sourceFullOptionRule(tableSourceFactory));
                 return;
             }
 

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/config/ClickhouseConfig.java
Patch:
@@ -129,7 +129,7 @@ public class ClickhouseConfig {
     public static final Option<List<NodePassConfig>> NODE_PASS = Options.key("node_pass").listType(NodePassConfig.class)
         .noDefaultValue().withDescription("The password of Clickhouse server node");
 
-    public static final Option<Map<String, String>> CLICKHOUSE_PREFIX = Options.key("clickhouse").mapType()
+    public static final Option<Map<String, String>> CLICKHOUSE_CONFIG = Options.key("clickhouse.config").mapType()
         .defaultValue(Collections.emptyMap()).withDescription("Clickhouse custom config");
 
     public static final Option<String> FILE_FIELDS_DELIMITER = Options.key("file_fields_delimiter").stringType()

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/ClickhouseSinkFactory.java
Patch:
@@ -19,7 +19,7 @@
 
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.ALLOW_EXPERIMENTAL_LIGHTWEIGHT_DELETE;
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.BULK_SIZE;
-import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.CLICKHOUSE_PREFIX;
+import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.CLICKHOUSE_CONFIG;
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.DATABASE;
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.FIELDS;
 import static org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseConfig.HOST;
@@ -48,7 +48,7 @@ public String factoryIdentifier() {
     public OptionRule optionRule() {
         return OptionRule.builder()
             .required(HOST, DATABASE, TABLE)
-            .optional(CLICKHOUSE_PREFIX,
+            .optional(CLICKHOUSE_CONFIG,
                 BULK_SIZE,
                 SPLIT_MODE,
                 FIELDS,

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaSinkFactory.java
Patch:
@@ -35,7 +35,7 @@ public String factoryIdentifier() {
     public OptionRule optionRule() {
         return OptionRule.builder()
                 .required(Config.TOPIC, Config.BOOTSTRAP_SERVERS)
-                .optional(Config.KAFKA_CONFIG_PREFIX, Config.ASSIGN_PARTITIONS, Config.TRANSACTION_PREFIX)
+                .optional(Config.KAFKA_CONFIG, Config.ASSIGN_PARTITIONS, Config.TRANSACTION_PREFIX)
                 .exclusive(Config.PARTITION, Config.PARTITION_KEY_FIELDS)
                 .build();
     }

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceFactory.java
Patch:
@@ -38,7 +38,7 @@ public OptionRule optionRule() {
         return OptionRule.builder()
             .required(Config.TOPIC, Config.BOOTSTRAP_SERVERS)
             .optional(Config.START_MODE, Config.PATTERN, Config.CONSUMER_GROUP, Config.COMMIT_ON_CHECKPOINT,
-                Config.KAFKA_CONFIG_PREFIX, Config.SCHEMA,
+                Config.KAFKA_CONFIG, Config.SCHEMA,
                 Config.FORMAT, Config.KEY_PARTITION_DISCOVERY_INTERVAL_MILLIS)
             .conditional(Config.START_MODE, StartMode.TIMESTAMP, Config.START_MODE_TIMESTAMP)
             .conditional(Config.START_MODE, StartMode.SPECIFIC_OFFSETS, Config.START_MODE_OFFSETS)

File: seatunnel-connectors-v2/connector-rabbitmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rabbitmq/sink/RabbitmqSinkFactory.java
Patch:
@@ -25,6 +25,7 @@
 import static org.apache.seatunnel.connectors.seatunnel.rabbitmq.config.RabbitmqConfig.PASSWORD;
 import static org.apache.seatunnel.connectors.seatunnel.rabbitmq.config.RabbitmqConfig.PORT;
 import static org.apache.seatunnel.connectors.seatunnel.rabbitmq.config.RabbitmqConfig.QUEUE_NAME;
+import static org.apache.seatunnel.connectors.seatunnel.rabbitmq.config.RabbitmqConfig.RABBITMQ_CONFIG;
 import static org.apache.seatunnel.connectors.seatunnel.rabbitmq.config.RabbitmqConfig.ROUTING_KEY;
 import static org.apache.seatunnel.connectors.seatunnel.rabbitmq.config.RabbitmqConfig.TOPOLOGY_RECOVERY_ENABLED;
 import static org.apache.seatunnel.connectors.seatunnel.rabbitmq.config.RabbitmqConfig.URL;
@@ -62,7 +63,8 @@ public OptionRule optionRule() {
                 NETWORK_RECOVERY_INTERVAL,
                 TOPOLOGY_RECOVERY_ENABLED,
                 AUTOMATIC_RECOVERY_ENABLED,
-                CONNECTION_TIMEOUT
+                CONNECTION_TIMEOUT,
+                RABBITMQ_CONFIG
             )
             .build();
     }

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/sink/StarRocksSinkFactory.java
Patch:
@@ -37,7 +37,7 @@ public OptionRule optionRule() {
                 .required(SinkConfig.NODE_URLS, SinkConfig.USERNAME, SinkConfig.PASSWORD, SinkConfig.DATABASE, SinkConfig.TABLE)
                 .optional(SinkConfig.LABEL_PREFIX, SinkConfig.BATCH_MAX_SIZE, SinkConfig.BATCH_MAX_BYTES,
                         SinkConfig.BATCH_INTERVAL_MS, SinkConfig.MAX_RETRIES, SinkConfig.MAX_RETRY_BACKOFF_MS,
-                        SinkConfig.RETRY_BACKOFF_MULTIPLIER_MS, SinkConfig.STARROCKS_SINK_CONFIG_PREFIX)
+                        SinkConfig.RETRY_BACKOFF_MULTIPLIER_MS, SinkConfig.STARROCKS_CONFIG)
                 .build();
     }
 }

File: seatunnel-connectors-v2/connector-amazondynamodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/amazondynamodb/source/AmazonDynamoDBSource.java
Patch:
@@ -28,6 +28,7 @@
 import org.apache.seatunnel.api.common.SeaTunnelAPIErrorCode;
 import org.apache.seatunnel.api.source.Boundedness;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.source.SupportColumnProjection;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
@@ -48,7 +49,7 @@
 
 @Slf4j
 @AutoService(SeaTunnelSource.class)
-public class AmazonDynamoDBSource extends AbstractSingleSplitSource<SeaTunnelRow> {
+public class AmazonDynamoDBSource extends AbstractSingleSplitSource<SeaTunnelRow> implements SupportColumnProjection {
 
     private AmazonDynamoDBSourceOptions amazondynamodbSourceOptions;
 

File: seatunnel-connectors-v2/connector-cassandra/src/main/java/org/apache/seatunnel/connectors/seatunnel/cassandra/source/CassandraSource.java
Patch:
@@ -25,6 +25,7 @@
 import org.apache.seatunnel.api.common.SeaTunnelAPIErrorCode;
 import org.apache.seatunnel.api.source.Boundedness;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.source.SupportColumnProjection;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
@@ -48,7 +49,7 @@
 import com.google.auto.service.AutoService;
 
 @AutoService(SeaTunnelSource.class)
-public class CassandraSource extends AbstractSingleSplitSource<SeaTunnelRow> {
+public class CassandraSource extends AbstractSingleSplitSource<SeaTunnelRow> implements SupportColumnProjection {
 
     private SeaTunnelRowType rowTypeInfo;
     private CassandraConfig cassandraConfig;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlIncrementalSource.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.source.SupportParallelism;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.catalog.TablePath;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
@@ -41,7 +42,7 @@
 import java.time.ZoneId;
 
 @AutoService(SeaTunnelSource.class)
-public class MySqlIncrementalSource<T> extends IncrementalSource<T, JdbcSourceConfig> {
+public class MySqlIncrementalSource<T> extends IncrementalSource<T, JdbcSourceConfig> implements SupportParallelism {
     static final String IDENTIFIER = "MySQL-CDC";
 
     @Override

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/source/SqlServerIncrementalSource.java
Patch:
@@ -22,6 +22,7 @@
 
 import org.apache.seatunnel.api.configuration.ReadonlyConfig;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.source.SupportParallelism;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.cdc.base.config.JdbcSourceConfig;
 import org.apache.seatunnel.connectors.cdc.base.config.SourceConfig;
@@ -44,7 +45,8 @@
 import java.time.ZoneId;
 
 @AutoService(SeaTunnelSource.class)
-public class SqlServerIncrementalSource<T> extends IncrementalSource<T, JdbcSourceConfig> {
+public class SqlServerIncrementalSource<T> extends IncrementalSource<T, JdbcSourceConfig> implements
+    SupportParallelism {
 
     @Override
     public String getPluginName() {

File: seatunnel-connectors-v2/connector-hudi/src/main/java/org/apache/seatunnel/connectors/seatunnel/hudi/source/HudiSource.java
Patch:
@@ -29,6 +29,7 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
+import org.apache.seatunnel.api.source.SupportParallelism;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
@@ -46,7 +47,7 @@
 import java.io.IOException;
 
 @AutoService(SeaTunnelSource.class)
-public class HudiSource implements SeaTunnelSource<SeaTunnelRow, HudiSourceSplit, HudiSourceState> {
+public class HudiSource implements SeaTunnelSource<SeaTunnelRow, HudiSourceSplit, HudiSourceState>, SupportParallelism {
 
     private SeaTunnelRowType typeInfo;
 

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSource.java
Patch:
@@ -41,6 +41,7 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
+import org.apache.seatunnel.api.source.SupportParallelism;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.config.CheckConfigUtil;
@@ -70,7 +71,8 @@
 import java.util.Properties;
 
 @AutoService(SeaTunnelSource.class)
-public class KafkaSource implements SeaTunnelSource<SeaTunnelRow, KafkaSourceSplit, KafkaSourceState> {
+public class KafkaSource implements SeaTunnelSource<SeaTunnelRow, KafkaSourceSplit, KafkaSourceState>,
+    SupportParallelism {
 
     private static final String DEFAULT_CONSUMER_GROUP = "SeaTunnel-Consumer-Group";
 

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/source/KuduSource.java
Patch:
@@ -24,6 +24,7 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
+import org.apache.seatunnel.api.source.SupportParallelism;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
@@ -55,7 +56,7 @@
 
 @Slf4j
 @AutoService(SeaTunnelSource.class)
-public class KuduSource implements SeaTunnelSource<SeaTunnelRow, KuduSourceSplit, KuduSourceState> {
+public class KuduSource implements SeaTunnelSource<SeaTunnelRow, KuduSourceSplit, KuduSourceState>, SupportParallelism {
     private SeaTunnelRowType rowTypeInfo;
     private KuduInputFormat kuduInputFormat;
     private PartitionParameter partitionParameter;

File: seatunnel-connectors-v2/connector-maxcompute/src/main/java/org/apache/seatunnel/connectors/seatunnel/maxcompute/source/MaxcomputeSource.java
Patch:
@@ -21,6 +21,7 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
+import org.apache.seatunnel.api.source.SupportParallelism;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.maxcompute.util.MaxcomputeTypeMapper;
@@ -32,7 +33,8 @@
 
 @Slf4j
 @AutoService(SeaTunnelSource.class)
-public class MaxcomputeSource implements SeaTunnelSource<SeaTunnelRow, MaxcomputeSourceSplit, MaxcomputeSourceState> {
+public class MaxcomputeSource implements SeaTunnelSource<SeaTunnelRow, MaxcomputeSourceSplit, MaxcomputeSourceState>,
+    SupportParallelism {
     private SeaTunnelRowType typeInfo;
     private Config pluginConfig;
 

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/source/MongodbSourceReader.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.api.source.Boundedness;
 import org.apache.seatunnel.api.source.Collector;
+import org.apache.seatunnel.api.source.SupportColumnProjection;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.common.source.AbstractSingleSplitReader;
@@ -40,7 +41,7 @@
 import java.util.Optional;
 
 @Slf4j
-public class MongodbSourceReader extends AbstractSingleSplitReader<SeaTunnelRow> {
+public class MongodbSourceReader extends AbstractSingleSplitReader<SeaTunnelRow> implements SupportColumnProjection {
 
     private final SingleSplitReaderContext context;
 

File: seatunnel-connectors-v2/connector-neo4j/src/main/java/org/apache/seatunnel/connectors/seatunnel/neo4j/source/Neo4jSource.java
Patch:
@@ -32,6 +32,7 @@
 import org.apache.seatunnel.api.common.SeaTunnelAPIErrorCode;
 import org.apache.seatunnel.api.source.Boundedness;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.source.SupportColumnProjection;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
@@ -55,7 +56,7 @@
 import java.net.URI;
 
 @AutoService(SeaTunnelSource.class)
-public class Neo4jSource extends AbstractSingleSplitSource<SeaTunnelRow> {
+public class Neo4jSource extends AbstractSingleSplitSource<SeaTunnelRow> implements SupportColumnProjection {
 
     private final Neo4jSourceQueryInfo neo4jSourceQueryInfo = new Neo4jSourceQueryInfo();
     private SeaTunnelRowType rowType;

File: seatunnel-connectors-v2/connector-openmldb/src/main/java/org/apache/seatunnel/connectors/seatunnel/openmldb/source/OpenMldbSource.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.seatunnel.api.common.SeaTunnelAPIErrorCode;
 import org.apache.seatunnel.api.source.Boundedness;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
+import org.apache.seatunnel.api.source.SupportColumnProjection;
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.LocalTimeType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
@@ -53,7 +54,7 @@
 import java.util.List;
 
 @AutoService(SeaTunnelSource.class)
-public class OpenMldbSource extends AbstractSingleSplitSource<SeaTunnelRow> {
+public class OpenMldbSource extends AbstractSingleSplitSource<SeaTunnelRow> implements SupportColumnProjection {
     private OpenMldbParameters openMldbParameters;
     private JobContext jobContext;
     private SeaTunnelRowType seaTunnelRowType;

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/PulsarSource.java
Patch:
@@ -44,6 +44,7 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
+import org.apache.seatunnel.api.source.SupportParallelism;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.config.CheckConfigUtil;
@@ -78,7 +79,8 @@
 import java.util.regex.Pattern;
 
 @AutoService(SeaTunnelSource.class)
-public class PulsarSource<T> implements SeaTunnelSource<T, PulsarPartitionSplit, PulsarSplitEnumeratorState> {
+public class PulsarSource<T> implements SeaTunnelSource<T, PulsarPartitionSplit, PulsarSplitEnumeratorState>,
+    SupportParallelism {
     private DeserializationSchema<T> deserialization;
 
     private PulsarAdminConfig adminConfig;

File: seatunnel-connectors-v2/connector-rabbitmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rabbitmq/source/RabbitmqSource.java
Patch:
@@ -33,6 +33,7 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.source.SourceSplitEnumerator;
+import org.apache.seatunnel.api.source.SupportParallelism;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
@@ -52,7 +53,8 @@
 import com.google.auto.service.AutoService;
 
 @AutoService(SeaTunnelSource.class)
-public class RabbitmqSource implements SeaTunnelSource<SeaTunnelRow, RabbitmqSplit, RabbitmqSplitEnumeratorState> {
+public class RabbitmqSource implements SeaTunnelSource<SeaTunnelRow, RabbitmqSplit, RabbitmqSplitEnumeratorState>,
+    SupportParallelism {
 
     private DeserializationSchema<SeaTunnelRow> deserializationSchema;
     private JobContext jobContext;

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SinkCommonOptions.java
Patch:
@@ -34,7 +34,7 @@ public class SinkCommonOptions {
     public static final Option<Integer> PARALLELISM =
         Options.key("parallelism")
             .intType()
-            .noDefaultValue()
+            .defaultValue(1)
             .withDescription("When parallelism is not specified, the parallelism in env is used by default. " +
                 "When parallelism is specified, it will override the parallelism in env.");
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SourceCommonOptions.java
Patch:
@@ -39,7 +39,7 @@ public class SourceCommonOptions {
     public static final Option<Integer> PARALLELISM =
         Options.key("parallelism")
             .intType()
-            .noDefaultValue()
+            .defaultValue(1)
             .withDescription("When parallelism is not specified, the parallelism in env is used by default. " +
                 "When parallelism is specified, it will override the parallelism in env.");
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base-hadoop/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/hdfs/sink/BaseHdfsFileSink.java
Patch:
@@ -24,9 +24,9 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
+import org.apache.seatunnel.connectors.seatunnel.file.config.BaseSinkConfig;
 import org.apache.seatunnel.connectors.seatunnel.file.config.HadoopConf;
 import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
-import org.apache.seatunnel.connectors.seatunnel.file.hdfs.source.config.HdfsSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.BaseFileSink;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
@@ -43,8 +43,8 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
         }
         super.prepare(pluginConfig);
         hadoopConf = new HadoopConf(pluginConfig.getString(FS_DEFAULT_NAME_KEY));
-        if (pluginConfig.hasPath(HdfsSourceConfig.HDFS_SITE_PATH.key())) {
-            hadoopConf.setHdfsSitePath(pluginConfig.getString(HdfsSourceConfig.HDFS_SITE_PATH.key()));
+        if (pluginConfig.hasPath(BaseSinkConfig.HDFS_SITE_PATH.key())) {
+            hadoopConf.setHdfsSitePath(pluginConfig.getString(BaseSinkConfig.HDFS_SITE_PATH.key()));
         }
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseSourceConfig.java
Patch:
@@ -24,8 +24,8 @@
 import org.apache.seatunnel.common.utils.TimeUtils;
 
 public class BaseSourceConfig {
-    public static final Option<String> FILE_TYPE = Options.key("type")
-            .stringType()
+    public static final Option<FileFormat> FILE_TYPE = Options.key("type")
+            .objectType(FileFormat.class)
             .noDefaultValue()
             .withDescription("File type");
     public static final Option<String> FILE_PATH = Options.key("path")
@@ -35,7 +35,7 @@ public class BaseSourceConfig {
     public static final Option<String> DELIMITER = Options.key("delimiter")
             .stringType()
             .defaultValue(String.valueOf('\001'))
-            .withDescription("The separator between columns in a row of data. Only needed by `text` and `csv` file format");
+            .withDescription("The separator between columns in a row of data. Only needed by `text` file format");
     public static final Option<DateUtils.Formatter> DATE_FORMAT = Options.key("date_format")
             .enumType(DateUtils.Formatter.class)
             .defaultValue(DateUtils.Formatter.YYYY_MM_DD)

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/config/S3Conf.java
Patch:
@@ -58,6 +58,9 @@ public static HadoopConf buildWithConfig(Config config) {
         if (CheckConfigUtil.isValidParam(config, S3Config.S3_PROPERTIES.key())) {
             config.getObject(S3Config.S3_PROPERTIES.key()).forEach((key, value) -> s3Options.put(key, String.valueOf(value.unwrapped())));
         }
+
+        s3Options.put(S3Config.S3A_AWS_CREDENTIALS_PROVIDER.key(), config.getString(S3Config.S3A_AWS_CREDENTIALS_PROVIDER.key()));
+        s3Options.put(S3Config.FS_S3A_ENDPOINT.key(), config.getString(S3Config.FS_S3A_ENDPOINT.key()));
         hadoopConf.setExtraOptions(s3Options);
         return hadoopConf;
     }

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSource.java
Patch:
@@ -113,6 +113,8 @@ public void prepare(Config config) throws PrepareFailException {
 
         if (config.hasPath(COMMIT_ON_CHECKPOINT.key())) {
             this.metadata.setCommitOnCheckpoint(config.getBoolean(COMMIT_ON_CHECKPOINT.key()));
+        } else {
+            this.metadata.setCommitOnCheckpoint(COMMIT_ON_CHECKPOINT.defaultValue());
         }
 
         if (config.hasPath(START_MODE.key())) {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/JobConfigParser.java
Patch:
@@ -34,6 +34,7 @@
 import org.apache.seatunnel.core.starter.config.ConfigBuilder;
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.exception.JobDefineCheckException;
+import org.apache.seatunnel.engine.common.loader.SeatunnelChildFirstClassLoader;
 import org.apache.seatunnel.engine.common.utils.IdGenerator;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
 import org.apache.seatunnel.engine.core.dag.actions.SinkAction;
@@ -108,6 +109,7 @@ public JobConfigParser(@NonNull String jobDefineFilePath,
     }
 
     public ImmutablePair<List<Action>, Set<URL>> parse() {
+        Thread.currentThread().setContextClassLoader(new SeatunnelChildFirstClassLoader(new ArrayList<>()));
         List<? extends Config> sinkConfigs = seaTunnelJobConfig.getConfigList("sink");
         List<? extends Config> transformConfigs =
             TypesafeConfigUtils.getConfigList(seaTunnelJobConfig, "transform", Collections.emptyList());

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/CoordinatorService.java
Patch:
@@ -263,7 +263,6 @@ private void restoreJobFromMasterActiveSwitch(@NonNull Long jobId, @NonNull JobI
                     onJobDone(jobMaster, jobId);
                 }
             });
-            return;
         }
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCloseReason.java
Patch:
@@ -17,17 +17,18 @@
 
 package org.apache.seatunnel.engine.server.checkpoint;
 
-public enum CheckpointFailureReason {
+public enum CheckpointCloseReason {
 
     PIPELINE_END("Pipeline turn to end state."),
     CHECKPOINT_EXPIRED("Checkpoint expired before completing."),
     CHECKPOINT_COORDINATOR_COMPLETED("CheckpointCoordinator completed."),
     CHECKPOINT_COORDINATOR_SHUTDOWN("CheckpointCoordinator shutdown."),
+    CHECKPOINT_COORDINATOR_RESET("CheckpointCoordinator reset."),
     CHECKPOINT_INSIDE_ERROR("CheckpointCoordinator inside have error.");
 
     private final String message;
 
-    CheckpointFailureReason(String message) {
+    CheckpointCloseReason(String message) {
         this.message = message;
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalVertex.java
Patch:
@@ -415,6 +415,7 @@ private void noticeTaskExecutionServiceCancel() {
                 }
             }
         }
+        this.taskFuture.complete(new TaskExecutionState(taskGroupLocation, ExecutionState.CANCELED, null));
     }
 
     private void updateStateTimestamps(@NonNull ExecutionState targetState) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -338,6 +338,7 @@ public void restorePipeline() {
                     forcePipelineFinish();
                     return;
                 }
+                jobMaster.getCheckpointManager().reportedPipelineRunning(pipelineId, false);
                 reSchedulerPipelineFuture = jobMaster.reSchedulerPipeline(this);
                 if (reSchedulerPipelineFuture != null) {
                     reSchedulerPipelineFuture.join();
@@ -371,7 +372,7 @@ public void restorePipelineState() {
         } else if (PipelineStatus.CANCELING.equals(getPipelineState())) {
             cancelPipelineTasks();
         } else if (PipelineStatus.RUNNING.equals(getPipelineState())) {
-            jobMaster.getCheckpointManager().reportedPipelineRunning(this.getPipelineLocation().getPipelineId());
+            jobMaster.getCheckpointManager().reportedPipelineRunning(this.getPipelineLocation().getPipelineId(), true);
         }
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/master/JobMasterTest.java
Patch:
@@ -28,8 +28,8 @@
 import org.apache.seatunnel.engine.core.job.PipelineStatus;
 import org.apache.seatunnel.engine.server.AbstractSeaTunnelServerTest;
 import org.apache.seatunnel.engine.server.TestUtils;
+import org.apache.seatunnel.engine.server.checkpoint.CheckpointCloseReason;
 import org.apache.seatunnel.engine.server.checkpoint.CheckpointException;
-import org.apache.seatunnel.engine.server.checkpoint.CheckpointFailureReason;
 import org.apache.seatunnel.engine.server.dag.physical.PipelineLocation;
 import org.apache.seatunnel.engine.server.execution.TaskGroupLocation;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.SlotProfile;
@@ -123,7 +123,7 @@ public void testHandleCheckpointTimeout() throws Exception {
             .untilAsserted(() -> Assertions.assertEquals(JobStatus.RUNNING, jobMaster.getJobStatus()));
 
         // call checkpoint timeout
-        jobMaster.handleCheckpointError(1, new CheckpointException(CheckpointFailureReason.CHECKPOINT_EXPIRED));
+        jobMaster.handleCheckpointError(1, new CheckpointException(CheckpointCloseReason.CHECKPOINT_EXPIRED));
 
         // Because handleCheckpointTimeout is an async method, so we need sleep 5s to waiting job status become running again
         Thread.sleep(5000);

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseSourceConfig.java
Patch:
@@ -28,8 +28,8 @@ public class BaseSourceConfig {
             .stringType()
             .noDefaultValue()
             .withDescription("File type");
-    public static final Option<FileFormat> FILE_PATH = Options.key("path")
-            .enumType(FileFormat.class)
+    public static final Option<String> FILE_PATH = Options.key("path")
+            .stringType()
             .noDefaultValue()
             .withDescription("The file path of source files");
     public static final Option<String> DELIMITER = Options.key("delimiter")

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/file/ClickhouseTable.java
Patch:
@@ -19,10 +19,11 @@
 
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.sink.DistributedEngine;
 
+import java.io.Serializable;
 import java.util.List;
 import java.util.Map;
 
-public class ClickhouseTable {
+public class ClickhouseTable implements Serializable {
 
     private String database;
     private String tableName;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/utils/SourceRecordUtils.java
Patch:
@@ -97,7 +97,8 @@ public static boolean isSchemaChangeEvent(SourceRecord sourceRecord) {
     public static boolean isDataChangeRecord(SourceRecord record) {
         Schema valueSchema = record.valueSchema();
         Struct value = (Struct) record.value();
-        return valueSchema.field(Envelope.FieldName.OPERATION) != null
+        return valueSchema != null
+                && valueSchema.field(Envelope.FieldName.OPERATION) != null
                 && value.getString(Envelope.FieldName.OPERATION) != null;
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkWriter.java
Patch:
@@ -88,7 +88,7 @@ public Optional<XidInfo> prepareCommit()
                 connectionProvider.getConnection().commit();
             }
         } catch (SQLException e) {
-            new JdbcConnectorException(JdbcConnectorErrorCode.TRANSACTION_OPERATION_FAILED, "commit failed," + e.getMessage(), e);
+            throw new JdbcConnectorException(JdbcConnectorErrorCode.TRANSACTION_OPERATION_FAILED, "commit failed," + e.getMessage(), e);
         }
         return Optional.empty();
     }
@@ -108,7 +108,7 @@ public void close()
                 connectionProvider.getConnection().commit();
             }
         } catch (SQLException e) {
-            new JdbcConnectorException(CommonErrorCode.WRITER_OPERATION_FAILED, "unable to close JDBC sink write", e);
+            throw new JdbcConnectorException(CommonErrorCode.WRITER_OPERATION_FAILED, "unable to close JDBC sink write", e);
         }
         outputFormat.close();
     }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/JdbcConnectionPoolFactory.java
Patch:
@@ -41,7 +41,7 @@ public HikariDataSource createPooledDataSource(JdbcSourceConfig sourceConfig) {
         config.setPassword(sourceConfig.getPassword());
         config.setMinimumIdle(MINIMUM_POOL_SIZE);
         config.setMaximumPoolSize(sourceConfig.getConnectionPoolSize());
-        config.setConnectionTimeout(sourceConfig.getConnectTimeout().toMillis());
+        config.setConnectionTimeout(sourceConfig.getConnectTimeoutMillis());
         config.addDataSourceProperty(SERVER_TIMEZONE_KEY, sourceConfig.getServerTimeZone());
         config.setDriverClassName(sourceConfig.getDriverClassName());
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/MySqlSourceConfig.java
Patch:
@@ -24,7 +24,6 @@
 import io.debezium.connector.mysql.MySqlConnectorConfig;
 import io.debezium.relational.RelationalTableFilters;
 
-import java.time.Duration;
 import java.util.List;
 import java.util.Properties;
 
@@ -52,7 +51,7 @@ public MySqlSourceConfig(
             String password,
             int fetchSize,
             String serverTimeZone,
-            Duration connectTimeout,
+            long connectTimeoutMillis,
             int connectMaxRetries,
             int connectionPoolSize) {
         super(
@@ -71,7 +70,7 @@ public MySqlSourceConfig(
                 password,
                 fetchSize,
                 serverTimeZone,
-                connectTimeout,
+                connectTimeoutMillis,
                 connectMaxRetries,
                 connectionPoolSize);
     }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/MySqlSourceConfigFactory.java
Patch:
@@ -71,7 +71,7 @@ public MySqlSourceConfig create(int subtaskId) {
         props.setProperty("database.history.skip.unparseable.ddl", String.valueOf(true));
         props.setProperty("database.history.refer.ddl", String.valueOf(true));
 
-        props.setProperty("connect.timeout.ms", String.valueOf(connectTimeout.toMillis()));
+        props.setProperty("connect.timeout.ms", String.valueOf(connectTimeoutMillis));
         // the underlying debezium reader should always capture the schema changes and forward them.
         // Note: the includeSchemaChanges parameter is used to control emitting the schema record,
         // only DataStream API program need to emit the schema record, the Table API need not
@@ -125,7 +125,7 @@ public MySqlSourceConfig create(int subtaskId) {
                 password,
                 fetchSize,
                 serverTimeZone,
-                connectTimeout,
+                connectTimeoutMillis,
                 connectMaxRetries,
                 connectionPoolSize);
     }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlIncrementalSource.java
Patch:
@@ -42,9 +42,11 @@
 
 @AutoService(SeaTunnelSource.class)
 public class MySqlIncrementalSource<T> extends IncrementalSource<T, JdbcSourceConfig> {
+    static final String IDENTIFIER = "MySQL-CDC";
+
     @Override
     public String getPluginName() {
-        return "MySQL-CDC";
+        return IDENTIFIER;
     }
 
     @Override

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/config/SqlServerSourceConfig.java
Patch:
@@ -24,7 +24,6 @@
 import io.debezium.connector.sqlserver.SqlServerConnectorConfig;
 import io.debezium.relational.RelationalTableFilters;
 
-import java.time.Duration;
 import java.util.List;
 import java.util.Properties;
 
@@ -52,7 +51,7 @@ public SqlServerSourceConfig(
             String password,
             int fetchSize,
             String serverTimeZone,
-            Duration connectTimeout,
+            long connectTimeoutMillis,
             int connectMaxRetries,
             int connectionPoolSize) {
         super(
@@ -71,7 +70,7 @@ public SqlServerSourceConfig(
                 password,
                 fetchSize,
                 serverTimeZone,
-                connectTimeout,
+                connectTimeoutMillis,
                 connectMaxRetries,
                 connectionPoolSize);
     }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-sqlserver/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/sqlserver/source/config/SqlServerSourceConfigFactory.java
Patch:
@@ -91,7 +91,7 @@ public SqlServerSourceConfig create(int subtask) {
                 password,
                 fetchSize,
                 serverTimeZone,
-                connectTimeout,
+                connectTimeoutMillis,
                 connectMaxRetries,
                 connectionPoolSize);
     }

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-doris-e2e/src/test/java/org/apache/seatunnel/e2e/connector/doris/DorisIT.java
Patch:
@@ -168,7 +168,7 @@ public void startUp() throws Exception {
         // wait for doris fully start
         given().ignoreExceptions()
                 .await()
-                .atMost(600, TimeUnit.SECONDS)
+                .atMost(1000, TimeUnit.SECONDS)
                 .untilAsserted(this::initializeJdbcConnection);
         initializeJdbcTable();
         batchInsertData();

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManager.java
Patch:
@@ -164,7 +164,7 @@ private CheckpointCoordinator getCheckpointCoordinator(int pipelineId) {
      */
     public void reportedTask(TaskReportStatusOperation reportStatusOperation) {
         // task address may change during restore.
-        log.debug("reported task({}) status{}", reportStatusOperation.getLocation().getTaskID(),
+        log.debug("reported task({}) status {}", reportStatusOperation.getLocation().getTaskID(),
             reportStatusOperation.getStatus());
         getCheckpointCoordinator(reportStatusOperation.getLocation()).reportedTask(reportStatusOperation);
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSplitEnumeratorTask.java
Patch:
@@ -58,6 +58,7 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
+import java.util.Objects;
 import java.util.Optional;
 import java.util.Set;
 import java.util.concurrent.ConcurrentHashMap;
@@ -149,7 +150,7 @@ public void triggerBarrier(Barrier barrier) throws Exception {
     public void restoreState(List<ActionSubtaskState> actionStateList) throws Exception {
         Optional<Serializable> state = actionStateList.stream()
             .map(ActionSubtaskState::getState)
-            .flatMap(Collection::stream)
+            .flatMap(Collection::stream).filter(Objects::nonNull)
             .map(bytes -> sneaky(() -> enumeratorStateSerializer.deserialize(bytes)))
             .findFirst();
         if (state.isPresent()) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/group/TaskGroupWithIntermediateQueue.java
Patch:
@@ -31,7 +31,7 @@
 
 public class TaskGroupWithIntermediateQueue extends TaskGroupDefaultImpl {
 
-    public static final int QUEUE_SIZE = 1000;
+    public static final int QUEUE_SIZE = 100000;
 
     public TaskGroupWithIntermediateQueue(TaskGroupLocation taskGroupLocation, String taskGroupName, Collection<Task> tasks) {
         super(taskGroupLocation, taskGroupName, tasks);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/config/JdbcConfig.java
Patch:
@@ -105,7 +105,7 @@ public static JdbcConnectionOptions buildJdbcConnectionOptions(Config config) {
             jdbcOptions.batchIntervalMs = config.getInt(JdbcConfig.BATCH_INTERVAL_MS.key());
         }
 
-        if (config.hasPath(JdbcConfig.IS_EXACTLY_ONCE.key())) {
+        if (config.hasPath(JdbcConfig.IS_EXACTLY_ONCE.key()) && config.getBoolean(JdbcConfig.IS_EXACTLY_ONCE.key())) {
             jdbcOptions.xaDataSourceClassName = config.getString(JdbcConfig.XA_DATA_SOURCE_CLASS_NAME.key());
             if (config.hasPath(JdbcConfig.MAX_COMMIT_ATTEMPTS.key())) {
                 jdbcOptions.maxCommitAttempts = config.getInt(JdbcConfig.MAX_COMMIT_ATTEMPTS.key());

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkAggregatedCommitter.java
Patch:
@@ -29,6 +29,7 @@
 import org.apache.seatunnel.connectors.seatunnel.jdbc.state.XidInfo;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.List;
 import java.util.stream.Collectors;
 
@@ -62,7 +63,7 @@ private void tryOpen() throws IOException {
     public List<JdbcAggregatedCommitInfo> commit(List<JdbcAggregatedCommitInfo> aggregatedCommitInfos) throws IOException {
         tryOpen();
         return aggregatedCommitInfos.stream().map(aggregatedCommitInfo -> {
-            GroupXaOperationResult<XidInfo> result = xaGroupOps.commit(aggregatedCommitInfo.getXidInfoList(), false, jdbcSinkOptions.getJdbcConnectionOptions().getMaxCommitAttempts());
+            GroupXaOperationResult<XidInfo> result = xaGroupOps.commit(new ArrayList<>(aggregatedCommitInfo.getXidInfoList()), false, jdbcSinkOptions.getJdbcConnectionOptions().getMaxCommitAttempts());
             return new JdbcAggregatedCommitInfo(result.getForRetry());
         }).filter(ainfo -> !ainfo.getXidInfoList().isEmpty()).collect(Collectors.toList());
     }

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-neo4j-e2e/src/test/java/org/apache/seatunnel/e2e/connector/neo4j/Neo4jIT.java
Patch:
@@ -64,7 +64,7 @@ public class Neo4jIT extends TestSuiteBase implements TestResource {
     private static final int HTTP_PORT = 7474;
     private static final int BOLT_PORT = 7687;
     private static final String CONTAINER_NEO4J_USERNAME = "neo4j";
-    private static final String CONTAINER_NEO4J_PASSWORD = "1234";
+    private static final String CONTAINER_NEO4J_PASSWORD = "Test@12343";
     private static final URI CONTAINER_URI = URI.create("neo4j://localhost:" + BOLT_PORT);
 
     private GenericContainer<?> container;

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/sink/ElasticsearchSinkWriter.java
Patch:
@@ -103,7 +103,7 @@ public Optional<ElasticsearchCommitInfo> prepareCommit() {
     public void abortPrepare() {
     }
 
-    public void bulkEsWithRetry(EsRestClient esRestClient, List<String> requestEsList) {
+    public synchronized void bulkEsWithRetry(EsRestClient esRestClient, List<String> requestEsList) {
         try {
             RetryUtils.retryWithException(() -> {
                 if (requestEsList.size() > 0) {

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/commit/FileSinkAggregatedCommitter.java
Patch:
@@ -53,7 +53,7 @@ public List<FileAggregatedCommitInfo> commit(List<FileAggregatedCommitInfo> aggr
                     FileSystemUtils.deleteFile(entry.getKey());
                 }
             } catch (Exception e) {
-                log.error("commit aggregatedCommitInfo error ", e);
+                log.error("commit aggregatedCommitInfo error, aggregatedCommitInfo = {} ", aggregatedCommitInfo, e);
                 errorAggregatedCommitInfoList.add(aggregatedCommitInfo);
             }
         });

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaNoTransactionSender.java
Patch:
@@ -76,8 +76,6 @@ public List<KafkaSinkState> snapshotState(long checkpointId) {
     @Override
     public void close() {
         kafkaProducer.flush();
-        try (KafkaProducer<?, ?> closedKafkaProducer = kafkaProducer) {
-            // close the producer
-        }
+        kafkaProducer.close();
     }
 }

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaSinkWriter.java
Patch:
@@ -127,11 +127,11 @@ public void abortPrepare() {
 
     @Override
     public void close() {
-        try (KafkaProduceSender<?, ?> kafkaProduceSender = kafkaProducerSender) {
-            // no-opt
+        try {
+            kafkaProducerSender.close();
         } catch (Exception e) {
             throw new KafkaConnectorException(CommonErrorCode.WRITER_OPERATION_FAILED,
-                    "Close kafka sink writer error", e);
+                "Close kafka sink writer error", e);
         }
     }
 

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaConsumerThread.java
Patch:
@@ -68,7 +68,7 @@ private KafkaConsumer<byte[], byte[]> initConsumer(String bootstrapServer, Strin
         properties.forEach((key, value) -> props.setProperty(String.valueOf(key), String.valueOf(value)));
         props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, consumerGroup);
         props.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);
-        props.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, CLIENT_ID_PREFIX + "-enumerator-consumer-" + this.hashCode());
+        props.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, CLIENT_ID_PREFIX + "-consumer-" + this.hashCode());
 
         props.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,
             ByteArrayDeserializer.class.getName());

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/config/JdbcConfig.java
Patch:
@@ -67,6 +67,9 @@ public class JdbcConfig implements Serializable {
 
     public static final Option<List<String>> PRIMARY_KEYS = Options.key("primary_keys").listType().noDefaultValue().withDescription("primary keys");
 
+    public static final Option<Boolean> SUPPORT_UPSERT_BY_QUERY_PRIMARY_KEY_EXIST = Options.key("support_upsert_by_query_primary_key_exist")
+        .booleanType().defaultValue(false).withDescription("support upsert by query primary_key exist");
+
     //source config
     public static final Option<String> PARTITION_COLUMN = Options.key("partition_column").stringType().noDefaultValue().withDescription("partition column");
     public static final Option<String> PARTITION_UPPER_BOUND = Options.key("partition_upper_bound").stringType().noDefaultValue().withDescription("partition upper bound");

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -378,7 +378,7 @@ private void forcePipelineFinish() {
     public void restorePipelineState() {
         // only need restore from RUNNING or CANCELING state
         if (getPipelineState().ordinal() < PipelineStatus.RUNNING.ordinal()) {
-            restorePipeline();
+            cancelPipelineTasks();
         } else if (PipelineStatus.CANCELING.equals(getPipelineState())) {
             cancelPipelineTasks();
         } else if (PipelineStatus.RUNNING.equals(getPipelineState())) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -176,13 +176,13 @@ public void init(long initializationTimestamp) throws Exception {
             runningJobStateTimestampsIMap);
         this.physicalPlan = planTuple.f0();
         this.physicalPlan.setJobMaster(this);
-        this.initStateFuture();
         this.checkpointManager = new CheckpointManager(
             jobImmutableInformation.getJobId(),
             nodeEngine,
             this,
             planTuple.f1(),
             checkpointConfig);
+        this.initStateFuture();
     }
 
     // TODO replace it after ReadableConfig Support parse yaml format, then use only one config to read engine and env config.

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/serializable/TaskDataSerializerHook.java
Patch:
@@ -86,6 +86,8 @@ public class TaskDataSerializerHook implements DataSerializerHook {
 
     public static final int SOURCE_READER_EVENT_OPERATOR = 20;
 
+    public static final int CHECK_TASKGROUP_IS_EXECUTING = 21;
+
     public static final int FACTORY_ID = FactoryIdHelper.getFactoryId(
         SeaTunnelFactoryIdConstant.SEATUNNEL_TASK_DATA_SERIALIZER_FACTORY,
         SeaTunnelFactoryIdConstant.SEATUNNEL_TASK_DATA_SERIALIZER_FACTORY_ID

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/state/FileSinkState.java
Patch:
@@ -28,6 +28,7 @@
 @AllArgsConstructor
 public class FileSinkState implements Serializable {
     private final String transactionId;
+    private final String uuidPrefix;
     private final Long checkpointId;
     private final Map<String, String> needMoveFiles;
     private final Map<String, List<String>> partitionDirAndValuesMap;

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/ParquetWriteStrategy.java
Patch:
@@ -84,8 +84,8 @@ public ParquetWriteStrategy(TextFileSinkConfig textFileSinkConfig) {
     }
 
     @Override
-    public void init(HadoopConf conf, String jobId, int subTaskIndex) {
-        super.init(conf, jobId, subTaskIndex);
+    public void init(HadoopConf conf, String jobId, String uuidPrefix, int subTaskIndex) {
+        super.init(conf, jobId, uuidPrefix, subTaskIndex);
         schemaConverter = new AvroSchemaConverter(getConfiguration(hadoopConf));
     }
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/WriteStrategy.java
Patch:
@@ -32,9 +32,10 @@
 public interface WriteStrategy extends Transaction, Serializable {
     /**
      * init hadoop conf
+     *
      * @param conf hadoop conf
      */
-    void init(HadoopConf conf, String jobId, int subTaskIndex);
+    void init(HadoopConf conf, String jobId, String uuidPrefix, int subTaskIndex);
 
     /**
      * use hadoop conf generate hadoop configuration

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -108,8 +108,6 @@ public class CheckpointCoordinator {
 
     private volatile CompletedCheckpoint latestCompletedCheckpoint = null;
 
-    private volatile CheckpointType latestAcceptedCheckpoint = null;
-
     private final CheckpointConfig coordinatorConfig;
 
     private int tolerableFailureCheckpoints;

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceSplitEnumerator.java
Patch:
@@ -207,7 +207,8 @@ public void notifyCheckpointComplete(long checkpointId) throws Exception {
     }
 
     private AdminClient initAdminClient(Properties properties) {
-        Properties props = new Properties(properties);
+        Properties props = new Properties();
+        props.putAll(properties);
         props.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, this.metadata.getBootstrapServers());
         props.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, CLIENT_ID_PREFIX + "-enumerator-admin-client-" + this.hashCode());
         return AdminClient.create(props);

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/config/S3Conf.java
Patch:
@@ -72,7 +72,7 @@ private String switchHdfsImpl() {
     }
 
     private static void putS3SK(Map<String, String> s3Options, Config config) {
-        if (!CheckConfigUtil.isValidParam(config, S3Config.S3_ACCESS_KEY.key()) && CheckConfigUtil.isValidParam(config, S3Config.S3_SECRET_KEY.key())) {
+        if (!CheckConfigUtil.isValidParam(config, S3Config.S3_ACCESS_KEY.key()) && !CheckConfigUtil.isValidParam(config, S3Config.S3_SECRET_KEY.key())) {
             return;
         }
         String accessKey = config.getString(S3Config.S3_ACCESS_KEY.key());

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-api/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/constants/StorageConstants.java
Patch:
@@ -25,5 +25,5 @@ public class StorageConstants {
     /**
      * The name of the configuration property that specifies the name of the file system.
      */
-    public static final String STORAGE_NAME_SPACE = "storageNameSpace";
+    public static final String STORAGE_NAME_SPACE = "namespace";
 }

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-hdfs/src/test/java/org/apache/seatunnel/engine/checkpoint/storage/hdfs/LocalFileCheckPointTest.java
Patch:
@@ -34,7 +34,7 @@ public class LocalFileCheckPointTest extends AbstractFileCheckPointTest {
     @BeforeAll
     public static void setup() throws CheckpointStorageException {
         HashMap config = new HashMap();
-        config.put("storageNameSpace", "/tmp/");
+        config.put("namespace", "/tmp/");
         STORAGE = new HdfsStorage(config);
         initStorageData();
     }

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/file/ClickhouseFileSink.java
Patch:
@@ -105,6 +105,7 @@ public void prepare(Config config) throws PrepareFailException {
 
         ClickhouseProxy proxy = new ClickhouseProxy(nodes.get(0));
         Map<String, String> tableSchema = proxy.getClickhouseTableSchema(config.getString(TABLE.key()));
+        ClickhouseTable table = proxy.getClickhouseTable(config.getString(DATABASE.key()), config.getString(TABLE.key()));
         String shardKey = null;
         String shardKeyType = null;
         if (config.hasPath(SHARDING_KEY.key())) {
@@ -116,6 +117,7 @@ public void prepare(Config config) throws PrepareFailException {
             shardKeyType,
             config.getString(DATABASE.key()),
             config.getString(TABLE.key()),
+            table.getEngine(),
             false, // we don't need to set splitMode in clickhouse file mode.
             new Shard(1, 1, nodes.get(0)), config.getString(USERNAME.key()), config.getString(PASSWORD.key()));
         List<String> fields;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointFailureReason.java
Patch:
@@ -22,7 +22,8 @@ public enum CheckpointFailureReason {
     PIPELINE_END("Pipeline turn to end state."),
     CHECKPOINT_EXPIRED("Checkpoint expired before completing."),
     CHECKPOINT_COORDINATOR_COMPLETED("CheckpointCoordinator completed."),
-    CHECKPOINT_COORDINATOR_SHUTDOWN("CheckpointCoordinator shutdown.");
+    CHECKPOINT_COORDINATOR_SHUTDOWN("CheckpointCoordinator shutdown."),
+    CHECKPOINT_INSIDE_ERROR("CheckpointCoordinator inside have error.");
 
     private final String message;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManager.java
Patch:
@@ -140,8 +140,8 @@ public void reportedPipelineRunning(int pipelineId) {
         getCheckpointCoordinator(pipelineId).tryTriggerPendingCheckpoint();
     }
 
-    protected void handleCheckpointTimeout(int pipelineId) {
-        jobMaster.handleCheckpointTimeout(pipelineId);
+    protected void handleCheckpointError(int pipelineId, Throwable e) {
+        jobMaster.handleCheckpointError(pipelineId, e);
     }
 
     private CheckpointCoordinator getCheckpointCoordinator(TaskLocation taskLocation) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -237,11 +237,11 @@ public void run() {
         }
     }
 
-    public void handleCheckpointTimeout(long pipelineId) {
+    public void handleCheckpointError(long pipelineId, Throwable e) {
         this.physicalPlan.getPipelineList().forEach(pipeline -> {
             if (pipeline.getPipelineLocation().getPipelineId() == pipelineId) {
                 LOGGER.warning(
-                    String.format("%s checkpoint timeout, cancel the pipeline", pipeline.getPipelineFullName()));
+                    String.format("%s checkpoint have error, cancel the pipeline", pipeline.getPipelineFullName()), e);
                 pipeline.cancelPipeline();
             }
         });

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/master/JobMasterTest.java
Patch:
@@ -28,6 +28,8 @@
 import org.apache.seatunnel.engine.core.job.PipelineStatus;
 import org.apache.seatunnel.engine.server.AbstractSeaTunnelServerTest;
 import org.apache.seatunnel.engine.server.TestUtils;
+import org.apache.seatunnel.engine.server.checkpoint.CheckpointException;
+import org.apache.seatunnel.engine.server.checkpoint.CheckpointFailureReason;
 import org.apache.seatunnel.engine.server.dag.physical.PipelineLocation;
 import org.apache.seatunnel.engine.server.execution.TaskGroupLocation;
 import org.apache.seatunnel.engine.server.resourcemanager.resource.SlotProfile;
@@ -121,7 +123,7 @@ public void testHandleCheckpointTimeout() throws Exception {
             .untilAsserted(() -> Assertions.assertEquals(JobStatus.RUNNING, jobMaster.getJobStatus()));
 
         // call checkpoint timeout
-        jobMaster.handleCheckpointTimeout(1);
+        jobMaster.handleCheckpointError(1, new CheckpointException(CheckpointFailureReason.CHECKPOINT_EXPIRED));
 
         // Because handleCheckpointTimeout is an async method, so we need sleep 5s to waiting job status become running again
         Thread.sleep(5000);

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseTextFileConfig.java
Patch:
@@ -42,7 +42,7 @@ public class BaseTextFileConfig implements DelimiterConfig, CompressConfig, Seri
     protected String rowDelimiter = BaseSinkConfig.ROW_DELIMITER.defaultValue();
     protected int batchSize = BaseSinkConfig.BATCH_SIZE.defaultValue();
     protected String path;
-    protected String fileNameExpression;
+    protected String fileNameExpression = BaseSinkConfig.FILE_NAME_EXPRESSION.defaultValue();
     protected FileFormat fileFormat = FileFormat.TEXT;
     protected DateUtils.Formatter dateFormat = DateUtils.Formatter.YYYY_MM_DD;
     protected DateTimeUtils.Formatter datetimeFormat = DateTimeUtils.Formatter.YYYY_MM_DD_HH_MM_SS;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceEventOperation.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.task.operation.source;
 
 import org.apache.seatunnel.api.source.SourceEvent;
+import org.apache.seatunnel.common.utils.SerializationUtils;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.serializable.TaskDataSerializerHook;
 import org.apache.seatunnel.engine.server.task.operation.TaskOperation;
@@ -30,7 +31,7 @@
 public abstract class SourceEventOperation extends TaskOperation {
     protected TaskLocation currentTaskLocation;
 
-    protected SourceEvent sourceEvent;
+    protected byte[] sourceEvent;
 
     public SourceEventOperation() {
     }
@@ -40,7 +41,7 @@ public SourceEventOperation(TaskLocation targetTaskLocation,
                                 SourceEvent event) {
         super(targetTaskLocation);
         this.currentTaskLocation = currentTaskLocation;
-        this.sourceEvent = event;
+        this.sourceEvent = SerializationUtils.serialize(event);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/TaskExecutionService.java
Patch:
@@ -513,8 +513,7 @@ void taskDone() {
             logger.info("taskDone: " + taskGroup.getTaskGroupLocation());
             if (completionLatch.decrementAndGet() == 0) {
                 TaskGroupLocation taskGroupLocation = taskGroup.getTaskGroupLocation();
-                finishedExecutionContexts.put(taskGroupLocation, executionContexts.get(taskGroupLocation));
-                executionContexts.remove(taskGroupLocation);
+                finishedExecutionContexts.put(taskGroupLocation, executionContexts.remove(taskGroupLocation));
                 cancellationFutures.remove(taskGroupLocation);
                 Throwable ex = executionException.get();
                 if (ex == null) {

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/sink/S3FileSinkFactory.java
Patch:
@@ -38,8 +38,8 @@ public OptionRule optionRule() {
         return OptionRule.builder()
                 .required(S3Config.FILE_PATH)
                 .required(S3Config.S3_BUCKET)
-                .required(S3Config.S3_ACCESS_KEY)
-                .required(S3Config.S3_SECRET_KEY)
+                .optional(S3Config.S3_ACCESS_KEY)
+                .optional(S3Config.S3_SECRET_KEY)
                 .optional(BaseSinkConfig.FILE_NAME_EXPRESSION)
                 .optional(BaseSinkConfig.FILE_FORMAT)
                 .optional(BaseSinkConfig.FILENAME_TIME_FORMAT)

File: seatunnel-connectors-v2/connector-file/connector-file-oss-jindo/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/source/OssFileSourceFactory.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.oss.source;
 
-import org.apache.seatunnel.api.configuration.util.Condition;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
@@ -27,6 +26,8 @@
 
 import com.google.auto.service.AutoService;
 
+import java.util.Arrays;
+
 @AutoService(Factory.class)
 public class OssFileSourceFactory implements TableSourceFactory {
     @Override
@@ -48,8 +49,7 @@ public OptionRule optionRule() {
                 .optional(OssConfig.DATE_FORMAT)
                 .optional(OssConfig.DATETIME_FORMAT)
                 .optional(OssConfig.TIME_FORMAT)
-                .conditional(Condition.of(OssConfig.FILE_TYPE, "text"), SeaTunnelSchema.SCHEMA)
-                .conditional(Condition.of(OssConfig.FILE_TYPE, "json"), SeaTunnelSchema.SCHEMA)
+                .conditional(OssConfig.FILE_TYPE, Arrays.asList("text", "json"), SeaTunnelSchema.SCHEMA)
                 .build();
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -118,11 +118,11 @@ public SeaTunnelTask(long jobID, TaskLocation taskID, int indexID, Flow executio
     @Override
     public void init() throws Exception {
         super.init();
+        metricsContext = new MetricsContext();
         this.currState = SeaTunnelTaskState.INIT;
         flowFutures = new ArrayList<>();
         allCycles = new ArrayList<>();
         startFlowLifeCycle = convertFlowToActionLifeCycle(executionFlow);
-        metricsContext = new MetricsContext();
         for (FlowLifeCycle cycle : allCycles) {
             cycle.init();
         }
@@ -206,7 +206,8 @@ private FlowLifeCycle convertFlowToActionLifeCycle(@NonNull Flow flow) throws Ex
             } else if (f.getAction() instanceof SinkAction) {
                 lifeCycle = new SinkFlowLifeCycle<>((SinkAction) f.getAction(), taskLocation, indexID, this,
                     ((SinkConfig) f.getConfig()).getCommitterTask(),
-                    ((SinkConfig) f.getConfig()).isContainCommitter(), completableFuture);
+                    ((SinkConfig) f.getConfig()).isContainCommitter(),
+                    completableFuture, this.getMetricsContext());
             } else if (f.getAction() instanceof TransformChainAction) {
                 lifeCycle =
                     new TransformFlowLifeCycle<SeaTunnelRow>((TransformChainAction) f.getAction(), this,

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSeaTunnelTask.java
Patch:
@@ -52,7 +52,7 @@ public void init() throws Exception {
         if (!(startFlowLifeCycle instanceof SourceFlowLifeCycle)) {
             throw new TaskRuntimeException("SourceSeaTunnelTask only support SourceFlowLifeCycle, but get " + startFlowLifeCycle.getClass().getName());
         } else {
-            this.collector = new SeaTunnelSourceCollector<>(checkpointLock, outputs);
+            this.collector = new SeaTunnelSourceCollector<>(checkpointLock, outputs, this.getMetricsContext());
             ((SourceFlowLifeCycle<T, SplitT>) startFlowLifeCycle).setCollector(collector);
         }
     }

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-api/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/api/AbstractCheckpointStorage.java
Patch:
@@ -95,7 +95,7 @@ public String getStorageParentDirectory() {
     }
 
     public String getCheckPointName(PipelineState state) {
-        return System.nanoTime() + FILE_NAME_SPLIT + ThreadLocalRandom.current().nextInt(FILE_NAME_RANDOM_RANGE) + FILE_NAME_SPLIT + state.getPipelineId() + FILE_NAME_SPLIT + state.getCheckpointId() + "." + FILE_FORMAT;
+        return System.currentTimeMillis() + FILE_NAME_SPLIT + ThreadLocalRandom.current().nextInt(FILE_NAME_RANDOM_RANGE) + FILE_NAME_SPLIT + state.getPipelineId() + FILE_NAME_SPLIT + state.getCheckpointId() + "." + FILE_FORMAT;
     }
 
     public byte[] serializeCheckPointData(PipelineState state) throws IOException {

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-local-file/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/localfile/LocalFileStorageFactory.java
Patch:
@@ -32,7 +32,10 @@
 /**
  * Local file storage plug-in, use local file storage,
  * only suitable for single-machine testing or small data scale use, use with caution in production environment
+ * <p>
+ * deprecated: use @see org.apache.seatunnel.engine.checkpoint.storage.hdfs.HdfsStorageFactory instead
  */
+@Deprecated
 @AutoService(Factory.class)
 public class LocalFileStorageFactory implements CheckpointStorageFactory {
 

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/SparkStarter.java
Patch:
@@ -206,6 +206,9 @@ protected List<String> buildFinal() {
         appendOption(commands, "--config", this.commandArgs.getConfigFile());
         appendOption(commands, "--master", this.commandArgs.getMaster());
         appendOption(commands, "--deploy-mode", this.commandArgs.getDeployMode().getName());
+        if (this.commandArgs.isCheckConfig()) {
+            commands.add("--check");
+        }
         return commands;
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/JdbcInputFormat.java
Patch:
@@ -130,6 +130,9 @@ public void closeInputFormat() {
      */
     public void open(JdbcSourceSplit inputSplit) throws IOException {
         try {
+            if (!connectionProvider.isConnectionValid()) {
+                openInputFormat();
+            }
             Object[] parameterValues = inputSplit.getParameterValues();
             if (parameterValues != null) {
                 for (int i = 0; i < parameterValues.length; i++) {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/HybridSplitAssigner.java
Patch:
@@ -111,7 +111,7 @@ public Optional<SourceSplitBase> getNext() {
             // we need to wait snapshot-assigner to be completed before
             // assigning the incremental split. Otherwise, records emitted from incremental split
             // might be out-of-order in terms of same primary key with snapshot splits.
-            return snapshotSplitAssigner.getNext();
+            return incrementalSplitAssigner.getNext();
         }
         // no more splits for the assigner
         return Optional.empty();

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/offset/OffsetFactory.java
Patch:
@@ -17,9 +17,10 @@
 
 package org.apache.seatunnel.connectors.cdc.base.source.offset;
 
+import java.io.Serializable;
 import java.util.Map;
 
-public abstract class OffsetFactory {
+public abstract class OffsetFactory implements Serializable {
     public OffsetFactory() {}
 
     public abstract Offset earliest();

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/IncrementalSplit.java
Patch:
@@ -26,6 +26,7 @@
 
 @Getter
 public class IncrementalSplit extends SourceSplitBase {
+    private static final long serialVersionUID = 1L;
 
     /**
      * All the tables that this incremental split needs to capture.

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/SnapshotSplit.java
Patch:
@@ -25,6 +25,7 @@
 
 @Getter
 public class SnapshotSplit extends SourceSplitBase {
+    private static final long serialVersionUID = 1L;
     private final TableId tableId;
     private final SeaTunnelRowType splitKeyType;
     private final Object splitStart;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MySqlIncrementalSource.java
Patch:
@@ -52,6 +52,8 @@ public SourceConfig.Factory<JdbcSourceConfig> createSourceConfigFactory(Readonly
         MySqlSourceConfigFactory configFactory = new MySqlSourceConfigFactory();
         configFactory.serverId(config.get(JdbcSourceOptions.SERVER_ID));
         configFactory.fromReadonlyConfig(readonlyConfig);
+        configFactory.startupOptions(startupConfig);
+        configFactory.stopOptions(stopConfig);
         return configFactory;
     }
 
@@ -63,7 +65,7 @@ public DebeziumDeserializationSchema<T> createDebeziumDeserializationSchema(Read
         // TODO: support multi-table
         // TODO: support metadata keys
         MySqlCatalog mySqlCatalog = new MySqlCatalog("mysql", jdbcSourceConfig.getDatabaseList().get(0), jdbcSourceConfig.getUsername(), jdbcSourceConfig.getPassword(), baseUrl);
-        CatalogTable table = mySqlCatalog.getTable(TablePath.of(jdbcSourceConfig.getDatabaseList().get(0), jdbcSourceConfig.getTableList().get(0)));
+        CatalogTable table = mySqlCatalog.getTable(TablePath.of(jdbcSourceConfig.getDatabaseList().get(0), config.get(JdbcSourceOptions.TABLE_NAME)));
         SeaTunnelRowType physicalRowType = table.getTableSchema().toPhysicalRowDataType();
         String zoneId = config.get(JdbcSourceOptions.SERVER_TIME_ZONE);
         return (DebeziumDeserializationSchema<T>) SeaTunnelRowDebeziumDeserializeSchema.builder()

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/JsonDeserializationSchema.java
Patch:
@@ -118,6 +118,9 @@ public void collect(byte[] message, Collector<SeaTunnelRow> out) throws IOExcept
                 SeaTunnelRow deserialize = convertJsonNode(arrayNode.get(i));
                 out.collect(deserialize);
             }
+        } else {
+            SeaTunnelRow deserialize = convertJsonNode(jsonNode);
+            out.collect(deserialize);
         }
     }
 

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/serialize/StarRocksJsonSerializer.java
Patch:
@@ -21,16 +21,13 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.utils.JsonUtils;
 
-import com.fasterxml.jackson.databind.ObjectMapper;
-
 import java.util.HashMap;
 import java.util.Map;
 
 public class StarRocksJsonSerializer extends StarRocksBaseSerializer implements StarRocksISerializer {
 
     private static final long serialVersionUID = 1L;
     private final SeaTunnelRowType seaTunnelRowType;
-    private final ObjectMapper mapper = new ObjectMapper();
 
     public StarRocksJsonSerializer(SeaTunnelRowType seaTunnelRowType) {
         this.seaTunnelRowType = seaTunnelRowType;

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/common/metrics/RawJobMetrics.java
Patch:
@@ -17,9 +17,10 @@
 
 package org.apache.seatunnel.api.common.metrics;
 
+import java.io.Serializable;
 import java.util.Arrays;
 
-public final class RawJobMetrics {
+public final class RawJobMetrics implements Serializable {
 
     private long timestamp;
     private byte[] blob;

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/env/EnvCommonOptions.java
Patch:
@@ -34,7 +34,7 @@ public class EnvCommonOptions {
     public static final Option<String> JOB_NAME =
         Options.key("job.name")
             .stringType()
-            .noDefaultValue()
+            .defaultValue("SeaTunnel_Job")
             .withDescription("The job name of this job");
 
     public static final Option<JobMode> JOB_MODE =

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceIT.java
Patch:
@@ -118,6 +118,7 @@ public void testBatchJobRunOkIn3Node() throws ExecutionException, InterruptedExc
 
             Long fileLineNumberFromDir = FileUtils.getFileLineNumberFromDir(testResources.getLeft());
             Assertions.assertEquals(testRowNumber * testParallelism, fileLineNumberFromDir);
+            System.out.println(engineClient.getJobMetrics(clientJobProxy.getJobId()));
         } finally {
             if (engineClient != null) {
                 engineClient.shutdown();

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/AsyncOperation.java
Patch:
@@ -26,7 +26,7 @@
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
-import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
+import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
 import com.hazelcast.nio.serialization.HazelcastSerializationException;
 import com.hazelcast.nio.serialization.IdentifiedDataSerializable;
@@ -102,6 +102,6 @@ public ExceptionAction onInvocationException(Throwable throwable) {
 
     @Override
     public final int getFactoryId() {
-        return OperationDataSerializerHook.FACTORY_ID;
+        return ClientToServerOperationDataSerializerHook.FACTORY_ID;
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/CancelJobOperation.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
-import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
+import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
 public class CancelJobOperation extends AbstractJobAsyncOperation {
     public CancelJobOperation() {
@@ -38,6 +38,6 @@ protected PassiveCompletableFuture<?> doRun() throws Exception {
 
     @Override
     public int getClassId() {
-        return OperationDataSerializerHook.CANCEL_JOB_OPERATOR;
+        return ClientToServerOperationDataSerializerHook.CANCEL_JOB_OPERATOR;
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/GetJobMetricsOperation.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.engine.server.operation;
 
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
-import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
+import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
 import com.hazelcast.nio.ObjectDataInput;
 import com.hazelcast.nio.ObjectDataOutput;
@@ -44,12 +44,12 @@ public GetJobMetricsOperation(long jobId) {
 
     @Override
     public final int getFactoryId() {
-        return OperationDataSerializerHook.FACTORY_ID;
+        return ClientToServerOperationDataSerializerHook.FACTORY_ID;
     }
 
     @Override
     public int getClassId() {
-        return OperationDataSerializerHook.GET_JOB_METRICS_OPERATOR;
+        return ClientToServerOperationDataSerializerHook.GET_JOB_METRICS_OPERATOR;
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/GetJobStateOperation.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
-import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
+import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
 import com.hazelcast.nio.ObjectDataInput;
 import com.hazelcast.nio.ObjectDataOutput;
@@ -45,12 +45,12 @@ public GetJobStateOperation(Long jobId) {
 
     @Override
     public final int getFactoryId() {
-        return OperationDataSerializerHook.FACTORY_ID;
+        return ClientToServerOperationDataSerializerHook.FACTORY_ID;
     }
 
     @Override
     public int getClassId() {
-        return OperationDataSerializerHook.PRINT_MESSAGE_OPERATOR;
+        return ClientToServerOperationDataSerializerHook.PRINT_MESSAGE_OPERATOR;
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/GetJobStatusOperation.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.engine.core.job.JobStatus;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
-import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
+import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
 import com.hazelcast.nio.ObjectDataInput;
 import com.hazelcast.nio.ObjectDataOutput;
@@ -45,12 +45,12 @@ public GetJobStatusOperation(long jobId) {
 
     @Override
     public final int getFactoryId() {
-        return OperationDataSerializerHook.FACTORY_ID;
+        return ClientToServerOperationDataSerializerHook.FACTORY_ID;
     }
 
     @Override
     public int getClassId() {
-        return OperationDataSerializerHook.GET_JOB_STATUS_OPERATOR;
+        return ClientToServerOperationDataSerializerHook.GET_JOB_STATUS_OPERATOR;
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/PrintMessageOperation.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.engine.server.operation;
 
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
-import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
+import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
 import com.hazelcast.nio.ObjectDataInput;
 import com.hazelcast.nio.ObjectDataOutput;
@@ -42,12 +42,12 @@ public PrintMessageOperation(String message) {
 
     @Override
     public final int getFactoryId() {
-        return OperationDataSerializerHook.FACTORY_ID;
+        return ClientToServerOperationDataSerializerHook.FACTORY_ID;
     }
 
     @Override
     public int getClassId() {
-        return OperationDataSerializerHook.PRINT_MESSAGE_OPERATOR;
+        return ClientToServerOperationDataSerializerHook.PRINT_MESSAGE_OPERATOR;
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/SubmitJobOperation.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
-import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
+import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
 import com.hazelcast.internal.nio.IOUtil;
 import com.hazelcast.internal.serialization.Data;
@@ -42,7 +42,7 @@ public SubmitJobOperation(long jobId, @NonNull Data jobImmutableInformation) {
 
     @Override
     public int getClassId() {
-        return OperationDataSerializerHook.SUBMIT_OPERATOR;
+        return ClientToServerOperationDataSerializerHook.SUBMIT_OPERATOR;
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/WaitForJobCompleteOperation.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
-import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
+import org.apache.seatunnel.engine.server.serializable.ClientToServerOperationDataSerializerHook;
 
 public class WaitForJobCompleteOperation extends AbstractJobAsyncOperation {
 
@@ -39,6 +39,6 @@ protected PassiveCompletableFuture<?> doRun() throws Exception {
 
     @Override
     public int getClassId() {
-        return OperationDataSerializerHook.WAIT_FORM_JOB_COMPLETE_OPERATOR;
+        return ClientToServerOperationDataSerializerHook.WAIT_FORM_JOB_COMPLETE_OPERATOR;
     }
 }

File: seatunnel-connectors-v2/connector-http/connector-http-gitlab/src/main/java/org/apache/seatunnel/connectors/seatunnel/gitlab/source/GitlabSource.java
Patch:
@@ -72,7 +72,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
 
     @Override
     public AbstractSingleSplitReader<SeaTunnelRow> createReader(SingleSplitReaderContext readerContext) throws Exception {
-        return new HttpSourceReader(this.gitlabSourceParameter, readerContext, this.deserializationSchema);
+        return new HttpSourceReader(this.gitlabSourceParameter, readerContext, this.deserializationSchema, jsonField, contentField);
     }
 
 }

File: seatunnel-connectors-v2/connector-http/connector-http-jira/src/main/java/org/apache/seatunnel/connectors/seatunnel/jira/source/JiraSource.java
Patch:
@@ -71,6 +71,6 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
 
     @Override
     public AbstractSingleSplitReader<SeaTunnelRow> createReader(SingleSplitReaderContext readerContext) throws Exception {
-        return new HttpSourceReader(this.jiraSourceParameter, readerContext, this.deserializationSchema);
+        return new HttpSourceReader(this.jiraSourceParameter, readerContext, this.deserializationSchema, jsonField, contentField);
     }
 }

File: seatunnel-connectors-v2/connector-http/connector-http-klaviyo/src/main/java/org/apache/seatunnel/connectors/seatunnel/klaviyo/source/KlaviyoSource.java
Patch:
@@ -61,6 +61,6 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
 
     @Override
     public AbstractSingleSplitReader<SeaTunnelRow> createReader(SingleSplitReaderContext readerContext) throws Exception {
-        return new HttpSourceReader(this.klaviyoSourceParameter, readerContext, this.deserializationSchema);
+        return new HttpSourceReader(this.klaviyoSourceParameter, readerContext, this.deserializationSchema, jsonField, contentField);
     }
 }

File: seatunnel-connectors-v2/connector-http/connector-http-lemlist/src/main/java/org/apache/seatunnel/connectors/seatunnel/lemlist/source/LemlistSource.java
Patch:
@@ -64,6 +64,6 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
 
     @Override
     public AbstractSingleSplitReader<SeaTunnelRow> createReader(SingleSplitReaderContext readerContext) throws Exception {
-        return new HttpSourceReader(this.lemlistSourceParameter, readerContext, this.deserializationSchema);
+        return new HttpSourceReader(this.lemlistSourceParameter, readerContext, this.deserializationSchema, jsonField, contentField);
     }
 }

File: seatunnel-connectors-v2/connector-http/connector-http-myhours/src/main/java/org/apache/seatunnel/connectors/seatunnel/myhours/source/MyHoursSource.java
Patch:
@@ -72,7 +72,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
 
     @Override
     public AbstractSingleSplitReader<SeaTunnelRow> createReader(SingleSplitReaderContext readerContext) throws Exception {
-        return new HttpSourceReader(this.myHoursSourceParameter, readerContext, this.deserializationSchema);
+        return new HttpSourceReader(this.myHoursSourceParameter, readerContext, this.deserializationSchema, jsonField, contentField);
     }
 
     private String getAccessToken(Config pluginConfig){

File: seatunnel-connectors-v2/connector-http/connector-http-onesignal/src/main/java/org/apache/seatunnel/connectors/seatunnel/onesignal/source/OneSignalSource.java
Patch:
@@ -56,6 +56,6 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
 
     @Override
     public AbstractSingleSplitReader<SeaTunnelRow> createReader(SingleSplitReaderContext readerContext) throws Exception {
-        return new HttpSourceReader(this.oneSignalSourceParameter, readerContext, this.deserializationSchema);
+        return new HttpSourceReader(this.oneSignalSourceParameter, readerContext, this.deserializationSchema, jsonField, contentField);
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-ftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/ftp/source/FtpFileSourceFactory.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.ftp.source;
 
-import org.apache.seatunnel.api.configuration.util.Condition;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
@@ -27,6 +26,8 @@
 
 import com.google.auto.service.AutoService;
 
+import java.util.Arrays;
+
 @AutoService(Factory.class)
 public class FtpFileSourceFactory implements TableSourceFactory {
     @Override
@@ -48,8 +49,7 @@ public OptionRule optionRule() {
                 .optional(FtpConfig.DATE_FORMAT)
                 .optional(FtpConfig.DATETIME_FORMAT)
                 .optional(FtpConfig.TIME_FORMAT)
-                .conditional(Condition.of(FtpConfig.FILE_TYPE, "text"), SeaTunnelSchema.SCHEMA)
-                .conditional(Condition.of(FtpConfig.FILE_TYPE, "json"), SeaTunnelSchema.SCHEMA)
+                .conditional(FtpConfig.FILE_TYPE, Arrays.asList("text", "json"), SeaTunnelSchema.SCHEMA)
                 .build();
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-hadoop/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/hdfs/source/HdfsFileSourceFactory.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.hdfs.source;
 
-import org.apache.seatunnel.api.configuration.util.Condition;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
@@ -27,6 +26,8 @@
 
 import com.google.auto.service.AutoService;
 
+import java.util.Arrays;
+
 @AutoService(Factory.class)
 public class HdfsFileSourceFactory implements TableSourceFactory {
     @Override
@@ -45,8 +46,7 @@ public OptionRule optionRule() {
                 .optional(HdfsSourceConfig.DATE_FORMAT)
                 .optional(HdfsSourceConfig.DATETIME_FORMAT)
                 .optional(HdfsSourceConfig.TIME_FORMAT)
-                .conditional(Condition.of(HdfsSourceConfig.FILE_TYPE, "text"), SeaTunnelSchema.SCHEMA)
-                .conditional(Condition.of(HdfsSourceConfig.FILE_TYPE, "json"), SeaTunnelSchema.SCHEMA)
+                .conditional(HdfsSourceConfig.FILE_TYPE, Arrays.asList("text", "json"), SeaTunnelSchema.SCHEMA)
                 .build();
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/source/LocalFileSourceFactory.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.local.source;
 
-import org.apache.seatunnel.api.configuration.util.Condition;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
@@ -27,6 +26,8 @@
 
 import com.google.auto.service.AutoService;
 
+import java.util.Arrays;
+
 @AutoService(Factory.class)
 public class LocalFileSourceFactory implements TableSourceFactory {
     @Override
@@ -44,8 +45,7 @@ public OptionRule optionRule() {
                 .optional(LocalSourceConfig.DATE_FORMAT)
                 .optional(LocalSourceConfig.DATETIME_FORMAT)
                 .optional(LocalSourceConfig.TIME_FORMAT)
-                .conditional(Condition.of(LocalSourceConfig.FILE_TYPE, "text"), SeaTunnelSchema.SCHEMA)
-                .conditional(Condition.of(LocalSourceConfig.FILE_TYPE, "json"), SeaTunnelSchema.SCHEMA)
+                .conditional(LocalSourceConfig.FILE_TYPE, Arrays.asList("text", "json"), SeaTunnelSchema.SCHEMA)
                 .build();
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/source/OssFileSourceFactory.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.oss.source;
 
-import org.apache.seatunnel.api.configuration.util.Condition;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
@@ -27,6 +26,8 @@
 
 import com.google.auto.service.AutoService;
 
+import java.util.Arrays;
+
 @AutoService(Factory.class)
 public class OssFileSourceFactory implements TableSourceFactory {
     @Override
@@ -48,8 +49,7 @@ public OptionRule optionRule() {
                 .optional(OssConfig.DATE_FORMAT)
                 .optional(OssConfig.DATETIME_FORMAT)
                 .optional(OssConfig.TIME_FORMAT)
-                .conditional(Condition.of(OssConfig.FILE_TYPE, "text"), SeaTunnelSchema.SCHEMA)
-                .conditional(Condition.of(OssConfig.FILE_TYPE, "json"), SeaTunnelSchema.SCHEMA)
+                .conditional(OssConfig.FILE_TYPE, Arrays.asList("text", "json"), SeaTunnelSchema.SCHEMA)
                 .build();
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/source/S3FileSourceFactory.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.s3.source;
 
-import org.apache.seatunnel.api.configuration.util.Condition;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
@@ -27,6 +26,8 @@
 
 import com.google.auto.service.AutoService;
 
+import java.util.Arrays;
+
 @AutoService(Factory.class)
 public class S3FileSourceFactory implements TableSourceFactory {
     @Override
@@ -47,8 +48,7 @@ public OptionRule optionRule() {
                 .optional(S3Config.DATE_FORMAT)
                 .optional(S3Config.DATETIME_FORMAT)
                 .optional(S3Config.TIME_FORMAT)
-                .conditional(Condition.of(S3Config.FILE_TYPE, "text"), SeaTunnelSchema.SCHEMA)
-                .conditional(Condition.of(S3Config.FILE_TYPE, "json"), SeaTunnelSchema.SCHEMA)
+                .conditional(S3Config.FILE_TYPE, Arrays.asList("text", "json"), SeaTunnelSchema.SCHEMA)
                 .build();
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-sftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sftp/source/SftpFileSourceFactory.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.sftp.source;
 
-import org.apache.seatunnel.api.configuration.util.Condition;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
@@ -27,6 +26,8 @@
 
 import com.google.auto.service.AutoService;
 
+import java.util.Arrays;
+
 @AutoService(Factory.class)
 public class SftpFileSourceFactory implements TableSourceFactory {
     @Override
@@ -48,8 +49,7 @@ public OptionRule optionRule() {
                 .optional(SftpConfig.DATE_FORMAT)
                 .optional(SftpConfig.DATETIME_FORMAT)
                 .optional(SftpConfig.TIME_FORMAT)
-                .conditional(Condition.of(SftpConfig.FILE_TYPE, "text"), SeaTunnelSchema.SCHEMA)
-                .conditional(Condition.of(SftpConfig.FILE_TYPE, "json"), SeaTunnelSchema.SCHEMA)
+                .conditional(SftpConfig.FILE_TYPE, Arrays.asList("text", "json"), SeaTunnelSchema.SCHEMA)
                 .build();
     }
 }

File: seatunnel-connectors-v2/connector-http/connector-http-gitlab/src/main/java/org/apache/seatunnel/connectors/seatunnel/gitlab/source/GitlabSourceFactory.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.gitlab.source;
 
-import org.apache.seatunnel.api.configuration.util.Condition;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
@@ -43,9 +42,9 @@ public OptionRule optionRule() {
                 .optional(GitlabSourceConfig.METHOD)
                 .optional(GitlabSourceConfig.HEADERS)
                 .optional(GitlabSourceConfig.PARAMS)
-                .conditional(Condition.of(HttpConfig.METHOD, HttpRequestMethod.POST), GitlabSourceConfig.BODY)
-                .conditional(Condition.of(HttpConfig.FORMAT, "json"), SeaTunnelSchema.SCHEMA)
                 .optional(GitlabSourceConfig.FORMAT)
+                .conditional(HttpConfig.METHOD, HttpRequestMethod.POST, GitlabSourceConfig.BODY)
+                .conditional(HttpConfig.FORMAT, HttpConfig.ResponseFormat.JSON, SeaTunnelSchema.SCHEMA)
                 .optional(GitlabSourceConfig.POLL_INTERVAL_MILLS)
                 .optional(GitlabSourceConfig.RETRY)
                 .optional(GitlabSourceConfig.RETRY_BACKOFF_MAX_MS)

File: seatunnel-connectors-v2/connector-http/connector-http-jira/src/main/java/org/apache/seatunnel/connectors/seatunnel/jira/source/JiraSourceFactory.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jira.source;
 
-import org.apache.seatunnel.api.configuration.util.Condition;
 import org.apache.seatunnel.api.configuration.util.OptionRule;
 import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
@@ -44,9 +43,9 @@ public OptionRule optionRule() {
             .optional(JiraSourceConfig.METHOD)
             .optional(JiraSourceConfig.HEADERS)
             .optional(JiraSourceConfig.PARAMS)
-            .conditional(Condition.of(HttpConfig.METHOD, HttpRequestMethod.POST), JiraSourceConfig.BODY)
-            .conditional(Condition.of(HttpConfig.FORMAT, "json"), SeaTunnelSchema.SCHEMA)
             .optional(JiraSourceConfig.FORMAT)
+            .conditional(HttpConfig.METHOD, HttpRequestMethod.POST, JiraSourceConfig.BODY)
+            .conditional(HttpConfig.FORMAT, HttpConfig.ResponseFormat.JSON, SeaTunnelSchema.SCHEMA)
             .optional(JiraSourceConfig.POLL_INTERVAL_MILLS)
             .optional(JiraSourceConfig.RETRY)
             .optional(JiraSourceConfig.RETRY_BACKOFF_MAX_MS)

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/PulsarSourceFactory.java
Patch:
@@ -54,13 +54,13 @@ public String factoryIdentifier() {
     public OptionRule optionRule() {
         return OptionRule.builder()
             .required(SUBSCRIPTION_NAME, CLIENT_SERVICE_URL, ADMIN_SERVICE_URL)
+            .optional(CURSOR_STARTUP_MODE, CURSOR_STOP_MODE, TOPIC_DISCOVERY_INTERVAL,
+                POLL_TIMEOUT, POLL_INTERVAL,
+                POLL_BATCH_SIZE, SeaTunnelSchema.SCHEMA)
             .exclusive(TOPIC, TOPIC_PATTERN)
             .conditional(CURSOR_STARTUP_MODE, SourceProperties.StartMode.TIMESTAMP, CURSOR_STARTUP_TIMESTAMP)
             .conditional(CURSOR_STARTUP_MODE, SourceProperties.StartMode.SUBSCRIPTION, CURSOR_RESET_MODE)
             .conditional(CURSOR_STOP_MODE, SourceProperties.StopMode.TIMESTAMP, CURSOR_STOP_TIMESTAMP)
-            .optional(CURSOR_STARTUP_MODE, CURSOR_STOP_MODE, TOPIC_DISCOVERY_INTERVAL,
-                POLL_TIMEOUT, POLL_INTERVAL,
-                POLL_BATCH_SIZE, SeaTunnelSchema.SCHEMA)
             .bundled(AUTH_PLUGIN_CLASS, AUTH_PARAMS)
             .build();
     }

File: seatunnel-connectors-v2/connector-rabbitmq/src/main/java/org/apache/seatunnel/connectors/seatunnel/rabbitmq/source/RabbitmqSourceFactory.java
Patch:
@@ -57,8 +57,6 @@ public OptionRule optionRule() {
                 HOST,
                 PORT,
                 VIRTUAL_HOST,
-                USERNAME,
-                PASSWORD,
                 QUEUE_NAME,
                 SCHEMA
             )

File: seatunnel-connectors-v2/connector-redis/src/main/java/org/apache/seatunnel/connectors/seatunnel/redis/source/RedisSourceFactory.java
Patch:
@@ -36,7 +36,8 @@ public String factoryIdentifier() {
     public OptionRule optionRule() {
         return OptionRule.builder()
             .required(RedisConfig.HOST, RedisConfig.PORT, RedisConfig.KEY, RedisConfig.DATA_TYPE)
-            .optional(RedisConfig.MODE, RedisConfig.HASH_KEY_PARSE_MODE, RedisConfig.AUTH, RedisConfig.USER, RedisConfig.KEY_PATTERN)
+            .optional(RedisConfig.MODE, RedisConfig.HASH_KEY_PARSE_MODE, RedisConfig.AUTH, RedisConfig.USER,
+                RedisConfig.KEY_PATTERN)
             .conditional(RedisConfig.MODE, RedisConfig.RedisMode.CLUSTER, RedisConfig.NODES)
             .bundled(RedisConfig.FORMAT, SeaTunnelSchema.SCHEMA)
             .build();

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/JobConfig.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.common.config;
 
 import org.apache.seatunnel.api.common.JobContext;
+import org.apache.seatunnel.api.env.EnvCommonOptions;
 import org.apache.seatunnel.engine.common.serializeable.ConfigDataSerializerHook;
 
 import com.hazelcast.nio.ObjectDataInput;
@@ -31,7 +32,7 @@
 
 @Data
 public class JobConfig implements IdentifiedDataSerializable {
-    private String name;
+    private String name = EnvCommonOptions.JOB_NAME.defaultValue();
     private JobContext jobContext;
 
     private Map<String, Object> envOptions = new HashMap<>();

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/AbstractSeaTunnelServerTest.java
Patch:
@@ -29,7 +29,7 @@
 
 @Slf4j
 @TestInstance(TestInstance.Lifecycle.PER_CLASS)
-public abstract class AbstractSeaTunnelServerTest {
+public abstract class AbstractSeaTunnelServerTest<T extends AbstractSeaTunnelServerTest> {
 
     protected SeaTunnelServer server;
 
@@ -41,8 +41,9 @@ public abstract class AbstractSeaTunnelServerTest {
 
     @BeforeAll
     public void before() {
+        String name = ((T) this).getClass().getName();
         instance = SeaTunnelServerStarter.createHazelcastInstance(
-            TestUtils.getClusterName("AbstractSeaTunnelServerTest_" + System.currentTimeMillis()));
+            TestUtils.getClusterName("AbstractSeaTunnelServerTest_" + name));
         nodeEngine = instance.node.nodeEngine;
         server = nodeEngine.getService(SeaTunnelServer.SERVICE_NAME);
         LOGGER = nodeEngine.getLogger(AbstractSeaTunnelServerTest.class);

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/master/JobMasterTest.java
Patch:
@@ -117,7 +117,7 @@ public void testHandleCheckpointTimeout() throws Exception {
         JobMaster jobMaster = server.getCoordinatorService().getJobMaster(JOB_ID);
 
         // waiting for job status turn to running
-        await().atMost(60000, TimeUnit.MILLISECONDS)
+        await().atMost(120000, TimeUnit.MILLISECONDS)
             .untilAsserted(() -> Assertions.assertEquals(JobStatus.RUNNING, jobMaster.getJobStatus()));
 
         // call checkpoint timeout
@@ -127,15 +127,15 @@ public void testHandleCheckpointTimeout() throws Exception {
         Thread.sleep(5000);
 
         // test job still run
-        await().atMost(60000, TimeUnit.MILLISECONDS)
+        await().atMost(120000, TimeUnit.MILLISECONDS)
             .untilAsserted(() -> Assertions.assertEquals(JobStatus.RUNNING, jobMaster.getJobStatus()));
 
         PassiveCompletableFuture<JobStatus> jobMasterCompleteFuture = jobMaster.getJobMasterCompleteFuture();
         // cancel job
         jobMaster.cancelJob();
 
         // test job turn to complete
-        await().atMost(60000, TimeUnit.MILLISECONDS)
+        await().atMost(120000, TimeUnit.MILLISECONDS)
             .untilAsserted(() -> Assertions.assertTrue(
                 jobMasterCompleteFuture.isDone() && JobStatus.CANCELED.equals(jobMasterCompleteFuture.get())));
 

File: seatunnel-transforms-v2/src/main/java/org/apache/seatunnel/transform/ReplaceTransform.java
Patch:
@@ -57,7 +57,7 @@ public class ReplaceTransform extends SingleFieldOutputTransform {
 
     public static final Option<Boolean> KEY_REPLACE_FIRST = Options.key("replace_first")
             .booleanType()
-            .defaultValue(false)
+            .noDefaultValue()
             .withDescription("Replace the first match string");
 
     private int inputFieldIndex;

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/env/EnvCommonOptions.java
Patch:
@@ -34,14 +34,14 @@ public class EnvCommonOptions {
     public static final Option<String> JOB_NAME =
         Options.key("job.name")
             .stringType()
-            .defaultValue("SeaTunnel Job")
+            .noDefaultValue()
             .withDescription("The job name of this job");
 
     public static final Option<JobMode> JOB_MODE =
         Options.key("job.mode")
             .enumType(JobMode.class)
-            .defaultValue(JobMode.BATCH)
-            .withDescription("The job mode of this job, support Batch and Stream, Default value is Batch");
+            .noDefaultValue()
+            .withDescription("The job mode of this job, support Batch and Stream");
 
     public static final Option<Long> CHECKPOINT_INTERVAL =
         Options.key("checkpoint.interval")

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/WriteStrategy.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.file.config.HadoopConf;
+import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
 
 import org.apache.hadoop.conf.Configuration;
 
@@ -44,9 +45,9 @@ public interface WriteStrategy extends Transaction, Serializable {
     /**
      * write seaTunnelRow to target datasource
      * @param seaTunnelRow seaTunnelRow
-     * @throws Exception Exceptions
+     * @throws FileConnectorException Exceptions
      */
-    void write(SeaTunnelRow seaTunnelRow) throws Exception;
+    void write(SeaTunnelRow seaTunnelRow) throws FileConnectorException;
 
     /**
      * set seaTunnelRowTypeInfo in writer

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/WriteStrategyFactory.java
Patch:
@@ -17,7 +17,9 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.sink.writer;
 
+import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
+import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.config.TextFileSinkConfig;
 
 import lombok.extern.slf4j.Slf4j;
@@ -33,7 +35,7 @@ public static WriteStrategy of(String fileType, TextFileSinkConfig textFileSinkC
             return fileFormat.getWriteStrategy(textFileSinkConfig);
         } catch (IllegalArgumentException e) {
             String errorMsg = String.format("File sink connector not support this file type [%s], please check your config", fileType);
-            throw new RuntimeException(errorMsg, e);
+            throw new FileConnectorException(CommonErrorCode.ILLEGAL_ARGUMENT, errorMsg);
         }
     }
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/AbstractReadStrategy.java
Patch:
@@ -27,7 +27,6 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.file.config.BaseSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.file.config.HadoopConf;
-import org.apache.seatunnel.connectors.seatunnel.file.exception.FilePluginException;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
@@ -93,7 +92,7 @@ public Configuration getConfiguration(HadoopConf hadoopConf) {
         return configuration;
     }
 
-    Configuration getConfiguration() throws FilePluginException {
+    Configuration getConfiguration() {
         return getConfiguration(hadoopConf);
     }
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/ReadStrategy.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.file.config.HadoopConf;
-import org.apache.seatunnel.connectors.seatunnel.file.exception.FilePluginException;
+import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
@@ -36,9 +36,9 @@ public interface ReadStrategy extends Serializable {
 
     Configuration getConfiguration(HadoopConf conf);
 
-    void read(String path, Collector<SeaTunnelRow> output) throws Exception;
+    void read(String path, Collector<SeaTunnelRow> output) throws IOException, FileConnectorException;
 
-    SeaTunnelRowType getSeaTunnelRowTypeInfo(HadoopConf hadoopConf, String path) throws FilePluginException;
+    SeaTunnelRowType getSeaTunnelRowTypeInfo(HadoopConf hadoopConf, String path) throws FileConnectorException;
 
     void setSeaTunnelRowTypeInfo(SeaTunnelRowType seaTunnelRowType);
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/ReadStrategyFactory.java
Patch:
@@ -17,7 +17,9 @@
 
 package org.apache.seatunnel.connectors.seatunnel.file.source.reader;
 
+import org.apache.seatunnel.common.exception.CommonErrorCode;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
+import org.apache.seatunnel.connectors.seatunnel.file.exception.FileConnectorException;
 
 import lombok.extern.slf4j.Slf4j;
 
@@ -32,7 +34,7 @@ public static ReadStrategy of(String fileType) {
             return fileFormat.getReadStrategy();
         } catch (IllegalArgumentException e) {
             String errorMsg = String.format("File source connector not support this file type [%s], please check your config", fileType);
-            throw new RuntimeException(errorMsg);
+            throw new FileConnectorException(CommonErrorCode.ILLEGAL_ARGUMENT, errorMsg);
         }
     }
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/FactoryUtil.java
Patch:
@@ -146,7 +146,7 @@ public static <T extends Factory> List<T> discoverFactories(ClassLoader classLoa
                 .collect(Collectors.toList());
     }
 
-    private static List<Factory> discoverFactories(ClassLoader classLoader) {
+    public static List<Factory> discoverFactories(ClassLoader classLoader) {
         try {
             final List<Factory> result = new LinkedList<>();
             ServiceLoader.load(Factory.class, classLoader)

File: seatunnel-connectors-v2/connector-kudu/src/main/java/org/apache/seatunnel/connectors/seatunnel/kudu/kuduclient/KuduTypeMapper.java
Patch:
@@ -22,6 +22,8 @@
 import org.apache.seatunnel.api.table.type.LocalTimeType;
 import org.apache.seatunnel.api.table.type.PrimitiveByteArrayType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
+import org.apache.seatunnel.common.exception.CommonErrorCode;
+import org.apache.seatunnel.connectors.seatunnel.kudu.exception.KuduConnectorException;
 
 import org.apache.kudu.ColumnSchema;
 import org.slf4j.Logger;
@@ -94,7 +96,7 @@ public static SeaTunnelDataType<?> mapping(List<ColumnSchema> columnSchemaList,
 
             case KUDU_UNKNOWN:
             default:
-                throw new UnsupportedOperationException(
+                throw new KuduConnectorException(CommonErrorCode.UNSUPPORTED_DATA_TYPE,
                     String.format(
                         "Doesn't support KUDU type '%s' .",
                         kuduType));

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/BaseFileSink.java
Patch:
@@ -77,7 +77,7 @@ public SinkWriter<SeaTunnelRow, FileCommitInfo, FileSinkState> restoreWriter(Sin
 
     @Override
     public Optional<SinkAggregatedCommitter<FileCommitInfo, FileAggregatedCommitInfo>> createAggregatedCommitter() throws IOException {
-        return Optional.of(new FileSinkAggregatedCommitter());
+        return Optional.of(new FileSinkAggregatedCommitter(hadoopConf));
     }
 
     @Override

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/HiveSink.java
Patch:
@@ -130,6 +130,6 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
 
     @Override
     public Optional<SinkAggregatedCommitter<FileCommitInfo, FileAggregatedCommitInfo>> createAggregatedCommitter() throws IOException {
-        return Optional.of(new HiveSinkAggregatedCommitter(pluginConfig, dbName, tableName));
+        return Optional.of(new HiveSinkAggregatedCommitter(pluginConfig, dbName, tableName, hadoopConf));
     }
 }

File: seatunnel-plugin-discovery/src/main/java/org/apache/seatunnel/plugin/discovery/seatunnel/SeaTunnelTransformPluginDiscovery.java
Patch:
@@ -18,12 +18,13 @@
 package org.apache.seatunnel.plugin.discovery.seatunnel;
 
 import org.apache.seatunnel.api.transform.SeaTunnelTransform;
+import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.plugin.discovery.AbstractPluginDiscovery;
 
 public class SeaTunnelTransformPluginDiscovery extends AbstractPluginDiscovery<SeaTunnelTransform> {
 
     public SeaTunnelTransformPluginDiscovery() {
-        super("seatunnel");
+        super(Common.libDir());
     }
 
     @Override

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/command/FlinkApiTaskExecuteCommand.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.core.starter.flink.command;
 
+import static org.apache.seatunnel.core.starter.utils.FileUtils.checkConfigExist;
+
 import org.apache.seatunnel.core.starter.command.Command;
 import org.apache.seatunnel.core.starter.config.ConfigBuilder;
 import org.apache.seatunnel.core.starter.exception.CommandExecuteException;
@@ -46,7 +48,7 @@ public FlinkApiTaskExecuteCommand(FlinkCommandArgs flinkCommandArgs) {
     @Override
     public void execute() throws CommandExecuteException {
         Path configFile = FileUtils.getConfigPath(flinkCommandArgs);
-
+        checkConfigExist(configFile);
         Config config = new ConfigBuilder(configFile).getConfig();
         FlinkExecution seaTunnelTaskExecution = new FlinkExecution(config);
         try {

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/command/SparkApiTaskExecuteCommand.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.core.starter.spark.command;
 
+import static org.apache.seatunnel.core.starter.utils.FileUtils.checkConfigExist;
+
 import org.apache.seatunnel.core.starter.command.Command;
 import org.apache.seatunnel.core.starter.config.ConfigBuilder;
 import org.apache.seatunnel.core.starter.exception.CommandExecuteException;
@@ -46,6 +48,7 @@ public SparkApiTaskExecuteCommand(SparkCommandArgs sparkCommandArgs) {
     @Override
     public void execute() throws CommandExecuteException {
         Path configFile = FileUtils.getConfigPath(sparkCommandArgs);
+        checkConfigExist(configFile);
         Config config = new ConfigBuilder(configFile).getConfig();
         try {
             SparkExecution seaTunnelTaskExecution = new SparkExecution(config);

File: seatunnel-core/seatunnel-starter/src/main/java/org/apache/seatunnel/core/starter/seatunnel/command/ClientExecuteCommand.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.core.starter.seatunnel.command;
 
+import static org.apache.seatunnel.core.starter.utils.FileUtils.checkConfigExist;
+
 import org.apache.seatunnel.core.starter.command.Command;
 import org.apache.seatunnel.core.starter.exception.CommandExecuteException;
 import org.apache.seatunnel.core.starter.seatunnel.args.ClientCommandArgs;
@@ -73,6 +75,7 @@ public void execute() throws CommandExecuteException {
                 System.out.println(jobState);
             } else {
                 Path configFile = FileUtils.getConfigPath(clientCommandArgs);
+                checkConfigExist(configFile);
                 JobConfig jobConfig = new JobConfig();
                 jobConfig.setName(clientCommandArgs.getJobName());
                 JobExecutionEnvironment jobExecutionEnv =

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/TableSourceFactory.java
Patch:
@@ -31,7 +31,6 @@ public interface TableSourceFactory extends Factory {
     /**
      * We will never use this method now. So gave a default implement and return null.
      * @param context TableFactoryContext
-     * @return
      */
     default <T, SplitT extends SourceSplit, StateT extends Serializable> TableSource<T, SplitT, StateT> createSource(TableFactoryContext context) {
         throw new UnsupportedOperationException("unsupported now");

File: seatunnel-connectors-v2/connector-amazondynamodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/amazondynamodb/sink/AmazonDynamoDBSink.java
Patch:
@@ -58,7 +58,7 @@ public String getPluginName() {
 
     @Override
     public void prepare(Config pluginConfig) throws PrepareFailException {
-        CheckResult result = CheckConfigUtil.checkAllExists(pluginConfig, URL, TABLE, REGION, ACCESS_KEY_ID, SECRET_ACCESS_KEY);
+        CheckResult result = CheckConfigUtil.checkAllExists(pluginConfig, URL.key(), TABLE.key(), REGION.key(), ACCESS_KEY_ID.key(), SECRET_ACCESS_KEY.key());
         if (!result.isSuccess()) {
             throw new AmazonDynamoDBConnectorException(SeaTunnelAPIErrorCode.CONFIG_VALIDATION_FAILED,
                     String.format("PluginName: %s, PluginType: %s, Message: %s",

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/function/ConsumerWithException.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.common.utils;
+package org.apache.seatunnel.common.utils.function;
 
 @FunctionalInterface
 public interface ConsumerWithException<T>  {

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/function/RunnableWithException.java
Patch:
@@ -16,7 +16,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.common.utils;
+package org.apache.seatunnel.common.utils.function;
 
 /**
  * Similar to a {@link Runnable}, this interface is used to capture a block of code to be executed.

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/function/SupplierWithException.java
Patch:
@@ -16,7 +16,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.common.utils;
+package org.apache.seatunnel.common.utils.function;
 
 /**
  * A functional interface for a {@link java.util.function.Supplier} that may throw exceptions.

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/config/BaseSourceConfig.java
Patch:
@@ -15,11 +15,12 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.config;
+package org.apache.seatunnel.connectors.cdc.base.config;
+
+import org.apache.seatunnel.connectors.cdc.base.source.IncrementalSource;
 
 import io.debezium.config.Configuration;
 import lombok.Getter;
-import org.seatunnel.connectors.cdc.base.source.IncrementalSource;
 
 import java.util.Properties;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/config/JdbcSourceConfig.java
Patch:
@@ -15,10 +15,11 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.config;
+package org.apache.seatunnel.connectors.cdc.base.config;
+
+import org.apache.seatunnel.connectors.cdc.base.source.IncrementalSource;
 
 import io.debezium.relational.RelationalDatabaseConnectorConfig;
-import org.seatunnel.connectors.cdc.base.source.IncrementalSource;
 
 import java.time.Duration;
 import java.util.List;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/config/JdbcSourceConfigFactory.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.config;
+package org.apache.seatunnel.connectors.cdc.base.config;
 
-import org.seatunnel.connectors.cdc.base.option.JdbcSourceOptions;
-import org.seatunnel.connectors.cdc.base.option.SourceOptions;
+import org.apache.seatunnel.connectors.cdc.base.option.JdbcSourceOptions;
+import org.apache.seatunnel.connectors.cdc.base.option.SourceOptions;
 
 import java.time.Duration;
 import java.util.Arrays;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/config/SourceConfig.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.config;
+package org.apache.seatunnel.connectors.cdc.base.config;
 
 import java.io.Serializable;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/option/JdbcSourceOptions.java
Patch:
@@ -15,12 +15,11 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.option;
+package org.apache.seatunnel.connectors.cdc.base.option;
 
 import org.apache.seatunnel.api.configuration.Option;
 import org.apache.seatunnel.api.configuration.Options;
-
-import org.seatunnel.connectors.cdc.base.source.IncrementalSource;
+import org.apache.seatunnel.connectors.cdc.base.source.IncrementalSource;
 
 import java.time.Duration;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/option/SourceOptions.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.option;
+package org.apache.seatunnel.connectors.cdc.base.option;
 
 import org.apache.seatunnel.api.configuration.Option;
 import org.apache.seatunnel.api.configuration.Options;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/option/StartupMode.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.option;
+package org.apache.seatunnel.connectors.cdc.base.option;
 
 /**
  * Startup modes for the CDC Connectors, see {@link SourceOptions#STARTUP_MODE}.

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/option/StopMode.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.option;
+package org.apache.seatunnel.connectors.cdc.base.option;
 
 /**
  * Stop mode for the CDC Connectors, see {@link SourceOptions#STOP_MODE}.

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/ConnectionPoolId.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.relational.connection;
+package org.apache.seatunnel.connectors.cdc.base.relational.connection;
 
 import java.io.Serializable;
 import java.util.Objects;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/ConnectionPools.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.relational.connection;
+package org.apache.seatunnel.connectors.cdc.base.relational.connection;
 
-import org.seatunnel.connectors.cdc.base.config.SourceConfig;
+import org.apache.seatunnel.connectors.cdc.base.config.SourceConfig;
 
 /** A pool collection that consists of multiple connection pools. */
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/JdbcConnectionFactory.java
Patch:
@@ -15,14 +15,14 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.relational.connection;
+package org.apache.seatunnel.connectors.cdc.base.relational.connection;
 
 import org.apache.seatunnel.common.utils.SeaTunnelException;
+import org.apache.seatunnel.connectors.cdc.base.config.JdbcSourceConfig;
 
 import com.zaxxer.hikari.HikariDataSource;
 import io.debezium.jdbc.JdbcConfiguration;
 import io.debezium.jdbc.JdbcConnection;
-import org.seatunnel.connectors.cdc.base.config.JdbcSourceConfig;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/JdbcConnectionPoolFactory.java
Patch:
@@ -15,11 +15,12 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.relational.connection;
+package org.apache.seatunnel.connectors.cdc.base.relational.connection;
+
+import org.apache.seatunnel.connectors.cdc.base.config.JdbcSourceConfig;
 
 import com.zaxxer.hikari.HikariConfig;
 import com.zaxxer.hikari.HikariDataSource;
-import org.seatunnel.connectors.cdc.base.config.JdbcSourceConfig;
 
 /** A connection pool factory to create pooled DataSource {@link HikariDataSource}. */
 public abstract class JdbcConnectionPoolFactory {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/relational/connection/JdbcConnectionPools.java
Patch:
@@ -15,10 +15,11 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.relational.connection;
+package org.apache.seatunnel.connectors.cdc.base.relational.connection;
+
+import org.apache.seatunnel.connectors.cdc.base.config.JdbcSourceConfig;
 
 import com.zaxxer.hikari.HikariDataSource;
-import org.seatunnel.connectors.cdc.base.config.JdbcSourceConfig;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/splitter/ChunkRange.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.enumerator.splitter;
+package org.apache.seatunnel.connectors.cdc.base.source.enumerator.splitter;
 
 import static com.google.common.base.Preconditions.checkArgument;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/splitter/ChunkSplitter.java
Patch:
@@ -15,10 +15,11 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.enumerator.splitter;
+package org.apache.seatunnel.connectors.cdc.base.source.enumerator.splitter;
+
+import org.apache.seatunnel.connectors.cdc.base.source.split.SnapshotSplit;
 
 import io.debezium.relational.TableId;
-import org.seatunnel.connectors.cdc.base.source.split.SnapshotSplit;
 
 import java.util.Collection;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/splitter/JdbcSourceChunkSplitter.java
Patch:
@@ -15,15 +15,15 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.enumerator.splitter;
+package org.apache.seatunnel.connectors.cdc.base.source.enumerator.splitter;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
+import org.apache.seatunnel.connectors.cdc.base.source.split.SnapshotSplit;
 
 import io.debezium.jdbc.JdbcConnection;
 import io.debezium.relational.Column;
 import io.debezium.relational.TableId;
-import org.seatunnel.connectors.cdc.base.source.split.SnapshotSplit;
 
 import java.sql.SQLException;
 import java.util.Collection;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/state/HybridPendingSplitsState.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.enumerator.state;
+package org.apache.seatunnel.connectors.cdc.base.source.enumerator.state;
 
 import lombok.Data;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/state/IncrementalPhaseState.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.enumerator.state;
+package org.apache.seatunnel.connectors.cdc.base.source.enumerator.state;
 
 import lombok.Data;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/enumerator/state/PendingSplitsState.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.enumerator.state;
+package org.apache.seatunnel.connectors.cdc.base.source.enumerator.state;
 
 import java.io.Serializable;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/event/CompletedSnapshotSplitsAckEvent.java
Patch:
@@ -15,12 +15,13 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.event;
+package org.apache.seatunnel.connectors.cdc.base.source.event;
 
 import org.apache.seatunnel.api.source.SourceEvent;
+import org.apache.seatunnel.connectors.cdc.base.source.enumerator.IncrementalSourceEnumerator;
+import org.apache.seatunnel.connectors.cdc.base.source.reader.IncrementalSourceReader;
 
 import lombok.Data;
-import org.seatunnel.connectors.cdc.base.source.enumerator.IncrementalSourceEnumerator;
 
 import java.util.List;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/event/CompletedSnapshotSplitsReportEvent.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.event;
+package org.apache.seatunnel.connectors.cdc.base.source.event;
 
 import org.apache.seatunnel.api.source.SourceEvent;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/event/SnapshotSplitWatermark.java
Patch:
@@ -15,10 +15,11 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.event;
+package org.apache.seatunnel.connectors.cdc.base.source.event;
+
+import org.apache.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 import lombok.Data;
-import org.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 import java.io.Serializable;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/offset/Offset.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.offset;
+package org.apache.seatunnel.connectors.cdc.base.source.offset;
 
 import lombok.Getter;
 import org.apache.kafka.connect.errors.ConnectException;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/offset/OffsetFactory.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.offset;
+package org.apache.seatunnel.connectors.cdc.base.source.offset;
 
 import java.util.Map;
 
@@ -32,5 +32,5 @@ public OffsetFactory() {}
 
     public abstract Offset specific(String filename, Long position);
 
-    public abstract Offset timstamp(long timestmap);
+    public abstract Offset timestamp(long timestamp);
 }

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/reader/external/Fetcher.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.reader.external;
+package org.apache.seatunnel.connectors.cdc.base.source.reader.external;
 
-import org.seatunnel.connectors.cdc.base.source.split.IncrementalSplit;
-import org.seatunnel.connectors.cdc.base.source.split.SnapshotSplit;
+import org.apache.seatunnel.connectors.cdc.base.source.split.IncrementalSplit;
+import org.apache.seatunnel.connectors.cdc.base.source.split.SnapshotSplit;
 
 import java.util.Iterator;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/ChangeEventRecords.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.split;
+package org.apache.seatunnel.connectors.cdc.base.source.split;
 
 import org.apache.seatunnel.connectors.seatunnel.common.source.reader.RecordsWithSplitIds;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/CompletedSnapshotSplitInfo.java
Patch:
@@ -15,13 +15,13 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.split;
+package org.apache.seatunnel.connectors.cdc.base.source.split;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
+import org.apache.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 import io.debezium.relational.TableId;
 import lombok.Getter;
-import org.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 import java.io.Serializable;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/IncrementalSplit.java
Patch:
@@ -15,11 +15,12 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.split;
+package org.apache.seatunnel.connectors.cdc.base.source.split;
+
+import org.apache.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 import io.debezium.relational.TableId;
 import lombok.Getter;
-import org.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 import java.util.List;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/SnapshotSplit.java
Patch:
@@ -15,13 +15,13 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.split;
+package org.apache.seatunnel.connectors.cdc.base.source.split;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
+import org.apache.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 import io.debezium.relational.TableId;
 import lombok.Getter;
-import org.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 @Getter
 public class SnapshotSplit extends SourceSplitBase {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/SourceRecords.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.split;
+package org.apache.seatunnel.connectors.cdc.base.source.split;
 
 import org.apache.kafka.connect.source.SourceRecord;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/SourceSplitBase.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.split;
+package org.apache.seatunnel.connectors.cdc.base.source.split;
 
 import org.apache.seatunnel.api.source.SourceSplit;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/state/SourceSplitStateBase.java
Patch:
@@ -15,11 +15,10 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.split.state;
+package org.apache.seatunnel.connectors.cdc.base.source.split.state;
 
 import org.apache.seatunnel.api.source.SourceSplit;
-
-import org.seatunnel.connectors.cdc.base.source.split.SourceSplitBase;
+import org.apache.seatunnel.connectors.cdc.base.source.split.SourceSplitBase;
 
 /** State of the reader, essentially a mutable version of the {@link SourceSplit}. */
 public abstract class SourceSplitStateBase {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/wartermark/WatermarkEvent.java
Patch:
@@ -15,14 +15,15 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.split.wartermark;
+package org.apache.seatunnel.connectors.cdc.base.source.split.wartermark;
+
+import org.apache.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 import io.debezium.util.SchemaNameAdjuster;
 import org.apache.kafka.connect.data.Schema;
 import org.apache.kafka.connect.data.SchemaBuilder;
 import org.apache.kafka.connect.data.Struct;
 import org.apache.kafka.connect.source.SourceRecord;
-import org.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 import java.util.Map;
 import java.util.Optional;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/source/split/wartermark/WatermarkKind.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.source.split.wartermark;
+package org.apache.seatunnel.connectors.cdc.base.source.split.wartermark;
 
 /** The watermark kind. */
 public enum WatermarkKind {

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/base/utils/SourceRecordUtils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.base.utils;
+package org.apache.seatunnel.connectors.cdc.base.utils;
 
 import static io.debezium.connector.AbstractSourceInfo.DATABASE_NAME_KEY;
 import static io.debezium.connector.AbstractSourceInfo.SCHEMA_NAME_KEY;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/apache/seatunnel/connectors/cdc/debezium/DebeziumDeserializationSchema.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.seatunnel.connectors.cdc.debezium;
+package org.apache.seatunnel.connectors.cdc.debezium;
 
 import org.apache.seatunnel.api.source.Collector;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/MySqlSourceConfigFactory.java
Patch:
@@ -19,9 +19,10 @@
 
 import static com.google.common.base.Preconditions.checkNotNull;
 
+import org.apache.seatunnel.connectors.cdc.base.config.JdbcSourceConfigFactory;
+
 import io.debezium.config.Configuration;
 import io.debezium.connector.mysql.MySqlConnectorConfig;
-import org.seatunnel.connectors.cdc.base.config.JdbcSourceConfigFactory;
 
 import java.util.Properties;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/config/ServerIdRange.java
Patch:
@@ -19,7 +19,7 @@
 
 import static com.google.common.base.Preconditions.checkArgument;
 
-import org.seatunnel.connectors.cdc.base.option.JdbcSourceOptions;
+import org.apache.seatunnel.connectors.cdc.base.option.JdbcSourceOptions;
 
 import java.io.Serializable;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/MysqlPooledDataSourceFactory.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source;
 
-import org.seatunnel.connectors.cdc.base.config.JdbcSourceConfig;
-import org.seatunnel.connectors.cdc.base.relational.connection.JdbcConnectionPoolFactory;
+import org.apache.seatunnel.connectors.cdc.base.config.JdbcSourceConfig;
+import org.apache.seatunnel.connectors.cdc.base.relational.connection.JdbcConnectionPoolFactory;
 
 /** A MySQL datasource factory. */
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/offset/BinlogOffset.java
Patch:
@@ -17,9 +17,10 @@
 
 package org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.offset;
 
+import org.apache.seatunnel.connectors.cdc.base.source.offset.Offset;
+
 import io.debezium.connector.mysql.GtidSet;
 import org.apache.commons.lang3.StringUtils;
-import org.seatunnel.connectors.cdc.base.source.offset.Offset;
 
 import java.util.HashMap;
 import java.util.Map;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/reader/fetch/binlog/MySqlBinlogFetchTask.java
Patch:
@@ -17,14 +17,14 @@
 
 package org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.reader.fetch.binlog;
 
+import org.apache.seatunnel.connectors.cdc.base.source.reader.external.FetchTask;
+import org.apache.seatunnel.connectors.cdc.base.source.split.IncrementalSplit;
+import org.apache.seatunnel.connectors.cdc.base.source.split.SourceSplitBase;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.reader.fetch.MySqlSourceFetchTaskContext;
 
 import io.debezium.connector.mysql.MySqlStreamingChangeEventSource;
 import io.debezium.pipeline.source.spi.ChangeEventSource;
 import io.debezium.util.Clock;
-import org.seatunnel.connectors.cdc.base.source.reader.external.FetchTask;
-import org.seatunnel.connectors.cdc.base.source.split.IncrementalSplit;
-import org.seatunnel.connectors.cdc.base.source.split.SourceSplitBase;
 
 public class MySqlBinlogFetchTask implements FetchTask<SourceSplitBase> {
     private final IncrementalSplit split;

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/reader/fetch/scan/MySqlSnapshotSplitReadTask.java
Patch:
@@ -21,6 +21,9 @@
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mysql.utils.MySqlUtils.buildSplitScanQuery;
 import static org.apache.seatunnel.connectors.seatunnel.cdc.mysql.utils.MySqlUtils.readTableSplitDataStatement;
 
+import org.apache.seatunnel.connectors.cdc.base.relational.JdbcSourceEventDispatcher;
+import org.apache.seatunnel.connectors.cdc.base.source.split.SnapshotSplit;
+import org.apache.seatunnel.connectors.cdc.base.source.split.wartermark.WatermarkKind;
 import org.apache.seatunnel.connectors.seatunnel.cdc.mysql.source.offset.BinlogOffset;
 
 import io.debezium.DebeziumException;
@@ -46,9 +49,6 @@
 import io.debezium.util.Strings;
 import io.debezium.util.Threads;
 import org.apache.kafka.connect.errors.ConnectException;
-import org.seatunnel.connectors.cdc.base.relational.JdbcSourceEventDispatcher;
-import org.seatunnel.connectors.cdc.base.source.split.SnapshotSplit;
-import org.seatunnel.connectors.cdc.base.source.split.wartermark.WatermarkKind;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/utils/MySqlUtils.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.cdc.mysql.utils;
 
-import static org.seatunnel.connectors.cdc.base.utils.SourceRecordUtils.rowToArray;
+import static org.apache.seatunnel.connectors.cdc.base.utils.SourceRecordUtils.rowToArray;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/utils/ExceptionUtil.java
Patch:
@@ -16,6 +16,9 @@
 
 package org.apache.seatunnel.engine.common.utils;
 
+import org.apache.seatunnel.common.utils.function.ConsumerWithException;
+import org.apache.seatunnel.common.utils.function.RunnableWithException;
+import org.apache.seatunnel.common.utils.function.SupplierWithException;
 import org.apache.seatunnel.engine.common.exception.JobDefineCheckException;
 import org.apache.seatunnel.engine.common.exception.JobNotFoundException;
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -29,7 +29,7 @@
 
 import org.apache.seatunnel.api.table.type.Record;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.engine.common.utils.ConsumerWithException;
+import org.apache.seatunnel.common.utils.function.ConsumerWithException;
 import org.apache.seatunnel.engine.core.checkpoint.InternalCheckpointListener;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
 import org.apache.seatunnel.engine.core.dag.actions.PartitionTransformAction;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/IntermediateQueueFlowLifeCycle.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.seatunnel.api.table.type.Record;
 import org.apache.seatunnel.api.transform.Collector;
-import org.apache.seatunnel.engine.common.utils.ConsumerWithException;
+import org.apache.seatunnel.common.utils.function.ConsumerWithException;
 import org.apache.seatunnel.engine.server.checkpoint.CheckpointBarrier;
 import org.apache.seatunnel.engine.server.task.SeaTunnelTask;
 import org.apache.seatunnel.engine.server.task.record.Barrier;

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-starrocks-e2e/src/test/java/org/apache/seatunnel/e2e/connector/starrocks/StarRocksIT.java
Patch:
@@ -99,7 +99,6 @@ public class StarRocksIT extends TestSuiteBase implements TestResource {
             "PROPERTIES (\n" +
             "\"replication_num\" = \"1\",\n" +
             "\"in_memory\" = \"false\"," +
-            "\"in_memory\" = \"false\"," +
             "\"storage_format\" = \"DEFAULT\"" +
             ")";
 
@@ -124,7 +123,6 @@ public class StarRocksIT extends TestSuiteBase implements TestResource {
             "PROPERTIES (\n" +
             "\"replication_num\" = \"1\",\n" +
             "\"in_memory\" = \"false\"," +
-            "\"in_memory\" = \"false\"," +
             "\"storage_format\" = \"DEFAULT\"" +
             ")";
 

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/inject/FloatInjectFunction.java
Patch:
@@ -27,7 +27,7 @@ public void injectFields(PreparedStatement statement, int index, Object value) t
         if (value instanceof BigDecimal) {
             statement.setFloat(index, ((BigDecimal) value).floatValue());
         } else {
-            statement.setFloat(index, (Float) value);
+            statement.setFloat(index, Float.parseFloat(value.toString()));
         }
     }
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/reader/fetch/binlog/MySqlBinlogFetchTask.java
Patch:
@@ -35,7 +35,7 @@ public MySqlBinlogFetchTask(IncrementalSplit split) {
     }
 
     @Override
-    public void execute(Context context) throws Exception {
+    public void execute(FetchTask.Context context) throws Exception {
         MySqlSourceFetchTaskContext sourceFetchContext = (MySqlSourceFetchTaskContext) context;
         taskRunning = true;
 

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/source/reader/fetch/scan/MySqlSnapshotFetchTask.java
Patch:
@@ -36,7 +36,7 @@ public MySqlSnapshotFetchTask(SnapshotSplit split) {
     }
 
     @Override
-    public void execute(Context context) throws Exception {
+    public void execute(FetchTask.Context context) throws Exception {
         MySqlSourceFetchTaskContext sourceFetchContext = (MySqlSourceFetchTaskContext) context;
         taskRunning = true;
         snapshotSplitReadTask =

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-mysql/src/main/java/org/apache/seatunnel/connectors/seatunnel/cdc/mysql/utils/MySqlTypeUtils.java
Patch:
@@ -26,7 +26,7 @@
 import io.debezium.relational.Column;
 import lombok.extern.slf4j.Slf4j;
 
-/** Utilities for converting from MySQL types to Flink types. */
+/** Utilities for converting from MySQL types to SeaTunnel types. */
 
 @Slf4j
 public class MySqlTypeUtils {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/config/JdbcConfig.java
Patch:
@@ -55,6 +55,9 @@ public class JdbcConfig implements Serializable {
 
     public static final String TRANSACTION_TIMEOUT_SEC = "transaction_timeout_sec";
 
+    public static final String TABLE = "table";
+
+    public static final String PRIMARY_KEYS = "primary_keys";
 
     //source config
     public static final String PARTITION_COLUMN = "partition_column";
@@ -73,7 +76,6 @@ public static JdbcConnectionOptions buildJdbcConnectionOptions(Config config) {
         if (config.hasPath(JdbcConfig.PASSWORD)) {
             jdbcOptions.password = config.getString(JdbcConfig.PASSWORD);
         }
-        jdbcOptions.query = config.getString(JdbcConfig.QUERY);
 
         if (config.hasPath(JdbcConfig.AUTO_COMMIT)) {
             jdbcOptions.autoCommit = config.getBoolean(JdbcConfig.AUTO_COMMIT);

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/config/JdbcSourceOptions.java
Patch:
@@ -33,13 +33,15 @@
 @AllArgsConstructor
 public class JdbcSourceOptions implements Serializable {
     private JdbcConnectionOptions jdbcConnectionOptions;
+    public String query;
     private String partitionColumn;
     private Long partitionUpperBound;
     private Long partitionLowerBound;
     private Integer partitionNumber;
 
     public JdbcSourceOptions(Config config) {
         this.jdbcConnectionOptions = buildJdbcConnectionOptions(config);
+        this.query = config.getString(JdbcConfig.QUERY);
         if (config.hasPath(JdbcConfig.PARTITION_COLUMN)) {
             this.partitionColumn = config.getString(JdbcConfig.PARTITION_COLUMN);
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/JdbcInputFormat.java
Patch:
@@ -208,7 +208,7 @@ public SeaTunnelRow nextRecord() throws IOException {
             if (!hasNext) {
                 return null;
             }
-            SeaTunnelRow seaTunnelRow = jdbcRowConverter.toInternal(resultSet, resultSet.getMetaData(), typeInfo);
+            SeaTunnelRow seaTunnelRow = jdbcRowConverter.toInternal(resultSet, typeInfo);
             // update hasNext after we've read the record
             hasNext = resultSet.next();
             return seaTunnelRow;

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/JdbcSource.java
Patch:
@@ -74,7 +74,7 @@ public String getPluginName() {
     public void prepare(Config pluginConfig) throws PrepareFailException {
         jdbcSourceOptions = new JdbcSourceOptions(pluginConfig);
         jdbcConnectionProvider = new SimpleJdbcConnectionProvider(jdbcSourceOptions.getJdbcConnectionOptions());
-        query = jdbcSourceOptions.getJdbcConnectionOptions().query;
+        query = jdbcSourceOptions.getQuery();
         jdbcDialect = JdbcDialectLoader.load(jdbcSourceOptions.getJdbcConnectionOptions().getUrl());
         try (Connection connection = jdbcConnectionProvider.getOrEstablishConnection()) {
             typeInfo = initTableField(connection);

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/AbstractReadStrategy.java
Patch:
@@ -127,8 +127,8 @@ public List<String> getFileNamesByPath(HadoopConf hadoopConf, String path) throw
     @Override
     public void setPluginConfig(Config pluginConfig) {
         this.pluginConfig = pluginConfig;
-        if (pluginConfig.hasPath(BaseSourceConfig.PARSE_PARTITION_FROM_PATH)) {
-            isMergePartition = pluginConfig.getBoolean(BaseSourceConfig.PARSE_PARTITION_FROM_PATH);
+        if (pluginConfig.hasPath(BaseSourceConfig.PARSE_PARTITION_FROM_PATH.key())) {
+            isMergePartition = pluginConfig.getBoolean(BaseSourceConfig.PARSE_PARTITION_FROM_PATH.key());
         }
     }
 

File: seatunnel-connectors-v2/connector-file/connector-file-ftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/ftp/sink/FtpFileSink.java
Patch:
@@ -41,8 +41,8 @@ public String getPluginName() {
     @Override
     public void prepare(Config pluginConfig) throws PrepareFailException {
         CheckResult result = CheckConfigUtil.checkAllExists(pluginConfig,
-                FtpConfig.FTP_HOST, FtpConfig.FTP_PORT,
-                FtpConfig.FTP_USERNAME, FtpConfig.FTP_PASSWORD);
+                FtpConfig.FTP_HOST.key(), FtpConfig.FTP_PORT.key(),
+                FtpConfig.FTP_USERNAME.key(), FtpConfig.FTP_PASSWORD.key());
         if (!result.isSuccess()) {
             throw new PrepareFailException(getPluginName(), PluginType.SINK, result.getMsg());
         }

File: seatunnel-connectors-v2/connector-file/connector-file-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/sink/OssFileSink.java
Patch:
@@ -42,9 +42,9 @@ public String getPluginName() {
     public void prepare(Config pluginConfig) throws PrepareFailException {
         super.prepare(pluginConfig);
         CheckResult result = CheckConfigUtil.checkAllExists(pluginConfig,
-                OssConfig.FILE_PATH,
-                OssConfig.BUCKET, OssConfig.ACCESS_KEY,
-                OssConfig.ACCESS_SECRET, OssConfig.BUCKET);
+                OssConfig.FILE_PATH.key(),
+                OssConfig.BUCKET.key(), OssConfig.ACCESS_KEY.key(),
+                OssConfig.ACCESS_SECRET.key(), OssConfig.BUCKET.key());
         if (!result.isSuccess()) {
             throw new PrepareFailException(getPluginName(), PluginType.SINK, result.getMsg());
         }

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/config/S3Conf.java
Patch:
@@ -42,10 +42,10 @@ private S3Conf(String hdfsNameKey) {
     }
 
     public static HadoopConf buildWithConfig(Config config) {
-        HadoopConf hadoopConf = new S3Conf(config.getString(S3Config.S3_BUCKET));
+        HadoopConf hadoopConf = new S3Conf(config.getString(S3Config.S3_BUCKET.key()));
         HashMap<String, String> s3Options = new HashMap<>();
-        s3Options.put("fs.s3n.awsAccessKeyId", config.getString(S3Config.S3_ACCESS_KEY));
-        s3Options.put("fs.s3n.awsSecretAccessKey", config.getString(S3Config.S3_SECRET_KEY));
+        s3Options.put("fs.s3n.awsAccessKeyId", config.getString(S3Config.S3_ACCESS_KEY.key()));
+        s3Options.put("fs.s3n.awsSecretAccessKey", config.getString(S3Config.S3_SECRET_KEY.key()));
         hadoopConf.setExtraOptions(s3Options);
         return hadoopConf;
     }

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/sink/S3FileSink.java
Patch:
@@ -42,8 +42,8 @@ public String getPluginName() {
     public void prepare(Config pluginConfig) throws PrepareFailException {
         super.prepare(pluginConfig);
         CheckResult result = CheckConfigUtil.checkAllExists(pluginConfig,
-                S3Config.FILE_PATH, S3Config.S3_BUCKET,
-                S3Config.S3_ACCESS_KEY, S3Config.S3_SECRET_KEY);
+                S3Config.FILE_PATH.key(), S3Config.S3_BUCKET.key(),
+                S3Config.S3_ACCESS_KEY.key(), S3Config.S3_SECRET_KEY.key());
         if (!result.isSuccess()) {
             throw new PrepareFailException(getPluginName(), PluginType.SINK, result.getMsg());
         }

File: seatunnel-connectors-v2/connector-file/connector-file-sftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sftp/sink/SftpFileSink.java
Patch:
@@ -41,8 +41,8 @@ public String getPluginName() {
     @Override
     public void prepare(Config pluginConfig) throws PrepareFailException {
         CheckResult result = CheckConfigUtil.checkAllExists(pluginConfig,
-                SftpConfig.SFTP_HOST, SftpConfig.SFTP_PORT,
-                SftpConfig.SFTP_USERNAME, SftpConfig.SFTP_PASSWORD);
+                SftpConfig.SFTP_HOST.key(), SftpConfig.SFTP_PORT.key(),
+                SftpConfig.SFTP_USERNAME.key(), SftpConfig.SFTP_PASSWORD.key());
         if (!result.isSuccess()) {
             throw new PrepareFailException(getPluginName(), PluginType.SINK, result.getMsg());
         }

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/utils/HiveMetaStoreProxy.java
Patch:
@@ -49,7 +49,7 @@ public static HiveMetaStoreProxy getInstance(Config config) {
         if (INSTANCE == null) {
             synchronized (HiveMetaStoreProxy.class) {
                 if (INSTANCE == null) {
-                    String metastoreUri = config.getString(HiveConfig.METASTORE_URI);
+                    String metastoreUri = config.getString(HiveConfig.METASTORE_URI.key());
                     INSTANCE = new HiveMetaStoreProxy(metastoreUri);
                 }
             }

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/source/ElasticsearchSourceReader.java
Patch:
@@ -24,7 +24,7 @@
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.client.EsRestClient;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.dto.source.ScrollResult;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.dto.source.SourceIndexInfo;
-import org.apache.seatunnel.connectors.seatunnel.elasticsearch.serialize.source.DeaultSeaTunnelRowDeserializer;
+import org.apache.seatunnel.connectors.seatunnel.elasticsearch.serialize.source.DefaultSeaTunnelRowDeserializer;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.serialize.source.ElasticsearchRecord;
 import org.apache.seatunnel.connectors.seatunnel.elasticsearch.serialize.source.SeaTunnelRowDeserializer;
 
@@ -58,7 +58,7 @@ public class ElasticsearchSourceReader implements SourceReader<SeaTunnelRow, Ela
     public ElasticsearchSourceReader(SourceReader.Context context, Config pluginConfig, SeaTunnelRowType rowTypeInfo) {
         this.context = context;
         this.pluginConfig = pluginConfig;
-        this.deserializer = new DeaultSeaTunnelRowDeserializer(rowTypeInfo);
+        this.deserializer = new DefaultSeaTunnelRowDeserializer(rowTypeInfo);
     }
 
     @Override

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/connection/SimpleJdbcConnectionProvider.java
Patch:
@@ -129,9 +129,6 @@ public Connection getOrEstablishConnection()
                 "No suitable driver found for " + jdbcOptions.getUrl(), "08001");
         }
 
-        //Auto commit is used by default
-        connection.setAutoCommit(true);
-
         return connection;
     }
 

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/inject/DoubleInjectFunction.java
Patch:
@@ -27,7 +27,7 @@ public void injectFields(PreparedStatement statement, int index, Object value) t
         if (value instanceof BigDecimal) {
             statement.setDouble(index, ((BigDecimal) value).doubleValue());
         } else {
-            statement.setDouble(index, (Double) value);
+            statement.setDouble(index, Double.parseDouble(value.toString()));
         }
     }
 

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/config/HttpConfig.java
Patch:
@@ -24,6 +24,7 @@
 
 public class HttpConfig {
     public static final String DEFAULT_FORMAT = "json";
+    public static final String BASIC = "Basic";
     public static final int DEFAULT_RETRY_BACKOFF_MULTIPLIER_MS = 100;
     public static final int DEFAULT_RETRY_BACKOFF_MAX_MS = 10000;
     public static final Option<String> URL = Options.key("url")

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/configuration/util/OptionValidationException.java
Patch:
@@ -34,6 +34,6 @@ public OptionValidationException(String message) {
     }
 
     public OptionValidationException(String formatMessage, Object... args) {
-        super(String.format(formatMessage, args));
+        super(SeaTunnelAPIErrorCode.OPTION_VALIDATION_FAILED, String.format(formatMessage, args));
     }
 }

File: seatunnel-connectors-v2/connector-http/connector-http-myhours/src/main/java/org/apache/seatunnel/connectors/seatunnel/myhours/source/config/MyHoursSourceParameter.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.connectors.seatunnel.http.config.HttpParameter;
+import org.apache.seatunnel.connectors.seatunnel.http.config.HttpRequestMethod;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
@@ -38,7 +39,7 @@ public void buildWithLoginConfig(Config pluginConfig) {
         // set url
         this.setUrl(MyHoursSourceConfig.AUTHORIZATION_URL);
         // set method
-        this.setMethod(MyHoursSourceConfig.POST);
+        this.setMethod(HttpRequestMethod.valueOf(MyHoursSourceConfig.POST));
         // set body
         Map<String, String> bodyParams = new HashMap<>();
         String email = pluginConfig.getString(MyHoursSourceConfig.EMAIL.key());

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/source/HttpSourceFactory.java
Patch:
@@ -23,6 +23,7 @@
 import org.apache.seatunnel.api.table.factory.TableSourceFactory;
 import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 import org.apache.seatunnel.connectors.seatunnel.http.config.HttpConfig;
+import org.apache.seatunnel.connectors.seatunnel.http.config.HttpRequestMethod;
 
 import com.google.auto.service.AutoService;
 
@@ -41,7 +42,7 @@ public OptionRule optionRule() {
                 .optional(HttpConfig.METHOD)
                 .optional(HttpConfig.HEADERS)
                 .optional(HttpConfig.PARAMS)
-                .conditional(Condition.of(HttpConfig.METHOD, "post"), HttpConfig.BODY)
+                .conditional(Condition.of(HttpConfig.METHOD, HttpRequestMethod.POST), HttpConfig.BODY)
                 .conditional(Condition.of(HttpConfig.FORMAT, "json"), SeaTunnelSchema.SCHEMA)
                 .optional(HttpConfig.FORMAT)
                 .optional(HttpConfig.POLL_INTERVAL_MILLS)

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/source/HttpSourceReader.java
Patch:
@@ -61,7 +61,7 @@ public void close() throws IOException {
     @Override
     public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
         try {
-            HttpResponse response = httpClient.execute(this.httpParameter.getUrl(), this.httpParameter.getMethod(), this.httpParameter.getHeaders(), this.httpParameter.getParams(), this.httpParameter.getBody());
+            HttpResponse response = httpClient.execute(this.httpParameter.getUrl(), this.httpParameter.getMethod().getMethod(), this.httpParameter.getHeaders(), this.httpParameter.getParams(), this.httpParameter.getBody());
             if (HttpResponse.STATUS_OK == response.getCode()) {
                 String content = response.getContent();
                 if (!Strings.isNullOrEmpty(content)) {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-starrocks-e2e/src/test/java/org/apache/seatunnel/e2e/connector/starrocks/StarRocksIT.java
Patch:
@@ -32,6 +32,7 @@
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.TestTemplate;
 import org.testcontainers.containers.Container;
 import org.testcontainers.containers.GenericContainer;
@@ -62,6 +63,7 @@
 import java.util.stream.Stream;
 
 @Slf4j
+@Disabled("disable because it can not success")
 public class StarRocksIT extends TestSuiteBase implements TestResource {
     private static final String DOCKER_IMAGE = "d87904488/starrocks-starter:2.2.1";
     private static final String DRIVER_CLASS = "com.mysql.cj.jdbc.Driver";

File: seatunnel-connectors-v2/connector-cdc/connector-cdc-base/src/main/java/org/seatunnel/connectors/cdc/base/source/event/CompletedSnapshotSplitReportEvent.java
Patch:
@@ -17,13 +17,14 @@
 
 package org.seatunnel.connectors.cdc.base.source.event;
 
+import org.apache.seatunnel.api.source.SourceEvent;
+
 import lombok.Data;
 
-import java.io.Serializable;
 import java.util.List;
 
 @Data
-public class CompletedSnapshotSplitReportEvent implements Serializable {
+public class CompletedSnapshotSplitReportEvent implements SourceEvent {
     private static final long serialVersionUID = 1L;
     List<SnapshotSplitWatermark> completedSnapshotSplitWatermarks;
 }

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/sink/StarRocksSink.java
Patch:
@@ -53,7 +53,7 @@ public String getPluginName() {
     @Override
     public void prepare(Config pluginConfig) throws PrepareFailException {
         this.pluginConfig = pluginConfig;
-        CheckResult result = CheckConfigUtil.checkAllExists(pluginConfig, NODE_URLS, DATABASE, TABLE, USERNAME, PASSWORD);
+        CheckResult result = CheckConfigUtil.checkAllExists(pluginConfig, NODE_URLS.key(), DATABASE.key(), TABLE.key(), USERNAME.key(), PASSWORD.key());
         if (!result.isSuccess()) {
             throw new PrepareFailException(getPluginName(), PluginType.SOURCE, result.getMsg());
         }

File: seatunnel-connectors-v2/connector-starrocks/src/main/java/org/apache/seatunnel/connectors/seatunnel/starrocks/client/StarRocksStreamLoadVisitor.java
Patch:
@@ -44,6 +44,7 @@ public class StarRocksStreamLoadVisitor {
     private final SinkConfig sinkConfig;
     private long pos;
     private static final String RESULT_FAILED = "Fail";
+    private static final String RESULT_SUCCESS = "Success";
     private static final String RESULT_LABEL_EXISTED = "Label Already Exists";
     private static final String LAEBL_STATE_VISIBLE = "VISIBLE";
     private static final String LAEBL_STATE_COMMITTED = "COMMITTED";
@@ -58,7 +59,7 @@ public StarRocksStreamLoadVisitor(SinkConfig sinkConfig, List<String> fieldNames
         this.fieldNames = fieldNames;
     }
 
-    public void doStreamLoad(StarRocksFlushTuple flushData) throws IOException {
+    public Boolean doStreamLoad(StarRocksFlushTuple flushData) throws IOException {
         String host = getAvailableHost();
         if (null == host) {
             throw new IOException("None of the host in `load_url` could be connected.");
@@ -106,6 +107,7 @@ public void doStreamLoad(StarRocksFlushTuple flushData) throws IOException {
             // has to block-checking the state to get the final result
             checkLabelState(host, flushData.getLabel());
         }
+        return RESULT_SUCCESS.equals(loadResult.get(keyStatus));
     }
 
     private String getAvailableHost() {

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-starrocks-e2e/src/test/java/org/apache/seatunnel/e2e/connector/starrocks/StarRocksIT.java
Patch:
@@ -170,7 +170,7 @@ public void startUp() throws Exception {
         // wait for starrocks fully start
         given().ignoreExceptions()
                 .await()
-                .atMost(180, TimeUnit.SECONDS)
+                .atMost(360, TimeUnit.SECONDS)
                 .untilAsserted(this::initializeJdbcConnection);
         initializeJdbcTable();
         batchInsertData();

File: seatunnel-connectors-v2/connector-redis/src/main/java/org/apache/seatunnel/connectors/seatunnel/redis/sink/RedisSink.java
Patch:
@@ -51,7 +51,7 @@ public String getPluginName() {
     @Override
     public void prepare(Config pluginConfig) throws PrepareFailException {
         this.pluginConfig = pluginConfig;
-        CheckResult result = CheckConfigUtil.checkAllExists(pluginConfig, RedisConfig.HOST, RedisConfig.PORT, RedisConfig.KEY, RedisConfig.DATA_TYPE);
+        CheckResult result = CheckConfigUtil.checkAllExists(pluginConfig, RedisConfig.HOST.key(), RedisConfig.PORT.key(), RedisConfig.KEY.key(), RedisConfig.DATA_TYPE.key());
         if (!result.isSuccess()) {
             throw new PrepareFailException(getPluginName(), PluginType.SINK, result.getMsg());
         }

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-starrocks-e2e/src/test/java/org/apache/seatunnel/e2e/connector/starrocks/StarRocksIT.java
Patch:
@@ -65,7 +65,7 @@
 public class StarRocksIT extends TestSuiteBase implements TestResource {
     private static final String DOCKER_IMAGE = "d87904488/starrocks-starter:2.2.1";
     private static final String DRIVER_CLASS = "com.mysql.cj.jdbc.Driver";
-    private static final String HOST = "e2e_starRocksdb";
+    private static final String HOST = "starrocks_e2e";
     private static final int SR_DOCKER_PORT = 9030;
     private static final int SR_PORT = 9033;
 

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/seatunnel/SeaTunnelContainer.java
Patch:
@@ -23,6 +23,7 @@
 import org.apache.seatunnel.e2e.common.container.ContainerExtendedFactory;
 import org.apache.seatunnel.e2e.common.container.TestContainer;
 import org.apache.seatunnel.e2e.common.container.TestContainerId;
+import org.apache.seatunnel.e2e.common.util.ContainerUtil;
 
 import com.google.auto.service.AutoService;
 import lombok.NoArgsConstructor;
@@ -52,7 +53,7 @@ public class SeaTunnelContainer extends AbstractTestContainer {
     public void startUp() throws Exception {
         server = new GenericContainer<>(getDockerImage())
             .withNetwork(NETWORK)
-            .withCommand(Paths.get(SEATUNNEL_HOME, "bin", SERVER_SHELL).toString())
+            .withCommand(ContainerUtil.adaptPathForWin(Paths.get(SEATUNNEL_HOME, "bin", SERVER_SHELL).toString()))
             .withNetworkAliases("server")
             .withExposedPorts()
             .withLogConsumer(new Slf4jLogConsumer(DockerLoggerFactory.getLogger("seatunnel-engine:" + JDK_DOCKER_IMAGE)))

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-cassandra-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/cassandra/CassandraIT.java
Patch:
@@ -241,7 +241,7 @@ private void clearSinkTable() {
         try {
             session.execute(SimpleStatement.builder(String.format("truncate table %s", SINK_TABLE)).setKeyspace(KEYSPACE).build());
         } catch (Exception e) {
-            throw new RuntimeException("Test clickhouse server image failed!", e);
+            throw new RuntimeException("Test Cassandra server image failed!", e);
         }
     }
 

File: seatunnel-connectors-v2/connector-google-sheets/src/main/java/org/apache/seatunnel/connectors/seatunnel/google/sheets/source/SheetsSource.java
Patch:
@@ -55,7 +55,7 @@ public String getPluginName() {
 
     @Override
     public void prepare(Config pluginConfig) throws PrepareFailException {
-        CheckResult checkResult = CheckConfigUtil.checkAllExists(pluginConfig, SheetsConfig.SERVICE_ACCOUNT_KEY, SheetsConfig.SHEET_ID, SheetsConfig.SHEET_NAME, SheetsConfig.RANGE, SeaTunnelSchema.SCHEMA.key());
+        CheckResult checkResult = CheckConfigUtil.checkAllExists(pluginConfig, SheetsConfig.SERVICE_ACCOUNT_KEY.key(), SheetsConfig.SHEET_ID.key(), SheetsConfig.SHEET_NAME.key(), SheetsConfig.RANGE.key(), SeaTunnelSchema.SCHEMA.key());
         if (!checkResult.isSuccess()) {
             throw new PrepareFailException(getPluginName(), PluginType.SOURCE, checkResult.getMsg());
         }

File: seatunnel-connectors-v2/connector-google-sheets/src/main/java/org/apache/seatunnel/connectors/seatunnel/google/sheets/source/SheetsSource.java
Patch:
@@ -55,13 +55,13 @@ public String getPluginName() {
 
     @Override
     public void prepare(Config pluginConfig) throws PrepareFailException {
-        CheckResult checkResult = CheckConfigUtil.checkAllExists(pluginConfig, SheetsConfig.SERVICE_ACCOUNT_KEY, SheetsConfig.SHEET_ID, SheetsConfig.SHEET_NAME, SheetsConfig.RANGE, SeaTunnelSchema.SCHEMA);
+        CheckResult checkResult = CheckConfigUtil.checkAllExists(pluginConfig, SheetsConfig.SERVICE_ACCOUNT_KEY, SheetsConfig.SHEET_ID, SheetsConfig.SHEET_NAME, SheetsConfig.RANGE, SeaTunnelSchema.SCHEMA.key());
         if (!checkResult.isSuccess()) {
             throw new PrepareFailException(getPluginName(), PluginType.SOURCE, checkResult.getMsg());
         }
         this.sheetsParameters = new SheetsParameters().buildWithConfig(pluginConfig);
-        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA)) {
-            Config schema = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA);
+        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA.key())) {
+            Config schema = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA.key());
             this.seaTunnelRowType = SeaTunnelSchema.buildWithConfig(schema).getSeaTunnelRowType();
         } else {
             this.seaTunnelRowType = SeaTunnelSchema.buildSimpleTextSchema();

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/ParquetReadStrategy.java
Patch:
@@ -202,7 +202,7 @@ public SeaTunnelRowType getSeaTunnelRowTypeInfo(HadoopConf hadoopConf, String pa
         Path filePath = new Path(path);
         ParquetMetadata metadata;
         try {
-            HadoopInputFile hadoopInputFile = HadoopInputFile.fromPath(filePath, getConfiguration());
+            HadoopInputFile hadoopInputFile = HadoopInputFile.fromPath(filePath, getConfiguration(hadoopConf));
             ParquetFileReader reader = ParquetFileReader.open(hadoopInputFile);
             metadata = reader.getFooter();
             reader.close();

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-udf/src/main/java/org/apache/seatunnel/flink/transform/UDF.java
Patch:
@@ -98,7 +98,7 @@ public void prepare(FlinkEnvironment prepareEnv) {
         functionNames = new ArrayList<>(properties.size());
 
         properties.forEach((k, v) -> {
-            classNames.add(String.valueOf(k));
+            classNames.add(String.valueOf(v));
             functionNames.add(String.valueOf(k));
         });
     }

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/dto/IndexInfo.java
Patch:
@@ -33,9 +33,9 @@ public class IndexInfo {
     private String type;
 
     public IndexInfo(Config pluginConfig) {
-        index = pluginConfig.getString(SinkConfig.INDEX);
-        if (pluginConfig.hasPath(SinkConfig.INDEX_TYPE)) {
-            type = pluginConfig.getString(SinkConfig.INDEX_TYPE);
+        index = pluginConfig.getString(SinkConfig.INDEX.key());
+        if (pluginConfig.hasPath(SinkConfig.INDEX_TYPE.key())) {
+            type = pluginConfig.getString(SinkConfig.INDEX_TYPE.key());
         }
     }
 

File: seatunnel-connectors-v2/connector-fake/src/test/java/org.apache.seatunnel.connectors.seatunnel.fake.source/FakeDataGeneratorTest.java
Patch:
@@ -43,7 +43,7 @@ public class FakeDataGeneratorTest {
     @ValueSource(strings = {"complex.schema.conf", "simple.schema.conf"})
     public void testComplexSchemaParse(String conf) throws FileNotFoundException, URISyntaxException {
         Config testConfig = getTestConfigFile(conf);
-        SeaTunnelSchema seaTunnelSchema = SeaTunnelSchema.buildWithConfig(testConfig.getConfig(SeaTunnelSchema.SCHEMA));
+        SeaTunnelSchema seaTunnelSchema = SeaTunnelSchema.buildWithConfig(testConfig.getConfig(SeaTunnelSchema.SCHEMA.key()));
         SeaTunnelRowType seaTunnelRowType = seaTunnelSchema.getSeaTunnelRowType();
         FakeConfig fakeConfig = FakeConfig.buildWithConfig(testConfig);
         FakeDataGenerator fakeDataGenerator = new FakeDataGenerator(seaTunnelSchema, fakeConfig);

File: seatunnel-connectors-v2/connector-file/connector-file-base-hadoop/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/hdfs/source/BaseHdfsFileSource.java
Patch:
@@ -59,7 +59,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 case CSV:
                 case TEXT:
                 case JSON:
-                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA);
+                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA.key());
                     SeaTunnelRowType userDefinedSchema = SeaTunnelSchema
                             .buildWithConfig(schemaConfig)
                             .getSeaTunnelRowType();

File: seatunnel-connectors-v2/connector-file/connector-file-ftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/ftp/source/FtpFileSource.java
Patch:
@@ -68,12 +68,12 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
         }
         // support user-defined schema
         // only json type support user-defined schema now
-        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA)) {
+        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA.key())) {
             switch (fileFormat) {
                 case CSV:
                 case TEXT:
                 case JSON:
-                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA);
+                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA.key());
                     SeaTunnelRowType userDefinedSchema = SeaTunnelSchema
                             .buildWithConfig(schemaConfig)
                             .getSeaTunnelRowType();

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/source/LocalFileSource.java
Patch:
@@ -65,12 +65,12 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
         // support user-defined schema
         FileFormat fileFormat = FileFormat.valueOf(pluginConfig.getString(LocalSourceConfig.FILE_TYPE).toUpperCase());
         // only json text csv type support user-defined schema now
-        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA)) {
+        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA.key())) {
             switch (fileFormat) {
                 case CSV:
                 case TEXT:
                 case JSON:
-                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA);
+                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA.key());
                     SeaTunnelRowType userDefinedSchema = SeaTunnelSchema
                             .buildWithConfig(schemaConfig)
                             .getSeaTunnelRowType();

File: seatunnel-connectors-v2/connector-file/connector-file-oss/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/oss/source/OssFileSource.java
Patch:
@@ -71,7 +71,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
                 case CSV:
                 case TEXT:
                 case JSON:
-                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA);
+                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA.key());
                     SeaTunnelRowType userDefinedSchema = SeaTunnelSchema
                             .buildWithConfig(schemaConfig)
                             .getSeaTunnelRowType();

File: seatunnel-connectors-v2/connector-file/connector-file-s3/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/s3/source/S3FileSource.java
Patch:
@@ -65,12 +65,12 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
         // support user-defined schema
         FileFormat fileFormat = FileFormat.valueOf(pluginConfig.getString(S3Config.FILE_TYPE).toUpperCase());
         // only json text csv type support user-defined schema now
-        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA)) {
+        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA.key())) {
             switch (fileFormat) {
                 case CSV:
                 case TEXT:
                 case JSON:
-                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA);
+                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA.key());
                     SeaTunnelRowType userDefinedSchema = SeaTunnelSchema
                             .buildWithConfig(schemaConfig)
                             .getSeaTunnelRowType();

File: seatunnel-connectors-v2/connector-file/connector-file-sftp/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sftp/source/SftpFileSource.java
Patch:
@@ -68,12 +68,12 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
         }
         // support user-defined schema
         // only json csv text type support user-defined schema now
-        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA)) {
+        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA.key())) {
             switch (fileFormat) {
                 case CSV:
                 case TEXT:
                 case JSON:
-                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA);
+                    Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA.key());
                     SeaTunnelRowType userDefinedSchema = SeaTunnelSchema
                             .buildWithConfig(schemaConfig)
                             .getSeaTunnelRowType();

File: seatunnel-connectors-v2/connector-neo4j/src/main/java/org/apache/seatunnel/connectors/seatunnel/neo4j/source/Neo4jSource.java
Patch:
@@ -66,13 +66,13 @@ public String getPluginName() {
     public void prepare(Config pluginConfig) throws PrepareFailException {
         neo4jSourceConfig.setDriverBuilder(prepareDriver(pluginConfig));
 
-        final CheckResult configCheck = CheckConfigUtil.checkAllExists(pluginConfig, KEY_QUERY, SeaTunnelSchema.SCHEMA);
+        final CheckResult configCheck = CheckConfigUtil.checkAllExists(pluginConfig, KEY_QUERY, SeaTunnelSchema.SCHEMA.key());
         if (!configCheck.isSuccess()) {
             throw new PrepareFailException(Neo4jSourceConfig.PLUGIN_NAME, PluginType.SOURCE, configCheck.getMsg());
         }
         neo4jSourceConfig.setQuery(pluginConfig.getString(KEY_QUERY));
 
-        this.rowType = SeaTunnelSchema.buildWithConfig(pluginConfig.getConfig(SeaTunnelSchema.SCHEMA)).getSeaTunnelRowType();
+        this.rowType = SeaTunnelSchema.buildWithConfig(pluginConfig.getConfig(SeaTunnelSchema.SCHEMA.key())).getSeaTunnelRowType();
     }
 
     @Override

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/PulsarSource.java
Patch:
@@ -152,7 +152,7 @@ public void prepare(Config config) throws PrepareFailException {
         setPartitionDiscoverer(config);
         setDeserialization(config);
 
-        if ((partitionDiscoverer instanceof TopicPatternDiscoverer)
+        if (partitionDiscoverer instanceof TopicPatternDiscoverer
             && partitionDiscoveryIntervalMs > 0
             && Boundedness.BOUNDED == stopCursor.getBoundedness()) {
             throw new IllegalArgumentException("Bounded streams do not support dynamic partition discovery.");
@@ -226,7 +226,7 @@ private void setPartitionDiscoverer(Config config) {
     private void setDeserialization(Config config) {
         String format = config.getString("format");
         // TODO: format SPI
-        SeaTunnelRowType rowType = SeaTunnelSchema.buildWithConfig(config.getConfig(SeaTunnelSchema.SCHEMA)).getSeaTunnelRowType();
+        SeaTunnelRowType rowType = SeaTunnelSchema.buildWithConfig(config.getConfig(SeaTunnelSchema.SCHEMA.key())).getSeaTunnelRowType();
         deserialization = (DeserializationSchema<T>) new JsonDeserializationSchema(false, false, rowType);
     }
 

File: seatunnel-connectors-v2/connector-redis/src/main/java/org/apache/seatunnel/connectors/seatunnel/redis/source/RedisSource.java
Patch:
@@ -57,8 +57,8 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
             throw new PrepareFailException(getPluginName(), PluginType.SOURCE, result.getMsg());
         }
         this.redisParameters.buildWithConfig(pluginConfig);
-        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA)) {
-            Config schema = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA);
+        if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA.key())) {
+            Config schema = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA.key());
             this.seaTunnelRowType = SeaTunnelSchema.buildWithConfig(schema).getSeaTunnelRowType();
         } else {
             this.seaTunnelRowType = SeaTunnelSchema.buildSimpleTextSchema();

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/source/HttpSourceReader.java
Patch:
@@ -61,7 +61,7 @@ public void close() throws IOException {
     @Override
     public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
         try {
-            HttpResponse response = httpClient.execute(this.httpParameter.getUrl(), this.httpParameter.getMethod(), this.httpParameter.getHeaders(), this.httpParameter.getParams());
+            HttpResponse response = httpClient.execute(this.httpParameter.getUrl(), this.httpParameter.getMethod(), this.httpParameter.getHeaders(), this.httpParameter.getParams(), this.httpParameter.getBody());
             if (HttpResponse.STATUS_OK == response.getCode()) {
                 String content = response.getContent();
                 if (!Strings.isNullOrEmpty(content)) {

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceIT.java
Patch:
@@ -392,7 +392,7 @@ public void testStreamJobRestoreIn3NodeWorkerDown() throws ExecutionException, I
             // shutdown on worker node
             node2.shutdown();
 
-            Awaitility.await().atMost(180000, TimeUnit.MILLISECONDS)
+            Awaitility.await().atMost(360000, TimeUnit.MILLISECONDS)
                 .untilAsserted(() -> {
                     // Wait job write all rows in file
                     Thread.sleep(2000);

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/Constant.java
Patch:
@@ -44,6 +44,8 @@ public class Constant {
 
     public static final String IMAP_RUNNING_JOB_STATE = "runningJobState";
 
+    public static final String IMAP_FINISHED_JOB_STATE = "finishedJobState";
+
     public static final String IMAP_STATE_TIMESTAMPS = "stateTimestamps";
 
     public static final String IMAP_OWNED_SLOT_PROFILES = "ownedSlotProfilesIMap";

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/CoordinatorServiceTest.java
Patch:
@@ -107,7 +107,7 @@ public void testClearCoordinatorService()
         clearCoordinatorServiceMethod.setAccessible(false);
 
         // because runningJobMasterMap is empty and we have no JobHistoryServer, so return finished.
-        Assertions.assertTrue(JobStatus.FINISHED.equals(coordinatorService.getJobStatus(jobId)));
+        Assertions.assertTrue(JobStatus.RUNNING.equals(coordinatorService.getJobStatus(jobId)));
         coordinatorServiceTest.shutdown();
     }
 
@@ -165,7 +165,7 @@ public void testJobRestoreWhenMasterNodeSwitch() throws InterruptedException {
         // because runningJobMasterMap is empty and we have no JobHistoryServer, so return finished.
         await().atMost(200000, TimeUnit.MILLISECONDS)
             .untilAsserted(
-                () -> Assertions.assertEquals(JobStatus.FINISHED, server2.getCoordinatorService().getJobStatus(jobId)));
+                () -> Assertions.assertEquals(JobStatus.CANCELED, server2.getCoordinatorService().getJobStatus(jobId)));
         instance2.shutdown();
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/config/TextFileSinkConfig.java
Patch:
@@ -130,12 +130,12 @@ public TextFileSinkConfig(@NonNull Config config, @NonNull SeaTunnelRowType seaT
         Map<String, Integer> columnsMap = new HashMap<>(seaTunnelRowTypeInfo.getFieldNames().length);
         String[] fieldNames = seaTunnelRowTypeInfo.getFieldNames();
         for (int i = 0; i < fieldNames.length; i++) {
-            columnsMap.put(fieldNames[i], i);
+            columnsMap.put(fieldNames[i].toLowerCase(), i);
         }
 
         // init sink column index and partition field index, we will use the column index to found the data in SeaTunnelRow
         this.sinkColumnsIndexInRow = this.sinkColumnList.stream()
-            .map(columnsMap::get)
+            .map(column -> columnsMap.get(column.toLowerCase()))
             .collect(Collectors.toList());
 
         if (!CollectionUtils.isEmpty(this.partitionFieldList)) {

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/OrcWriteStrategy.java
Patch:
@@ -99,6 +99,7 @@ public void finishAndCloseFile() {
             }
             needMoveFiles.put(k, getTargetLocation(k));
         });
+        this.beingWrittenWriter.clear();
     }
 
     private Writer getOrCreateWriter(@NonNull String filePath) {
@@ -165,7 +166,7 @@ private TypeDescription buildFieldWithRowType(SeaTunnelDataType<?> type) {
                 TypeDescription struct = TypeDescription.createStruct();
                 SeaTunnelDataType<?>[] fieldTypes = ((SeaTunnelRowType) type).getFieldTypes();
                 for (int i = 0; i < fieldTypes.length; i++) {
-                    struct.addField(((SeaTunnelRowType) type).getFieldName(i), buildFieldWithRowType(fieldTypes[i]));
+                    struct.addField(((SeaTunnelRowType) type).getFieldName(i).toLowerCase(), buildFieldWithRowType(fieldTypes[i]));
                 }
                 return struct;
             case NULL:
@@ -179,7 +180,7 @@ private TypeDescription buildSchemaWithRowType() {
         TypeDescription schema = TypeDescription.createStruct();
         for (Integer i : sinkColumnsIndexInRow) {
             TypeDescription fieldType = buildFieldWithRowType(seaTunnelRowType.getFieldType(i));
-            schema.addField(seaTunnelRowType.getFieldName(i), fieldType);
+            schema.addField(seaTunnelRowType.getFieldName(i).toLowerCase(), fieldType);
         }
         return schema;
     }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/configuration/Option.java
Patch:
@@ -42,7 +42,7 @@ public class Option<T> {
      */
     String description = "";
 
-    Option(String key, TypeReference<T> typeReference, T defaultValue) {
+    public Option(String key, TypeReference<T> typeReference, T defaultValue) {
         this.key = key;
         this.typeReference = typeReference;
         this.defaultValue = defaultValue;

File: seatunnel-api/src/test/java/org/apache/seatunnel/api/configuration/util/OptionRuleTest.java
Patch:
@@ -66,7 +66,7 @@ public void testBuildSuccess() {
     @Test
     public void testOptionalException() {
         Assertions.assertThrows(OptionValidationException.class,
-            () -> OptionRule.builder().optional(TEST_NUM, TEST_MODE, TEST_PORTS).build(),
+            () -> OptionRule.builder().required(TEST_NUM, TEST_MODE, TEST_PORTS).build(),
             "Optional option 'option.ports' should have default value.");
     }
 

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/connector-jdbc-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/jdbc/JdbcGreenplumIT.java
Patch:
@@ -158,6 +158,9 @@ public void closeGreenplumContainer() throws SQLException {
         if (jdbcConnection != null) {
             jdbcConnection.close();
         }
+        if (greenplumServer != null) {
+            greenplumServer.stop();
+        }
     }
 
     @Override

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/connector-jdbc-spark-e2e/src/test/java/org/apache/seatunnel/e2e/spark/v2/jdbc/JdbcGreenplumIT.java
Patch:
@@ -159,6 +159,9 @@ public void closeGreenplumContainer() throws SQLException {
         if (jdbcConnection != null) {
             jdbcConnection.close();
         }
+        if (greenplumServer != null) {
+            greenplumServer.stop();
+        }
     }
 
     @Override

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/connector-jdbc-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/jdbc/JdbcGreenplumIT.java
Patch:
@@ -79,7 +79,7 @@ public void startGreenplumContainer() throws ClassNotFoundException, SQLExceptio
             .await()
             .atLeast(100, TimeUnit.MILLISECONDS)
             .pollInterval(500, TimeUnit.MILLISECONDS)
-            .atMost(180, TimeUnit.SECONDS)
+            .atMost(360, TimeUnit.SECONDS)
             .untilAsserted(() -> initializeJdbcConnection());
         initializeJdbcTable();
         batchInsertData();

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/connector-jdbc-spark-e2e/src/test/java/org/apache/seatunnel/e2e/spark/v2/jdbc/JdbcGreenplumIT.java
Patch:
@@ -80,7 +80,7 @@ public void startGreenplumContainer() throws ClassNotFoundException, SQLExceptio
             .await()
             .atLeast(100, TimeUnit.MILLISECONDS)
             .pollInterval(500, TimeUnit.MILLISECONDS)
-            .atMost(180, TimeUnit.SECONDS)
+            .atMost(360, TimeUnit.SECONDS)
             .untilAsserted(() -> initializeJdbcConnection());
         initializeJdbcTable();
         batchInsertData();

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeSourceSplitEnumerator.java
Patch:
@@ -139,7 +139,7 @@ private void assignPendingSplits() {
                 // Mark pending splits as already assigned
                 assignedSplits.addAll(pendingAssignmentForReader);
                 // Assign pending splits to reader
-                LOG.info("Assigning splits to readers {}", pendingAssignmentForReader);
+                LOG.info("Assigning splits to readers {} {}", pendingReader, pendingAssignmentForReader);
                 enumeratorContext.assignSplit(pendingReader, new ArrayList<>(pendingAssignmentForReader));
                 enumeratorContext.signalNoMoreSplits(pendingReader);
             }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/JdbcSource.java
Patch:
@@ -86,7 +86,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
 
         inputFormat = new JdbcInputFormat(
             jdbcConnectionProvider,
-            jdbcDialect.getRowConverter(),
+            jdbcDialect,
             typeInfo,
             query,
             0,
@@ -147,7 +147,7 @@ private SeaTunnelRowType initTableField(Connection conn) {
         } catch (Exception e) {
             LOG.warn("get row type info exception", e);
         }
-        return new SeaTunnelRowType(fieldNames.toArray(new String[fieldNames.size()]), seaTunnelDataTypes.toArray(new SeaTunnelDataType<?>[seaTunnelDataTypes.size()]));
+        return new SeaTunnelRowType(fieldNames.toArray(new String[0]), seaTunnelDataTypes.toArray(new SeaTunnelDataType<?>[0]));
     }
 
     private PartitionParameter initPartitionParameter(String columnName, Connection connection) throws SQLException {

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceIT.java
Patch:
@@ -215,7 +215,7 @@ public void testStreamJobRunOkIn3Node() throws ExecutionException, InterruptedEx
                 return clientJobProxy.waitForJobComplete();
             });
 
-            Awaitility.await().atMost(60000, TimeUnit.MILLISECONDS)
+            Awaitility.await().atMost(3, TimeUnit.MINUTES)
                 .untilAsserted(() -> {
                     Thread.sleep(2000);
                     System.out.println(FileUtils.getFileLineNumberFromDir(testResources.getLeft()));

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/parse/JobConfigParser.java
Patch:
@@ -123,6 +123,7 @@ public ImmutablePair<List<Action>, Set<URL>> parse() {
             complexAnalyze(sourceConfigs, transformConfigs, sinkConfigs);
         }
         actions.forEach(this::addCommonPluginJarsToAction);
+        jarUrlsSet.addAll(commonPluginJars);
         return new ImmutablePair<>(actions, jarUrlsSet);
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManager.java
Patch:
@@ -41,7 +41,6 @@
 import org.apache.seatunnel.engine.server.task.statemachine.SeaTunnelTaskState;
 import org.apache.seatunnel.engine.server.utils.NodeEngineUtil;
 
-import com.hazelcast.cluster.Address;
 import com.hazelcast.map.IMap;
 import com.hazelcast.spi.impl.NodeEngine;
 import com.hazelcast.spi.impl.operationservice.impl.InvocationFuture;
@@ -218,8 +217,6 @@ public void acknowledgeTask(TaskAcknowledgeOperation ackOperation) {
     }
 
     protected InvocationFuture<?> sendOperationToMemberNode(TaskOperation operation) {
-        Address address =
-            jobMaster.queryTaskGroupAddress(operation.getTaskLocation().getTaskGroupLocation().getTaskGroupId());
         return NodeEngineUtil.sendOperationToMemberNode(nodeEngine, operation,
             jobMaster.queryTaskGroupAddress(operation.getTaskLocation().getTaskGroupLocation().getTaskGroupId()));
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/CheckpointFinishedOperation.java
Patch:
@@ -76,9 +76,9 @@ protected void readInternal(ObjectDataInput in) throws IOException {
     public void run() throws Exception {
         SeaTunnelServer server = getService();
         RetryUtils.retryWithException(() -> {
-            Task task = server.getTaskExecutionService().getExecutionContext(taskLocation.getTaskGroupLocation())
-                .getTaskGroup().getTask(taskLocation.getTaskID());
             try {
+                Task task = server.getTaskExecutionService().getExecutionContext(taskLocation.getTaskGroupLocation())
+                    .getTaskGroup().getTask(taskLocation.getTaskID());
                 if (successful) {
                     task.notifyCheckpointComplete(checkpointId);
                 } else {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/TaskLocation.java
Patch:
@@ -95,19 +95,22 @@ public int getClassId() {
     public void writeData(ObjectDataOutput out) throws IOException {
         out.writeObject(taskGroupLocation);
         out.writeLong(taskID);
+        out.writeInt(index);
     }
 
     @Override
     public void readData(ObjectDataInput in) throws IOException {
         taskGroupLocation = in.readObject();
         taskID = in.readLong();
+        index = in.readInt();
     }
 
     @Override
     public String toString() {
         return "TaskLocation{" +
             "taskGroupLocation=" + taskGroupLocation +
             ", taskID=" + taskID +
+            ", index=" + index +
             '}';
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SinkAggregatedCommitterTask.java
Patch:
@@ -117,6 +117,7 @@ public ProgressState call() throws Exception {
         return progress.toState();
     }
 
+    @SuppressWarnings("checkstyle:MagicNumber")
     protected void stateProcess() throws Exception {
         switch (currState) {
             case INIT:
@@ -142,6 +143,8 @@ protected void stateProcess() throws Exception {
             case RUNNING:
                 if (prepareCloseStatus) {
                     currState = PREPARE_CLOSE;
+                } else {
+                    Thread.sleep(100);
                 }
                 break;
             case PREPARE_CLOSE:

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/IntermediateQueueFlowLifeCycle.java
Patch:
@@ -26,6 +26,7 @@
 
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.TimeUnit;
 
 public class IntermediateQueueFlowLifeCycle extends AbstractFlowLifeCycle implements OneInputFlowLifeCycle<Record<?>>,
         OneOutputFlowLifeCycle<Record<?>> {
@@ -48,10 +49,11 @@ public void received(Record<?> record) {
         }
     }
 
+    @SuppressWarnings("checkstyle:MagicNumber")
     @Override
     public void collect(Collector<Record<?>> collector) throws Exception {
         while (true) {
-            Record<?> record = queue.poll();
+            Record<?> record = queue.poll(100, TimeUnit.MILLISECONDS);
             if (record != null) {
                 handleRecord(record, collector::collect);
             } else {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/SinkFlowLifeCycle.java
Patch:
@@ -130,10 +130,10 @@ public void received(Record<?> record) {
                         writer.abortPrepare();
                         throw e;
                     }
+                    List<StateT> states = writer.snapshotState(barrier.getId());
                     if (!writerStateSerializer.isPresent()) {
                         runningTask.addState(barrier, sinkAction.getId(), Collections.emptyList());
                     } else {
-                        List<StateT> states = writer.snapshotState(barrier.getId());
                         runningTask.addState(barrier, sinkAction.getId(), serializeStates(writerStateSerializer.get(), states));
                     }
                     if (containAggCommitter) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/GetTaskGroupAddressOperation.java
Patch:
@@ -30,6 +30,7 @@
 import com.hazelcast.spi.impl.operationservice.Operation;
 
 import java.io.IOException;
+import java.util.Objects;
 
 public class GetTaskGroupAddressOperation extends Operation implements IdentifiedDataSerializable {
 
@@ -50,7 +51,7 @@ public void run() throws Exception {
         response = RetryUtils.retryWithException(() -> server.getCoordinatorService().getJobMaster(taskLocation.getJobId())
                 .queryTaskGroupAddress(taskLocation.getTaskGroupLocation().getTaskGroupId()),
             new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-                exception -> exception instanceof Exception, Constant.OPERATION_RETRY_SLEEP));
+                Objects::nonNull, Constant.OPERATION_RETRY_SLEEP));
     }
 
     @Override

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/JdbcStarRocksdbIT.java
Patch:
@@ -66,7 +66,6 @@ public class JdbcStarRocksdbIT extends AbstractJdbcIT {
         "PROPERTIES (\n" +
         "\"replication_num\" = \"1\",\n" +
         "\"in_memory\" = \"false\"," +
-        "\"in_memory\" = \"false\"," +
         "\"storage_format\" = \"DEFAULT\"" +
         ")";
 
@@ -92,7 +91,6 @@ public class JdbcStarRocksdbIT extends AbstractJdbcIT {
         "PROPERTIES (\n" +
         "\"replication_num\" = \"1\",\n" +
         "\"in_memory\" = \"false\"," +
-        "\"in_memory\" = \"false\"," +
         "\"storage_format\" = \"DEFAULT\"" +
         ")";
 

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/flink/AbstractTestFlinkContainer.java
Patch:
@@ -75,6 +75,7 @@ public void startUp() throws Exception {
                 .withRegEx(".*Starting the resource manager.*")
                 .withStartupTimeout(Duration.ofMinutes(2)));
         copySeaTunnelStarterToContainer(jobManager);
+        copySeaTunnelStarterLoggingToContainer(jobManager);
 
         taskManager = new GenericContainer<>(dockerImage)
             .withCommand("taskmanager")

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/spark/AbstractTestSparkContainer.java
Patch:
@@ -57,6 +57,7 @@ public void startUp() throws Exception {
                 .withRegEx(".*Master: Starting Spark master at.*")
                 .withStartupTimeout(Duration.ofMinutes(2)));
         copySeaTunnelStarterToContainer(master);
+        copySeaTunnelStarterLoggingToContainer(master);
 
         // In most case we can just use standalone mode to execute a spark job, if we want to use cluster mode, we need to
         // start a worker.

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/ExceptionUtils.java
Patch:
@@ -33,7 +33,6 @@ public static String getMessage(Throwable e) {
             sw.flush();
             return sw.toString();
         } catch (Exception e1) {
-            e1.printStackTrace();
             throw new RuntimeException("Failed to print exception logs", e1);
         }
     }

File: seatunnel-e2e/seatunnel-engine-e2e/connector-seatunnel-e2e-base/src/test/java/org/apache/seatunnel/engine/e2e/ClusterFaultToleranceIT.java
Patch:
@@ -144,7 +144,6 @@ public void testBatchJobRunOkIn3Node() throws ExecutionException, InterruptedExc
      * @param jobMode      jobMode
      * @param rowNumber    row.num per FakeSource parallelism
      * @param parallelism  FakeSource parallelism
-     * @return
      */
     private ImmutablePair<String, String> createTestResources(@NonNull String testCaseName, @NonNull JobMode jobMode,
                                                               long rowNumber, int parallelism) {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/source/JdbcSourceSplitEnumerator.java
Patch:
@@ -98,8 +98,8 @@ private void assignPendingSplits() {
                 // Assign pending splits to reader
                 LOG.info("Assigning splits to readers {}", pendingAssignmentForReader);
                 enumeratorContext.assignSplit(pendingReader, new ArrayList<>(pendingAssignmentForReader));
-                enumeratorContext.signalNoMoreSplits(pendingReader);
             }
+            enumeratorContext.signalNoMoreSplits(pendingReader);
         }
     }
 

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/Constant.java
Patch:
@@ -36,7 +36,7 @@ public class Constant {
 
     public static final String HAZELCAST_SEATUNNEL_DEFAULT_YAML = "seatunnel.yaml";
 
-    public static final int OPERATION_RETRY_TIME = 5;
+    public static final int OPERATION_RETRY_TIME = 10;
 
     public static final int OPERATION_RETRY_SLEEP = 2000;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -381,6 +381,7 @@ protected void cleanPendingCheckpoint(CheckpointFailureReason failureReason) {
             );
             // TODO: clear related future & scheduler task
             pendingCheckpoints.clear();
+            pendingCounter.set(0);
             scheduler.shutdownNow();
             scheduler = Executors.newScheduledThreadPool(
                 1, runnable -> {

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-hdfs/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/hdfs/HdfsStorage.java
Patch:
@@ -184,7 +184,7 @@ public List<PipelineState> getCheckpointsByJobIdAndPipelineId(String jobId, Stri
 
         List<PipelineState> pipelineStates = new ArrayList<>();
         fileNames.forEach(file -> {
-            String filePipelineId = file.split(FILE_NAME_SPLIT)[FILE_NAME_PIPELINE_ID_INDEX];
+            String filePipelineId = getPipelineIdByFileName(file);
             if (pipelineId.equals(filePipelineId)) {
                 try {
                     pipelineStates.add(readPipelineState(file, jobId));

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/FlinkEnvironment.java
Patch:
@@ -184,7 +184,9 @@ private void createStreamTableEnvironment() {
     }
 
     private void createStreamEnvironment() {
-        environment = StreamExecutionEnvironment.getExecutionEnvironment();
+        Configuration configuration = new Configuration();
+        EnvironmentUtil.initConfiguration(config, configuration);
+        environment = StreamExecutionEnvironment.getExecutionEnvironment(configuration);
         setTimeCharacteristic();
 
         setCheckpoint();

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/config/EnvironmentFactory.java
Patch:
@@ -44,7 +44,7 @@ public synchronized ENVIRONMENT getEnvironment() {
         Config envConfig = config.getConfig("env");
         ENVIRONMENT env = newEnvironment();
         env.setConfig(envConfig)
-            .setJobMode(getJobMode(envConfig)).prepare();
+            .setJobMode(getJobMode(config)).prepare();
         return env;
     }
 
@@ -66,8 +66,9 @@ protected boolean checkIsContainHive() {
         return false;
     }
 
-    private JobMode getJobMode(Config envConfig) {
+    public static JobMode getJobMode(Config config) {
         JobMode jobMode;
+        Config envConfig = config.getConfig("env");
         if (envConfig.hasPath("job.mode")) {
             jobMode = envConfig.getEnum(JobMode.class, "job.mode");
         } else {

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/FlinkStarter.java
Patch:
@@ -33,7 +33,7 @@
 public class FlinkStarter implements Starter {
 
     private static final String APP_NAME = SeatunnelFlink.class.getName();
-    private static final String APP_JAR_NAME = "seatunnel-flink-starter.jar";
+    public static final String APP_JAR_NAME = "seatunnel-flink-starter.jar";
 
     /**
      * SeaTunnel parameters, used by SeaTunnel application. e.g. `-c config.conf`

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/TestContainerId.java
Patch:
@@ -27,7 +27,7 @@
 @Getter
 public enum TestContainerId {
     FLINK_1_13(FLINK, "1.13.6"),
-    SPARK_2_4(SPARK, "2.4.3"),
+    SPARK_2_4(SPARK, "2.4.6"),
     SEATUNNEL(EngineType.SEATUNNEL, "2.2.0");
 
     private final EngineType engineType;

File: seatunnel-connectors-v2/connector-hudi/src/main/java/org/apache/seatunnel/connectors/seatunnel/hudi/source/HudiSourceSplitEnumerator.java
Patch:
@@ -112,7 +112,7 @@ private void assignSplit(Collection<Integer> taskIDList) {
     }
 
     private static int getSplitOwner(String tp, int numReaders) {
-        return tp.hashCode() % numReaders;
+        return (tp.hashCode() & Integer.MAX_VALUE) % numReaders;
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/YamlSeaTunnelDomConfigProcessor.java
Patch:
@@ -34,7 +34,6 @@
 import org.w3c.dom.Node;
 
 public class YamlSeaTunnelDomConfigProcessor extends AbstractDomConfigProcessor {
-
     private static final ILogger LOGGER = Logger.getLogger(YamlSeaTunnelDomConfigProcessor.class);
 
     private final SeaTunnelConfig config;

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-clickhouse-e2e/src/test/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/ClickhouseIT.java
Patch:
@@ -36,6 +36,7 @@
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.TestTemplate;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -73,6 +74,7 @@
 
 import scala.Tuple2;
 
+@Disabled("Temporary fast fix, reason1: Transactions are not supported. reason2: Invalid boolean value, should be true or false controlled by setting bool_true_representation and bool_false_representation")
 public class ClickhouseIT extends TestSuiteBase implements TestResource {
     private static final Logger LOG = LoggerFactory.getLogger(ClickhouseIT.class);
     private static final String CLICKHOUSE_DOCKER_IMAGE = "yandex/clickhouse-server:latest";

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/command/BaseTaskExecuteCommand.java
Patch:
@@ -24,7 +24,6 @@
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.common.config.DeployMode;
-import org.apache.seatunnel.core.base.utils.AsciiArtUtils;
 import org.apache.seatunnel.core.base.utils.CompressionUtils;
 
 import lombok.extern.slf4j.Slf4j;
@@ -96,7 +95,8 @@ protected final void close(List<? extends Plugin<E>>... plugins) {
     protected void showAsciiLogo() {
         String printAsciiLogo = System.getenv("SEATUNNEL_PRINT_ASCII_LOGO");
         if ("true".equalsIgnoreCase(printAsciiLogo)) {
-            AsciiArtUtils.printAsciiArt(Constants.LOGO);
+            log.info('\n' + Constants.ST_LOGO);
+            log.info(Constants.COPYRIGHT_LINE);
         }
     }
 
@@ -145,5 +145,4 @@ private void deployModeCheck() {
             log.info("succeeded to decompress plugins.tar.gz");
         }
     }
-
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/commit/FileSinkAggregatedCommitter.java
Patch:
@@ -83,6 +83,7 @@ public FileAggregatedCommitInfo combine(List<FileCommitInfo> commitInfos) {
      */
     @Override
     public void abort(List<FileAggregatedCommitInfo> aggregatedCommitInfos) throws Exception {
+        log.info("rollback aggregate commit");
         if (aggregatedCommitInfos == null || aggregatedCommitInfos.size() == 0) {
             return;
         }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/WriteStrategy.java
Patch:
@@ -72,4 +72,6 @@ public interface WriteStrategy extends Transaction, Serializable {
      * when a transaction is triggered, release resources
      */
     void finishAndCloseFile();
+
+    long getCheckpointId();
 }

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/server/ServerConfigOptions.java
Patch:
@@ -35,7 +35,7 @@ public class ServerConfigOptions {
 
     public static final Option<Integer> CHECKPOINT_INTERVAL = Options.key("interval").intType().defaultValue(300000).withDescription("The interval (in milliseconds) between two consecutive checkpoints.");
 
-    public static final Option<Integer> CHECKPOINT_TIMEOUT = Options.key("timeout").intType().defaultValue(300000).withDescription("The timeout (in milliseconds) for a checkpoint.");
+    public static final Option<Integer> CHECKPOINT_TIMEOUT = Options.key("timeout").intType().defaultValue(30000).withDescription("The timeout (in milliseconds) for a checkpoint.");
 
     public static final Option<Integer> CHECKPOINT_MAX_CONCURRENT = Options.key("max-concurrent").intType().defaultValue(1).withDescription("The maximum number of concurrent checkpoints.");
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/SeaTunnelServer.java
Patch:
@@ -203,6 +203,9 @@ public boolean isMasterNode() {
                 return nodeEngine.getMasterAddress().equals(nodeEngine.getThisAddress());
             }, new RetryUtils.RetryMaterial(20, true,
                 exception -> exception instanceof NullPointerException && isRunning, 1000));
+        } catch (InterruptedException e) {
+            LOGGER.info("master node check interrupted");
+            return false;
         } catch (Exception e) {
             throw new SeaTunnelEngineException("cluster have no master node", e);
         }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/SeaTunnelServerStarter.java
Patch:
@@ -36,14 +36,14 @@ public static HazelcastInstanceImpl createHazelcastInstance(String clusterName)
         return ((HazelcastInstanceProxy) HazelcastInstanceFactory.newHazelcastInstance(
             seaTunnelConfig.getHazelcastConfig(),
             HazelcastInstanceFactory.createInstanceName(seaTunnelConfig.getHazelcastConfig()),
-            new SeaTunnelNodeContext(new SeaTunnelConfig()))).getOriginal();
+            new SeaTunnelNodeContext(seaTunnelConfig))).getOriginal();
     }
 
     public static HazelcastInstanceImpl createHazelcastInstance() {
         SeaTunnelConfig seaTunnelConfig = ConfigProvider.locateAndGetSeaTunnelConfig();
         return ((HazelcastInstanceProxy) HazelcastInstanceFactory.newHazelcastInstance(
             seaTunnelConfig.getHazelcastConfig(),
             HazelcastInstanceFactory.createInstanceName(seaTunnelConfig.getHazelcastConfig()),
-            new SeaTunnelNodeContext(new SeaTunnelConfig()))).getOriginal();
+            new SeaTunnelNodeContext(seaTunnelConfig))).getOriginal();
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointFailureReason.java
Patch:
@@ -19,7 +19,7 @@
 
 public enum CheckpointFailureReason {
 
-    TASK_FAILURE("Task has failed."),
+    PIPELINE_END("Pipeline turn to end state."),
     CHECKPOINT_EXPIRED("Checkpoint expired before completing."),
     CHECKPOINT_COORDINATOR_COMPLETED("CheckpointCoordinator completed."),
     CHECKPOINT_COORDINATOR_SHUTDOWN("CheckpointCoordinator shutdown.");

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalVertex.java
Patch:
@@ -242,7 +242,6 @@ private TaskGroupImmutableInformation getTaskGroupImmutableInformation() {
 
     private boolean turnToEndState(@NonNull ExecutionState endState) {
         synchronized (this) {
-            jobMaster.getCheckpointManager().listenTaskGroup(taskGroupLocation, endState);
             // consistency check
             ExecutionState currentState = (ExecutionState) runningJobStateIMap.get(taskGroupLocation);
             if (currentState.isEndState()) {
@@ -327,7 +326,7 @@ public void cancel() {
     private void noticeTaskExecutionServiceCancel() {
         int i = 0;
         // In order not to generate uncontrolled tasks, We will try again until the taskFuture is completed
-        while (!taskFuture.isDone()) {
+        while (!taskFuture.isDone() && nodeEngine.getClusterService().getMember(getCurrentExecutionAddress()) != null) {
             try {
                 i++;
                 LOGGER.info(String.format("send cancel %s operator to member %s", taskFullName, getCurrentExecutionAddress()));

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/SubPlan.java
Patch:
@@ -381,6 +381,8 @@ public void restorePipelineState() {
             restorePipeline();
         } else if (PipelineStatus.CANCELING.equals(getPipelineState())) {
             cancelPipelineTasks();
+        } else if (PipelineStatus.RUNNING.equals(getPipelineState())) {
+            jobMaster.getCheckpointManager().reportedPipelineRunning(this.getPipelineLocation().getPipelineId());
         }
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManagerTest.java
Patch:
@@ -69,10 +69,9 @@ public void testHAByIMapCheckpointIDCounter() throws CheckpointStorageException
             planMap,
             new CheckpointConfig());
         Assertions.assertTrue(checkpointManager.isCompletedPipeline(1));
-        CompletableFuture<Void> future = checkpointManager.listenPipeline(1, PipelineStatus.FINISHED);
-        future.join();
+        checkpointManager.listenPipeline(1, PipelineStatus.FINISHED);
         Assertions.assertNull(checkpointIdMap.get(1));
-        future = checkpointManager.shutdown(JobStatus.FINISHED);
+        CompletableFuture<Void> future = checkpointManager.shutdown(JobStatus.FINISHED);
         future.join();
         Assertions.assertTrue(checkpointStorage.getAllCheckpoints(jobId + "").isEmpty());
     }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/FileSystemType.java
Patch:
@@ -24,6 +24,7 @@ public enum FileSystemType implements Serializable {
     LOCAL("LocalFile"),
     OSS("OssFile"),
     FTP("FtpFile"),
+    SFTP("SftpFile"),
     S3("S3File");
 
     private final String fileSystemPluginName;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSplitEnumeratorTask.java
Patch:
@@ -126,6 +126,7 @@ public ProgressState call() throws Exception {
     public void triggerBarrier(Barrier barrier) throws Exception {
         if (barrier.prepareClose()) {
             this.currState = PREPARE_CLOSE;
+            this.prepareCloseBarrierId.set(barrier.getId());
         }
         final long barrierId = barrier.getId();
         Serializable snapshotState = null;
@@ -273,15 +274,15 @@ public Set<URL> getJarsUrl() {
     @Override
     public void notifyCheckpointComplete(long checkpointId) throws Exception {
         enumerator.notifyCheckpointComplete(checkpointId);
-        if (prepareCloseStatus) {
+        if (currState == PREPARE_CLOSE && prepareCloseBarrierId.get() == checkpointId) {
             closeCall();
         }
     }
 
     @Override
     public void notifyCheckpointAborted(long checkpointId) throws Exception {
         enumerator.notifyCheckpointAborted(checkpointId);
-        if (prepareCloseStatus) {
+        if (currState == PREPARE_CLOSE && prepareCloseBarrierId.get() == checkpointId) {
             closeCall();
         }
     }

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/SeaTunnelClientInstance.java
Patch:
@@ -26,4 +26,6 @@ public interface SeaTunnelClientInstance {
     JobExecutionEnvironment createExecutionContext(String filePath, JobConfig config);
 
     JobClient createJobClient();
+
+    void close();
 }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/job/Job.java
Patch:
@@ -33,5 +33,4 @@ public interface Job {
 
     JobStatus waitForJobComplete();
 
-    void close();
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/PendingCheckpoint.java
Patch:
@@ -30,6 +30,7 @@
 import java.time.Instant;
 import java.util.List;
 import java.util.Map;
+import java.util.Objects;
 import java.util.Set;
 import java.util.concurrent.CompletableFuture;
 
@@ -125,7 +126,7 @@ public void acknowledgeTask(TaskLocation taskLocation, List<ActionSubtaskState>
             if (actionState == null) {
                 return;
             }
-            stateSize += state.getState().stream().map(s -> s.length).count();
+            stateSize += state.getState().stream().filter(Objects::nonNull).map(s -> s.length).count();
             actionState.reportState(state.getIndex(), state);
         }
         statistics.reportSubtaskStatistics(new SubtaskStatistics(

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -225,7 +225,7 @@ private void scheduleTriggerPendingCheckpoint(long delayMills) {
         scheduler.schedule(this::tryTriggerPendingCheckpoint, delayMills, TimeUnit.MILLISECONDS);
     }
 
-    private void tryTriggerPendingCheckpoint() {
+    protected void tryTriggerPendingCheckpoint() {
         synchronized (lock) {
             final long currentTimestamp = Instant.now().toEpochMilli();
             if (currentTimestamp - latestTriggerTimestamp.get() >= coordinatorConfig.getCheckpointInterval() &&
@@ -282,7 +282,7 @@ private void startTriggerPendingCheckpoint(CompletableFuture<PendingCheckpoint>
                     if (pendingCheckpoints.get(pendingCheckpoint.getCheckpointId()) != null && !pendingCheckpoint.isFullyAcknowledged()) {
                         if (tolerableFailureCheckpoints-- <= 0) {
                             cleanPendingCheckpoint(CheckpointFailureReason.CHECKPOINT_EXPIRED);
-                            // TODO: notify job master to restore the pipeline.
+                            checkpointManager.handleCheckpointTimeout(pipelineId);
                         }
                     }
                 }, coordinatorConfig.getCheckpointTimeout(),
@@ -427,6 +427,7 @@ public void completePendingCheckpoint(CompletedCheckpoint completedCheckpoint) {
         } catch (IOException | CheckpointStorageException e) {
             sneakyThrow(e);
         }
+        LOG.info("pending checkpoint({}/{}@{}) notify finished!", completedCheckpoint.getCheckpointId(), completedCheckpoint.getPipelineId(), completedCheckpoint.getJobId());
         InvocationFuture<?>[] invocationFutures = notifyCheckpointCompleted(checkpointId);
         CompletableFuture.allOf(invocationFutures).join();
         // TODO: notifyCheckpointCompleted fail

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/TaskReportStatusOperation.java
Patch:
@@ -67,6 +67,6 @@ public void run() {
         ((SeaTunnelServer) getService())
             .getCoordinatorService().getJobMaster(location.getJobId())
             .getCheckpointManager()
-            .reportedTask(this, getCallerAddress());
+            .reportedTask(this);
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/master/JobMaster.java
Patch:
@@ -151,6 +151,7 @@ public void init(long initializationTimestamp) throws Exception {
         this.checkpointManager = new CheckpointManager(
             jobImmutableInformation.getJobId(),
             nodeEngine,
+            this,
             planTuple.f1(),
             checkpointConfig);
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -70,12 +70,12 @@
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.ConcurrentHashMap;
 import java.util.function.BiConsumer;
 import java.util.stream.Collectors;
 
@@ -94,9 +94,9 @@ public abstract class SeaTunnelTask extends AbstractTask {
 
     protected List<CompletableFuture<Void>> flowFutures;
 
-    protected final Map<Long, List<ActionSubtaskState>> checkpointStates = new HashMap<>();
+    protected final Map<Long, List<ActionSubtaskState>> checkpointStates = new ConcurrentHashMap<>();
 
-    private final Map<Long, Integer> cycleAcks = new HashMap<>();
+    private final Map<Long, Integer> cycleAcks = new ConcurrentHashMap<>();
 
     protected int indexID;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SinkAggregatedCommitterTask.java
Patch:
@@ -48,7 +48,6 @@
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -95,7 +94,7 @@ public SinkAggregatedCommitterTask(long jobID, TaskLocation taskID, SinkAction<?
     public void init() throws Exception {
         super.init();
         currState = INIT;
-        this.checkpointBarrierCounter = new HashMap<>();
+        this.checkpointBarrierCounter = new ConcurrentHashMap<>();
         this.commitInfoCache = new ConcurrentHashMap<>();
         this.writerAddressMap = new ConcurrentHashMap<>();
         this.checkpointCommitInfoMap = new ConcurrentHashMap<>();

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointManagerTest.java
Patch:
@@ -64,6 +64,7 @@ public void testHAByIMapCheckpointIDCounter() throws CheckpointStorageException
         CheckpointManager checkpointManager = new CheckpointManager(
             jobId,
             nodeEngine,
+            null,
             planMap,
             new CheckpointConfig());
         Assertions.assertTrue(checkpointManager.isCompletedPipeline(1));

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinator.java
Patch:
@@ -192,7 +192,7 @@ private void restoreTaskState(TaskLocation taskLocation) {
                         return;
                     }
                     for (int i = tuple.f1(); i < actionState.getParallelism(); i += currentParallelism) {
-                        states.add(actionState.getSubtaskStates()[i]);
+                        states.add(actionState.getSubtaskStates().get(i));
                     }
                 });
         }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSplitEnumeratorTask.java
Patch:
@@ -180,6 +180,7 @@ public void addTaskMemberMapping(TaskLocation taskID, Address memberAdder) {
         taskMemberMapping.put(taskID, memberAdder);
         taskIDToTaskLocationMapping.put(taskID.getTaskID(), taskID);
         taskIndexToTaskLocationMapping.put(taskID.getTaskIndex(), taskID);
+        unfinishedReaders.add(taskID.getTaskID());
     }
 
     public Address getTaskMemberAddress(long taskID) {

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/util/FileSystemUtils.java
Patch:
@@ -25,9 +25,9 @@
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
 
-import java.io.File;
 import java.io.FileNotFoundException;
 import java.io.IOException;
+import java.net.URI;
 import java.util.ArrayList;
 import java.util.List;
 
@@ -39,7 +39,7 @@ public class FileSystemUtils {
     public static Configuration CONF;
 
     public static FileSystem getFileSystem(@NonNull String path) throws IOException {
-        FileSystem fileSystem = FileSystem.get(new File(path).toURI(), CONF);
+        FileSystem fileSystem = FileSystem.get(URI.create(path.replaceAll("\\\\", "/")), CONF);
         fileSystem.setWriteChecksum(false);
         return fileSystem;
     }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/reader/ParquetReadStrategy.java
Patch:
@@ -114,6 +114,9 @@ public void read(String path, Collector<SeaTunnelRow> output) throws Exception {
     }
 
     private Object resolveObject(Object field, SeaTunnelDataType<?> fieldType) {
+        if (field == null) {
+            return null;
+        }
         switch (fieldType.getSqlType()) {
             case ARRAY:
                 ArrayList<Object> origArray = new ArrayList<>();

File: seatunnel-core/seatunnel-starter/src/main/java/org/apache/seatunnel/core/starter/seatunnel/command/ClientExecuteCommand.java
Patch:
@@ -73,12 +73,12 @@ public void execute() throws CommandExecuteException {
         } catch (ExecutionException | InterruptedException e) {
             throw new CommandExecuteException("SeaTunnel job executed failed", e);
         } finally {
-            if (instance != null) {
-                instance.shutdown();
-            }
             if (clientJobProxy != null) {
                 clientJobProxy.close();
             }
+            if (instance != null) {
+                instance.shutdown();
+            }
         }
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/service/slot/DefaultSlotService.java
Patch:
@@ -95,7 +95,6 @@ public void init() {
                     nodeEngine.getClusterService().getThisAddress());
                 sendToMaster(new WorkerHeartbeatOperation(toWorkerProfile())).join();
             } catch (Exception e) {
-                LOGGER.warning(e);
                 LOGGER.warning("failed send heartbeat to resource manager, will retry later. this address: " +
                     nodeEngine.getClusterService().getThisAddress());
             }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -181,7 +181,7 @@ private FlowLifeCycle convertFlowToActionLifeCycle(@NonNull Flow flow) throws Ex
         FlowLifeCycle lifeCycle;
         List<OneInputFlowLifeCycle<Record<?>>> flowLifeCycles = new ArrayList<>();
         if (!flow.getNext().isEmpty()) {
-            for (Flow f : executionFlow.getNext()) {
+            for (Flow f : flow.getNext()) {
                 flowLifeCycles.add((OneInputFlowLifeCycle<Record<?>>) convertFlowToActionLifeCycle(f));
             }
         }
@@ -203,7 +203,7 @@ private FlowLifeCycle convertFlowToActionLifeCycle(@NonNull Flow flow) throws Ex
                         new SeaTunnelTransformCollector(flowLifeCycles), completableFuture);
             } else if (f.getAction() instanceof PartitionTransformAction) {
                 // TODO use index and taskID to create ringbuffer list
-                if (executionFlow.getNext().isEmpty()) {
+                if (flow.getNext().isEmpty()) {
                     lifeCycle = new PartitionTransformSinkFlowLifeCycle(this, completableFuture);
                 } else {
                     lifeCycle = new PartitionTransformSourceFlowLifeCycle(this, completableFuture);

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeSourceSplitEnumerator.java
Patch:
@@ -136,6 +136,8 @@ private void assignPendingSplits() {
                 pendingSplits.remove(pendingReader);
 
             if (pendingAssignmentForReader != null && !pendingAssignmentForReader.isEmpty()) {
+                // Mark pending splits as already assigned
+                assignedSplits.addAll(pendingAssignmentForReader);
                 // Assign pending splits to reader
                 LOG.info("Assigning splits to readers {}", pendingAssignmentForReader);
                 enumeratorContext.assignSplit(pendingReader, new ArrayList<>(pendingAssignmentForReader));

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/util/TypeConvertUtil.java
Patch:
@@ -28,6 +28,7 @@
 import com.clickhouse.client.ClickHouseValue;
 
 import java.math.BigDecimal;
+import java.math.BigInteger;
 import java.net.Inet4Address;
 import java.net.Inet6Address;
 import java.time.LocalDate;
@@ -71,6 +72,8 @@ public static SeaTunnelDataType<?> convert(ClickHouseColumn column) {
             return BasicType.STRING_TYPE;
         } else if (Object.class.equals(type)) {
             return BasicType.STRING_TYPE;
+        } else if (BigInteger.class.equals(type)) {
+            return BasicType.STRING_TYPE;
         } else {
             // TODO support pojo
             throw new IllegalArgumentException("not supported data type: " + column.getDataType());

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/TextWriteStrategy.java
Patch:
@@ -101,6 +101,8 @@ public void finishAndCloseFile() {
             }
             needMoveFiles.put(key, getTargetLocation(key));
         });
+        beingWrittenOutputStream.clear();
+        isFirstWrite.clear();
     }
 
     private FSDataOutputStream getOrCreateOutputStream(@NonNull String filePath) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinatorConfiguration.java
Patch:
@@ -101,7 +101,8 @@ public static CheckpointCoordinatorConfiguration.Builder builder() {
 
     @SuppressWarnings("MagicNumber")
     public static final class Builder {
-        private long checkpointInterval = 300000;
+        // TODO 5000 is for test, we can update checkpointInterval to 300000 after we support it read from job config
+        private long checkpointInterval = 5000;
         private long checkpointTimeout = 300000;
         private int maxConcurrentCheckpoints = 1;
         private int tolerableFailureCheckpoints = 0;

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/AbstractTestContainer.java
Patch:
@@ -72,8 +72,8 @@ protected void executeExtraCommands(GenericContainer<?> container) throws IOExce
         //do nothing
     }
 
-    protected void bindSeaTunnelStarter(GenericContainer<?> container) {
-        ContainerUtil.bindSeaTunnelStarter(container,
+    protected void copySeaTunnelStarterToContainer(GenericContainer<?> container) {
+        ContainerUtil.copySeaTunnelStarterToContainer(container,
             this.startModuleName,
             this.startModuleFullPath,
             SEATUNNEL_HOME);

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/flink/AbstractTestFlinkContainer.java
Patch:
@@ -74,7 +74,7 @@ public void startUp() throws Exception {
             .waitingFor(new LogMessageWaitStrategy()
                 .withRegEx(".*Starting the resource manager.*")
                 .withStartupTimeout(Duration.ofMinutes(2)));
-        bindSeaTunnelStarter(jobManager);
+        copySeaTunnelStarterToContainer(jobManager);
 
         taskManager = new GenericContainer<>(dockerImage)
             .withCommand("taskmanager")

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/seatunnel/SeaTunnelContainer.java
Patch:
@@ -32,6 +32,7 @@
 import org.testcontainers.containers.output.Slf4jLogConsumer;
 import org.testcontainers.containers.wait.strategy.Wait;
 import org.testcontainers.utility.DockerLoggerFactory;
+import org.testcontainers.utility.MountableFile;
 
 import java.io.IOException;
 import java.nio.file.Paths;
@@ -56,8 +57,8 @@ public void startUp() throws Exception {
             .withExposedPorts()
             .withLogConsumer(new Slf4jLogConsumer(DockerLoggerFactory.getLogger("seatunnel-engine:" + JDK_DOCKER_IMAGE)))
             .waitingFor(Wait.forLogMessage(".*received new worker register.*\\n", 1));
-        bindSeaTunnelStarter(server);
-        server.withFileSystemBind(PROJECT_ROOT_PATH + "/seatunnel-engine/seatunnel-engine-common/src/main/resources/",
+        copySeaTunnelStarterToContainer(server);
+        server.withCopyFileToContainer(MountableFile.forHostPath(PROJECT_ROOT_PATH + "/seatunnel-engine/seatunnel-engine-common/src/main/resources/"),
             Paths.get(SEATUNNEL_HOME, "config").toString());
         server.start();
         // execute extra commands

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/spark/AbstractTestSparkContainer.java
Patch:
@@ -56,7 +56,7 @@ public void startUp() throws Exception {
             .waitingFor(new LogMessageWaitStrategy()
                 .withRegEx(".*Master: Starting Spark master at.*")
                 .withStartupTimeout(Duration.ofMinutes(2)));
-        bindSeaTunnelStarter(master);
+        copySeaTunnelStarterToContainer(master);
 
         // In most case we can just use standalone mode to execute a spark job, if we want to use cluster mode, we need to
         // start a worker.

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/checkpoint/CheckpointIDCounter.java
Patch:
@@ -18,14 +18,14 @@
 
 package org.apache.seatunnel.engine.core.checkpoint;
 
-import org.apache.seatunnel.engine.core.job.JobStatus;
+import org.apache.seatunnel.engine.core.job.PipelineState;
 
 import java.util.concurrent.CompletableFuture;
 
 /** A checkpoint ID counter. */
 public interface CheckpointIDCounter {
 
-    int INITIAL_CHECKPOINT_ID = 1;
+    long INITIAL_CHECKPOINT_ID = 1;
 
     /** Starts the {@link CheckpointIDCounter} service down. */
     void start() throws Exception;
@@ -38,7 +38,7 @@ public interface CheckpointIDCounter {
      *
      * @return The {@code CompletableFuture} holding the result of the shutdown operation.
      */
-    CompletableFuture<Void> shutdown(JobStatus jobStatus);
+    CompletableFuture<Void> shutdown(PipelineState jobStatus);
 
     /**
      * Atomically increments the current checkpoint ID.

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/StandaloneCheckpointIDCounter.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.engine.server.checkpoint;
 
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointIDCounter;
-import org.apache.seatunnel.engine.core.job.JobStatus;
+import org.apache.seatunnel.engine.core.job.PipelineState;
 
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.atomic.AtomicLong;
@@ -32,7 +32,7 @@ public void start() throws Exception {
     }
 
     @Override
-    public CompletableFuture<Void> shutdown(JobStatus jobStatus) {
+    public CompletableFuture<Void> shutdown(PipelineState pipelineStatus) {
         return CompletableFuture.completedFuture(null);
     }
 

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-api/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/api/AbstractCheckpointStorage.java
Patch:
@@ -168,7 +168,7 @@ public String getPipelineIdByFileName(String fileName) {
      * @return the checkpoint id of the file.
      */
     public String getCheckpointIdByFileName(String fileName) {
-        return fileName.split(FILE_NAME_SPLIT)[FILE_NAME_CHECKPOINT_ID_INDEX];
+        return fileName.split(FILE_NAME_SPLIT)[FILE_NAME_CHECKPOINT_ID_INDEX].split("\\.")[0];
     }
 
     @Override

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeDataGenerator.java
Patch:
@@ -25,6 +25,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
+import org.apache.seatunnel.connectors.seatunnel.fake.config.FakeConfig;
 
 import org.apache.commons.lang3.RandomStringUtils;
 import org.apache.commons.lang3.RandomUtils;

File: seatunnel-connectors-v2/connector-fake/src/test/java/org.apache.seatunnel.connectors.seatunnel.fake.source/FakeDataGeneratorTest.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
+import org.apache.seatunnel.connectors.seatunnel.fake.config.FakeConfig;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/BaseTextFileConfig.java
Patch:
@@ -50,11 +50,11 @@ public BaseTextFileConfig(@NonNull Config config) {
             throw new RuntimeException("compress not support now");
         }
 
-        if (config.hasPath(Constant.FIELD_DELIMITER) && !StringUtils.isBlank(config.getString(Constant.FIELD_DELIMITER))) {
+        if (config.hasPath(Constant.FIELD_DELIMITER) && StringUtils.isNotEmpty(config.getString(Constant.FIELD_DELIMITER))) {
             this.fieldDelimiter = config.getString(Constant.FIELD_DELIMITER);
         }
 
-        if (config.hasPath(Constant.ROW_DELIMITER) && !StringUtils.isBlank(config.getString(Constant.ROW_DELIMITER))) {
+        if (config.hasPath(Constant.ROW_DELIMITER) && StringUtils.isNotEmpty(config.getString(Constant.ROW_DELIMITER))) {
             this.rowDelimiter = config.getString(Constant.ROW_DELIMITER);
         }
 

File: seatunnel-connectors-v2/connector-iotdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/iotdb/sink/IoTDBSinkClient.java
Patch:
@@ -124,7 +124,9 @@ public synchronized void close() throws IOException {
         flush();
 
         try {
-            session.close();
+            if (session != null) {
+                session.close();
+            }
         } catch (IoTDBConnectionException e) {
             log.error("Close IoTDB client failed.", e);
             throw new IOException("Close IoTDB client failed.", e);

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeDataGenerator.java
Patch:
@@ -113,7 +113,7 @@ private Object randomColumnValue(SeaTunnelDataType<?> fieldType) {
             case NULL:
                 return null;
             case BYTES:
-                return RandomUtils.nextBytes(fakeConfig.getBytesLength());
+                return RandomStringUtils.randomAlphabetic(fakeConfig.getBytesLength()).getBytes();
             case DATE:
                 return randomLocalDateTime().toLocalDate();
             case TIME:

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/sqlserver/SqlserverTypeMapper.java
Patch:
@@ -111,10 +111,10 @@ public SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex) th
                 return LocalTimeType.LOCAL_TIME_TYPE;
             case SQLSERVER_DATETIME:
             case SQLSERVER_DATETIME2:
-            case SQLSERVER_TIMESTAMP:
             case SQLSERVER_SMALLDATETIME:
             case SQLSERVER_DATETIMEOFFSET:
                 return LocalTimeType.LOCAL_DATE_TIME_TYPE;
+            case SQLSERVER_TIMESTAMP:
             case SQLSERVER_BINARY:
             case SQLSERVER_VARBINARY:
             case SQLSERVER_IMAGE:

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/CheckpointBarrierTriggerOperation.java
Patch:
@@ -22,7 +22,6 @@
 import org.apache.seatunnel.common.utils.RetryUtils;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
-import org.apache.seatunnel.engine.server.checkpoint.CheckpointBarrier;
 import org.apache.seatunnel.engine.server.execution.Task;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.serializable.CheckpointDataSerializerHook;
@@ -64,7 +63,7 @@ protected void writeInternal(ObjectDataOutput out) throws IOException {
     protected void readInternal(ObjectDataInput in) throws IOException {
         super.readInternal(in);
         // TODO: support another barrier
-        barrier = in.readObject(CheckpointBarrier.class);
+        barrier = in.readObject();
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/RequestSplitOperation.java
Patch:
@@ -73,8 +73,8 @@ protected void writeInternal(ObjectDataOutput out) throws IOException {
     @Override
     protected void readInternal(ObjectDataInput in) throws IOException {
         super.readInternal(in);
-        taskID.readData(in);
-        enumeratorTaskID.readData(in);
+        taskID = in.readObject();
+        enumeratorTaskID = in.readObject();
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceRegisterOperation.java
Patch:
@@ -73,8 +73,8 @@ public String getServiceName() {
     @Override
     protected void writeInternal(ObjectDataOutput out) throws IOException {
         super.writeInternal(out);
-        readerTaskID.writeData(out);
-        enumeratorTaskID.writeData(out);
+        out.writeObject(readerTaskID);
+        out.writeObject(enumeratorTaskID);
     }
 
     @Override

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/config/Constant.java
Patch:
@@ -22,10 +22,11 @@ public class Constant {
     public static final String NON_PARTITION = "NON_PARTITION";
     public static final String TRANSACTION_ID_SPLIT = "_";
     public static final String TRANSACTION_EXPRESSION = "transactionId";
-
     public static final String SAVE_MODE = "save_mode";
     public static final String COMPRESS_CODEC = "compress_codec";
-
+    public static final String DATE_FORMAT = "date_format";
+    public static final String DATETIME_FORMAT = "datetime_format";
+    public static final String TIME_FORMAT = "time_format";
     public static final String PATH = "path";
     public static final String FIELD_DELIMITER = "field_delimiter";
     public static final String ROW_DELIMITER = "row_delimiter";

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/TaskExecutionService.java
Patch:
@@ -38,8 +38,8 @@
 import org.apache.seatunnel.engine.server.execution.TaskGroupLocation;
 import org.apache.seatunnel.engine.server.execution.TaskLocation;
 import org.apache.seatunnel.engine.server.execution.TaskTracker;
-import org.apache.seatunnel.engine.server.operation.NotifyTaskStatusOperation;
 import org.apache.seatunnel.engine.server.task.TaskGroupImmutableInformation;
+import org.apache.seatunnel.engine.server.task.operation.NotifyTaskStatusOperation;
 
 import com.google.common.collect.Lists;
 import com.hazelcast.internal.serialization.Data;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/NotifyTaskRestoreOperation.java
Patch:
@@ -71,7 +71,7 @@ protected void readInternal(ObjectDataInput in) throws IOException {
         int size = in.readInt();
         this.restoredState = new ArrayList<>(size);
         for (int i = 0; i < size; i++) {
-            restoredState.add(in.readObject(ActionSubtaskState.class));
+            restoredState.add(in.readObject());
         }
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/TaskAcknowledgeOperation.java
Patch:
@@ -65,8 +65,8 @@ protected void writeInternal(ObjectDataOutput out) throws IOException {
 
     @Override
     protected void readInternal(ObjectDataInput in) throws IOException {
-        taskLocation = in.readObject(TaskLocation.class);
-        barrier = in.readObject(CheckpointBarrier.class);
+        taskLocation = in.readObject();
+        barrier = in.readObject();
         states = in.readObject();
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/TaskReportStatusOperation.java
Patch:
@@ -53,11 +53,13 @@ public int getClassId() {
     @Override
     protected void writeInternal(ObjectDataOutput out) throws IOException {
         out.writeObject(location);
+        out.writeObject(status);
     }
 
     @Override
     protected void readInternal(ObjectDataInput in) throws IOException {
         location = in.readObject(TaskLocation.class);
+        status = in.readObject();
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/GetTaskGroupAddressOperation.java
Patch:
@@ -66,13 +66,13 @@ public String getServiceName() {
     @Override
     protected void writeInternal(ObjectDataOutput out) throws IOException {
         super.writeInternal(out);
-        taskLocation.writeData(out);
+        out.writeObject(taskLocation);
     }
 
     @Override
     protected void readInternal(ObjectDataInput in) throws IOException {
         super.readInternal(in);
-        taskLocation.readData(in);
+        taskLocation = in.readObject();
     }
 
     @Override
@@ -82,6 +82,6 @@ public int getFactoryId() {
 
     @Override
     public int getClassId() {
-        return TaskDataSerializerHook.CLOSE_REQUEST_TYPE;
+        return TaskDataSerializerHook.GET_TASKGROUP_ADDRESS_TYPE;
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/checkpoint/CloseRequestOperation.java
Patch:
@@ -62,13 +62,13 @@ public String getServiceName() {
     @Override
     protected void writeInternal(ObjectDataOutput out) throws IOException {
         super.writeInternal(out);
-        readerLocation.writeData(out);
+        out.writeObject(readerLocation);
     }
 
     @Override
     protected void readInternal(ObjectDataInput in) throws IOException {
         super.readInternal(in);
-        readerLocation.readData(in);
+        readerLocation = in.readObject();
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/AssignSplitOperation.java
Patch:
@@ -65,13 +65,13 @@ public void run() throws Exception {
     @Override
     protected void writeInternal(ObjectDataOutput out) throws IOException {
         out.writeByteArray(splits);
-        taskID.writeData(out);
+        out.writeObject(taskID);
     }
 
     @Override
     protected void readInternal(ObjectDataInput in) throws IOException {
         splits = in.readByteArray();
-        taskID.readData(in);
+        taskID = in.readObject();
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/RequestSplitOperation.java
Patch:
@@ -66,8 +66,8 @@ public String getServiceName() {
     @Override
     protected void writeInternal(ObjectDataOutput out) throws IOException {
         super.writeInternal(out);
-        taskID.writeData(out);
-        enumeratorTaskID.writeData(out);
+        out.writeObject(taskID);
+        out.writeObject(enumeratorTaskID);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceRegisterOperation.java
Patch:
@@ -80,8 +80,8 @@ protected void writeInternal(ObjectDataOutput out) throws IOException {
     @Override
     protected void readInternal(ObjectDataInput in) throws IOException {
         super.readInternal(in);
-        readerTaskID.readData(in);
-        enumeratorTaskID.readData(in);
+        readerTaskID = in.readObject();
+        enumeratorTaskID = in.readObject();
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/AbstractSeaTunnelServerTest.java
Patch:
@@ -36,8 +36,9 @@ public abstract class AbstractSeaTunnelServerTest {
     protected static ILogger LOGGER;
 
     @BeforeAll
-    public void before() {
-        instance = TestUtils.createHazelcastInstance("AbstractSeaTunnelServerTest" + "_" + System.currentTimeMillis());
+    public  void before() {
+        instance = SeaTunnelServerStarter.createHazelcastInstance(
+            TestUtils.getClusterName("AbstractSeaTunnelServerTest_" + System.currentTimeMillis()));
         nodeEngine = instance.node.nodeEngine;
         server = nodeEngine.getService(SeaTunnelServer.SERVICE_NAME);
         LOGGER = nodeEngine.getLogger(AbstractSeaTunnelServerTest.class);

File: seatunnel-e2e/seatunnel-engine-e2e/connector-console-seatunnel-e2e/src/test/java/org/apache/seatunnel/engine/e2e/console/FakeSourceToConsoleIT.java
Patch:
@@ -20,13 +20,11 @@
 import org.apache.seatunnel.engine.e2e.SeaTunnelContainer;
 
 import org.junit.jupiter.api.Assertions;
-import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.testcontainers.containers.Container;
 
 import java.io.IOException;
 
-@Disabled("Disabled because connector-v2 jar dist not exist")
 public class FakeSourceToConsoleIT extends SeaTunnelContainer {
 
     @Test

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/connector-iceberg-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/iceberg/IcebergSourceIT.java
Patch:
@@ -103,7 +103,7 @@ public void start() {
     @Test
     public void testIcebergSource() throws IOException, InterruptedException {
         Container.ExecResult execResult = executeSeaTunnelFlinkJob("/iceberg/iceberg_source.conf");
-        Assertions.assertEquals(0, execResult.getExitCode());
+        Assertions.assertEquals(0, execResult.getExitCode(), execResult.getStderr());
     }
 
     private void initializeIcebergTable() {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/ExecutionPlanGenerator.java
Patch:
@@ -194,7 +194,7 @@ public static Action recreateAction(Action action, Long id, int parallelism) {
                 action.getName(),
                 ((SinkAction<?, ?, ?, ?>) action).getSink(),
                 action.getJarUrls());
-        } else if (action instanceof SourceAction){
+        } else if (action instanceof SourceAction) {
             newAction = new SourceAction<>(id,
                 action.getName(),
                 ((SourceAction<?, ?, ?>) action).getSource(),

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/CheckpointBarrierTriggerOperation.java
Patch:
@@ -81,6 +81,7 @@ public void run() throws Exception {
             }
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException, Constant.OPERATION_RETRY_SLEEP));
+            exception -> exception instanceof NullPointerException &&
+                !server.taskIsEnded(taskLocation.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/CheckpointFinishedOperation.java
Patch:
@@ -89,6 +89,7 @@ public void run() throws Exception {
             }
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException, Constant.OPERATION_RETRY_SLEEP));
+            exception -> exception instanceof NullPointerException &&
+                !server.taskIsEnded(taskLocation.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/NotifyTaskRestoreOperation.java
Patch:
@@ -88,6 +88,7 @@ public void run() throws Exception {
             }
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException, Constant.OPERATION_RETRY_SLEEP));
+            exception -> exception instanceof NullPointerException &&
+                !server.taskIsEnded(taskLocation.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/operation/NotifyTaskStartOperation.java
Patch:
@@ -53,6 +53,7 @@ public void run() throws Exception {
             task.startCall();
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException, Constant.OPERATION_RETRY_SLEEP));
+            exception -> exception instanceof NullPointerException &&
+                !server.taskIsEnded(taskLocation.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/checkpoint/CloseRequestOperation.java
Patch:
@@ -50,7 +50,8 @@ public void run() throws Exception {
             task.close();
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException, Constant.OPERATION_RETRY_SLEEP));
+            exception -> exception instanceof NullPointerException &&
+                !server.taskIsEnded(readerLocation.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/AssignSplitOperation.java
Patch:
@@ -58,7 +58,8 @@ public void run() throws Exception {
             task.receivedSourceSplit(Arrays.stream(o).map(i -> (SplitT) i).collect(Collectors.toList()));
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException, Constant.OPERATION_RETRY_SLEEP));
+            exception -> exception instanceof NullPointerException &&
+                !server.taskIsEnded(taskID.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/RequestSplitOperation.java
Patch:
@@ -54,7 +54,8 @@ public void run() throws Exception {
             task.requestSplit(taskID.getTaskID());
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException, Constant.OPERATION_RETRY_SLEEP));
+            exception -> exception instanceof NullPointerException &&
+                !server.taskIsEnded(enumeratorTaskID.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceNoMoreElementOperation.java
Patch:
@@ -53,7 +53,8 @@ public void run() throws Exception {
             task.readerFinished(currentTaskID.getTaskID());
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException, Constant.OPERATION_RETRY_SLEEP));
+            exception -> exception instanceof NullPointerException &&
+                !server.taskIsEnded(enumeratorTaskID.getTaskGroupLocation()), Constant.OPERATION_RETRY_SLEEP));
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceRegisterOperation.java
Patch:
@@ -61,7 +61,8 @@ public void run() throws Exception {
             task.receivedReader(readerTaskID, readerAddress);
             return null;
         }, new RetryUtils.RetryMaterial(RETRY_TIME, true,
-            exception -> exception instanceof NullPointerException, RETRY_TIME_OUT));
+            exception -> exception instanceof NullPointerException &&
+                !server.taskIsEnded(enumeratorTaskID.getTaskGroupLocation()), RETRY_TIME_OUT));
     }
 
     @Override

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/connector-jdbc-spark-e2e/src/test/java/org/apache/seatunnel/e2e/spark/v2/jdbc/JdbcPostgresIT.java
Patch:
@@ -57,7 +57,7 @@ public class JdbcPostgresIT extends SparkContainer {
     @SuppressWarnings("checkstyle:MagicNumber")
     @BeforeEach
     public void startPostgreSqlContainer() throws Exception {
-        pg = new PostgreSQLContainer<>(DockerImageName.parse("postgres:14.3"))
+        pg = new PostgreSQLContainer<>(DockerImageName.parse("postgres:14-alpine"))
             .withNetwork(NETWORK)
             .withNetworkAliases("postgresql")
             .withCommand("postgres -c max_prepared_transactions=100")

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/TaskLocation.java
Patch:
@@ -32,13 +32,15 @@ public class TaskLocation implements IdentifiedDataSerializable, Serializable {
 
     private TaskGroupLocation taskGroupLocation;
     private long taskID;
+    private int index;
 
     public TaskLocation() {
     }
 
     public TaskLocation(TaskGroupLocation taskGroupLocation, long idPrefix, int index) {
         this.taskGroupLocation = taskGroupLocation;
         this.taskID = mixIDPrefixAndIndex(idPrefix, index);
+        this.index = index;
     }
 
     @SuppressWarnings("checkstyle:MagicNumber")
@@ -67,9 +69,8 @@ public long getTaskVertexId() {
         return taskID / 10000;
     }
 
-    @SuppressWarnings("checkstyle:MagicNumber")
     public int getTaskIndex() {
-        return (int) (taskID % 10000);
+        return index;
     }
 
     public void setTaskGroupLocation(TaskGroupLocation taskGroupLocation) {

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/Constants.java
Patch:
@@ -31,7 +31,7 @@ public final class Constants {
 
     public static final String SOURCE_SERIALIZATION = "source.serialization";
 
-    public static final String SOURCE_PARALLELISM = "source.parallelism";
+    public static final String SOURCE_PARALLELISM = "parallelism";
 
     public static final String HDFS_ROOT = "hdfs.root";
 

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/enumerator/PulsarSplitEnumerator.java
Patch:
@@ -151,13 +151,13 @@ private void discoverySplits() {
     private void checkPartitionChanges(Set<TopicPartition> fetchedPartitions) {
         // Append the partitions into current assignment state.
         final Set<TopicPartition> newPartitions = getNewPartitions(fetchedPartitions);
-        if (newPartitions.isEmpty()) {
-            return;
-        }
         if (partitionDiscoveryIntervalMs <= 0 && !noMoreNewPartitionSplits) {
             LOG.debug("Partition discovery is disabled.");
             noMoreNewPartitionSplits = true;
         }
+        if (newPartitions.isEmpty()) {
+            return;
+        }
         List<PulsarPartitionSplit> newSplits = newPartitions.stream()
             .map(this::createPulsarPartitionSplit)
             .collect(Collectors.toList());

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-redis-e2e/src/test/java/org/apache/seatunnel/e2e/connector/redis/RedisIT.java
Patch:
@@ -29,7 +29,6 @@
 import org.apache.seatunnel.e2e.common.TestResource;
 import org.apache.seatunnel.e2e.common.TestSuiteBase;
 import org.apache.seatunnel.e2e.common.container.TestContainer;
-import org.apache.seatunnel.e2e.common.junit.DisabledOnContainer;
 import org.apache.seatunnel.format.json.JsonSerializationSchema;
 
 import lombok.extern.slf4j.Slf4j;
@@ -57,7 +56,6 @@
 
 import scala.Tuple2;
 
-@DisabledOnContainer(value = "spark:2.4.3", disabledReason = "json-format conflicts with the Jackson version of Spark-2.4.3, see:https://github.com/apache/incubator-seatunnel/issues/2929")
 @Slf4j
 public class RedisIT extends TestSuiteBase implements TestResource {
     private static final String IMAGE = "redis:latest";
@@ -162,6 +160,7 @@ private static Tuple2<SeaTunnelRowType, List<SeaTunnelRow>> generateTestDataSet(
     private void initJedis() {
         Jedis jedis = new Jedis(redisContainer.getHost(), redisContainer.getFirstMappedPort());
         jedis.auth(PASSWORD);
+        jedis.ping();
         this.jedis = jedis;
     }
 

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/RetryUtils.java
Patch:
@@ -34,14 +34,14 @@ public static <T> T retryWithException(Execution<T, Exception> execution, RetryM
         if (retryMaterial.getRetryTimes() < 0) {
             throw new IllegalArgumentException("Retry times must be greater than 0");
         }
-        Exception lastE;
+        Exception lastException;
         int i = 0;
         do {
             i++;
             try {
                 return execution.execute();
             } catch (Exception e) {
-                lastE = e;
+                lastException = e;
                 if (retryCondition != null && !retryCondition.canRetry(e)) {
                     if (retryMaterial.shouldThrowException()) {
                         throw e;
@@ -52,7 +52,7 @@ public static <T> T retryWithException(Execution<T, Exception> execution, RetryM
             }
         } while (i <= retryTimes);
         if (retryMaterial.shouldThrowException()) {
-            throw new RuntimeException("Execute given execution failed after retry " + retryTimes + " times", lastE);
+            throw new RuntimeException("Execute given execution failed after retry " + retryTimes + " times", lastException);
         }
         return null;
     }

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/container/spark/AbstractTestSparkContainer.java
Patch:
@@ -35,7 +35,7 @@
 public abstract class AbstractTestSparkContainer extends AbstractTestContainer {
 
     private static final Logger LOG = LoggerFactory.getLogger(AbstractTestSparkContainer.class);
-    private static final String DEFAULT_DOCKER_IMAGE = "bitnami/spark:2.4.3";
+    private static final String DEFAULT_DOCKER_IMAGE = "bitnami/spark:2.4.6";
 
     protected GenericContainer<?> master;
 

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/config/SparkApiConfigChecker.java
Patch:
@@ -19,7 +19,6 @@
 
 import org.apache.seatunnel.core.starter.config.ConfigChecker;
 import org.apache.seatunnel.core.starter.exception.ConfigCheckException;
-import org.apache.seatunnel.spark.SparkEnvironment;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-e2e/seatunnel-engine-e2e/connector-console-seatunnel-e2e/src/test/java/org/apache/seatunnel/engine/e2e/console/FakeSourceToConsoleIT.java
Patch:
@@ -19,8 +19,8 @@
 
 import org.apache.seatunnel.engine.e2e.SeaTunnelContainer;
 
-import org.junit.Assert;
-import org.junit.Test;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Test;
 import org.testcontainers.containers.Container;
 
 import java.io.IOException;
@@ -30,6 +30,6 @@ public class FakeSourceToConsoleIT extends SeaTunnelContainer {
     @Test
     public void testFakeSourceToConsoleSink() throws IOException, InterruptedException {
         Container.ExecResult execResult = executeSeaTunnelJob("/fakesource_to_console.conf");
-        Assert.assertEquals(0, execResult.getExitCode());
+        Assertions.assertEquals(0, execResult.getExitCode());
     }
 }

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/sink/AbstractSinkWriter.java
Patch:
@@ -24,7 +24,7 @@
 public abstract class AbstractSinkWriter<T, StateT> implements SinkWriter<T, Void, StateT> {
 
     @Override
-    public final Optional<Void> prepareCommit() {
+    public Optional<Void> prepareCommit() {
         return Optional.empty();
     }
 

File: seatunnel-connectors-v2/connector-iotdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/iotdb/constant/SourceConstants.java
Patch:
@@ -27,6 +27,8 @@ public class SourceConstants {
 
     public static final String SQL_WHERE = "where";
 
+    public static final String SQL_ALIGN = "align by";
+
     public static final String DEFAULT_PARTITIONS = "0";
 
 }

File: seatunnel-connectors-v2/connector-iotdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/iotdb/sink/IoTDBSinkClient.java
Patch:
@@ -131,7 +131,7 @@ public synchronized void close() throws IOException {
         }
     }
 
-    private synchronized void flush() throws IOException {
+    synchronized void flush() throws IOException {
         checkFlushException();
         if (batchList.isEmpty()) {
             return;

File: seatunnel-connectors-v2/connector-iotdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/iotdb/source/IoTDBSource.java
Patch:
@@ -94,7 +94,7 @@ public SourceSplitEnumerator<IoTDBSourceSplit, IoTDBSourceState> createEnumerato
 
     @Override
     public SourceSplitEnumerator<IoTDBSourceSplit, IoTDBSourceState> restoreEnumerator(SourceSplitEnumerator.Context<IoTDBSourceSplit> enumeratorContext, IoTDBSourceState checkpointState) throws Exception {
-        return new IoTDBSourceSplitEnumerator(enumeratorContext, checkpointState, configParams);
+        return new IoTDBSourceSplitEnumerator(enumeratorContext, configParams, checkpointState);
     }
 
 }

File: seatunnel-connectors-v2/connector-iotdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/iotdb/source/IoTDBSourceSplit.java
Patch:
@@ -19,6 +19,9 @@
 
 import org.apache.seatunnel.api.source.SourceSplit;
 
+import lombok.ToString;
+
+@ToString
 public class IoTDBSourceSplit implements SourceSplit {
 
     private static final long serialVersionUID = -1L;

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/source/split/FileSourceSplitEnumerator.java
Patch:
@@ -102,7 +102,7 @@ private void assignSplit(int taskId) {
     }
 
     private static int getSplitOwner(String tp, int numReaders) {
-        return Math.abs(tp.hashCode()) % numReaders;
+        return (tp.hashCode() & Integer.MAX_VALUE) % numReaders;
     }
 
     @Override

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/source/ParallelEnumeratorContext.java
Patch:
@@ -42,7 +42,7 @@ public ParallelEnumeratorContext(ParallelSource<?, SplitT, ?> parallelSource,
 
     @Override
     public int currentParallelism() {
-        return running ? parallelism : 0;
+        return parallelism;
     }
 
     @Override

File: seatunnel-e2e/seatunnel-connector-v2-e2e/connector-jdbc-it/src/test/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/XaGroupOpsImplIT.java
Patch:
@@ -29,6 +29,7 @@
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -44,6 +45,7 @@
 
 import java.util.stream.Stream;
 
+@Disabled("Temporary fast fix, reason: JdbcDatabaseContainer: ClassNotFoundException: com.mysql.jdbc.Driver")
 class XaGroupOpsImplIT {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(XaGroupOpsImplIT.class);

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/utils/TypeConverterUtils.java
Patch:
@@ -35,13 +35,15 @@
 import org.apache.flink.api.java.typeutils.RowTypeInfo;
 import org.apache.flink.table.runtime.typeutils.BigDecimalTypeInfo;
 
+import java.math.BigDecimal;
 import java.time.LocalDate;
 import java.time.LocalDateTime;
 import java.time.LocalTime;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
 
+@SuppressWarnings("checkstyle:MagicNumber")
 public class TypeConverterUtils {
 
     private static final Map<Class<?>, BridgedType> BRIDGED_TYPES = new HashMap<>(32);
@@ -57,6 +59,7 @@ public class TypeConverterUtils {
         BRIDGED_TYPES.put(Float.class, BridgedType.of(BasicType.FLOAT_TYPE, BasicTypeInfo.FLOAT_TYPE_INFO));
         BRIDGED_TYPES.put(Double.class, BridgedType.of(BasicType.DOUBLE_TYPE, BasicTypeInfo.DOUBLE_TYPE_INFO));
         BRIDGED_TYPES.put(Void.class, BridgedType.of(BasicType.VOID_TYPE, BasicTypeInfo.VOID_TYPE_INFO));
+        BRIDGED_TYPES.put(BigDecimal.class, BridgedType.of(new DecimalType(38, 18), BasicTypeInfo.BIG_DEC_TYPE_INFO));
         // data time types
         BRIDGED_TYPES.put(LocalDate.class, BridgedType.of(LocalTimeType.LOCAL_DATE_TYPE, LocalTimeTypeInfo.LOCAL_DATE));
         BRIDGED_TYPES.put(LocalTime.class, BridgedType.of(LocalTimeType.LOCAL_TIME_TYPE, LocalTimeTypeInfo.LOCAL_TIME));

File: seatunnel-translation/seatunnel-translation-flink/src/test/java/org/apache/seatunnel/translation/flink/utils/TypeConverterUtilsTest.java
Patch:
@@ -23,7 +23,6 @@
 
 import org.apache.flink.api.common.typeinfo.BasicArrayTypeInfo;
 import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
-import org.apache.flink.table.runtime.typeutils.BigDecimalTypeInfo;
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
 
@@ -74,7 +73,7 @@ public void convertShortType() {
 
     @Test
     public void convertBigDecimalType() {
-        Assertions.assertEquals(new BigDecimalTypeInfo(30, 2), TypeConverterUtils.convert(new DecimalType(30, 2)));
+        Assertions.assertEquals(BasicTypeInfo.BIG_DEC_TYPE_INFO, TypeConverterUtils.convert(new DecimalType(30, 2)));
     }
 
     @Test

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/HiveSink.java
Patch:
@@ -129,6 +129,6 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
         } catch (URISyntaxException e) {
             throw new RuntimeException("Get hdfs cluster address failed, please check.", e);
         }
-        super.prepare(pluginConfig);
+        this.pluginConfig = pluginConfig;
     }
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/dialect/mysql/MySqlTypeMapper.java
Patch:
@@ -103,6 +103,7 @@ public SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex) th
             case MYSQL_MEDIUMINT_UNSIGNED:
             case MYSQL_INT:
             case MYSQL_INTEGER:
+            case MYSQL_YEAR:
                 return BasicType.INT_TYPE;
             case MYSQL_INT_UNSIGNED:
             case MYSQL_INTEGER_UNSIGNED:
@@ -138,8 +139,6 @@ public SeaTunnelDataType<?> mapping(ResultSetMetaData metadata, int colIndex) th
                         + "the precision will be set to 2147483647.",
                     MYSQL_LONGTEXT);
                 return BasicType.STRING_TYPE;
-
-            case MYSQL_YEAR:
             case MYSQL_DATE:
                 return LocalTimeType.LOCAL_DATE_TYPE;
             case MYSQL_TIME:

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcExactlyOnceSinkWriter.java
Patch:
@@ -134,6 +134,7 @@ public void write(SeaTunnelRow element)
     @Override
     public Optional<XidInfo> prepareCommit()
         throws IOException {
+        tryOpen();
         prepareCurrentTx();
         this.currentXid = null;
         beginTx();

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkWriter.java
Patch:
@@ -79,6 +79,7 @@ public void write(SeaTunnelRow element)
     @Override
     public Optional<XidInfo> prepareCommit()
         throws IOException {
+        tryOpen();
         outputFormat.flush();
         return Optional.empty();
     }
@@ -91,6 +92,8 @@ public void abortPrepare() {
     @Override
     public void close()
         throws IOException {
+        tryOpen();
+        outputFormat.flush();
         outputFormat.close();
     }
 }

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/source/AbstractSingleSplitSource.java
Patch:
@@ -29,7 +29,7 @@ public abstract class AbstractSingleSplitSource<T> implements SeaTunnelSource<T,
 
     @Override
     public final AbstractSingleSplitReader<T> createReader(SourceReader.Context readerContext) throws Exception {
-        checkArgument(readerContext.getIndexOfSubtask() == 0, "A single split source allows only one single reader to be created.");
+        checkArgument(readerContext.getIndexOfSubtask() == 0, "A single split source allows only one single reader to be created. Please make sure source parallelism = 1");
         return createReader(new SingleSplitReaderContext(readerContext));
     }
 

File: seatunnel-connectors-v2/connector-elasticsearch/src/main/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/sink/ElasticsearchSinkWriter.java
Patch:
@@ -46,7 +46,7 @@
  */
 public class ElasticsearchSinkWriter<ElasticsearchSinkStateT> implements SinkWriter<SeaTunnelRow, ElasticsearchCommitInfo, ElasticsearchSinkStateT> {
 
-    private final Context context;
+    private final SinkWriter.Context context;
 
     private final SeaTunnelRowSerializer seaTunnelRowSerializer;
     private final List<String> requestEsList;
@@ -56,7 +56,7 @@ public class ElasticsearchSinkWriter<ElasticsearchSinkStateT> implements SinkWri
     private static final Logger LOGGER = LoggerFactory.getLogger(ElasticsearchSinkWriter.class);
 
     public ElasticsearchSinkWriter(
-            Context context,
+            SinkWriter.Context context,
             SeaTunnelRowType seaTunnelRowType,
             Config pluginConfig,
             List<ElasticsearchSinkStateT> elasticsearchStates) {

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeRandomData.java
Patch:
@@ -114,7 +114,7 @@ private Object randomColumnValue(SeaTunnelDataType<?> fieldType) {
         } else if (fieldType instanceof PrimitiveByteArrayType) {
             return RandomUtils.nextBytes(3);
         } else if (VOID_TYPE.equals(fieldType) || fieldType == null) {
-            return Void.TYPE;
+            return null;
         } else {
             throw new UnsupportedOperationException("Unexpected value: " + fieldType);
         }

File: seatunnel-connectors-v2/connector-fake/src/test/java/org.apache.seatunnel.connectors.seatunnel.fake.source/FakeRandomDataTest.java
Patch:
@@ -56,7 +56,7 @@ public void testComplexSchemaParse(String conf) throws FileNotFoundException, UR
             if (fieldTypes[i].getSqlType() != SqlType.NULL) {
                 Assertions.assertNotNull(fields[i]);
             } else {
-                Assertions.assertSame(fields[i], Void.TYPE);
+                Assertions.assertSame(fields[i], null);
             }
             if (fieldTypes[i].getSqlType() == SqlType.MAP) {
                 Assertions.assertTrue(fields[i] instanceof Map);

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/source/HiveSource.java
Patch:
@@ -29,7 +29,7 @@
 import org.apache.seatunnel.common.constants.PluginType;
 import org.apache.seatunnel.connectors.seatunnel.file.config.BaseSourceConfig;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
-import org.apache.seatunnel.connectors.seatunnel.file.hdfs.source.HdfsFileSource;
+import org.apache.seatunnel.connectors.seatunnel.file.hdfs.source.BaseHdfsFileSource;
 import org.apache.seatunnel.connectors.seatunnel.hive.config.HiveConfig;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
@@ -43,7 +43,7 @@
 import java.net.URISyntaxException;
 
 @AutoService(SeaTunnelSource.class)
-public class HiveSource extends HdfsFileSource {
+public class HiveSource extends BaseHdfsFileSource {
     private Table tableInformation;
 
     @Override
@@ -75,7 +75,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
             String path = uri.getPath();
             String defaultFs = hdfsLocation.replace(path, "");
             pluginConfig = pluginConfig.withValue(BaseSourceConfig.FILE_PATH, ConfigValueFactory.fromAnyRef(path))
-                    .withValue(FS_DEFAULT_NAME_KEY, ConfigValueFactory.fromAnyRef(defaultFs));
+                .withValue(FS_DEFAULT_NAME_KEY, ConfigValueFactory.fromAnyRef(defaultFs));
         } catch (URISyntaxException e) {
             throw new RuntimeException("Get hdfs cluster address failed, please check.", e);
         }

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-common/src/main/java/org/apache/seatunnel/translation/spark/common/serialization/InternalRowConverter.java
Patch:
@@ -119,7 +119,7 @@ private static InternalRow convert(SeaTunnelRow seaTunnelRow, SeaTunnelRowType r
         return new SpecificInternalRow(values);
     }
 
-    private static Object convertMap(Map<?, ?> mapData, MapType<?, ?> mapType) {
+    private static ArrayBasedMapData convertMap(Map<?, ?> mapData, MapType<?, ?> mapType) {
         if (mapData == null || mapData.size() == 0) {
             return ArrayBasedMapData.apply(new Object[]{}, new Object[]{});
         }
@@ -132,7 +132,7 @@ private static Object convertMap(Map<?, ?> mapData, MapType<?, ?> mapType) {
         return ArrayBasedMapData.apply(keys, values);
     }
 
-    private static Object reconvertMap(MapData mapData, MapType<?, ?> mapType) {
+    private static Map<Object, Object> reconvertMap(MapData mapData, MapType<?, ?> mapType) {
         if (mapData == null || mapData.numElements() == 0) {
             return Collections.emptyMap();
         }

File: seatunnel-connectors-v2/connector-pulsar/src/main/java/org/apache/seatunnel/connectors/seatunnel/pulsar/source/PulsarSource.java
Patch:
@@ -128,7 +128,7 @@ public void prepare(Config config) throws PrepareFailException {
         // source properties
         setOption(config,
             TOPIC_DISCOVERY_INTERVAL,
-            30000L,
+            -1L,
             config::getLong,
             v -> this.partitionDiscoveryIntervalMs = v);
         setOption(config,

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/utils/CompressionUtils.java
Patch:
@@ -107,6 +107,9 @@ public static void unTar(final File inputFile, final File outputDir) throws IOEx
             TarArchiveEntry entry = null;
             while ((entry = (TarArchiveEntry) debInputStream.getNextEntry()) != null) {
                 final File outputFile = new File(outputDir, entry.getName()).toPath().normalize().toFile();
+                if (!outputFile.toPath().normalize().startsWith(outputDir.toPath())) {
+                    throw new IllegalStateException("Bad zip entry");
+                }
                 if (entry.isDirectory()) {
                     LOGGER.info("Attempting to write output directory {}.", outputFile.getAbsolutePath());
                     if (!outputFile.exists()) {

File: seatunnel-connectors-v2/connector-common/src/test/java/org/apache/seatunnel/connector/common/schema/SchemaParseTest.java
Patch:
@@ -23,6 +23,7 @@
 import org.apache.seatunnel.api.table.type.MapType;
 import org.apache.seatunnel.api.table.type.PrimitiveByteArrayType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
+import org.apache.seatunnel.api.table.type.SqlType;
 import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
@@ -73,6 +74,7 @@ public void testComplexSchemaParse() throws FileNotFoundException, URISyntaxExce
                 new MapType<>(BasicType.STRING_TYPE, new MapType<>(BasicType.STRING_TYPE, BasicType.STRING_TYPE)));
         Assertions.assertEquals(seaTunnelRowType.getFieldType(1),
                 new MapType<>(BasicType.STRING_TYPE, new MapType<>(BasicType.STRING_TYPE, ArrayType.INT_ARRAY_TYPE)));
+        Assertions.assertEquals(seaTunnelRowType.getFieldType(17).getSqlType(), SqlType.ROW);
     }
 
     public static String getTestConfigFile(String configFile) throws FileNotFoundException, URISyntaxException {

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/sink/HttpSinkWriter.java
Patch:
@@ -34,14 +34,15 @@
 
 public class HttpSinkWriter extends AbstractSinkWriter<SeaTunnelRow, Void> {
     private static final Logger LOGGER = LoggerFactory.getLogger(HttpSinkWriter.class);
-    protected final HttpClientProvider httpClient = HttpClientProvider.getInstance();
+    protected final HttpClientProvider httpClient;
     protected final SeaTunnelRowType seaTunnelRowType;
     protected final HttpParameter httpParameter;
     protected final SerializationSchema serializationSchema;
 
     public HttpSinkWriter(SeaTunnelRowType seaTunnelRowType, HttpParameter httpParameter) {
         this.seaTunnelRowType = seaTunnelRowType;
         this.httpParameter = httpParameter;
+        this.httpClient = new HttpClientProvider(httpParameter);
         this.serializationSchema = new JsonSerializationSchema(seaTunnelRowType);
     }
 

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/JsonSerializationSchema.java
Patch:
@@ -26,6 +26,7 @@
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import com.fasterxml.jackson.databind.node.ObjectNode;
+import lombok.Getter;
 
 public class JsonSerializationSchema implements SerializationSchema {
 
@@ -38,6 +39,7 @@ public class JsonSerializationSchema implements SerializationSchema {
     private transient ObjectNode node;
 
     /** Object mapper that is used to create output JSON objects. */
+    @Getter
     private final ObjectMapper mapper = new ObjectMapper();
 
     private final RowToJsonConverters.RowToJsonConverter runtimeConverter;
@@ -59,7 +61,7 @@ public byte[] serialize(SeaTunnelRow row) {
             return mapper.writeValueAsBytes(node);
         } catch (Throwable e) {
             throw new RuntimeException(
-                    String.format("Failed to deserialize JSON '%s'.", row), e);
+                String.format("Failed to deserialize JSON '%s'.", row), e);
         }
     }
 }

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-common/src/main/java/org/apache/seatunnel/translation/spark/common/utils/InstantConverterUtils.java
Patch:
@@ -21,7 +21,7 @@
 
 public class InstantConverterUtils {
 
-    private static final int MICRO_OF_SECOND = 1000_000;
+    private static final long MICRO_OF_SECOND = 1000_000;
     private static final int MICRO_OF_NANOS = 1000;
 
     /**

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/connection/SimpleJdbcConnectionProvider.java
Patch:
@@ -129,6 +129,9 @@ public Connection getOrEstablishConnection()
                 "No suitable driver found for " + jdbcOptions.getUrl(), "08001");
         }
 
+        //Auto commit is used by default
+        connection.setAutoCommit(true);
+
         return connection;
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/options/JdbcConnectorOptions.java
Patch:
@@ -81,7 +81,7 @@ public JdbcConnectorOptions(@NonNull Config config) {
             this.batchIntervalMs = config.getInt(JdbcConfig.BATCH_INTERVAL_MS);
         }
 
-        if (config.hasPath(JdbcConfig.IS_EXACTLY_ONCE)) {
+        if (config.hasPath(JdbcConfig.IS_EXACTLY_ONCE) && config.getBoolean(JdbcConfig.IS_EXACTLY_ONCE)) {
             this.isExactlyOnce = true;
             this.xaDataSourceClassName = config.getString(JdbcConfig.XA_DATA_SOURCE_CLASS_NAME);
             if (config.hasPath(JdbcConfig.MAX_COMMIT_ATTEMPTS)) {

File: seatunnel-connectors-v2/connector-mongodb/src/main/java/org/apache/seatunnel/connectors/seatunnel/mongodb/sink/MongodbSink.java
Patch:
@@ -30,6 +30,7 @@
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.PluginType;
+import org.apache.seatunnel.connectors.seatunnel.common.schema.SeaTunnelSchema;
 import org.apache.seatunnel.connectors.seatunnel.common.sink.AbstractSimpleSink;
 import org.apache.seatunnel.connectors.seatunnel.common.sink.AbstractSinkWriter;
 import org.apache.seatunnel.connectors.seatunnel.mongodb.config.MongodbParameters;
@@ -75,6 +76,7 @@ public SeaTunnelDataType<SeaTunnelRow> getConsumedType() {
 
     @Override
     public AbstractSinkWriter<SeaTunnelRow, Void> createWriter(SinkWriter.Context context) throws IOException {
-        return new MongodbSinkWriter(rowType, params);
+        boolean useSimpleTextSchema = SeaTunnelSchema.buildSimpleTextSchema().equals(rowType);
+        return new MongodbSinkWriter(rowType, useSimpleTextSchema, params);
     }
 }

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/config/HiveConfig.java
Patch:
@@ -27,7 +27,7 @@
 public class HiveConfig {
     public static final String TABLE_NAME = "table_name";
     public static final String METASTORE_URI = "metastore_uri";
-    public static final String TEXT_INPUT_FORMAT_CLASSNAME = "org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextInputFormat";
+    public static final String TEXT_INPUT_FORMAT_CLASSNAME = "org.apache.hadoop.mapred.TextInputFormat";
     public static final String TEXT_OUTPUT_FORMAT_CLASSNAME = "org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat";
     public static final String PARQUET_INPUT_FORMAT_CLASSNAME = "org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat";
     public static final String PARQUET_OUTPUT_FORMAT_CLASSNAME = "org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat";

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/command/SparkApiTaskExecuteCommand.java
Patch:
@@ -54,6 +54,7 @@ public void execute() throws CommandExecuteException {
             seaTunnelTaskExecution.execute();
         } catch (Exception e) {
             LOGGER.error("Run SeaTunnel on spark failed.", e);
+            throw new CommandExecuteException(e.getMessage());
         }
     }
 

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/source/LocalFileSource.java
Patch:
@@ -61,7 +61,7 @@ public void prepare(Config pluginConfig) throws PrepareFailException {
             throw new PrepareFailException(getPluginName(), PluginType.SOURCE, "Check file path fail.");
         }
         // support user-defined schema
-        FileFormat fileFormat = FileFormat.valueOf(pluginConfig.getString(LocalSourceConfig.FILE_PATH).toUpperCase());
+        FileFormat fileFormat = FileFormat.valueOf(pluginConfig.getString(LocalSourceConfig.FILE_TYPE).toUpperCase());
         // only json type support user-defined schema now
         if (pluginConfig.hasPath(SeaTunnelSchema.SCHEMA) && fileFormat.equals(FileFormat.JSON)) {
             Config schemaConfig = pluginConfig.getConfig(SeaTunnelSchema.SCHEMA);

File: seatunnel-connectors-v2/connector-console/src/main/java/org/apache/seatunnel/connectors/seatunnel/console/sink/ConsoleSinkWriter.java
Patch:
@@ -76,7 +76,7 @@ private String fieldToString(SeaTunnelDataType<?> type, Object value) {
                 List<String> rowData = new ArrayList<>();
                 SeaTunnelRowType rowType = (SeaTunnelRowType) type;
                 for (int i = 0; i < rowType.getTotalFields(); i++) {
-                    rowData.add(fieldToString(rowType.getFieldTypes()[i], Array.get(value, i)));
+                    rowData.add(fieldToString(rowType.getFieldTypes()[i], ((SeaTunnelRow) value).getField(i)));
                 }
                 return rowData.toString();
             default:

File: seatunnel-connectors-v2/connector-console/src/test/java/org/apache/seatunnel/connectors/seatunnel/console/sink/ConsoleSinkWriterIT.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.seatunnel.api.table.type.MapType;
 import org.apache.seatunnel.api.table.type.PrimitiveByteArrayType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
+import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.utils.ReflectionUtils;
 
@@ -101,7 +102,8 @@ void rowTypeTest() {
             SeaTunnelRowType seaTunnelRowType = new SeaTunnelRowType(fieldNames, fieldTypes);
             byte[] bytes = RandomUtils.nextBytes(10);
             Object[] rowData = {(byte) 1, bytes, bytes};
-            Object rowString = fieldToStringTest(seaTunnelRowType, rowData);
+            SeaTunnelRow seaTunnelRow = new SeaTunnelRow(rowData);
+            Object rowString = fieldToStringTest(seaTunnelRowType, seaTunnelRow);
             Assertions.assertNotNull(rowString);
             Assertions.assertEquals(String.format("[1, %s, %s]", Arrays.toString(bytes), Arrays.toString(bytes)), rowString.toString());
         });

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-common/src/main/java/org/apache/seatunnel/translation/spark/common/utils/TypeConverterUtils.java
Patch:
@@ -125,7 +125,7 @@ public static SeaTunnelDataType<?> convert(DataType sparkType) {
         }
         if (sparkType instanceof org.apache.spark.sql.types.MapType) {
             org.apache.spark.sql.types.MapType mapType = (org.apache.spark.sql.types.MapType) sparkType;
-            return new MapType<>(convert(mapType.valueType()), convert(mapType.valueType()));
+            return new MapType<>(convert(mapType.keyType()), convert(mapType.valueType()));
         }
         if (sparkType instanceof org.apache.spark.sql.types.DecimalType) {
             org.apache.spark.sql.types.DecimalType decimalType = (org.apache.spark.sql.types.DecimalType) sparkType;

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/config/Common.java
Patch:
@@ -145,7 +145,7 @@ public static Path pluginLibDir(String pluginName) {
     /**
      * return plugin's dependent jars, which located in 'plugins/${pluginName}/lib/*'.
      */
-    public static List<Path> getPluginsJarDependencies(){
+    public static List<Path> getPluginsJarDependencies() {
         Path pluginRootDir = Common.pluginRootDir();
         if (!Files.exists(pluginRootDir) || !Files.isDirectory(pluginRootDir)) {
             return Collections.emptyList();

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/AbstractSparkContainer.java
Patch:
@@ -61,7 +61,8 @@ public void before() {
             .withNetworkAliases("spark-master")
             .withExposedPorts()
             .withEnv("SPARK_MODE", "master")
-            .withLogConsumer(new Slf4jLogConsumer(LOG));
+            .withLogConsumer(new Slf4jLogConsumer(LOG))
+            .withCreateContainerCmdModifier(cmd -> cmd.withUser("root"));
         // In most case we can just use standalone mode to execute a spark job, if we want to use cluster mode, we need to
         // start a worker.
         Startables.deepStart(Stream.of(master)).join();
@@ -79,7 +80,7 @@ public void close() {
     @Override
     protected List<String> getExtraStartShellCommands() {
         return Arrays.asList("--master local",
-                             "--deploy-mode client");
+            "--deploy-mode client");
     }
 
     public Container.ExecResult executeSeaTunnelSparkJob(String confFile) throws IOException, InterruptedException {

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/LogicalDagGeneratorTest.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.engine.client;
 
+import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.common.config.DeployMode;
 import org.apache.seatunnel.engine.client.job.JobConfigParser;
@@ -45,10 +46,11 @@ public void testLogicalGenerator() {
         String filePath = TestUtils.getResource("/batch_fakesource_to_file_complex.conf");
         JobConfig jobConfig = new JobConfig();
         jobConfig.setName("fake_to_file");
+        jobConfig.setJobContext(new JobContext());
 
         IdGenerator idGenerator = new IdGenerator();
         ImmutablePair<List<Action>, Set<URL>> immutablePair =
-            new JobConfigParser(filePath, idGenerator, new JobConfig()).parse();
+            new JobConfigParser(filePath, idGenerator, jobConfig).parse();
 
         LogicalDagGenerator logicalDagGenerator =
             new LogicalDagGenerator(immutablePair.getLeft(), jobConfig, idGenerator);

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/config/Config.java
Patch:
@@ -31,7 +31,7 @@ public class Config {
     /**
      * The server address of kafka cluster.
      */
-    public static final String BOOTSTRAP_SERVER = "bootstrap.server";
+    public static final String BOOTSTRAP_SERVERS = "bootstrap.servers";
 
     public static final String KAFKA_CONFIG_PREFIX = "kafka.";
 

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSource.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.kafka.source;
 
-import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.BOOTSTRAP_SERVER;
+import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.BOOTSTRAP_SERVERS;
 import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.COMMIT_ON_CHECKPOINT;
 import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.CONSUMER_GROUP;
 import static org.apache.seatunnel.connectors.seatunnel.kafka.config.Config.PATTERN;
@@ -67,15 +67,15 @@ public String getPluginName() {
 
     @Override
     public void prepare(Config config) throws PrepareFailException {
-        CheckResult result = CheckConfigUtil.checkAllExists(config, TOPIC, BOOTSTRAP_SERVER);
+        CheckResult result = CheckConfigUtil.checkAllExists(config, TOPIC, BOOTSTRAP_SERVERS);
         if (!result.isSuccess()) {
             throw new PrepareFailException(getPluginName(), PluginType.SOURCE, result.getMsg());
         }
         this.metadata.setTopic(config.getString(TOPIC));
         if (config.hasPath(PATTERN)) {
             this.metadata.setPattern(config.getBoolean(PATTERN));
         }
-        this.metadata.setBootstrapServer(config.getString(BOOTSTRAP_SERVER));
+        this.metadata.setBootstrapServers(config.getString(BOOTSTRAP_SERVERS));
         this.metadata.setProperties(new Properties());
 
         if (config.hasPath(CONSUMER_GROUP)) {

File: seatunnel-connectors-v2/connector-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceReader.java
Patch:
@@ -73,7 +73,7 @@ public class KafkaSourceReader implements SourceReader<SeaTunnelRow, KafkaSource
 
     @Override
     public void open() {
-        this.consumer = initConsumer(this.metadata.getBootstrapServer(), this.metadata.getConsumerGroup(),
+        this.consumer = initConsumer(this.metadata.getBootstrapServers(), this.metadata.getConsumerGroup(),
                 this.metadata.getProperties(), !this.metadata.isCommitOnCheckpoint());
         isRunning = true;
     }

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/ConnectorInstanceLoader.java
Patch:
@@ -78,7 +78,6 @@ public static ImmutablePair<SeaTunnelSink<SeaTunnelRow, Serializable, Serializab
         SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializable> seaTunnelSink =
             sinkPluginDiscovery.createPluginInstance(pluginIdentifier);
         seaTunnelSink.prepare(sinkConfig);
-        seaTunnelSink.setTypeInfo(null);
         seaTunnelSink.setJobContext(jobContext);
         return new ImmutablePair<>(seaTunnelSink, new HashSet<>(pluginJarPaths));
     }

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/JobConfigParser.java
Patch:
@@ -270,8 +270,6 @@ private void sampleAnalyze(List<? extends Config> sourceConfigs,
                 pair.getRight());
         sourceAction.setParallelism(getSourceParallelism(sourceConfigs.get(0)));
         SeaTunnelDataType dataType = sourceAction.getSource().getProducedType();
-        ImmutablePair<SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializable>, Set<URL>>
-            sinkListImmutablePair = ConnectorInstanceLoader.loadSinkInstance(sinkConfigs.get(0), jobConfig.getJobContext());
 
         Action sinkUpstreamAction = sourceAction;
 
@@ -294,6 +292,8 @@ private void sampleAnalyze(List<? extends Config> sourceConfigs,
             sinkUpstreamAction = transformAction;
         }
 
+        ImmutablePair<SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializable>, Set<URL>>
+            sinkListImmutablePair = ConnectorInstanceLoader.loadSinkInstance(sinkConfigs.get(0), jobConfig.getJobContext());
         SinkAction sinkAction = createSinkAction(
             idGenerator.getNextId(),
             sinkListImmutablePair.getLeft().getPluginName(),

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/AbstractAction.java
Patch:
@@ -26,7 +26,7 @@
 
 public abstract class AbstractAction implements Action {
     private String name;
-    private List<Action> upstreams = new ArrayList<>();
+    private transient List<Action> upstreams = new ArrayList<>();
     // This is used to assign a unique ID to every Action
     private long id;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/ExecutionPlanGenerator.java
Patch:
@@ -187,13 +187,11 @@ public static Action recreateAction(Action action, Long id, int parallelism) {
         if (action instanceof PartitionTransformAction) {
             newAction = new PartitionTransformAction(id,
                 action.getName(),
-                action.getUpstream(),
                 ((PartitionTransformAction) action).getPartitionTransformation(),
                 action.getJarUrls());
         } else if (action instanceof SinkAction) {
             newAction = new SinkAction<>(id,
                 action.getName(),
-                action.getUpstream(),
                 ((SinkAction<?, ?, ?, ?>) action).getSink(),
                 action.getJarUrls());
         } else if (action instanceof SourceAction){

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelTask.java
Patch:
@@ -233,9 +233,8 @@ private FlowLifeCycle convertFlowToActionLifeCycle(@NonNull Flow flow) throws Ex
     public Set<URL> getJarsUrl() {
         List<Flow> now = Collections.singletonList(executionFlow);
         Set<URL> urls = new HashSet<>();
-        List<Flow> next = new ArrayList<>();
         while (!now.isEmpty()) {
-            next.clear();
+            final List<Flow> next = new ArrayList<>();
             now.forEach(n -> {
                 if (n instanceof PhysicalExecutionFlow) {
                     urls.addAll(((PhysicalExecutionFlow) n).getAction().getJarUrls());

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-common/src/main/java/org/apache/seatunnel/translation/spark/common/utils/TypeConverterUtils.java
Patch:
@@ -85,8 +85,8 @@ public static DataType convert(SeaTunnelDataType<?> dataType) {
                 return DataTypes.BinaryType;
             case DATE:
                 return DataTypes.DateType;
-            case TIME:
-                // TODO: how reconvert?
+            // case TIME:
+                // TODO: not support now, how reconvert?
             case TIMESTAMP:
                 return DataTypes.TimestampType;
             case ARRAY:

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SeaTunnelSink.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.common.PluginIdentifierInterface;
 import org.apache.seatunnel.api.common.SeaTunnelPluginLifeCycle;
 import org.apache.seatunnel.api.serialization.Serializer;
-import org.apache.seatunnel.api.source.SeaTunnelContextAware;
+import org.apache.seatunnel.api.source.SeaTunnelJobAware;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 
@@ -43,7 +43,7 @@
  *                                {@link SinkAggregatedCommitter} handle it, this class should implement interface {@link Serializable}.
  */
 public interface SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT>
-    extends Serializable, PluginIdentifierInterface, SeaTunnelPluginLifeCycle, SeaTunnelContextAware {
+    extends Serializable, PluginIdentifierInterface, SeaTunnelPluginLifeCycle, SeaTunnelJobAware {
 
     /**
      * Set the row type info of sink row data. This method will be automatically called by translation.

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SeaTunnelSource.java
Patch:
@@ -34,7 +34,7 @@
  * @param <StateT> The type of checkpoint states.
  */
 public interface SeaTunnelSource<T, SplitT extends SourceSplit, StateT extends Serializable>
-    extends Serializable, PluginIdentifierInterface, SeaTunnelPluginLifeCycle, SeaTunnelContextAware {
+    extends Serializable, PluginIdentifierInterface, SeaTunnelPluginLifeCycle, SeaTunnelJobAware {
 
     /**
      * Get the boundedness of this source.

File: seatunnel-connectors-v2/connector-elasticsearch/src/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/config/SinkConfig.java
Patch:
@@ -35,11 +35,11 @@ public class SinkConfig {
 
     public static final String MAX_RETRY_SIZE = "max_retry_size";
 
-    public static void setValue(org.apache.seatunnel.shade.com.typesafe.config.Config pluginConfig){
-        if(pluginConfig.hasPath(MAX_BATCH_SIZE)){
+    public static void setValue(org.apache.seatunnel.shade.com.typesafe.config.Config pluginConfig) {
+        if (pluginConfig.hasPath(MAX_BATCH_SIZE)) {
             BulkConfig.MAX_BATCH_SIZE = pluginConfig.getInt(MAX_BATCH_SIZE);
         }
-        if(pluginConfig.hasPath(MAX_RETRY_SIZE)){
+        if (pluginConfig.hasPath(MAX_RETRY_SIZE)) {
             BulkConfig.MAX_RETRY_SIZE = pluginConfig.getInt(MAX_RETRY_SIZE);
         }
     }

File: seatunnel-connectors-v2/connector-elasticsearch/src/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/constant/BulkConfig.java
Patch:
@@ -27,11 +27,13 @@ public class BulkConfig {
      * once bulk es include max document size
      * {@link SinkConfig#MAX_BATCH_SIZE}
      */
+    @SuppressWarnings("checkstyle:MagicNumber")
     public static int MAX_BATCH_SIZE = 10;
 
     /**
      * the max retry size of bulk es
      * {@link SinkConfig#MAX_RETRY_SIZE}
      */
+    @SuppressWarnings("checkstyle:MagicNumber")
     public static int MAX_RETRY_SIZE = 3;
 }

File: seatunnel-connectors-v2/connector-elasticsearch/src/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/SeaTunnelRowSerializer.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.elasticsearch.serialize;
 
-
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 
 public interface SeaTunnelRowSerializer {

File: seatunnel-connectors-v2/connector-elasticsearch/src/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/index/impl/VariableIndexSerializer.java
Patch:
@@ -33,7 +33,7 @@ public class VariableIndexSerializer implements IndexSerializer {
     private final String index;
     private final Map<String, Integer> fieldIndexMap;
 
-    private final String NULL_DEFAULT = "null";
+    private final String nullDefault = "null";
 
     public VariableIndexSerializer(SeaTunnelRowType seaTunnelRowType, String index, List<String> fieldNames) {
         this.index = index;
@@ -61,7 +61,7 @@ public String serialize(SeaTunnelRow row) {
     private String getValue(int fieldIndex, SeaTunnelRow row) {
         Object valueObj = row.getField(fieldIndex);
         if (valueObj == null) {
-            return NULL_DEFAULT;
+            return nullDefault;
         } else {
             return valueObj.toString();
         }

File: seatunnel-connectors-v2/connector-elasticsearch/src/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/type/IndexTypeSerializer.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.elasticsearch.serialize.type;
 
-
 import java.util.Map;
 
 public interface IndexTypeSerializer {

File: seatunnel-connectors-v2/connector-elasticsearch/src/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/serialize/type/impl/NotIndexTypeSerializer.java
Patch:
@@ -26,7 +26,6 @@
  */
 public class NotIndexTypeSerializer implements IndexTypeSerializer {
 
-
     @Override
     public void fillType(Map<String, String> indexInner) {
 

File: seatunnel-connectors-v2/connector-elasticsearch/src/java/org/apache/seatunnel/connectors/seatunnel/elasticsearch/util/RegexUtils.java
Patch:
@@ -20,7 +20,6 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.regex.Matcher;
-
 import java.util.regex.Pattern;
 
 public class RegexUtils {

File: seatunnel-connectors-v2/connector-iotdb/src/main/java/org/apache/seatunnel/connectors/seatunnel/iotdb/source/IoTDBSource.java
Patch:
@@ -21,8 +21,8 @@
 import static org.apache.seatunnel.connectors.seatunnel.iotdb.config.SourceConfig.NODE_URLS;
 import static org.apache.seatunnel.connectors.seatunnel.iotdb.config.SourceConfig.PORT;
 
+import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.common.PrepareFailException;
-import org.apache.seatunnel.api.common.SeaTunnelContext;
 import org.apache.seatunnel.api.source.Boundedness;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceReader;
@@ -46,7 +46,7 @@
 @AutoService(SeaTunnelSource.class)
 public class IoTDBSource implements SeaTunnelSource<SeaTunnelRow, IoTDBSourceSplit, IoTDBSourceState> {
 
-    private SeaTunnelContext seaTunnelContext;
+    private JobContext jobContext;
 
     private SeaTunnelRowType typeInfo;
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/SemanticXidGenerator.java
Patch:
@@ -19,7 +19,7 @@
 
 import static com.google.common.base.Preconditions.checkArgument;
 
-import org.apache.seatunnel.api.common.SeaTunnelContext;
+import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.sink.SinkWriter;
 
 import javax.transaction.xa.Xid;
@@ -63,7 +63,7 @@ public void open() {
     }
 
     @Override
-    public Xid generateXid(SeaTunnelContext context, SinkWriter.Context sinkContext, long checkpointId) {
+    public Xid generateXid(JobContext context, SinkWriter.Context sinkContext, long checkpointId) {
         byte[] jobIdBytes = context.getJobId().getBytes();
         checkArgument(jobIdBytes.length <= JOB_ID_BYTES);
         System.arraycopy(jobIdBytes, 0, gtridBuffer, 0, JOB_ID_BYTES);
@@ -75,7 +75,7 @@ public Xid generateXid(SeaTunnelContext context, SinkWriter.Context sinkContext,
     }
 
     @Override
-    public boolean belongsToSubtask(Xid xid, SeaTunnelContext context, SinkWriter.Context sinkContext) {
+    public boolean belongsToSubtask(Xid xid, JobContext context, SinkWriter.Context sinkContext) {
         if (xid.getFormatId() != FORMAT_ID) {
             return false;
         }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/XaGroupOps.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.xa;
 
-import org.apache.seatunnel.api.common.SeaTunnelContext;
+import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.sink.SinkWriter;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.state.XidInfo;
 
@@ -38,6 +38,6 @@ public GroupXaOperationResult<XidInfo> commit(
 
     GroupXaOperationResult<XidInfo> failAndRollback(Collection<XidInfo> xids);
 
-    void recoverAndRollback(SeaTunnelContext context, SinkWriter.Context sinkContext, XidGenerator xidGenerator, Xid excludeXid);
+    void recoverAndRollback(JobContext context, SinkWriter.Context sinkContext, XidGenerator xidGenerator, Xid excludeXid);
 
 }

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/XaGroupOpsImpl.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.xa;
 
-import org.apache.seatunnel.api.common.SeaTunnelContext;
+import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.sink.SinkWriter;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.state.XidInfo;
 
@@ -112,7 +112,7 @@ public GroupXaOperationResult<XidInfo> failAndRollback(Collection<XidInfo> xids)
     }
 
     @Override
-    public void recoverAndRollback(SeaTunnelContext context, SinkWriter.Context sinkContext, XidGenerator xidGenerator, Xid excludeXid) {
+    public void recoverAndRollback(JobContext context, SinkWriter.Context sinkContext, XidGenerator xidGenerator, Xid excludeXid) {
         Collection<Xid> recovered = xaFacade.recover();
         recovered.remove(excludeXid);
         if (recovered.isEmpty()) {

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/XidGenerator.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.xa;
 
-import org.apache.seatunnel.api.common.SeaTunnelContext;
+import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.sink.SinkWriter;
 
 import javax.transaction.xa.Xid;
@@ -31,14 +31,14 @@
 public interface XidGenerator
     extends Serializable, AutoCloseable {
 
-    Xid generateXid(SeaTunnelContext context, SinkWriter.Context sinkContext, long checkpointId);
+    Xid generateXid(JobContext context, SinkWriter.Context sinkContext, long checkpointId);
 
     default void open() {}
 
     /**
      * @return true if the provided transaction belongs to this subtask
      */
-    boolean belongsToSubtask(Xid xid, SeaTunnelContext context, SinkWriter.Context sinkContext);
+    boolean belongsToSubtask(Xid xid, JobContext context, SinkWriter.Context sinkContext);
 
     @Override
     default void close() {}

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcExactlyOnceSinkWriter.java
Patch:
@@ -20,7 +20,7 @@
 import static com.google.common.base.Preconditions.checkArgument;
 import static com.google.common.base.Preconditions.checkState;
 
-import org.apache.seatunnel.api.common.SeaTunnelContext;
+import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.api.sink.SinkWriter;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.connectors.seatunnel.jdbc.config.JdbcSinkOptions;
@@ -53,7 +53,7 @@ public class JdbcExactlyOnceSinkWriter
 
     private final SinkWriter.Context sinkcontext;
 
-    private final SeaTunnelContext context;
+    private final JobContext context;
 
     private final List<JdbcSinkState> recoverStates;
 
@@ -72,7 +72,7 @@ public class JdbcExactlyOnceSinkWriter
 
     public JdbcExactlyOnceSinkWriter(
         SinkWriter.Context sinkcontext,
-        SeaTunnelContext context,
+        JobContext context,
         JdbcStatementBuilder<SeaTunnelRow> statementBuilder,
         JdbcSinkOptions jdbcSinkOptions,
         List<JdbcSinkState> states) {

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/TransformExecuteProcessor.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.core.starter.flink.execution;
 
+import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.core.starter.exception.TaskExecuteException;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.flink.stream.FlinkStreamTransform;
@@ -39,8 +40,9 @@ public class TransformExecuteProcessor extends AbstractPluginExecuteProcessor<Fl
     private static final String PLUGIN_TYPE = "transform";
 
     protected TransformExecuteProcessor(FlinkEnvironment flinkEnvironment,
+                                        JobContext jobContext,
                                         List<? extends Config> pluginConfigs) {
-        super(flinkEnvironment, pluginConfigs);
+        super(flinkEnvironment, jobContext, pluginConfigs);
     }
 
     @Override

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/TransformExecuteProcessor.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.core.starter.spark.execution;
 
+import org.apache.seatunnel.api.common.JobContext;
 import org.apache.seatunnel.core.starter.exception.TaskExecuteException;
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
 import org.apache.seatunnel.plugin.discovery.seatunnel.SeaTunnelSparkTransformPluginDiscovery;
@@ -39,8 +40,9 @@ public class TransformExecuteProcessor extends AbstractPluginExecuteProcessor<Ba
     private static final String PLUGIN_TYPE = "transform";
 
     protected TransformExecuteProcessor(SparkEnvironment sparkEnvironment,
+                                        JobContext jobContext,
                                         List<? extends Config> pluginConfigs) {
-        super(sparkEnvironment, pluginConfigs);
+        super(sparkEnvironment, jobContext, pluginConfigs);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/TaskGroupContext.java
Patch:
@@ -22,4 +22,6 @@
 @Data
 public class TaskGroupContext {
     final TaskGroup taskGroup;
+
+    final ClassLoader classLoader;
 }

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/connector-jdbc-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/jdbc/JdbcDmdbIT.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.e2e.flink.v2.jdbc;
 
-import static org.testcontainers.shaded.org.awaitility.Awaitility.given;
+import static org.awaitility.Awaitility.given;
 
 import org.apache.seatunnel.e2e.flink.FlinkContainer;
 

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/connector-mongodb-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/mongodb/MongodbSourceToConsoleIT.java
Patch:
@@ -26,6 +26,7 @@
 import com.mongodb.client.MongoClients;
 import com.mongodb.client.MongoCollection;
 import lombok.extern.slf4j.Slf4j;
+import org.awaitility.Awaitility;
 import org.bson.Document;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.Assertions;
@@ -36,7 +37,6 @@
 import org.testcontainers.containers.output.Slf4jLogConsumer;
 import org.testcontainers.containers.wait.strategy.HttpWaitStrategy;
 import org.testcontainers.lifecycle.Startables;
-import org.testcontainers.shaded.org.awaitility.Awaitility;
 import org.testcontainers.utility.DockerImageName;
 
 import java.io.IOException;
@@ -77,7 +77,8 @@ public void startMongoContainer() {
         Startables.deepStart(Stream.of(mongodbContainer)).join();
         log.info("Mongodb container started");
         Awaitility.given().ignoreExceptions()
-            .await()
+            .atLeast(100, TimeUnit.MILLISECONDS)
+            .pollInterval(500, TimeUnit.MILLISECONDS)
             .atMost(180, TimeUnit.SECONDS)
             .untilAsserted(this::initConnection);
         this.generateTestData();

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/connector-jdbc-spark-e2e/src/test/java/org/apache/seatunnel/e2e/spark/v2/jdbc/JdbcDmdbIT.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.e2e.spark.v2.jdbc;
 
-import static org.testcontainers.shaded.org.awaitility.Awaitility.given;
+import static org.awaitility.Awaitility.given;
 
 import org.apache.seatunnel.e2e.spark.SparkContainer;
 

File: seatunnel-e2e/seatunnel-e2e-common/src/test/java/org/apache/seatunnel/e2e/common/AbstractSparkContainer.java
Patch:
@@ -35,6 +35,7 @@
 
 @TestInstance(TestInstance.Lifecycle.PER_CLASS)
 public abstract class AbstractSparkContainer extends AbstractContainer {
+
     private static final Logger LOG = LoggerFactory.getLogger(AbstractSparkContainer.class);
 
     private static final String SPARK_SEATUNNEL_HOME = "/tmp/spark/seatunnel";
@@ -78,7 +79,7 @@ public void close() {
     @Override
     protected List<String> getExtraStartShellCommands() {
         return Arrays.asList("--master local",
-            "--deploy-mode client");
+                             "--deploy-mode client");
     }
 
     public Container.ExecResult executeSeaTunnelSparkJob(String confFile) throws IOException, InterruptedException {

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/connector-flink-e2e-base/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -32,7 +32,7 @@ protected String getDockerImage() {
     }
 
     @Override
-    protected String getStartModulePath() {
+    protected String getStartModuleName() {
         return "seatunnel-flink-starter";
     }
 

File: seatunnel-e2e/seatunnel-flink-e2e/seatunnel-connector-flink-e2e-base/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -27,7 +27,7 @@
 public abstract class FlinkContainer extends AbstractFlinkContainer {
 
     @Override
-    protected String getStartModulePath() {
+    protected String getStartModuleName() {
         return "seatunnel-core-flink";
     }
 

File: seatunnel-e2e/seatunnel-flink-sql-e2e/setunnel-connector-flink-sql-e2e-base/src/test/java/org/apache/seatunnel/e2e/flink/sql/FlinkContainer.java
Patch:
@@ -33,7 +33,7 @@
 public abstract class FlinkContainer extends AbstractFlinkContainer {
 
     @Override
-    protected String getStartModulePath() {
+    protected String getStartModuleName() {
         return "seatunnel-core-flink-sql";
     }
 

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/connector-spark-e2e-base/src/test/java/org/apache/seatunnel/e2e/spark/SparkContainer.java
Patch:
@@ -26,7 +26,7 @@
 public abstract class SparkContainer extends AbstractSparkContainer {
 
     @Override
-    protected String getStartModulePath() {
+    protected String getStartModuleName() {
         return "seatunnel-spark-starter";
     }
 

File: seatunnel-e2e/seatunnel-spark-e2e/seatunnel-connector-spark-e2e-base/src/test/java/org/apache/seatunnel/e2e/spark/SparkContainer.java
Patch:
@@ -26,7 +26,7 @@
 public abstract class SparkContainer extends AbstractSparkContainer {
 
     @Override
-    protected String getStartModulePath() {
+    protected String getStartModuleName() {
         return "seatunnel-core-spark";
     }
 

File: seatunnel-e2e/seatunnel-flink-e2e/seatunnel-connector-flink-e2e-base/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -38,7 +38,7 @@ protected String getStartShellName() {
 
     @Override
     protected String getConnectorType() {
-        return "seatunnel";
+        return "flink";
     }
 
     @Override

File: seatunnel-core/seatunnel-core-starter/src/main/java/org/apache/seatunnel/core/starter/config/ConfigChecker.java
Patch:
@@ -17,17 +17,15 @@
 
 package org.apache.seatunnel.core.starter.config;
 
-import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.core.starter.exception.ConfigCheckException;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
 /**
  * Check the config is valid.
  *
- * @param <ENVIRONMENT> the environment type.
  */
-public interface ConfigChecker<ENVIRONMENT extends RuntimeEnv> {
+public interface ConfigChecker {
 
     /**
      * Check if the config is validated, if check fails, throw exception.

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/config/FlinkApiConfigChecker.java
Patch:
@@ -22,7 +22,7 @@
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
-public class FlinkApiConfigChecker implements ConfigChecker<FlinkApiEnvironment> {
+public class FlinkApiConfigChecker implements ConfigChecker {
 
     @Override
     public void checkConfig(Config config) throws ConfigCheckException {

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/config/SparkApiConfigChecker.java
Patch:
@@ -22,7 +22,7 @@
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
-public class SparkApiConfigChecker implements ConfigChecker<SparkEnvironment> {
+public class SparkApiConfigChecker implements ConfigChecker {
 
     @Override
     public void checkConfig(Config config) throws ConfigCheckException {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/SeaTunnelServer.java
Patch:
@@ -128,6 +128,7 @@ public void shutdown(boolean terminate) {
         if (resourceManager != null) {
             resourceManager.close();
         }
+        executorService.shutdown();
         taskExecutionService.shutdown();
     }
 

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/JobConfigParserTest.java
Patch:
@@ -46,7 +46,6 @@ public void testSimpleJobParse() {
         ImmutablePair<List<Action>, Set<URL>> parse = jobConfigParser.parse();
         List<Action> actions = parse.getLeft();
         Assert.assertEquals(1, actions.size());
-
         Assert.assertEquals("LocalFile", actions.get(0).getName());
         Assert.assertEquals(1, actions.get(0).getUpstream().size());
         Assert.assertEquals("FakeSource", actions.get(0).getUpstream().get(0).getName());

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/GetTaskGroupAddressOperation.java
Patch:
@@ -50,7 +50,7 @@ public void run() throws Exception {
         response = RetryUtils.retryWithException(() -> server.getJobMaster(taskLocation.getJobId())
                 .queryTaskGroupAddress(taskLocation.getTaskGroupLocation().getTaskGroupId()),
             new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-                exception -> exception instanceof IllegalArgumentException, Constant.OPERATION_RETRY_SLEEP));
+                exception -> exception instanceof Exception, Constant.OPERATION_RETRY_SLEEP));
     }
 
     @Override

File: seatunnel-server/seatunnel-app/src/test/java/org/apache/seatunnel/app/controller/UserControllerTest.java
Patch:
@@ -30,13 +30,15 @@
 
 import com.fasterxml.jackson.core.type.TypeReference;
 import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.mockito.Mockito;
 import org.springframework.boot.test.mock.mockito.MockBean;
 import org.springframework.http.MediaType;
 import org.springframework.test.web.servlet.MvcResult;
 import org.springframework.test.web.servlet.result.MockMvcResultHandlers;
 
+@Disabled("todo:this test is not working, waiting fix")
 public class UserControllerTest extends WebMvcApplicationTest {
 
     @MockBean

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/SeaTunnelClientTest.java
Patch:
@@ -87,7 +87,7 @@ public void testExecuteJob() {
                 return clientJobProxy.waitForJobComplete();
             });
 
-            await().atMost(20000, TimeUnit.MILLISECONDS)
+            await().atMost(30000, TimeUnit.MILLISECONDS)
                 .untilAsserted(() -> Assert.assertTrue(
                     objectCompletableFuture.isDone() && JobStatus.FINISHED.equals(objectCompletableFuture.get())));
 

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/utils/ConsumerWithException.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.server.utils;
+package org.apache.seatunnel.engine.common.utils;
 
 @FunctionalInterface
 public interface ConsumerWithException<T>  {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/checkpoint/Checkpoint.java
Patch:
@@ -27,4 +27,6 @@ public interface Checkpoint {
     long getJobId();
 
     long getCheckpointTimestamp();
+
+    CheckpointType getCheckpointType();
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/ActionSubtaskState.java
Patch:
@@ -20,11 +20,12 @@
 import lombok.Data;
 
 import java.io.Serializable;
+import java.util.List;
 
 @Data
 public class ActionSubtaskState implements Serializable {
     private static final long serialVersionUID = 1L;
     private final long actionId;
     private final int index;
-    private final byte[] state;
+    private final List<byte[]> state;
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/checkpoint/CheckpointCoordinatorConfiguration.java
Patch:
@@ -99,9 +99,10 @@ public static CheckpointCoordinatorConfiguration.Builder builder() {
         return new Builder();
     }
 
+    @SuppressWarnings("MagicNumber")
     public static final class Builder {
-        private long checkpointInterval = MINIMAL_CHECKPOINT_TIME;
-        private long checkpointTimeout = MINIMAL_CHECKPOINT_TIME;
+        private long checkpointInterval = 300000;
+        private long checkpointTimeout = 300000;
         private int maxConcurrentCheckpoints = 1;
         private int tolerableFailureCheckpoints = 0;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/serializable/TaskDataSerializerHook.java
Patch:
@@ -24,11 +24,11 @@
 import org.apache.seatunnel.engine.server.task.operation.CancelTaskOperation;
 import org.apache.seatunnel.engine.server.task.operation.DeployTaskOperation;
 import org.apache.seatunnel.engine.server.task.operation.GetTaskGroupAddressOperation;
+import org.apache.seatunnel.engine.server.task.operation.checkpoint.CloseRequestOperation;
 import org.apache.seatunnel.engine.server.task.operation.sink.SinkPrepareCommitOperation;
 import org.apache.seatunnel.engine.server.task.operation.sink.SinkRegisterOperation;
 import org.apache.seatunnel.engine.server.task.operation.sink.SinkUnregisterOperation;
 import org.apache.seatunnel.engine.server.task.operation.source.AssignSplitOperation;
-import org.apache.seatunnel.engine.server.task.operation.source.CloseRequestOperation;
 import org.apache.seatunnel.engine.server.task.operation.source.RequestSplitOperation;
 import org.apache.seatunnel.engine.server.task.operation.source.SourceNoMoreElementOperation;
 import org.apache.seatunnel.engine.server.task.operation.source.SourceRegisterOperation;
@@ -70,8 +70,8 @@ public class TaskDataSerializerHook implements DataSerializerHook {
 
 
     public static final int FACTORY_ID = FactoryIdHelper.getFactoryId(
-            SeaTunnelFactoryIdConstant.SEATUNNEL_TASK_DATA_SERIALIZER_FACTORY,
-            SeaTunnelFactoryIdConstant.SEATUNNEL_TASK_DATA_SERIALIZER_FACTORY_ID
+        SeaTunnelFactoryIdConstant.SEATUNNEL_TASK_DATA_SERIALIZER_FACTORY,
+        SeaTunnelFactoryIdConstant.SEATUNNEL_TASK_DATA_SERIALIZER_FACTORY_ID
     );
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/AbstractFlowLifeCycle.java
Patch:
@@ -28,10 +28,13 @@ public class AbstractFlowLifeCycle implements FlowLifeCycle {
 
     protected final CompletableFuture<Void> completableFuture;
 
+    protected Boolean prepareClose;
+
     public AbstractFlowLifeCycle(SeaTunnelTask runningTask,
                                  CompletableFuture<Void> completableFuture) {
         this.runningTask = runningTask;
         this.completableFuture = completableFuture;
+        this.prepareClose = false;
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/checkpoint/CloseRequestOperation.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.server.task.operation.source;
+package org.apache.seatunnel.engine.server.task.operation.checkpoint;
 
 import org.apache.seatunnel.common.utils.RetryUtils;
 import org.apache.seatunnel.engine.common.Constant;

File: seatunnel-server/seatunnel-app/src/main/java/org/apache/seatunnel/app/service/impl/ScriptServiceImpl.java
Patch:
@@ -44,7 +44,7 @@
 import org.apache.seatunnel.app.domain.response.script.ScriptSimpleInfoRes;
 import org.apache.seatunnel.app.service.IScriptService;
 import org.apache.seatunnel.app.service.ITaskService;
-import org.apache.seatunnel.app.util.Md5Utils;
+import org.apache.seatunnel.app.utils.Md5Utils;
 import org.apache.seatunnel.scheduler.dolphinscheduler.impl.InstanceServiceImpl;
 import org.apache.seatunnel.server.common.PageData;
 

File: seatunnel-server/seatunnel-app/src/main/java/org/apache/seatunnel/app/service/impl/UserServiceImpl.java
Patch:
@@ -32,7 +32,7 @@
 import org.apache.seatunnel.app.domain.response.user.UserSimpleInfoRes;
 import org.apache.seatunnel.app.service.IRoleService;
 import org.apache.seatunnel.app.service.IUserService;
-import org.apache.seatunnel.app.util.PasswordUtils;
+import org.apache.seatunnel.app.utils.PasswordUtils;
 import org.apache.seatunnel.server.common.PageData;
 import org.apache.seatunnel.server.common.SeatunnelException;
 

File: seatunnel-server/seatunnel-app/src/main/java/org/apache/seatunnel/app/utils/GlobalExceptionHandler.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.app.util;
+package org.apache.seatunnel.app.utils;
 
 import org.apache.seatunnel.app.common.Result;
 import org.apache.seatunnel.server.common.SeatunnelErrorEnum;

File: seatunnel-server/seatunnel-app/src/main/java/org/apache/seatunnel/app/utils/Md5Utils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.app.util;
+package org.apache.seatunnel.app.utils;
 
 import org.springframework.util.DigestUtils;
 

File: seatunnel-server/seatunnel-app/src/main/java/org/apache/seatunnel/app/utils/PasswordUtils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.app.util;
+package org.apache.seatunnel.app.utils;
 
 import org.springframework.util.DigestUtils;
 

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/connector-flink-e2e-base/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -52,7 +52,7 @@ public abstract class FlinkContainer {
 
     protected GenericContainer<?> jobManager;
     protected GenericContainer<?> taskManager;
-    private static final Path PROJECT_ROOT_PATH = Paths.get(System.getProperty("user.dir")).getParent().getParent();
+    private static final Path PROJECT_ROOT_PATH = Paths.get(System.getProperty("user.dir")).getParent().getParent().getParent();
     private static final String SEATUNNEL_FLINK_BIN = "start-seatunnel-flink-new-connector.sh";
     private static final String SEATUNNEL_FLINK_JAR = "seatunnel-flink-starter.jar";
     private static final String PLUGIN_MAPPING_FILE = "plugin-mapping.properties";

File: seatunnel-e2e/seatunnel-flink-e2e/seatunnel-connector-flink-e2e-base/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -52,7 +52,7 @@ public abstract class FlinkContainer {
 
     protected GenericContainer<?> jobManager;
     protected GenericContainer<?> taskManager;
-    private static final Path PROJECT_ROOT_PATH = Paths.get(System.getProperty("user.dir")).getParent().getParent();
+    private static final Path PROJECT_ROOT_PATH = Paths.get(System.getProperty("user.dir")).getParent().getParent().getParent();
     private static final String SEATUNNEL_FLINK_BIN = "start-seatunnel-flink.sh";
     private static final String SEATUNNEL_FLINK_JAR = "seatunnel-core-flink.jar";
     private static final String PLUGIN_MAPPING_FILE = "plugin-mapping.properties";

File: seatunnel-e2e/seatunnel-flink-sql-e2e/setunnel-connector-flink-sql-e2e-base/src/test/java/org/apache/seatunnel/e2e/flink/sql/FlinkContainer.java
Patch:
@@ -52,7 +52,7 @@ public abstract class FlinkContainer {
 
     protected GenericContainer<?> jobManager;
     protected GenericContainer<?> taskManager;
-    private static final Path PROJECT_ROOT_PATH = Paths.get(System.getProperty("user.dir")).getParent().getParent();
+    private static final Path PROJECT_ROOT_PATH = Paths.get(System.getProperty("user.dir")).getParent().getParent().getParent();
     private static final String SEATUNNEL_FLINK_BIN = "start-seatunnel-sql.sh";
     private static final String SEATUNNEL_FLINK_SQL_JAR = "seatunnel-core-flink-sql.jar";
     private static final String SEATUNNEL_HOME = "/tmp/flink/seatunnel";

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/connector-spark-e2e-base/src/test/java/org/apache/seatunnel/e2e/spark/SparkContainer.java
Patch:
@@ -51,7 +51,7 @@ public abstract class SparkContainer {
     public static final Network NETWORK = Network.newNetwork();
 
     protected GenericContainer<?> master;
-    private static final Path PROJECT_ROOT_PATH = Paths.get(System.getProperty("user.dir")).getParent().getParent();
+    private static final Path PROJECT_ROOT_PATH = Paths.get(System.getProperty("user.dir")).getParent().getParent().getParent();
     private static final String SEATUNNEL_SPARK_BIN = "start-seatunnel-spark-new-connector.sh";
     private static final String SEATUNNEL_SPARK_JAR = "seatunnel-spark-starter.jar";
     private static final String PLUGIN_MAPPING_FILE = "plugin-mapping.properties";

File: seatunnel-e2e/seatunnel-spark-e2e/seatunnel-connector-spark-e2e-base/src/test/java/org/apache/seatunnel/e2e/spark/SparkContainer.java
Patch:
@@ -51,7 +51,7 @@ public abstract class SparkContainer {
     public static final Network NETWORK = Network.newNetwork();
 
     protected GenericContainer<?> master;
-    private static final Path PROJECT_ROOT_PATH = Paths.get(System.getProperty("user.dir")).getParent().getParent();
+    private static final Path PROJECT_ROOT_PATH = Paths.get(System.getProperty("user.dir")).getParent().getParent().getParent();
     private static final String SEATUNNEL_SPARK_BIN = "start-seatunnel-spark.sh";
     private static final String SEATUNNEL_SPARK_JAR = "seatunnel-core-spark.jar";
     private static final String PLUGIN_MAPPING_FILE = "plugin-mapping.properties";

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/exception/JobNoEnoughResourceException.java
Patch:
@@ -18,8 +18,8 @@
 package org.apache.seatunnel.engine.common.exception;
 
 public class JobNoEnoughResourceException extends SeaTunnelEngineException {
-    public JobNoEnoughResourceException(String jobName, long jobId, int pipelineIndex, int totalPipelineNum) {
-        super(String.format("Job %s (%s), Pipeline [(%s/%s)] have no enough resource.", jobName, jobId, pipelineIndex + 1, totalPipelineNum));
+    public JobNoEnoughResourceException(String jobName, long jobId, int pipelineId, int totalPipelineNum) {
+        super(String.format("Job %s (%s), Pipeline [(%s/%s)] have no enough resource.", jobName, jobId, pipelineId + 1, totalPipelineNum));
     }
 
     public JobNoEnoughResourceException(String message) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlan.java
Patch:
@@ -138,7 +138,7 @@ private void cancelRunningJob() {
                 CompletableFuture<Void> future = CompletableFuture.supplyAsync(() -> {
                     pipeline.cancelPipeline();
                     return null;
-                });
+                }, executorService);
                 return future;
             }
             return null;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/NotifyTaskStatusOperation.java
Patch:
@@ -20,7 +20,6 @@
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.execution.TaskExecutionState;
 import org.apache.seatunnel.engine.server.execution.TaskGroupLocation;
-import org.apache.seatunnel.engine.server.master.JobMaster;
 
 import com.hazelcast.spi.impl.operationservice.Operation;
 
@@ -38,8 +37,7 @@ public NotifyTaskStatusOperation(TaskGroupLocation taskGroupLocation, TaskExecut
     @Override
     public void run() throws Exception {
         SeaTunnelServer service = getService();
-        JobMaster jobMaster = service.getJobMaster(taskGroupLocation.getJobId());
-        //TODO Notify jobMaster of TaskGroup State
+        service.updateTaskExecutionState(taskExecutionState);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/scheduler/PipelineBaseScheduler.java
Patch:
@@ -72,7 +72,7 @@ public Map<Integer, Map<PhysicalVertex, SlotProfile>> startScheduling() {
                 Map<PhysicalVertex, SlotProfile> slotProfiles;
                 try {
                     slotProfiles = applyResourceForPipeline(pipeline);
-                    ownedSlotProfiles.put(pipeline.getPipelineIndex(), slotProfiles);
+                    ownedSlotProfiles.put(pipeline.getPipelineId(), slotProfiles);
                 } catch (Exception e) {
                     throw new RuntimeException(e);
                 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/GetTaskGroupAddressOperation.java
Patch:
@@ -50,7 +50,7 @@ public void run() throws Exception {
         response = RetryUtils.retryWithException(() -> server.getJobMaster(taskLocation.getJobId())
                 .queryTaskGroupAddress(taskLocation.getTaskGroupLocation().getTaskGroupId()),
             new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,
-                exception -> exception instanceof NullPointerException, Constant.OPERATION_RETRY_SLEEP));
+                exception -> exception instanceof IllegalArgumentException, Constant.OPERATION_RETRY_SLEEP));
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/sink/SinkRegisterOperation.java
Patch:
@@ -59,7 +59,7 @@ public void run() throws Exception {
                 task = server.getTaskExecutionService().getTask(committerTaskID);
                 break;
             } catch (NullPointerException e) {
-                LOGGER.warning("can't get committer task , waiting task started");
+                LOGGER.warning("can't get committer task , waiting task started, retry " + i);
                 Thread.sleep(RETRY_INTERVAL);
             }
         }

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/redis/RedisIT.java
Patch:
@@ -64,6 +64,7 @@ public void startRedisContainer() {
 
     private void initJedis() {
         jedis = new Jedis(REDIS_HOST, REDIS_PORT);
+        jedis.connect();
     }
 
     private void generateTestData() {

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/spark/v2/redis/RedisIT.java
Patch:
@@ -64,6 +64,7 @@ public void startRedisContainer() {
 
     private void initJedis() {
         jedis = new Jedis(REDIS_HOST, REDIS_PORT);
+        jedis.connect();
     }
 
     private void generateTestData() {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/checkpoint/Checkpoint.java
Patch:
@@ -22,7 +22,7 @@ public interface Checkpoint {
 
     long getCheckpointId();
 
-    long getPipelineId();
+    int getPipelineId();
 
     long getJobId();
 

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/checkpoint/CheckpointIDCounter.java
Patch:
@@ -18,6 +18,8 @@
 
 package org.apache.seatunnel.engine.core.checkpoint;
 
+import org.apache.seatunnel.engine.core.job.JobStatus;
+
 import java.util.concurrent.CompletableFuture;
 
 /** A checkpoint ID counter. */
@@ -36,7 +38,7 @@ public interface CheckpointIDCounter {
      *
      * @return The {@code CompletableFuture} holding the result of the shutdown operation.
      */
-    CompletableFuture<Void> shutdown();
+    CompletableFuture<Void> shutdown(JobStatus jobStatus);
 
     /**
      * Atomically increments the current checkpoint ID.

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/TaskGroupLocation.java
Patch:
@@ -29,7 +29,7 @@
 public class TaskGroupLocation implements Serializable {
     private final long jobId;
 
-    private final long pipelineId;
+    private final int pipelineId;
 
     private final long taskGroupId;
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SeaTunnelSourceCollector.java
Patch:
@@ -54,7 +54,7 @@ public void close() throws IOException {
         sendRecordToNext(new Record<>(new ClosedSign()));
     }
 
-    private void sendRecordToNext(Record<?> record) throws IOException {
+    public void sendRecordToNext(Record<?> record) throws IOException {
         synchronized (checkpointLock) {
             for (OneInputFlowLifeCycle<Record<?>> output : outputs) {
                 output.received(record);

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/TaskExecutionServiceTest.java
Patch:
@@ -52,7 +52,7 @@ public class TaskExecutionServiceTest extends AbstractSeaTunnelServerTest {
     FlakeIdGenerator flakeIdGenerator;
     long taskRunTime = 2000;
     long jobId = 10001;
-    long pipeLineId = 100001;
+    int pipeLineId = 100001;
 
     @Before
     @Override

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-api/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/PipelineState.java
Patch:
@@ -29,6 +29,6 @@ public class PipelineState {
 
     private String jobId;
     private int pipelineId;
-    private int checkpointId;
+    private long checkpointId;
     private byte[] states;
 }

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-hdfs/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/hdfs/HdfsStorageFactory.java
Patch:
@@ -20,6 +20,7 @@
 
 package org.apache.seatunnel.engine.checkpoint.storage.hdfs;
 
+import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.engine.checkpoint.storage.api.CheckpointStorage;
 import org.apache.seatunnel.engine.checkpoint.storage.api.CheckpointStorageFactory;
 import org.apache.seatunnel.engine.checkpoint.storage.exception.CheckpointStorageException;
@@ -28,10 +29,10 @@
 
 import java.util.Map;
 
-@AutoService(CheckpointStorageFactory.class)
+@AutoService(Factory.class)
 public class HdfsStorageFactory implements CheckpointStorageFactory {
     @Override
-    public String name() {
+    public String factoryIdentifier() {
         return "hdfs";
     }
 

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-local-file/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/localfile/LocalFileStorageFactory.java
Patch:
@@ -20,6 +20,7 @@
 
 package org.apache.seatunnel.engine.checkpoint.storage.localfile;
 
+import org.apache.seatunnel.api.table.factory.Factory;
 import org.apache.seatunnel.engine.checkpoint.storage.api.CheckpointStorage;
 import org.apache.seatunnel.engine.checkpoint.storage.api.CheckpointStorageFactory;
 
@@ -31,11 +32,11 @@
  * Local file storage plug-in, use local file storage,
  * only suitable for single-machine testing or small data scale use, use with caution in production environment
  */
-@AutoService(CheckpointStorageFactory.class)
+@AutoService(Factory.class)
 public class LocalFileStorageFactory implements CheckpointStorageFactory {
 
     @Override
-    public String name() {
+    public String factoryIdentifier() {
         return "localfile";
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlan.java
Patch:
@@ -88,7 +88,7 @@ public PhysicalPlan(@NonNull List<SubPlan> pipelineList,
     }
 
     public void initStateFuture() {
-        pipelineList.stream().forEach(subPlan -> {
+        pipelineList.forEach(subPlan -> {
             PassiveCompletableFuture<PipelineState> future = subPlan.initStateFuture();
             future.whenComplete((v, t) -> {
                 // We need not handle t, Because we will not return t from Pipeline

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/Task.java
Patch:
@@ -40,7 +40,7 @@ default boolean isThreadsShare() {
     default void close() throws IOException {
     }
 
-    default void setTaskExecutionContext(TaskExecutionContext taskExecutionContext){
+    default void setTaskExecutionContext(TaskExecutionContext taskExecutionContext) {
     }
 
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSplitEnumeratorTask.java
Patch:
@@ -57,7 +57,7 @@ public class SourceSplitEnumeratorTask<SplitT extends SourceSplit> extends Coord
     private Map<TaskLocation, Address> taskMemberMapping;
     private Map<Long, TaskLocation> taskIDToTaskLocationMapping;
 
-    private EnumeratorState currState;
+    private volatile EnumeratorState currState;
 
     private CompletableFuture<Void> readerRegisterFuture;
     private CompletableFuture<Void> readerFinishFuture;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/sink/SinkUnregisterOperation.java
Patch:
@@ -46,7 +46,7 @@ public SinkUnregisterOperation(TaskLocation currentTaskID, TaskLocation committe
     public void run() throws Exception {
         SeaTunnelServer server = getService();
         SinkAggregatedCommitterTask<?> task =
-                server.getTaskExecutionService().getExecutionContext(committerTaskID.getTaskGroupLocation()).getTaskGroup().getTask(committerTaskID.getTaskID());
+                server.getTaskExecutionService().getTask(committerTaskID);
         task.receivedWriterUnregister(currentTaskID);
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/AssignSplitOperation.java
Patch:
@@ -50,9 +50,7 @@ public AssignSplitOperation(TaskLocation taskID, List<SplitT> splits) {
     public void run() throws Exception {
         SeaTunnelServer server = getService();
         RetryUtils.retryWithException(() -> {
-            SourceSeaTunnelTask<?, SplitT> task =
-                server.getTaskExecutionService().getExecutionContext(taskID.getTaskGroupLocation()).getTaskGroup()
-                    .getTask(taskID.getTaskID());
+            SourceSeaTunnelTask<?, SplitT> task = server.getTaskExecutionService().getTask(taskID);
             task.receivedSourceSplit(splits);
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/CloseRequestOperation.java
Patch:
@@ -46,9 +46,7 @@ public CloseRequestOperation(TaskLocation readerLocation) {
     public void run() throws Exception {
         SeaTunnelServer server = getService();
         RetryUtils.retryWithException(() -> {
-            SourceSeaTunnelTask<?, ?> task =
-                server.getTaskExecutionService().getExecutionContext(readerLocation.getTaskGroupLocation())
-                    .getTaskGroup().getTask(readerLocation.getTaskID());
+            SourceSeaTunnelTask<?, ?> task = server.getTaskExecutionService().getTask(readerLocation);
             task.close();
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/RequestSplitOperation.java
Patch:
@@ -50,9 +50,7 @@ public void run() throws Exception {
         SeaTunnelServer server = getService();
 
         RetryUtils.retryWithException(() -> {
-            SourceSplitEnumeratorTask<?> task =
-                server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupLocation())
-                    .getTaskGroup().getTask(enumeratorTaskID.getTaskID());
+            SourceSplitEnumeratorTask<?> task = server.getTaskExecutionService().getTask(enumeratorTaskID);
             task.requestSplit(taskID.getTaskID());
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceNoMoreElementOperation.java
Patch:
@@ -49,8 +49,7 @@ public void run() throws Exception {
         SeaTunnelServer server = getService();
         RetryUtils.retryWithException(() -> {
             SourceSplitEnumeratorTask<?> task =
-                server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupLocation())
-                    .getTaskGroup().getTask(enumeratorTaskID.getTaskID());
+                server.getTaskExecutionService().getTask(enumeratorTaskID);
             task.readerFinished(currentTaskID.getTaskID());
             return null;
         }, new RetryUtils.RetryMaterial(Constant.OPERATION_RETRY_TIME, true,

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceRegisterOperation.java
Patch:
@@ -57,8 +57,7 @@ public void run() throws Exception {
         Address readerAddress = getCallerAddress();
         RetryUtils.retryWithException(() -> {
             SourceSplitEnumeratorTask<?> task =
-                server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupLocation()).getTaskGroup()
-                    .getTask(enumeratorTaskID.getTaskID());
+                server.getTaskExecutionService().getTask(enumeratorTaskID);
             task.receivedReader(readerTaskID, readerAddress);
             return null;
         }, new RetryUtils.RetryMaterial(RETRY_TIME, true,

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeRandomData.java
Patch:
@@ -125,7 +125,7 @@ private LocalDateTime randomLocalDateTime() {
         return LocalDateTime.of(
             LocalDateTime.now().getYear(),
             RandomUtils.nextInt(1, 12),
-            RandomUtils.nextInt(1, LocalDateTime.now().getDayOfMonth()),
+            RandomUtils.nextInt(1, 28),
             RandomUtils.nextInt(0, 24),
             RandomUtils.nextInt(0, 59)
         );

File: seatunnel-config/seatunnel-config-shade/src/test/java/org/apache/seatunnel/config/ConfigFactoryTest.java
Patch:
@@ -47,7 +47,7 @@ public void testBasicParseAppConf() throws URISyntaxException {
         Assertions.assertEquals("2", env.getString("spark.executor.instances"));
         Assertions.assertEquals("1", env.getString("spark.executor.cores"));
         Assertions.assertEquals("1g", env.getString("spark.executor.memory"));
-        Assertions.assertEquals("5", env.getString("spark.streaming.batchDuration"));
+        Assertions.assertEquals("5", env.getString("spark.stream.batchDuration"));
 
         // check custom plugin
         Assertions.assertEquals("c.Console", config.getConfigList("sink").get(1).getString("plugin_name"));
@@ -73,7 +73,7 @@ public void testTransformOrder() throws URISyntaxException {
     @Test
     public void testQuotedString() throws URISyntaxException {
         List<String> keys = Arrays.asList("spark.app.name", "spark.executor.instances", "spark.executor.cores",
-                "spark.executor.memory", "spark.streaming.batchDuration");
+                "spark.executor.memory", "spark.stream.batchDuration");
 
         Config config = ConfigFactory.parseFile(FileUtils.getFileFromResources("/factory/config.conf"));
         Config evnConfig = config.getConfig("env");

File: seatunnel-connectors-v2/connector-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeRandomData.java
Patch:
@@ -112,7 +112,7 @@ private Object randomColumnValue(SeaTunnelDataType<?> fieldType) {
             objectObjectHashMap.put(key, value);
             return objectObjectHashMap;
         } else if (fieldType instanceof PrimitiveByteArrayType) {
-            return RandomUtils.nextBytes(100);
+            return RandomUtils.nextBytes(3);
         } else if (VOID_TYPE.equals(fieldType) || fieldType == null) {
             return Void.TYPE;
         } else {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/TaskGroup.java
Patch:
@@ -23,7 +23,7 @@
 
 public interface TaskGroup extends Serializable {
 
-    long getId();
+    TaskGroupLocation getTaskGroupInfo();
 
     void init();
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/scheduler/PipelineBaseScheduler.java
Patch:
@@ -100,7 +100,7 @@ private void applyResourceForTask(PhysicalVertex task) {
             // TODO If there is no enough resources for tasks, we need add some wait profile
             if (task.updateTaskState(ExecutionState.CREATED, ExecutionState.SCHEDULED)) {
                 resourceManager.applyForResource(physicalPlan.getJobImmutableInformation().getJobId(),
-                    task.getTaskGroup().getId());
+                    task.getTaskGroup().getTaskGroupInfo());
             } else {
                 handleTaskStateUpdateError(task, ExecutionState.SCHEDULED);
             }
@@ -115,7 +115,7 @@ private CompletableFuture<Void> deployTask(PhysicalVertex task) {
             return CompletableFuture.supplyAsync(() -> {
                 task.deploy(
                     resourceManager.getAppliedResource(physicalPlan.getJobImmutableInformation().getJobId(),
-                        task.getTaskGroup().getId()));
+                        task.getTaskGroup().getTaskGroupInfo()));
                 return null;
             });
         } else {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/group/TaskGroupWithIntermediateQueue.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.api.table.type.Record;
 import org.apache.seatunnel.engine.server.execution.Task;
 import org.apache.seatunnel.engine.server.execution.TaskGroupDefaultImpl;
+import org.apache.seatunnel.engine.server.execution.TaskGroupLocation;
 import org.apache.seatunnel.engine.server.task.SeaTunnelTask;
 
 import java.util.Collection;
@@ -32,8 +33,8 @@ public class TaskGroupWithIntermediateQueue extends TaskGroupDefaultImpl {
 
     public static final int QUEUE_SIZE = 1000;
 
-    public TaskGroupWithIntermediateQueue(long id, String taskGroupName, Collection<Task> tasks) {
-        super(id, taskGroupName, tasks);
+    public TaskGroupWithIntermediateQueue(TaskGroupLocation taskGroupLocation, String taskGroupName, Collection<Task> tasks) {
+        super(taskGroupLocation, taskGroupName, tasks);
     }
 
     private Map<Long, BlockingQueue<Record<?>>> blockingQueueCache = null;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/sink/SinkRegisterOperation.java
Patch:
@@ -56,7 +56,7 @@ public void run() throws Exception {
         SinkAggregatedCommitterTask<?> task = null;
         for (int i = 0; i < RETRY_TIME; i++) {
             try {
-                task = server.getTaskExecutionService().getExecutionContext(committerTaskID.getTaskGroupID())
+                task = server.getTaskExecutionService().getExecutionContext(committerTaskID.getTaskGroupLocation())
                         .getTaskGroup().getTask(committerTaskID.getTaskID());
                 break;
             } catch (NullPointerException e) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/sink/SinkUnregisterOperation.java
Patch:
@@ -46,7 +46,7 @@ public SinkUnregisterOperation(TaskLocation currentTaskID, TaskLocation committe
     public void run() throws Exception {
         SeaTunnelServer server = getService();
         SinkAggregatedCommitterTask<?> task =
-                server.getTaskExecutionService().getExecutionContext(committerTaskID.getTaskGroupID()).getTaskGroup().getTask(committerTaskID.getTaskID());
+                server.getTaskExecutionService().getExecutionContext(committerTaskID.getTaskGroupLocation()).getTaskGroup().getTask(committerTaskID.getTaskID());
         task.receivedWriterUnregister(currentTaskID);
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/AssignSplitOperation.java
Patch:
@@ -51,7 +51,7 @@ public void run() throws Exception {
         SeaTunnelServer server = getService();
         RetryUtils.retryWithException(() -> {
             SourceSeaTunnelTask<?, SplitT> task =
-                server.getTaskExecutionService().getExecutionContext(taskID.getTaskGroupID()).getTaskGroup()
+                server.getTaskExecutionService().getExecutionContext(taskID.getTaskGroupLocation()).getTaskGroup()
                     .getTask(taskID.getTaskID());
             task.receivedSourceSplit(splits);
             return null;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/CloseRequestOperation.java
Patch:
@@ -47,7 +47,7 @@ public void run() throws Exception {
         SeaTunnelServer server = getService();
         RetryUtils.retryWithException(() -> {
             SourceSeaTunnelTask<?, ?> task =
-                server.getTaskExecutionService().getExecutionContext(readerLocation.getTaskGroupID())
+                server.getTaskExecutionService().getExecutionContext(readerLocation.getTaskGroupLocation())
                     .getTaskGroup().getTask(readerLocation.getTaskID());
             task.close();
             return null;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/RequestSplitOperation.java
Patch:
@@ -51,7 +51,7 @@ public void run() throws Exception {
 
         RetryUtils.retryWithException(() -> {
             SourceSplitEnumeratorTask<?> task =
-                server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupID())
+                server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupLocation())
                     .getTaskGroup().getTask(enumeratorTaskID.getTaskID());
             task.requestSplit(taskID.getTaskID());
             return null;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceNoMoreElementOperation.java
Patch:
@@ -49,7 +49,7 @@ public void run() throws Exception {
         SeaTunnelServer server = getService();
         RetryUtils.retryWithException(() -> {
             SourceSplitEnumeratorTask<?> task =
-                server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupID())
+                server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupLocation())
                     .getTaskGroup().getTask(enumeratorTaskID.getTaskID());
             task.readerFinished(currentTaskID.getTaskID());
             return null;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceRegisterOperation.java
Patch:
@@ -57,7 +57,7 @@ public void run() throws Exception {
         Address readerAddress = getCallerAddress();
         RetryUtils.retryWithException(() -> {
             SourceSplitEnumeratorTask<?> task =
-                server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupID()).getTaskGroup()
+                server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupLocation()).getTaskGroup()
                     .getTask(enumeratorTaskID.getTaskID());
             task.receivedReader(readerTaskID, readerAddress);
             return null;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/SeaTunnelServer.java
Patch:
@@ -138,6 +138,7 @@ public PassiveCompletableFuture<Void> submitJob(long jobId, Data jobImmutableInf
         executorService.submit(() -> {
             try {
                 jobMaster.init();
+                jobMaster.getPhysicalPlan().initStateFuture();
                 runningJobMasterMap.put(jobId, jobMaster);
             } catch (Throwable e) {
                 LOGGER.severe(String.format("submit job %s error %s ", jobId, ExceptionUtils.getMessage(e)));

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -116,8 +116,9 @@ public Container.ExecResult executeSeaTunnelFlinkJob(String confFile) throws IOE
 
         // Running IT use cases under Windows requires replacing \ with /
         String conf = targetConfInContainer.replaceAll("\\\\", "/");
+        String binPath = Paths.get(SEATUNNEL_HOME, "bin", SEATUNNEL_FLINK_BIN).toString().replaceAll("\\\\", "/");
         final List<String> command = new ArrayList<>();
-        command.add(Paths.get(SEATUNNEL_HOME, "bin", SEATUNNEL_FLINK_BIN).toString());
+        command.add(binPath);
         command.add("--config " + conf);
 
         Container.ExecResult execResult = jobManager.execInContainer("bash", "-c", String.join(" ", command));

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/SourceSplitEnumeratorTask.java
Patch:
@@ -135,7 +135,7 @@ public void readerFinished(long taskID) {
     private void stateProcess() throws Exception {
         switch (currState) {
             case INIT:
-                if (readerFinishFuture.isDone()) {
+                if (readerRegisterFuture.isDone()) {
                     readerRegisterFuture.get();
                     currState = EnumeratorState.READER_REGISTER_COMPLETE;
                 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/SourceFlowLifeCycle.java
Patch:
@@ -80,8 +80,9 @@ public void init() throws Exception {
 
     @Override
     public void close() throws IOException {
-        super.close();
+        collector.close();
         reader.close();
+        super.close();
     }
 
     public void collect() throws Exception {
@@ -91,10 +92,9 @@ public void collect() throws Exception {
     }
 
     public void signalNoMoreElement() {
-        // Close this reader
+        // ready close this reader
         try {
             this.closed = true;
-            collector.close();
             runningTask.getExecutionContext().sendToMaster(new SourceNoMoreElementOperation(currentTaskID,
                     enumeratorTaskID)).get();
         } catch (Exception e) {

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/JobClient.java
Patch:
@@ -34,7 +34,7 @@ public long getNewJobId() {
         return hazelcastClient.getHazelcastInstance().getFlakeIdGenerator(Constant.SEATUNNEL_ID_GENERATOR_NAME).newId();
     }
 
-    public JobProxy createJobProxy(@NonNull JobImmutableInformation jobImmutableInformation) {
-        return new JobProxy(hazelcastClient, jobImmutableInformation);
+    public ClientJobProxy createJobProxy(@NonNull JobImmutableInformation jobImmutableInformation) {
+        return new ClientJobProxy(hazelcastClient, jobImmutableInformation);
     }
 }

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/JobConfigParserTest.java
Patch:
@@ -41,7 +41,7 @@ public class JobConfigParserTest {
     @Test
     public void testSimpleJobParse() {
         Common.setDeployMode(DeployMode.CLIENT);
-        String filePath = TestUtils.getResource("/fakesource_to_file.conf");
+        String filePath = TestUtils.getResource("/batch_fakesource_to_file.conf");
         JobConfigParser jobConfigParser = new JobConfigParser(filePath, new IdGenerator(), new JobConfig());
         ImmutablePair<List<Action>, Set<URL>> parse = jobConfigParser.parse();
         List<Action> actions = parse.getLeft();
@@ -59,7 +59,7 @@ public void testSimpleJobParse() {
     @Test
     public void testComplexJobParse() {
         Common.setDeployMode(DeployMode.CLIENT);
-        String filePath = TestUtils.getResource("/fakesource_to_file_complex.conf");
+        String filePath = TestUtils.getResource("/batch_fakesource_to_file_complex.conf");
         JobConfigParser jobConfigParser = new JobConfigParser(filePath, new IdGenerator(), new JobConfig());
         ImmutablePair<List<Action>, Set<URL>> parse = jobConfigParser.parse();
         List<Action> actions = parse.getLeft();

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/LogicalDagGeneratorTest.java
Patch:
@@ -19,7 +19,6 @@
 
 import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.common.config.DeployMode;
-import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.engine.client.job.JobConfigParser;
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.utils.IdGenerator;
@@ -43,9 +42,8 @@ public class LogicalDagGeneratorTest {
     @Test
     public void testLogicalGenerator() {
         Common.setDeployMode(DeployMode.CLIENT);
-        String filePath = TestUtils.getResource("/fakesource_to_file_complex.conf");
+        String filePath = TestUtils.getResource("/batch_fakesource_to_file_complex.conf");
         JobConfig jobConfig = new JobConfig();
-        jobConfig.setMode(JobMode.BATCH);
         jobConfig.setName("fake_to_file");
 
         IdGenerator idGenerator = new IdGenerator();

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/dag/TaskTest.java
Patch:
@@ -77,7 +77,6 @@ public void testTask() throws MalformedURLException {
 
         JobConfig config = new JobConfig();
         config.setName("test");
-        config.setMode(JobMode.BATCH);
 
         JobImmutableInformation jobImmutableInformation = new JobImmutableInformation(1,
             nodeEngine.getSerializationService().toData(logicalDag), config, Collections.emptyList());
@@ -115,7 +114,6 @@ public void testLogicalToPhysical() throws MalformedURLException {
 
         JobConfig config = new JobConfig();
         config.setName("test");
-        config.setMode(JobMode.BATCH);
 
         JobImmutableInformation jobImmutableInformation = new JobImmutableInformation(1,
             nodeEngine.getSerializationService().toData(logicalDag), config, Collections.emptyList());

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/serialization/SerializationSchema.java
Patch:
@@ -19,7 +19,9 @@
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 
-public interface SerializationSchema {
+import java.io.Serializable;
+
+public interface SerializationSchema extends Serializable {
     /**
      * Serializes the incoming element to a specified type.
      *

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/source/AbstractSingleSplitSource.java
Patch:
@@ -17,8 +17,6 @@
 
 package org.apache.seatunnel.connectors.seatunnel.common.source;
 
-import static com.google.common.base.Preconditions.checkArgument;
-
 import org.apache.seatunnel.api.serialization.DefaultSerializer;
 import org.apache.seatunnel.api.serialization.Serializer;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
@@ -29,7 +27,6 @@ public abstract class AbstractSingleSplitSource<T> implements SeaTunnelSource<T,
 
     @Override
     public final AbstractSingleSplitReader<T> createReader(SourceReader.Context readerContext) throws Exception {
-        checkArgument(readerContext.getIndexOfSubtask() == 0, "A single split source allows only one single reader to be created.");
         return createReader(new SingleSplitReaderContext(readerContext));
     }
 

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/SeaTunnelClientTest.java
Patch:
@@ -67,7 +67,7 @@ public void testSayHello() {
     @Test
     public void testExecuteJob() {
         Common.setDeployMode(DeployMode.CLIENT);
-        String filePath = TestUtils.getResource("/fakesource_to_file_complex.conf");
+        String filePath = TestUtils.getResource("/client_test.conf");
         JobConfig jobConfig = new JobConfig();
         jobConfig.setMode(JobMode.BATCH);
         jobConfig.setName("fake_to_file");

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/ExecutionPlanGenerator.java
Patch:
@@ -175,6 +175,7 @@ private void createExecutionVertex(LogicalVertex logicalVertex) {
                 String.join("->", names),
                 jars,
                 transforms);
+            newAction.setParallelism(logicalVertex.getAction().getParallelism());
         }
         ExecutionVertex executionVertex = new ExecutionVertex(newId, newAction, logicalVertex.getParallelism());
         executionVertexMap.put(newId, executionVertex);
@@ -208,6 +209,7 @@ public static Action recreateAction(Action action, Long id) {
         } else {
             throw new UnknownActionException(action);
         }
+        newAction.setParallelism(action.getParallelism());
         return newAction;
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceRegisterOperation.java
Patch:
@@ -63,7 +63,6 @@ public void run() throws Exception {
             return null;
         }, new RetryUtils.RetryMaterial(RETRY_TIME, true,
             exception -> exception instanceof NullPointerException, RETRY_TIME_OUT));
-
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-api/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/api/CheckpointStorageFactory.java
Patch:
@@ -20,6 +20,8 @@
 
 package org.apache.seatunnel.engine.checkpoint.storage.api;
 
+import org.apache.seatunnel.engine.checkpoint.storage.exception.CheckpointStorageException;
+
 import java.util.Map;
 
 /**
@@ -43,5 +45,5 @@ public interface CheckpointStorageFactory {
      *                      value: "fs.defaultFS"
      *                      return storage plugin instance
      */
-    CheckpointStorage create(Map<String, String> configuration);
+    CheckpointStorage create(Map<String, String> configuration) throws CheckpointStorageException;
 }

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-local-file/src/main/java/org/apache/seatunnel/engine/checkpoint/storage/localfile/LocalFileStorageFactory.java
Patch:
@@ -41,6 +41,6 @@ public String name() {
 
     @Override
     public CheckpointStorage create(Map<String, String> configuration) {
-        return new LocalFileStorage();
+        return new LocalFileStorage(configuration);
     }
 }

File: seatunnel-engine/seatunnel-engine-storage/checkpoint-storage-plugins/checkpoint-storage-local-file/src/test/java/org/apache/seatunnel/engine/checkpoint/storage/localfile/LocalFileStorageTest.java
Patch:
@@ -37,7 +37,7 @@
 @EnabledOnOs({LINUX, MAC})
 public class LocalFileStorageTest {
 
-    private static LocalFileStorage STORAGE = new LocalFileStorage();
+    private static LocalFileStorage STORAGE = new LocalFileStorage(null);
     private static final String JOB_ID = "chris";
 
     @Before
@@ -60,7 +60,7 @@ public void setup() throws CheckpointStorageException {
     public void testGetAllCheckpoints() throws CheckpointStorageException {
 
         List<PipelineState> pipelineStates = STORAGE.getAllCheckpoints(JOB_ID);
-        Assertions.assertEquals(4, pipelineStates.size());
+        Assertions.assertEquals(3, pipelineStates.size());
     }
 
     @Test

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/schema/SeatunnelSchema.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.seatunnel.api.table.type.DecimalType;
 import org.apache.seatunnel.api.table.type.LocalTimeType;
 import org.apache.seatunnel.api.table.type.MapType;
+import org.apache.seatunnel.api.table.type.PrimitiveByteArrayType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.api.table.type.SqlType;
@@ -155,8 +156,9 @@ private static SeaTunnelDataType<?> parseTypeByString(String type) {
             case BOOLEAN:
                 return BasicType.BOOLEAN_TYPE;
             case TINYINT:
-            case BYTES:
                 return BasicType.BYTE_TYPE;
+            case BYTES:
+                return PrimitiveByteArrayType.INSTANCE;
             case SMALLINT:
                 return BasicType.SHORT_TYPE;
             case INT:

File: seatunnel-connectors-v2/connector-common/src/test/java/org/apache/seatunnel/connector/common/schema/SchemaParseTest.java
Patch:
@@ -21,6 +21,7 @@
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.DecimalType;
 import org.apache.seatunnel.api.table.type.MapType;
+import org.apache.seatunnel.api.table.type.PrimitiveByteArrayType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.common.schema.SeatunnelSchema;
 
@@ -53,6 +54,8 @@ public void testSimpleSchemaParse() throws FileNotFoundException, URISyntaxExcep
         Assertions.assertEquals(seaTunnelRowType.getFieldType(1), ArrayType.BYTE_ARRAY_TYPE);
         Assertions.assertEquals(seaTunnelRowType.getFieldType(2), BasicType.STRING_TYPE);
         Assertions.assertEquals(seaTunnelRowType.getFieldType(10), new DecimalType(30, 8));
+        Assertions.assertEquals(seaTunnelRowType.getFieldType(11), BasicType.VOID_TYPE);
+        Assertions.assertEquals(seaTunnelRowType.getFieldType(12), PrimitiveByteArrayType.INSTANCE);
     }
 
     @Test

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/serialization/RowConverter.java
Patch:
@@ -124,5 +124,5 @@ protected boolean validate(Object field, SeaTunnelDataType<?> dataType) {
      *
      * @throws IOException Thrown, if the conversion fails.
      */
-    public abstract SeaTunnelRow convert(T engineRow) throws IOException;
+    public abstract SeaTunnelRow reconvert(T engineRow) throws IOException;
 }

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/serialization/FlinkRowConverter.java
Patch:
@@ -86,7 +86,7 @@ private static Object convertMap(Map<?, ?> mapData, MapType<?, ?> mapType, BiFun
     }
 
     @Override
-    public SeaTunnelRow convert(Row engineRow) throws IOException {
+    public SeaTunnelRow reconvert(Row engineRow) throws IOException {
         return (SeaTunnelRow) reconvert(engineRow, dataType);
     }
 

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/sink/FlinkSinkWriter.java
Patch:
@@ -48,7 +48,7 @@ public class FlinkSinkWriter<InputT, CommT, WriterStateT> implements SinkWriter<
     @Override
     public void write(InputT element, org.apache.flink.api.connector.sink.SinkWriter.Context context) throws IOException {
         if (element instanceof Row) {
-            sinkWriter.write(rowSerialization.convert((Row) element));
+            sinkWriter.write(rowSerialization.reconvert((Row) element));
         } else {
             throw new InvalidClassException("only support Flink Row at now, the element Class is " + element.getClass());
         }

File: seatunnel-translation/seatunnel-translation-spark/seatunnel-translation-spark-2.4/src/main/java/org/apache/seatunnel/translation/spark/sink/SparkDataWriter.java
Patch:
@@ -55,7 +55,7 @@ public class SparkDataWriter<CommitInfoT, StateT> implements DataWriter<Internal
 
     @Override
     public void write(InternalRow record) throws IOException {
-        sinkWriter.write(rowConverter.convert(record));
+        sinkWriter.write(rowConverter.reconvert(record));
     }
 
     @Override

File: seatunnel-core/seatunnel-core-spark/src/test/java/org/apache/seatunnel/core/spark/args/SparkCommandArgsTest.java
Patch:
@@ -29,12 +29,12 @@ public class SparkCommandArgsTest {
 
     @Test
     public void testParseSparkArgs() {
-        String[] args = {"-c", "app.conf", "-e", "client", "-m", "yarn", "-i", "city=shijiazhuang", "-i", "name=Tom"};
+        String[] args = {"-c", "app.conf", "-e", "client", "-m", "yarn", "-i", "city=shijiazhuang", "-i", "name=Tom", "-i", "hobby=basketball,football"};
         SparkCommandArgs sparkArgs = CommandLineUtils.parse(args, new SparkCommandArgs(), "seatunnel-spark", true);
         Assertions.assertEquals("app.conf", sparkArgs.getConfigFile());
         Assertions.assertEquals(DeployMode.CLIENT, sparkArgs.getDeployMode());
         Assertions.assertEquals("yarn", sparkArgs.getMaster());
-        Assertions.assertEquals(Arrays.asList("city=shijiazhuang", "name=Tom"), sparkArgs.getVariables());
+        Assertions.assertEquals(Arrays.asList("city=shijiazhuang", "name=Tom", "hobby=basketball,football"), sparkArgs.getVariables());
     }
 
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlanGenerator.java
Patch:
@@ -188,7 +188,7 @@ private List<PhysicalVertex> getCommitterTask(List<ExecutionEdge> edges,
                     long taskGroupID = idGenerator.getNextId();
                     SinkAggregatedCommitterTask<?> t =
                         new SinkAggregatedCommitterTask(jobImmutableInformation.getJobId(),
-                            new TaskLocation(taskGroupID, convertToTaskID(idGenerator.getNextId(), 1)), s,
+                            new TaskLocation(taskGroupID, convertToTaskID(idGenerator.getNextId(), 0)), s,
                             sinkAggregatedCommitter.get());
                     committerTaskIDMap.put(s, new TaskLocation(taskGroupID, t.getTaskID()));
                     CompletableFuture<TaskExecutionState> taskFuture = new CompletableFuture<>();
@@ -261,7 +261,7 @@ private List<PhysicalVertex> getEnumeratorTask(List<SourceAction<?, ?, ?>> sourc
         return sources.stream().map(s -> {
             long taskGroupID = idGenerator.getNextId();
             SourceSplitEnumeratorTask<?> t = new SourceSplitEnumeratorTask<>(jobImmutableInformation.getJobId(),
-                new TaskLocation(taskGroupID, convertToTaskID(idGenerator.getNextId(), 1)), s);
+                new TaskLocation(taskGroupID, convertToTaskID(idGenerator.getNextId(), 0)), s);
             enumeratorTaskIDMap.put(s, new TaskLocation(taskGroupID, t.getTaskID()));
             CompletableFuture<TaskExecutionState> taskFuture = new CompletableFuture<>();
             waitForCompleteByPhysicalVertexList.add(new PassiveCompletableFuture<>(taskFuture));

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SinkCommitter.java
Patch:
@@ -34,11 +34,11 @@ public interface SinkCommitter<CommitInfoT> extends Serializable {
     /**
      * Commit message to third party data receiver, The method need to achieve idempotency.
      *
-     * @param committables The list of commit message
+     * @param commitInfos The list of commit message
      * @return The commit message need retry.
      * @throws IOException throw IOException when commit failed.
      */
-    List<CommitInfoT> commit(List<CommitInfoT> committables) throws IOException;
+    List<CommitInfoT> commit(List<CommitInfoT> commitInfos) throws IOException;
 
     /**
      * Abort the transaction, this method will be called (**Only** on Spark engine) when the commit is failed.

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/Action.java
Patch:
@@ -22,6 +22,7 @@
 import java.io.Serializable;
 import java.net.URL;
 import java.util.List;
+import java.util.Set;
 
 public interface Action extends Serializable {
     @NonNull
@@ -40,5 +41,5 @@ public interface Action extends Serializable {
 
     long getId();
 
-    List<URL> getJarUrls();
+    Set<URL> getJarUrls();
 }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/PartitionTransformAction.java
Patch:
@@ -23,6 +23,7 @@
 
 import java.net.URL;
 import java.util.List;
+import java.util.Set;
 
 public class PartitionTransformAction extends AbstractAction {
 
@@ -32,15 +33,15 @@ public PartitionTransformAction(long id,
                                     @NonNull String name,
                                     @NonNull List<Action> upstreams,
                                     @NonNull PartitionSeaTunnelTransform partitionTransformation,
-                                    @NonNull List<URL> jarUrls) {
+                                    @NonNull Set<URL> jarUrls) {
         super(id, name, upstreams, jarUrls);
         this.partitionTransformation = partitionTransformation;
     }
 
     public PartitionTransformAction(long id,
                                     @NonNull String name,
                                     @NonNull PartitionSeaTunnelTransform partitionTransformation,
-                                    @NonNull List<URL> jarUrls) {
+                                    @NonNull Set<URL> jarUrls) {
         super(id, name, jarUrls);
         this.partitionTransformation = partitionTransformation;
     }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/SinkAction.java
Patch:
@@ -23,6 +23,7 @@
 
 import java.net.URL;
 import java.util.List;
+import java.util.Set;
 
 @SuppressWarnings("checkstyle:ClassTypeParameterName")
 public class SinkAction<IN, StateT, CommitInfoT, AggregatedCommitInfoT> extends AbstractAction {
@@ -32,15 +33,15 @@ public SinkAction(long id,
                       @NonNull String name,
                       @NonNull List<Action> upstreams,
                       @NonNull SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT> sink,
-                      @NonNull List<URL> jarUrls) {
+                      @NonNull Set<URL> jarUrls) {
         super(id, name, upstreams, jarUrls);
         this.sink = sink;
     }
 
     public SinkAction(long id,
                       @NonNull String name,
                       @NonNull SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT> sink,
-                      @NonNull List<URL> jarUrls) {
+                      @NonNull Set<URL> jarUrls) {
         super(id, name, jarUrls);
         this.sink = sink;
     }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/SourceAction.java
Patch:
@@ -25,7 +25,7 @@
 
 import java.io.Serializable;
 import java.net.URL;
-import java.util.List;
+import java.util.Set;
 
 public class SourceAction<T, SplitT extends SourceSplit, StateT extends Serializable> extends AbstractAction {
 
@@ -35,7 +35,7 @@ public class SourceAction<T, SplitT extends SourceSplit, StateT extends Serializ
     public SourceAction(long id,
                         @NonNull String name,
                         @NonNull SeaTunnelSource<T, SplitT, StateT> source,
-                        @NonNull List<URL> jarUrls) {
+                        @NonNull Set<URL> jarUrls) {
         super(id, name, Lists.newArrayList(), jarUrls);
         this.source = source;
     }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/TransformAction.java
Patch:
@@ -23,6 +23,7 @@
 
 import java.net.URL;
 import java.util.List;
+import java.util.Set;
 
 public class TransformAction extends AbstractAction {
     private final SeaTunnelTransform<?> transform;
@@ -31,15 +32,15 @@ public TransformAction(long id,
                            @NonNull String name,
                            @NonNull List<Action> upstreams,
                            @NonNull SeaTunnelTransform<?> transform,
-                           @NonNull List<URL> jarUrls) {
+                           @NonNull Set<URL> jarUrls) {
         super(id, name, upstreams, jarUrls);
         this.transform = transform;
     }
 
     public TransformAction(long id,
                            @NonNull String name,
                            @NonNull SeaTunnelTransform<?> transform,
-                           @NonNull List<URL> jarUrls) {
+                           @NonNull Set<URL> jarUrls) {
         super(id, name, jarUrls);
         this.transform = transform;
     }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/TransformChainAction.java
Patch:
@@ -23,6 +23,7 @@
 
 import java.net.URL;
 import java.util.List;
+import java.util.Set;
 
 public class TransformChainAction<T> extends AbstractAction {
 
@@ -32,15 +33,15 @@ public class TransformChainAction<T> extends AbstractAction {
     public TransformChainAction(long id,
                                 @NonNull String name,
                                 @NonNull List<Action> upstreams,
-                                @NonNull List<URL> jarUrls,
+                                @NonNull Set<URL> jarUrls,
                                 @NonNull List<SeaTunnelTransform<T>> transforms) {
         super(id, name, upstreams, jarUrls);
         this.transforms = transforms;
     }
 
     public TransformChainAction(long id,
                                 @NonNull String name,
-                                @NonNull List<URL> jarUrls,
+                                @NonNull Set<URL> jarUrls,
                                 @NonNull List<SeaTunnelTransform<T>> transforms) {
         super(id, name, jarUrls);
         this.transforms = transforms;

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/job/Job.java
Patch:
@@ -24,5 +24,5 @@ public interface Job {
 
     void submitJob() throws ExecutionException, InterruptedException;
 
-    void waitForJobComplete();
+    JobStatus waitForJobComplete();
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/SeaTunnelServer.java
Patch:
@@ -23,6 +23,7 @@
 import org.apache.seatunnel.engine.core.job.JobStatus;
 import org.apache.seatunnel.engine.server.master.JobMaster;
 
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
 import com.hazelcast.instance.impl.Node;
 import com.hazelcast.internal.serialization.Data;
 import com.hazelcast.internal.services.ManagedService;
@@ -69,7 +70,8 @@ public SeaTunnelServer(@NonNull Node node, @NonNull SeaTunnelConfig seaTunnelCon
         this.liveOperationRegistry = new LiveOperationRegistry();
         this.seaTunnelConfig = seaTunnelConfig;
         this.executorService =
-            Executors.newFixedThreadPool(seaTunnelConfig.getEngineConfig().getServerExecutorPoolSize());
+            Executors.newCachedThreadPool(new ThreadFactoryBuilder()
+                .setNameFormat("seatunnel-server-executor-%d").build());
         logger.info("SeaTunnel server start...");
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/ExecutionPlanGenerator.java
Patch:
@@ -173,7 +173,7 @@ private void createExecutionVertex(LogicalVertex logicalVertex) {
                 });
             newAction = new TransformChainAction(newId,
                 String.join("->", names),
-                new ArrayList<>(jars),
+                jars,
                 transforms);
         }
         ExecutionVertex executionVertex = new ExecutionVertex(newId, newAction, logicalVertex.getParallelism());

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/PhysicalPlanGenerator.java
Patch:
@@ -204,7 +204,7 @@ private List<PhysicalVertex> getCommitterTask(List<ExecutionEdge> edges,
                         flakeIdGenerator,
                         pipelineIndex,
                         totalPipelineNum,
-                        null,
+                        s.getJarUrls(),
                         jobImmutableInformation,
                         initializationTimestamp,
                         nodeEngine);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceRegisterOperation.java
Patch:
@@ -36,8 +36,8 @@
  * the {@link org.apache.seatunnel.api.source.SourceSplitEnumerator}
  */
 public class SourceRegisterOperation extends Operation implements IdentifiedDataSerializable {
-
     private static final int RETRY_TIME = 5;
+
     private static final int RETRY_TIME_OUT = 2000;
 
     private TaskLocation readerTaskID;
@@ -57,7 +57,8 @@ public void run() throws Exception {
         Address readerAddress = getCallerAddress();
         RetryUtils.retryWithException(() -> {
             SourceSplitEnumeratorTask<?> task =
-                    server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupID()).getTaskGroup().getTask(enumeratorTaskID.getTaskID());
+                server.getTaskExecutionService().getExecutionContext(enumeratorTaskID.getTaskGroupID()).getTaskGroup()
+                    .getTask(enumeratorTaskID.getTaskID());
             task.receivedReader(readerTaskID, readerAddress);
             return null;
         }, new RetryUtils.RetryMaterial(RETRY_TIME, true,

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/execution/TestTask.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.engine.server.execution;
 
+import org.apache.seatunnel.common.utils.ExceptionUtils;
+
 import com.hazelcast.logging.ILogger;
 import lombok.NonNull;
 
@@ -48,8 +50,7 @@ public ProgressState call() {
             try {
                 Thread.sleep(sleep);
             } catch (InterruptedException e) {
-                // The test needs to do that
-                logger.info(e.getMessage());
+                logger.severe(ExceptionUtils.getMessage(e));
             }
             progressState = ProgressState.MADE_PROGRESS;
         } else {

File: seatunnel-connectors-v2/connector-http/connector-http-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/config/HttpParameter.java
Patch:
@@ -47,7 +47,7 @@ public void buildWithConfig(Config pluginConfig) {
         }
         // set params
         if (pluginConfig.hasPath(HttpConfig.PARAMS)) {
-            this.setHeaders(pluginConfig.getConfig(HttpConfig.PARAMS).entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, entry -> String.valueOf(entry.getValue().unwrapped()), (v1, v2) -> v2)));
+            this.setParams(pluginConfig.getConfig(HttpConfig.PARAMS).entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, entry -> String.valueOf(entry.getValue().unwrapped()), (v1, v2) -> v2)));
         }
         // set body
         if (pluginConfig.hasPath(HttpConfig.BODY)) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/CheckpointTriggerOperation.java
Patch:
@@ -38,7 +38,7 @@ public CheckpointTriggerOperation(CheckpointBarrier checkpointBarrier) {
 
     @Override
     public int getClassId() {
-        return OperationDataSerializerHook.SUBMIT_OPERATOR;
+        return OperationDataSerializerHook.CHECKPOINT_TRIGGER_OPERATOR;
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceRegisterOperation.java
Patch:
@@ -61,7 +61,7 @@ public void run() throws Exception {
             task.receivedReader(readerTaskID, readerAddress);
             return null;
         }, new RetryUtils.RetryMaterial(RETRY_TIME, true,
-                exception -> exception instanceof NullPointerException, RETRY_TIME_OUT));
+            exception -> exception instanceof NullPointerException, RETRY_TIME_OUT));
 
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/dag/TaskTest.java
Patch:
@@ -36,7 +36,7 @@
 import org.apache.seatunnel.engine.server.SeaTunnelNodeContext;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.dag.physical.PhysicalPlan;
-import org.apache.seatunnel.engine.server.dag.physical.PhysicalPlanUtils;
+import org.apache.seatunnel.engine.server.dag.physical.PlanUtils;
 
 import com.hazelcast.config.Config;
 import com.hazelcast.instance.impl.HazelcastInstanceFactory;
@@ -145,11 +145,11 @@ public void testLogicalToPhysical() throws MalformedURLException {
         JobImmutableInformation jobImmutableInformation = new JobImmutableInformation(1,
                 nodeEngine.getSerializationService().toData(logicalDag), config, Collections.emptyList());
 
-        PhysicalPlan physicalPlan = PhysicalPlanUtils.fromLogicalDAG(logicalDag, nodeEngine,
+        PhysicalPlan physicalPlan = PlanUtils.fromLogicalDAG(logicalDag, nodeEngine,
                 jobImmutableInformation,
                 System.currentTimeMillis(),
                 Executors.newCachedThreadPool(),
-                instance.getFlakeIdGenerator(Constant.SEATUNNEL_ID_GENERATOR_NAME));
+                instance.getFlakeIdGenerator(Constant.SEATUNNEL_ID_GENERATOR_NAME)).f0();
 
         Assert.assertEquals(physicalPlan.getPipelineList().size(), 1);
         Assert.assertEquals(physicalPlan.getPipelineList().get(0).getCoordinatorVertexList().size(), 1);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceRegisterOperation.java
Patch:
@@ -38,6 +38,7 @@
 public class SourceRegisterOperation extends Operation implements IdentifiedDataSerializable {
 
     private static final int RETRY_TIME = 5;
+    private static final int RETRY_TIME_OUT = 2000;
 
     private TaskLocation readerTaskID;
     private TaskLocation enumeratorTaskID;
@@ -60,7 +61,7 @@ public void run() throws Exception {
             task.receivedReader(readerTaskID, readerAddress);
             return null;
         }, new RetryUtils.RetryMaterial(RETRY_TIME, true,
-                exception -> exception instanceof NullPointerException));
+                exception -> exception instanceof NullPointerException, RETRY_TIME_OUT));
 
     }
 

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/SeaTunnelClientTest.java
Patch:
@@ -84,8 +84,6 @@ public void testExecuteJob() {
             jobProxy.waitForJobComplete();
         } catch (ExecutionException | InterruptedException e) {
             throw new RuntimeException(e);
-            // TODO throw exception after fix sink.setTypeInfo in ConnectorInstanceLoader
-            //            throw new RuntimeException(e);
         }
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/DeployTaskOperation.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.engine.server.operation;
 
 import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
-import org.apache.seatunnel.engine.server.TaskExecutionService;
+import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
 
 import com.hazelcast.internal.nio.IOUtil;
@@ -41,8 +41,8 @@ public DeployTaskOperation(@NonNull Data taskImmutableInformation) {
 
     @Override
     protected PassiveCompletableFuture<?> doRun() throws Exception {
-        TaskExecutionService taskExecutionService = getService();
-        return taskExecutionService.deployTask(taskImmutableInformation);
+        SeaTunnelServer server = getService();
+        return server.getTaskExecutionService().deployTask(taskImmutableInformation);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/flow/SourceFlowLifeCycle.java
Patch:
@@ -25,8 +25,8 @@
 import org.apache.seatunnel.engine.server.task.SeaTunnelTask;
 import org.apache.seatunnel.engine.server.task.context.SourceReaderContext;
 import org.apache.seatunnel.engine.server.task.operation.source.RequestSplitOperation;
+import org.apache.seatunnel.engine.server.task.operation.source.SourceNoMoreElementOperation;
 import org.apache.seatunnel.engine.server.task.operation.source.SourceRegisterOperation;
-import org.apache.seatunnel.engine.server.task.operation.source.SourceUnregisterOperation;
 
 import com.hazelcast.logging.ILogger;
 import com.hazelcast.logging.Logger;
@@ -95,9 +95,8 @@ public void signalNoMoreElement() {
         try {
             this.closed = true;
             collector.close();
-            runningTask.getExecutionContext().sendToMaster(new SourceUnregisterOperation(currentTaskID,
+            runningTask.getExecutionContext().sendToMaster(new SourceNoMoreElementOperation(currentTaskID,
                     enumeratorTaskID)).get();
-            this.close();
         } catch (Exception e) {
             LOGGER.warning("source close failed ", e);
             throw new RuntimeException(e);

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/task/operation/source/SourceNoMoreElementOperation.java
Patch:
@@ -29,15 +29,15 @@
 
 import java.io.IOException;
 
-public class SourceUnregisterOperation extends Operation implements IdentifiedDataSerializable {
+public class SourceNoMoreElementOperation extends Operation implements IdentifiedDataSerializable {
 
     private TaskLocation currentTaskID;
     private TaskLocation enumeratorTaskID;
 
-    public SourceUnregisterOperation() {
+    public SourceNoMoreElementOperation() {
     }
 
-    public SourceUnregisterOperation(TaskLocation currentTaskID, TaskLocation enumeratorTaskID) {
+    public SourceNoMoreElementOperation(TaskLocation currentTaskID, TaskLocation enumeratorTaskID) {
         this.currentTaskID = currentTaskID;
         this.enumeratorTaskID = enumeratorTaskID;
     }

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/execution/ExceptionTestTask.java
Patch:
@@ -33,9 +33,9 @@ public class ExceptionTestTask implements Task {
     @NonNull
     @Override
     public ProgressState call() {
-        if(!throwE.isEmpty()){
+        if (!throwE.isEmpty()) {
             throw throwE.get(0);
-        }else {
+        } else {
             Thread.sleep(callTime);
         }
         return ProgressState.MADE_PROGRESS;

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/execution/FixedCallTestTimeTask.java
Patch:
@@ -29,7 +29,7 @@ public class FixedCallTestTimeTask implements Task {
     CopyOnWriteArrayList<Long> lagList;
     AtomicBoolean stop;
 
-    public FixedCallTestTimeTask(long callTime, String name, AtomicBoolean stop, CopyOnWriteArrayList<Long> lagList){
+    public FixedCallTestTimeTask(long callTime, String name, AtomicBoolean stop, CopyOnWriteArrayList<Long> lagList) {
         this.callTime = callTime;
         this.name = name;
         this.stop = stop;
@@ -39,7 +39,7 @@ public FixedCallTestTimeTask(long callTime, String name, AtomicBoolean stop, Cop
     @NonNull
     @Override
     public ProgressState call() {
-        if(currentTime != 0){
+        if (currentTime != 0) {
             lagList.add(System.currentTimeMillis() - currentTime);
         }
         currentTime = System.currentTimeMillis();
@@ -49,7 +49,7 @@ public ProgressState call() {
         } catch (InterruptedException e) {
             throw new RuntimeException(e.toString());
         }
-        if(stop.get()){
+        if (stop.get()) {
             return ProgressState.DONE;
         }
         return ProgressState.MADE_PROGRESS;

File: seatunnel-engine/seatunnel-engine-server/src/test/java/org/apache/seatunnel/engine/server/execution/StopTimeTestTask.java
Patch:
@@ -37,7 +37,7 @@ public ProgressState call() {
         } catch (InterruptedException e) {
             throw new RuntimeException(e.toString());
         }
-        if(stop.get()){
+        if (stop.get()) {
             stopList.add(Thread.currentThread().getId());
             return ProgressState.DONE;
         }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/logical/LogicalDagGenerator.java
Patch:
@@ -88,8 +88,8 @@ private Set<LogicalEdge> createLogicalEdges() {
                 .stream()
                 .map(entry -> entry.getValue()
                         .stream()
-                        .map(upstreamId -> new LogicalEdge(logicalVertexMap.get(upstreamId),
-                                logicalVertexMap.get(entry.getKey())))
+                        .map(targetId -> new LogicalEdge(logicalVertexMap.get(entry.getKey()),
+                                logicalVertexMap.get(targetId)))
                         .collect(Collectors.toList()))
                 .flatMap(Collection::stream)
                 .collect(Collectors.toSet());

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/LogicalDagGeneratorTest.java
Patch:
@@ -57,7 +57,7 @@ public void testLogicalGenerator() {
         LogicalDag logicalDag = logicalDagGenerator.generate();
         JsonObject logicalDagJson = logicalDag.getLogicalDagAsJson();
         String result =
-            "{\"vertices\":[{\"id\":1,\"name\":\"LocalFile(id=1)\",\"parallelism\":6},{\"id\":2,\"name\":\"FakeSource(id=2)\",\"parallelism\":3},{\"id\":3,\"name\":\"FakeSource(id=3)\",\"parallelism\":3}],\"edges\":[{\"inputVertex\":\"LocalFile\",\"targetVertex\":\"FakeSource\"},{\"inputVertex\":\"LocalFile\",\"targetVertex\":\"FakeSource\"}]}";
+            "{\"vertices\":[{\"id\":1,\"name\":\"LocalFile(id=1)\",\"parallelism\":6},{\"id\":2,\"name\":\"FakeSource(id=2)\",\"parallelism\":3},{\"id\":3,\"name\":\"FakeSource(id=3)\",\"parallelism\":3}],\"edges\":[{\"inputVertex\":\"FakeSource\",\"targetVertex\":\"LocalFile\"},{\"inputVertex\":\"FakeSource\",\"targetVertex\":\"LocalFile\"}]}";
         Assert.assertEquals(result, logicalDagJson.toString());
     }
 }

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/SeaTunnelClient.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.engine.client;
 
+import org.apache.seatunnel.engine.client.job.JobClient;
+import org.apache.seatunnel.engine.client.job.JobExecutionEnvironment;
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.core.protocol.codec.SeaTunnelPrintMessageCodec;
 

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/SeaTunnelClientInstance.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.engine.client;
 
+import org.apache.seatunnel.engine.client.job.JobClient;
+import org.apache.seatunnel.engine.client.job.JobExecutionEnvironment;
 import org.apache.seatunnel.engine.common.config.JobConfig;
 
 public interface SeaTunnelClientInstance {

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/job/JobClient.java
Patch:
@@ -15,8 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.client;
+package org.apache.seatunnel.engine.client.job;
 
+import org.apache.seatunnel.engine.client.SeaTunnelHazelcastClient;
 import org.apache.seatunnel.engine.common.Constant;
 import org.apache.seatunnel.engine.core.job.JobImmutableInformation;
 

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/JobConfigParserTest.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.common.config.DeployMode;
+import org.apache.seatunnel.engine.client.job.JobConfigParser;
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.utils.IdGenerator;
 import org.apache.seatunnel.engine.core.dag.actions.Action;

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/LogicalDagGeneratorTest.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.common.config.DeployMode;
 import org.apache.seatunnel.common.constants.JobMode;
+import org.apache.seatunnel.engine.client.job.JobConfigParser;
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.utils.IdGenerator;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
@@ -48,7 +49,8 @@ public void testLogicalGenerator() {
         jobConfig.setName("fake_to_file");
 
         IdGenerator idGenerator = new IdGenerator();
-        ImmutablePair<List<Action>, Set<URL>> immutablePair = new JobConfigParser(filePath, idGenerator, new JobConfig()).parse();
+        ImmutablePair<List<Action>, Set<URL>> immutablePair =
+            new JobConfigParser(filePath, idGenerator, new JobConfig()).parse();
 
         LogicalDagGenerator logicalDagGenerator =
             new LogicalDagGenerator(immutablePair.getLeft(), jobConfig, idGenerator);

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/job/Job.java
Patch:
@@ -23,4 +23,6 @@ public interface Job {
     long getJobId();
 
     void submitJob() throws ExecutionException, InterruptedException;
+
+    void waitForJobComplete();
 }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/protocol/codec/SeaTunnelPrintMessageCodec.java
Patch:
@@ -61,9 +61,6 @@ public static ClientMessage encodeRequest(java.lang.String message) {
         return clientMessage;
     }
 
-    /**
-     *
-     */
     public static java.lang.String decodeRequest(ClientMessage clientMessage) {
         ClientMessage.ForwardFrameIterator iterator = clientMessage.frameIterator();
         //empty initial frame

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/AsyncOperation.java
Patch:
@@ -23,7 +23,7 @@
 import static com.hazelcast.spi.impl.operationservice.ExceptionAction.THROW_EXCEPTION;
 
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
-import org.apache.seatunnel.engine.common.utils.NonCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.server.SeaTunnelServer;
 import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
 
@@ -47,7 +47,7 @@ public void beforeRun() {
 
     @Override
     public final void run() {
-        NonCompletableFuture<?> future;
+        PassiveCompletableFuture<?> future;
         try {
             future = doRun();
         } catch (Exception e) {
@@ -58,7 +58,7 @@ public final void run() {
         future.whenComplete(withTryCatch(getLogger(), (r, f) -> doSendResponse(f != null ? peel(f) : r)));
     }
 
-    protected abstract NonCompletableFuture<?> doRun() throws Exception;
+    protected abstract PassiveCompletableFuture<?> doRun() throws Exception;
 
     @Override
     public final boolean returnsResponse() {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/operation/CheckpointTriggerOperation.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.engine.server.operation;
 
-import org.apache.seatunnel.engine.common.utils.NonCompletableFuture;
+import org.apache.seatunnel.engine.common.utils.PassiveCompletableFuture;
 import org.apache.seatunnel.engine.core.checkpoint.CheckpointBarrier;
 import org.apache.seatunnel.engine.server.serializable.OperationDataSerializerHook;
 
@@ -52,7 +52,7 @@ protected void readInternal(ObjectDataInput in) throws IOException {
     }
 
     @Override
-    protected NonCompletableFuture<?> doRun() throws Exception {
+    protected PassiveCompletableFuture<?> doRun() throws Exception {
         // TODO: All source Vertexes executed
         return null;
     }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/protocol/task/SubmitJobTask.java
Patch:
@@ -23,10 +23,9 @@
 import com.hazelcast.client.impl.protocol.ClientMessage;
 import com.hazelcast.instance.impl.Node;
 import com.hazelcast.internal.nio.Connection;
-import com.hazelcast.internal.serialization.Data;
 import com.hazelcast.spi.impl.operationservice.Operation;
 
-public class SubmitJobTask extends AbstractSeaTunnelMessageTask<Data, Void> {
+public class SubmitJobTask extends AbstractSeaTunnelMessageTask<SeaTunnelSubmitJobCodec.RequestParameters, Void> {
 
     protected SubmitJobTask(ClientMessage clientMessage, Node node, Connection connection) {
         super(clientMessage, node, connection,
@@ -36,7 +35,7 @@ protected SubmitJobTask(ClientMessage clientMessage, Node node, Connection conne
 
     @Override
     protected Operation prepareOperation() {
-        return new SubmitJobOperation(parameters);
+        return new SubmitJobOperation(parameters.jobId, parameters.jobImmutableInformation);
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/LogicalDagGeneratorTest.java
Patch:
@@ -55,7 +55,7 @@ public void testLogicalGenerator() {
         LogicalDag logicalDag = logicalDagGenerator.generate();
         JsonObject logicalDagJson = logicalDag.getLogicalDagAsJson();
         String result =
-            "{\"vertices\":[{\"id\":2,\"name\":\"FakeSource(id=2)\",\"parallelism\":3},{\"id\":3,\"name\":\"FakeSource(id=3)\",\"parallelism\":3},{\"id\":1,\"name\":\"LocalFile(id=1)\",\"parallelism\":6}],\"edges\":[{\"leftVertex\":\"FakeSource\",\"rightVertex\":\"LocalFile\"},{\"leftVertex\":\"FakeSource\",\"rightVertex\":\"LocalFile\"}]}";
+            "{\"vertices\":[{\"id\":1,\"name\":\"LocalFile(id=1)\",\"parallelism\":6},{\"id\":2,\"name\":\"FakeSource(id=2)\",\"parallelism\":3},{\"id\":3,\"name\":\"FakeSource(id=3)\",\"parallelism\":3}],\"edges\":[{\"inputVertex\":\"LocalFile\",\"targetVertex\":\"FakeSource\"},{\"inputVertex\":\"LocalFile\",\"targetVertex\":\"FakeSource\"}]}";
         Assert.assertEquals(result, logicalDagJson.toString());
     }
 }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/logical/LogicalDag.java
Patch:
@@ -105,8 +105,8 @@ public JsonObject getLogicalDagAsJson() {
         JsonArray edges = new JsonArray();
         this.edges.stream().forEach(e -> {
             JsonObject edge = new JsonObject();
-            edge.add("leftVertex", e.getLeftVertex().getAction().getName());
-            edge.add("rightVertex", e.getRightVertex().getAction().getName());
+            edge.add("inputVertex", e.getInputVertex().getAction().getName());
+            edge.add("targetVertex", e.getTargetVertex().getAction().getName());
             edges.add(edge);
         });
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/physical/flow/Flow.java
Patch:
@@ -31,4 +31,6 @@ public Flow(List<Flow> next) {
     public List<Flow> getNext() {
         return next;
     }
+
+    public abstract long getFlowID();
 }

File: seatunnel-core/seatunnel-seatunnel-starter/src/main/java/org/apache/seatunnel/core/starter/seatunnel/SeaTunnelStarter.java
Patch:
@@ -39,6 +39,7 @@ public static void main(String[] args) {
         Common.setDeployMode(DeployMode.CLIENT);
         JobConfig jobConfig = new JobConfig();
         jobConfig.setName("fake_to_file");
+        // TODO change jobConfig mode
 
         ClientConfig clientConfig = ConfigProvider.locateAndGetClientConfig();
         SeaTunnelClient engineClient = new SeaTunnelClient(clientConfig);

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/ConnectorInstanceLoader.java
Patch:
@@ -79,15 +79,16 @@ public static ImmutablePair<SeaTunnelSink<SeaTunnelRow, Serializable, Serializab
         return new ImmutablePair<>(seaTunnelSink, pluginJarPaths);
     }
 
-    public static ImmutablePair<SeaTunnelTransform, List<URL>> loadTransformInstance(Config transformConfig) {
+    public static ImmutablePair<SeaTunnelTransform<?>, List<URL>> loadTransformInstance(Config transformConfig) {
         SeaTunnelTransformPluginDiscovery transformPluginDiscovery = new SeaTunnelTransformPluginDiscovery();
         PluginIdentifier pluginIdentifier = PluginIdentifier.of(
             CollectionConstants.SEATUNNEL_PLUGIN,
             CollectionConstants.TRANSFORM_PLUGIN,
             transformConfig.getString(CollectionConstants.PLUGIN_NAME));
 
         List<URL> pluginJarPaths = transformPluginDiscovery.getPluginJarPaths(Lists.newArrayList(pluginIdentifier));
-        SeaTunnelTransform seaTunnelTransform = transformPluginDiscovery.createPluginInstance(pluginIdentifier);
+        SeaTunnelTransform<?> seaTunnelTransform =
+                transformPluginDiscovery.createPluginInstance(pluginIdentifier);
         return new ImmutablePair<>(seaTunnelTransform, pluginJarPaths);
     }
 }

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/LogicalDagGeneratorTest.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.seatunnel.engine.client;
 
-import org.apache.seatunnel.api.source.Boundedness;
 import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.common.config.DeployMode;
+import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.utils.IdGenerator;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
@@ -44,7 +44,7 @@ public void testLogicalGenerator() {
         Common.setDeployMode(DeployMode.CLIENT);
         String filePath = TestUtils.getResource("/fakesource_to_file_complex.conf");
         JobConfig jobConfig = new JobConfig();
-        jobConfig.setBoundedness(Boundedness.BOUNDED);
+        jobConfig.setMode(JobMode.BATCH);
         jobConfig.setName("fake_to_file");
 
         IdGenerator idGenerator = new IdGenerator();

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/config/JobConfig.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.engine.common.config;
 
-import org.apache.seatunnel.api.source.Boundedness;
+import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.engine.common.serializeable.ConfigDataSerializerHook;
 
 import com.hazelcast.nio.ObjectDataInput;
@@ -30,7 +30,7 @@
 @Data
 public class JobConfig implements IdentifiedDataSerializable {
     private String name;
-    private Boundedness boundedness;
+    private JobMode mode;
 
     @Override
     public int getFactoryId() {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/ExecutionState.java
Patch:
@@ -18,6 +18,8 @@
 
 package org.apache.seatunnel.engine.server.execution;
 
+import java.io.Serializable;
+
 /**
  * An enumeration of all states that a task can be in during its execution. Tasks usually start in
  * the state {@code CREATED} and switch states according to this diagram:
@@ -43,7 +45,7 @@
  * <p>The states {@code FINISHED}, {@code CANCELED}, and {@code FAILED} are considered terminal
  * states.
  */
-public enum ExecutionState {
+public enum ExecutionState implements Serializable {
     CREATED,
 
     SCHEDULED,

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/execution/TaskExecutionState.java
Patch:
@@ -17,7 +17,9 @@
 
 package org.apache.seatunnel.engine.server.execution;
 
-public class TaskExecutionState {
+import java.io.Serializable;
+
+public class TaskExecutionState implements Serializable {
 
     private final long taskExecutionId;
 

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/LocalFileSink.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local.sink;
 
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.AbstractFileSink;

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/filesystem/LocalFileSystem.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local.sink.filesystem;
 
 import org.apache.seatunnel.connectors.seatunnel.file.sink.spi.FileSystem;
 

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/filesystem/LocalFileSystemCommitter.java
Patch:
@@ -15,8 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local.sink.filesystem;
 
+import org.apache.seatunnel.connectors.seatunnel.file.local.sink.util.FileUtils;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileAggregatedCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.spi.FileSystemCommitter;
 

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/util/FileUtils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local.sink.util;
 
 import lombok.NonNull;
 import org.slf4j.Logger;

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/writer/LocalJsonTransactionStateFileWriter.java
Patch:
@@ -15,11 +15,12 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local.sink.writer;
 
 import org.apache.seatunnel.api.serialization.SerializationSchema;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
+import org.apache.seatunnel.connectors.seatunnel.file.local.sink.util.FileUtils;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.spi.FileSystem;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.transaction.TransactionFileNameGenerator;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.writer.AbstractTransactionStateFileWriter;

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/writer/LocalOrcTransactionStateFileWriter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local.sink.writer;
 
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/writer/LocalParquetTransactionStateFileWriter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local.sink.writer;
 
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/writer/LocalTransactionStateFileWriteFactory.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local.sink.writer;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/local/sink/writer/LocalTxtTransactionStateFileWriter.java
Patch:
@@ -15,10 +15,11 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local.sink.writer;
 
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
+import org.apache.seatunnel.connectors.seatunnel.file.local.sink.util.FileUtils;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.spi.FileSystem;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.transaction.TransactionFileNameGenerator;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.writer.AbstractTransactionStateFileWriter;

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/test/java/org/apache/seatunnel/connectors/seatunnel/file/local/FileSinkAggregatedCommitterTest.java
Patch:
@@ -15,8 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local;
 
+import org.apache.seatunnel.connectors.seatunnel.file.local.sink.filesystem.LocalFileSystemCommitter;
+import org.apache.seatunnel.connectors.seatunnel.file.local.sink.util.FileUtils;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileAggregatedCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileSinkAggregatedCommitter;

File: seatunnel-connectors-v2/connector-file/connector-file-local/src/test/java/org/apache/seatunnel/connectors/seatunnel/file/local/TestLocalTxtTransactionStateFileWriter.java
Patch:
@@ -15,13 +15,15 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.connectors.seatunnel.file.sink.local;
+package org.apache.seatunnel.connectors.seatunnel.file.local;
 
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.file.config.FileFormat;
+import org.apache.seatunnel.connectors.seatunnel.file.local.sink.filesystem.LocalFileSystem;
+import org.apache.seatunnel.connectors.seatunnel.file.local.sink.writer.LocalTxtTransactionStateFileWriter;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.transaction.TransactionStateFileWriter;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.writer.FileSinkPartitionDirNameGenerator;

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/JobExecutionEnvironment.java
Patch:
@@ -31,6 +31,7 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
+import java.util.concurrent.ExecutionException;
 
 public class JobExecutionEnvironment {
 
@@ -74,7 +75,7 @@ public List<Action> getActions() {
         return actions;
     }
 
-    public JobProxy execute() {
+    public JobProxy execute() throws ExecutionException, InterruptedException {
         JobClient jobClient = new JobClient(seaTunnelHazelcastClient);
         JobImmutableInformation jobImmutableInformation = new JobImmutableInformation(
             jobClient.getNewJobId(),

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/utils/IdGenerator.java
Patch:
@@ -26,9 +26,9 @@
 public class IdGenerator implements Serializable {
 
     private static final long serialVersionUID = 7683323453014131725L;
-    private int id = 0;
+    private long id = 0;
 
-    public int getNextId() {
+    public long getNextId() {
         id++;
         return id;
     }

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/utils/NonCompletableFuture.java
Patch:
@@ -62,7 +62,7 @@ public void obtrudeValue(T value) {
         throw new UnsupportedOperationException("This future can't be completed by an outside caller");
     }
 
-    public void internalComplete(T value) {
+    private void internalComplete(T value) {
         super.complete(value);
     }
 

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/Action.java
Patch:
@@ -38,7 +38,7 @@ public interface Action extends Serializable {
 
     void setParallelism(int parallelism);
 
-    int getId();
+    long getId();
 
     List<URL> getJarUrls();
 }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/PartitionTransformAction.java
Patch:
@@ -27,7 +27,7 @@
 public class PartitionTransformAction extends AbstractAction {
     private final PartitionSeaTunnelTransform partitionTransformation;
 
-    public PartitionTransformAction(int id,
+    public PartitionTransformAction(long id,
                                     @NonNull String name,
                                     @NonNull List<Action> upstreams,
                                     @NonNull PartitionSeaTunnelTransform partitionTransformation,
@@ -36,7 +36,7 @@ public PartitionTransformAction(int id,
         this.partitionTransformation = partitionTransformation;
     }
 
-    public PartitionTransformAction(int id,
+    public PartitionTransformAction(long id,
                                     @NonNull String name,
                                     @NonNull PartitionSeaTunnelTransform partitionTransformation,
                                     @NonNull List<URL> jarUrls) {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/PhysicalSourceAction.java
Patch:
@@ -33,7 +33,7 @@ public class PhysicalSourceAction<T, SplitT extends SourceSplit, StateT extends
     private final SeaTunnelSource<T, SplitT, StateT> source;
     private final List<SeaTunnelTransform> transforms;
 
-    public PhysicalSourceAction(int id,
+    public PhysicalSourceAction(long id,
                                 @NonNull String name,
                                 @NonNull SeaTunnelSource<T, SplitT, StateT> source,
                                 @NonNull List<URL> jarUrls,
@@ -43,7 +43,7 @@ public PhysicalSourceAction(int id,
         this.transforms = transforms;
     }
 
-    protected PhysicalSourceAction(int id, @NonNull String name, @NonNull List<Action> upstreams,
+    protected PhysicalSourceAction(long id, @NonNull String name, @NonNull List<Action> upstreams,
                                    @NonNull SeaTunnelSource<T, SplitT, StateT> source,
                                    @NonNull List<URL> jarUrls,
                                    List<SeaTunnelTransform> transforms) {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/SinkAction.java
Patch:
@@ -28,7 +28,7 @@
 public class SinkAction<IN, StateT, CommitInfoT, AggregatedCommitInfoT> extends AbstractAction {
     private SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT> sink;
 
-    public SinkAction(int id,
+    public SinkAction(long id,
                       @NonNull String name,
                       @NonNull List<Action> upstreams,
                       @NonNull SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT> sink,
@@ -37,7 +37,7 @@ public SinkAction(int id,
         this.sink = sink;
     }
 
-    public SinkAction(int id,
+    public SinkAction(long id,
                       @NonNull String name,
                       @NonNull SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT> sink,
                       @NonNull List<URL> jarUrls) {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/SourceAction.java
Patch:
@@ -32,7 +32,7 @@ public class SourceAction<T, SplitT extends SourceSplit, StateT extends Serializ
     private static final long serialVersionUID = -4104531889750766731L;
     private final SeaTunnelSource<T, SplitT, StateT> source;
 
-    public SourceAction(int id,
+    public SourceAction(long id,
                         @NonNull String name,
                         @NonNull SeaTunnelSource<T, SplitT, StateT> source,
                         @NonNull List<URL> jarUrls) {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/TransformAction.java
Patch:
@@ -27,7 +27,7 @@
 public class TransformAction extends AbstractAction {
     private SeaTunnelTransform transform;
 
-    public TransformAction(int id,
+    public TransformAction(long id,
                            @NonNull String name,
                            @NonNull List<Action> upstreams,
                            @NonNull SeaTunnelTransform transform,
@@ -36,7 +36,7 @@ public TransformAction(int id,
         this.transform = transform;
     }
 
-    public TransformAction(int id,
+    public TransformAction(long id,
                            @NonNull String name,
                            @NonNull SeaTunnelTransform transform,
                            @NonNull List<URL> jarUrls) {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/TransformChainAction.java
Patch:
@@ -29,7 +29,7 @@ public class TransformChainAction extends AbstractAction {
     private static final long serialVersionUID = -340174711145367535L;
     private final List<SeaTunnelTransform> transforms;
 
-    public TransformChainAction(int id,
+    public TransformChainAction(long id,
                                 @NonNull String name,
                                 @NonNull List<Action> upstreams,
                                 @NonNull List<URL> jarUrls,
@@ -38,7 +38,7 @@ public TransformChainAction(int id,
         this.transforms = transforms;
     }
 
-    public TransformChainAction(int id,
+    public TransformChainAction(long id,
                                 @NonNull String name,
                                 @NonNull List<URL> jarUrls,
                                 @NonNull List<SeaTunnelTransform> transforms) {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/internal/IntermediateDataQueue.java
Patch:
@@ -23,17 +23,17 @@ public class IntermediateDataQueue implements Serializable {
 
     private static final long serialVersionUID = -3049265155605303992L;
 
-    private final int id;
+    private final long id;
     private final int parallelism;
     private final String name;
 
-    public IntermediateDataQueue(int id, String name, int parallelism) {
+    public IntermediateDataQueue(long id, String name, int parallelism) {
         this.id = id;
         this.name = name;
         this.parallelism = parallelism;
     }
 
-    public int getId() {
+    public long getId() {
         return id;
     }
 

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/logical/LogicalVertex.java
Patch:
@@ -32,7 +32,7 @@
 @AllArgsConstructor
 public class LogicalVertex implements IdentifiedDataSerializable {
 
-    private Integer vertexId;
+    private Long vertexId;
     private Action action;
     private int parallelism;
 
@@ -51,14 +51,14 @@ public int getClassId() {
 
     @Override
     public void writeData(ObjectDataOutput out) throws IOException {
-        out.writeInt(vertexId);
+        out.writeLong(vertexId);
         out.writeObject(action);
         out.writeInt(parallelism);
     }
 
     @Override
     public void readData(ObjectDataInput in) throws IOException {
-        vertexId = in.readInt();
+        vertexId = in.readLong();
         action = in.readObject();
         parallelism = in.readInt();
     }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/job/Job.java
Patch:
@@ -17,8 +17,10 @@
 
 package org.apache.seatunnel.engine.core.job;
 
+import java.util.concurrent.ExecutionException;
+
 public interface Job {
     long getJobId();
 
-    void submitJob();
+    void submitJob() throws ExecutionException, InterruptedException;
 }

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/job/PipelineState.java
Patch:
@@ -73,7 +73,7 @@ public enum PipelineState {
     /** Restoring last possible valid state of the pipeline if it has it. */
     INITIALIZING;
 
-    public boolean isEnd() {
+    public boolean isEndState() {
         return this == FINISHED || this == CANCELED || this == FAILED;
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/ExecutionEdge.java
Patch:
@@ -24,9 +24,9 @@ public class ExecutionEdge {
     private ExecutionVertex leftVertex;
     private ExecutionVertex rightVertex;
 
-    private Integer leftVertexId;
+    private Long leftVertexId;
 
-    private Integer rightVertexId;
+    private Long rightVertexId;
 
     public ExecutionEdge(ExecutionVertex leftVertex, ExecutionVertex rightVertex) {
         this.leftVertex = leftVertex;

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/ExecutionVertex.java
Patch:
@@ -25,7 +25,7 @@
 @Data
 @AllArgsConstructor
 public class ExecutionVertex {
-    private Integer vertexId;
+    private Long vertexId;
     private Action action;
     private int parallelism;
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/Pipeline.java
Patch:
@@ -23,9 +23,9 @@
 public class Pipeline {
     private final List<ExecutionEdge> edges;
 
-    private final Map<Integer, ExecutionVertex> vertexes;
+    private final Map<Long, ExecutionVertex> vertexes;
 
-    Pipeline(List<ExecutionEdge> edges, Map<Integer, ExecutionVertex> vertexes) {
+    Pipeline(List<ExecutionEdge> edges, Map<Long, ExecutionVertex> vertexes) {
         this.edges = edges;
         this.vertexes = vertexes;
     }
@@ -34,7 +34,7 @@ public List<ExecutionEdge> getEdges() {
         return edges;
     }
 
-    public Map<Integer, ExecutionVertex> getVertexes() {
+    public Map<Long, ExecutionVertex> getVertexes() {
         return vertexes;
     }
 

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/dag/execution/PipelineGenerator.java
Patch:
@@ -34,7 +34,7 @@ public static List<Pipeline> generatePipelines(List<ExecutionEdge> edges) {
         // cache in the future
 
         return edgesList.stream().map(e -> {
-            Map<Integer, ExecutionVertex> vertexes = new HashMap<>();
+            Map<Long, ExecutionVertex> vertexes = new HashMap<>();
             List<ExecutionEdge> pipelineEdges = e.stream().map(edge -> {
                 if (!vertexes.containsKey(edge.getLeftVertexId())) {
                     vertexes.put(edge.getLeftVertexId(), edge.getLeftVertex());

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/scheduler/JobScheduler.java
Patch:
@@ -19,6 +19,4 @@
 
 public interface JobScheduler {
     void startScheduling();
-
-    boolean updateExecutionState();
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/serializable/TaskDataSerializerHook.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.engine.server.serializable;
 
 import org.apache.seatunnel.engine.common.serializeable.SeaTunnelFactoryIdConstant;
-import org.apache.seatunnel.engine.server.task.TaskGroupInfo;
+import org.apache.seatunnel.engine.server.task.TaskGroupImmutableInformation;
 import org.apache.seatunnel.engine.server.task.operation.AssignSplitOperation;
 import org.apache.seatunnel.engine.server.task.operation.RegisterOperation;
 import org.apache.seatunnel.engine.server.task.operation.RequestSplitOperation;
@@ -64,7 +64,7 @@ public IdentifiedDataSerializable create(int typeId) {
                 case ASSIGN_SPLIT_TYPE:
                     return new AssignSplitOperation();
                 case TASK_GROUP_INFO_TYPE:
-                    return new TaskGroupInfo();
+                    return new TaskGroupImmutableInformation();
                 default:
                     return null;
             }

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/SeaTunnelClientTest.java
Patch:
@@ -44,7 +44,7 @@ public static void beforeClass() throws Exception {
         SeaTunnelConfig seaTunnelConfig = ConfigProvider.locateAndGetSeaTunnelConfig();
         HazelcastInstanceFactory.newHazelcastInstance(seaTunnelConfig.getHazelcastConfig(),
             Thread.currentThread().getName(),
-            new SeaTunnelNodeContext());
+            new SeaTunnelNodeContext(ConfigProvider.locateAndGetSeaTunnelConfig()));
     }
 
     @Test

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/exception/JobDefineCheckException.java
Patch:
@@ -17,13 +17,13 @@
 
 package org.apache.seatunnel.engine.common.exception;
 
-public class JobDefineCheckExceptionSeaTunnel extends SeaTunnelEngineException {
+public class JobDefineCheckException extends SeaTunnelEngineException {
 
-    public JobDefineCheckExceptionSeaTunnel(String message) {
+    public JobDefineCheckException(String message) {
         super(message);
     }
 
-    public JobDefineCheckExceptionSeaTunnel(String message, Throwable cause) {
+    public JobDefineCheckException(String message, Throwable cause) {
         super(message, cause);
     }
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/AbstractTransactionStateFileWriter.java
Patch:
@@ -116,7 +116,6 @@ public String getTargetLocation(@NonNull String seaTunnelFilePath) {
 
     @Override
     public String beginTransaction(@NonNull Long checkpointId) {
-        this.finishAndCloseWriteFile();
         this.transactionId = "T" + Constant.TRANSACTION_ID_SPLIT + jobId + Constant.TRANSACTION_ID_SPLIT + subTaskIndex + Constant.TRANSACTION_ID_SPLIT + checkpointId;
         this.transactionDir = getTransactionDir(this.transactionId);
         this.needMoveFiles = new HashMap<>();

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/JobExecutionEnvironment.java
Patch:
@@ -21,8 +21,8 @@
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.utils.IdGenerator;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
-import org.apache.seatunnel.engine.core.dag.logicaldag.LogicalDag;
-import org.apache.seatunnel.engine.core.dag.logicaldag.LogicalDagGenerator;
+import org.apache.seatunnel.engine.core.dag.logical.LogicalDag;
+import org.apache.seatunnel.engine.core.dag.logical.LogicalDagGenerator;
 import org.apache.seatunnel.engine.core.job.JobImmutableInformation;
 
 import org.apache.commons.lang3.tuple.ImmutablePair;

File: seatunnel-engine/seatunnel-engine-client/src/test/java/org/apache/seatunnel/engine/client/LogicalDagGeneratorTest.java
Patch:
@@ -23,8 +23,8 @@
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.utils.IdGenerator;
 import org.apache.seatunnel.engine.core.dag.actions.Action;
-import org.apache.seatunnel.engine.core.dag.logicaldag.LogicalDag;
-import org.apache.seatunnel.engine.core.dag.logicaldag.LogicalDagGenerator;
+import org.apache.seatunnel.engine.core.dag.logical.LogicalDag;
+import org.apache.seatunnel.engine.core.dag.logical.LogicalDagGenerator;
 
 import com.hazelcast.internal.json.JsonObject;
 import org.apache.commons.lang3.tuple.ImmutablePair;

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/utils/IdGenerator.java
Patch:
@@ -24,6 +24,8 @@
  * unique.
  */
 public class IdGenerator implements Serializable {
+
+    private static final long serialVersionUID = 7683323453014131725L;
     private int id = 0;
 
     public int getNextId() {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/PartitionTransformAction.java
Patch:
@@ -25,7 +25,7 @@
 import java.util.List;
 
 public class PartitionTransformAction extends AbstractAction {
-    private PartitionSeaTunnelTransform partitionTransformation;
+    private final PartitionSeaTunnelTransform partitionTransformation;
 
     public PartitionTransformAction(int id,
                                     @NonNull String name,

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/logical/LogicalDagGenerator.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.core.dag.logicaldag;
+package org.apache.seatunnel.engine.core.dag.logical;
 
 import org.apache.seatunnel.engine.common.config.JobConfig;
 import org.apache.seatunnel.engine.common.utils.IdGenerator;

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/logical/LogicalEdge.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.core.dag.logicaldag;
+package org.apache.seatunnel.engine.core.dag.logical;
 
 import static com.google.common.base.Preconditions.checkNotNull;
 

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/logical/LogicalVertex.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.engine.core.dag.logicaldag;
+package org.apache.seatunnel.engine.core.dag.logical;
 
 import org.apache.seatunnel.engine.core.dag.actions.Action;
 import org.apache.seatunnel.engine.core.serializable.JobDataSerializerHook;
@@ -31,6 +31,7 @@
 @Data
 @AllArgsConstructor
 public class LogicalVertex implements IdentifiedDataSerializable {
+
     private Integer vertexId;
     private Action action;
     private int parallelism;

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/SeaTunnelClientConfig.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.engine.client;
 
+import org.apache.seatunnel.engine.common.Constant;
+
 import com.hazelcast.client.config.ClientConfig;
 
 public class SeaTunnelClientConfig extends ClientConfig {
@@ -25,9 +27,8 @@ public class SeaTunnelClientConfig extends ClientConfig {
      * Creates a new config instance with default group name for SeaTunnel Engine
      */
     public SeaTunnelClientConfig() {
-        // TODO we should get cluster name from server config instead of return a constant name.
         super();
-        setClusterName("SeaTunnel Engine");
+        setClusterName(Constant.DEFAULT_SEATUNNEL_CLUSTER_NAME);
     }
 }
 

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/serializeable/ConfigDataSerializerHook.java
Patch:
@@ -17,9 +17,10 @@
 
 package org.apache.seatunnel.engine.common.serializeable;
 
+import org.apache.seatunnel.engine.common.config.JobConfig;
+
 import com.hazelcast.internal.serialization.DataSerializerHook;
 import com.hazelcast.internal.serialization.impl.FactoryIdHelper;
-import com.hazelcast.jet.config.JobConfig;
 import com.hazelcast.nio.serialization.DataSerializableFactory;
 import com.hazelcast.nio.serialization.IdentifiedDataSerializable;
 

File: seatunnel-engine/seatunnel-engine-common/src/main/java/org/apache/seatunnel/engine/common/utils/ExceptionUtil.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.engine.common.utils;
 
+import org.apache.seatunnel.engine.common.exception.JobDefineCheckExceptionSeaTunnel;
 import org.apache.seatunnel.engine.common.exception.JobNotFoundExceptionSeaTunnel;
 import org.apache.seatunnel.engine.common.exception.SeaTunnelEngineException;
 
@@ -36,7 +37,8 @@ public final class ExceptionUtil {
 
     private static final List<ImmutableTriple<Integer, Class<? extends Throwable>, ClientExceptionFactory.ExceptionFactory>> EXCEPTIONS = Arrays.asList(
         new ImmutableTriple<>(ClientProtocolErrorCodes.USER_EXCEPTIONS_RANGE_START, SeaTunnelEngineException.class, SeaTunnelEngineException::new),
-        new ImmutableTriple<>(ClientProtocolErrorCodes.USER_EXCEPTIONS_RANGE_START + 1, JobNotFoundExceptionSeaTunnel.class, JobNotFoundExceptionSeaTunnel::new)
+        new ImmutableTriple<>(ClientProtocolErrorCodes.USER_EXCEPTIONS_RANGE_START + 1, JobNotFoundExceptionSeaTunnel.class, JobNotFoundExceptionSeaTunnel::new),
+        new ImmutableTriple<>(ClientProtocolErrorCodes.USER_EXCEPTIONS_RANGE_START + 2, JobDefineCheckExceptionSeaTunnel.class, JobDefineCheckExceptionSeaTunnel::new)
     );
 
     private ExceptionUtil() {

File: seatunnel-engine/seatunnel-engine-core/src/main/java/org/apache/seatunnel/engine/core/dag/actions/Action.java
Patch:
@@ -20,6 +20,7 @@
 import lombok.NonNull;
 
 import java.io.Serializable;
+import java.net.URL;
 import java.util.List;
 
 public interface Action extends Serializable {
@@ -38,4 +39,6 @@ public interface Action extends Serializable {
     void setParallelism(int parallelism);
 
     int getId();
+
+    List<URL> getJarUrls();
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/SeaTunnelServerStarter.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.engine.server;
 
+import org.apache.seatunnel.engine.common.Constant;
+
 import com.hazelcast.config.Config;
 import com.hazelcast.instance.impl.HazelcastInstanceFactory;
 
@@ -26,6 +28,7 @@ public static void main(String[] args) {
         Config config = new Config();
         config.getSecurityConfig().setEnabled(false);
         config.getJetConfig().setEnabled(false);
+        config.setClusterName(Constant.DEFAULT_SEATUNNEL_CLUSTER_NAME);
         HazelcastInstanceFactory.newHazelcastInstance(config, Thread.currentThread().getName(), new SeaTunnelNodeContext());
     }
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/protocol/task/SeaTunnelMessageTaskFactoryProvider.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.engine.server.protocol.task;
 
 import org.apache.seatunnel.engine.core.protocol.codec.SeaTunnelPrintMessageCodec;
+import org.apache.seatunnel.engine.core.protocol.codec.SeaTunnelSubmitJobCodec;
 
 import com.hazelcast.client.impl.protocol.MessageTaskFactory;
 import com.hazelcast.client.impl.protocol.MessageTaskFactoryProvider;
@@ -42,5 +43,6 @@ public Int2ObjectHashMap<MessageTaskFactory> getFactories() {
 
     private void initFactories() {
         factories.put(SeaTunnelPrintMessageCodec.REQUEST_MESSAGE_TYPE, (clientMessage, connection) -> new PrintMessageTask(clientMessage, node, connection));
+        factories.put(SeaTunnelSubmitJobCodec.REQUEST_MESSAGE_TYPE, (clientMessage, connection) -> new SubmitJobTask(clientMessage, node, connection));
     }
 }

File: seatunnel-connectors-v2/connector-http/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/source/HttpSourceReader.java
Patch:
@@ -71,7 +71,7 @@ public void pollNext(Collector<SeaTunnelRow> output) throws Exception {
         } finally {
             if (Boundedness.BOUNDED.equals(context.getBoundedness())) {
                 // signal to the source that we have reached the end of the data.
-                LOGGER.info("Closed the bounded fake source");
+                LOGGER.info("Closed the bounded http source");
                 context.signalNoMoreElement();
             }
         }

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/ReflectionUtils.java
Patch:
@@ -61,7 +61,7 @@ public static void setField(Object object, Class<?> clazz, String fieldName, Obj
             field.setAccessible(true);
             field.set(object, value);
         } catch (NoSuchFieldException | IllegalAccessException e) {
-            throw new RuntimeException("Incompatible KafkaProducer version", e);
+            throw new RuntimeException("field set failed", e);
         }
     }
 

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -47,7 +47,7 @@ public abstract class FlinkContainer {
 
     private static final Logger LOG = LoggerFactory.getLogger(FlinkContainer.class);
 
-    private static final String FLINK_DOCKER_IMAGE = "flink:1.13.6-scala_2.11";
+    private static final String FLINK_DOCKER_IMAGE = "tyrantlucifer/flink:1.13.6-scala_2.11_hadoop27";
     protected static final Network NETWORK = Network.newNetwork();
 
     protected GenericContainer<?> jobManager;

File: seatunnel-connectors-v2/connector-http/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/client/HttpResponse.java
Patch:
@@ -17,13 +17,15 @@
 
 package org.apache.seatunnel.connectors.seatunnel.http.client;
 
+import org.apache.http.HttpStatus;
+
 import java.io.Serializable;
 
 public class HttpResponse implements Serializable {
 
     private static final long serialVersionUID = 2168152194164783950L;
 
-    public static final int STATUS_OK = 200;
+    public static final int STATUS_OK = HttpStatus.SC_OK;
     /**
      * response status code
      */

File: seatunnel-connectors-v2/connector-http/src/main/java/org/apache/seatunnel/connectors/seatunnel/http/client/HttpClientProvider.java
Patch:
@@ -55,7 +55,7 @@ private HttpClientProvider() {
     }
 
     public static HttpClientProvider getInstance() {
-        return Sigleton.INSTANCE;
+        return Singleton.INSTANCE;
     }
 
     public HttpResponse execute(String url, String method, Map<String, String> headers, Map<String, String> params) throws Exception {
@@ -277,7 +277,7 @@ public void close() throws IOException {
         }
     }
 
-    private static class Sigleton {
+    private static class Singleton {
         private static final HttpClientProvider INSTANCE = new HttpClientProvider();
     }
 }

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/serialization/InternalRowConverter.java
Patch:
@@ -162,6 +162,8 @@ public static Object reconvert(Object field, SeaTunnelDataType<?> dataType) {
                 return ((Timestamp) field).toLocalDateTime();
             case MAP:
                 return convertMap((Map<?, ?>) field, (MapType<?, ?>) dataType, InternalRowConverter::reconvert);
+            case STRING:
+                return field.toString();
             default:
                 return field;
         }

File: seatunnel-engine/seatunnel-engine-client/src/main/java/org/apache/seatunnel/engine/client/SeaTunnelClientInstance.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.engine.client;
 
+import org.apache.seatunnel.engine.common.config.JobConfig;
+
 import com.hazelcast.core.HazelcastInstance;
 import lombok.NonNull;
 
@@ -29,5 +31,5 @@ public interface SeaTunnelClientInstance {
     @NonNull
     HazelcastInstance getHazelcastInstance();
 
-    JobExecutionEnvironment createExecutionContext(String filePath, SeaTunnelClientConfig config);
+    JobExecutionEnvironment createExecutionContext(String filePath, JobConfig config);
 }

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/NodeExtension.java
Patch:
@@ -28,7 +28,7 @@ public class NodeExtension extends DefaultNodeExtension {
 
     public NodeExtension(Node node) {
         super(node);
-        extCommon = new NodeExtensionCommon(node, new Server(node));
+        extCommon = new NodeExtensionCommon(node, new SeaTunnelServer(node));
     }
 
     @Override

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/SeaTunnelNodeContext.java
Patch:
@@ -21,7 +21,7 @@
 import com.hazelcast.instance.impl.Node;
 import com.hazelcast.instance.impl.NodeExtension;
 
-public class NodeContext extends DefaultNodeContext {
+public class SeaTunnelNodeContext extends DefaultNodeContext {
 
     @Override
     public NodeExtension createNodeExtension(Node node) {

File: seatunnel-engine/seatunnel-engine-server/src/main/java/org/apache/seatunnel/engine/server/SeaTunnelServer.java
Patch:
@@ -29,13 +29,13 @@
 
 import java.util.Properties;
 
-public class Server implements ManagedService, MembershipAwareService, LiveOperationsTracker {
+public class SeaTunnelServer implements ManagedService, MembershipAwareService, LiveOperationsTracker {
     public static final String SERVICE_NAME = "st:impl:seaTunnelServer";
 
     private NodeEngineImpl nodeEngine;
     private final ILogger logger;
 
-    public Server(Node node) {
+    public SeaTunnelServer(Node node) {
         this.logger = node.getLogger(getClass());
         logger.info("SeaTunnel server start...");
     }

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/command/SparkApiTaskExecuteCommand.java
Patch:
@@ -32,8 +32,8 @@
 import java.nio.file.Path;
 
 /**
- * todo: do we need to move these class to a new module? since this may cause version conflict with the old flink version.
- * This command is used to execute the Flink job by SeaTunnel new API.
+ * todo: do we need to move these class to a new module? since this may cause version conflict with the old Spark version.
+ * This command is used to execute the Spark job by SeaTunnel new API.
  */
 public class SparkApiTaskExecuteCommand implements Command<SparkCommandArgs> {
 

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/file/ClickhouseFileSinkWriter.java
Patch:
@@ -207,8 +207,9 @@ private List<String> generateClickhouseLocalFiles(List<SeaTunnelRow> rows) throw
 
     private void attachClickhouseLocalFileToServer(Shard shard, List<String> clickhouseLocalFiles) throws ClickHouseException {
         String hostAddress = shard.getNode().getAddress().getHostName();
+        String user = readerOption.getNodeUser().getOrDefault(hostAddress, "root");
         String password = readerOption.getNodePassword().getOrDefault(hostAddress, null);
-        FileTransfer fileTransfer = FileTransferFactory.createFileTransfer(this.readerOption.getCopyMethod(), hostAddress, password);
+        FileTransfer fileTransfer = FileTransferFactory.createFileTransfer(this.readerOption.getCopyMethod(), hostAddress, user, password);
         fileTransfer.init();
         fileTransfer.transferAndChown(clickhouseLocalFiles, shardLocalDataPaths.get(shard).get(0) + "detached/");
         fileTransfer.close();

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/file/FileTransferFactory.java
Patch:
@@ -20,12 +20,12 @@
 import org.apache.seatunnel.connectors.seatunnel.clickhouse.config.ClickhouseFileCopyMethod;
 
 public class FileTransferFactory {
-    public static FileTransfer createFileTransfer(ClickhouseFileCopyMethod type, String host, String password) {
+    public static FileTransfer createFileTransfer(ClickhouseFileCopyMethod type, String host, String user, String password) {
         switch (type) {
             case SCP:
-                return new ScpFileTransfer(host, password);
+                return new ScpFileTransfer(host, user, password);
             case RSYNC:
-                return new RsyncFileTransfer(host, password);
+                return new RsyncFileTransfer(host, user, password);
             default:
                 throw new RuntimeException("unsupported clickhouse file copy method:" + type);
         }

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/command/FlinkApiTaskExecuteCommand.java
Patch:
@@ -71,7 +71,7 @@ public void execute() throws CommandExecuteException {
         List<BaseSink<FlinkEnvironment>> sinks = executionContext.getSinks();
 
         checkPluginType(executionContext.getJobMode(), sources, transforms, sinks);
-        baseCheckConfig(sinks, transforms, sinks);
+        baseCheckConfig(sources, transforms, sinks);
         showAsciiLogo();
 
         try (Execution<BaseSource<FlinkEnvironment>,

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/batch/ParallelBatchPartitionReader.java
Patch:
@@ -92,7 +92,7 @@ protected void prepare() {
             this.internalSource.open();
         } catch (Exception e) {
             running = false;
-            throw new RuntimeException("");
+            throw new RuntimeException("Failed to open internal source.", e);
         }
         executorService.execute(() -> {
             try {

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/connector/TableSource.java
Patch:
@@ -20,7 +20,9 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceSplit;
 
-public interface TableSource<T, SplitT extends SourceSplit, StateT> {
+import java.io.Serializable;
+
+public interface TableSource<T, SplitT extends SourceSplit, StateT extends Serializable> {
 
     SeaTunnelSource<T, SplitT, StateT> createSource();
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/FactoryUtil.java
Patch:
@@ -27,6 +27,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.LinkedList;
 import java.util.List;
@@ -42,7 +43,7 @@ public final class FactoryUtil {
 
     private static final Logger LOG = LoggerFactory.getLogger(FactoryUtil.class);
 
-    public static <T, SplitT extends SourceSplit, StateT> List<SeaTunnelSource<T, SplitT, StateT>> createAndPrepareSource(
+    public static <T, SplitT extends SourceSplit, StateT extends Serializable> List<SeaTunnelSource<T, SplitT, StateT>> createAndPrepareSource(
         List<CatalogTable> multipleTables,
         Map<String, String> options,
         ClassLoader classLoader,

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/TableSourceFactory.java
Patch:
@@ -20,11 +20,13 @@
 import org.apache.seatunnel.api.source.SourceSplit;
 import org.apache.seatunnel.api.table.connector.TableSource;
 
+import java.io.Serializable;
+
 /**
  * This is an SPI interface, used to create {@link TableSource}. Each plugin need to have it own implementation.
  * todo: now we have not use this interface, we directly use {@link org.apache.seatunnel.api.source.SeaTunnelSource} as the SPI interface
  */
 public interface TableSourceFactory extends Factory {
 
-    <T, SplitT extends SourceSplit, StateT> TableSource<T, SplitT, StateT> createSource(TableFactoryContext context);
+    <T, SplitT extends SourceSplit, StateT extends Serializable> TableSource<T, SplitT, StateT> createSource(TableFactoryContext context);
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelRow.java
Patch:
@@ -87,7 +87,6 @@ public boolean equals(Object o) {
         return tableId == that.tableId && kind == that.kind && Arrays.deepEquals(fields, that.fields);
     }
 
-    @SuppressWarnings("magicnumber")
     @Override
     public int hashCode() {
         int result = Objects.hash(tableId, kind);

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelRowType.java
Patch:
@@ -98,7 +98,6 @@ public boolean equals(Object obj) {
     }
 
     @Override
-    @SuppressWarnings("MagicNumber")
     public int hashCode() {
         int result = Arrays.hashCode(fieldNames);
         result = 31 * result + Arrays.hashCode(fieldTypes);

File: seatunnel-common/src/test/java/org/apache/seatunnel/common/utils/VariablesSubstituteTest.java
Patch:
@@ -26,7 +26,6 @@
 
 public class VariablesSubstituteTest {
 
-    @SuppressWarnings("checkstyle:MagicNumber")
     @Test
     public void testSubstitute() {
         String timeFormat = "yyyyMMddHHmmss";

File: seatunnel-connectors-v2/connector-assert/src/test/java/org/apache/seatunnel/flink/assertion/AssertExecutorTest.java
Patch:
@@ -29,7 +29,6 @@
 
 import java.util.List;
 
-@SuppressWarnings("magicnumber")
 public class AssertExecutorTest extends TestCase {
     SeaTunnelRow row = new SeaTunnelRow(new Object[]{"jared", 17});
     SeaTunnelRowType rowType = new SeaTunnelRowType(new String[]{"name", "age"}, new SeaTunnelDataType[]{BasicType.STRING_TYPE, BasicType.INT_TYPE});

File: seatunnel-connectors-v2/connector-assert/src/test/java/org/apache/seatunnel/flink/assertion/rule/AssertRuleParserTest.java
Patch:
@@ -28,7 +28,6 @@
 
 import java.util.List;
 
-@SuppressWarnings("magicnumber")
 public class AssertRuleParserTest extends TestCase {
     AssertRuleParser parser = new AssertRuleParser();
 

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/AbstractFileSink.java
Patch:
@@ -41,7 +41,6 @@
 
 /**
  * Hive Sink implementation by using SeaTunnel sink API.
- * This class contains the method to create {@link TransactionStateFileSinkWriter} and {@link FileSinkAggregatedCommitter}.
  */
 public abstract class AbstractFileSink implements SeaTunnelSink<SeaTunnelRow, FileSinkState, FileCommitInfo, FileAggregatedCommitInfo> {
     private Config config;
@@ -92,7 +91,7 @@ public SinkWriter<SeaTunnelRow, FileCommitInfo, FileSinkState> createWriter(Sink
     @Override
     public SinkWriter<SeaTunnelRow, FileCommitInfo, FileSinkState> restoreWriter(SinkWriter.Context context, List<FileSinkState> states) throws IOException {
         if (this.getSinkConfig().isEnableTransaction()) {
-            return new TransactionStateFileSinkWriter(seaTunnelRowTypeInfo,
+            return new FileSinkWriterWithTransaction(seaTunnelRowTypeInfo,
                 config,
                 context,
                 textFileSinkConfig,

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/FileAggregatedCommitInfo.java
Patch:
@@ -21,6 +21,7 @@
 import lombok.Data;
 
 import java.io.Serializable;
+import java.util.List;
 import java.util.Map;
 
 @Data
@@ -33,4 +34,6 @@ public class FileAggregatedCommitInfo implements Serializable {
      * V is the target file path of the data file.
      */
     private Map<String, Map<String, String>> transactionMap;
+
+    private Map<String, List<String>> partitionDirAndValsMap;
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/FileCommitInfo.java
Patch:
@@ -21,6 +21,7 @@
 import lombok.Data;
 
 import java.io.Serializable;
+import java.util.List;
 import java.util.Map;
 
 @Data
@@ -34,5 +35,7 @@ public class FileCommitInfo implements Serializable {
      */
     private Map<String, String> needMoveFiles;
 
+    private Map<String, List<String>> partitionDirAndValsMap;
+
     private String transactionDir;
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/transaction/Transaction.java
Patch:
@@ -22,7 +22,6 @@
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileSinkAggregatedCommitter;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileSinkState;
-import org.apache.seatunnel.connectors.seatunnel.file.sink.TransactionStateFileSinkWriter;
 
 import lombok.NonNull;
 
@@ -40,7 +39,7 @@ public interface Transaction extends Serializable {
     String beginTransaction(@NonNull Long checkpointId);
 
     /**
-     * Abort current Transaction, called when {@link TransactionStateFileSinkWriter#prepareCommit()} or {@link TransactionStateFileSinkWriter#snapshotState(long)} failed
+     * Abort current Transaction, called when {@link org.apache.seatunnel.connectors.seatunnel.file.sink.TransactionStateFileSinkWriter#prepareCommit()} or {@link org.apache.seatunnel.connectors.seatunnel.file.sink.TransactionStateFileSinkWriter#snapshotState(long)} failed
      */
     void abortTransaction();
 
@@ -56,7 +55,7 @@ public interface Transaction extends Serializable {
     List<String> getTransactionAfter(@NonNull String transactionId);
 
     /**
-     * Called by {@link TransactionStateFileSinkWriter#prepareCommit()}
+     * Called by {@link org.apache.seatunnel.connectors.seatunnel.file.sink.TransactionStateFileSinkWriter#prepareCommit()}
      * We should end the transaction in this method. After this method is called, the transaction will no longer accept data writing
      *
      * @return Return the commit information that can be commit in {@link FileSinkAggregatedCommitter#commit(List)}

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/PartitionDirNameGenerator.java
Patch:
@@ -20,7 +20,9 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 
 import java.io.Serializable;
+import java.util.List;
+import java.util.Map;
 
 public interface PartitionDirNameGenerator extends Serializable {
-    String generatorPartitionDir(SeaTunnelRow seaTunnelRow);
+    Map<String, List<String>> generatorPartitionDir(SeaTunnelRow seaTunnelRow);
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/test/java/org/apache/seatunnel/connectors/seatunnel/file/writer/TestFileSinkPartitionDirNameGenerator.java
Patch:
@@ -55,15 +55,15 @@ public void testPartitionDirNameGenerator() {
         partitionFieldsIndexInRow.add(3);
 
         PartitionDirNameGenerator partitionDirNameGenerator = new FileSinkPartitionDirNameGenerator(partitionFieldList, partitionFieldsIndexInRow, "${v0}/${v1}");
-        String partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow);
+        String partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow).keySet().toArray()[0].toString();
         Assert.assertEquals("test/3", partitionDir);
 
         partitionDirNameGenerator = new FileSinkPartitionDirNameGenerator(partitionFieldList, partitionFieldsIndexInRow, "${k0}=${v0}/${k1}=${v1}");
-        partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow);
+        partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow).keySet().toArray()[0].toString();
         Assert.assertEquals("c3=test/c4=3", partitionDir);
 
         partitionDirNameGenerator = new FileSinkPartitionDirNameGenerator(null, null, "${k0}=${v0}/${k1}=${v1}");
-        partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow);
+        partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow).keySet().toArray()[0].toString();
         Assert.assertEquals(Constant.NON_PARTITION, partitionDir);
     }
 }

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/HiveSinkState.java
Patch:
@@ -25,5 +25,6 @@
 @Data
 @AllArgsConstructor
 public class HiveSinkState implements Serializable {
-    private HiveSinkConfig hiveSinkConfig;
+    private String transactionId;
+    private Long checkpointId;
 }

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/source/file/reader/format/TextReadStrategy.java
Patch:
@@ -44,7 +44,7 @@ public void read(String path, Collector<SeaTunnelRow> output) throws IOException
         FileSystem fs = FileSystem.get(conf);
         Path filePath = new Path(path);
         try (BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(filePath), StandardCharsets.UTF_8))) {
-            reader.lines().forEach(line -> output.collect(new SeaTunnelRow(new String[]{"TEXT_FIELD_NAME", line})));
+            reader.lines().forEach(line -> output.collect(new SeaTunnelRow(new String[]{line})));
         }
     }
 

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/catalog/MySqlCatalog.java
Patch:
@@ -130,7 +130,7 @@ public CatalogTable getTable(TablePath tablePath) throws CatalogException, Table
                 getPrimaryKey(metaData, tablePath.getDatabaseName(), tablePath.getTableName());
 
             PreparedStatement ps =
-                conn.prepareStatement(String.format("SELECT * FROM %s LIMIT 1;", tablePath.getFullName()));
+                conn.prepareStatement(String.format("SELECT * FROM %s WHERE 1 = 0;", tablePath.getFullName()));
 
             ResultSetMetaData tableMetaData = ps.getMetaData();
 

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-assert/src/test/java/org/apache/seatunnel/flink/assertion/AssertExecutorTest.java
Patch:
@@ -26,7 +26,6 @@
 
 import java.util.List;
 
-@SuppressWarnings("magicnumber")
 public class AssertExecutorTest extends TestCase {
     Row row = Row.withNames();
     AssertExecutor assertExecutor = new AssertExecutor();

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-assert/src/test/java/org/apache/seatunnel/flink/assertion/rule/AssertRuleParserTest.java
Patch:
@@ -25,7 +25,6 @@
 
 import java.util.List;
 
-@SuppressWarnings("magicnumber")
 public class AssertRuleParserTest extends TestCase {
     AssertRuleParser parser = new AssertRuleParser();
 

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-clickhouse/src/main/java/org/apache/seatunnel/flink/clickhouse/pojo/Shard.java
Patch:
@@ -114,7 +114,6 @@ public boolean equals(Object o) {
     }
 
     @Override
-    @SuppressWarnings("magicnumber")
     public int hashCode() {
         if (hashCode != -1) {
             return hashCode;

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-clickhouse/src/main/java/org/apache/seatunnel/flink/clickhouse/pojo/ShardMetadata.java
Patch:
@@ -122,7 +122,6 @@ public boolean equals(Object o) {
     }
 
     @Override
-    @SuppressWarnings("magicnumber")
     public int hashCode() {
         int result = shardKey.hashCode();
         result = 31 * result + shardKeyType.hashCode();

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/command/AbstractCommandArgs.java
Patch:
@@ -38,7 +38,7 @@ public abstract class AbstractCommandArgs implements CommandArgs {
     private List<String> variables = Collections.emptyList();
 
     // todo: use command type enum
-    @Parameter(names = {"-t", "--check"},
+    @Parameter(names = {"-ck", "--check"},
             description = "check config")
     private boolean checkConfig = false;
 

File: seatunnel-core/seatunnel-core-flink/src/test/java/org/apache/seatunnel/core/flink/args/FlinkCommandArgsTest.java
Patch:
@@ -27,7 +27,7 @@ public class FlinkCommandArgsTest {
 
     @Test
     public void testParseFlinkArgs() {
-        String[] args = {"-c", "app.conf", "-t", "-i", "city=shenyang", "-i", "date=20200202"};
+        String[] args = {"-c", "app.conf", "-ck", "-i", "city=shenyang", "-i", "date=20200202"};
         FlinkCommandArgs flinkArgs = new FlinkCommandArgs();
         JCommander.newBuilder()
             .addObject(flinkArgs)

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -52,7 +52,7 @@ protected SinkExecuteProcessor(FlinkEnvironment flinkEnvironment,
 
     @Override
     protected List<SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializable>> initializePlugins(List<? extends Config> pluginConfigs) {
-        SeaTunnelSinkPluginDiscovery sinkPluginDiscovery = new SeaTunnelSinkPluginDiscovery();
+        SeaTunnelSinkPluginDiscovery sinkPluginDiscovery = new SeaTunnelSinkPluginDiscovery(addUrlToClassloader);
         List<URL> pluginJars = new ArrayList<>();
         List<SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializable>> sinks = pluginConfigs.stream().map(sinkConfig -> {
             PluginIdentifier pluginIdentifier = PluginIdentifier.of(ENGINE_TYPE, PLUGIN_TYPE, sinkConfig.getString(PLUGIN_NAME));

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SourceExecuteProcessor.java
Patch:
@@ -101,7 +101,7 @@ private DataStreamSource<Row> addSource(
 
     @Override
     protected List<SeaTunnelSource> initializePlugins(List<? extends Config> pluginConfigs) {
-        SeaTunnelSourcePluginDiscovery sourcePluginDiscovery = new SeaTunnelSourcePluginDiscovery();
+        SeaTunnelSourcePluginDiscovery sourcePluginDiscovery = new SeaTunnelSourcePluginDiscovery(addUrlToClassloader);
         List<SeaTunnelSource> sources = new ArrayList<>();
         Set<URL> jars = new HashSet<>();
         for (Config sourceConfig : pluginConfigs) {

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/fake/FakeSourceToConsoleIT.java
Patch:
@@ -28,7 +28,6 @@
 public class FakeSourceToConsoleIT extends FlinkContainer {
 
     @Test
-    @SuppressWarnings("magicnumber")
     public void testFakeSourceToConsoleSink() throws IOException, InterruptedException {
         Container.ExecResult execResult = executeSeaTunnelFlinkJob("/fake/fakesource_to_console.conf");
         Assert.assertEquals(0, execResult.getExitCode());

File: seatunnel-e2e/seatunnel-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/clickhouse/FakeSourceToClickhouseIT.java
Patch:
@@ -50,7 +50,6 @@ public class FakeSourceToClickhouseIT extends FlinkContainer {
     private static final Logger LOGGER = LoggerFactory.getLogger(FakeSourceToClickhouseIT.class);
 
     @Before
-    @SuppressWarnings("magicnumber")
     public void startClickhouseContainer() throws InterruptedException {
         clickhouseServer = new GenericContainer<>(CLICKHOUSE_DOCKER_IMAGE)
             .withNetwork(NETWORK)

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/spark/v2/fake/FakeSourceToConsoleIT.java
Patch:
@@ -32,7 +32,6 @@
 public class FakeSourceToConsoleIT extends SparkContainer {
 
     @Test
-    @SuppressWarnings("magicnumber")
     public void testFakeSourceToConsoleSine() throws IOException, InterruptedException {
         Container.ExecResult execResult = executeSeaTunnelSparkJob("/fake/fakesource_to_console.conf");
         Assert.assertEquals(0, execResult.getExitCode());

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/spark/v2/file/FakeSourceToFileIT.java
Patch:
@@ -32,7 +32,6 @@
 public class FakeSourceToFileIT extends SparkContainer {
 
     @Test
-    @SuppressWarnings("magicnumber")
     public void testFakeSourceToFile() throws IOException, InterruptedException {
         Container.ExecResult execResult = executeSeaTunnelSparkJob("/file/fakesource_to_file.conf");
         Assert.assertEquals(0, execResult.getExitCode());

File: seatunnel-examples/seatunnel-spark-connector-v2-example/src/main/java/org/apache/seatunnel/example/spark/v2/SeaTunnelApiExample.java
Patch:
@@ -38,9 +38,9 @@ public static void main(String[] args) throws FileNotFoundException, URISyntaxEx
         sparkCommandArgs.setCheckConfig(false);
         sparkCommandArgs.setVariables(null);
         sparkCommandArgs.setDeployMode(DeployMode.CLIENT);
-        Command<SparkCommandArgs> flinkCommand =
+        Command<SparkCommandArgs> sparkCommand =
                 new SparkCommandBuilder().buildCommand(sparkCommandArgs);
-        Seatunnel.run(flinkCommand);
+        Seatunnel.run(sparkCommand);
     }
 
     public static String getTestConfigFile(String configFile) throws FileNotFoundException, URISyntaxException {

File: seatunnel-plugin-discovery/src/main/java/org/apache/seatunnel/plugin/discovery/PluginIdentifier.java
Patch:
@@ -70,7 +70,6 @@ public boolean equals(Object o) {
     }
 
     @Override
-    @SuppressWarnings("checkstyle:magicnumber")
     public int hashCode() {
         int result = engineType != null ? engineType.hashCode() : 0;
         result = 31 * result + (pluginType != null ? pluginType.hashCode() : 0);

File: seatunnel-plugin-discovery/src/main/java/org/apache/seatunnel/plugin/discovery/flink/FlinkSinkPluginDiscovery.java
Patch:
@@ -18,9 +18,8 @@
 package org.apache.seatunnel.plugin.discovery.flink;
 
 import org.apache.seatunnel.flink.BaseFlinkSink;
-import org.apache.seatunnel.plugin.discovery.AbstractPluginDiscovery;
 
-public class FlinkSinkPluginDiscovery extends AbstractPluginDiscovery<BaseFlinkSink> {
+public class FlinkSinkPluginDiscovery extends FlinkAbstractPluginDiscovery<BaseFlinkSink> {
 
     public FlinkSinkPluginDiscovery() {
         super("flink");

File: seatunnel-plugin-discovery/src/main/java/org/apache/seatunnel/plugin/discovery/flink/FlinkSourcePluginDiscovery.java
Patch:
@@ -18,9 +18,8 @@
 package org.apache.seatunnel.plugin.discovery.flink;
 
 import org.apache.seatunnel.flink.BaseFlinkSource;
-import org.apache.seatunnel.plugin.discovery.AbstractPluginDiscovery;
 
-public class FlinkSourcePluginDiscovery extends AbstractPluginDiscovery<BaseFlinkSource> {
+public class FlinkSourcePluginDiscovery extends FlinkAbstractPluginDiscovery<BaseFlinkSource> {
     public FlinkSourcePluginDiscovery() {
         super("flink");
     }

File: seatunnel-plugin-discovery/src/main/java/org/apache/seatunnel/plugin/discovery/flink/FlinkTransformPluginDiscovery.java
Patch:
@@ -18,14 +18,13 @@
 package org.apache.seatunnel.plugin.discovery.flink;
 
 import org.apache.seatunnel.flink.BaseFlinkTransform;
-import org.apache.seatunnel.plugin.discovery.AbstractPluginDiscovery;
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
 
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.List;
 
-public class FlinkTransformPluginDiscovery extends AbstractPluginDiscovery<BaseFlinkTransform> {
+public class FlinkTransformPluginDiscovery extends FlinkAbstractPluginDiscovery<BaseFlinkTransform> {
 
     public FlinkTransformPluginDiscovery() {
         super("flink");

File: seatunnel-server/seatunnel-app/src/main/java/org/apache/seatunnel/app/common/SeatunnelErrorEnum.java
Patch:
@@ -24,7 +24,7 @@ public enum SeatunnelErrorEnum {
     USER_ALREADY_EXISTS(10003, "user already exist", "The same username [%s] is exist."),
     NO_SUCH_USER(10002, "no such user", "No such user. Maybe deleted by others."),
     ILLEGAL_STATE(99998, "illegal state", "%s"),
-    UNKNOWN(99999, "unknown exception", "unknown exception")
+    UNKNOWN(99999, "unknown exception", "%s")
     ;
 
     private final int code;

File: seatunnel-server/seatunnel-app/src/main/java/org/apache/seatunnel/app/util/GlobalExceptionHandler.java
Patch:
@@ -52,11 +52,11 @@ private Result<String> exceptionHandler(IllegalStateException e) {
     @ExceptionHandler(value = Exception.class)
     private Result<String> exceptionHandler(Exception e) {
         logError(e);
-        return Result.failure(SeatunnelErrorEnum.UNKNOWN);
+        return Result.failure(SeatunnelErrorEnum.UNKNOWN, e.getMessage());
     }
 
     private void logError(Throwable throwable) {
-        log.error("", throwable);
+        log.error(throwable.getMessage(), throwable);
     }
 
 }

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/source/CoordinatedSource.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.seatunnel.translation.util.ThreadPoolExecutorFactory;
 
 import java.io.IOException;
+import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
@@ -39,7 +40,7 @@
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.stream.Collectors;
 
-public class CoordinatedSource<T, SplitT extends SourceSplit, StateT> implements BaseSourceFunction<T> {
+public class CoordinatedSource<T, SplitT extends SourceSplit, StateT extends Serializable> implements BaseSourceFunction<T> {
     protected static final long SLEEP_TIME_INTERVAL = 5L;
     protected final SeaTunnelSource<T, SplitT, StateT> source;
     protected final Map<Integer, List<byte[]>> restoredState;

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/source/ParallelSource.java
Patch:
@@ -28,6 +28,7 @@
 import org.apache.seatunnel.translation.util.ThreadPoolExecutorFactory;
 
 import java.io.IOException;
+import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
@@ -36,7 +37,7 @@
 import java.util.concurrent.Future;
 import java.util.concurrent.ScheduledThreadPoolExecutor;
 
-public class ParallelSource<T, SplitT extends SourceSplit, StateT> implements BaseSourceFunction<T> {
+public class ParallelSource<T, SplitT extends SourceSplit, StateT extends Serializable> implements BaseSourceFunction<T> {
 
     protected final SeaTunnelSource<T, SplitT, StateT> source;
     protected final ParallelEnumeratorContext<SplitT> parallelEnumeratorContext;

File: seatunnel-translation/seatunnel-translation-flink/src/test/java/org/apache/seatunnel/translation/flink/utils/TypeConverterUtilsTest.java
Patch:
@@ -73,7 +73,6 @@ public void convertShortType() {
     }
 
     @Test
-    @SuppressWarnings("MagicNumber")
     public void convertBigDecimalType() {
         Assert.assertEquals(new BigDecimalTypeInfo(30, 2), TypeConverterUtils.convert(new DecimalType(30, 2)));
     }

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/batch/CoordinatedBatchPartitionReader.java
Patch:
@@ -26,6 +26,7 @@
 import org.apache.seatunnel.translation.source.CoordinatedSource;
 import org.apache.seatunnel.translation.spark.source.InternalRowCollector;
 
+import java.io.Serializable;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
@@ -55,7 +56,7 @@ protected BaseSourceFunction<SeaTunnelRow> createInternalSource() {
             parallelism);
     }
 
-    public class InternalCoordinatedSource<SplitT extends SourceSplit, StateT> extends CoordinatedSource<SeaTunnelRow, SplitT, StateT> {
+    public class InternalCoordinatedSource<SplitT extends SourceSplit, StateT extends Serializable> extends CoordinatedSource<SeaTunnelRow, SplitT, StateT> {
 
         public InternalCoordinatedSource(SeaTunnelSource<SeaTunnelRow, SplitT, StateT> source, Map<Integer, List<byte[]>> restoredState, int parallelism) {
             super(source, restoredState, parallelism);

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/batch/ParallelBatchPartitionReader.java
Patch:
@@ -32,6 +32,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.io.IOException;
+import java.io.Serializable;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ExecutorService;
@@ -132,7 +133,7 @@ public void close() throws IOException {
         executorService.shutdown();
     }
 
-    public class InternalParallelSource<SplitT extends SourceSplit, StateT> extends ParallelSource<SeaTunnelRow, SplitT, StateT> {
+    public class InternalParallelSource<SplitT extends SourceSplit, StateT extends Serializable> extends ParallelSource<SeaTunnelRow, SplitT, StateT> {
 
         public InternalParallelSource(SeaTunnelSource<SeaTunnelRow, SplitT, StateT> source, Map<Integer, List<byte[]>> restoredState, int parallelism, int subtaskId) {
             super(source, restoredState, parallelism, subtaskId);

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/micro/CoordinatedMicroBatchPartitionReader.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.seatunnel.translation.spark.source.InternalRowCollector;
 import org.apache.seatunnel.translation.spark.source.ReaderState;
 
+import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
@@ -96,7 +97,7 @@ protected BaseSourceFunction<SeaTunnelRow> createInternalSource() {
             parallelism);
     }
 
-    public class InternalCoordinatedSource<SplitT extends SourceSplit, StateT> extends CoordinatedSource<SeaTunnelRow, SplitT, StateT> {
+    public class InternalCoordinatedSource<SplitT extends SourceSplit, StateT extends Serializable> extends CoordinatedSource<SeaTunnelRow, SplitT, StateT> {
 
         public InternalCoordinatedSource(SeaTunnelSource<SeaTunnelRow, SplitT, StateT> source, Map<Integer, List<byte[]>> restoredState, int parallelism) {
             super(source, restoredState, parallelism);

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/connector/TableSource.java
Patch:
@@ -20,7 +20,9 @@
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.api.source.SourceSplit;
 
-public interface TableSource<T, SplitT extends SourceSplit, StateT> {
+import java.io.Serializable;
+
+public interface TableSource<T, SplitT extends SourceSplit, StateT extends Serializable> {
 
     SeaTunnelSource<T, SplitT, StateT> createSource();
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/FactoryUtil.java
Patch:
@@ -27,6 +27,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.LinkedList;
 import java.util.List;
@@ -42,7 +43,7 @@ public final class FactoryUtil {
 
     private static final Logger LOG = LoggerFactory.getLogger(FactoryUtil.class);
 
-    public static <T, SplitT extends SourceSplit, StateT> List<SeaTunnelSource<T, SplitT, StateT>> createAndPrepareSource(
+    public static <T, SplitT extends SourceSplit, StateT extends Serializable> List<SeaTunnelSource<T, SplitT, StateT>> createAndPrepareSource(
         List<CatalogTable> multipleTables,
         Map<String, String> options,
         ClassLoader classLoader,

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/TableSourceFactory.java
Patch:
@@ -20,11 +20,13 @@
 import org.apache.seatunnel.api.source.SourceSplit;
 import org.apache.seatunnel.api.table.connector.TableSource;
 
+import java.io.Serializable;
+
 /**
  * This is an SPI interface, used to create {@link TableSource}. Each plugin need to have it own implementation.
  * todo: now we have not use this interface, we directly use {@link org.apache.seatunnel.api.source.SeaTunnelSource} as the SPI interface
  */
 public interface TableSourceFactory extends Factory {
 
-    <T, SplitT extends SourceSplit, StateT> TableSource<T, SplitT, StateT> createSource(TableFactoryContext context);
+    <T, SplitT extends SourceSplit, StateT extends Serializable> TableSource<T, SplitT, StateT> createSource(TableFactoryContext context);
 }

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/source/CoordinatedSource.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.seatunnel.translation.util.ThreadPoolExecutorFactory;
 
 import java.io.IOException;
+import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
@@ -39,7 +40,7 @@
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.stream.Collectors;
 
-public class CoordinatedSource<T, SplitT extends SourceSplit, StateT> implements BaseSourceFunction<T> {
+public class CoordinatedSource<T, SplitT extends SourceSplit, StateT extends Serializable> implements BaseSourceFunction<T> {
     protected static final long SLEEP_TIME_INTERVAL = 5L;
     protected final SeaTunnelSource<T, SplitT, StateT> source;
     protected final Map<Integer, List<byte[]>> restoredState;

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/source/ParallelSource.java
Patch:
@@ -28,6 +28,7 @@
 import org.apache.seatunnel.translation.util.ThreadPoolExecutorFactory;
 
 import java.io.IOException;
+import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
@@ -36,7 +37,7 @@
 import java.util.concurrent.Future;
 import java.util.concurrent.ScheduledThreadPoolExecutor;
 
-public class ParallelSource<T, SplitT extends SourceSplit, StateT> implements BaseSourceFunction<T> {
+public class ParallelSource<T, SplitT extends SourceSplit, StateT extends Serializable> implements BaseSourceFunction<T> {
 
     protected final SeaTunnelSource<T, SplitT, StateT> source;
     protected final ParallelEnumeratorContext<SplitT> parallelEnumeratorContext;

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/batch/CoordinatedBatchPartitionReader.java
Patch:
@@ -26,6 +26,7 @@
 import org.apache.seatunnel.translation.source.CoordinatedSource;
 import org.apache.seatunnel.translation.spark.source.InternalRowCollector;
 
+import java.io.Serializable;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
@@ -55,7 +56,7 @@ protected BaseSourceFunction<SeaTunnelRow> createInternalSource() {
             parallelism);
     }
 
-    public class InternalCoordinatedSource<SplitT extends SourceSplit, StateT> extends CoordinatedSource<SeaTunnelRow, SplitT, StateT> {
+    public class InternalCoordinatedSource<SplitT extends SourceSplit, StateT extends Serializable> extends CoordinatedSource<SeaTunnelRow, SplitT, StateT> {
 
         public InternalCoordinatedSource(SeaTunnelSource<SeaTunnelRow, SplitT, StateT> source, Map<Integer, List<byte[]>> restoredState, int parallelism) {
             super(source, restoredState, parallelism);

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/batch/ParallelBatchPartitionReader.java
Patch:
@@ -32,6 +32,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.io.IOException;
+import java.io.Serializable;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ExecutorService;
@@ -132,7 +133,7 @@ public void close() throws IOException {
         executorService.shutdown();
     }
 
-    public class InternalParallelSource<SplitT extends SourceSplit, StateT> extends ParallelSource<SeaTunnelRow, SplitT, StateT> {
+    public class InternalParallelSource<SplitT extends SourceSplit, StateT extends Serializable> extends ParallelSource<SeaTunnelRow, SplitT, StateT> {
 
         public InternalParallelSource(SeaTunnelSource<SeaTunnelRow, SplitT, StateT> source, Map<Integer, List<byte[]>> restoredState, int parallelism, int subtaskId) {
             super(source, restoredState, parallelism, subtaskId);

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/micro/CoordinatedMicroBatchPartitionReader.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.seatunnel.translation.spark.source.InternalRowCollector;
 import org.apache.seatunnel.translation.spark.source.ReaderState;
 
+import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Iterator;
 import java.util.List;
@@ -96,7 +97,7 @@ protected BaseSourceFunction<SeaTunnelRow> createInternalSource() {
             parallelism);
     }
 
-    public class InternalCoordinatedSource<SplitT extends SourceSplit, StateT> extends CoordinatedSource<SeaTunnelRow, SplitT, StateT> {
+    public class InternalCoordinatedSource<SplitT extends SourceSplit, StateT extends Serializable> extends CoordinatedSource<SeaTunnelRow, SplitT, StateT> {
 
         public InternalCoordinatedSource(SeaTunnelSource<SeaTunnelRow, SplitT, StateT> source, Map<Integer, List<byte[]>> restoredState, int parallelism) {
             super(source, restoredState, parallelism);

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/source/file/reader/format/TextReadStrategy.java
Patch:
@@ -44,7 +44,7 @@ public void read(String path, Collector<SeaTunnelRow> output) throws IOException
         FileSystem fs = FileSystem.get(conf);
         Path filePath = new Path(path);
         try (BufferedReader reader = new BufferedReader(new InputStreamReader(fs.open(filePath), StandardCharsets.UTF_8))) {
-            reader.lines().forEach(line -> output.collect(new SeaTunnelRow(new String[]{"TEXT_FIELD_NAME", line})));
+            reader.lines().forEach(line -> output.collect(new SeaTunnelRow(new String[]{line})));
         }
     }
 

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/FlinkEnvironment.java
Patch:
@@ -141,13 +141,13 @@ public void registerPlugin(List<URL> pluginPaths) {
             jars = new ArrayList<>();
         }
         jars.addAll(pluginPaths.stream().map(URL::toString).collect(Collectors.toList()));
-        configuration.set(PipelineOptions.JARS, jars);
+        configuration.set(PipelineOptions.JARS, jars.stream().distinct().collect(Collectors.toList()));
         List<String> classpath = configuration.get(PipelineOptions.CLASSPATHS);
         if (classpath == null) {
             classpath = new ArrayList<>();
         }
         classpath.addAll(pluginPaths.stream().map(URL::toString).collect(Collectors.toList()));
-        configuration.set(PipelineOptions.CLASSPATHS, classpath);
+        configuration.set(PipelineOptions.CLASSPATHS, classpath.stream().distinct().collect(Collectors.toList()));
     }
 
     public StreamExecutionEnvironment getStreamExecutionEnvironment() {

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/command/AbstractCommandArgs.java
Patch:
@@ -38,7 +38,7 @@ public abstract class AbstractCommandArgs implements CommandArgs {
     private List<String> variables = Collections.emptyList();
 
     // todo: use command type enum
-    @Parameter(names = {"-t", "--check"},
+    @Parameter(names = {"-ck", "--check"},
             description = "check config")
     private boolean checkConfig = false;
 

File: seatunnel-core/seatunnel-core-flink/src/test/java/org/apache/seatunnel/core/flink/args/FlinkCommandArgsTest.java
Patch:
@@ -27,7 +27,7 @@ public class FlinkCommandArgsTest {
 
     @Test
     public void testParseFlinkArgs() {
-        String[] args = {"-c", "app.conf", "-t", "-i", "city=shenyang", "-i", "date=20200202"};
+        String[] args = {"-c", "app.conf", "-ck", "-i", "city=shenyang", "-i", "date=20200202"};
         FlinkCommandArgs flinkArgs = new FlinkCommandArgs();
         JCommander.newBuilder()
             .addObject(flinkArgs)

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/AbstractFileSink.java
Patch:
@@ -41,7 +41,6 @@
 
 /**
  * Hive Sink implementation by using SeaTunnel sink API.
- * This class contains the method to create {@link TransactionStateFileSinkWriter} and {@link FileSinkAggregatedCommitter}.
  */
 public abstract class AbstractFileSink implements SeaTunnelSink<SeaTunnelRow, FileSinkState, FileCommitInfo, FileAggregatedCommitInfo> {
     private Config config;
@@ -92,7 +91,7 @@ public SinkWriter<SeaTunnelRow, FileCommitInfo, FileSinkState> createWriter(Sink
     @Override
     public SinkWriter<SeaTunnelRow, FileCommitInfo, FileSinkState> restoreWriter(SinkWriter.Context context, List<FileSinkState> states) throws IOException {
         if (this.getSinkConfig().isEnableTransaction()) {
-            return new TransactionStateFileSinkWriter(seaTunnelRowTypeInfo,
+            return new FileSinkWriterWithTransaction(seaTunnelRowTypeInfo,
                 config,
                 context,
                 textFileSinkConfig,

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/FileAggregatedCommitInfo.java
Patch:
@@ -21,6 +21,7 @@
 import lombok.Data;
 
 import java.io.Serializable;
+import java.util.List;
 import java.util.Map;
 
 @Data
@@ -33,4 +34,6 @@ public class FileAggregatedCommitInfo implements Serializable {
      * V is the target file path of the data file.
      */
     private Map<String, Map<String, String>> transactionMap;
+
+    private Map<String, List<String>> partitionDirAndValsMap;
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/FileCommitInfo.java
Patch:
@@ -21,6 +21,7 @@
 import lombok.Data;
 
 import java.io.Serializable;
+import java.util.List;
 import java.util.Map;
 
 @Data
@@ -34,5 +35,7 @@ public class FileCommitInfo implements Serializable {
      */
     private Map<String, String> needMoveFiles;
 
+    private Map<String, List<String>> partitionDirAndValsMap;
+
     private String transactionDir;
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/transaction/Transaction.java
Patch:
@@ -22,7 +22,6 @@
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileSinkAggregatedCommitter;
 import org.apache.seatunnel.connectors.seatunnel.file.sink.FileSinkState;
-import org.apache.seatunnel.connectors.seatunnel.file.sink.TransactionStateFileSinkWriter;
 
 import lombok.NonNull;
 
@@ -40,7 +39,7 @@ public interface Transaction extends Serializable {
     String beginTransaction(@NonNull Long checkpointId);
 
     /**
-     * Abort current Transaction, called when {@link TransactionStateFileSinkWriter#prepareCommit()} or {@link TransactionStateFileSinkWriter#snapshotState(long)} failed
+     * Abort current Transaction, called when {@link org.apache.seatunnel.connectors.seatunnel.file.sink.TransactionStateFileSinkWriter#prepareCommit()} or {@link org.apache.seatunnel.connectors.seatunnel.file.sink.TransactionStateFileSinkWriter#snapshotState(long)} failed
      */
     void abortTransaction();
 
@@ -56,7 +55,7 @@ public interface Transaction extends Serializable {
     List<String> getTransactionAfter(@NonNull String transactionId);
 
     /**
-     * Called by {@link TransactionStateFileSinkWriter#prepareCommit()}
+     * Called by {@link org.apache.seatunnel.connectors.seatunnel.file.sink.TransactionStateFileSinkWriter#prepareCommit()}
      * We should end the transaction in this method. After this method is called, the transaction will no longer accept data writing
      *
      * @return Return the commit information that can be commit in {@link FileSinkAggregatedCommitter#commit(List)}

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/main/java/org/apache/seatunnel/connectors/seatunnel/file/sink/writer/PartitionDirNameGenerator.java
Patch:
@@ -20,7 +20,9 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 
 import java.io.Serializable;
+import java.util.List;
+import java.util.Map;
 
 public interface PartitionDirNameGenerator extends Serializable {
-    String generatorPartitionDir(SeaTunnelRow seaTunnelRow);
+    Map<String, List<String>> generatorPartitionDir(SeaTunnelRow seaTunnelRow);
 }

File: seatunnel-connectors-v2/connector-file/connector-file-base/src/test/java/org/apache/seatunnel/connectors/seatunnel/file/writer/TestFileSinkPartitionDirNameGenerator.java
Patch:
@@ -55,15 +55,15 @@ public void testPartitionDirNameGenerator() {
         partitionFieldsIndexInRow.add(3);
 
         PartitionDirNameGenerator partitionDirNameGenerator = new FileSinkPartitionDirNameGenerator(partitionFieldList, partitionFieldsIndexInRow, "${v0}/${v1}");
-        String partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow);
+        String partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow).keySet().toArray()[0].toString();
         Assert.assertEquals("test/3", partitionDir);
 
         partitionDirNameGenerator = new FileSinkPartitionDirNameGenerator(partitionFieldList, partitionFieldsIndexInRow, "${k0}=${v0}/${k1}=${v1}");
-        partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow);
+        partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow).keySet().toArray()[0].toString();
         Assert.assertEquals("c3=test/c4=3", partitionDir);
 
         partitionDirNameGenerator = new FileSinkPartitionDirNameGenerator(null, null, "${k0}=${v0}/${k1}=${v1}");
-        partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow);
+        partitionDir = partitionDirNameGenerator.generatorPartitionDir(seaTunnelRow).keySet().toArray()[0].toString();
         Assert.assertEquals(Constant.NON_PARTITION, partitionDir);
     }
 }

File: seatunnel-connectors-v2/connector-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/HiveSinkState.java
Patch:
@@ -25,5 +25,6 @@
 @Data
 @AllArgsConstructor
 public class HiveSinkState implements Serializable {
-    private HiveSinkConfig hiveSinkConfig;
+    private String transactionId;
+    private Long checkpointId;
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/util/SchemaUtil.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.seatunnel.flink.util;
 
-import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.flink.enums.FormatType;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
@@ -203,7 +202,6 @@ public static RowTypeInfo getTypeInformation(ObjectNode json) {
         int size = json.size();
         String[] fields = new String[size];
         TypeInformation<?>[] informations = new TypeInformation[size];
-        Map<String, Object> jsonMap = JsonUtils.toMap(json);
         int i = 0;
         Iterator<Map.Entry<String, JsonNode>> nodeIterator = json.fields();
         while (nodeIterator.hasNext()) {

File: seatunnel-core/seatunnel-core-flink-sql/src/main/java/org/apache/seatunnel/core/sql/FlinkSqlStarter.java
Patch:
@@ -39,6 +39,7 @@ public class FlinkSqlStarter implements Starter {
     FlinkSqlStarter(String[] args) {
         this.flinkCommandArgs = CommandLineUtils.parseCommandArgs(args, FlinkJobType.SQL);
         // set the deployment mode, used to get the job jar path.
+        Common.setStarter(true);
         Common.setDeployMode(flinkCommandArgs.getDeployMode());
         this.appJar = Common.appLibDir().resolve(APP_JAR_NAME).toString();
     }

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/FlinkStarter.java
Patch:
@@ -47,6 +47,7 @@ public class FlinkStarter implements Starter {
         this.flinkCommandArgs = CommandLineUtils.parseCommandArgs(args, FlinkJobType.JAR);
         // set the deployment mode, used to get the job jar path.
         Common.setDeployMode(flinkCommandArgs.getDeployMode());
+        Common.setStarter(true);
         this.appJar = Common.appLibDir().resolve(APP_JAR_NAME).toString();
     }
 

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/FlinkStarter.java
Patch:
@@ -47,6 +47,7 @@ public class FlinkStarter implements Starter {
         this.flinkCommandArgs = CommandLineUtils.parseCommandArgs(args, FlinkJobType.JAR);
         // set the deployment mode, used to get the job jar path.
         Common.setDeployMode(flinkCommandArgs.getDeployMode());
+        Common.setStarter(true);
         this.appJar = Common.appLibDir().resolve(APP_JAR_NAME).toString();
     }
 

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-kafka/src/main/java/org/apache/seatunnel/flink/kafka/source/KafkaTableStream.java
Patch:
@@ -111,7 +111,7 @@ public void prepare(FlinkEnvironment env) {
         }
         String schemaContent = config.getString(SCHEMA);
         format = FormatType.from(config.getString(SOURCE_FORMAT).trim().toLowerCase());
-        schemaInfo = JsonUtils.parseObject(schemaContent);
+        schemaInfo = JsonUtils.parseArray(schemaContent);
     }
 
     @Override

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/ClickhouseSinkWriter.java
Patch:
@@ -193,10 +193,10 @@ private Map<String, ClickhouseFieldInjectFunction> initFieldInjectFunctionMap()
                 new BigDecimalInjectFunction(),
                 new DateInjectFunction(),
                 new DateTimeInjectFunction(),
+                new LongInjectFunction(),
                 new DoubleInjectFunction(),
                 new FloatInjectFunction(),
                 new IntInjectFunction(),
-                new LongInjectFunction(),
                 new StringInjectFunction()
         );
         ClickhouseFieldInjectFunction defaultFunction = new StringInjectFunction();

File: seatunnel-core/seatunnel-core-spark/src/main/java/org/apache/seatunnel/core/spark/SparkStarter.java
Patch:
@@ -50,9 +50,11 @@
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Objects;
+import java.util.Set;
 import java.util.function.Function;
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
@@ -213,7 +215,7 @@ private List<Path> getConnectorJarDependencies() {
             return Collections.emptyList();
         }
         Config config = new ConfigBuilder(Paths.get(commandArgs.getConfigFile())).getConfig();
-        List<URL> pluginJars = new ArrayList<>();
+        Set<URL> pluginJars = new HashSet<>();
         SparkSourcePluginDiscovery sparkSourcePluginDiscovery = new SparkSourcePluginDiscovery();
         SparkSinkPluginDiscovery sparkSinkPluginDiscovery = new SparkSinkPluginDiscovery();
         pluginJars.addAll(sparkSourcePluginDiscovery.getPluginJarPaths(getPluginIdentifiers(config, PluginType.SOURCE)));

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -62,7 +62,7 @@ protected List<SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializa
             seaTunnelSink.prepare(sinkConfig);
             seaTunnelSink.setSeaTunnelContext(SeaTunnelContext.getContext());
             return seaTunnelSink;
-        }).collect(Collectors.toList());
+        }).distinct().collect(Collectors.toList());
         flinkEnvironment.registerPlugin(pluginJars);
         return sinks;
     }

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/TransformExecuteProcessor.java
Patch:
@@ -55,7 +55,7 @@ protected List<FlinkStreamTransform> initializePlugins(List<? extends Config> pl
                 pluginInstance.setConfig(transformConfig);
                 pluginInstance.prepare(flinkEnvironment);
                 return pluginInstance;
-            }).collect(Collectors.toList());
+            }).distinct().collect(Collectors.toList());
         flinkEnvironment.registerPlugin(pluginJars);
         return transforms;
     }

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/SparkStarter.java
Patch:
@@ -51,9 +51,11 @@
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Objects;
+import java.util.Set;
 import java.util.function.Function;
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
@@ -225,7 +227,7 @@ private List<Path> getConnectorJarDependencies() {
             return Collections.emptyList();
         }
         Config config = new ConfigBuilder(Paths.get(commandArgs.getConfigFile())).getConfig();
-        List<URL> pluginJars = new ArrayList<>();
+        Set<URL> pluginJars = new HashSet<>();
         SparkSourcePluginDiscovery sparkSourcePluginDiscovery = new SparkSourcePluginDiscovery();
         SparkSinkPluginDiscovery sparkSinkPluginDiscovery = new SparkSinkPluginDiscovery();
         pluginJars.addAll(sparkSourcePluginDiscovery.getPluginJarPaths(getPluginIdentifiers(config, PluginType.SOURCE)));

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -58,7 +58,7 @@ protected SinkExecuteProcessor(SparkEnvironment sparkEnvironment,
             seaTunnelSink.prepare(sinkConfig);
             seaTunnelSink.setSeaTunnelContext(SeaTunnelContext.getContext());
             return seaTunnelSink;
-        }).collect(Collectors.toList());
+        }).distinct().collect(Collectors.toList());
         sparkEnvironment.registerPlugin(pluginJars);
         return sinks;
     }

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/TransformExecuteProcessor.java
Patch:
@@ -55,7 +55,7 @@ protected List<BaseSparkTransform> initializePlugins(List<? extends Config> plug
                 pluginInstance.setConfig(transformConfig);
                 pluginInstance.prepare(sparkEnvironment);
                 return pluginInstance;
-            }).collect(Collectors.toList());
+            }).distinct().collect(Collectors.toList());
         sparkEnvironment.registerPlugin(pluginJars);
         return transforms;
     }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/serialization/Serializer.java
Patch:
@@ -18,9 +18,8 @@
 package org.apache.seatunnel.api.serialization;
 
 import java.io.IOException;
-import java.io.Serializable;
 
-public interface Serializer<T> extends Serializable {
+public interface Serializer<T> {
 
     /**
      * Serializes the given object.

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SeaTunnelSink.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.seatunnel.api.common.PluginIdentifierInterface;
 import org.apache.seatunnel.api.common.SeaTunnelPluginLifeCycle;
 import org.apache.seatunnel.api.serialization.Serializer;
-import org.apache.seatunnel.api.source.SeaTunnelRuntimeEnvironment;
+import org.apache.seatunnel.api.source.SeaTunnelContextAware;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 
@@ -43,7 +43,7 @@
  *                                {@link SinkAggregatedCommitter} handle it, this class should implement interface {@link Serializable}.
  */
 public interface SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT>
-    extends Serializable, PluginIdentifierInterface, SeaTunnelPluginLifeCycle, SeaTunnelRuntimeEnvironment {
+    extends Serializable, PluginIdentifierInterface, SeaTunnelPluginLifeCycle, SeaTunnelContextAware {
 
     /**
      * Set the row type info of sink row data. This method will be automatically called by translation.

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SeaTunnelContextAware.java
Patch:
@@ -22,7 +22,7 @@
 /**
  * This interface defines the runtime environment of the SeaTunnel application.
  */
-public interface SeaTunnelRuntimeEnvironment {
+public interface SeaTunnelContextAware {
 
     default void setSeaTunnelContext(SeaTunnelContext seaTunnelContext){
         // nothing

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SeaTunnelSource.java
Patch:
@@ -34,7 +34,7 @@
  * @param <StateT> The type of checkpoint states.
  */
 public interface SeaTunnelSource<T, SplitT extends SourceSplit, StateT>
-    extends Serializable, PluginIdentifierInterface, SeaTunnelPluginLifeCycle, SeaTunnelRuntimeEnvironment {
+    extends Serializable, PluginIdentifierInterface, SeaTunnelPluginLifeCycle, SeaTunnelContextAware {
 
     /**
      * Get the boundedness of this source.

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SourceReader.java
Patch:
@@ -114,6 +114,6 @@ interface Context {
          *
          * @param sourceEvent the source event to coordinator.
          */
-        void sendSourceEventToCoordinator(SourceEvent sourceEvent);
+        void sendSourceEventToEnumerator(SourceEvent sourceEvent);
     }
 }

File: seatunnel-connectors-v2/connector-common/src/main/java/org/apache/seatunnel/connectors/seatunnel/common/source/AbstractSingleSplitSource.java
Patch:
@@ -29,7 +29,7 @@ public abstract class AbstractSingleSplitSource<T> implements SeaTunnelSource<T,
 
     @Override
     public final AbstractSingleSplitReader<T> createReader(SourceReader.Context readerContext) throws Exception {
-        checkArgument(readerContext.getIndexOfSubtask() == 0, "Single split source allows only a single reader to be created.");
+        checkArgument(readerContext.getIndexOfSubtask() == 0, "A single split source allows only one single reader to be created.");
         return createReader(new SingleSplitReaderContext(readerContext));
     }
 

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/source/CoordinatedReaderContext.java
Patch:
@@ -56,7 +56,7 @@ public void sendSplitRequest() {
     }
 
     @Override
-    public void sendSourceEventToCoordinator(SourceEvent sourceEvent) {
+    public void sendSourceEventToEnumerator(SourceEvent sourceEvent) {
         coordinatedSource.handleReaderEvent(subtaskId, sourceEvent);
     }
 }

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/source/ParallelReaderContext.java
Patch:
@@ -56,7 +56,7 @@ public void sendSplitRequest() {
     }
 
     @Override
-    public void sendSourceEventToCoordinator(SourceEvent sourceEvent) {
+    public void sendSourceEventToEnumerator(SourceEvent sourceEvent) {
         // TODO: exception
         throw new RuntimeException("");
     }

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -164,5 +164,4 @@ private String getResource(String confFile) {
     private String getConnectorPath(String fileName) {
         return Paths.get(SEATUNNEL_CONNECTORS, "seatunnel", fileName).toString();
     }
-
 }

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/assertion/FakeSourceToAssertIT.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.e2e.flink.assertion;
+package org.apache.seatunnel.e2e.flink.v2.assertion;
 
 import org.apache.seatunnel.e2e.flink.FlinkContainer;
 

File: seatunnel-e2e/seatunnel-flink-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/flink/v2/fake/FakeSourceToConsoleIT.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.e2e.flink.fake;
+package org.apache.seatunnel.e2e.flink.v2.fake;
 
 import org.apache.seatunnel.e2e.flink.FlinkContainer;
 

File: seatunnel-e2e/seatunnel-spark-connector-v2-e2e/src/test/java/org/apache/seatunnel/e2e/spark/v2/fake/FakeSourceToConsoleIT.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.e2e.spark.fake;
+package org.apache.seatunnel.e2e.spark.v2.fake;
 
 import org.apache.seatunnel.e2e.spark.SparkContainer;
 

File: seatunnel-examples/seatunnel-flink-connector-v2-example/src/main/java/org/apache/seatunnel/example/flink/v2/SeaTunnelApiExample.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.example.flink;
+package org.apache.seatunnel.example.flink.v2;
 
 import org.apache.seatunnel.core.starter.Seatunnel;
 import org.apache.seatunnel.core.starter.command.Command;

File: seatunnel-examples/seatunnel-spark-connector-v2-example/src/main/java/org/apache/seatunnel/example/spark/v2/SeaTunnelApiExample.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.example.spark;
+package org.apache.seatunnel.example.spark.v2;
 
 import org.apache.seatunnel.common.config.DeployMode;
 import org.apache.seatunnel.core.starter.Seatunnel;

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/config/FlinkExecutionContext.java
Patch:
@@ -63,7 +63,7 @@ public List<BaseSource<FlinkEnvironment>> getSources() {
         return configList.stream()
             .map(pluginConfig -> {
                 PluginIdentifier pluginIdentifier = PluginIdentifier.of(engineType, pluginType, pluginConfig.getString("plugin_name"));
-                BaseSource<FlinkEnvironment> pluginInstance = flinkSourcePluginDiscovery.getPluginInstance(pluginIdentifier);
+                BaseSource<FlinkEnvironment> pluginInstance = flinkSourcePluginDiscovery.createPluginInstance(pluginIdentifier);
                 pluginInstance.setConfig(pluginConfig);
                 return pluginInstance;
             }).collect(Collectors.toList());
@@ -77,7 +77,7 @@ public List<BaseTransform<FlinkEnvironment>> getTransforms() {
         return configList.stream()
             .map(pluginConfig -> {
                 PluginIdentifier pluginIdentifier = PluginIdentifier.of(engineType, pluginType, pluginConfig.getString("plugin_name"));
-                BaseTransform<FlinkEnvironment> pluginInstance = flinkTransformPluginDiscovery.getPluginInstance(pluginIdentifier);
+                BaseTransform<FlinkEnvironment> pluginInstance = flinkTransformPluginDiscovery.createPluginInstance(pluginIdentifier);
                 pluginInstance.setConfig(pluginConfig);
                 return pluginInstance;
             }).collect(Collectors.toList());
@@ -91,7 +91,7 @@ public List<BaseSink<FlinkEnvironment>> getSinks() {
         return configList.stream()
             .map(pluginConfig -> {
                 PluginIdentifier pluginIdentifier = PluginIdentifier.of(engineType, pluginType, pluginConfig.getString("plugin_name"));
-                BaseSink<FlinkEnvironment> pluginInstance = flinkSinkPluginDiscovery.getPluginInstance(pluginIdentifier);
+                BaseSink<FlinkEnvironment> pluginInstance = flinkSinkPluginDiscovery.createPluginInstance(pluginIdentifier);
                 pluginInstance.setConfig(pluginConfig);
                 return pluginInstance;
             }).collect(Collectors.toList());

File: seatunnel-core/seatunnel-core-spark/src/main/java/org/apache/seatunnel/core/spark/config/SparkExecutionContext.java
Patch:
@@ -62,7 +62,7 @@ public List<BaseSource<SparkEnvironment>> getSources() {
         return configList.stream()
             .map(pluginConfig -> {
                 PluginIdentifier pluginIdentifier = PluginIdentifier.of(engineType, pluginType, pluginConfig.getString("plugin_name"));
-                BaseSource<SparkEnvironment> pluginInstance = sparkSourcePluginDiscovery.getPluginInstance(pluginIdentifier);
+                BaseSource<SparkEnvironment> pluginInstance = sparkSourcePluginDiscovery.createPluginInstance(pluginIdentifier);
                 pluginInstance.setConfig(pluginConfig);
                 return pluginInstance;
             }).collect(Collectors.toList());
@@ -76,7 +76,7 @@ public List<BaseTransform<SparkEnvironment>> getTransforms() {
         return configList.stream()
             .map(pluginConfig -> {
                 PluginIdentifier pluginIdentifier = PluginIdentifier.of(engineType, pluginType, pluginConfig.getString("plugin_name"));
-                BaseTransform<SparkEnvironment> pluginInstance = sparkTransformPluginDiscovery.getPluginInstance(pluginIdentifier);
+                BaseTransform<SparkEnvironment> pluginInstance = sparkTransformPluginDiscovery.createPluginInstance(pluginIdentifier);
                 pluginInstance.setConfig(pluginConfig);
                 return pluginInstance;
             }).collect(Collectors.toList());
@@ -90,7 +90,7 @@ public List<BaseSink<SparkEnvironment>> getSinks() {
         return configList.stream()
             .map(pluginConfig -> {
                 PluginIdentifier pluginIdentifier = PluginIdentifier.of(engineType, pluginType, pluginConfig.getString("plugin_name"));
-                BaseSink<SparkEnvironment> pluginInstance = sparkSinkPluginDiscovery.getPluginInstance(pluginIdentifier);
+                BaseSink<SparkEnvironment> pluginInstance = sparkSinkPluginDiscovery.createPluginInstance(pluginIdentifier);
                 pluginInstance.setConfig(pluginConfig);
                 return pluginInstance;
             }).collect(Collectors.toList());

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -58,7 +58,7 @@ protected List<SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializa
             PluginIdentifier pluginIdentifier = PluginIdentifier.of(ENGINE_TYPE, PLUGIN_TYPE, sinkConfig.getString(PLUGIN_NAME));
             pluginJars.addAll(sinkPluginDiscovery.getPluginJarPaths(Lists.newArrayList(pluginIdentifier)));
             SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializable> seaTunnelSink =
-                sinkPluginDiscovery.getPluginInstance(pluginIdentifier);
+                sinkPluginDiscovery.createPluginInstance(pluginIdentifier);
             seaTunnelSink.prepare(sinkConfig);
             seaTunnelSink.setSeaTunnelContext(SeaTunnelContext.getContext());
             return seaTunnelSink;

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SourceExecuteProcessor.java
Patch:
@@ -106,7 +106,7 @@ protected List<SeaTunnelSource> initializePlugins(List<? extends Config> pluginC
             PluginIdentifier pluginIdentifier = PluginIdentifier.of(
                 ENGINE_TYPE, PLUGIN_TYPE, sourceConfig.getString(PLUGIN_NAME));
             jars.addAll(sourcePluginDiscovery.getPluginJarPaths(Lists.newArrayList(pluginIdentifier)));
-            SeaTunnelSource seaTunnelSource = sourcePluginDiscovery.getPluginInstance(pluginIdentifier);
+            SeaTunnelSource seaTunnelSource = sourcePluginDiscovery.createPluginInstance(pluginIdentifier);
             seaTunnelSource.prepare(sourceConfig);
             seaTunnelSource.setSeaTunnelContext(SeaTunnelContext.getContext());
             if (SeaTunnelContext.getContext().getJobMode() == JobMode.BATCH

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/TransformExecuteProcessor.java
Patch:
@@ -51,7 +51,7 @@ protected List<FlinkStreamTransform> initializePlugins(List<? extends Config> pl
             .map(transformConfig -> {
                 PluginIdentifier pluginIdentifier = PluginIdentifier.of(ENGINE_TYPE, PLUGIN_TYPE, transformConfig.getString(PLUGIN_NAME));
                 pluginJars.addAll(transformPluginDiscovery.getPluginJarPaths(Lists.newArrayList(pluginIdentifier)));
-                FlinkStreamTransform pluginInstance = (FlinkStreamTransform) transformPluginDiscovery.getPluginInstance(pluginIdentifier);
+                FlinkStreamTransform pluginInstance = (FlinkStreamTransform) transformPluginDiscovery.createPluginInstance(pluginIdentifier);
                 pluginInstance.setConfig(transformConfig);
                 pluginInstance.prepare(flinkEnvironment);
                 return pluginInstance;

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -54,7 +54,7 @@ protected SinkExecuteProcessor(SparkEnvironment sparkEnvironment,
         List<SeaTunnelSink<?, ?, ?, ?>> sinks = pluginConfigs.stream().map(sinkConfig -> {
             PluginIdentifier pluginIdentifier = PluginIdentifier.of(ENGINE_TYPE, PLUGIN_TYPE, sinkConfig.getString(PLUGIN_NAME));
             pluginJars.addAll(sinkPluginDiscovery.getPluginJarPaths(Lists.newArrayList(pluginIdentifier)));
-            SeaTunnelSink<?, ?, ?, ?> seaTunnelSink = sinkPluginDiscovery.getPluginInstance(pluginIdentifier);
+            SeaTunnelSink<?, ?, ?, ?> seaTunnelSink = sinkPluginDiscovery.createPluginInstance(pluginIdentifier);
             seaTunnelSink.prepare(sinkConfig);
             seaTunnelSink.setSeaTunnelContext(SeaTunnelContext.getContext());
             return seaTunnelSink;

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SourceExecuteProcessor.java
Patch:
@@ -70,7 +70,7 @@ public List<Dataset<Row>> execute(List<Dataset<Row>> upstreamDataStreams) {
             PluginIdentifier pluginIdentifier = PluginIdentifier.of(
                 ENGINE_TYPE, PLUGIN_TYPE, sourceConfig.getString(PLUGIN_NAME));
             jars.addAll(sourcePluginDiscovery.getPluginJarPaths(Lists.newArrayList(pluginIdentifier)));
-            SeaTunnelSource<?, ?, ?> seaTunnelSource = sourcePluginDiscovery.getPluginInstance(pluginIdentifier);
+            SeaTunnelSource<?, ?, ?> seaTunnelSource = sourcePluginDiscovery.createPluginInstance(pluginIdentifier);
             seaTunnelSource.prepare(sourceConfig);
             seaTunnelSource.setSeaTunnelContext(SeaTunnelContext.getContext());
             sources.add(seaTunnelSource);

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/TransformExecuteProcessor.java
Patch:
@@ -51,7 +51,7 @@ protected List<BaseSparkTransform> initializePlugins(List<? extends Config> plug
             .map(transformConfig -> {
                 PluginIdentifier pluginIdentifier = PluginIdentifier.of(ENGINE_TYPE, PLUGIN_TYPE, transformConfig.getString(PLUGIN_NAME));
                 pluginJars.addAll(transformPluginDiscovery.getPluginJarPaths(Lists.newArrayList(pluginIdentifier)));
-                BaseSparkTransform pluginInstance = transformPluginDiscovery.getPluginInstance(pluginIdentifier);
+                BaseSparkTransform pluginInstance = transformPluginDiscovery.createPluginInstance(pluginIdentifier);
                 pluginInstance.setConfig(transformConfig);
                 pluginInstance.prepare(sparkEnvironment);
                 return pluginInstance;

File: seatunnel-plugin-discovery/src/main/java/org/apache/seatunnel/plugin/discovery/PluginDiscovery.java
Patch:
@@ -58,7 +58,7 @@ public interface PluginDiscovery<T> {
      * @param pluginIdentifier plugin identifier.
      * @return plugin instance. If not found, throw IllegalArgumentException.
      */
-    T getPluginInstance(PluginIdentifier pluginIdentifier);
+    T createPluginInstance(PluginIdentifier pluginIdentifier);
 
     /**
      * Get all plugin instances.

File: seatunnel-connectors-v2/connector-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/sink/JdbcSinkAggregatedCommitter.java
Patch:
@@ -83,7 +83,9 @@ public void abort(List<JdbcAggregatedCommitInfo> aggregatedCommitInfo) throws IO
     public void close()
         throws IOException {
         try {
-            xaFacade.close();
+            if (xaFacade.isOpen()) {
+                xaFacade.close();
+            }
         } catch (Exception e) {
             ExceptionUtils.rethrowIOException(e);
         }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchExecution.java
Patch:
@@ -118,6 +118,6 @@ public Config getConfig() {
     }
 
     private boolean whetherExecute(List<FlinkBatchSink> sinks) {
-        return sinks.stream().anyMatch(s -> !"ConsoleSink".equals(s.getPluginName()));
+        return sinks.stream().noneMatch(s -> "ConsoleSink".equals(s.getPluginName()) || "AssertSink".equals(s.getPluginName()));
     }
 }

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-fake/src/main/java/org/apache/seatunnel/flink/fake/Config.java
Patch:
@@ -143,7 +143,7 @@ public final class Config {
     /**
      * mock_data_size Default value.
      */
-    public static final int MOCK_DATA_SIZE_DEFAULT_VALUE = 300;
+    public static final int MOCK_DATA_SIZE_DEFAULT_VALUE = 10;
 
     /**
      * Create data interval, unit is second. Default is 1 second.

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-fake/src/main/java/org/apache/seatunnel/flink/fake/source/FakeSourceStream.java
Patch:
@@ -84,7 +84,7 @@ public void run(SourceFunction.SourceContext<Row> ctx) throws Exception {
         while (running){
             Row rowData = MockSchema.mockRowData(mockDataSchema);
             ctx.collect(rowData);
-            TimeUnit.MILLISECONDS.sleep(mockDataInterval);
+            TimeUnit.SECONDS.sleep(mockDataInterval);
         }
     }
 

File: seatunnel-core/seatunnel-core-spark/src/main/java/org/apache/seatunnel/core/spark/SparkStarter.java
Patch:
@@ -25,6 +25,7 @@
 import org.apache.seatunnel.common.constants.PluginType;
 import org.apache.seatunnel.core.base.Starter;
 import org.apache.seatunnel.core.base.config.ConfigBuilder;
+import org.apache.seatunnel.core.base.config.ConfigParser;
 import org.apache.seatunnel.core.base.config.EngineType;
 import org.apache.seatunnel.core.base.utils.CompressionUtils;
 import org.apache.seatunnel.core.spark.args.SparkCommandArgs;

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/env/RuntimeEnv.java
Patch:
@@ -23,7 +23,7 @@
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
 import java.net.URL;
-import java.util.Set;
+import java.util.List;
 
 /**
  * engine related runtime environment
@@ -42,6 +42,6 @@ public interface RuntimeEnv {
 
     JobMode getJobMode();
 
-    void registerPlugin(Set<URL> pluginPaths);
+    void registerPlugin(List<URL> pluginPaths);
 
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/FlinkEnvironment.java
Patch:
@@ -50,7 +50,6 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Objects;
-import java.util.Set;
 import java.util.stream.Collectors;
 
 public class FlinkEnvironment implements RuntimeEnv {

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/SparkEnvironment.java
Patch:
@@ -38,7 +38,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.net.URL;
-import java.util.Set;
+import java.util.List;
 
 public class SparkEnvironment implements RuntimeEnv {
 
@@ -89,7 +89,7 @@ public CheckResult checkConfig() {
     }
 
     @Override
-    public void registerPlugin(Set<URL> pluginPaths) {
+    public void registerPlugin(List<URL> pluginPaths) {
         LOGGER.info("register plugins :" + pluginPaths);
         // TODO we use --jar parameter to support submit multi-jar in spark cluster at now. Refactor it to
         //  support submit multi-jar in code or remove this logic.

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/command/Command.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.core.base.command;
 
 import org.apache.seatunnel.apis.base.command.CommandArgs;
+import org.apache.seatunnel.core.base.exception.CommandException;
 
 /**
  * Command interface.

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/ConfigBuilder.java
Patch:
@@ -17,8 +17,6 @@
 
 package org.apache.seatunnel.core.base.config;
 
-
-import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.config.ConfigRuntimeException;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/EnvironmentFactory.java
Patch:
@@ -20,9 +20,6 @@
 import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.common.constants.PluginType;
-
-import org.apache.seatunnel.apis.base.env.RuntimeEnv;
-import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.spark.SparkEnvironment;
 

File: seatunnel-core/seatunnel-core-flink/src/test/java/org/apache/seatunnel/core/flink/command/FlinkTaskExecuteCommandTest.java
Patch:
@@ -36,7 +36,7 @@ public class FlinkTaskExecuteCommandTest {
     @Test
     public void checkPluginType() {
         List<MockBatchSource> sources = Lists.newArrayList(new MockBatchSource());
-        FlinkTaskExecuteCommand flinkTaskExecuteCommand = new FlinkTaskExecuteCommand(null);
+        FlinkApiTaskExecuteCommand flinkTaskExecuteCommand = new FlinkApiTaskExecuteCommand(null);
         // check success
         flinkTaskExecuteCommand.checkPluginType(JobMode.BATCH, sources);
         Assert.assertThrows("checkPluginType should throw IllegalException", IllegalArgumentException.class, () -> {

File: seatunnel-connectors-v2/connector-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/sink/client/ClickhouseSinkWriter.java
Patch:
@@ -57,7 +57,7 @@ public class ClickhouseSinkWriter implements SinkWriter<SeaTunnelRow, CKCommitIn
 
     private static final Logger LOGGER = LoggerFactory.getLogger(ClickhouseSinkWriter.class);
 
-    private final SinkWriter.Context context;
+    private final Context context;
     private final ReaderOption option;
     private final ShardRouter shardRouter;
     private final transient ClickhouseProxy proxy;
@@ -69,7 +69,7 @@ public class ClickhouseSinkWriter implements SinkWriter<SeaTunnelRow, CKCommitIn
     private static final Pattern NULLABLE = Pattern.compile("Nullable\\((.*)\\)");
     private static final Pattern LOW_CARDINALITY = Pattern.compile("LowCardinality\\((.*)\\)");
 
-    ClickhouseSinkWriter(ReaderOption option, SinkWriter.Context context) {
+    ClickhouseSinkWriter(ReaderOption option, Context context) {
         this.option = option;
         this.context = context;
 

File: seatunnel-e2e/seatunnel-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -153,7 +153,7 @@ protected void copySeaTunnelFlinkFile() {
 
         // copy plugin-mapping.properties
         jobManager.copyFileToContainer(
-            MountableFile.forHostPath(PROJECT_ROOT_PATH + "/seatunnel-connectors/plugin-mapping.properties"),
+            MountableFile.forHostPath(PROJECT_ROOT_PATH + "/plugin-mapping.properties"),
             Paths.get(SEATUNNEL_CONNECTORS, PLUGIN_MAPPING_FILE).toString());
     }
 

File: seatunnel-e2e/seatunnel-flink-new-connector-e2e/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -144,16 +144,16 @@ protected void copySeaTunnelFlinkFile() {
 
         // copy connectors
         File jars = new File(PROJECT_ROOT_PATH +
-            "/seatunnel-connectors/seatunnel-connectors-seatunnel-dist/target/lib");
-        Arrays.stream(Objects.requireNonNull(jars.listFiles(f -> f.getName().startsWith("seatunnel-connector-seatunnel"))))
+            "/seatunnel-connectors-v2-dist/target/lib");
+        Arrays.stream(Objects.requireNonNull(jars.listFiles(f -> f.getName().startsWith("connector-"))))
             .forEach(jar ->
                 jobManager.copyFileToContainer(
                     MountableFile.forHostPath(jar.getAbsolutePath()),
                     getConnectorPath(jar.getName())));
 
         // copy plugin-mapping.properties
         jobManager.copyFileToContainer(
-            MountableFile.forHostPath(PROJECT_ROOT_PATH + "/seatunnel-connectors/plugin-mapping.properties"),
+            MountableFile.forHostPath(PROJECT_ROOT_PATH + "/plugin-mapping.properties"),
             Paths.get(SEATUNNEL_CONNECTORS, PLUGIN_MAPPING_FILE).toString());
     }
 

File: seatunnel-e2e/seatunnel-spark-e2e/src/test/java/org/apache/seatunnel/e2e/spark/SparkContainer.java
Patch:
@@ -133,7 +133,7 @@ protected void copySeaTunnelSparkFile() {
 
         // copy plugin-mapping.properties
         master.copyFileToContainer(
-            MountableFile.forHostPath(PROJECT_ROOT_PATH + "/seatunnel-connectors/plugin-mapping.properties"),
+            MountableFile.forHostPath(PROJECT_ROOT_PATH + "/plugin-mapping.properties"),
             Paths.get(CONNECTORS_PATH, PLUGIN_MAPPING_FILE).toString());
     }
 

File: seatunnel-e2e/seatunnel-spark-new-connector-e2e/src/test/java/org/apache/seatunnel/e2e/spark/SparkContainer.java
Patch:
@@ -134,7 +134,7 @@ protected void copySeaTunnelSparkFile() {
 
         // copy plugin-mapping.properties
         master.copyFileToContainer(
-            MountableFile.forHostPath(PROJECT_ROOT_PATH + "/seatunnel-connectors/plugin-mapping.properties"),
+            MountableFile.forHostPath(PROJECT_ROOT_PATH + "/plugin-mapping.properties"),
             Paths.get(CONNECTORS_PATH, PLUGIN_MAPPING_FILE).toString());
     }
 
@@ -148,11 +148,11 @@ private String getConnectorPath(String fileName) {
 
     private List<File> getConnectorJarFiles() {
         File jars = new File(PROJECT_ROOT_PATH +
-            "/seatunnel-connectors/seatunnel-connectors-seatunnel-dist/target/lib");
+            "/seatunnel-connectors-v2-dist/target/lib");
         return Arrays.stream(
                 Objects.requireNonNull(
                     jars.listFiles(
-                        f -> f.getName().contains("seatunnel-connector-seatunnel"))))
+                        f -> f.getName().contains("connector-"))))
             .collect(Collectors.toList());
     }
 }

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/connection/SimpleJdbcConnectionProvider.java
Patch:
@@ -19,7 +19,7 @@
 
 import static com.google.common.base.Preconditions.checkNotNull;
 
-import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.options.JdbcConnectorOptions;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.options.JdbcConnectionOptions;
 
 import lombok.NonNull;
 import org.slf4j.Logger;
@@ -43,7 +43,7 @@ public class SimpleJdbcConnectionProvider
 
     private static final long serialVersionUID = 1L;
 
-    private final JdbcConnectorOptions jdbcOptions;
+    private final JdbcConnectionOptions jdbcOptions;
 
     private transient Driver loadedDriver;
     private transient Connection connection;
@@ -60,7 +60,7 @@ public class SimpleJdbcConnectionProvider
         DriverManager.getDrivers();
     }
 
-    public SimpleJdbcConnectionProvider(@NonNull JdbcConnectorOptions jdbcOptions) {
+    public SimpleJdbcConnectionProvider(@NonNull JdbcConnectionOptions jdbcOptions) {
         this.jdbcOptions = jdbcOptions;
     }
 

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-jdbc/src/main/java/org/apache/seatunnel/connectors/seatunnel/jdbc/internal/xa/XaFacade.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.jdbc.internal.xa;
 
 import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.connection.JdbcConnectionProvider;
-import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.options.JdbcConnectorOptions;
+import org.apache.seatunnel.connectors.seatunnel.jdbc.internal.options.JdbcConnectionOptions;
 
 import javax.transaction.xa.XAException;
 import javax.transaction.xa.Xid;
@@ -46,8 +46,8 @@ public interface XaFacade
         extends JdbcConnectionProvider, Serializable, AutoCloseable {
 
     static XaFacade fromJdbcConnectionOptions(
-            JdbcConnectorOptions jdbcConnectorOptions) {
-        return  new XaFacadeImplAutoLoad(jdbcConnectorOptions);
+            JdbcConnectionOptions jdbcConnectionOptions) {
+        return  new XaFacadeImplAutoLoad(jdbcConnectionOptions);
     }
 
     void open() throws Exception;

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeSourceReader.java
Patch:
@@ -37,7 +37,6 @@ public class FakeSourceReader implements SourceReader<SeaTunnelRow, FakeSourceSp
 
     private final String[] names = {"Wenjun", "Fanjia", "Zongwen", "CalvinKirs"};
     private final int[] ages = {11, 22, 33, 44};
-    private final Random random = ThreadLocalRandom.current();
 
     public FakeSourceReader(SourceReader.Context context) {
         this.context = context;
@@ -57,7 +56,8 @@ public void close() {
     @SuppressWarnings("magicnumber")
     public void pollNext(Collector<SeaTunnelRow> output) throws InterruptedException {
         // Generate a random number of rows to emit.
-        int size = random.nextInt(10);
+        Random random = ThreadLocalRandom.current();
+        int size = random.nextInt(10) + 1;
         for (int i = 0; i < size; i++) {
             int randomIndex = random.nextInt(names.length);
             SeaTunnelRow seaTunnelRow = new SeaTunnelRow(new Object[]{names[randomIndex], ages[randomIndex], System.currentTimeMillis()});

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SeaTunnelSource.java
Patch:
@@ -48,9 +48,9 @@ default Boundedness getBoundedness() {
     }
 
     /**
-     * Get the row type information of the records produced by this source.
+     * Get the data type of the records produced by this source.
      *
-     * @return SeaTunnel row type information.
+     * @return SeaTunnel data type.
      */
     SeaTunnelDataType<T> getProducedType();
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelRow.java
Patch:
@@ -63,7 +63,7 @@ public int getTableId() {
         return tableId;
     }
 
-    public RowKind geRowKind() {
+    public RowKind getRowKind() {
         return this.kind;
     }
 

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-clickhouse/src/main/java/org/apache/seatunnel/connectors/seatunnel/clickhouse/source/ClickhouseSource.java
Patch:
@@ -94,7 +94,7 @@ public void prepare(Config config) throws PrepareFailException {
 
             for (int i = 0; i < columnSize; i++) {
                 fieldNames[i] = response.getColumns().get(i).getColumnName();
-                seaTunnelDataTypes[i] = TypeConvertUtil.convert(response.getColumns().get(i).getDataType());
+                seaTunnelDataTypes[i] = TypeConvertUtil.convert(response.getColumns().get(i));
             }
 
             this.rowTypeInfo = new SeaTunnelRowType(fieldNames, seaTunnelDataTypes);

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -19,12 +19,14 @@
 
 import org.apache.seatunnel.api.common.SeaTunnelContext;
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
+import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.core.starter.exception.TaskExecuteException;
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
 import org.apache.seatunnel.plugin.discovery.seatunnel.SeaTunnelSinkPluginDiscovery;
 import org.apache.seatunnel.spark.SparkEnvironment;
 import org.apache.seatunnel.translation.spark.sink.SparkSinkInjector;
+import org.apache.seatunnel.translation.spark.utils.TypeConverterUtils;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
@@ -71,7 +73,7 @@ public List<Dataset<Row>> execute(List<Dataset<Row>> upstreamDataStreams) throws
             SeaTunnelSink<?, ?, ?, ?> seaTunnelSink = plugins.get(i);
             Dataset<Row> dataset = fromSourceTable(sinkConfig, sparkEnvironment).orElse(input);
             // TODO modify checkpoint location
-            // TODO add set type info: seaTunnelSink.setTypeInfo();
+            seaTunnelSink.setTypeInfo((SeaTunnelRowType) TypeConverterUtils.convert(dataset.schema()));
             SparkSinkInjector.inject(dataset.write(), seaTunnelSink, new HashMap<>(Common.COLLECTION_SIZE)).option(
                 "checkpointLocation", "/tmp").save();
         }

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/JsonDeserializationSchema.java
Patch:
@@ -85,7 +85,7 @@ public JsonDeserializationSchema(boolean failOnMissingField,
     }
 
     private static boolean hasDecimalType(SeaTunnelDataType<?> dataType) {
-        if (SqlType.of(dataType) == SqlType.DECIMAL) {
+        if (dataType.getSqlType() == SqlType.DECIMAL) {
             return true;
         }
         if (dataType instanceof CompositeType) {

File: seatunnel-formats/seatunnel-format-json/src/main/java/org/apache/seatunnel/format/json/JsonToRowConverters.java
Patch:
@@ -75,7 +75,7 @@ public JsonToRowConverter createConverter(SeaTunnelDataType<?> type) {
     /** Creates a runtime converter which assuming input object is not null. */
     @SuppressWarnings("unchecked")
     private JsonToRowConverter createNotNullConverter(SeaTunnelDataType<?> type) {
-        SqlType sqlType = SqlType.of(type);
+        SqlType sqlType = type.getSqlType();
         switch (sqlType) {
             case ROW:
                 return createRowConverter((SeaTunnelRowType) type);

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/source/BaseSeaTunnelSourceFunction.java
Patch:
@@ -74,7 +74,7 @@ public void open(Configuration parameters) throws Exception {
 
     @Override
     public void run(SourceFunction.SourceContext<Row> sourceContext) throws Exception {
-        internalSource.run(new RowCollector(sourceContext, sourceContext.getCheckpointLock()));
+        internalSource.run(new RowCollector(sourceContext, sourceContext.getCheckpointLock(), source.getProducedType()));
     }
 
     @Override

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/micro/ParallelMicroBatchPartitionReader.java
Patch:
@@ -31,7 +31,6 @@
 import org.apache.hadoop.fs.FSDataOutputStream;
 import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.Path;
-import org.apache.spark.sql.types.StructType;
 
 import java.io.ByteArrayOutputStream;
 import java.io.File;
@@ -58,13 +57,12 @@ public class ParallelMicroBatchPartitionReader extends ParallelBatchPartitionRea
     public ParallelMicroBatchPartitionReader(SeaTunnelSource<SeaTunnelRow, ?, ?> source,
                                              Integer parallelism,
                                              Integer subtaskId,
-                                             StructType rowType,
                                              Integer checkpointId,
                                              Integer checkpointInterval,
                                              String checkpointPath,
                                              String hdfsRoot,
                                              String hdfsUser) {
-        super(source, parallelism, subtaskId, rowType);
+        super(source, parallelism, subtaskId);
         this.checkpointId = checkpointId;
         this.checkpointInterval = checkpointInterval;
         this.checkpointPath = checkpointPath;

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceReader.java
Patch:
@@ -147,10 +147,11 @@ public void notifyCheckpointComplete(long checkpointId) throws Exception {
 
     private KafkaConsumer<byte[], byte[]> initConsumer(String bootstrapServer, String consumerGroup,
                                                        Properties properties, boolean autoCommit) {
-        Properties props = new Properties(properties);
+        Properties props = new Properties();
+        properties.forEach((key, value) -> props.setProperty(String.valueOf(key), String.valueOf(value)));
         props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, consumerGroup);
         props.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServer);
-        props.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, CLIENT_ID_PREFIX + "-enumerator-consumer");
+        props.setProperty(ConsumerConfig.CLIENT_ID_CONFIG, CLIENT_ID_PREFIX + "-enumerator-consumer-" + this.hashCode());
 
         props.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,
                 ByteArrayDeserializer.class.getName());

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/HiveAggregatedCommitInfo.java
Patch:
@@ -20,11 +20,12 @@
 import lombok.AllArgsConstructor;
 import lombok.Data;
 
+import java.io.Serializable;
 import java.util.Map;
 
 @Data
 @AllArgsConstructor
-public class HiveAggregatedCommitInfo {
+public class HiveAggregatedCommitInfo implements Serializable {
 
     /**
      * Storage the commit info in map.

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/file/writer/HdfsTxtFileWriter.java
Patch:
@@ -21,9 +21,10 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.hive.sink.HiveSinkConfig;
 
+import org.apache.seatunnel.shade.org.apache.hadoop.fs.FSDataOutputStream;
+
 import lombok.Lombok;
 import lombok.NonNull;
-import org.apache.hadoop.fs.FSDataOutputStream;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/batch/CoordinatedBatchPartitionReader.java
Patch:
@@ -32,7 +32,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicBoolean;
-import java.util.concurrent.atomic.AtomicInteger;
 
 public class CoordinatedBatchPartitionReader extends ParallelBatchPartitionReader {
 
@@ -59,7 +58,6 @@ protected BaseSourceFunction<SeaTunnelRow> createInternalSource() {
     }
 
     public class InternalCoordinatedSource<SplitT extends SourceSplit, StateT> extends CoordinatedSource<SeaTunnelRow, SplitT, StateT> {
-        protected final AtomicInteger completedReader = new AtomicInteger(0);
 
         public InternalCoordinatedSource(SeaTunnelSource<SeaTunnelRow, SplitT, StateT> source, Map<Integer, List<byte[]>> restoredState, int parallelism) {
             super(source, restoredState, parallelism);

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/micro/CoordinatedMicroBatchPartitionReader.java
Patch:
@@ -34,7 +34,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicBoolean;
-import java.util.concurrent.atomic.AtomicInteger;
 
 public class CoordinatedMicroBatchPartitionReader extends ParallelMicroBatchPartitionReader {
     protected final Map<Integer, InternalRowCollector> collectorMap;
@@ -93,7 +92,6 @@ protected BaseSourceFunction<SeaTunnelRow> createInternalSource() {
     }
 
     public class InternalCoordinatedSource<SplitT extends SourceSplit, StateT> extends CoordinatedSource<SeaTunnelRow, SplitT, StateT> {
-        protected final AtomicInteger completedReader = new AtomicInteger(0);
 
         public InternalCoordinatedSource(SeaTunnelSource<SeaTunnelRow, SplitT, StateT> source, Map<Integer, List<byte[]>> restoredState, int parallelism) {
             super(source, restoredState, parallelism);

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/FlinkExecution.java
Patch:
@@ -56,6 +56,7 @@ public FlinkExecution(Config config) {
         this.sinkPluginExecuteProcessor = new SinkExecuteProcessor(flinkEnvironment, config.getConfigList("sink"));
     }
 
+    @Override
     public void execute() throws TaskExecuteException {
         List<DataStream<Row>> dataStreams = new ArrayList<>();
         dataStreams = sourcePluginExecuteProcessor.execute(dataStreams);

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-file/src/test/java/org/apache/seatunnel/fink/file/source/FileSourceTest.java
Patch:
@@ -46,6 +46,7 @@ public void getJsonDate() throws Exception {
         FlinkEnvironment flinkEnvironment = createFlinkStreamEnvironment(configFile);
 
         try (FileSource fileSource = createFileSource(configFile, flinkEnvironment)) {
+            fileSource.prepare(flinkEnvironment);
             DataSet<Row> data = fileSource.getData(flinkEnvironment);
             Assert.assertNotNull(data);
         }
@@ -57,6 +58,7 @@ public void getTextData() throws Exception {
         FlinkEnvironment flinkEnvironment = createFlinkStreamEnvironment(configFile);
 
         try (FileSource fileSource = createFileSource(configFile, flinkEnvironment)) {
+            fileSource.prepare(flinkEnvironment);
             DataSet<Row> data = fileSource.getData(flinkEnvironment);
             Assert.assertNotNull(data);
         }

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/env/RuntimeEnv.java
Patch:
@@ -23,7 +23,7 @@
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
 import java.net.URL;
-import java.util.List;
+import java.util.Set;
 
 /**
  * engine related runtime environment
@@ -42,6 +42,6 @@ public interface RuntimeEnv {
 
     JobMode getJobMode();
 
-    void registerPlugin(List<URL> pluginPaths);
+    void registerPlugin(Set<URL> pluginPaths);
 
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/FlinkEnvironment.java
Patch:
@@ -49,6 +49,7 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Objects;
+import java.util.Set;
 import java.util.stream.Collectors;
 
 public class FlinkEnvironment implements RuntimeEnv {
@@ -120,7 +121,7 @@ public JobMode getJobMode() {
     }
 
     @Override
-    public void registerPlugin(List<URL> pluginPaths) {
+    public void registerPlugin(Set<URL> pluginPaths) {
         LOGGER.info("register plugins :" + pluginPaths);
         Configuration configuration;
         try {

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/SparkEnvironment.java
Patch:
@@ -38,7 +38,7 @@
 import org.slf4j.LoggerFactory;
 
 import java.net.URL;
-import java.util.List;
+import java.util.Set;
 
 public class SparkEnvironment implements RuntimeEnv {
 
@@ -89,7 +89,7 @@ public CheckResult checkConfig() {
     }
 
     @Override
-    public void registerPlugin(List<URL> pluginPaths) {
+    public void registerPlugin(Set<URL> pluginPaths) {
         LOGGER.info("register plugins :" + pluginPaths);
         // TODO we use --jar parameter to support submit multi-jar in spark cluster at now. Refactor it to
         //  support submit multi-jar in code or remove this logic.

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -71,6 +71,7 @@ public List<Dataset<Row>> execute(List<Dataset<Row>> upstreamDataStreams) throws
             SeaTunnelSink<?, ?, ?, ?> seaTunnelSink = plugins.get(i);
             Dataset<Row> dataset = fromSourceTable(sinkConfig, sparkEnvironment).orElse(input);
             // TODO modify checkpoint location
+            // TODO add set type info: seaTunnelSink.setTypeInfo();
             SparkSinkInjector.inject(dataset.write(), seaTunnelSink, new HashMap<>(Common.COLLECTION_SIZE)).option(
                 "checkpointLocation", "/tmp").save();
         }

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/source/CoordinatedSource.java
Patch:
@@ -139,6 +139,7 @@ public void run(Collector<T> collector) throws Exception {
                 while (flag.get()) {
                     try {
                         reader.pollNext(collector);
+                        Thread.sleep(SLEEP_TIME_INTERVAL);
                     } catch (Exception e) {
                         running = false;
                         flag.set(false);

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/source/ParallelSource.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.seatunnel.translation.source;
 
+import static org.apache.seatunnel.translation.source.CoordinatedSource.SLEEP_TIME_INTERVAL;
+
 import org.apache.seatunnel.api.serialization.Serializer;
 import org.apache.seatunnel.api.source.Collector;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
@@ -116,6 +118,7 @@ public void run(Collector<T> collector) throws Exception {
                 future.get();
             }
             reader.pollNext(collector);
+            Thread.sleep(SLEEP_TIME_INTERVAL);
         }
     }
 

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/utils/TypeConverterUtils.java
Patch:
@@ -95,7 +95,6 @@ private TypeConverterUtils() {
         throw new UnsupportedOperationException("TypeConverterUtils is a utility class and cannot be instantiated");
     }
 
-    @SuppressWarnings("unchecked")
     public static SeaTunnelDataType<?> convert(TypeInformation<?> dataType) {
         BridgedType bridgedType = BRIDGED_TYPES.get(dataType.getTypeClass());
         if (bridgedType != null) {

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/batch/CoordinatedBatchPartitionReader.java
Patch:
@@ -75,6 +75,7 @@ public void run(Collector<SeaTunnelRow> collector) throws Exception {
                     while (flag.get()) {
                         try {
                             reader.pollNext(rowCollector);
+                            Thread.sleep(SLEEP_TIME_INTERVAL);
                         } catch (Exception e) {
                             this.running = false;
                             flag.set(false);

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/micro/CoordinatedMicroBatchPartitionReader.java
Patch:
@@ -109,6 +109,7 @@ public void run(Collector<SeaTunnelRow> collector) throws Exception {
                     while (flag.get()) {
                         try {
                             reader.pollNext(rowCollector);
+                            Thread.sleep(SLEEP_TIME_INTERVAL);
                         } catch (Exception e) {
                             this.running = false;
                             flag.set(false);

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SeaTunnelSink.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.common.SeaTunnelPluginLifeCycle;
 import org.apache.seatunnel.api.serialization.Serializer;
 import org.apache.seatunnel.api.source.SeaTunnelRuntimeEnvironment;
-import org.apache.seatunnel.api.table.type.SeaTunnelRowTypeInfo;
+import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 
 import java.io.IOException;
 import java.io.Serializable;
@@ -47,9 +47,9 @@ public interface SeaTunnelSink<IN, StateT, CommitInfoT, AggregatedCommitInfoT>
     /**
      * Set the row type info of sink row data. This method will be automatically called by translation.
      *
-     * @param seaTunnelRowTypeInfo The row type info of sink.
+     * @param seaTunnelRowType The row type info of sink.
      */
-    default void setTypeInfo(SeaTunnelRowTypeInfo seaTunnelRowTypeInfo) {
+    default void setTypeInfo(SeaTunnelRowType seaTunnelRowType) {
 
     }
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SeaTunnelSource.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.common.SeaTunnelPluginLifeCycle;
 import org.apache.seatunnel.api.serialization.DefaultSerializer;
 import org.apache.seatunnel.api.serialization.Serializer;
-import org.apache.seatunnel.api.table.type.SeaTunnelRowTypeInfo;
+import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.common.constants.JobMode;
 
 import java.io.Serializable;
@@ -52,7 +52,7 @@ default Boundedness getBoundedness() {
      *
      * @return SeaTunnel row type information.
      */
-    SeaTunnelRowTypeInfo getRowTypeInfo();
+    SeaTunnelDataType<T> getProducedType();
 
     /**
      * Create source reader, used to produce data.

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/CompositeType.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.seatunnel.api.table.type;
 
-public interface Converter<T1, T2> {
+import java.util.List;
 
-    T2 convert(T1 dataType);
+public interface CompositeType<T> extends SeaTunnelDataType<T> {
 
-    T1 reconvert(T2 dataType);
+    List<SeaTunnelDataType<?>> getChildren();
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelDataType.java
Patch:
@@ -24,5 +24,5 @@
  */
 public interface SeaTunnelDataType<T> extends Serializable {
 
-
+    Class<T> getTypeClass();
 }

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceReader.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.seatunnel.api.source.Collector;
 import org.apache.seatunnel.api.source.SourceReader;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.api.table.type.SeaTunnelRowTypeInfo;
+import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 
 import com.google.common.collect.Maps;
 import org.apache.kafka.clients.consumer.ConsumerConfig;
@@ -59,10 +59,10 @@ public class KafkaSourceReader implements SourceReader<SeaTunnelRow, KafkaSource
     private final Set<KafkaSourceSplit> sourceSplits;
     private final Map<TopicPartition, Long> endOffset;
     // TODO support user custom type
-    private SeaTunnelRowTypeInfo typeInfo;
+    private SeaTunnelRowType typeInfo;
     private volatile boolean isRunning;
 
-    KafkaSourceReader(ConsumerMetadata metadata, SeaTunnelRowTypeInfo typeInfo,
+    KafkaSourceReader(ConsumerMetadata metadata, SeaTunnelRowType typeInfo,
                       SourceReader.Context context) {
         this.metadata = metadata;
         this.context = context;

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-socket/src/main/java/org/apache/seatunnel/connectors/seatunnel/socket/source/SocketSource.java
Patch:
@@ -27,7 +27,7 @@
 import org.apache.seatunnel.api.table.type.BasicType;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
-import org.apache.seatunnel.api.table.type.SeaTunnelRowTypeInfo;
+import org.apache.seatunnel.api.table.type.SeaTunnelRowType;
 import org.apache.seatunnel.connectors.seatunnel.socket.state.SocketState;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
@@ -60,8 +60,8 @@ public void setSeaTunnelContext(SeaTunnelContext seaTunnelContext) {
     }
 
     @Override
-    public SeaTunnelRowTypeInfo getRowTypeInfo() {
-        return new SeaTunnelRowTypeInfo(new String[]{"value"}, new SeaTunnelDataType<?>[]{BasicType.STRING});
+    public SeaTunnelDataType<SeaTunnelRow> getProducedType() {
+        return new SeaTunnelRowType(new String[]{"value"}, new SeaTunnelDataType<?>[]{BasicType.STRING_TYPE});
     }
 
     @Override

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SourceExecuteProcessor.java
Patch:
@@ -30,6 +30,7 @@
 import com.google.common.collect.Lists;
 import org.apache.spark.sql.Dataset;
 import org.apache.spark.sql.Row;
+import org.apache.spark.sql.types.StructType;
 
 import java.net.URL;
 import java.util.ArrayList;
@@ -53,7 +54,7 @@ public List<Dataset<Row>> execute(List<Dataset<Row>> upstreamDataStreams) {
                 .read()
                 .format(SeaTunnelSource.class.getSimpleName())
                 .option("source.serialization", SerializationUtils.objectToString(source))
-                .schema(TypeConverterUtils.convertRow(source.getRowTypeInfo())).load();
+                .schema((StructType) TypeConverterUtils.convert(source.getProducedType())).load();
             sources.add(dataset);
             registerInputTempView(pluginConfigs.get(i), dataset);
         }

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaNoTransactionSender.java
Patch:
@@ -48,7 +48,7 @@ public void send(ProducerRecord<K, V> producerRecord) {
     }
 
     @Override
-    public void beginTransaction() {
+    public void beginTransaction(String transactionId) {
         // no-op
     }
 
@@ -63,12 +63,12 @@ public void abortTransaction() {
     }
 
     @Override
-    public void abortTransaction(List<KafkaSinkState> kafkaStates) {
+    public void abortTransaction(long checkpointId) {
         // no-op
     }
 
     @Override
-    public List<KafkaSinkState> snapshotState() {
+    public List<KafkaSinkState> snapshotState(long checkpointId) {
         kafkaProducer.flush();
         return Collections.emptyList();
     }

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/source/KafkaSourceSplitEnumerator.java
Patch:
@@ -135,7 +135,7 @@ private Set<KafkaSourceSplit> getTopicInfo() throws ExecutionException, Interrup
             topics = Arrays.asList(this.metadata.getTopic().split(","));
         }
         Collection<TopicPartition> partitions =
-                adminClient.describeTopics(topics).allTopicNames().get().values().stream().flatMap(t -> t.partitions().stream()
+                adminClient.describeTopics(topics).all().get().values().stream().flatMap(t -> t.partitions().stream()
                         .map(p -> new TopicPartition(t.name(), p.partition()))).collect(Collectors.toSet());
         return adminClient.listOffsets(partitions.stream().collect(Collectors.toMap(p -> p, p -> OffsetSpec.latest())))
                 .all().get().entrySet().stream().map(partition -> {

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/state/KafkaCommitInfo.java
Patch:
@@ -29,5 +29,7 @@ public class KafkaCommitInfo implements Serializable {
 
     private final String transactionId;
     private final Properties kafkaProperties;
+    private final long producerId;
+    private final short epoch;
 
 }

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/state/KafkaSinkState.java
Patch:
@@ -28,6 +28,8 @@
 public class KafkaSinkState implements Serializable {
 
     private final String transactionId;
+    private final String transactionIdPrefix;
+    private final long checkpointId;
     private final Properties kafkaProperties;
 
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SourceReader.java
Patch:
@@ -33,7 +33,7 @@ public interface SourceReader<T, SplitT extends SourceSplit> extends AutoCloseab
     /**
      * Open the source reader.
      */
-    void open();
+    void open() throws Exception;
 
     /**
      * Called to close the reader, in case it holds on to any resources, like threads or network

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SinkAggregatedCommitter.java
Patch:
@@ -24,6 +24,8 @@
 /**
  * The committer combine taskManager/Worker Commit message. Then commit it uses
  * {@link SinkAggregatedCommitter#commit(List)}. This class will execute in single thread.
+ * <p>
+ * See Also {@link SinkCommitter}
  *
  * @param <CommitInfoT>           The type of commit message.
  * @param <AggregatedCommitInfoT> The type of commit message after combine.
@@ -48,7 +50,7 @@ public interface SinkAggregatedCommitter<CommitInfoT, AggregatedCommitInfoT> ext
     AggregatedCommitInfoT combine(List<CommitInfoT> commitInfos);
 
     /**
-     * If commit failed, this method will be called.
+     * If {@link #commit(List)} failed, this method will be called (**Only** on Spark engine at now).
      *
      * @param aggregatedCommitInfo The list of combine commit message.
      * @throws Exception throw Exception when abort failed.

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-console/src/main/java/org/apache/seatunnel/connectors/seatunnel/console/sink/ConsoleSinkWriter.java
Patch:
@@ -50,7 +50,7 @@ public Optional<ConsoleCommitInfo> prepareCommit() {
     }
 
     @Override
-    public void abort() {
+    public void abortPrepare() {
 
     }
 

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-hive/src/main/java/org/apache/seatunnel/connectors/seatunnel/hive/sink/HiveSinkWriter.java
Patch:
@@ -81,7 +81,7 @@ public Optional<HiveCommitInfo> prepareCommit() throws IOException {
     }
 
     @Override
-    public void abort() {
+    public void abortPrepare() {
         fileWriter.abort();
     }
 
@@ -91,7 +91,7 @@ public void close() throws IOException {
     }
 
     @Override
-    public List<HiveSinkState> snapshotState() throws IOException {
+    public List<HiveSinkState> snapshotState(long checkpointId) throws IOException {
         //reset FileWrite
         fileWriter.resetFileWriter(System.currentTimeMillis() + "");
         return Lists.newArrayList(new HiveSinkState(hiveSinkConfig));

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaSinkWriter.java
Patch:
@@ -87,7 +87,7 @@ public Optional<KafkaCommitInfo> prepareCommit() {
     }
 
     @Override
-    public void abort() {
+    public void abortPrepare() {
         kafkaProducerSender.abortTransaction();
     }
 

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaTransactionSender.java
Patch:
@@ -85,7 +85,6 @@ public void abortTransaction(List<KafkaSinkState> kafkaStates) {
                 LOGGER.debug("Abort kafka transaction: {}", kafkaState.getTransactionId());
             }
             KafkaProducer<K, V> historyProducer = getTransactionProducer(kafkaProperties, kafkaState.getTransactionId());
-            historyProducer.initTransactions();
             historyProducer.abortTransaction();
             historyProducer.close();
         }

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -70,6 +70,7 @@ public List<Dataset<Row>> execute(List<Dataset<Row>> upstreamDataStreams) throws
             Config sinkConfig = pluginConfigs.get(i);
             SeaTunnelSink<?, ?, ?, ?> seaTunnelSink = plugins.get(i);
             Dataset<Row> dataset = fromSourceTable(sinkConfig, sparkEnvironment).orElse(input);
+            // TODO modify checkpoint location
             SparkSinkInjector.inject(dataset.write(), seaTunnelSink, new HashMap<>(Common.COLLECTION_SIZE)).option(
                 "checkpointLocation", "/tmp").save();
         }

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/sink/SparkDataWriter.java
Patch:
@@ -83,7 +83,7 @@ public WriterCommitMessage commit() throws IOException {
 
     @Override
     public void abort() throws IOException {
-        sinkWriter.abort();
+        sinkWriter.abortPrepare();
         if (sinkCommitter != null) {
             if (latestCommitInfoT == null) {
                 sinkCommitter.abort(Collections.emptyList());

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-clickhouse/src/main/java/org/apache/seatunnel/flink/clickhouse/sink/client/ClickhouseClient.java
Patch:
@@ -24,14 +24,14 @@
 import static org.apache.seatunnel.flink.clickhouse.ConfigKey.USERNAME;
 
 import org.apache.seatunnel.common.config.TypesafeConfigUtils;
+import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.flink.clickhouse.pojo.DistributedEngine;
 import org.apache.seatunnel.flink.clickhouse.pojo.Shard;
 import org.apache.seatunnel.flink.clickhouse.sink.file.ClickhouseTable;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
-import com.alibaba.fastjson.JSON;
-import com.alibaba.fastjson.TypeReference;
+import com.fasterxml.jackson.core.type.TypeReference;
 import ru.yandex.clickhouse.BalancedClickhouseDataSource;
 import ru.yandex.clickhouse.ClickHouseConnection;
 import ru.yandex.clickhouse.ClickHouseConnectionImpl;
@@ -191,7 +191,7 @@ public ClickhouseTable getClickhouseTable(String database, String table) {
             String engine = resultSet.getString(1);
             String createTableDDL = resultSet.getString(2);
             String engineFull = resultSet.getString(3);
-            List<String> dataPaths = JSON.parseObject(resultSet.getString(4).replaceAll("'", "\""), new TypeReference<List<String>>() {
+            List<String> dataPaths = JsonUtils.parseObject(resultSet.getString(4).replaceAll("'", "\""), new TypeReference<List<String>>() {
             });
             DistributedEngine distributedEngine = null;
             if ("Distributed".equals(engine)) {

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/serialize/DefaultSeaTunnelRowSerializer.java
Patch:
@@ -20,8 +20,8 @@
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.api.table.type.SeaTunnelRowTypeInfo;
 import org.apache.seatunnel.common.config.Common;
+import org.apache.seatunnel.common.utils.JsonUtils;
 
-import com.alibaba.fastjson.JSON;
 import org.apache.kafka.clients.producer.ProducerRecord;
 
 import java.util.HashMap;
@@ -45,6 +45,6 @@ public ProducerRecord<String, String> serializeRow(SeaTunnelRow row) {
         for (int i = 0; i < fieldNames.length; i++) {
             map.put(fieldNames[i], fields[i]);
         }
-        return new ProducerRecord<>(topic, null, JSON.toJSONString(map));
+        return new ProducerRecord<>(topic, null, JsonUtils.toJsonString(map));
     }
 }

File: seatunnel-common/src/test/java/org/apache/seatunnel/common/config/CommonTest.java
Patch:
@@ -26,7 +26,7 @@
 public class CommonTest {
 
     static {
-        Common.setDeployMode("client");
+        Common.setDeployMode(DeployMode.CLIENT);
     }
 
     @Test

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/command/BaseTaskExecuteCommand.java
Patch:
@@ -33,7 +33,6 @@
 import java.io.File;
 import java.util.List;
 import java.util.Objects;
-import java.util.Optional;
 
 /**
  * Base task execute command.
@@ -126,8 +125,8 @@ private void pluginCheck(List<? extends Plugin<E>>... plugins) {
     }
 
     private void deployModeCheck() {
-        final Optional<String> mode = Common.getDeployMode();
-        if (mode.isPresent() && DeployMode.CLUSTER.getName().equals(mode.get())) {
+        final DeployMode mode = Common.getDeployMode();
+        if (DeployMode.CLUSTER == mode) {
 
             LOGGER.info("preparing cluster mode work dir files...");
             File workDir = new File(".");

File: seatunnel-core/seatunnel-core-flink-sql/src/main/java/org/apache/seatunnel/core/sql/FlinkSqlStarter.java
Patch:
@@ -39,7 +39,7 @@ public class FlinkSqlStarter implements Starter {
     FlinkSqlStarter(String[] args) {
         this.flinkCommandArgs = CommandLineUtils.parseCommandArgs(args, FlinkJobType.SQL);
         // set the deployment mode, used to get the job jar path.
-        Common.setDeployMode(flinkCommandArgs.getDeployMode().getName());
+        Common.setDeployMode(flinkCommandArgs.getDeployMode());
         this.appJar = Common.appLibDir().resolve(APP_JAR_NAME).toString();
     }
 

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/FlinkStarter.java
Patch:
@@ -46,7 +46,7 @@ public class FlinkStarter implements Starter {
     FlinkStarter(String[] args) {
         this.flinkCommandArgs = CommandLineUtils.parseCommandArgs(args, FlinkJobType.JAR);
         // set the deployment mode, used to get the job jar path.
-        Common.setDeployMode(flinkCommandArgs.getDeployMode().getName());
+        Common.setDeployMode(flinkCommandArgs.getDeployMode());
         this.appJar = Common.appLibDir().resolve(APP_JAR_NAME).toString();
     }
 

File: seatunnel-core/seatunnel-core-spark/src/main/java/org/apache/seatunnel/core/spark/SparkStarter.java
Patch:
@@ -143,7 +143,7 @@ private static SparkCommandArgs parseCommandArgs(String[] args) {
     @Override
     public List<String> buildCommands() throws IOException {
         setSparkConf();
-        Common.setDeployMode(commandArgs.getDeployMode().getName());
+        Common.setDeployMode(commandArgs.getDeployMode());
         this.jars.addAll(getPluginsJarDependencies());
         this.jars.addAll(listJars(Common.appLibDir()));
         this.jars.addAll(getConnectorJarDependencies());
@@ -395,7 +395,7 @@ private ClusterModeSparkStarter(String[] args, SparkCommandArgs commandArgs) {
 
         @Override
         public List<String> buildCommands() throws IOException {
-            Common.setDeployMode(commandArgs.getDeployMode().getName());
+            Common.setDeployMode(commandArgs.getDeployMode());
             Path pluginTarball = Common.pluginTarball();
             if (Files.notExists(pluginTarball)) {
                 CompressionUtils.tarGzip(Common.pluginRootDir(), pluginTarball);

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/FlinkStarter.java
Patch:
@@ -46,7 +46,7 @@ public class FlinkStarter implements Starter {
     FlinkStarter(String[] args) {
         this.flinkCommandArgs = CommandLineUtils.parseCommandArgs(args, FlinkJobType.JAR);
         // set the deployment mode, used to get the job jar path.
-        Common.setDeployMode(flinkCommandArgs.getDeployMode().getName());
+        Common.setDeployMode(flinkCommandArgs.getDeployMode());
         this.appJar = Common.appLibDir().resolve(APP_JAR_NAME).toString();
     }
 

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/SparkStarter.java
Patch:
@@ -148,7 +148,7 @@ private static SparkCommandArgs parseCommandArgs(String[] args) {
     @Override
     public List<String> buildCommands() throws IOException {
         setSparkConf();
-        Common.setDeployMode(commandArgs.getDeployMode().getName());
+        Common.setDeployMode(commandArgs.getDeployMode());
         this.jars.addAll(getPluginsJarDependencies());
         this.jars.addAll(listJars(Common.appLibDir()));
         this.jars.addAll(getConnectorJarDependencies());
@@ -416,7 +416,7 @@ private ClusterModeSparkStarter(String[] args, SparkCommandArgs commandArgs) {
 
         @Override
         public List<String> buildCommands() throws IOException {
-            Common.setDeployMode(commandArgs.getDeployMode().getName());
+            Common.setDeployMode(commandArgs.getDeployMode());
             Path pluginTarball = Common.pluginTarball();
             if (Files.notExists(pluginTarball)) {
                 CompressionUtils.tarGzip(Common.pluginRootDir(), pluginTarball);

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/sink/SinkAggregatedCommitter.java
Patch:
@@ -22,7 +22,7 @@
 import java.util.List;
 
 /**
- * The committer combine taskManager/Worker Commit message. Then commit it use
+ * The committer combine taskManager/Worker Commit message. Then commit it uses
  * {@link SinkAggregatedCommitter#commit(List)}. This class will execute in single thread.
  *
  * @param <CommitInfoT>           The type of commit message.

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaProduceSender.java
Patch:
@@ -29,7 +29,7 @@ public interface KafkaProduceSender<K, V> extends AutoCloseable {
     /**
      * Send data to kafka.
      *
-     * @param seaTunnelRow data to send
+     * @param producerRecord data to send
      */
     void send(ProducerRecord<K, V> producerRecord);
 

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaSinkWriter.java
Patch:
@@ -66,7 +66,7 @@ public KafkaSinkWriter(
         this.seaTunnelRowTypeInfo = seaTunnelRowTypeInfo;
         this.pluginConfig = pluginConfig;
         this.seaTunnelRowSerializer = getSerializer(pluginConfig, seaTunnelRowTypeInfo);
-        if (KafkaSemantics.AT_LEAST_ONCE.equals(getKafkaSemantics(pluginConfig))) {
+        if (KafkaSemantics.EXACTLY_ONCE.equals(getKafkaSemantics(pluginConfig))) {
             // the recover state
             this.kafkaProducerSender = new KafkaTransactionSender<>(getKafkaProperties(pluginConfig));
             this.kafkaProducerSender.abortTransaction(kafkaStates);

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-clickhouse/src/main/java/org/apache/seatunnel/flink/clickhouse/sink/client/ClickhouseClient.java
Patch:
@@ -24,14 +24,14 @@
 import static org.apache.seatunnel.flink.clickhouse.ConfigKey.USERNAME;
 
 import org.apache.seatunnel.common.config.TypesafeConfigUtils;
+import org.apache.seatunnel.common.utils.JsonUtils;
 import org.apache.seatunnel.flink.clickhouse.pojo.DistributedEngine;
 import org.apache.seatunnel.flink.clickhouse.pojo.Shard;
 import org.apache.seatunnel.flink.clickhouse.sink.file.ClickhouseTable;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
-import com.alibaba.fastjson.JSON;
-import com.alibaba.fastjson.TypeReference;
+import com.fasterxml.jackson.core.type.TypeReference;
 import ru.yandex.clickhouse.BalancedClickhouseDataSource;
 import ru.yandex.clickhouse.ClickHouseConnection;
 import ru.yandex.clickhouse.ClickHouseConnectionImpl;
@@ -191,7 +191,7 @@ public ClickhouseTable getClickhouseTable(String database, String table) {
             String engine = resultSet.getString(1);
             String createTableDDL = resultSet.getString(2);
             String engineFull = resultSet.getString(3);
-            List<String> dataPaths = JSON.parseObject(resultSet.getString(4).replaceAll("'", "\""), new TypeReference<List<String>>() {
+            List<String> dataPaths = JsonUtils.parseObject(resultSet.getString(4).replaceAll("'", "\""), new TypeReference<List<String>>() {
             });
             DistributedEngine distributedEngine = null;
             if ("Distributed".equals(engine)) {

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SeaTunnelRuntimeEnvironment.java
Patch:
@@ -29,7 +29,7 @@ public interface SeaTunnelRuntimeEnvironment {
      *
      * @return seaTunnelContext
      */
-    default SeaTunnelContext getSeaTunnelContext() {
-        return SeaTunnelContext.getContext();
-    }
+    SeaTunnelContext getSeaTunnelContext();
+
+    void setSeaTunnelContext(SeaTunnelContext seaTunnelContext);
 }

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connector-seatunnel-fake/src/main/java/org/apache/seatunnel/connectors/seatunnel/fake/source/FakeSourceReader.java
Patch:
@@ -71,6 +71,7 @@ public void pollNext(Collector<SeaTunnelRow> output) throws InterruptedException
         }
         if (Boundedness.BOUNDED.equals(context.getBoundedness())) {
             // signal to the source that we have reached the end of the data.
+            LOGGER.info("Closed the bounded fake source");
             context.signalNoMoreElement();
         }
         Thread.sleep(1000L);

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/FlinkExecution.java
Patch:
@@ -49,7 +49,7 @@ public class FlinkExecution implements TaskExecution {
 
     public FlinkExecution(Config config) {
         this.config = config;
-        this.flinkEnvironment = (FlinkEnvironment) new EnvironmentFactory<>(config, EngineType.FLINK).getEnvironment();
+        this.flinkEnvironment = new EnvironmentFactory<FlinkEnvironment>(config, EngineType.FLINK).getEnvironment();
         SeaTunnelContext.getContext().setJobMode(flinkEnvironment.getJobMode());
         this.sourcePluginExecuteProcessor = new SourceExecuteProcessor(flinkEnvironment, config.getConfigList("source"));
         this.transformPluginExecuteProcessor = new TransformExecuteProcessor(flinkEnvironment, config.getConfigList("transform"));

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SinkExecuteProcessor.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.core.starter.flink.execution;
 
+import org.apache.seatunnel.api.common.SeaTunnelContext;
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
 import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 import org.apache.seatunnel.api.table.type.SeaTunnelRow;
@@ -63,6 +64,7 @@ protected List<SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializa
             SeaTunnelSink<SeaTunnelRow, Serializable, Serializable, Serializable> seaTunnelSink =
                 sinkPluginDiscovery.getPluginInstance(pluginIdentifier);
             seaTunnelSink.prepare(sinkConfig);
+            seaTunnelSink.setSeaTunnelContext(SeaTunnelContext.getContext());
             return seaTunnelSink;
         }).collect(Collectors.toList());
         flinkEnvironment.registerPlugin(pluginJars);

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/SourceExecuteProcessor.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.core.starter.flink.execution;
 
+import org.apache.seatunnel.api.common.SeaTunnelContext;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
@@ -68,6 +69,7 @@ protected List<SeaTunnelParallelSource> initializePlugins(List<? extends Config>
             jars.addAll(sourcePluginDiscovery.getPluginJarPaths(Lists.newArrayList(pluginIdentifier)));
             SeaTunnelSource seaTunnelSource = sourcePluginDiscovery.getPluginInstance(pluginIdentifier);
             seaTunnelSource.prepare(sourceConfig);
+            seaTunnelSource.setSeaTunnelContext(SeaTunnelContext.getContext());
             sources.add(new SeaTunnelParallelSource(seaTunnelSource));
         }
         flinkEnvironment.registerPlugin(jars);

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SinkExecuteProcessor.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.core.starter.spark.execution;
 
+import org.apache.seatunnel.api.common.SeaTunnelContext;
 import org.apache.seatunnel.api.sink.SeaTunnelSink;
 import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.core.starter.exception.TaskExecuteException;
@@ -55,6 +56,7 @@ protected SinkExecuteProcessor(SparkEnvironment sparkEnvironment,
             pluginJars.addAll(sinkPluginDiscovery.getPluginJarPaths(Lists.newArrayList(pluginIdentifier)));
             SeaTunnelSink<?, ?, ?, ?> seaTunnelSink = sinkPluginDiscovery.getPluginInstance(pluginIdentifier);
             seaTunnelSink.prepare(sinkConfig);
+            seaTunnelSink.setSeaTunnelContext(SeaTunnelContext.getContext());
             return seaTunnelSink;
         }).collect(Collectors.toList());
         sparkEnvironment.registerPlugin(pluginJars);

File: seatunnel-core/seatunnel-spark-starter/src/main/java/org/apache/seatunnel/core/starter/spark/execution/SourceExecuteProcessor.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.core.starter.spark.execution;
 
+import org.apache.seatunnel.api.common.SeaTunnelContext;
 import org.apache.seatunnel.api.source.SeaTunnelSource;
 import org.apache.seatunnel.common.utils.SerializationUtils;
 import org.apache.seatunnel.plugin.discovery.PluginIdentifier;
@@ -70,6 +71,7 @@ public List<Dataset<Row>> execute(List<Dataset<Row>> upstreamDataStreams) {
             jars.addAll(sourcePluginDiscovery.getPluginJarPaths(Lists.newArrayList(pluginIdentifier)));
             SeaTunnelSource<?, ?, ?> seaTunnelSource = sourcePluginDiscovery.getPluginInstance(pluginIdentifier);
             seaTunnelSource.prepare(sourceConfig);
+            seaTunnelSource.setSeaTunnelContext(SeaTunnelContext.getContext());
             sources.add(seaTunnelSource);
         }
         sparkEnvironment.registerPlugin(jars);

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/Collector.java
Patch:
@@ -17,8 +17,6 @@
 
 package org.apache.seatunnel.api.source;
 
-import org.apache.seatunnel.api.state.CheckpointLock;
-
 /**
  * A {@link Collector} is used to collect data from {@link SourceReader}.
  *
@@ -33,5 +31,5 @@ public interface Collector<T> {
      *
      * @return The object to use as the lock
      */
-    CheckpointLock getCheckpointLock();
+    Object getCheckpointLock();
 }

File: seatunnel-translation/seatunnel-translation-base/src/main/java/org/apache/seatunnel/translation/source/ParallelReaderContext.java
Patch:
@@ -47,7 +47,6 @@ public Boundedness getBoundedness() {
 
     @Override
     public void signalNoMoreElement() {
-        // todo: if we have multiple subtasks, we need to know if all subtask is stopped
         parallelSource.handleNoMoreElement();
     }
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SourceSplitEnumerator.java
Patch:
@@ -37,7 +37,7 @@ public interface SourceSplitEnumerator<SplitT extends SourceSplit, StateT> exten
     /**
      * The method is executed by the engine only once.
      */
-    void run();
+    void run() throws Exception;
 
     /**
      * Called to close the enumerator, in case it holds on to any resources, like threads or network

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connectors-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaNoTransactionSender.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.kafka.sink;
 
 import org.apache.seatunnel.connectors.seatunnel.kafka.state.KafkaCommitInfo;
-import org.apache.seatunnel.connectors.seatunnel.kafka.state.KafkaState;
+import org.apache.seatunnel.connectors.seatunnel.kafka.state.KafkaSinkState;
 
 import org.apache.kafka.clients.producer.KafkaProducer;
 import org.apache.kafka.clients.producer.ProducerRecord;
@@ -63,12 +63,12 @@ public void abortTransaction() {
     }
 
     @Override
-    public void abortTransaction(List<KafkaState> kafkaStates) {
+    public void abortTransaction(List<KafkaSinkState> kafkaStates) {
         // no-op
     }
 
     @Override
-    public List<KafkaState> snapshotState() {
+    public List<KafkaSinkState> snapshotState() {
         kafkaProducer.flush();
         return Collections.emptyList();
     }

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connectors-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaProduceSender.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.connectors.seatunnel.kafka.sink;
 
 import org.apache.seatunnel.connectors.seatunnel.kafka.state.KafkaCommitInfo;
-import org.apache.seatunnel.connectors.seatunnel.kafka.state.KafkaState;
+import org.apache.seatunnel.connectors.seatunnel.kafka.state.KafkaSinkState;
 
 import org.apache.kafka.clients.producer.ProducerRecord;
 
@@ -52,13 +52,13 @@ public interface KafkaProduceSender<K, V> extends AutoCloseable {
      *
      * @param kafkaStates kafka states about the transaction info.
      */
-    void abortTransaction(List<KafkaState> kafkaStates);
+    void abortTransaction(List<KafkaSinkState> kafkaStates);
 
     /**
      * Get the current kafka state of the sender.
      *
      * @return kafka state List, or empty if no state is available.
      */
-    List<KafkaState> snapshotState();
+    List<KafkaSinkState> snapshotState();
 
 }

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connectors-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/state/KafkaSinkState.java
Patch:
@@ -25,7 +25,7 @@
 
 @Data
 @AllArgsConstructor
-public class KafkaState implements Serializable {
+public class KafkaSinkState implements Serializable {
 
     private final String transactionId;
     private final Properties kafkaProperties;

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/sink/SparkDataWriter.java
Patch:
@@ -44,7 +44,7 @@ public class SparkDataWriter<CommitInfoT, StateT> implements DataWriter<Internal
     private CommitInfoT latestCommitInfoT;
 
     SparkDataWriter(SinkWriter<SeaTunnelRow, CommitInfoT, StateT> sinkWriter,
-                    SinkCommitter<CommitInfoT> sinkCommitter,
+                    @Nullable SinkCommitter<CommitInfoT> sinkCommitter,
                     StructType schema) {
         this.sinkWriter = sinkWriter;
         this.sinkCommitter = sinkCommitter;

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connectors-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaProduceSender.java
Patch:
@@ -17,10 +17,11 @@
 
 package org.apache.seatunnel.connectors.seatunnel.kafka.sink;
 
-import org.apache.seatunnel.api.table.type.SeaTunnelRow;
 import org.apache.seatunnel.connectors.seatunnel.kafka.state.KafkaCommitInfo;
 import org.apache.seatunnel.connectors.seatunnel.kafka.state.KafkaState;
 
+import org.apache.kafka.clients.producer.ProducerRecord;
+
 import java.util.List;
 import java.util.Optional;
 
@@ -30,7 +31,7 @@ public interface KafkaProduceSender<K, V> extends AutoCloseable {
      *
      * @param seaTunnelRow data to send
      */
-    void send(SeaTunnelRow seaTunnelRow);
+    void send(ProducerRecord<K, V> producerRecord);
 
     void beginTransaction();
 

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connectors-seatunnel-kafka/src/main/java/org/apache/seatunnel/connectors/seatunnel/kafka/sink/KafkaSink.java
Patch:
@@ -31,6 +31,8 @@
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
+import com.google.auto.service.AutoService;
+
 import java.util.Collections;
 import java.util.List;
 import java.util.Optional;
@@ -39,6 +41,7 @@
  * Kafka Sink implementation by using SeaTunnel sink API.
  * This class contains the method to create {@link KafkaSinkWriter} and {@link KafkaSinkCommitter}.
  */
+@AutoService(SeaTunnelSink.class)
 public class KafkaSink implements SeaTunnelSink<SeaTunnelRow, KafkaState, KafkaCommitInfo, KafkaAggregatedCommitInfo> {
 
     private Config pluginConfig;

File: seatunnel-core/seatunnel-flink-starter/src/main/java/org/apache/seatunnel/core/starter/flink/execution/AbstractPluginExecuteProcessor.java
Patch:
@@ -38,6 +38,8 @@ public abstract class AbstractPluginExecuteProcessor<T> implements PluginExecute
     protected final FlinkEnvironment flinkEnvironment;
     protected final List<? extends Config> pluginConfigs;
     protected final List<T> plugins;
+    protected static final String ENGINE_TYPE = "seatunnel";
+    protected static final String PLUGIN_NAME = "plugin_name";
 
     protected AbstractPluginExecuteProcessor(FlinkEnvironment flinkEnvironment,
                                              List<? extends Config> pluginConfigs) {

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/source/batch/BatchPartitionReader.java
Patch:
@@ -76,7 +76,7 @@ public boolean next() throws IOException {
                 throw new RuntimeException(e);
             }
         }
-        return running;
+        return running || !handover.isEmpty();
     }
 
     protected void prepare() {

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/command/FlinkTaskExecuteCommand.java
Patch:
@@ -70,7 +70,7 @@ public void execute() {
         List<BaseSink<FlinkEnvironment>> sinks = executionContext.getSinks();
 
         checkPluginType(executionContext.getJobMode(), sources, transforms, sinks);
-        baseCheckConfig(sinks, transforms, sinks);
+        baseCheckConfig(sources, transforms, sinks);
         showAsciiLogo();
 
         try (Execution<BaseSource<FlinkEnvironment>,

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/Converter.java
Patch:
@@ -20,4 +20,6 @@
 public interface Converter<T1, T2> {
 
     T2 convert(T1 dataType);
+
+    T1 reconvert(T2 dataType);
 }

File: seatunnel-translation/seatunnel-translation-spark/src/main/java/org/apache/seatunnel/translation/spark/types/SparkDataTypeConverter.java
Patch:
@@ -32,4 +32,7 @@ public interface SparkDataTypeConverter<T1, T2> extends Converter<T1, T2> {
      */
     @Override
     T2 convert(T1 seaTunnelDataType);
+
+    @Override
+    T1 reconvert(T2 dataType);
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelDataType.java
Patch:
@@ -17,10 +17,12 @@
 
 package org.apache.seatunnel.api.table.type;
 
+import java.io.Serializable;
+
 /**
  * Logic data type of column in SeaTunnel.
  */
-public interface SeaTunnelDataType<T> {
+public interface SeaTunnelDataType<T> extends Serializable {
 
 
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/FlinkEnvironment.java
Patch:
@@ -121,7 +121,7 @@ public JobMode getJobMode() {
 
     @Override
     public void registerPlugin(List<URL> pluginPaths) {
-        LOGGER.info("register plugins :" + pluginPaths);
+        pluginPaths.forEach(url -> LOGGER.info("register plugins : {}", url));
         Configuration configuration;
         try {
             if (isStreaming()) {

File: seatunnel-connectors/seatunnel-connectors-seatunnel/seatunnel-connectors-seatunnel-console/src/main/java/org/apache/seatunnel/connectors/seatunnel/console/sink/ConsoleSinkWriter.java
Patch:
@@ -24,14 +24,16 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.util.Arrays;
+
 public class ConsoleSinkWriter implements SinkWriter<SeaTunnelRow, ConsoleCommitInfo, ConsoleState> {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(ConsoleSinkWriter.class);
 
     @Override
     @SuppressWarnings("checkstyle:RegexpSingleline")
     public void write(SeaTunnelRow element) {
-        System.out.println(element.toString());
+        System.out.println(Arrays.toString(element.getFields()));
     }
 
     @Override

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/command/SeaTunnelApiTaskExecuteCommand.java
Patch:
@@ -68,11 +68,12 @@ public void execute() throws CommandExecuteException {
         Path configFile = FileUtils.getConfigPath(flinkCommandArgs);
 
         Config config = new ConfigBuilder(configFile).getConfig();
+        FlinkEnvironment flinkEnvironment = getFlinkEnvironment(config);
+
         SeaTunnelParallelSource source = getSource(config);
         // todo: add basic type
         Sink<WrappedRow, Object, Object, Object> flinkSink = getSink(config);
 
-        FlinkEnvironment flinkEnvironment = getFlinkEnvironment(config);
         registerPlugins(flinkEnvironment);
 
         StreamExecutionEnvironment streamExecutionEnvironment = flinkEnvironment.getStreamExecutionEnvironment();
@@ -129,7 +130,7 @@ private void registerPlugins(FlinkEnvironment flinkEnvironment) {
     private FlinkEnvironment getFlinkEnvironment(Config config) {
         FlinkEnvironment flinkEnvironment = new FlinkEnvironment();
         flinkEnvironment.setJobMode(JobMode.STREAMING);
-        flinkEnvironment.setConfig(config);
+        flinkEnvironment.setConfig(config.getConfig("env"));
         flinkEnvironment.prepare();
 
         return flinkEnvironment;

File: seatunnel-core/seatunnel-core-flink-sql/src/main/java/org/apache/seatunnel/core/sql/FlinkSqlStarter.java
Patch:
@@ -45,7 +45,7 @@ public class FlinkSqlStarter implements Starter {
 
     @Override
     public List<String> buildCommands() throws Exception {
-        return CommandLineUtils.buildFlinkCommand(flinkCommandArgs, CLASS_NAME, appJar, FlinkJobType.SQL);
+        return CommandLineUtils.buildFlinkCommand(flinkCommandArgs, CLASS_NAME, appJar);
     }
 
     @SuppressWarnings("checkstyle:RegexpSingleline")

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/FlinkStarter.java
Patch:
@@ -57,8 +57,8 @@ public static void main(String[] args) throws Exception {
     }
 
     @Override
-    public List<String> buildCommands() throws Exception {
-        return CommandLineUtils.buildFlinkCommand(flinkCommandArgs, APP_NAME, appJar, FlinkJobType.JAR);
+    public List<String> buildCommands() {
+        return CommandLineUtils.buildFlinkCommand(flinkCommandArgs, APP_NAME, appJar);
     }
 
 }

File: seatunnel-core/seatunnel-core-flink/src/test/java/org/apache/seatunnel/core/flink/FlinkStarterTest.java
Patch:
@@ -32,7 +32,6 @@ public void buildCommands() throws Exception {
         // since we cannot get the actual jar path, so we just check the command contains the command
         Assert.assertTrue(flinkExecuteCommand.contains("--config " + APP_CONF_PATH));
         Assert.assertTrue(flinkExecuteCommand.contains("-m yarn-cluster"));
-        Assert.assertTrue(flinkExecuteCommand.contains("-Dkey1=value1"));
         Assert.assertTrue(flinkExecuteCommand.contains("${FLINK_HOME}/bin/flink run"));
 
         String[] args1 = {"--config", APP_CONF_PATH, "-m", "yarn-cluster", "-i", "key1=value1", "-i", "key2=value2", "--run-mode", "run-application"};

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/sink/FlinkGlobalCommitter.java
Patch:
@@ -28,7 +28,7 @@
 
 public class FlinkGlobalCommitter<CommT, GlobalCommT> implements GlobalCommitter<CommT, GlobalCommT> {
 
-    private SinkAggregatedCommitter<CommT, GlobalCommT> aggregatedCommitter;
+    private final SinkAggregatedCommitter<CommT, GlobalCommT> aggregatedCommitter;
 
     FlinkGlobalCommitter(SinkAggregatedCommitter<CommT, GlobalCommT> aggregatedCommitter) {
         this.aggregatedCommitter = aggregatedCommitter;

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/sink/FlinkSinkWriter.java
Patch:
@@ -21,7 +21,6 @@
 import org.apache.seatunnel.translation.flink.serialization.FlinkRowSerialization;
 
 import org.apache.flink.api.connector.sink.SinkWriter;
-import org.apache.flink.api.connector.sink.SinkWriter.Context;
 import org.apache.flink.types.Row;
 
 import java.io.IOException;
@@ -39,7 +38,7 @@ public class FlinkSinkWriter<InputT, CommT, WriterStateT> implements SinkWriter<
     }
 
     @Override
-    public void write(InputT element, Context context) throws IOException {
+    public void write(InputT element, org.apache.flink.api.connector.sink.SinkWriter.Context context) throws IOException {
         if (element instanceof Row) {
             sinkWriter.write(rowSerialization.deserialize((Row) element));
         } else {

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/connector/SupportReadingMetadata.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.seatunnel.api.table.connector;
 
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
-import org.apache.seatunnel.api.table.type.DataType;
+import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 
 import java.util.List;
 import java.util.Map;
@@ -28,7 +28,7 @@
  */
 public interface SupportReadingMetadata {
 
-    Map<String, DataType<?>> listReadableMetadata(CatalogTable catalogTable);
+    Map<String, SeaTunnelDataType<?>> listReadableMetadata(CatalogTable catalogTable);
 
-    void applyReadableMetadata(CatalogTable catalogTable, List<String> metadataKeys, DataType<?> dataType);
+    void applyReadableMetadata(CatalogTable catalogTable, List<String> metadataKeys, SeaTunnelDataType<?> dataType);
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/ArrayType.java
Patch:
@@ -1,6 +1,6 @@
 package org.apache.seatunnel.api.table.type;
 
-public class ArrayType<T> implements DataType<T> {
+public class ArrayType<T> implements SeaTunnelDataType<T> {
 
     private final BasicType<T> elementType;
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/BasicType.java
Patch:
@@ -22,7 +22,7 @@
 import java.time.Instant;
 import java.util.Date;
 
-public class BasicType<T> implements DataType<T> {
+public class BasicType<T> implements SeaTunnelDataType<T> {
 
     public static final BasicType<Boolean> BOOLEAN = new BasicType<>(Boolean.class);
     public static final BasicType<String> STRING = new BasicType<>(String.class);

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/EnumType.java
Patch:
@@ -1,6 +1,6 @@
 package org.apache.seatunnel.api.table.type;
 
-public class EnumType<T extends Enum<T>> implements DataType<T> {
+public class EnumType<T extends Enum<T>> implements SeaTunnelDataType<T> {
     private final Class<T> enumClass;
 
     public EnumType(Class<T> enumClass) {

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/SeaTunnelDataType.java
Patch:
@@ -20,7 +20,7 @@
 /**
  * Logic data type of column in SeaTunnel.
  */
-public interface DataType<T> {
+public interface SeaTunnelDataType<T> {
 
 
 }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/type/TimestampType.java
Patch:
@@ -2,7 +2,7 @@
 
 import java.sql.Timestamp;
 
-public class TimestampType implements DataType<Timestamp> {
+public class TimestampType implements SeaTunnelDataType<Timestamp> {
 
     private final int precision;
 

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/types/BasicTypeConverter.java
Patch:
@@ -85,7 +85,7 @@ public class BasicTypeConverter<T1>
             BasicType.BIG_INTEGER,
             BasicTypeInfo.BIG_INT_TYPE_INFO);
 
-    public static final BasicTypeConverter<BigDecimal> BIG_DECIMAL =
+    public static final BasicTypeConverter<BigDecimal> BIG_DECIMAL_CONVERTER =
         new BasicTypeConverter<>(
             BasicType.BIG_DECIMAL,
             BasicTypeInfo.BIG_DEC_TYPE_INFO);

File: seatunnel-translation/seatunnel-translation-flink/src/test/java/org/apache/seatunnel/translation/flink/types/BasicTypeConverterTest.java
Patch:
@@ -123,7 +123,7 @@ public void convertBigIntegerType() {
     public void convertBigDecimalType() {
         BasicType<BigDecimal> bigDecimalBasicType = BasicType.BIG_DECIMAL;
         TypeInformation<BigDecimal> bigDecimalTypeInformation =
-            BasicTypeConverter.BIG_DECIMAL.convert(bigDecimalBasicType);
+            BasicTypeConverter.BIG_DECIMAL_CONVERTER.convert(bigDecimalBasicType);
         Assert.assertEquals(BasicTypeInfo.BIG_DEC_TYPE_INFO, bigDecimalTypeInformation);
     }
 

File: seatunnel-translation/seatunnel-translation-flink/src/test/java/org/apache/seatunnel/translation/flink/types/PojoTypeConverterTest.java
Patch:
@@ -18,9 +18,9 @@
 package org.apache.seatunnel.translation.flink.types;
 
 import org.apache.seatunnel.api.table.type.BasicType;
-import org.apache.seatunnel.api.table.type.DataType;
 import org.apache.seatunnel.api.table.type.ListType;
 import org.apache.seatunnel.api.table.type.PojoType;
+import org.apache.seatunnel.api.table.type.SeaTunnelDataType;
 
 import org.apache.flink.api.java.typeutils.PojoTypeInfo;
 import org.apache.flink.api.java.typeutils.TypeExtractor;
@@ -36,7 +36,7 @@ public class PojoTypeConverterTest {
     public void convert() {
         PojoTypeConverter<MockPojo> pojoTypeConverter = new PojoTypeConverter<>();
         Field[] fields = MockPojo.class.getDeclaredFields();
-        DataType<?>[] fieldTypes = {BasicType.STRING, new ListType<>(BasicType.INTEGER)};
+        SeaTunnelDataType<?>[] fieldTypes = {BasicType.STRING, new ListType<>(BasicType.INTEGER)};
         PojoTypeInfo<MockPojo> pojoTypeInfo =
             pojoTypeConverter.convert(new PojoType<>(MockPojo.class, fields, fieldTypes));
         Assert.assertEquals(

File: seatunnel-core/seatunnel-core-flink-sql/src/main/java/org/apache/seatunnel/core/sql/job/Executor.java
Patch:
@@ -66,7 +66,7 @@ private static StatementSet handleStatements(String workFlowContent, StreamTable
             Optional<String[]> optional = setOperationParse(stmt);
             if (optional.isPresent()) {
                 String[] setOptionStrs = optional.get();
-                callSetOperation(configuration, setOptionStrs[0], setOptionStrs[1]);
+                callSetOperation(configuration, setOptionStrs[0].trim(), setOptionStrs[1].trim());
                 continue;
             }
             Operation op = stEnv.getParser().parse(stmt).get(0);

File: seatunnel-core/seatunnel-core-flink-sql/src/main/java/org/apache/seatunnel/core/sql/FlinkSqlStarter.java
Patch:
@@ -45,7 +45,7 @@ public class FlinkSqlStarter implements Starter {
 
     @Override
     public List<String> buildCommands() throws Exception {
-        return CommandLineUtils.buildFlinkCommand(flinkCommandArgs, CLASS_NAME, appJar);
+        return CommandLineUtils.buildFlinkCommand(flinkCommandArgs, CLASS_NAME, appJar, FlinkJobType.SQL);
     }
 
     @SuppressWarnings("checkstyle:RegexpSingleline")

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/FlinkStarter.java
Patch:
@@ -58,7 +58,7 @@ public static void main(String[] args) throws Exception {
 
     @Override
     public List<String> buildCommands() throws Exception {
-        return CommandLineUtils.buildFlinkCommand(flinkCommandArgs, APP_NAME, appJar);
+        return CommandLineUtils.buildFlinkCommand(flinkCommandArgs, APP_NAME, appJar, FlinkJobType.JAR);
     }
 
 }

File: seatunnel-core/seatunnel-core-spark/src/main/java/org/apache/seatunnel/core/spark/SparkStarter.java
Patch:
@@ -195,7 +195,7 @@ private List<Path> getPluginsJarDependencies() throws IOException {
             return stream
                     .filter(it -> pluginRootDir.relativize(it).getNameCount() == PLUGIN_LIB_DIR_DEPTH)
                     .filter(it -> it.getParent().endsWith("lib"))
-                    .filter(it -> it.getFileName().endsWith("jar"))
+                    .filter(it -> it.getFileName().toString().endsWith("jar"))
                     .collect(Collectors.toList());
         }
     }

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/types/ArrayTypeConverter.java
Patch:
@@ -27,6 +27,7 @@ public class ArrayTypeConverter<T1, T2> implements FlinkTypeConverter<ArrayType<
     @Override
     @SuppressWarnings("unchecked")
     public BasicArrayTypeInfo<T1, T2> convert(ArrayType<T1> arrayType) {
+        // todo: now we only support basic array types
         BasicType<T1> elementType = arrayType.getElementType();
         if (BasicType.BOOLEAN.equals(elementType)) {
             return (BasicArrayTypeInfo<T1, T2>) BasicArrayTypeInfo.BOOLEAN_ARRAY_TYPE_INFO;

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/connector/SupportReadingMetadata.java
Patch:
@@ -28,7 +28,7 @@
  */
 public interface SupportReadingMetadata {
 
-    Map<String, DataType> listReadableMetadata(CatalogTable catalogTable);
+    Map<String, DataType<?>> listReadableMetadata(CatalogTable catalogTable);
 
-    void applyReadableMetadata(CatalogTable catalogTable, List<String> metadataKeys, DataType dataType);
+    void applyReadableMetadata(CatalogTable catalogTable, List<String> metadataKeys, DataType<?> dataType);
 }

File: seatunnel-core/seatunnel-core-flink-sql/src/main/java/org/apache/seatunnel/core/sql/FlinkSqlStarter.java
Patch:
@@ -44,12 +44,12 @@ public class FlinkSqlStarter implements Starter {
     }
 
     @Override
-    public List<String> buildCommands() {
+    public List<String> buildCommands() throws Exception {
         return CommandLineUtils.buildFlinkCommand(flinkCommandArgs, CLASS_NAME, appJar);
     }
 
     @SuppressWarnings("checkstyle:RegexpSingleline")
-    public static void main(String[] args) {
+    public static void main(String[] args) throws Exception {
         FlinkSqlStarter flinkSqlStarter = new FlinkSqlStarter(args);
         System.out.println(String.join(" ", flinkSqlStarter.buildCommands()));
     }

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/FlinkStarter.java
Patch:
@@ -51,13 +51,13 @@ public class FlinkStarter implements Starter {
     }
 
     @SuppressWarnings("checkstyle:RegexpSingleline")
-    public static void main(String[] args) {
+    public static void main(String[] args) throws Exception {
         FlinkStarter flinkStarter = new FlinkStarter(args);
         System.out.println(String.join(" ", flinkStarter.buildCommands()));
     }
 
     @Override
-    public List<String> buildCommands() {
+    public List<String> buildCommands() throws Exception {
         return CommandLineUtils.buildFlinkCommand(flinkCommandArgs, APP_NAME, appJar);
     }
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/catalog/TableSchema.java
Patch:
@@ -20,6 +20,9 @@
 import java.io.Serializable;
 import java.util.List;
 
+/**
+ * Represent a physical table schema.
+ */
 public final class TableSchema implements Serializable {
     private static final long serialVersionUID = 1L;
     private final List<Column> columns;

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/api/BaseSink.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.apis;
+package org.apache.seatunnel.apis.base.api;
 
-import org.apache.seatunnel.env.RuntimeEnv;
-import org.apache.seatunnel.plugin.Plugin;
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 
 /**
  * a base interface indicates a sink plugin which will write data to other system.

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/api/BaseSource.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.apis;
+package org.apache.seatunnel.apis.base.api;
 
-import org.apache.seatunnel.env.RuntimeEnv;
-import org.apache.seatunnel.plugin.Plugin;
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 
 /**
  * a base interface indicates a source plugin which will read data from other system.

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/api/BaseTransform.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.apis;
+package org.apache.seatunnel.apis.base.api;
 
-import org.apache.seatunnel.env.RuntimeEnv;
-import org.apache.seatunnel.plugin.Plugin;
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 
 /**
  * a base interface indicates a transform plugin which will do transformations on data.

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/command/Command.java
Patch:
@@ -15,15 +15,15 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.command;
+package org.apache.seatunnel.apis.base.command;
 
 /**
  * Command interface.
  *
  * @param <T> args type
  */
 @FunctionalInterface
-public interface Command<T extends AbstractCommandArgs> {
+public interface Command<T extends CommandArgs> {
 
     /**
      * Execute command

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/env/RuntimeEnv.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.env;
+package org.apache.seatunnel.apis.base.env;
 
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.JobMode;

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/plugin/Plugin.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.plugin;
+package org.apache.seatunnel.apis.base.plugin;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.config.CheckResult;
-import org.apache.seatunnel.env.RuntimeEnv;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/plugin/PluginClosedException.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.plugin;
+package org.apache.seatunnel.apis.base.plugin;
 
 /**
  * an Exception used for the scenes when plugin closed error.

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/BaseFlinkSink.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.flink;
 
-import org.apache.seatunnel.apis.BaseSink;
+import org.apache.seatunnel.apis.base.api.BaseSink;
 
 /**
  * a base interface indicates a sink plugin running on Flink.

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/BaseFlinkSource.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.flink;
 
-import org.apache.seatunnel.apis.BaseSource;
+import org.apache.seatunnel.apis.base.api.BaseSource;
 
 /**
  * a base interface indicates a source plugin running on Flink.

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/BaseFlinkTransform.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.flink;
 
-import org.apache.seatunnel.apis.BaseTransform;
+import org.apache.seatunnel.apis.base.api.BaseTransform;
 
 /**
  * a base interface indicates a transform plugin running on Flink.

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/FlinkEnvironment.java
Patch:
@@ -17,10 +17,10 @@
 
 package org.apache.seatunnel.flink;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.common.utils.ReflectionUtils;
-import org.apache.seatunnel.env.RuntimeEnv;
 import org.apache.seatunnel.flink.util.ConfigKeyName;
 import org.apache.seatunnel.flink.util.EnvironmentUtil;
 

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchExecution.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.flink.batch;
 
-import org.apache.seatunnel.env.Execution;
+import org.apache.seatunnel.apis.base.env.Execution;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.flink.util.TableUtil;
 

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/stream/FlinkStreamExecution.java
Patch:
@@ -17,10 +17,10 @@
 
 package org.apache.seatunnel.flink.stream;
 
-import org.apache.seatunnel.env.Execution;
+import org.apache.seatunnel.apis.base.env.Execution;
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.flink.util.TableUtil;
-import org.apache.seatunnel.plugin.Plugin;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/BaseSparkSink.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.spark;
 
-import org.apache.seatunnel.apis.BaseSink;
+import org.apache.seatunnel.apis.base.api.BaseSink;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/BaseSparkSource.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.spark;
 
-import org.apache.seatunnel.apis.BaseSource;
+import org.apache.seatunnel.apis.base.api.BaseSource;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/BaseSparkTransform.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.spark;
 
-import org.apache.seatunnel.apis.BaseTransform;
+import org.apache.seatunnel.apis.base.api.BaseTransform;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/SparkEnvironment.java
Patch:
@@ -17,13 +17,13 @@
 
 package org.apache.seatunnel.spark;
 
-import static org.apache.seatunnel.plugin.Plugin.RESULT_TABLE_NAME;
-import static org.apache.seatunnel.plugin.Plugin.SOURCE_TABLE_NAME;
+import static org.apache.seatunnel.apis.base.plugin.Plugin.RESULT_TABLE_NAME;
+import static org.apache.seatunnel.apis.base.plugin.Plugin.SOURCE_TABLE_NAME;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.config.ConfigRuntimeException;
 import org.apache.seatunnel.common.constants.JobMode;
-import org.apache.seatunnel.env.RuntimeEnv;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/batch/SparkBatchExecution.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.spark.batch;
 
-import org.apache.seatunnel.env.Execution;
+import org.apache.seatunnel.apis.base.env.Execution;
 import org.apache.seatunnel.spark.BaseSparkTransform;
 import org.apache.seatunnel.spark.SparkEnvironment;
 

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/structuredstream/StructuredStreamingExecution.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.spark.structuredstream;
 
-import org.apache.seatunnel.env.Execution;
+import org.apache.seatunnel.apis.base.env.Execution;
 import org.apache.seatunnel.spark.BaseSparkTransform;
 import org.apache.seatunnel.spark.SparkEnvironment;
 

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/Starter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel;
+package org.apache.seatunnel.core.base;
 
 import java.util.List;
 

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/command/DeployModeConverter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.command;
+package org.apache.seatunnel.core.base.command;
 
 import org.apache.seatunnel.common.config.DeployMode;
 

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/ConfigBuilder.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.base.config;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.config.ConfigRuntimeException;
-import org.apache.seatunnel.env.RuntimeEnv;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/EngineType.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.base.config;
 
 public enum EngineType {
     SPARK("spark"),

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/EnvironmentFactory.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.base.config;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.constants.JobMode;
-import org.apache.seatunnel.env.RuntimeEnv;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.spark.SparkEnvironment;
 

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/PluginFactory.java
Patch:
@@ -15,14 +15,14 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.base.config;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 import org.apache.seatunnel.common.config.Common;
-import org.apache.seatunnel.env.RuntimeEnv;
 import org.apache.seatunnel.flink.BaseFlinkSink;
 import org.apache.seatunnel.flink.BaseFlinkSource;
 import org.apache.seatunnel.flink.BaseFlinkTransform;
-import org.apache.seatunnel.plugin.Plugin;
 import org.apache.seatunnel.spark.BaseSparkSink;
 import org.apache.seatunnel.spark.BaseSparkSource;
 import org.apache.seatunnel.spark.BaseSparkTransform;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/PluginType.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.base.config;
 
 public enum PluginType {
     SOURCE("source"), TRANSFORM("transform"), SINK("sink");

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/utils/AsciiArtUtils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.utils;
+package org.apache.seatunnel.core.base.utils;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/utils/CompressionUtils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.utils;
+package org.apache.seatunnel.core.base.utils;
 
 import org.apache.commons.compress.archivers.ArchiveException;
 import org.apache.commons.compress.archivers.ArchiveStreamFactory;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/utils/FileUtils.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.utils;
+package org.apache.seatunnel.core.base.utils;
 
-import org.apache.seatunnel.command.AbstractCommandArgs;
+import org.apache.seatunnel.core.base.command.AbstractCommandArgs;
 
 import java.io.File;
 import java.nio.file.Path;

File: seatunnel-core/seatunnel-core-base/src/test/java/org/apache/seatunnel/core/base/utils/CompressionUtilsTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.utils;
+package org.apache.seatunnel.core.base.utils;
 
 import static org.junit.Assert.assertTrue;
 

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/config/FlinkRunMode.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.flink.config;
 
 /**
  * Flink run mode, used to determine whether to run in local or cluster mode.

File: seatunnel-core/seatunnel-core-flink/src/test/java/org/apache/seatunnel/core/flink/FlinkStarterTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel;
+package org.apache.seatunnel.core.flink;
 
 import org.junit.Assert;
 import org.junit.Test;

File: seatunnel-core/seatunnel-core-flink/src/test/java/org/apache/seatunnel/core/flink/args/FlinkCommandArgsTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.command;
+package org.apache.seatunnel.core.flink.args;
 
 import com.beust.jcommander.JCommander;
 import org.junit.Assert;
@@ -37,4 +37,5 @@ public void testParseFlinkArgs() {
         Assert.assertTrue(flinkArgs.isCheckConfig());
         Assert.assertEquals(Arrays.asList("city=shenyang", "date=20200202"), flinkArgs.getVariables());
     }
+
 }

File: seatunnel-core/seatunnel-core-spark/src/test/java/org/apache/seatunnel/core/spark/SparkStarterTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel;
+package org.apache.seatunnel.core.spark;
 
 import static org.junit.Assert.assertEquals;
 

File: seatunnel-core/seatunnel-core-spark/src/test/java/org/apache/seatunnel/core/spark/args/SparkCommandArgsTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.command;
+package org.apache.seatunnel.core.spark.args;
 
 import org.apache.seatunnel.common.config.DeployMode;
 
@@ -25,7 +25,7 @@
 
 import java.util.Arrays;
 
-public class CommandSparkArgsTest {
+public class SparkCommandArgsTest {
 
     @Test
     public void testParseSparkArgs() {
@@ -63,4 +63,5 @@ public void testDashDash() {
             .build()
             .parse(args);
     }
+
 }

File: seatunnel-core/seatunnel-core-spark/src/test/java/org/apache/seatunnel/core/spark/utils/CommandLineUtilsTest.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.utils;
+package org.apache.seatunnel.core.spark.utils;
 
-import org.apache.seatunnel.command.SparkCommandArgs;
+import org.apache.seatunnel.core.spark.args.SparkCommandArgs;
 
 import com.beust.jcommander.ParameterException;
 import org.junit.Assert;
@@ -39,5 +39,4 @@ public void testParseSparkArgsException() {
         String[] args = {"-c", "app.conf", "-e", "cluster2xxx", "-m", "local[*]"};
         Assert.assertThrows(ParameterException.class, () -> CommandLineUtils.parseSparkArgs(args));
     }
-
 }

File: seatunnel-e2e/seatunnel-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -118,7 +118,7 @@ public Container.ExecResult executeSeaTunnelFlinkJob(String confFile) throws IOE
         final List<String> command = new ArrayList<>();
         command.add("flink");
         command.add("run");
-        command.add("-c org.apache.seatunnel.SeatunnelFlink " + jar);
+        command.add("-c org.apache.seatunnel.core.flink.SeatunnelFlink " + jar);
         command.add("--config " + conf);
 
         Container.ExecResult execResult = jobManager.execInContainer("bash", "-c", String.join(" ", command));

File: seatunnel-e2e/seatunnel-spark-e2e/src/test/java/org/apache/seatunnel/e2e/spark/SparkContainer.java
Patch:
@@ -98,7 +98,7 @@ public Container.ExecResult executeSeaTunnelSparkJob(String confFile) throws IOE
         final List<String> command = new ArrayList<>();
         command.add("spark-submit");
         command.add("--class");
-        command.add("org.apache.seatunnel.SeatunnelSpark");
+        command.add("org.apache.seatunnel.core.spark.SeatunnelSpark");
         command.add("--name");
         command.add("SeaTunnel");
         command.add("--master");

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-datastream2table/src/main/java/org/apache/seatunnel/flink/transform/DataStreamToTable.java
Patch:
@@ -17,12 +17,12 @@
 
 package org.apache.seatunnel.flink.transform;
 
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.flink.batch.FlinkBatchTransform;
 import org.apache.seatunnel.flink.stream.FlinkStreamTransform;
-import org.apache.seatunnel.plugin.Plugin;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-table2datastream/src/main/java/org/apache/seatunnel/flink/transform/TableToDataStream.java
Patch:
@@ -17,13 +17,13 @@
 
 package org.apache.seatunnel.flink.transform;
 
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.flink.batch.FlinkBatchTransform;
 import org.apache.seatunnel.flink.stream.FlinkStreamTransform;
 import org.apache.seatunnel.flink.util.TableUtil;
-import org.apache.seatunnel.plugin.Plugin;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-translation/seatunnel-translation-flink/src/main/java/org/apache/seatunnel/translation/flink/serialization/FlinkRowSerialization.java
Patch:
@@ -27,6 +27,7 @@ public class FlinkRowSerialization implements RowSerialization<Row> {
 
     @Override
     public Row serialize(org.apache.seatunnel.api.table.type.Row seaTunnelRow) throws IOException {
+
         return null;
     }
 

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/api/BaseSink.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.apis;
+package org.apache.seatunnel.apis.base.api;
 
-import org.apache.seatunnel.env.RuntimeEnv;
-import org.apache.seatunnel.plugin.Plugin;
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 
 /**
  * a base interface indicates a sink plugin which will write data to other system.

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/api/BaseSource.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.apis;
+package org.apache.seatunnel.apis.base.api;
 
-import org.apache.seatunnel.env.RuntimeEnv;
-import org.apache.seatunnel.plugin.Plugin;
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 
 /**
  * a base interface indicates a source plugin which will read data from other system.

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/api/BaseTransform.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.apis;
+package org.apache.seatunnel.apis.base.api;
 
-import org.apache.seatunnel.env.RuntimeEnv;
-import org.apache.seatunnel.plugin.Plugin;
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 
 /**
  * a base interface indicates a transform plugin which will do transformations on data.

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/command/Command.java
Patch:
@@ -15,15 +15,15 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.command;
+package org.apache.seatunnel.apis.base.command;
 
 /**
  * Command interface.
  *
  * @param <T> args type
  */
 @FunctionalInterface
-public interface Command<T extends AbstractCommandArgs> {
+public interface Command<T extends CommandArgs> {
 
     /**
      * Execute command

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/env/RuntimeEnv.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.env;
+package org.apache.seatunnel.apis.base.env;
 
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.JobMode;

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/plugin/Plugin.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.plugin;
+package org.apache.seatunnel.apis.base.plugin;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.config.CheckResult;
-import org.apache.seatunnel.env.RuntimeEnv;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/apis/base/plugin/PluginClosedException.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.plugin;
+package org.apache.seatunnel.apis.base.plugin;
 
 /**
  * an Exception used for the scenes when plugin closed error.

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/BaseFlinkSink.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.flink;
 
-import org.apache.seatunnel.apis.BaseSink;
+import org.apache.seatunnel.apis.base.api.BaseSink;
 
 /**
  * a base interface indicates a sink plugin running on Flink.

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/BaseFlinkSource.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.flink;
 
-import org.apache.seatunnel.apis.BaseSource;
+import org.apache.seatunnel.apis.base.api.BaseSource;
 
 /**
  * a base interface indicates a source plugin running on Flink.

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/BaseFlinkTransform.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.flink;
 
-import org.apache.seatunnel.apis.BaseTransform;
+import org.apache.seatunnel.apis.base.api.BaseTransform;
 
 /**
  * a base interface indicates a transform plugin running on Flink.

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/FlinkEnvironment.java
Patch:
@@ -17,10 +17,10 @@
 
 package org.apache.seatunnel.flink;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.common.utils.ReflectionUtils;
-import org.apache.seatunnel.env.RuntimeEnv;
 import org.apache.seatunnel.flink.util.ConfigKeyName;
 import org.apache.seatunnel.flink.util.EnvironmentUtil;
 

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchExecution.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.flink.batch;
 
-import org.apache.seatunnel.env.Execution;
+import org.apache.seatunnel.apis.base.env.Execution;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.flink.util.TableUtil;
 

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/stream/FlinkStreamExecution.java
Patch:
@@ -17,10 +17,10 @@
 
 package org.apache.seatunnel.flink.stream;
 
-import org.apache.seatunnel.env.Execution;
+import org.apache.seatunnel.apis.base.env.Execution;
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.flink.util.TableUtil;
-import org.apache.seatunnel.plugin.Plugin;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/BaseSparkSink.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.spark;
 
-import org.apache.seatunnel.apis.BaseSink;
+import org.apache.seatunnel.apis.base.api.BaseSink;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/BaseSparkSource.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.spark;
 
-import org.apache.seatunnel.apis.BaseSource;
+import org.apache.seatunnel.apis.base.api.BaseSource;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/BaseSparkTransform.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.spark;
 
-import org.apache.seatunnel.apis.BaseTransform;
+import org.apache.seatunnel.apis.base.api.BaseTransform;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/SparkEnvironment.java
Patch:
@@ -17,13 +17,13 @@
 
 package org.apache.seatunnel.spark;
 
-import static org.apache.seatunnel.plugin.Plugin.RESULT_TABLE_NAME;
-import static org.apache.seatunnel.plugin.Plugin.SOURCE_TABLE_NAME;
+import static org.apache.seatunnel.apis.base.plugin.Plugin.RESULT_TABLE_NAME;
+import static org.apache.seatunnel.apis.base.plugin.Plugin.SOURCE_TABLE_NAME;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.config.ConfigRuntimeException;
 import org.apache.seatunnel.common.constants.JobMode;
-import org.apache.seatunnel.env.RuntimeEnv;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/batch/SparkBatchExecution.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.spark.batch;
 
-import org.apache.seatunnel.env.Execution;
+import org.apache.seatunnel.apis.base.env.Execution;
 import org.apache.seatunnel.spark.BaseSparkTransform;
 import org.apache.seatunnel.spark.SparkEnvironment;
 

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/structuredstream/StructuredStreamingExecution.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.seatunnel.spark.structuredstream;
 
-import org.apache.seatunnel.env.Execution;
+import org.apache.seatunnel.apis.base.env.Execution;
 import org.apache.seatunnel.spark.BaseSparkTransform;
 import org.apache.seatunnel.spark.SparkEnvironment;
 

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/Starter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel;
+package org.apache.seatunnel.core.base;
 
 import java.util.List;
 

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/command/DeployModeConverter.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.command;
+package org.apache.seatunnel.core.base.command;
 
 import org.apache.seatunnel.common.config.DeployMode;
 

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/ConfigBuilder.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.base.config;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.config.ConfigRuntimeException;
-import org.apache.seatunnel.env.RuntimeEnv;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/EngineType.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.base.config;
 
 public enum EngineType {
     SPARK("spark"),

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/EnvironmentFactory.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.base.config;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
 import org.apache.seatunnel.common.constants.JobMode;
-import org.apache.seatunnel.env.RuntimeEnv;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.spark.SparkEnvironment;
 

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/PluginFactory.java
Patch:
@@ -15,14 +15,14 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.base.config;
 
+import org.apache.seatunnel.apis.base.env.RuntimeEnv;
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 import org.apache.seatunnel.common.config.Common;
-import org.apache.seatunnel.env.RuntimeEnv;
 import org.apache.seatunnel.flink.BaseFlinkSink;
 import org.apache.seatunnel.flink.BaseFlinkSource;
 import org.apache.seatunnel.flink.BaseFlinkTransform;
-import org.apache.seatunnel.plugin.Plugin;
 import org.apache.seatunnel.spark.BaseSparkSink;
 import org.apache.seatunnel.spark.BaseSparkSource;
 import org.apache.seatunnel.spark.BaseSparkTransform;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/config/PluginType.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.base.config;
 
 public enum PluginType {
     SOURCE("source"), TRANSFORM("transform"), SINK("sink");

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/utils/AsciiArtUtils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.utils;
+package org.apache.seatunnel.core.base.utils;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/utils/CompressionUtils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.utils;
+package org.apache.seatunnel.core.base.utils;
 
 import org.apache.commons.compress.archivers.ArchiveException;
 import org.apache.commons.compress.archivers.ArchiveStreamFactory;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/core/base/utils/FileUtils.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.utils;
+package org.apache.seatunnel.core.base.utils;
 
-import org.apache.seatunnel.command.AbstractCommandArgs;
+import org.apache.seatunnel.core.base.command.AbstractCommandArgs;
 
 import java.io.File;
 import java.nio.file.Path;

File: seatunnel-core/seatunnel-core-base/src/test/java/org/apache/seatunnel/core/base/utils/CompressionUtilsTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.utils;
+package org.apache.seatunnel.core.base.utils;
 
 import static org.junit.Assert.assertTrue;
 

File: seatunnel-core/seatunnel-core-flink-sql/src/main/java/org/apache/seatunnel/core/sql/SeatunnelSql.java
Patch:
@@ -17,10 +17,10 @@
 
 package org.apache.seatunnel.core.sql;
 
-import org.apache.seatunnel.command.FlinkCommandArgs;
+import org.apache.seatunnel.core.flink.args.FlinkCommandArgs;
+import org.apache.seatunnel.core.flink.utils.CommandLineUtils;
 import org.apache.seatunnel.core.sql.job.Executor;
 import org.apache.seatunnel.core.sql.job.JobInfo;
-import org.apache.seatunnel.utils.CommandLineUtils;
 
 import org.apache.commons.io.FileUtils;
 

File: seatunnel-core/seatunnel-core-flink-sql/src/test/java/org/apache/seatunnel/core/sql/SqlVariableSubstitutionTest.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.seatunnel.core.sql;
 
-import org.apache.seatunnel.command.FlinkCommandArgs;
+import org.apache.seatunnel.core.flink.args.FlinkCommandArgs;
+import org.apache.seatunnel.core.flink.utils.CommandLineUtils;
 import org.apache.seatunnel.core.sql.job.JobInfo;
-import org.apache.seatunnel.utils.CommandLineUtils;
 
 import org.apache.commons.io.FileUtils;
 import org.junit.Assert;

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/FlinkStarter.java
Patch:
@@ -15,10 +15,11 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel;
+package org.apache.seatunnel.core.flink;
 
-import org.apache.seatunnel.command.FlinkCommandArgs;
 import org.apache.seatunnel.common.config.Common;
+import org.apache.seatunnel.core.base.Starter;
+import org.apache.seatunnel.core.flink.args.FlinkCommandArgs;
 
 import com.beust.jcommander.JCommander;
 

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/core/flink/config/FlinkRunMode.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.config;
+package org.apache.seatunnel.core.flink.config;
 
 /**
  * Flink run mode, used to determine whether to run in local or cluster mode.

File: seatunnel-core/seatunnel-core-flink/src/test/java/org/apache/seatunnel/core/flink/FlinkStarterTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel;
+package org.apache.seatunnel.core.flink;
 
 import org.junit.Assert;
 import org.junit.Test;

File: seatunnel-core/seatunnel-core-flink/src/test/java/org/apache/seatunnel/core/flink/args/FlinkCommandArgsTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.command;
+package org.apache.seatunnel.core.flink.args;
 
 import com.beust.jcommander.JCommander;
 import org.junit.Assert;
@@ -37,4 +37,5 @@ public void testParseFlinkArgs() {
         Assert.assertTrue(flinkArgs.isCheckConfig());
         Assert.assertEquals(Arrays.asList("city=shenyang", "date=20200202"), flinkArgs.getVariables());
     }
+
 }

File: seatunnel-core/seatunnel-core-spark/src/test/java/org/apache/seatunnel/core/spark/SparkStarterTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel;
+package org.apache.seatunnel.core.spark;
 
 import static org.junit.Assert.assertEquals;
 

File: seatunnel-core/seatunnel-core-spark/src/test/java/org/apache/seatunnel/core/spark/args/SparkCommandArgsTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.command;
+package org.apache.seatunnel.core.spark.args;
 
 import org.apache.seatunnel.common.config.DeployMode;
 
@@ -25,7 +25,7 @@
 
 import java.util.Arrays;
 
-public class CommandSparkArgsTest {
+public class SparkCommandArgsTest {
 
     @Test
     public void testParseSparkArgs() {
@@ -63,4 +63,5 @@ public void testDashDash() {
             .build()
             .parse(args);
     }
+
 }

File: seatunnel-core/seatunnel-core-spark/src/test/java/org/apache/seatunnel/core/spark/utils/CommandLineUtilsTest.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.utils;
+package org.apache.seatunnel.core.spark.utils;
 
-import org.apache.seatunnel.command.SparkCommandArgs;
+import org.apache.seatunnel.core.spark.args.SparkCommandArgs;
 
 import com.beust.jcommander.ParameterException;
 import org.junit.Assert;
@@ -39,5 +39,4 @@ public void testParseSparkArgsException() {
         String[] args = {"-c", "app.conf", "-e", "cluster2xxx", "-m", "local[*]"};
         Assert.assertThrows(ParameterException.class, () -> CommandLineUtils.parseSparkArgs(args));
     }
-
 }

File: seatunnel-e2e/seatunnel-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -118,7 +118,7 @@ public Container.ExecResult executeSeaTunnelFlinkJob(String confFile) throws IOE
         final List<String> command = new ArrayList<>();
         command.add("flink");
         command.add("run");
-        command.add("-c org.apache.seatunnel.SeatunnelFlink " + jar);
+        command.add("-c org.apache.seatunnel.core.flink.SeatunnelFlink " + jar);
         command.add("--config " + conf);
 
         Container.ExecResult execResult = jobManager.execInContainer("bash", "-c", String.join(" ", command));

File: seatunnel-e2e/seatunnel-spark-e2e/src/test/java/org/apache/seatunnel/e2e/spark/SparkContainer.java
Patch:
@@ -98,7 +98,7 @@ public Container.ExecResult executeSeaTunnelSparkJob(String confFile) throws IOE
         final List<String> command = new ArrayList<>();
         command.add("spark-submit");
         command.add("--class");
-        command.add("org.apache.seatunnel.SeatunnelSpark");
+        command.add("org.apache.seatunnel.core.spark.SeatunnelSpark");
         command.add("--name");
         command.add("SeaTunnel");
         command.add("--master");

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-datastream2table/src/main/java/org/apache/seatunnel/flink/transform/DataStreamToTable.java
Patch:
@@ -17,12 +17,12 @@
 
 package org.apache.seatunnel.flink.transform;
 
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.flink.batch.FlinkBatchTransform;
 import org.apache.seatunnel.flink.stream.FlinkStreamTransform;
-import org.apache.seatunnel.plugin.Plugin;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-table2datastream/src/main/java/org/apache/seatunnel/flink/transform/TableToDataStream.java
Patch:
@@ -17,13 +17,13 @@
 
 package org.apache.seatunnel.flink.transform;
 
+import org.apache.seatunnel.apis.base.plugin.Plugin;
 import org.apache.seatunnel.common.config.CheckConfigUtil;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.flink.batch.FlinkBatchTransform;
 import org.apache.seatunnel.flink.stream.FlinkStreamTransform;
 import org.apache.seatunnel.flink.util.TableUtil;
-import org.apache.seatunnel.plugin.Plugin;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/source/SourceSplitEnumerator.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.api.source;
 
 import org.apache.seatunnel.api.state.CheckpointListener;
+import org.apache.seatunnel.common.constants.CollectionConstants;
 
 import java.util.Collections;
 import java.util.HashMap;
@@ -64,7 +65,7 @@ interface Context<SplitT extends SourceSplit> {
          * @param subtask The index of the operator's parallel subtask that shall receive the split.
          */
         default void assignSplit(SplitT split, int subtask) {
-            Map<Integer, List<SplitT>> splits = new HashMap<>();
+            Map<Integer, List<SplitT>> splits = new HashMap<>(CollectionConstants.MAP_SIZE);
             splits.put(subtask, Collections.singletonList(split));
             assignSplits(splits);
         }

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/catalog/Column.java
Patch:
@@ -23,6 +23,7 @@
 import java.util.Objects;
 import java.util.Optional;
 
+@SuppressWarnings("PMD.AbstractClassShouldStartWithAbstractNamingRule")
 public abstract class Column {
 
     protected final String name;

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/FactoryUtil.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.seatunnel.api.table.catalog.Catalog;
 import org.apache.seatunnel.api.table.catalog.CatalogTable;
 import org.apache.seatunnel.api.table.connector.TableSource;
+
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -46,7 +47,6 @@ public static List<Source> createAndPrepareSource(
             ClassLoader classLoader,
             String factoryIdentifier) {
 
-
         try {
             final TableSourceFactory factory = discoverFactory(classLoader, TableSourceFactory.class, factoryIdentifier);
             List<Source> sources = new ArrayList<>(multipleTables.size());

File: seatunnel-api/src/main/java/org/apache/seatunnel/api/table/factory/TableFactoryContext.java
Patch:
@@ -37,7 +37,6 @@ public TableFactoryContext(
         this.classLoader = classLoader;
     }
 
-
     public ClassLoader getClassLoader() {
         return this.classLoader;
     }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchExecution.java
Patch:
@@ -48,7 +48,6 @@ public FlinkBatchExecution(FlinkEnvironment flinkEnvironment) {
     }
 
     @Override
-
     public void start(List<FlinkBatchSource> sources, List<FlinkBatchTransform> transforms, List<FlinkBatchSink> sinks) throws Exception {
         List<DataSet<Row>> data = new ArrayList<>();
 

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/config/ExecutionContext.java
Patch:
@@ -49,6 +49,7 @@ public ExecutionContext(Config config, EngineType engine) {
         this.environment = new EnvironmentFactory<ENVIRONMENT>(config, engine).getEnvironment();
         this.jobMode = environment.getJobMode();
         PluginFactory<ENVIRONMENT> pluginFactory = new PluginFactory<>(config, engine);
+        this.environment.registerPlugin(pluginFactory.getPluginJarPaths());
         this.sources = pluginFactory.createPlugins(PluginType.SOURCE);
         this.transforms = pluginFactory.createPlugins(PluginType.TRANSFORM);
         this.sinks = pluginFactory.createPlugins(PluginType.SINK);

File: seatunnel-core/seatunnel-core-flink/src/main/java/org/apache/seatunnel/FlinkStarter.java
Patch:
@@ -104,7 +104,6 @@ public List<String> buildCommands() {
         if (flinkCommandArgs.isCheckConfig()) {
             command.add("--check");
         }
-
         // set System properties
         flinkCommandArgs.getVariables().stream()
             .filter(Objects::nonNull)

File: seatunnel-e2e/seatunnel-spark-e2e/src/test/java/org/apache/seatunnel/e2e/spark/fake/HttpSourceToConsoleIT.java
Patch:
@@ -20,7 +20,6 @@
 import org.apache.seatunnel.e2e.spark.SparkContainer;
 
 import org.junit.Assert;
-import org.junit.Test;
 import org.testcontainers.containers.Container;
 
 import java.io.IOException;
@@ -31,8 +30,8 @@
  */
 public class HttpSourceToConsoleIT extends SparkContainer {
 
-    @Test
     public void testHttpSourceToConsoleSine() throws IOException, InterruptedException {
+        // skip this test case, since there exist some problem to run streaming in e2e
         Container.ExecResult execResult = executeSeaTunnelSparkJob("/http/httpsource_to_console.conf");
         Assert.assertEquals(0, execResult.getExitCode());
     }

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/config/DeployMode.java
Patch:
@@ -20,6 +20,7 @@
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
+import java.util.Optional;
 
 public enum DeployMode {
     CLIENT("client"),
@@ -39,8 +40,8 @@ public String getName() {
         return name;
     }
 
-    public static DeployMode from(String name) {
-        return NAME_MAP.get(name);
+    public static Optional<DeployMode> from(String name) {
+        return Optional.ofNullable(NAME_MAP.get(name));
     }
 
 }

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/command/flink/FlinkTaskExecuteCommand.java
Patch:
@@ -28,9 +28,11 @@
 import org.apache.seatunnel.config.ExecutionFactory;
 import org.apache.seatunnel.env.Execution;
 import org.apache.seatunnel.flink.FlinkEnvironment;
+import org.apache.seatunnel.utils.FileUtils;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
+import java.nio.file.Path;
 import java.util.List;
 
 /**
@@ -41,7 +43,7 @@ public class FlinkTaskExecuteCommand extends BaseTaskExecuteCommand<FlinkCommand
     @Override
     public void execute(FlinkCommandArgs flinkCommandArgs) {
         EngineType engine = flinkCommandArgs.getEngineType();
-        String configFile = flinkCommandArgs.getConfigFile();
+        Path configFile = FileUtils.getConfigPath(flinkCommandArgs);
 
         Config config = new ConfigBuilder<>(configFile, engine).getConfig();
         ExecutionContext<FlinkEnvironment> executionContext = new ExecutionContext<>(config, engine);

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/command/spark/SparkTaskExecuteCommand.java
Patch:
@@ -28,17 +28,19 @@
 import org.apache.seatunnel.config.ExecutionFactory;
 import org.apache.seatunnel.env.Execution;
 import org.apache.seatunnel.spark.SparkEnvironment;
+import org.apache.seatunnel.utils.FileUtils;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
+import java.nio.file.Path;
 import java.util.List;
 
 public class SparkTaskExecuteCommand extends BaseTaskExecuteCommand<SparkCommandArgs, SparkEnvironment> {
 
     @Override
     public void execute(SparkCommandArgs sparkCommandArgs) {
         EngineType engine = sparkCommandArgs.getEngineType();
-        String confFile = sparkCommandArgs.getConfigFile();
+        Path confFile = FileUtils.getConfigPath(sparkCommandArgs);
 
         Config config = new ConfigBuilder<>(confFile, engine).getConfig();
         ExecutionContext<SparkEnvironment> executionContext = new ExecutionContext<>(config, engine);

File: seatunnel-examples/seatunnel-spark-examples/src/main/java/org/apache/seatunnel/example/spark/LocalSparkExample.java
Patch:
@@ -31,7 +31,7 @@ public static void main(String[] args) {
         sparkArgs.setConfigFile(configFile);
         sparkArgs.setCheckConfig(false);
         sparkArgs.setVariables(null);
-        sparkArgs.setDeployMode(DeployMode.CLIENT.getName());
+        sparkArgs.setDeployMode(DeployMode.CLIENT);
         Seatunnel.run(sparkArgs);
     }
 

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/utils/CompressionUtils.java
Patch:
@@ -97,7 +97,7 @@ public FileVisitResult visitFile(Path path, BasicFileAttributes attrs) throws IO
      * @throws FileNotFoundException file not found exception
      * @throws ArchiveException      archive exception
      */
-    public static void unTar(final File inputFile, final File outputDir) throws  IOException, ArchiveException {
+    public static void unTar(final File inputFile, final File outputDir) throws IOException, ArchiveException {
 
         LOGGER.info("Untaring {} to dir {}.", inputFile.getAbsolutePath(), outputDir.getAbsolutePath());
 

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/config/Common.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.common.config;
 
+import java.io.File;
 import java.net.URISyntaxException;
 import java.nio.file.Path;
 import java.nio.file.Paths;
@@ -67,6 +68,7 @@ public static Path appRootDir() {
         if (MODE.equals(Optional.of(DeployMode.CLIENT.getName()))) {
             try {
                 String path = Common.class.getProtectionDomain().getCodeSource().getLocation().toURI().getPath();
+                path = new File(path).getPath();
                 return Paths.get(path).getParent().getParent();
             } catch (URISyntaxException e) {
                 throw new RuntimeException(e);

File: seatunnel-config/seatunnel-config-shade/src/test/java/org/apache/seatunnel/config/CompleteTest.java
Patch:
@@ -26,21 +26,22 @@
 import org.junit.Assert;
 import org.junit.Test;
 
+import java.net.URISyntaxException;
 import java.util.HashMap;
 import java.util.Map;
 
 public class CompleteTest {
 
     @Test
-    public void testVariables() {
+    public void testVariables() throws URISyntaxException {
         // We use a map to mock the system property, since the system property will be only loaded once
         // after the test is run. see Issue #1670
         Map<String, String> systemProperties = new HashMap<>();
         systemProperties.put("dt", "20190318");
         systemProperties.put("city2", "shanghai");
 
         Config config = ConfigFactory
-            .parseFile(FileUtils.getFileFromResources("seatunnel/variables.conf"))
+            .parseFile(FileUtils.getFileFromResources("/seatunnel/variables.conf"))
             .resolveWith(ConfigFactory.parseMap(systemProperties), ConfigResolveOptions.defaults().setAllowUnresolved(true));
         String sql1 = config.getConfigList("transform").get(1).getString("sql");
         String sql2 = config.getConfigList("transform").get(2).getString("sql");

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/stream/FlinkStreamExecution.java
Patch:
@@ -79,7 +79,7 @@ public void start(List<FlinkStreamSource> sources, List<FlinkStreamTransform> tr
         }
     }
 
-    private void registerResultTable(Plugin plugin, DataStream dataStream) {
+    private void registerResultTable(Plugin<FlinkEnvironment> plugin, DataStream<Row> dataStream) {
         Config config = plugin.getConfig();
         if (config.hasPath(RESULT_TABLE_NAME)) {
             String name = config.getString(RESULT_TABLE_NAME);

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-split/src/main/java/org/apache/seatunnel/flink/transform/Split.java
Patch:
@@ -94,7 +94,7 @@ public void prepare(FlinkEnvironment prepareEnv) {
         if (config.hasPath(SEPARATOR)) {
             separator = config.getString(SEPARATOR);
         }
-        TypeInformation[] types = new TypeInformation[fields.size()];
+        TypeInformation<?>[] types = new TypeInformation[fields.size()];
         for (int i = 0; i < types.length; i++) {
             types[i] = Types.STRING();
         }

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-console/src/main/java/org/apache/seatunnel/flink/console/sink/ConsoleSink.java
Patch:
@@ -48,7 +48,6 @@ public void outputBatch(FlinkEnvironment env, DataSet<Row> rowDataSet) {
         } catch (Exception e) {
             LOGGER.error("Failed to print result! ", e);
         }
-        rowDataSet.output(this);
     }
 
     @Override

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/config/TypesafeConfigUtils.java
Patch:
@@ -105,6 +105,9 @@ public static <T> T getConfig(final Config config, final String configKey, @NonN
         if (defaultValue.getClass().equals(String.class)) {
             return config.hasPath(configKey) ? (T) config.getString(configKey) : defaultValue;
         }
+        if (defaultValue.getClass().equals(Boolean.class)) {
+            return config.hasPath(configKey) ? (T) Boolean.valueOf(config.getString(configKey)) : defaultValue;
+        }
         throw new RuntimeException("Unsupported config type, configKey: " + configKey);
     }
 }

File: seatunnel-e2e/seatunnel-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/clickhouse/FakeSourceToClickhouseIT.java
Patch:
@@ -45,7 +45,7 @@ public class FakeSourceToClickhouseIT extends FlinkContainer {
 
     private GenericContainer<?> clickhouseServer;
     private BalancedClickhouseDataSource dataSource;
-    private static final String CLICKHOUSE_DOCKER_IMAGE = "yandex/clickhouse-server:21.3.20.1";
+    private static final String CLICKHOUSE_DOCKER_IMAGE = "yandex/clickhouse-server:22.1.3.7";
 
     private static final Logger LOGGER = LoggerFactory.getLogger(FakeSourceToClickhouseIT.class);
 

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/config/TypesafeConfigUtils.java
Patch:
@@ -21,6 +21,8 @@
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;
 import org.apache.seatunnel.shade.com.typesafe.config.ConfigValue;
 
+import lombok.NonNull;
+
 import java.util.LinkedHashMap;
 import java.util.Map;
 
@@ -93,7 +95,7 @@ public static Config extractSubConfigThrowable(Config source, String prefix, boo
     }
 
     @SuppressWarnings("unchecked")
-    public static <T> T getConfig(final Config config, final String configKey, final T defaultValue) {
+    public static <T> T getConfig(final Config config, final String configKey, @NonNull final T defaultValue) {
         if (defaultValue.getClass().equals(Long.class)) {
             return config.hasPath(configKey) ? (T) Long.valueOf(config.getString(configKey)) : defaultValue;
         }

File: seatunnel-e2e/seatunnel-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/FlinkContainer.java
Patch:
@@ -46,7 +46,7 @@ public abstract class FlinkContainer {
     private static final Logger LOG = LoggerFactory.getLogger(FlinkContainer.class);
 
     private static final String FLINK_DOCKER_IMAGE = "flink:1.13.6-scala_2.11";
-    public static final Network NETWORK = Network.newNetwork();
+    protected static final Network NETWORK = Network.newNetwork();
 
     protected GenericContainer<?> jobManager;
     protected GenericContainer<?> taskManager;
@@ -85,7 +85,7 @@ public void before() {
         Startables.deepStart(Stream.of(jobManager)).join();
         Startables.deepStart(Stream.of(taskManager)).join();
         copySeaTunnelFlinkCoreJar();
-        LOG.info("Containers are started.");
+        LOG.info("Flink containers are started.");
     }
 
     @After

File: seatunnel-e2e/seatunnel-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/fake/FakeSourceToConsoleIT.java
Patch:
@@ -28,7 +28,7 @@
 public class FakeSourceToConsoleIT extends FlinkContainer {
 
     @Test
-    public void testFakeSourceToConsoleSine() throws IOException, InterruptedException {
+    public void testFakeSourceToConsoleSink() throws IOException, InterruptedException {
         Container.ExecResult execResult = executeSeaTunnelFlinkJob("/fake/fakesource_to_console.conf");
         Assert.assertEquals(0, execResult.getExitCode());
     }

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-elasticsearch6/src/main/java/org/apache/seatunnel/flink/elasticsearch6/config/Config.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.flink.elasticsearch.config;
+package org.apache.seatunnel.flink.elasticsearch6.config;
 
 /**
  * ElasticSearch sink configuration options

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-elasticsearch7/src/main/java/org/apache/seatunnel/flink/elasticsearch/sink/ElasticsearchOutputFormat.java
Patch:
@@ -46,7 +46,7 @@ public class ElasticsearchOutputFormat<T> extends RichOutputFormat<T> {
     private static final long serialVersionUID = 2048590860723433896L;
     private static final Logger LOGGER = LoggerFactory.getLogger(ElasticsearchOutputFormat.class);
 
-    private Config config;
+    private final Config config;
 
     private static final String PREFIX = "es.";
 

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-doris/src/main/java/org/apache/seatunnel/flink/doris/sink/DorisOutputFormat.java
Patch:
@@ -207,7 +207,7 @@ public synchronized void flush() throws IOException {
                 result = OBJECT_MAPPER.writeValueAsString(batch);
             }
         } else {
-            result = String.join(this.lineDelimiter, (CharSequence) batch);
+            result = String.join(this.lineDelimiter, batch.toArray(new CharSequence[batch.size()]));
         }
         for (int i = 0; i <= maxRetries; i++) {
             try {

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/config/PluginFactory.java
Patch:
@@ -120,8 +120,7 @@ private Plugin<?> createPluginInstanceIgnoreCase(PluginType pluginType, String p
         for (Iterator<Plugin<?>> it = plugins.iterator(); it.hasNext(); ) {
             try {
                 Plugin<?> plugin = it.next();
-                Class<?> serviceClass = plugin.getClass();
-                if (StringUtils.equalsIgnoreCase(serviceClass.getSimpleName(), pluginName)) {
+                if (StringUtils.equalsIgnoreCase(plugin.getPluginName(), pluginName)) {
                     return plugin;
                 }
             } catch (ServiceConfigurationError e) {

File: seatunnel-core/seatunnel-core-spark/src/main/java/org/apache/seatunnel/SparkStarter.java
Patch:
@@ -125,8 +125,8 @@ private static SparkCommandArgs parseCommandArgs(String[] args) {
         JCommander commander = JCommander.newBuilder()
             .programName("start-seatunnel-spark.sh")
             .addObject(commandArgs)
+            .args(args)
             .build();
-        commander.parse(args);
         if (commandArgs.isHelp()) {
             commander.usage();
             System.exit(USAGE_EXIT_CODE);

File: seatunnel-examples/seatunnel-spark-examples/src/main/java/org/apache/seatunnel/example/spark/LocalSparkExample.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.seatunnel.Seatunnel;
 import org.apache.seatunnel.command.SparkCommandArgs;
+import org.apache.seatunnel.common.config.DeployMode;
 
 public class LocalSparkExample {
 
@@ -30,6 +31,7 @@ public static void main(String[] args) {
         sparkArgs.setConfigFile(configFile);
         sparkArgs.setCheckConfig(false);
         sparkArgs.setVariables(null);
+        sparkArgs.setDeployMode(DeployMode.CLIENT.getName());
         Seatunnel.run(sparkArgs);
     }
 

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-file/src/main/java/org/apache/seatunnel/flink/file/sink/FileSink.java
Patch:
@@ -61,7 +61,7 @@ public class FileSink implements FlinkStreamSink, FlinkBatchSink {
     private static final String DEFAULT_TIME_FORMAT = "yyyyMMddHHmmss";
     // *********************** For stream mode config ************************
     private static final String ROLLOVER_INTERVAL = "rollover_interval";
-    private static final long DEFAULE_ROLLOVER_INTERVAL = 60;
+    private static final long DEFAULT_ROLLOVER_INTERVAL = 60;
     private static final String MAX_PART_SIZE = "max_part_size";
     private static final long DEFAULT_MAX_PART_SIZE = 1024;
     private static final String PART_PREFIX = "prefix";
@@ -82,7 +82,7 @@ public DataStreamSink<Row> outputStream(FlinkEnvironment env, DataStream<Row> da
         final DefaultRollingPolicy<Row, String> rollingPolicy = DefaultRollingPolicy.builder()
             .withMaxPartSize(MB * TypesafeConfigUtils.getConfig(config, MAX_PART_SIZE, DEFAULT_MAX_PART_SIZE))
             .withRolloverInterval(
-                TimeUnit.MINUTES.toMillis(TypesafeConfigUtils.getConfig(config, ROLLOVER_INTERVAL, DEFAULE_ROLLOVER_INTERVAL)))
+                TimeUnit.MINUTES.toMillis(TypesafeConfigUtils.getConfig(config, ROLLOVER_INTERVAL, DEFAULT_ROLLOVER_INTERVAL)))
             .build();
         OutputFileConfig outputFileConfig = OutputFileConfig.builder()
             .withPartPrefix(TypesafeConfigUtils.getConfig(config, PART_PREFIX, DEFAULT_PART_PREFIX))

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-sql/src/main/java/org/apache/seatunnel/flink/transform/Sql.java
Patch:
@@ -48,7 +48,7 @@ public DataStream<Row> processStream(FlinkEnvironment env, DataStream<Row> dataS
         try {
             table = tableEnvironment.sqlQuery(sql);
         } catch (Exception e) {
-            throw new Exception("Flink streaming transform sql execute failed, SQL: "+sql, e);
+            throw new Exception("Flink streaming transform sql execute failed, SQL: " + sql, e);
         }
         return TableUtil.tableToDataStream(tableEnvironment, table, false);
     }
@@ -60,7 +60,7 @@ public DataSet<Row> processBatch(FlinkEnvironment env, DataSet<Row> data) throws
         try {
             table = tableEnvironment.sqlQuery(sql);
         } catch (Exception e) {
-            throw new Exception("Flink batch transform sql execute failed, SQL: "+sql, e);
+            throw new Exception("Flink batch transform sql execute failed, SQL: " + sql, e);
         }
         return TableUtil.tableToDataSet(tableEnvironment, table);
     }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/FlinkEnvironment.java
Patch:
@@ -77,7 +77,6 @@ public CheckResult checkConfig() {
     }
 
     @Override
-
     public FlinkEnvironment prepare() {
         if (isStreaming()) {
             createStreamEnvironment();
@@ -100,6 +99,7 @@ public boolean isStreaming() {
         return JobMode.STREAMING.equals(jobMode);
     }
 
+    @Override
     public FlinkEnvironment setJobMode(JobMode jobMode) {
         this.jobMode = jobMode;
         return this;

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/Constants.java
Patch:
@@ -20,7 +20,6 @@
 public final class Constants {
     public static final String ROW_ROOT = "__root__";
     public static final String ROW_TMP = "__tmp__";
-    public static final String ROW_JSON = "__json__";
 
     public static final String LOGO = "SeaTunnel";
 

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/env/Execution.java
Patch:
@@ -41,4 +41,5 @@ public interface Execution<
      * @param sinks      sink plugin list
      */
     void start(List<SR> sources, List<TF> transforms, List<SK> sinks) throws Exception;
+
 }

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/env/RuntimeEnv.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.env;
 
 import org.apache.seatunnel.common.config.CheckResult;
+import org.apache.seatunnel.common.constants.JobMode;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
@@ -34,4 +35,6 @@ public interface RuntimeEnv {
 
     RuntimeEnv prepare();
 
+    RuntimeEnv setJobMode(JobMode mode);
+
 }

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/plugin/Plugin.java
Patch:
@@ -39,6 +39,7 @@
  *
  * }</pre>
  */
+
 public interface Plugin<T extends RuntimeEnv> extends Serializable, AutoCloseable {
     String RESULT_TABLE_NAME = "result_table_name";
     String SOURCE_TABLE_NAME = "source_table_name";

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchExecution.java
Patch:
@@ -48,6 +48,7 @@ public FlinkBatchExecution(FlinkEnvironment flinkEnvironment) {
     }
 
     @Override
+
     public void start(List<FlinkBatchSource> sources, List<FlinkBatchTransform> transforms, List<FlinkBatchSink> sinks) throws Exception {
         List<DataSet<Row>> data = new ArrayList<>();
 

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-file/src/test/java/org/apache/seatunnel/flink/source/FileSourceTest.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.flink.source;
 
+import org.apache.seatunnel.common.constants.JobMode;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
@@ -62,7 +63,7 @@ private FlinkEnvironment createFlinkStreamEnvironment(String configFile) {
         Config rootConfig = getRootConfig(configFile);
 
         return new FlinkEnvironment()
-            .setStreaming(false)
+            .setJobMode(JobMode.BATCH)
             .setConfig(rootConfig)
             .prepare();
     }

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/utils/CompressionUtils.java
Patch:
@@ -65,6 +65,9 @@ public static void unTar(final File inputFile, final File outputDir) throws  IOE
             TarArchiveEntry entry = null;
             while ((entry = (TarArchiveEntry) debInputStream.getNextEntry()) != null) {
                 final File outputFile = new File(outputDir, entry.getName());
+                if (!outputFile.toPath().normalize().startsWith(outputDir.toPath())) {
+                    throw new IllegalStateException("Bad zip entry");
+                }
                 if (entry.isDirectory()) {
                     LOGGER.info("Attempting to write output directory {}.", outputFile.getAbsolutePath());
                     if (!outputFile.exists()) {

File: seatunnel-e2e/seatunnel-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/fake/FakeSourceToConsoleIT.java
Patch:
@@ -29,7 +29,7 @@ public class FakeSourceToConsoleIT extends FlinkContainer {
 
     @Test
     public void testFakeSourceToConsoleSine() throws IOException, InterruptedException {
-        Container.ExecResult execResult = executeSeaTunnelFLinkJob("/fake/fakesource_to_console.conf");
+        Container.ExecResult execResult = executeSeaTunnelFlinkJob("/fake/fakesource_to_console.conf");
         Assert.assertEquals(0, execResult.getExitCode());
     }
 }

File: seatunnel-e2e/seatunnel-flink-e2e/src/test/java/org/apache/seatunnel/e2e/flink/file/FakeSourceToFileIT.java
Patch:
@@ -31,7 +31,7 @@ public class FakeSourceToFileIT extends FlinkContainer {
 
     @Test
     public void testFakeSource2FileSink() throws Exception {
-        Container.ExecResult execResult = executeSeaTunnelFLinkJob("/file/fakesource_to_file.conf");
+        Container.ExecResult execResult = executeSeaTunnelFlinkJob("/file/fakesource_to_file.conf");
         Assert.assertEquals(0, execResult.getExitCode());
     }
 }

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-doris/src/main/java/org/apache/seatunnel/flink/sink/DorisSink.java
Patch:
@@ -44,8 +44,8 @@
 public class DorisSink implements FlinkStreamSink, FlinkBatchSink {
 
     private static final long serialVersionUID = 4747849769146047770L;
-    private static final int DEFAULT_BATCH_SIZE = 100;
-    private static final long DEFAULT_INTERVAL_MS = TimeUnit.SECONDS.toMillis(1);
+    private static final int DEFAULT_BATCH_SIZE = 5000;
+    private static final long DEFAULT_INTERVAL_MS = TimeUnit.SECONDS.toMillis(5);
     private static final String PARALLELISM = "parallelism";
 
     private Config config;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/command/flink/FlinkTaskExecuteCommand.java
Patch:
@@ -46,11 +46,12 @@ public void execute(FlinkCommandArgs flinkCommandArgs) {
             execution = configBuilder.createExecution();
 
         baseCheckConfig(sources, transforms, sinks);
-        prepare(configBuilder.getEnv(), sources, transforms, sinks);
         showAsciiLogo();
 
         try {
+            prepare(configBuilder.getEnv(), sources, transforms, sinks);
             execution.start(sources, transforms, sinks);
+            close(sources, transforms, sinks);
         } catch (Exception e) {
             throw new RuntimeException("Execute Flink task error", e);
         }

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/command/spark/SparkTaskExecuteCommand.java
Patch:
@@ -43,11 +43,12 @@ public void execute(SparkCommandArgs sparkCommandArgs) {
         Execution<BaseSource<SparkEnvironment>, BaseTransform<SparkEnvironment>, BaseSink<SparkEnvironment>, SparkEnvironment>
             execution = configBuilder.createExecution();
         baseCheckConfig(sources, transforms, sinks);
-        prepare(configBuilder.getEnv(), sources, transforms, sinks);
         showAsciiLogo();
 
         try {
+            prepare(configBuilder.getEnv(), sources, transforms, sinks);
             execution.start(sources, transforms, sinks);
+            close(sources, transforms, sinks);
         } catch (Exception e) {
             throw new RuntimeException("Execute Spark task error", e);
         }

File: seatunnel-config/seatunnel-config-shade/src/main/java/org/apache/seatunnel/shade/com/typesafe/config/impl/ConfigParser.java
Patch:
@@ -111,7 +111,7 @@ private AbstractConfigValue parseValue(AbstractConfigNodeValue n, List<String> c
 
                 Path path = pathStack.peekFirst();
 
-                if (path != null
+                if (path != null && !ConfigSyntax.JSON.equals(flavor)
                     && ("source".equals(path.first())
                     || "transform".equals(path.first())
                     || "sink".equals(path.first()))) {

File: seatunnel-apis/seatunnel-api-base/src/main/java/org/apache/seatunnel/plugin/Plugin.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.plugin;
 
 import org.apache.seatunnel.common.config.CheckResult;
+import org.apache.seatunnel.env.RuntimeEnv;
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
@@ -26,7 +27,7 @@
 /**
  * a base interface indicates belonging to SeaTunnel.
  */
-public interface Plugin<T> extends Serializable {
+public interface Plugin<T extends RuntimeEnv> extends Serializable {
     String RESULT_TABLE_NAME = "result_table_name";
     String SOURCE_TABLE_NAME = "source_table_name";
 

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/BaseFlinkSink.java
Patch:
@@ -23,4 +23,5 @@
  * a base interface indicates a sink plugin running on Flink.
  */
 public interface BaseFlinkSink extends BaseSink<FlinkEnvironment> {
+
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/stream/FlinkStreamExecution.java
Patch:
@@ -36,7 +36,7 @@
 import java.util.List;
 import java.util.Optional;
 
-public class FlinkStreamExecution implements Execution<FlinkStreamSource, FlinkStreamTransform, FlinkStreamSink> {
+public class FlinkStreamExecution implements Execution<FlinkStreamSource, FlinkStreamTransform, FlinkStreamSink, FlinkEnvironment> {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(FlinkStreamExecution.class);
 
@@ -121,6 +121,6 @@ public CheckResult checkConfig() {
     }
 
     @Override
-    public void prepare(Void prepareEnv) {
+    public void prepare(FlinkEnvironment prepareEnv) {
     }
 }

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/BaseSparkSource.java
Patch:
@@ -25,7 +25,7 @@
 /**
  * a base interface indicates a source plugin running on Spark.
  */
-public abstract class BaseSparkSource<T> implements BaseSource<SparkEnvironment> {
+public abstract class BaseSparkSource<OUT> implements BaseSource<SparkEnvironment> {
 
     protected Config config = ConfigFactory.empty();
 
@@ -39,5 +39,5 @@ public Config getConfig() {
         return this.config;
     }
 
-    public abstract T getData(SparkEnvironment env);
+    public abstract OUT getData(SparkEnvironment env);
 }

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/batch/SparkBatchExecution.java
Patch:
@@ -33,7 +33,7 @@
 
 import java.util.List;
 
-public class SparkBatchExecution implements Execution<SparkBatchSource, BaseSparkTransform, SparkBatchSink> {
+public class SparkBatchExecution implements Execution<SparkBatchSource, BaseSparkTransform, SparkBatchSink, SparkEnvironment> {
 
     private final SparkEnvironment environment;
 
@@ -123,7 +123,7 @@ public CheckResult checkConfig() {
     }
 
     @Override
-    public void prepare(Void prepareEnv) {
+    public void prepare(SparkEnvironment prepareEnv) {
 
     }
 }

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/structuredstream/StructuredStreamingExecution.java
Patch:
@@ -27,7 +27,7 @@
 
 import java.util.List;
 
-public class StructuredStreamingExecution implements Execution<StructuredStreamingSource, BaseSparkTransform, StructuredStreamingSink> {
+public class StructuredStreamingExecution implements Execution<StructuredStreamingSource, BaseSparkTransform, StructuredStreamingSink, SparkEnvironment> {
 
     private final SparkEnvironment sparkEnvironment;
 
@@ -58,7 +58,7 @@ public CheckResult checkConfig() {
     }
 
     @Override
-    public void prepare(Void prepareEnv) {
+    public void prepare(SparkEnvironment prepareEnv) {
 
     }
 }

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/command/flink/FlinkConfValidateCommand.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.command.Command;
 import org.apache.seatunnel.command.FlinkCommandArgs;
 import org.apache.seatunnel.config.ConfigBuilder;
+import org.apache.seatunnel.flink.FlinkEnvironment;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -34,7 +35,7 @@ public class FlinkConfValidateCommand implements Command<FlinkCommandArgs> {
     @Override
     public void execute(FlinkCommandArgs flinkCommandArgs) {
         String configPath = flinkCommandArgs.getConfigFile();
-        new ConfigBuilder(configPath, flinkCommandArgs.getEngineType()).checkConfig();
+        new ConfigBuilder<FlinkEnvironment>(configPath, flinkCommandArgs.getEngineType()).checkConfig();
         LOGGER.info("config OK !");
     }
 }

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/command/spark/SparkConfValidateCommand.java
Patch:
@@ -21,6 +21,7 @@
 import org.apache.seatunnel.command.SparkCommandArgs;
 import org.apache.seatunnel.common.config.DeployMode;
 import org.apache.seatunnel.config.ConfigBuilder;
+import org.apache.seatunnel.spark.SparkEnvironment;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -42,7 +43,7 @@ public void execute(SparkCommandArgs sparkCommandArgs) {
         } else {
             confPath = sparkCommandArgs.getConfigFile();
         }
-        new ConfigBuilder(confPath, sparkCommandArgs.getEngineType()).checkConfig();
+        new ConfigBuilder<SparkEnvironment>(confPath, sparkCommandArgs.getEngineType()).checkConfig();
         LOGGER.info("config OK !");
     }
 

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/BaseFlinkSource.java
Patch:
@@ -22,5 +22,7 @@
 /**
  * a base interface indicates a source plugin running on Flink.
  */
-public interface BaseFlinkSource extends BaseSource<FlinkEnvironment> {
+public interface BaseFlinkSource<OUT> extends BaseSource<FlinkEnvironment> {
+
+    OUT getData(FlinkEnvironment env);
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchSink.java
Patch:
@@ -22,14 +22,15 @@
 
 import org.apache.flink.api.java.DataSet;
 import org.apache.flink.api.java.operators.DataSink;
+import org.apache.flink.types.Row;
 
 import javax.annotation.Nullable;
 
 /**
  * a FlinkBatchSink plugin will write data to other system using Flink DataSet API.
  */
-public interface FlinkBatchSink<IN, OUT> extends BaseFlinkSink {
+public interface FlinkBatchSink extends BaseFlinkSink {
 
     @Nullable
-    DataSink<OUT> outputBatch(FlinkEnvironment env, DataSet<IN> inDataSet);
+    DataSink<Row> outputBatch(FlinkEnvironment env, DataSet<Row> inDataSet);
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchSource.java
Patch:
@@ -21,11 +21,12 @@
 import org.apache.seatunnel.flink.FlinkEnvironment;
 
 import org.apache.flink.api.java.DataSet;
+import org.apache.flink.types.Row;
 
 /**
  * a FlinkBatchSource plugin will read data from other system using Flink DataSet API.
  */
-public interface FlinkBatchSource<T> extends BaseFlinkSource {
+public interface FlinkBatchSource extends BaseFlinkSource<DataSet<Row>> {
 
-    DataSet<T> getData(FlinkEnvironment env);
+    DataSet<Row> getData(FlinkEnvironment env);
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchTransform.java
Patch:
@@ -21,12 +21,13 @@
 import org.apache.seatunnel.flink.FlinkEnvironment;
 
 import org.apache.flink.api.java.DataSet;
+import org.apache.flink.types.Row;
 
 /**
  * a FlinkBatchTransform plugin will do transformations to Flink DataSet.
  */
-public interface FlinkBatchTransform<IN, OUT> extends BaseFlinkTransform {
+public interface FlinkBatchTransform extends BaseFlinkTransform {
 
-    DataSet<OUT> processBatch(FlinkEnvironment env, DataSet<IN> data);
+    DataSet<Row> processBatch(FlinkEnvironment env, DataSet<Row> data);
 
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/stream/FlinkStreamSink.java
Patch:
@@ -22,15 +22,16 @@
 
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.datastream.DataStreamSink;
+import org.apache.flink.types.Row;
 
 import javax.annotation.Nullable;
 
 /**
  * a FlinkStreamSink plugin will write data to other system using Flink DataStream API.
  */
-public interface FlinkStreamSink<IN, OUT> extends BaseFlinkSink {
+public interface FlinkStreamSink extends BaseFlinkSink {
 
     @Nullable
-    DataStreamSink<OUT> outputStream(FlinkEnvironment env, DataStream<IN> dataStream);
+    DataStreamSink<Row> outputStream(FlinkEnvironment env, DataStream<Row> dataStream);
 
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/stream/FlinkStreamSource.java
Patch:
@@ -21,12 +21,12 @@
 import org.apache.seatunnel.flink.FlinkEnvironment;
 
 import org.apache.flink.streaming.api.datastream.DataStream;
+import org.apache.flink.types.Row;
 
 /**
  * a FlinkStreamSource plugin will read data from other system using Flink DataStream API.
  */
-public interface FlinkStreamSource<T> extends BaseFlinkSource {
-
-    DataStream<T> getData(FlinkEnvironment env);
+public interface FlinkStreamSource extends BaseFlinkSource<DataStream<Row>> {
 
+    DataStream<Row> getData(FlinkEnvironment env);
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/stream/FlinkStreamTransform.java
Patch:
@@ -21,11 +21,12 @@
 import org.apache.seatunnel.flink.FlinkEnvironment;
 
 import org.apache.flink.streaming.api.datastream.DataStream;
+import org.apache.flink.types.Row;
 
 /**
  * a FlinkBatchTransform plugin will do transformations to Flink DataStream.
  */
-public interface FlinkStreamTransform<IN, OUT> extends BaseFlinkTransform {
+public interface FlinkStreamTransform extends BaseFlinkTransform {
 
-    DataStream<OUT> processStream(FlinkEnvironment env, DataStream<IN> dataStream);
+    DataStream<Row> processStream(FlinkEnvironment env, DataStream<Row> dataStream);
 }

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-console/src/main/java/org/apache/seatunnel/flink/sink/ConsoleSink.java
Patch:
@@ -34,7 +34,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-public class ConsoleSink extends RichOutputFormat<Row> implements FlinkBatchSink<Row, Row>, FlinkStreamSink<Row, Row> {
+public class ConsoleSink extends RichOutputFormat<Row> implements FlinkBatchSink, FlinkStreamSink {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(ConsoleSink.class);
 

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-doris/src/main/java/org/apache/seatunnel/flink/sink/DorisSink.java
Patch:
@@ -41,7 +41,7 @@
 import java.util.Properties;
 import java.util.concurrent.TimeUnit;
 
-public class DorisSink implements FlinkStreamSink<Row, Row>, FlinkBatchSink<Row, Row> {
+public class DorisSink implements FlinkStreamSink, FlinkBatchSink {
 
     private static final long serialVersionUID = 4747849769146047770L;
     private static final int DEFAULT_BATCH_SIZE = 100;

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-druid/src/main/java/org/apache/seatunnel/flink/sink/DruidSink.java
Patch:
@@ -28,7 +28,7 @@
 import org.apache.flink.api.java.operators.DataSink;
 import org.apache.flink.types.Row;
 
-public class DruidSink implements FlinkBatchSink<Row, Row> {
+public class DruidSink implements FlinkBatchSink {
 
     private static final long serialVersionUID = -2967782261362988646L;
     private static final String COORDINATOR_URL = "coordinator_url";

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-druid/src/main/java/org/apache/seatunnel/flink/source/DruidSource.java
Patch:
@@ -52,7 +52,7 @@
 import java.util.LinkedHashMap;
 import java.util.List;
 
-public class DruidSource implements FlinkBatchSource<Row> {
+public class DruidSource implements FlinkBatchSource {
 
     private static final long serialVersionUID = 8152628883440481281L;
     private static final Logger LOGGER = LoggerFactory.getLogger(DruidSource.class);

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-elasticsearch/src/main/java/org/apache/seatunnel/flink/sink/Elasticsearch.java
Patch:
@@ -55,7 +55,7 @@
 import java.util.List;
 import java.util.Map;
 
-public class Elasticsearch implements FlinkStreamSink<Row, Row>, FlinkBatchSink<Row, Row> {
+public class Elasticsearch implements FlinkStreamSink, FlinkBatchSink {
 
     private static final long serialVersionUID = 8445868321245456793L;
     private static final int DEFAULT_CONFIG_SIZE = 3;

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-fake/src/main/java/org/apache/seatunnel/flink/source/FakeSourceStream.java
Patch:
@@ -35,7 +35,7 @@
 
 import java.util.concurrent.TimeUnit;
 
-public class FakeSourceStream extends RichParallelSourceFunction<Row> implements FlinkStreamSource<Row> {
+public class FakeSourceStream extends RichParallelSourceFunction<Row> implements FlinkStreamSource {
 
     private static final long serialVersionUID = -3026082767246767679L;
     private volatile boolean running = true;

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-file/src/main/java/org/apache/seatunnel/flink/sink/FileSink.java
Patch:
@@ -44,7 +44,7 @@
 
 import java.io.PrintStream;
 
-public class FileSink implements FlinkStreamSink<Row, Row>, FlinkBatchSink<Row, Row> {
+public class FileSink implements FlinkStreamSink, FlinkBatchSink {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(FileSink.class);
 

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-file/src/main/java/org/apache/seatunnel/flink/source/FileSource.java
Patch:
@@ -45,7 +45,7 @@
 import java.util.List;
 import java.util.Map;
 
-public class FileSource implements FlinkBatchSource<Row> {
+public class FileSource implements FlinkBatchSource {
 
     private static final long serialVersionUID = -5206798549756998426L;
     private static final int DEFAULT_BATCH_SIZE = 1000;

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-influxdb/src/main/java/org/apache/seatunnel/flink/sink/InfluxDbSink.java
Patch:
@@ -30,7 +30,7 @@
 
 import java.util.List;
 
-public class InfluxDbSink implements FlinkBatchSink<Row, Row> {
+public class InfluxDbSink implements FlinkBatchSink {
 
     private static final long serialVersionUID = 7358988750295693096L;
     private static final String SERVER_URL = "server_url";

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-influxdb/src/main/java/org/apache/seatunnel/flink/source/InfluxDbSource.java
Patch:
@@ -42,7 +42,7 @@
 import java.util.HashMap;
 import java.util.List;
 
-public class InfluxDbSource implements FlinkBatchSource<Row> {
+public class InfluxDbSource implements FlinkBatchSource {
 
     private Config config;
     private InfluxDbInputFormat influxDbInputFormat;

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-jdbc/src/main/java/org/apache/seatunnel/flink/sink/JdbcSink.java
Patch:
@@ -52,7 +52,7 @@
 
 import java.util.Arrays;
 
-public class JdbcSink implements FlinkStreamSink<Row, Row>, FlinkBatchSink<Row, Row> {
+public class JdbcSink implements FlinkStreamSink, FlinkBatchSink {
 
     private static final long serialVersionUID = 3677571223952518115L;
     private static final int DEFAULT_BATCH_SIZE = 5000;

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-jdbc/src/main/java/org/apache/seatunnel/flink/source/JdbcSource.java
Patch:
@@ -56,7 +56,7 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-public class JdbcSource implements FlinkBatchSource<Row> {
+public class JdbcSource implements FlinkBatchSource {
 
     private static final long serialVersionUID = -3349505356339446415L;
     private static final Logger LOGGER = LoggerFactory.getLogger(JdbcSource.class);

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-kafka/src/main/java/org/apache/seatunnel/flink/sink/KafkaTable.java
Patch:
@@ -42,7 +42,7 @@
 
 import java.util.Properties;
 
-public class KafkaTable implements FlinkStreamSink<Row, Row> {
+public class KafkaTable implements FlinkStreamSink {
 
     private static final long serialVersionUID = 3980751499724935230L;
     private Config config;

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-kafka/src/main/java/org/apache/seatunnel/flink/source/KafkaTableStream.java
Patch:
@@ -46,7 +46,7 @@
 import java.util.HashMap;
 import java.util.Properties;
 
-public class KafkaTableStream implements FlinkStreamSource<Row> {
+public class KafkaTableStream implements FlinkStreamSource {
 
     private static final long   serialVersionUID = 5287018194573371428L;
     private static final Logger LOGGER = LoggerFactory.getLogger(KafkaTableStream.class);

File: seatunnel-connectors/seatunnel-connectors-flink/seatunnel-connector-flink-socket/src/main/java/org/apache/seatunnel/flink/source/SocketStream.java
Patch:
@@ -30,7 +30,7 @@
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.types.Row;
 
-public class SocketStream implements FlinkStreamSource<Row> {
+public class SocketStream implements FlinkStreamSource {
 
     private static final long serialVersionUID = 986629276153771291L;
     private Config config;

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-datastream2table/src/main/java/org/apache/seatunnel/flink/transform/DataStreamToTable.java
Patch:
@@ -31,7 +31,7 @@
 import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;
 import org.apache.flink.types.Row;
 
-public class DataStreamToTable implements FlinkStreamTransform<Row, Row>, FlinkBatchTransform<Row, Row> {
+public class DataStreamToTable implements FlinkStreamTransform, FlinkBatchTransform {
 
     private static final long serialVersionUID = -7861928245025199286L;
     private Config config;

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-split/src/main/java/org/apache/seatunnel/flink/transform/Split.java
Patch:
@@ -34,7 +34,7 @@
 
 import java.util.List;
 
-public class Split implements FlinkStreamTransform<Row, Row>, FlinkBatchTransform<Row, Row> {
+public class Split implements FlinkStreamTransform, FlinkBatchTransform {
 
     private Config config;
 

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-sql/src/main/java/org/apache/seatunnel/flink/transform/Sql.java
Patch:
@@ -33,7 +33,7 @@
 import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;
 import org.apache.flink.types.Row;
 
-public class Sql implements FlinkStreamTransform<Row, Row>, FlinkBatchTransform<Row, Row> {
+public class Sql implements FlinkStreamTransform, FlinkBatchTransform {
 
     private String sql;
 

File: seatunnel-transforms/seatunnel-transforms-flink/seatunnel-transform-flink-table2datastream/src/main/java/org/apache/seatunnel/flink/transform/TableToDataStream.java
Patch:
@@ -34,7 +34,7 @@
 import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;
 import org.apache.flink.types.Row;
 
-public class TableToDataStream implements FlinkStreamTransform<Row, Row>, FlinkBatchTransform<Row, Row> {
+public class TableToDataStream implements FlinkStreamTransform, FlinkBatchTransform {
 
     private static final long serialVersionUID = 4556842426965038124L;
     private Config config;

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/util/SchemaUtil.java
Patch:
@@ -155,7 +155,6 @@ public static TypeInformation<?>[] getCsvType(List<Map<String, String>> schemaLi
         return typeInformation;
     }
 
-
     /**
      * todo
      *
@@ -166,7 +165,6 @@ private static void getOrcSchema(Schema schema, JSONObject json) {
 
     }
 
-
     /**
      * todo
      *

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/config/ConfigBuilder.java
Patch:
@@ -165,7 +165,6 @@ private <T extends Plugin<?>> T createPluginInstanceIgnoreCase(String name, Plug
         throw new ClassNotFoundException("Plugin class not found by name :[" + canonicalName + "]");
     }
 
-
     /**
      * check if config is valid.
      **/

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/utils/CompressionUtils.java
Patch:
@@ -53,7 +53,7 @@ private CompressionUtils() {
      * @param outputDir the output directory file.
      * @throws IOException           io exception
      * @throws FileNotFoundException file not found exception
-     * @throws ArchiveException      a rchive exception
+     * @throws ArchiveException      archive exception
      */
     public static void unTar(final File inputFile, final File outputDir) throws FileNotFoundException, IOException, ArchiveException {
 

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchExecution.java
Patch:
@@ -67,6 +67,7 @@ public void start(List<FlinkBatchSource> sources, List<FlinkBatchTransform> tran
             }
             input = transform.processBatch(flinkEnvironment, dataSet);
             registerResultTable(transform, input);
+            transform.registerFunction(flinkEnvironment);
         }
 
         for (FlinkBatchSink sink : sinks) {

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/config/command/CommandLineUtils.java
Patch:
@@ -48,7 +48,7 @@ public static CommandLineArgs parseFlinkArgs(String[] args) {
         return new CommandLineArgs(
             commandFlinkArgs.getConfigFile(),
             commandFlinkArgs.isTestConfig(),
-            commandFlinkArgs.getVariable()
+            commandFlinkArgs.getVariables()
         );
     }
 

File: seatunnel-core/seatunnel-core-sql/src/main/java/org/apache/seatunnel/core/sql/SeatunnelSql.java
Patch:
@@ -40,7 +40,7 @@ private static JobInfo parseJob(String[] args) throws IOException {
         String configFilePath = flinkArgs.getConfigFile();
         String jobContent = FileUtils.readFileToString(new File(configFilePath), StandardCharsets.UTF_8);
         JobInfo jobInfo = new JobInfo(jobContent);
-        jobInfo.substitute(flinkArgs.getVariable());
+        jobInfo.substitute(flinkArgs.getVariables());
         return jobInfo;
     }
 

File: seatunnel-core/seatunnel-core-sql/src/test/java/org/apache/seatunnel/core/sql/SqlVariableSubstitutionTest.java
Patch:
@@ -42,7 +42,7 @@ public void normalizeStatementsWithMultiSqls() throws Exception {
         JobInfo jobInfo = new JobInfo(jobContent);
         Assert.assertFalse(jobInfo.getJobContent().contains("events"));
 
-        jobInfo.substitute(flinkArgs.getVariable());
+        jobInfo.substitute(flinkArgs.getVariables());
         Assert.assertTrue(jobInfo.getJobContent().contains("events"));
     }
 

File: seatunnel-connectors/seatunnel-connector-flink-file/src/main/java/org/apache/seatunnel/flink/sink/JsonRowOutputFormat.java
Patch:
@@ -20,6 +20,7 @@
 import com.alibaba.fastjson.JSONArray;
 import com.alibaba.fastjson.JSONObject;
 import org.apache.flink.api.common.io.FileOutputFormat;
+import org.apache.flink.api.common.typeinfo.AtomicType;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.java.typeutils.ObjectArrayTypeInfo;
 import org.apache.flink.api.java.typeutils.RowTypeInfo;
@@ -98,7 +99,7 @@ private JSONObject getJson(Row record, RowTypeInfo rowTypeInfo) {
         for (String name : fieldNames) {
             Object field = record.getField(i);
             final TypeInformation type = rowTypeInfo.getTypeAt(i);
-            if (type.isBasicType()) {
+            if (type instanceof AtomicType) {
                 json.put(name, field);
             } else if (type instanceof ObjectArrayTypeInfo) {
                 ObjectArrayTypeInfo arrayTypeInfo = (ObjectArrayTypeInfo) type;

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/utils/SparkStructTypeUtil.java
Patch:
@@ -64,7 +64,7 @@ public static StructType getStructType(StructType schema, JSONObject json) {
     }
 
     private static DataType getType(String type) {
-        DataType dataType = DataTypes.NullType;
+        DataType dataType;
         switch (type.toLowerCase()) {
             case "string":
                 dataType = DataTypes.StringType;

File: seatunnel-connectors/seatunnel-connector-flink-doris/src/main/java/org/apache/seatunnel/flink/sink/DorisSink.java
Patch:
@@ -57,7 +57,7 @@ public class DorisSink implements FlinkStreamSink<Row, Row>, FlinkBatchSink<Row,
     private int batchSize = DEFAULT_BATCH_SIZE;
     private long batchIntervalMs = DEFAULT_INTERVAL_MS;
     private int maxRetries = 1;
-    private Properties streamLoadProp = new Properties();
+    private final Properties streamLoadProp = new Properties();
 
     @Override
     public Config getConfig() {

File: seatunnel-connectors/seatunnel-connector-flink-druid/src/main/java/org/apache/seatunnel/flink/sink/DruidOutputFormat.java
Patch:
@@ -102,7 +102,7 @@ public void writeRecord(Row element) {
                 this.data.append(DEFAULT_FIELD_DELIMITER);
             }
             if (v != null) {
-                this.data.append(v.toString());
+                this.data.append(v);
             }
         }
         this.data.append(DEFAULT_LINE_DELIMITER);

File: seatunnel-connectors/seatunnel-connector-flink-elasticsearch/src/main/java/org/apache/seatunnel/flink/sink/ElasticsearchOutputFormat.java
Patch:
@@ -83,12 +83,15 @@ public void configure(Configuration configuration) {
         }
 
         BulkProcessor.Builder bulkProcessorBuilder = BulkProcessor.builder(transportClient, new BulkProcessor.Listener() {
+            @Override
             public void beforeBulk(long executionId, BulkRequest request) {
             }
 
+            @Override
             public void afterBulk(long executionId, BulkRequest request, BulkResponse response) {
             }
 
+            @Override
             public void afterBulk(long executionId, BulkRequest request, Throwable failure) {
             }
         });

File: seatunnel-connectors/seatunnel-connector-flink-file/src/main/java/org/apache/seatunnel/flink/sink/FileSink.java
Patch:
@@ -81,8 +81,7 @@ public DataSink<Row> outputBatch(FlinkEnvironment env, DataSet<Row> dataSet) {
                 outputFormat = new JsonRowOutputFormat(filePath, rowTypeInfo);
                 break;
             case "csv":
-                CsvRowOutputFormat csvFormat = new CsvRowOutputFormat(filePath);
-                outputFormat = csvFormat;
+                outputFormat = new CsvRowOutputFormat(filePath);
                 break;
             case "text":
                 outputFormat = new TextOutputFormat(filePath);

File: seatunnel-connectors/seatunnel-connector-flink-socket/src/main/java/org/apache/seatunnel/flink/source/SocketStream.java
Patch:
@@ -27,7 +27,6 @@
 import org.apache.flink.api.java.typeutils.RowTypeInfo;
 import org.apache.flink.api.scala.typeutils.Types;
 import org.apache.flink.streaming.api.datastream.DataStream;
-import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.types.Row;
 
@@ -46,13 +45,12 @@ public class SocketStream implements FlinkStreamSource<Row> {
     @Override
     public DataStream<Row> getData(FlinkEnvironment env) {
         final StreamExecutionEnvironment environment = env.getStreamExecutionEnvironment();
-        final SingleOutputStreamOperator<Row> operator = environment.socketTextStream(host, port)
+        return environment.socketTextStream(host, port)
                 .map((MapFunction<String, Row>) value -> {
                     Row row = new Row(1);
                     row.setField(0, value);
                     return row;
                 }).returns(new RowTypeInfo(Types.STRING()));
-        return operator;
     }
 
     @Override

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/Seatunnel.java
Patch:
@@ -103,10 +103,11 @@ private static void entryPoint(String configFile, Engine engine) throws Exceptio
         execution.start(sources, transforms, sinks);
     }
 
+    @SafeVarargs
     private static void baseCheckConfig(List<? extends Plugin>... plugins) {
         for (List<? extends Plugin> pluginList : plugins) {
             for (Plugin plugin : pluginList) {
-                CheckResult checkResult = null;
+                CheckResult checkResult;
                 try {
                     checkResult = plugin.checkConfig();
                 } catch (Exception e) {

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/batch/SparkBatchExecution.java
Patch:
@@ -44,7 +44,7 @@ public SparkBatchExecution(SparkEnvironment environment) {
     }
 
     public static void registerTempView(String tableName, Dataset<Row> ds) {
-        ds.createOrReplaceGlobalTempView(tableName);
+        ds.createOrReplaceTempView(tableName);
     }
 
     public static void registerInputTempView(BaseSparkSource<Dataset<Row>> source, SparkEnvironment environment) {
@@ -96,7 +96,7 @@ public void start(List<SparkBatchSource> sources, List<BaseSparkTransform> trans
         if (!sources.isEmpty()) {
             Dataset<Row> ds = sources.get(0).getData(environment);
             for (BaseSparkTransform transform : transforms) {
-                if (ds.head().size() > 0) {
+                if (ds.takeAsList(1).size() > 0) {
                     ds = SparkBatchExecution.transformProcess(environment, transform, ds);
                     SparkBatchExecution.registerTransformTempView(transform, ds);
                 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/FlinkEnvironment.java
Patch:
@@ -81,8 +81,8 @@ public void prepare(Boolean isStreaming) {
             createStreamEnvironment();
             createStreamTableEnvironment();
         } else {
-            createBatchTableEnvironment();
             createExecutionEnvironment();
+            createBatchTableEnvironment();
         }
         if (config.hasPath("job.name")) {
             jobName = config.getString("job.name");

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/config/ConfigBuilder.java
Patch:
@@ -190,7 +190,7 @@ private RuntimeEnv createEnv() {
                 env = new FlinkEnvironment();
                 break;
             default:
-                break;
+                throw new IllegalArgumentException("Engine: " + engine + " is not supported");
         }
         env.setConfig(envConfig);
         env.prepare(streaming);

File: seatunnel-apis/seatunnel-api-spark/src/main/java/org/apache/seatunnel/spark/batch/SparkBatchExecution.java
Patch:
@@ -85,7 +85,7 @@ public static void sinkProcess(SparkEnvironment environment, BaseSparkSink<?> si
         Dataset<Row> fromDs;
         Config config = sink.getConfig();
         if (config.hasPath(SparkBatchExecution.SOURCE_TABLE_NAME)) {
-            String sourceTableName = config.getString(SparkBatchExecution.RESULT_TABLE_NAME);
+            String sourceTableName = config.getString(SparkBatchExecution.SOURCE_TABLE_NAME);
             fromDs = environment.getSparkSession().read().table(sourceTableName);
         } else {
             fromDs = ds;

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/config/CheckConfigUtil.java
Patch:
@@ -56,7 +56,7 @@ public static CheckResult checkAtLeastOneExists(Config config, String... params)
             return CheckResult.success();
         }
 
-        List<String> missingParams = new LinkedList();
+        List<String> missingParams = new LinkedList<>();
         for (String param : params) {
             if (!config.hasPath(param) || config.getAnyRef(param) == null) {
                 missingParams.add(param);

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/utils/StringTemplate.java
Patch:
@@ -37,7 +37,7 @@ public static String substitute(String str, String timeFormat) {
         final SimpleDateFormat sdf = new SimpleDateFormat(timeFormat);
         final String formattedDate = sdf.format(new Date());
 
-        final Map<String, String> valuesMap = new HashMap(3);
+        final Map<String, String> valuesMap = new HashMap<>(3);
         valuesMap.put("uuid", UUID.randomUUID().toString());
         valuesMap.put("now", formattedDate);
         valuesMap.put(timeFormat, formattedDate);

File: seatunnel-config/seatunnel-config-shade/src/main/java/org/apache/seatunnel/shade/com/typesafe/config/ConfigParseOptions.java
Patch:
@@ -2,7 +2,7 @@
  *   Copyright (C) 2011-2012 Typesafe Inc. <http://typesafe.com>
  */
 
-package com.typesafe.config;
+package org.apache.seatunnel.shade.com.typesafe.config;
 
 /**
  * A set of options related to parsing.

File: seatunnel-config/seatunnel-config-shade/src/main/java/org/apache/seatunnel/shade/com/typesafe/config/impl/Path.java
Patch:
@@ -2,10 +2,10 @@
  *   Copyright (C) 2011-2012 Typesafe Inc. <http://typesafe.com>
  */
 
-package com.typesafe.config.impl;
+package org.apache.seatunnel.shade.com.typesafe.config.impl;
 
-import com.typesafe.config.ConfigException;
-import com.typesafe.config.ConfigParseOptions;
+import org.apache.seatunnel.shade.com.typesafe.config.ConfigException;
+import org.apache.seatunnel.shade.com.typesafe.config.ConfigParseOptions;
 
 import java.util.Iterator;
 import java.util.List;

File: seatunnel-config/seatunnel-config-shade/src/test/java/org/apache/seatunnel/config/CompleteTest.java
Patch:
@@ -19,9 +19,9 @@
 
 import org.apache.seatunnel.config.utils.FileUtils;
 
-import com.typesafe.config.Config;
-import com.typesafe.config.ConfigFactory;
-import com.typesafe.config.ConfigResolveOptions;
+import org.apache.seatunnel.shade.com.typesafe.config.Config;
+import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;
+import org.apache.seatunnel.shade.com.typesafe.config.ConfigResolveOptions;
 import org.junit.Assert;
 import org.junit.Test;
 

File: seatunnel-config/seatunnel-config-shade/src/test/java/org/apache/seatunnel/config/ConfigFactoryTest.java
Patch:
@@ -19,8 +19,8 @@
 
 import org.apache.seatunnel.config.utils.FileUtils;
 
-import com.typesafe.config.Config;
-import com.typesafe.config.ConfigFactory;
+import org.apache.seatunnel.shade.com.typesafe.config.Config;
+import org.apache.seatunnel.shade.com.typesafe.config.ConfigFactory;
 import org.junit.Assert;
 import org.junit.Test;
 

File: seatunnel-config/src/main/java/com/typesafe/config/ConfigParseOptions.java
Patch:
@@ -1,4 +1,4 @@
-/**
+/*
  *   Copyright (C) 2011-2012 Typesafe Inc. <http://typesafe.com>
  */
 

File: seatunnel-config/src/main/java/com/typesafe/config/impl/ConfigNodePath.java
Patch:
@@ -1,6 +1,7 @@
-/**
+/*
  *   Copyright (C) 2011-2012 Typesafe Inc. <http://typesafe.com>
  */
+
 package com.typesafe.config.impl;
 
 import com.typesafe.config.ConfigException;

File: seatunnel-config/src/main/java/com/typesafe/config/impl/ConfigParser.java
Patch:
@@ -1,4 +1,4 @@
-/**
+/*
  *   Copyright (C) 2011-2012 Typesafe Inc. <http://typesafe.com>
  */
 

File: seatunnel-config/src/main/java/com/typesafe/config/impl/Path.java
Patch:
@@ -1,4 +1,4 @@
-/**
+/*
  *   Copyright (C) 2011-2012 Typesafe Inc. <http://typesafe.com>
  */
 

File: seatunnel-config/src/main/java/com/typesafe/config/impl/PathParser.java
Patch:
@@ -1,4 +1,4 @@
-/**
+/*
  *   Copyright (C) 2011-2012 Typesafe Inc. <http://typesafe.com>
  */
 

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchSink.java
Patch:
@@ -23,10 +23,13 @@
 import org.apache.flink.api.java.DataSet;
 import org.apache.flink.api.java.operators.DataSink;
 
+import javax.annotation.Nullable;
+
 /**
  * a FlinkBatchSink plugin will write data to other system using Flink DataSet API.
  */
 public interface FlinkBatchSink<IN, OUT> extends BaseFlinkSink {
 
+    @Nullable
     DataSink<OUT> outputBatch(FlinkEnvironment env, DataSet<IN> inDataSet);
 }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/stream/FlinkStreamSink.java
Patch:
@@ -23,11 +23,14 @@
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.datastream.DataStreamSink;
 
+import javax.annotation.Nullable;
+
 /**
  * a FlinkStreamSink plugin will write data to other system using Flink DataStream API.
  */
 public interface FlinkStreamSink<IN, OUT> extends BaseFlinkSink {
 
+    @Nullable
     DataStreamSink<OUT> outputStream(FlinkEnvironment env, DataStream<IN> dataStream);
 
 }

File: seatunnel-connectors/seatunnel-connector-flink-doris/src/main/java/org/apache/seatunnel/flink/sink/DorisSink.java
Patch:
@@ -36,6 +36,8 @@
 import org.apache.flink.types.Row;
 import org.apache.flink.util.Preconditions;
 
+import javax.annotation.Nullable;
+
 import java.util.Properties;
 import java.util.concurrent.TimeUnit;
 
@@ -113,6 +115,7 @@ public DataSink<Row> outputBatch(FlinkEnvironment env, DataSet<Row> dataSet) {
     }
 
     @Override
+    @Nullable
     public DataStreamSink<Row> outputStream(FlinkEnvironment env, DataStream<Row> dataStream) {
         StreamTableEnvironment tableEnvironment = env.getStreamTableEnvironment();
         Table table = tableEnvironment.fromDataStream(dataStream);

File: seatunnel-connectors/seatunnel-connector-flink-druid/src/main/java/org/apache/seatunnel/flink/source/DruidInputFormat.java
Patch:
@@ -31,6 +31,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import javax.annotation.Nullable;
+
 import java.io.IOException;
 import java.math.BigDecimal;
 import java.sql.Array;
@@ -170,6 +172,7 @@ public boolean reachedEnd() {
     }
 
     @Override
+    @Nullable
     public Row nextRecord(Row row) throws IOException {
         try {
             if (!hasNext) {

File: seatunnel-connectors/seatunnel-connector-flink-kafka/src/main/java/org/apache/seatunnel/flink/sink/KafkaTable.java
Patch:
@@ -38,6 +38,8 @@
 import org.apache.flink.table.descriptors.Schema;
 import org.apache.flink.types.Row;
 
+import javax.annotation.Nullable;
+
 import java.util.Properties;
 
 public class KafkaTable implements FlinkStreamSink<Row, Row> {
@@ -48,6 +50,7 @@ public class KafkaTable implements FlinkStreamSink<Row, Row> {
     private String topic;
 
     @Override
+    @Nullable
     public DataStreamSink<Row> outputStream(FlinkEnvironment env, DataStream<Row> dataStream) {
         StreamTableEnvironment tableEnvironment = env.getStreamTableEnvironment();
         Table table = tableEnvironment.fromDataStream(dataStream);

File: seatunnel-connectors/seatunnel-connector-flink-doris/src/main/java/org/apache/seatunnel/flink/sink/DorisOutputFormat.java
Patch:
@@ -43,7 +43,7 @@
  * DorisDynamicOutputFormat
  **/
 public class DorisOutputFormat<T> extends RichOutputFormat<T> {
-    private static final Logger LOGGER = LoggerFactory.getLogger(DorisSinkFunction.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(DorisOutputFormat.class);
     private static final long DEFAULT_INTERVAL_MS = TimeUnit.SECONDS.toMillis(1);
     private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
     private static final String FIELD_DELIMITER_KEY = "column_separator";

File: seatunnel-connectors/seatunnel-connector-flink-file/src/main/java/org/apache/seatunnel/flink/sink/FileSink.java
Patch:
@@ -60,8 +60,9 @@ public DataStreamSink<Row> outputStream(FlinkEnvironment env, DataStream<Row> da
 
         final StreamingFileSink<Row> sink = StreamingFileSink
                 .forRowFormat(filePath, (Encoder<Row>) (element, stream) -> {
-                    PrintStream out = new PrintStream(stream);
-                    out.println(element);
+                    try (PrintStream out = new PrintStream(stream)) {
+                        out.println(element);
+                    }
                 })
                 .build();
         return dataStream.addSink(sink);

File: seatunnel-connectors/seatunnel-connector-flink-doris/src/main/java/org/apache/seatunnel/flink/sink/DorisOutputFormat.java
Patch:
@@ -44,6 +44,7 @@
  **/
 public class DorisOutputFormat<T> extends RichOutputFormat<T> {
     private static final Logger LOGGER = LoggerFactory.getLogger(DorisSinkFunction.class);
+    private static final long DEFAULT_INTERVAL_MS = TimeUnit.SECONDS.toMillis(1);
     private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
     private static final String FIELD_DELIMITER_KEY = "column_separator";
     private static final String FIELD_DELIMITER_DEFAULT = "\t";
@@ -219,7 +220,7 @@ public synchronized void flush() throws IOException {
                     throw new IOException(e);
                 }
                 try {
-                    Thread.sleep(1000L * i);
+                    Thread.sleep(DEFAULT_INTERVAL_MS * i);
                 } catch (InterruptedException ex) {
                     Thread.currentThread().interrupt();
                     throw new IOException("unable to flush; interrupted while doing another attempt", e);

File: seatunnel-connectors/seatunnel-connector-flink-doris/src/main/java/org/apache/seatunnel/flink/sink/DorisStreamLoad.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.seatunnel.flink.sink;
 
 import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;
+import org.apache.flink.shaded.netty4.io.netty.handler.codec.http.HttpResponseStatus;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -83,7 +84,7 @@ private HttpURLConnection getConnection(String urlStr, String label) throws IOEx
     public void load(String value) {
         LoadResponse loadResponse = loadBatch(value);
         LOGGER.info("Streamload Response:{}", loadResponse);
-        if (loadResponse.status != 200) {
+        if (loadResponse.status != HttpResponseStatus.OK.code()) {
             throw new RuntimeException("stream load error: " + loadResponse.respContent);
         } else {
             try {
@@ -111,7 +112,7 @@ private LoadResponse loadBatch(String data) {
             feConn = getConnection(loadUrlStr, label);
             int status = feConn.getResponseCode();
             // fe send back http response code TEMPORARY_REDIRECT 307 and new be location
-            if (status != 307) {
+            if (status != HttpResponseStatus.TEMPORARY_REDIRECT.code()) {
                 throw new Exception("status is not TEMPORARY_REDIRECT 307, status: " + status);
             }
             String location = feConn.getHeaderField("Location");

File: seatunnel-connectors/seatunnel-connector-flink-elasticsearch/src/main/java/org/apache/seatunnel/flink/sink/Elasticsearch.java
Patch:
@@ -93,8 +93,8 @@ public DataStreamSink<Row> outputStream(FlinkEnvironment env, DataStream<Row> da
                 httpHosts,
                 new ElasticsearchSinkFunction<Row>() {
                     public IndexRequest createIndexRequest(Row element) {
-                        Map<String, Object> json = new HashMap<>(100);
                         int elementLen = element.getArity();
+                        Map<String, Object> json = new HashMap<>(elementLen);
                         for (int i = 0; i < elementLen; i++) {
                             json.put(fieldNames[i], element.getField(i));
                         }
@@ -132,8 +132,8 @@ public void process(Row element, RuntimeContext ctx, RequestIndexer indexer) {
             }
 
             private IndexRequest createIndexRequest(Row element) {
-                Map<String, Object> json = new HashMap<>(100);
                 int elementLen = element.getArity();
+                Map<String, Object> json = new HashMap<>(elementLen);
                 for (int i = 0; i < elementLen; i++) {
                     json.put(fieldNames[i], element.getField(i));
                 }

File: seatunnel-connectors/seatunnel-connector-flink-file/src/main/java/org/apache/seatunnel/flink/sink/CsvRowOutputFormat.java
Patch:
@@ -30,8 +30,8 @@
 
 public class CsvRowOutputFormat extends FileOutputFormat<Row> {
 
+    private static final int STREAM_BUFFER_SIZE = 4096;
     public static final String DEFAULT_LINE_DELIMITER = CsvInputFormat.DEFAULT_LINE_DELIMITER;
-
     public static final String DEFAULT_FIELD_DELIMITER = CsvInputFormat.DEFAULT_FIELD_DELIMITER;
 
     private transient Writer wrt;
@@ -131,8 +131,8 @@ public void setQuoteStrings(boolean quoteStrings) {
     @Override
     public void open(int taskNumber, int numTasks) throws IOException {
         super.open(taskNumber, numTasks);
-        this.wrt = this.charsetName == null ? new OutputStreamWriter(new BufferedOutputStream(this.stream, 4096)) :
-                new OutputStreamWriter(new BufferedOutputStream(this.stream, 4096), this.charsetName);
+        this.wrt = this.charsetName == null ? new OutputStreamWriter(new BufferedOutputStream(this.stream, STREAM_BUFFER_SIZE)) :
+                new OutputStreamWriter(new BufferedOutputStream(this.stream, STREAM_BUFFER_SIZE), this.charsetName);
     }
 
     @Override

File: seatunnel-connectors/seatunnel-connector-flink-file/src/main/java/org/apache/seatunnel/flink/source/FileSource.java
Patch:
@@ -43,6 +43,8 @@
 
 public class FileSource implements FlinkBatchSource<Row> {
 
+    private static final int DEFAULT_BATCH_SIZE = 1000;
+
     private Config config;
 
     private InputFormat inputFormat;
@@ -90,7 +92,7 @@ public void prepare(FlinkEnvironment env) {
                 inputFormat = new ParquetRowInputFormat(filePath, messageType);
                 break;
             case "orc":
-                OrcRowInputFormat orcRowInputFormat = new OrcRowInputFormat(path, schemaContent, null, 1000);
+                OrcRowInputFormat orcRowInputFormat = new OrcRowInputFormat(path, schemaContent, null, DEFAULT_BATCH_SIZE);
                 this.inputFormat = orcRowInputFormat;
                 break;
             case "csv":

File: seatunnel-connectors/seatunnel-connector-flink-jdbc/src/main/java/org/apache/seatunnel/flink/sink/JdbcSink.java
Patch:
@@ -37,13 +37,15 @@
 
 public class JdbcSink implements FlinkStreamSink<Row, Row>, FlinkBatchSink<Row, Row> {
 
+    private static final int DEFAULT_BATCH_SIZE = 5000;
+
     private Config config;
     private String driverName;
     private String dbUrl;
     private String username;
     private String password;
     private String query;
-    private int batchSize = 5000;
+    private int batchSize = DEFAULT_BATCH_SIZE;
 
     @Override
     public void setConfig(Config config) {

File: seatunnel-connectors/seatunnel-connector-flink-kafka/src/main/java/org/apache/seatunnel/flink/source/KafkaTableStream.java
Patch:
@@ -62,6 +62,7 @@ public class KafkaTableStream implements FlinkStreamSource<Row> {
     private static final String GROUP_ID = "group.id";
     private static final String BOOTSTRAP_SERVERS = "bootstrap.servers";
     private static final String OFFSET_RESET = "offset.reset";
+    private static final int DEFAULT_INITIAL_CAPACITY = 16;
 
     @Override
     public void setConfig(Config config) {
@@ -142,7 +143,7 @@ private Kafka getKafkaConnect() {
                     break;
                 case "specific":
                     String offset = config.getString("offset.reset.specific");
-                    HashMap<Integer, Long> map = new HashMap<>(16);
+                    HashMap<Integer, Long> map = new HashMap<>(DEFAULT_INITIAL_CAPACITY);
                     JSONObject.parseObject(offset).forEach((k, v) -> map.put(Integer.valueOf(k), Long.valueOf(v.toString())));
                     kafka.startFromSpecificOffsets(map);
                     break;

File: seatunnel-connectors/seatunnel-connector-flink-socket/src/main/java/org/apache/seatunnel/flink/source/SocketStream.java
Patch:
@@ -36,10 +36,10 @@ public class SocketStream implements FlinkStreamSource<Row> {
 
     private static final String HOST = "host";
     private static final String PORT = "port";
+    private static final int DEFAULT_PORT = 9999;
 
     private String host = "localhost";
-
-    private int port = 9999;
+    private int port = DEFAULT_PORT;
 
     @Override
     public DataStream<Row> getData(FlinkEnvironment env) {

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/Constants.java
Patch:
@@ -22,6 +22,8 @@ public final class Constants {
     public static final String ROW_TMP = "__tmp__";
     public static final String ROW_JSON = "__json__";
 
+    public static final String LOGO = "SeaTunnel";
+
     public static final String CHECK_SUCCESS = "All check is success";
 
     private Constants() {

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/Seatunnel.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.seatunnel.apis.BaseSink;
 import org.apache.seatunnel.apis.BaseSource;
 import org.apache.seatunnel.apis.BaseTransform;
+import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.common.config.Common;
 import org.apache.seatunnel.common.config.ConfigRuntimeException;
@@ -158,7 +159,7 @@ private static void prepare(RuntimeEnv env, List<? extends Plugin>... plugins) {
     private static void showAsciiLogo() {
         String printAsciiLogo = System.getenv("SEATUNNEL_PRINT_ASCII_LOGO");
         if ("true".equalsIgnoreCase(printAsciiLogo)) {
-            AsciiArtUtils.printAsciiArt(printAsciiLogo);
+            AsciiArtUtils.printAsciiArt(Constants.LOGO);
         }
     }
 

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/batch/FlinkBatchExecution.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.flink.batch;
 
+import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.env.Execution;
 import org.apache.seatunnel.flink.FlinkEnvironment;
@@ -120,7 +121,7 @@ public Config getConfig() {
 
     @Override
     public CheckResult checkConfig() {
-        return new CheckResult(true, "");
+        return new CheckResult(true, Constants.CHECK_SUCCESS);
     }
 
     @Override

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/stream/FlinkStreamExecution.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.flink.stream;
 
+import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.env.Execution;
 import org.apache.seatunnel.flink.FlinkEnvironment;
@@ -120,7 +121,7 @@ public Config getConfig() {
 
     @Override
     public CheckResult checkConfig() {
-        return new CheckResult(true, "");
+        return new CheckResult(true, Constants.CHECK_SUCCESS);
     }
 
     @Override

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/util/EnvironmentUtil.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.flink.util;
 
+import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.flink.api.common.ExecutionConfig;
@@ -76,9 +77,9 @@ public static CheckResult checkRestartStrategy(Config config) {
                     }
                     break;
                 default:
-                    return new CheckResult(true, "");
+                    return new CheckResult(true, Constants.CHECK_SUCCESS);
             }
         }
-        return new CheckResult(true, "");
+        return new CheckResult(true, Constants.CHECK_SUCCESS);
     }
 }

File: seatunnel-common/src/main/java/org/apache/seatunnel/common/config/CheckConfigUtil.java
Patch:
@@ -19,6 +19,8 @@
 
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 
+import static org.apache.seatunnel.common.Constants.CHECK_SUCCESS;
+
 public class CheckConfigUtil {
 
     public static CheckResult check(Config config, String... params) {
@@ -34,7 +36,7 @@ public static CheckResult check(Config config, String... params) {
                     missingParams.deleteCharAt(missingParams.length() - 1));
             return new CheckResult(false, errorMsg);
         } else {
-            return new CheckResult(true, "");
+            return new CheckResult(true, CHECK_SUCCESS);
         }
     }
 }

File: seatunnel-connectors/seatunnel-connector-flink-console/src/main/java/org/apache/seatunnel/flink/sink/ConsoleSink.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.flink.sink;
 
+import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.flink.FlinkEnvironment;
 import org.apache.seatunnel.flink.batch.FlinkBatchSink;
@@ -58,7 +59,7 @@ public Config getConfig() {
 
     @Override
     public CheckResult checkConfig() {
-        return new CheckResult(true, "");
+        return new CheckResult(true, Constants.CHECK_SUCCESS);
     }
 
     @Override

File: seatunnel-connectors/seatunnel-connector-flink-fake/src/main/java/org/apache/seatunnel/flink/source/FakeSourceStream.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;
 import org.apache.flink.streaming.api.functions.source.SourceFunction.SourceContext;
 import org.apache.flink.types.Row;
+import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.flink.FlinkEnvironment;
@@ -55,7 +56,7 @@ public Config getConfig() {
 
     @Override
     public CheckResult checkConfig() {
-        return new CheckResult(true, "");
+        return new CheckResult(true, Constants.CHECK_SUCCESS);
     }
 
     @Override

File: seatunnel-connectors/seatunnel-connector-flink-socket/src/main/java/org/apache/seatunnel/flink/source/SocketStream.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.seatunnel.flink.source;
 
+import org.apache.seatunnel.common.Constants;
 import org.apache.seatunnel.shade.com.typesafe.config.Config;
 import org.apache.seatunnel.common.config.CheckResult;
 import org.apache.seatunnel.flink.FlinkEnvironment;
@@ -64,7 +65,7 @@ public Config getConfig() {
 
     @Override
     public CheckResult checkConfig() {
-        return new CheckResult(true, "");
+        return new CheckResult(true, Constants.CHECK_SUCCESS);
     }
 
     @Override

File: seatunnel-examples/seatunnel-flink-examples/src/main/java/org/apache/seatunnel/example/flink/LocalFlinkExample.java
Patch:
@@ -15,14 +15,14 @@
  * limitations under the License.
  */
 
-package org.apache.seatunnel.test.flink;
+package org.apache.seatunnel.example.flink;
 
 import static org.apache.seatunnel.utils.Engine.FLINK;
 
 import org.apache.seatunnel.Seatunnel;
 import org.apache.seatunnel.config.command.CommandLineArgs;
 
-public class LocalTest {
+public class LocalFlinkExample {
 
     public static final String TEST_RESOURCE_DIR = "/seatunnel-examples/seatunnel-flink-examples/src/main/resources/examples/";
 

File: seatunnel-examples/seatunnel-flink-examples/src/main/java/org/apache/seatunnel/test/flink/LocalTest.java
Patch:
@@ -27,7 +27,7 @@ public class LocalTest {
     public static final String TEST_RESOURCE_DIR = "/seatunnel-examples/seatunnel-flink-examples/src/main/resources/examples/";
 
     public static void main(String[] args) {
-        String configFile = getTestConfigFile("fake_to_console.config");
+        String configFile = getTestConfigFile("fake_to_console.conf");
         CommandLineArgs flinkArgs = new CommandLineArgs(configFile, false);
         Seatunnel.run(flinkArgs, FLINK, args);
     }

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/utils/CompressionUtils.java
Patch:
@@ -92,7 +92,7 @@ public static List<File> unTar(final File inputFile, final File outputDir) throw
      *
      * @param inputFile the input .gz file
      * @param outputDir the output directory file.
-     * @return The {@File} with the ungzipped content.
+     * @return The {@link File} with the ungzipped content.
      * @throws IOException           io exception
      * @throws FileNotFoundException file not found exception
      */

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/FlinkEnvironment.java
Patch:
@@ -41,7 +41,7 @@
 
 public class FlinkEnvironment implements RuntimeEnv {
 
-    private static final Logger LOG = LoggerFactory.getLogger(FlinkEnvironment.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(FlinkEnvironment.class);
 
     private Config config;
 
@@ -172,7 +172,7 @@ private void setTimeCharacteristic() {
                     environment.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime);
                     break;
                 default:
-                    LOG.warn("set time-characteristic failed, unknown time-characteristic [{}],only support event-time,ingestion-time,processing-time", timeType);
+                    LOGGER.warn("set time-characteristic failed, unknown time-characteristic [{}],only support event-time,ingestion-time,processing-time", timeType);
                     break;
             }
         }
@@ -194,7 +194,7 @@ private void setCheckpoint() {
                         checkpointConfig.setCheckpointingMode(CheckpointingMode.AT_LEAST_ONCE);
                         break;
                     default:
-                        LOG.warn("set checkpoint.mode failed, unknown checkpoint.mode [{}],only support exactly-once,at-least-once", mode);
+                        LOGGER.warn("set checkpoint.mode failed, unknown checkpoint.mode [{}],only support exactly-once,at-least-once", mode);
                         break;
                 }
             }

File: seatunnel-apis/seatunnel-api-flink/src/main/java/org/apache/seatunnel/flink/util/EnvironmentUtil.java
Patch:
@@ -29,7 +29,7 @@
 
 public class EnvironmentUtil {
 
-    private static final Logger LOG = LoggerFactory.getLogger(EnvironmentUtil.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(EnvironmentUtil.class);
 
     public static void setRestartStrategy(Config config, ExecutionConfig executionConfig) {
         try {
@@ -53,7 +53,7 @@ public static void setRestartStrategy(Config config, ExecutionConfig executionCo
                                 Time.of(delayInterval, TimeUnit.MILLISECONDS)));
                         break;
                     default:
-                        LOG.warn("set restart.strategy failed, unknown restart.strategy [{}],only support no,fixed-delay,failure-rate", restartStrategy);
+                        LOGGER.warn("set restart.strategy failed, unknown restart.strategy [{}],only support no,fixed-delay,failure-rate", restartStrategy);
                 }
             }
         } catch (Exception e) {

File: seatunnel-connectors/seatunnel-connector-flink-doris/src/main/java/org/apache/seatunnel/flink/sink/DorisOutputFormat.java
Patch:
@@ -43,7 +43,7 @@
  * DorisDynamicOutputFormat
  **/
 public class DorisOutputFormat<T> extends RichOutputFormat<T> {
-    private static final Logger LOG = LoggerFactory.getLogger(DorisSinkFunction.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(DorisSinkFunction.class);
     private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
     private static final String FIELD_DELIMITER_KEY = "column_separator";
     private static final String FIELD_DELIMITER_DEFAULT = "\t";
@@ -186,7 +186,7 @@ public synchronized void close() throws IOException {
             try {
                 flush();
             } catch (Exception e) {
-                LOG.warn("Writing records to doris failed.", e);
+                LOGGER.warn("Writing records to doris failed.", e);
                 throw new RuntimeException("Writing records to doris failed.", e);
             }
         }
@@ -214,7 +214,7 @@ public synchronized void flush() throws IOException {
                 batch.clear();
                 break;
             } catch (Exception e) {
-                LOG.error("doris sink error, retry times = {}", i, e);
+                LOGGER.error("doris sink error, retry times = {}", i, e);
                 if (i >= maxRetries) {
                     throw new IOException(e);
                 }

File: seatunnel-connectors/seatunnel-connector-flink-doris/src/main/java/org/apache/seatunnel/flink/sink/DorisStreamLoad.java
Patch:
@@ -44,7 +44,7 @@
  */
 public class DorisStreamLoad implements Serializable {
 
-    private static final Logger LOG = LoggerFactory.getLogger(DorisStreamLoad.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(DorisStreamLoad.class);
     private static final List<String> DORIS_SUCCESS_STATUS = Arrays.asList("Success", "Publish Timeout");
     private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();
     private static final String LOAD_URL_PATTERN = "http://%s/api/%s/%s/_stream_load?";
@@ -82,7 +82,7 @@ private HttpURLConnection getConnection(String urlStr, String label) throws IOEx
 
     public void load(String value) {
         LoadResponse loadResponse = loadBatch(value);
-        LOG.info("Streamload Response:{}", loadResponse);
+        LOGGER.info("Streamload Response:{}", loadResponse);
         if (loadResponse.status != 200) {
             throw new RuntimeException("stream load error: " + loadResponse.respContent);
         } else {
@@ -138,7 +138,7 @@ private LoadResponse loadBatch(String data) {
             return new LoadResponse(status, respMsg, response.toString());
         } catch (Exception e) {
             String err = "failed to stream load data with label:" + label;
-            LOG.warn(err, e);
+            LOGGER.warn(err, e);
             throw new RuntimeException("stream load error: " + err);
         } finally {
             if (feConn != null) {

File: seatunnel-connectors/seatunnel-connector-flink-file/src/main/java/org/apache/seatunnel/flink/sink/FileSink.java
Patch:
@@ -43,7 +43,7 @@
 
 public class FileSink implements FlinkStreamSink<Row, Row>, FlinkBatchSink<Row, Row> {
 
-    private static final Logger LOG = LoggerFactory.getLogger(FileSink.class);
+    private static final Logger LOGGER = LoggerFactory.getLogger(FileSink.class);
 
     private static final String PATH = "path";
     private static final String FORMAT = "format";
@@ -83,7 +83,7 @@ public DataSink<Row> outputBatch(FlinkEnvironment env, DataSet<Row> dataSet) {
                 outputFormat = new TextOutputFormat(filePath);
                 break;
             default:
-                LOG.warn(" unknown file_format [{}],only support json,csv,text", format);
+                LOGGER.warn(" unknown file_format [{}],only support json,csv,text", format);
                 break;
 
         }

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/Seatunnel.java
Patch:
@@ -52,7 +52,7 @@ public static void run(CommandLineArgs commandLineArgs, Engine engine, String[]
         String configFilePath = getConfigFilePath(commandLineArgs, engine);
         boolean testConfig = commandLineArgs.isTestConfig();
         if (testConfig) {
-            new ConfigBuilder(configFilePath).checkConfig();
+            new ConfigBuilder(configFilePath, engine).checkConfig();
             LOGGER.info("config OK !");
         } else {
             try {

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/config/command/CommandFlinkArgs.java
Patch:
@@ -32,7 +32,7 @@ public class CommandFlinkArgs {
 
     @Parameter(names = {"-t", "--check"},
         description = "check config")
-    private boolean testConfig = true;
+    private boolean testConfig = false;
 
     public String getConfigFile() {
         return configFile;

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/config/command/CommandSparkArgs.java
Patch:
@@ -43,7 +43,7 @@ public class CommandSparkArgs {
 
     @Parameter(names = {"-t", "--check"},
         description = "check config")
-    private boolean testConfig = true;
+    private boolean testConfig = false;
 
     public String getConfigFile() {
         return configFile;

File: seatunnel-config/src/test/java/org/apache/seatunnel/config/CompleteTests.java
Patch:
@@ -26,7 +26,7 @@ public static void main(String[] args) {
 
         CompleteTests completeTests = new CompleteTests();
 
-        Config config = ConfigFactory.parseFile(completeTests.getFileFromResources("interestinglab/variables.conf"));
+        Config config = ConfigFactory.parseFile(completeTests.getFileFromResources("seatunnel/variables.conf"));
 
         config = config.resolve(ConfigResolveOptions.defaults().setAllowUnresolved(true))
                 .resolveWith(ConfigFactory.systemProperties(), ConfigResolveOptions.defaults().setAllowUnresolved(true));

File: seatunnel-core/seatunnel-core-base/src/main/java/org/apache/seatunnel/Seatunnel.java
Patch:
@@ -71,14 +71,14 @@ private static String getConfigFilePath(CommandLineArgs cmdArgs, Engine engine)
         String path = null;
         switch (engine) {
             case FLINK:
-                path = cmdArgs.getConfiFile();
+                path = cmdArgs.getConfigFile();
                 break;
             case SPARK:
                 final Optional<String> mode = Common.getDeployMode();
                 if (mode.isPresent() && "cluster".equals(mode.get())) {
-                    path = Paths.get(cmdArgs.getConfiFile()).getFileName().toString();
+                    path = Paths.get(cmdArgs.getConfigFile()).getFileName().toString();
                 } else {
-                    path = cmdArgs.getConfiFile();
+                    path = cmdArgs.getConfigFile();
                 }
                 break;
             default:

File: seatunnel-core/seatunnel-core-base/src/test/java/org/apache/seatunnel/config/command/CommandLineUtilsTest.java
Patch:
@@ -28,7 +28,7 @@ public void testParseSparkArgs() {
         String[] args = {"-c", "app.conf", "-e", "cluster", "-m", "local[*]"};
         CommandLineArgs commandLineArgs = CommandLineUtils.parseSparkArgs(args);
 
-        Assert.assertEquals("app.conf", commandLineArgs.getConfiFile());
+        Assert.assertEquals("app.conf", commandLineArgs.getConfigFile());
         Assert.assertEquals("cluster", commandLineArgs.getDeployMode());
     }
 

File: seatunnel-core/seatunnel-core-sql/src/main/java/org/apache/seatunnel/core/sql/SeatunnelSql.java
Patch:
@@ -36,7 +36,7 @@ public static void main(String[] args) throws Exception {
 
     private static JobInfo parseJob(String[] args) throws IOException {
         CommandLineArgs flinkArgs = CommandLineUtils.parseFlinkArgs(args);
-        String configFilePath = flinkArgs.getConfiFile();
+        String configFilePath = flinkArgs.getConfigFile();
         String jobContent = FileUtils.readFileToString(new File(configFilePath), StandardCharsets.UTF_8);
         return new JobInfo(jobContent);
     }

File: seatunnel-apis/seatunnel-api-spark/src/main/java/io/github/interestinglab/waterdrop/spark/utils/SparkSturctTypeUtil.java
Patch:
@@ -50,7 +50,7 @@ public static StructType getStructType(StructType schema, JSONObject json) {
                         newSchema = newSchema.add(field, DataTypes.createArrayType(st, true));
                     } else {
                         DataType st = getType(o.toString());
-                        newSchema = newSchema.add(field,  DataTypes.createArrayType(st, true));
+                        newSchema = newSchema.add(field, DataTypes.createArrayType(st, true));
                     }
                 }
 

File: seatunnel-common/src/main/java/io/github/interestinglab/waterdrop/common/config/TypesafeConfigUtils.java
Patch:
@@ -29,8 +29,8 @@ public class TypesafeConfigUtils {
     /**
      * Extract sub config with fixed prefix
      *
-     * @param source config source
-     * @param prefix config prefix
+     * @param source     config source
+     * @param prefix     config prefix
      * @param keepPrefix true if keep prefix
      */
     public static Config extractSubConfig(Config source, String prefix, boolean keepPrefix) {
@@ -57,6 +57,7 @@ public static Config extractSubConfig(Config source, String prefix, boolean keep
 
     /**
      * Check if config with specific prefix exists
+     *
      * @param source config source
      * @param prefix config prefix
      * @return true if it has sub config

File: seatunnel-common/src/main/java/io/github/interestinglab/waterdrop/common/utils/StringTemplate.java
Patch:
@@ -28,10 +28,10 @@
 public class StringTemplate {
 
     /**
-     * @param str raw string
+     * @param str        raw string
      * @param timeFormat example : "yyyy-MM-dd HH:mm:ss"
      * @return replaced string
-     * */
+     */
     public static String substitute(String str, String timeFormat) {
 
         final SimpleDateFormat sdf = new SimpleDateFormat(timeFormat);

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigList.java
Patch:
@@ -44,7 +44,6 @@
  * library internals assume a specific concrete implementation. Also, this
  * interface is likely to grow new methods over time, so third-party
  * implementations will break.
- *
  */
 public interface ConfigList extends List<ConfigValue>, ConfigValue {
 

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigLoadingStrategy.java
Patch:
@@ -20,10 +20,10 @@
 /**
  * This method allows you to alter default config loading strategy for all the code which
  * calls {@link ConfigFactory#load}.
- *
+ * <p>
  * Usually you don't have to implement this interface but it may be required
  * when you fixing a improperly implemented library with unavailable source code.
- *
+ * <p>
  * You have to define VM property {@code config.strategy} to replace default strategy with your own.
  */
 public interface ConfigLoadingStrategy {

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigResolver.java
Patch:
@@ -22,6 +22,7 @@
  * {@link ConfigResolveOptions#appendResolver ConfigResolveOptions.appendResolver()}
  * to provide custom behavior when unresolved substitutions are encountered
  * during resolution.
+ *
  * @since 1.3.2
  */
 public interface ConfigResolver {
@@ -41,7 +42,7 @@ public interface ConfigResolver {
     /**
      * Returns a new resolver that falls back to the given resolver if this
      * one doesn't provide a substitution itself.
-     *
+     * <p>
      * It's important to handle the case where you already have the fallback
      * with a "return this", i.e. this method should not create a new object if
      * the fallback is the same one you already have. The same fallback may be

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigSyntax.java
Patch:
@@ -23,7 +23,6 @@
  * aka ".conf", or <a href=
  * "http://download.oracle.com/javase/7/docs/api/java/util/Properties.html#load%28java.io.Reader%29"
  * >Java properties</a>).
- *
  */
 public enum ConfigSyntax {
     /**

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigDelayedMerge.java
Patch:
@@ -77,8 +77,8 @@ ResolveResult<? extends AbstractConfigValue> resolveSubstitutions(ResolveContext
 
     // static method also used by ConfigDelayedMergeObject
     static ResolveResult<? extends AbstractConfigValue> resolveSubstitutions(ReplaceableMergeStack replaceable,
-            List<AbstractConfigValue> stack,
-            ResolveContext context, ResolveSource source) throws NotPossibleToResolve {
+                                                                             List<AbstractConfigValue> stack,
+                                                                             ResolveContext context, ResolveSource source) throws NotPossibleToResolve {
         if (ConfigImpl.traceSubSituationsEnable()) {
             ConfigImpl.trace(context.depth(), "delayed merge stack has " + stack.size() + " items:");
             int count = 0;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNull.java
Patch:
@@ -30,7 +30,6 @@
  * where it was set to null) in case someone asks for the value. Also, null
  * overrides values set "earlier" in the search path, while missing values do
  * not.
- *
  */
 final class ConfigNull extends AbstractConfigValue implements Serializable {
 

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNumber.java
Patch:
@@ -98,15 +98,15 @@ public int hashCode() {
     }
 
     static ConfigNumber newNumber(ConfigOrigin origin, long number,
-            String originalText) {
+                                  String originalText) {
         if (number <= Integer.MAX_VALUE && number >= Integer.MIN_VALUE) {
             return new ConfigInt(origin, (int) number, originalText);
         }
         return new ConfigLong(origin, number, originalText);
     }
 
     static ConfigNumber newNumber(ConfigOrigin origin, double number,
-            String originalText) {
+                                  String originalText) {
         long asLong = (long) number;
         if (asLong == number) {
             return newNumber(origin, asLong, originalText);

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/FullIncluder.java
Patch:
@@ -23,6 +23,6 @@
 import io.github.interestinglab.waterdrop.config.ConfigIncluderURL;
 
 interface FullIncluder extends ConfigIncluder, ConfigIncluderFile, ConfigIncluderURL,
-            ConfigIncluderClasspath {
+        ConfigIncluderClasspath {
 
 }

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/MemoKey.java
Patch:
@@ -17,7 +17,9 @@
 
 package io.github.interestinglab.waterdrop.config.impl;
 
-/** The key used to memoize already-traversed nodes when resolving substitutions */
+/**
+ * The key used to memoize already-traversed nodes when resolving substitutions
+ */
 final class MemoKey {
     MemoKey(AbstractConfigValue value, Path restrictToChildOrNull) {
         this.value = value;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/PropertiesParser.java
Patch:
@@ -69,7 +69,7 @@ static Path pathFromPropertyKey(String key) {
     }
 
     static AbstractConfigObject fromProperties(ConfigOrigin origin,
-            Properties props) {
+                                               Properties props) {
         return fromEntrySet(origin, props.entrySet());
     }
 
@@ -95,7 +95,7 @@ static AbstractConfigObject fromStringMap(ConfigOrigin origin, Map<String, Strin
     }
 
     static AbstractConfigObject fromPathMap(ConfigOrigin origin,
-            Map<?, ?> pathExpressionMap) {
+                                            Map<?, ?> pathExpressionMap) {
         Map<Path, Object> pathMap = new LinkedHashMap<Path, Object>();
         for (Map.Entry<?, ?> entry : pathExpressionMap.entrySet()) {
             Object keyObj = entry.getKey();

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ResolveContext.java
Patch:
@@ -258,7 +258,7 @@ private ResolveResult<? extends AbstractConfigValue> realResolve(AbstractConfigV
     }
 
     static AbstractConfigValue resolve(AbstractConfigValue value, AbstractConfigObject root,
-            ConfigResolveOptions options) {
+                                       ConfigResolveOptions options) {
         ResolveSource source = new ResolveSource(root);
         ResolveContext context = new ResolveContext(options, null /* restrictToChild */);
 

File: seatunnel-core/seatunnel-core-base/src/main/java/io/github/interestinglab/waterdrop/config/ExposeSparkConf.java
Patch:
@@ -28,7 +28,7 @@ public static void main(String[] args) throws Exception {
                 .resolveWith(ConfigFactory.systemProperties(), ConfigResolveOptions.defaults().setAllowUnresolved(true));
 
         StringBuilder stringBuilder = new StringBuilder();
-        for (Map.Entry<String, ConfigValue> entry: appConfig.getConfig("env").entrySet()) {
+        for (Map.Entry<String, ConfigValue> entry : appConfig.getConfig("env").entrySet()) {
             String conf = String.format(" --conf \"%s=%s\" ", entry.getKey(), entry.getValue().unwrapped());
             stringBuilder.append(conf);
         }

File: seatunnel-core/seatunnel-core-base/src/main/java/io/github/interestinglab/waterdrop/utils/CompressionUtils.java
Patch:
@@ -49,9 +49,9 @@ public class CompressionUtils {
      * @param inputFile the input .tar file
      * @param outputDir the output directory file.
      * @return The {@link List} of {@link File}s with the untared content.
-     * @throws IOException io exception
+     * @throws IOException           io exception
      * @throws FileNotFoundException file not found exception
-     * @throws ArchiveException a rchive exception
+     * @throws ArchiveException      a rchive exception
      */
     public static List<File> unTar(final File inputFile, final File outputDir) throws FileNotFoundException, IOException, ArchiveException {
 
@@ -93,7 +93,7 @@ public static List<File> unTar(final File inputFile, final File outputDir) throw
      * @param inputFile the input .gz file
      * @param outputDir the output directory file.
      * @return The {@File} with the ungzipped content.
-     * @throws IOException io exception
+     * @throws IOException           io exception
      * @throws FileNotFoundException file not found exception
      */
     public static File unGzip(final File inputFile, final File outputDir) throws FileNotFoundException, IOException {

File: seatunnel-core/seatunnel-core-sql/src/main/java/io/github/interestinglab/waterdrop/core/sql/splitter/SqlStatementSplitter.java
Patch:
@@ -70,8 +70,8 @@ private static List<String> splitContent(String content) {
      */
     private static String normalizeLine(List<String> buffer) {
         return buffer.stream()
-            .map(statementLine -> statementLine.replaceAll(BEGINNING_COMMENT_MASK, ""))
-            .collect(Collectors.joining("\n"));
+                .map(statementLine -> statementLine.replaceAll(BEGINNING_COMMENT_MASK, ""))
+                .collect(Collectors.joining("\n"));
     }
 
     private static boolean isEndOfStatement(String line) {

File: plugin-flink-sink-elasticsearch/src/main/java/io/github/interestinglab/waterdrop/flink/sink/Elasticsearch.java
Patch:
@@ -62,9 +62,8 @@ public Config getConfig() {
     public CheckResult checkConfig() {
         if (config.hasPath("hosts")) {
             return new CheckResult(true, "");
-        } else {
-            return new CheckResult(false, "please specify [hosts] as a non-empty string list");
         }
+        return new CheckResult(false, "please specify [hosts] as a non-empty string list");
     }
 
     @Override

File: plugin-flink-sink-elasticsearch/src/main/java/io/github/interestinglab/waterdrop/flink/sink/ElasticsearchOutputFormat.java
Patch:
@@ -40,7 +40,7 @@ public class ElasticsearchOutputFormat<T> extends RichOutputFormat<T> {
 
     private Config config;
 
-    private final static String PREFIX = "es.";
+    private static final String PREFIX = "es.";
 
     private final ElasticsearchSinkFunction<T> elasticsearchSinkFunction;
 

File: plugin-flink-sink-file/src/main/java/io/github/interestinglab/waterdrop/flink/sink/FileSink.java
Patch:
@@ -44,9 +44,9 @@ public class FileSink implements FlinkStreamSink<Row, Row>, FlinkBatchSink<Row,
 
     private static final Logger LOG = LoggerFactory.getLogger(FileSink.class);
 
-    private final static String PATH = "path";
-    private final static String FORMAT = "format";
-    private final static String WRITE_MODE = "write_mode";
+    private static final String PATH = "path";
+    private static final String FORMAT = "format";
+    private static final String WRITE_MODE = "write_mode";
 
     private Config config;
 

File: plugin-flink-source-file/src/main/java/io/github/interestinglab/waterdrop/flink/source/FileSource.java
Patch:
@@ -47,9 +47,9 @@ public class FileSource implements FlinkBatchSource<Row> {
 
     private InputFormat inputFormat;
 
-    private final static String PATH = "path";
-    private final static String SOURCE_FORMAT = "format.type";
-    private final static String SCHEMA = "schema";
+    private static final String PATH = "path";
+    private static final String SOURCE_FORMAT = "format.type";
+    private static final String SCHEMA = "schema";
 
     @Override
     public DataSet<Row> getData(FlinkEnvironment env) {

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigMemorySize.java
Patch:
@@ -28,8 +28,9 @@ public final class ConfigMemorySize {
     private final long bytes;
 
     private ConfigMemorySize(long bytes) {
-        if (bytes < 0)
+        if (bytes < 0) {
             throw new IllegalArgumentException("Attempt to construct ConfigMemorySize with negative number: " + bytes);
+        }
         this.bytes = bytes;
     }
 
@@ -64,9 +65,8 @@ public String toString() {
     public boolean equals(Object other) {
         if (other instanceof ConfigMemorySize) {
             return ((ConfigMemorySize) other).bytes == this.bytes;
-        } else {
-            return false;
         }
+        return false;
     }
 
     @Override

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigResolveOptions.java
Patch:
@@ -141,10 +141,9 @@ public ConfigResolveOptions appendResolver(ConfigResolver value) {
             throw new ConfigException.BugOrBroken("null resolver passed to appendResolver");
         } else if (value == this.resolver) {
             return this;
-        } else {
-            return new ConfigResolveOptions(useSystemEnvironment, allowUnresolved,
-                    this.resolver.withFallback(value));
         }
+        return new ConfigResolveOptions(useSystemEnvironment, allowUnresolved,
+                this.resolver.withFallback(value));
     }
 
     /**

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/AbstractConfigNode.java
Patch:
@@ -25,7 +25,7 @@ abstract class AbstractConfigNode implements ConfigNode {
     abstract Collection<Token> tokens();
 
     @Override
-    final public String render() {
+    public final String render() {
         StringBuilder origText = new StringBuilder();
         Iterable<Token> tokens = tokens();
         for (Token t : tokens) {
@@ -35,12 +35,12 @@ final public String render() {
     }
 
     @Override
-    final public boolean equals(Object other) {
+    public final boolean equals(Object other) {
         return other instanceof AbstractConfigNode && render().equals(((AbstractConfigNode) other).render());
     }
 
     @Override
-    final public int hashCode() {
+    public final int hashCode() {
         return render().hashCode();
     }
 }

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigBoolean.java
Patch:
@@ -27,7 +27,7 @@ final class ConfigBoolean extends AbstractConfigValue implements Serializable {
 
     private static final long serialVersionUID = 2L;
 
-    final private boolean value;
+    private final boolean value;
 
     ConfigBoolean(ConfigOrigin origin, boolean value) {
         super(origin);

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeComplexValue.java
Patch:
@@ -21,13 +21,13 @@
 import java.util.Collection;
 
 abstract class ConfigNodeComplexValue extends AbstractConfigNodeValue {
-    final protected ArrayList<AbstractConfigNode> children;
+    protected final ArrayList<AbstractConfigNode> children;
 
     ConfigNodeComplexValue(Collection<AbstractConfigNode> children) {
         this.children = new ArrayList<AbstractConfigNode>(children);
     }
 
-    final public Collection<AbstractConfigNode> children() {
+    public final Collection<AbstractConfigNode> children() {
         return children;
     }
 

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeField.java
Patch:
@@ -24,7 +24,7 @@
 import java.util.List;
 
 final class ConfigNodeField extends AbstractConfigNode {
-    final private ArrayList<AbstractConfigNode> children;
+    private final ArrayList<AbstractConfigNode> children;
 
     public ConfigNodeField(Collection<AbstractConfigNode> children) {
         this.children = new ArrayList<AbstractConfigNode>(children);

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeRoot.java
Patch:
@@ -25,7 +25,7 @@
 import java.util.Collection;
 
 final class ConfigNodeRoot extends ConfigNodeComplexValue {
-    final private ConfigOrigin origin;
+    private final ConfigOrigin origin;
 
     ConfigNodeRoot(Collection<AbstractConfigNode> children, ConfigOrigin origin) {
         super(children);

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/PathBuilder.java
Patch:
@@ -23,17 +23,18 @@
 
 final class PathBuilder {
     // the keys are kept "backward" (top of stack is end of path)
-    final private Stack<String> keys;
+    private final Stack<String> keys;
     private Path result;
 
     PathBuilder() {
         keys = new Stack<String>();
     }
 
     private void checkCanAppend() {
-        if (result != null)
+        if (result != null) {
             throw new ConfigException.BugOrBroken(
                     "Adding to PathBuilder after getting result");
+        }
     }
 
     void appendKey(String key) {

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ResolveMemos.java
Patch:
@@ -28,7 +28,7 @@
 final class ResolveMemos {
     // note that we can resolve things to undefined (represented as Java null,
     // rather than ConfigNull) so this map can have null values.
-    final private Map<MemoKey, AbstractConfigValue> memos;
+    private final Map<MemoKey, AbstractConfigValue> memos;
 
     private ResolveMemos(Map<MemoKey, AbstractConfigValue> memos) {
         this.memos = memos;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ResolveResult.java
Patch:
@@ -36,8 +36,9 @@ static <V extends AbstractConfigValue> ResolveResult<V> make(ResolveContext cont
     // better option? we don't have variance
     @SuppressWarnings("unchecked")
     ResolveResult<AbstractConfigObject> asObjectResult() {
-        if (!(value instanceof AbstractConfigObject))
+        if (!(value instanceof AbstractConfigObject)) {
             throw new ConfigException.BugOrBroken("Expecting a resolve result to be an object, but it was " + value);
+        }
         Object o = this;
         return (ResolveResult<AbstractConfigObject>) o;
     }

File: seatunnel-core/src/main/java/io/github/interestinglab/waterdrop/Waterdrop.java
Patch:
@@ -130,8 +130,7 @@ private static void baseCheckConfig(List<? extends Plugin>... plugins) {
                 }
                 if (!checkResult.isSuccess()) {
                     configValid = false;
-                    LOGGER.error("Plugin[{}] contains invalid config, error: {} \n"
-                            , plugin.getClass().getName(), checkResult.getMsg());
+                    LOGGER.error("Plugin[{}] contains invalid config, error: {} \n", plugin.getClass().getName(), checkResult.getMsg());
                 }
                 if (!configValid) {
                     System.exit(-1); // invalid configuration

File: seatunnel-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigBuilder.java
Patch:
@@ -138,9 +138,8 @@ private String buildClassFullQualifier(String name, PluginType classType) throws
                 }
             }
             return qualifierWithPackage;
-        } else {
-            return name;
         }
+        return name;
     }
 
 

File: plugin-flink-sink-console/src/main/java/io/github/interestinglab/waterdrop/flink/sink/ConsoleSink.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.sink;
 
 import io.github.interestinglab.waterdrop.config.Config;
@@ -31,7 +32,7 @@
 
 import java.io.IOException;
 
-public class ConsoleSink extends RichOutputFormat<Row> implements FlinkBatchSink<Row, Row>, FlinkStreamSink<Row,Row> {
+public class ConsoleSink extends RichOutputFormat<Row> implements FlinkBatchSink<Row, Row>, FlinkStreamSink<Row, Row> {
 
     private Config config;
 
@@ -57,7 +58,7 @@ public Config getConfig() {
 
     @Override
     public CheckResult checkConfig() {
-        return new CheckResult(true,"");
+        return new CheckResult(true, "");
     }
 
     @Override
@@ -76,7 +77,6 @@ public void open(int taskNumber, int numTasks) throws IOException {
 
     @Override
     public void writeRecord(Row record) throws IOException {
-        System.out.println(record);
     }
 
     @Override

File: plugin-flink-sink-elasticsearch/src/main/java/io/github/interestinglab/waterdrop/flink/sink/Elasticsearch.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.sink;
 
 import io.github.interestinglab.waterdrop.config.Config;
@@ -42,7 +43,6 @@
 import java.util.List;
 import java.util.Map;
 
-
 public class Elasticsearch implements FlinkStreamSink<Row, Row>, FlinkBatchSink<Row, Row> {
 
     private Config config;
@@ -67,7 +67,6 @@ public CheckResult checkConfig() {
         }
     }
 
-
     @Override
     public void prepare(FlinkEnvironment env) {
         Config defaultConfig = ConfigFactory.parseMap(new HashMap<String, String>(2) {
@@ -115,7 +114,6 @@ public void process(Row element, RuntimeContext ctx, RequestIndexer indexer) {
                 }
         );
 
-
         // configuration for the bulk requests; this instructs the sink to emit after every element, otherwise they would be buffered
         esSinkBuilder.setBulkFlushMaxActions(1);
 

File: plugin-flink-sink-elasticsearch/src/main/java/io/github/interestinglab/waterdrop/flink/sink/ElasticsearchOutputFormat.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.sink;
 
 import io.github.interestinglab.waterdrop.config.Config;
@@ -35,7 +36,6 @@
 import java.net.InetAddress;
 import java.util.List;
 
-
 public class ElasticsearchOutputFormat<T> extends RichOutputFormat<T> {
 
     private Config config;

File: plugin-flink-sink-file/src/main/java/io/github/interestinglab/waterdrop/flink/sink/CsvRowOutputFormat.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.sink;
 
 import org.apache.flink.api.common.io.FileOutputFormat;
@@ -33,7 +34,6 @@ public class CsvRowOutputFormat extends FileOutputFormat<Row>  {
 
     public static final String DEFAULT_FIELD_DELIMITER = CsvInputFormat.DEFAULT_FIELD_DELIMITER;
 
-
     private transient Writer wrt;
 
     private String fieldDelimiter;
@@ -131,7 +131,6 @@ public void setQuoteStrings(boolean quoteStrings) {
         this.quoteStrings = quoteStrings;
     }
 
-
     @Override
     public void open(int taskNumber, int numTasks) throws IOException {
         super.open(taskNumber, numTasks);

File: plugin-flink-sink-file/src/main/java/io/github/interestinglab/waterdrop/flink/sink/FileSink.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.sink;
 
 import io.github.interestinglab.waterdrop.config.Config;
@@ -85,7 +86,7 @@ public DataSink<Row> outputBatch(FlinkEnvironment env, DataSet<Row> dataSet) {
                 break;
 
         }
-        if (config.hasPath(WRITE_MODE)){
+        if (config.hasPath(WRITE_MODE)) {
             String mode = config.getString(WRITE_MODE);
             outputFormat.setWriteMode(FileSystem.WriteMode.valueOf(mode));
         }
@@ -104,7 +105,7 @@ public Config getConfig() {
 
     @Override
     public CheckResult checkConfig() {
-        return CheckConfigUtil.check(config,PATH,FORMAT);
+        return CheckConfigUtil.check(config, PATH, FORMAT);
     }
 
     @Override

File: plugin-flink-source-file/src/main/java/io/github/interestinglab/waterdrop/flink/source/FileSource.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.source;
 
 import com.alibaba.fastjson.JSONObject;
@@ -40,7 +41,6 @@
 import java.util.List;
 import java.util.Map;
 
-
 public class FileSource implements FlinkBatchSource<Row> {
 
     private Config config;
@@ -56,7 +56,6 @@ public DataSet<Row> getData(FlinkEnvironment env) {
         return env.getBatchEnvironment().createInput(inputFormat);
     }
 
-
     @Override
     public void setConfig(Config config) {
         this.config = config;
@@ -69,7 +68,7 @@ public Config getConfig() {
 
     @Override
     public CheckResult checkConfig() {
-        return CheckConfigUtil.check(config,PATH,SOURCE_FORMAT,SCHEMA);
+        return CheckConfigUtil.check(config, PATH, SOURCE_FORMAT, SCHEMA);
     }
 
     @Override

File: plugin-flink-source-socket/src/main/java/io/github/interestinglab/waterdrop/flink/source/SocketStream.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.source;
 
 import io.github.interestinglab.waterdrop.config.Config;
@@ -39,7 +40,6 @@ public class SocketStream implements FlinkStreamSource<Row> {
 
     private int port = 9999;
 
-
     @Override
     public DataStream<Row> getData(FlinkEnvironment env) {
         final StreamExecutionEnvironment environment = env.getStreamExecutionEnvironment();
@@ -69,10 +69,10 @@ public CheckResult checkConfig() {
 
     @Override
     public void prepare(FlinkEnvironment prepareEnv) {
-        if (config.hasPath(HOST)){
+        if (config.hasPath(HOST)) {
             host = config.getString(HOST);
         }
-        if (config.hasPath(PORT)){
+        if (config.hasPath(PORT)) {
             port = config.getInt(PORT);
         }
     }

File: plugin-flink-transform-split/src/main/java/io/github/interestinglab/waterdrop/flink/transform/ScalarSplit.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.transform;
 
 import org.apache.flink.api.common.typeinfo.TypeInformation;

File: plugin-flink-transform-sql/src/main/java/io/github/interestinglab/waterdrop/flink/transform/Sql.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.transform;
 
 import io.github.interestinglab.waterdrop.config.Config;
@@ -62,10 +63,9 @@ public Config getConfig() {
         return config;
     }
 
-
     @Override
     public CheckResult checkConfig() {
-       return CheckConfigUtil.check(config,SQL);
+        return CheckConfigUtil.check(config, SQL);
     }
 
     @Override

File: plugin-flink-transform-table2datasteam/src/main/java/io/github/interestinglab/waterdrop/flink/transform/TableToDataStream.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.transform;
 
 import io.github.interestinglab.waterdrop.config.Config;
@@ -61,7 +62,6 @@ public Config getConfig() {
         return config;
     }
 
-
     @Override
     public CheckResult checkConfig() {
         return CheckConfigUtil.check(config, SOURCE_TABLE_NAME);

File: seatunnel-apis/src/main/java/io/github/interestinglab/waterdrop/apis/BaseSink.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.apis;
 
 import io.github.interestinglab.waterdrop.env.RuntimeEnv;

File: seatunnel-apis/src/main/java/io/github/interestinglab/waterdrop/apis/BaseSource.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.apis;
 
 import io.github.interestinglab.waterdrop.env.RuntimeEnv;

File: seatunnel-apis/src/main/java/io/github/interestinglab/waterdrop/apis/BaseTransform.java
Patch:
@@ -14,8 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package io.github.interestinglab.waterdrop.apis;
 
+package io.github.interestinglab.waterdrop.apis;
 
 import io.github.interestinglab.waterdrop.env.RuntimeEnv;
 import io.github.interestinglab.waterdrop.plugin.Plugin;

File: seatunnel-apis/src/main/java/io/github/interestinglab/waterdrop/env/Execution.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.env;
 
 import io.github.interestinglab.waterdrop.apis.BaseSink;

File: seatunnel-apis/src/main/java/io/github/interestinglab/waterdrop/env/RuntimeEnv.java
Patch:
@@ -14,12 +14,11 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package io.github.interestinglab.waterdrop.env;
 
+package io.github.interestinglab.waterdrop.env;
 
 import io.github.interestinglab.waterdrop.plugin.Plugin;
 
-
 public interface RuntimeEnv extends Plugin<Boolean> {
 
 }

File: seatunnel-apis/src/main/java/io/github/interestinglab/waterdrop/plugin/Plugin.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.plugin;
 
 import io.github.interestinglab.waterdrop.config.Config;

File: seatunnel-common/src/main/java/io/github/interestinglab/waterdrop/common/config/CheckConfigUtil.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.common.config;
 
 import io.github.interestinglab.waterdrop.config.Config;
@@ -26,6 +27,6 @@ public static CheckResult check(Config config, String... params) {
                 return new CheckResult(false, "please specify [" + param + "] as non-empty");
             }
         }
-        return new CheckResult(true,"");
+        return new CheckResult(true, "");
     }
 }

File: seatunnel-common/src/main/java/io/github/interestinglab/waterdrop/common/config/CheckResult.java
Patch:
@@ -14,8 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package io.github.interestinglab.waterdrop.common.config;
 
+package io.github.interestinglab.waterdrop.common.config;
 
 import lombok.Data;
 

File: seatunnel-common/src/main/java/io/github/interestinglab/waterdrop/common/config/ConfigRuntimeException.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.common.config;
 
 public class ConfigRuntimeException extends RuntimeException {

File: seatunnel-common/src/main/java/io/github/interestinglab/waterdrop/common/config/TypesafeConfigUtils.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.common.config;
 
 import io.github.interestinglab.waterdrop.config.Config;

File: seatunnel-common/src/main/java/io/github/interestinglab/waterdrop/common/utils/StringTemplate.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.common.utils;
 
 import org.apache.commons.lang3.text.StrSubstitutor;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigBeanFactory.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 import io.github.interestinglab.waterdrop.config.impl.ConfigBeanImpl;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigException.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 import io.github.interestinglab.waterdrop.config.impl.ConfigImplUtil;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigIncludeContext.java
Patch:
@@ -14,8 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package io.github.interestinglab.waterdrop.config;
 
+package io.github.interestinglab.waterdrop.config;
 
 /**
  * Context provided to a {@link ConfigIncluder}; this interface is only useful

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigIncluder.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 /**
@@ -45,14 +46,14 @@ public interface ConfigIncluder {
      * Parses another item to be included. The returned object typically would
      * not have substitutions resolved. You can throw a ConfigException here to
      * abort parsing, or return an empty object, but may not return null.
-     * 
+     *
      * This method is used for a "heuristic" include statement that does not
      * specify file, URL, or classpath resource. If the include statement does
      * specify, then the same class implementing {@link ConfigIncluder} must
      * also implement {@link ConfigIncluderClasspath},
      * {@link ConfigIncluderFile}, or {@link ConfigIncluderURL} as needed, or a
      * default includer will be used.
-     * 
+     *
      * @param context
      *            some info about the include context
      * @param what

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigIncluderClasspath.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 /**

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigIncluderFile.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 import java.io.File;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigIncluderURL.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 import java.net.URL;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigList.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 import java.util.List;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigLoadingStrategy.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 /**

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigOrigin.java
Patch:
@@ -14,12 +14,12 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 import java.net.URL;
 import java.util.List;
 
-
 /**
  * Represents the origin (such as filename and line number) of a
  * {@link ConfigValue} for use in error messages. Obtain the origin of a value
@@ -87,7 +87,7 @@ public interface ConfigOrigin {
      * change, but at the moment comments that are immediately before an array
      * element or object field, with no blank line after the comment, "go with"
      * that element or field.
-     * 
+     *
      * @return any comments that seemed to "go with" this origin, empty list if
      *         none
      */

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigOriginFactory.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 import io.github.interestinglab.waterdrop.config.impl.ConfigImpl;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigParseable.java
Patch:
@@ -14,8 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package io.github.interestinglab.waterdrop.config;
 
+package io.github.interestinglab.waterdrop.config;
 
 /**
  * An opaque handle to something that can be parsed, obtained from

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigRenderOptions.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 /**

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigResolver.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 /**

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigSyntax.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 /**
@@ -22,7 +23,7 @@
  * aka ".conf", or <a href=
  * "http://download.oracle.com/javase/7/docs/api/java/util/Properties.html#load%28java.io.Reader%29"
  * >Java properties</a>).
- * 
+ *
  */
 public enum ConfigSyntax {
     /**

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigValueType.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 /**

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/Optional.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 import java.lang.annotation.Documented;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/AbstractConfigNode.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.parser.ConfigNode;
@@ -22,6 +23,7 @@
 
 abstract class AbstractConfigNode implements ConfigNode {
     abstract Collection<Token> tokens();
+
     @Override
     final public String render() {
         StringBuilder origText = new StringBuilder();
@@ -34,7 +36,7 @@ final public String render() {
 
     @Override
     final public boolean equals(Object other) {
-        return other instanceof AbstractConfigNode && render().equals(((AbstractConfigNode)other).render());
+        return other instanceof AbstractConfigNode && render().equals(((AbstractConfigNode) other).render());
     }
 
     @Override

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/AbstractConfigNodeValue.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 // This is required if we want

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/AbstractConfigObject.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;
@@ -71,7 +72,7 @@ public AbstractConfigObject toFallbackValue() {
      * resolved along the nodes needed to get the key or
      * ConfigException.NotResolved will be thrown.
      *
-     * @param key
+     * @param key key
      * @return the unmodified raw value or null
      */
     protected final AbstractConfigValue peekAssumingResolved(String key, Path originalPath) {

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigBoolean.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigOrigin;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigDelayedMergeObject.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigDouble.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigOrigin;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigIncludeKind.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 enum ConfigIncludeKind {

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigInt.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigOrigin;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigLong.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigOrigin;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeArray.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import java.util.Collection;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeComment.java
Patch:
@@ -14,8 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package io.github.interestinglab.waterdrop.config.impl;
 
+package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;
 

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeComplexValue.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import java.util.ArrayList;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeConcatenation.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import java.util.Collection;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeField.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;
@@ -52,7 +53,7 @@ public ConfigNodeField replaceValue(AbstractConfigNodeValue newValue) {
     public AbstractConfigNodeValue value() {
         for (int i = 0; i < children.size(); i++) {
             if (children.get(i) instanceof AbstractConfigNodeValue) {
-                return (AbstractConfigNodeValue)children.get(i);
+                return (AbstractConfigNodeValue) children.get(i);
             }
         }
         throw new ConfigException.BugOrBroken("Field node doesn't have a value");
@@ -61,7 +62,7 @@ public AbstractConfigNodeValue value() {
     public ConfigNodePath path() {
         for (int i = 0; i < children.size(); i++) {
             if (children.get(i) instanceof ConfigNodePath) {
-                return (ConfigNodePath)children.get(i);
+                return (ConfigNodePath) children.get(i);
             }
         }
         throw new ConfigException.BugOrBroken("Field node doesn't have a path");

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeInclude.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import java.util.ArrayList;
@@ -54,7 +55,7 @@ protected boolean isRequired() {
     protected String name() {
         for (AbstractConfigNode n : children) {
             if (n instanceof ConfigNodeSimpleValue) {
-                return (String)Tokens.getValue(((ConfigNodeSimpleValue) n).token()).unwrapped();
+                return (String) Tokens.getValue(((ConfigNodeSimpleValue) n).token()).unwrapped();
             }
         }
         return null;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeRoot.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;
@@ -39,7 +40,7 @@ protected ConfigNodeRoot newNode(Collection<AbstractConfigNode> nodes) {
     protected ConfigNodeComplexValue value() {
         for (AbstractConfigNode node : children) {
             if (node instanceof ConfigNodeComplexValue) {
-                return (ConfigNodeComplexValue)node;
+                return (ConfigNodeComplexValue) node;
             }
         }
         throw new ConfigException.BugOrBroken("ConfigNodeRoot did not contain a value");
@@ -54,7 +55,7 @@ protected ConfigNodeRoot setValue(String desiredPath, AbstractConfigNodeValue va
                     throw new ConfigException.WrongType(origin, "The ConfigDocument had an array at the root level, and values cannot be modified inside an array.");
                 } else if (node instanceof ConfigNodeObject) {
                     if (value == null) {
-                        childrenCopy.set(i, ((ConfigNodeObject)node).removeValueOnPath(desiredPath, flavor));
+                        childrenCopy.set(i, ((ConfigNodeObject) node).removeValueOnPath(desiredPath, flavor));
                     } else {
                         childrenCopy.set(i, ((ConfigNodeObject) node).setValueOnPath(desiredPath, value, flavor));
                     }

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNodeSimpleValue.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;
@@ -24,6 +25,7 @@
 
 final class ConfigNodeSimpleValue extends AbstractConfigNodeValue {
     final Token token;
+
     ConfigNodeSimpleValue(Token value) {
         token = value;
     }

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNull.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigOrigin;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigNumber.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/Container.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigValue;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/DefaultTransformer.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigValueType;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/FromMapMode.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 enum FromMapMode {

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/FullIncluder.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigIncluder;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/MemoKey.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 /** The key used to memoize already-traversed nodes when resolving substitutions */

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/MergeableValue.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigMergeable;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/OriginType.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 // caution: ordinals used in serialization

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/PathBuilder.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/PropertiesParser.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ReplaceableMergeStack.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 /**

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ResolveMemos.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import java.util.HashMap;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ResolveResult.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ResolveStatus.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import java.util.Collection;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/SimpleConfigDocument.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/SimpleIncludeContext.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigIncludeContext;
@@ -44,7 +45,7 @@ SimpleIncludeContext withParseable(Parseable parseable) {
 
     @Override
     public ConfigParseable relativeTo(String filename) {
-        if (ConfigImpl.traceLoadsEnabled())
+        if (ConfigImpl.TRACE_LOADS_ENABLE())
             ConfigImpl.trace("Looking for '" + filename + "' relative to " + parseable);
         if (parseable != null)
             return parseable.relativeTo(filename);

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/SubstitutionExpression.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 final class SubstitutionExpression {

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/Token.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/TokenType.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 enum TokenType {

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/Unmergeable.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.impl;
 
 import java.util.Collection;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/parser/ConfigDocument.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.parser;
 
 import io.github.interestinglab.waterdrop.config.ConfigValue;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/parser/ConfigDocumentFactory.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.parser;
 
 import io.github.interestinglab.waterdrop.config.ConfigException;

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/parser/ConfigNode.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config.parser;
 
 /**

File: seatunnel-config/src/test/java/beanconfig/ArraysConfig.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 import java.util.List;

File: seatunnel-config/src/test/java/beanconfig/BooleansConfig.java
Patch:
@@ -14,8 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package beanconfig;
 
+package beanconfig;
 
 public class BooleansConfig {
     Boolean trueVal;

File: seatunnel-config/src/test/java/beanconfig/BytesConfig.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 import io.github.interestinglab.waterdrop.config.ConfigMemorySize;

File: seatunnel-config/src/test/java/beanconfig/DifferentFieldNameFromAccessorsConfig.java
Patch:
@@ -14,14 +14,14 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 public class DifferentFieldNameFromAccessorsConfig {
 
     private String customStringField;
     private Long number;
 
-
     public String getStringField() {
         return customStringField;
     }

File: seatunnel-config/src/test/java/beanconfig/DurationsConfig.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 import java.time.Duration;
@@ -23,7 +24,6 @@ public class DurationsConfig {
     Duration secondAsNumber;
     Duration halfSecond;
 
-
     public Duration getSecond() {
         return second;
     }

File: seatunnel-config/src/test/java/beanconfig/NotABeanFieldConfig.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 public class NotABeanFieldConfig {

File: seatunnel-config/src/test/java/beanconfig/NumbersConfig.java
Patch:
@@ -14,20 +14,18 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package beanconfig;
 
+package beanconfig;
 
 public class NumbersConfig {
 
-
     private int intVal;
     private Integer intObj;
     private long longVal;
     private Long longObj;
     private double doubleVal;
     private Double doubleObj;
 
-
     public int getIntVal() {
         return intVal;
     }

File: seatunnel-config/src/test/java/beanconfig/ObjectsConfig.java
Patch:
@@ -14,8 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package beanconfig;
 
+package beanconfig;
 
 import io.github.interestinglab.waterdrop.config.Optional;
 
@@ -73,7 +73,6 @@ public int hashCode() {
         return getValueObject() != null ? getValueObject().hashCode() : 0;
     }
 
-
     @Override
     public String toString() {
         final StringBuffer sb = new StringBuffer("ObjectsConfig{");

File: seatunnel-config/src/test/java/beanconfig/SetsConfig.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 import io.github.interestinglab.waterdrop.config.Config;

File: seatunnel-config/src/test/java/beanconfig/StringsConfig.java
Patch:
@@ -14,8 +14,8 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package beanconfig;
 
+package beanconfig;
 
 public class StringsConfig {
     String abcd;
@@ -42,7 +42,7 @@ public boolean equals(Object o) {
         if (o instanceof StringsConfig) {
             StringsConfig sc = (StringsConfig) o;
             return sc.abcd.equals(abcd) &&
-                sc.yes.equals(yes);
+                    sc.yes.equals(yes);
         } else {
             return false;
         }

File: seatunnel-config/src/test/java/beanconfig/TestBeanConfig.java
Patch:
@@ -14,11 +14,11 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 public class TestBeanConfig {
 
-
     private NumbersConfig numbers;
 
     public NumbersConfig getNumbers() {

File: seatunnel-config/src/test/java/beanconfig/UnsupportedListElementConfig.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 import java.net.URI;
@@ -29,4 +30,4 @@ public List<URI> getUri() {
     public void setUri(List<URI> uri) {
         this.uri = uri;
     }
-}
\ No newline at end of file
+}

File: seatunnel-config/src/test/java/beanconfig/UnsupportedMapKeyConfig.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 import java.util.Map;
@@ -29,4 +30,4 @@ public void setMap(Map<Integer, Object> map) {
         this.map = map;
     }
 
-}
\ No newline at end of file
+}

File: seatunnel-config/src/test/java/beanconfig/UnsupportedMapValueConfig.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 import java.util.Map;
@@ -29,4 +30,4 @@ public void setMap(Map<String, Integer> map) {
         this.map = map;
     }
 
-}
\ No newline at end of file
+}

File: seatunnel-config/src/test/java/beanconfig/ValidationBeanConfig.java
Patch:
@@ -14,11 +14,12 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 import java.util.List;
 
-public class ValidationBeanConfig extends TestBeanConfig{
+public class ValidationBeanConfig extends TestBeanConfig {
 
     private String propNotListedInConfig;
     private int shouldBeInt;

File: seatunnel-config/src/test/java/beanconfig/ValuesConfig.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package beanconfig;
 
 import java.util.Map;
@@ -31,7 +32,7 @@ public class ValuesConfig {
     ConfigObject configObj;
     ConfigValue configValue;
     ConfigList list;
-    Map<String,Object> unwrappedMap;
+    Map<String, Object> unwrappedMap;
 
     public Object getObj() {
         return obj;

File: seatunnel-core/src/main/java/io/github/interestinglab/waterdrop/WaterdropFlink.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop;
 
 import io.github.interestinglab.waterdrop.config.CommandLineArgs;
@@ -22,7 +23,6 @@
 
 import static io.github.interestinglab.waterdrop.utils.Engine.FLINK;
 
-
 public class WaterdropFlink {
 
     public static void main(String[] args) {

File: seatunnel-core/src/main/java/io/github/interestinglab/waterdrop/config/ExposeSparkConf.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.config;
 
 import java.io.File;

File: seatunnel-core/src/main/java/io/github/interestinglab/waterdrop/utils/Engine.java
Patch:
@@ -14,12 +14,14 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.utils;
 
 public enum Engine {
-    SPARK("spark"),FLINK("flink"),NULL("");
+    SPARK("spark"), FLINK("flink"), NULL("");
 
     private String engine;
+
     Engine(String engine) {
         this.engine = engine;
     }

File: seatunnel-core/src/main/java/io/github/interestinglab/waterdrop/utils/PluginType.java
Patch:
@@ -14,12 +14,14 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.utils;
 
 public enum PluginType {
-    SOURCE("source"),TRANSFORM("transform"),SINK("sink");
+    SOURCE("source"), TRANSFORM("transform"), SINK("sink");
 
     private String type;
+
     private PluginType(String type) {
         this.type = type;
     }

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/BaseFlinkSink.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink;
 
 import io.github.interestinglab.waterdrop.apis.BaseSink;

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/BaseFlinkSource.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink;
 
 import io.github.interestinglab.waterdrop.apis.BaseSource;

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/BaseFlinkTransform.java
Patch:
@@ -14,14 +14,14 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink;
 
 import io.github.interestinglab.waterdrop.apis.BaseTransform;
 
-
 public interface BaseFlinkTransform extends BaseTransform<FlinkEnvironment> {
 
-    default void registerFunction(FlinkEnvironment flinkEnvironment){
+    default void registerFunction(FlinkEnvironment flinkEnvironment) {
 
     }
 

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/batch/FlinkBatchExecution.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.batch;
 
 import io.github.interestinglab.waterdrop.config.Config;
@@ -91,7 +92,6 @@ private void registerResultTable(Plugin plugin, DataSet dataSet) {
         }
     }
 
-
     private DataSet fromSourceTable(Plugin plugin) {
         Config config = plugin.getConfig();
         if (config.hasPath(SOURCE_TABLE_NAME)) {

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/batch/FlinkBatchSink.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.batch;
 
 import io.github.interestinglab.waterdrop.flink.BaseFlinkSink;

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/batch/FlinkBatchSource.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.batch;
 
 import io.github.interestinglab.waterdrop.flink.BaseFlinkSource;

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/batch/FlinkBatchTransform.java
Patch:
@@ -14,13 +14,14 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.batch;
 
 import io.github.interestinglab.waterdrop.flink.BaseFlinkTransform;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import org.apache.flink.api.java.DataSet;
 
-public interface FlinkBatchTransform<IN,OUT> extends BaseFlinkTransform {
+public interface FlinkBatchTransform<IN, OUT> extends BaseFlinkTransform {
 
     DataSet<OUT> processBatch(FlinkEnvironment env, DataSet<IN> data);
 

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/FlinkStreamExecution.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.stream;
 
 import io.github.interestinglab.waterdrop.config.Config;
@@ -36,7 +37,6 @@ public class FlinkStreamExecution implements Execution<FlinkStreamSource, FlinkS
 
     private FlinkEnvironment flinkEnvironment;
 
-
     public FlinkStreamExecution(FlinkEnvironment streamEnvironment) {
         this.flinkEnvironment = streamEnvironment;
     }

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/FlinkStreamSink.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.stream;
 
 import io.github.interestinglab.waterdrop.flink.BaseFlinkSink;

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/FlinkStreamSource.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.stream;
 
 import io.github.interestinglab.waterdrop.flink.BaseFlinkSource;
@@ -24,5 +25,4 @@ public interface FlinkStreamSource<T> extends BaseFlinkSource {
 
     DataStream<T> getData(FlinkEnvironment env);
 
-
 }

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/FlinkStreamTransform.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.stream;
 
 import io.github.interestinglab.waterdrop.flink.BaseFlinkTransform;

File: seatunnel-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/util/ConfigKeyName.java
Patch:
@@ -14,6 +14,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package io.github.interestinglab.waterdrop.flink.util;
 
 public class ConfigKeyName {
@@ -39,4 +40,4 @@ public class ConfigKeyName {
     public final static String MIN_STATE_RETENTION_TIME = "execution.query.state.min-retention";
     public final static String STATE_BACKEND = "execution.state.backend";
 
-}
\ No newline at end of file
+}

File: seatunnel-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/AbstractConfigNode.java
Patch:
@@ -22,6 +22,7 @@
 
 abstract class AbstractConfigNode implements ConfigNode {
     abstract Collection<Token> tokens();
+    @Override
     final public String render() {
         StringBuilder origText = new StringBuilder();
         Iterable<Token> tokens = tokens();

File: plugin-flink-sink-elasticsearch/src/main/java/io/github/interestinglab/waterdrop/flink/sink/Elasticsearch.java
Patch:
@@ -1,7 +1,7 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.waterdrop.Config;
-import com.typesafe.config.waterdrop.ConfigFactory;
+import io.github.interestinglab.waterdrop.config.Config;
+import io.github.interestinglab.waterdrop.config.ConfigFactory;
 import io.github.interestinglab.waterdrop.common.utils.StringTemplate;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSink;

File: plugin-flink-sink-elasticsearch/src/main/java/io/github/interestinglab/waterdrop/flink/sink/ElasticsearchOutputFormat.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import org.apache.flink.api.common.io.RichOutputFormat;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;

File: waterdrop-common/src/main/java/io/github/interestinglab/waterdrop/common/utils/StringTemplate.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.common.utils;
 
-import org.apache.commons.lang.text.StrSubstitutor;
+import org.apache.commons.lang3.text.StrSubstitutor;
 
 import java.text.SimpleDateFormat;
 import java.util.Date;
@@ -11,7 +11,9 @@
 public class StringTemplate {
 
     /**
+     * @param str raw string
      * @param timeFormat example : "yyyy-MM-dd HH:mm:ss"
+     * @return replaced string
      * */
     public static String substitute(String str, String timeFormat) {
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/WaterdropFlink.java
Patch:
@@ -4,14 +4,15 @@
 import io.github.interestinglab.waterdrop.config.CommandLineUtils;
 import scopt.OptionParser;
 
+import static io.github.interestinglab.waterdrop.utils.Engine.FLINK;
+
 
 /**
  * @author mr_xiong
  * @date 2019-12-29 16:15
  * @description
  */
 public class WaterdropFlink {
-    private static final String FLINK = "flink";
 
     public static void main(String[] args) {
         OptionParser<CommandLineArgs> flinkParser = CommandLineUtils.flinkParser();

File: plugin-flink-source-file/src/main/java/io/github/interestinglab/waterdrop/flink/source/FileSource.java
Patch:
@@ -16,10 +16,8 @@
 import org.apache.flink.api.java.typeutils.RowTypeInfo;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.formats.parquet.ParquetRowInputFormat;
-import org.apache.flink.formats.parquet.utils.ParquetSchemaConverter;
 import org.apache.flink.orc.OrcRowInputFormat;
 import org.apache.flink.types.Row;
-import org.apache.hadoop.conf.Configuration;
 import org.apache.parquet.avro.AvroSchemaConverter;
 import org.apache.parquet.schema.MessageType;
 
@@ -34,7 +32,7 @@ public class FileSource implements FlinkBatchSource<Row> {
     private InputFormat inputFormat;
 
     private final static String PATH = "path";
-    private final static String SOURCE_FORMAT = "source_format";
+    private final static String SOURCE_FORMAT = "format.type";
     private final static String SCHEMA = "schema";
 
     @Override

File: plugin-flink-source-kafka/src/main/java/io/github/interestinglab/waterdrop/flink/source/KafkaTableStream.java
Patch:
@@ -38,7 +38,7 @@ public class KafkaTableStream implements FlinkStreamSource<Row> {
     private static final String ROWTIME_FIELD = "rowtime.field";
     private static final String WATERMARK_VAL = "watermark";
     private static final String SCHEMA = "schema";
-    private static final String SOURCE_FORMAT = "format";
+    private static final String SOURCE_FORMAT = "format.type";
     private static final String GROUP_ID = "group.id";
     private static final String BOOTSTRAP_SERVERS = "bootstrap.servers";
     private static final String OFFSET_RESET = "offset.reset";
@@ -140,6 +140,7 @@ private FormatDescriptor setFormat() {
         try {
             return SchemaUtil.setFormat(format, config);
         } catch (Exception e) {
+            // TODO: logging
             e.printStackTrace();
         }
         throw new RuntimeException("format配置错误");

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/util/SchemaUtil.java
Patch:
@@ -4,6 +4,7 @@
 import com.alibaba.fastjson.JSONObject;
 import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.config.ConfigValue;
+import org.apache.commons.lang.StringUtils;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.java.typeutils.ObjectArrayTypeInfo;
 import org.apache.flink.api.java.typeutils.RowTypeInfo;
@@ -46,7 +47,7 @@ public static void setSchema(Schema schema, Object info, String format) {
 
     public static FormatDescriptor setFormat(String format, Config config) throws Exception {
         FormatDescriptor formatDescriptor = null;
-        switch (format.toLowerCase()) {
+        switch (format.toLowerCase().trim()) {
             case "json":
                 formatDescriptor = new Json().failOnMissingField(false).deriveSchema();
                 break;
@@ -60,7 +61,7 @@ public static FormatDescriptor setFormat(String format, Config config) throws Ex
                 putMethod.setAccessible(true);
                 for (Map.Entry<String, ConfigValue> entry : config.entrySet()) {
                     String key = entry.getKey();
-                    if (key.startsWith("format.")) {
+                    if (key.startsWith("format.") && ! StringUtils.equals(key, "format.type")) {
                         String value = config.getString(key);
                         putMethod.invoke(desc, key, value);
                     }

File: plugin-flink-source-file/src/main/java/io/github/interestinglab/waterdrop/flink/source/FileSource.java
Patch:
@@ -16,10 +16,8 @@
 import org.apache.flink.api.java.typeutils.RowTypeInfo;
 import org.apache.flink.core.fs.Path;
 import org.apache.flink.formats.parquet.ParquetRowInputFormat;
-import org.apache.flink.formats.parquet.utils.ParquetSchemaConverter;
 import org.apache.flink.orc.OrcRowInputFormat;
 import org.apache.flink.types.Row;
-import org.apache.hadoop.conf.Configuration;
 import org.apache.parquet.avro.AvroSchemaConverter;
 import org.apache.parquet.schema.MessageType;
 
@@ -34,7 +32,7 @@ public class FileSource implements FlinkBatchSource<Row> {
     private InputFormat inputFormat;
 
     private final static String PATH = "path";
-    private final static String SOURCE_FORMAT = "source_format";
+    private final static String SOURCE_FORMAT = "format.type";
     private final static String SCHEMA = "schema";
 
     @Override

File: plugin-flink-source-kafka/src/main/java/io/github/interestinglab/waterdrop/flink/source/KafkaTableStream.java
Patch:
@@ -38,7 +38,7 @@ public class KafkaTableStream implements FlinkStreamSource<Row> {
     private static final String ROWTIME_FIELD = "rowtime.field";
     private static final String WATERMARK_VAL = "watermark";
     private static final String SCHEMA = "schema";
-    private static final String SOURCE_FORMAT = "format";
+    private static final String SOURCE_FORMAT = "format.type";
     private static final String GROUP_ID = "group.id";
     private static final String BOOTSTRAP_SERVERS = "bootstrap.servers";
     private static final String OFFSET_RESET = "offset.reset";
@@ -140,6 +140,7 @@ private FormatDescriptor setFormat() {
         try {
             return SchemaUtil.setFormat(format, config);
         } catch (Exception e) {
+            // TODO: logging
             e.printStackTrace();
         }
         throw new RuntimeException("format配置错误");

File: waterdrop-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigBeanImpl.java
Patch:
@@ -28,7 +28,7 @@
 
 /**
  * Internal implementation detail, not ABI stable, do not touch.
- * For use only by the {@link com.typesafe.config} package.
+ * For use only by the {@link io.github.interestinglab.waterdrop.config} package.
  */
 public class ConfigBeanImpl {
 

File: waterdrop-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigImpl.java
Patch:
@@ -30,7 +30,7 @@
 
 /**
  * Internal implementation detail, not ABI stable, do not touch.
- * For use only by the {@link com.typesafe.config} package.
+ * For use only by the {@link io.github.interestinglab.waterdrop.config} package.
  */
 public class ConfigImpl {
 

File: waterdrop-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigImplUtil.java
Patch:
@@ -18,7 +18,7 @@
 
 /**
  * Internal implementation detail, not ABI stable, do not touch.
- * For use only by the {@link com.typesafe.config} package.
+ * For use only by the {@link io.github.interestinglab.waterdrop.config} package.
  */
 final public class ConfigImplUtil {
     static boolean equalsHandlingNull(Object a, Object b) {

File: waterdrop-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/Parseable.java
Patch:
@@ -30,7 +30,7 @@
 
 /**
  * Internal implementation detail, not ABI stable, do not touch.
- * For use only by the {@link com.typesafe.config} package.
+ * For use only by the {@link io.github.interestinglab.waterdrop.config} package.
  * The point of this class is to avoid "propagating" each
  * overload on "thing which can be parsed" through multiple
  * interfaces. Most interfaces can have just one overload that

File: waterdrop-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigBeanImpl.java
Patch:
@@ -28,7 +28,7 @@
 
 /**
  * Internal implementation detail, not ABI stable, do not touch.
- * For use only by the {@link com.typesafe.config} package.
+ * For use only by the {@link io.github.interestinglab.waterdrop.config} package.
  */
 public class ConfigBeanImpl {
 

File: waterdrop-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigImpl.java
Patch:
@@ -30,7 +30,7 @@
 
 /**
  * Internal implementation detail, not ABI stable, do not touch.
- * For use only by the {@link com.typesafe.config} package.
+ * For use only by the {@link io.github.interestinglab.waterdrop.config} package.
  */
 public class ConfigImpl {
 

File: waterdrop-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/ConfigImplUtil.java
Patch:
@@ -18,7 +18,7 @@
 
 /**
  * Internal implementation detail, not ABI stable, do not touch.
- * For use only by the {@link com.typesafe.config} package.
+ * For use only by the {@link io.github.interestinglab.waterdrop.config} package.
  */
 final public class ConfigImplUtil {
     static boolean equalsHandlingNull(Object a, Object b) {

File: waterdrop-config/src/main/java/io/github/interestinglab/waterdrop/config/impl/Parseable.java
Patch:
@@ -30,7 +30,7 @@
 
 /**
  * Internal implementation detail, not ABI stable, do not touch.
- * For use only by the {@link com.typesafe.config} package.
+ * For use only by the {@link io.github.interestinglab.waterdrop.config} package.
  * The point of this class is to avoid "propagating" each
  * overload on "thing which can be parsed" through multiple
  * interfaces. Most interfaces can have just one overload that

File: waterdrop-config/src/main/java/io/github/interestinglab/waterdrop/config/ConfigParseOptions.java
Patch:
@@ -24,7 +24,7 @@ public final class ConfigParseOptions {
 
     /**
      * a.b.c
-     * a->b->c
+     * a-&gt;b-&gt;c
      * */
     public static final String pathTokenSeparator = "->";
 

File: common/src/main/java/io/github/interestinglab/waterdrop/common/PropertiesUtil.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.common;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 
 import java.util.Properties;
 

File: common/src/main/java/io/github/interestinglab/waterdrop/common/config/CheckConfigUtil.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.common.config;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 
 /**
  * @author mr_xiong

File: common/src/main/java/io/github/interestinglab/waterdrop/common/config/TypesafeConfigUtils.java
Patch:
@@ -1,8 +1,8 @@
 package io.github.interestinglab.waterdrop.common.config;
 
-import com.typesafe.config.waterdrop.Config;
-import com.typesafe.config.waterdrop.ConfigFactory;
-import com.typesafe.config.waterdrop.ConfigValue;
+import io.github.interestinglab.waterdrop.config.Config;
+import io.github.interestinglab.waterdrop.config.ConfigFactory;
+import io.github.interestinglab.waterdrop.config.ConfigValue;
 
 import java.util.LinkedHashMap;
 import java.util.Map;

File: plugin-flink-sink-console/src/main/java/io/github/interestinglab/waterdrop/flink/sink/ConsoleSink.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSink;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamSink;

File: plugin-flink-sink-elasticsearch/src/main/java/io/github/interestinglab/waterdrop/flink/sink/Elasticsearch.java
Patch:
@@ -1,7 +1,7 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.waterdrop.Config;
-import com.typesafe.config.waterdrop.ConfigFactory;
+import io.github.interestinglab.waterdrop.config.Config;
+import io.github.interestinglab.waterdrop.config.ConfigFactory;
 import io.github.interestinglab.waterdrop.common.utils.StringTemplate;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSink;

File: plugin-flink-sink-elasticsearch/src/main/java/io/github/interestinglab/waterdrop/flink/sink/ElasticsearchOutputFormat.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import org.apache.flink.api.common.io.RichOutputFormat;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.connectors.elasticsearch.ElasticsearchSinkFunction;

File: plugin-flink-sink-file/src/main/java/io/github/interestinglab/waterdrop/flink/sink/FileSink.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSink;

File: plugin-flink-sink-jdbc/src/main/java/io/github/interestinglab/waterdrop/flink/sink/JdbcSink.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSink;

File: plugin-flink-sink-kafka/src/main/java/io/github/interestinglab/waterdrop/flink/sink/KafkaTable.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.PropertiesUtil;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;

File: plugin-flink-source-fake/src/main/java/io/github/interestinglab/waterdrop/flink/source/FakeSourceStream.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.source;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamSource;
 import io.github.interestinglab.waterdrop.common.config.CheckResult;

File: plugin-flink-source-file/src/main/java/io/github/interestinglab/waterdrop/flink/source/FileSource.java
Patch:
@@ -1,7 +1,7 @@
 package io.github.interestinglab.waterdrop.flink.source;
 
 import com.alibaba.fastjson.JSONObject;
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSource;

File: plugin-flink-source-jdbc/src/main/java/io/github/interestinglab/waterdrop/flink/source/JdbcSource.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.source;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSource;

File: plugin-flink-source-kafka/src/main/java/io/github/interestinglab/waterdrop/flink/source/KafkaTableStream.java
Patch:
@@ -2,7 +2,7 @@
 
 import com.alibaba.fastjson.JSONObject;
 import com.alibaba.fastjson.parser.Feature;
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.PropertiesUtil;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
 import io.github.interestinglab.waterdrop.common.config.TypesafeConfigUtils;

File: plugin-flink-source-socket/src/main/java/io/github/interestinglab/waterdrop/flink/source/SocketStream.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.source;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.config.CheckResult;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamSource;

File: plugin-flink-transform-datastream2table/src/main/java/io/github/interestinglab/waterdrop/flink/transform/DataSteamToTable.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.transform;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchTransform;

File: plugin-flink-transform-split/src/main/java/io/github/interestinglab/waterdrop/flink/transform/Split.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.transform;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
 import io.github.interestinglab.waterdrop.common.config.CheckResult;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;

File: plugin-flink-transform-sql/src/main/java/io/github/interestinglab/waterdrop/flink/transform/Sql.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.transform;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchTransform;

File: plugin-flink-transform-table2datasteam/src/main/java/io/github/interestinglab/waterdrop/flink/transform/TableToDataStream.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.transform;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchTransform;

File: waterdrop-apis/src/main/java/io/github/interestinglab/waterdrop/plugin/Plugin.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.plugin;
 
-import com.typesafe.config.waterdrop.Config;
+import io.github.interestinglab.waterdrop.config.Config;
 import io.github.interestinglab.waterdrop.common.config.CheckResult;
 
 import java.io.Serializable;

File: plugin-flink-source-kafka/src/main/java/io/github/interestinglab/waterdrop/flink/source/KafkaTableStream.java
Patch:
@@ -1,6 +1,7 @@
 package io.github.interestinglab.waterdrop.flink.source;
 
 import com.alibaba.fastjson.JSONObject;
+import com.alibaba.fastjson.parser.Feature;
 import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.common.PropertiesUtil;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
@@ -85,7 +86,7 @@ public void prepare(FlinkEnvironment env) {
         }
         String schemaContent = config.getString(SCHEMA);
         format = config.getString(SOURCE_FORMAT);
-        schemaInfo = JSONObject.parse(schemaContent);
+        schemaInfo = JSONObject.parse(schemaContent, Feature.OrderedField);
     }
 
     @Override

File: plugin-flink-source-kafka/src/main/java/io/github/interestinglab/waterdrop/flink/source/KafkaTableStream.java
Patch:
@@ -1,6 +1,7 @@
 package io.github.interestinglab.waterdrop.flink.source;
 
 import com.alibaba.fastjson.JSONObject;
+import com.alibaba.fastjson.parser.Feature;
 import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.common.PropertiesUtil;
 import io.github.interestinglab.waterdrop.common.config.CheckConfigUtil;
@@ -85,7 +86,7 @@ public void prepare(FlinkEnvironment env) {
         }
         String schemaContent = config.getString(SCHEMA);
         format = config.getString(SOURCE_FORMAT);
-        schemaInfo = JSONObject.parse(schemaContent);
+        schemaInfo = JSONObject.parse(schemaContent, Feature.OrderedField);
     }
 
     @Override

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigBuilder.java
Patch:
@@ -14,9 +14,6 @@
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchExecution;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamExecution;
 import io.github.interestinglab.waterdrop.plugin.Plugin;
-import io.github.interestinglab.waterdrop.spark.BaseSparkSink;
-import io.github.interestinglab.waterdrop.spark.BaseSparkSource;
-import io.github.interestinglab.waterdrop.spark.BaseSparkTransform;
 import io.github.interestinglab.waterdrop.spark.SparkEnvironment;
 import io.github.interestinglab.waterdrop.spark.batch.SparkBatchExecution;
 import io.github.interestinglab.waterdrop.spark.stream.SparkStreamingExecution;

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/batch/FlinkBatchSink.java
Patch:
@@ -1,6 +1,5 @@
 package io.github.interestinglab.waterdrop.flink.batch;
 
-import io.github.interestinglab.waterdrop.apis.BaseSink;
 import io.github.interestinglab.waterdrop.flink.BaseFlinkSink;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import org.apache.flink.api.java.DataSet;

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/FlinkStreamSink.java
Patch:
@@ -1,12 +1,11 @@
 package io.github.interestinglab.waterdrop.flink.stream;
 
-import io.github.interestinglab.waterdrop.apis.BaseSink;
 import io.github.interestinglab.waterdrop.flink.BaseFlinkSink;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.datastream.DataStreamSink;
 
-public interface FlinkStreamSink<IN,OUT> extends BaseFlinkSink {
+public interface FlinkStreamSink<IN, OUT> extends BaseFlinkSink {
 
     DataStreamSink<OUT> outputStream(FlinkEnvironment env, DataStream<IN> dataStream);
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigBuilder.java
Patch:
@@ -20,7 +20,6 @@
 
 import java.io.File;
 import java.util.ArrayList;
-import java.util.Iterator;
 import java.util.List;
 import java.util.ServiceLoader;
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/Waterdrop.java
Patch:
@@ -33,7 +33,7 @@ public class Waterdrop {
     private static final String SPARK = "spark";
     public static void main(String[] args) {
         OptionParser<CommandLineArgs> sparkParser = CommandLineUtils.sparkParser();
-        run(sparkParser,SPARK,args);
+        run(sparkParser, SPARK, args);
     }
 
     public static void run(OptionParser<CommandLineArgs> parser,String engine,String[] args){
@@ -48,7 +48,7 @@ public static void run(OptionParser<CommandLineArgs> parser,String engine,String
                 System.out.println("config OK !");
             } else {
                 try {
-                    entrypoint(configFilePath,engine);
+                    entrypoint(configFilePath, engine);
                 } catch (ConfigRuntimeException e) {
                     showConfigError(e);
                 }catch (Exception e){

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/WaterdropFlink.java
Patch:
@@ -15,7 +15,7 @@ public class WaterdropFlink {
 
     public static void main(String[] args) {
         OptionParser<CommandLineArgs> flinkParser = CommandLineUtils.flinkParser();
-        Waterdrop.run(flinkParser,FLINK,args);
+        Waterdrop.run(flinkParser, FLINK, args);
     }
 
 }

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigBuilder.java
Patch:
@@ -55,7 +55,7 @@ public ConfigBuilder(String configFile) {
 
     private Config load() {
 
-        if (configFile == "") {
+        if (configFile.isEmpty()) {
             throw new ConfigRuntimeException("Please specify config file");
         }
 

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/FlinkStreamExecution.java
Patch:
@@ -2,7 +2,6 @@
 
 import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.env.Execution;
-import io.github.interestinglab.waterdrop.env.RuntimeEnv;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.util.TableUtil;
 import io.github.interestinglab.waterdrop.common.config.CheckResult;

File: plugin-flink-sink-kafka/src/main/java/io/github/interestinglab/waterdrop/flink/sink/KafkaTable.java
Patch:
@@ -26,7 +26,7 @@
  * @date 2019-07-22 18:39
  * @description
  */
-public class KafkaTable implements FlinkStreamSink<Row, Void>, FlinkBatchSink<Row, Void> {
+public class KafkaTable implements FlinkStreamSink<Row, Row>, FlinkBatchSink<Row, Row> {
 
     private Config config;
     private Properties kafkaParams = new Properties();
@@ -35,7 +35,7 @@ public class KafkaTable implements FlinkStreamSink<Row, Void>, FlinkBatchSink<Ro
 
 
     @Override
-    public DataStreamSink<Void> outputStream(FlinkEnvironment env, DataStream<Row> dataStream) {
+    public DataStreamSink<Row> outputStream(FlinkEnvironment env, DataStream<Row> dataStream) {
         StreamTableEnvironment tableEnvironment = env.getStreamTableEnvironment();
         Table table = tableEnvironment.fromDataStream(dataStream);
         TypeInformation<?>[] types = table.getSchema().getFieldTypes();
@@ -52,7 +52,7 @@ public DataStreamSink<Void> outputStream(FlinkEnvironment env, DataStream<Row> d
     }
 
     @Override
-    public DataSink<Void> outputBatch(FlinkEnvironment env, DataSet<Row> dataSet) {
+    public DataSink<Row> outputBatch(FlinkEnvironment env, DataSet<Row> dataSet) {
         BatchTableEnvironment tableEnvironment = env.getBatchTableEnvironment();
         Table table = tableEnvironment.fromDataSet(dataSet);
         TypeInformation<?>[] types = table.getSchema().getFieldTypes();

File: plugin-flink-source-file/src/main/java/io/github/interestinglab/waterdrop/flink/source/FileSource.java
Patch:
@@ -92,6 +92,7 @@ public void prepare() {
             case "text":
                 TextRowInputFormat textInputFormat = new TextRowInputFormat(filePath);
                 inputFormat = textInputFormat;
+                break;
             default:
                 break;
         }

File: plugin-flink-transform-datastream2table/src/main/java/io/github/interestinglab/waterdrop/flink/transform/DataSteamToTable.java
Patch:
@@ -23,13 +23,13 @@ public class DataSteamToTable implements FlinkStreamTransform<Row,Row>, FlinkBat
     @Override
     public DataStream<Row> processStream(FlinkEnvironment env, DataStream<Row> dataStream) {
         StreamTableEnvironment tableEnvironment = env.getStreamTableEnvironment();
-        tableEnvironment.registerDataStream(RESULT_TABLE_NAME,dataStream);
+        tableEnvironment.registerDataStream(config.getString(RESULT_TABLE_NAME),dataStream);
         return dataStream;
     }
 
     @Override
     public DataSet<Row> processBatch(FlinkEnvironment env, DataSet<Row> data) {
-        env.getBatchTableEnvironment().registerDataSet(RESULT_TABLE_NAME,data);
+        env.getBatchTableEnvironment().registerDataSet(config.getString(RESULT_TABLE_NAME),data);
         return data;
     }
 

File: common/src/main/java/io/github/interestinglab/waterdrop/common/config/TypesafeConfigUtils.java
Patch:
@@ -11,10 +11,11 @@ public class TypesafeConfigUtils {
 
     /**
      * Extract sub config with fixed prefix
+     *
      * @param source
      * @param prefix
      * @param keepPrefix
-     * */
+     */
     public static Config extractSubConfig(Config source, String prefix, boolean keepPrefix) {
 
         // use LinkedHashMap to keep insertion order
@@ -39,7 +40,7 @@ public static Config extractSubConfig(Config source, String prefix, boolean keep
 
     /**
      * Check if config with specific prefix exists
-     * */
+     */
     public static boolean hasSubConfig(Config source, String prefix) {
 
         boolean hasConfig = false;

File: waterdrop-apis/src/main/java/io/github/interestinglab/waterdrop/env/Execution.java
Patch:
@@ -8,6 +8,5 @@
 import java.util.List;
 
 public interface Execution<SR extends BaseSource, TF extends BaseTransform, SK extends BaseSink> extends Plugin {
-
     void start(List<SR> sources, List<TF> transforms, List<SK> sinks);
 }

File: waterdrop-apis/src/main/java/io/github/interestinglab/waterdrop/plugin/Plugin.java
Patch:
@@ -21,4 +21,5 @@ public interface Plugin extends Serializable {
     CheckResult checkConfig();
 
     void prepare();
+
 }

File: common/src/main/java/io/github/interestinglab/waterdrop/common/config/TypesafeConfigUtils.java
Patch:
@@ -11,10 +11,11 @@ public class TypesafeConfigUtils {
 
     /**
      * Extract sub config with fixed prefix
+     *
      * @param source
      * @param prefix
      * @param keepPrefix
-     * */
+     */
     public static Config extractSubConfig(Config source, String prefix, boolean keepPrefix) {
 
         // use LinkedHashMap to keep insertion order
@@ -39,7 +40,7 @@ public static Config extractSubConfig(Config source, String prefix, boolean keep
 
     /**
      * Check if config with specific prefix exists
-     * */
+     */
     public static boolean hasSubConfig(Config source, String prefix) {
 
         boolean hasConfig = false;

File: waterdrop-apis/src/main/java/io/github/interestinglab/waterdrop/env/Execution.java
Patch:
@@ -8,6 +8,5 @@
 import java.util.List;
 
 public interface Execution<SR extends BaseSource, TF extends BaseTransform, SK extends BaseSink> extends Plugin {
-
     void start(List<SR> sources, List<TF> transforms, List<SK> sinks);
 }

File: waterdrop-apis/src/main/java/io/github/interestinglab/waterdrop/plugin/Plugin.java
Patch:
@@ -21,4 +21,5 @@ public interface Plugin extends Serializable {
     CheckResult checkConfig();
 
     void prepare();
+
 }

File: plugin-flink-sink-elasticsearch/src/main/java/io/github/interestinglab/waterdrop/flink/sink/Elasticsearch.java
Patch:
@@ -48,7 +48,7 @@ public CheckResult checkConfig() {
 
     @Override
     public void prepare() {
-        Config defaultConfig = ConfigFactory.parseMap(new HashMap<String, String>() {
+        Config defaultConfig = ConfigFactory.parseMap(new HashMap<String, String>(2) {
             {
                 put("index", "waterdrop");
                 put("index_type", "log");

File: plugin-flink-sink-elasticsearch/src/main/java/io/github/interestinglab/waterdrop/flink/sink/ElasticsearchOutputFormat.java
Patch:
@@ -23,7 +23,7 @@ public class ElasticsearchOutputFormat<T> extends RichOutputFormat<T> {
 
     private Config config;
 
-    private final static String prefix = "";
+    private final static String PREFIX = "";
 
     private final ElasticsearchSinkFunction<T> elasticsearchSinkFunction;
 
@@ -44,8 +44,8 @@ public void configure(Configuration configuration) {
         config.entrySet().forEach(entry -> {
             String key = entry.getKey();
             Object value = entry.getValue().unwrapped();
-            if (key.startsWith(prefix)) {
-                settings.put(key.substring(prefix.length()), value.toString());
+            if (key.startsWith(PREFIX)) {
+                settings.put(key.substring(PREFIX.length()), value.toString());
             }
         });
 

File: common/src/main/java/io/github/interestinglab/waterdrop/common/config/TypesafeConfigUtils.java
Patch:
@@ -11,10 +11,11 @@ public class TypesafeConfigUtils {
 
     /**
      * Extract sub config with fixed prefix
+     *
      * @param source
      * @param prefix
      * @param keepPrefix
-     * */
+     */
     public static Config extractSubConfig(Config source, String prefix, boolean keepPrefix) {
 
         // use LinkedHashMap to keep insertion order
@@ -39,7 +40,7 @@ public static Config extractSubConfig(Config source, String prefix, boolean keep
 
     /**
      * Check if config with specific prefix exists
-     * */
+     */
     public static boolean hasSubConfig(Config source, String prefix) {
 
         boolean hasConfig = false;

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ExposeSparkConf.java
Patch:
@@ -16,7 +16,7 @@ public static void main(String[] args) throws Exception {
                 .resolveWith(ConfigFactory.systemProperties(), ConfigResolveOptions.defaults().setAllowUnresolved(true));
 
         StringBuilder stringBuilder = new StringBuilder();
-        for (Map.Entry<String, ConfigValue> entry: appConfig.getConfig("spark").entrySet()) {
+        for (Map.Entry<String, ConfigValue> entry: appConfig.getConfig("env").entrySet()) {
             String conf = String.format(" --conf \"%s=%s\" ", entry.getKey(), entry.getValue().unwrapped());
             stringBuilder.append(conf);
         }

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/FlinkEnvironment.java
Patch:
@@ -68,7 +68,7 @@ public void prepare() {
     @Override
     public void prepare(boolean isStreaming) {
         if (isStreaming) {
-            createEnvironment();
+            createStreamEnvironment();
             createStreamTableEnvironment();
         } else {
             createBatchTableEnvironment();
@@ -98,9 +98,8 @@ private void createStreamTableEnvironment() {
         }
     }
 
-    private void createEnvironment() {
+    private void createStreamEnvironment() {
         environment = StreamExecutionEnvironment.getExecutionEnvironment();
-
         setTimeCharacteristic();
 
         setCheckpoint();

File: plugin-flink-source-jdbc/src/main/java/io/github/interestinglab/waterdrop/flink/source/JdbcSource.java
Patch:
@@ -5,7 +5,6 @@
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSource;
 import io.github.interestinglab.waterdrop.common.config.CheckResult;
-import org.apache.commons.lang3.StringUtils;
 import org.apache.flink.api.common.typeinfo.SqlTimeTypeInfo;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.java.DataSet;

File: plugin-flink-transform-datastream2table/src/main/java/io/github/interestinglab/waterdrop/flink/transform/DataSteamToTable.java
Patch:
@@ -6,7 +6,6 @@
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchTransform;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamTransform;
 import io.github.interestinglab.waterdrop.common.config.CheckResult;
-import org.apache.commons.lang3.StringUtils;
 import org.apache.flink.api.java.DataSet;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.table.api.java.StreamTableEnvironment;

File: plugin-flink-transform-sql/src/main/java/io/github/interestinglab/waterdrop/flink/transform/Sql.java
Patch:
@@ -7,7 +7,6 @@
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamTransform;
 import io.github.interestinglab.waterdrop.flink.util.TableUtil;
 import io.github.interestinglab.waterdrop.common.config.CheckResult;
-import org.apache.commons.lang3.StringUtils;
 import org.apache.flink.api.java.DataSet;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.table.api.Table;

File: plugin-flink-transform-table2datasteam/src/main/java/io/github/interestinglab/waterdrop/flink/transform/TableToDataStream.java
Patch:
@@ -7,7 +7,6 @@
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamTransform;
 import io.github.interestinglab.waterdrop.flink.util.TableUtil;
 import io.github.interestinglab.waterdrop.common.config.CheckResult;
-import org.apache.commons.lang3.StringUtils;
 import org.apache.flink.api.java.DataSet;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.table.api.Table;

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/utils/AsciiArtUtils.java
Patch:
@@ -3,7 +3,7 @@
 import java.awt.*;
 import java.awt.image.BufferedImage;
 
-public class AsciiArt {
+public class AsciiArtUtils {
 
     /**
      * Print ASCII art of string

File: plugin-flink-sink-file/src/main/java/io/github/interestinglab/waterdrop/flink/sink/FileSink.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSink;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamSink;

File: plugin-flink-sink-jdbc/src/main/java/io/github/interestinglab/waterdrop/flink/sink/JdbcSink.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSink;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamSink;

File: plugin-flink-source-fake/src/main/java/io/github/interestinglab/waterdrop/flink/source/FakeSource.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.source;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamSource;
 import io.github.interestinglab.waterdrop.plugin.CheckResult;

File: plugin-flink-source-file/src/main/java/io/github/interestinglab/waterdrop/flink/source/FileSource.java
Patch:
@@ -1,7 +1,7 @@
 package io.github.interestinglab.waterdrop.flink.source;
 
 import com.alibaba.fastjson.JSONObject;
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSource;
 import io.github.interestinglab.waterdrop.flink.util.SchemaUtil;

File: plugin-flink-source-jdbc/src/main/java/io/github/interestinglab/waterdrop/flink/source/JdbcSource.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.source;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchSource;
 import io.github.interestinglab.waterdrop.plugin.CheckResult;

File: plugin-flink-source-jdbc/src/main/java/io/github/interestinglab/waterdrop/flink/source/JdbcSourceV2.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.source;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamSource;
 import io.github.interestinglab.waterdrop.plugin.CheckResult;

File: plugin-flink-source-kafka/src/main/java/io/github/interestinglab/waterdrop/flink/source/KafkaTableStream.java
Patch:
@@ -101,7 +101,7 @@ private Kafka getKafkaConnect(){
 
     private FormatDescriptor setFormat(){
         try {
-            return SchemaUtil.setFormat(format,config);
+            return SchemaUtil.setFormat(format, config);
         } catch (Exception e) {
             e.printStackTrace();
         }

File: plugin-flink-transform-datastream2table/src/main/java/io/github/interestinglab/waterdrop/flink/transform/DataSteamToTable.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.transform;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchTransform;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamTransform;

File: plugin-flink-transform-sql/src/main/java/io/github/interestinglab/waterdrop/flink/transform/Sql.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.transform;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchTransform;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamTransform;

File: plugin-flink-transform-table2datasteam/src/main/java/io/github/interestinglab/waterdrop/flink/transform/TableToDataStream.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.transform;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.batch.FlinkBatchTransform;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamTransform;

File: waterdrop-apis/src/main/java/io/github/interestinglab/waterdrop/env/RuntimeEnv.java
Patch:
@@ -11,4 +11,5 @@
  */
 public interface RuntimeEnv extends Plugin {
 
+    void prepare(boolean isStreaming);
 }

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/batch/FlinkBatchExecution.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.batch;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.env.Execution;
 import io.github.interestinglab.waterdrop.flink.FlinkEnvironment;
 import io.github.interestinglab.waterdrop.flink.util.TableUtil;

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/util/EnvironmentUtil.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.util;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.plugin.CheckResult;
 import org.apache.flink.api.common.restartstrategy.RestartStrategies;
 import org.apache.flink.api.common.time.Time;

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/util/SchemaUtil.java
Patch:
@@ -2,8 +2,8 @@
 
 import com.alibaba.fastjson.JSONArray;
 import com.alibaba.fastjson.JSONObject;
-import com.typesafe.config.Config;
-import com.typesafe.config.ConfigValue;
+import com.typesafe.config.waterdrop.Config;
+import com.typesafe.config.waterdrop.ConfigValue;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.api.java.typeutils.ObjectArrayTypeInfo;
 import org.apache.flink.api.java.typeutils.RowTypeInfo;

File: common/src/main/java/io/github/interestinglab/waterdrop/common/PropertiesUtil.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.common;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 
 import java.util.Properties;
 

File: common/src/main/java/io/github/interestinglab/waterdrop/common/config/TypesafeConfigUtils.java
Patch:
@@ -1,8 +1,8 @@
 package io.github.interestinglab.waterdrop.common.config;
 
-import com.typesafe.config.Config;
-import com.typesafe.config.ConfigFactory;
-import com.typesafe.config.ConfigValue;
+import com.typesafe.config.waterdrop.Config;
+import com.typesafe.config.waterdrop.ConfigFactory;
+import com.typesafe.config.waterdrop.ConfigValue;
 
 import java.util.LinkedHashMap;
 import java.util.Map;

File: plugin-flink-sink-console/src/main/java/io/github/interestinglab/waterdrop/flink/sink/ConsoleSink.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamEnvironment;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamSink;
 import io.github.interestinglab.waterdrop.plugin.CheckResult;

File: plugin-flink-sink-kafka/src/main/java/io/github/interestinglab/waterdrop/flink/sink/KafkaTable.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.sink;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.common.PropertiesUtil;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamEnvironment;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamSink;

File: plugin-flink-source-kafka/src/main/java/io/github/interestinglab/waterdrop/flink/source/KafkaTableStream.java
Patch:
@@ -2,7 +2,7 @@
 
 import com.alibaba.fastjson.JSONArray;
 import com.alibaba.fastjson.JSONObject;
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.common.PropertiesUtil;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamEnvironment;
 import io.github.interestinglab.waterdrop.flink.stream.FlinkStreamSource;

File: waterdrop-apis/src/main/java/io/github/interestinglab/waterdrop/plugin/Plugin.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.plugin;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 
 import java.io.Serializable;
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigParser.java
Patch:
@@ -1,8 +1,8 @@
 package io.github.interestinglab.waterdrop.config;
 
 
-import com.typesafe.config.Config;
-import com.typesafe.config.ConfigFactory;
+import com.typesafe.config.waterdrop.Config;
+import com.typesafe.config.waterdrop.ConfigFactory;
 import io.github.interestinglab.waterdrop.apis.BaseSink;
 import io.github.interestinglab.waterdrop.apis.BaseSource;
 import io.github.interestinglab.waterdrop.apis.BaseTransform;

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/batch/FlinkBatchEnvironment.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.batch;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.env.RuntimeEnv;
 import io.github.interestinglab.waterdrop.plugin.CheckResult;
 import org.apache.flink.api.java.ExecutionEnvironment;

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/AbstractFlinkStreamTransform.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.stream;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.apis.BaseTransform;
 import org.apache.flink.streaming.api.datastream.DataStream;
 

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/BaseInternalFlinkStreamSource.java
Patch:
@@ -1,6 +1,7 @@
 package io.github.interestinglab.waterdrop.flink.stream;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
+
 
 /**
  * @author mr_xiong

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/FlinkStreamEnvironment.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.stream;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.env.RuntimeEnv;
 import io.github.interestinglab.waterdrop.plugin.CheckResult;
 import org.apache.flink.streaming.api.TimeCharacteristic;

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/FlinkStreamExecution.java
Patch:
@@ -1,6 +1,6 @@
 package io.github.interestinglab.waterdrop.flink.stream;
 
-import com.typesafe.config.Config;
+import com.typesafe.config.waterdrop.Config;
 import io.github.interestinglab.waterdrop.env.Execution;
 import io.github.interestinglab.waterdrop.plugin.CheckResult;
 import org.apache.flink.streaming.api.datastream.DataStream;

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigParser.java
Patch:
@@ -56,7 +56,6 @@ public ConfigParser(File file) {
     public void parse() throws ConfigErrorException {
 
         logger.info("Parsing Config: \n" + config.root().render());
-        System.out.print(config);
         if (config.getConfig("base").hasPath("engine")) {
             String engine = config.getString("base.engine");
             switch (engine) {

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/Application.java
Patch:
@@ -19,7 +19,7 @@
  */
 public class Application {
 
-    public static void main(String[] args) throws ConfigParser.ConfigError {
+    public static void main(String[] args) throws ConfigParser.ConfigErrorException {
 
         File file = new File(args[0]);
 

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/BaseInternalFlinkStreamSource.java
Patch:
@@ -7,7 +7,7 @@
  * @date 2019-05-31 17:07
  * @description
  */
-public abstract class InternalFlinkStreamSource<T> implements FlinkStreamSource<T> {
+public abstract class BaseInternalFlinkStreamSource<T> implements FlinkStreamSource<T> {
 
     protected Config config;
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/Application.java
Patch:
@@ -19,7 +19,7 @@
  */
 public class Application {
 
-    public static void main(String[] args) throws ConfigParser.ConfigError {
+    public static void main(String[] args) throws ConfigParser.ConfigErrorException {
 
         File file = new File(args[0]);
 

File: waterdrop-flink-api/src/main/java/io/github/interestinglab/waterdrop/flink/stream/BaseInternalFlinkStreamSource.java
Patch:
@@ -7,7 +7,7 @@
  * @date 2019-05-31 17:07
  * @description
  */
-public abstract class InternalFlinkStreamSource<T> implements FlinkStreamSource<T> {
+public abstract class BaseInternalFlinkStreamSource<T> implements FlinkStreamSource<T> {
 
     protected Config config;
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/utils/JdbcConnectionPoll.java
Patch:
@@ -13,10 +13,10 @@ public class JdbcConnectionPoll implements Serializable {
 
     private static JdbcConnectionPoll poll;
 
-    private static DruidDataSource DS;
+    private  DruidDataSource dataSource;
 
     private JdbcConnectionPoll(Properties properties) throws Exception {
-        DS = (DruidDataSource) DruidDataSourceFactory.createDataSource(properties);
+        dataSource = (DruidDataSource) DruidDataSourceFactory.createDataSource(properties);
     }
 
     public static JdbcConnectionPoll getPoll(Properties properties) throws Exception {
@@ -32,7 +32,7 @@ public static JdbcConnectionPoll getPoll(Properties properties) throws Exception
 
     public Connection getConnection() throws SQLException {
 
-       return DS.getConnection();
+       return dataSource.getConnection();
     }
 
 }

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/entity/OpentsdbCallBack.java
Patch:
@@ -14,12 +14,12 @@ public class OpentsdbCallBack implements FutureCallback<HttpResponse> {
 
     private String postBody = "";
 
+    private static Logger logger = LoggerFactory.getLogger(OpentsdbCallBack.class);
+
     public OpentsdbCallBack(String postBody) {
         this.postBody = postBody;
     }
 
-    private static Logger logger = LoggerFactory.getLogger(OpentsdbCallBack.class);
-
     public void completed(HttpResponse response) {
 
         int status = response.getStatusLine().getStatusCode();
@@ -33,7 +33,7 @@ public void completed(HttpResponse response) {
     }
 
     public void cancelled() {
-
+        logger.info("Send to Opentsdb cancelled");
     }
 
     public void failed(Exception e) {

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/utils/HttpClientFactory.java
Patch:
@@ -7,13 +7,13 @@
 public class HttpClientFactory {
  
 	private static HttpAsyncClient httpAsyncClient = new HttpAsyncClient();
- 
+
+	private static HttpClientFactory httpClientFactory = new HttpClientFactory();
  
 	private HttpClientFactory() {
 	}
  
-	private static HttpClientFactory httpClientFactory = new HttpClientFactory();
- 
+
 	public static HttpClientFactory getInstance() {
  
 		return httpClientFactory;

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigCommand.java
Patch:
@@ -10,7 +10,6 @@
 import io.github.interestinglab.waterdrop.configparser.ConfigVisitor;
 
 /**
- * Created by gaoyingju on 11/09/2017.
  */
 public class ConfigCommand {
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigRuntimeException.java
Patch:
@@ -1,7 +1,6 @@
 package io.github.interestinglab.waterdrop.config;
 
 /**
- * Created by gaoyingju on 18/09/2017.
  */
 public class ConfigRuntimeException extends RuntimeException {
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigVisitorImpl.java
Patch:
@@ -18,7 +18,6 @@
 // TODO: visit if_statement
 
 /**
- * Created by gaoyingju on 11/09/2017.
  */
 public class ConfigVisitorImpl extends ConfigBaseVisitor<Config> {
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigCommand.java
Patch:
@@ -10,7 +10,6 @@
 import io.github.interestinglab.waterdrop.configparser.ConfigVisitor;
 
 /**
- * Created by gaoyingju on 11/09/2017.
  */
 public class ConfigCommand {
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigRuntimeException.java
Patch:
@@ -1,7 +1,6 @@
 package io.github.interestinglab.waterdrop.config;
 
 /**
- * Created by gaoyingju on 18/09/2017.
  */
 public class ConfigRuntimeException extends RuntimeException {
 

File: waterdrop-core/src/main/java/io/github/interestinglab/waterdrop/config/ConfigVisitorImpl.java
Patch:
@@ -18,7 +18,6 @@
 // TODO: visit if_statement
 
 /**
- * Created by gaoyingju on 11/09/2017.
  */
 public class ConfigVisitorImpl extends ConfigBaseVisitor<Config> {
 

File: src/main/java/org/interestinglab/waterdrop/docutils/PluginDocMarkdownRender.java
Patch:
@@ -40,6 +40,7 @@ public int compare(PluginDoc.PluginOption o1, PluginDoc.PluginOption o2) {
 
         // append markdown table
         str.append("| name | type | required | default value |\n");
+        str.append("| --- | --- | --- | --- |\n");
         for (PluginDoc.PluginOption option : pluginDoc.getPluginOptions()) {
             str.append(String.format("| %s | %s | %s | %s |\n",
                     option.getOptionName(), option.getOptionType(), option.isRequired(), "null"));

File: src/main/java/org/interestinglab/waterdrop/config/ConfigVisitorImpl.java
Patch:
@@ -130,6 +130,8 @@ public Config visitPlugin(ConfigParser.PluginContext ctx) {
                 final Config entries = visit(ctx.entries());
                 if (entries != null && ! entries.isEmpty()) {
                     plugin = plugin.withValue("entries", entries.root());
+                } else {
+                    plugin = plugin.withValue("entries", ConfigFactory.empty().root());
                 }
             }
         }

